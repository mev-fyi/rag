00:00:00.410 - 00:00:22.890, Speaker A: Returning to the stage to discuss horizontal scaling, please welcome Avi Zerlo, chief product officer at Nil foundation. Okay, we're good. Welcome everyone. Thanks again. You probably know me by now. This is my third time on stage and thankfully my last. I'm Avi.
00:00:22.890 - 00:01:09.700, Speaker A: I'm the chief product officer at Nation. Today I'm going to be talking about horizontal scaling for Ethereum and pretty much laying the foundation for the motivation of what we're doing at nil this year. And by the end of this presentation, hopefully you get an understanding of why we're doing it. So we're talking about scaling for Ethereum. So the natural starting point here is Ethereum's rollup centric roadmap, right? And after spending a lot of resources researching execution sharding, Ethereum opted for a roll up centric roadmap. And this has served the needs for users and developers quite well. Roll ups have done well.
00:01:09.700 - 00:02:03.460, Speaker A: Transaction costs are about an order of magnitude cheaper on layer two s today than they are on l one. They're faster transaction times in a practical setting, thanks to the soft finality guarantees that a roll up can offer end users. I know this says okay job, but they've actually done a very good job at rolling out pretty much state of the art cryptography and proof mechanisms to maintain security of these systems. And by the grace of l two beat and together, the Ethereum l two ecosystem has become home for application design innovation. But l two s are not necessarily perfect. They have problems of their own. First, transaction fees are still too high, and there's going to be quite a few memes, so bear with me.
00:02:03.460 - 00:03:58.940, Speaker A: High load and price sensitive applications are not viable on general purpose roll ups today. And while people often think about lower transaction fees as sort of a terminal value for end users, which is absolutely true, they're also incredibly important for moving more computation and data processing onto trustless systems, and these ultimately lead to more robust systems. Second, we have a bit of a paradox in that Ethereum, a maximally decentralized, censorship resistant permissionless blockchain, which has spearheaded those values across crypto for years, has effectively opted for roll up architectures that run under single operator models. And while many roll ups are working towards promoting these values, these core values, from a community perspective, frankly fewer are actually substantiating that with engineering and design decisions. And without the engineering to substantiate it, l two s potentially pose a risk to compromising these values for Ethereum at large. Third, we live in a world of overabundance, which is ironic because I'm up here about to tell you about another layer two, but there is so many choices for an application developer to make before simply deploying their application. And this in of itself has become a problem and in modularity in spirit was supposed to simplify the developer experience, and instead we've overcomplicated it with a number of decisions that a developer needs to make before even getting to their application.
00:03:58.940 - 00:05:20.770, Speaker A: And finally, and most importantly, and this is a problem many of you have probably heard already, but l two s, metaphorically speaking, are bleeding out over this state fragmentation problem. And this is where I'm going to focus the talk today. So if we look closely at the consequences of state fragmentation, which again may be redundant for some of you, but it compromises the network effects of global state. And this is in terms of liquidity, user distribution and mindshare, who's focused on building on a global notion of state. We have compounding complexity of interoperability standards, and this is for heterogeneous interoperability and homogeneous in terms of execution environments. And we have this huge global coordination problem that we actually have to come to an agreement on what are the standards if we want interoperability between these roll ups across thousands of stakeholders. And at the end of the day, it's just we objectively have a worse developer and user experience, and we're talking about Ethereum scaling here.
00:05:20.770 - 00:06:48.750, Speaker A: But I think there's a lot to be learned from this sort of monolithic, integrated l ones in delivering a really seamless, pleasant, easy to use experience for developers who are just looking to deploy an application on trustless infrastructure. And unfortunately, these problems are getting worse by the day. So, limited by existing infrastructure, price sensitive applications, typically high load applications, are forced onto app specific infrastructure. And as we head into this next cycle, which is hopefully here to stay, congestion fees are only going to go up, which is only going to force more applications onto their own app specific infrastructure, which is only going to make this state fragmentation problem more pervasive. And so all things considered here, I think we really need to ask ourselves what is going on with state fragmentation? How have we ended up here? And to revisit our Monty Python meme from just a few moments ago, state fragmentation has fundamentally been miscategorized as an interoperability problem. It's not an interoperability problem, it is a scaling problem. The more scalable a layer two can be, the less state fragmentation you impose on the ecosystem.
00:06:48.750 - 00:08:13.660, Speaker A: And this is sort of our starting insight at nil. So what do we do? Well, we scale and there are two primary frameworks that you can adopt to scale a blockchain or any database, or any data intensive application for that matter. One is to vertically scale, and this is effectively boosting the hardware utilization or the hardware requirements that a given node actually runs on. And we can think of paralyzed virtual machines or introducing sort of more powerful hardware to that node as sort of under this vertical scaling framework. The second option, which I think everybody who was here earlier today for the future of rollups panel heard people talk about, is horizontal scaling. And horizontal scaling gives this really nice property of being able to simply add nodes, add a new machines to the system, distribute the load over those nodes, and effectively increase the scale of the system of interest. And this is most commonly done in traditional systems with sharding, and there's actually a few examples of it in blockchains as well.
00:08:13.660 - 00:09:19.150, Speaker A: To dig a little bit deeper into what are some of the trade offs of either approach. Vertical scaling is a pretty easy fix in that you can very quickly upgrade and boost the hardware of a given system by simply purchasing a new piece of hardware. It scales with the hardware, which has followed Moore's law for a number of years, and it's relatively easy to upgrade in a permissioned setting. The trade off is that you're actually limited by hardware, or rather you're limited by the capacity of a single piece of hardware. And in sort of distributed systems, this typically trends towards centralization, right, because you have higher hardware requirements. Alternatively, you can scale with horizontal scaling, and this has a great benefit of keeping hardware requirements relatively low. And thus you're able to promote decentralization in these distributed systems.
00:09:19.150 - 00:09:53.894, Speaker A: You have actually higher theoretical scaling limits. And just intuitively, you can think of two of the world's most powerful computers if they're not even operating at full capacity. Those two working together are more powerful than a single one. And it actually still allows for vertical optimizations to take place. Right, for paralyzed virtual machines, or increasing the hardware requirements where necessary. And the big trade off is complexity. These horizontally scalable solutions are quite complex.
00:09:53.894 - 00:11:18.910, Speaker A: There's networking overheads you have to solve for data validity, which is a big open problem for blockchains, and you have to bootstrap a network of nodes, which is typically more expensive. And so when we come back to this roll up centric sort of view with these scaling frameworks in mind, and I recognize this may be a little controversial, but roll ups haven't really scaled in that they haven't taken advantage of vertical scaling techniques yet. And there are a few teams that I think I'll mention later on in a few slides that are actually implementing things like paralyzed virtual machines and taking advantage of more powerful hardware. And when we consider that all blockchains are sort of defined by the ledger that they maintain, and that today a smart contract deployed on a roll up can arbitrarily call another smart contract on a different roll up. Unequivocally. Roll ups do not horizontally scale, and this is sort of a current view of the landscape, but there are obviously solutions. Sorry.
00:11:18.910 - 00:12:13.560, Speaker A: So there's two starting points. We can take existing roll ups and merge them into a single system. And there's a lot of work being done towards these efforts. And I think this slide is probably, there's too small, you may not be able to read, but. Okay, I'm losing my notes. But in essence, these solutions introduce a middle layer to what are existing roll up execution environments. And this middle layer offers some sort of shared consensus guarantee that effectively allows you to facilitate cross roll up communication.
00:12:13.560 - 00:13:29.792, Speaker A: And broadly speaking, if we can pull this off and we can identify interoperability standards to actually allow certain message passing through these roll up nodes, then we effectively have horizontal scalability. Right. And again, I'm drastically oversimplifying how complicated these solutions are. I definitely don't want to take away of the work that's being put into them, but they do generally follow this architecture and they don't come without trade offs. So first, all of these systems, because they're essentially relying on this middle layer for some sort of consensus guarantee, which is effectively soft finality, you have this weakest chain vulnerability in that these middle layers aren't actually checking the data execution or the validity of data execution. And this is primarily today a function of we don't have real time zero knowledge proofs. In a world where we have real time zero knowledge proofs, we can generate those proofs in parallel along the side of the computation, and then very quickly send it to whatever this middle layer is.
00:13:29.792 - 00:14:49.150, Speaker A: And this middle layer can check whether or not a roll up node was executed, executed their transactions properly, or sequences their transactions properly, or they're not withholding data, et cetera. But today we do not have this, right. So what ends up happening is you have these permissioned sets, you have to permission these sets, these middle layers to roll up nodes that you can trust. Second, we still haven't fundamentally solved anything at the developer interface level, right? These middle layers are essentially glue that sit behind these developer environments, these execution environments. They sit behind where liquidity lives, they sit behind where user addresses live, they sit behind where actually developers deploy their smart contracts. And so we still have this sort of very fragmented developer interface. And then third, and I mentioned this a little bit earlier, but this is truly, maybe it's not necessarily an engineering challenge as much as it is a social challenge, in that we have thousands of stakeholders who have their own set of incentives who are trying to decide on what these interoperability standards will be.
00:14:49.150 - 00:16:40.640, Speaker A: And this starts at the very low level of what does the actual transaction formatting need to be in order to enable this cross chain messaging to how do we streamline roll up node upgrades such that whenever a roll up upgrades their node, that everybody else within this system is aware of the upgrade and the implications that it has? And so all that being said, what might it look like if we actually started from, started fresh? What if we started from sort of very first principles approached of how do we enable more scale for layer twos? And we can revisit our friendly little diagram here where there's two frameworks to do this, vertical or horizontal scaling. And I think there's a shout out here to eclipse and movement labs who are introducing paralyzed virtual machines that allow for vertical scaling to take place at the l two. And they're likely to hold very significant performance improvements for l two s that implement these virtual machines. But as we sort of mentioned before about sort of the benefits of horizontal versus vertical scaling, there's actually some really interesting properties that we would want at the l two that horizontal scaling gives us. And this is essentially why, coming to what we're doing at nil, this is how we came to Zk sharding, right? And Zk sharding is approvable sharding architecture. It brings the power of thousands of roll ups to a single unified layer two and developer environment. And this helps us promote decentralization.
00:16:40.640 - 00:17:29.680, Speaker A: It is a network, it's not a single operator l two. We have much higher scaling limits than any single operator roll up model. And it still allows us to explore things like paralyzed virtual machines, right. And to push vertical optimizations where necessary. And cool thing we got going on is essentially a mullet, right? We have this integrated front end where for a developer you simply deploy a smart contract to nil. You don't have to think about internalizing any sort of application specific infrastructure. You don't have to worry about congestion fees because we handle all of the complexity of horizontal scalability in protocol.
00:17:29.680 - 00:18:33.750, Speaker A: And on the back end we utilize ethereum for verifying correct state transitions at the local and global level. And we use it for data availability of our consensus shard. We also have sort of a fancy sharding algorithm, dynamic sharding. And this allows us to allocate resources, network resources, to in demand pieces of state, right. And essentially splitting and merging shards based on the load that they're receiving for any particular piece of state. And no shade at local fee markets, because those are great. And finally, and maybe most importantly, nil structurally allows for us to substantiate sort of our community values of decentralization, censorship, resistance, permissionlessness with engineering and design.
00:18:33.750 - 00:18:58.188, Speaker A: And ultimately, we believe that these values are imperative for any l two. That's going to last for decades to come. We're also very committed to the EVM. And I know there's been a lot of talk as of late about alternative virtual machines. And as I mentioned, there's some really great teams that are working on that. But the EVM works just fine. It is a fully turing complete instruction set.
00:18:58.188 - 00:19:51.864, Speaker A: It does everything you would want it to do. It's just been moving quite slow. And we're very committed, I think, along with many other l two s, to improving the EVM. Right, enabling paralyzed virtual machines, adding opcodes and support for additional curves, or allowing for, in our case, async communication across two different EVM state machines. And with that, I've got 20 seconds left. I'm sure you have many questions, or maybe you don't, but either way, go check out what Misha, our CEO, and Elia is going to share in our workshop sort of coworking space in the back. We're going to be diving a little bit deeper into sort of the architecture of ZK sharding.
00:19:51.864 - 00:20:03.930, Speaker A: We also have a new spec, which we released our initial spec in November. We have a new one coming out in the coming days. And that is all. Thank you.

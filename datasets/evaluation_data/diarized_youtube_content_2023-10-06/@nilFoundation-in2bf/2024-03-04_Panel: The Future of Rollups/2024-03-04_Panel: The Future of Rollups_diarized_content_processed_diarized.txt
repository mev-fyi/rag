00:00:00.570 - 00:00:25.230, Speaker A: Now for the first panel at scale summit, let's explore the future of roll ups. Please welcome Misha Kamarov of Nil Foundation, Brendan Farmer of Polygon, Luis Guthman of Starkware, and Alex Glukowski from Matter Labs. Moderating this discussion is Jan Han Li, principal at Blockchain Capital. Please welcome them to the stage.
00:01:02.110 - 00:01:02.570, Speaker B: Hello.
00:01:02.640 - 00:01:26.834, Speaker C: Hello. Hope everyone's doing well today. Thank you for being here. I think. Why don't we start off with a round of introductions. I think you can tell the audience a little bit about yourselves, what you're working on, the role of contributing to. Yeah, I think.
00:01:26.834 - 00:01:28.498, Speaker C: Alex, do you want to start us off?
00:01:28.584 - 00:01:54.646, Speaker A: Happy to start. My name is Alex Kuchowski. I'm co founder and CEO of Matterlabs, the company behind Ziki Sync, the creators of Ziki sync. And how many of you guys know Ziki sync? Can you raise your hand so everyone knows? I'm flattered. We are a mission driven project. We want to advance freedom for humanity and we believe that blockchains are the best way to do it. And we are operating starting from these principles.
00:01:54.646 - 00:02:01.790, Speaker A: And we are currently the most popular by volume roll up on Ethereum overall.
00:02:03.410 - 00:02:24.450, Speaker D: I can do an introduction for Brendan because he drank something which made him transparent, mean. This is like. He looks like this today. Whatever. Let's go forward. I'm Misha. I'm bringing coffee at nil.
00:02:24.450 - 00:02:53.200, Speaker D: Just doing stuff at right. So nil like since November of last year, kind know got to that point when we feel confident we can bring long promised sharding to Ethereum back without upgrading Ethereum. We call this thing GK sharding. So that's the thing. We try to prevent liquidity fragmentation and state fragmentation effectively of ETH. We try to prevent Ethereum state Balkanization. That's what we do.
00:02:55.810 - 00:03:41.190, Speaker B: Can you hear me? No. Thank you. Hi, so I'm Louis. I'm the head of strategy at Starquare, not the head of product. So Starquare, for those who don't know, is one of the leading VK company in the world. We invented some of the leading stack and technology that is powering the space at the moment. And we launched years ago and even more recently starknet, which is the first ZK rollab to come to production, and a ZK rollab that tends to focus towards performance and optimizing for new use cases.
00:03:41.190 - 00:03:59.730, Speaker B: And so what can I say more? We've seen coming out from the ecosystem, things like team building, DKML Advance, Oracle and all sort of new application or on chain gaming and so if you want to hear more, I'm happy to discuss it afterwards.
00:04:00.710 - 00:04:09.054, Speaker C: I think a great place to start today would just be talking about each of your visions for how you think we should scale blockchains.
00:04:09.102 - 00:04:09.374, Speaker D: Right.
00:04:09.432 - 00:04:32.010, Speaker C: I think everyone here who's used any app, on any blockchain realizes that we are not quite there yet in terms of UX and scalability. So I'm curious how you're all thinking about what the right way to scale blockchains, know, your vision for it and what you think some of the largest challenges we're still facing today. Hey Brendan.
00:04:41.390 - 00:05:02.120, Speaker E: Hey everyone. So in my defense, I was on a plane like 3 hours ago and I guess it was snowing in Denver. And so we were just circling for like an hour. I'm just like watching the clock and I'm knowing, I'm realizing that I'm going to be late to this panel. And so I apologize to everyone.
00:05:03.130 - 00:05:25.246, Speaker C: Didn't miss much. We were just running through introductions. But yeah, I think a great place to start would just be maybe you can introduce yourself and then talk a bit about what you think the right way to scale blockchains is. What's your vision for scalability long term, and what you think some of the largest challenges that remain unsolved today are?
00:05:25.428 - 00:06:15.526, Speaker E: Yeah, sure. So I'm Brendan, I work on ZK stuff at Polygon. I think probably like many of the people up here, I think that my vision for scaling blockchains is to scale them horizontally. So to allow a system to add block space to meet demand, like sort of without an upper bound, but to do so while maintaining unified liquidity. And basically, if you think about what we're trying to do and what we mean when we talk about scaling blockchains, it's scaling access to liquidity and shared state. And so we can add as much block space and as many empty chains that don't have any liquidity as we want. And we won't be succeeding in that mission.
00:06:15.526 - 00:06:24.430, Speaker E: And so I think scaling horizontally, but not giving up composability and unified liquidity in shirts.
00:06:26.450 - 00:06:28.834, Speaker C: Alex, do you want to go next?
00:06:28.952 - 00:07:07.998, Speaker A: Sure. I think we will all converge on this vision because that's the only thing that makes sense with advance of ZK. We want to preserve the properties that made blockchain valuable in the first place. We want to preserve decentralization, trustlessness, security against arbitrary powerful adversaries. And the only way to do it is to. And of course we want to preserve the usability. We want blockchains to be accessible by anyone that means if someone from one country, one place in the world has access to blockchain, they should be able to interact with anyone else.
00:07:07.998 - 00:07:40.226, Speaker A: So the future we envision at ZK sync is you have thousands of permissionless chains. Like anyone can launch a chain horizontally, sharded, meaning all of them are being processed in parallel, all of sequencing in parallel. They are modular. They have different approaches and different layers of the stack. Some of them are having centralized sequencers, some having decentralized sequencers with their own tokens or on community rules, et cetera. But they are all connected to each other. They can all interoperate.
00:07:40.226 - 00:08:43.754, Speaker A: Like a user of one chain does not need to breach funds on the other chain to be able to interact with some app or interact with the app chain. On application specific chain, you have your wallet, you have a magic experience of just like, do one click, see exactly what you're doing there, and interact with any user, any other chain, and within seconds, within some very short, negligible amount of time, you will get a result, and it feels seamless. No overhat in terms of capital, no overhat in terms of additional trust assumptions. I think that's the only vision. I would call it the ZK singularity, because all of those chains would have to interoperate through aggregating the proofs and eventually settling down on Ethereum. And then maybe we generate a proof for Ethereum block itself. And then you have your mobile phone with your wallet that verifies in under 1 second the state of the latest block on Ethereum, completely with all its transactions and with all the millions of transactions that happened on the thousands of chain there in a single ZK proof.
00:08:43.754 - 00:08:46.720, Speaker A: I think this is fascinating, and I'm really excited for this future.
00:08:49.760 - 00:09:30.650, Speaker D: This one doesn't work. All right. I think we all kind of agree on the way that it should be scaled horizontally. I mean, that's what everybody in here pushes, including me, I guess so. Literally everyone. I guess maybe we a little bit diverge on the ways we see this might be the best way to do this. On our side, for example, we kind of think that you got to go from the first principles, and you got to keep all those l two s, not just trying to keep them, trying to make them go together back again.
00:09:30.650 - 00:10:04.784, Speaker D: I don't know, just shared sequencers or something. Right? But you got to keep them together from the very beginning. You got to make things start at one place, you got to make things end at one place. But it shouldn't be, and it can be not enforced for things to be together in the middle of a process. So it's somehow similar to maybe like, I don't know, like a double map reducer or something. So that's the way and of mean, we do agree that it should be composable. We do agree that it should be like unified liquidity.
00:10:04.784 - 00:10:12.310, Speaker D: And that's just different approaches. ZK sharding also allows this. So that's the thing.
00:10:17.310 - 00:11:12.938, Speaker B: As everyone said, oriental execution, scaling. I just want to maybe add a couple of also granularity of what needs to be still solved and what is currently not solved. And hopefully we will get around this table to converge on solution, which is we've been talking about how ZK scale. But usually people don't really understand why Vkps tend to scale things. The reason why ZKP scales a execution environment is because it allows you to separate between a powerful adversary, the validators, the sequencers, and you end users validating on your phone. And when people, for instance, compare bitcoin to Ethereum, Solana, they don't compare the same thing. They always compare like Apple, orange and Ferrari, they are not comparing the same thing, because bitcoin's target machine is a raspberry PI.
00:11:12.938 - 00:12:13.838, Speaker B: Ethereum target machine is MacBook Pro 2021. And Solana basically requires you to have a $2,000 machine per month. And so if you want, where ZK comes to play, is allowing you validators, a set of validators to run data centers. And still you being able to check on them, to check their integrity and validate that they don't basically fuck with. And so the end game of this is also, as Alex said, a very iterogenous environment of execution, where you have single sequencer, we have decentralized sequencer, you have environment without fees, your environment with various mechanism for fees. And my end game of all the scaling looks is the following one. I always say the following thing, which is if blockchain is going to be the intent of money, then we're going to need web servers, web application capable of supporting native bridge, supporting what the wallet is, what an account is, what smart contract is, what an asset is, and at the same time run efficiently.
00:12:13.838 - 00:12:31.720, Speaker B: And the only way to get there is what I call Zika servers. At the end of the day, what we're going to look like, the intent will be running on a bunch of servers that would be just proving themselves to the blockchain to guarantee this noncustodity, this trustlessness of the web environment that we, the web of integrity that we wish for.
00:12:33.930 - 00:12:44.886, Speaker C: So I think something that would be great to discuss next. Right? I think broadly, all four of you, when you just spoke about your vision for how users should interact with blockchains.
00:12:44.918 - 00:12:45.818, Speaker E: In the future, right?
00:12:45.904 - 00:13:25.180, Speaker C: You all mentioned horizontal scalability as kind of the approach. I think all of you in each respective ecosystems call it something different, like Misha, you guys call it ZK. Sharding Koski, you guys call it hyperchains. Brendan, I believe you guys just released announced Ag layer. And Louis, you guys have talked about l three s for the longest time, right? I'm curious to everyone, you all use the word horizontal scalability as a way to solve kind of the state fragmentation problem in the future. What are some of the trade offs that you're thinking about as you think through all the different kind of approaches you can take to kind of arrive at this endgame, this vision that you guys are all working towards?
00:13:26.990 - 00:14:11.994, Speaker A: Really good question. I can share some challenges that we have with hyperchains, and I know that different teams are solving them in different ways. When you have fully sovereign independent chains connected in this ZK singularity network, they want to bridge from each other in a trustless way. Then to make the interaction truly trustless, you would have to wait for the proof of the other chain to actually settle. But that means you need to wait for. You have to allow for some latency of the proof generation on the other side. We want to bring this latency down to under 1 second.
00:14:11.994 - 00:15:07.050, Speaker A: And this is happening. You guys just announced a paper together, what's it called? 23 circular stocks, right? There are multivariate fields. There's a bunch of research going on that will bring, which will get us probably in order or more magnitude lower on proof generation costs and corresponding latency. But for now, we still have some latency, right? And so it's very tempting to do something like optimistic acceptance of transactions from other chains and say, like, okay, you have economic guarantees of validity on that chain, so we're going to optimistically accept it. You never can settle invalid state because you need to provide zero knowledge, proof of validity eventually. But it could lead to reorgs. And we know that reorgs are painful.
00:15:07.050 - 00:15:15.274, Speaker A: They are like a massive developer experience, friction point, and basically break projects.
00:15:15.402 - 00:15:16.800, Speaker D: If this happens a lot.
00:15:19.250 - 00:15:31.802, Speaker A: That would mean if you want this to operate efficiently and avoid reworks, all of those chains that participate in this fast, instant bridging network would have to be kind of coming out of one hand, be more centralized.
00:15:31.866 - 00:15:32.058, Speaker D: Right.
00:15:32.084 - 00:16:06.220, Speaker A: Which would be a painful trade off. So this is one interesting. I don't have an answer, what approach will win? We'll see, we'll experiment. But I have a preference for what I want to win. I want the sovereignty to win. I want everyone to be able to have full control, full ownership of their chain, and not depend on anyone else. And I really want us to avoid the situation where everyone is just using the same solution for whatever from the same two, three providers, which is like a potential future, which we could be ending up with.
00:16:09.630 - 00:16:10.620, Speaker B: Thank you.
00:16:11.070 - 00:18:11.590, Speaker E: Yeah, so I agree with that. I think that maybe we have different views on how you solve that trade off, but I think that it's actually even worse than what Alex is describing, because not only do you have to wait for proof to be generated, but you actually have to wait for the block verifying that proof to be finalized on Ethereum. And so your minimal latency in the fully trustless case is actually like twelve to 19 minutes. And so if we talk on the one hand about defragmenting liquidity and creating this composable environment, and on the other hand, we're talking about users having to wait twelve to 19 minutes to submit and confirm a cross chain transaction, that's not a very good or like a viable approach. And so that's the problem that we're trying to set out to solve with the AG layer, is like, how do we allow chains to navigate the trade offs that make sense for them between sort of like liveness guarantees and low latency while maintaining safety? You have this strong guarantee that's provided by zero knowledge proofs that when your batch as a chain is accepted by Ethereum, it is consistent with the whole universe of other chains in polygon. But I think one other problem that's really interesting is I think what Alex is describing is like a homogeneous environment for execution in sort of like a ZK constellation of chains. But I think it's really interesting to consider what is a heterogeneous execution environment look like, where one chain could be running like ZKVM, one chain could be running polygon, MIDN, one chain could be running some custom VM that's written in rust.
00:18:11.590 - 00:19:06.390, Speaker E: And fundamentally, how do we enable that without sacrificing safety? Because the problem with that view of the world is for every marginal virtual machine or execution environment that you add, you're assuming additional risk that there might be some soundness issue or some bug in that VM. And if you have this setup where all funds are pooled and you have unified liquidity, you're taking this extraordinary risk by admitting potentially less secure execution environments. And so for us, the AG layer is an attempt to offer a solution to both of these problems, is how do we do crosschain composability at super low latency, and how do we provide safety in an environment where we have unified liquidity, but we also have heterogeneous execution environments?
00:19:07.530 - 00:20:25.742, Speaker B: Interesting. So actually, I do have a bit of a counter angle from the perspective of the trade off, which is kind of like a callback to monolithic design, and not fully monolithic, but at least in some sense of this word, of where everyone launched its own chain is phenomenal for scaling, of course, but it does bring a lot of issues. One of them that was Brendan wrote, is what I type fragmentation, which what other people tend to call liquidity fragmentation. But more than that, there is also a huge ux issue coming from it. Because when you launch a new chain, then how do you get included into the block explorers, how do you get included into the wallets? The portfolio manager, how do you get included into all the stack of tools around the chain that makes the user experience of the user understandable, easy to use, and so on. And so while I do see a lot of benefits for this sort of vertical scale scaling through layering and through independent chain and cross chain communication, my end goal personally is to bring back a way to get this execution charting within the same environment than the base layer, the l two itself. And ZK can allow you to do that.
00:20:25.742 - 00:20:59.690, Speaker B: And one thing that hasn't been touched also right now that has been solved so far by ZK, is all the state issue we have, the question of data availability, the question of state proof, the question of state fragmentation. And so I think, at least on the startup front, one angle we're looking at is how can we use those very magical technology that is decay, to get all of those into this single synchronous environment and not losing all these infrastructure benefit that you want to have when you launch your chain that you might not have if you're a small player.
00:21:03.620 - 00:21:13.510, Speaker D: So you're effectively proposing just setting up like one c conserve for all the l three s. No, thank you. Thanks God.
00:21:16.360 - 00:21:34.110, Speaker B: What I'm suggesting is we can probably do better than just like layering, layering on top of layers and where you can have within the same synchronous environment, things happening independently in the style of Solana, but in a way that is much more trust minimized than what Solana does.
00:21:36.160 - 00:22:21.240, Speaker D: So it's mean. All right, so the trade off, I see trade offs. I mean, I kind of do stand closer to maybe the Lewis position in here, because you can't just layers upon layers upon layers upon layers, because that's what we tried to do and that's what led us to the position where we are. That's troublesome. So the trade off, for example, which you get when you try to apply the horizontal scaling, I mean, like just having shard after shard after shard, maybe like considering ETH is just one of the shards, right? I mean, it's effectively just one of the shards, right? So very expensive. Yes, but okay, whatever. So that's the thing.
00:22:21.240 - 00:22:57.140, Speaker D: And the trade off in that. Yes, there is a trade off that you got to prove all the shards to some kind of consensus shard eventually. Maybe. It cannot be like consensus shard and Eth can be like two different shards. I mean, you can prove just a consensus one and then prove one to EtH, which effectively turns into aggregation. So that's the thing. And with bootstrapping new shards, it kind of turns into something like, into something like just one more and one more and one more shard, which is at some point it will not be possible to figure out which one was the original eth.
00:22:57.140 - 00:23:31.680, Speaker D: It's going to be just a set of shards, and you will not be able to figure out which one was original eth. I mean, it's going to be just differentiation in costs, and you can submit, like, for example, transaction to any of them and get that executed on any of them. Troublesome. Several hops sequencing tricks operating with the original ETH directly might be a little bit expensive because you got to play by the rules, right? I mean, you can't break the rules. So these are the trade offs.
00:23:37.300 - 00:24:14.850, Speaker C: I think what's interesting is none of you mentioned the word atomicity. And so I think one thing that people, at least on Twitter, have been talking a lot about, and certain people at the ethereum foundation have been pushing. And some of the other, I think particularly the non Z cable ecosystems have been exploring, is our shared sequencers. Right. I think a lot of the conversation around that is how that enables atomicity. Seems like for all of you, you don't think that the trade offs that you get from getting atomicity are worth it, right? So I'm curious if you guys could talk a bit more about why that is.
00:24:15.220 - 00:25:08.976, Speaker E: I actually like atomicity quite a bit. One thing that's been sort of interesting for me to learn more about is this vision for shared sequencing and proposer builder separation. And so my naive view of shared sequencing was, oh, you have this consensus mechanism, and it accepts all of the transactions, and it orders them, and then it's forwarded on to approver, and it generates a proof. But actually, that's not the view. And the proposal for what shared sequencing is. Shared sequencing should be seen as basically granting the ability to propose blocks for chains at particular slots. And this is actually really interesting, because you can know ahead of time who the proposer for a particular block will be.
00:25:08.976 - 00:26:08.820, Speaker E: So who the sequencer will be, and so that proposer can coordinate with a block builder that can basically leverage all of the benefits of centralization. They can be in a data center, they can be super parallelized. They can be like a very professionalized and high throughput, high scale entity. And this allows us to offer atomic guarantees across a large number of chains, because you have a builder that can basically guarantee that transactions can execute successfully, and then that guarantee is obviously proven with a zero knowledge proof. To me, I think this gets a little bit at what Louis was talking about. It's sort of an interesting view of the world in that it allows us to preserve all the properties of decentralization that we like, while also leveraging centralization for much, much higher throughput.
00:26:10.600 - 00:26:51.884, Speaker A: I have a strong opinion, which would be unpopular. I think that you indeed get all the benefits of centralization because it's essentially a centralizing solution. So to me, multiple roll ups with shared validity sequencing are essentially one roll up with multiple shards. But if you want to do cross shard transactions and you want them to make them atomic, you have these cross logs. So you eventually reinvent something like Solana's approach to just like, let's give up decentralization. We have this one powerful sequencer, and we will be able to process more transactions than anything else. And this is a viable approach.
00:26:51.884 - 00:27:17.876, Speaker A: But if you want to go down this route, why build a Goldberg machine of decentralization theater of many chains? Just build one centralized, high throughput chain with validity proofs, with maybe some things that prevent censorship, with some timelong encryption. But don't play the theater, just say it straight out like we have a solution with all the benefits of centralization because it's a centralized solution.
00:27:17.988 - 00:28:43.700, Speaker E: No, I don't think that's an accurate view, because there is not like an enshrined operator of that chain. There is like a marketplace that's permissionless and where, hypothetically, rent seeking cannot occur. And so you do have this benefit of decentralization where you can't get capture and you can't have the enshrinement of a rent seeker or rent extractor, but at the same time, you don't need to deal with locks because you have a builder that's, that's actually executing transactions on all chains concurrently. And so, I mean, I, I think that we should ask like decentralization for what the goal of decentralization is not to like perpetually limit scale so that we have a ton of roll ups and we don't have atomicity. I think the point of decentralization is like an instrumental good to ensure that we always have market structures that respect users where rent seekers and monopolists cannot basically achieve a privileged position. For me, I think that there's a much broader design space than I think, sort of the stereotypical decentralized roll up with a sort of logically partitioned sequencer.
00:28:44.920 - 00:29:57.348, Speaker B: I tend to also disagree with you, Brendan, on this one, because you're saying that first of all, I do see a big issue of, in this shared sequencing environment, about the most popular staker, the richest staker, Lido, basically being basically in charge of having even more power because they would control most of the blocks, and therefore most of the other block of the other chain. Which means that that's a very concentrating force inside the system. When at least on Alex's point, at least enshrining this to the entire system makes more efficient, more fairer, I would say even a fairer approach to this shared sequencing. Shared environment. And what's baffled me so far, especially in the shared sequencing environment, is the claim, I keep saying, that also we're talking about multiple type of proof. And now he has a question of coordination of the system themselves. And finally, this is where it doesn't make sense to me, I have to admit, is in the case where you want sequential atomicity, it sensed to be for very time sensitive and operation.
00:29:57.348 - 00:30:27.620, Speaker B: Otherwise you can be asynchronous. Why do I care so much about being run in exactly one operation? Fail or succeed versus withdraw and have a continuation from there. And that place only makes most sense in defi kind of operation or financial operation. And then where's the UX of it? How does it work from the user's perspective? How do I make sure that my transaction will get me front run mvv, whatever in this environment by this centralized entity?
00:30:31.100 - 00:30:43.916, Speaker E: I think that there were two claims. The first is that shared sequencing is unfair in some sense to roll ups because they basically have to cede this economic power to.
00:30:44.018 - 00:30:54.012, Speaker B: It's unfair to users because it creates a centralizing force which will lead towards more stronger centralized actor. The winner takes all.
00:30:54.146 - 00:31:35.160, Speaker A: Yeah, it's like you're defeating the very purpose of web three. So how many guys have you read write own by Chris Dixon? A few hands, but it's a really good book. And he walks you through the history of the Internet and explains why we need web three. What is wrong with web two? And what's wrong is think of Google. Is it a monopoly? Obviously it is. Right? It controls like 99% of search, email, whatever. Is it the monopoly because it has some power, some special authority from the state? No, there were incentives in place that made it possible for this monopoly to exist and capitalize on your data.
00:31:35.160 - 00:32:16.650, Speaker A: And they control your account. You don't own it. They decide what you do. If they want to exclude you, they just deplatform you and there is nothing you can do. They can do it without due process, without your ability to claim whatever. And we want to avoid that in web three. But if we create the same incentive structure where people are like when a monopoly can naturally occur and control everything, and if they don't like you, they can exclude you, or they can change subtle rules of the game to favor slightly certain players and create better positions for them, we will end up reinventing the same web two story, we will just recreate the same structures and the same problems.
00:32:17.260 - 00:32:20.356, Speaker E: Who do you see as the monopolist in the proposals?
00:32:20.468 - 00:32:25.336, Speaker A: Proposers. Because you will eventually end up with like one or two proposers, which we.
00:32:25.358 - 00:32:28.328, Speaker B: Already see on EF. I mean rocket pool. Ido.
00:32:28.504 - 00:32:31.212, Speaker A: Sorry, builders. I always mix them up, the guys.
00:32:31.266 - 00:32:38.708, Speaker E: I think you mean builders. Yeah, but fundamentally it's a permissionless marketplace, and if you're able to create blocks.
00:32:38.824 - 00:32:42.050, Speaker A: Because you sell like, it's not really.
00:32:43.620 - 00:32:48.130, Speaker E: The proposer will accept the block that gives them the most economic value.
00:32:48.840 - 00:33:12.890, Speaker A: The problem with this approach is you force everyone in the same solution, like you say. Sure, you don't need to use Google or Gmail for email, you can go with any other provider, but then all the websites only have login with Google button, right? So if you don't have a Google account, you effectively, or Apple account, you effectively exclude it from a convenience of single sign on.
00:33:13.200 - 00:33:36.124, Speaker E: Conversely. But conversely, if you don't participate, like if users are getting a better deal from shared sequencing, if they're getting better ux, if they're able to access more economic value because liquidity is shared, then by not opting in, you are imposing a cost on your users.
00:33:36.252 - 00:33:42.916, Speaker A: They should not be. We can design systems that are equally usable, just without shared sequencing, using the easyk proof system.
00:33:42.938 - 00:33:49.750, Speaker B: I have actually an extra point I want to make about this. We're ganging up.
00:33:50.060 - 00:33:57.370, Speaker E: So, disclaimer. This is Justin Drake's proposal. And so if you argue against it, you're not aligned with.
00:33:58.940 - 00:34:22.370, Speaker B: Right, I know, but there is another thing that upsets me with the shared sequencing environment, which is like it sort of completely gave up on solving mev to what? By Mev, I mean like all the front running type of mev. And that upsets me very much. The fact that we normalize the idea that transactions should be visible ahead of time is highly problematic to me.
00:34:27.300 - 00:34:33.588, Speaker E: Are you saying that with threshold encryption you don't get the scale benefits of.
00:34:33.674 - 00:35:26.884, Speaker B: I mean, the thing is, for people who don't know, that is my perspective. The only true way to solve mev, at least to some capacity, is ordering without execution. So for those who don't understand just very clearly, blockchain are just consensus is just about which order transaction happened, and not so much about actually what happened in them. And I won't get into the detail here, but if you could encrypt a transaction in a way that only unlock itself at finality, which, what would be possible in the context of single short finality, meaning the second I get included, the transaction itself, transaction reveal itself after finalization, then there is no mev in the send that we hear about today. Liquidation will still happen and there would still be sort of mev. But you still don't have mev of the sandwiching attack and all those sort of things that are nefarious to system.
00:35:27.002 - 00:35:38.250, Speaker D: I mean, come on, it reduces the mev. It doesn't eliminate that you can't eliminate. Okay, you eliminate sandwiching attacks and that's it. But like everything else, like front running. No, of course not.
00:35:39.260 - 00:35:40.184, Speaker A: Front running is.
00:35:40.222 - 00:35:41.876, Speaker B: Yes, front running. You can solve it.
00:35:41.918 - 00:35:45.950, Speaker A: It solves. Yes, because you cannot see what you're. You don't know who you.
00:35:51.280 - 00:35:54.620, Speaker D: I mean, you don't eliminate all kinds of mev. That's my point.
00:35:54.690 - 00:35:57.216, Speaker A: Correct. You eliminate the harmful, the most harmful type of.
00:35:57.238 - 00:36:23.240, Speaker B: Yeah, with all the love for flashbud, they did this marduous thing of mixing like normal Mev, which is like liquidation, with nefarious Mev, and claims it's all the same thing. They cannot be solved at the same time. And that's very annoying. There are such a thing as front running. It's forbidden in traditional market for plenty of reason. It should be also prevented from technical perspective in blockchain. We just gave up on that so far, unfortunately, in my opinion.
00:36:25.660 - 00:37:12.200, Speaker E: Yeah, I would say that to your first point, so your first point was that lack of fairness and then whether animicity is actually useful to users. And I think that that's just something that the market will determine. And if in fact atomicity is good and if it does present a meaningful benefit to users, then I think that there will be like a market pressure to use shared sequencing. And I don't think that we can run away from that because we're already seeing momentum to support shared sequencing on ethereum. I think in some sense if it is in fact better for users, then it's inevitable.
00:37:15.020 - 00:37:43.570, Speaker D: Here goes. Not so hot take on shared sequencers. Right? Shared sequencers being not deeply embedded into the protocol are just another l one like for real. And using shared sequencing without having it designed, being deeply embedded into the protocol from the first principle, just from the very beginning, you effectively reduce the security of the whole system to just this l one l, one more l one security. So it's like anyone wants that.
00:37:48.840 - 00:39:07.212, Speaker C: So I think this has been a very interesting discussion on your views on round shared sequencing and what the right approaches are to maybe take here. I think at the end of the day developers are going to choose what makes most sense for their application. I think one thing that I've been thinking a lot about is also, okay, you have shared sequencing. That seems like the option today that can get you something close to atomicity, right? But I think long term, and you all alluded to this earlier too, as the length of time it takes to generate a ZKP keeps coming down and the cost keeps coming down. If we can get to the level where you can generate proofs within like a second, maybe even like milliseconds, then I think for all intents and purposes, for a lot of developers it doesn't actually matter or not whether it's truly atomic, right? So I think on that note, something I wanted to get all your takes on because I think the fact of the matter is most developers today who are building a roll up, they are choosing to go with optimistic roll up stacks, I suspect. And I'm open to hearing your views on this too. One of the reasons for that is just ZK is still a bit expensive today, right? And I think on this point about getting the cost and the latencies down, that's going to take some time.
00:39:07.212 - 00:39:21.568, Speaker C: So I'm curious if you all have thoughts on how much left do we have, how far do we have to keep going? When will ZK truly get to the point where it's economically like a no brainer for developers, right?
00:39:21.654 - 00:39:52.196, Speaker A: So if you open growdepy.com. I think look at transaction costs. ZK sync is by far 50% cheaper than all the optimistic roll ups already today for average transactions. So this happens since two months. I think the reason why ZK has not yet taken off is because there was a period of warming up when optimistic rollups launched. Initially they had a lot of developer fiction. Things worked just slightly differently.
00:39:52.196 - 00:40:11.824, Speaker A: There were some inconveniences, some tooling did not pass. It took a while. It took approximately a year for arbitrum to polish the experience and make it really mature. It took a bit longer for optimism. We experienced the same thing. We did not have some basic tooling and some basic things available on ZK sync. It's not like EVM equivalent roll up yet.
00:40:11.824 - 00:40:32.890, Speaker A: You need to recompile. But things work now and we're, I think like 95% there and we're serving the last miles. But you're right, costs were a major factor. They were more expensive than optimistic roll ups. That's not the case anymore. At least one ZK roll up is cheaper than optimistic roll ups. You can check it for yourself.
00:40:33.820 - 00:41:20.870, Speaker B: I will agree with Alex. And right now he's right. They are cheaper than every other LTU, including Starknet, because they launched their very good upgrade boardroom with compression, which I congrats you for. It was a very impressive work. But more, I mean, to go back to your point about why people still do stay, tend to favor optimistic roll up. My perspective, there is two answer to this. The first one is we are still talking at this stage with the same builder that we have lifecycle I haven't seen yet, truly new things, truly new application that has been coming up in the last two years.
00:41:20.870 - 00:42:20.792, Speaker B: And regardless of tech stack, and I'm not going to Starknet and Cairo and all that. Just when you look at what's going on in the market, we see a lot of new projects coming up with new incentive mechanism, new ways to do things, but the core of the product hasn't truly changed. And so I'm expecting that in this new bull, we're going to see new things. Things like on chain gaming or things like advanced cryptography for Oracle, things like Erodotus Axiom with twice proof, all the Zikeco processors, all of that, it's getting to market and the implication of their outcome will finally arrive, will arrive soon, and will be as a native base home in the ZK roll up word. Because if you want to verify proof, I can tell you that ZK Rollup are the right place if you want. Zkrop are the chain for proofs, especially.
00:42:20.846 - 00:43:03.940, Speaker A: ZK rollups with state divs because you don't have to publish the proofs. But I want to say that we actually see really interesting use cases being developed, at least on Ziki sync in the Ziki roller board. We have for example, Quark ID, the project we're doing with the government of Buenos Aires where this Friday they open source the platform. It's a platform for self sovereign id where citizens can control their know, they don't delegate it to government. The government actually gave it to them. And you can use your identity on Ziki sync with Quark ID to access goods and services and governmental things. And they're now expanding to Mexico and Colombia.
00:43:03.940 - 00:43:24.284, Speaker A: We're seeing things like tokenization of real world assets. We're working with traditional institutions. It's taking them longer time to warm up. They take years longer than startups and obviously than crypto native folks. But they are coming there. We're in conversations with banks, with central banks even. They are coming there.
00:43:24.284 - 00:44:00.792, Speaker A: They are building things that are coming to, they're going to on chain the traditional finance and they will only use ek roll ups. They are looking beyond marketing hype. They are looking into the essence, what's the most secure technology available to us? What is the technology that gives us privacy and yet interoperability with other systems like that? My bank interacts with other banks, but I don't want to disclose the data of my customers. That's only possible ZK rollups. I think the ZK revolution will actually unlock the full potential of Ethereum. And this is already happening.
00:44:00.926 - 00:44:52.568, Speaker B: We can totally see mean. I was more referring to optimistic rollup based project I've seen, at least not without dissing anyone, just to be clear. And to go alongside on the Starknet front, a new application that has been very exciting. There are multiple dimensions, people using the language. So Starknet has this Carol language is optimized for proving, but also now also looking towards privacy. And so you have a team right now called Giza, which is presenting a workshop around here where you can see how they're using this new language to make VKML provable inference of machine money model and on chain gaming. Once again, what I'm trying to say is the stage where we see projects taking advantage of what ZK allows is rising and not fully there yet.
00:44:52.568 - 00:44:56.990, Speaker B: When it's going to come out, you're going to be surprised of the new application coming in.
00:45:01.590 - 00:45:39.120, Speaker D: You kind of touched all the points, I would say except the points for which all of those roll ups we're building are there high performance stuff. It's like managing the block building, for example, or transactions operations over high performance roll ups. Or it's like kind of suave style, right? Just not an l one. That's the thing. Or it's like purpose changes, the most usual thing.
00:45:41.730 - 00:45:43.760, Speaker A: It didn't get the question quite.
00:45:51.830 - 00:46:05.942, Speaker D: You gave those examples of apps. It's like which kind of are kind of still possible on ETH, just a little bit more expensive, but still possible in there.
00:46:06.076 - 00:46:19.340, Speaker A: Well, I think it's prohibitively expensive. On layer one, the costs are a factor. If a transaction fee costs like $10, you cannot buy a coffee with it, right.
00:46:20.510 - 00:46:58.280, Speaker B: I can give you a very good example. Star Queer has been having Starkx, which has been by far in term of volume of trade happening on the system. The most successful Ziki and even per environment in crypto. And with Dydx we did a trillion dollars of volume with Apex, with Brian, with all the new the other one now the more so flying. And those application could literally not have been built on any environment that is non ZK based. And the very reason is. The reason is actually quite simple.
00:46:58.280 - 00:47:29.186, Speaker B: The reason is those application cannot leave in fee based environment. In environment where they have to compete for block space. And so this is the bullcase or those Zk servers, those centralized app chain where I can define my own fee mechanism. Or maybe I just don't take any fees because I have other DDoS protection. And I know that I'm going to make money in average of all the thing happening in my system. No, I'm talking. No, it's an l three.
00:47:29.186 - 00:48:08.830, Speaker B: So paradex for instance right now is running a stock chain. They did 200 million volume daily I think lately. And why they use an app chain here is or a private app chain is because they are protecting themselves against dose through regular web. Two solution, meaning ip filtering, rate limiting and so on. And they can allow their user to trade, to accept limit order, to cancel limit orders without fees. Because that's the biggest hurdle for a centralized order book on the blockchain. And they know that in average all the settlement that's going to happen, they're going to make money.
00:48:08.830 - 00:48:52.780, Speaker B: And so they don't have to price actual transaction fee at every transaction. But the environment itself is the same environment that if you were running on a public network. For me, that's actually what the end game of those l three looks like. Centralized noncustodial environment that understand what the smart contract is. And can run without running fees for your specific application. And just, I would even argue to make the bull case what is actually this one, which is cheap, is never cheap enough for every application. If you have application that requires to be cheap, there is always something will price you out at some point if the block space is limited and you need an environment where you can control what's going on.
00:48:53.950 - 00:49:06.400, Speaker E: So here's a slightly spicy rejoinder to that. They don't need to be l three s, right? Like you could have l two s. Where we do proof aggregation, there's no dependence that they settle on an l two.
00:49:07.730 - 00:49:38.458, Speaker B: It comes down to semantic. Basically what you're saying is ag layer versus settling proof on an l two itself. In my opinion, it's actually better to do proof submission on a public network because it's asynchronous and I don't need to co organize on which order I need to send my proof. And if I trust the l two itself, I just can trust what's going on. The settlement itself, it's now based on trust assumption of the consensus mechanism of the l two versus the l one. And at this point it's kind of semantic and like what level optimicity we're talking about.
00:49:38.544 - 00:49:46.126, Speaker E: Well, but the problem is you can't have, it's much more difficult to have cross l three transactions for l three s that are settling on different l.
00:49:46.148 - 00:50:30.650, Speaker B: Two s. That's true. But I think it's literally, honestly, you can probably draw exact the same sort of operation between settling your proof and directly executing a transaction to the other environment, versus coordinating everything in a single proof. So when I'm saying like, for instance, let me give an example, paradex. Let's say you have an EB three that sets it on Starknet, okay? They send the proof as part of the state update of the execution of that transaction. A transaction is automatically emitted on behalf of the user, and this transaction directly deposit to the l three. That's equivalent to aggregation.
00:50:32.350 - 00:50:33.162, Speaker E: Within a single.
00:50:33.216 - 00:50:36.310, Speaker B: L two within assuming within the same environment.
00:50:36.390 - 00:51:02.180, Speaker E: Yeah, but I do think that we're sort of like the nice thing in my opinion, about the ag layer is that there's not a contention for block space and for resources that you run into on an l two. Because on an l two you're not just aggregating proofs or sort of being this settlement layer for l three s. You also have transactions and smart contracts that are deployed directly to the l two. And so I'm not sure we're going to resolve this.
00:51:02.490 - 00:51:20.890, Speaker B: So you can argue in this case, and this is a Solana bull case, which is paralyzation parisation at transaction level when you, I'm not saying that full access is the way they do it, but at some level of parisation gives you solve a block space issue while becoming.
00:51:21.470 - 00:51:28.078, Speaker A: You can build the transaction dependency graph and those settlements will all be isolated from the rest.
00:51:28.244 - 00:51:41.506, Speaker E: Yeah, but you're still contending for network resources with the Aglair. Not every validator on the Aglair even has to download or receive every proof. This is sort of the nice thing.
00:51:41.528 - 00:51:49.746, Speaker B: About proof aggregation, but there is now a coordination requirement between the two l three s to know that the message was sent from one to the other.
00:51:49.928 - 00:51:54.274, Speaker E: Yeah, of course. But you're going to have that. You're going to have some coordination.
00:51:54.322 - 00:52:10.140, Speaker B: Yeah, but in this case, the other l three doesn't actually just have to look on the r two as opposed to actually talking to the other, the one that's sending the message itself. But I think we're digressing. I think it gets too semantic at some point.
00:52:10.510 - 00:52:16.800, Speaker C: Guys, this has been an interesting discussion, but I think we also want to give the audience some time to ask some questions.
00:52:17.250 - 00:52:18.000, Speaker A: Sure.
00:52:26.740 - 00:52:44.076, Speaker C: Does anyone have any questions they want to ask? So actually, I want to revisit question, because his last question is about the.
00:52:44.098 - 00:52:45.692, Speaker B: Cost of ZK being high.
00:52:45.826 - 00:52:50.428, Speaker C: Do you think that with things like technology advancement or hardware acceleration, this can.
00:52:50.434 - 00:52:54.060, Speaker B: Be practical so that people will be thinking about ZK instead of optimistic?
00:52:54.140 - 00:52:59.024, Speaker C: What do you guys think? All of you guys invest into ZK hardware like companies?
00:52:59.222 - 00:54:12.052, Speaker E: Yeah. So it's interesting because I think everyone on this stage has been working on ZK for a long time. But my personal experience was starting a ZK project in 2019 and being extremely nervous that we were raising money and the technology was not ready for what we wanted to build. And I think that everyone on this stage has gotten very lucky that we entered the technology at a time when it was increasing in speed and performance and efficiency exponentially. And so I think it's fundamentally just a mistake to ever bet against technology. But I would just echo Alex and Louie when if you look at transaction fees currently on l two s, they're extremely competitive with optimistic roll ups. There is a question about whether proving costs are being included in these fees, but I think what this argument misses is that optimistic roll up users, they aren't just paying transaction fees, right? Because the seven day withdrawal delay imposes capital inefficiency on the users of optimistic roll ups.
00:54:12.052 - 00:54:55.140, Speaker E: And so if you try to quantify this capital inefficiency and you look at the aggregate fees that users have paid to third party bridges, it's like tens of millions of dollars to avoid the seven day withdrawal delay. And so if you compare that with the cost that it would have taken to prove every single transaction on arbitrum or optimism, we just released a type one prover. We could generate proofs for optimism and arbitrum tomorrow. It's like orders of magnitude less. And so optimistic roll ups are already extremely cost prohibitive and we haven't even started talking about their limitations in cross chain and composable settings. To me, the debate is no longer really ongoing.
00:54:56.840 - 00:55:33.510, Speaker D: Just to add to that, I would say regarding the proven cost, it's like eventually it is going to be priced in into transactions cost on ZTL two s for sure. The best way maybe to reduce that is just marketplace like, market dynamics, like something like this. Just apply that to proof generation and you're good. It's like if the hardware comes up show, if it doesn't comes up, and there's a lot of software implementations, software optimizations show. I mean, just apply market dynamics, the market will solve it all. You don't believe it?
00:55:35.640 - 00:56:27.190, Speaker B: Yeah, and the proof being expensive is a meme for all capacity and for a very long time. And I think all of us can just apt this type for it. It's been a meme for like two years at this point, and a meme that's been pushed by vcs to justify funding other companies. With all the respect I have for other companies, which I appreciate, we just released a new paper called Circus Stark literally last week, and Bronky three and a bunch of other announcements coming up. Just say that the improvement at the research in the software level already, I mean, there is so much to improve just right now that this claim of it's going to stay expanded forever is just like mid curve completely.
00:56:35.270 - 00:56:38.740, Speaker C: I think we might have time for one or two more questions.
00:56:46.430 - 00:57:15.510, Speaker E: Hey guys, that was a great conversation about shared sequencing. I tend to agree with Misha that shared sequencing is basically creating a new l one because you're recreating consensus. Another thing that you could do is that just use a faster l one. And I'm specifically talking about Monad, which is going to be copy paste with Ethereum. So how do you guys view Monad? Do you think that you could see yourselves having products moving to Monad as roll ups?
00:57:18.250 - 00:58:19.340, Speaker A: So Monad is doing optimistic parallelization of transactions, and this way they can process more. They claim they will see how it plays out. They have not live yet, but you can totally do the same thing on any other l two, right? Like there are way more high load system engineers in the world than there are ZK researchers. So that's a lesser bottleneck in my opinion. We will all add that eventually, some sooner, some later, it makes sense, right? And then we can prove all of the transactions in parallel, in batches, with your knowledge proves they are basically infinitely parallelizable. So I think Monet will compete with Ethereum for the mine share and for liquidity and for decentralization. So yeah, it's like in layer one category, whereas ltus will be able to offer the same thing.
00:58:23.470 - 00:59:06.658, Speaker B: I would even say that the question is, will we settle? First of all, starknet specifically. For instance, we are working right now on Block STM, which was invented by Aptos. Aptos, right, block STM, whatever Monad is doing, all the will do it at some point, because there is no reason why not, as now settling on Monad versus Ethereum. Never say never. But at the end of the day, it's a question of crypto is not just AWS versus GCP. Otherwise we'll be settling on EOS or Solana or whatever chain that might be relevant. There is a notion of who you cut it to and which currency you cut it to.
00:59:06.658 - 00:59:28.960, Speaker B: And like Mona has a very happy battle to prove its credible naturality and attract the user base before I think any of the established l two. We think before moving there. But never say like someone may just take the stack and deploy there and good for them. It's a permission at the end of the day.
00:59:32.580 - 01:00:15.050, Speaker D: I mean, it's like mentioning Manad. You're effectively trying know write like piggyback on a parallelized evm meme, which mean of course like parallelization on a VM level. Sure. I mean, just sit and do it, it's not a big deal. It's like at Ziki, sharding things we've done much more than just evm parallelization. It's like data parallelization. Not just computation parallelization, but also data parallelization effectively, because just to avoid locks, I mean, you kind of asked some time ago, by the way, about what's the point of doing a damn sharding just settle on salon or whatever, right? So it's like, my point is data locks, state locks, it's like data exclusivity access.
01:00:15.050 - 01:00:49.752, Speaker D: You effectively get a locked a particular index when several users access to that. So to prevent the locking of that, just putting the whole thing on pause you got to shard that thing, just split the data. And that's what makes it different from salon and things. That's what it makes sense, and it keeps it decentralized. So why to not to use a better l one? I mean, better l one still has. First of all, it's like, what's the better l one, right? It's just different design. Second of all, it doesn't mean that there are no such problems which eth kind of encountered already.
01:00:49.752 - 01:01:09.580, Speaker D: And the third thing, protocol design. Sure, it's like decentralized. Volupt will all have their own kind of protocol. We have it from day one. Guys will achieve it. All of them will get their protocol up and running, of course, as well. So it's much easier.
01:01:09.580 - 01:01:12.110, Speaker D: It's not that of a big deal.
01:01:18.320 - 01:01:53.400, Speaker B: And one last thing about the Monet versus EVM or Ethereum parisation. The current problem of scale on Ethereum is not execution, it's state. So the only thing Monad will achieve, if applied on the Ethereum state will make proof, I mean, computation cheaper. The state will still be super expensive because it's growing. It's a single threaded at this point. There is no excess lease or other mechanism that is going there. It's still going to grow.
01:01:53.400 - 01:02:12.160, Speaker B: And I mean, I would love Ethereum to be paralyzable. You make stark proof much cheaper. So please do. But other than that, I don't really see the advantage of the the narrative behind it, like, outside of being a cool feature on top of the network.
01:02:13.940 - 01:02:20.690, Speaker C: I think we're at time, guys. Thank you for all joining this panel, and thank you for your thoughtful questions, guys.
01:02:22.820 - 01:02:41.940, Speaker A: And just one last thing, guys, I got a bunch of really interesting zkquest things. So you can find me after the panel and you can win all love up to several hundred usd just by passing the test the quest. And it's pretty fun and a lot of cool swag that you can get at our booth at if Denver.

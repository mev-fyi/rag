00:00:00.360 - 00:00:01.934, Speaker A: Hey everyone, we're back for day two.
00:00:02.022 - 00:00:16.102, Speaker B: Yesterday we covered just how to see how many pairs had certain tokens in it. Today we're gonna dive deeper into the actual usage of those pairs and we're specifically going to look at how many swaps per week for a given pair and what is the total volume in.
00:00:16.126 - 00:00:18.182, Speaker A: USD terms of those swaps.
00:00:18.246 - 00:01:05.560, Speaker C: So before we dive into the actual query, let's talk about the concepts of getting this question. Number one. So how do you find the swap pair addresses? There's three, three different ways you can do it. You can either go to Etherscan, search for it, you can go to the uniswap's own UI and search for it, or you can query for it the same way we were querying for it yesterday. And then, so when we talk about like how many swaps, how do you find that? Basically looking at the count of the swap events being emitted from the swap events table. And then, so when we talk about the volume, you can use the same swap events table and then look for the raw token amount and then adjust for that raw token amount by the correct decimal and then further adjust that by the prices in USD. So the way you can find the decimal adjustment is by querying for the tokens ERC 20 table.
00:01:05.560 - 00:01:13.936, Speaker C: Another way you can query for the prices USD is by using the prices USD table. And then without further ado, Andrew will walk you through the actual query.
00:01:14.008 - 00:01:35.310, Speaker B: So now that Jackie's given you the logical explanation, we highly recommend that you go and try and write out the query yourself and then come back and check your answer afterwards. I'm going to give you 5 seconds to go pause this video and try it out on dune. All right, so without further ado, I'm going to get into it.
00:01:35.470 - 00:02:22.896, Speaker A: I've created a new query and I'm going to start by pasting in the address, just commenting it out and we're going to look for the swap event first. Going to go to Unisolt V two and I'm going to look at the pair contract now. And what you'll notice on the pair contract is there's a swap function and a swap event. Sometimes you have to look through the contract logic to understand what's going on. In this case, you'll see swap has just amounts out. It doesn't tell you amount in versus swap event actually tells you the amount in and the amount out. That's because when you're calling the swap function you don't actually know what the price and slippage is going to be and then after the trade is completed, then the swap event is admitted.
00:02:22.896 - 00:03:21.920, Speaker A: So the swap event is giving you, and you might not know which one to use technically the most accurate data. So we're going to do a selects all from swap event and you'll see that events have a contract address column no matter what the event is, this is the address is emitting the event. So in our case, if we say where contract address equals this pair, then I'm getting all of the swaps from this pair. First we wanted frequency, so I'm going to say I want the daily frequency. So I use a date truncate function which says I don't care what hour or minute of the day it is, I want to truncate it just to whatever day this event occurred on. So I'm going to truncate the event block time to the specific day and I'm just going to do a basic aggregation. However, instead of just doing the count this time, I need a group by because I'm getting the count of swaps per day.
00:03:21.920 - 00:03:57.150, Speaker A: All right, so I can run this and here I can just do a basic visualization to check my work and I'll say all right, for each day this is roughly how many swaps are happening. This is a lot of data. So I'm going to just change this to week instead. And I'm going to call this time just because it's easier to generalize. And while that's running, I'm going to put this query into a CTE, which is a common table expression which sounds fancy and it's just a way of saying all right, I want to be able to reference this later without typing it all out. Again. This is a good way of organizing your code.
00:03:57.150 - 00:04:25.288, Speaker A: This doesn't actually change any logic. So I can run this and you'll end up seeing that it gives you the same. And now this is the weekly amount of swaps for the USD ETH pair. Next is volume. For volume. I need to figure out the raw amount of the token swapped and then the USD value of that amount swapped first. Let's get the amount swapped.
00:04:25.288 - 00:05:26.874, Speaker A: I can use all of the same logic, except this time I want the token address that was swapped first. So I'm going to say case one amount zero out equals zero. Then that means that amount one or token one was the one swapped, right? Otherwise if this is not zero, then token zero is the one swapped. And how do we get the token addresses of token zero and token one? Hopefully you remember from yesterday that data is contained on the pair created event from the factory as token one and token zero. So we're going to do a left join, but it doesn't really matter what kind of join you do here because every pair has to have had a pair created event and I'm going to join it on p pair, which is the pair address equals contract address. This contract address is the contract address of the swap. But you'll probably run into this error that both of these events have a contract address column.
00:05:26.874 - 00:06:09.890, Speaker A: So I'm going to alias this with s and say I want this to match the swap contract address. And then now I can put in the pair created table token one. Because again, if the amount out of token zero is zero, that means that token one was the one bot else p tokenization zero as token bot address. I need an end here for the case statement. Again, case when is just an if statement. So saying if this is true then this, if it's not true then that. So now I'm going to do the same case when amount zero out equals zero, then now I just want the amounts.
00:06:09.890 - 00:06:40.800, Speaker A: So that means amount one out is the value that was bought, else amount zero out and as token bought amount. So we can run this if we want. But it's a lot of data. So I'm going to put a limit just to check that it doesn't run with errors. And you see there is error because I didn't add an s here to specify. I only want the contract address of the swap. It says it's ambiguous because there's also a contract address on payer created.
00:06:44.670 - 00:06:45.054, Speaker B: And.
00:06:45.102 - 00:07:16.060, Speaker A: Again ambiguous because of block time. I'm going to want to swap block time. And you'll see now again, oh no, varchar equals integer. I can see the only place I have that comparison is here. And you'll quickly notice that any value, even if it is an integer or something on chain, it's a string in dune SQL. So you need to cast it as a double, which means we need to cast it here as well. Casting just means we're changing the type in the database so that it works nicely with numerical functions.
00:07:16.060 - 00:08:10.836, Speaker A: And last time cast zero out as double. Let's run this again and you'll see some y axis because the visualization, but we can see, all right, there's all these swaps on some day or some week in our case with this token being bought and this amount bought raw. Right? So we have volume now, so volume as. But I'm going to do this as base. But yes, you can do ctes within ctes. I do this for when I have multiple logics to get to a desired table. I have some base.
00:08:10.836 - 00:08:51.432, Speaker A: I'm going to remove the limit and now we have to add the price, right? We need price and we need to aggregate. So I have some token bottom out raw. I need to divide by the decimals and supply decimals and then multiply by the price at that time. So let's go get that data. I'm doing this from base. I'm going to alias alias B and I'm going to join get the decimals first. Hopefully you remember from yesterday that there's a tokens ERC 20 table that contains a bunch of different token contract addresses and their decimals and other values.
00:08:51.432 - 00:09:27.916, Speaker A: I'm going to say token ERC 20 t and I'm joining that on t. Contract address equals D token bought amount address or token bot address. If you're wondering how I have autocomplete on, you can click the setting button and enable it here. So that gives me this. So I can now fill this in and say I want the power of ten to the decimals given by. But it's possible that this token doesn't exist in the tokens table, so that's going to be null. So I want a default of 18 decimals in case the token's not found.
00:09:27.916 - 00:09:43.200, Speaker A: And what coalesced does is it says, all right, I'm going to take the first non null value you put into this function. So if I had selects coalesce no. 213, this is going to give me two.
00:09:46.340 - 00:09:46.772, Speaker B: Right?
00:09:46.836 - 00:11:01.262, Speaker A: Because two was the first non null value. If I put a one up here, it's going to give me one, right? So in our case to check that token decimals exists, if it doesn't exist in this table, meaning it's not a token that we've put the metadata in for, then it's just going to default to 18 decimals. I need prices. So their prices, USD table. If I go all the way to explorer here prices and I'll see USD and I can look and say all right, prices at USD aliases p and I want to join it on p minute equals b time and p blockchain equals ethereum and I and I want p contract address to equal this bot. But now I can replace this here with p price and I'm going to list this as total USD amount to save another CTE. I'm going to just sum this here instead of summing it in the next query, and I'm going to have to group by one.
00:11:01.262 - 00:11:13.390, Speaker A: So I'm saying, all right, for each time, for each week, I want the raw token amount divided by decimals, multiplied by the price of that token. At that during that week.
00:11:15.210 - 00:11:15.706, Speaker B: You might.
00:11:15.738 - 00:11:51.244, Speaker A: Say, oh, if I want this to be more accurate, I should join this on the minute of the actual token transaction. So to fix it, we're going to date trunk into a minute, first doing this on time, and then we're going to actually date chunk time. One more to our desired total, which is week. This is time. It's not longer s, it's actually, and this will give us a more accurate volume. Cool. So now it's loaded, I can pull our chart and I'll see.
00:11:51.244 - 00:12:27.068, Speaker A: All right, there's some spikes here. 2.45 billion traded on May 17 in 2021. Some spikes here around May of 2022. There's another way, actually that we could have gotten this data, and that would have been by using the Dextrades table. Dextrades is a spell and spellbook where we've already put together all of the different kind of exchanges into one spell or one aggregated model. So if you go to spellbook on GitHub and then you look for Dex, and then you go to Dex trades, you can see all of the different exchanges we've already added.
00:12:27.068 - 00:13:11.450, Speaker A: This is all community contributed. You can do this as well. If you go into the Uniswap V, two Ethereum trades, you can see that their query here has a lot of more casting and renaming to fit the Dex trade schema, but it's basically the same thing we just did. So I can actually just say, all right, I want to find the Dex trades table and I'm going to look here and say, okay, there's a block date already. I need to date trunk this so week. And then I want just the sum of amount USD of the trades. Let's call this total USD amount DX.
00:13:11.450 - 00:13:57.234, Speaker A: And then this is from Dex trades where blockchain equals Ethereum. And let's see, we need the project contract address, which I know is the pair, but if you wanted to look, you could see project contract address that the swap event alias t was renamed as project contract address here. So I can say where project contract address equals this pair. And then let's just do a group by so group by one. So this should give us essentially the same data. I'm going to run it as a selection here. So it's finished running.
00:13:57.234 - 00:14:25.226, Speaker A: In this case, I called a week, so we have to change the name of these columns. But you'll see here that it's giving us exactly the same data right there is this spike here. There are two more spikes down here. So let's just join everything together and then we're done with the problem. So volume, I'm going to alias at v and then I'm going to just left join frequency. Let's call it f on f dot time equals v dot time. Check.
00:14:25.226 - 00:15:00.494, Speaker A: That is what I called it. And count here I'm going to rename as num swaps. If I left join on time, I only need v dot time and then I can just do f dot num swaps. V dot volume. And just for fun, let's also join dextrades dx on dx dot week equals v dot time. And then let's do dx dot. This is not volume, this is total USD amount.
00:15:00.494 - 00:15:32.980, Speaker A: And then this is total USD amount. Dx while this is running, I will say that sometimes if you have a case where there's a period of time with no swaps, you're actually going to have to generate a time series to show those missing dates. We're not going to do that in this query. That's going to be done in a future query. Cool. Again you'll see missing axes because I renamed it to time again. And so now let's actually put the USD amount, put the number of swaps and let's put the dex trades amount.
00:15:32.980 - 00:16:04.348, Speaker A: So we're to put the number of swaps and the total USD amount. The swaps. I'm going to change into a line and I'm going to enable the right axes and call this number swaps left axis. I'm going to call total volume USDA swaps. I don't need logarithmic. I can just do abbreviations here. Swaps is going to be the right axes.
00:16:04.348 - 00:16:48.120, Speaker A: So I can see. All right, there were 64,000 swaps that total $22.45 billion here. All right, I now have the answer to my question here. I can just say volume and frequency of swaps for USDC eth B two Uniswap. So on top of this, we're also going to add just a check of basically the Dex version and then our raw version of swaps. And the lines of should be.
00:16:48.120 - 00:17:01.156, Speaker A: And the lines should be perfectly overlapping showing us that our data is complete. And with that, you are now done with problem two. Good job.
00:17:01.348 - 00:17:34.840, Speaker C: Thank you, Andrew for that beautiful walkthrough of the query. So for bonus point, if you want to investigate further, something else you can do is which pair containing wrapped ETH had the highest total volume in the line that you can filter down to to only tokens that exist in the prices USD table. And then, so for tomorrow, we're going to take the same concept. So to look at the frequency and the total USD volume for, of the swaps of USDC and wrapped ETh. But we're going to take a step further and we're going to see the source of these swaps who actually originated the swap costs. All right, cool. See you guys tomorrow.

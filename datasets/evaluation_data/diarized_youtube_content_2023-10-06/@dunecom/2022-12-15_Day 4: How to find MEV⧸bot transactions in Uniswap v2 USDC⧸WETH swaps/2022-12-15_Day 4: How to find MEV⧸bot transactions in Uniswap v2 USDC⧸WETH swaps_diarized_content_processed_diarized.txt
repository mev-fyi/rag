00:00:00.360 - 00:00:15.910, Speaker A: Welcome back to day four of twelve days of Dune. So today we're gonna go back to looking at the actual pair that we've been analyzing. And then today's goal is to identify organic versus spot. And I will hand it to Andrew to explain the logics and do the query walkthrough.
00:00:16.030 - 00:01:17.952, Speaker B: Yeah, so we're gonna take the volume and frequency calculations we did in problem two, and we're gonna be using the transactions table, the labels contracts table, and as well as the traces table to put together a view of how do bots usually conduct mev or arbitrage transactions. And is there a way that we generalize categorizing and identifying their approach? If so, then we can figure out what percent of swaps are mev versus non MEv transactions. And that'll give us a better idea of organic versus inorganic swaps. Without further ado, let's jump into the query. So, for identifying Mavbots, normally they use a contract to conduct. The reason for this being that if you're doing arbitrage, you essentially have to swap against different pools in different protocols. So there might be a USDC ETH pool in Sushiswap as well as in uniswap that don't have the same price.
00:01:17.952 - 00:02:03.828, Speaker B: So you'll buy from the lower priced one and sell to the higher priced one to balance things out. But you can't do that in a single transaction if you just call the Sushiswap or Uniswap contract. So you have to create a new contract that allows you to basically multicall or batch contract calls together so that it all happens in one transaction. You might ask, why does it have to happen in one transaction? If you do it in separate transactions, someone might get in there before you. And then that's going deep into what's called the dark forest of MeV and bribing miners and whatnot changed with staking. But I'm not going to go into that. Our goal is to see can we identify these MEV contracts without relying on the labels.
00:02:03.828 - 00:02:38.476, Speaker B: So you can see here that all of the MeV bots kind of, there's 300 of them that are tracked in Etherscan with labels. We actually have those labels inside of dune as well. If you search labels and then you'll see Mev Ethereum, you'll see that this table actually captures what we have in spellbook models under MeV as well. This is a custom table built by Hildebe, sourced probably from Etherscan. Yep. So we could just query that. But we want to see if there's a generalized approach.
00:02:38.476 - 00:03:14.804, Speaker B: So to do this, we are going to start by taking the swaps. We already have volumes here. Let me just copy this in to this new query. I'm going to make this a parameter, which Jackie has already shown off from yesterday. But essentially a parameter just allows you to make it easier to test different variables. You don't have to copy and paste across the whole, the whole, you have to copy, paste across the whole query. In our case, we actually don't need to do this in two steps.
00:03:14.804 - 00:04:13.360, Speaker B: What we can do is say, all right, so in our case we don't need this frequency part here. So I'm just going to copy this down to this point and I'm going to remove this frequency CTE and this comment. All right, so right now it's just volume where there's some token bought and some raw amount of it bought. I want to try and figure out the token. Okay, so what I need to figure out is did someone use a contract to basically do a multicall across exchanges? That's somewhat complex to do. So I'm going to simplify it to say did they call a contract that then interacted with this swap at some point? So they could have used like this mevbot contract to interact with the router, which then interacted with the swap. But the first two, or the transaction two is always going to be the Mevbot contract.
00:04:13.360 - 00:04:54.088, Speaker B: So that means that if I just take every swap and I do a left join on Ethereum transactions, which is one of the raw tables inside of dune, that stores essentially what you see here. All of these hashes blocks from to value transaction fee. If I join this hash on the swap, transaction hash. So it's an event. So it's event transaction hash, which is a standard column of this table. If I join this, I can now add transaction two as contract interacted. So let's just say that this is the contract that was called.
00:04:54.088 - 00:05:32.802, Speaker B: I'm going to keep the transaction hash just in case we need it for an example later, just like we did in the router query. And we already have this, which is going to be helpful for you, calculating USD volumes. And then now we want some amount of labeling, right? So the first way to start this labeling is just to check. All right, what contract was interacted with. So I'm going to do another join here and this is going to be on the contracts labels data set. So I'm going to do labels and then find contracts. And this just stores all of the contract names.
00:05:32.802 - 00:06:13.412, Speaker B: That we have. So C on C address equals transaction two. So this is saying, all right, for the contract called, what is the name of the contract? Sometimes you don't have that data because it hasn't been decoded. Most of the times you should. So we're going to get the decoded name for reference, which in this case is just c name as, we'll just leave as name. And then I'm going to just check that this contract was not basically a Uniswap contract. So the way to do that is just to check is the name Uniswap in the name of the contract somewhere.
00:06:13.412 - 00:07:01.866, Speaker B: So if it's the router, it's going to say uniswap router. If it's the pair, it's going to say Uniswap v two pair in the name. So this is just a quick way for me to check, like, all right, is it uniswap or not? Case when it is Uniswap, then I'm just going to call this a Uniswap contract, else not Uniswap and as contract to type. Okay, so lastly, this is a lot of data to join on. So what I'm going to do is make a time filter, especially if you're on other blockchains like optimism or polygon that have a lot more transactions. You're going to need some sort of time filter to get things to run smoothly. So I'm just going to do interval one year for now.
00:07:01.866 - 00:07:35.420, Speaker B: I'm going to comment this out for now just so we can check that this is running the way we want. So I've select from base here and this is a nested CTE. So I need another one. Select all from volumes and let me add a limit just so it runs faster. Contract address is ambiguous. Yeah. So here I want where the swap contract address.
00:07:35.420 - 00:08:00.214, Speaker B: Cool. So I can see that this is the contract called. This is transaction hash, which token was bought, the raw amount and also the name of the contract. So a lot of these are just going to be. The router was called and that's totally fine. We just wanted to check. I doubt any of these are not uniswap just for now.
00:08:00.214 - 00:08:39.990, Speaker B: Because again, most of the trades are just going to come from people calling the router. So we have this. So let's just join on the prices data. And what we're going to want to do here to join on the prices data is add on our extra columns. So we have contract interacted, we have the transaction hash, and we have the name and the contract to type. So we already have the sum. We have a group by Ondezenhe five columns.
00:08:39.990 - 00:09:28.190, Speaker B: But you'll notice transaction hash, if we group by, that's just going to give us the amount of that transaction. So instead, I'm going to take this to arbitrary already to give us a random transaction hash to work with. Again, arbitrary is an aggregate that just gives you a random value of that column that's non null. So in this case, we have four columns. I just only need to group by four. And what this is saying is, all right, for each week, give me the number, the total amount traded in USD based off of which contract was called. So in our case, this should be one of the columns we get, or one of the values we get is how much did this contract trade per week.
00:09:28.190 - 00:10:01.990, Speaker B: I can make this easier to see by just putting contract interacted equals this. And I'm going to run it. Oh, we actually hit a memory limit. So this one's not going to work just because I think I'm asking for too much data here. So let's actually move this up to here. Just, it runs faster. We'll just have to remember to remove this later.
00:10:01.990 - 00:10:36.372, Speaker B: All right, we're still hitting the memory limit, so let us, let's see. So for testing, I'm just going to shorten this interval to just a month. And instead here we are going to. If you checked the prices table before. So if I go out to here, I search prices USDA, you'll see that decimals is actually on prices. So I don't have to join this here. I can just use P decimals.
00:10:36.372 - 00:11:01.314, Speaker B: And I'm also going to filter on top minute here. So p minute greater than now minus interval one month. So we're just making all the filters and joins faster. So hopefully this runs faster than great. That ran a lot faster. So a few filters help. You'll see.
00:11:01.314 - 00:11:28.910, Speaker B: There's five weeks here where it looks like there was an interaction from this contract and the total USD amount of each interaction was around 18,000 or so. Actually not that high. There was just this week that was really high. Just some may not tell us all the information we need. So let's get count as well. So we get number of swaps and I'm going to comment this out and move on for now. So we have volumes that are priced.
00:11:28.910 - 00:12:13.218, Speaker B: So now what we can do is say, I now want the aggregate swaps per week. So now we have volumes. Usually if I start doing more complex joins, I will do like a sanity check. Query. So I'm going to take for the given time weeks, I'm going to sum the number of swaps to get total swaps and I'm going to get sum of total USD amount as total USD amount from volume group by one. And let's make these, let's make this a time length parameter. Just so I don't have to keep clicking through these.
00:12:13.218 - 00:12:49.140, Speaker B: Let's rename that to this and default value of maybe let's say three months. Cool. So this is just going to be a QA. I want the total swaps and I want the total USD amount swaps. I'm going to have a line enable the right axes, push swaps on the right just so we can quickly check. Okay. The USD swaps is this one and number of swaps is this one.
00:12:49.140 - 00:13:17.106, Speaker B: So this is 64k swaps. 281 million on November 7. If I go here, if I go November 7, I can see it's the same value. It is not the same value. The value is not the same. This is why we do QA checks when we join. Turns out this labels contracts actually has a blockchain variable or column.
00:13:17.106 - 00:13:44.150, Speaker B: So I need to add a contains, so contains within the blockchain column ethereum. So I need to add this to specify my join. Cool. So what you'll notice now is that we do have the right 178.8 million 27.3k swaps which matches here. So now QA check.
00:13:44.150 - 00:14:08.654, Speaker B: Now that's set. I can just comment this out. I'm going to name this QA volume check again. Anytime you do some new joins on your data, please add some sort of QA just to make sure you haven't messed up that step. It's going to save you headache in the long run. When you finish a query and you're like, oh, these values look right, but they're not exactly right. Yeah.
00:14:08.654 - 00:14:35.060, Speaker B: So please make sure to have the QA. Next step, we're going to create an aggregated swap table. So we have weekly swaps now. But weekly software contracts interacted doesn't really mean anything to us yet. It's hard to compare over time. So instead, now we're going to basically take everything we have here and then aggregate it without time. So I'm going to take select contract interacted.
00:14:35.060 - 00:15:21.596, Speaker B: I'm going to take the name of the contract. I'm going to take the type of if it's uniswap or not, I'm going to have to take an arbitrary transaction hash again because now this gave me a random hash for the week. But I need a random hash over the full time now. And then I'm going to sum over num swaps to get total swaps, and also sum over total USD amount to get total USD amount. Now I also want the median. So that's the number of swaps on average for a given week. They were active, right? So to take the median, you can use approximate percentile, which just says what is the value at a certain percentile for the column that you're passing in.
00:15:21.596 - 00:15:57.850, Speaker B: So for all numbers of swaps per week for this contract interacted, what is the 50th percentile, which is by definition the median as median num swaps. I'm going to do the same thing for total USD amount as median USD trade. So we're going to do this is from volume group. Bye. One, two, three. Because we have three columns that aren't aggregate. All the rest of these columns are aggregated columns.
00:15:57.850 - 00:16:35.178, Speaker B: So we can just select from this just to double check things. So our query has run and you can see that a lot of these contractors are not uniswap. We can see the total swaps they've made, as well as the median number of swaps they've made per week. Note that this might not be super accurate if they only swapped in one week. So if they've only swapped once ever, then the median is going to be the same as the totals. You could do a generated series with. Oh, count how much they interacted each week, and if they didn't interact that week, make it zero.
00:16:35.178 - 00:17:11.172, Speaker B: However, we're not going to do that for our purposes. We can start to use a scatter chart to examine the data. So if I put media, let's say total swaps and total USD amount make the axis logarithmic, and then group by contract. Two type. I can see there's a few Uniswap contracts in here, and there's a few big ones over here, so I might want to group by name instead and see. Oh, this is Uniswap router zero two. Or this is v three swap router zero two.
00:17:11.172 - 00:17:50.668, Speaker B: I can add a circle radius as well. So let's say I have the totals. Let's say I want the median USD trade as well. That's duplicative, but I can now see, all right, for each week, what was the average amount traded? And to make this a little more legible, we'll add, let's see, USD amount is y column. So we'll just add this here so I can see. All right, totals about 159 million in this three month period on average each week is about 10 million through swap router zero two. It is actually interesting to note that the V three router passes more volume through this pair than the v two router.
00:17:50.668 - 00:18:33.586, Speaker B: But this isn't really good enough yet for us to figure out which is a mev contract. Instead, we need to do one more step. If you think about it, if someone deployed a mev contract, there shouldn't be that many people interacting with it. My hypothesis is there's maybe ten or 20 wallet addresses that actually execute on the Mevbot contract. It's not like the router where there's probably millions of people calling it. So what I'm going to do is I'm going to basically count the approximate amount of contracts interactors. So to do this, I'm going to take all of the traces, right? So traces is just any call to a contract.
00:18:33.586 - 00:19:29.730, Speaker B: It could be top level of a wallet calling it if it's the first trace, or it could be a subtrace where it's a contract calling a contract. And we'll say two as contract address. And I want the traces where the trace two is in select contract interacted from aggregated swaps. So this is saying take all of these guys, so all of these points here. And what we're going to do is we're going to count approximately the distinct number of interactors, right? So this is the account to as approx interactors. However, since this is traces, some of them might be wallets, some of them might be contracts. So I'm going to add another join here, I'm going to say left join ethereum dot creation traces on create address.
00:19:29.730 - 00:20:13.290, Speaker B: I'm going to explain it in a second. Equals tr dot from. So creation traces is all of the contract deployments recorded to the blockchain. So if I join it on the caller, I should be able to tell if the caller is a contract or not. So I'll say case one create address is no then from else no end. So then this would give me the number of wallet interactors, right? So this is saying, all right, if you're not a wallet, we don't care about you. And if I copy and paste this over here, then I can say where is not null means that this is a contract interactor.
00:20:13.290 - 00:20:46.482, Speaker B: Now we also want to do a time filter here, just because otherwise this is going to crash. So we're going to say when transaction trace block time is greater than now minus interval. Remember, we already have a variable for this in months. So now we can take what we already have in the aggregated swaps. I'll call it ag and let's left join. Ag. Let's left join approx interactors.
00:20:46.482 - 00:21:32.160, Speaker B: ACI on ACI dot contract address equals aggregated dot contract interacted. So I'll take all the values I already have from ag and then I am going to take the coalesce of ACI approx wallet interactors approx wallet interactors. And then I'm going to copy and paste this to get the contract interactors. Right. So now this gives me a lot more enhanced metadata. Let's run this transaction from cannot be resolved. That's because it should be traced from.
00:21:32.160 - 00:21:55.382, Speaker B: Let's rerun it. All right, so our data loaded. So let's now play with this new data. I like having the USD trade as the circle size. So I'm going to change this column to number of wallet interactors and I'll just change this one to total swaps. But I can see there's some separation going on here. The swap routers are still out here and there's a bunch of routers.
00:21:55.382 - 00:22:31.120, Speaker B: These are basically you're going to find all of these are different aggregator contracts that have 50,000 or more interactors down here in the 300 to 40 range. You'll see there's this one big contract here called generalized frontrunner. This is like probably one of the biggest contracts are funds basically in the space for at least for uniswap v two. Nothing else really stands out near it right now. But that's also because we're grouping by name. So if there is no name then it won't show up. So I need to make this better by doing a coalesce of name.
00:22:31.120 - 00:23:10.152, Speaker B: And if name doesn't exist then we're going to call it the contract interacted as source label. And I'm also going to start checking my work against the mev data set. So again, if I do labels and I find mevethereum, I can just bring that in here. So left join. I don't have to filter on chain because this is already ethereum. I'm going to call this MEV on MEV address equals ag dot contract interacted. And we're just going to do a case.
00:23:10.152 - 00:23:36.914, Speaker B: One mav address is null, then not mev else. Mev as mev type. We have labels in here. Now let's join it again. I forgot end case when always an end. Let's run it again. Cool.
00:23:36.914 - 00:24:19.090, Speaker B: So our data has rerun and I'm going to replace group by here with source label, and this is going to start crashing my computer because it's so many data points here. But you'll see there's another contract here, Xerox beef, something that has more volume on medium than even the generalized front row does. So I might actually search it up here. Let's see, was it categorized as meV? It is categorized as Mev inside of our labels. But I can search it in here as well. See that it is a mev bot. So we're already able to start getting at the data.
00:24:19.090 - 00:25:20.966, Speaker B: The best way to check is now that we have the MeV labels in here, I change this to total interactors, change this one to number of swaps, change this one to median USD trade, and I group by Mev type. You can see based on the labels of Etherscan, all of the mev is down here, right? Everything up here is not meV. There's probably maybe a good chunk of a third contracts here that are Mev based off of this. This is actually a great example of maybe being able to use linear regression or not linear regression in this case, logistic regression, or the SVM methodology in Trino. So Trino, SQL ML, they have some machine learning functions if you want to play with it. For the bonus question, that would be a great way of taking this further. However, what I can decide from this is there really isn't a good way of checking if contract is Mev or not.
00:25:20.966 - 00:26:05.620, Speaker B: My method works in separation and separating the contracts too, but it doesn't work perfectly. So I can't just say, oh, if you're under 300 interactors and you have 100 swaps total, then you're a MEV bot. Like, I can't really do that. There's ways of improving this approach as well by checking like, oh, for their swaps, how many exchanges did they interact with? So we did just two trace. We did just a join on transactions, but you could join on all traces of the transaction and get the number of exchange contracts interacted with. That might do better as well. So for now, we're stuck with just trusting the MEV labels data.
00:26:05.620 - 00:27:08.440, Speaker B: So if I wanted to basically go all the way back to the volumes query up here. So I have volumes here, right? All I'm going to do is say select from volume. And I have, this was by minute and it has prices by week. So this was by week. And what I want to say is let me join volume by labels and join it on v dot contract interacted. So I have time, I can do a case. One basically I did up here and let's just do the sum of total swaps.
00:27:08.440 - 00:27:52.408, Speaker B: Right? And just for fun, we can. All right, so we have this. Let's run it. It's a good example that sometimes you do a lot of data exploration, like test analysis and work, and you can get a better intuition for the data, but there might not be anything actual you can do with it and then you end up having to go to a much simpler method. In our case, you could have just started with this and this would be the correct answer as well. But obviously manually labeling things is not always the best method. If there was a way to generalize it through some sort of functional methodology, then that would be amazing.
00:27:52.408 - 00:28:16.000, Speaker B: But unfortunately we can't do that. So we're running it this way. So I added a comment just so people who read this query know what's going on. I can't do better than labels right now with my exploration. So we're sticking with just labels. And I'm going to have a bar chart here with time. Total USD amount, total swaps.
00:28:16.000 - 00:28:54.926, Speaker B: I'm going to put the swaps on the right side. So right side is total swaps, left side is total USD volume zero a 0.0 a, 0.0 a. And I'm going to group by mev type and enable stacking. Oops. All right, so I can't actually put these values together on the group by, but I can see what amount of trades each week are mev versus not mev.
00:28:54.926 - 00:29:32.476, Speaker B: So I'm going to say this is USD mev versus non Mev trades. And if I wanted to, I could normalize to percentage. And you kind of see that. Oh, on average, maybe 50% of swap volume for USDC ETH is a MEV trade. I think that the percentage is actually even higher than this. But without finding a better methodology for identifying MeV trades right now we can only go with labels. So if you find a better way, definitely let us know in the comments or on Twitter or in the discord.
00:29:32.476 - 00:29:35.112, Speaker B: This was just a first run at it and you're done.
00:29:35.216 - 00:29:59.592, Speaker A: Thank you, Andrew, for that beautiful walkthrough. Very informative. Next, for bonus points, you could train on our labels data table to try and generalize things using the SVM classification. You heard it right, you can train machine learning models. So we're going to put a link on how to do that on our engine. And then, so for tomorrow, we're going to identify the volume frequency of swaps based on the source. See you tomorrow.
00:29:59.616 - 00:29:59.880, Speaker B: See you tomorrow.

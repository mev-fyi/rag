00:00:20.720 - 00:01:21.158, Speaker A: Cool. So if any of you have followed Anatoly's Twitter from before Solana took off, you'll know that censorship resistance was one of the things he often got in fights with other people on Twitter about. And one of the reasons it's the most contentious thing, perhaps especially for newcomers who haven't seen over the last five, six years, some of the things that go wrong when you don't have censorship resistance is that it can be kind of this daunting task when you kind of have to change your mindset from thinking about centralized services and developing in the centralized world. So maybe we'll start by first having each person briefly say what they kind of are most interested in, why they're interested in censorship resistance, and then either provide us with their favorite metric for measuring it, or their favorite attack. So I'll start with Antoli.
00:01:21.206 - 00:01:21.814, Speaker B: Oh, man.
00:01:21.934 - 00:01:24.638, Speaker A: I mean, you have a long provenance on Twitter.
00:01:24.686 - 00:02:15.874, Speaker B: Yeah, the basic theory that I have is the network is trying to reduce information entropy in the world. You're trying to synchronize all this noise into some real state that's agreed upon by the entire globe, and you're trying to do this at the speed of light. And we don't have a way to do the physics. One way I can think of is we all have neutrinos that all have a fully connected point to point network, but we don't have that. So what we can build are these BFT systems, and the way to guarantee that things are synchronized and nobody's mucking with the information flow is to maximize the Nakamoto coefficient. So that's the main metric that I think of. The minimum set of nodes at up to 33%.
00:02:16.694 - 00:02:17.430, Speaker C: Cool.
00:02:17.582 - 00:02:17.886, Speaker D: Yeah.
00:02:17.910 - 00:02:59.268, Speaker C: So, hey, everyone, name's Anthony Diprenzio from Alio. And I would say that when it comes to censorship resistance, the reason that I'm so interested in it has to come from a privacy perspective. So I'm a huge privacy advocate. And when we talk about scaling and censorship resistance, I think that's actually a really important topic to take into consideration. And a lot of the things we're doing at Alio are actually very much focused on that. And I guess a metric I like to look at is just one, how decentralized the network is overall, and then specifically how particular layer ones are tackling that. I think there's many different ways in which we'll probably cover that in this discussion, but I would say that, for me, that's the first thing that I typically look at.
00:02:59.268 - 00:03:15.504, Speaker C: And then again, looking at how security works as well. Is it sort of like a shared security architecture? Is it coming from the layer one itself? Is it coming from a L2 solution? So I would say those things in general are what I typically look for when thinking about censorship, resistance.
00:03:16.204 - 00:03:48.084, Speaker D: And I'm Larry Cermak, I lead the research at the block. For me, decentralization is about two things. So first, obviously it has to be difficult and expensive to shut down the network, and then it also has to have a good uptime. So it has to stay up. So the metrics for me is geographical dispersion and then also ability for people, and not just hobbies, but in general, people have the ability to run the node. Those are the two most important things for me.
00:03:48.704 - 00:04:37.354, Speaker A: Cool. And with that, scaling has kind of been on the tip of the cryptocurrency research community's tongue since basically 2015. That was the first sort of scaling bitcoin conference. We've seen a lot of improvements made to scaling, and at the same time we've seen sort of a lot of stumbling blocks where a lot of things that people thought would lead to better scaling kind of didn't. Or in, you know, theoretically they worked, but in practice, the engineering difficulties were super high. So maybe let's start with the losses. So in your minds, what were some of the biggest failures in scaling that we've seen over time, especially as we tried to make them censorship resistant and maybe start again with you, Antoley, because failures.
00:04:38.134 - 00:04:42.034, Speaker B: Shoot, why don't Larry go?
00:04:44.844 - 00:05:23.174, Speaker D: Yeah, so I think if I'm not being too specific, I think one of the bigger failures has been just complete inability to estimate how long things will take. So, like, if you look at, you know, I joined crypto full time, like 2016. Back then people were saying, you know, shorting in two years, proof of stake, like stop mining now, it makes no sense. Like you're going to lose money. And it's been, you know, it's been five years and there still hasn't been a proof of stake switch sharding, still probably two or three years away. And no one really has the ability to estimate these things well. So I think that to me is the biggest failure because it kind of discouraged a lot of people that were thinking this is going to scale soon.
00:05:23.174 - 00:05:40.574, Speaker D: And now you have tens of thousands, mostly hundreds of thousands of people joining, and they're looking at Ethereum history and saying, why didn't this happen? Is it just broken? So from my perspective, that's the biggest failure. If I'm not going to specific details like plasma and all that.
00:05:41.714 - 00:06:21.934, Speaker C: Yeah, I guess for me, I think when you're trying to inherently change something fundamental about the layer one protocol itself, sometimes you see failures there. So an example would be something like, maybe. I don't want to name a specific project, but like, changing the block size, for example. I think maybe we could all agree, perhaps, was something that wasn't as successful as maybe we would have thought. But when you're looking at least from a L2 perspective, I think there's a lot of promising solutions out there. Larry just alluded to some of them, and I'm sure we'll get into a discussion about it. But I think, yeah, generally, just making that distinction between what are the changes happening on the layer one versus the L2 is important when looking at successes and failures.
00:06:22.834 - 00:06:26.734, Speaker B: Should I go? Okay, I don't want to be too spicy.
00:06:28.994 - 00:06:31.414, Speaker A: I think the seat is yours.
00:06:32.344 - 00:07:14.076, Speaker B: I think things that have basically not succeeded are things that are trying to scale application level TPS without getting to the core of what the network does. And that core censorship resistant piece, the Nakamoto coefficient, if you don't tackle that problem and you're only working at the higher levels, you end up with a system that has a very slow bottleneck at some point or another, and that will manifest itself as a failure. You'll have those bottlenecks that constantly back up against adoption, against real world usage, against unpredictable real world usage. So that's kind of how I look.
00:07:14.100 - 00:07:27.312, Speaker A: At it, for sure. That certainly comes is a spicy take in that it's the opposite of what Larry wanted, which is Larry wants everyone to run their own node, which might not be be totally possible outside of the app change.
00:07:27.448 - 00:07:50.220, Speaker D: Maybe not everyone, but at least everyone has the ability to, if they have decently enough resources. I don't want anyone to have to spend, like hundreds of thousands of dollars to run a node a year. I think there's a certain threshold, and I think that's why there's so much nuance here. It's like, I don't want anyone on their phone to run nodes, but I want anyone who at least tries reasonably enough to be able to do that. And a lot of blockchains don't allow you to do that.
00:07:50.352 - 00:09:08.304, Speaker A: Aren't you happy that we're done with the 2017 pitches of validate ZK proofs on your phone? Yeah, I feel like I remember a million of those pitches. Man, what a wild. At least this time I haven't seen anything that dumb. So scaling inevitably comes at a cost to censorship resistance, and a lot of this gets passed on to the users or validators, or both. And at the end, sort of the goal of improving throughput or reducing latency, or reducing the number of interactions a user has to make kind of come at the expense of how easy it is to be a validator and also how many validators you can actually have. Things that oftentimes can be a little bit difficult in this world are sort of a lack of decentralization. So to Anatoly's point, kind of Nakamoto coefficient, a lack of verifiability, there's sort of, to Larry's point, sort of this voter apathy thing, right? So in blockchains, people vote with their node, but if there's not really that many people running nodes that are adversarial, then everyone is just, you know, checking the yes box oftentimes.
00:09:08.304 - 00:10:01.844, Speaker A: One thing I think that has, you know, I think has been interesting, especially in the Solana community, is sort of difficulty in indexing data and doing sort of retrospective analyses, given certain constraints that have been built into the protocol. And then sort of one thing that to the end user that is quite apparent is alternative forms of sort of extractable value. More than your traditional sort of mev. Your choice of design for scalability and censorship resistance can actually introduce extra forms of extractable value. So which costs do each of you think are sort of acceptable to place on the user versus the validator? And how do you kind of reason about that spectrum of who bears the burden? Because there's no way of getting around the fact that someone's going to bear that burden.
00:10:02.544 - 00:10:02.896, Speaker D: Yeah.
00:10:02.920 - 00:11:23.934, Speaker B: The way that I think about it is there's like some fundamental way to measure decentralization. And I always like, look at the nodes, how much do they cost a year to run? That's like a measurement. And if the network charges the user of multiple that is ridiculously high, like above four x, to use that level of decentralization, then it is overpriced to a point that there should be a competitor that's just beating them at it. That's effectively, you have some margin of how much you can screw the user. And if you go beyond that, it doesn't make any sense that you just don't replace that whole thing. If you take that into account, then the optimizations that get you to that low margin where the user fees are low enough to where the costs of the hardware are barely covered, you're effectively doing that by scaling the single node, making it faster and cheaper, because that's where you get scalability you get cheaper access to bandwidth at a data center, you get more throughput out of more cores in a single system than a bunch of small systems, and that's where that curve maximization occurs.
00:11:25.614 - 00:11:25.990, Speaker D: Yeah.
00:11:26.022 - 00:12:09.458, Speaker C: So I would echo a lot of things that anatoly just mentioned, and specifically, like with Alio, like our consensus mechanism is an offshoot of proof of work called proof of succinct work. And with that model, the general idea is to actually incentivize miners in the system to build more efficient hardware for basically mining blocks and grinding snarks in our system. So I think perhaps if you start off with a system that's really heavy in terms of costs for validators and other users on the network, as long as you are trending toward a scenario where you're making it more accessible for a larger and more generalized community, I think that's actually a really good strategy. So, yeah, just to add on to maybe what Anatoly mentioned, that that would be like, another point I would want.
00:12:09.466 - 00:13:16.764, Speaker D: To say, yeah, for me, what's really important is, like you said, Tarun, verifiability, not trusting Anatoly, like what he says, and actually verifying for yourself is very, very important. And one of the issues, I think, with Solana early on, not just when it comes to verifiability, but also just data availability and being able to verify some of the things that Solana was saying was quite difficult initially, and that has improved a lot in the last six months or something, but that is very important. I would not want to make any compromises on that side. I think when it comes to decentralization, it's such a contested thing. But in general, I think it's okay if a network starts relatively centralized or not the most decentralized, as long as there's the assumption that it will get more decentralized in the long term. And in general, I mean, we've seen it this year, a lot of people in general either cannot kind of be able to establish what's decentralized. It's a very difficult thing to measure, in a way, especially for people that are joining now, a lot of retail and sophisticated people, they don't know what's decentralized and what's decentralized.
00:13:16.764 - 00:13:34.604, Speaker D: So in general, as long as those people believe that it will be decentralized enough and that you will be able to perform some sort of like, regulatory arbitrage through enough decentralization, that I think it's fine, as long as it keeps kind of going to a goal of decentralization so that's the most important for me.
00:13:34.944 - 00:14:05.118, Speaker A: Well, actually, maybe this brings us to another point, which is how do you present the value of censorship, resistance or decentralization to the end user? Because I think especially as we get a larger swath of users who don't care about pseudonymity, anonymity, privacy, or any of the earlier goals of cryptocurrencies, you start running into a lot more difficult of a time of sort of explaining to the average person why you care about this.
00:14:05.216 - 00:14:25.346, Speaker B: So it depends on what they want, right? So you can have a network that is really decentralized, but it has one leader that's always coordinating, and that's fine, actually. Like, if that thing goes down, if all the state is available, people will recover and continue. And that may be okay for some.
00:14:25.370 - 00:14:36.394, Speaker D: Use cases, but how many copies or copies of state do you need that you think that you need to be able to do that? Because, like a lot of people would say you need several of them to be able to verify that that's the correct one.
00:14:36.474 - 00:14:45.426, Speaker B: So the user shouldn't pay for more copies, like 1000 x more copies than they're getting. Like me as a user, I should know, hey, I'm paying, but you as.
00:14:45.450 - 00:15:12.868, Speaker A: A validator, if I'm a seed in a torrent, well, there's certain number, there's a certain depth of data availability that I need, or if I'm a data availability layer, there's a certain amount of error correcting code paths that I need and shares that I need. I guess the question is back to this minor versus validator versus user spectrum. Who do you put the onus on? Because you really are kind of splitting this worst case cost between them.
00:15:13.036 - 00:15:33.486, Speaker B: Well, the network needs to receive enough fees to cover its costs and plus some margin to make it interesting for validators. But beyond like a forex, it's basically like infeasible. You look at something like Verizon, right? They don't charge you forex the data rate, sure.
00:15:33.590 - 00:15:40.954, Speaker A: But actually, why do you anchor yourself to the number four? I'm kind of curious. It seems like there's a magical constant you picked here.
00:15:41.494 - 00:15:48.434, Speaker B: If it's like eight, then it's easy to look at the network and be like, okay, I can compete with that by cutting it by half. Right?
00:15:49.774 - 00:15:57.554, Speaker A: To your point, if there exists existing telecom networks that don't even need four, why four? It seems like kind of a random number.
00:15:58.754 - 00:16:21.214, Speaker B: Random in the sense that it's hard to get enough people together to only cut the cost by two. It's just like a capitalism problem. I need to build another competitive network, and I'm only getting this margin. There's just some way in place where the network can extract value, but it can't grow too large.
00:16:22.274 - 00:17:07.264, Speaker A: This actually brings us to the, the sort of next thing I wanted to talk about, which was, as we've kind of seen alternative assets increase in popularity in crypto past just defi and store value assets. We've also seen the sort of stratification of the type of user and chain. So different users will go to different chains. So users who are more price sensitive or kind of, this is their first ever usage of crypto. They're not trying to send, like, a million dollars to someone. They're trying to buy like a $10 ape number five. And that's kind of like, you know, caused a huge amount of growth in polygon and Solana in particular for these types of transactions.
00:17:07.264 - 00:17:56.604, Speaker A: But one question is, you know, as we enter this world where there's different qualities of service and different demands of service from different users, how do you think the definition of censorship resistance will change over time? Because clearly it's already changed since. I think at each market cycle, there's a slight deviation in what the definition of censorship resistance means to the end user. So how do you kind of see how it will change, and how do you kind of sort of see censorship resistance being demanded by users at different levels of quality of service, especially in a cross chain world where someone might say, have done $100 transaction with Solana, but they want to exit to ETH and they're like, their mind is blown when they saw a transaction fee. Right?
00:17:58.904 - 00:17:59.216, Speaker C: Yeah.
00:17:59.240 - 00:18:00.872, Speaker A: Maybe you can start with Anthony.
00:18:01.008 - 00:19:17.336, Speaker C: Yeah, sure. So I think that's a really good point, and I'm a huge advocate or somebody that believes this industry is going to scale horizontally such that you have application specific blockchains out there? Kind of what Tarun was just mentioning right there. And so I think the thing to consider is that because these blockchains will be built for certain applications, like, people are going to be drawn to those specific blockchains for whatever specific application is that they're trying to build, and there's going to be trade offs with that. Right? Like, when you look at these different layer ones, there's sort of this classic trilemma that people talk about, which is scalability, privacy, and security, which we've been talking about, decentralization, which we've been talking about as well. And so you need to make that decision as to what am I willing to make a trade off for from the layer one based protocol perspective out of those three things. And then once we start having these interoperable blockchains, sort of like interacting with each other, then we're going to start to see things like shared security, which I mentioned before. So basically, if you have a certain way in which your protocol is operating in your base layer one, it's actually going to be interesting to see how that impacts another blockchain which somebody is connecting to, especially when we're talking about complex defi applications.
00:19:17.336 - 00:19:52.464, Speaker C: So I guess the definition, I don't know specifically how it would be quantified in the future, but I think it would have something to do with how is your chain and its underlying principles as a protocol contributing to this shared security of the overall network. Perhaps there will be some interesting ways that people will be able to quantify that. And I actually heard a talk by a good friend of mine who was talking about something called superfluid staking between different blockchains. And when they described that concept to me, it kind of seemed interesting how some of these things might transpire in the future.
00:19:54.644 - 00:20:27.924, Speaker D: Yeah, really tough question. I think in general, I think people just are the people that are coming in right now unable to just determine what is decentralized, what isn't. So in general, I think people right now are drawn to just the opportunities. So we saw it with Solana, polygon, avalanche, all of this. You have new protocols there, but you're basically mirroring the stuff that's happening on Ethereum. And a lot of these people are joining because they can't afford to trade on Ethereum or use Ethereum. And they think that there's 101,000 x opportunity in there.
00:20:27.924 - 00:21:17.252, Speaker D: And in general, they don't care how decentralized it is unless they lose money in some way. So that's kind of my view right now, is that most people that are joining right now, they just don't care, and they're not going to care for a long time. What they care about is the opportunity and what they can do on the chain, which they currently can't do on Ethereum. But yeah, just in general, I totally agree. I think there are different use cases that work for different blockchains based on how different people perceive them in censorship resistance. So, for example, for me, if I saw that Solana was down for one day, I would probably not want to trade $1 million positions and risk potentially being liquidated if the price moves too much in that time. That being said, I would happily trade nfts on Solana because I don't really care.
00:21:17.252 - 00:21:39.168, Speaker D: That's good enough. The blockchain is secure and decentralized enough for that, at least from my perspective. I think a lot of people will start thinking about it in that way as well. Like institutional investors, they're putting billions of dollars on the line, or hundreds of millions. They think obviously differently than the retail investors they're joining right now, the people that are starting to use fantom. So I think it's just going to.
00:21:39.176 - 00:21:56.884, Speaker A: Be very use case specific, nice little, nice little jab. And I feel like you actually disagree with both of these because you believe in the one size rules.
00:21:56.924 - 00:23:13.394, Speaker B: All I think the most important thing is going to be, in some ways kind of agree with you guys, is the cost to exit, like the cost to run away. And to market makers, that is the cost of a cancel message. How fast can it get out of my position? And to users it might be how fast can I get to an exchange or something like that, or convert to native USDC. That said, I don't know if users will attach that to censorship resistance in the sense that I think it's very hard to build a global financial chain that connects all the exchanges, all the liquidity providers, all the stablecoin issuers without that. Because the fundamental thing that layer one provides is the security properties of running this node that each exchange, each provider runs. And the synchronization guarantees that they get that nobody's messing with their state, nobody's messing with the information they're receiving. Their security teams need to understand the properties of the system and they need to feel secure about it because they're actually putting real capital at risk there.
00:23:13.394 - 00:23:24.874, Speaker B: So if you don't have censorship resistance, it might be really, really hard to, to build that network. And ultimately that's what's going to decide where users go and where they feel comfortable.
00:23:25.034 - 00:23:39.330, Speaker A: So your argument is that the whales will lead. The whales care about censorship resistance. The users depend on the whales. And so because the users depend on the whales, they implicitly are second order carers of censorship resistance by whales.
00:23:39.362 - 00:23:43.730, Speaker B: I mean applications like businesses like things that care, right?
00:23:43.802 - 00:24:38.744, Speaker A: They are the biggest wallets also, some might call them whales, depending how you think about it. What do you think the things that kind of these larger institutions who are evaluating, building on these things, what do you think they are evaluating about censorship resistance right now versus individual users? So Larry, you're talking about how users are just like, hey, my friend got rich off the uni airdrop, so I want to get into quick swap and saber and whatever as one modality of user behavior. But on the other hand, on the institutional side, let's say we take the anatolian model of the trickle down censorship resistance theory. What is the minimum viable set of features that institutions need, or that you think institutions need?
00:24:41.344 - 00:25:09.704, Speaker D: Yeah, I think they just need some sort of guarantees that their money is safe if something happens. I think that's really the biggest point. Like, when we talk to institutional investors in general, censorship resistance only matters to them for two reasons. One is regulatory arbitrage. So being able to somehow interact in things that they were not able to interact with before. And then second thing is, like, how safe are these things? How can we evaluate these things? And it's very difficult. Like, I don't really know how to answer that.
00:25:09.704 - 00:25:49.174, Speaker D: I would say probably ethereum right now is obviously more secure, but it's hard. It's like, how do you define that? Can you lose some money if, like I said, I don't want to take jobs, but if Solana goes down for some time, what happens? Do you have guarantees that your money will still be there that's not going to be liquidated? How do you explain it to those guys who are already basically struggling with simple things? Most people probably think that institutions are pretty sophisticated, but the guys that we have coming to us on the research side, they're very beginner focused right now. They don't really know how to think about these things. They pay us to tell them how to think about them, and we tell them. We don't really know.
00:25:50.874 - 00:25:57.570, Speaker A: It's hard, brutally honest. Panel audience I think maybe we've been.
00:25:57.602 - 00:26:47.710, Speaker B: Lucky that a lot of the institutionals we're dealing with are traders jump, and they inherently understand risk. Something like a 17 hours block time to them. They can actually model that as, okay, the liquidation engine's down because the Oracle updates are not happening. And what happens in the smart contract if that price moves by, so forth? Does the smart contract actually handle that kind of difference? So there's effectively kind of ways to go deep in the finances of how the state updates work and understand it from a mechanical perspective. As a trader, I think the killer use case of these systems is price discovery. It's trading. And those are the folks that will get onboarded first.
00:26:47.710 - 00:27:03.070, Speaker B: They'll trade, they'll make markets. And the institutions that sit on top of that level, that need liquidity, that are actually doing the big movements of money for business reasons, they will get comfortable because the market makers are there.
00:27:03.262 - 00:27:21.542, Speaker D: Yeah, actually, maybe. Quick question also for antilles so jump. Obviously, one of the biggest market makers in crypto, maybe the biggest right now tower as well, somehow active. How did you guys, or why do you think they're interested in Solana so much? And they're also doing a lot of venture in Solana. Just in general, how did you attract these guys?
00:27:21.718 - 00:28:15.374, Speaker B: It was that core idea that in theory, if we keep optimizing this thing, then the information traveling through the network is going to move at the speed of light through fiber, and that's as fast as news can go. So things like Nasdaq, that trade at sub microsecond speed, those trades are not actually happening at new news. It's just the statistical noise in the order queue. So if Solana gets at the theoretical limit, imagine a news wires flying from Singapore to New York, that state transition is propagating. At the same time, the trader, when they look at a market running in Solana, or one at New York stock Exchange or CME, they should see that price already reflected. So you don't have arbitrage on real information. And the costs are the cost of hardware, and that's effectively zero.
00:28:15.374 - 00:28:22.714, Speaker B: So from their perspective, this is like, okay, all the people that are charging us billions of dollars in fees for the work that we're doing, they're now disrupted.
00:28:25.454 - 00:29:50.724, Speaker A: Yeah, I mean, I guess, from my perspective, I guess when I was in trading, one of the things that doesn't really exist in a lot of HFT kind of environments is atomic transactions between multiple venues. So you have to maintain your best view of what multiple closed source systems are doing and then try to guess, like, when they can actually interact with each other correctly. And a blockchain gets rid of a lot of the guesswork you do there, which can cost you billions of dollars. So I guess one kind of maybe more. Last thing that we haven't touched on in censorship resistance is improvements in cryptography. So if we think about the last cycle in 2017, a lot of people were really promising a ton of huge improvements on cryptography, both on the zero knowledge proof side, as well as in sort of like, other forms of NPC, all sorts of things that should, in theory, allow you to make weaker assumptions in your blockchain in other ways, like weaker consensus protocols, faster latencies, whatever. But the cryptography would make sure that you would be able to have a high level of censorship resistance.
00:29:50.724 - 00:30:44.172, Speaker A: We've seen some of that come to fruition. So we had sort of a Moore's law in snarks during the bear market. So I think for those of you who know. Gross 16 from. Gross 16 until sort of like basically the stark paper in 2018, we saw this pretty much exponential curve since then. It's kind of flattened a lot, but a lot of these kind of dreamlike cryptographic instructions that would really dramatically enhance censorship resistance in the sense that there was a great quote I saw from a talk recently, which is zero knowledge proofs let you reduce your model of your adversary from malicious to honest but curious. And so we haven't quite hit that point yet.
00:30:44.172 - 00:31:10.964, Speaker A: But if we do hit that point, I think there's a lot of work that we will reach on validator diversity and kind of being able to kind of reduce state of these networks, make cross chain stuff easier. So how do you view the impact of cryptographic improvements versus sort of engineering improvements over time? And what types of new censorship resistant applications will that enable?
00:31:12.064 - 00:32:11.272, Speaker C: Yeah, so I think this is a really interesting question, and one of the things I would say is that when thinking about this topic, essentially, I think a term at least that we used earlier, and I think a lot of other projects are looking towards, is building systems that are private by default. So basically allowing users to selectively reveal information that they want to about a given transaction. And I think that's super powerful. So I know, like Tarun, I think we were talking before this about, like, vanity addresses, right? Like, it's interesting to think about that as a concept because you're basically adding some sort of human readable element to an address, which I guess implies lack of privacy, unlike layer ones. But if you can come up with certain solutions, that, for example, everything we do at Alio is so actually, interesting fact here. So Alio actually stands for autonomous ledger executions off chain. You're the first all here.
00:32:11.272 - 00:32:41.876, Speaker C: This is not published anywhere. Basically everything we do is off chain. So we're generating these ur knowledge proofs off chain, bring them on chain with this type of construction. Even if you have a vanity address, because we're private by default, you can actually, I can send your vanity address and you can spend from it. And you don't actually have to reveal that vanity if you don't want to. Maybe there's a specific reason why you wouldn't want to do that. Maybe it has to do with a particular financial transaction, that you don't want to reveal certain information, but again, you can do that.
00:32:41.876 - 00:33:02.732, Speaker C: So I think moving forward, once we see more of these kinds of cryptographic techniques allowing you to do these sorts of things, we'll see much larger scale adoption. One specific area that I'm really interested in is. So everybody knows about DeFi. So I think like Z Fi, like zero knowledge finance is going to be something really interesting.
00:33:02.908 - 00:33:05.820, Speaker A: First time I've ever heard that and I've written papers on this.
00:33:06.012 - 00:33:36.580, Speaker C: So yeah, I think, yeah, there's a lot of interesting things going on, but definitely being able to bring some of these privacy preserving primitives to existing things like DeFi, I think can lead to a host of really interesting applications, given that you can also maintain composability, which I think is really important as well because that was one of the big takeaways I think that we got from DeFi summer and kind of what's been going on in the space right now. So yeah, generally I think those are some of the interesting updates I'm looking forward to, at least from a cryptographic perspective.
00:33:36.772 - 00:34:23.236, Speaker B: I'm bullish on zero knowledge privacy preserving finance, but not on ZKP improving scalability to the level that you should see a reduction in user fees compared to the amount of decentralization that's provided. So like, simply because if you start like just the engineering optimizations and you start getting to those limits like 40 milliseconds is pretty slow, but it's pretty fast and there's no place for us to stuff a ZKP because the prover times are going to push the network into a slower state and therefore increase the cost of the users, like in the worst case. And those limits are just easier to solve with cores and bandwidth, like you actually end up with it.
00:34:23.300 - 00:34:40.706, Speaker A: But there could be asics that are built that are, that get. I think that to me is like the biggest investment opportunity in this space that has been untapped is basically asics for this stuff. But yeah, to your point, the current implementations are quite for, they're great.
00:34:40.770 - 00:34:56.174, Speaker B: I mean like massive amounts of investment and innovation happened over the last five years, but it's still pretty far from guaranteeing that like real time censorship resistance, that's still just bandwidth and packets.
00:34:57.514 - 00:35:33.984, Speaker D: I think that most of the privacy will have to happen in l two s is my opinion. I think if all that is happening in l one, I'm very skeptical, not just from the regulatory reasons. I mean we've seen like how much governments and in general exchanges have been delisting Monero, sometimes even zcash, because they're scared of like, you know, being able to I guess comply with some of the regulations. And I think, I personally think that most of this will just go into privacy first ck roll ups on these solutions, at least that's my opinion. Just from a practicality perspective.
00:35:34.444 - 00:35:38.252, Speaker A: Anthony, you wanna rebut? I feel like you got two.
00:35:38.388 - 00:35:43.460, Speaker C: Yeah, I was gonna say, could you elaborate on, like, why you think privacy should only be handled on L2?
00:35:43.492 - 00:35:53.144, Speaker D: Cause I don't think it should. I just think it's like very impractical. It's impractical from a regulatory perspective. So, like, why is Monero being delisted on most exchanges right now?
00:35:54.964 - 00:35:56.948, Speaker C: I guess cause of. Yeah, like.
00:35:57.076 - 00:35:58.140, Speaker D: Cause it's private, right?
00:35:58.212 - 00:35:59.384, Speaker C: Yeah, like you can.
00:35:59.804 - 00:36:02.944, Speaker B: What is an l two, though? Like, is it just like a Merkle route?
00:36:03.594 - 00:36:09.010, Speaker D: Yeah, like a. Yeah, private zk roll up. Like something like aztec or some of these solutions?
00:36:09.122 - 00:37:04.614, Speaker A: Yeah, I think it's a verifier on another chain that can verify both the Merkle route and the commitments without actually having the data present. Right. So it needs to be a verifier that can be run remotely on another virtual machine that has a different, like, interface. That's roughly the minimum definition, minimum viable definition. But I think I kind of agree with Larry a lot on this, which is like, layer ones to some extent are going to have a really hard time being the dominant player right now until we get to a world where cross chain communication is so good that people don't go to exchanges as much. And once there's actually bridges, then private layer ones are probably going to be able to succeed to some extent. But I think having to go through exchanges just makes it quite arduous for sure.
00:37:04.614 - 00:37:33.314, Speaker A: All right, so we got three minutes left. Let's go through your takeaways. Where do you guys think we're going in 2022 in terms of both censorship resistant technology as well as some of the new applications, whether it's in Defi NFT privacy and so, yeah, maybe start with what area you think is the most interesting and then which one you think will have the biggest. And I will go last.
00:37:35.134 - 00:37:44.634, Speaker B: I think we'll probably see that it's easier to upgrade validator hardware than it is to write new software.
00:37:45.994 - 00:37:48.374, Speaker A: All right, the colo model.
00:37:49.354 - 00:38:17.584, Speaker C: Yeah, I guess I'll stick with like, the privacy perspective. I think that's going to be a huge focus area for people moving forward. I think. Yeah, once people. I think the biggest thing is just being able to educate people on, like, what applications they would actually care to have privacy for. Because I actually get in this debate all the time, is like, why do people even really care about privacy? And to what extent? But I think once we start to see some of these more specific applications where it makes sense, that'll certainly be an area of interest.
00:38:19.884 - 00:38:52.210, Speaker D: Yeah, I'm optimistic about ZK rollups just becoming much more widely used. I think Zksync and Starknet are probably closer than people think, and because they're now thinking it's a year away. Year away? Year away. I think probably in six months we're going to see some relatively meaningful adoption for ZK rollups. And I think a lot of people are underestimating that. And we've seen pretty disappointing traction so far with the optimistic roll ups. So there just isn't that much interest in DeFi on Ethereum right now.
00:38:52.210 - 00:39:16.964, Speaker D: And I think probably like Q one, Q two next year. I would guess that would change pretty significantly. I think privacy will be huge as well, but I think it's going to be slightly later. I would guess end of next year or the year after. I think it's going to be slower. Just because it takes a long time for people to adopt something and then get used to it and then start using something private, I think it's still going to take time, but I 100% agree. Privacy is one of the biggest reasons why I'm here as well.
00:39:16.964 - 00:39:27.000, Speaker D: It's absolutely essential for people to be able to interact privately without leaving all this information on chain that's then traceable by anyone.
00:39:27.112 - 00:39:43.844, Speaker C: Yeah, maybe just add on to that really quickly. So I think the other piece to consider is plausible deniability as well. So I think, yeah, just I want to give Tarun some time as well. But I think, yeah, that's something else to consider when we're talking about, like the privacy question, why it'll be so important moving forward.
00:39:44.664 - 00:39:46.352, Speaker A: You look like you want to add something.
00:39:46.528 - 00:39:56.924, Speaker B: No, no. Anything that's a year away is effectively like an unknown, unknown timeline, engineering estimates, and go beyond two weeks.
00:39:57.944 - 00:40:27.618, Speaker A: So I guess the two things I guess I'm most interested in is so Anatoly's whale trickle down thesis I actually agree with for privacy, which is I think daos that have large treasuries are the number one consumers of privacy preserving technology because they have to interact on chain. And I have been involved in some large art dao transactions where we would have loved to have privacy. So with that, that's the end of our panel. Thank you.
00:40:27.706 - 00:40:28.146, Speaker D: Thank you, guys.
00:40:28.170 - 00:40:28.354, Speaker C: Thank you.

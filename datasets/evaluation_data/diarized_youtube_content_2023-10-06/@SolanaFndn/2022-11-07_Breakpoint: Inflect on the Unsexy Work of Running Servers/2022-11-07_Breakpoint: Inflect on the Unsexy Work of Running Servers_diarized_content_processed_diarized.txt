00:00:00.960 - 00:00:37.014, Speaker A: My name is Brandon, I'm from inflect. My position is the head of customer engineering. Basically, my job is to help my partners and customers optimize their infrastructure. Awesome. So I've been with inflect for about six months now doing that. A couple years before that I worked at Equinix Metal helping run these Solana server program at that level. In that time, when we started setting this up, we found that there was a couple different hardware types that we were utilizing.
00:00:37.014 - 00:01:44.868, Speaker A: One of them was really designed for rpcs and the other was designed for validators. The RPC specific node was really similar, but the main difference between the two came down to really in the processor. So the processor of the RPCs had 32 cores and was a bit slower of a clock speed, whereas the validators were lower core counts but higher clock. What we started to find though was that essentially we were dividing the pool into two separate groups, and if we could find a way to make those act the same, that we would give validators and RPCs more options. So the real goal was to figure out, is there a way to make these slower running RPC nodes catch up with the faster? If you're not familiar, most modern processors are limited by what they call the TDP or the thermal design power. Essentially, there's a maximum amount of heat that can be generated in the processor and it can't be exceeded. If the server is configured properly, it'll actually throttle the clock speed to maximize that performance.
00:01:44.868 - 00:02:25.244, Speaker A: So the theory that I had was, if we can turn down the number of cores in that system, we end up allowing more of that power threshold to be applied to the clock speed. So I took a system and I turned it from 32 cores down to 24, and quickly realized that I didn't have a way to benchmark it. So the reason that I should benchmark Solana is necessity. So when I was getting started, I just knew that I wanted to push the processor as hard as possible. And there's an old tool that some of you may know called Prime 95. It's an old open source project that Linux guys use. It was designed for calculating large prime numbers.
00:02:25.244 - 00:02:58.356, Speaker A: What it does is completely hammer processors. It doesn't touch ram, it doesn't touch anything else, but it'll destroy the processor. So I stood up a system, made the BIOS changes, deployed the operating system, installed Prime 95, ran it, and my first try worked. So I took a system that was designed to run at 2.6 GHz, would usually run up to closer to 2.8 and was easily hitting 3 GHz, which was our target number. So we took those systems, took those BIOS changes, rolled it out to the entire fleet, and gave them out to the community.
00:02:58.356 - 00:03:39.038, Speaker A: And what we found was they didn't see the same results that we did. And my key takeaway from that was that workloads really, really matter, right? So in theory, by hammering the processor, we should see kind of a similar result. But what we found is that Prime 95 is very well multi threaded. If you put it on a system with 128 cores, it would hit every single one of them at its full capacity. Solana, by comparison, for all intents and purposes, is more single threaded. And so what ends up happening is a single core consumes most of the power, while the others sit idle. What we know about thermal design pressure or power, is that whenever we're using less power, it ups the clock speed.
00:03:39.038 - 00:04:17.934, Speaker A: So I lucked out in the sense that the validators weren't seeing the same results that I'm seeing, but they were actually seeing much better results. So dodged a bullet. But the reality was that I knew that I needed a better way to test. And so I went out and started doing research into what are the best ways to actually kind of benchmark Solana or hardware. I went through and kind of identified three potential options. The first was simply just run it in testnet. The theory was that it's free money, you don't have to worry about the actual economics of it working, and it should have what I would think to be similar to real world traffic.
00:04:17.934 - 00:05:12.594, Speaker A: The reality is that the traffic is not real or similar to the real world, and so it just doesn't function the same. The next thing I considered was just running it in Mainnet. That solves the traffic problem, but the other thing that it introduces is there's significant financial costs of actually running the server. And the other main concern with running in Mainnet is that the traffic isn't consistent. So I know that I could hit the server hard, see the same results that end users are seeing, but I couldn't do it consistently, and I couldn't say that the changes and results that I'm seeing were necessarily directly the results of the work that I was doing, as opposed to just it happening to be a busier or slower time on net. And then the third thing that I discovered was the Solana benchmark utility, which is free, it's open source, and it's really designed to do this. It's definitely not the perfect solution, but it runs the same every single time, and a lot of the main concerns can actually be offset with a better process.
00:05:12.594 - 00:06:11.464, Speaker A: So I went ahead and used this launch benchmark utility. My process with this was essentially just do a fresh reinstall every single run. I let it run for 2 hours, so the system would become completely heat soaked, so it would kind of stabilize and then make a minimum of five runs, so that every time there was a weird result, we could kind of average that out and make sure that we were getting more consistent. And that was really when I kind of found the power of this repeatable process. So at that time, I took a position with inflect, really, to kind of focus on the work that I was doing up to that point was with a single provider on a single series of processors, if I could go a little bit farther up the chain, I could start looking holistically at the Solana network and benchmarking. And so I did. And when I got here, what I really found was that the first thing that stuck out to me, I should say, is that a large majority of the Solana network runs on AMD currently.
00:06:11.464 - 00:07:14.144, Speaker A: And that felt really odd to me, because I knew that intel had recently invested tens of millions of dollars into developing their ice lake generation processors with the sole purpose of trying to break into the web3 and cryptography world. And so it felt really odd that this major company would invest a ton of money and build this processor, and then it would not be reflected within kind of the makeup of the network. So I kind of felt like, why? And so I took this process, and I got my hands on some ice lakes, and I started benchmarking, and it wasn't even surprising. What I found was that these systems were out performing even the latest generation AMD by some, sometimes 25% to 30%. But that ends up bringing up an even weirder question, is then, if these are better and they're the same price, why aren't people using them? And what I found was maybe a little bit more discouraging. It's just a byproduct of how people kind of get started in this, right? If you're new to validating, you get on discord, you get on Reddit, and you just try to find things out. What ended up happening in a lot of these cases was simply people were finding old posts that just said things like, AMD is better, and so they would go out and they would find an AMD processor, and they wouldn't test it.
00:07:14.144 - 00:07:59.924, Speaker A: So that kind of brings me back to the original question, why do all this work, right. For Solana to fully realize its potential. It needs to be decentralized. And I think we use this as a buzzword in the industry a lot, talking about data and business structures, but the reality is much, much bigger than that. We need to be decentralized from the standpoint of hardware providers, from telco providers, from geographic locations because of hurricanes or tsunamis, there's geopolitical issues. Like, we really do need to push this all kind of across the entire spectrum. And having everything fundamentally pushed onto AMD can be problematic.
00:07:59.924 - 00:08:45.964, Speaker A: On top of that, it also has to be performant. We can't just be decentralized. It has to actually do what we need it to do. And what makes that really odd to me is kind of a byproduct of decentralization, is that there's no way to enforce or tell somebody to do something, right. So if we say we need more makeup to be intel, we can't just go buy more intel. There's no authority structure by which to do that. And so in this decentralized world, what ends up happening is that information becomes a market force, right? So by doing this work, by benchmarking, by having these conversations, we can actually put that information out there and make a compelling argument as to why people would want to do these things, and it ends up helping the entire ecosystem.
00:08:45.964 - 00:09:04.404, Speaker A: And that's all I had to talk about. If you guys want to catch up with me, we actually have a booth in the back, so please feel free to come chat. I know this is really high level. I'd love to get more down into the weeds and talk. If you have questions about specific processors or processes. Thank you.

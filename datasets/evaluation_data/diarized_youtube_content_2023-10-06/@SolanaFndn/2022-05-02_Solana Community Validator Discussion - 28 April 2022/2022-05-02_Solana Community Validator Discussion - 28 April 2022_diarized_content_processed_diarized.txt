00:00:02.840 - 00:00:43.336, Speaker A: All right, welcome, everyone to the validator community discussion. Thanks for taking the time and joining us. So today our agenda is pretty straightforward. We've got some updates on 1.10, and then Nick from Kronos is going to talk a little bit about his project, some plans for, I guess, future roadmap plans, and then potential help from the validator community that he's looking for. So I'll give some updates and then we'll have Nick give his talk, also get some updates, and then after that we'll have a Q and a discussion. Yeah.
00:00:43.336 - 00:01:05.550, Speaker A: Thank you, Dan. Dan posted the agenda there in the chat. All right, so 1st 1.10 updates again, the updates are pretty similar to what Anatoly said last validator meeting. So Qwik is still under development. The QWik update, of course, is a big change. So there's going to be a lot of testing on that one.
00:01:05.550 - 00:01:43.496, Speaker A: Still. Still no plans for a release date, but yeah, that's going to be a big one. So expect a lot of testing, a lot of time kind of configuring it and making sure that everything's working well before we put it on Mainnet. The other change, which is a little bit more minor, is the account index memory limit was causing a bit of a slowdown on startup. So if you have the account index memory limit mb, sorry, account index memory limit megabyte flag enabled for your validator, then the startup time on 1.9 was a little bit slower. So on 1.10,
00:01:43.496 - 00:02:13.632, Speaker A: we see a close to two times speed up when you've got that flag enabled. So be aware of that for 1.10. Any questions on those changes on any status updates there? All right, great. Well, then I'll kick it off to Nick. Nick's going to talk about Kronos. You could find him on discord, as I'll put it in the chat. But time composer and.
00:02:13.632 - 00:02:16.284, Speaker A: Yeah, thanks. Thanks for taking the time, Nick.
00:02:17.584 - 00:03:24.524, Speaker B: Yeah, hey, great to be here. Honestly wish I could have made these validator meetups earlier. Yeah. Basic summary of Kronos is basically a keeper network for Solana. So if you're familiar with DVM world, is kind of similar to like, gelato, but the main difference is that, like, rather than being kind of an opaque auxiliary bot network that stands like, you know, separate from the core core validator miner network, we're building a plugin to run on the validator nodes and basically make the Solana, you know, validators and RPC nodes that the keepers of the Solana network, and that's like the high level gist of it. It's like you could run this plugin and stake your nodes with the Kronos network and in return for that, crank tasks for users and programs and earn automation fees for doing that. And so basically like utilize spare memory computes that you have on your servers.
00:03:24.524 - 00:04:08.602, Speaker B: As part of that protocol, it's looking to use a token and a proof of stake system to moderate the spam. And what I have to mean, like in order for to enable your node to crank the tasks on Kronos, you need to stake Cron, which is a token we're looking at launching later this year with the node. And Cron works very similarly to the way that the Sol staking token works. And that's like you stake SOl with your node, it goes into this leader rotation process. And when you're leader, you can process transactions and collect the fees. The cron system works very similarly. And that's like you say, cron with a node.
00:04:08.602 - 00:05:05.870, Speaker B: We periodically take snapshots, those live stakes. And then from the snapshot we do a stake weighted sample to basically rotate nodes in and out of this delegate pool, effectively a multilater setup. And so the idea is that only the nodes in this delegate pool are authorized to crank tasks on kronos. And your time spent in the pool is proportional to your stakeholder. So effectively, the rough version TLDR is like, if you have 5% of the crown stake, your nodes will spend roughly 5% of the time in the delegate pool, will crank roughly 5% of the tasks, and earn roughly 5% of the automation fees that are being paid by users and programs. Yeah, so there's, that's kind of like the high level mechanics of the token. All the automation fees, I should say, are paid in sole by users and programs.
00:05:05.870 - 00:05:55.354, Speaker B: So the crown token is non inflationary in that sense. It's just kind of a pure like work token model. And the idea behind a delegate pool is that it will give us a lever on spam and we'll be able to configure and like tune for every task that gets scheduled in Kronos. How many threads across the network are we going to spin up to submit transactions and crank that task? And so we could set the delegate pool size to like three nodes, set it to ten, maybe 20. Makes sense. We're going to be doing a bunch of testing to figure out where that's like ideal number is. And yeah, it would allow us to effectively, if there are other parties in the ecosystem that attempt to crank these tasks on Chronos, but they're not in the delegate pool.
00:05:55.354 - 00:06:52.392, Speaker B: We could penalize them by debiting lan ports. And then the other element there is that if you have cron staked with your nodes and it is going into this delegate pool, but not submitting transactions to crank tasks, there is potential. This is theory right now, but we could slash the Cron stake as well. That's how the incentives are set up. That's the high level technical gist, I think from the node operator perspective around like what Kronos is and how it works. Happy to take any questions there, but there's quite a few I see who consider parameters of delegation pool. Right now it's just an admin address, an admin authority that is able to change the delegate pool size, where for the time being that's kind of controlled by the team on a multi sig wallet.
00:06:52.392 - 00:07:46.354, Speaker B: But long term would be transitioned into a DAo and could be able to be voted on by the token holders and why whatever, not centralized, just the way it's trans. Oh yeah. If I understand the question correctly, I think you're asking like if whoever has that admin authority to change the delegate pool size, if they, if they're malicious and wanted to set the pool to zero, it just stop all pranks that could happen. Yeah, long term, I just voted on by a doubt. It's hard to imagine like the token holders wanting to vote full size to zero, but that could. Yeah, in theory happen. But I can tell you, like, you know, from our standpoint, we're trying to get to mainnet, we'll set the w pool size to a number.
00:07:46.354 - 00:09:06.984, Speaker B: That kind of makes the economics make sense for the network in terms of roadmap. This is the other thing. We're looking to roll out the testnet over the course of May. And so we'll roll off various iterations of the plugin. I think there's quite a bit of optimization work to do there in terms of minimizing the footprints, um, that the plugin takes up. And yeah, we're kind of building out a stress testing suite right now, a benchmarking tool to kind of be able to ask questions like if we schedule 1000 tasks every second for the next thousand seconds, like can the system keep up with that, that execution rates? Or does it start to fall behind? How many nodes do we need in the pool to be able to keep up with that rate? And then how does that change with tasks that can be executed in parallel versus if half the tasks have a shared mutable account that might change the performance of the system a bit. And then also how does the scheduler keep up with network congestion as well? We're basically looking for node operated partners that would be interested in running this plugin on Testnet and Devnet with us to be able to help us kind of find those performance bounds.
00:09:06.984 - 00:10:23.770, Speaker B: And yeah, moving into like the summer, late summer, early fall, we are looking to get to Mainnet like once we have those numbers and kind of prove out like performance of the system. And so to get to Mainnet though, we're basically looking at doing kind of a, the token deal with a few like node operator partners and running as a federated network on Mainnet to buy us some time before an eventual idea of when the token would be publicly accessible and tradable. And that will just give us some time like six to 18 months or so to be able to run this thing on Mainnet without having to deal with the noise of like a openly traded token. And yeah, and then with Rolex on Devnet, basically be working with app developers. We've been chatting with a number of teams for quite a few months from like Marginfi and friction and switchboard and UXD and Sierra one exchange jets. Like all these teams have various background tasks and automations that they need to run. And the vast majority of them right now just using about the native us to spam the program and like crank their automations.
00:10:23.770 - 00:11:00.544, Speaker B: And they'd like to be able to schedule it with you guys, the node operators. And so we're going to be working with them on the Devnet side to work out the exact dev integration. And ideally we'll be able to get it down to a one or two line, just anchor macro that devs can put into their programs and basically say hash Cron, set a schedule for ten star star, and that will be able to queue these instructions as just a periodic batch job that's running in the background and.
00:11:01.684 - 00:11:04.624, Speaker A: Yeah, oh, sorry, go ahead.
00:11:05.044 - 00:11:39.554, Speaker B: Oh my only other thing on the roadmap was like through the summer and fall, you're kind of also pursuing outside audits. The whole system is open source, so if you have concerns about the code, it's openly available on GitHub. And then yeah, we're working like right now working through kind of DevOps issues related to just keeping up with Solana's rapid or at least schedule. So I need to work through some of those. But yeah, it's kind of a high level summary. So.
00:11:41.374 - 00:12:01.314, Speaker A: Yeah, so Michael's question was around open source, it looks like you answered that one. It's going to be open, or it is open source, and it will be audited soon. Sorry, I'm just trying to keep up with the questions as well. There's a question about it being a separate binary or built into the validator binary.
00:12:03.414 - 00:13:05.648, Speaker B: Yeah, for now it will be a plugin binary. So using the geyser plugin interface, I have to talk to the Solana team about what they're not that gets pre installed. I've not partaken in any discussions with Solana team about that yet. So is it able to self update? The plugin is not able to self update, but we will be publishing versions that like. Part of the DevOps kind of challenges we're working through right now is just being able to publish a version of the plugin that matches the Solana, you know, Solana version that it's running with. And you kind of get into like memory compatibility issues if the plugin is running with a different sauna dependency version than what the node is actually running with. And so we will be like keeping up a regular release schedule to keep up with Solana.
00:13:05.648 - 00:14:21.724, Speaker B: And when you restart the nodes, it's effectively you can just pull at the Kronos plugin config and yeah, it should select the right version, so, but it will require like restarting the validator to run with the new version. How do you protect yourself as a validator from Chronos leaking your identity key or interfering with your operation somehow? Yeah, I'm not, I don't believe you have access to your identity key. As far as I'm aware. We haven't really looked at that. But in terms of interfering with the validator performance, we are trying to minimize the footprint of the plugin to be as small as possible. We've had different feedback on that. I'm curious what the community thinks, because running the plugin on a validator with Solestake, I'm still trying to understand the exact replica propagation algorithm, but my understanding is that the nodes with stake receive those replicas a little bit faster than, say, the RPC nodes who don't have any stake.
00:14:21.724 - 00:15:39.594, Speaker B: Your performance may be a little bit better if you do run the plugin on a node with full stake. Yeah, the risk that we're trying to work with is like, how do we keep that memory footprint small enough that it doesn't lead the node into delinquency as it fall behind? And so that's kind of what we're focused on right now. But the benefit of running it done in RPC mode, for example, is that there is no soul stake there, so there's no risk of falling behind and getting stake slashed. Can kernels be used for mvv? Yes, there is like a, we've identified one mev opportunity between, if you have nodes that have both Cron and Soul stake, there will be brief moments in time. For example like if you are the leader node and you have a node in the Kronos delegate pool, you are still racing with the other nodes in the delegate pool to be able to submit your transactions and crank this task. And only the node that whose transaction gets there first wins the automation fee and the others will be reimbursed for the network fee. But only one wins the automation fee.
00:15:39.594 - 00:16:15.736, Speaker B: And so if you are the leader node at that time that you also have a note in the delegate pool. In theory you would be able to block out the other contestants. So that is like one. But it's kind of a transient like opportunity because this pool is constantly rotating. Leader rotation is constantly changing. But yeah, that opportunity will exist at least in the system as it's designed right now. Yeah, yeah.
00:16:15.736 - 00:16:55.162, Speaker B: It needs to dig into the identity key thing. But we're not closed source though. The whole plugin and on chain programs are untouling is all open source. The telemetry service is not something that is intended to run on the validator. That's meant to be a kind of monitoring service for the network. So it just kind of, there's a health check program that we can schedule a recurring task with. It's basically just a counter.
00:16:55.162 - 00:17:30.714, Speaker B: And so it schedules a recurring like ping transaction and really just pings every seconds or every few seconds. And we can track if the, if the network is able to keep up with that recurring task. And the telemetry service just monitors that counter and says, is the network keeping up or is it starting to fall behind with where the scheduled tasks should be and that you can run on a local laptop or aws or wherever you want to run it. It's just meant to be, it's a tooling service that we had built out to be able to track the performance.
00:17:50.754 - 00:17:53.898, Speaker A: Maybe for the purpose of video. Just repeat the question there.
00:17:54.026 - 00:18:37.158, Speaker B: Sure, yeah, sorry, there's one question, another MeV aspect. Through Kronos you can sample and read gossip data from all the elevators that run Kronos. Feed this back to an MEV searcher service and then parse and do as it pleases. Yeah, we're not leveraging the gossip network at all. The plugins don't communicate with each other in any way. At least right now we have no plans to do that, but there might be some optimization we could make by adding that in. Right now all the coordination, I should say, happens through on chain programs.
00:18:37.158 - 00:19:31.918, Speaker B: We leverage the core as long as state layer to coordinate all of these tasks. There's an on chain program that we just call the Chronos scheduler program where users are able to come and they basically create tasks which are serialized instruction data with a schedule. And so what the geyser plugin is doing is really watching that program for new task accounts and then it caches them and also watches the SysbaR clock account. And as the Unix time updates in the SySpar clock account, the node is just checking to see if it has any cache tasks that are now due. And then we'll spawn a thread to submit a transaction to crank the task. And that's effectively all the plugin is doing. And so what we're trying to do right now is optimize the memory footprint of that.
00:19:31.918 - 00:20:17.274, Speaker B: And then. Yeah, like how many threads we're spinning up. And that should be configurable as well. Like we want to be able to add into the plugin configs like don't spin up more than, you know, a few hundred or thousand threads or so for any given like time window. Percent of state Kronos needs to participate. I haven't worked out all the, shouldn't need to be a minimum requirement on the cron stake to participate. There's that network program, that staking program is also just another on chain program.
00:20:17.274 - 00:21:13.420, Speaker B: And so the way that that works is like if you have some cron tokens, you stake it with that program and specify the like node public gossip address there. And that's what registers the node in the Kronos network. And then we have very various background tasks to be able to take the snapshots of those live stakes and then do the stake weighted sampling. So yeah, there isn't a minimum stake requirement there, at least right now. How do I get tokens for participating? Yeah, so we will be distributing tokens for like Testnet and Devnet partners that want to, want to participate. And then yeah, for the Mainnet launch. I haven't worked out all the details for the basic plan.
00:21:13.420 - 00:22:08.874, Speaker B: It's just like everyone that we've been working with on Devnet and Testnet, we would like to work with you guys as a federated network on Mainnet as well. And so there will likely be some token distribution to those node partners and then that would come with a lockup period on Mainnet to be able to run is this like federated network on Mainnet for six to 18 months. Why start Testnet? Starting Testnet just to be able to do the stress testing. We figured that was the network to do those benchmark benchmarking on. If 30% of the blocks are produced by Kronos nodes, the service wouldn't need to be more reliable. Now. Yeah, this is a good question.
00:22:08.874 - 00:22:43.584, Speaker B: I don't really think of them as like Chronos nodes per se. In theory you can stake cron with a node that also has soul stake. Like those aren't mutually exclusive. I think so. But I think there is a question around like what percentage of transactions will be Chronos tasks, and we don't really know the answer to that yet. That kind of is dependent on like demand for the system. Yeah, let's see.
00:22:43.584 - 00:24:01.324, Speaker B: My estimates have been between like one and 10% of it out of size 30. Yes, the system would have to be far more reliable, and that's ideally what we're trying to figure out on Testnet is to be able to really push that system and figure out where does it fall over if the demand far outpaces what we're expecting. And the switchboards and margin files of the world just have insane background tasks that they need to run. You know, how can we make sure that, like the system is able to keep up with that execution rate? Where would a validator reach out to help on testnet? You can ping me on telegram or discordimecomposer. We also have kind of an airtable form, a link on our landing page where you can just like fill out your name there and I'll reach out from there. If you would like to be involved. Is this established question where other plugins are going to want to woo validators for space on their machines? Mostly rhetorical questions, you know, I think so.
00:24:01.324 - 00:25:35.944, Speaker B: I think in some ways, at least through like chatter, I've been hearing one of the most exciting things about the slanted space is that like we can build these plugins and kind of add new functionality to the network that it didn't have before. And that's something that we haven't really seen, unlike too many other chains. And so, yeah, Kronos is a service where we're intending to basically add new functionality to the network to make all the nodes keepers as well for the network. And I imagine there could be some other use cases down the line where new opportunities would arise for node operators that want to run some plugin from notify or dialect or some other teams that are doing some interesting stuff in space. Genesis, go. Maybe I don't not, you know, fully caught up on all of those teams plans and like what they're intending to do, but I wouldn't be surprised if some of them, yeah, come out over the next few months with a plugin that they would like to incentivize operators to run. I think we'll eventually see a kind of market where plugins compete for validators to implement them through various economic incentives.
00:25:35.944 - 00:26:02.334, Speaker B: Yeah, yeah. In a way I think that comment kind of gets at it and that there is like spare memory compute available. So to the extent that like teams can build new features with that spare capacity, yeah, they'll probably be competing for node operator attention to be able to get the plugin installed and provide their services.
00:26:06.194 - 00:26:11.522, Speaker C: Hey, I can just actually jump in here real quick and kind of comment a little further on that.
00:26:11.658 - 00:26:12.130, Speaker A: Thanks, Nick.
00:26:12.162 - 00:27:31.874, Speaker C: By the way, these are awesome discussion, but yeah, to their questions about sort of this, the market for validator compute space. Yeah, I think this really is kind of the first step of seeing a more robust economy with multi pronged incentives for high performing validators thus far. And primarily validators are entirely dependent on the amount of consensus stake that they receive and that should always be the strongest incentive alignment for network success. This is something I've been really thinking a lot about, and we're talking a lot about this on the foundation team, looking at a validator and or an RPC operator as a value added service or service provider to the network that can offer a variety of services and potentially various potential revenue streams in addition to just consensus rewards. And I think Kronos is really kind of leading the charge here. It's definitely the first example of that. I mean, RPC operators ostensibly are like, I guess the OG, right? You spin up these nodes and you pay people to access them and API access to the network.
00:27:31.874 - 00:29:27.434, Speaker C: I think what we're going to see over the next couple quarters is like Nick was saying, a bunch more services coming online that can take advantage of either running on a validator machine or perhaps just configuring or like working with a particular validator and say co locate their machine or their server in the same data center or with the same traffic routing patterns as a particular validator and able to take advantage of that. So Chrono, certainly one neon labs, is developing their EVM proxy. I think that might be one to keep an eye out that might be able to sort of have the success of a proxy operator tied to mutual success of a node operator. I think there's going to be a number of things coming here. And my hope is that what this drives towards is a more complex and therefore more robust validator, sort of like a whole validator economy, you know, if there are multiple different parties, not just your consensus delegators, that are depending on the validator to have good performance and good uptime, and all of these characteristics that are also important for consensus. What we end up with are this aligned incentive structure where you have users and builders and Dapp developers just as dependent on a robust validator community as the underlying network infrastructure. My longer term vision here is this vertically integrated incentive alignment where DApp developers and users, not so much users, but DAP developers, understand that understanding the validator network and the validator network performance has a direct impact on their users UX.
00:29:27.434 - 00:29:44.914, Speaker C: And so sort of mutually assured successes from the infra layer up to the DAP layer up to the UX layer, I think is really going to help kind of move like the incentives for running quality infrastructure to the next layer of kind of maturity over the next year or so.
00:29:49.694 - 00:31:07.884, Speaker B: Yeah, yeah. I mean, I can speak to like, the reasons why we chose to build a plugin to provide the service was mostly the most performant and cost efficient way we could think to do it. And then it also made like the go to markets a little bit simpler because at the end of the day, there's only so many people running this infrastructure. And so it's way easier just to add an extra config to your validator startup command than it is to like, you know, run an entirely new host and server and like spin up some, some bots there. So yeah, it's the most like cost efficient architecture we could think of. And then from the dev standpoints, like, from the perspective of an app developer who wants to schedule these tasks, it just mentally like, the idea that these tasks are going to be cranked by the Solana network that those devs already trust, so to speak, is like solve so many problems as compared to trying to convince devs like, hey, you should trust this separate auxiliary network over here that is really opaque and you don't know how many nodes are running it or who's running the nodes. It's kind of, it's like a way harder sell.
00:31:07.884 - 00:31:24.264, Speaker B: And so, yeah, I think just that mental model of like adding extra features to these nodes that devs could rely on to build like cool features, it kind of solves a trust problem when they realize it's the Solana notes themselves that are powering it.
00:31:29.244 - 00:31:51.244, Speaker A: All right, we're about out of time. Looks like questions are all done in the chat as well. I left the contact info in there in the chat. So people want to get in touch with Elias or with Nick on Discord. Nick is time composer. And then the websites there as well. There's a link to a form where you can fill out your info and talk to them about participating in testnet.
00:31:51.244 - 00:31:59.364, Speaker A: So anyway, I want to thank Nick. Thank everyone for joining. Great discussion. Really appreciate it. So thank you, everyone.
00:32:02.064 - 00:32:04.884, Speaker B: See you. Next one. Thank you. Bye bye.
00:32:05.664 - 00:32:06.224, Speaker C: Thanks, everybody.

00:00:05.240 - 00:00:15.662, Speaker A: Two potential talks today. The first major one is around account hashing, and Josh will lead that discussion. Take it away. Anytime you're ready.
00:00:15.718 - 00:01:15.784, Speaker B: Hi there. Hi there. I'm Josh from Firedancer. Josh Siegel from Fire Dancer. Anyways, yeah, so I want to do is just sort of, I want to say socialize, sort of a project that we've sort of been doing off to the side, which one of the goals of Solana, and I want to say indirectly, also a goal, obviously, of fire dancer, is sort of massive scaling and massive performance. And one of the issues that we ran into that's been this recurring issue is at the end of a block, or even for an entire epoch, there is what's called the account state delta hash, which involves a sort of, of, sort of all accounts that have been updated and then a merkle tree against that. And also, once per epoch, we take all the accounts, all 340 million accounts that currently exist in Mainnet, and we do, again, a giant sort and a giant merkle tree to create a single state of all the accounts.
00:01:15.784 - 00:01:42.216, Speaker B: And we could optimize this within an inch of our life. But in the end, if we add two zeros onto the size of Solana, this becomes a performance problem. And it's annoying. It's complexity. I stupidly brought up, hey, I'm sure we could come up with a better solution. We're now four solutions into this process. Now, we've actually think we've come to a really good one.
00:01:42.216 - 00:02:50.654, Speaker B: That's remarkably simple. Obviously, we started with the really simple and naive solution, which it turned out Solana had already done, which was great, because immediately Solana came back and said, no, we've already been had a white hat hacker tell us this is a bad solution. What we're trying to do, basically, is we're trying to, if you imagine I've got a bunch of accounts that are being updated, and I need to create a uniform description of that entire state update right now, as I said, we create a merkle tree out of it, and you use the root of that merkle tree that describes the state update. I naively said, well, why don't we just xor all those hashes together? Because that's effectively a checksum of the change. It turned out that, well, with some cleverness, you could actually successfully fake that hatch. So we went back to the drawing board, and the next solution we came up with was, well, actually two solutions later. We came up with, using elliptic curve math, where you create elliptic curve points and you can add and subtract elliptic curve points.
00:02:50.654 - 00:03:43.504, Speaker B: And the advantages we're trying to do is we're trying to avoid the sort. We want to be able to add up all of the accounts and create a single thing that's representative, and we're trying to avoid the sort. And we want to be able to take an existing point, subtract out a change, add in the new change, so we can sort of maintain a running version of all the account states. And we want to be able to do it all in parallel, which means we want no ordering, want to be able to run everything in any order. And the elliptic curve map worked great, except it actually took too long to convert from, I'm going to say these, the hash to the elliptic curve point, and it became now a performance problem. How are we going to do it? How are we going to make it faster? And we came up with needless complexity. Well, we'd have parallel threads going off and calculating the elliptic curve points, and I hate needless complexity.
00:03:43.504 - 00:05:01.684, Speaker B: So we said, well, we'll have Kevin Bowers go off and do an amazing implementation of this, but in the end, it was going to be slow. Okay. So we went off, and actually, one of the cryptographers from Solana actually sort of kick back another proposal, which was actually very similar to something that Kevin Bowers had proposed, to be honest, which is just basically sort of arithmetic adds and subtracts of hashes, if the hash field is sufficiently large, is actually secure, according to a bunch of papers that are out there. And because we're already doing the hash one's to generate a 256 bit hash, if we instead use that to generate a 2048 bit hash, we can then do arithmetic adds and subtracts against that, and that is cryptographically secure. Interestingly enough, from a 2048 bit hash, you can derive the 256 bit hash that we actually use in the existing code, which means that we can make this change. And there's no performance downside. We're literally using the existing hash that's already done.
00:05:01.684 - 00:05:37.504, Speaker B: We generate this larger hash. We do it at runtime, it slows nothing down, which is really great. It's great when you can make it like a huge performance change. That's nothing but a performance improvement. So right now, that seems to be good. We've sort of prototyped parts of it already in fire dancer. The next phase, to be honest, is we're going to try to, even though the hasher that Solana is currently using is super fast, it's still not fast by firedancer standards.
00:05:37.504 - 00:06:36.478, Speaker B: We have a bunch of hackers within firedancer or non hackers who really want to go off and implement this in optimal assembly language to see if we can, in fact, make it faster, and then we would share that code between us and Solana so that we actually get a performance improvement on both platforms and we eliminate this sort and this merge and everything. There's one or two downsides. We're still trying to figure out. We're trying to figure out, obviously, this has a problem with inclusion proofs, and so we need to figure out what is the true market requirement for inclusion proofs, and sort of what if we cost ourselves with it? We don't have a good answer for that yet. That's going to be an argument over large quantities of beer, I think. Anyhow, that's sort of the long and short us getting rid of, effectively getting rid of the account state delta hash mechanism and the epoch account hash mechanism entirely. And so it's nothing.
00:06:36.478 - 00:06:46.674, Speaker B: But every slot will have a full hash that's representative of all the accounts in the entire Solana system, and it will actually be faster than we're currently doing.
00:06:47.694 - 00:06:51.314, Speaker C: So I can't believe you guys figured this out.
00:06:53.254 - 00:07:01.054, Speaker B: It took a while. It took a while. We had to keep having a. Kept coming to be hitting the head with sticks to say, no, make it faster, make it faster.
00:07:01.754 - 00:07:09.494, Speaker C: Is there, like, a cryptographic computation to figure out if you have this many accounts, you need a hash this big?
00:07:10.154 - 00:07:25.126, Speaker B: I will send. Why don't I send you the paper? The paper, of course, was only talking about using 256 bits, and I think Sam said, why don't we use 2048 bits or something? Make it something ridiculous. That's just way too large.
00:07:25.270 - 00:07:47.474, Speaker D: That was one of the initial arguments in that the arithmetic add converts the gaussian elimination attack against the XOR into a knapsack problem. But the width necessary was a bit of controversy. But I think Emmanuel has the paper you're referring to that gives the width, and you make it wide enough. It's hard enough, but I'll defend the manual on that.
00:07:49.754 - 00:07:53.454, Speaker C: Yeah, I mean, I'll read it and I'll pretend to understand it.
00:07:56.754 - 00:07:58.962, Speaker D: I just like that it's very, you.
00:07:58.978 - 00:08:00.934, Speaker C: Know, this is how we get into trouble.
00:08:01.634 - 00:08:02.866, Speaker A: Yeah, that.
00:08:02.890 - 00:08:14.506, Speaker D: It's very kind of simultaneously elegant and surprisingly simple. That if you just make the XOR and arithmetic add, it becomes hard.
00:08:14.530 - 00:08:15.534, Speaker C: How old is it?
00:08:16.634 - 00:08:20.482, Speaker B: The original paper that I had was in 2019. I'll just send it to you right now.
00:08:20.538 - 00:08:44.334, Speaker C: Yeah. It's, like a couple years old, at least not three months. Cool. I mean, yeah, in my mind, this makes sense. I didn't understand. Like, this was kind of our intuition, too. If you hashes have impossibly to break preimages, you should be able to combine them in some efficient way, like arithmetically.
00:08:44.334 - 00:08:56.744, Speaker C: That's cool. It's interesting that an ad, it works, but is it like a straight up addition, or is it some kind of operation on top of it? That's an addition.
00:08:58.164 - 00:09:06.220, Speaker B: You actually do, I think, like each. Each word or each long within it sort of is individually added. They call it sort of a lattice.
00:09:06.372 - 00:09:09.304, Speaker C: It's a lattice that works, but an XOR doesn't.
00:09:10.564 - 00:09:22.784, Speaker B: I don't understand. Personally, my intuition is that that would be the same, but I'm a cryptographer, so Sam and I'll ask Sam. Damn. And everybody argued over this.
00:09:23.724 - 00:09:24.584, Speaker C: Okay.
00:09:25.244 - 00:09:43.264, Speaker E: I'm also. I'm not a cryptographer by far, but I do recall from when I used to do quantum computing, that lattice based methods tend to be quantum like, much closer to quantum resistant than most other approaches. So just another small bonus.
00:09:44.124 - 00:09:56.044, Speaker C: So it's some kind of lattice based addition. Okay, yeah, I can shock, I can pretend that that's a magic edition.
00:09:56.204 - 00:10:08.264, Speaker B: I'll call it magic edition. The code is remarkably simple. I'll send you the code, and then you'll say, well, why is this better then? Yeah, smart people.
00:10:09.964 - 00:11:14.114, Speaker C: I think for inclusion proofs, I think that's a separate problem. And I would actually rather run like a system call or instruction that the user that needs an inclusion proof pays for in calls, because it always bothered me the idea that we have to pay for the cost of inclusion proofs on everything, when in reality, vast majority of transactions are not going to be tested for inclusion, like, ever. I would say six nines worth of transactions are never going to be tested for inclusions. So it doesnt make sense to have the entire system pay for it. And I think we should be able to come up with basically some kind of state, maybe its hashed in alongside of this thing state hash plus merkel root of anyone that pays for inclusion proof as the block hash. And that's kind of the easy way to. For these things to register themselves.
00:11:17.414 - 00:11:31.222, Speaker B: Yes. Yeah, that. I think it's. Yeah, I don't want to strangle the entire network for a very small group. I'd much rather pay for it. And once we take, like, clients and inclusion proofs off the table, the solution becomes easy.
00:11:31.398 - 00:12:03.140, Speaker C: Yep. Cool. Yeah, that's great. It's really cool. It's awesome. And I think we still. Yeah, we still need to probably run the, like, the nice thing is that I think we still should run like a sweep of the accounts and recompute them and gossip those out, or like at least locally compare that you got the answer that the running cache has, but that could be run offline.
00:12:03.140 - 00:12:10.624, Speaker C: It's not in the hot path for anything. It's just a much, much easier problem. You can run it with your idle cores whenever.
00:12:16.324 - 00:12:27.304, Speaker F: I think we then get in a situation where individual validators could choose to do that or not. Also similar to how today you can say halt or not when your hash calculation mismatches the network.
00:12:28.654 - 00:12:54.050, Speaker C: Yeah, they can also skip the calculation and just copy the one from somebody from the first submitter. Like people can cheat already. We kind of run in the assumption that the reason that they're running these nodes is they're somewhat incentivized to not cheat, to actually verify what everyone else is doing. And I think two thirds are pretty likely to keep doing that, I suspect.
00:12:54.082 - 00:12:59.614, Speaker F: So. I just wanted to make it clear that it's entirely on the side of the validator. They could choose to not do that.
00:13:00.914 - 00:13:46.732, Speaker C: Yeah, as soon as you have more than the median amount of the stake, you kind of like care that the network doesn't go down anymore. You stop trying to extract, well, you stop trying to secure it. So that's what, you know, that, that happens eventually. Anyone that's successful enough at extracting value will start securing it at some point. Um, cool. Yeah, um, this is really cool. I don't know, I think on the lab side, Steve Akridge, do you, I mean you worked on the original XOR implementation.
00:13:46.732 - 00:13:50.904, Speaker C: This seems like really easy to plug into what we have right now, right?
00:13:52.484 - 00:13:54.064, Speaker E: Yeah, it should be very similar.
00:13:58.604 - 00:14:15.114, Speaker A: Well, do you have next steps for. Yeah, we heard you said do you have a sense of next steps for the inclusion proof work? Like who owns that and especially as it relates to light clients or whatever.
00:14:18.854 - 00:15:22.834, Speaker E: Well, from our end, like, I mean, I've said this multiple times and I'm kind of a parrot in some sense, but I guess like what SIMD 64 covers a mechanism for generating inclusion proofs. If you inclusion proofs of transaction receipts, which I see is, it may not be, it's immediately more useful and clear to me what the use case of that is for end users, especially people on mobile devices, trying to just get a transaction through and just get it executed. Just simple transfers and things like that. To see that either the transaction went through or it failed. These are simple things that are nice to have. It's just a matter of implementing that into the client itself. So I think as far as state inclusion proofs, I think like that work we can defer to when someone really, like, when there's a real need and a want for those things, at least that's my opinion.
00:15:38.114 - 00:15:44.534, Speaker G: All right. Were there any other questions or topics that you all wanted to bring up this time around?
00:15:46.274 - 00:15:47.414, Speaker B: On this topic?
00:15:48.434 - 00:16:34.894, Speaker A: I think as something moderately related, there's just an initiative that just started for a verifying node that just takes, can just take a history and just certify all the transactions. It will be, it won't, it doesn't need to keep up with the tip and stuff, but just make sure that, you know, if you're going to exchange or something, you don't want to run a full voting node and, but you still want to be able to verify all transactions. It's a pretty, it's a much lighter way of doing that. It just makes sure that, you know, in some timeframe, again, not a timeframe that is necessary for vote or whatever, but just to make sure that the balances are correct within you some limit. And that is being worked on actively, which isn't quite this, but it's all about just certifying the transactions and stake of the network.
00:16:37.394 - 00:17:11.554, Speaker E: We're kind of, I'll be agey about how much I say, but we're building this right now as a part of our runtime effort. So we will have something like this before. Like we basically are deferring the fork choice algorithm to a few weeks from now or a month from now and getting the like non voting, just reading blocks of the network actually accepted and doing that first before we do fork choice.
00:17:11.854 - 00:17:17.470, Speaker C: That's all we need for safety. That's done. It's like a major milestone because like.
00:17:17.542 - 00:17:18.194, Speaker A: Yeah.
00:17:20.204 - 00:17:54.924, Speaker C: Fetch voted blocks that already been voted on. You don't have to deal with turbine or anything and you just verify the state. It's all we really need for safety. And I can sleep at night, so I think that'd be awesome. And I think a lot of exchanges actually have trouble running full nodes on AWS because their network stack is virtualized. There's more layers of virtualization than a nested doll. So if they can just download the blocks and verify them, they would be a lot happier.
00:17:54.924 - 00:18:13.364, Speaker C: That'd be really cool too, if we can have the labs version of that and firedancer version of that running in parallel. So it probably take less resources than the current labs client.
00:18:17.844 - 00:18:40.464, Speaker B: Yeah, it's significantly lighter weight, obviously, because I mean, you can even cheat. I said, you can use the repair protocol even to sort of keep up. So you don't even have to even, don't even have to be running turbine. You just repair block as they come in. You watch gossip. You keep up 32 blocks behind, and you use repair protocols and retrieve it. And you execute it.
00:18:41.244 - 00:18:41.836, Speaker C: Yeah.
00:18:41.940 - 00:18:44.184, Speaker B: It's pretty lightweight, very straightforward.
00:18:54.084 - 00:19:19.764, Speaker G: All right. If there are no other topics, thank you, Josh, for presenting today, and I wish you all happy holidays. Reminder, if anybody has items for the agenda for future calls, you can put them on the core community. Call Solana Foundation, GitHub, repo, just make a pr and add them as an agenda item. We have these roughly every month. But thank you all for coming and discussing today.
00:19:23.904 - 00:19:25.016, Speaker B: Thanks a lot, everybody.
00:19:25.120 - 00:19:25.544, Speaker C: See you guys.

00:00:08.440 - 00:00:10.862, Speaker A: Nicholas, Connor, welcome to validate it.
00:00:10.998 - 00:00:13.038, Speaker B: Hey, Austin, thanks for having us.
00:00:13.166 - 00:01:17.050, Speaker A: Yeah. So we did an episode about a year ago with the CTO of Ledger talking about personal self custody. And Ledger obviously has an enterprise offering, but most people know it as building the most popular consumer grade hardware wallet for blockchain. But there's a whole emerging problem that everything from hedge funds and VC's to now institutions building on blockchain have really been struggling with for a number of years, which is how do you build a self custody solution that meets the needs of businesses, is flexible enough to work in a ton of different use cases, but also has some of the same safeties and controls that businesses are used to in more traditional systems for managing things like us dollar flows in and out of accounts. I'm really excited to talk to you guys today about this. I want to get into the details of what you've built, what the origins of this are, and where it came from. But just to start out, Connor, Nicholas, how did you guys first get involved in the blockchain space and the idea of building a custody solution for blockchain?
00:01:17.162 - 00:02:18.410, Speaker B: So Nicolas and I, we first started working together, actually at a small hardware company where we made open source security keys people have heard of as Fido two or Webauthn keys, where you normally use them to authorize. Are there a single factor, second factor to your online accounts, like Gmail or Microsoft? And we didn't do anything with cryptocurrency, but we were very familiar with the problems of, let's say, preserving credentials. What do you do when you lose your credential? How do you recover in general, like good hygiene and management of your secure secrets? You knew a couple people at jump trading, and as of a few years ago, they were having a lot of problems with. Custody Ledger is a really great product. They handle credential management and interoperability with chains really well. But when you're working on a team of people at an enterprise like Jump crypto and you have people spread all over the world, you start to have limitations. When the wallet you need to access is in another office or it's locked or maybe someone like dropped it in a crack in the floor or something.
00:02:18.410 - 00:02:24.738, Speaker B: So you kind of want things to be more online, but you don't want to sacrifice any of that high security you get from using a hardware wallet.
00:02:24.906 - 00:02:42.570, Speaker A: Yeah, this is like a very classic problem for enterprises trying to build on blockchain, where especially someone like jump, I imagine even 20 milliseconds in the delay of signing a transaction may have a real economic impact on something like jump trading.
00:02:42.722 - 00:03:31.556, Speaker C: Yeah, I mean, so to clarify, we should distinguish kind of the custody problem and the trading problem. So these are different things. Like, if you want to be ultimately fast, you can have too many security layers in between. But the big question that we came in to jump to tackle is how to secure substantial amounts of crypto. Right. Like something between a cold wallet and a warm wallet. How do you make things really, really safe but still usable to move maybe a certain part of those funds to a designated trading area where the securities may be lower, but speed is faster? So we've always been focused on more the custody, moving funds around safely from place to place, and not so much in the microsecond game.
00:03:31.740 - 00:03:42.080, Speaker A: That's fair. Walk me through that scope of problem that an organization like JMP was having when it came to custody, and then what you guys ended up building there.
00:03:42.232 - 00:04:19.782, Speaker B: So at the time, a number of, let's say, vendor solutions were used. And I think this is during the bull market, there was a lot of volatility. Maybe some organizations were getting bought out or turning off their services. We might find an enterprise grade custody solution that looked really good, but it was hard to have the assurance to know if it would still be around and work as it looked at the time before, you'd have to, like, move your funds and migrate to something else. And migrating your custody solution tends to be a pretty foundational layer for your company. It's not easy to migrate, and it's certainly not a safe thing to do. You want to be, like, very careful moving all of your funds or private keys around.
00:04:19.782 - 00:04:51.694, Speaker B: So a big concern was how do we make something that we can rely on having? So, like, if we have to move later on, we can, but we don't. We don't have to. We can, like, let's say, build something we know it's going to be around for a long time. A large goal is that we wanted to make a solution. You could basically just self host and run on your own infrastructure without relying on another vendor. Now, there's a lot of challenges, and that makes it really difficult. So if we're moving away from, let's say, using hardware devices, because we want to be able to share access to the custody to multiple people on a team, we don't want to sacrifice any of the security assurances.
00:04:51.694 - 00:05:38.404, Speaker B: We don't want some random person that gets on the network to be able to start sending large amounts of funds. There need to be, like, pretty strict policies in place. So the architecture there's really like two technical foundations to the scheme that we and everyone else got to be pretty comfortable with. One was the use of MPC, which people don't know stands for multi party computation. In crypto, people pretty much are only using this for threshold signatures, where you take a key and you split it into multiple different key shares. This allows you to distribute trust. If you split a key into two parts given to two independent participants, then a single person can't rug the key or take all the funds they would need to work together or collude to make a transaction.
00:05:38.404 - 00:06:10.616, Speaker B: Now, this is only the first part. Simply just splitting your keys and using MPC is not a magic bullet that will solve all your custody problems. At the end of the day, if you have two key shares, you give one to Joe and you give one to Mary, and you tell them, keep these key shares safe, they'll do a very good job. But if they sign the wrong transaction, it's kind of all for not. Like, who are Joe and Mary listening to? Who are they signing transactions for? They both have to follow the rules correctly for this decentralization of trust to be effective.
00:06:10.800 - 00:06:18.004, Speaker A: Right. And also an eight out of ten multisig is also a three out of seven brick for all of your funds.
00:06:18.984 - 00:06:24.360, Speaker B: Yeah, yeah. Recovery is another problem as well.
00:06:24.392 - 00:06:57.656, Speaker A: Yeah, maybe this metaphor is a stretch. Let me know. But it seems like the closest thing that most big companies are used to dealing with that comes anywhere close to this is probably signing drivers for operating system level work. And my understanding is most of that is very secure compute environments that are fully air gapped and fully offline. But you guys had to end up building something that was actually online and could be pretty readily accessed. It's not a sort of take a flash drive into a vault, sign something, take it back out sort of situation. Right?
00:06:57.800 - 00:07:31.012, Speaker B: Yeah, that's a good analogy. If you ever want to increase your security, you can always go down the rabbit hole of making your product or service more of a brick. But you need to go into a vault. Everything becomes really slow and careful, and that's always the way to go. The really tricky thing, security innovation, security engineering of products, is how do we make our products more secure? But we don't have to sacrifice a lot of operational burden or slowness or what have you. In a lot of situations, you might not have a choice. Maybe you don't have the work or the capability to.
00:07:31.012 - 00:07:53.084, Speaker B: Maybe there is no innovation. I think the interesting thing about custody today, as of like five or ten years ago, it really wasn't easy to leverage and deploy MPC. And it certainly wasn't easy to have an application come to a consensus about how to use these keys. But with blockchains, there's been a whole lot of innovation in both MPC and let's say consensus technologies to make distributed applications.
00:07:53.744 - 00:08:39.965, Speaker C: Yeah. So, I mean, picking up, talking about a break, I think that is kind of the classical approach, right, where either it's a break in a safe which is protected by a lot of corporate procedure, or generally if you have long term secrets, there's hsms which perform this brick duty and then you need to control access to it. Classically, this is done by some web service you, for instance, have GCP, AWS, they all offer HSM services. And then you can configure some kind of policy like who can access the secret. But it has two issues. It's not very granular like, because it's usually like a blind signing kind of thing. Like either some employee can sign or they can't.
00:08:39.965 - 00:09:42.680, Speaker C: And secondly, it's like a SaaS solution, right? So you put your policies in someone else's hands and they then intercept the request and make a decision depending on how it's pre configured. But it's a third party who makes this decision. And that's also what we see with a lot of the existing custody solutions in the space where the HSM brick is replaced by some NPC components, where usually the customer has parts of the key shares or all of the key shares, but usually they only have part of the key shares. But more importantly, then the policy has the same implementation where the vendor completely stores the policies and essentially makes the decision. It's not the customer who makes the decision. Making sure that the policies are in the customer's hands and not just the key shares or part of the keys, is what we found lacking when we came in to jump. In the end, it's not much difference to a centralized exchange, which also can let you implement policies and then follow the policies.
00:09:42.680 - 00:09:46.456, Speaker C: The only thing you've done so far is distribute the key material, right?
00:09:46.520 - 00:10:32.574, Speaker A: Yeah, because, Nicholas, what you're talking about is pretty rare nowadays in most software solutions, which is something that is not hosted on someone else's servers, is actually meant to be deployed by your own team, on your own infrastructure. It seems like most in the traditional software space and web two world, a lot of that is driven by outsourcing risk. So if GCP gets hacked, they have a massive insurance policy covering that. But due to the nature of blockchain, you really can't get insurance for self custody in that same sort of way. So when you're going through this process of saying we have to build infrastructure that has all these capabilities that can be run locally, that's doing all these things, what sort of trade offs and decisions did you have to make? And what was the end architecture like for the system?
00:10:33.154 - 00:11:53.236, Speaker C: The goal we set ourselves is to make no trade offs whatsoever. So we wanted to have usability on the one hand, but kind of as a guiding principle to have no single point of compromise of the system, where this is like a dial which you can dial up and down, but at minimum we wanted to have a system where no human or no machine involved by themselves can circumvent the intent of the system, whether that be steal keys or initiate transactions that get affected. And so for that reason, we had to look at what is the policy layer? How can we distribute the policy layer? Keeping in mind also how do people authenticate to the system? Because in the discussion earlier, we talked about long term secrets, the key pair or the mnemonic or what have you, of a specific blockchain address that's a long term secret. And most blockchains conflate this key pair with the identity of the owner of the key pair. It's like there's no abstraction. In the middle you have the key, you don't have the key, whereas in a system, in an environment, like an institutional environment, you have humans, you have machines, just like you have in classical APIs, humans authenticate. That's where we picked up our web authent background.
00:11:53.236 - 00:12:40.224, Speaker C: The world is coming to a place where if you interact on a browser, originally you had Yubikeys, Fido keys, now you have face id and all of these things. But it's the same principle. One human has some kind of hardware backed authentication factor that identifies them. And machines may have other things, but the users have credentials and the assets have credentials. And in the middle is the policy layer, which should make decisions, whether somebody who's trying to make a request that clearly identified themselves securely, whether that request went through. And so coming into JMP, we're kind of presented also with like an approach how to deal with this. Namely what we essentially want is a policy engine, which cannot be circumvented.
00:12:40.224 - 00:12:58.028, Speaker C: And the way to do that is with replicated state machines, or in other words, a blockchain, where the policy is not one server which you can attack, but the policies on multiple servers. And passing policy is a joint decision by multiple nodes.
00:12:58.156 - 00:13:04.276, Speaker A: Yeah, it's kind of beautifully recursive that in some ways you built a blockchain for securing blockchain assets.
00:13:04.420 - 00:13:05.956, Speaker B: Yeah, that's a good way to put it.
00:13:06.020 - 00:13:15.530, Speaker A: So from an architecture standpoint and a programming standpoint, are you functionally, when you're writing a policy governing the movement of assets, are you functionally writing a smart contract for that?
00:13:15.652 - 00:13:38.782, Speaker B: Yeah, I mean, a lot of the program is analogous to a smart contract. We're not writing smart contracts and then deploying them to a, let's say this distributed treasury instance, it's more of a native module to the chain. And then users or operators of the custody solution can then start building their policies, which then gets interpreted by the distributed policy engine.
00:13:38.878 - 00:14:26.452, Speaker C: If you look at Nocysafe, they do exactly that. They have a multi signature authentication, and then they implement the logic in a smart contract, and then they can affect transactions on the blockchain where the safe is running. So that's definitely a step forward. What we wanted is to have, like a multi purpose thing, because at jump there was a multitude of blockchains that were being used or also explored. Right now is maybe not the hugest time for new blockchains, but there are new chains over time, and some of them are, you know, bitcoin clones or Ethereum clones. But there are also fundamentally new chains and different chains which just work completely differently, which you cannot drive out of Ethereum. You need to have a standalone solution to fix that problem.
00:14:26.452 - 00:15:08.878, Speaker C: And so being more of a computer scientist than a blockchain person, think of replicated state machines. But I don't know of any that are out there that are not actually blockchains. And so there's kind of, to my knowledge, two widespread ones. One is the cosmos approach to things, where there's Cosmos SDK, where you kind of write, it's as if you're writing a server, right? You get a request, you do some go code, and then you send a response back. Polkadot has the same thing in rust instead of go, like in their substrate framework. So these are the kind of the two natural choices. And in our case, we picked cosmos because it was kind of a bit more approachable or also just that existed for longer, would be more mature.
00:15:09.046 - 00:15:47.264, Speaker A: Yeah, I mean, this is one of those classic, great applications of cosmos where you have something that needs to be very specialized but also needs to be fairly universal to program on from that perspective. So let's run through a bit of the layers of how this actually works. So you have your multiple state replicators that are deployed. There's some policy threshold deployed on top of that. But then somewhere there actually are keys for all these different networks stored. My guess is there's multiple wallet addresses possible for each network. But you have to build support for multiple curves from many different types of transaction signing.
00:15:47.264 - 00:15:59.292, Speaker A: It has to talk to RPC servers somewhere to get data about the state of those public blockchains. When someone's actually looking at deploying this, what is the full spectrum of what they're deploying and what are the layers in that stack?
00:15:59.488 - 00:16:46.564, Speaker C: Yeah, so we started with kind of an abstraction of what a transfer is. So the core problem we're solving is sending x amount of some asset from one address to the other. Now for different chains, this is a bit different, but the concept exists everywhere. You have some asset that you want to transfer. So we start with this abstraction, and there we have a component which is open source, which is called cross chain, which is a go library, which basically translates from a semantic representation of a transfer to ultimately with the input of some signing mechanism, a signed transaction which you can relay onto an upstream chain. So your question is like, how does this come about? Right?
00:16:46.684 - 00:16:47.244, Speaker A: Yeah.
00:16:47.364 - 00:17:16.814, Speaker C: So it starts with some user intent. So somebody sends a request to the system in some specific format, specifying the transfer and putting a signature on top. So this would be signed by web. Authent means typically for humans. So now it comes into the system. So it's distributed on all of the nodes and they all make the decision to validate the signature. So the system knows all of the public keys of the credentials, so it authenticates the user and then authorizes the transfer.
00:17:16.814 - 00:17:24.793, Speaker C: So this is the core part of the policy engine. Does it pass this? And do all nodes agree that it passes this or it doesn't?
00:17:24.913 - 00:18:13.218, Speaker B: When someone says, I want to move Solana from a to b, or like USDC on Solana or Ethereum, they're basically making a transaction that's going to get validated on every single treasury node. Like if you have a three or four instance, it's going to get sent around to and needs to be validated by at least three of those nodes. It's going to check, is this user have a valid role? Are they an admin, are they a trader? Or are they like an auditor? In which case they're not allowed to send transfers. It'll check to see if the address or the account that these addresses associated with needs any additional provers. Is this like logically a colder wallet? Are you going to need other people to sign off on this transaction? Is the destination? Let's say on your contact list, has it been approved? This is generally like what the policy means, and it's important that this isn't simply decided in one place, it's being decided on all the nodes.
00:18:13.386 - 00:18:13.858, Speaker A: Right.
00:18:13.946 - 00:18:27.526, Speaker B: And once that passes the MPC component on all the nodes, they'll start to participate, and you need at least three of them willingly participating in order to actually produce a signature for this Solana or Ethereum transaction, whatever it is.
00:18:27.630 - 00:19:37.142, Speaker A: Yeah, it's funny because a lot of blockchain systems can feel when you have to describe, oh, here's how they work and here's how you implement it. It can feel a little bit like that Carl Sagan quote, to bake an apple pie, first you must invent the universe. And so the scope of what could possibly fall into asset security is pretty broad. It's everything from as you're talking about, is the core code running on these machines I deploy not compromised? Is that safe, et cetera, all up to like, hey, is this defi app I'm trying to interact with actually the defi app that I claim it is, or am I on a fake uniswap website or something along those lines? So in the current version of the system you guys have built, where do you sort of draw that bound and say, within this, you're on our system, but when you go to this level, you're outside of the system. I ask this because there's all sorts of, I think, mostly theoretical concerns about like RPC server attacks and getting fed incorrect data from like a public blockchain. So does your system actually rely on, you know, running nodes for all these networks as well? Are you pulling data from other sources for that? Where are the bounds of the system?
00:19:37.238 - 00:20:44.062, Speaker C: This is like an internally deployed system, so we can talk about the integrity of the system, like the whole question of software updates. But assuming the system is set up correctly, it's a distributed system, so there's distributed policy, and each node has a distributed signer attached. So this system holds the keys, right. If you send your request to the wrong system, it will just not have the keys, right? So you have to send your request to this system, and this system has your public keys, so it authenticates you. What you need is some kind of like a trusted display, which essentially means that you're able to send correct message, you know, the request format that you're supposed to send. And if you're talking about approving other people's transactions because maybe somebody is not allowed to make a transaction by themselves, you need to actually understand what you're approving. So, you know, you kind of read out of the system the transaction that's in like an authorizing state, and you have to show it correctly, because if that transaction would say, you know, move 100 bitcoin and it shows you, yeah, move like Solana, then that's a bit of a problem.
00:20:44.062 - 00:21:13.908, Speaker C: So you need to think about also the front end where the human makes the decision. But between these two things, essentially there's a cryptographic channel. This is the way that all blockchains work. You have a message with a signature, and if somebody mangles it on the way, then either it will get lost or the signature won't verify anymore. But you as the user of the system, talk directly to the core of the custody solution, where the policy decision is then made.
00:21:13.996 - 00:21:15.500, Speaker B: You mentioned RPC nodes.
00:21:15.612 - 00:21:15.996, Speaker A: Yes.
00:21:16.060 - 00:21:37.698, Speaker B: Do not require running full nodes on chains. We just use commodity RPC node access. Yep. You could argue the RPC node could be a point of failure. They could start lying about the chain state. And generally we set this as okay as it's not going to lead to any sort of failure in the threshold that you deploy. It's basically only going to result in failed transactions or reliability failures.
00:21:37.786 - 00:22:09.684, Speaker C: Because this cross chain library, which abstracts the transfer, it's a trusted piece of software, but it runs on each node, so it understands whether a transaction that is going to let it sign or sign whether it's actually the right transaction, which corresponds to the high level description of the transaction. So the RPC nodes are needed because on the one hand to actually relay a signed transaction, but also to construct a transaction, usually you need some technical inputs, like a sequence number, need to.
00:22:09.684 - 00:22:12.268, Speaker B: Be able to figure out the market rate for gas prices.
00:22:12.356 - 00:22:12.988, Speaker A: Oh yeah.
00:22:13.076 - 00:22:21.044, Speaker C: So this is all related to availability. So if this information is mangled, then your thing will just fail, but it won't turn into the wrong transaction.
00:22:21.164 - 00:22:32.866, Speaker B: You do need to make sure that the market price for gas is saying that you're not going to spend a million dollars on gas or something. Yeah, that's the paranoia I have about RPC nodes, at least with working with custody.
00:22:32.980 - 00:22:59.040, Speaker A: Oh, that's interesting. So you guys built this first internally for jump as one of their internal trading system custody solutions, and now you're actually going out and turning this into a company and a product that anyone can use. So tell me a little bit about how that came about and sort of what changes you needed to make to take something that was an internal tool and now productize it into something that anyone can come and deploy.
00:22:59.222 - 00:23:31.390, Speaker B: We've done a whole lot of technical work to kind of clean up the product, to make it suitable for running in various different environments outside of the one that we were used to inside of jump, and make it very agnostic and easy to use. And we're pretty close to being able to announce initial product for people to start trying out and using like our whole value proposition. If you want to have self custody and to be able to secure it with self replicated policies with a threshold, two or three, three or four, like what have you, we want to make it very easy for you to do that it wasn't really feasible to do before.
00:23:31.502 - 00:24:23.126, Speaker C: But by the time this, this podcast is out, hopefully the product will be on the market to actually look at it. Yeah. Also to add like two relatively major changes that we made between the product that was running at JMP and the product that will be launched is on the one hand, we made the policy more general. So inside jump, there were some things that were configurable and some things that were a bit hard coded because there were assumptions that would fit the internal processes. Whereas everybody can have different risk levels and some things they want to restrict more, others they want to restrict less. So we built out the policy layer and a language to express these things on the one hand. And the other thing was classically, Cosmos uses GRPC, and there's a very specific way of encoding transactions with protobufs and so on.
00:24:23.126 - 00:24:50.820, Speaker C: And most of the rest of the world for simple programmatic APIs, use rest APIs. You post some JSon to some endpoint and then you get something back. So we changed out the programmatic interface to just simplify the usability of these things. Still keeping signatures on top, but getting a bit away out of the bit niche API that Cosmos has to people who are not in the cosmos ecosystem.
00:24:50.932 - 00:26:06.766, Speaker A: Yeah, it's a really interesting kind of problem to go through, and you guys are tackling it in a very different way than most other solutions out there. Ledger enterprise is a semi custodial system. Fireblocks is a semi custodial system. How are you guys thinking about the market? One of the trends we've seen in a lot of software is, again, as we talked about earlier, moving away from a self hosted model. What kinds of organizations do you see as organizations that want the actual self hosted model, as opposed to saying, look, there's a bunch of engineers at Fireblocks and at somewhere like ledger that are doing this full time? I think there's the classic internal business unit logic of how could we possibly do it better than X, Y or Z. I think you guys have made a compelling case as to why an organization may want to go with a solution like yours that's self hosted, as opposed to something hosted by someone else. But how are those conversations structured when you go to organizations that are saying, hey, we need something else, and we're willing to take on the added responsibility of actually hosting it ourselves, because the flip side of that is, of course, you can't save them in the way that another type of solution might be able to.
00:26:06.910 - 00:27:25.030, Speaker C: Yeah, that's the important point, I agree. So the core, the security relevant component, which is the policy engine and the signing, is what we call the appliance. To go back to the brick analogy, it's like an HSM with a smarter access control. So that's where security lives. And ideally, we'd like to have a deployment spectrum from the institution runs all of these nodes, the full appliance by themselves, to maybe the institution runs some of these nodes, and some second or third party runs another part of it, a bit like a custodian model or like a validator that would run validators for institutions, they just are responsible for running their node, not colluding with others with the key shares. But it's a very clearly defined task. And the other end of the spectrum, which is where maybe consumers would come in, it would be like a fully SaaS deployment, but with the twist that maybe it's not just one vendor running the SaaS, but you're still running the distributed system, but among several entities, which together are kind of the custodians, like known entities, actual real life companies that you can sue if they do something wrong.
00:27:25.030 - 00:28:11.286, Speaker C: So you can deploy our system as just a single server, and then you're back. In the classical case, you can do a two server with two of two nodes, then you have a bit of security, but you don't have any redundancy. You always need to have these two nodes. So in that simplest case, the institution could run one server, they would need to have an infosec team to run it, and we or some third party could run the other node. So there's a bit of a spectrum, and as we're going to market, we will find out what the appetite is. Because if the institution says we're going to run this all internally, then they do have to somehow split their Ops team in two pieces. Because if there's the classical CISO at the top who has root access to all of the machines, then this person can compromise the system.
00:28:11.286 - 00:28:11.782, Speaker C: Right.
00:28:11.838 - 00:29:08.952, Speaker A: I guess there is a model someday where I may, as a, let's just say a hypothetical, or I run a big fund or something like that, might say, hey, we're going to do a five server deployment and we actually want to pay you guys to run one of them. We want it to primarily function as someone to send up an alarm if something looks like it's doing improper, or to have an extra state replication that has its own keys that's not connected to us. So there's a lot of really interesting applications here. It also makes me think about what the role of an active audit firm could be. We typically think of audits as something that's done several months after the fact by a financial team that's going in and looking after the fact that, well, did you spend money on things you shouldn't have, or are all the funds properly accounted for? And if not, let's go figure out where those went, as opposed to something that is probably more akin to active fraud prevention on sending a credit card.
00:29:09.088 - 00:29:44.366, Speaker C: Yeah, exactly. We have the policy engine which has automated checks. You would limit the notional amounts or just block certain addresses. But we also have this approval process, which on the one hand can just be a second human eye that is required. But this is also an extension point in the programmatic API. You can say that some process, call it the audit process or the risk process, has to sign off on every transaction. So this could be like an automated machine which reaches out to some known list of bad addresses, or just injects additional intelligence into the approval process.
00:29:44.550 - 00:30:09.554, Speaker B: From what Austin suggested, we could just have a node with no keys or no voting power. It's just more or less just an RPC node replicating the state so other people can just look at it and read, it's good for transparency. Maybe that is something given to an auditing firm, maybe it's even something that's public and people can just view it as maybe an analog for proof of custody or proof of good policies on top of custody, or something like that. It's already possible.
00:30:09.714 - 00:30:52.904, Speaker A: This reminds me a lot of the consensus node versus century node model that a few networks were kicking around in 20 1819, where you permission the validation network in a much tighter way. But then there's maybe. I mean, Libra's architecture is very similar to this, where you'd have a core actual signing network and then you'd have a whole RPC and data availability ring kind of around that, and you could very much see a business or an institution wanting something very similar for them as well. Have you guys thought about actually making this something that businesses can deploy? Logic past policy implementation on? Is there a world where this is just a very secure, slow journey into a private blockchain?
00:30:53.024 - 00:31:05.296, Speaker B: In other words, could they deploy their own smart contract on top that implements how to, I don't know, do policies around a niche staking protocol that we wouldn't otherwise be able to cover with our policy engine or something like that?
00:31:05.400 - 00:31:23.710, Speaker A: Yeah. Or deploying, for lack of a better term, you could see someone deploying a currency effects system on top of this or some sort of actual smart contract programmability, for lack of a better term, where you're building applications for business use cases, not just policies for transfers.
00:31:23.862 - 00:31:47.114, Speaker B: Yeah. The more flexible your policy engine is in describing FX or trading or whatever it is that you want your custody system to start doing. Maybe it's a holy grail, but it has its trade offs. The more complexity you add to your policy engine, the harder it is to actually understand what it's doing. Is there a bug in it? Can I accidentally trade all of my USDC with the wrong shitcoin or something?
00:31:48.274 - 00:31:48.698, Speaker C: Yeah.
00:31:48.746 - 00:32:17.480, Speaker B: So it's definitely something like, we have to tread very carefully. I know. What other solutions do is there's always some sort of escape hatch where if you can't do what you want, you can provision, let's say a hot wallet, and you can just access the NPC signing. Now you don't really get the policies. You're basically your policy. Or your risk plan becomes hierarchical where the majority of your funds should be kept in a normal natively policy quality garden. And then for all of your niche things, you kind of send to the hot wallet, whether it's an escape hatch.
00:32:17.480 - 00:32:25.264, Speaker B: Now, that's not a perfect solution. Ideally you want a policy engine you can perfectly understand and make rules to do anything that you want.
00:32:25.384 - 00:32:59.840, Speaker C: Yeah, we ran into this. Like, what can we build on top? Also inside jump. And there's kind of two places you can do it. You can do it inside the system, or you can do it as an extension point from outside the system. So when you're doing things inside the system. Yeah, you could introduce a smart contract kind of language, or you could natively build in stuff like for instance, wrapping or unwrapping ethereum, or bridging an asset from one chain to the other, or staking an asset and unstaking it again, having native support in the system. I think that's nice.
00:32:59.840 - 00:33:46.794, Speaker C: I'm not so sure one can really build a marketplace on top so the more natural place to extend it is probably outside the system where you insert these additional checks on APIs. And if you want to do that distributed that itself could be a distributed replicated state machine or just simply two separate servers that do a risk check or whatever. So there's a lot of places to go. What we just saw is that there are a lot of niche providers or solutions, point solutions in this space, but without a solid foundation, it's kind of hard to know what you're building doing on. So our focus initially is to solve like, you know, the 80% case with ways to do the other things you also want to do with your assets, but not build everything in all at once.
00:33:46.954 - 00:33:56.010, Speaker A: Well, if people are interested in learning more, where can they learn more about what you guys are building? Get in touch and sign up for the product.
00:33:56.122 - 00:34:09.124, Speaker B: So our company name is Cordial Systems, which I'm not sure if anything will show up if you search that, but if you go to cordialsystems.com will be the entry point for describing everything that we're doing. Email us or set up a time to talk to us from there.
00:34:09.204 - 00:34:13.740, Speaker A: Awesome. Well, Nicholas Connor, thanks for joining us today on Validated.
00:34:13.812 - 00:34:14.548, Speaker B: Thanks for having us.
00:34:14.596 - 00:34:15.624, Speaker C: Thank you, Austin.
00:34:19.844 - 00:34:28.954, Speaker A: Validated is produced by Ray Belli with help from Ross Cohen, Brandon Ector, Emira Valiani and Ainsley Medford engineering by Tyler Morissette.

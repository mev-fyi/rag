00:00:14.440 - 00:00:31.414, Speaker A: Welcome. Welcome, everyone. Breakpoint 2022. Let's hear it. So excited to be here. This is actually my second breakpoint. Hopefully Lisbon's treating you well.
00:00:31.414 - 00:01:03.224, Speaker A: So far, the weather has been spectacular since Thursday. Looks to be good for the rest of the weekend. We've got an amazing, amazing schedule of events. Welcome to Pateo Degale. This is the laboratory. This is where you're going to see some deep dives, some technical talks, and it's a really unique stage. This was actually the location for our closing party last year, so to see it now filled with devs bright and early on a Saturday morning is quite the experience for me.
00:01:03.224 - 00:01:30.874, Speaker A: But thank you for coming. Thank you for being here. I know there are three other options for you guys to explore this weekend, but you're in the right place. A little bit of housekeeping. I'll be your host for the morning session. We have refreshments scattered around the venue, so help yourself to coffee, breakfast, lunch when the time comes. Restroom is over here to my right, stage left, I guess that would be.
00:01:30.874 - 00:02:15.024, Speaker A: This is also the only location where you can borrow disco, sort of silent disco, noise canceling headsets. So if your head's down and you want to focus towards the front where you came in, grab a set of those headphones, put them on, get in the zone, return them on your way out. The only place where you can grab those. So we have quite the program for you guys today. If you do want to explore the other venues, we have shuttles running on a loop every 15 minutes to the other three venues. So of course you can spend the day with us. But if you'd like to get to any of the other great programming, head outside, find that shuttle.
00:02:15.024 - 00:03:26.176, Speaker A: I think that's it for housekeeping. If there's any questions, you can find me in between sessions over here, we've got a great program. Our first session today is with my colleague Jacob Creech, who is going to be talking about the developer tooling ecosystem that's come into play over the last year. How far we've come, and we've come a long way. We have come so far that some of my non technical, non dev colleagues have explored the tooling ecosystem to teach themselves hello world type programs. And one of my colleagues, Andrea, completed the hello World program, posted on Twitter that he had just completed his first Solana program, and within a short amount of time, two job offers flowed his way. So I don't know if that could be said with the tooling that we had in place for developers a year ago, but it's pretty impressive that we've come this far, that those of us who don't code can jump right in and become Solana devs quickly and efficiently, efficiently enough to generate job offers.
00:03:26.176 - 00:04:00.846, Speaker A: So with that, I'm going to turn the stage over to Jacob. Please give Jacob Creech a warm welcome. All right. Hello everyone. My name is Jacob Creech. I lead developer relations at Solana Foundation. I will be going over the Solana tooling ecosystem at the developer relations.
00:04:00.846 - 00:05:11.764, Speaker A: One of the things that we focus on the most is improving the developer experience. How does a developer get to building an application as fast as possible? How do we improve the speed to developer success and get it as low as possible? How do we enable developers that are learning or brand new to be able to jumpstart and just jump into the ecosystem and start building? So there are a number of things that we've gone and what we can do is we can look a year back at the old tools so that we can appreciate where we are today with the tooling ecosystem that we have today. So we look back about a year ago, we have this Solana test validator. It's still an awesome tool to use today. What you use this is to build and deploy local applications to your local environment so that you can test out how your programs work. You can test out like one, like do my instructions, run a bunch of things with the Solana Cli, you can build, you can do a bunch of stuff. That's an awesome tool.
00:05:11.764 - 00:05:35.530, Speaker A: Still a great tool today. We also had the create the SBL token Cli. Still a great tool today. You can use it to create tokens, create the mint account, initialize your tokens in your account, transfer tokens. It was a great setup. That's something we had and still have today. We also had the anchor ClI.
00:05:35.530 - 00:06:13.694, Speaker A: So anchor was existent as a year ago. What you could use is you can also use it to build and deploy programs. You could use it to initialize a startup application so that you could use anchor with a front end and build your Solana programs with anchor. And then finally a year ago, nfts were just starting. And so you have the Metaplex ClI as well as the Metaboss CLI that enabled developers to mint nfts to manage their nfts and work with them. So yeah, this is all great. These are all amazing tools and still great tools today.
00:06:13.694 - 00:07:20.972, Speaker A: But this was just about it in what existed a year ago. Like, there wasn't much else. So now let's look into some of the major tools that came out in the past year and how they work, starting with my favorite one, Solana Playground. So Solana Playground, the way that it works is it is a web idea so that it allows you and enables you to quickly jump into Teslana development without having to install a single thing on your computer. And this is incredibly powerful. So like if a new user wanted to try out Solana development and see, okay, how does it work? How do I interact with programs? What kind of things can I do with Solana? They can just load up beta SolpG, IO, or Solana playground and be able to quickly build their programs and see with any errors and also test them. There's a fancy little anchor functionality to where you can actually test with button clicks your program, which is amazing.
00:07:20.972 - 00:07:55.724, Speaker A: That didn't exist a year ago. This is honestly my favorite tool that came out in the past year. So cool. So good for as developer relations to onboard new developers. And so I did also mention that it is incredibly fast to build Solana programs. So this is me building with the Solana Cli, a hello world program on my M one Max MacBook Pro, which is incredibly fast, supposed to be incredibly fast. Took 18 ish seconds to compile the rest program.
00:07:55.724 - 00:08:37.270, Speaker A: You can grab a cup of coffee, you can come back, you can continue your hello world. You can imagine that once you have bigger programs, this would take a lot longer, like magnitudes longer. Now we check playground, same program, 400 milliseconds. This is, as I said, enabling developers to quickly get to developer success. I started hello world. I compile, I try it out, and then the next moment I'm doing something with accounts, or the next moment I'm doing CPI calls to different programs. It makes the speed of development so much faster so that you can get to those really cool applications in the future.
00:08:37.270 - 00:09:46.102, Speaker A: So no longer do you have to have a mini fridge looking computer or server in your home in order to offload your rust compilation times. You can just use Solana playground, get it within like less than a second, usually, depending on the program size, you don't have to rely on this beefy looking machine to actually get good speeds. Next up, let's talk about create Solana Dapp. So this is a CLI command that was created by someone on my team who's actually currently in the audience today. And what you can use this to do is quickly bootstrap your Solana development environment with a basic app and multiple frameworks. So today it supports next vue, svelte, and then anchor and native Solana and what you can do is just you write a simple command and you're quickly enabled to like build on top of an app versus having to build your basic app in next. And then learn how to do the wallet adapter and then learn how to add web3 js and do airdrops.
00:09:46.102 - 00:10:33.142, Speaker A: It wasn't that great. So whenever you run this, you're greeted with like a very basic application of like hey, you can airdrop so that you can test out your application. You can connect to a wallet so that you can test out like hey, how does my dapp interact with other wallets? And what does it look like whenever I'm sending transactions? Really cool. The next one that we'll go over is creating tokens. So I did mention a while back that hey, this SPL token CLI existed, still exists today and you can use to create tokens. That's great and all, but to view these tokens, it was a little bit difficult. The previous and a year back.
00:10:33.142 - 00:11:17.208, Speaker A: The way that you did this is that you used a repository called Tokenlist and added the token metadata or your logo, your name, your symbol and a myriad of different additional information so that people could actually see your token on explorers, on wallets and just be able to understand what the token is. It's not just some weird looking string. This is the old way of doing it. This is honestly a bad developer experience. It's a bad user experience, bad developer experience. And the minimum amount of time that it would take to do this is around 30 minutes because that's how often the Ci CD ran for this. But it could take a lot longer.
00:11:17.208 - 00:12:01.434, Speaker A: So say if you're updating a token versus just creating a new token, this would take, you could take weeks. And that's just terrible. So let's look at the new way. I mentioned Metaboss. Metaboss has now added functionality in order to create a metadata account and be able to display that information via explorers to wallets and more. So we worked with wallets, we worked with explorers to add the ability to grab the metadata from Metaplex's metadata program and be able to display it immediately. So you can do in a single line on your CLI to display, create tokens, mint your tokens to your token account and so much more so in the single line.
00:12:01.434 - 00:12:40.426, Speaker A: Suddenly you can create this little studious crabs token that I created in Devnet and you can see everything about it. And it's super quick. Takes as long as an optimized, as long as you feel like waiting for a confirmation. That's how long it takes. So you end up seeing this comically looking chart now of how long at the minimum it used to take for creating a token with tokenless and SVL token to now using Metaboss, which still uses the token program. It takes mere seconds at this point. So next one we're going to go up is talking about geyser.
00:12:40.426 - 00:13:14.254, Speaker A: So to understand geyser is a way to read data from Solana as fast as possible. So to understand Geyser, you have to kind of understand what you had to do before and what some people still do today. So they use, a lot of people use like get program accounts. It's an RPC call, incredibly expensive. For both the RPC, the user locks up a bunch of information on the RPC. It's not that great. You could get something like 10,000 records from your program.
00:13:14.254 - 00:13:55.674, Speaker A: Or if your program has a ton of different program data accounts, good luck. It probably won't come back as an API call. And with Geyser, what you could do is you could have a validator, like a non voting validator, put a plug in the geyser plugin on it and output that data to your data store of choice. You can do it like a year ago, the only thing that existed I think was postgres database. So you could output all the data to your postgres database. You can build a microservice on top of it, and then it ends up being like what you're normally used to building applications. You just have your database, your microservice, your front end, you expose it via restful API and you're off to the races.
00:13:55.674 - 00:14:54.826, Speaker A: Build this very quickly, you could manage it. And since a year ago you can actually, geyser plugins actually support multiple different outputs and interfaces like Kafka, GRPC and more like it used to be just be postgres. So you can use what you're used to building your normal tech applications or your websites in highly scalable form, and use that to read data on Solana. So you can kind of get your web3, the capabilities with what you're used to with the web, two ish speeds. So as I said earlier, hey, this geyser plugin, you kind of have to put it on a validator or RPC node or non voting validator and output to a database. This is kind of high maintenance for some teams. They can't really do this, especially starting out.
00:14:54.826 - 00:15:33.864, Speaker A: So there are other avenues that you can actually get these capabilities without having to start your own validator run it and test it out. So the answer to these today is actually what we call indexers. So indexers are basically like Geyser as a service. They allow you to expose an API. It's actually under the hood using geyser outputting accounts. And it's still doing that, just API. So it's still doing the data store, the microservice exposed API, and then I, as a user or developer can just call that, get the information immediately and move on.
00:15:33.864 - 00:16:37.506, Speaker A: So we can see that throughout like the past year, what the progression of getting highly available read speeds. On Solana, originally, everybody was using get program accounts, basically unusable, terrible user experience, like 80 seconds per call depending on the call you're doing to geyser, where you get a little bit more, but it's a bit higher on the maintenance side. A lot of teams can't do that, especially starting out. It's just, it's a little bit hard as a developer to reach developer success as fast as possible. So now we have indexer solutions to where like, hey, I can just onboard to an API endpoint, get my API key and be able to read data incredibly quickly. So there's a number of other tools that were created, honestly, a ton of tools that were created this past year that I'm excited about. These are just a few of them that are really groundbreaking and enable developers a lot more so to build on top of Solana.
00:16:37.506 - 00:17:21.226, Speaker A: So there's actually, I'm going to highlight now one tool that I'm looking forward to coming out, breakpoints. What I like to call breakpoints. At breakpoint, there's a user, the Twitter user's up there. He is building a way to do debugging applications via breakpoints. So what you can do with this is you can just run your program locally, you can put your breakpoint there, and then you can replay your transactions locally and see how it interacted with that program, see what the state of your program was at, different lines of your code, and be able to step through it. Like if you're familiar with C debugging, it's like GDB. It really is GDB under the hood with a lot of nice UX around it.
00:17:21.226 - 00:17:57.756, Speaker A: You can see what data at a specific point was and be able to understand, like, okay, I got this error. What did that error like, where did that come from? Why did I get it? Versus having to do your normal console logs everywhere or messages everywhere. That's incredibly powerful. Looking forward to when this finally comes out, just follow that user. He'll obviously announce it when it comes out. So that's a lot of the tooling that is coming out. If y'all have tooling that like, hey, I'm really excited about building this, or I have built this tool and it enables developer experience a lot better.
00:17:57.756 - 00:18:21.506, Speaker A: Feel free to reach out to me at any point in time. My name Jacob Creech. On Twitter, I'm jacob vcreach. I'm happy to help out, especially if, like, if you want to know, like, what more opportunities there are in order to improve the developer experience at devrelations, we're always happy to help. Thank you. Okay, here we have time for questions. Yeah, we have time for questions.
00:18:21.506 - 00:18:46.158, Speaker A: If anybody has any questions, we're running a little bit ahead of schedule, which is great. So if there are questions, there's a couple of mics set up here in the aisles. We can take questions, anything, right? Yeah, anything about tooling, anything, developer experience wise. Happy to help. Come on down to the mic in the aisle. Yeah. Hi, my name is Sebastian.
00:18:46.158 - 00:19:44.586, Speaker A: Thanks for the intro talk. I was having one question about get program accounts and why they seem to be the requests for. While they seem to be limited for certain accounts, like radium is a perfect example, like the official RPC is limiting the abilities for getting program accounts for radio. Why that is so some RPCs, like the public RPCs I have Brian long right here, who runs Triton. What they have is they have a bunch of programs. And what you have programs that whenever they have tons of accounts, like for example, metaplex metadata program, and if you're doing get program accounts on it, it's kind of insane because there's like millions upon millions of accounts and you lock the state on the RPC and it's incredibly expensive. And it basically won't come back because the RPC limits, I think is like 15 meg of data that can come back.
00:19:44.586 - 00:20:32.096, Speaker A: So what happens is in order to improve the developer experience for everyone, they limit the amount of programs that you can use to a sub system amount of all of them. It's to the ones that like, hey, you're using spl token Cli or you're using the Solana Cli and you're just trying it out so that people that, hey, I'm trying out Solana and trying to learn about it, they can do that in a very efficient manner versus having to go get their own RPC. Now, once they have the ability to know, like, hey, I want to dev on Solana. I want to build something a lot bigger on Solana, then they can go get their RPC and help fund that. There's plenty of other free options out there that allow you to do this. Thanks. Thank you.
00:20:32.096 - 00:20:56.638, Speaker A: Thanks. This side. Yeah. I was wondering if you have like a blog post kind of version of this so we can reference this on our own time to build faster for all the different tools. Yeah, yeah, that'd be super nice. I don't have the links available, but I can totally get them to you. I'll post something on Twitter with all the links of like the geyser, how to run geyser locally, how to do spl token.
00:20:56.638 - 00:21:17.658, Speaker A: Actually, I think spl token is like right after me, so you'll learn about that as well. Meta boss. I can post it all on Twitter and if you catch me afterwards, I can also help you find them. Thank you. Awesome. Anybody else? All right, cool. Thank you so much.
00:21:17.658 - 00:21:44.144, Speaker A: One more time. Round of a round of applause. Thank you. Let's keep going. Great way to kick off the day. All right, next up, we're going to talk about minting nfts on Solana at scale. You know, Solana is the best chain for nfts.
00:21:44.144 - 00:22:22.624, Speaker A: Let's talk about how to scale that in a big way. We're going to bring up Austin, Noah and John Wong from Solana foundation coming up, guys. Hey. There are a lot of people here. Non zero amount of attendance. This is amazing. My mom's never going to believe this.
00:22:22.624 - 00:22:45.146, Speaker A: Thanks all for being here so early on a Saturday. Echoing Josh, there's a lot of other places you could have been. We know you went out hard last night. Thanks for coffee and being here. My name is John. I'm the tech lead on the NFT team here at the Solana foundation. And I'm so happy to be on stage here with Noah and Austin.
00:22:45.146 - 00:22:58.430, Speaker A: I'm going to have them introduce themselves. Hi, I'm Austin. I'm a protocol engineer on the metaplex side. Enjoyed working with these guys. Yeah. My name is Noah Gendotra. I'm with labs.
00:22:58.430 - 00:23:30.174, Speaker A: It's a pleasure to be here. A year ago, actually, I was in the crowd, so it's kind of crazy to be here now on the stage talking about NFTs with Austin and John. So super excited to be here and talk with you guys. Awesome. And we do want to do a quick shout out to Jerry. I don't know if he's here, the professor, you know, this is a lot of his work that we're presenting up here. So credit to Jerry, I don't see him in the crowd, but at the Solana foundation.
00:23:30.174 - 00:24:24.346, Speaker A: We're here to help grow the adoption of the Solana network, obviously by different efforts, like throwing events like Breakpoint, as well as looking into the technology and understanding how this is going to fit for companies and teams of all sizes. And one of those things, excuse me, one of the things that we've been thinking about, too, is like, how is this going to scale? So we spend a lot of time talking to big companies. We spend a lot of time talking to different teams and seeing where their constraints are. And some of the things that have come up that have been the most obvious places where Solana just doesn't yet scale to are things like games. Games want to be able to issue millions of digital assets as nfTs. They want to be able to do this on behalf of their users. They want to be able to do great experiences for their users.
00:24:24.346 - 00:24:55.204, Speaker A: They don't want to have their users have to think about Sol or the tokens and things like that. They just want it to work. Enterprises want to be able to do the same thing. They want to say, hey, I have hundreds of thousands, if not millions of users. They all need an NFT. I want to be able to provide it to them and give them this super slick experience and kind of graduate them into the world of web3. And so when we think about these kinds of things, we really do want to make sure that the tech can actually handle that kind of scale.
00:24:55.204 - 00:26:09.904, Speaker A: Now, the other piece, too, is like, as we evolve the idea of nfts, as we understand different things like identity, and thinking about how that's going to end up kind of merging as our identities, our sort of personal identities, increasingly become digital, we want to also think about, like, what does it mean for many more people to be on chain, especially on Solana? So we have this grand vision of a billion people with self custody. And when we think about minting nfts at scale, we don't think about one person with a billion nfts. We think about a billion people with one or many nfts. And so how do we enable that with the technology? And where are the places where this is just not feasible? So the big thing, if you're familiar with nfts metaplex nfts on Solana, is how much they cost. And I think so, you know, there's four accounts. The thing that you're paying for when you're minting an NFT is the account space, right? The rent for these accounts and storing all those bytes on chain. And this is fine at the first 1.012
00:26:09.904 - 00:26:28.938, Speaker A: sol. I'm gonna disclaimer, not financial advice, but this is like, you know, 30 or $0.40, right? And this works well for individuals. But when we think about scale and we think about millions of nfts, 12,000 sol. I don't have 12,000 soul. Like, I don't think anyone has 12,000 soul. Right.
00:26:28.938 - 00:27:44.394, Speaker A: So this is just not feasible for a company to be able to say, hey, I want to mint nfts on behalf of my users and let them, you know, represent something, maybe their identity, things like that. I'm so happy to be able to be on stage here to present the technology that we've been working on and just doing for months now, and to be able to really dramatically change this particular slide. So the thing that we're going to be talking about, and we're going to be saying this word a lot today, we're going to be talking about compressed nfts. And just to really make it clear how freaking awesome this is, with compressed nfts, we can mint a million nfts for five sol. We can mint 100 million nfts for 50 soul. This is a game changer for all of the things that we can now envision when minting nfts is as cheap as a transaction on the Solana network. And this slide is missing a bottom line here, which is we can do a billion nfts for 500 sol.
00:27:44.394 - 00:28:18.964, Speaker A: I don't have 500 sol, but someone probably has 500 sol somewhere. And what's really incredible about this cost comparison thing here is twofold. Like one, you know, again, no one has 12 million sold for this. This 500 Sol is actually predominantly transaction cost, the actual on chain account space needed to store a billion nfts. It's like ten sol. Someone here has ten sol. So this number is something that can change over time as we explore and really mature the technology around compressed nfts.
00:28:18.964 - 00:29:08.334, Speaker A: But when we look at this cost savings 24,000 times and we talk to companies, this is magical. This is that moment where they can actually do the things that they've been wanting to do and not have to push this cost to the user. This is really great. So how does this actually work? Like, what the heck is this? Are we just making things up? Like, you know, what's going on here? So how is this so inexpensive? Compressed nfts, just like any other NFT, get minted through transactions that we get sent to the Solana network. None of that changes. The big thing here is that we're adding a second layer here around indexing, and the indexers really help make sure that we're powering dapps and wallets and that sort of stuff. Under the hood, compressed nfts are structurally identical to the current metaplex nfts that you're already familiar with.
00:29:08.334 - 00:29:43.304, Speaker A: And the big thing here is that per account rent that we were talking about, that zero, one, two, Sol. That part is the part that's being compressed. So the NFT itself is structurally identical. The thing that we're taking out is the actual account space part of it. I talked a little bit about indexers, and the big thing here around indexing compressed nfts is, as I mentioned before, we're minting these nfts and updating them, all that sort of stuff. They still go through the smart contract, they still go onto the ledger, and they still go through the typical consensus mechanisms, like that part is not changing at all. All that is on chain.
00:29:43.304 - 00:30:47.034, Speaker A: The big piece here is that that data gets emitted into the ledger, and that information is where the indexers are looking for to provide the information that we are going to need for Dapps and things like that. I know that this still feels vague, and that's why I have Noah and Austin here to go through the details. The key piece about this is if we have indexers powering a lot of the flows that we need for these client applications, we have all this off chain data that we need to make sure works with our on chain smart contracts. And this is a really important piece, is how do we actually trust that even though we've emitted this into the ledger and this indexer is doing something, that the indexer is actually going to provide the right information that we can validate when we're doing updates to entities and all that sort of stuff. So to go through the actual details here, I'm going to send it over to Noah. Hello, everyone. I'm here to talk about how we solve this at labs.
00:30:47.034 - 00:31:51.144, Speaker A: So, as you guys know, we're talking about Metaplex compressed nfts, which we've been working with, with Austin from Metaplex on for a while. And also, again, a gigantic shout out to Jerry Zhao, who helped us out and architect this and designed this. So, without further ado, the two constraints that we had to work with when helping Metaplex come up with compress nfts was that compress nfts depend on indexing. So that indexing has to be one publicly available and operable by anybody in the ecosystem. So it has to be open and available in the ledger and the second was that the compressed nfts, when they're served, we have to make sure that the data that's served by the indexer is safe from malicious edits or other corruptions. We solve both of these problems with account compression. Account compression is our way of allowing metaplex to trustlessly index compressed nfts.
00:31:51.144 - 00:33:19.374, Speaker A: What this diagram here shows is that when you're minting a compressed NFT, the compressed metadata is logged via the SPL no op program which is actually executing a CPI. And that CPI data is the compression of t metadata that is being indexed and picked up by the metaplex read API. And so when it's time for you to list or sell or transfer that compress NFT, the metaplex read API not only serves you your compress NFT data, but also a proof that that data was not tampered with in any way. And so what we're showing here on the right is that when it's time for you to execute that transaction, the metaplex compress NFT program cpis into account compression, which verifies the state was not edited since the time that it was logged. So how does this all work? Well, under the hood, account compression is using merkle trees to guarantee the state of all compressed nfts. What this means is that the compressed nfts are hashed into 32 byte leaves of a merkle tree, which are all hashed together into a 32 byte merkle tree root. When it's time to actually use your NFT, along with the verification proof, those are hashed together to compute a merkle tree root which is verified against the on chain merkle tree root.
00:33:19.374 - 00:33:52.984, Speaker A: If both of those 232 by hashes match, then the transaction will continue as normal and you can execute normal NFT operations. If they don't match, the transaction will fail. So that solves our constraints. But now we have a new problem. Miracle trees can only handle one update per block, as many of you might know. Now, as John brought up, we have high expectations. We expect to have a billion people with one NFT each.
00:33:52.984 - 00:34:26.184, Speaker A: One update per block is not going to cut it. We have to have more updates per block. We have to find a way to get around this. So to talk about how we got around this, I first have to explain what the problem is. And so what I'm going to show you is the problem inherent to merkle trees, and then talk about how we solve them with account compression. What I'm showing you here is a merkle tree. Merkle trees are used to secure and associate a list of data with a 32 byte hash.
00:34:26.184 - 00:35:30.574, Speaker A: So the white boxes here at the bottom is a list of data with arbitrary information in it. That's what the row a, B, C, D, E is, along with some empty items in between. What we do is we hash each leaf into 32 bytes, and then we hash all of those 32 bytes together again and again and again until we get a single root. When we talk about verifying the existence of a particular NFT in this tree, what we're doing is we're hashing the path from that, from the NFT in the tree into its leaf node, up to its parent, up to its parent, and then all the way up to the root of the tree. When referring to merkle tree proofs, we're talking about the adjacent nodes, which are the minimum amount of information necessary to hash the computed root of the merkle tree. When we're talking about when we want to update a compressed NFT. So for example, I want to transfer it, I want to sell it, et cetera.
00:35:30.574 - 00:36:15.254, Speaker A: We actually have to perform two operations. The first operation is we have to verify the computed root, which is what we need the proof for. The proof, in addition to the actual compress NFT itself, are used to hash all the way up to the root, which gets us the computed merkle tree root. Once that is verified against the on chain root, we can then update the compressant of t. So here I'm representing that with an updated row at the bottom, which has an updated path all the way up to tree. So that's it? We're just executing an update against a tree. The issue is that when we imagine a mercury tree processing two updates at the same time, there's a clash.
00:36:15.254 - 00:37:00.878, Speaker A: This is a geometry problem specifically. Oh, my apologies, but I can see it doesn't line up perfect. But there's two updates, right? The first update for Merco tree lands within the block perfectly, which is shown in pink. When we process that second proof, which is shown in green here, what's happening is that the proof is now out of date. The top left green node here in the proof is now out of date because that node at the top left has changed. The miracle tree has been updated. So what this means is that we're not able to compute an accurate on chain root that matches with what we expect it to be.
00:37:00.878 - 00:37:39.090, Speaker A: So all of our transactions after the first are going to fail. So that's what we had to design around. And this is what we solved with concurrent merkle trees. Again, this is in large part thanks to Jerry Zhao, with which we express much gratitude. So concurrent merkle trees are designed to handle multiple updates per block. And we do this with an operation that we call fast forwarding. And what fast forwarding allows us to do is it allows us to take this conflicted node here, which is shown with that collision, and we're actually able to update the proof in green.
00:37:39.090 - 00:38:28.094, Speaker A: So that way, rather than having an outdated proof, that proof gets updated and then now becomes a valid, we can compute a valid root from it and then execute an updated change. Concurrent miracle trees are awesome because they allow us to handle up to 2048 updates per block. That allows us to take full advantage of the Solana runtime and update these trees as many times as we want in a block without sacrificing the normal hit that you would expect from using a merkle tree. So this is not that complicated. There's four steps that are necessary for metaplex to use this. Well, I'll try to break you down. There's four necessary steps for metaplex to mint you a compressed NFT.
00:38:28.094 - 00:39:33.374, Speaker A: You have to create the normal metadata arguments which is shown here. Then you have to log that using a CPI into the SPL know program which is picked up by the metaplex read API. The third step is you use the on chain kecat hash function which which associates the new NFT with a hash. And then you have to CPI into account compression to make sure that the numerical tree updates and that proof, the updated proof and the updated state of the tree is indexed by the Metaplex read API. Now I have great news. Austin here has already done all the hard work for all of us, and this is already done by the Metaplex compressed NFT program. So just before I hand this off to Austin to talk about the Metaplex read API, I just wanted to recap that we solved a problem, which is what happens if the indexer is wrong? Well, if the indexer is wrong, your transaction will simply not go through.
00:39:33.374 - 00:40:10.754, Speaker A: We talked about that with the Merco trees. But the second amazing thing which Austin and the Metaplex team have worked on so diligently is creating an open source standard. So the metaplex read API can be operated by anyone. So if the data is wrong, you yourself can operate the Metaplex read API and reconstruct the information necessary to edit and update your compressed nfts. And with that, I'm going to hand it off to Austin to talk about the Metaplex read API and compress nfts that changes over. Yeah, okay. Hey everyone, thanks for coming.
00:40:10.754 - 00:41:07.324, Speaker A: I'll just start off by saying, it's been an honor to work with the giga brains at Solana Labs and Solana foundation. You want to shout out some of the OG compression crew, Larry Wu, Steven Lucher, and everyone in the Chicago hacker house that was listening in and shouting out, no, that's a bug. That's not going to work. Yeah, thanks, Noah. So the Metaplex read API, like he said, is it's not just some service that Metaplex provides. It's an open source implementation against a specification for serving NFT data much faster than the current Solana RPC does. Which is a really good thing, because metaplex dapps now typically require some custom indexer or a bunch of caching, or an RPC provider that's extremely forgiving and has their extremely fast nodes like Triton here.
00:41:07.324 - 00:41:47.840, Speaker A: But I'm happy to say that the Metaplex read API is a disaggregated sort of open source system that's already been implemented by two RPC providers. Triton, who's here, amazing RPC provider and Genesis go as well. Yeah, yeah. Shout out to them. Amazing engineers. This open source code base provides an API not just for compressed nfts, but for regular nfts and for a lot of metaplex open source protocols on chain. Where we really needed the Metaplex read API was to be able to serve the merkle proofs.
00:41:47.840 - 00:42:45.614, Speaker A: As Noah mentioned, the Merkle routes are stored on chain and some information about how to cache different changelogs and paths and blah, blah, blah, blah, blah, all the super gigabrain stuff. But we needed a way to get the proofs down to the SDKs and the Dapps and the apps so they can transfer, so they can decompress, so they can fuse it and all these other cool things. So the metaplex read API follows the ledger and serves proofs accurately. And like he said, if one indexer goes down, or if one of the RPC nodes starts to become malicious, you can switch over to the other one. It's very similar to the Solana RPC in that the data is derived off of the blockchain and served to the user. Our hope here was to create a way for metaplex Dapps or Dapps using metaplex APIs to be much, much faster. Hence we're indexing regular nfts as well.
00:42:45.614 - 00:43:52.774, Speaker A: Yeah, we have multiple people running this. We have wallet providers integrating, and now instead of having to do get program accounts and jump around at different byte offsets, you can simply call out to some RPC endpoints and get results back in milliseconds instead of minutes. We do have some limitations. Currently three nfts can be edited in one transaction because of the transaction size limitations. But that's actually gonna, that's actually, you know, that limitations getting loosened because of lookup tables and things like that. Nfts in the same tree are processed serially in the sense that you can still do concurrent updates to that tree, but your updates to that specific NFT need to happen in serial, which I think, I think that makes a lot of sense. Interacting with compressed nfts is now becoming much easier due to SDKs.
00:43:52.774 - 00:44:36.322, Speaker A: And like we said, the read API, we have some example code. We already have soulflare integrated it, so that's how easy it is. Also there are gigabrains as well. Currently you might have some questions about what you can do with compressed nfts. Like the slides say, you can mint them, we have a listing protocol that works with them. You can transfer them, freeze them, but we hope to support all the functionality that current metaplex nfts can do, like fusing, staking, fractionalizing, things like that. So the compression contracts are available on Devnet and Mainnet if you really want to go chew the glass.
00:44:36.322 - 00:45:04.404, Speaker A: But we have several RPC providers that have implemented the read API, including Metaplex has an instance, and we'd love for you to come over to our booth and check it out. We can help you get started with that. I'll hand it back over to John. Great. So just to kind of pull all that together, the things that we want to take away for compressed nfts, one, they're cheaper, much cheaper. Much much cheaper. Very, very cheap.
00:45:04.404 - 00:45:25.384, Speaker A: Very inexpensive nfts for everyone. This is really important. The second part is that you're going to need an indexer. Likely you can use the Metaplex read API, you can use the metaplex hosted services. You can use Triton, Genesis, go. Any RPC that has this support, if you feel like it, you could write it yourself. You can take this stuff off the shelf.
00:45:25.384 - 00:45:57.494, Speaker A: It's all open source, all the data is on the ledger. You can write this indexer yourself if you want to, and implement the metaplex read API. Just make it really, really simple. And the last piece here is that it's all secured by the account compression program itself, which is part of the Solana program library. So we mentioned a little bit about some of the providers and the different places that have this kind of support for the people who are building. Now is the time to do it. All these contracts are on Devnet as mentioned, and account compression is on Mainnet as well.
00:45:57.494 - 00:46:18.746, Speaker A: We've been working with the Gigamaranes at Solflare. Solflare has support for compressed nfts. Go use it. Thank you so much, solflare. We have service providers also using compressed nfts, cross mint. If you mint APIs with the cross mint API, it'll mint compressed nfts. Awesome.
00:46:18.746 - 00:46:57.270, Speaker A: There is a couple more informational panels happening on some of the other stages later, talking a little bit about some of the more business use cases and that sort of stuff. As Austin mentioned, there's a metaplex booth over there. There's devs there to get you set up, get you started and thinking about how to use compressed nfts. We're going to go to this next slide and see if it works, which is a video and someone gave me a signal if this is not going to play, I don't know if this actually, I can't interact with this. No, hey, no video. This never happened. So go forth and biddle, like, use some mint, some compressed nfts.
00:46:57.270 - 00:47:29.536, Speaker A: Thank you so much for listening to us talk and we have time for questions. So there are some handhelds here. If you guys want to line up next to the mics, go ahead. And you can line up at that mic there and ask the questions just so everyone can hear. We're happy to answer any questions. Yeah, go ahead. Yeah, hi, I just wanted to ask, is that going to be.
00:47:29.536 - 00:48:07.068, Speaker A: So, for example, a compressed NFT is going to show up in soul scan or in the explorer, a similar way that nfts show up now. And if yes, what would be searched for? What would you like? What would be put into the query? For example, like with a regular NFT, we just put in the token address. Right. With the compressed NFT, how would it look like? Yeah. So currently explorers, like, if you copy paste, because no one's ever typed a full mint address by hand into an explorer, you'll just see a transaction. It won't pull the metadata and stuff. We're going to work with all the explorers and if they want to implement it, I think they will.
00:48:07.068 - 00:48:45.594, Speaker A: They're extremely fast to implement new stuff, but because there's no data, only the routes are on chain and all that data is bundled up into that route, there's nothing for the explorer to grab onto unless it calls out to the read API. But the id of the compressed NFT, when you decompress it, is the mint address. And so we keep that same id for the whole lifecycle of the NFT. So I do think they'll implement it soon. If you're an explorer here, please do that. Austin did say the word decompress. We did not put this in the slides yet, but this is actually really important.
00:48:45.594 - 00:49:26.074, Speaker A: So we have these compressed nfts that live in these merkle trees, but there are times that you need to use it with an old contract that only expects nfts decompression, we can actually take one of these leaves and actually decompress it back into account space into the prototypical metaplex NFT, you know, today. So you could decompress it, use it in a smart contract, and if it's on token 22, you can recompress it back into the tree. So that's how the sort of interoperability. So that address is a mint address. It is a public key, just like you're expecting from any other entity. Thank you, Brian. Hey, so you talked about this being under open source.
00:49:26.074 - 00:49:57.984, Speaker A: I know that Metaplex just changed their open source license for some other projects. Can you talk a little bit about what the licensing is? You moved from AGpl to something else. How does it all that work? Yeah, I'm not super up to speed on that. I can't actually remember what the license of the read API is. I believe the license only changed for the contracts. Consult your tax professional. I have no idea how all that works, but the read API stuff is a permissive license.
00:49:57.984 - 00:50:26.280, Speaker A: Please don't use it to do evil things. But like, it's running, it's open. We want people to run a bunch of different implementations under the same spec. We want people to contribute to it, make it better. Shout out to caveman Loverboy from the Genesis go team for fixing bugs in his fork and not pr'ing them back and making me find them. But amazing. Dev, Sebastian.
00:50:26.280 - 00:51:09.584, Speaker A: Hello guys. So I work on the DAO tooling and governance, and my question is, how generic is the technology you've created? Like, can we not only use this to mint cheap nfts, but also create a cheap governance? Because sometimes even right now, Sona is cheap, but still, the entry to vote and participate in governance is still high. Yeah, thanks for asking. Account compression is generic. It can help with a bunch of different problems where you have a lot of account state and you want to only verify that account state. And yeah, I think it would work for voting. It could work for a lot of different applications.
00:51:09.584 - 00:51:39.784, Speaker A: Yeah, we'll be rolling that out hopefully with some integration soon. Amazing. Thank you guys. So my first question is, why do you always use such ridiculous names. Like, you know, bubblegum, Candyland. It's really confusing. When I first discovered about the compression compressed nfts, I had no idea what it about.
00:51:39.784 - 00:52:06.874, Speaker A: So I'll take that. So we're a company and an ecosystem that helps people put up really good art, but a lot of it is fun and some of it is just frankly, like, silly. So it's a silly vibe. We don't do it to confuse people. But I don't think I came up with bubblegum. I'm more boring. I forget who came up with bubblegum.
00:52:06.874 - 00:52:28.106, Speaker A: I think it was the last one. It was gummy roll and then gummy roll, bubble gum, purple roll, then. Yeah, that is confusing. But that's, you know, to your point, we did start it off by calling these different names, like candy land. The program name in the Solana program library is account compression. Like, that's exactly what it does. There's a no op program.
00:52:28.106 - 00:52:45.454, Speaker A: That's all it does is literally no op. So yeah, we definitely take that. Take that into account when we're thinking about how to productionize it. But at the very beginning, it's just like, just, you know, slap a funny name on it. It's Jordan's fault. This all is. Thank you very much.
00:52:45.454 - 00:53:32.824, Speaker A: Thank you. Any other questions? Thank you all. All right, give it up one more time for my friends John, Austin and Noah. That was awesome. All right, so it's a little bit more crowded than when I came out at ten and welcomed you, so I think a few of you might not have heard the opening spielberg where I talk logistics. So I'm just going to go over a couple of quick things. As a reminder, there are restrooms this way.
00:53:32.824 - 00:53:53.284, Speaker A: There is food in almost every direction you can look. We will be feeding you throughout the day, so you don't really need to leave for any of your meals up until dinnertime. I believe dinner is up to you. I mentioned the disco, silent disco noise canceling headphones. They look like this. They light up on the side. They're pretty awesome.
00:53:53.284 - 00:54:21.246, Speaker A: If the echo or your sort of talkative neighbor are really getting to you and you just want to focus on the content and tune everybody out, it's been a while since we were all in a room together and it can be a little distracting. Grab a pair of these. They're at the front. Throw them on. We won't be offended. We know that you can hear us through these headphones, so it's not like anybody on stage will be upset to see you in them. They're yours.
00:54:21.246 - 00:55:01.604, Speaker A: For the day, this is the only stage that offers them. So feel free to plug in, jack in, and just focus on the content. Shuttles are running to the other venues, so you're at the laboratory, Pateo de Galle, and shuttles are running to the other venues every 15 minutes on a loop. So if you need to get to one of the other talks, head outside, look for that shuttle, and you'll be there shortly. It is Saturday, so traffic is lighter than it was the last couple days if you were here. You know, Lisbon can get pretty messy out there, but traffic this morning was super light, and I got here from the hotel in like, 15 minutes. Should take you 1520 minutes to get to any of the other venues.
00:55:01.604 - 00:55:43.758, Speaker A: Okay, we're good. Awesome. The next talk is from one of my colleagues at Solana Labs, John Cinque, my italian compatriot, and he's going to talk about token 2022, the new token program for fungible and non fungible tokens. So warm welcome from my colleague, John Cinque. Okay. All right. Oh, there it is.
00:55:43.758 - 00:56:08.542, Speaker A: Okay, cool. So I'm gonna be telling you all about token 2022. It's a new token program that we're gonna add a lot of new functionality to. It's already all there, I guess, first off, a little bit from me. So I'm John. I'm one of the engineers at Solana Labs, for the most part, working on Solana program library. So if you've looked at any of the snippets there, chances are I've done some maintenance on it.
00:56:08.542 - 00:56:39.274, Speaker A: Oh, no one can hear. Yeah, sure. Hello. Is this better? Okay, cool. So I'm John, as I was saying, one of the engineers at Solana Labs, for the most part, working on the Solana program library. So if you've looked at that repo, if you've looked at some of the reference implementations like token swap or stake pools or. I helped a little bit with governance sort of going around that side of the world.
00:56:39.274 - 00:57:30.434, Speaker A: So I'm going to go through this essentially saying why we're doing this. I'm going to talk about what the extensions are in the new token program, and then I'm going to try and do this through a frequently asked questions thing, because I've had this conversation with a lot of different people. So I'm going to assume that you, the audience, is sort of someone who has a vague idea of what this is and is going to ask me questions about it. And sometimes this audience person is a little passive aggressive with their questions, and that happens. I've gotten a lot of passive aggressive questions about this. All right, so why? You all know SPL token, it works, it's better battle tested. It has been through so many audits, a lot of security has been, a lot of time has been spent making it secure.
00:57:30.434 - 00:58:31.928, Speaker A: But we really need some more stuff on it. We need more protocol level functionality in order to actually do cool stuff with these tokens, all without causing any problems with the existing millions of tokens that exist on the system. So we're going to write and deploy a new and separate token program in 2022. So that's why it's called Token 2022. And then usually the first question I get is like, John, are you really sure you want to do this? I literally got this question yesterday and two days ago, like, are you really sure you want to make a new token program? Because adopting a new token program is going to be tricky, but I think it's going to be really good. A lot of people want to add new functionality to token programs, and the way they've had to do it now is through composability. You add another program on top of the token program that does certain things, it's limiting in the end.
00:58:31.928 - 00:59:00.996, Speaker A: And so what we think is that right now everyone assumes just one token program everywhere. Great. If we now have two token programs, then you sort of have to re architect everything into imagining, okay, there might be one, there might be two. And then at that point, if anyone wants to add another token program, I think it's going to end up being a lot easier. I get this a lot. I don't like the name and it's almost 2023. It's not a question.
00:59:00.996 - 00:59:20.566, Speaker A: Maybe we'll rename it. But I do get that a lot. We started this in the start of 2022. So yeah, projects are long. Maybe we'll rename it and then others like, oh, what about token 2023? People are just going to get confused. Yeah, they probably will. So we'll come up with better names later then.
00:59:20.566 - 00:59:58.086, Speaker A: A lot of times people still don't agree with me, so they want to know how this works. So token 22 is a superset of SPL token. So that means that the structures and the instructions have for the most part, the same exact ABI. Eventually you opt into new functionality through what we call extensions. And if you want to know about how we encode them, I think it's super cool. The person who designed it used to work a little bit more in telephony, came up with this really cool way in order for us to store variable data at the end. We can nerd out on that later, but just to talk about it.
00:59:58.086 - 01:00:40.428, Speaker A: Generally all new data is written after the 165th byte. This is very important. 165 bytes is the size of a token account. So the idea is everything is written after that. So if you've got a mint, which is normally 82 bytes, we write out different bits into it and then we'll have to add some padding and then all of the new stuff is written. So it's a way to make it easier for us to figure out like is this a mint or is it not? Because otherwise you could probably create some rugs. Then the next part is people say well, can I even use this? And I always say yes, it has been deployed to mainnet since Anatoly forced me to do it in the summer.
01:00:40.428 - 01:01:09.618, Speaker A: It was like in the early summer. So really all you can do is get token accounts by owner and you literally just pass in another program id and it works. I swear, I swear that it works. And then if you're using JavaScript, the SPL token package, if you're using anything greater than version 0.3, will have token 22 support and then the CLI starting with version 2.1 will have it. It's not released yet because circular dependencies suck.
01:01:09.618 - 01:01:36.662, Speaker A: We spend so many hours trying to sort it all out. We're almost there, but we'll be able to get the CLI out soonish. And the next thing people ask me is like awesome. Is this even safe to use? Mostly yes. So there's four audits done. We want to get one more done for some new functionality that we're adding in the next couple of weeks. So this means that the program is currently upgradable.
01:01:36.662 - 01:02:06.418, Speaker A: We're hoping to freeze it before the end of the year. So that way it can really be token 22. Absolutely. Like time boxed in a year. So if you were to look at it, it's under this really fun program id, which is token Z. We got this pub key, we were really happy about it. It's like tokens, it's like the next generate, it's the Gen Z token, and it's right now the program upgrade authority is this three URRP, which to me just sounds like BURP.
01:02:06.418 - 01:02:37.476, Speaker A: I thought that was a pretty funny thing, so I wanted to share it with you all. So maybe you're thinking to yourself like okay, another token program, what does this mean? What are the knock on effects? You might be thinking oh God, please not another associated token account program. Don't worry you're safe. We did this all for you. We deployed it during the summer. You're all good. So the one associated token account program works with token 22 and even adds immutable ownership.
01:02:37.476 - 01:03:02.898, Speaker A: So you can simply, this is already works. You can do this on all networks, create your token 22 account mint, it's all there. So at this point you might be thinking immutable ownership now. That's cool. I know. So there's a lot of extensions that we've added, one of them being immutable ownership. And then you might say like all right, tell me about some of these other extensions.
01:03:02.898 - 01:03:26.784, Speaker A: And typically when people ask me this question, I can't remember them all off the top of my head. So I'm really happy. There's a screen that gives it all to me so you can use it for confidential transfers. This is a really big feature that's been worked on Pooboy for a long time. We'll get more into that later. You can also add a CPI guard. This is a new one that we recently added.
01:03:26.784 - 01:03:51.944, Speaker A: We'll be able to talk about it a bit more later. You can add memo requirements on transfers. So this way people have to add a memo if they're going to transfer into your account. And then there's immutable ownership. And then when we're talking about mints, there's quite a few extensions for those. So again it's confidential transfers. It has to get enabled on the mint first before you can use it in your account.
01:03:51.944 - 01:04:22.852, Speaker A: You can also add transfer fees, you can close your mints, you can add interest to your token, you can make it non transferable, you can give a default account state and a permanent delegation. I'm just going through the list now so that you all have it. You'll see. We'll do something more interesting to learn a bit more about this, because you might be thinking, that's a lot. You all have been working really hard. Of course we have. You might not understand what they're for, so we're going to do this with a game.
01:04:22.852 - 01:05:11.774, Speaker A: Game. What I'll do is I was trying to think about this in terms of jeopardy context, but then it didn't super work out. But the idea is I'll describe a token design, give you like a moment to think about it, but you probably don't know all these extensions yet. I know off the top of my head, give you a moment to think about how to do it and then I'll explain how you would make this work with a live demo while live ish it's on my computer. All right, so you might be thinking to yourself, I just saw this awesome presentation about compressed nfts. How can I make a token that can be compressed, decompressed and recompressed with an off chain merkle tree? And the answer there is, you use the close mint authority extension. So this way, as soon as the supply of the token is zero, you can close it just like a normal token account.
01:05:11.774 - 01:06:02.034, Speaker A: So I will give a quick demo of how that would look with one hand. So yeah, I just, I made shell scripts because I do not trust my typing when there's people looking. So we're going to run through this. So pretty much very simply, what happened, if I can do this with one hand. So what happened over here? We created a mint with this enable close flag. Important thing, you have to create it with token 22 because the normal token keg program will not be able to support this. And then I closed the mint right over here, and then I recreated it over here, so the whole thing got closed and recreated.
01:06:02.034 - 01:06:32.562, Speaker A: So this one's pretty simple. Big fan of it. All right, so next you might be thinking, I want to send a token without anyone knowing how much I have or how much I transferred. This one's pretty easy. The answer is you had the confidential transfer extension. So a lot of people have asked about this. I think it's probably one of the coolest features that we have worked on.
01:06:32.562 - 01:07:12.004, Speaker A: There's even like a patent for it, I believe, and a really, really good white paper. So the basic concept is, I'm not a cryptographer, I also didn't work on this, so don't worry. The basic concept is you deposit tokens from your public account as a ciphertext into the sort of confidential part of your account, into the extension, and then from there you can transfer tokens around and all the amounts are masked. So it's just amounts that are masked. This is a bit of a misconception. A lot of times people think like, oh, we're doing anonymous transfers. This is not anonymous transfers, it is confidential.
01:07:12.004 - 01:07:58.564, Speaker A: So this way I send money to you, people will see that I transacted with you, but they won't see the amounts. So this means that when you first do that deposit, people will know, like, oh, they deposited 100 tokens into their account confidentially, so they'll know that you have at least 100. The idea being is that over time as people use this, it gets mixed around and you won't be able to know how much people have. There isn't a demo for this one because I wasn't sure how to get my validator set up for it because we need larger transaction sizes, which the next project, I'm really excited to do it. It's something that requires quic. So we were really happy that quic was going to be added to the network so that we can have larger transaction sizes. All right, another one.
01:07:58.564 - 01:08:51.504, Speaker A: So if you're someone who runs a stake pool or a lending protocol, you may have some LP tokens and you want them to go up in value over time, like some sort of a rebasing token. So this is another pretty easy one. You create the mint with the interest bearing extension and then a pretty fun one, you could have your protocol update the sort of perceived interest rate every epoch. So you just create your token with the interest rate and then it works. So I'll do a quick demo on this one. Okay, so here. Okay, so if we go up, we'll see that we're creating the mint with this interest rate.
01:08:51.504 - 01:09:35.904, Speaker A: I gave a really big number creating an account for it, mincing some tokens into it, and then. So unfortunately not everything is using the new amount to UI amount instruction. Essentially this all works through a UI trick, so we pretty much assume an interest rate. The actual amount of tokens isn't changing, but the sort of UI amount is. This is how a lot of these sort of rebasing tokens work on other networks. So we're hoping that a lending protocol or perhaps a state pool will like to be able to use this, but then you can reset the interest rate to anything else that you want. Oops, whoops.
01:09:35.904 - 01:10:20.436, Speaker A: Okay, another use case. So if you're creating a bank like payment system, you want to create monthly statements for your clients, and you also don't want them to get rugged by sketchy protocols. So what do you do? You can enforce that all client token accounts require memos when funds are coming in. The idea being is that you could then sort of look through. If you're talking about any popular payment provider, typically you add in a little bit of a memo, or even if you're using your bank, you add a memo before you do a transfer. And then the other one is if you want to add the CPI guard extension. This way DAP transfers must go through a delegate.
01:10:20.436 - 01:11:00.414, Speaker A: This is a really, really cool feature. The concept being that if you add the CPI guard extension and then you sign a transaction to some sort of a sketchy dapp, they literally cannot move funds. If you signed it yourself, you must approve a delegate and sign with that delegate in order for the transfer to go through in through this dap. And then it also adds a bunch of other niceties. It's a pretty fun one. So I'll do a quick one, quick demo on this one. Okay, this one takes a little longer.
01:11:00.414 - 01:11:52.954, Speaker A: So if we go up, we're just creating tokens at first, so that's not such a big one. And then where did it go? So on the recipients we're going to use this, enable required transfer memos on it. And then when I try and transfer without a memo, it'll fail. Please provide a memo and then I provide a memo of find memo and then it goes through. So this way if you're trying to create some sort of a robust client facing payment system, you can do that. And then the CPI guard is an extra little thing so that this person could interact with all sorts of sketchy dapps and there's a much lower chance that they'll get rugged. Or at least the amount that they can get stolen is limited by how much you delegate or how much you approve.
01:11:52.954 - 01:12:40.474, Speaker A: Okay, this one's cool. So if you're developing a game and you only want players to hold your token, maybe transfer it between each other without being able to dump it on an exchange. So this you could do with the default account state extension with the frozen, making it frozen. So the idea being is that anytime someone creates a token account with this mint, it'll just be frozen. This way you can create a small network of people that are allowed to use this token. And then if you wanted, when unfreezing people's accounts, you make sure that has immutable ownership. And that way any sort of player can't just give the token account to an exchange, thereby completely obviating what you're trying to do.
01:12:40.474 - 01:13:19.334, Speaker A: So this one's pretty simple to work with. So here, if you see we're creating our mint up here with the default account state of frozen, then we're creating an account. And then if I check the account, you'll see that the state is frozen. Nothing was done to it. We didn't have to do anything else, it just starts off frozen. So think about creating closed networks of tokens or permission tokens could be created with this. This way not just anybody can have a token account for your mint.
01:13:19.334 - 01:13:54.412, Speaker A: Okay, this one's also really cool. If you're running a DAO or something, you want to create some sort of a privilege token for your council members. Since they are council members, your DAO has given them special authority. You don't want them to be able to move or sell their tokens, and then eventually you might want the DAO to be able to take that token back. So if you find out one of your council members is doing something sketchy, you want to revoke their ownership. The way you would do this now is going to be really difficult. You have to go through some sort of a delegate or something.
01:13:54.412 - 01:14:31.044, Speaker A: It kind of stinks. So the way you would do this is you create a mint with two different extensions. So one is you have a permanent delegation to the DAO, which means that it could burn anything on the network, anything on that mint, and then you make the token non transferable. So this way a member can't just give it over to their friend or something like that. And what's cool is if you have the non transferable part, immutable ownership is required in order to make that work. And you could do this in other ways, right? This is just one model. Perhaps you use the default account state extension instead.
01:14:31.044 - 01:15:02.118, Speaker A: So this way, all the accounts are frozen. You only unfreeze accounts for your council members. That's another option. Like, one of the big things about this is we really want to give full flexibility for people to design the token that is going to be best for their use case. And I don't have a demo for that because I didn't finish the CLI, but it's there, I swear. So you might already be thinking to yourself, like, okay, this is all really cool, but I already have a token. Is there any way to migrate over to token 22? Of course there is.
01:15:02.118 - 01:15:47.232, Speaker A: So you can create a new mint and then use this new SPL token upgrade program. This is a stateless protocol that we designed to be like, as simple as possible. The idea being that you mint a bunch of new tokens to some sort of a bag, an escrow, whatever you want, and then this protocol will burn the old tokens and receive new ones. So I'll give a quick demo for this one. This one also takes a little longer. Okay, cool. So, all right, so, yeah, there's a little bit of setup because you have to, like, create the new mint.
01:15:47.232 - 01:16:11.410, Speaker A: Up here is at the top. The old mints created a little bit higher than that. Create an account, mint some tokens into it, create the new account to receive the tokens. And then over here, we create a special escrow. It doesn't need to be a special escrow. Literally any token account that is owned or even delegated to the escrow authority can work for this. Again, stateless protocol.
01:16:11.410 - 01:16:45.150, Speaker A: We wanted to make this as flexible as possible if you wanted to migrate. So I mint a bunch into the escrow, and then I exchange my old tokens for my new tokens over here in the SPL token upgrade CLI. Then you'll see I got my new tokens at the end, so that's a pretty cool one too. And what's pretty cool is you can do this between any two mints that you want. You can do this migration path. So after I talked about this, you're like, yeah, ok, cool, awesome. I don't want to burn tokens though.
01:16:45.150 - 01:17:18.824, Speaker A: And you know what? That's fine. We're creating a new token wrap program that allows you to wrap tokens between any two mints. This is still work in progress. We're really at the proposal stage with it, but we're building out the functionality bit by bit. So what you do is you create a wrapper mint on the old token, and then what you do is you send the old token into a bag controlled by the program, and on the other side it'll mint you the wrapped token. So it's sort of just like a bridge, the way that wormhole works, things like that. But it would be all on Solana.
01:17:18.824 - 01:17:52.012, Speaker A: We're going to add some other bits in order to make it more usable for nfTs, in order to give a back pointer to what is like the mint that you're wrapping. But that's sort of the idea. We think that probably wrapping tokens is going to be the big way forward for most people. We'll see. Okay, there's a lot of different use cases, so we have to keep going through this. If you're someone who has an on chain program and you want to add support for Token 22, how would you do that? First of all, I think that's awesome. If you want to add support, talk to me.
01:17:52.012 - 01:18:33.420, Speaker A: I'm happy to help you figure out how to do it. In general, if you're only using one token at a time, the upgrade process is extremely easy. So for example, if you're a stake pool, in which case you're working with Sol and you're working with one SPL token, you're fine. If you're an NFT project, you're probably also fine. If you're using multiple token programs at once for like trading. That's when it gets trickier. So I went through the whole painful process of upgrading the amm, the token swap, to work with both Token and Token 22 at the same time, which means you could trade one for the other, it wasn't really easy, but I did it and I documented the whole thing.
01:18:33.420 - 01:19:23.284, Speaker A: So this way, if this is something you're thinking about doing, you can read through all of the docs. It goes through step by step in a test driven development way, which is I guess better in order to add that support. And then you might be thinking, well, I have a wallet, how am I going to work with Token 22? Nice, awesome. We want more wallets to support it. We're still working on the docs, but pretty much it should, should big word just boil down to getting another set of accounts? Right now you just get the token accounts by the wallet address and implicitly you're passing in the Token program id. So now you would also get them for Token 22. And then eventually if you're doing a transfer, you literally just need to change that last parameter to Token 22.
01:19:23.284 - 01:19:54.418, Speaker A: That's really it. At this point you might be overwhelmed. That's fine, we're done. So thank you. We got a bunch of links over here. I'll probably be adding these to the Token 22 documentation so that this way you have all the different possibilities and how you want to use them. And the CLI examples that I'm using will also be added to the doc.
01:19:54.418 - 01:20:11.234, Speaker A: So thank you very much for listening. I think we've got five minutes. I don't know if that's enough time to do questions. No one's stopping me. So we've got five minutes. If you want to ask any questions, please use a microphone. I'm happy to answer anything.
01:20:11.234 - 01:21:12.942, Speaker A: Hello. So in the first token program there were a lot of vulnerabilities that came about because of the delegate functionality. Do you remember that? The delegate functionality, yeah. So a lot of user error came about that. So in the new token program this sounds like that times a million, right? You've got all these different features, so much capacity per user. What are you doing to reduce that? So how do we reduce user error with token 22? Yeah, given the context that the delegate authority functionality led to a lot of vulnerabilities when people were using the original SPL token program because they didn't realize it was there. And so people would like you wouldn't check that the delegate hadn't been assigned, and so someone would maliciously assign their own delegate authority, assign a token account and then steal all their money, which is quite common thing.
01:21:12.942 - 01:21:55.090, Speaker A: Yeah, so the way that, so the CPI guard actually covers for that also, the idea being that you cannot do an approval inside a CPI. So the only way that you would get rugged is if you don't look at the transaction and you don't see that at the top level it's doing an approval. So this way you have to approve at the top level. You cannot approve in a CPI, that's what the CPI guard is trying to do, among other things. But that's just one feature. So I mean, for all of the different features, is there like an easy way to check that all the features are turned off or these kind of things? Yeah, it depends on the extensions that, oh yes. So if you want to target different extensions that, for example, if you don't want the mint to be closed, you can just check that pretty easily in your on chain program.
01:21:55.090 - 01:22:22.232, Speaker A: The idea is we've got like, we did some fun little metaprogramming stuff in order to make it work. So you just like say get extension for that type and if it works, that means it's there. If it doesn't work, then it's not. So you might, you will have to add different checks if you want to prevent certain extensions from being enabled. Yeah, yeah, definitely. Okay, cool. Hey, how's it going? You mentioned there's like a new get token accounts by owner for the new token program.
01:22:22.232 - 01:22:52.348, Speaker A: It'll be indexed by all rPCs. Does that mean you expect like all wallets and Dapps to do two network calls to get all token accounts if they need to support both? Or do you think that RPCs will support unified index on those two programs? Yeah, that's a good question. We're not planning on doing that for now. The idea being is you do one call and you do the other. So this way it's an extra call if you want to get all their token accounts. Unifying them is going to be kind of gross and tricky, but we can be flexible. We'll see.
01:22:52.348 - 01:23:22.860, Speaker A: I mean, I think the idea would be if you want to do that, use a geyser plugin, put it in a different database and query that. That would be my case. Got it, makes sense. Yeah. Got another two minutes? I have another question. It sure hit me. For getting extensions, are those all built into the mint and token accounts, like at the end of the account data, or are they separate accounts? In other words, can you get all the extensions and look at them without another network call? Sorry, I missed that last part.
01:23:22.860 - 01:23:41.888, Speaker A: You get all the extensions in what? In other words, can you get all the extensions and check which ones are active without an additional network call to an existing RPC? Oh no. So the way when you get your token account all the extensions. If you do like getaccount, that's the full data, and then if you parse it, the extensions are there. So, yeah, that's just one call. Got it? Yeah. Double the hooking. Thanks.
01:23:41.888 - 01:24:15.504, Speaker A: Yeah, sure. Hey, congrats on the talks. Really, really cool. Small question with regards to zero downtime migrations is the right approach to use the wrapping system for what type of migration? Say that again. Zero downtime. So if you're like a wallet or an exchange or so. Well, especially if you're a wallet, like, how would you do that with zero downtime? Zero downtime to who? To, I guess the token in a certain sense, yeah.
01:24:15.504 - 01:24:31.862, Speaker A: So that's. I think it's an open question. Probably what you'd want to do is wrap them. So this way the tokens always exist somewhere. You can always. So if a program only supports token, that's fine. You wrap token 22 into token, use it there, and then get out whenever you need to.
01:24:31.862 - 01:24:46.614, Speaker A: That would probably be the best way. Have them both wrapped. Thank you. All right, I don't know if we have time for one more. I don't know if I'm going to get booted. Ok. I'm going to be over there or I'll be in the back.
01:24:46.614 - 01:25:17.654, Speaker A: If you have any questions about this other use cases, please feel free to get in touch. I'd be happy to talk through anything otherwise. Thank you very much for listening, I really appreciate your time. Thank you. Nice work. Awesome. Thank you so much, John.
01:25:17.654 - 01:25:46.956, Speaker A: To quickly introduce myself, my name is David McIntyre. I work on grants at the Solana foundation. I'll be mcing for the rest of the day. So very excited to be here and really appreciate John's presentation, as well as my colleague Josh this morning. Mce, just to sort of do some logistics, we're going to take a quick break, 15 minutes. We'll be back at 1145. So grab a drink, take a little walk, grab a snack, and we'll be back very shortly with some great content.
01:25:46.956 - 01:26:17.834, Speaker A: So thank you. Hello, everyone. Again, thanks for the wave in the back. I hope you enjoyed the break again, my name is David McIntyre. I work on grants at the Solana foundation. So working with a lot of developers and projects who are building public goods for Solana, I'm really excited to be emceeing on this stage today. I work with a ton of developers all the time, but I'm not a developer myself, so it's amazing to hear about all of these advances, all of these really practical pieces that are coming to life on Solana.
01:26:17.834 - 01:27:06.910, Speaker A: And so I wanted to kick off our next bit of programming by introducing a really exciting talk about the verification of Solana programs. So please give a really warm welcome to Stepan Simpkin from squads and Robert Chen from Otterseck. Yeah. Okay. Hi everybody, my name is Stepan. I'm the coffee. Can you hear me? Yeah.
01:27:06.910 - 01:27:35.898, Speaker A: Okay. This is Robert from. We're going to talk about formal verification. Robert is really the start of the show. I'm just going to explain how this whole thing came about and give you some more context. Yeah, okay. Hi.
01:27:35.898 - 01:27:55.534, Speaker A: Okay. Yeah, but first let's talk about Squaz a little bit. I'll give you some more context on why this is happening. Can I get the. Okay, yeah. So Squaz is the multi seq infrastructure for Solana. We have been on Mainnet for a while and we have over 3000 multisents deployed to date.
01:27:55.534 - 01:28:34.534, Speaker A: The way we like to talk about squads is we like to separate the standard and the products that we build on top of them. So the standard is really the protocol layer. There's the core multiseq program that's really minimal, really agnostic. Then there's the Squads Multiseq program library, which is a collection of programs that expand the functionality for the products that we build. Then there's the work on the ecosystem front, we have a robust SDK, a lot of technical docs and encourage people to build projects and products on top of squads. Streamflow, for instance, have completed their integration, so you can stream tokens directly from the squads. Multisig Magna is working on one for investor unlocks and really looking forward to them to come to Solana.
01:28:34.534 - 01:28:55.244, Speaker A: And then there's many more. And then there's a lot of the work we're doing on the security side. So squads is open source, it's written on anchor, anchor verified. It's been audited multiple times. And auto Stack is our ongoing security partner for all the, the security orders that we do. It's been peer reviewed before launch and we have a perpetual bug bounty. So if you find any bugs, please reach out.
01:28:55.244 - 01:29:40.196, Speaker A: And then we have the SEC three tool running for any changes that we do to the code base. On the product side, we have two products live right now. So that's squad's the main product that focusing on treasure management, program management, token management, workflow management, and validator management. So allowing teams institutions on Solana to manage these quarantine assets via Multisig. And we just launched our CLI tool, which we're going to announce later today that allows the pro and power users to interact with the Multisig directly with the CLI. And then there's this squads X, something that we're working on right now, another product built on top of our standard that's yet to be revealed, and so we'll be sharing more details on that shortly. And then there's SCN.
01:29:40.196 - 01:30:12.148, Speaker A: SCS is a collective of teams that rely on the standard that we build, that help us to promote it, or integrate with us, or build products on top. Those are friends and partners and end users. And we're excited that this list is growing day by day. And so, for us, the core objective for squads was always to make it the go to multiseq standard for Solana. And security is top of mind. So we kind of did this sort of checklist of everything we want to do to make sure that squads is secure program. And you saw that on the previous slide.
01:30:12.148 - 01:30:45.528, Speaker A: But formal verification has always been this kind of final frontier. And as soon as we completed, like, this sort of initial checklist, we reached out to Robert saying, we want to formally verify squads v three, the main model program. And we figured out that the framework doesn't really exist for Solana, and there's not really any program on Solana that is formally verified. And so, so Robert decided to help us out on that. And I'm gonna hand over the mic to him so he can share all the amazing work that him and the auto stack team have been doing in the last few weeks and months. Yeah, thank you. Does my mic work? Do I need this? Hello.
01:30:45.528 - 01:30:56.776, Speaker A: Testing. Okay. Yeah, thanks. So, auto sec, we do Solana smart contract audits. We read a lot of code. So we work with, you know, Solana core directly. We read the validator code.
01:30:56.776 - 01:31:20.768, Speaker A: We also look at anchor internals and also a lot of protocols, such as squads. Yeah. Quick list of our clients. Yeah. Okay, let's get to the. Actually interesting stuff. So I think formal verification is kind of like this buzzword, right? Like a lot of people say, oh, let's formally verify our programs.
01:31:20.768 - 01:32:12.086, Speaker A: But what does that actually mean? So, in a nutshell, formal verification lets you prove that compile time critical properties about your code. And I guess this kind of lends itself to the question, what are, like, what are critical properties? Right. It's like a very vague concept. For example, if you have a lending protocol, what is critical to the functioning of a lending protocol? And oftentimes that's not really obvious. Right. You might be able to think of some examples, for example, like a lending protocol should probably be fully collateralized, but it's kind of unclear if this definition of fully collateralized in and of itself is enough to define the security of a lending protocol or if it's just one of the properties. I guess another example of this would be, for example, that a multisig threshold is always less than the number of owners.
01:32:12.086 - 01:32:52.472, Speaker A: This means that you can't brick the multisig. You're always able to to theoretically propose a transaction and sign for it, I guess kind of as a caveat. Moving into this presentation, one thing that I want to keep in mind is we don't really want to over promise here. Formal verification, I think, is a really useful tool. But when some people claim that formal verification solves all your security issues, that it makes it impossible to get hacked, I feel like that's not really true. I think it makes it harder to get hacked, and I think it lets you more clearly reason about critical properties about your program. But it's not always that straightforward.
01:32:52.472 - 01:33:31.840, Speaker A: Some examples of this would be it's not always clear what you should be even verifying with formal verification. For example, with the multisig squads, maybe it's more straightforward. We have a threshold less than the owners. Whenever we execute a transaction, you need to sign for all of the owners. I think, for example, for a lending protocol, it becomes a lot more opaque. What actually defines critical properties of making a lending protocol secure? And I guess there's also some non trivialities with actually using formal verification modeling the Solana VM is pretty non trivial. What actually happens during a CPI? It's hard to reason about that.
01:33:31.840 - 01:34:05.008, Speaker A: Loops are also like a pretty painful for formal verification. Yeah, I guess this is kind of like a high level overview. Let's talk about what existing work looks like. So the interesting thing that we were looking into as we started this project for squads is that there's a reasonably mature rust formal verification ecosystem already. There's a lot of existing rust verifiers. They take rust code, and then you're able to assume and assert certain properties. The one that we chose to build out this proof of concept was Connie.
01:34:05.008 - 01:34:50.844, Speaker A: There's also many others. I listed Presley here. I think there's another one, like Vipers or something. Yeah, there's a lot of verifiers, and essentially what they do is they let you take assumptions about your code and also assert statements that you think must be true. So for the rust level, this is kind of solved. I guess one caveat here is that we're doing verification at the rust IR level, so this doesn't go into BPF code, which means that theoretically, if, for example, the BPF compiler messed up, you could verify something with an existing rust framework, but you wouldn't be able to, it would fail in the real world. I think this is kind of a trade off here.
01:34:50.844 - 01:35:51.120, Speaker A: Like, we could also write a framework to verify at the BPF level, at the VM level directly. But I think that makes it a lot more difficult to actually prove anything, because it's a lot more complex when you're proving things at a lower level, it's often harder for the prover to terminate. And I guess another example is we've, for example, found issues in the Solana VM where the Solana VM doesn't actually respect the rust standard. For example, Solana stack behavior sometimes differs from normal systems, and due to a cork in boundary processing in memory pages at the VM level. So I guess that's another example of an issue where you could theoretically have an issue at the VM level that doesn't actually get solved or doesn't actually get reasoned about in formal verification. I would say that these are probably very theoretical issues. The boundary issue that we found in the VM was extremely unlikely to trigger.
01:35:51.120 - 01:36:29.384, Speaker A: It required very precise stack boundary alignments. So that's kind of why we chose let's just do this at the rust IR level. Let's just use this really mature, existing formal verification ecosystem, and we're pretty confident that it's unlikely to actually cause any real issues. I guess the main difficulty here is we have these really nice formal verification, or somewhat nice formal verification tools. The hard part is adapting it to the Solana framework. If you try to naively run connie on an anchor program, you get this really nice error, which is very obscure. I think this is something to do with.
01:36:29.384 - 01:37:01.626, Speaker A: Something to do with concurrency in the Solana VM or something. It's like they use probably unsafe code or something that just causes this error. And I guess, yeah, so when we were doing this verification, the approach that we took was to essentially not use any Solana framework code, but to try to write out stubs for all anchor salon of code. And this way we could actually get these tools to run. Yeah. So, I guess so. These tools work pretty well, except for when they don't.
01:37:01.626 - 01:37:27.712, Speaker A: Like, they don't work on Solana code when Mainnet. Oh, yeah. So let's actually talk about what we did. So we built this nice proof of concept called Otter verify, which is Solana anchor and Connie. Yeah, and we actually verified a. I think we verified the threshold property on the squads multisig. Okay.
01:37:27.712 - 01:38:00.174, Speaker A: Yeah, so some, okay, I think there's like two kinds of invariants that you can, you can think about with formal verification. So one of them would be function level invariance. So this is squad's create code. And this is like you might want to reason about, you know, invariants after create runs. For example, after the create function runs, you should always have at least one member. You should have less than members. The threshold should be greater than some number, threshold should be less than the size of the members.
01:38:00.174 - 01:38:42.498, Speaker A: And then if you look at this invariant, it's probably relatively straightforward to reason about. Maybe this is sufficient to define the security of a multisig. It's like these properties are pretty good to verify if this is always true, we can be confident that, for example, modulo some issue in the signing that, that the multi sig is in a valid state. I think the other kind of invariant is like a structure level invariant. So this is the squads multisig object. It's called Ms. And then it's often useful, for example, to know that at the end of every function's execution, that the threshold is less than or equal to the number of keys.
01:38:42.498 - 01:39:19.076, Speaker A: So this is similar to the invariant we described previously. But this is like for every function. Yeah, yeah. So for example, in the remove member, how do we actually verify this invariant? Right. It's like, I think if we look at this code. Yeah, it's like the if statement there. Like ifcontext counts, multisig keys length is less than the threshold, then we just change the threshold to the number of keys.
01:39:19.076 - 01:40:24.520, Speaker A: So by reading this code, we can relatively easily see that this invariant does hold. But what happens if we comment this out? And this is actually kind of interesting, because when we were testing this code, we tried commenting this out, and then we saw that the verification still passed, that we were still able to prove that the threshold is less than the length of the keys, which is kind of surprising, because we see that clearly we removed some supposedly critical code that is supposed to update the threshold when the number of keys has decreased. And I think this example really illustrates the beauty of formal verification, because we have this assumption. We think that this code looks critical, that it's critical to the functioning of the multisig, but our framework tells us that it's not. And then if we look into it a little bit deeper, it turns out that actually the squad's removemember function. So this is pretty good design practice on their part. There's actually a redundant check when they remove a member.
01:40:24.520 - 01:41:14.014, Speaker A: Whenever they remove a member, if the threshold is greater than the number of keys, they automatically reassign that threshold to the number of keys. So it turns out that the previous check was actually extraneous and we didn't actually need it. So if we comment out this check, then we get what we actually expect, which is that the code doesn't actually verify. And I think this is kind of an example of where formal verification is really cool because it lets you reason about these state transitions in a non trivial way. You have many places where you could, for example, update these critical fields. But by defining the property once, we only need to say we think that the threshold must always be less than or equal to the number of keys. And then we just run this framework, and then we're able to immediately know that this critical property is true.
01:41:14.014 - 01:42:02.508, Speaker A: The caveat is, of course, maybe there's other critical properties that we haven't defined, and maybe that could be the cause of an issue. But for now, this is, is pretty promising, I think. Yeah. I guess as a concrete example for a little bit more on the internals for how we do this. I guess this is a little bit more technical, but Connie has essentially any structure which lets you define your own structures. So in this case, we have this MS object, and then we fill it in with arbitrary numbers, and then we have like. Yeah, okay, this is a video.
01:42:02.508 - 01:42:15.500, Speaker A: I don't know if it will actually play. Can we play the video? Okay, maybe not. Okay. Oh, wait. No, it does play. That's great. Oh, yeah.
01:42:15.500 - 01:42:36.814, Speaker A: So this is running it twice. And then this is like what the code actually looks like when we run it. And. Yeah, there's like a lot of warnings. We should probably filter those out at some point. Yeah. And then we can see that, you know, when it doesn't work, it prints out that it failed.
01:42:36.814 - 01:43:21.864, Speaker A: And I think the other one should be like, when we actually fix it. So this, these two are the. I believe this is the threshold changing one. If we could run the other video, that would be nice, too. Yeah, I think for these videos, we probably should have actually shown what code we changed, but, yeah, this was like a very last minute, kind of approve a concept that we recorded. So, yeah, we were kind of rushing this a little bit, rushing this presentation a little bit because we wanted to get it in by breakpoint. Yeah.
01:43:21.864 - 01:44:00.214, Speaker A: Okay. So I guess, yeah. Like, the actual code that we updated was like the ones on the previous slides where we updated threshold changing. Yeah, this kind of shows that we can actually verify a property, and hopefully we'll be able to verify, you know, many properties about both squads and moving forward, other programs. Yeah, I think that's it. We have actually ten minutes for questions, so if anybody wants to ask something, we're here, or we can just do it after. Whatever works for you guys.
01:44:00.214 - 01:44:18.198, Speaker A: Okay. All right. Yeah. Thanks, guys. Thanks, guys. Appreciate it. It was an amazing talk.
01:44:18.198 - 01:44:42.118, Speaker A: I saw a ton of people in the audience being really, really focused on that talk, so obviously, the content was very, very relevant. I also saw a lot of people using these headphones here. Highly suggest this. I know the room is a little bit echoey, and there's some background noise. Beautiful space here, but it does have very high ceilings, so you can hear the speakers a lot more clearly. Or if you're. If you just want to kind of zone in and focus.
01:44:42.118 - 01:45:06.416, Speaker A: These are very, very helpful. Also, just a couple of logistics. Restrooms are over there. There's also a big room with refreshments and food just behind me here. So behind the stage, if you haven't checked that out, as well as all these amazing booths back here as well. I also wanted to say a little bit more about myself. I work on grants with the Solana foundation, so working to fund public goods on the Solana network.
01:45:06.416 - 01:46:25.226, Speaker A: So things that may not have a commercial reason to exist, but which, if they did exist, would help Solana grow, help it be more decentralized, help the network, help other developers. And so happy to chat with anyone during this conference about your project, about grants in general, any questions you might have, things like that. And actually, as a part of the grants program, we're always trying to sort of be more data driven and really work with our projects to measure their impact in more sort of data driven ways. And so I'm really excited to introduce the next panel, which is about measuring what matters with some of the leaders of the best analytics platforms in crypto. So I'm going to start off by introducing Frederick from Dune, who's going to give a little presentation. Then we're going to do a great panel with some other folks that he will introduce, so give him a big round of applause. Working now it is.
01:46:25.226 - 01:46:52.182, Speaker A: Yeah. All right. Hey, good day, everyone. I'm Frederik from Dune. We're a crypto data company that allows anyone to easily write some SQL on our website, analyze blockchain data, and visualize the results. And so I'm going to start this off by telling you a little bit about what is happening on Solana when it comes to activity. So from a high level.
01:46:52.182 - 01:47:49.770, Speaker A: We can see that Solana has started sort of half year ago, there was about 2.3 million active users a month. Then that has been trending downwards, but not as much downwards as sort of the prices. And now actually in October, the first month in the last half year, where daily active users is up again. So that is good news. If we look more deeply at specific sectors, we could look at Dexs, for instance, and see that this has also been trending downwards, but not a lot like, it's not like dropping like a stone. We can see that there's stepn and serum have by far their largest market share of users, and it's now at around 25,000 daily active users.
01:47:49.770 - 01:48:22.654, Speaker A: And this is not that far from Dexs on Ethereum, which is around 35,000. So it's the same order of magnitude of users. But as you probably know, something that's even bigger than Dexs on Solana is nfts. So let's have a look at some NFT stats. So number of projects on Ethereum is only around 60,000. It's obviously quite expensive to create them, versus on Solana there is 3.6 million NFT projects.
01:48:22.654 - 01:49:26.350, Speaker A: And we can see that the weekly number of projects created for Ethereum is around 1000 a week, versus Solana, where it's been way, way more. It's now down more, but it's still way, way higher than Ethereum. I think this is around 30,000 a week of projects created. And if we look at the unique buyers, Solana is now at around 40% market share in terms of unique NFT buyers relative to Ethereum. But if you look at the volume, the actual sort of gross market value of these trades, it's only around 10%. And so hopefully, if you're a curious mind, you're now wondering, how do I make these charts? Maybe I can look deeper. What can I do? And so Solana launched on Dune earlier this year, and we only had a few data tables available.
01:49:26.350 - 01:50:06.494, Speaker A: So these were the tables that you could use on Dune for Solana. So this is pretty low level stuff. You have the blocks, the rewards, the transactions. And these schemas give you certain tables that are things like block time and fee. And then there's instructions where most of the interesting stuff around the program happens. And if we look deeper at a table like this, this data is pretty low level. Like you get an array of instructs and deep in the weeds here, you find out who's actually using what product and what they're doing.
01:50:06.494 - 01:50:54.824, Speaker A: Which is a bit hard to work with. And dune pioneered user friendly data tables for Ethereum. We created the easiest to work with datasets for the Ethereum space starting four years ago. And that has been the key thing we've enabled for that space. And the thesis behind that is that basically raw blockchain data is made for machines. Blockchain is just a computer and anyone can't look at this and make any sense of it because computers talk in a different language than humans. And so a simple thesis behind Dune has been that humans are not computers and they rather want to look at human readable tables.
01:50:54.824 - 01:51:43.374, Speaker A: So today I have an amazing new announcement for the Solana space. So Solana is now becoming the first non EVM chain on Dune with decoded data. Woo. That means you will all have a set of super nice human readable tables to work from. So let's have a quick look at what this looks like. Basically what you get here is a schema for each project instead of only the low level blockchain stuff. So all the different projects, you can submit idls and create these schemas, and then you get a set of tables for each function.
01:51:43.374 - 01:52:31.734, Speaker A: And so what that looks like is you get a nice column for each data field. So then you can way more easily see who are the traders, what is the activity, what are the amounts and whatnot. So this is way, way easier to work with. And so let's take an example. If you want to look at Jupiter, the aggregator and count daily transactions the last six months previously or daily trades previously, you would have to work with some messy arrays to figure out the actual stuff you want to do. And there would be so much data because you have to scan so many tables to figure this out that it would time out. So this one specifically last six months is 60 million data points.
01:52:31.734 - 01:53:13.042, Speaker A: And now with these new tables, this same query runs in 6 seconds. And it is way, way easier to work with both better performance and better ux with working with the data. So that means that you can super easily go ahead and create all kinds of dashboards and visualizations in seconds with easy to use data. So we're rolling this out these days. So if you want to check this out, you should join our Solana channel in our discord. We also have an API product that's coming very soon. And all of this you can do for free open access on dune.com.
01:53:13.042 - 01:54:00.054, Speaker A: So thank you very much. All right. And then we're doing a panel and I'm not sure if I'm introducing us or not. Your name? Yeah, there we go. Is this thing working? I think so. All right, guys. Well, first of all, Frederick Dune.
01:54:00.054 - 01:54:34.538, Speaker A: Guys, we have big brains on this stage. I think we'll just start with quick introductions. I'll kick it off. My name is James Troutman. I'm a research analyst with Masari. And in particular, I work with our protocol reporting group and cover, basically, protocols, including Solana. And essentially what we do is, if you want to call them that.
01:54:34.538 - 01:55:00.678, Speaker A: Right. So, quarterly reports, four base layers. And as part of doing that, we do a lot of quantitative work and evaluate on chain data, off chain data, basically, as much information as we can. We use Dune, we use lots of different explorers, block explorers. We have data scientists that are pulling data in order to drive insights, understand what's going on. Right. And following the progress of Solana, specifically in this case.
01:55:00.678 - 01:55:32.490, Speaker A: So that's a little bit about me and why I'm here, but excited to discuss, you know, measuring what matters with these guys. I think they know a little bit about that. So, I guess quick introduction, starting with yourself. So, hi, guys, I'm Nicholas. I'm one of the co founders of Slana FM. So what Solana FM is, is that we are basically a data infrastructure provider for the entire Solana layer. So we not just build explorers in general, we actually offer APIs that are easy for you to access, probably what was mentioned earlier, like human readable data APIs.
01:55:32.490 - 01:56:26.134, Speaker A: So that's what we focus on. And we are also striving towards building maybe SDKs and tooling that helps Solana builders build much quicker and easier. I mean, you have introduced yourself already, but I guess maybe you can just tell us really quickly, why dune? Right? I mean, we know who you are, right? You started created dune, but why give us a sense of where you started? Yeah, I think for us, it's always been very interesting that blockchains are these open data sets that just keeps producing more data. But that's just like a theoretical thing. It's in practice and to some extent still, it's like, very hard to work with these things and actually make it a practical reality to leverage this data in various ways. And so that's basically what we're trying to solve. Makes sense.
01:56:26.134 - 01:57:06.552, Speaker A: I'm Dave with Etherfuse. Our mission is essentially to promote the decentralized centralization of infrastructure that powers the blockchain. We're really focused on helping more emerging markets capture the value they create with crypto. And so a big kind of value statement for us is to know where infrastructure is not to set it up there and write tools and legal frameworks so that they can do it profitably and we can kind of promote the strength and security of the blockchain through that. Great. I could barely hear you, but I think I got it. I know I'm getting the gist of everything.
01:57:06.552 - 01:57:29.624, Speaker A: I think they can hear us, but we are having a hard time hearing each other just scream at me. Okay, I'll do my best. All right, so this session and topic is measuring what matters. And that's a very loaded topic. It could be anything and everything. It may exist already. It may not exist.
01:57:29.624 - 01:57:52.856, Speaker A: There may be things that I'm sure all of you guys are working on, right, towards measuring something. But I guess let's just start right with the session. Right with the topic what matters. Right. Frederick, you kind of pulled up some high level data around Solana. We know that the NFT activity on Solana is, is exploding. It's continuing to explode.
01:57:52.856 - 01:58:52.358, Speaker A: We saw over the third quarter, right, 10% of sales volume, but there was a 5% change over the quarter. Right. So it was a massive influx during as well, a pretty slow market, so. But that's just one thing to measure, right? And does it really matter? I think it sure matters. But I guess starting with you, you know, what do you think really matters? Is there something that is already, that already exists that we should truly be tracking, or is there something else that doesn't exist that you're working on that we should be also? Like, what do you think really matters in terms of measuring activity? And so I think, speaking specifically for Solana, right, since we specifically just built data pipelines just for Solana, I can only speak for that generally. What we've been doing so far is that we've been going deep down into actual things like per se blocks. Like, let's say maybe there's n number of actually transactions they can squeeze inside the block, right? So what transactions comprise in that block? That's a big question.
01:58:52.358 - 01:59:27.774, Speaker A: We can find out, right? Like, is it Jupiter swaps happening in majority of this block, or is it something like that? We could find out how efficient blocks are packed. So just speaking on the technical aspect, we can find out, you know, huge, major activity patterns happening inside Solana. So, for example, mints or NFT activities actually happen much more proactively inside gmt zero between maybe, say, twelve all the way to 06:00 p.m. So I actually reside in Singapore. So in the middle of the night. Right. You won't actually get very little activity you actually get a lot of activity in the sag salana, but during the day in Singapore, right.
01:59:27.774 - 02:00:05.310, Speaker A: We actually have little to no activity compared to what's at night. Right. So that's, for example, something we find out. But maybe to answer your question in more explicitness, I would say we are trying to find more granular details here and there so that guys like Frederick per se, Dune can actually build on top of that. And per se wizards, right? Dune wizards could be like, oh, actually, SOlana FM has a couple of much more granular, detailed point of metrics. Maybe Dune could have that because for us, we are showing you what matters right now, but Dune shows you what matters in the entire long term and historical sense. Right.
02:00:05.310 - 02:01:04.010, Speaker A: So, yeah, that's what we cover here. Well, you certainly do a lot of it and are continuing to measure everything and anything. So I guess, like you personally like or whatever it is that you're working, like, really to you, what really matters? Like, if you had, let's say, one dashboard, you had only one choice. You had to look at that one thing. What would it be? I think crypto people sometimes like to try to reinvent everything, but I think there's, you know, there's a very well written and tested playbook for how to build technology products in startups. And I think, you know, if you build a technology product, you need to understand, like, are people using my thing? Are they coming back? How engaged are they? You know, just like growth in usage, growth in retention, these type of things. And I think that is still, like, under leveraged in crypto as a whole.
02:01:04.010 - 02:01:55.114, Speaker A: Like, people, you know, look at aggregated metrics or these type of things. But actually, at the end of the day, you know, we know sort of, you know, the technology industry knows how to build sticky, incredibly useful products. And I think those same metrics should be leveraged way more in crypto as well. If you're building something, doesn't matter if it's on chain or in like, you know, traditional web app, like, the same thing counts. Like, you need people to use it. And I think that's something maybe even the Solana ecosystem is somewhat more sort of leaned towards than maybe some of these others that are very sort of leaning towards the technology side. But also in Solana, actually thinking about, you know, how do we get mass adoption? How do we reach a large audience? And so I think, yeah, that's the metrics I would track.
02:01:55.114 - 02:02:25.118, Speaker A: Like, do the startup 101 metrics and do that for your product on chain. That's what I think we should see more of. Makes sense. So again, with what I do, and I'm joking, hear me that if you looked at one thing, there's no such thing as looking at one thing. Right? So what I evaluate a base layer. It's network activity, it's network functionality, it's transactions per second. It's everything.
02:02:25.118 - 02:02:53.770, Speaker A: Right. And I could go really, really deep into. Into Solana and the metrics that I track and that we look at at Masari. Dave, you had sent an email a couple of days ago. One thing that is lacking, or that I wish we had more of, is actually around the decentralization of a network. We know, say, the validator count on a network and we might be able to calculate a Nakamoto coefficient. Right.
02:02:53.770 - 02:03:28.098, Speaker A: Which is interesting. I think it's a. I think it's a good start. It's certainly not the end all, be all measure for decentralization or gauging the decentralization of a network. I think you had emailed a little bit about this, and I think, in my opinion, being able to get more insight into the actual decentralization of a network matters. So maybe you can tell us a little bit about your thoughts on that. Yeah, I mean, we say measure what matters, which is a good phrase, but sometimes we also measure to find out what matters.
02:03:28.098 - 02:04:06.720, Speaker A: And in our case, you know, decentralization is really important. You hear a lot of stuff online that says, you know, just kind of, we're centralized or we have these things. So I wanted to find out and come up with a measure of that. And, you know, Balaji has a great paper on measuring decentralization, mostly focused on proof of work. And so what we did is we created. We actually didn't create a site created personally at first, but I launched the site at measure Dot etherfused.com, where we picked five new subsystems to measure for proof of state networks, which is political ownership, corporate, algorithmic and regional.
02:04:06.720 - 02:04:54.024, Speaker A: We wanted to measure decentralization in those terms. What's the Nakamoto coefficient for each of those terms? And it's really helpful because you hear things like, some of the biggest things people will say about Solana is it's dependent on Amazon Aws. And if you look at corporate, the Nakamoto corporate coefficient, if you go to that site, which I know it's a crappy site, when I found out I was speaking, we really quickly made it. Not a dashboard, it's open source. So anyone can help us make it better, but it will be better in three months. You can see Amazon has a relatively small footprint, considering size for Solana. In addition to that, you can also see Solana is doing pretty well with stake distribution compared to, like, other chains like Ethereum, you know, Coinbase has a relatively small footprint.
02:04:54.024 - 02:05:28.524, Speaker A: And in our case, we really want to help. We view the infrastructure as a way to help folks in a community capture the value they're creating. So when we wanted to go see where should we set up validators that they currently aren't, we wanted to actually physically see where they were. We decided to prove some of our other products not related to this in Mexico. And we really got that insight by looking at decentralization, having a number and define. Yeah, so again, I heard maybe. Sorry, a little bit of that.
02:05:28.524 - 02:05:59.508, Speaker A: I'm working on my lip reading here. I got a little bit of it. But what I think I heard in this there is, of course, measuring decentralization across several vectors that go beyond, again, the number of, say, validators on a network and the distribution of state. Right. That's pretty much a little bit what we have now to understand how decentralized the network is. I think what you were getting at is there are other aspects of the network that we can probably measure, such as location. Right.
02:05:59.508 - 02:06:43.980, Speaker A: Geographic location and distribution across the globe. Do you see a world where we can actually quantify that? Say, we enhance the Nakamoto coefficient with some other quantitative. And I think you might have been getting to that to be able to measure that. Right. Like, so maybe it's some sort of weighted average of this amount of distribution across the globe, this much concentration in this part of the world, this much exposure to this geopolitical risk, so on and so forth. Do you see that as a way to go, like, are we. Are we moving to enhancing, like, the Nakamoto coefficient with some other type of coefficient to get a better idea of decentralization? Yeah, I think one way to do it is to create, like, an average of Nakamoto coefficients upon an agreed set of subsystems.
02:06:43.980 - 02:07:09.604, Speaker A: I know that's a word salad, but really, it's hard to compare. Who's decentralized is really like a loaded terminal. You know, it can mean a lot of things. So I think that we could one, I think the community needs to agree upon what measurements we use and then compare those evenly and maybe create. Have it float up and create a way of measuring. I like a Nakamoto coefficient. I think it's helpful.
02:07:09.604 - 02:07:39.184, Speaker A: It's a discreet goal. But there are also other ways to measure inequality. And maybe a discrete discussion needs to be had and we're open to prs that help discuss those things, too. Great. Broderick, I'm going to come back to you. You've pulled up some dashboards, some dune dashboards, kind of looking at nfts, gamefi. So we don't have a lot of data yet.
02:07:39.184 - 02:09:03.004, Speaker A: When we look at Gamefi activity, it's starting to come a little bit more, certainly a lot more than even six months ago. Can we expect to see a lot more gamefi applications and measures that we can look at, especially on Dune? Or do you see a different sector perhaps, or a different vector outside of gamefire? There's social applications that are also kind of rolling out. What do you, what are you thinking about in terms of what's next? What are we measuring beyond defi and nfts? Yeah, I guess at June we kind of have the, we don't try to predict as much and let whatever emerges emerge. So, I mean, I probably would have been a vc if I knew what was the next big thing. But I think, yeah, obviously, obviously there's, throughout the last couple of years there have been a bunch of things happening and Axie had massive numbers at some point. So maybe, I think one thing in these dynamics, whatever sector it is, one thing that's important is to bake in and understand the tokens that go into the token mechanisms that go into it. Independent of exact sector.
02:09:03.004 - 02:10:26.824, Speaker A: There are some extreme growth happening every now and then in some products or categories. And I think one thing that's very important to think about then is like, what's the incentive to use this thing? And I think we saw that with Luxrare versus Opensea. Now there's a thing called blur on Ethereum that's competing with Opensea, but they have a token that you will get airdropped. And so I think this is maybe like a little bit of the elephant in the room when looking at some of these stats on whatever category it is that if you make money for using the product, then those numbers are probably going down if that incentive goes away. And I think this, again, if you bring it back to traditional sort of company building or product building, that's like customer acquisition costs, right? There's no such thing as a free lunch if someone gets paid money, like someone else is paying that money in some shape or form. So I think that's, you know, whatever emerges, it's the dashboards will pop up and then the question I would ask myself is like, what's the insight? The incentive behind this usage is to what extent is it organic versus incentivized. Sounds good, I think.
02:10:26.824 - 02:10:54.224, Speaker A: Still having a hard time hearing you guys making out the best that I can. It was a great response. It was good. It was good. Well, again, we talked a little bit about measuring decentralization. We just talked about like, what are, what are we going to have to measure going forward? And it's really, you're just saying, let's just build a foundation to be able to measure anything and everything. Not really like trying to predict anything or anything like that.
02:10:54.224 - 02:11:43.504, Speaker A: You know, I don't know if any of you guys can speak to developer data, but that's another, what I think is a very important measure is the development activity that's actually occurring within an ecosystem or within the core network itself. There's not a really good place to find that. Right. So I personally think that being able to measure the actual decentralization of a network matters probably one of the top. And what you were alluding to, I think, is probably the best way to go about it. And Solana and Solana foundation actually did a health report in Q three and got into some of that data. And actually I was able to get, and there's a dashboard out there that shows where each data center is, the concentration in each data center.
02:11:43.504 - 02:12:11.584, Speaker A: We know that there's a bit of concentration in Germany, right. We know that there's a bit of concentration across some data centers. Very, very important. But what we don't really have a clear picture on is the actual developer activity. Are you guys seeing anything where, you know something that's reliable so we can get a good sense of the actual developer adoption of a network that goes beyond like a GitHub commit and things like that. Right. Because those numbers can be noisy.
02:12:11.584 - 02:12:45.484, Speaker A: Any thoughts on that? I mean, if it's way out of left field, just slap me when we get backstage. But anything that you guys can recommend or that you can track when it comes to actual developer engagement, actually, I'm not really sure about ETH views, but not sure about Etherfuse, whether Etherfuse has anything specific to Solana like related programs. Right. But I think for Dune, a couple of wizards crafted a couple of charts, right, where they can see how many programs are deployed or upgraded every couple of days. Right. I think that's a very good, useful metric. Another metric we could see is a very old time player.
02:12:45.484 - 02:13:20.960, Speaker A: I think maybe folks from Korokube, an NFT marketplace in Solana, right. The core origins of that team, they built this site called Chain Crunch. So Chaincrunch has a very nice site for you to just view a very clear detail of what's going on, like how many programs have been deployed so far. So as vice, I know a couple of months back, we have over 4000 programs deployed. So that's pretty crazy of a number to see, right? I think for what I can speak for myself, for our team, we've always been focused on more granular pieces of data. Data that's really new and really novel. You know, you don't get to see this out there.
02:13:20.960 - 02:14:03.500, Speaker A: So one thing we've been trying to find out is this word in Solana called compute units cus. So in an actual block, right, there's only a maximum finite number of cus you can squeeze into a specific transaction. So by doing so, we can kind of measure exactly how devs are working around and playing around with, like, exactly how they can pack transactions. Like, for example, for Jupyter swaps. I think you wouldn't have known this, but sometimes you got to pack one or three transactions to make a specific trade, you got to make at least three transactions. So we're trying to measure stuff like that, like how much compute units are consumed for a specific swap in Solana. And I think Solana is pretty much focused on being green.
02:14:03.500 - 02:14:24.312, Speaker A: We want to calculate how much power is consumed for, say, a Jupyter swap. So, yeah, that's. I think CU is quite an interesting thing. Maybe Masari as well. I don't think Massari has much of a focus on programs and dev centric metrics because Masari has to attend to the complete mass adoption side of things. Right. So I completely understand that.
02:14:24.312 - 02:14:54.790, Speaker A: So my perspective is like ether fuse focuses kind of like more validated infrastructure, network infrastructure, and decentralization kind of things. And then Dune does it, in a way, wizardry kind of form. Like, you get data analysts, data scientists to get together, build cool ass metrics that are pretty novel and new with the entire big data warehouse you have. And then for us, we go deep into details. We try to show you details that are going to happen right now. And then for Masari is just, let's bring the attention to the broad scale. Right? So I think, yeah, our panel here is quite crazy.
02:14:54.790 - 02:15:27.034, Speaker A: We are all covering different fronts, and I guess that's how we could, you know, probably show dev metrics like that. And I would like to reinforce that. You know, when we pre ordered a saga phone about four months ago, and you could mint an NFT and I couldn't remember what wallet I used to pre order it, and we used Solana FM to figure that out. I was like, I don't know what wallet I used, but so those details I was able to easily follow through the explorer. So thank you for that. Thanks, man. Awesome.
02:15:27.034 - 02:16:16.502, Speaker A: Well, we're at time. We're coming up on time here. You know, I guess I'll just kind of close it out, bring some relevance, you know, back to Solana and the Solana network and measuring what matters. And, you know, we talked about measuring decentralization, we talked about measuring activity, we talked about measuring developer engagement, all these sorts of things. What I think also really, really matters is measuring the effectiveness of a solution. And Solana, you know, we know, was experiencing some network performance issues at the end of Q four, into Q one and even into Q two, where, you know, there was no real mechanism to order transactions, right. So there was no fee market.
02:16:16.502 - 02:16:38.070, Speaker A: There was really no solution. But solutions were rolled out. And it was very, very clear, and it was important to follow that, to track that, to measure those implementations to see. And I've been telling people like, hey, you know, I just had an interview with, with Fortune magazine. I said, look, the narrative is still over here. It needs to change. You need to look at the data.
02:16:38.070 - 02:17:09.221, Speaker A: And there is a clear improvement in performance, network performance, based on the issues that were plaguing it earlier. Right. Those solutions have been working, and it's very obvious to see in the data, we're seeing TPS improving in its all time highs. We're seeing a flow of transactions without interruption. Right. That's the result of rolling out the upgrades. So in my opinion, that's another thing that I think is very important to measure, is the effectiveness of a solution.
02:17:09.221 - 02:17:45.974, Speaker A: So, and I think that Solana is doing a good job of actually implementing things that we can see working and we can actually measure it. So in any case, we're a little bit behind. Any last thoughts on anything? Measuring anything else? Yeah, just measure what matters. Measure what matters. All right, thank you. Love that panel. I really love those comments about decentralization from Dave at Etherfuse, which kind of means all things to all people.
02:17:45.974 - 02:18:28.522, Speaker A: And so it's really incredible to see the insights from the three leading data analytics companies on Solana and their leaders and some amazing announcements from Dune as well. I know that for me, those changes are going to make things a lot easier, a lot simpler, a lot faster to understand what's going on in Solana. So what an amazing panel. And wanted to say that this is the last session before a 45 minutes break. And so we're going to do three more sessions after that, but that's sort of the lunch break. So if you're feeling a little tired, just have one more session to get through, and then we'll take a more extended break. And there's again, a lot of refreshments and food and stuff like that around here in the back behind me.
02:18:28.522 - 02:19:12.917, Speaker A: And so next up, I wanted to introduce a really important topic, something that sounds like something that a lot of people here will care about, which is automating smart contract security. And so I wanted to introduce Chris Wong of SEC three, who's going to discuss how SEC three can help you do that. So give a big round of applause for Chris. All right, how's everybody doing? Great. Good afternoon. My name is Chris Wong from sex three. This is my very first time to the break point.
02:19:12.917 - 02:20:11.974, Speaker A: Very humbled, actually, to be given the stage here to show, share with you some of our thoughts regarding automating smart contract security. So in the next 20 minutes or so, I'd like to cover a few topics. First, why automating smart contract security is even important, given that we have security audits. I'll use two examples drawing from our experience, hopefully to make a case for that. Then I'll list some of the existing solutions out there today in Solana ecosystem so you can use. And then most important to me today is I want to talk about security post deployment. I want to make a case, hopefully convince you there is a really good opportunity to build a solid solution to define smart contract in real time on chain.
02:20:11.974 - 02:20:59.674, Speaker A: And if time allows, I'll do a small demo. And afterwards, I want to talk about some of the limitations in some of the solutions I talked today. So let's, before we get into the topic today, allow me to do a quick introduction about ourselves. So who is sextray? What do we do? Sec three. All the letters in our name, written in lowercase, actually derives the name from two words, secure web3. We are a security research firm. We focus on preparing Solana products like yours for millions of users and for millions of users you are going to onboard in the future.
02:20:59.674 - 02:21:46.014, Speaker A: What do we do? First, we provide a range of services around security audits. We can examine your smart contract. We can look at your front end. We can look at the whole thing. We even do security related trainings and consulting as well. What is more relevant to today's talk? Equally important for us is that we're building a set of automated security tools for the system. So what are the tools? First, we have a command line based on premise so you can download to your computer completely free.
02:21:46.014 - 02:22:18.774, Speaker A: It's a vulnerability scanner. It's fast. It scans some of the most common vulnerabilities, such as overflow, underflow, account validation, so on and so forth. This is our first product in the ecosystem. I'm happy to report that this tool has been downloaded more than 30,000 times. The only reason I brought that number here today is it speaks volume about what a vibrant developers community we have inside. That's something to celebrate.
02:22:18.774 - 02:22:46.334, Speaker A: We also have, we call it X ray. It's a software service, security software platform. So you can use a web interface to upload your smart contract. We'll do the scan for you right now. It covers over 50 types of security vulnerabilities and we keep adding to it. And also we're adding a few other components into the platform. This is what it looks like.
02:22:46.334 - 02:23:42.156, Speaker A: Last piece is what we call Watchtower. It's a real time threat monitor after you deploy your contract to the chain. So with the introduction out of the way, let's dive into the topic. So why automating security for smart contract is even important? Especially given that most projects today before they launch, they go through a security audit where some product even goes through multiple audits. Excuse me, oops. But if you look at the product has lost fund in the past. Despite they have gone through security audits, some have gone through multiple security audits, they still lost funds by burning up.
02:23:42.156 - 02:24:09.014, Speaker A: That don't get me wrong, by no means I'm assigning blame to auditors. As a matter of fact, Sextri, we do security audit as well. We know how valuable security audits do. It's invaluable work and most auditors do excellent, excellent work. However, we're all humans. Humans make mistakes. Even a small mistake can open door for a big loss sometimes.
02:24:09.014 - 02:24:48.894, Speaker A: And never before in history has so much value been directly attached to a piece of software. The keyword here is directly. So that's why we believe tools are very important. Tools and humans are complementary to each other. There are things that humans find very difficult, but tools find quite easy. And humans are better in terms of ingenuity, creativity, and dealing with things unknown and finding corner cases. But for tools, if within their capacity, they can do it consistently, they can do a very good job.
02:24:48.894 - 02:25:18.124, Speaker A: The other reason is really scalability. And as we know, human experts like you guys are not very scalable. They tend to be very scarce and they tend to be expensive. It takes time to grow into for somebody to grow into an expert tools. On the other side, software is one of the most scalable things human being ever invented. So let me use maybe two examples to illustrate those points. Points.
02:25:18.124 - 02:26:20.584, Speaker A: First, I'll draw experience from our experience in building a checker into our actuarial software. So this tracker, there's this kind of vulnerabilities, it's so called semantic inconsistency, I guess, to explain it. And the core of it is really the two things, or multiple things are associated logically, but they do not necessarily show up together in the same spot. If I can make an analogy that when you enter a dark room, you open the door, then you turn the lights, but the door and lights may not be in the same location, they may not be associated exactly timing, but logically they are associated. If you find in your software, one thing is missing, it's a red flag, something might be wrong. This kind of issues is difficult for developers because they need to make a conscious effort to really dig into code. Because those are, those two things could be thousand apart or functions apart.
02:26:20.584 - 02:27:02.184, Speaker A: This is really good for tools to do that. So we actually built quite a few of these kind of checkers into our software. For example, we had a checker there to check when sonata developers use anchor framework, sometimes you use this framework inconsistently across different spots. So we build these checkers to go through the code, go through every code path exhaustively to check for things. Very consistent. So we have used this checkers, I mean it's pretty popular. And we have used checkers to consistently finding issues that developers sleep, developers check.
02:27:02.184 - 02:27:41.110, Speaker A: Another example is that it's how we dock footing x ray. It's another piece of software, or it's a piece of software we're building. And we have a security audit team. Our team is the most avid and active user of our own software. Our team and our team work together. I think that closely working model makes both our team and two better. Because every time our team finding a new type of issue, our development team is going to design a signature and build into our tool.
02:27:41.110 - 02:28:29.218, Speaker A: And so our other team has a tool has better coverage and as the user more they have chances to further validate those results, to say those results are true positive or false positives and giving that feedback loop, the tool gets better. Our development team have chance to further validate the checkers and refine the algorithm and adding corner cases. So by working closely together, tools get better, our team gets better. So what can be automotive? So this is a chart. If we look at this chart, I really separate the full lifecycle of a protocol into two phases. The first phase is really dormant. You do a lot of coding, you try to build field features, sometimes you do refactoring, you fix bugs.
02:28:29.218 - 02:29:11.838, Speaker A: So there's a whole range of solutions right now out there that can help you do that. Development framework, scanners, linters, including our x ray testing, five frameworks and help you to do tests. Some even go further to do formal verifications. And then there's another phase which I will touch, which I'll discuss later in the presentation is on chain. Once you deploy your smart contract to the mainnet, what do you do? So here's a list of some of the solutions out there. The space moves very fast and people are developing very hard in the space. By no means.
02:29:11.838 - 02:29:28.254, Speaker A: This is an exhaust list. So if I missed something really interesting, please let me know. We're happy to learn as well. So on top of the list, I'll just mention a few. I'll highlight a few. On top of the list, there's an anchor. Anchor is a very useful framework.
02:29:28.254 - 02:30:01.114, Speaker A: Not only anchor greatly improve the dropper's efficiency, but also anchor does quite a feeling. Security checks for developers as well, so you don't have to do that. There's a vrast worth mentioning. Vrast is open source. I wouldn't be complete if I don't mention that. Vras the major contributor to Vedras, including one of our co founders, Jeff, and his students. He's a professor and taxi NM.
02:30:01.114 - 02:31:03.154, Speaker A: Vras converts ras source code into an intermediate representation, so called IR, and then build an algorithm on top of that to check for security vulnerabilities. There's a paper to be published soon. I believe that the open source code has been validated on over 100 Solana products, and the result is quite good. The tool discovered more than a dozen security vulnerabilities didn't service before, and at least three of them are critical. So I encourage everybody to check out that software and even better, to be a contributor. On the testing side, I will highlight Neodymium's PoC framework. Neodymium's POC framework is an excellent tool to help you simulate in a local environment of your smart contract.
02:31:03.154 - 02:32:04.694, Speaker A: Also, you can combine a scanner, such as x ray, with Neodym's POC framework to drive to the bottom. So a scanner will give you a bunch of warnings, and for each one you can easily and quickly conveniently build a a testing framework to try to explore it to verify whether that warning is really true or not. There's also formal verification, which really means they're trying to use mathematic proofs to prove certain security attributes. I'll just give you one example. There is. If you withdraw from account, the balance after the withdrawal should be mathematically proven to be sound, so you don't have a security issue there. Also, I like to mention that within the move prover, there is an important, very important component called Z three.
02:32:04.694 - 02:32:45.694, Speaker A: One of our tech series co founder Nick. During his PhD work he wrote a big portion of the Z three solver. Then lastly is our watchtower in deal with on chain threat monitoring. So I guess it's a good point. It's a good point to switch to post warmth security, which I'd really like to spend some time talking about. Once a smart contract is deployed on chain, I think the security, at least in the past, becomes a game of more reactive and waiting for something to happen. More manning work.
02:32:45.694 - 02:33:49.030, Speaker A: Have you ever wondered, is somebody trying to messing up with your smart contract at this very moment? Have you ever? Well, in that case, what can you do? What can we do about it? What can we do to build a defense system in reality real time for smart contracts already deployed out there, is it possible to detect and stop attacks in real time? We believe the answer is yes, and I'll try to explain our reasoning from two aspects. First, let's do a quick review of what's in common over the past. Actual hacks, what do they have in common? What we can draw from them. For one, almost all hacks crafted one or more fake accounts. You need an account to supply data to sign a smart contract in order to manipulate. So you have to prepare that data. For two, almost all hacks involve multiple transactions.
02:33:49.030 - 02:34:17.954, Speaker A: You need to prepare the data. You need to supply that data to the smart contract. You use that to manipulate smart contracts and gain some access control, and then withdraw funds in multiple steps for three. It takes time, at least for a few minutes. And sometimes we have seen cases, hours, even days. And that's a surprise to me when I first saw that number. In other words, there's enough time.
02:34:17.954 - 02:34:55.952, Speaker A: There is enough time for you to detect it and do something about it. Another important aspect I hope to be able to build a case is Sonata's unique programming model. Sonata's programming model is rather unique in that it decouples data and code, unlike some of the other chains. Some other chains that the data is sometimes in the smart contract itself. This is very, very intuitive, easy to understand. Solana is different. This actually has quite a bit of advantages.
02:34:55.952 - 02:35:58.844, Speaker A: It enables many copies of your smart contract deal with different inputs, different data at the same time. Running in parallel. So that's one of the key reason why Solana has better throughput, but also it has security implications. It can, from here, you have opportunity to build a better security system. So as we discussed, attacker must do at least two steps to launch attack, prepare the data and use that data. Right? So this gave us opportunity to be able to detect in step one when they prepare that data and try to do something in step two. So to do that, how do we do that? I guess, number one, we have to monitor all on chain activities and be able to tell the malicious activities from the normal ones.
02:35:58.844 - 02:37:36.244, Speaker A: So we build this engine that we can continuously take in data from onchain real time and then learn what is normal, what is abnormal, and we call it invariance. I'll give you a few examples. What is the environment? So, for example, when a user interface a smart contract, it provided in that input, the force input account should always be essentially a pointer to the system program. If for some reason somebody supplied that account to a different program, that's a red flag that breaks invariant, because that account should always be, a system, should always point to a system account. Another example, even though this is one, it's a more weaker one, is that if a user, if your users consistently in the past doing transactions less than 1000, so now, all of a sudden, if somebody submitted a instruction to do transactions over 100,000, that's another big flag. So when a transaction or a serious transaction violates or violent or violate one inverter or multiple invariants, you can build a different degree, a various degree of confidence, something is going on. I'll use a real attack as a case study to demonstrate the concept.
02:37:36.244 - 02:38:20.664, Speaker A: This is a simplified real case, just to illustrate the concept. So I took out some of the details. So on the left side is what a normal user interacts with that smart contract. Essentially, this is a deposit some tokens on chain one, and then withdraw different tokens, but with the same value on chain two. Okay? So the user first interact with the chain on the smart contract on Solana side is that they send a verified signature, associated payload. Payload is really a fancy word for the value of the token. Then you post that signature and payload via smart contract.
02:38:20.664 - 02:39:26.664, Speaker A: Then you transfer the payload. So it's three steps, easy. That's when things are normal. What the monitor can learn from that, as the monitor keeps learning from that transaction, first it learns even without the source code, okay? So when users supply that instruction, the force account, it should be, should always point to a system account, okay? And then the payload amount should match the other chain, because if you deposit x in the other chain, you should only be able to withdraw, withdraw same value on Solana. Third, even though this is a weaker environment that we have learned over the transaction period, maximum payload less than 1000. Okay. And then in a real attack, what happens? Attacker actually supplied the instruction, replaced that system account pointer and pointed to a smart contract the attacker launched.
02:39:26.664 - 02:40:05.384, Speaker A: So each of those steps, the monitor find now the force account does not point to a system account anymore. That's a big no no. That's a red flag. And then the value submitted does not match the other chain anymore. That's another red flag. If you wasn't sure in the first step, I think by now you should be very sure something's happening, you should do something about it. And then there's another, even though it's a weaker one, that the instructions submitted was to withdraw more than 100,000.
02:40:05.384 - 02:40:36.368, Speaker A: That's a two degree of magnitude bigger. I'll do a small demo. This is a replay of the actual transaction. So the setup of the demo is that we'll play 100 transactions right before the attack happened. Okay. And the monitor, our monitor in the background, continues to learn about the environment. So set up the monitor system.
02:40:36.368 - 02:41:07.004, Speaker A: Then when the attack actually happens, the system will alert you. There will be three alerts, each highlighted in red color. We intentionally made the phone solo small so I wouldn't be able to see anything. I'm sure you are able to see everything, so you just have to trust my words. Open. So the transaction gets played. There's 100 transactions, it's fast forwarding, and then the system starts learning.
02:41:07.004 - 02:41:35.584, Speaker A: The system actually learn more variants than the three. More invariants than the three invariants I talked about. Okay. And then that's the first alert. That's when the hacker supplied in their input a different pointer than the system program. That's the first alert and then the second alert, although this is the first one, sorry, this is the second one. This is the third one.
02:41:35.584 - 02:42:38.004, Speaker A: Apply the same concept along the same way. We can build a lot more customized monitoring in sectarian, we call it bots, to do different things. In my mind, essentially it's taking in data, apply certain domain knowledge. In our case, it is security domain knowledge, and then process that data, extract useful information and use that information to do something. We encourage the community to work with us, that we're just starting on this and we'd like to hear from you what you like us to build for you. What are the things that can make your protocol more secure. And we have that domain knowledge that we hope to be able to, to work with you on those things to really understand your needs.
02:42:38.004 - 02:43:17.504, Speaker A: So I have a little time left, so I'd like to go over this is silver bullets are the solutions we talked about today. Automated solutions for smart contract. Are there silver bullets? In my opinion, but in my opinion, there's very few silver bullets in life. Also in this case, I don't think there's any silver bullets. Almost all tools have limitations. There are things that tools can't do and there are things tools cannot do. I'll just pick on ourselves in this case.
02:43:17.504 - 02:43:48.800, Speaker A: So we have this scanner x ray. It scans more than 50 types of security vulnerabilities. But, but here's a but. This type of scanners, assuming you have a dial, you can dial all the way to the left, under which the tool will leave no doubt unreported. Essentially, you report everything suspicious. Okay. Or you can dial the dial all the way to the right.
02:43:48.800 - 02:44:20.444, Speaker A: In that case, the tool will only report to you. There's a warning when the tool is 100% sure this is an issue, which way you would prefer. It's a hard choice because either way there's pros and cons. I like to dial it to the left. That's where our tool is. Because security is important, any small issues can lead to big loss. So we want to present to you everything we are suspicious of.
02:44:20.444 - 02:44:51.588, Speaker A: So you can do some investigations and validations. But it takes work. It takes work. So some people don't like that. Some people don't like seeing 25 warnings, right. And after investigation only find five issues. But in my opinion, even though even one issue is worth the effort, and also every tool, it takes effort, takes resources, takes time to bring it fully into your workflow, into your system to make it work for you.
02:44:51.588 - 02:45:51.924, Speaker A: Again, I'm picking on our system called x ray, is that we actually provided a range of user features for you to start using the tool and further validate it customer to your needs. Label those, label those false positives so the tool learns if on a stable code base over time, if you put into the work, if you work with the tool, then you'll find the tool gets better and better. Tools knows your code base better and better. It generates better results, but the developers need to put in that work initially. So I'm a firm believer, we are a firm believer of tools, even though, as I said, we run two arms, we have security audit at the same time we're building tools. We firmly believe each side is very important. Everybody should have hopefully check out both to make both solutions work for you.
02:45:51.924 - 02:46:16.110, Speaker A: I think I ran out of my time, maybe have time for one or two questions. Most. Thank you very much. Appreciate it. Again. I really appreciate that Solana, bringing us all together here in this great event. Thank you for the talk.
02:46:16.110 - 02:46:59.542, Speaker A: Please. I was curious if it is an option to hard code the accounts in the program code, so that whenever it, a function is called, you can verify, let's say, in the case when the accounts are predefined. You mean hard coded? Yeah. So let's say like we first deploy a program, then create an account, and then redeploy it with the account id hard coded. Yeah, I think that's just a different program model. Is that in that model, you put the code itself in a smart contract. Again, Solana is a different programming model, which I think is a better programming model.
02:46:59.542 - 02:47:23.174, Speaker A: Is that. That is not a hard coded number. It's a user supply input. All data in Solana smart contract are provided as inputs, all data. So that's just a programming model. So you can have many copies of using different inputs, but the crack inputs, so. And run your smart contract in parallel.
02:47:23.174 - 02:48:09.278, Speaker A: Thank you. Thanks. Hello. So you were saying your automated tools could scan and detect potential vulnerabilities and attacks happening? So, like, if your tools detect an attacks happening on a program, what exactly would the maintainers of that program be able to do in the short time that they have to potentially stop the exploit and attack from happening? Yeah, I guess the question is. Let me just repeat the question. The question is that in the case you detected something is happening, what can you do about it right there? I guess there are multiple ways. I just thinking aloud, I guess.
02:48:09.278 - 02:48:48.374, Speaker A: We're still developing solutions, really working with protocols and products on those kind of things. One idea is that we just provide an API. Right. It's up to you to decide, what do you want to do about it? You can have a kill switch, you can abort it, you can freeze it, you can do all sorts of things. So it's really up to you. Or what we can do is potentially a on chain smart contract. So to process that and generate that signal and use some sort of multisig mechanism to work with the protocol to do something about it.
02:48:48.374 - 02:49:14.334, Speaker A: Right. I guess it's not an exhaustive list. There's some other ideas that will also be considering as well. Yeah, I think, I think I read all my time, apologize right on time. So thanks so much for listening. Appreciate it. Thank you very much, Chris.
02:49:14.334 - 02:49:31.314, Speaker A: Great presentation. Very important subject, for sure. So, yeah, we're going to take a break and be back here at 02:00. So 45 minutes, 50 minutes break. Great time to grab some food in the back or head outside. It's an absolutely spectacularly beautiful day. Day.
02:49:31.314 - 02:49:49.654, Speaker A: So looking forward to seeing you all when we resume for three more sessions at 02:00. So in about 50 minutes. Hello, everyone. Welcome back. I hope everyone had a great break. Got to get some lunch. Got to go outside in the beautiful sun.
02:49:49.654 - 02:50:21.310, Speaker A: We're going to get started again. Just to quickly reintroduce myself, my name is David. I work at the Solana foundation on our grants program. So working with developers and projects who are building public goods on the Solana ecosystem. So really excited to be here. It's amazing to be at the workshop stage to hear a lot of incredibly practical advice about the latest in all of the technology that supports development on Solana. We had some amazing sessions this morning and an amazing three sessions this afternoon to finish us up.
02:50:21.310 - 02:51:02.406, Speaker A: So without further ado, I wanted to introduce our next speaker from one of the most respected companies in the crypto security space. Pyotr from Halborn is going to be talking about lessons learned when auditing Solana. So wanted to welcome PeTr to the stage, give him a huge round of applause. Hello, everybody. My name is Piotr. I work at Halborn. Offers full suite security services for blockchain companies.
02:51:02.406 - 02:51:47.566, Speaker A: And what I'd like to show you today is, what I'd like to talk about today is lessons learned from Solana program audits that we did at Holborn. So let me see. Okay, so I have some background in it. So, web3 cybersecurity is, like, one of the recent things I've taken up. And what I'm going to show is what we've seen, what you guys are building. What is the security impact of all your work? So, let's just start with, I'm going to show you, like, a bunch of charts. And, you know, just please remember, like, this is data you guys created.
02:51:47.566 - 02:52:24.558, Speaker A: I'm just showing it to you. So, like, you created this, those slides, I'm just presenting them. So starting with, like, the, I suppose, most important metric of them all. So while just looking at this chart, we can immediately tell that one of, like, we see, like, there's, on average, there's, like, about eight vulnerabilities, eight findings in every project, and, like, one of five is really, really, like, critical or high. So the severity is, you know, is very high in this case. So, like, eight up to ten. So you can see there's a sum of likelihood.
02:52:24.558 - 02:52:51.774, Speaker A: This is our metric how we measure severity. So likelihood one to five, five is like most likely and then impact one to five. Again, five is like the most devastating impact. So we can see like, you know, from eight to ten. So like really, really bad issues, bad vulnerabilities. It's just one in every five. So this is something concerning, I think.
02:52:51.774 - 02:53:48.400, Speaker A: And then looking at the, another chart, we can see what's the ratio between users and protocol in terms of the affected party. So it does seem like users are impacted way more often than protocols. Again, if a protocol is impacted, then users are usually impacted as well. But in general, users are like way more vulnerable to attacks than protocol vaults or conflict parameters. And just looking at types of impact, we've noticed. So what we can see that almost one in ten issues is loss of funds. Now that's obviously like the most devastating thing that can happen to a protocol.
02:53:48.400 - 02:54:57.976, Speaker A: Losing, you know, their, their users funds or the protocol fund fonts, then we can see that, you know, we have like if you look at the, if you look at the, the issues here, like for example, denial of service, that's a web two problem. So you might think that it's not applicable to web3, but it is, it's not that common, but it's still there since something goes for a loss of privileged access and some other types of vulnerabilities, like susceptibles, which means it may happen but not necessarily going forward. Now we can see why those vulnerabilities pop up in the programs you guys develop. So we can see that one of the most prevalent causes here, here is sanity check missing. And the sanity check, it's just usually one if statement. So one if statement is something that, you know, prevents bad actors from accessing your protocol funds. And, you know, like it's almost 20%.
02:54:57.976 - 02:55:28.316, Speaker A: Again, it's almost one in five. Next we have edge. Case is not handled. Again, it's a really simple if statement, statement checking, you know, if a value does not exceed, like, you know, something you guys can expect. And then we have poor business process design. So, meaning the logic that was implemented could have been implemented, you know, in a more robust or a better way. And again, it's like 15% in 15%.
02:55:28.316 - 02:56:44.384, Speaker A: So it's as, as we can see at the other issues, it's still quite common, which is interesting because like in traditional web security, usually insufficient input sanitization. So basically input validation is the number one cause of vulnerabilities. Whereas in Web three, it's like somewhere in the middle which paints really nice picture how, you know, different root causes of vulnerabilities in Web three are to web two. And just looking at the critical vulnerabilities, so obviously, like the most often we see like almost three out of four critical vulnerabilities are about loss of funds. So there are different types of, you know, fund loss vulnerabilities. So one obvious, like one is draining use of protocol vaults, but also stealing and bypassing fees. And something that might not be that, you know, obvious is rent stealing, meaning closing accounts on behalf without proper authorization, and in consequence losing the rent.
02:56:44.384 - 02:57:38.844, Speaker A: Then we have loss of privileged access, meaning you guys just, you know, lose control over config accounts over the entire protocol. And users in turn may also lose access over their own accounts, incorrect processing results. That's, that's a sort of a consequence of poor business process design. Meaning like, for example, mathematical formula was implemented incorrectly or there's like a step in business logic that can be bypassed in certain circumstances. And we have also denial of service in just 7% of cases. Meaning use, your users cannot access, they cannot interact with your programs. So this is quite critical because it threatens the entire business model.
02:57:38.844 - 02:58:01.388, Speaker A: Now, looking at root causes now, we can see this is pretty evenly distributed here. So insufficient input sanitization, somewhat similar to web two, is the most common cause. So we have 36%. So more than one in three root causes. It's exactly. Insufficient input sanitization. We have poor business process design.
02:58:01.388 - 02:58:54.972, Speaker A: So again, implementation issues, insufficient access control, the famous signage check missing or more generic identity check missing. And we have sanity check missing. So just one if statement that should check that, you know, ratio should be lower than 100%, that's missing. And that's why, you know, fees are charged, you know, way over what it should be. Now to something even more interesting, we're going to have a look how encore framework improves or how anchor framework affects program security. So I imagine right now most of you, if you're building, you're building with anchor. So, you know, you might think that because it's a framework, like it implicitly makes your project more secure.
02:58:54.972 - 03:00:12.624, Speaker A: So let's have a look if that's exactly the case. So looking at vulnerability severity, so how many issues that we found were critical or high, so, you know, it's not a copy paste, those charts are very much similar. So looking at that, especially those most critical issues, so the highest severity, we can see that those values are pretty comparable. So, you know, again, this might mean there might be an issue in, you know, sort of understanding how you can utilize the framework in your protocols. When we look at the sort of lower severity issues, then again, there are pretty much the same like, I guess the key takeaway from here is, I mean, regardless if you develop, you know, in native Solana without any frameworks or you develop with anchor, there's like the chance you're going to make a mistake and someone may exploit it or an auditor is going to catch it. Well, it's pretty much the same now, looking at what issues are most common. So obviously we have low quality of service, and that's a very broad term.
03:00:12.624 - 03:01:38.284, Speaker A: Low quality of service means, for example, generic error messages or missing on wraps or just sort of very complex instruction data sets that make it a bit awkward for users to interact with. So then that may in turn means there's a loss of revenue or some other projects may not be willing to work with your project because interacting with it, it's not fun. It's like the user experience is something that could be improved on. We have also corrupted data and we can see that it happens more often with anchor programs than with native programs and corrupted data, meaning you end up saving state that is pretty much invalid. Then we have increased operational cost. Now this covers like two categories because we have protocol operational cost and we also have client or user operational cost. So if you have increased user operational cost, that means users pay more fees, transaction fees for using your protocol, because like the implementation, implementation is suboptimal, whereas if there is a protocol increased operational cost, that means you might have implemented some dead code.
03:01:38.284 - 03:02:34.604, Speaker A: There may be some tautology expressions, there could be, you know, some redundant state variables, which means it's more expensive for you to deploy the program and if you want to upgrade it, it's going to cost you more too. Looking at lots of funds, we can see that it happens twice as often in encore programs compared to native programs. Loss of privileged access, it's more of a problem in native Solana, low ci CD rating. That's something that comes from the web tool world. And that means you guys might be using components with known vulnerabilities, outdated packages, crates. So if someone were to plug your project as a dependency, so in a CI CD pipeline, the score would be appropriately lower. Loss of privilege, access.
03:02:34.604 - 03:03:16.210, Speaker A: Again, more of a problem in native programs. Same goes for denial of service, missed revenue, increase opportunity. So for example, you give a chance, you give the possibility to users to, you know, for example, set fees to what? To a value that's too low. So your protocol earns less from, you know, user interactions, ineffective business process. That might be kind of cryptic, but pretty much what it means is you implemented a feature that does nothing. And it might sound, you know, like something that doesn't happen, but it actually does. And we also have lots of rewards.
03:03:16.210 - 03:04:23.634, Speaker A: So this is quite different to lots of funds because funds are, you know, something that, you know, someone entrusted to your project, and if they lose it, they lose something that entrusted to you. However, loss of rewards, that's something, you know, optional. You know, you, it's like a yield farm that, you know, you can get some tokens from it, but if you lose those tokens, you technically don't lose your funds, you just lose the rewards. So it's not, it is critical, I definitely agree, but it's not as critical as losing your capital. So looking again at root causes, we can see how Angkor abstracting away most or many of low level operations help, you know, sort of mitigate the feature not implemented root cause. It's almost twice as, almost like half as common as in native programs because like obviously in native Solana, you know, in edge case, you have to implement your own serialization format. Anchor does it for you.
03:04:23.634 - 03:05:09.592, Speaker A: So feature not implemented is not that much of an issue. However, in sufficient inputs and it now you might think anchor does so many things for you, it's virtually impossible to accept invalid input, but it seems like it actually is. And compared to native Solana, you know, it happens a bit more often. Could be because you have to implement so many things when you develop the native Solana that, you know, you do it sort of automatically. Again, insufficient access control is more of a problem in native programs because anchor does a lot of that for you. Business process design, it's pretty much comparable. Sanity check missing happens a bit more often in encore programs.
03:05:09.592 - 03:05:47.522, Speaker A: Edge case not handled again, happens more often than native programs again, probably because encore does so many things for you. However, if you've ever run cargo expand on an encore program, you'll see a lot of code. So that means there may be, you know, some redundant state or transmission data required by encore program. Best practice is not followed. Well, that's, it's kind of, you know, natural. It happens more often in native programs because like best practices are, you know, somewhat automatically implemented by encore. Missing documentation.
03:05:47.522 - 03:06:46.904, Speaker A: So that's, you know, that's what that means is error messages are not verbose enough or, you know, in general, documentation is lacking some quality, or the error messages are misleading or, you know, too generic. It's a bit more often in anchor programs, but still, it's, you know, it's a very low value anyway. And components with no vulnerability, that's pretty much the same in both. Now, looking at, you know, root causes for loss of funds vulnerabilities. So this is something that happens in almost, you know, half the anchor programs that we've audited. So insufficient input sanitization. So, you know, even though you have all the constraints, all the, you know, conditions you can implement with anchor attributes, still, you know, you could do better with input sanitization.
03:06:46.904 - 03:07:39.532, Speaker A: However, access control is a bit more of a problem in native Solana programs. Same goes for poor business process design. However, sanity checks and edge cases, that's a problem in uncor program, albeit it's not that common. So, like, I guess, key takeaway in native SolaNa programs, what you really need to pay attention to is, you know, just doing that signer check and just looking, you know, at your business process implementation. If you did handle all the cases, you know, even those you did not think of initially, just having tunnel vision or on the happy path. So, like, you know, you might think what are, what could be common issues in Angkor. I mean, it does so many things for me.
03:07:39.532 - 03:08:12.432, Speaker A: And, like, there are two, which basically boil down to one thing. So we have those two properties of Angkor context, which. And one is remaining accounts. So remaining accounts. So with Angkor programs, you basically know what accounts you expect. So you define the context. But you might have some, you know, Edge, some business logic edge cases where some account might be optional.
03:08:12.432 - 03:08:42.886, Speaker A: And that's where it goes. It goes to the remaining account slice. What's important is what we can see here. This is account info. Account account info is like barebones Solana account metadata. So that means all encore security checks are not applied to a remaining account. So if you do use remaining accounts, please remember to, you know, do the sign a check, do ownership check, you know, please try and avoid type confusion.
03:08:42.886 - 03:09:44.314, Speaker A: So all the, you know, five common Solana vulnerabilities, they can apply to remaining accounts. And same goes for unchecked accounts. Now, the name is quite verbose, but, you know, it still happens that, you know, unchecked accounts remain unchecked in the code. And unchecked account means, basically, you don't know in Angkor, you cannot specify the type of the account because you don't know it, or there are no anchor types for that account. So if there are none, if that's the case and you do have to use unchecked accounts, please check them because, like, all those, you know, five common Solana vulnerabilities apply to unchecked accounts, too. And just, you know, looking at, you know, how the findings that we reported were addressed. So looking at, you know, there's some.
03:09:44.314 - 03:10:30.014, Speaker A: Some bad data here, but we can see that, like, in the general, findings are fixed. Like, one of three is acknowledged, meaning, you know, it's not a feature. Like, it's a. It's not a bug, it's a feature, or you're just accepting the risk. And just 1% of findings are pending patches, meaning a program was deployed, but the vulnerability was not fixed. And it's pending, it's going to be fixed in a future release and getting to the last slide. So, breaking down finding studies by severity, we can see that 100% of critical findings are fixed.
03:10:30.014 - 03:11:01.464, Speaker A: So no loss of funds, no loss of privileged access in deployed programs. Almost every high finding is also fixed. Just, you know, a very small part is acknowledged. Now what I guess we can. We all can see a pattern here. So, as, you know, severity decreases, so does decrease the ratio of, you know, fixed to, well, not fixed in general issues. So we can see that, you know, with medium, it's three out of four, they're fixed.
03:11:01.464 - 03:11:16.124, Speaker A: With low, it's 50 50. And informational is also pretty much just as low. So that's all I had for you today. Hope you guys enjoyed it. Hope it was informational. Thanks so much for your time and see you around. Thank you.
03:11:16.124 - 03:11:58.422, Speaker A: Thank you very much. Appreciate that. Pyotr, we're gonna have another session in just a second, but I would strongly suggest if you don't have some of these, these headphones, if you want to listen to the content here today, makes it a lot clearer. They're available in the back. This beautiful space is a little bit echoey, so if you want to focus in, these are the things to have. But without further ado, we're just going to move right along. And I wanted to introduce our next speaker from trail of bits, Sam, who's going to be discussing how to write secure contracts on Solana.
03:11:58.422 - 03:13:18.234, Speaker A: So, a very important topic, please give it up for Sam. Can everybody hear me okay? Good afternoon, everyone. So, I'm Sam Molius, and I work for a company called Trellobits. If you're not familiar with Trello bits, we specialize in high end security software, and a large area of focus for us is blockchain. We try to apply real world research to specific speed up our security reviews, and much of that research is turned into tools that we then open source and open source tools of ours that you might have heard of or used include Slither, a static analyzer for solidity echidna, an Ethereum smart contract fuzzer Amarna, a static analyzer for Cairo smart contracts, and tealer, a static analyzer for Algorand smart contracts. But in this, in this talk, of course we're going to talk about Solana. So in particular, I'm going to describe to you some lints that we have developed for Solana programs, and those lints were inspired by the sea level attacks, and one runs those lints using dielint.
03:13:18.234 - 03:14:11.488, Speaker A: So in this talk I'll describe the sea level attacks. I'll say a little bit about dielent and how it works. I'll then describe the lints themselves, and then explain how you can try these lints on your own programs. So first, what are the C level attacks? So from their GitHub description, they are examples of common exploits unique to the Solana programming model and recommended idioms for avoiding these attacks using the anchor framework. Now, I'm sure that many of you are familiar with the anchor framework, but in case not from its GitHub description, it is a framework for Solana sea level runtime, providing several convenient developer tools for writing smart contracts. Tracks again, if you're not familiar with it, anchor has both on chain and off chain components. By on chain I mean it consists of types, traits, macros, etcetera to assist in writing solana programs, and it also has off chain components to assist in testing solana programs.
03:14:11.488 - 03:15:01.644, Speaker A: But for the purposes of this talk, we're mostly interested in the on chain components. So the C level attacks are a set of programs whose perks our purpose is to demonstrate proper use of the anchor framework. Today, the repository consists of eleven examples, so each example has three versions, an insecure, a secure, and a recommended version. Roughly speaking, the insecure version is a program that exhibits some vulnerability. The secure version is a version of that program with the vulnerability mitigated in some way way, but not necessarily the recommended way. And then the recommended version is, quote unquote, the idiomatic version of secure, as encouraged by the anchor framework. And this is according to Armani Ferrante, who, if you don't know, is the creator of the anchor framework.
03:15:01.644 - 03:15:48.514, Speaker A: So as I mentioned, there are currently eleven examples, and you can see them up here on the slide. So they range from things like ensuring that signers are properly checked, to ensuring that accounts are properly initialized, to ensuring that accounts are properly closed. But the one we're going to dive into a little bit in this talk is ensuring that owners are properly checked. Okay, so as I mentioned, each example has three versions, an insecure, a secure, and a recommended version. And what you see on the slide right now are the essential components of the insecure and the secure version. So what these programs do is they take an account which is expected to have been created by the SPL token program. They fetch a balance from that account and then they log it.
03:15:48.514 - 03:16:41.958, Speaker A: Now why is the insecure version insecure? It is because it doesn't check context account's token owner. That is, it doesn't verify that the passed in account is actually owned by the token program. So in theory, the caller could could have created the account moments before issuing the transaction and passed it into this function log message. And the insecure version of log message would happily accept that account, whereas the secure version would reject that account because it is not owned by the token program. Okay, now if you're looking carefully, you may notice that there is this reference to an owner field here. And you may wonder, well, isn't that the owner check? Why is that not the owner check? And the answer is that this is subtle, but there are actually multiple notions of owner at play here. So what you see on the slide now is two structs.
03:16:41.958 - 03:17:13.634, Speaker A: The struct on the left is Solana program account info. Account info. So this is the data that a solana node associates with each account. And you'll notice it has an owner field. This is the one that we're interested in because this owner field determines who gets to write to the account data. For example, now for the SPL token program. For some accounts that it manages, it interprets the data within those accounts to have this structure here, that is the structure of an SPL token state account.
03:17:13.634 - 03:18:03.492, Speaker A: That struct has an owner field, and that field is checked by both the insecure and the secure versions of the program. However, that's not the one we're interested in for this example. The one we're interested in is this one, and that is the field that is not checked by the insecure example. Okay, I just want to mention quickly that many of the details I just covered, one is largely left to figure those out on one's own, which is to say the sea level attacks documentation is somewhat light. Having said that, someone who goes by the hand handle of pencil flip on Twitter wrote a really nice thread describing ten of the eleven sea level attacks, and I highly recommend it as a resource for understanding these attacks. Okay, so that's a little bit about the sea level attacks. So now I'm going to talk about dielent.
03:18:03.492 - 03:18:48.324, Speaker A: So dielent is a tool for running rust lints from dynamic libraries. So first, what do we mean by a lint? So the Wikipedia definition definition of a lint says the following. It is a static code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. If you've been programming in rust for long, you've probably run into compiler lints, such as unreachable code, unused imports, or wild true. So these are links that are built into the rust compiler. And if you regularly run Clippy on your projects, and I highly recommend that you do, then you've probably run into clippy lints, such as too many arguments from over into a redundant closure. These are examples of lints built into the clippy linter.
03:18:48.324 - 03:19:57.572, Speaker A: Okay, so dielent is similar to Clippy, but whereas Clippy runs a predetermined static set of lints, dielent runs lints from dynamic libraries that the user names. And in this way dielent allows developers to maintain their own personal lint collections. So here's a little bit about how it works. So for reasons not terribly important to this talk, both Clippy and dialint are divided into a cargo command and then what is called a driver. And intuitively you can think of the driver as a wrapper around the rust compiler. So when you run Clippy, for example, you invoke the cargo command, which in turn launches the driver, and then the driver says to the compiler, hey, when you run your own Linux, would you please in addition run these lints that I have statically linked in? So dilint is similar. You invoke the cargo command, which in turn launches the driver, which then loads one or more dynamic libraries, and then the driver says to the compiler, hey, when you run your own lints, would you please in addition run these lints that I have dynamically loaded? You can put as many lints as you want want into a dynamic library.
03:19:57.572 - 03:20:51.220, Speaker A: However, we have optimized for the case of putting one lint into a library, and the reason why I say this is we want to make it easy to get a lint up and running quickly. So we make it easy to package a single lint into a library. And for the case of a one lint library, the structure of the lib rs file will typically be like this. So there will be an invocation of a declare late lint macro, which by convention has a rust doc comment with some documentation about the lint. Then there's the lint name, the default lint level which is nearly always worn, and then a short description which appears if you ask dielent to list the lints in the library, and then every lint will include an implementation of a lintpass trait. That implementation will include one or more check functions. And these check functions are concretely things like check expression, check statement, check block, what have you.
03:20:51.220 - 03:21:45.914, Speaker A: And it's within those check functions where the actual analysis is done and the determination of whether or not a warning should be omitted. One point I want to leave you with before continuing is that while some packaging is necessary to put the lint into a library, by and large writing a dilant lint is essentially no different than writing a clippy lint is essentially no different than writing a rust compiler lint. And what I mean by that is that the APIs that you use to do the actual linting are the same in each of the three cases. So dielent doesn't force you to learn a dielent specific API. So, for example, the late lint pass trait that you saw on the previous slide, that's a that trait comes from the rust compiler, it doesn't come from dilint. Okay, so as I mentioned, we have developed these lints which were inspired by the sea level attacks. And so here again are the sea level attacks.
03:21:45.914 - 03:22:46.238, Speaker A: We currently have lints for six of them. For two of them, lints are currently in development for three of the sea level attacks. We have not yet been able to identify a lintable condition. And what I mean by this is we haven't been able to identify a feature that a program would have to exhibit that if it did, meant the program was vulnerable to that sea level attack, and which feature we could identify programmatically. Having said that, if this is a failure of imagination on our part, and you have ideas, we'd be open to pull requests. But now, just as we went into the owner check's sea level attack in some detail, I'm going to go into the missing owner check lint, and just enough detail to give you the flavor for what one of these lints looks like. Okay, so as I mentioned, there's typically an invocation of the clear late lint macro, and so it will include a rust comment with some documentation describing the lint.
03:22:46.238 - 03:23:28.790, Speaker A: In this case, it's been slightly abbreviated. Then there is the lint name, the default lint level, and a description which appears, if you ask dialint to look, list the lints in the library. Okay, and then, as I mentioned, every lint includes an implementation of a lintpass object with one or more check functions. Now before we get into too much detail, I just want to remind you what the vulnerability was in the insecure example. The vulnerability was that it made reference to a Solana program account info account info struct, but didn't check its owner field. So this is the lintable condition that we want to identify with this lint. And so the way this works is as follows.
03:23:28.790 - 03:24:27.714, Speaker A: So this method check function this will get called by the rust compiler for each function method or closure. Then this function get referenceaccounts is a function defined within the same lib rs file, and what it does is it walks over each expression expression within the function body, and it identifies those which have type solana program account info account info. It collects those all into a vector. Then for each such expression identified, this function contains owner use is called what this function does is it does a second traversal of the function body and it looks for an expression of the form account expression owner. So account expression is one of the expressions we just found in get referenced accounts, and this dot and owner are literal. If no such expression can be found, then a warning is issued. This account struct is used, but there is no check of its owner field.
03:24:27.714 - 03:25:34.274, Speaker A: So by and large we test the lints with the actual sea level attack code. In a couple cases we have to make small modifications in order to get the code to compile, but by and large we use the actual sea level ATT and CK code to test. And so if you run the lints on the insecure version of the owner check example, you get a warning like this which should look familiar to if you're used to seeing rust compiler or clippy lints. And what it's saying is it identified this expression here which has type Solana program account info account info and yet nowhere within the body in which this expression appeared could it find context. Accounts token owner if you run the lint on the secure example, you get, as you'd expect, no warnings. Now, before closing, I want to make a quick point in regard to how our lints behave with respect to anchor programs specifically. And to do that I'm going to make this point by saying a few words about the the type cosplay c level attack and the length that we developed for it.
03:25:34.274 - 03:26:23.744, Speaker A: So I won't go into the same level of detail, but here is the type cosplay vulnerability in a nutshell. So you have a program which does proper ownership checks but operates on multiple types of accounts and doesn't have a way to distinguish among them. So here you see we have this update user function which expects to receive a user account. However, it actually operates on multiple types of accounts, user and metadata. And if you notice, both contain a single public key. So we would expect these two accounts to serialize the same way. So the issue is that an attacker could pass into update user a metadata account and there is nothing to stop update user from operating on that metadata account as though it were a user account.
03:26:23.744 - 03:27:13.384, Speaker A: So one way to mitigate this vulnerability is to add to each type of account that the function operates on a discriminate field. And what this field will do is it will hold one constant for one type of account, it will hold a different constant for every other type of account. And so then the idea is that the program can check the value within this field in order to determine the type of account that it is operating on. On. So that's the vulnerability in a nutshell. Now what you're looking at now is no longer the insecure and secure versions, but the insecure version and a slightly modified version that we have prepared for testing. So in this slightly modified version, what we have done is we have replaced this use of the derive macro with a use of the anchor account macro.
03:27:13.384 - 03:27:52.664, Speaker A: Now what does this macro do? Well, it does several things. In particular, it implements these traits for the struct that it annotates. And what I want to highlight here is the way that it implements serialization for that struct. So in particular it reserves the first eight bytes for a unique account discriminator. So more or less the fix I was just describing previously. Moreover, the way it implements anchor deserialize is such that this tride deserialize function will check those eight bytes. And if those eight bytes are not the value that is expected for the account that you're trying to deserialize, it will raise an error.
03:27:52.664 - 03:28:43.342, Speaker A: So if you run the lint on the insecure example, you get a warning like this type does not have a proper discriminant and may be indistinguishable when deserialized. However, if you run the lint on the insecure anchor example which I just showed you, you instead get this warning. User type implements discriminator trait if you are attempting to serialize here, you probably want to try deserialize. So in other words, what the lint is saying is hey, I noticed that you derived the discriminator trait for this type user here, yet you're calling try from slice and try from slice doesn't get you the benefit of having implemented that trait. So that's probably a mistake. Probably what you meant to do was call, try deserialize. Okay, so I would like to invite you to try these lints on your own code.
03:28:43.342 - 03:29:14.454, Speaker A: Doing so is relatively easy. It's three steps. First, you're going to install two binaries from crace IO using the command cargo install cargo dilant link. You're then going to add these lines to your project's cargo toml file, which tells dilant where to obtain the lints that you want to run on your project. And then finally, you're going to run this command cargo dielent alt. And what this will do is it will download all the lints in the lint subdirectory from the Solana lints repository. It will build them, and it will then run those lints on your project.
03:29:14.454 - 03:30:11.014, Speaker A: I just want to mention that all of the hard work, all of the hard work done and what I just talked about is actually due to these two gentlemen. Victor Way, who is currently a senior at Truman State University, and Andrew Haberland, who is currently a first year PhD student at Carnegie Mellon. And I'll leave you with some links in case you want to learn more about the Solana lints, about Dailand itself for the sea level attacks. And with that, I will happily take any questions. Okay, no questions. All right, thank you very much, everyone. All right, thank you very much, Sam.
03:30:11.014 - 03:30:52.784, Speaker A: I think security has been sort of the theme of the day. That was some incredibly useful advice. I saw a lot of people really engaged with that presentation, so thank you again, Sam. All right, we're about to start the last talk of the day, and I know it's highly anticipated. We're going to hear from Brandon from Phantom, and he's going to be discussing a super important topic which is preventing phishing in wallets and in phantom specifically. So, without further ado, I want to introduce Brandon, give him a hand, and welcome him here. Hey, everyone.
03:30:52.784 - 03:31:28.868, Speaker A: Thanks so much for coming out to the talk. Hope everyone's having a good breakpoint so far. I was here last year around the same time, and it's just really awesome to see how the community has grown in just a year. Really amazing to see. So really excited to talk to you today about what I think is pretty much the biggest obstacle for mainstream adoption of crypto today, which is fighting phishing and scamming. So the talk today is entitled how Phantom is fighting phishing and scamming. I'm going to be going over a couple things.
03:31:28.868 - 03:31:59.864, Speaker A: So one, going to kind of define what I think phishing means in a crypto context. I'm going to talk a little bit about the types of different attacks that we're actually been seeing out in the field, the different solutions that we've implemented along with their effectiveness, and, yeah, how everyone in this room can work together to combat phishing. So here we go. So, yeah, next. Oh, but just quickly as a quick intro. So my name is Brandon. I'm the CEO and one of three co founders of Phantom.
03:31:59.864 - 03:32:57.018, Speaker A: My Twitter handle ishillman and I'll be around the conference for the next couple days if anyone wants to chat. So happy to meet you guys all in person. Cool. So next up, so what is phishing exactly? So Merriam Webster defines phishing as the practice of tricking Internet users as to the use of deceptive email messages or websites into revealing personal or confidential information, which can then be used illicitly. If we're then to transform that into more of a crypto flavor, you could say phishing is the practice of tricking crypto users as through the use of deceptive discord telegram messages or websites into revealing secret recovery phrases or approving malicious transactions. So that's the type of phishing that I'm going to be referencing today. And just to kind of level set things a bit and kind of give you guys an understanding of the type of scale that we're seeing.
03:32:57.018 - 03:33:53.524, Speaker A: So since launching Phantom back in May of last year, we've actually hit over 3 million active users. We facilitated 49 million Dapp connections, and we've actually facilitated 325 million lifetime transactions. And to put that into perspective, that's actually an average of seven transactions per second for a year and a half straight. And at our peak, we hit number 20 in the finance section in the App Store. And through that we've seen a lot of shit. So I'm excited to kind of show you guys what we've seen. Yeah, so there's a lot of different types of phishing attacks out there, and we really want to give Dapp developers basically a sneak preview of the types of problems that they're going to see at scale and also kind of give you guys a sense of what solutions exist out there, both from a technical perspective and also from an operational perspective.
03:33:53.524 - 03:34:28.144, Speaker A: And yeah, something that I can't emphasize enough is that we all need to work together to solve this issue. And basically every single trusted NFT project, dapp or token out there is affected by this problem. And scammers are basically utilizing everyone's brand equity to steal from their users. And so it's really a common problem that we all need to solve. And, yeah, excited to kind of like teach you guys what we've seen. So first up, fake websites. So I'm sure a lot of you guys have seen a lot of these fake websites, especially around mints and stuff like that.
03:34:28.144 - 03:35:28.674, Speaker A: So, yeah, basically, scammers will go at great lengths to mimic, like, the apps that we all know and love in order to coerce them into signing a malicious transaction. So, for example, they may get you to sign a transaction that actually enables transfers or approvals to then sweep your account at a later date. We've also seen a lot of instances of scammers seizing domains as soon as they get released or expired, and even paying for fraudulent search ads. Like you can see here, we've seen instances not only fake websites, but fake applications as well. So we've dealt with tons of fake Android apps, fake chrome extensions and all that sort of thing. You can kind of see here an example of something that we've seen in the wild. And yeah, as many of you have probably encountered, scammers also often use various forms of social engineering to try to get you to give up your sequel phrase or sign a malicious transaction.
03:35:28.674 - 03:36:53.554, Speaker A: So these attacks include fake telegram users, fake phantom support, which I'm sure everyone has seen. And yeah, on top of all the attacks that I just mentioned, we have seen a lot of other attacks, including spam, nfTs, rotten seed phrases, which are actually like pre compromised seed phrases that an attacker will try to get you to import into your normal app to actually add another layer of misdirection on the attack. And so what else? Yeah, copy and paste malware, complicated Devnet soul scams, where a scammer will try to get a user to think that they're on Devnet and actually send them real money. So the list really goes on. Something I want to emphasize is that phishing and scamming is basically continuous cat in mouse game, where elaborate scams are getting more and more complicated, and therefore the measures that we have to take to mediate them are also need to get more and more complicated. And these are just kind of a subset of the attacks going out in the wild. So basically, from the remainder of my time, I want to basically walk through an example user journey of what a new user coming into the ecosystem might experience as a first time user, the pitfalls that await them in this journey, and then how Phantom is sort of helping them every step of the way to keep them safe.
03:36:53.554 - 03:37:20.550, Speaker A: So we have a fictitious person here, Alice, who is a software engineer. She had just heard about nfts from her friends and she wants to give web3 a shot. And so she talks to her friends about how to buy nfts. She was able to successfully buy her first NFT on hyperspace. Has a great time. This is Alice donning her brand new profile picture. Djen.
03:37:20.550 - 03:37:47.114, Speaker A: Trash pandas was a good choice. Now she's hooked and now she gets getting deeper in the rabbit hole. She hears about a hyped up mint called Toots. She wants to participate. So she signs up for the discord, anxiously awaits for the day of the mint. Finally, the mint day comes and the discord sort of floods with different links. Unbeknownst to her, she clicks on a link to an incorrect site called toots.com,
03:37:47.114 - 03:38:34.226, Speaker A: not with zeros but with Os. And then she's bet with this. And so this is quite surprising, I think the first time if anyone's seen this, what's actually going on here? So if you're a phantom user and you are accessing a malicious domain, we actually have this public repository called the Phantom block list. And what this actually is, is a community maintained list of fake domains that lets us communicate to the community about fake domains that we've discovered and vice versa. And Phantom as an application will actually pick up on these malicious domains and actually actively block a user from being able to access them. So when we hear about a malicious site. Oh sorry, 1 second.
03:38:34.226 - 03:39:18.792, Speaker A: Yeah, so, yeah, so we have this block list, but however, if someone's using not Phantom, they may actually, they're not actually going to benefit from this list. So what do we do in that case to help solve this? Sorry, here's an example of some examples of domains that we've blocked in the past. So you can see some familiar names on there for sure. As of right now, the block list stands at over 2000 block domains. But like I was saying, if a user doesn't have Phantom installed and is using another wallet, that interstitial is not actually going to show up. But we still want to be able to protect users in that case. So what do we do? So to help solve that case, what we do to try to take, we actually try to take down these sites proactively.
03:39:18.792 - 03:40:16.544, Speaker A: So when we hear about a malicious domain, not only do we add it to this block list, but we actually have partnered with multiple external firms called Fishfort and redpoints that will actually go and try to pull the domains down so that if you're using another wallet. If you're part of the broader ecosystem, you'll actually reach this when you hit a malicious domain. And yeah, just to give you kind of some stats on how many sites we've actually taken down. So like I said, our block list has over 2000 entries. We've actually managed to take over 1000 fake websites, all targeting the Solana ecosystem. And we also managed to take down around 250 social profiles, including fake telegram bots, as well as fake Twitter accounts as well. So just to give you a sense of how much we're doing behind the scenes here, another common path to scammers to lead users to fake websites is through fake NFT airdrops.
03:40:16.544 - 03:41:27.224, Speaker A: So unsuspecting users may receive one of these NFT airdrops after interacting with magic Eden or other popular dapps. And these NFTs often have instructions on how to win some prize or claim some airdrop, often in the metadata or even sometimes in the image of the NFT itself, making them very difficult to detect. So we actually use the same block list sort of technology to block these types of nfts as well. And we're also investing in automated spam filters, much like you would kind of use on your email inbox today. Want to quickly plug our burn nfts feature? So although this actually does not protect someone from a scam necessarily, it's like an awesome way to kind of get back at scammers. So since we've launched our, since we launched this feature back in August, we've actually facilitated over 600,000 burns. And what you're doing when you're burning an NFT is you're actually reclaiming a small amount of soul that the scammer used to kind of fund this campaign in the beginning.
03:41:27.224 - 03:42:05.924, Speaker A: So it's kind of a way of getting back of those guys, but just wanted to quickly plug that in. Yeah. So back to our protagonist, Alice. So if our block list and our takedown precautions are not successful, then Alice may actually find herself on a very convincing phishing website called toots.com dot. In a rush to mint, Alice may click on the mint button up there and the Dap may then try to coerce her into approving a malicious transaction. If Alice is using phantom, then instead of the normal transaction pop up, she'll actually see this.
03:42:05.924 - 03:43:15.496, Speaker A: And this is a result of an advanced transaction simulation system that we've been working on for a while that's able to recognize that the action that she's about to take is going to drain her or be malicious and warns her it is actually possible to bypass this transaction using the link down low if you are really confident in what you are doing. And then if Alice moves on to that step, will actually give her a human readable diff about everything that is about to go onto her account. In this case, the transaction is coercing her to approve a bunch of delegate approved to the app for a bunch of tokens in which the app will then sweep at a later date. So, yeah, if this warning is, so, how does this all work exactly? So I'm really excited to talk about this. So at Fanta, we basically recognize that this problem, like I said, is a continuous cat and mouse game. We have to get more and more advanced in our ability to block these. And so to do that, we've actually incubated a small security company called blowfish.
03:43:15.496 - 03:44:18.084, Speaker A: And Blowfish is a company that produces this advanced transaction simulation software and actually produces this proprietary detection engine, which has two main parts. So the first part is a rules based engine, which is basically you can think of as a giant if else statement that looks at the transaction and tries to look at common properties of the transactions that mark that show them as malicious. So for example, if a transaction is trying to change the owner of one of your associated token accounts, then the blowfish engine will say, hey, this is very likely to be malicious, but of course this is not going to work in all cases. So blowfish also includes a machine learning aspect as well, where it's constantly learning about all the new scams that are coming out and improving. So yeah, here, I'm really excited to talk about this. So here's some stats on how many users we've actually saved using this system. So overall, we scanned 85 million transactions using this system.
03:44:18.084 - 03:45:02.638, Speaker A: We've prevented over 18,000 wallet draining transactions. And in the last month alone, we've actually saved 3000 unique users from getting drained. And this is really important because if a user gets drained, they're never coming back to the ecosystem. And everyone here is trying so hard to get these users in the door. And so we all have an obligation to try to make sure it's a safe environment for them to explore web3 and do what they want to do. So, really proud of these stats specifically. All right, so if alice is able to bypass our block list takedown and the transaction simulation efforts, unfortunately, she may lose funds to the scammers.
03:45:02.638 - 03:45:46.726, Speaker A: Operatingtooths.com dot when this happens, this is where our world class customer support team comes in. So yeah, I quickly want to talk about this because I think unfortunately the current state of customer support on web3 is extremely primitive. Honestly, pretty borderline negligence. So normally when someone using a web3 app and someone's encountering a problem or has a question, the state of the art is to kind of usher them into a discord channel and then they talk to a moderator. They may start to get DM's from fake accounts. If they're already sort of in a vulnerable or agitated state, they may be more likely to answer responses to these DM's.
03:45:46.726 - 03:46:37.532, Speaker A: And overall, it's a very dangerous system. So we've kind of foregone that entire system and kind of created a normal customer support system that you might expect from sort of a web two company or like a more established company. Yeah, and so really excited to talk about this. We basically have built a world class support team with the former head of support from Metamask, who has used all of his years of experience to basically build a team to create an awesome support team with a number of goals. So first off, we want to be able to educate users to safely navigate web3. We want to help users get back on track if they lose their way. We want to protect users from known phishing scams, and we also want to identify bugs, feedback and opportunities to improve the user experience.
03:46:37.532 - 03:47:04.034, Speaker A: So these are kind of all the explicit goals of our customer support team and to give you a little bit of understanding of the skill that they deal with. So they have lifetime resolve. 30,000 tickets in total. We actually goal on things like median response time to actually put together a professional operation. So we have a median response time about 14.8 hours. And this is all accomplished by a full time staff of seven support agents.
03:47:04.034 - 03:47:42.922, Speaker A: And we also have a help center which has gotten over a million views by itself. So, yeah, that's pretty much it for the user journey. Hopefully that gives you a good idea of both the technical and operational complexities of fighting phishing in web3. And I basically wanted to end this session with a couple of key takeaways. So one, like I said multiple times, fighting, fishing and scamming is a continuous cat and mouse game. Fighting, fishing and scamming is not only a technical challenge, but also an immense operational challenge. And then fighting, fishing and scamming is probably the most important problem to solve for the mainstream adoption of crypto.
03:47:42.922 - 03:48:27.818, Speaker A: And I truly believe that things that we can actually do together, things that everyone can do in this room. So one, contributing to the block list. So like I showed you before, we have this open source GitHub repository. If anyone out there sees a malicious domain or experiences a scam, please reach out to us, please contribute to the block list, and we can actually fan that information out to the broader ecosystem. Two, if you're running a popular dapp NFT collection or token, if you have things like trademarks, if you have things and things like that, you can actually participate in the takedown process yourself as well. And if you have more questions about that, I'm happy to introduce you to the right people. And three, just more user education.
03:48:27.818 - 03:48:57.524, Speaker A: I think more and more people are getting to this space. We want to onboard the next billion users. And to do that, people really need to know how to properly defend themselves in this space. And then, yeah, some plans for the future. Like I mentioned, we're going to be improving our NFT spam detection. It's a really difficult problem, very much akin to spam on email. We're going to be continuing to improve our transaction approval and simulation through blowfish, and we're going to be experimenting with different kinds of self custody solutions.
03:48:57.524 - 03:49:44.406, Speaker A: So one thing I didn't really touch on is we focus mostly on this path of signing malicious transactions, but there's actually a whole breed of attacks that are designed for for you to give up your seed phrase. And so we're really excited to experiment with different types of self custody solutions that give people, continue to give people the benefits of non custodial solutions, but help limit some of the damage of giving away your private key. Cool. And yeah, thanks so much again. If you want to get in contact or if you're interested in working on any of these problems, please let me know. We have our website jobs page, my personal email, as well as my Twitter here. And yeah, I'll be around the conference for the next couple days.
03:49:44.406 - 03:50:13.074, Speaker A: If anyone wants to talk about this topic, just hit me up and that's it. Thank you very much. Awesome. Thank you very much, Brandon. What a great day. That concludes our scheduled programming at this stage for this afternoon. Make sure though, that you check out the great events tonight.
03:50:13.074 - 03:50:31.974, Speaker A: I know a lot of people are excited for Anatolian Raj's talk at 610 over at the forum. So that's the convento dubiatu site, as well as the opening night celebration at 07:00 until eleven. So hope to see you all there. Hope to see you back here tomorrow for some more great developer content, but otherwise, enjoy the evening. Thank you.

00:00:22.480 - 00:00:40.036, Speaker A: Bartage. I must have the stage to myself. Hello, Solana developers and just all the people. Holy crap. What a year it's been for Solana. The last week. I feel like the price of soul has hit all time highs almost every day.
00:00:40.036 - 00:01:02.570, Speaker A: It's crazy. It's at $250, I think. I didn't look at it this morning, but yesterday it was at dollar 250 per coin. That's pretty great. I know people say, look, the price is not the most interesting thing, but it surely is one of the more exciting things. That also means that Solana is up 17,000% on the year. So Solana has just had such a massive year, it's crazy.
00:01:02.570 - 00:01:33.504, Speaker A: And it means that the Solana blockchain is now worth $76 billion. That is billion with a b. What else starts with a b? That's me, Bailey, and I'm your emcee for this morning and probably for most of the mornings over on this developer stage. This is Sud Liz Boa. I'll just go through some of the stages, all three of the stages that we have here at Solana breakpoint. So if you're confused about where you are, this is Sudlasboa developer stage. Couple developer panels to start off the day and then developer workshops throughout.
00:01:33.504 - 00:02:08.846, Speaker A: A ten to 15 minutes walk in that direction is LX factory. LX factory is our ecosystem stage. So that's where you're going to hear all about the ecosystem that is built up around Solana over the past year or two. And then we also have a Stuffa fria. A stufa fria in Portuguese means cold greenhouse, and it is in a greenhouse. It's a beautiful venue and that's where you will hear about all of the things, all of the projects on entrepreneurs that are trying to get to the next million or billion people on Solana. Some other housekeeping.
00:02:08.846 - 00:02:45.226, Speaker A: If you are tweeting about this conference, please use the hashtag Solana breakpoint. I know you all will be sitting on Twitter most of the day, so please do that. There's not necessarily dedicated Q and a here on the developer stage, but I'm happy to sort of push some questions to some of the panelists if you all want. So just tag melr 13 if you have any comments, and I'll try to get those. But we have a full packed day of workshops, so sorry if I can't get to those otherwise. If you want to go between venues, we have some shuttle buses and some tuk tuks out there. The tuk tuks are all branded with slope, finance, so thanks to slope finance for doing that.
00:02:45.226 - 00:03:13.644, Speaker A: And those are free, so you can get around the venues that way. Let's see, what else. Anything else that I need to say? I don't think so. All right, so we're going to go ahead and get started. Let's kick this off. Our first session. So with Ethereum, with the first mover advantage, and then a whole bunch of other layer ones and L2s gaining market share, the question is, why Solana? Why build on Solana? Why participate in the Solana ecosystem? And so we have a panel today of five amazing developers to discuss this.
00:03:13.644 - 00:03:23.924, Speaker A: I'm going to go ahead and bring those folks on stage, and that will be moderated. Come on up, guys. That will be moderated by Chase Barker from our very own Solana labs. Thanks so much.
00:03:38.384 - 00:04:10.102, Speaker B: Hello, everyone. It seems like everybody wanted to go get a nice, quick glimpse of Raj and anatoly for the first time, but super excited to be here. This is actually crazy. Lots of us at Solana labs have actually never met each other either. So we've been spending the past few days just hanging out and getting to know each other. And then yesterday, the registration kicked off, and it was really cool to start meeting the people that I thought wouldn't be as social as they actually are. Maybe it was the alcohol.
00:04:10.102 - 00:04:31.954, Speaker B: Maybe it was just people aren't as antisocial as I thought in this space. So it's been pretty incredible. So welcome to Ysalana developer's perspective. When I was first asked to do this, I thought it was kind of weird. I was like, I'm the most biased person in this company to talk about Ysalana. That's actually part of my job. So I decided to bring in kind of a.
00:04:31.954 - 00:04:59.960, Speaker B: A little unique collection of people. We have Bartosz Lipinski, Solana Labs. Previously in the Tradfi. We have Irvin Cardena from open era. And then we have Ian and Dylan Macleano from Sabre. So I'm gonna let everybody do a brief little introduction against the wishes of Bailey in here. So we're gonna keep these short, and we'll go ahead, Bartosz and.
00:04:59.960 - 00:05:20.848, Speaker B: Sure. Thanks for having me here, Bartosz. I've been on Solana for about a year. I primarily focus on building apps on top of Solana, and before that, I worked on trading systems instead of a few other financial institutions. Yeah. Thank you guys for having me here. I'm Irvin.
00:05:20.848 - 00:06:14.462, Speaker B: I'm co founder of Opendive Technologies, and we're building Openera and a few other immersive reality tools and applications that leverage Solana, blockchain. And previous to that, I founded a bitcoin startup back in 2012, worked at Goldman Sachs strategic blockchain technologies, and a few other things across various blockchains that, you know, like Polkadot, Harmony, Polygon, and also received grants from Chainlink and other projects. Hey, guys, my name is Dylan. I'm working on Sabre, which is a decentralized exchange on Solana, focusing unstable swaps of assets. I was also working on Metaplex, which is the NFT protocol in Solana. Before that was working in fintech, worked as a product manager at Okoy, which is the crypto exchange, and before that was doing tokenized securities on Ethereum and hi, I'm Ian. I was an EVM dev.
00:06:14.462 - 00:07:20.046, Speaker B: Before this I built a big amm on Celo called Ubaswap, and I was also working at a fintech company called Pipe. We were doing lending, but yeah, cool. Thank you, everybody. So I think we're just going to kick this off. I think one of the most, like, the number one thing I wanted to do with this, this is why I brought people like Ervin and Sabre, Ian and Dylan from Sabre, is because they come from different blockchains. The number one question kind of that came to my mind whenever I was putting this together, was that, like, what was the original kind of moment for each of you guys to propel you into diving into Solana? I know coming from trad five, Bartosz might have a little bit of a different situation here, but as blockchain developers, it seems that it's not always the easiest thing to change your mind and switch to something completely different. Obviously fast, fast, cheap, secure, like blah, blah, blah.
00:07:20.046 - 00:08:11.574, Speaker B: But there's obviously lots of different nuances and reasons here. So, Bartosz, did you want to give an answer to this, since you're from the traditional finance world? I mean, I can just say why, I guess, in general, from my perspective, why I picked Solana instead of other blockchains. So, primarily, when I think about building trading systems like throughput and latency, and how quickly you can get out of the orders that you have in the market. And at that time, like at the specific time, usually it's around the cancellation. It's when the throughput and latency matters. I think we are still not there yet with getting an actual trad five market makers migrating to Solana, but it's extremely important to have a plan how you would get there. And based on my talk with Alek Anatoly before I started, I believe it's possible.
00:08:11.574 - 00:08:47.534, Speaker B: Yeah. So we kind of talked before this, though, and I know Ervin was going to also mention some things around, like the traditional finance world, but, like, how. How is Solana fast and efficient enough right now to run what Anatoly would basically say, running like the Nasdaq on Solana? Are we there yet to be able to do that? Go ahead. Yeah, we can. Yeah, Ervin. So, like, Bartosz, you're one of the core developers, so chime in right after you. Sure.
00:08:47.534 - 00:10:04.088, Speaker B: I think from the cancellation perspective, it's tricky just because, like, how you communicate with the validators, there's no easy way for the market makers to actually, like, guarantee that their cancellations will hit the specific time. So I think there's still a couple of things that need to happen. I think this startup called Jitta is thinking about it, how it could be approached, and, like, market makers that are building on Solana are thinking about it quite a bit as well, like Susquehanna and Chicago trading company. I think they are doing interesting things with the validators to figure out how they can actually get out of the market, which is the most critical aspect, at least from my perspective, that people that are looking at Nasdaq don't think about, because it's like executing orders, but executing orders is actually less important than canceling them. Yeah. So there's a huge misconception around the blockchain world. I think every blockchain will pitch you saying, we have a million TPS transactions per second, but in the world of finance, or overall, TPS is not the only thing that matters.
00:10:04.088 - 00:10:40.234, Speaker B: It's fast finality, because, as Bartosz was saying, was that you want the transaction to have complete finality. You don't want to have uncertainty for milliseconds or a large number of seconds. I think we're getting there, but definitely, I would say from that angle that Solana is one of the blockchains that is pushing towards mainstream adoption. For us, that was one of the key things. When we spoke to anatolian Raj, that was a key thing. And so that's good and all. And I honestly asked, well, how are you going to achieve this? And they kind of gave us a rundown, and you guys already seen this happen and play it out.
00:10:40.234 - 00:11:34.584, Speaker B: And so as you're building a product, you're a technologist, the technology itself matters, and a lot of the technology is there, but also, how is the technology being adopted by the entire world? Because essentially, you're building a product and you want your product to be used across the entire world. And so that's one of the things that I would say, expanding upon what Bartosz say. Yeah. So is that just circling back, since I kind of, like, distracted away from that? So what was the first, like, what brought you into as open air? Like, how did you jump from Polygon and all the other blockchains that you were working on, which the list is actually quite long, but to make the jump to Solana? Yeah, yeah. So, you know, wag me, I think, you know, that's like, we're all gonna make it. I think we all have to be friends in this ecosystem. And, you know, firstly, my team and I, up and I, we work with a few different blockchains.
00:11:34.584 - 00:11:52.934, Speaker B: So we're Polygon. We love those guys. We love Harmony. I'm a substrate academy fellow, which is the framework for Polkadot. And also, I was part of Pokeahouse. Shout out to them. And, you know, like, we decided to build, build a product early this year.
00:11:52.934 - 00:12:21.528, Speaker B: And so we came up with open dive, which focuses on immersive reality tech. And we really wanted to bring our technology and connect it to blockchain and so on. So we were looking for this kind of home we had worked on. Like Chase mentioned, Polygo is one of them. Harmony did avalanche and stuff like that, and SVF pitched us Solana and serum. Sarah over there, we love serum. And so we were like, okay, we've done so many hackathons, so many projects, a few alphas.
00:12:21.528 - 00:12:42.192, Speaker B: I was like, Sam was like, come check out the Defi hackathon. There were like two weeks left. Yeah. And so Sean, my co founder, and I were like, okay, do we want to do another hackathon? Because we had said, like, we're done with hackathons. Let's build, like, for long term. We're like, fine, let's do it. We get there, and I would say that it was like, documentation was bad.
00:12:42.192 - 00:13:30.620, Speaker B: Like I told Ratosh, document was horrible. I was like, how do I get started? I had to review it. Paul X blog was there. And so as someone who's trying to build a startup, a product and going towards Dao, like I said, one of the core things is technology. And what I truly valued when I learned about Solana and I talked to the team, and I'll tell you, was that they're trying to innovate outside of other blockchains, because if you look at the space, there's a whole bunch of EVM compatible blockchains. So what's the innovation there? Is it a minor tweak? In terms of how the transactions are propagated, is it the validator set? And so it's something completely different. And I would tell you that it takes a lot of grit to build something from scratch because you're jumping into the unknown.
00:13:30.620 - 00:13:57.986, Speaker B: And so I've personally been there, and my co founder, Shawn, we're trying to build robots and stuff like that. Tough. And so I valued that tremendously. The other part that we also valued with Solana early on was that the ecosystem was growing, and they had a plan on how to create these tools. So we came in there and we said, okay, so the wallets weren't there. This is like Varche from a. Right, and Varchar, we get them done.
00:13:57.986 - 00:14:35.854, Speaker B: And so we assess this and stuff like that. And at the end, it was a combination of, I would say three things, right? The technology, the ecosystem, the community is growing there. And there's one third one, which I'll leave it out there, but these are key things to look into when you come into Solana, or perhaps other ecosystems, right? Technology, ecosystem and community, how fast they're growing. And the third one is probably quite obvious, but I think I'd like to touch upon that later on. Yeah, yeah, I think it's. I think the community aspect of it, it's like, obviously part of my job is to speak with developers. And, like, I started six months ago, and, like, my DM's went from, like, five DM's a day to, I probably wake up to about 80 a day.
00:14:35.854 - 00:15:21.734, Speaker B: 90% of those are people sometimes from FAANG developers being like, hey, I'm getting into this. Don't tell anybody, but, like, where do I get started? So, like, that community aspect, it's actually been crazy for me to watch that happen. But I am, like, super interested to hear from Dylan and Ian about, like, what? Like, you guys were building on Celo and ETH, and all of a sudden you're on Solana. So, like, how did that end up happening? Or what drew you to it? Yeah, maybe it's easier, actually, if Ian goes first. Me? Okay. Yeah. I mean, what drew us to Solana initially for building, I guess the curve of Solana was the low fees and the fast transaction time.
00:15:21.734 - 00:16:02.146, Speaker B: Some more background on me. I've been involved in Defi for a long time, since the term came out. I guess in 2018, I was really involved in Ethereum defi trading since March 2020. I saw the entire ecosystem grow from before yield farming, when DeFi TbL was under a billion to, I guess, where it is today. But yeah, from that, curve was something that I used all the time, but it's very expensive because it's not like uniswap, where it's just x times y equals k, which. Which is already kind of expensive, but it's a little more complicated than that. And from that, you're easily spending maybe even like $50 per transaction as a cheap transaction to just swap between stables.
00:16:02.146 - 00:16:41.404, Speaker B: But curve is a really good idea. It's a LP or it's an exchange where you don't have any impermanent loss. So it's like a good risk free rate of crypto, but we basically just wanted to have that, except cheaper, so we didn't have to pay tons of money whenever we wanted to change between USDC and USD across different exchanges. So that's why I got into the ecosystem in the first place. Why I stayed was because of the community. So I think the Twitter community is just really good. In Solana, it's very motivating as a defi developer to just build when people are actually saying they like your product and they want you to keep building more products and keep just growing the ecosystem out.
00:16:41.404 - 00:17:15.172, Speaker B: And that's not something you really get easily in other chains, trying to get people to rally behind you and have that specific type of culture where people get excited about what you're building. So, yeah, that's what I like about Solana. On top of that, there's really good exchange support. So the support from FTX and just institutional stuff in general is really nice, because then it's really easy for me to get my friend to just put a bunch of USDC into FTX us and just withdraw it. But that's not something you get on a lot of other chains. On other chains, you might need to use a VPN. That's not allowed.
00:17:15.172 - 00:18:05.444, Speaker B: You're not supposed to be doing stuff like that. But FTX has actual official support in the US and also every other country, so it's been really easy to integrate. Yeah, I'll add to that, too. So Sabre actually was started, I guess the first version of Sabre was end of last year as part of the first Solana Hackathon. So that's something that Ian and then our other co founder, Michael, participated in. And yeah, back then, though, the developer experience of Solana and even just the ecosystem in general was just a lot less than it it is now was. And even when we basically got back into working on Sabre, which was in April of this year, and the way that I got involved with Solana, so, yeah, I was working full time at a fintech startup that wasn't in crypto, but still just really interested in crypto trading and also building on the side.
00:18:05.444 - 00:18:48.424, Speaker B: And I was looking for a fun project to do. Ended up just randomly seeing a tweet from Raj one day. He was like, oh, we're looking to incubate a project that is going to do or basically start NFTs on Solana, which is the project that ended up being called Metaplex. I reached out to him, I was like, hey, I'm interested in working on this. And ended up just working on it part time. I think one is just meeting the Solana team, Raj, Anatoly, people like Bartosz as well. I think they just had a very good vision of how they see the Solana ecosystem growing really fast and how they can basically create a niche amongst all these other l one s.
00:18:48.424 - 00:19:24.384, Speaker B: Yeah, as Eden was saying before, also institutional support. So, yeah, I was talking to some of the guys from Alameda, from jump, and, yeah, honestly just felt inevitable that Solana was going to become a big chain for finance. But what the problem was at that point was just there were not very many DeFi protocols. I think back at that time, it was mainly radium, serum, orca. I'm probably forgetting some other ones. But those are the main projects there. And there was no stable swap because we already had this code that was written for the first Solana hackathon.
00:19:24.384 - 00:19:47.254, Speaker B: And also, just seeing insight curve is just a very foundational piece of defi. You can really build everything on top of stable swaps. It's just more efficient than a normal stable coin to use. Yeah. Just made a lot of sense. And so me and Ian started working on that while we were still part time at our other job. Ended up finally quitting and going full time on Solana in, I think, like, July of this year.
00:19:47.254 - 00:20:13.404, Speaker B: And, yeah, it's been a lot of fun. Yeah, man, it's crazy. You were talking about building and, like, the developer experience, which is, like, my job to fix, so just give me some time. But anyways, I look back at, like, mango and Daffy and some of these guys, and I actually asked Daffy one day on Twitter. I was like, how the hell did you build mango? With literally docs and Pawlik's escrow tutorial. But people got it done. Like, I don't think that it was easy.
00:20:13.404 - 00:20:41.518, Speaker B: And then we also have a couple guys on discord that I promised I wouldn't name by name here. And developer support, that kind of just one off helped everybody get through a lot of this stuff. So that was super cool. Did you have something to say, Ervin? Because. Yeah, I think so. They talked, really, about Defi, and one of the things that actually happens nowadays, that you want to have compostability, right? So you want to have Lego blocks coming together. And so l ones in general are pretty good for this.
00:20:41.518 - 00:21:20.422, Speaker B: And so it was a matter of seeing, like they said, there were a lot of defi protocols coming over, and because compostability is just much smoother. And so there's a multi chain world. People are talking about, you know, compostability also across these multi chain ecosystems. But Solana had that in its sleeve, right? Yeah. So I had another question up here, which is, why did you stay? But, like, now that I'm thinking about it, the kind of, like, all this kind of just ties together. And it's probably the things, the reasons you came here are also the reasons you stayed. Except for, like, the community part, which I think, again, I just have to note that it was really shocking to see how quickly that community grew.
00:21:20.422 - 00:21:59.964, Speaker B: And, like, I think the NFTs actually allowed non developer participants to now, like, join Daos, and, like, there's a whole nother level there. But we can talk about that another time. I can talk specifically about staying. So I think when you and I first started working on Saver, we weren't really thinking, this is going to be a huge project on Solana, at least in the beginning, a lot of it was. I think Ian briefly mentioned on this, he was working on a lot of cello stuff. And so we were looking at, how can we basically make the cello dollar bigger? And one of those ways was like, oh, we can build a stable swap on another l one. That seems really promising.
00:21:59.964 - 00:22:28.116, Speaker B: But I think as soon as we started, Ian posted a tweet on the saber Twitter. It was called stableswap back then, and after I was seven, it was just something random, and it just got tons of hype. Everyone was really excited about it. I think SPF tweeted it or retweeted it, and we were just like, oh, wow, Solana seems a lot bigger than we thought it was. And, yeah, from there, like, I basically just kind of went all in on Solana after that. Yeah, it's not that it was. I guess Solana was big.
00:22:28.116 - 00:23:33.274, Speaker B: It's that the community members were really active and involved in trying to get the egos to be bigger. And, I mean, even within Solana labs, like the employees of Solana Labs and even Anatolia and Raj themselves, they encouraged us to build on top of Solana. Vitalik doesn't do that for you people in Ethereum. So it just feels a lot more motivating that these people that are building this chain really want you guys to succeed and grow the ecosystem out. So that's just been really great, I think. Another thing that was surprising, and I don't know if this happens on other chains, but you really have seen somewhat direct and indirect competitors that you would consider competitors in this space actually helping each other out with code and building in this kind of open, collaborative way. Obviously that Utopia doesn't last forever as things get kind of a little more competitive down the line, but when you're kind of like have a trajectory that's like a hockey stick in terms of developer community and projects, I feel like people are more willing to help each other, but maybe not again, like forever.
00:23:33.274 - 00:24:07.442, Speaker B: Yeah, I think so. Like they were saying, honestly, what's really exciting as a developer is that you really get to shape things bottom up. It's like the opportunity to do that. And if you're thinking about coming to Solana, you're still pretty early. I became an advisor for Metaplex. I have a lot of nfts and did a lot of NFT work. And it's kind of fascinating how the discussions about how do NFTs work on these other chains, let's say EVM compatible, you see that kind of like being applied, implemented right there.
00:24:07.442 - 00:25:09.620, Speaker B: And I had conversations with Jordan and Bartosz and that are taking place, but getting a bit technical, for example, to discussing nfts on Solana or something, when you look at EVM compatible chains, the standard for nfts is at the business or social level. So an NFT is just a contract that you constantly deploy on Solana, the concept of NFT, and even a metaplex is the standard at the protocol level. It's on chain that people use. So what does this mean? Well, this means that rather than you having to say, okay, you have opensea, then you have known origin, and you have this other marketplace. If you're a creator and you want to have royalties on the nfts on these EVM chains, all these quote unquote, marketplaces have to come into a business agreement for these royalties to take place. With matterplex on Solana, that standard or that concept of royalties is already baked or built in on chain. So the standard is already on the protocol.
00:25:09.620 - 00:25:56.954, Speaker B: So it means that artists, when they come in and mint NFT using matterplex storefront, and then they go and connect to a marketplace their royalties are there, which is very different. And it's also very motivating for artists and creators to kind of have this. It's also something to consider when you look at coming in and being able to shape the ecosystem and make it better. Yeah, I completely agree with that. And we do all owe a lot of thanks to Mister Bartosz Lipinski here for not sleeping for two months straight and helping build the metaplex standard with redacted J. Jordan, who I believe is probably sitting at the hacker house like he has been for the last five days straight. So we have about 15 minutes left.
00:25:56.954 - 00:26:36.284, Speaker B: And the more exciting question that I wanted to ask, and I feel everybody might have a different kind of answer here. And we'll start with Bartosz. What's the thing that probably most excites you with Solana? I think the NFT world blew up. That excites some people. I'm personally, just to give a brief opinion, I've been excited about gaming for probably the last three years in crypto. I know a lot of people from the finance world, they're excited about DeFi. So super curious to hear what everybody else as a developer is most excited of, whether it's what's going to be built or how it's going to change the world, or basically anything.
00:26:36.284 - 00:28:19.516, Speaker B: So, Bartosz, what are you thinking here? What's the most exciting thing about the next six months to a year on Solana? Yeah, sure. For me, it's maybe not the most exciting things, but three things. So the first one, everyone is talking about games, and we have been talking with Arvind for weeks, months about games in general, great team, tons of ideas, and we are basically thinking, how can we build it into a standard that's on chain, that games can become interoperable? And it's very tricky because you need to balance the composability of the games with the freedom for the game designers. So it's even harder than composing DeFi because the DeFi protocols somewhat agree on, for example, what money is, games sometimes don't. The other thing is, outside of games is seeing more collaboration from traditional finance. I think seeing what PIV did is like, from the outside it looks very straightforward, but if you worked at any of those financial institutions, from the inside of those institutions, you would argue that something like that, it's almost impossible where you have multiple market makers and investment banks and exchanges actually sitting at the same table and exchanging technology. Where like, for those people, like when I was working at Citadel, we were not even able to contribute open source software from our personal accounts during personal time, and I'm seeing contributing them and actually talking is very interesting.
00:28:19.516 - 00:29:06.286, Speaker B: So like being in Chicago and having multiple people come to the office from those firms and actually talk what they are going to build, it's just crazy. We'd have jumps esque hana CTC in the same room talking. What they are building is just crazy. And so like, just real quick, like in traditional finance, in case some people don't know, is like the closed source is where the money comes from, right? Like there's no such thing as sharing and open source. It's like kind of the antithesis of what we're all doing right now. So it has to be crazy to come from like traditional finance into crypto. So Ervin, what about you, man? Like, what excites you the most about the next six months to a year here on Solana? I think a lot of things, gaming is one.
00:29:06.286 - 00:29:49.486, Speaker B: We're talking about gaming for a long, long time. And, you know, standards on chain standards are a critical thing for interoperability, because, you know, people think about the metaverse, and right now you're pitched like a high level interoperability. Or they say, you know, there's this game a and game b, and then you can share assets, but then you look deep down and how does sharing assets take place? Where there's a business agreement that game a will allow game b to integrate. And so is that really interoperability? I'd say no, it's interoperability at the business level, not at the protocol level. You can quote me on that. So that's the huge thing for us. And our background overall has been in immersive reality and even robotics.
00:29:49.486 - 00:30:33.706, Speaker B: I've been in the space since 2012. One particular use case that I haven't seen really take off is things related to data in IoT, the Internet of Things. And we're working on research papers, we publish academic papers, and we did a comparison of IoT architectures with Solana and other chains, too. When you start thinking about what's going to happen in the next five to ten years, you look at 5G. Great. I think the US is just figuring out 5g. Actually, we're already researching seven g and other places, and people are deploying six g, right? And so when you have these interconnected devices and you have cell towers nearby, you have all this collection of data.
00:30:33.706 - 00:31:14.148, Speaker B: So what can we do? How can we provide provenance? And I think that's something exciting that needs to be explored more. And I'm looking forward to that in a near future. Besides that, I think anything goes like Defi and new models are yet to come, so you guys. You guys should keep an eye for that. Yeah. I think the whole thing about you, how you talked about being able to be so early and build this up and have so much influence, and I think that somebody brand new could come into Solana, a new project, and completely just shift everything in one direction. Just because it is still so small and we are so early, it won't take much to influence the way that things are moving.
00:31:14.148 - 00:31:41.214, Speaker B: I'm not so sure how I feel about Internet of things. I don't know if I want my refrigerator habits on the blockchain. I'm just kind of joking. So, Dylan, how about you? Yeah, I'm super excited about just seeing Lora composability. When we first started working in Solana, like I said, there weren't that many Defi primitives. Now we're getting to the point where I think pretty much every basic primitive exists out there and it is of high quality. So, yeah, really cool to see.
00:31:41.214 - 00:32:27.232, Speaker B: Just even speaking in terms of saber, in the past months or even past couple of weeks, I've seen a lot of new projects come out that are building on top of sabre, doing really cool things, and then now new protocols can come and build on top of those things. I think for the next few months, just going to see a lot more really interworking projects. What's really cool about being here in Lisbon and working at that hagger house is just meeting other teams. They're like, oh, yeah, we were thinking of building this thing on top of saver and we can help them out and stuff. Just super exciting to see more composability throughout DeFi and gaming NFT. Just everything cool. Yeah, just you mentioned in the hacker house, again, reminded me is just so everybody knows, apparently the mango team has put up some bounties over there.
00:32:27.232 - 00:32:55.006, Speaker B: So, like, if you want to go hack and build some stuff and then hit some of those bounty awards, it's a fair game. Yeah, there's a few of them. There's like, drift protocol, hero. Hero. Yeah, I'm bad with names. There's more than 100,000. So, Ian, you're the last one.
00:32:55.006 - 00:33:40.128, Speaker B: So, like, what's most exciting to you in the next six months to a year here on Solana? Yeah, yeah. For me, I think the most important thing is trustlessness. So, like, on Ethereum, right, or any EVM chain, you can basically verify the contract source and know exactly what your running and on top of that, there's a community of people that know solidity and can basically say if there's going to be a rug pull or not. But basically, since Solana doesn't really have a system for that, people really have to rely on other people to say that something's good or not. But what this does is it restricts people from innovating. If you think about all the big developments that happened in the Ethereum ecosystem, a lot of them come from these anon proton mail email addresses that just post some random white paper. They create really cool things, but they don't want to say who they are.
00:33:40.128 - 00:34:11.340, Speaker B: But I want to see a culture like that develop in Solana. And for that we need people to open source their code and verify the contracts and have a centralized repository, not centralized, a repository where people can actually verify the contracts very easily and see what's going on with that. My favorite project in Ethereum was basis cash. It's like a basis protocol clone. They took the basis protocol whitepaper. It's a stable coin. And they built it on Ethereum and just launched as an anon team.
00:34:11.340 - 00:34:54.668, Speaker B: But that could never really exist in Solana today just because people would not trust something like that. So I just want to see an environment where people could just launch a project like that, build it and put it out there and people can just use it. And from that I would see, I think the TVL of Solana would skyrocket after that, because then you just have all these forks of random projects all keep building and keep pushing out new things, just like we see with Metaplex. NFTs only really got big in Solana because metaplex made it really easy for someone to create a relatively trustworthy NfT where you know, you're interacting with a candy machine. Contract with Phantom, you can even see if you're actually going to get all your funds taken from you. And from that people are able to just go into it and not have to worry about losing all their money. But I want to see something like that for just defi in general.
00:34:54.668 - 00:35:27.142, Speaker B: And I think contract verification is like the first step, but governance is also another thing. But yeah, just trustlessness in general, I think is the most important thing. Yeah, I have a somewhat just sense I'm not typically building on a regular basis. I have a little bit different perspective on what I'm excited about, and I think everybody kind of is probably also in agreement with us. I hope is that streamlining the developer onboarding and developer experience? Obviously it's been a huge challenge since day one. There was docs and there was POW X. Now we're starting to see all these developers.
00:35:27.142 - 00:36:14.392, Speaker B: Like, I just saw somebody, I think his name is Brian Frail. He just created a whole full medium or like hacker hack two or dev two article on PDA's. Like, people were going and finding all these gaps that have been confusing and they're now, like, writing content. And originally I was out there trying to find developers to help produce content. Now it's almost becoming a full time job to just capture that content and find it because people are just like, coming onto Solana and making things and, like, I know I wanted to kind of, since we have a few minutes left, one of the big ones here. I don't know if Armani is here, but, like, he is doing the Lord's work out there building anchor. And now it sounds like I see Ian tweeting about this all the time, that crates are coming out left and right.
00:36:14.392 - 00:36:37.668, Speaker B: And, like, I mean, honestly, like, I think from. Most likely from the ETH community, like, that's going to be like, the go to. Like, there's, there's. I don't think we're at version one yet. On, on anchor, are we? Like, we don't have a fully. Do we know when that's coming? The fully audited, like, v one version? I think harmonic gave me like a month or two, like, kind of timeframe when then that would actually happen. Yeah.
00:36:37.668 - 00:37:05.600, Speaker B: So. But I did think, like, just so we do have some time. Like, what are your thoughts on that, Ian? Like, in terms of, like, anchor, like, you guys started out Sabre b one straight Solana rust, and then part of that. Still that. But you've also built some components. Yeah. So the core saber contract, the actual swap is not written in anchor, but every single other program we've ever used is built on anchor.
00:37:05.600 - 00:37:33.470, Speaker B: But why anchor is really important, is that it? So in Solana, you basically have to deal with these raw byte arrays to do everything. So you don't actually know what you're calling. You have to know what program you're calling in order to understand what's going on. But ethereum is not that the case. In ethereum, you have these things called Abis, like application binary interface, where you can actually see what's going on in a contract. So it's also important for this trustlessness, auditability stuff where you actually can see what's going to happen whenever you do something with a contract. But, yeah, that's why I think anchor is really important.
00:37:33.470 - 00:38:06.840, Speaker B: And just onboarding a lot of people, not just for developer speed, but also for this, like, auditability thing where people can actually integrate and see what's going on. Yeah, super excited to see this happen. Like, I know there's some anchor maxis out there now that don't even, like, want to even look at, like, natives and rusty. Yeah. So we got a couple minutes left. Did anybody have any final thoughts on, like, obviously we're talking about why Solana developers perspective. So, Ervin, did you have any final thoughts? Oh, yeah.
00:38:06.840 - 00:38:53.774, Speaker B: So I think I had that last third point. Yeah, yeah, yeah. So for us, it was very strategic, honestly, coming to Solana, and I mentioned the tech and the commander one thing. But, you know, personally, as a founder and someone who's been since 2012, you know, one of the most important thing are the people. Right. And this matters because you're essentially as a founder or someone who's creating a product, you're going to dedicate your entire life for your entire weeks or weekends to really build on this ecosystem. So ideally, what you want is you want people that, one, have a strong conviction and vision for the product that they're building.
00:38:53.774 - 00:39:20.286, Speaker B: You want, two, you want people that are eating their own dog food. So not just folks who are saying, we're building this. And you ask them, are you writing the code? Are you actually using the product? And you don't find that a lot. Right. And three, you want people who are going to be there as you build a product and their ecosystem. And this is what we really found. Like, when we talked to Anatoly, Raj, Tristan, who's not here, was a key person.
00:39:20.286 - 00:40:04.864, Speaker B: And Bartosz, when I talk to him, and now Jordan and Chase, you people are key. And this is what we see in these folks. In all honesty, I think I told Chase earlier, I would say that Chase is one of the top developer advocates out there, because if you go on discord, you go on Twitter, he's out there. People do matter. And so if you're a founder or looking to create a product, you'll find those key things amongst the people that are building and those that are coming also, and building Solana as a whole, as an ecosystem. Yeah, I would definitely agree with that as well. I mean, I've talked to several ecosystem teams, I guess, on different l one s, and I think the level of support that Solana gives is just way beyond anyone else.
00:40:04.864 - 00:40:27.806, Speaker B: And, yeah, really excited to be here for that reason. 100%. Yeah, well, we're kind of rounding it off here. Thank you guys for coming again. Bartosz Lipinski, Irvin. Now I'm, like, forgetting all the names that I was kind of memorizing as I was coming here. Cardenas and Dylan and ian Macleano.
00:40:27.806 - 00:40:42.074, Speaker B: So thank you guys so much for coming. It was great to have all these different perspectives up here. So. And that's it for our talk. So thank you, and we'll catch you around here.
00:40:48.234 - 00:41:17.638, Speaker A: All right, thanks, guys. One thing I picked up chase quoting about the amount of people in his DM's, 80 people in his DM's now that he's a Solana developer. So that's funny. I realized that I did not introduce myself. I am Bailey, but I didn't even say why I'm here. You guys are looking at me like, what the hell is she doing here? I'm a longtime crypto reporter, started writing about bitcoin in 2012 and have moved on to events. So I am part of the team that has helped build Solana breakpoint.
00:41:17.638 - 00:41:52.740, Speaker A: So if you all have any questions, wi fi, how to get to venues, yada yada, you can come and find me. I will be at this venue suit all day today. All right, so up next, we have the Rockstar himself, Anatoly, the CEO and founder of Solana, who also I read on the Internet, is a world class underwater hockey player. I honestly do not know what underwater hockey is. So I hope that they maybe touch on that a little bit here, but they are going to have a debate about censorship, resistance and scaling. And with him is Anthony D. Prinzio of Alio.
00:41:52.740 - 00:42:03.584, Speaker A: We don't have Greg. Ok, don't have Greg. Larry Cermak of the block. And then our moderator today is Tarun Shitra of Gauntlet. So, guys, come on up.
00:42:13.334 - 00:42:14.514, Speaker C: Oh, there, you see it.
00:42:20.294 - 00:43:24.478, Speaker B: Cool. So if any of you have followed Anatoly's Twitter from before Solana took off, you'll know that censorship resistance was one of the things he often got in fights with other people on Twitter about. And one of the reasons it's the most contentious thing, perhaps especially for newcomers who haven't seen over the last five, six years, some of the kind of things that go wrong when you don't have censorship resistance is that it can be kind of this daunting task when you kind of have to change your mindset from thinking about centralized services and developing in a centralized world. So maybe we'll start by first having each person briefly say what they kind are most interested in, why they're interested in censorship resistance, and then either provide us with their favorite metric for measuring it, or their favorite attack. So I'll start with Antoli. Oh, man. I mean, you have a long provenance on Twitter.
00:43:24.478 - 00:44:15.684, Speaker B: Yeah. So the basic theory that I have is the network is trying to reduce information entropy in the world. You're trying to synchronize all this noise into some real state that's agreed upon by the entire globe, and you're trying to do this at the speed of light. And we don't have a way to do the physics. One way I can think of is we all have neutrinos that all have a fully connected point to point network, but we don't have that. So what we can build are these BFT systems, and the way to guarantee that things are synchronized and nobody's mucking with the information flow is to maximize the Nakamoto coefficient. So that's the main metric that I think of, the minimum set of nodes that are up to 33%.
00:44:16.504 - 00:44:17.240, Speaker C: Cool.
00:44:17.392 - 00:44:17.696, Speaker B: Yeah.
00:44:17.720 - 00:44:49.786, Speaker C: So, hey, everyone. Name's Anthony Diprenzio from Alio. And I would say that when it comes to censorship resistance, the reason that I'm so interested in it has to come from a privacy perspective. So I'm a huge privacy advocate. And when we talk about scaling and censorship resistance, I think that's actually a really important topic to take into consideration. And a lot of the things we're doing at Alio are actually very much focused on that. And I guess a metric I like to look at is just one, how decentralized the network is overall, and then specifically how particular layer ones are tackling that.
00:44:49.786 - 00:45:15.334, Speaker C: I think there's many different ways in which we'll probably cover that in this discussion, but I would say that, for me, that's the first thing that I typically look at. And then again, looking at how security works as well, is it sort of like a shared security architecture? Is it coming from the layer one itself? Is it coming from a L2 solution? So I would say those things in general are what I typically look for when thinking about censorship resistance.
00:45:16.034 - 00:45:40.048, Speaker D: And I'm Larry Cermak, I lead the research at the block. For me, decentralization is. It's about two things. So first, obviously, it has to be difficult and expensive to shut down the network. And then it also has to have a good uptime. So it has to stay up. So the metrics for me is geographical dispersion, and then also ability for people.
00:45:40.048 - 00:45:47.884, Speaker D: And not just hobbies, but in general, people have the ability to run the node. Those are the two most important things for me.
00:45:48.524 - 00:46:37.184, Speaker B: Cool. And with that, scaling has kind of been on the tip of the cryptocurrency research community's tongue since basically 2015. That was the first sort of scaling bitcoin conference. We've seen a lot of improvements made to scaling, and at the same time we've seen sort of a lot of stumbling blocks where a lot of things that people thought would lead to better scaling kind of didn't. Or in, you know, theoretically they worked, but in practice, the engineering difficulties were super high. So maybe let's start with the losses. So in your minds, what were some of the biggest failures in scaling that we've seen over time, especially as we try to make them censorship resistant and maybe start again with you, Antholi, because failures.
00:46:37.184 - 00:46:41.864, Speaker B: Shoot. Why don't Larry go?
00:46:44.674 - 00:47:16.078, Speaker D: Yeah, so I think if I'm not being too specific, I think one of the bigger failures has been just complete inability to estimate how long things will take. So, like, if you look at, you know, I joined crypto full time, like 2016. Back then, people were saying, you know, shorting in two years proof of stake. Like stop mining now it makes no sense. Like you're going to lose money. And it's been, you know, it's been five years and there still hasn't been a proof of stake switch sharding, still probably two or three years away. And no one really has the ability to estimate these things well.
00:47:16.078 - 00:47:40.414, Speaker D: So I think that, to me, is the biggest failure because it kind of discouraged a lot of people that were thinking, this is going to scale soon. And now you have tens of thousands, mostly hundreds of thousands of people joining and they're looking at ethereum history and saying, why didn't this happen? Is it just broken? So from my perspective, that's the biggest failure if I'm not going to specific details like plasma and all that.
00:47:41.554 - 00:48:21.794, Speaker C: Yeah, I guess for me, I think when you're trying to inherently change something fundamental about the layer one protocol itself, sometimes you see failures there. So an example would be something like, maybe I don't want to name a specific project, but like changing the block size, for example. I think maybe we could all agree perhaps was something that wasn't as successful as maybe we would have thought. But when you're looking at least from a L2 perspective, I think there's a lot of promising solutions out there. Larry just alluded to some of them and I'm sure we'll get into a discussion about it. But I think, yeah, generally, just making that distinction between what are the changes happening on the layer one versus the L2 is important when looking at successes and failures.
00:48:22.654 - 00:49:15.578, Speaker B: Should I go? Okay, I don't want to be too spicy. I think the seat is yours. I think things that have basically not succeeded are things that are trying to scale application level TPS without getting to the core of what the network does. And that core censorship resistant piece to Nakamoto coefficient. If you don't tackle that problem and you're only working at the higher levels, you end up with a system that has a very slow bottleneck at some point or another, and that will manifest itself as a failure. You'll have those bottlenecks that constantly back up against adoption, against real world usage, against unpredictable real world usage. So that's kind of how I look at it, for sure.
00:49:15.578 - 00:49:27.142, Speaker B: That certainly comes is a spicy take in that it's the opposite of what Larry wanted, which is Larry wants everyone to run their own node, which might not be totally possible outside of the app change.
00:49:27.278 - 00:49:50.090, Speaker D: Maybe not everyone, but at least everyone has the ability to, if they have decently enough resources. I don't want anyone to have to spend like hundreds of thousands of dollars to run a node a year. I think there's a certain threshold in it. I think that's why there's so much nuance here. It's like, I don't want anyone on their phone to run nodes, but I want anyone who at least tries reasonably enough to be able to do that. And a lot of blockchains don't allow you to do that.
00:49:50.222 - 00:50:43.250, Speaker B: Aren't you happy that we're done with the 2017 pitches of validate ZK proofs on your phone? Yeah, I feel like I remember a million of those pitches. Man, what a wild. At least this time, I haven't seen anything that dumb. So, scaling inevitably comes at a cost to censorship resistance, and a lot of this gets passed. Passed on to the users, or validators, or both. And at the end, sort of the goal of improving throughput, or reducing latency, or reducing the number of interactions a user has to make kind of come at the expense of how easy it is to be a validator, and also how many validators you can actually have. Things that oftentimes can be a little bit difficult in this world.
00:50:43.250 - 00:51:45.644, Speaker B: Sort of a lack of decentralization. So to Anatoly's point, kind of Nakamoto coefficient, a lack of verifiability. There's sort of, to Larry's point, sort of this voter apathy thing, right? So in blockchains, people vote with their node, but if there's not really that many people running nodes that are adversarial, then everyone is just checking the yes box oftentimes. One thing I think that has, you know, I think has been interesting, especially in the Solana community, is sort of difficulty in indexing data and doing sort of retrospective analyses given certain constraints that have been built into the protocol. And then sort of one thing that to the end user that is quite apparent is alternative forms of sort of extractable value. More than your traditional sort of mev. Your choice of design for scalability and censorship resistance can actually introduce extra forms of extractable value.
00:51:45.644 - 00:52:49.284, Speaker B: So which costs do each of you think are sort of acceptable to place on the user versus the validator? And how do you kind of reason about that spectrum of who bears the burden? Because there's no way of getting around the fact that someone's going to bear that burden. Yeah. The way that I think about it is there's some fundamental way to measure decentralization. And I always look at the nodes, how much do they cost a year to run? That's like a measurement. And if the network charges the user of multiple that is ridiculously high, like above four x, to use that level of decentralization, then it is overpriced to a point that there should be a competitor that's just beating them at it. That's effectively, you have some margin of how much you can screw the user. And if you go beyond that, it doesn't make any sense that you just don't replace that whole thing.
00:52:49.284 - 00:53:23.754, Speaker B: If you take that into account, then the optimizations that get you to that low margin where the user fees are low enough to where the costs of the hardware are barely covered, you're effectively doing that by scaling the single node, making it faster and cheaper, because that's where you get scalability. You get cheaper access to bandwidth at a data center. You get more throughput out of more cores in a single system than a bunch of small systems, and that's where that curve maximization occurs.
00:53:25.454 - 00:54:09.934, Speaker C: Yeah, so I would echo a lot of things that anatoly just mentioned. And specifically, like with Alio, like our consensus mechanism is an offshoot of proof of work called proof of succinct work. And with that model, the general idea is to actually incentivize miners in the system to build more efficient hardware for basically mining blocks and grinding snarks in our system. I think perhaps if you start off with a system that's really heavy in terms of costs for validators and other users on the network, as long as you are trending toward a scenario where you're making it more accessible for a larger and more generalized community. I think that's actually a really good strategy. So, yeah, just to add on to maybe what anatoly mentioned, that would be another point I would want to say.
00:54:10.234 - 00:55:07.524, Speaker D: Yeah, for me, what's really important is, like you said, Tarun, verifiability. Not trusting anatoly, like what he says, and actually verifying for yourself is very, very important. And one of the issues, I think, with Solana early on, not just when it comes to verifiability, but also just data availability and being able to verify some of the things that Solana was saying was quite difficult initially, and that has improved a lot in the last six months or something, but that is very important. I would not want to make any compromises on that side. I think when it comes to decentralization, it's like such a contested thing. But in general, I think it's okay if a network starts relatively centralized or not the most decentralized, as long as there's the assumption that it will get more decentralized in the long term. And in general, I mean, we've seen it this year, a lot of people in general, either cannot kind of be able to establish what's decentralized.
00:55:07.524 - 00:55:34.444, Speaker D: It's a very difficult thing to measure, in a way, and especially for people that are joining now, a lot of retail and sophisticated people, they don't know what's decentralized and what's decentralized. So in general, as long as those people believe that it will be decentralized enough and that you will be able to perform some sort of regulatory arbitrage through enough decentralization, that I think is fine, as long as it keeps going to that goal of decentralization. So that's the most important for me.
00:55:34.784 - 00:56:25.878, Speaker B: Well, actually, maybe this brings us to another point, uh, which is, how do you present the value of censorship, resistance, or decentralization to the end user? Because I think, especially as we, we get a larger swath of users who don't care about pseudonymity, anonymity, privacy, or any of kind of the earlier goals of cryptocurrencies, you start running into a lot more difficult of a time of sort of explaining to the average person, like, why you care about this. So it depends on what they want, right? So you can have a network that is really decentralized, but it has one leader that's always coordinating, and that's fine, actually, like, if that thing goes down, if all the state is available, people will recover and continue, and that may be okay for some use cases.
00:56:26.006 - 00:56:36.256, Speaker D: But how many copies or copies of state do you need that you think that you need to be able to do that? Because a lot of people would say you need several of them to be able to then verify that that's the correct one.
00:56:36.320 - 00:57:33.326, Speaker B: So the user shouldn't pay for more copies, like 1000 x more copies than they're getting. Like me as a user, I should know, hey, I'm paying, but you as a validator, if I'm a seed in a torrent, well, there's certain number, there's a certain depth of data availability that I need, or if I'm sort of a data availability layer, there's a certain amount of error correcting code paths that I need and shares that I need. So I guess the question is back to this minor versus validator versus user spectrum. Who do you put the onus on? Because you really are kind of splitting this worst case cost between them. Well, the network needs to receive enough fees to cover its costs and plus some margin to make it interesting for validators. But beyond a forex, it's basically infeasible. You look at something like Verizon, right? They don't charge you four x the data rate, sure.
00:57:33.326 - 00:58:08.860, Speaker B: But actually, why do you anchor yourself to the number four? I'm kind of curious. It seems like there's a magical constant. You think here, if it's eight, then it's easy to look at the network and be like, okay, I can compete with that by cutting it by half. Right. To your point, if there exists existing telecom networks that don't even need four, why four? It seems like kind of a random number. Random in the sense that it's hard to get enough people together to only cut the cost by two. It's just like a capitalism problem.
00:58:08.860 - 00:58:57.184, Speaker B: I need to build another competitive network, and I'm only getting this margin. There's just some way in place where the network can extract value, but it can't grow too large. So this actually brings us to the sort of next thing I wanted to talk about, which was as we've kind of seen alternative assets increase in popularity in crypto past just defi and store value assets. We've also seen the sort of stratification of the type of user and chain, so different users will go to different chains. So users who are more price sensitive or kind of, this is their first ever usage of crypto. They're not trying to send like a million dollars to someone. They're trying to buy like a $10 ape number five.
00:58:57.184 - 01:00:00.702, Speaker B: And that's kind of like, you know, caused a huge amount of growth in polygon and solana in particular for these types of transactions. But one question is, as we enter this world where there's different qualities of service and different demands of service from different users, how do you think the definition of censorship resistance will change over time? Because clearly it's already changed since. I think at each market cycle, there's a slight deviation in what the definition of censorship resistance means to the end user. So how do you kind of see how it will change? And how do you kind of sort of see censorship resistance being demanded by users at different levels of quality of service, especially in a cross chain world where someone might say, have done $100 transaction with Solana, but they want to exit to ETH, and they're like, their mind is blown when they saw the transaction fee. Right? Yeah. Maybe you can start with Anthony.
01:00:00.838 - 01:01:01.160, Speaker C: Yeah, sure. So I think that's a really good point, and I'm a huge advocate or somebody that believes this industry is going to scale horizontally, such that you have application specific blockchains out there, kind of what Tarun was just mentioning right there. And so I think the thing to consider is that because these blockchains will be built for certain applications, like, people are going to be drawn to those specific blockchains for whatever specific application is that they're trying to build, and there's going to be trade offs with that. Right. Like when you look at these different layer ones, there's sort of this classic trilemma that people talk about, which is scalability, privacy and security, which we've been talking about, decentralization, which we've been talking about as well. And so you need to make that decision as to what am I willing to make a trade off for from the layer one based protocol perspective, out of those three things. And then once we start having these interoperable blockchains, sort of like interacting with each other, then we're going to start to see things like shared security, which I mentioned before.
01:01:01.160 - 01:01:52.284, Speaker C: So basically, like, if you have a certain way in which your protocol is operating and you're basically player one, it's actually going to be interesting to see how that impacts another blockchain, which somebody is connecting to, especially when we're talking about complex defi applications. So I guess the definition, I don't know specifically how it would be quantified in the future, but I think it would have something to do with how is your chain and its underlying principles as a protocol contributing to this shared security of the overall network. Perhaps there will be some interesting ways that people will be able to quantify that. And I actually heard a talk by a good friend of mine who was talking about something called superfluid staking between different blockchains. And when they described that concept to me, it kind of seemed interesting how some of these things might transpire in the future.
01:01:54.504 - 01:02:27.784, Speaker D: Yeah, really tough question. I think in general, I think people just are the people that are coming in right now unable to just determine what is decentralized, what isn't. So in general, I think people right now are drawn to just the opportunities. So we saw it with Solana, polygon, avalanche, all of this. You have new protocols there, but you're basically mirroring the stuff that's happening on ethereum. And a lot of these people are joining because they can't afford to trade on Ethereum or use Ethereum. And they think that there's 101,000 x opportunity in there.
01:02:27.784 - 01:03:17.072, Speaker D: And in general, they don't care how decentralized it is unless they lose money in some way. So that's kind of my view right now, is that most people that are joining right now, they just don't care and they're not going to care for a long time. What they care about is the opportunity and what they can do on a chain which they currently can't do on Ethereum. But yeah, just in general, I totally agree. I think there are different use cases that work for different blockchains based on how different people perceive them in censorship resistance. So for example, for me, if I saw that Solana was done for one day, I would probably not want to trade $1 million positions and kind of risk potentially being liquidated if the price moves too much in that time. That being said, I would happily trade NFTs on Solana because I don't really care.
01:03:17.072 - 01:03:39.008, Speaker D: That's good enough. The blockchain is secure and decentralized enough for that, at least from my perspective. And I think a lot of people will start thinking about it in that way as well. Like institutional investors, they're putting billions of dollars on the line, or hundreds of millions. They think obviously differently than the retail investors they're joining right now, the people that are starting to use fantom. So I think it's just going to.
01:03:39.016 - 01:05:12.604, Speaker B: Be very use case specific, nice little, nice little jab. And I feel like you actually disagree with both of these because you believe in the one size rules. All I think the most important thing is going to be, in some ways kind of agree with you guys is the cost to exit. Like the cost to run away and to market makers, that is the cost of a cancel message. How fast can it get out of my position? And to users, it might be, how fast can I get to an exchange or something like that, or convert to native USDC? That said, I don't know if users will attach that to censorship resistance, in the sense that I think it's very hard to build a global financial chain that connects all the exchanges, all the liquidity providers, all the stablecoin issuers without that. Because the fundamental thing that layer one provides is the security properties of running this node that each exchange, each provider runs, and the synchronization guarantees that they get that nobody's messing with their state, nobody's messing with the information they're receiving. Their security teams need to understand the properties of the system, and they need to feel secure about it, because they're actually putting real capital at risk.
01:05:12.604 - 01:05:38.550, Speaker B: There's. So if you don't have censorship resistance, it might be really, really hard to build that network. And ultimately, that's what's going to decide where users go and where they feel comfortable. So your argument is that the whales will lead. The whales care about censorship resistance. The users depend on the whales. And so because the users depend on the whales, they implicitly are second order careers of censorship resistance.
01:05:38.550 - 01:06:38.574, Speaker B: By whales, I mean applications like businesses, like things that care, right? Like, they are the biggest wallets. Also, some might call them whales, depending on. Depending how you think about it, what do you think the things that kind of these larger institutions who are evaluating, building on these things, what do you think they are evaluating about censorship resistance right now versus individual users? So, Larry, you're talking about how users are just like, hey, my friend got rich off the uni airdrop, so I want to get into quick swap and saber and whatever as one modality of user behavior. But on the other hand, on the institutional side, let's say we take the anatolian model of the trickle down censorship resistance theory. What is the minimum viable set of features that institutions need, or that you think institutions need?
01:06:41.154 - 01:07:14.910, Speaker D: Yeah, I think they just need some sort of guarantees that their money is safe if something happens. I think that's really the biggest point. Like, you know, when we talk to institutional investors in general, censorship resistance only matters to them for two reasons. One is regulatory arbitrage. So being able to somehow interact in things that they were not able to interact with before, and then second thing is like, how safe are these things? How can we evaluate these things? And it's very difficult. Like, I don't really know how to answer that. I would say probably Ethereum right now is obviously more secure, but it's hard.
01:07:14.910 - 01:07:49.044, Speaker D: It's like, how do you define that? Can you lose some money if, like I said, I don't want to take jazz, but if Solana goes down for some time, what happens? Right. Do you have guarantees that your money will still be there that's not going to be liquidated? How do you explain to those guys who are already basically struggling with simple things? Most people probably think that institutions are pretty sophisticated, but the guys that we have coming to us on the research side, they're very beginner focused right now. They don't really know how to think about these things. They pay us to tell them how to think about them, and we tell them. We don't really know.
01:07:50.704 - 01:08:49.426, Speaker B: It's hard, brutally, honestly. Panel audience, I think maybe we've been lucky that a lot of the institutionals we're dealing with are traders jump and they inherently understand risk and something like a 17 hours block time to them, they can actually model that as, okay, the liquidation engine's down because the Oracle updates are not happening. And what happens in the smart contract if that price moves by so forth? Does a smart contract actually handle that kind of difference? So there's effectively kind of ways to go deep in the finances of how the state updates work and understand it from like a mechanical perspective as a trader. And I think the killer use case of these systems is price discovery. It's trading. And those are the folks that will like get onboarded first. They'll trade, they'll make markets.
01:08:49.426 - 01:09:02.814, Speaker B: And the institutions that sit on top of that level that need liquidity, that are actually doing the big movements of money for business reasons, they will get comfortable because the market makers are there.
01:09:03.114 - 01:09:21.386, Speaker D: Yeah, actually, maybe. Quick question also for Antilles jump, obviously one of the biggest market makers in crypto, maybe the biggest right now tower as well, somehow active. How did you guys, or why do you think they're interested in Solana so much? And they're also doing a lot venture in Solana, just in general, how did you attract these guys?
01:09:21.570 - 01:10:06.442, Speaker B: It was that core idea that in theory, if we keep optimizing this thing, then the information traveling through the network is going to move at the speed of light, through fiber, and that's as fast as news can go. So things like Nasdaq that trade at sub microsecond speed, those trades are not actually happening at new news. It's just the statistical noise in the order queue. So if Solana gets at its theoretical limit. Imagine a newswire is flying from Singapore to New York. That state transition is propagating. At the same time, the trader, when they look at a market running in Solana or one at New York Stock Exchange or CME, they should see that price already reflected.
01:10:06.442 - 01:11:15.468, Speaker B: So you don't have arbitrage and real information, and the costs are the cost of hardware, and that's effectively zero. So from their perspective, this is like, okay, all the people that are charging us billions of dollars in fees for the work that we're doing, they're now disrupted. Yeah, I mean, I guess from my perspective, I guess when I was in trading, one of the things that doesn't really exist in a lot of HFT kind of environments is atomic transactions between multiple venues. So you have to maintain your best view of what multiple closed source systems are doing and then try to guess when they can actually interact with each other correctly. And a blockchain gets rid of a lot of the guesswork you do there, which can cost you billions of dollars. So I guess one, maybe more. Last thing that we kind of haven't touched on in censorship resistance is improvements in cryptography.
01:11:15.468 - 01:12:44.002, Speaker B: So if we think about the last cycle in 2017, a lot of people were really promising a ton of huge improvements on cryptography, both on the zero knowledge proof side as well as in sort of like other forms of NPC, all sorts of things that should, in theory, allow you to make weaker assumptions in your blockchain in other ways, like weaker consensus protocols, faster latencies, whatever. But the cryptography would make sure that you would be able to have a high level of censorship resistance. We've seen some of that come to fruition. So we had sort of amours law in snarks during the bear market. So I think for those of you who know gross 16 from gross 16 until sort of like basically the stark paper in 2018, we saw this pretty much exponential curve since then. It's kind of flattened a lot, but a lot of these kind of dreamlike cryptographic instructions that would really dramatically enhance censorship resistance in the sense that there was a great quote I saw from a talk recently, which is zero knowledge proofs let you reduce your model, your sort of model of your adversary from malicious to honest, but curious. And so we haven't quite hit that point yet.
01:12:44.002 - 01:13:10.774, Speaker B: But if we do hit that point, I think there's a lot of work that we will reach on validator diversity and kind of being able to kind of reduce state of these networks, make cross chain stuff easier. So how do you view the impact of cryptographic improvements versus sort of engineering improvements over time. And, like, what types of new censorship resistant applications will that enable?
01:13:11.914 - 01:14:11.092, Speaker C: Yeah, so I think this is a really interesting question, and one of the things I would say is that when thinking about this topic, essentially, I think like a term, at least, that we used earlier, and I think a lot of other projects are looking towards, is building systems that are private by default. So basically allowing users to selectively reveal information that they want to about a given transaction. And I think that's super powerful. So I know, like, tarun, I think we were talking before this about, like, vanity addresses, right? Like, it's interesting to think about that as a concept, because you're basically adding some sort of human readable element to an address, which I guess implies lack of privacy, unlike layer ones. But if you can come up with certain solutions, that, for example, everything we do at Alio is actually, interesting fact here. So Alio actually stands for autonomous ledger executions off chain. You're the first all here.
01:14:11.092 - 01:14:41.726, Speaker C: This is not published anywhere. Basically everything we do is off chain. So we're generating these zero knowledge proofs off chain, bring them on chain with this type of construction. Even if you have a vanity address, because we're private by default, you can actually. I can send your vanity address, and you can spend from it, and you don't actually have to reveal that vanity if you don't want to. So maybe there's a specific reason why you wouldn't want to do that. Maybe it has to do with a particular financial transaction, that you don't want to reveal certain information, but again, you can do that.
01:14:41.726 - 01:15:02.562, Speaker C: So I think moving forward, once we see more of these kinds of cryptographic techniques allowing you to do these sorts of things, we'll see much larger scale adoption. And I guess one specific area that I'm really interested in is. So everybody knows about DeFi. So I think z fi, like, zero knowledge finance is going to be something really interesting.
01:15:02.738 - 01:15:05.650, Speaker B: First time I've ever heard that, and I've written papers on this.
01:15:05.842 - 01:15:36.400, Speaker C: So, yeah, I think there's a lot of interesting things going on. But definitely being able to bring some of these privacy preserving primitives to existing things like DeFi, I think, can lead to a host of really interesting applications, given that you can also maintain composability, which I think is really important as well, because that was one of the big takeaways, I think, that we got from Defi summer and what's been going on in the space right now. So, yeah, generally, I think those are some of the interesting updates I'm looking forward to, at least from a cryptographic perspective.
01:15:36.592 - 01:16:35.198, Speaker B: I'm bullish on zero knowledge, privacy preserving finance, but not on ZKP's improving scalability to the level that you should see a reduction in user fees compared to the amount of decentralization that's provided. So simply because if you start just the engineering optimizations and you start getting to those limits, 400 milliseconds is pretty slow, but it's pretty fast. And there's no place for us to stuff a ZKP because the prover times are going to push the network into a slower state and therefore increase the cost of the users, like in the worst case. And those limits are just easier to solve with cores and bandwidth. Like you actually end up with a. But there could be asics that are built that are, that get. I think that to me is like the biggest investment opportunity in the space that has been untapped is basically asics for this stuff.
01:16:35.198 - 01:16:55.994, Speaker B: But yeah, to your point, the current implementations are quite poor. They're great. I mean like massive amounts of investment and like innovation happened over the last five years, but it's still pretty far from guaranteeing that like real time censorship resistance, that's still just bandwidth and packets.
01:16:57.374 - 01:17:33.854, Speaker D: I think that most of the privacy will have to happen in l two s is my opinion. I think like if all that is happening in l one, I'm very skeptical, not just from the regulatory reasons. We've seen how much governments and in general exchanges have been delisting Monero, sometimes even zcash, because they're scared of being able to, I guess, compliant with some of the regulations. And I personally think that most of this will just go into privacy first ZK roll ups on these solutions. At least that's my opinion, just from a practicality perspective.
01:17:34.274 - 01:17:38.082, Speaker B: Anthony, do you want to rebut? I feel like you got too.
01:17:38.218 - 01:17:43.290, Speaker C: Yeah, I was going to say, could you elaborate on why you think privacy should only be handled on L2?
01:17:43.322 - 01:17:52.974, Speaker D: Because I, I don't think it should. I just think it's like very impractical. It's impractical from a regular regulatory perspective. So like, why is Monero being delisted on most exchanges right now?
01:17:54.794 - 01:17:59.224, Speaker C: I guess because of. Yeah, because it's private, right? Yeah, like you can.
01:17:59.644 - 01:18:02.784, Speaker B: What is an l two though? Like is it just like a Merkle route?
01:18:03.404 - 01:18:08.860, Speaker D: Yeah, like a. Yeah, private ZK roll up. Like something like aztec or some of these solutions.
01:18:08.972 - 01:19:04.424, Speaker B: Yeah, I think it's a verifier on another chain that can verify both the Merkle route and the commitments without actually having the data present. Right. So it needs to be a verifier that can be run remotely on another virtual machine that has a different interface. That's roughly the minimum definition, minimum viable definition for it. But I kind of agree with Larry a lot on this, which is like, layer ones to some extent are going to have a really hard time being the dominant player right now until we get to a world where cross chain communication is so good that people don't go to exchanges as much. And once there's actually bridges, then private layer ones are probably going to be able to succeed to some extent. But I think having to go through exchanges just makes it quite arduous for sure.
01:19:04.424 - 01:19:48.204, Speaker B: All right, so we got three minutes left. Let's go through your takeaways. Where do you guys think we're going in 2022 in terms of both censorship resistant technology as well as sort of some of the new applications, whether it's in Defi NFT privacy. And so, yeah, maybe start with, like, what area you think is the most interesting, and then which one you think will have the biggest. And I will go last. I think we'll probably see that it's easier to upgrade validator hardware than it is to write new software. All right, the colo model.
01:19:49.224 - 01:20:17.424, Speaker C: Yeah, I guess I'll stick with like, the privacy perspective. I think that's going to be a huge focus area for people moving forward, I think. Yeah, once people. I think the biggest thing is just being able to educate people on, like, what applications they would actually care to have privacy for. Because I actually get in this debate all the time is like, why do people even really care about privacy and to what extent? But I think once we start to see some of these more specific applications where it makes sense, that'll certainly be an area of interest.
01:20:19.724 - 01:20:52.030, Speaker D: Yeah, I'm optimistic about ZK rollups just becoming much more used, widely used. I think Zksync and Starknet are probably closer than people think, and because they're now thinking it's a year away. A year away? Year away. I think probably in six months we're going to see some relatively meaningful adoption for ZK rollups. And I think a lot of people are underestimating that. And we've seen pretty disappointing traction so far with the optimistic roll ups. So there just isn't that much interest in DeFi on Ethereum right now.
01:20:52.030 - 01:21:14.084, Speaker D: And I think probably like Q one, Q two next year. I would guess that would change pretty significantly. I think privacy will be huge as well. But I think it's going to be slightly later. I would guess end of next year or the year after. I think it's going to be slower just because it takes a long time for people to adopt something and then get used to it and then start using something private. I think it's still going to take time, but I 100% agree.
01:21:14.084 - 01:21:26.820, Speaker D: Privacy is one of the biggest reasons why I'm here as well. It's absolutely essential for people to be able to interact privately without leaving all this information on chain that's then traceable by anyone.
01:21:26.932 - 01:21:43.684, Speaker C: Yeah, maybe just add on to that really quickly. So I think the other piece to consider is plausible deniability as well. So I think, yeah, just I want to give Tarun some time as well. But I think, yeah, that's something else to consider when we're talking about, like, the privacy question, why it'll be so important moving forward.
01:21:44.504 - 01:22:26.832, Speaker B: You look like you want to add something. No, no. Anything that's a year away is effectively like an unknown, unknown timeline, engineering estimates, and go beyond two weeks. So I guess the. The two things I guess I'm most interested in is so Anatoly's whale trickle down thesis I actually agree with for privacy, which is, I think daos that have large treasuries are the number one consumers of privacy preserving technology because they have to interact on chain. And I have been involved in some large art Dao transactions where we would have loved to have privacy. So with that, that's the end of our panel.
01:22:26.832 - 01:22:27.448, Speaker B: Thank you.
01:22:27.536 - 01:22:27.944, Speaker E: Thank you.
01:22:27.984 - 01:22:28.684, Speaker C: Thank you.
01:22:33.104 - 01:22:33.928, Speaker A: Awesome.
01:22:34.096 - 01:22:34.424, Speaker B: Cool.
01:22:34.464 - 01:22:46.204, Speaker A: Thank you so much, guys. It is time to start our developer workshops. So get out your laptops. It is time for that. I see people getting up. That's not what you're supposed to be doing. Get out your laptops.
01:22:46.204 - 01:22:59.964, Speaker A: All right, so our first one, we had one cancel. COVID is weird, but our first one is going to be Marius with the Hubble protocol, and he's going to be talking about maintaining global state on Solana. So, Marius, come on up.
01:23:13.704 - 01:23:29.924, Speaker B: Hi, guys. Hi, everyone. I'm gonna let people settle down for a bit. So my name is Maris. Let me just check how this works. Okay. My name is Maris.
01:23:29.924 - 01:24:02.766, Speaker B: I work for Hubble protocol. We're building a stablecoin in Solana. Cross collateralized, yield bearing stablecoin. And we've been facing a lot of challenges building the stablecoin, building the protocol, and basically today I'm here to talk to you about our. Our journey and how we thought about scaling and the issues we encountered and the lessons we've learned. So, yeah, so about me, just a little bit. I've been working, before going to Defi to crypto full time.
01:24:02.766 - 01:24:40.724, Speaker B: I was working at Bloomberg for about eight years. I was building derivative pricing systems. I was writing c o Kaml, and that led me to learn and love rust. And recently I've been working at Hubble and building the stablecoin. So if we think about the situation where we're in right now, or what we've been seeing for the past year, is that we have this new chain, Solana, which can actually finally scale. You have something, you have the opportunity to build something for the entire world. You have real people that can use it without paying a lot of fees.
01:24:40.724 - 01:25:29.150, Speaker B: Ux is great, it's censorship resistant, so they don't worry about it. And you can finally, if you can, onboard 1 million people, you need to start raising to the challenge and see what can we actually build for them. And of course, Solana allows this to happen, but it comes with constraints. So there are two main major concerns, two major constraints we faced when building Hubble. One is the account model, the way you store state, and the other one is the compute budget. If you've written code for Solana, you've seen that it's the first three weeks, you go into a deep depression about how to write code for Solana. It's like everything is very weird, and then you start getting it, and then you start thinking different solutions, and then you hit compute budget exceeded.
01:25:29.150 - 01:26:18.462, Speaker B: And then you're like, what am I doing? This is all annoying, and I need to find a way around it. And you eventually find your way around it. It's just like you emerge from the depths of Solana, and then you start thinking about scaling, and then you have the breakthrough, essentially. So I'm going to talk about both of them and how we think about it and what solutions you can consider. So, to put everything in context, let's just consider this simple instruction, obviously a DeFi application. You have a borrower which deposits all and takes a loan in dollars, and it's over collateralized because we still haven't solved necessarily the under collateralization issue. But you just hold that data, and then there is an instruction called tri liquidate.
01:26:18.462 - 01:27:03.000, Speaker B: And if the deposit amount is below the collateral ratio, then you liquidate the liquidator, pays the debt and then receives back the collateral. And if you do it at a higher collateral ratio, then you, you make some gain and then you keep the system healthy. So if we look here, we have two CPI calls at the top CPI transfer for two of them, and then you have state update, you update the user balance and the user's collateral. So this is nice. And it's like the hello world of. And it's just everything is beautiful. But then you start thinking, how do I scale? Like, how do I make this work for a million users? And why should I even think about this at the beginning, everything, if it works for two users, maybe it already works for a million.
01:27:03.000 - 01:27:33.814, Speaker B: But maybe you have, when you have a complex system, you have weird interactions that you can't foresee ahead of time. So you actually need to start thinking about testing, stress testing and so on. And as you scale for users, you actually scale with the complexity of the project. You add metadata, you add different collateral ratios for different tokens within your user. You can start adding yield, you can start adding strategies, and then things become more complex. So you need to start adding more data. So you need to scale horizontally, and then you need to scale vertically for users and for data.
01:27:33.814 - 01:28:03.074, Speaker B: And then you deploy, and then you have the MVP. But anything, how do I deploy in Mainnet? What issues can I have? And on Mainnet, it's pretty scary to change things because you deal with people's money. You're not doing something that you're doing something that is quite sensitive, bugs. So that's one concern. And the second concern is that you want to scale. You don't want to do migrations. If everyone has done ever database migrations before, I know you haven't had a good time, so you want to kind of avoid this.
01:28:03.074 - 01:28:53.484, Speaker B: So these are the things that I've been thinking about for scaling Hubble. And now if you think you have basically two fixed constraints, you have state account sizes, or the fact that you have to declare them up front is that this is one constraint. Compute budget is another constraint. The only degree of freedom you have is actually the way you design your state. Like, how do you maintain state? How do you save it across instructions, and how do you reason about it, basically. And there are a few common patterns people have tried out, padding, of course, to protect from future behavior, pagination, queuing and splitting your instructions across transactions, and basically off chain processes like bots or cranks. So these are the four things I'm going to talk about.
01:28:53.484 - 01:29:10.024, Speaker B: So if we look here, for example, the easiest thing is like, I have a borrower. I want to scale for a lot of users. I can allocate, let's say, ten megabytes. That's already expensive. First of all, it's like seven days old, it's already 15k. Declare up front, maybe two months ago. That was nice.
01:29:10.024 - 01:29:33.764, Speaker B: But that's like soul is growing. You want to be smart about how much you pay for rental, but it's obvious to think like this. You have an array, everything is great to want to scale to more users. You start adding pagination, you paginate and then every user belongs to a page. And then as you grow, you start scaling like that. And you see that, you notice the padding part in the borrower. You save like 1000 bytes.
01:29:33.764 - 01:30:06.810, Speaker B: Those are bytes you pay upfront for users you don't have yet. And also the user doesn't pay for it. You pay for it and it's a lot of an upfront cost which you don't want to if you're just starting, you know, maybe you don't have it. So it's a solution to maybe not a very thoughtful design. So yeah, the problem is you pay a lot upfront, but this is, for example, this is how you would scale. You have some bytes, you add more types to it and then you decrease the padding. And this, this is how you can scale.
01:30:06.810 - 01:30:35.410, Speaker B: But still you have the user positions array, which is fixed and you encounter the issue. So the solution is pretty much don't use arrays. You pay a lot upfront and then you have problem scaling. That doesn't mean that arrays are all bad by themselves. Arrays can be useful if they don't scale linearly with the users, but they represent some sort of queue. So for example, if you want to, you can use an array. Sorry.
01:30:35.410 - 01:31:10.410, Speaker B: The benefit for using array in this case is that you can iterate to a lot of users at the same time. You can actually loop through all the users or as much compute budget as you have, mark them as mark for liquidation, and then proceed an instruction after. So that's one cool thing you can do and we can reason about it a bit later. The better solution is don't use array at all, indexed by account type, but you still keep padding. You know, you kind of get the best of both worlds. You keep some padding, you pre allocate a little bit, but you operate on user accounts only. No raise.
01:31:10.410 - 01:32:01.698, Speaker B: So the user pays. You grow when the users are being acquired and you don't have to stress that you reach the account limit and you won't be able to add new users. This is how, for example, then let's say you run out of padding. You can create a borrower v two that contains new metadata, and you create a liquidate function v two. That takes the new user type, and then maybe you can convert that user to the old user to the new user, and every new user comes with a new type, and then you migrate on the fly so you might get away with it. I promised I would get back to kind of how user a. So we have a process in our protocol called redemptions, which means we need to process a lot of users at the same time, sort them and do something with their collateral.
01:32:01.698 - 01:32:41.916, Speaker B: And of course, because you can't loop over it, because compute budget is expensive and you don't want to rely on an off chain bot like a permissioned off chain bot, because it's a single point of failure. You can actually create a queue, you can fill the queue. Another bot can clear the queue once everything's done once like the requested amount and remaining amount. If they're still different, you can start the process all over again. So you can use the queue just to like a buffer, for example. This is a great way to use the queues, and serum are using queues and it's a good primitive. So now this is how I reason about state how you should grow.
01:32:41.916 - 01:33:10.204, Speaker B: You should grow linearly. You shouldn't have arrays. If you use arrays, use them for queues. Now the question, the other challenge is compute budget. If you've encountered the 200,000 compute budget limit, you've always think, how can I optimize it? You try to optimize it, make less clones, but then eventually you still can't scale, you still have a fixed budget. And that's just no matter how complex, no matter how smart you are, you're still going to hit that limit. So the solution becomes split like make it like a state machine.
01:33:10.204 - 01:33:43.934, Speaker B: You can choose a user. If the user can be liquidated based on collateral ratio, then you can update the status as marked for liquidation. And then you have another bot running it later and processing the order. And doing this allows you to scale. You can do very small transactions and fast, and you're not worried about blowing out of compute budget. But this requires having an off chain bot finish the processing. The bot will, will see are there any accounts marked for liquidation? They will loop on like a cloud somewhere.
01:33:43.934 - 01:34:17.706, Speaker B: And if it is, they're going to do a transfer and then update the state. And you can do it, you can parallelize it. If you don't have overlapping global state, you can parallelize it and you have a lot of room to play around with that. And then as you grow, as you need more and more complex operations, if your protocol is not necessarily simple, you need to add. It becomes more complex. You add liquidation, add order, fill order, clear order, and then it starts being more and more involved, and you rely on a lot of off chain computation. And that's fine if you can manage it.
01:34:17.706 - 01:34:54.784, Speaker B: Like off chain computation is not that expensive. You can have some sort of like a mirror or a shadow library that can see, can track the global state off chain, and then execute whenever something is needed. But you need to incentivize these bots to actually do the processing, because if they don't do it, if you're the only one running it, then you're the single point of failure. Being the single point of failure is a danger to the protocol. Maybe whatever your machine or your cloud, you forgot to pay the bills on AWS and they shut you down, and then your protocol is not moving forward. So you want to incentivize people to actually run the bus themselves. You want them to compete on speed.
01:34:54.784 - 01:35:55.104, Speaker B: The first one transaction gets the fee, so there's a healthy competition, and your protocol is stable. But as you add these things, your protocol grows more and more complex. So let's say someone added a liquidation order. The user is not quite yet processed, is marked as liquidatable, and then the user wants to do something after that. In that case, the problem is that the user is marked for liquidation, that maybe the data is not yet, the collateral is not yet moved, and that's fine, you can manage it, but you have to add more logic inside your original instructions to say, is the user active? Can I use it? Can I process it? And this basically means you're adding more and more complexity. The cost of the idea is that if you have some constraints in Solana, you engineer a way around it by adding complexity. And this complexity needs to be managed if you want to add further instruction, if you want to enhance the protocol.
01:35:55.104 - 01:36:52.542, Speaker B: So as you add scale and complexity, you need testing essentially becomes, I know people have different feelings about testing, but becomes absolutely essential because complexity means that you can break something later on when you're trying to do something else. And then because of that, you need to lock behavior and have test coverage, and you need to make sure that everything works fine. And typically people do testing the obvious way. You write like you deploy it on the local validator, compile, deploy, write the typescript, test, run typescript, test, assert balances, or assert that state is okay, and then you know that you've implemented right or wrong, and there's a problem with that. There's like the feedback loop is crazy. Like you wait so long for something to run, you spend, spend time doing the setup, spend time doing RPC calls, and then only later you find out if you did it right. And if you do it for two, three users, maybe you can get away with 1 minute.
01:36:52.542 - 01:37:15.964, Speaker B: But if you do it for 1000 years, it just becomes prohibitive. And when you're doing that integration test, you're testing a lot of things. You're testing that the validator works, you're testing that RPC calls work, you're testing that token transfer works. These are primitives that already work. Solana's job to make sure that it works. It's your job to make sure that the smart contract logic works. So you shouldn't be testing all of these things.
01:37:15.964 - 01:37:52.634, Speaker B: And it becomes difficult to write tests. And people don't like writing tests if they're annoying to write, so they will avoid writing tests. They will be like, yeah, if it compiles, it works. So it's not a great solution. So you need to find a way around it. And the way we thought about it about solving this complexity problem and testing problem is how do you reason about your program? So if you think about how your function actually looks, you're doing two things. You're modifying the state, you're updating the state, you're mutating the state, and then you do some side effects like token operations, CPI calls, this is pretty much what all instructions look like.
01:37:52.634 - 01:38:58.474, Speaker B: So if we look, one way of us designing it is we encapsulate the state mutation inside the single function and outside of that function we run the side effects. The token transfer and the result of the encapsulated function are the effects that you need to run on the chain itself. So in this case, triliquidate will mutate, the user will mutate the market global state, and it will tell me that I need to do some USD transfer and some sole transfer. And I don't need to test the CPI transfer function because I know it works. I've tested it many times and I know that it will transfer this exact amount of dollars that I've told it to do. So then it's like writing an, it's like separating the concerns only, you only care about the top function. So now, because you can do this, you can split it like this, you can take the effects, you can, you can think about, you can think about your, your instruction is what, what should my instruction do? What are the side effects of my instruction? And what are the mutations of my instruction? Instruction is to perform.
01:38:58.474 - 01:39:33.814, Speaker B: What do I want to test? What am I actually doing in this instruction? So this encapsulation separates the state mutation from the side effects. I know functional people will call this blasphemy. Not everything is a side effect here. The statement itself is a side effect. If clones and copies would not be expensive, you would get the user account and the market account as a side effect of the computation, and then you'll reassign it. But because you want to save computing, it's, you actually do the mutation inside the function. That's the compromise we reached.
01:39:33.814 - 01:39:53.920, Speaker B: So then you can basically test 4 million users inside rust. Testing in rust is right there, front and center. You just slap an annotation on top of the function. It becomes a test. You don't need to build a new binary, you don't need to create a new makefile. It just works. Just do cargo test and it just works.
01:39:53.920 - 01:40:14.204, Speaker B: And it's extremely fast. It's blazingly fast. It doesn't run on BPF, it actually runs on your machine, and you should take advantage of that. Rust brings new tools to the smart contract problem. So you can literally take advantage of this. That's the cool part. You have so many property based test libraries, you have so many benchmark tests.
01:40:14.204 - 01:40:47.324, Speaker B: You can profile, you can do a lot of things. And in this case, I can create a million users. I can run liquidation effects over, I can fold over them, like, let's say, in a functional way. I can accumulate the results and then assert that the results that are what I was expecting and these effects would be actually what the CPI call would do. So if you've designed your state well, then you don't have to write integration tests for a million users. You can actually write an integration test inside rust, like a user unit test. That's kind of our way to think about it.
01:40:47.324 - 01:41:19.076, Speaker B: And this unlocks a few cool things about designing your program. You can test the scale, you can do property basis, you can do fuzzing all of them inside rust. You can take advantage of the rust ecosystem to test your smart contract. It runs in the blink of an eye. If you want to, I challenge you to build a million users for your protocol. Tell me how long that takes and I'll write it in rust and see how long that takes. And the other cool thing is that you can, you know, because you have to go around the engineering problems to write your smart contract.
01:41:19.076 - 01:41:53.500, Speaker B: And if you do a lot of complexity in rust, you can actually write the lazy implementation. I wrote one part of our protocol in like 20 lines of code, because I can do a massive for loop. I can have a hash map, I can have a lot of things. And I just test that implementation with the rust implementation, because the last unit tests are complete, they match what the side effects would be. So I can test those two implementations against each other and assert correctness. And you have more confidence in the correctness of your program. And ultimately, of course, you can copy three lines of code, do cargo test, and it just works.
01:41:53.500 - 01:42:18.752, Speaker B: The feedback loop is much faster. It's going to be much easier to write, to do TDD. Yeah, so this is the. This is what I was trying to. Basically what we've learned from building Hubble, how you deal with state and how you deal with time complexity. Don't use arrays, use queues. Arrays make sense for queues.
01:42:18.752 - 01:42:50.452, Speaker B: In Solana, if an instruction is too much, split it. Create a state machine where multiple bots will turn the crank and push the state forward to the end state. Separate your concerns, your side effects from the mutations, and try to test the mutations themselves. And, yeah, stress test, because you don't want to test in production, you kind of want to test in development, basically, I guess. Yeah, that will be it. We're building Hubble. It's a new stable coin in Solana.
01:42:50.452 - 01:43:03.616, Speaker B: We're going to launch in December, so we're looking for devs. So if you want to write rust, come talk to me. Thank you. Awesome.
01:43:03.680 - 01:43:31.034, Speaker A: Thank you so much, Marius. Ok, now it's time for a break. I'm just going to give everybody a little synopsis of what's going on. You can go upstairs. There's a really great view. This is one of the best developer venues I've ever been in, so go take advantage of that because we had a cancellation. Our break's a bit longer, but during that break, we're gonna have rocket hub Liz Boa come up on stage here, and they're gonna talk about the co working spaces and nice coffee shops and where you should work in Lisbon.
01:43:31.034 - 01:43:53.994, Speaker A: If you're planning on extending your stay after this conference or want to come live here, they'll talk about that as well. And then the next developer series of workshops is all about the Solana user experience. And that'll start at 150. But we have food out there for you. We know you guys haven't seen each other in a long time, so go talk to each other and be friendly. Okay, thanks. See you later.
01:43:53.994 - 01:44:58.004, Speaker A: All right. Hey, there. Sorry, she's just. We're going to have a quick smoke break and then she's going to come up here and start the presentation. We are now going to have rocket hub Liz Boa present. They're going to talk about where you can work throughout Lisbon. So if you're here for an extended stay past the conference, or if you are planning to maybe move here, because Lisbon is really great and they have awesome crypto tax laws.
01:44:58.004 - 01:45:55.084, Speaker A: So she's going to come up here and present, give you some options for where you can work. And we're also piping it upstairs, so if you're grabbing lunch, you will be able to hear it up there. So. All right. Thank you very much. Thank you. Allah Tsuch Benvin Zulieshboa it is a pleasure to welcome you to my beautiful city of Lisbon.
01:45:55.084 - 01:46:53.464, Speaker A: I was born and brought up in Portugal, and let me tell you that in the last few years we quite transformed ourselves. Don't get me wrong, we are still very proud of our bread, our wine, our olive oils and our delicious pastel ze natto. But tech in Portugal has been growing at an exponential rate in the last ten years. We managed to capture high qualified talent, and that too at a very competitive cost. In general, most portuguese founders are highly qualified, with the majority holding at least one master's degree. We are also quite good in English, at least compared to our neighbors Spain and also Italy and France. However, the whole ecosystem is still in an early phase.
01:46:53.464 - 01:48:24.326, Speaker A: When analyzed, there are actually very few portuguese founders that have turned into angel investors, and that's because up until now, very few of them got exited plans. The domestic VC capacity went through a period of great scarcity in the 2015 to 16, but this has improved from the late 2019. International VC's, including our nearby spanish investors, are taking a higher interest in the ecosystem because the recent success of Farfetch'd, Talkdesk, outsystems and Feedzai are very much our pride. They are our unicorns. But these international investors and VC's account for only 35% of seed and pre seed rounds. The entire VC industry in Portugal is growing, but is still very small, and that's why we decided to create Silverace Ventures to mainly capture the opportunity at a high speed rate. In 2016, Silverace saw an opportunity in its real estate portfolio by reinvesting and reinventing the workspace solutions and by building a coworking concept with flexible integrations with office solutions.
01:48:24.326 - 01:49:09.808, Speaker A: Silverace Ventures created Rocket Hub, the perfect fit for small teams growing at a fast pace. Rocket Hub, a co working space in Lisbon, has come as a need in the market for young teams that are solely focused in their growth and in doing things faster. Rocket Hub does not only provide workspace solutions and flexible offices, but it also does corporate events and meetups. We're actually doing quite a few of the meetups of the crypto people. We also provide virtual offices. Our virtual offices is basically a p o box that you can use to register your company. And it's quite easy.
01:49:09.808 - 01:50:13.668, Speaker A: You don't even have to use the rocket hub facilities. After we reinvented the physical workspace, we then created a digital one, a virtual office. The virtual office puts together a move to Portugal setup and package that allows international teams to relocate in a smooth and an easy way. Our move to Portugal service will guide you through incentive programs provided by the government and startup incentives, easy online processes to open and register companies, and also resident permits. Are you still not convinced? Well, we don't have imposed taxes on crypto gains as well, unless you are a full time trader. This is normally when I stop and do a QA, but because of the limited time, you can find my email right there. And if you have any questions to move to Portugal and to bring your company to Portugal, hit me up.
01:50:13.668 - 01:52:19.616, Speaker A: Me and my team will sure help you out. Let me before we start talking about the other coworking solutions in Portugal, let me show you the rocket. Rocket Hub was and continues to be home to the most creative teams that are focused on innovation. We remember when we incubated Glovu, a spanish delivery company that started in Portugal with just one member in 2017. Today they have raised close to a billion in valuation and we are very proud to tell that Glovu started these operations in Portugal with the rocket hub. Also, just last month we proudly brought Alshaya Group, major retailer in the Middle east region. And we are proudly also that they are calling Rocket Hub their home.
01:52:19.616 - 01:52:51.348, Speaker A: And they have now started with a team of 40 developers. And we're just keeping. We just keep growing. There's also other coworking space solutions in Lisbon. You can find multiple workspace solutions that provide you just that, a workplace for you to work. So quite a few places like that. If you want to have a note, it's Ideahub LX factory as well.
01:52:51.348 - 01:53:38.020, Speaker A: As you can see, we have major events happening in LX factory. We also have spaces, which is basically a new concept created by regos. The location is amazing. It's in a building in the middle of the city center, but it's also just that. It's just a workspace. What is our plan now? We want to switch, in our view, the way VC's are financially structured and alongside with our concept of shared coworking spaces and our incubation methods, the switch to blockchain makes sense. The aim is to move the entire structure and the operation of silverace ventures to blockchain and switch from what we once considered a normal standard by integrating squads.
01:53:38.020 - 01:54:16.934, Speaker A: A DaO generator on Solana, which is an interface that combines a treasury, an on chain voting and a chat, will be closer in capturing more productive teams. Squads plans to be super user friendly and its interface will surely help us towards taking closer steps towards the switch. Our aim is to bring together our community and our ecosystem in Portugal in a trustless environment that aims to be the go to fund to all things Portugal. This, I believe, will be the major switch in the path of Lisbon becoming the european major hub. Thank you very much.
01:54:18.524 - 01:54:19.264, Speaker B: It.
01:54:49.524 - 01:55:00.452, Speaker A: All right. Hello, everyone. We are back. We've got a bunch of developer workshops coming at you. One panel. I'm going to hand it over to Chase to do the rest of the emceeing. I know, that's really sad.
01:55:00.452 - 01:55:22.342, Speaker A: I will be around though, so if anybody wants to talk to me, I do have one announcement that I want to make. There is a concurrent developer workshop happening upstairs, so Neodym is presenting on their EVM for Solana, and that'll happen at 02:00 p.m. So if you want to do that one, that'll be an hour long. Upstairs they've got mics just like this. Otherwise, chase, hand it over to you for the rest of the day.
01:55:22.438 - 01:55:38.874, Speaker B: All right, guys, how's it going? I'm going to be emceeing for the rest of the day and up right now we have a talk on the Solana user experience. With us, we have slope finance, project serum, drift labs, and foresight. So come on down, guys.
01:55:54.524 - 01:56:18.524, Speaker A: Hello, everyone. My name is Maria Phillips. I'm the head of communications with Slope Finance. The topic today we're talking about is the Solana user experience, which is extremely important to slope finance and where we are in the market. But if I could start by asking each of you to introduce yourselves one by one, tell me who you are, where you're from, and what your project's doing.
01:56:18.644 - 01:56:38.344, Speaker B: Yeah, sure. I'm Edward. I do business development for. I'm a senior advisor for project serum, helping them with the business development front. Before this, I did a bit of travels in the Hong Kong exchanges and clearing, and their strategy team for that bit of investment banking. So made the migration over to the blockchain and haven't looked back since.
01:56:38.804 - 01:56:40.268, Speaker A: Awesome. Tom.
01:56:40.356 - 01:57:15.282, Speaker B: Yeah, my name is Tom. Before I started on Solana, I was working with Spelunk home for a few years, and primarily as a front end dev. I do full stack for foresight. And what we're building is we wanted to build a new type of form of governance completely, and we kind of thought a prediction market would be the best way to do it. We're building a prediction market first, but it's really what we're really after is like, trying to redefine how governance works everywhere. So that's awesome.
01:57:15.338 - 01:57:16.134, Speaker A: Very good.
01:57:16.674 - 01:57:35.134, Speaker B: Hey, I'm Chris. I'm the engineering lead for drift labs. We're building a decentralized derivatives exchange on Solana, and our goal is to basically build a centralized trading experience on chain with all the benefits of censorship, resistance on custodial, et cetera, et cetera.
01:57:35.274 - 01:57:45.918, Speaker A: Very, very good. Okay, so I thought we'd start with really just looking at Solana and saying, why Solana? Why now? Why did you make the choice to work with Solana? Ed, do you want to go first?
01:57:46.046 - 01:58:24.474, Speaker B: Yeah, sure. So I joined the serum project, you know, kind of in the middle. But when serum first started, that was kind of the beginning of this huge movement for Solana, and we needed certain primitives in the ecosystem. One of those primitives was a fully on chain, you know, central limit order book. This has been something that people building in Ethereum dreamed of and wanted to build, but they couldn't quite due to issues with throughput and scalability. And that kind of led to the invention of the AMm model by Vitalik in 2015. And then I think the way I kind of view the history is people have tried L2 solutions, or they sort of put the order book back on the shelf.
01:58:24.474 - 01:59:04.904, Speaker B: But with Sam and his team from FTX and Alameda, they revisited things from first principles. They saw what Solano's doing, what Solano's capable of, and they thought, well, if we want DeFi to become huge and not just some hobby horse project, what do we need? Where are some of the primitives that absolutely have to be there? And one of them would be, for the first time, this on chain order book and matching engine architecture. So a lot of people in the CRM teams sort of saw this opportunity in Solana, and they sort of went for it, built this out into building the ecosystem on top of it, a whole ecosystem that can make use of this liquidity infrastructure and matching service that CIRM provides. So that's kind of the story from the cirm perspective.
01:59:05.964 - 01:59:06.904, Speaker A: And Chris.
01:59:07.604 - 01:59:56.428, Speaker B: Yeah. So we saw Defi becoming pretty popular last year, and there was an absence of derivatives, and I think arguably, up until Solana comes onto the scene, it's very hard to build derivatives on l one just because of the cost and the speed. As arbitrage is, you're interacting on chain constantly. And so we saw with Solana, with the speed and the cost, both for retail users, we could build a great trading experience with a GUI as well as arbitrage. To actually be able to interact on chain and do all that arbitraging that's necessary. And then by being on the l one, we can actually keep defi composability, which is actually breaking arguably across all these l two s in sharding. So we were just really bullish on seed time in Solana.
01:59:56.596 - 01:59:59.244, Speaker A: Awesome. And that brings me to Tom, then, on the UI side.
01:59:59.364 - 01:59:59.732, Speaker C: Yeah.
01:59:59.788 - 02:00:42.474, Speaker B: So I think in Solana there's an opportunity to build really cool things that have never been done before. And that's kind of like, one thing we always strive to do at foresight is to always build something that's great for the ecosystem, and it's trying to always push the boundaries, and all of our projects reflect that. The primary reason why I got into Solana was the first hackathon. It just seemed kind of fun, and it was kind of really addicting to coding, to code in it, because there was no docs, and you would always get a dopamine spike whenever you figured something out. And I got kind of addicted to that dopamine spike, so that's why I'm here.
02:00:43.094 - 02:00:44.454, Speaker A: Is that part of the attraction?
02:00:44.534 - 02:01:39.560, Speaker B: Yeah, it's the constant amount of dopamine spikes. If you want more developers, don't add docs. I don't know about YouTube, but I've always found that with the steep learning, relatively, you know, the steep learning curve of both Rosta and Solana, it's led to a couple interesting consequences for good results for the ecosystem and the community. I mean, first of all, you didn't have all these scammers at the beginning because they weren't able to build whatever scams they wanted to. They had so much to figure out. So the people who ended up kind of sticking with Solana are people who not only saw the benefits, but I find it's a lot of, like, ex traders or ex exchange operators or people from, like, these really technical backgrounds who look at Solana, they really see the whole vision, and they're so committed that they don't mind, you know, the pains that the temporary pains that come with learning something like rust and learning how to build on Solana even before anchor was around. So I thought that was quite interesting.
02:01:39.560 - 02:01:51.674, Speaker B: But I don't know if you guys had a similar experience. Yeah, you have to be a little more long term oriented if you're going to build on Solana. You can't just fork a solidity contract, deploy it, and run a yield farm.
02:01:52.614 - 02:02:06.314, Speaker A: And in terms of getting developers to come on board and use Solana, what can be done in that sense? What do you think? You're talking about dopamine spikes and the attraction and new space, but how can you encourage other people?
02:02:07.714 - 02:02:43.214, Speaker B: So I feel like there's been quite a lot done. It's kind of been the sexy thing to go into. I think anchor is doing a really good job onboarding new devs. I think it's just in terms of getting devs on board, I think it's kind of just a matter of time and showing people what's possible on Solana, because you can't do what we're doing on any other chain. And in terms of getting users in general, there's a lot of work that needs to be done that I don't even think we've begun starting. So we can talk about that, too, if you want.
02:02:43.334 - 02:03:01.294, Speaker A: Definitely. Well, I was going to ask you in terms of the end user, because you're talking about what you're getting from it in this new space, but in terms of the end user and what they're going to get from it, can you give us some insight on that? The end user of the mobile wallets, of the. What are they seeing in terms of to being the user of Solana.
02:03:02.234 - 02:03:32.488, Speaker B: Right. So end users on the mobile platform, I found this kind of interesting because one of my favorite sort of pastimes is to force my Normie friends at gunpoint to use Solana. I make sure they make a wallet. I'm kidding. But no, but it's interesting because, let's say you got one of your friends interested in crypto and you want them to have a Solana wallet. You want them to start playing around with these dapps and do cool things, whether it's on mobile or web. I think there's a couple of issues.
02:03:32.488 - 02:04:13.876, Speaker B: First is fiat on ramping, because you realize, well, I have to be seeing them like SPL wrapped USDC, or have to send them so they have to KYC through another centralized exchange in order to figure that out. So there's a bit of friction there, I think. It's not something you easily pick up, start using intuitive gestures and immediately doing things. So I see that kind of on the user front. Yeah. So just to continue, I think, I don't remember the company, but I heard there's someone who's trying to do plaid for crypto. So you would be able to just go on your bank on a wallet and just say, hey, I'm attached to this bank, and just buy it immediately.
02:04:13.876 - 02:04:44.524, Speaker B: And I think something like that would be super helpful. It doesn't solve, like, the credit card Kyc, but it does solve, like, the bank Kyc. I don't know how far along it is. I don't even remember the name. But that kind of idea, I think, would really do a lot. Yeah. I think somehow enabling tighter integration between wallets and smart contract developers could make the experience a lot better in the sense that you look at traditional web two companies, the designers are working with the people on the back end, and they can build this great experience.
02:04:44.524 - 02:05:35.538, Speaker B: In crypto, you kind of have people write smart contracts and you have people develop wallets and they don't necessarily overlap. And so I think the more we can figure out the APIs on how they can communicate. So I, as a smart contractor, can, like, smart contractor, I want to just coin phrase. If I can go and, like, document and, like, kind of guide the wallet experience and, like, explain what's happening and guide the user, I think it might make people more comfortable using it, because right now, you literally go on and you're signing transactions and you have no idea what's going on. And obviously, like the wallet person, the wallet developers can't go and tightly integrate with every single protocol. And so we need to come up with a way to more create more, like, unified experiences that you get on web two. And so if you're a wallet provider, I think you need to start looking at anchor ideals.
02:05:35.538 - 02:05:36.850, Speaker B: That's my show.
02:05:37.042 - 02:05:52.110, Speaker A: Very good. And that leads me to the next question, which is really around blockers in your space. What do you feel could be done better? What do you feel you need aside from these pieces so that you can progress in your own projects?
02:05:52.302 - 02:06:41.606, Speaker B: I mean, I think the biggest blocker we tend to run into is weird Solana quirks. The compute limit would just break if you do too many things, and you'll just get all these weird stack blowing up issues that you really have to optimize for. And it kind of does make building the best possible ux kind of hard because you are kind of limited by Solana still. I mean, it's fine. There's workarounds but it still makes it more of a challenge. Yeah, I think there's a couple of things I want to point out when it comes to blockers, and especially for the front end side of things. And one is that funny issue of you come onto a dab, you click the menu of what wallet you want to connect, and your wallet might not be there unless you're using something like solid or phantom or software big ones.
02:06:41.606 - 02:07:36.374, Speaker B: And the smaller wallet companies or projects who are doing a great job, they might not be listed there already, and that's no fun. Right. But I think this leads to a bigger, I suppose, topic of like, I think one of the differentiating factors between C five and DeFi is that in DeFi, in CeFi, everything's kind of like accessed by one point. They've really have put in a lot of focus in making sure that accessibility, that user intuitiveness is there. And again, if I wanted one of my friends to go into DeFi, go into the slanted universe, I feel like I had to give them a whole tour and show them what's what and what's a scam and what's good and what's in Devnet versus Mainnet. I think making that experience, I don't know what a good solution to this is, but making a better solution just for a complete newbie to come in and just be able to start on something and have a great time immediately, that could go a very long way, in my opinion.
02:07:37.114 - 02:07:37.894, Speaker A: Chris?
02:07:38.754 - 02:08:26.354, Speaker B: Yeah, I guess two things that come to mind. One, I think we need more designers in this space. We kind of always talk about the dev shortage and. Yeah, more designers that can kind of talk to engineers and bring them up a level of abstraction because we understand how to manage our keys, but we can't necessarily build the things that help people manage their keys. And then I think we're still missing core infrastructure for Devs on Solana to make really good retail experiences. Indexing the history of the chain is really hard, and users are used to expecting a history of all their transactions, but as a dev, it's really hard to do that. I think we still are kind of missing infrastructure that'll make it easier for us to build, like, top notch experiences.
02:08:26.894 - 02:08:28.634, Speaker A: Tom, do you have anything to add on that?
02:08:31.614 - 02:08:49.634, Speaker B: Sorry. I think what I said with the Solana being pretty. There are just some things that are pretty difficult with Solana, and you can work through them and there are solutions to them, but you just have to work through them. I think we're just a year or two away from it being very good.
02:08:49.754 - 02:09:01.414, Speaker A: Okay. And that leads me to my next question. What needs to happen in terms of wallets and where they're going so that it will help you in the future for your projects?
02:09:02.114 - 02:09:44.914, Speaker B: So for me, like, the most frustrating part about wallets is you don't really know if you're going to get scammed or not. And it's like a pretty big deal. And I think that's the first thing that every wallet should do, is take out auto settling. And because you're taking out auto selling, it kind of ruins the experience in other ways. So until there's a better solution for that, you're just always going to have a mediocre ish experience until we can figure out how to do auto settling in a secure way. Another issue is no wallets. Talk about when block hashes will expire, so you'll randomly get errors and you won't even know why.
02:09:44.914 - 02:09:50.274, Speaker B: So there's a few things you can improve there, and I mean, there's quite a bit.
02:09:51.614 - 02:09:54.926, Speaker A: Fair enough. Do you have anything to add?
02:09:55.030 - 02:10:25.132, Speaker B: I mean, those are major ones, but sort of from like the user's perspective, I think finalizing the solutions we have for bridging, especially for something like, you know, serum where you can have multiple serum based Gui's and wherever you want to trade, maybe you also want to trade like cross chain or whatever. And wormhole has been doing a great job, but they're still deploying it. And I think that's like a critical next step before at least people within who are defi native feel more comfortable coming into Solana.
02:10:25.268 - 02:10:27.988, Speaker A: Okay, Chris, do you have anything to add on that?
02:10:28.156 - 02:11:19.260, Speaker B: Yeah, I think I'm going to echo what I said before about figuring out ways for the wallets and the kind of protocol designers in some way cooperate better. And for the people building the protocols to guide the wallet experience, even error handling, everyone has to build custom error handling. If there is a way that you could customize how the wallet displays errors in a way that a user can understand what's going on, that would be great. Right now, the block hash error happens and then it's really hard. Describe to users what to do besides like Command R and try again. It would be also nice if you could write descriptions for every transaction so the user knows what they're doing when they approve something too. It would be great, like if the wallet didn't disappear and was always on the screen.
02:11:19.260 - 02:11:36.446, Speaker B: Like there's so many things that could be great. They really resolve a lot of customer support issues. I think for every protocol out there? Yeah, I mean, I think they're doing a good job. It's like the first thing you get to is like, okay, let's start signing transactions and people using stuff. And now it's like, how do we just keep cooperating better to make better user experience?
02:11:36.590 - 02:11:55.194, Speaker A: Very much so. Okay. So obviously, it feels like we're at the beginning of this. Right. But what needs to happen, in your point of view, for this mass adoption piece that they were talking about this morning and this kind of conversion and people coming across and using Solana, or indeed even just decentralized finance or crypto asset?
02:11:56.174 - 02:12:32.136, Speaker B: Yeah. Two things I kind of want to point out here. I think one is sort of a cultural one. I think Solana is a incredible community, an incredible culture, and I think what we're seeing at breakpoint is it demonstrates that. And I look forward to continued development in the ecosystem. But I think as when I was talking about the sort of difference between c five and Defi versus, and trying to create one accessible point within Defi and within Solana, that's going to require a lot of coordination between teams, including teams who may be building the same set of services. And that's not easy.
02:12:32.136 - 02:13:17.750, Speaker B: And that's not exactly, that's not an engineering problem. That's a cultural problem. That's a community problem. So I really hope that we can continue the good vibes and the camaraderie, because I don't think we want to be looking at, like, we don't want to be looking at Solana like, competition within Solana. I want it to be like, you know, Solana, maybe those other chains, but slant on taking over the world and doing what we have to to get there. And then the other thing about is about, like, how do we, you know, bring it to the world, which is basically, how do we get to the next 10 million users, 100 million users, 1 billion users? And you really think about what that entails. Like, I'm not going to go to all my friends all, like, they say, like, 300 on Facebook is, like, the norm.
02:13:17.750 - 02:14:04.344, Speaker B: Maybe in your lifetime, you know, like, thousands of people. I'm not going to teach all of them what the blockchain is and what Defi is and what Solana really is or how it works in the background. They don't need to know how the Internet works in the background either, but I know they're going to use the Internet, so whatever we build, it has to be useful for them, and they have to be able to, what do you call it? Like, blind traffic or something. We need to get people using Solana without realizing they're using Solana or realizing DeFi. There's a few clever ways of doing this. I've seen people do things like try and acquire existing preexisting apps with pre existing user bases and then sort of slipping defi services underneath to sort of get that traffic or even that liquidity. But I think that's just like a pretty straightforward, like, maybe naive way.
02:14:04.344 - 02:14:11.004, Speaker B: And I really hope we can come together and think of other innovative ways to reach that next 100 million users.
02:14:11.624 - 02:14:12.216, Speaker A: Tom?
02:14:12.320 - 02:15:25.730, Speaker B: Yeah, I think there's a lot of niches, and every niche has their own problems that they need to solve. So I think the goal is, I think foresight is a really good example of something that could onboard a lot of people into Solanic because there's no great prediction markets on Solana, and there's a huge prediction market niche. And if you can just make a product that's ten to 100 times better than anything that exists in the traditional world, I think you can do pretty cool things. And onboard, not just 100 million, but everyone. Chris yeah, I think maybe a good heuristic is like, can we drive the risk of people losing their funds close to zero? And I think that's, like, a reason a lot of people don't use crypto is they're afraid of losing their money. And I think even there's so many benefits to it and, like, people that are more technical can deal with that, but people who are less technical are very afraid to use crypto. And so the more we can take that risk of losing your funds out of participating, I think the more people will just eagerly sign up because there are all these benefits.
02:15:25.730 - 02:15:33.162, Speaker B: So I think that would be like the KPI to watch. And obviously, that we're doing really bad on that KPI, so very good.
02:15:33.178 - 02:15:52.998, Speaker A: And for me, I think when I think of banking, I think of sitting down at a laptop. When I think of credit crypto, I have it on my mobile, right. So it is for me, it's very much a mobile experience. And we're hearing an awful lot of talk in terms of e comm and a movement there to bring it into that space. So I think that's super interesting in that mass adoption piece as well, right?
02:15:53.086 - 02:16:10.144, Speaker B: I mean, when you think about banking, too, you also think about insurance on your own account. You don't really get that in Defi. I know people are trying to build similar solutions, but that's it's just a worry among people who are not crypto native. They're just like, oh, but it feels like, you know, illegal money that I'm gonna lose, too, so.
02:16:11.764 - 02:16:21.984, Speaker A: And then. So Solana has been criticized for not being decentralized enough. Do you have opinion on that?
02:16:23.284 - 02:16:55.134, Speaker B: Yeah, I guess I can talk about that for a bit. I think it's like how you define decentralization, and I think there's a lot of different methods. I do think that the bitcoin model, where even if you have a really bad Internet, you can still do a proof of work algorithm and sustain the network. I think that's really important. I think if major governments decided to cut the bandwidth for Solana, it'd be a pretty big problem. It would just die overnight. But it is more decentralized in other ways, too.
02:16:55.134 - 02:17:12.124, Speaker B: That's quite interesting. Bitcoin is basically all co located. Well, it was in China, but now it's in Austin, and Solana's worldwide more, so it's different. And I guess I can see arguments either way.
02:17:14.464 - 02:17:15.768, Speaker A: Ed, do you want to take a step?
02:17:15.896 - 02:17:50.944, Speaker B: I mean, Anatolia, I think, has talked about this, and you'll say it much better than I can, but I think it depends what you mean by decentralization. There's really, as Tom alluded to, there's a lot of ways to look at it. One might be accessibility and people's ability to participate. And, yeah, you have these insane or seemingly insane hardware requirements with Solana, but hardware will get better over time. That's part of the Solana philosophy. I think decentralization can also be looked at as an issue of resilience. And the way ethereum might do it is only one way.
02:17:50.944 - 02:18:27.572, Speaker B: If there's another way to get to that level of resilience for the network, then I think it may be worth pursuing. That's how I interpret the direction. Yeah, I think decentralization is a bit of. There's no pure decentralization. So even bitcoin, which is arguably most decentralized, still has areas of centralization like mining pools, et cetera. And so I think sometimes we use decentralization as, like, an argument on the Internet about why one thing is better than the other. And maybe it's not.
02:18:27.572 - 02:19:11.604, Speaker B: It's, like, dumbed down a little bit for the sake of, like, arguing. And I guess I would add to that, that I think underestimated about crypto is, like, really the cryptography of, like, things. Like, I can use my keys to make a statement, and no one else could have said that they did that statement. And so it's really about choice, in a sense of, like, in freedom of expression, and there's never gonna be, like, perfect centralization or decentralization in the network. And so as long as we keep leaning on that cryptography and, like, no one can forge what you're saying, I think we should play that up a bit more. So I guess I'm not directly answering your question, but I'm, like, saying there's these other things that I wish were in the conversation more.
02:19:13.904 - 02:19:27.856, Speaker A: And when we think about the future and where this is going, do you see it more in app based from your project perspective, or do you see it more browser based that you're working on? Like, where is your focus right now? Chris, do you want to go?
02:19:28.040 - 02:20:27.114, Speaker B: Yeah. So we're looking to basically bring more traders that are kind of using centralized experiences on chain. And that's part of the reason we picked Solana, is because we think the fees and the speed can allow for us to basically make an experience that can eventually mirror what people are already doing on FTX and binance, and that's just not possible on other chains. And so, yeah, we're trying to attract existing retail traders and arbitrageurs onto Solana. And I think if you zoom out for DeFi on Solana, there's still such little activity that really, we're all in this together of bringing all the existing institutions and getting them into DeFi, and it's really zero sum in that sense, and pretty excited that we're all working together to bring all these old players on chain.
02:20:27.534 - 02:20:28.554, Speaker A: Very cool.
02:20:28.934 - 02:21:05.472, Speaker B: Yeah. App based stuff has a lot of advantages, because you have more control over the UX. And when you do a browser thing, you need to listen to whatever the Chrome team says, and you just don't have as much flexibility. However, you kind of. I mean, it's like, kind of closed source. You don't really know what's going on in an app based, and when they push updates, you're not really sure what's happening either. So I kind of think there's, like, I'm not quite sure if app based will be the future, but I'm pretty okay with doing it on the browser for a very long time.
02:21:05.568 - 02:21:06.324, Speaker A: Okay.
02:21:07.384 - 02:21:36.034, Speaker B: Yes. The context for serum is unique. We try to remain neutral as a platform. Whatever you want to build on serum, whatever you want to build on serum, go ahead. The matching engine, the base of liquidity, is all there for you. So whether you're a dapp or a browser based dapp, or you're trying to build something on mobile, we invite all use cases, whatever you think is necessary to get to that next 100 million users for DeFi, we will support it.
02:21:37.534 - 02:21:47.674, Speaker A: Awesome. So do you want to wrap up with your final comments and tell everybody how they can maybe contact you off stage and continue the conversation? Who wants to start?
02:21:48.614 - 02:22:04.262, Speaker B: Ed? Yeah, you can recognize me by the giant serum logo on my back. Feel free. And the serum team is. The serum contributors are here, too. You could see the giant teardrop on their back go up. You could introduce yourself, say hi. You can check out projectserum.com
02:22:04.262 - 02:22:22.064, Speaker B: dot. You can also check out portal dot projectserum.com dot. The serum portal is live, and we're going to be listing more and more of the serum and Solana ecosystem there to make it the gateway for, for Solana for Solana based apps. And you can also check out our discord and our telegram. Always happy to answer questions there.
02:22:22.924 - 02:22:24.584, Speaker A: Tom, do you have any final comments?
02:22:25.524 - 02:22:44.934, Speaker B: Yeah, I primarily hang out on Discord. We have the foresight discord would be pretty cool, but I'm usually on the anchor discord. You can also find me on Twitter, and sometimes if people don't get an answer for three or 4 hours, I'll hop onto the Solana dev channel chat and respond to them.
02:22:45.474 - 02:22:46.934, Speaker A: Very good, Chris.
02:22:47.354 - 02:23:06.814, Speaker B: Yeah, you can follow drift at drift protocol on Twitter. We have a discord, and we're currently the app's out at drift trade, so if you want to check it out, you can. Yeah, I'm floating around on Twitter and Discord verse, so you can also find me there.
02:23:07.314 - 02:23:15.834, Speaker A: Awesome. Well, thank you so much for your time today. And I think we're going to wrap it up there. So if you could give it up for Ed, tom, and Chris, please.
02:23:22.374 - 02:23:56.748, Speaker B: All right, thank you, guys. Thank you. All right, everybody, next up, we actually have a familiar face. Tom here from foresight is going to be doing a UX workshop on Solana. And then after that, we have a talk on the graphs, fire hose, and Armani, who I hear actually has a working microphone, this time for the first time in his life, so. All right, Tom, take it away. Hi, guys.
02:23:56.748 - 02:24:00.324, Speaker B: I don't know if you missed me. Will it show up?
02:24:00.444 - 02:24:00.916, Speaker C: Oh, sweet.
02:24:00.940 - 02:24:42.830, Speaker B: It's right there. So I'm going to go over four common problems we ran into when building foresight. Some of the most common issues I've seen devs run into in general. So just to be pretty transparent, I don't think this workshop will work for everything. Foresight is truly committed to being 100% defi. So we don't have a database, we will probably never use a database. There are also some things that I know people ask about that I won't really go over too much that are pretty clearly bugs.
02:24:42.830 - 02:25:43.904, Speaker B: One of the most common issues that people run into, I think, is websockets when they try to connect to an RPC pool. So I'll just bring that out there, but I'm not going to go into too much detail on those. So one of the problems that I ran into when I first started building it is that I would do a buy order and the transaction wouldn't really change at all. And it was really frustrating because I would press approve and nothing would change. And the primary reason for that is the confirmation levels. So when you do a new connection or you call an RPC, there's a different type of commitment that you can put in, and the default one is finalized, which is pretty great. It means that it's waiting for the supermajority to be confirmed, but that takes dozens of seconds.
02:25:43.904 - 02:26:47.642, Speaker B: What I've also seen people do is use processed everywhere or recent was before processed. And the problem with using processed on your is my mic dead. The problem with using processed on your Dapp is that you'll always get errors way more than normal. So it's great for doing things like let's say you want to do 20 30,000 transactions and you don't care about if the data is correct or not, but it kind of sucks on adaptation. So after like months, I kind of just like figured out that you're supposed to use confirm and it's kind of in the middle of the two. It's slightly slower than process, it works like good enough, but it's, it still has some risk. It's not finalized, and if a lot of validators are slashed, it will break.
02:26:47.642 - 02:27:47.260, Speaker B: But it's, it's kind of like an edge case. So this is like, so this is like an example of how you would do it in an RPC call. Normally I primarily use like RPC endpoints rather than the web3 library in our code base. And each time you have to send the commitment level in a parameter, otherwise it will default to, I believe, finalized. Another issue that we ran into is that we want to pre populate lots of market information all at the same time. And in order to do that, sometimes it's like 50, 60, 70 RPC requests. So the way we solve that is we basically batched all of the RPC requests that we would need to do.
02:27:47.260 - 02:28:45.570, Speaker B: So this is kind of one of the functions we have, and we have like five or six of these that just get all of the info and then we decode it later. So this will get all of the yes tokens and all of the no tokens from all of the markets that we have in one go. And we'll just send a structure that looks like this and an RPC call, and we'll have all of the yes and no token balances filled out in just one request. And I haven't noticed an issue until you get more than 300 of these when it starts to break sometimes. And this is how the end result will look. Cool. So another thing that we had in foresight was we didn't want to have a create an account button, which you'll see on a lot of different programs.
02:28:45.570 - 02:29:50.654, Speaker B: You might not even notice it, but there's always this hidden approval step where they try to hide away that you have to create an account before you can actually use the product. And we really didn't think that would be a UX that is ideal to users. So we only have like one buy s button. And we solve this by first we check for the PDA of the account, we fetch that data, and if that data exists, we basically either do an update or we run the instruction with an anchor to create the account and do the update at the same time. And I know that anchor built something called init account if needed. I'm not sure on the correct terminology, but that's primarily not to solve this issue. It's to solve the issue when two transactions go into a block hash at the same time, and you're trying to create an account twice and one will fail.
02:29:50.654 - 02:30:49.582, Speaker B: So while it does do this, I would kind of recommend still using this pattern, but maybe Armani can talk about that more. And then the final thing that I want to talk about is that we wanted to get rid of this concept of settling. So this crank that I'm going to show you doesn't quite have it. We actually have a custom crank, but I did not get a chance to put that in this presentation. But essentially, in order to abstract the idea that something else is happening on the blockchain that doesn't require a user input, you need a third party to run transactions and move the order flow across the time. And the way I think that's most common is a crank. And a lot of people just don't, you don't need it.
02:30:49.582 - 02:31:26.594, Speaker B: For every type of program like in Amm, the transactions are settled instantly. But if you're a market order and your order is like 15 minutes waiting to be filled. You can't really do that. So we use cranks to clear up the CR market events queue and process market order. And there are some kind of like downsides. You need people to run the cranks constantly and you also need to pay transaction fees every time you run it and they get quite costly. So they do need to, like, people who run cranks do need to be monetarily rewarded.
02:31:26.594 - 02:32:21.092, Speaker B: Otherwise, like, why would you just spend money for no reason? At foresight, we have a bunch of little teddy Sears at the bottom that do it for us. And this is an example of the CRM crank. The only difference with ours is we have a custom consume events instruction, which I think you can see at the TX add that also settles the market orders for us. Cool. So just a little bit about what we're doing at foresight in general, if you want to help out. We primarily started foresight as a governance. We are all really passionate about creating a new form of governance and we think prediction markets are kind of the best way to do that.
02:32:21.092 - 02:33:09.964, Speaker B: So if you guys have an interest in daos, we would like to talk to you. We have some spitball ideas for storing historical data cheap and efficiently. On Solana, it involves using multiple ring buffers to do it, but I'm hearing there are probably better solutions. So if you guys have strong opinions on that, we'd love to talk to you too. We want to do a dress up NFT game just because we think it'd be really fun to dress up our teddies here in lots of different ways. And I'm really excited about being able to do that myself. And we love auctions and rewarding people who are referring other people is something that we're also really, really interested in doing.
02:33:09.964 - 02:33:57.656, Speaker B: If you want to follow me, I'm Tom Gishuri, and there's the foresight market, Twitter as well on the bottom. And you can check us out with this QR code. Yeah, I think I'm done, but if you guys want to take a photo of that, that would be great. Thank you. Thank you, Tom. So next up, we have indexing Solana with the graph, with the graphs. Fire hose.
02:33:57.656 - 02:34:48.238, Speaker B: And we have with us Alexandra Borguet, and it's looking like maybe they're not here right now. And then we also have Julian, who's going to be joining us via Zoom. Oh, sorry. Okay, perfect. We ready? What's that? Yeah, yeah, yeah. We're waiting. Alright, guys, here we go.
02:34:48.238 - 02:35:07.450, Speaker B: Good luck. Hey, does everyone hear me? Well, we got the feedback there. I don't hear you guys. That'd be awesome. Okay. Whoa, great. Hear a little clap there.
02:35:07.450 - 02:35:23.182, Speaker B: So. So. Hi, everyone. My name is Alexander. Fair assumption there. I will do the demo in the emacs, and that's not true. So, I'm Alexander Bojet, CTO at streaming fast, one of the core devs of the graph.
02:35:23.182 - 02:35:47.954, Speaker B: I'm really stoked to be with you guys today. I'm in that shitty place here, but I'm super happy I can bring that firehose thing to you guys. I think it'll be great. So, first of all, I want to say that people in this room, our team is there. So if you have any questions after the conference, please go to them. They know the whole thing and it'll be awesome. Okay, let's start here.
02:35:47.954 - 02:36:23.718, Speaker B: The firehose is what? Okay, this is our team. Thank you. The firehose is a means of data extraction and replication. Let me give you a little context here. We're attacking the problem of blockchain data and indexing. The goal of the graph is to index the data so that you can have queries and do things with the data that lives on the blockchain that transits through the blockchain. And so firehose is a radical approach to tackling that issue that works across blockchain has been proven to work on many other protocols.
02:36:23.718 - 02:37:13.906, Speaker B: This thing runs on 20 other blockchains here. Different implementation, different languages. And there's a few principles I want to announce, to sort of to tell you here, so that you feel it with me, maybe I can announce here that the firehose, therefore the graph, because this is technology that's going to underpin the graphs. Indexing tech is coming to Solana. So all these Solana folks, all of you guys, will be able to index a lot of things, because there's a lot of data there on Solana with the graph protocol. To give you a little idea, I've got technical folks here in the room, there's a dev segment. So our goal is to take blockchain nodes and extract the data out of it in the most efficient way, to store it in a way that is easily retrieved and easily parallelized.
02:37:13.906 - 02:37:43.822, Speaker B: And to the tech folks, I like to see the room. That'd be awesome. I see myself here. So the data to be easily parallelized and so that it can be consumed at high speeds. It is a files based and streaming first approach. What does that mean? So we take the nodes, we extract the data, put them in files so that it can be consumed from files. Files are the delight of data scientists, the delight of anyone working with data, because of the things that scale the most easily.
02:37:43.822 - 02:38:15.440, Speaker B: There's no cpu machine overhead and SSD. These things have been optimized like crazy. So we took that approach to have files on disk, but at the same time to have the fastest streaming system. And so, so, so you have a node, and imagine it's outputting the data of each and every transaction execution. And the goal is to log an output. Imagine printing to standard output, okay, have a node Solana validator. It's outputting everything to the standard output.
02:38:15.440 - 02:39:09.388, Speaker B: Any transaction being executed, any instruction being executed, and extracting thereby any state changes, but all in context of a block, of a transaction of instruction and of its tree, and then outpouring that and then providing a nice and clean interface to the next consumer. Like this allows for subsystem like massively paralyzed operations. And so give you a few technical details there. The whole shebang has been coded using GRPC and protobuf. So we have the deepest representation, that's about richest data around here, the deepest data representation of the different chains and the richest. So you have all for each protocol, even more so than the protocols do themselves in their own node. Because we don't compromise on, for example, block rounding.
02:39:09.388 - 02:39:56.970, Speaker B: We hate block rounding, because when you have a block, and there's few things that happening in mid block, like you would as well be interested in what's happening here, not necessarily like 75 transactions tweaking the same balance. If you're analyzing what happened here, you want to know the truth at that time. So we'll provide all the rich data so that your stream can be absolutely, you know, congruous and not round things. If you're getting the state at the end, you're getting the summation of all the operations in between. Okay, so that's about the richest data. Now, the firehose is also the only thing on earth that I've observed, that I've seen that handles forks gracefully and in a guaranteed way, it has guaranteed linearity. That means that.
02:39:56.970 - 02:40:29.054, Speaker B: Let me share my screen, something very ugly that I just whipped off this morning. It's okay, this thing, right? You have a fork, like you have a block here, another block, and then we have some forked blocks. They get eventually forked. And this is the canonical chain here. Okay, so what happens is that the stream will send you this block and this block and this block. But then it knows, it learns through the protocol that it needs to be forked out. And it'll send you a cursor for each message.
02:40:29.054 - 02:41:07.894, Speaker B: It comes with a cursor. And that cursor, if you bring it back to the connection, it's a GRPC stream. So you get disconnected, bring back the cursor, and it will continue exactly where it left off. So if it was undoing this for you and it disconnected right in the middle here of those two blocks, it will continue doing the undo exactly where it left off, giving you sort of a guaranteed linearity of the stream. Nothing does. No websocket protocol you connect, sometimes you disconnect while it's reorganizing, whatever, and you'll miss some information. There's just no way the node will tell you that, because there's no distinction between the node and what's happening on the network.
02:41:07.894 - 02:41:46.716, Speaker B: Here, the fire hose will cobble from different, for example, Solana validator nodes, and merge all the fork information into what we call 100 blocks files. We'll merge them and we'll have all the views of the perceived forks. So you can always continue from where you left off. It also allows the systems to be detached from the Solana validator node. Think of the whole thing as a master slave replication protocol. You have MySQL, you have its writing operations, but then there's that bin log replication protocol that sends it to a slave for having increased read queries. And that's similar here.
02:41:46.716 - 02:42:26.256, Speaker B: The firehose is sort of a thing to extract and have the least burden on the node. Right? The least burden on the performance. So you're not hitting that node with crazy RPC calls. No. First you output the data, and you can feed just the right data to perhaps another subsystem, like a graph indexer that's putting data in a right spot, or another system that would think about, like, a very lightweight system that only tracks the state for one contract, keeps it in memory, like super high speed, and then you can scale that, because the firehose replicates you. Scaling the read thing here, you're not putting more burden on the load on the Solana validator that's doing right. So think of it as replication protocol.
02:42:26.256 - 02:42:55.146, Speaker B: I think it's a fair thing to say. Okay, so we have crazy perfs, file based streaming. What else is there to say? I want to say that we've introduced the firehose in the graph ecosystem. So we were joined to the graph ecosystem. And in here, if you search that, introducing the firehose, you'll have a lot of depth. There's a document that is linked in here. It has all the spec, right? All the principles on which we base ourselves for designing this thing.
02:42:55.146 - 02:43:16.544, Speaker B: So I encourage you to just search that. Introducing the fire hose. You'll find it right away. And this, doc, is what we are bringing to Solana. Oh, you weren't seeing that, right? That's crazy. I was showing you this here, the firehose dock. Introducing the fire hose, like search that it has all these details and the links so you could find the principles and all that.
02:43:16.544 - 02:43:59.324, Speaker B: This is the thing we're bringing to Solana. So right now there is a pr open in Solana land, and our goal is to have that merged so that this principle can arrive and we have it working. The thing can be piped to a graph node like in a week, let's say. And I think that's going to change really the face of what we can do. So give me now a few details. What are specifics to Solana? Unless obviously there are questions in the audience. I love if someone stand up, would stand up and then would just scream out some, but someone, we need to get that audio back to me, otherwise we'll have questions from, from the folks on stage there.
02:43:59.324 - 02:44:35.434, Speaker B: So, okay, what's specific to Solana? Right here we have, first of all, full history. Now, do you know what that means? You know how crazy that is? Here we're talking about full history with the richness of the data that includes transaction and structured call tree and state change. I'm going to show you the protobuf model, because you all are geeks. I'm going to show you the depth of the data here. Okay, so this is the protobuf model. It's in this repository, proto Solana. Okay, tick, tick, tick.
02:44:35.434 - 02:45:03.602, Speaker B: And you have that block. Each sort of thing that streams in our system is a block, and it contains all the things you would expect from a block. Right? And also the transactions here, they're a little bit more enriched. Right. Let's say a transaction will include again, a few of the fields you're familiar with, the iD, the first signature, additional signatures, the header, whatever. But log message and instruction, this is where it changes a little bit. And each instruction.
02:45:03.602 - 02:45:21.010, Speaker B: Whoops. Whoa, whoa, whoa. It's crazy here. I'm new to Mac manual, so instruction. Wow, wow, wow. Always. What is that? I'm in edit mode.
02:45:21.010 - 02:46:05.800, Speaker B: Okay, forgive that, that's crazy. Message, instruction. So we have here, like all the data that is needed to recreate the call tree. And when you get that information, you get it in context, you get the block, the transaction, it's in the instructions, you can go from the instruction to the transaction and see what was the first signature there and then instruction and the instructions related to one another. So you can actually model bunch of instructions as something happening, like a serum Dex operation is happening. You have all that information to create the tree and these little sweet, sweet things, the balance change and the account change. And you can see here, you'll see the effect of an instruction before and after.
02:46:05.800 - 02:46:48.102, Speaker B: You'll get the previous amount of lamports and the next amount of lamports for a given key. And this too here, you'll get the previous data in the full account data of what's after and remind you, you get that at the instruction level, and you could squash that in a transaction level, but most systems right now just rely that as being cobbled up to the block level. So actually, this is the only way. The serum dex. Using the serum dex, we're able to extract all of the orders and fills. It's only by getting the order book, the previous one extracting, because we have domain knowledge of how the thing is laid out in the account. Found it from the list here, because it's sort of a queue.
02:46:48.102 - 02:47:15.156, Speaker B: Extract what was there and then the other one, the new one, and do a diff and say, oh, this instruction added that specific fill. It's the only way. It's the only way to get something reliable. And once we have you guys, you'll say, this is a lot of data. It is true. And we will. Once we're talking about history, we will go and back, process segments of history.
02:47:15.156 - 02:47:54.984, Speaker B: That means taking those epochs, two days, crunching the ledger. You know that the ledger is unexecuted transactions, so we don't know if it's failed or not. We will go and crunch that and extract that rich data out, put it in files, perhaps once and for all. Once that's done, you don't have any other information to extract. It's in files, so easy to paralyze, to stream out. And so we will have that for all the pieces of history, so we can take it, reduce this, crunch it, pipe that into the graph indexer to make sense out of it. Okay, so, tech, I haven't seen your face there, but I'm confident that you're with me here.
02:47:54.984 - 02:48:14.120, Speaker B: Okay, so, yes, we'll have full history. Now, the firehose itself is. Let me show you the, the protocol. So just the query. That's the query you're sending. It's very simple. So you have that in proto, in the streaming fast proto.
02:48:14.120 - 02:48:48.880, Speaker B: Here it's b stream. Eventually it renamed to firehose. That's firehose. B stream is firehose. And you do a simple request that has a start block and a start cursor and eventually a stop block and different forking steps. Let's say you want the new only things that pass certain level of irreversibility and you have a few filters in there that you can select to shrink the data a little bit and the response is an agnostic. Any field that will encode any blockchains, things like that, same principles as apply to all these protocols.
02:48:48.880 - 02:49:21.524, Speaker B: They'll get step here. So it says, is it a new, is it an undone, an undo signal? Or is it you've passed the reversibility plus that cursor and if you give it the start block of one, it'll just pipe in your face the whole history. And each time you have a message there you get a cursor. You can interrupt the stream and then start again with cursor. It'll continue exactly where it left off. Give it the star block of minus ten. It'll start ten blocks from head a stop block.
02:49:21.524 - 02:50:02.900, Speaker B: You can give it to stop at some point so you can get segments to process things in parallel. The interface is very simple and the richness comes from the absolutely exhaustive data model that exists for each protocol in particular Solana. And that's what makes it so that you don't need to. There's a nice and beautiful trade off here between the flat aspect of files and a running beast with a lot of SSD's that you have a hard time just rebooting to catch up and all these things. Or that consumes a lot of memory that you will query for it in turn to go and query a key value store somewhere. Right. And it's going to work for a certain period of time that's really cumbersome to work with.
02:50:02.900 - 02:50:19.924, Speaker B: It's not the thing data scientists like to work with. Flat. Give them flat files. Okay, stop block. Dooba do do bada. Do you have any questions there? No. You'll send them over after, right? Okay, I still have four minutes.
02:50:19.924 - 02:50:38.254, Speaker B: There's so much to be said about that. I'd like to see your. You're cheering up here. I'll let you write. I'll let you read these things later on. Did we have 20 minutes? So until 50. Right, I see you now.
02:50:38.254 - 02:51:30.674, Speaker B: How are you loving it right now? Show me the audience. How are you loving it? Wave. Okay, so maybe one question is when to expect that in the coming weeks this is being worked on actively, but the team is in the room. I don't have a fixed announcement date, but if we have a lot of cheer up and a lot of need for that, I think we can converge on effort and making habits sooner than later. I wanted to tell one thing, reduce risk. Okay. Okay.
02:51:30.674 - 02:52:36.382, Speaker B: Why don't you take questions from people in the room there? Two minutes? Yeah, right here. Yeah, you can come up. Cool, right? Yeah, hi, I hear you. Cool. Awesome. Yeah, go ahead. Nice.
02:52:36.382 - 02:52:42.670, Speaker B: First thing for the talk, it was very technical. I could see well that this must.
02:52:42.702 - 02:52:48.198, Speaker D: Be probably pretty big on performance, like all the streaming.
02:52:48.246 - 02:53:32.784, Speaker B: That's fine. But I didn't get the gist of how would I actually use your service as a front end or backend engine? Are there any interfaces, frameworks to actually interact with it? Very good question. So I've talked about the firehose because this is the underpinning of what will be served as the graph. So you want to use the graph, and the moment integration of firehose is done, then you'll be able to use very standard the graph ways of indexing. There'll be mappings, you'll be able to write that assembly script, and then you'll be able to map those things to entity entities with meaning and fields. So that's standard the graph. I highly encourage you go to thegraph.com,
02:53:32.784 - 02:54:02.060, Speaker B: look at the docs, these things for Ethereum right now for near we just shipped. And so that's the sort of experience you'll be able to use to have a decentralized network index your things for you. So that's the value proposition of the graph. Now, the firehose in and of itself can provide value also, if only for inspection and things like that. But the streaming aspect of firehose will be there. You could hook up a lot of things to that for a bunch of different purposes. And I've shown you the interface is GRPC interface.
02:54:02.060 - 02:55:16.494, Speaker B: That's how you would connect with HTTPs socket to some people in the graph ecosystem. We're going to serve this information eventually, who knows? That becomes an IETF spec that all blockchains output data and sort of in a similar consumable way, so that we can even index bridges here and there using the fire hose output of a chain in a much more reliable way than what we have right now, the fire hose. All that is also high availability ready multiple, let's say solenoid validator nodes that all contribute to one or two firehose endpoints and that little service is a thing that can plug up from files and stream directly, and you join from files to the real time stream so that you have, you don't see anything happening. You see archives and then real time stream. And from an end user's perspective is just extremely reliable data from a chain and that can be all hidden. I don't know if that answers the question, does it? Direct way to interact now with firehose would be through your graphql API or through the graph, right. So most direct GRPC and then the graph, we're going to be shipping that part where you'll actually write mappings and you won't query the thing, you'll just have it shipped in your face.
02:55:16.494 - 02:55:34.226, Speaker B: And so there's a small wasm vm here. You'll get the data in, it'll execute, and you can store entities to a database and then you can query it using GraphQL. Right. That's the second part. First part for our house is GrPC. All right. Yeah, that makes it clear for me.
02:55:34.226 - 02:56:02.362, Speaker B: Thank you. Hey, bring on the other questions. I appreciate, it's fun to be able to, even though remote, to interact with you guys. Come on, come on. Who had challenges with Solana indexing? Whatever, raise your hand. No one had challenges. I don't believe you.
02:56:02.362 - 02:56:11.222, Speaker B: Yeah, yeah. You there? Another question. Yeah, go ahead. Hi. So my question is, suppose I want to create a new index and I.
02:56:11.238 - 02:56:13.326, Speaker C: Want to data to be indexed from.
02:56:13.350 - 02:56:40.642, Speaker B: Like three months ago. How much should I wait for that. So like, how fast can you process the transactions? Suppose I want to like create a new index on all the serum events, for example. Yes. Okay, so we have come to the graph ecosystem because we were able to make an 800 x performance increase. Why? Because the fire hose is highly parallelizable. Because you have a history.
02:56:40.642 - 02:57:25.990, Speaker B: It's on disk. You have six months of history, it's on disk. You can run many processes to take chunk of history and extract them and then cobble that up into one unified view. So that's what we've done initially, and that's why I think the attention has been brought to us and all that happened. So that can be done also eventually using the graph, we're currently working on parallelism in the graph so that we could bring that sort of crazy throughput. But then after that, just think it, you spin off more machines and then eventually that gets, you know, trickled down to the decentralized ecosystem. So maybe, maybe if you have a, like, I don't know if you have a petabyte of data, you'll pay a little bit more, maybe for the initial, for additional sync, but at least it'll be possible to get it out of there because the technology allows it.
02:57:25.990 - 02:58:02.104, Speaker B: Right now, most systems will go linearly, and they'll just go through the information linearly. And that is going to take absurdly amounts of time. If we don't have a system like that, where we decouple data and we don't have a possibility for parallelism, we're dead in the water. Blockchains are ever growing things. Social database, everyone writes into your database, so you need to be ready for crazy scale. And I think the firehose pattern there, applied to different chains that we have experience with, that is the solution. And I've seen other things in the ecosystem, trying to wire in directly into the Solana validator node, writing to databases.
02:58:02.104 - 02:58:50.310, Speaker B: I think it's great. I'm happy that this happens. It's innovation. I've seen that time and time over again that the Solana validator, being directly linked with some other database systems, is inevitably going to be brittle. You want that distinction? You want that clear data centric interface between systems makes things much easier, you decoupling like that. Is that so? Maybe I used your question for a tangent, but does that answer the question? Yes, but in order for the code to work faster, I should make sure that my code doesn't depend on the linear, that the execution is linear, right? Yeah. Well, we took a subgraph that was based on the fact that it's not linear, doing sums and whatever, and we made it in stages.
02:58:50.310 - 02:59:12.074, Speaker B: So that summation at one stage would be then in a relative way, for a small segment of history, was then cobbled up in an absolute way at the next stage. So there's ways, you know, slice and dice. If you have files, you can smash slice and dice in different directions to increase performance. So I don't think that would be a necessary compromise. Okay, thanks. That was really helpful. Pleasure.
02:59:12.074 - 02:59:42.382, Speaker B: Come on, we got one question over here on the side. Go ahead. John. Hi. Thanks for the talk. It was great. Have you thought about when Solana is working with other chains? With Metaplex, storing Arweave data and stuff, you're getting like a snapshot view of what the world was like at that moment in time.
02:59:42.382 - 03:00:43.456, Speaker B: But if it's like a mutable NFT, and you're querying past events on Solana, but the data's changed on Arweave, at the point of query, are you thinking about how to represent external dependencies? Yes. Okay, so the firehose is not in play here. Firehose gives you data of what happened in the richest way. Now the graphs ecosystem is working on that issue because obviously an NFT won't store everything on chain and you will want to have these things synced. So there's a design that's put out right now and is being worked on. So that rweaves, ipfs and other things can be synced in a deterministic way, which is crazy, but, and you will be able to, you'll be able to index things that are, you know, so you'll say, receive a signal on chain in an account says, oh, this is the pointer on Arweave. Well, you'll be able to go and fetch it and bring it into the, bring it into the indexing flow so that certain fields that depend on it would be present still being in a centralized network.
03:00:43.456 - 03:01:06.594, Speaker B: So these things are being worked on. But right now you can use ipfs fetchers in the subgraphs that go through Ethereum. But there's more challenges than meet the eye here. But I think you're aware, right, this is actively being worked on and it's going to come up together. But one is needed. The other is needed too. There's no history right now, there's just zero history.
03:01:06.594 - 03:01:39.396, Speaker B: How do you get the history? You can't, you pull the node as it's going. So that's one thing. Pulling nodes at a fast pace is crazy. It's absurd. You're going to miss some data. The only way to work that is to pipe it out to make sure you miss nothing and have fixed commit at the end of each block, even though if in the end Solana nodes output only one block out of five, and you have five nodes contributing streaming blocks. And so the firehose can be the one that sort of gets the fuses, the different contribution of data extraction if we're worried about performance or things like that.
03:01:39.396 - 03:02:10.448, Speaker B: So there's many things, when we decide to decouple data from the nodes, there's many, many things that we could do to speed up data systems and filter and reduce and whatever. Okay, what else? So we're about to wrap up. We're running short on time here, I'm not sure. Yeah. So thank you so much for joining us today. We like the indexing. Now we're going to go ahead and bring up Armani for our serum powering DeFi 2.0
03:02:10.448 - 03:02:33.764, Speaker B: talk today, which it seems that many of you have been trickling in for the past hour just to meet this man in the flesh. And here he is about to set up his laptop. Oh, we're good to go. All right, perfect. Okay, this is working.
03:02:33.804 - 03:02:34.380, Speaker F: Cool.
03:02:34.532 - 03:02:34.884, Speaker B: Yes.
03:02:34.924 - 03:03:07.334, Speaker F: I'm not talking about serum, I'm talking about anchor. But yeah. So, hey everyone, my name is Armani, and today I'm going to introduce writing smart contracts on Solana with Anchor. So here we go. So, if you don't know, you might ask, what is anchor? So in short, it's a programming framework. So in the web two world, we have tools like Ruby on rails, on Ethereum we have solidity web3 js and hardhat. And on Solana, we have anchor.
03:03:07.334 - 03:04:01.014, Speaker F: And the thing that all of these tools have in common is that they allow you to ten x developer productivity by abstracting away the complexity of the underlying platform. And we can see this on Solana by taking a look at the projects that are currently using anchor. So if you take a look at seven of the top ten protocols sorted by TVL on Solana, seven of them are using anchor. The mango Ido program is written in anchor. In fact, it was originally an open source contribution to the repository, the metaplex candy machine anchor. And to me, it's no surprise that for the past two hackathons, the grand prize winners wrote their protocols in anchor. If we take a look at GitHub, we can see we have over 1000 repositories depending on anchor packages.
03:04:01.014 - 03:04:43.324, Speaker F: We have over 800 stars and over 95 unique contributors from teams all around the world. So that's a little bit about an introduction. Let's take a look at the tools. So anchor provides a bunch of different things. So we've got rust smart contracts, we've got a interface definition language. So this is effectively the protocol that the smart contracts and the clients implement so that they can communicate with each other. We have client generators that use the IDL to communicate with the smart contracts, and then we have a CLI to tie everything together into a coherent developer experience.
03:04:43.324 - 03:05:46.514, Speaker F: And so all this kind of comes together to create a very productive workflow. So you can write your smart contract, you can build it and parse it into a higher level representation, which we call the interface description. And then we can use that interface description to generate clients, which then will talk to the smart contracts and test it. So what we have here is this very productive workflow where anytime you change your smart contract, all the downstream dependencies are automatically updated. So not only do we have rust smart contracts and rust clients, but in fact we have clients in any programming language that are automatically generated and so what we're going to do for the rest of the talk is, you know, we're going to go through a concrete example of this workflow. We're going to talk about smart contracts, we're going to talk about an IDL, and then we're going to write a typescript test to test the end to end, the end to end product. So, yeah, let's start with that.
03:05:46.514 - 03:06:24.224, Speaker F: So we're going to do the smart contract, but before looking at code, let's paint a picture of the program we're going to write. So what we're going to do is write the simplest program possible. It's going to be a counter program. There's going to be some data stored in an account starting at zero and associated with this data, we'll have some wallets. And this wallet is going to be the authority of the data. It's going to be the only thing that is allowed to mutate it, so it'll be able to increment the data. And if any other wallet comes along and tries to mutate that data, what we want to do is we want to abort the transaction and not allow that to happen.
03:06:24.224 - 03:06:42.436, Speaker F: So that's the program we're going to write. And let's look at some rust code. Yeah, so this is a smart contract. If you've never seen rust or if you've never seen a contract on Solana, it might be complicated, but we'll go through all the sections. We'll start at a high level. So first line, we have this prelude, import. This is just rust code.
03:06:42.436 - 03:07:10.806, Speaker F: And there's nothing anchor specific here, just importing types. Second line, declare id. This line is pretty subtle, and I'll get into why it's important later, but what you need to know for now is we're just embedding a hard coded address into the contract. This is going to be the program id. And. Yeah, just a static constant. And we'll come back to this later section is the program module.
03:07:10.806 - 03:07:42.664, Speaker F: So this is like the meat and potatoes of the program. This is where all the business logic is defined. And you'll see we have these two functions here, initialize and increment. These would be analogous to the methods in a solidity contract or your rest API on rails, but these are really the entry points into the program. So you have two options here. You can either initialize a counter or you can increment the counter. And so this is where inside of these methods is where we're going to execute the code to update the counter.
03:07:42.664 - 03:08:26.252, Speaker F: So in the next section we have the accounts context. So Solana is a bit unique in the sense that all of the clients provide the data or they specify what accounts they're going to access. And so the accounts context is effectively all of the data that your smart contract contract can read, all the data your smart contract can write and access it inside of the program. So, you know, we have two structs here, initialize and increment, and each one of them correspond to a method inside of the program module. So we'll come back to this later. The next section is the account declaration. So this would be like known as like a model in rails, but it's effectually just the storage layout.
03:08:26.252 - 03:09:08.154, Speaker F: So this is like the data that we can read data, we can write the data that's going to be controlled by the program. So those are the sections, we have that id, we have the program module, we have the accounts context, and we have the account. What we're going to do now is drill into each of these sections and talk about them in more detail. So here's our accounts we have, the first thing you'll notice is this account macro. This is some anchor macro, blackmagic, to effectively just label this struct and say that we can use it for storage. So we're going to have this counter struct, just a regular rust type, and there's going to be two fields in it. It's going to be the authority.
03:09:08.154 - 03:09:31.034, Speaker F: The authority is going to be the wallet address that has the ability to update the counter. And then the count is just going to be our data. So it's going to start at zero increment to one. But this is just the storage laid out for the program. So we have a single counter that we're defining, and that is our account. Okay, so that's the declaration. Let's move up to the context and drill in.
03:09:31.034 - 03:10:42.114, Speaker F: Okay, so as I mentioned before, one thing that's unique on Solana is that like clients provide the accounts, or they provide the set of data that your program can read and set a data that your program can write. This is great for parallelism because it allows scheduling too. It's easier to schedule parallel transactions, but it's a total nightmare for your program because it means that the client is effectively injecting data that you then have to validate. What we do with anchor is we provide this derived macro with an embedded DSS that allows you to basically specify declarative constraints that will run when you initialize these individual structs. And so what that allows us to do is on construction run a bunch of code that basically prove a bunch of properties about our accounts. So when you have one of these accounts contexts, you also have a guarantee or a proof that certain constraints hold. So we'll take a look at this in more detail.
03:10:42.114 - 03:11:18.014, Speaker F: So first thing you'll notice is the derive macro. This is how you declare one of these structs. And you'll notice we have two structs, one for initialize, one for increment. Again, they correspond to the instructions in the program. And yeah, let's get started inside of initialize. So here we have this account attribute that's inside of this derive, and this account attribute is what allows us to declare constraints within it. And so here we have a bunch of them, right? So we have init stands for initialize.
03:11:18.014 - 03:11:57.374, Speaker F: This would be like analogous to Malik and C. So you're basically creating an account, you're going to pay for some rent exemption. Here we're specifying payer is equal to the authority, and that authority is just like another account in the struct. So that's going to be the wallet that pays for the rent exemption tool. And then lastly we have space. It's going to be 48 bytes, that's just the space for our counter. So what you have here is this constraint or this macro that will allocate an account, pay for the rent exception Sol, and allocate 48 bytes, and it will do this all on construction of this struct.
03:11:57.374 - 03:12:42.298, Speaker F: And we're going to do it for the field that it is decorating. So here we have the counter, and what you notice here is we have this new account type that we introduce. And the account type is basically just like a deserialized account wrapper for the internal type, which is here is the counter which we previously defined in the previous section. And so what's nice about this is that whenever you have one of these structs, you can guarantee that you have a counter. It's deserialized, it's a normal rest struct, and no other type can be passed into here. So next line we have the authority and we introduce this new signer type. This will effectively just do validation checks on creation.
03:12:42.298 - 03:13:26.744, Speaker F: So if the account signs the transaction, we're good. If it doesn't sign the transaction, then it will abort and the transaction will fail. And then the next line here is the system program, and we introduce this new program type which just basically asserts that the account is executable and that the address of the program is indeed equal to the address inside. So here it's a system program. So all of this comes together to effectively give you this guarantee that if you have one of these structs, then you know you have a brand new counter. You know the rent exemption was paid for by the authority, and you know that authority did indeed sign the transaction. So that's initialize.
03:13:26.744 - 03:14:32.658, Speaker F: Um, we move down to increments. Um, and notice we have this like new mute, uh, keyword right here. Um, the mute keyword stands for mutable, and it basically allows us to persist the state transition whenever we update, destruct. So if we modify any of the fields on the counter that is being decorated here, then we'll store that to storage and the state transition will be persisted. Next thing we have here is this has one thing, this is some syntactic sugar, but it basically defines a constraint that basically says if the counters authority property is indeed equal to the given authority, then the struct will successfully be created. And if it's not, then the struct will fail and the transaction will abort. So all of this comes together such that when you see one of these increment structs, you can prove to yourself that, okay, you have a counter was previously created and the authority signed the transaction.
03:14:32.658 - 03:15:14.024, Speaker F: So then it's probably safe to do something, or it is safe to do something. So yeah, those are the two account contexts for the program. And what's nice about all of this is that what we've done is we've encapsulated all of the account validation logic in these structs in this declarative fashion, which allows us to to separate a lot of validation logic from the business logic in our program. So we'll see that in the next section. So let's go ahead and open up the program module. Here's the program module. This is again where the business logic lies.
03:15:14.024 - 03:16:00.544, Speaker F: First thing you'll notice we have the program attribute that basically just labels this module such that all of the functions inside of it will be treated as instructions. So these are your APIs. So we have initialize, we can initialize the counter, we have increments, we can increment the counter. And let's take a look at initialize first. So what you'll notice is the first parameter here is this context generic over some inner type which is the initialized structure. This is the same initialized struct we previously defined. And so what we know is by just looking at this code, if we ever enter the body of this function, then we can prove to ourselves that we have a new counter.
03:16:00.544 - 03:16:49.332, Speaker F: It's zero initialized and the rent exemption sold has already been paid for. And the subsequent parameters are just instruction data. So these are just parameters that we pass in from the client and yeah, let's enter the function body. So the first line here is we have a mutable reference to the counter. As I said previously, this accounts context is what gives us access to all the data. So we're going to get a mutable reference and we're going to initialize the data, we're going to set the authority, we're going to set the count, and then we're going to return success. And that's initialized, and then we can move down to increments, take a look at the context, and prove to ourselves that okay, well, you know, we have this increment context.
03:16:49.332 - 03:17:51.864, Speaker F: There's some constraints in the increment context, and that means that if we ever enter the body of this function, then we can prove to ourselves that okay, we have a valid counter and the authority of that counter did indeed sign the transaction. And if either of those things aren't true, then we'll actually never hit the function body. So, you know, we take immutable reference to the counter, we update the count, increment it by one, and we return success. And that is the increment method and that is the program module. What you'll notice here is like, okay, well not only do we just like not do any account validation logic here, but we're just playing with rust structs. There's no deserialization, there's no serialization, it's just kind of what you want out of your programming model in the sense that yeah, you're mutating some types of memory and you're able to reason about the logic of the program because it's not polluted with a bunch of other checks. That would make it harder to reason about the business logic.
03:17:51.864 - 03:18:34.544, Speaker F: Yeah, so that is the program module. And then lastly we'll talk about this declare id thing. So let's open it up and what this macro will expand into, it's pretty simple. It's just a static id variable that's created. So we've hard coded it, we have a static id. But the reason why this is so important is because it allows us to bind the program address to all accounts that we declare in our program. So what this means is that, okay, if we ever have one of these counter objects, then what we also have is a guarantee that that counter is indeed owned by this program.
03:18:34.544 - 03:19:20.978, Speaker F: And so it completely eliminates a class of security vulnerabilities where if you omit an ownership check, you know, something in your program might go wrong. So, you know, this is the type of thing that, you know, anchor provides not just like productivity improvements, but also these entire classes of security foot guns that you're exposed to in the vanilla Solana runtime. So yeah, that's the program. What we do then is we have the program, we compile it, parse it, and we get this higher level representation which we call the IDL. This is what it looks like some Json. You'll never really actually open it up. Maybe you will, depending on what you're doing.
03:19:20.978 - 03:19:57.356, Speaker F: But it's worth pointing out that this corresponds one to one to the smart contract. But it's really just the connective tissue that allows you to tie the smart contract to the client so that they can communicate via a well defined protocol. So we have some fields in here. We have the counter, which is the name of the program. We have our two instructions, initialized increment. We have the arguments for each instruction. The accounts and the account declaration don't need to follow all this, but it exists.
03:19:57.356 - 03:20:27.284, Speaker F: You can open it up in your terminal, but worth pointing out. So yeah, that is the IDL. Next we can see how to tie this all together with a test so we can write some client code. Here is the test. This is just like a moca test. And you know, the first chunk of code here is just the imports. Second line, just this describe counter.
03:20:27.284 - 03:21:22.080, Speaker F: This is just like a moca syntax for starting the test. And then the first line inside of the test is pretty important. So here we have this program variable that's introduced where we have anchor workspace counter. And what's happening here is, you know, the anchor package is like reading the local workspace, looking up the file system, fetching the IDL, and then using the IDL to generate a client. So this program variable is going to be our typescript representation of our smart contract in a mocha test. And what we want out of this client is for the API to correspond one to one to the smart contract, so that we can just read the smart contract and know exactly how to use it from the client side. So next line is just like, you know, we're creating a counter.
03:21:22.080 - 03:21:45.960, Speaker F: This is just like generating a key pair. This is going to be the address of the account that holds our data. And then, you know, we're going to take a look at the actual test here. So here we're going to create a counter, and we are going to to invoke the initialize function. So you know, there's a couple things here. You know, we have the program which is the client. We have this RPC thing which is like we call them namespaces.
03:21:45.960 - 03:22:23.126, Speaker F: Inside of the client there's a couple of them. But the RPC namespace effectively allows you to sign a transaction and send it to the cluster. And on of that namespace you have a bunch of functions that correspond one to one to the instructions inside of your program. So here we have the initialize instruction and we just invoke it like a normal function call. So we have the data. So this is going to be the start counter and then the context here at the end. So in the context we have the accounts, this is going to be all the data that our program is going to read and write, and we just pass in the pub keys.
03:22:23.126 - 03:23:05.614, Speaker F: So we have the counter, the authority, the system program, and this is exactly the initialize account context struct from our rest program. So yeah, those are the accounts. And then lastly we have the signers field, kind of a detail, but in the slanted runtime you have to sign the transaction with all accounts that you create. So here we're creating a counter account with the system program that's going to be owned by our program, and so we need to sign the transaction with the counter account. So yeah, that is the first test here. So that is how to initialize the counter. Next we increment the counter.
03:23:05.614 - 03:23:42.088, Speaker F: So same thing. We have program RPC increments, just a normal function call. There's no parameters here, but we still have to pass in the accounts. So here we have the counter, we have the authority, and that is it for incrementing the counter, just a function call. Next we have this new line right here we have this new account variable that we're defining. This is basically fetching the account from the blockchain, deserializing it and giving you a typescript type. So we have program account.
03:23:42.088 - 03:24:23.486, Speaker F: So instead of RPC we're using this account namespace that gives you access to all of the accounts that are declared inside of your program. So here we have this counter account, or this corresponds to the rust struct in our contract, and then we fetch it with a pub key and that will return to you an account. And that's just a typescript object, it's just an object with some fields. So we have the count field, we can assert it's equal to one, and the authority field which is going to be our wallet. So, yeah, that is the typescript test. So what you do is you have this typescript test, you have the smart contract, and then normally you run the test. I'm not going to do this live because I'm not crazy.
03:24:23.486 - 03:24:58.482, Speaker F: But, yeah, you would run in your terminal, and what anchor would do is it would spin up the validator, deploy the program, run the test, and then tear down the validator and hopefully return success. And, yeah, that is our typescript, and that is the entire workflow in one. So if you're interested in more, and you want to learn more about anchor, here's some resources. Check out the GitHub. There's tons of examples in there and tests, some tutorials, some API documentation. Probably most importantly is the discord. Definitely join that.
03:24:58.482 - 03:25:08.424, Speaker F: If you're looking to learn, you're looking for help. There's tons of, of really smart people that just hang out in there all day, every day that like helping out people. So, yeah, that's it. Thanks for listening.
03:25:15.724 - 03:26:44.244, Speaker B: Thank you, Armani. All right, so we have another talk starting at, I believe it's starting at 330, so I guess we can take like an eight minute break. And next up, we're gonna have here with how to create pools using kive efficiently store and validate or how to create pools using kive to efficiently store and validate data streams. So looking about like seven minutes, and we can take a short little break here. Hello. All right. All right, everybody, we're back.
03:26:44.244 - 03:27:16.078, Speaker B: Go ahead and welcome up the Kive team here for a talk and demo on how to create polls using kive to efficiently store and validate data streams. Welcome, guys. All right. Hello, everyone. Thank you so much for having us. I'm Fabian, the co founder of Kaif Network, together with John. Hey, guys.
03:27:16.078 - 03:27:46.034, Speaker B: And I'm a blockchain engineer from Germany. Started out in the crypto space in end of 2019, I would say. And since summer last year, I'm full on Arweave. Created my first project there called Avarify, and then in February, together with John, co founded KYF. And this session, you'll get familiar with the Kyiv protocol, and you can see how you can use it in your Dapp to basically store and retrieve data really efficiently. So basically. Oh, sorry, here we go.
03:27:46.034 - 03:28:22.218, Speaker B: One fundamental problem in crypto, like, around the whole ecosystem, not only Solana specific, is that basically, it's super, super hard to get access to all the data. I mean, on Solana, you guys are familiar with the RPC endpoints not serving all the data. And this really applies to any system. Let it be avalanche or others. It's getting harder and harder and harder, and even for nodes, also more expensive, keeping all the data and making sure you retrieve it. And the solution to this is Kive. And Kive is a next generation protocol that enables data providers to really seamlessly store and retrieve the data.
03:28:22.218 - 03:29:08.874, Speaker B: And the way it works is you set up a smart contract as a storage pool which has one uploader node and multiple validator nodes so it's fully decentralized. And then the uploader can listen to any kind of data source demo. You will see we hook it up to some more web two data so it can be used really all around the whole ecosystem. And then basically the uploader listens to the piece of data, he bundles it in big bundles, stores it onto a we saw a permanent storage layer and then makes sure that he registers the transaction id in the smart contracts. So after time, developers then pick up the transactions from the uploader coming in and then run some custom validate function against it. And for you guys developers, it's completely custom. Whatever you want to put in a validate function, it can be an oracle based system, it can be a simple matching algorithm, it can be really anything.
03:29:08.874 - 03:29:43.846, Speaker B: And basically then the way it works is then the validator runs the validate function, gets to a result, then takes the result and votes on the piece of data. And then if the data is found valid, I mean it's all good, we can safely retrieve it. And if it's invalid, the uploader receives a slashing point. And the more slashing points he has, the more likely he is to get slashed. And of course all our nodes are staked in the pool, so it's a proof of stake system to make sure that uploaded data is accessible and always retrievable. And we really hope that Kaif becomes the main layer. Between your guys, dapp, blockchain and arwy, there's a permanent storage layer.
03:29:43.846 - 03:30:28.114, Speaker B: We can also switch to different storage layers. We're not ay specific, but it's like our use case we use for the best scalability purposes. And you can imagine us basically sitting between like a graph for example. Nah weave and kite sits in the middle responsible for data collection and making sure data integrity is basically given. Kive started out early this year as a bounty project in which we first worked on some bitcoin boundary for bridging polkadot data over to Arweave. We started out with first integration, so Polkadot was our first one. Really fast build out evm integrations and other things like that in Q two this year we then released our testnet and funded our pre seed round.
03:30:28.114 - 03:31:15.004, Speaker B: Build an amazing team. They've given us great support over there so it's absolutely amazing. And then we just started improving our testnet, getting more integration, so on, getting more notes on and then I would say a few weeks ago closed our seed round and now really targeting to create some UI UX improvements, make our notes more stable. Just to give you an example, we right now have around 6000 nodes active on the storage pool for avalanche, another few thousand on the cosmos at the Moon river one. And kive really integrates with basically all l one s around right now. So we have signed partnerships with Polkadot, Solana, Celo and lots of other El Silica avalanche, you all name them because it's super, super easy to hook it up to your data source. And the cool thing is it really also works with aggregated data.
03:31:15.004 - 03:31:59.314, Speaker B: You can bring the data into specific specific formats. So for example, we had to talk with streaming fast before it. So you can put it up into more firehose like data stream and store it and validate it. So it's really really easy for indexers to go ahead and consume our data and then give it out as a better developer experience through the indexing systems to you guys, we will just switch into a quick demo, give me just 1 second so I can move my c around. I think that might be it. Not yet. Okay.
03:31:59.314 - 03:32:41.918, Speaker B: Do I need to switch to some sync mode? Yeah, there you go. Awesome. All right. Yeah, you can see that's great. So in this demo we will set up a very very basic example of how Kaif works. So in this demo we will use the European Central Bank API to get the USD to euro price. Basically historically from the 1 January 2000 up until now, store it, validate it and make it available to you guys on permanent arweave storage.
03:32:41.918 - 03:33:19.502, Speaker B: So the way it works, we start off with a very, very basic utility function which is just a getprice function. All of stuff is written open source and in typescript by the way. So as you can see, we're just making a very basic get request to this API we're converting from USD to euro at a given date and then at the end we just return the result. So we have a lot of pre built SDKs and for our core SDK you can just import an upload in a validate function which basically need to override and then assign to the node. So just jump into the upload function. There we go. And as you can see, you import it up here from our SDK, you just define it.
03:33:19.502 - 03:34:01.044, Speaker B: And then we define our main loop, which basically sets the 1 January as our starting date, and then today as the current date. And while the date we're iterating over is the same, or before today, we're going to get the price for this specific date. And then subscriber dot next is the part where Kaif comes in, pass it into the uploader. So you do have this piece of data, it's stringified, you're passing it in, and then you can also specify text for easier data retrieval later on. So basically here we're just setting the date and formatting it as a text. So you're always able to very easily get the price for the specific date. Then just in the loop, adding another day to it, sleeping for demo purposes, because we don't want to, to run through, call the main function.
03:34:01.044 - 03:34:41.048, Speaker B: That's it. That's all you need to make sure your data gets uploaded through kive. You then also just specify a validate function where you're basically subscribing to this bundle of data. And then for each item of this proposals bundle, you go ahead, you fetch the tag again, and then we're just fetching the data from it. And then down there you can see the if statement where we say, well, if the price we do get from the API does not equal the one we uploaded, well then we can just abort and call the whole bundle invalid. But if we do get through, basically, as you can see here, we're passing true for this proposal transaction to the validator. And that's really all of the core logic behind kive.
03:34:41.048 - 03:35:19.976, Speaker B: You can of course now extend this thing to EVM compatible data, to Solana data. You can hook up to RPC nodes, you can aggregate data from a to b, combine it in the uploader, put it into different formats, and all stores through there, then you would go ahead and deploy pool. We created the demo pool here for today. You can just see the total balance of kiv tokens. So the way it works is users which are dependent on our data would fund the kite pool to make sure that the pool keeps running. Because in every iteration where you upload some data and it gets validated, this funding gets paid out to upload and validator as an incentive for them to be active in that pool. And so basically whenever the pool runs out of funding, it would.
03:35:19.976 - 03:35:56.474, Speaker B: So of course every node operator and every project being dependent on KaiF data is highly incentivized to make sure that the poor always has some funding here then comes up an explore page. If you just head over to app dot kyft.net work, you can just see it here on the avalanche pool. So you can see here some changes in the stake right now and how it's all coming together. And then explore tab. Oh, nice demo got still kicking in. Usually you can see a list of transactions being voted on, valid or invalid, so hopefully we can get it in somehow.
03:35:56.474 - 03:36:24.894, Speaker B: And then you can also see it's a pool id. It's a smart contract, right, I'm sorry, pool id being here and the upload being here, both being ethereum based addresses. So our smart contracting layer is actually solidity. We're right now deploying on Moonbase, so Moonbeam network for that purpose. But we are able to in theory deploy a pool for specific chains just to get some benefits really across the whole solidity ecosystem. And then basically running a node is very simple. We do have prepared some videos for that.
03:36:24.894 - 03:36:51.644, Speaker B: There we go. So first, it was important that operating a node is as easy as possible. So the way it works is we have autostake and everything implemented. So you can see the node starts up, you can see the name of a node, the address the pool is operating in, a desired stake, and some version required of this integration to run. Then you can see it's automatically attempting to stake the. Just pause the video for a second. There you go.
03:36:51.644 - 03:37:24.888, Speaker B: So you can see as it's loading up all the pool demo, it's then trying to stake the tokens. Approving it, sorry, approving it first, of course, staking it second, and then saying it's successfully running. So basically super, super easy to spin up your own node, making sure it exists. And you can see now we're requesting in this while loop the API. And you can see how we basically increase our bundle size and then until we hit 50, which is the configuration value of this pool. There you can see. So we're then creating the bundle, storing it to au, if you can see the awave transaction id being down here.
03:37:24.888 - 03:37:55.840, Speaker B: And then it just continues, of course. And it's created a new proposal here in the smart contract. And then on the validator side, this basically looks the same, really. So what you can see here, it's starting up kind of the same interface. You can see it says it's already staked with the correct amount. So basically if you just stop your notes, start it again, it keeps continuing on that it found the proposal there you see the bytes are matching for the payout. This is kind of important.
03:37:55.840 - 03:38:19.074, Speaker B: And then you can see it voted valid on that bundle and received the reward of 0.3 kive in this one bundle. And this is the way how you incentivize. And if you would run the uploader for a longer time, once this proposal passes, you would also see that the uploader also received a reward for that base system. And that's basically how it works. We do have multiple integrations across whole ecosystem. And then accessing the data is also very easy.
03:38:19.074 - 03:38:34.516, Speaker B: Basically it's stored on Arweave. There you go. Just make it a bit bigger maybe. Perfect. So you can see this is the data we store, right? 1.01, it's the price data and then the tags we have in there. So the date, the value, things like that.
03:38:34.516 - 03:39:01.700, Speaker B: And then this would be the data indexers or Dapp could consume. Of course, it's more beneficial for indexes because data is always bundled. So for a normal developer, it is a bit tricky to unbundle the data and then fetch the item you would get. So of course we mostly target indexing networks, for example, to then make data available. And we have here, as I said this for EVM based integrations, solana based integrations. We're right now building our Solana snapshot integration. We bundle big blocks of Solana data starting early on, saving them on top of r.
03:39:01.700 - 03:39:32.576, Speaker B: We've been making them available for others to query from. And yeah, I would say that's it. From a demo perspective, we are fully open source. Feel free to check out the code and reach out to us if we do have any questions. We will do a q and a session now following this. So feel free to ask any questions you have around the system. There you go.
03:39:32.576 - 03:40:02.508, Speaker B: Awesome. I will sit next to John then for that. Any questions about anything? Would it be data storage on our weave, the retrieval part, the node part, something around that? Yeah. Do we have a mic? Yeah, I got it.
03:40:02.556 - 03:40:03.144, Speaker C: Perfect.
03:40:14.144 - 03:40:36.244, Speaker B: Hello. Thank you for your presentation. It was really interesting. I'm not so much on the technical side. I'd like to ask about how you're looking to incentivize a testnet and reward your early adopters. What's the plan behind that? And how do you plan to bring more people to your protocol? Yeah. Okay, so right now we're in testnet, not incentivized yet.
03:40:36.244 - 03:41:24.584, Speaker B: Right now we have actually in the avalanche pro, like 6000 validators just running nodes on their own accord, which is super exciting to see. We are planning on launching in a full incentivized testnet later this year, I would say probably. And then that will be on the moon river chain. And then yeah, we're going to work on some incentivization mechanisms. Not fully 100% sure on that yet, but there will be something to do with the mainnet token there as well. But yeah, as far as nodes rewards are concerned, that's really configurable per pool, because we really just want to make sure that everyone can reward the nodes properly. So if you have an integration that's very computation heavy, then you can reward the nodes with more kive tokens than say something that's just uploading data or something like that.
03:41:24.584 - 03:41:48.884, Speaker B: Any more questions? No. This one go up? Yeah, it's kind of a down to earth kind of question, but do you have any idea of the kind of rough pricing in terms of data?
03:41:49.544 - 03:41:51.208, Speaker C: How much would it cost to store.
03:41:51.296 - 03:42:45.246, Speaker B: A given amount of data using kive? Go for it. Okay, so I see the way it works is because we're utilizing arweave, of course you have this base cost of a storage price, right, which right now fluctuates a bit, but I know there's maybe some mechanisms coming up to keep the price more stable right around that. And then of course the other question and that is then basically what kind of incentive does a node need to be active in that pool? So this kind of the additional cost of validation. Then the other question is of course, what is validation worth, right? Like how much are people going to be able to put on top of it? And maybe you have like a pool, you say, well, we're really desperate to get a lot of data validated so you can increase rewards artificially, right, to incentivize nodes coming onto your pool and participating in that action. But the floor price, of course is our AuF based storage costs or the permanent storage costs. Right. And then the fee for validation on top of it.
03:42:45.390 - 03:42:46.594, Speaker C: Okay, thank you.
03:42:47.594 - 03:43:28.394, Speaker B: And maybe interesting about that in general is that the way we set it up is there is also treasury basically being part of the protocol. So every time fees get paid out, one part of the fee gets put into the protocol. Treasury just ensure that basically the community is able to fund pools in case the pool is running out of funding or things like that. So we really have this whole governance platform also around Kaif, besides the known voting system. Yeah, we actually had a follow up question to the one right before that. Awesome. I just want to ask, you mentioned that you're looking to make the validator sequence open to people who are non technical.
03:43:28.394 - 03:44:19.910, Speaker B: You said that you have 6000 users already on avalanche. Do you know if those users are technical users developers or are they just someone who's just started in crypto and they've come across and they've decided I'm going to have a go at this. And are you looking to focus on developers and experts or are you looking to bring in retail users and incentivize them with a testnet to give a validator and make it open to more public people? Yeah, I think that's a great question because with Kaif we are in a really interesting position where of course our main users, I mean it's a b, two b of crypto if you think about it, because other indexing networks will actually use the data. But we see a huge, huge amount of people coming in being very little technica. And we see that by some questions popping up in our telegram chats. Right. And so you can see this, it's really interesting how people getting crypto and then say, oh wow, I mean, running a validator and some other.
03:44:19.910 - 03:44:49.260, Speaker B: Because it's super, super hard on Kiv. It's very easy. And we created videos around that. We have a documentation around it and actually lots of our community ambassadors are writing awesome articles in their own native languages to just publish it there. And this is also where we see the biggest traction around it. So I would say it's very cool for us that we can focus on the node part of things, on really getting the broad crypto community in. Although the product itself is very technical, I always like to say it's like my mom when she ever is in crypto would never use Kaif as a crypto project.
03:44:49.260 - 03:45:18.344, Speaker B: She'd probably use some deFi platform or some crypto platform which then utilizes an indexer, which utilizes Kaif, which gets the data from arweef. And this is how we belong into the crypto stack. This one? Yeah. This one behind you. Yeah. Hi, thanks for the presentation. I'm having a question.
03:45:18.344 - 03:46:04.030, Speaker B: So you guys will be a data storage framework and you guys are working with the rV. But is there a reason why you guys choose are we? Because there are lots of other like decentralized storage platforms like Firecoin and others. So why are we? I'm just curious. And the second one question is for the alib, is there any reason they are not like directly just making own framework like that, why they guys need the clive for them? Yeah, that's my question. Yeah. So we choose Arwyf as our storage platform. First of all, because John and I, we both emerge out of the ARWYF ecosystem, we offer projects there.
03:46:04.030 - 03:46:42.642, Speaker B: So which is our native place to start? But then also looking at other storage projects, you can really see that allows us the most scalability in terms of data, because querying is a lot of easier with data tagging. And then also in terms of pricing, of course, course it's a good option for permanent storage. Of course you could argue, well, ipfs for short term is much cheaper, but we do want to build a permanent product. So this is the reason we choose arweave. But we are also, I mean, as I said, kind of blockchain agnostic on the storage side. So we don't have any integration on that yet. But in theory, like someone could build out integrations for ipfs, for a file coin system and things like that.
03:46:42.642 - 03:47:29.704, Speaker B: But it was really just, I would say that the nativeness of us coming from Arweave and then building on top of that, and I think team, to answer your second question, is they of course could build a kaif, but it's super, super tricky to build a generalized framework into your native blockchain because you don't know what kind of use cases people come up with. So I would say this is the reason why we were in a good position on that, building our own project on top of our, we have to just give them the flexibility they have on the storage side, but allow us and also the flexibility to work with different integrations partners around crypto. All right, guys, thank you, Kai, this was great. And we actually have our next presentation coming up right now. Thanks so much. Thank you. Thank you guys.
03:47:29.704 - 03:48:30.890, Speaker B: All right, next we're going to see how to build a Solana Explorer explorer without a hassle, using web3 js with Giovanni Foulin. Welcome to the stage. So thank you. To be here today I'm going to show you how to create a very simple solar explorer. And with this we want to learn web3 js. So how it started, I wanted to build something on Solana and I wanted to see some real use cases of web3 js. So I discovered this open source that is really great, but we can say that the code is very complete and it's not for beginner.
03:48:30.890 - 03:49:38.084, Speaker B: And that's why I create a very simple solar explorer where today we are going to see how it's built so you can learn something from this project to give you more context. I built this project with react chakra Ui for the components and typescript. So if you brought here your laptop, you can ground the final project and play around with the code so you can follow better this project. Now a quick introduction to in deploy we are going to use fandom wallet, so if you don't have it, I suggest you to install this extension. So a quick introduction to myself. I'm Jovan Furin and I come from Italy and I'm an open source contributor to Muncho Collective and Gitcoin. Right now I'm working on Discovery, which within Discovery we are going to launch our first product, that is Decompass.
03:49:38.084 - 03:50:38.998, Speaker B: Decompass will be a platform to welcome new users to the web3, so we want to guide them and help them to learn Decompass. Recently we pass it with 2.5 million GTC on Gitcoin proposal and we are going to launch the Alpha version by December. So if you feel that you align with our mission and want to contribute, it will be a pleasure for me to talk to you more about this project after this talk now the first thing that we want to get to build the Solana Explorer is the to get the price. One of the most popular and best solution out there is to get it from Goingecho. Now I'm going to show you three points why Coingecko is one of the best solutions. The first one is that it's publicly available.
03:50:38.998 - 03:52:15.510, Speaker B: That means that you don't need to create an account and then a token to use it, then it's 100% free, so you don't pay anything to use those API and you have a vast data, more than 1000 coins to get from. So to put the first two points into practice that means that you just need few seconds to get the data, you declare the id in this guy we want the price of Solana, then we just fit the URL and we get the data because we are using react we create the state and we set the response to our state. How can we know what's the structure of the response body? We can use console log but we also can go directly to documentation. It's very easy, you just have to select the API, try out inside the required parameters and run execute the API and you get right here in front on the page of going echo the response where you can choose what data you want to get from. Now this data allows us to create the flexation of the final project. So the price now we are going to div into web3, so we are going to get the active stake and the supply. So from web3 we want to import the cluster API URL so we get the URL.
03:52:15.510 - 03:53:12.490, Speaker B: Then we use the connection to connect to the URL and we get the data. Because we are using typescript, we import the type supply and also type both account status from there and what inside those types for supply we have for example total circulating. Those are number that is returned in Lamport that then we need to convert to Sol. If we want to show this to the final user in a more user friendly human readable way then we have both account return, right? And that's why we use reduce to get the total amount. So as I said, we need to convert lampo to solve from. We can import the constant lamp, we can use it to create our function to format. Okay good.
03:53:12.490 - 03:53:52.684, Speaker B: And with that we create the second section. Now let's review what we have learned so far by creating the cluster stats and transaction stats. For cluster start we import connection and cluster API URL. We get the URL from the cluster, use the connection to connect, get the data. Then we use the structuring syntax to unpack the values and set the value to our state. And for 10,000 /second we do the same connection. Trust API URL, we get the URL, we get the connection with the URL and get the data.
03:53:52.684 - 03:54:53.994, Speaker B: So as you can see the most important class within web3 js to get all the data is connection. We can know and check what we can get from connection through the documentation that is available on GitHub. But I think that there is a better place directory in the node module. So that's it within our editor we don't need to open a browser and go back and forth using the node module. We can be more productive because we don't need to move out. So if you go inside the node module and search for class connection, you can see here are the functions that you can use and they are self explanatory. As you can see everything are commented.
03:54:53.994 - 03:55:43.384, Speaker B: Now because we are building icebroller we need build the search. So we build the search in this way. Now you can see that we have submit function that will be called when the user input the query and hit the submit button. We import the base 58 encoding to decode the query. Then we evaluate the length. If this 62 is an address and if 64 is a signature then we show it the component accordingly. Now for the transaction we create those code where for example we can get the syntax status and get the block time.
03:55:43.384 - 03:56:34.218, Speaker B: What's inside the synod status. I said before we can go inside node modules and we can see that syntax t two returns slot that indicate when the transition when was processed, the confirmation and so on. And then we create account details occurred here. We need to import public key that we need to create a class and pass as parameter to get Passaccountinfo. And we may need to evaluate if it's a token because not all accounts are the same. To make sure that we align with the terminology. Account is a record addressable by a public key, and it might be an executable, executable program.
03:56:34.218 - 03:57:36.254, Speaker B: And a program is the code that interpret the instructions. So in this chart that doesn't see, I think there are several accounts on Solana, the special program like the system program that create the main account. Then we have a token program which creates a mint account and also the token account initiated to our main account. So with all those different account we can evaluate with the code and show on the UI, depending on the type of token in a different way. For example, for account we show the mint, and for token account we can show the supply and mint authority. So till now we built a very basic Solana. If we want to go further, we can also allow the user to connect the wallet and see his amount of Solana.
03:57:36.254 - 03:58:14.134, Speaker B: And to do that we are going to evaluate if Solana exists within the window. So if they exist, we return it back as a provider and use it to connect to the wallet. Once connected, we can get the user public key and use the connection to get the balance. And then we set the balance to our component to show it on the UI. So if you go to the last part of the final project, you can hit the connect fandom and once connected, it will show the user balance. That's all. Thank you.
03:58:14.134 - 03:59:11.884, Speaker B: Thank you, Giovanni. So we're going to take a 20 minutes break right now. And coming back from that 20 minutes break, we're going to be doing a talk on governance. Lots of smart people going to be here. Please stick around, grab some food, grab some drinks, and we will see you guys here in a bit. Thank you. Hello.
03:59:11.884 - 03:59:51.286, Speaker B: All right, guys, we're going to go ahead and kick things off about ten minutes early. So welcome to the governance conversation. We have with us today, unique club hero, launchdao Polom and Solana Labs. So let these guys take it away. Here we go. All right. Okay.
03:59:51.286 - 04:00:08.914, Speaker B: Welcome everybody to governance conversation. My name is Sebastian Bohr. I work for Solana dev Labs as a developer. And we are going to talk today about decentralized autonomous organizations. And Dao or not to dao. This is not the question. We know it's Dao.
04:00:08.914 - 04:00:49.354, Speaker B: We know this is the way. The question is why? And this is why we brought you this bright panel of engineers and entrepreneurs who are going to share with you the knowledge and experience of building Dao. So please welcome, if you want to go from zero to hero, this is your man. Karen Schaller, hero Launchdao. Please welcome Alex Migutko from unique clubs world and watch this evolving universe. Nfts. Welcome.
04:00:49.354 - 04:01:08.422, Speaker B: And last but not least, Kyle Kado, former jig stack and now polio. He brings lots of experience with him, so watch what this man has to say because he has lots of tricks in his sleeves. Welcome.
04:01:08.598 - 04:01:09.514, Speaker E: Thank you.
04:01:11.594 - 04:01:27.574, Speaker B: All right, so we know we want daos, right? But the question is, before we have the daos, how do we create them? So can you, Karen, can you share with us how easy or difficult is it to create Dao on Solana?
04:01:29.474 - 04:02:20.624, Speaker C: Yeah, thanks for the introduction. So daos have been proliferating lately, especially on other blockchains. And now Solana is taking root more and more. And on other chains, we have solutions like Aragon, that are enabling toolkits for daos. And I expect some of that to come out soon on Solana, so it makes it easier. Other solutions, like squads, enable on Solana to create small daos for small organizations, friends, small friends groups, even to share a common interest. All in all, it's just wonderful, all the things that are coming out, and especially you are in the midst of it, building the Solana Dao infrastructure, basically, right?
04:02:20.664 - 04:02:29.032, Speaker B: Yes, that's correct. I'm building tools to create daos. Okay, Kara, what's your experience on Solana?
04:02:29.208 - 04:02:59.814, Speaker E: Yeah, so there are plenty of examples of little snippets you can already use to do voting on Solana. Like, less than 50 lines of code. So in order to build a dell, you don't need much further than that. And it's just a question of how deep you want to go. And I think, like, just the efficiency and scalability brought by Solana really enables for, you know, democratic and generalistic governance to be implemented in an easy way. So I think it's pretty easy. If you guys want to do it, we can do it after the conference.
04:03:01.214 - 04:03:30.794, Speaker B: Everybody is invited. We can even start our own Dao for this panel, and everybody can join. We have a token, too, Alex. Well, yeah, definitely. It's much easier, in some sense, to build on Solana, all those things. And that allows us to go to other questions and to go deeper into the whole topic. Why and what exactly do we expect from jar? We can do molding simply enough.
04:03:30.794 - 04:04:45.024, Speaker B: But what can we do more than that? Where can we go beyond mounting? I guess that's something that Solana actually embraces us to ask. Yeah, I think that's a very good question because I think that experience to creating a DAO is relatively simple right now with Solana. But I think really, what matters, what happens after that, really, you get excited, you get your adrenaline flowing, and then your dopamine goes down. And now what? And now I think this is the big challenge. So how can we take our daos to the next level? So, I mean, Alex, what's your approach with clubs? How to engage community, to participate, how to engage, really people you don't know to work towards a common goal? Well, I have most of my experience basically coming from game development and especially mmorpgs. And that's one of the questions that also happens there a lot of times because we have guilds, we have this whole social interaction going on. And so there's always a question, how do you actually engage more people into that? And the question is, you don't.
04:04:45.024 - 04:05:44.932, Speaker B: Most of people will never care about those things no matter what you offer, no matter what incentives you bring to the table. And then there's going to be like, you know, your core community, basically, core contributors, whatever. Like, it happens everywhere in the absolutely the same manner. Who are going to actually, like, you know, create the most important parts, vote on the most important things, propose the most important things for the entire community, and then there are going to be like, I don't know, 9% of people actually participate in it some degree, 90% never going to care about pretty much anything happening. And I guess it's much better to accept it as a reality and build from there and say, okay, let me focus on those components for people who are actually, who are the most active ones who are creating the value because they will need the tools, not the 90%. So, you know, let's go from there and see what they need. Let's talk to them on a daily level.
04:05:44.932 - 04:06:42.564, Speaker B: It's like, you know, create for them, create this experience that will allow them to actually create this value for the rest of the community who doesn't care, but which is still there, participating in some form by just being there. That's, that's already. Okay, so is that the role of curator in our case? Yes, it's role of curator of the club, leader of the club, whoever, somebody who is like, you know, who has experience, who has expertise and understanding what he's doing in terms of collecting nfts and all these things. And so we are giving them a lot of tools, obviously, and we help them focus on the ownership aspect of the DAO in general, because it's not that generalistic on one hand, but on the other hand, gives a lot of road ahead as well. Okay, so, Karan, is it the same concept for hero launch Dao where you have those managers who are hands on managing? Is it the same, or you are trying to solve the same problems?
04:06:42.944 - 04:07:31.884, Speaker C: Yeah, we are. So we're trying to solve it by breaking a DaO up into different user groups and taking the voting mechanism away from a single token and instead having multiple different incentivization mechanisms backed by to run these coordination games. I would have a question for Alex. If you are focusing on the core contributors, do you then not sideline potential contributors that want to come in at a later point? How do you make sure that you are still acting well, still enabling everybody to participate like Adao was envisaged while being. While still focusing on the core contributors, like you were saying? Because I do. I do think they are the very most important ones.
04:07:32.984 - 04:08:13.288, Speaker B: I guess that's, again, it's something you see in every social group. You know, the dynamics of it would be pretty much the same because you have, like, you know, vertical and horizontal basic expansion. Right. So there are some people within the group who can, like, you know, just move up in the hierarchy, let's say, and then they would become also contributors, probably like, you know, moving from 90% to 9% and then probably to 1% within this particular dao. Or that it can be a horizontal expansion where people live some dao, because they collect enough experience, they have a different vision, potentially, or different area of interest. So they go out to create their own dao. Right.
04:08:13.288 - 04:08:55.924, Speaker B: And that's how this expertise keep growing across the whole industry or bigger community and so on. So at least that's what you usually see in social groups. All right, so it feels like we have to take some divide and conquer approach, Raj, this is how we can do it. Because I can imagine that I have a large company with, let's say, million employees and all of them, we are going to each of them to ask to vote on every single decision. Right? So how we can solve this? By dividing and concurring to smaller daos.
04:08:56.384 - 04:09:43.920, Speaker E: Yeah, exactly. So Dao is an envision kind of to divide and conquer by distributing power and influence overall in a fair manner. So as you said, if you have millions of representatives, it's pretty tough to do the math and make it fair in the end. So what really needs to be done is make people feel like their voices are being heard and they are being represented overall, because we're like a small bobo still in crypto. So our profile is very similar, especially here. We're all engineers, and there are some people that are way more vocal and some people that, you know, they have a lot of money or influence inside, but they're just delegating power and so on. So when you split that, it really makes it more manageable.
04:09:43.920 - 04:10:47.924, Speaker E: And even those people who are active members of the community, but maybe they're not so vocal or, you know, just voting too much, they're still represented. And in order for this underlying infrastructure to work, those smaller daos also need to be interconnected and just communicate with one another. And because people don't want to be just muffled and feel like they are being isolated from the rest of the ecosystem, too. And that is like the largest challenge on that. So, and this is the good thing about being on Solana, too, because we're all still early, and we have this room to talk, and it's not really creating another doll is not really fragmenting your community or your ecosystem if you are communicating, if you're working together to achieve something. So if you have this kind of conversation and this room to work together alongside one another and with the underlying infrastructure, the system itself is also being tracked horizontally, as Alex was saying, then I think it's a more sustainable way of scaling up Taos.
04:10:48.304 - 04:11:43.794, Speaker B: All right, so what's possible, even possible right now, that we have to balance, like, one extreme. We have to protect Daos money. Let's imagine we have a huge treasury account with billions of dollars. And so for certain, we don't want this to be easily taken from the Dow. But on the other hand, we want the company to be flexible. What do you think we can do about that? I mean, how would you envision that? We have this large coffers, but then also we want to be flexible and want to, as you said, everybody from the community to be involved. So any ideas how you are solving these problems in hero launchdao?
04:11:45.674 - 04:12:30.304, Speaker C: So for this problem, I think it's a question of how much risk do you want to take versus flexibility. So if you have a custodian, a treasurer, if you may, for the treasury of a Dao who's delegated by all the other DAO members, they choose one, then it's very flexible, one person making the decision, but also very risky. If you add a couple more people, it'll become less risky, less flexible, and you got to find that sweet spot of how flexible do you need it in your. So it's a. It's not a one size fits all parameter, in my opinion. You pick how many treasurers do you want for the level of safety that you require depending on the size of your treasury and depending on what.
04:12:30.684 - 04:12:59.364, Speaker B: What. So you essentially have to balance the risk versus the flexibility. Right. Because. Because you cannot have both. Yeah, that's the other way. And like we are talking about nfts of gaming, do you, Alex, find the same issues there or you think that you are facing totally different world on different challenges than what we are talking about? For example, investment dows, where you invest, somebody saves money.
04:12:59.364 - 04:14:00.674, Speaker B: Well, in the end of the day, again, from my experience, what gaming related does are essentially guilds that you can find in any game, basically, especially in mmorpgs. And then the question of ownership and treasury management and vault management becomes actually very important because especially if it's a top guild, usually in the game or on the server or whatever, it can have extremely valuable items that were obtained because of the common effort of the entire guild. Right. And now, how do you manage this? Well, if somebody wants to leave the guild, right? How do you balance those things? Do you really want your guild leader to have an ultimate authority over this whole value that is stored somewhere? Usually you have to do it because in the end of the day, we all say, okay, it's a game. It's just like imaginary value. It's just a bunch of pixels. But even back then, we all knew it's not really.
04:14:00.674 - 04:14:53.894, Speaker B: It does have a lot of monetary value. Actually, you can sell this stuff for a lot of money with nfts. Okay, so let me stop you there. So you are saying that you can have your dao, which you called a guild in the game, and that guild also exists in the real world. But basically, yeah, I mean, it's the same, it's the same mechanics, same dynamics. In the end of the day, same for, I don't know, people collecting art together or a game guild or a company like, you know, where we are three co founders, for example, it's the same problem of management, controlling the value, our common assets and distributing the roles, again across ourselves. Because in the end of the day, like you were saying, maybe I'm not the best person to judge on our marketing expenses.
04:14:53.894 - 04:15:25.820, Speaker B: And you might want to be the best person to judge in our new developer hire because we just don't have the same experience, but we do want to have some influence over those spendings. So creating those different roles, creating those different permissions, maybe is one of the ways to actually manage the whole job. Probably. We don't know yet. All right, so. But I think really crucial for, at least for games, is the immersion of the UI. So it doesn't feel like proposals and decision process.
04:15:25.820 - 04:15:37.036, Speaker B: But on the other hand, sometimes you need a structure, right. And I think, like Jig Stack, I think they really got it right. Can you tell us more about that, about the user experience and the quality of the UI that's needed?
04:15:37.140 - 04:16:27.724, Speaker E: Yeah, sure thing. So our proposal was to bring your grammar to defi in general, so anyone can just join and you don't really have to know, approve here, go there, and do this whole crypto native. That for us, it's pretty simple, but in order for crypto to reach the next step, it's pretty tough. So for people that are older or they're just outside, don't really give the damn that much to be on that data loop. So putting that all under this flow of this friendly ux overall was really important. And it's just down to getting the tech right and getting the integrations right as well. So once you have this kind of basic framework, slash blueprint across one product, you can kind of scale that alongside the rest of them, and then it's way more welcoming.
04:16:27.724 - 04:16:59.624, Speaker E: And this is one thing that's doing some off chain governance, things that happen more on EVM networks, it's not that friendly. Like snapshot.org comma, like you need to go back and forth, and this kind of just filters down your engagement to the last bit of people that are really, really engaged, and that's not something you want. So this is the real power of on chain governance, being accessible for everyone and being committed directly there. And, yeah, it also opens paves the way of, way more experimentation down the line.
04:16:59.744 - 04:17:41.952, Speaker B: Yeah, I really agree. I think that makes a huge difference where if you compare snapshot to what we have on Solana, where snapshot is essentially off chain voting. So there have been cases where community voted one way and then the maintainers refused to actually execute that action. So I think there is definitely, there is a conflict. Why? Because we can leverage the speed and price of Solana. We can have the whole governance really on chain. So once the decision is made, once the community votes, that becomes the law, because part of the proposal is executable instruction that you can actually execute.
04:17:41.952 - 04:17:57.822, Speaker B: And I think that really brings the speed and cost of Solana, really brings lawsuit to the table and probably for the UI as well. Right. Because you can actually engage users in the experience. Right.
04:17:57.918 - 04:18:40.362, Speaker E: And the influence process as well. And what weight are you using? So things like DxDao, they have this very specific for them that they have this kind of token tracker that is specific for a person. And over time, if you're not contributing to the dao yet, like this really drops. So it keeps it fresh and so on. You can do such things on. And if you have this stale framework that only has a few options for you to choose from, it's very likely it's not going to fit your community. So that flexibility and what Solana is doing to empower future daos and future developers is really important because it's not one size fits all, period.
04:18:40.362 - 04:18:41.250, Speaker E: It's not.
04:18:41.402 - 04:19:02.264, Speaker B: Yeah. And I think that's also important thing that we have to go beyond token voting. Right. We have to find different ways, like reputation scores. So is there anything like that in hero launchdao that you can just vote with, not your economic. With a token that has economic value?
04:19:03.124 - 04:19:40.942, Speaker C: Yeah. So I'll talk about this after this panel. But I'm very much in favor of modeling on chain governance out after traditional governance. And in traditional companies, you don't have shareholders making all the decisions either. People don't buy the shares to make every little decision in the governance process. They elect a board and the board chooses some managers and whatnot, and they decide all of the day to day business stuff. And then once a year, maybe all the shareholders come together and make some, make a couple of important decisions.
04:19:40.942 - 04:19:59.134, Speaker C: And that's how I think on chain governance should work too. And it should be more merit based. And like you said, with reputation and where it tracks it within one Dao, how much you are committing, how much you're contributing, and then you get rewarded with more voting power as a result.
04:19:59.254 - 04:20:40.396, Speaker B: Yeah, yeah, yeah. I think this is exactly how we are still thinking about this SPL governance program. We have the concept of the council. So council is like a small Dao inside the large dao. Essentially, this divide and conquer strategy, that you divide your large Dao and you essentially focus the decision making to smaller groups that can make the decision more effectively. Because, I mean, what can happen if the whole community has to vote on a critical security upgrade, right? We know what can happen. Right? You have to upgrade instantaneously.
04:20:40.396 - 04:20:48.104, Speaker B: You cannot have vault open in the air for a week while people are stealing your money. And it has happened on other chains.
04:20:49.204 - 04:20:50.348, Speaker C: You don't want to name names.
04:20:50.396 - 04:22:14.600, Speaker B: No, it was recent. Okay, so let's imagine that we are successful that we create lots of those daos and everybody of us is going to end up with hundreds of them. How are we going to manage that? Alex, do you have some ideas? Because unique creates lots of daos, right? So potentially anybody who gets, you know, immersed, gets inside unique can have, like, a lot of doubts. How do you manage the problem that, you know, are those people going to really vote? Are they going to participate? How to keep the engagement, how to fight what I call the governance fatigue? Yeah, well, again, I don't believe that they're actually going to actually participate in all of the daos where they have a stake in effectively. And my biggest hope is basically that through this process, we'll also like, you know, create more curators, more collectors, you know, and by these two, we will grow, like, you know, the professional level of the market in general. And I guess that applies to any other type of, you know, communities of this kind, let's say, that are focused on ownership, on business or something like that. We want to grow more new leaders.
04:22:14.600 - 04:22:28.852, Speaker B: Right? That's, that's what decentralization is all about in the end of this a day. So that's our approach to that. Okay, so, Karl, do you think more people will be voting by themselves or they will be delegating and asking others to do the jobs?
04:22:28.948 - 04:23:20.780, Speaker E: Well, if you're in an organization and you're vertically in a higher level, it's very likely that your opinion matters in not one squad but multiple as well. So this is a really scalable way to think of it in the end, because you can delegate. Like Alex was saying, maybe I'm not good in marketing, but sometimes they need my opinion so I can delegate there, but really focus my active contribution on somewhere. I'm building something that's more important, and my skills are put to best practice, while I think most of them statistically are going to be delegated, because that's always how it is. But over time, we don't really know. It's all about experimenting and just this intercommunication is really important, and standardization is about that. It's not about just limiting what you can do.
04:23:20.780 - 04:23:40.448, Speaker E: It's just about putting together a common framework that those daos can communicate with one another. Maybe transact voting power, maybe transact members, but not really capping their creativity and their ability to evolve over time. Because that's what kills a DAO. Not evolving over time.
04:23:40.496 - 04:24:40.088, Speaker B: Yeah, that's. I think this is like, I think most of the daos are learning that, yeah, we created our dao. It's all fine, but then, like, you know, nobody wants to vote and really governance becomes a chore and it's not that funny any longer. Right. So I even imagine that in the future we can see like a professional governors that the job will be to actually govern protocols, right? Because, I mean, if I had like a cool protocol like mango and I wanted to govern this, I mean, why do I have to do this myself? Why I can hire somebody who knows. Because, you know, because on one hand, this is cool because the proposal is about executable instruction, but on the other hand, is everybody, can everybody really verify that the instruction does or the proposal does what it says? And you have to be very careful, right. Because the instructions will be executed.
04:24:40.088 - 04:24:49.644, Speaker B: Right. So definitely, I think there's going to be need for people who actually will be doing this professionally. What do you think about that idea?
04:24:50.864 - 04:25:03.332, Speaker C: Sometimes I think in this world, we're just rebuilding everything that already exists beforehand. And this very much feels like you're talking about politicians because that's what they do professionally. Professionally, they're there to vote.
04:25:03.388 - 04:25:59.764, Speaker B: I didn't want to say the key word, but yeah, but like old style politics, like, probably something that we really romanticize in terms of, you know, ancient Greece and stuff like that, where, you know, people who were really dedicated their life to politics in a way. Like, it's a philosophy of how do you manage the, you know, the state? So it's very close to what you're saying in the end of the day. And I guess one of the things that you mentioned is really important as well, the standardization of approach to daos. Just like Metaplex this standardization of approach to nfts on Solana, maybe that's something that should be considered as well. And all the people that are working on Dao related and governance related things to come together and have a common opinion on that. Yeah, that's really the goal and vision of split governance program to provide core framework to build any kind of daos so they can communicate with each other. We can create daos or daos or like Dao to Dao business model.
04:25:59.764 - 04:26:34.110, Speaker B: So, yeah, I really think if you can get this core that I think it will open, like a lot of possibilities and really possibilities for explorations and innovation. Right. So we have like four minutes left. Are there any questions for the audience? No. Okay, then I will just use this time for panelists so they can tell you about the projects and what they currently working on. So, Karen?
04:26:34.262 - 04:27:06.902, Speaker C: Yeah, I'll go into it later. Right now, I just wanted to say following up on your point and Alex's words that we do need to have something standardized to move forward with so that we can build upon that in the future. And the issues that in our world, everything moves so quickly. We need all the input we can get in how to develop this standard now before things have moved past it. And people are using all sorts of different things that are. Aren't interconnecting.
04:27:06.998 - 04:27:07.654, Speaker B: Yeah.
04:27:07.814 - 04:27:10.034, Speaker C: So input is welcome.
04:27:10.654 - 04:27:19.718, Speaker B: Yeah, I mean, we will be available for discussion even if you want. We can create dials for you after the bundle, Carol.
04:27:19.806 - 04:27:52.364, Speaker E: Yeah, awesome. I follow Carol's lead. Like, I will present about the company a little later, but, yeah, talking about this, this is really important, you know, this standardization and about this politics thing, we're talking about governance. So it's pretty tough to avoid that overall. This is the big ten years from now, it might be the new way even countries are run in decentralized governance. And we kind of have a bit of a stigma still in crypto. We're really development focused still.
04:27:52.364 - 04:28:29.114, Speaker E: The CEO is a coder, everyone's a dev. And we're now starting to segment into that. NFts really did a lot for just making more democratic, and more people are more heterogeneous overall in crypto right now. So I totally believe that sometimes we'll have crypto politicians, just governors and people who know how community works and community building and the organization as well. And if they're good at doing that, why not just segment their. Their participation in the doubt what they are really good at?
04:28:29.774 - 04:28:36.870, Speaker B: But that's an opportunity, right? We just enabling one of the politicians who would never have a chance to be a politician in real world.
04:28:37.062 - 04:28:49.898, Speaker E: Yeah. If they would, it wouldn't be transparent, wouldn't be auditable. It wouldn't be like doing decentralized governance. So this is the evolution of human to human interaction in power dynamics. So why not?
04:28:50.006 - 04:29:24.284, Speaker B: Yeah, sounds cool. Because at the end of the day, like, you know, I guess we hate current politics because it turns into popularity contests instead of, like, you know, actually people presenting their skill at governance, which can happen, you know, if we develop a proper framework. Yeah, because we can measure this. Right? Yeah. Because if you propose proposals that are accepted by the community, you gain some scores, like reputation score, and that can be measured. And that if you go more power, if you propose proposals which are rejected, then you are not a good politician. Right, exactly.
04:29:25.304 - 04:29:46.260, Speaker E: There might be some breakthroughs on that on the way that we're tracking this score, this fixed score, non transferable with this economic power. Some mixture of that might work and we just might adopt that as a new standard and build upon that. It's all about just keep experimenting, keep on coding, keep on cryptoing.
04:29:46.332 - 04:30:13.914, Speaker B: Yeah, we have to keep exploring, definitely, because, as I said, we know how to create those, we kind of know how to manage them. But I think still, we need ideas and explorations, how to go to the next step so they really can perform and not like chores. And I really, really can serve the purpose. All right, thank you, guys, and big welcome. Thank you. Thank you. Thank you, guys.
04:30:13.914 - 04:30:42.894, Speaker B: So we're going to go ahead and keep Karen up here to talk about meritocratic Daos, and then we actually have another 20 minutes in governance. So for the next 40 minutes, we're going to continue. Yeah, after we get a drink of water right here. So thanks, everybody, for coming today. And then there's events going on all over the city. I'm actually going to grab that list before we wrap things up and let people know where things are happening tonight. So, Karen, take it away.
04:30:42.894 - 04:30:44.154, Speaker B: Thank you very much.
04:30:54.534 - 04:31:41.036, Speaker C: Hi. Still here? Yeah. So, as Sebastian alluded to, we're working on making a reputation system on chain, and in that way, trying to bring a meritocracy on chain. A little bit about me. I'm working at Hero Launchdao, together with Lennart up here and a couple of other guys spread across the world. I also am a data scientist at Anyblock analytics, and because I wanted to put three things up here, I have a finance background from Rotterdam School of management. Yeah, like I was saying at the beginning, daos have proliferated recently and everyone's talking about it.
04:31:41.036 - 04:32:57.984, Speaker C: Everyone's trying to bring governance on chain and agree with everybody all across the world. And all a Dao really is, is just a worldwide coordination game. And the way to deal with making decisions all across the world is still hotly debated. And we'd like to toss our ring in the field, I hope you can see it. But a couple of governance issues that we identified when we set out with hero in the summer, during the first or the second, I think Solana Hackathon, well, the main one, the one that everybody knows about, and I'm sure you guys don't think of it as a problem, because you guys are probably the ruling elite in this plutocracy with all your bags, but it leads to inequalities and misaligned incentives. If you have a big bag in multiple protocols, then you can skew the vote in one protocol towards profiting off the other one. Of course, and this hurts the small guy and it hurts everybody else who's in basically, the common interest is hurt, whereas the individual interest gains.
04:32:57.984 - 04:33:43.734, Speaker C: Well, this is also the tragedy of the commons, where everybody sets out to maximize their own gains, and as a result, the overall gains go down and, well, the whole system loses out. And we see that in the real world. We see it on chain. We saw it here, for example, the Defi education fund, where all these uni tokens were sent away and then immediately, immediately turned into, well, immediately sold, immediately dumped. Of course, we also have voting inefficiencies on Ethereum and other expensive chains where small guys aren't voting because it doesn't make any sense to. Because they can't afford to. Yeah.
04:33:43.734 - 04:34:13.975, Speaker C: Then we would also have elected specialists, for example, here in this djnape organization. Organization where there's a group of 15 individuals deciding about governance within the protocol, rather than everybody voting. But this is opaque. It's like politics today. You don't know whether they're going to do what they, what they set out to do. It's not properly on chain. Yeah, sometimes it is, sometimes it isn't.
04:34:13.975 - 04:34:52.758, Speaker C: Yeah. And what this could lead to is career politicians who set out with the intention of remaining in power rather than helping out the whole organization. Another example here is steemit, which had elected specialists. I don't know if everybody knows about what happened there. Basically, Justin son bought the illegitimate original stake in steemit and then tried to take it over and put it on his chain. The elected officials blocked his stake from voting. So he was his, or from being moved.
04:34:52.758 - 04:35:36.071, Speaker C: So his funds were now trapped. So what he did instead is he got his friends at his exchange, Poloniex, Huobi and Binance, to come in with all their steemit tokens. Well, their steemit tokens, because they were actually somebody else's steemit tokens. They're just held in custody of the exchanges. And then those were used to vote in individuals that could free up Justin's bag and basically choose, basically vote for the things that he wanted to say set in motion on steemit. So what happened instead is most people. Well, the good actors, they left and they started hive.
04:35:36.071 - 04:36:08.418, Speaker C: But in the end, it kind of turned out all right. But it shows that if you have a coin in the custody of an exchange, it's not your coin, and they might use it for illicit purposes, such as taking over other, such as pushing in one direction. They have a lot of power as well. What I'm saying. Oh, I wanted to show an example of. I can't show it. Oh, well, it's okay.
04:36:08.418 - 04:36:39.597, Speaker C: I wanted to show Truefi. Truefi is a platform that I have a bit of a stake in, where you can vote on non collateralized loans. And if you vote yes and you're in the majority, you get rewarded with some tokens. So basically it's incentivized voting. The small guy will have to pay $50 in transaction fees to even send a vote. So it doesn't make sense to. And then they won't get rewarded with much because their stake is so small.
04:36:39.597 - 04:37:34.822, Speaker C: That's one of the voting inefficiencies I was talking about. And also something I call bandwagon voting. If you see that a vote is already quite heavily skewed towards a yes vote, there's no reason for you to vote no if you're looking out for your own interests, because at some point it'll be too obvious that the vote will not be able to be overturned. And then people aren't voting anymore for the outcome that they think is the best outcome, but instead voting for the outcome that they think will give them the most return, which is not what we're intending. Right? Oh, right. Potential solutions will be on chain delegation, which we discussed a little bit about here, but where you give your vote to someone who's trustworthy. But the issue is this is, it could still be used.
04:37:34.822 - 04:38:16.566, Speaker C: Somebody could incentivize you to stake your vote to them, to delegate to them so that they can make decisions with that. So I don't think that's the best solution. What I think we should do is we decouple the voting from the appreciating assets. So we take the coin, which can vote, and you separate the two. But honestly, this is already being done, because when you borrow anything on a lending platform, you're barring the right to vote with it without borrowing the economical incentives. So you no longer care whether the token goes up or down or the coin goes up or down because you're going to return it anyways. So you have no stake in it, but you're still voting with it.
04:38:16.566 - 04:38:57.686, Speaker C: And on the other side, the lender has lost the ability to influence the protocol, the Dow, but has given up the economic incentive. So it already exists with what I'm saying, and that it needs to be solved in a different way. And as I was also mentioned with the exchanges, the custodial ownership also separates those two in the same way. Another way to do it is a logarithmic voting power, where you don't have whales making as much of a dent. But you could game that by spreading across multiple addresses. So I'm getting to meritocracy. What's merit? Basically, everything in the real world is merit.
04:38:57.686 - 04:39:51.834, Speaker C: You guys are all participating in merit. If you guilds were mentioned earlier, this is a guild in World of Warcraft, and those ran on merit, right? If you played the game and you did well and you were great at leading raids or something, you could rise in the ranks, and eventually you'd be officer, you'd be in charge of leading raids and whatnot. And unless. So most of the time, this worked. Unless maybe the guild leader overnight promoted his girlfriend or her boyfriend to an officer, and you're like, what happened? But in a traditional company, it's also all merit based, right? If you do well, you rise in the ranks, you get promoted. If you don't do well, you might get fired. So this is really something that works, and it's evolved in humanity over time, and that's why we want to bring it on chain.
04:39:51.834 - 04:40:44.314, Speaker C: The issue is on chain, everything's deterministic, and therefore, the product needs to be built with merit in mind. You need to keep in mind what you're building and how you want to tie merit into that. What I'm saying is, how do we reward or what do we reward for within the DAO, and how do we guide the project towards rewarding those actions? We also mentioned that earlier. It's not a one size fits all thing. It really needs to be developed individually, but also in a way that can interact between various daos. Yeah. So the goals for meritocracy on chain is overcompensating the valuable contributors, the top guys or girls that are providing the most valuable value to the DAO, to the organization.
04:40:44.314 - 04:41:26.388, Speaker C: Also, we want to have it be a long term incentive alignment so that voters or decision makers have an incentive to stick with it and see that their decisions actually come, will have. Will basically see through the impact of their decisions. Of course, open and transparent. It's on chain, after all. And with the bandwagon voting, we want to make voting edgeless. So this is the financial theory about how data is valuable or information is valuable. And if you have information, you have an edge.
04:41:26.388 - 04:41:53.332, Speaker C: Well, if you know how the previous decision maker voted and you have a linear reward, then you have an edge on the person who voted before you. And that's what I'm talking about. So getting rid of that possibility that you can gain the same reward despite voting after somebody else for an incentivized voting mechanism. Great.
04:41:53.388 - 04:41:53.692, Speaker E: Yeah.
04:41:53.748 - 04:42:36.108, Speaker C: So I was talking about coins earlier, and the way that we're implementing merit is through a non transferable token, so we're no longer using a coin. Other ways that have been brought up was proof of humanity. So you could. So that whales could no longer split across different addresses. You need, for example, tying your address to your Twitter account or something else that proves that you're a real person. And quadratic voting has, of course, gotten a lot of discussion over the past few years. So the non transferable token I'm talking about, it's used to track merit on an address basis.
04:42:36.108 - 04:43:04.578, Speaker C: So we can do this on Solana because we can just put it as a property in individual accounts. And every address has an account that just tracks this number. It's non transferable, but it can go up and it go down based on how the protocol decides. And I also mentioned earlier that merit, it needs to be decided how merit is rewarded. And that's going to change over time. So that's going to be decided upon by merit, by previous merit. So it's a self perpetuating thing.
04:43:04.578 - 04:43:56.142, Speaker C: And we see this, actually, I get into this a bit later, but we see this as very much as a fractional system where we need to decentralize slowly and over time. And it's kind of like a kid growing up. So you have a child and you need to take care of them, you need to show them the way things work and they become more and more autonomous. And then eventually they're 18 or, I don't know, 28, and you set them out into the world, and then you just hope that everything works out and you just let the DAO. And same here with the DAO, you just eventually it's decentralized, you set it out there and it follows some sort of brownian motion and hopefully ends up in the right place. That's all. And of course, it's not a one size fits all solution.
04:43:56.142 - 04:44:46.526, Speaker C: So with merit, it's going to be different on different platforms. If it's a World of Warcraft guild or an investment platform, there's going to be different things that grant you merit. So the things about reputation are you can't buy it, and it's a way of showing skin in the game. And we also mentioned earlier the various task forces you can set up. And with reputation, it's no longer a one coin for each protocol kind of thing. Instead, you can have different sections, have different types of reputation, because reputation is, in the end, not tradable and not you can't swap it for money. It is valuable because everything is valuable in some way or another, but you can't swap it anymore.
04:44:46.526 - 04:45:54.464, Speaker C: And therefore you can set up different versions of reputation within the same DaO, within the same protocol without it getting in the way of that one token that you have set up. And the way that we are using reputation is on the futarchy model. That was that an economist, I forgot his name came up with 15 years ago, 20 years ago, where you put votes on a prediction market. And this, this solves the bandwagon voting problem I was talking about, where the price of the vote, where you stake reputation to vote, it moves along the spectrum. So in this binary voting mechanism here, if more people vote yes, it moves up towards 100 and the no vote moves down to zero, and it changes based on how people vote. And then in the end, it might end up like this. And then everybody who voted yes, no matter at what price they got in, they receive 100 rep back in this simple model.
04:45:54.464 - 04:47:15.458, Speaker C: And here you can also, well, some of the difficulties that you can see here is if the vote ends, let's say, in seven days or in one day, it's going to be, you're going to be voting differently. Because if it ends in one day and you see this right here, you'll be like, okay, I should still vote yes because this won't be flipped, most likely, which. So this vote starts acting like an option and you have an inherent theta. But you can make this vote more liquid and more true to its true value and more efficiently priced by allowing people to sell their vote ahead of time before the vote ends, and basically take profits if they expect the vote to not swing further in that direction. This makes the voting much more. Well, it ties in the whole efficient market ideas with voting and makes, well, yeah, you get your voting, your incentive for voting, and your incentive for gains in terms of reputation will be aligned under this model. But as you probably realize, this will require a lot of transactions, which is why Solana, which is why we're doing it on Solana, because everybody's going to be going in, out, in, out, maybe 20 times a vote.
04:47:15.458 - 04:48:13.964, Speaker C: Who knows? Yeah. And yeah, another factor of our model is you can slash the reputation of a bad actor. So if, or somebody who's amassed a lot of reputation, because if they're an outlier, that's bad for the, for the overall protocol, for the overall DaO. So the rest of the DAo can choose this guy, Justin son, we want to slash his voting power because it's a bit too much. He's turned into a Julius Caesar and we want to bring him back down a notch, which can be done, because reputation isn't money, right? It's not a share in the model. Now, what I think is interesting is that this reputation system could be used to govern many daos, because some people are part. This will be a bigger problem as daos become more established.
04:48:13.964 - 04:49:13.708, Speaker C: Maybe somebody is part of 20 different daos and they are not able to contribute to all of them to the same level as somebody who is only part of one dao. So we would need an overarching mechanism to track how much people are contributing to all the daos they are part of. Because who is to say that somebody who is, who's participating in one vote a week in 30 different daos, rather than someone versus someone who's participating in five votes in just one dao per week who's doing more? And if we're only tracking individual daos, then we're not getting the full picture. And a reputation system like this built into every dao could. Could be used to track participation in all of them, because reputation would be used as a symbol of trust and commitment. Great. I don't really want to talk too much about what we did in the summer hackathon, because I don't have much time left.
04:49:13.708 - 04:50:32.492, Speaker C: But the way we use the reputation here was we envisaged an investment dao where there's gps and LP's, LP's over here on the left, providing liquidity and gps, making the decisions, being the managers, choosing which protocols to invest into, and then being rewarded with reputation. If they did well and if the project succeeded or was a good investment, that was the idea. But of course, as maybe some of you who work at VC's know, it's quite difficult to make a decision. It's not as simple as yes, no, and there's a lot more nuance to it. So this wouldn't be the perfect model for this, but this is what we worked through in the summer hackathon. Yeah. Now what we're doing, what we're trying now, is to make hero as a platform for early stage project collaboration, where we instead track the commitment of individual users in a platform where early stage projects can be listed and rise up will be decided by filtering, incentivization scheme, and then devs or designers or something can work with the projects.
04:50:32.492 - 04:51:21.124, Speaker C: We provide some sort of contracts as a service for them to agree on a superfluid money exchange, basically. And then how much they committed would be tracked within their reputation account, and they could then take that to the next project that they might want to help later on. And it would be an overarching theme for participating in multiple projects over time. Yeah, I'm out of time, but this is what I was saying earlier. You can bridge. Oh, yeah, I guess I had this twice. You can bridge reputation across all of Solana and have different daos that you're participating in and reputation across all of those as a symbol of trust.
04:51:21.124 - 04:51:23.604, Speaker C: Thank you very much.
04:51:26.904 - 04:51:36.984, Speaker B: Thank you, Karen. And now for our last talk of the evening. K Al is going to be up here to talk about next next gen governance in simple steps. So welcome.
04:52:10.224 - 04:52:32.770, Speaker E: Okay, hello, ladies and gentlemen. Congratulations. Making it to the last talk here. And, yeah, it's been pretty awesome, these last governance steps. And thank you for the Solana conference. Like, pretty good to have this kind of big focus on governance, and I think it's really important. So I'm Kelly from Brazil, and yeah, we're going to talk about next gen governance and simple steps.
04:52:32.770 - 04:53:17.614, Speaker E: So learning from hero and what the guys are doing, we're just going to like, if you have your Solana project, how you can implement governance into it and what are the best steps to get at it. So overall, we're just going to introduce me, my company, and the topic as a whole. Dan, we're going to do an overview of governance across Solana and other ecosystems, and crypto, too. And of course, last, we're going to talk about NextGen and what I personally advise you, emerging Solana protocols to deal with governance. So, introduction. I'm Kawe Kano. I'm a brazilian spanish developer.
04:53:17.614 - 04:53:49.826, Speaker E: My background is in AI. I'm a developer and I migrated a couple of years ago to full time blockchain. It's been a ride. It's awesome. Up until like a few weeks ago, I worked at jstack, which is a cross chain dao that has a plethora of different DeFi protocols that are ruled by the community. And it's pretty fun, actually, to think about it because we implemented this reputation model, too. And this is one of my talks on the Chainlink conference as well.
04:53:49.826 - 04:54:26.674, Speaker E: So it's really awesome to see the hero guys doing something that goes even beyond that. And yeah, congratulations. And yeah, I'm also a co founder of Palm. And what Palm does is pretty standard, I think. It's not. Okay, we're a blockchain software studio, but not just a normal one, because I've been on the other side as a hiring contractors and outside companies to work for my protocol and sometimes the communication and just like the code quality wasn't up there. So what we do is we're partners.
04:54:26.674 - 04:55:11.808, Speaker E: We're not just these outside developers that are delivering code with you. We actually have a voice. We actually have stakes, skin in the game to develop long lasting partnerships because that's what you need your dev team to be and anyone that's working with your code and with your protocol to be as well. So this is pretty much what we do and could be just there. Like we have stakes in the protocols we're building and that's it. But governance really helps accelerate that to the next level. We don't only have the economic incentive to be part and to of advance the protocol, we also have the voting and the voice to do so.
04:55:11.808 - 04:55:53.098, Speaker E: So that's really interesting. We've built something all over Defi, like a wallet, amms, NFT marketplaces, launchpads, staking platforms, you name it. So yeah, if you see me around, let's chat now introducing the topic itself, governance. So yeah, Muriel Webster definitions the act of process of governing or overseeing the control of direction or something. So this goes, it's a bit beyond daos. So usually when we're talking about centralized governance, we think of daos immediately, but that's not really necessarily the case. And if you're building something, there is governance already embedded into it.
04:55:53.098 - 04:56:49.358, Speaker E: It might not be, you know, processualized, not be out there, and, you know, you have a flow to do it, but the governance is already out there. It's just a matter of what you're going to do with it. And the centralization, this actually came from the French, the centralization and in the 1820s, so during the French Revolution, and it's very similar to what crypto is all about. Like you have this scale that was really unbalanced about power and, you know, people decapitated some other folks and, yeah, big revolution and so on, we're doing that, but without blood, which is good. And there is this big social political aspect. And if you look that up, it actually took quite a while to get into technology itself, like in electronics and even AI, there's a lot of decentralized computing, you know, distributed computing, we call it. But it took a while for us to just say decentralization as a tech.
04:56:49.358 - 04:57:55.644, Speaker E: And when you think about crypto as a whole, like when 2008, Satoshi went out there and put the white paper for bitcoin out, and immediately after that, the governing process for that is just a random forum on the Internet that people who no one knows who they are, they just write in their two cent about it. That's the governance process from day one, right from the get go, like crypto's governance, and Degov is blockchain. You can't really run away from it. And even if you're just seeing it for the tech, and even if you're just speculating on it, this is an integral part of the ecosystem, and you can't really overlook it. So in the next few minutes, we're going to just very quickly go over the forms of DGoV, do some benchmarking, how to get in, like what are good steps to getting to that, and why Solana and what this future holds for Solana on DGov. So, a little overview. We have two forms of governance, of course.
04:57:55.644 - 04:58:46.550, Speaker E: We have off chain and on chain, as you guys saw that there are some examples there. So the larger protocols, like bitcoin, Ethereum, they have more sluggish process, and also snapshot.org, which is all off chain. And then there is on chain governance that we have core protocols like Solana, Tezos, or smart contract protocols like compound Nickerdao and gitcoin, which is a very good example of on chain governance. So just comparing both off chain governance is generally easier to implement, and that goes with the big asterisk, because we're talking about Solana, and we'll go into more detail on that later. It has more control to the dev team. So it's all about the point of your project and the timeline of it, and how mature your community is.
04:58:46.550 - 04:59:16.810, Speaker E: Sometimes having more control as a dev is better, but sometimes it's not so transparent. It's potentially more private. So our computation and voting is done off chain. So you could potentially just secret it and requires less security because you're not mingling with the on chain code. So not necessarily like the most hazardous stuff the cons are. Of course, it's slower. You don't have really, the assurance that what was voted is going to be enforced.
04:59:16.810 - 04:59:47.570, Speaker E: It's just your word, basically. And that's why it also has more control to the dev team. And it's potentially less transparent because of being off chain. And also, it's potentially socially plutocratic, okay. Because, well, people who have a lot of influence, they can tip the scale to their favor and not really the favor of the protocol of the project itself. While on chain governance is more novel, it's more funky. A lot of projects are moving over to that.
04:59:47.570 - 05:00:52.104, Speaker E: So because it's more decentralized into spans, so it's way more well cohesive with the whole crypto idea and blockchain. There's more room for modular expansions because you can take a look at governance modules from Ethereum like Governor Alpha and Bravo, or even some Solana projects that do so you can take the outputs of some voting and do other cool things on top of it. It's less dependent on dev team relatively, because after the voting process, if you put in place some sort of pipeline for decentralized DevOps, or, you know, just changing parameters and maintaining the protocol itself, you can't really be easier on your developers. But I assure you, like, no one's gonna get fired because you implemented governance like, everyone needs devs and period. So there's also a quicker turnaround time. Of course that's relevant. And with some examples in the past, it can take a long while to fix something that's really clearly an issue with the protocol.
05:00:52.104 - 05:01:53.220, Speaker E: And a good thing is also that there is less room for hard forks, because if your community can really change from the inside out your protocol, it doesn't really make sense to fork it and do something else. The cons are, there's more development involved. You really need to make sure everything works fine, potentially even audit your code again, to make sure everything is prestige. And not only that, there is also security and mathematical analysis, because as Karen was saying, you can implement some logarithmic or quadratic based voting functions, but that's still exploitable. You can turn, I don't know, dollar 200 of voting power into 400 if you just distribute the wallets accordingly, or the funds. So you need to not only look at the code itself, but also the architecture and the whole idea, the whole flow of what you're doing. And it is also like, it has like the less and more expensive participation.
05:01:53.220 - 05:02:36.050, Speaker E: And that also comes with a big asterisk, because we're dealing with Solana, so that's not really the case. And also it's like Karen was saying, potentially more monetary, plutocratic. So if I'm a whale, I can just rug everyone and push the protocol to give me money or something like that. So in the end, is on chain governance superior to off chain ones. And we even have this meme like everyone's talking about building daos, especially on EVM based network and ecosystem. And usually it's just a snapshot.org that people put on knows the safe or some other multisig solution.
05:02:36.050 - 05:03:10.374, Speaker E: And that's the dell, right? And it's not different. It's not really bringing something new to the table. But my answer to that personally is it depends. It's whatever suits your project. Because you need to have a mature community. You need to like doesn't make sure for you to go to your garage and spend months and months while the bull market is well running, just developing a good governance on chain governance model for them to people not use it. So really depends on what you're doing.
05:03:10.374 - 05:03:42.514, Speaker E: But at the same time, this is Solana, so we don't really have this option of just putting snapshot.org. But, but that's not necessarily negative because we can have better things to integrate with. And like I was saying, network scales. So on chain governance is just as if not even better than putting in place some snapshot.org solution. And there's no work around tooling. So everything we're going to be building is on chain directly.
05:03:42.514 - 05:04:40.286, Speaker E: And that is a big plus when you're talking about verification and transparency. And there are plenty of big users, big stakeholders in the ecosystem, they are really incentivizing and supporting dao tooling from this point on. How old is Solana? Less than two years from the previous Ethereum conferences. People are getting really big on dao tooling right now, while Solana is after six years of Ethereum Mainnet. But now Solana is really doing that well in less than two years. So it's a very different scope and this can really be way more impactful, and it's best to do it now since we're still early than later, because we can have this power of standardization and this can lead to a lot of interesting stuff in the future. So in the end, it's also a very similar mentality to Sloan itself.
05:04:40.286 - 05:05:06.062, Speaker E: So we can experiment and fail fast. And this is what daos need right now because no one has figured out daos yet. No one. Not on Ethereum, not on Solana, not on phazos. Like. No, because we have examples like Uniswap, only devs basically can have a bag large enough to propose to create proposals. In general, we have like the compound hack that happened.
05:05:06.062 - 05:05:37.294, Speaker E: So, and we have like a good example of on chain governance, makerdao. Everyone knows that. And it's a very good pipeline, you know, active community engaged. No, it's a good example, but at the same time, $50 to vote on something, $100 depending on network conditions. So this small guy doesn't really participate. They don't even delegate their voting power. So it's a lot of missed opportunities and missed potential that Solana can leverage.
05:05:37.294 - 05:06:43.154, Speaker E: So talking about next gen governance. The flow of assessing and implementing governance in your protocol is still relatively the same when you look at any protocol or any ecosystem out there, because your devs should not be taken away from building what you're supposed to build, because this is where your skills and, you know, you need to build your defi block, your lego block for other people to use. And if you're taking that time away and, you know, just capacity away from that to put into governance, governance is hurting you, it's hurting your team. And you also need to assess your community and your token distribution as a whole. Because if your tokens are already in the hands of some big vc's, big investors, it might not be the best way to move forward with your protocol. And there are ways around that. You can create a new token, you can implement something similar to what hero is doing, which is really awesome.
05:06:43.154 - 05:07:46.610, Speaker E: And after that you really need to structure your gov internally. Not really with the politicians yet, but know what exactly does governance impact in your code, in your protocol, and who's in charge of just monitoring that, seeing if that checks out, just reviewing the proposals and so on. And of course the most important thing is reacting fast because no doubt is constant throughout time. It's just an evolving, as with any protocol, you need to really react fast and listen to your community and your numbers. So taken from lavoisier, usually you have a big scope because we're all engineers. When we start doing something like, ok, let's put governance to change a little parameter here, we're not going to stop there. We're engineers, we want to decentralize the whole thing and we want to do something proper.
05:07:46.610 - 05:08:38.892, Speaker E: So it's pretty tough to contain yourself to small changes when you're doing such an impactful and different implementation. We have little time because this is crypto, like one tradfi year is one month here. So it's very different. You have few people because blockchain devs are scarce and usually you don't really have cash to just outsource that or so we're going to do what Luvusier says, which is nothing is lost, nothing is created, everything is transformed. So decentralized governance and daos as a whole should be necessarily open source, because then you can actually employ the state of the art concept, which is like the tech is here. I can try to put that in another way. I put a little twist here.
05:08:38.892 - 05:09:14.384, Speaker E: I can fail, but this doesn't mean that it's bad. Like failing is good because other people can actually take some things. I did right from here and actually push the state of the art further. So this is. And this is only available, like, if we open source stuff. And this is one thing that I think the whole ecosystem could really improve. And you also need to be strategic, because if you try to squeeze everything to one update or know, try to put in a lot of scope in your dao, it might not be, like, the best shot.
05:09:14.384 - 05:09:51.320, Speaker E: So what I recommend to Dao on Solana when you're building a Dao is, first of all, you're gonna do that assessment. Your community, your tokens, and the general fairness of what you have in mind and what your economic model could, you know, lead to. Decisions, join forces before even touching any code. And after benchmarking the ecosystem, you need to talk with other people that might be doing something very similar to what you're doing. And this is really fun. This actually happened to me and Sebastian, like, we were just chatting. Oh, we're doing something very similar.
05:09:51.320 - 05:10:43.118, Speaker E: Let's just do it together. It's way more efficient generally, and this is something like we from Solana, we can steal from other ecosystems, is just use tooling as much as possible. And if you have a proper tooling, it's not something that's limiting you, limiting your decisions, and the flexibility you have to implement your decentralized processes, then it's good. And this is one thing that Solana is really trying to do. So if you have a good tool, you're really just shortcutting your way to something way better than if you're just reinventing the wheel. And, of course, you need to iterate, listen to the community and the numbers really important, and contribute. So any changes you make, give it back to the community.
05:10:43.118 - 05:11:32.284, Speaker E: It might not be usable for everyone right out the gate, but some contributor might come in and change what you did, make it, you know, just a cargo package or something like that, and everyone can use it out of the blue. So that's really interesting. And the true potential is something that we were saying on the panel, is to standardize. And no other ecosystem had that potential. Like, throughout 2021, Solana kind of established nfts and deFi, and it's doing pretty well. If we can make that for daos as well and do things like Metaplex did for nfts and did for DeFi, this might be, like, a really game changing moment. Another thing is security as a whole.
05:11:32.284 - 05:12:22.052, Speaker E: Solon is using rust. That is a good step. But, of course, it's still protocols that are dealing with millions and millions of dollars in code. So when you're joining forces using audited standards and, you know, just not really straining that further away from what the rest of the ecosystem is doing, it's way more secure, generally. And also this modularity kind of paves the way for you to expand to, you know, more uncharted territory in a more sustainable way and reusable way for other people. So just my closing thoughts here. So Satoshi introduced bitcoin in 2008, took a lot of time to get into blockchain 2.0
05:12:22.052 - 05:13:21.100, Speaker E: and ethereum, programmable money in general. And since then, relatively very little time has passed, and a lot of things happened. There was the first dao that got the big hack, not such a good novel implementation. But then Makerdao, which is arguably one of the best standing dials around, and they're still changing their protocol, changing the whole way they're functioning. And now we have Solana that in very little time managed to get a lot of attention, a lot of good folks on board, and a lot of awesome protocols and different things going. So when we go back to the other slide, and if we have that standard, we have that adoption, we might get into this kind of Dao Woodstock for Solana. And this is what I believe will probably happen on 2022, especially if we have this Dao tooling focus.
05:13:21.100 - 05:13:30.340, Speaker E: We can sort that out right now. So this is basically my presentation. Okay.
05:13:30.412 - 05:13:30.708, Speaker B: Yeah.
05:13:30.756 - 05:13:31.544, Speaker E: Thank you.
05:13:36.824 - 05:13:49.604, Speaker B: Thank you, Cowe. So that's it for today. Thanks, everybody, for coming. We'll see you out in the city, and we will see you here again tomorrow. Have a good night, everybody.

00:00:03.080 - 00:00:48.288, Speaker A: So Kevin just talked about how a single cpu is already a distributed system and all the challenges involved in getting high performance on just a single cpu, a single socket. And unfortunately, these challenges don't get any easier when you go from the distributed system inside a core or inside a box to the distributed system around the world. I'm Philip Taffet. I'm one of the core engineers on Firedancer, and I'm going to talk about some of the work we've done accelerating Reed Solomon for fast network communications. So the core of the problem, to use a phrase that our team likes to throw around, is that networks aren't magic. We have this goal that we need to distribute new network, new transactions that are landing on chain around the whole world, you know, across the whole, you know, the world is big. And so you might think about several ways to solve this problem.
00:00:48.288 - 00:01:26.804, Speaker A: One is, okay, maybe there's, you know, some Ethernet broadcast, and you can just have the network do it. Well, no, that doesn't work. It might work on a local network, but in reality, the Internet is point to point, so you can't just have the network magically broadcast your packet. Okay, well, then you could try solving this by saying, have the, you know, the core of the distribution, send this information to each recipient. That solves the point to point issue. But no, that doesn't work either, because real networks have finite bandwidth, and if you are sending each packet multiple, you know, this basically doesn't scale. If you're sending each packet tons and tons of times, you're cutting your bandwidth by a huge factor.
00:01:26.804 - 00:02:21.330, Speaker A: All right, well, then we can solve the bandwidth problem by, say, distributing it in a ring where you send the packet to the first recipient, they forward it along, and that does solve the bandwidth problem. But no, this is not a good idea either, because real networks have non trivial latency. So each of these links might be halfway around the world, and by the time you add up a bunch of these, you try to scale this idea, you might as well be sending a postcard. Okay, so then idea four, we're running out of ideas here, but how about we distribute it in a tree? So if you think about the last two ideas, the ring and the all to all, they're both kind of extremes of the tree. So all to all is a tree with very high radix, and ring is a tree with very low radix. But we can take this as a dial, and dial the radix of you send a packet to one recipient, and they forward it to just a few recipients and this lets us trade off the balance between latency and bandwidth. Well, still no getting closer.
00:02:21.330 - 00:02:58.758, Speaker A: But the problem with this idea is that real networks are lossy. And of course, this problem affects all the ideas we just talked about, but it is particularly insidious for this one. Let's take a look at why. So say we lose this packet between l and a. Well, then it's not just a that doesn't get the data, it's a and anything that a would have sent it to, which means potentially the whole me large portion of the network isn't getting this packing. So then how about we solve this problem by sending it in a tree, but also sending some redundant information, some parity information, and here we go. This is the way that we'll solve it.
00:02:58.758 - 00:03:35.878, Speaker A: So that motivates our need. In order to get a working high performance distributed global broadcast, we need some kind of parity information, some kind of redundancy information, so that we can recover when packets get lost. There are many ways to do this. Readsoloman is one way, and that's the way we'll focus on now. So I'll dive into Reedsoloman and explain first, like, you know, the background, how it works, and then how we implement it in a high performance way. Okay, so to start with explaining Reed Salman, we need to start with just a very basic, a fact that you might remember from grade school, and that's that two points. Define a line.
00:03:35.878 - 00:03:50.914, Speaker A: So say we have two points. I'm standing in the middle, in the way two and three. Well, then there's only one line that goes through them. It's this line that I've shown in green, and there's no choice. We can't, like, wiggle the line. We can't shove it around. It has to be that line.
00:03:50.914 - 00:04:18.412, Speaker A: And that's true for any pair of numbers. So say five and five, four and zero. Any pair of numbers like that. Define exactly one line. And we can use this line to define some more points just by taking the y value at subsequent x coordinates. So say, you know, what is that? Four, five and six. And so the cool part is that we can use any two of those points we had five points, any two of those points, to find the exact same line.
00:04:18.412 - 00:05:13.780, Speaker A: So if we start with the first and the last, instead of starting with the first two, we get back the same line, and then we can use the same line to regenerate the points in the middle, and we get back the same five points that we got when we started with the leftmost two. That's it. That's the core idea behind read Solomon encoding. So if we want to send the byte two and the byte three, then we build, you know, we construct this line, and we also send redundant information, say four and five, and we send these, each in different packets, so that as long as the recipient has received two of these packets, they can reconstruct the line and reconstruct two and three, which are the values that they actually cared about. Of course, they might want to send, or we might want to send more than just two values. But this two points define a line has a very simple extension, which is that end points define an order n minus one polynomial. So if we wanted to send three points, say four, one and two, we just build a quadratic instead.
00:05:13.780 - 00:05:47.504, Speaker A: If we wanted to send four or three, we'd build a cubic for, sorry, three builds a quad, makes a quadratic, four a cubic, and so on. So if we wanted to send four, one and two, then the additional parity information we'd send, in this case is seven. You might start to notice a problem, though. So here, seven's not that big, but this quadratic is growing pretty fast. So the next point, if we wanted to send two parity points, would be 16, then 29. And these numbers are growing kind of fast, quadratically, to be precise. And if, you know, this is just an order two polynomial.
00:05:47.504 - 00:06:20.136, Speaker A: Imagine we had an order 32 polynomial, which is what we actually want. These numbers are going to grow super fast. So here we hearken back to what Kevin just talked about. You didn't think you'd be hearing about finite fields so soon again. So we're back to Galois Fields for dummies. And the key thing is that they don't blow up, that this fact of n points define an order n minus one polynomial is still true in a finite field. And, you know, I'm going to keep showing these polynomials as if they're ordinary, your garden run of the middle polynomials over real numbers.
00:06:20.136 - 00:07:01.258, Speaker A: But the key thing to know is that we have this blowing up issue under control. Okay, so far, everything I've talked about you could probably find on Wikipedia, maybe on the geocidies website, just a basic explanation of Reed Solomon encoding. But now let's get into how we actually calculate this, first from a theoretical perspective and then from a computational perspective. Okay? So, you know, back to our friendly line where we have the, um, the values two and three, and we want to find what y two and y three are. So, I mean, your first thought of, or at least my first thought of how I would do. This is, you know, going back to what I learned in high school. We have the parent function for any line.
00:07:01.258 - 00:07:23.814, Speaker A: Y equals ax plus b, where a is the slope and b is the intercept. And we have some. Some values of x and some values of y. And we want this line to pass through. So we set up a system equations, and we solve it for a and we solve it for b, and we get a is one and b is two. And then we have some x values where we want to evaluate it. So we plug in our a and b that we just computed, and we get our new y values.
00:07:23.814 - 00:08:08.634, Speaker A: All right, so this works, but it's very slow, because solving the system equations, probably you do it with, like, gaussian elimination or something, and it's o of n cubed, where n is the number of data points we want to. Or, you know, the size of our system of equations here. Um, so, okay, that's, you know, o of n cubed is slow. Uh, and if our process of computing parity information is, you know, slow compared to the process of, say, retransmitting, this whole idea falls apart. So we need to make this much faster. So the key insight in making it faster is that we actually don't care at all about the values of a and b. We only needed them as sort of an instrument to compute the points that the parity points that we cared about.
00:08:08.634 - 00:08:40.454, Speaker A: But if we had some technique where we could compute the parity points we cared about without computing a and b, that would be just fine. So we use a technique called Lagrange polynomials. Um, so this is a special set of functions that have, uh, you know, well known. They have, they take value one at one of the points we care about and zero at all the other points we care about. So here they're lines, because we're working with lines. So l zero is a line which takes value one as zero and value zero at all the other points we care about. In this case, it's just one.
00:08:40.454 - 00:09:16.674, Speaker A: And we take this line and we scale it by two, because we're looking for a line that has two at zero. And of course, two times zero is still zero, so that part doesn't stay. Okay, let's leave that line there and move on to l one, the second Lagrange polynomial for lines. So, again, this one takes value zero at zero and value one at one. And we scale this one by three again, because we're looking for a line that has value three at one. Okay? And then we take these two and we add them up. So I'm going to temporarily shade the region under so you can see the addition.
00:09:16.674 - 00:10:09.008, Speaker A: So we add them up, and what do you know, we get the line that we care about. So another way of expressing this line, you know, earlier we had the y equals ax plus b format. Another way of expressing it is two times l zero plus three times l one, where two and three are the actual data points that we were interested in sending. Okay, so how does this help at all? Well, the nice thing is that these Lagrange polynomials are well known. These are something that you can find in a textbook, something you can write down, and so you can compute them, these precomputed tables of their values at any point you might care about, way ahead of time. You don't have to do this at runtime, which means that you can compute y at these points by say, taking the, you know, the first column and multiplying it by two, and the second column and multiplying it by three. And then you add those up and you get your y values that you wanted to send.
00:10:09.008 - 00:10:53.414, Speaker A: So again, the two point, the two points on top are the data points, and then the parity points on the bottom. So I've placed all these numbers very suggestively, because this compute, this process that I just showed is actually just a matrix vector product. You have this hard coded matrix determined by the Lagrange polynomials, something you could find in a textbook or precompute. And then you multiply it by the data you want to send, and you get the data you want to send, followed by the parity points that you need to send so that the recipient can reconstruct missing packets. And the cool thing is that this same process works. I was just showing it with lines, but it works even with higher order polynomials. So, you know, this is a linear operator.
00:10:53.414 - 00:11:41.494, Speaker A: You might think it only works with lines, but actually the Lagrange polynomials kind of encapsulate all the non linearity or the higher orderedness. So when you have, say, an order ten or order 30 polynomial, this still becomes just a matrix vector product. Okay, so how does this do? Well, it's o of n times n, where n is the number of data points and m is the number of parity points. And it's okay, it's a lot better than o of Nq. So we're making progress. But is this where you want to stop? Well, no, we can go faster. So if you look at this matrix, you know, building off this idea, if you look at the matrix that we were actually sending in the finite field that we're working with two to the two to the power eight for, say, like this is 16 entries.
00:11:41.494 - 00:12:21.094, Speaker A: You can see, you know, at first glance it might look like a bunch of random numbers, but I've colored it and hopefully you can see the patterns. This matrix is actually super structured. So you have the top left quadrant and the bottom right quadrant, and they're actually identical, same with the top right and the bottom left. And this pattern repeats recursively. So within the top left quadrant, the top left sub quadrant and the bottom right sub quadrant of the top left quadrant are the same. And actually, this whole matrix is defined entirely by the first row, the numbers in the first 1st row or first column, and then this recursive pattern. So you just apply it recursively and you build the whole matrix out of that one row.
00:12:21.094 - 00:13:21.490, Speaker A: And in this kind of math, typically structured in the matrix means that there's a faster way to multiply by it. Maybe it means you can represent it sparsely, or you can represent it as a product of sparse matrices or something like that. And so after seeing that this was the matrix, I started digging around on the Internet to see what I could find of, you know, thinking there's surely a faster way to multiply by this matrix. And I actually found a relatively recent paper from 2016 about using a FFT like approach, that's fast Fourier transformer like approach, for multiplying by this matrix. So, you know, this is Reed Solomon encoding has been around since, I think, the forties, so, you know, really old technique, and 2016 really, you know, relatively speaking, a really new paper. And this paper gives an in login approach for multiplying by that matrix. We'll go into a little bit of the details, but if you've seen any ffts, you know that they're built out of these butterfly operators, and they, you get pictures that look like this.
00:13:21.490 - 00:14:11.966, Speaker A: So here they're slightly different, you know, compared to a normal FFT. And, but this is the core idea inside the paper, basically is encapsulated in these two pictures. All right, so that, you know, with this, with the ideas in this paper, we get a very fast theoretical approach in log in for computing Reed Solomon encoding. Now we have to take a look at how we can actually compute this on real hardware. All right, let's expand a little bit on one of these diagrams. So you might notice the diagram looked like a lot of combinations of this, and the details are not terribly important. But what this diagram means, and, you know, broadly speaking, the whole, the whole bigger diagram, is that you take some input value and you multiply it by a constant, and then you add it to another input value, and then you add it to another input value, and that gives you two output values.
00:14:11.966 - 00:15:12.954, Speaker A: And you do this recursively, which means that the entire computation of Reed solment encoding can be done by just multiplication by constants and additions, which is great because those are, you know, this complicated operation boils down to a bunch of really simple operations and all the details are in, you know, which constants you multiply by, which things you multiply those constants by and like the exact order in which you add them. All right, but now we got to go back to Kevin's slide and remember that we're actually working in a finite field and not just, you know, normal integers or normal real numbers. And we go back to specifically this line at the bottom. Galois fields use weird addition and multiplication tables. And here this, you know, this is a different finite field than Kevin was working in, much, much smaller, but even in some senses weirder. So addition is not addition mod something like you would expect for a prime field. It's actually just binary Xor, which is nice because this is, you know, a primitive built into every single programming image, something CPU's can do very well.
00:15:12.954 - 00:16:16.834, Speaker A: But on the other hand, multiplication is not multiplication mod something. There's no easy way to describe it, it's what Kevin was talking about, irreducible polynomials and so on. Thankfully, this finite field is common enough that CPU's actually have multiple instructions, or newer CPU's have instructions for computing it. So here we have the catwalk across the keyboard, as Kevin calls it, VGF two p eight affine QB. So this instruction, if you read the description of it, doesn't really seem to have much to do with finite fields at all, except for the GF two p eight, is kind of suggestive. But if you look at it a little bit sideways and squint, you can see that this actually can be used for Galois field multiplication in this finite field, but only really when you're multiplying by constants, because you have to formulate one of the arguments in a very esoteric format. And if you had to compute that at runtime, you would lose all the benefits you get of multiplying it by.
00:16:16.834 - 00:17:00.434, Speaker A: But thankfully, you might remember from the previous slide, all we want to do is multiply by constants. So this is perfect for us. And then this gives us an implementation of the two little primitives. But now we still have this problem of how do we make sure we're multiplying by the right constants. How do we make sure we're multiplying the right things and adding the right things at all time? So we take a page from the normal f of t literature and use a technique that people have been using to accelerate fast Fourier transforms for years. And, you know, people have put a lot of effort into this, and that's one of auto generated codelets. So this is where you take the take, you make all these, you pre compute a piece of straight line c code, so no branches, no if statements.
00:17:00.434 - 00:18:02.206, Speaker A: And you compute all the, you make all the decisions that you need at computation of the code, let time. So this is where you decide which things you're going to multiply by, which constants you'll multiply by, and you put those, generate, make all those decisions way ahead of time so that when the cpu gets the code that it needs to execute, all those decisions have been made. The constant just appears as, like a literal in the assembly code, and the cpu can run through this code blazing fast. All right, so what do we get when we put all these techniques together? Well, a very fast read Solomon encoding library and decoding library. So we get, you know, this is just some ice lake machine that I do some development work on. I benchmarked it quickly, I don't know, yesterday or the day before, and I was getting 120 gigabits per second for one core for read Solomon encoding and 50 gigabits per second for decoding. And this is our common case that we've optimized most heavily.
00:18:02.206 - 00:18:53.934, Speaker A: And if you compare that to the rust crate that does similar work that's used by many projects, we're 14 times faster, basically. All right, so wrapping up, I think it's pretty easy to summarize this. We take the fastest theoretical approach that's known in the literature, this n login FFT like approach, and we combine it with some of the fastest implementation approaches at the low level, nitty gritty, and we get a blazing fast read Solomon library, which means that when we need to transmit data to broadcast it worldwide, we have a fast, low latency, reliable global broadcast for firedancer. All right, thanks, and I'll be happy to take questions.

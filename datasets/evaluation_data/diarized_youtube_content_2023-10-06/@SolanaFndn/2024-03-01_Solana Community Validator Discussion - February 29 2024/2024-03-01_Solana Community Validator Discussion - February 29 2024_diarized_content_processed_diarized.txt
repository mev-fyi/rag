00:00:01.920 - 00:00:24.714, Speaker A: All right, welcome, everyone to the Solana community validator discussion. February 29, 2024, leap day agenda. Today we've got quite a few things to talk about, so some changes to this call. First of all, I'm going to propose some changes. We'll see what the feedback is. Normal validator updates. We'll talk a bit about Mainnet and the Testnet outage.
00:00:24.714 - 00:01:02.024, Speaker A: Validator educational workshop recap from the last workshop. That was last week, maybe the week before. And then I think what we'll take most of the time is some more discussion about timely vote credits. So let's get into it. First of all, scheduling. So the, the reason for this change or proposed change is that the community is really started to take over a lot of this self communication, let's say. And really the foundation's goal is to have the community take over more and more of what it does.
00:01:02.024 - 00:01:53.444, Speaker A: So very in support of that, Chris from Chainflow and Max from H two o nodes have been running a community led call on the fourth Wednesday of the month. And as many of you know, this is just a day after that call. So going forward, the proposal would be, instead of doing this call roughly twice a month, we're going to just do it one time a month on the second Thursday of the month, and then have the community led call sort of pick up the slack on the fourth Wednesday of the month. So we'd roughly have the same number of calls. It would just be the foundation based community validator discussion on the second Thursday, and then the community led call on the fourth Wednesday of the month. Any, any thoughts or feedback on that?
00:01:58.904 - 00:02:18.344, Speaker B: Would it, like, would it be helpful for us to, like, differentiate the name? I think I saw all the people discussing that, but maybe we just call this one the sauna foundation, valid discussion schedule, and have the other one be the community led one. The community led versus the community. Just pick up the lead. I don't think it was, like, easy for anybody to distinguish.
00:02:19.284 - 00:03:11.314, Speaker A: Fair enough. Yeah, I'm fine. Changing the name. I think the idea of changing it to community validator discussion in the first place was to emphasize the fact that it's for the community, but if we make that distinction, it's just easier. And, yeah, there's a comment from Zentetsu about the timing of the community led call, and the, the idea would be to have both calls on a Thursday rather than have one Wednesday, one Thursday. Yeah. Any thoughts on that? This just comes down to, like, who's available on what days, and we can't really accommodate everyone, but I'll kind of leave it up to Max and Chris on when they want to do their call.
00:03:11.854 - 00:03:14.074, Speaker C: Yeah, I don't see why we couldn't do it on Thursday.
00:03:14.374 - 00:03:14.710, Speaker A: Yeah.
00:03:14.742 - 00:03:47.284, Speaker D: The reason I suggested is, I know for the one that Max and Chris have led, it's typically been a process where they send out feelers. Is this day okay with you? And I think they kind of converged on something that seemed okay for everyone. But we know that this time slot must be at least minimal level of pay for everyone because that's when everyone's currently getting together. And so keeping it consistent by having it the same day just every other week as it is currently now, just each other, one run by a different. That just seems like the simplest to me. But other can, others can give their feedback.
00:03:52.664 - 00:03:54.600, Speaker A: Yeah. Make sense to me. Yeah, I agree.
00:03:54.632 - 00:03:57.824, Speaker E: We keep it the same. I would prefer that.
00:04:00.724 - 00:04:17.424, Speaker D: I mean, if you want to open a broader discussion about, you know, whether or not Thursday at eleven Pacific time, whatever it is for you, I don't know, is the best time we can have that discussion too. I'm happy to move it, you know, to some other time as long, but keeping it consistent seems like a good idea.
00:04:18.884 - 00:04:30.684, Speaker C: Yeah, I mean, we used to send out feelers, but I think we just got tired of that because, you know, there was never a time that was going to work for everybody, so it just became easier to do it on a running basis. But, yeah, I don't see why we shouldn't do it on Thursday going forward.
00:04:36.304 - 00:04:59.294, Speaker A: Yeah, I think Michael's point is good. We can figure out the details. I think overall there seems to be not much pushback on this plan. So I think we'll try that out going forward at least. And then if we feel like we need to change, we will. But let's kind of nail down the details and MD planning. Fair enough.
00:04:59.294 - 00:05:25.114, Speaker A: Yeah, I guess. Exactly. When we do, which I think we can kind of converge on a timeframe in discord. But, yeah, I think this is like enough info to see. Just, there's no pushback. Okay, cool. Moving on.
00:05:25.114 - 00:05:40.394, Speaker A: All right. For main net beta, the recommended version still 117 22. I believe there's going to be a new release fairly shortly. Will's on the call.
00:05:43.574 - 00:06:02.204, Speaker E: Yeah, 117 23 is actually available as a pre release. I will announce it well, probably today. The delay is because something's wrong with my announcing system, not because there's anything wrong with the release. So feel free to adopt 100 1723 if you'd like.
00:06:03.704 - 00:06:37.674, Speaker A: Okay, great. A couple notes here. So 117 22 or 23 as soon as it comes out or already out. Highly recommended for the RPC operators. There are feature activations coming up pretty soon for 117, so if you have not already upgraded, please do so as soon as possible. Also, there's a feature activation coming up that may or may not affect validators and their delegators. I think most of kind of the edge cases here have been communicated well enough, but these be.
00:06:37.674 - 00:07:35.040, Speaker A: Let's see here, this rent, again, excuse me, rent exempt split recipients is going to be activated within the next three or four epochs, I believe. And this essentially makes it so that when you make a new stake account for splitting stake, that new stake account must have the rent exempt minimum in it. That was not the case before this feature activation. So I actually ran into this in a couple of different projects and you get an error saying that there's insufficient funds even though you have sufficient funds in order to do the split. The issue is actually that the split account doesn't have the rent exempt minimum in it. There's a question for Zen Tetsu. If Solana splits stake, does that have the rent exempt minimum in it? I actually don't know the answer to that.
00:07:35.040 - 00:07:38.764, Speaker A: Maybe if will or others are on the call would know.
00:07:39.864 - 00:07:44.004, Speaker E: I don't know, but I will ping Tiara who wrote this and see if she can answer.
00:07:44.744 - 00:08:31.470, Speaker A: Okay, yeah, hopefully we'll get an update on the call, but if not, I'll, I'll get the answer in. Answer in discord. This feature is live on Testnet, so if you want to test it out, you can try on Testnet and see if anything that you're running does or does not work. Yeah, any stake pool operators. If you're running the Solana stake pool, then this, all these features have been fixed, so the current stake pool implementation should handle this. All right, moving on to Testnet 118.2 is recommended for Testnet.
00:08:31.470 - 00:09:09.906, Speaker A: I assume a new Testnet version is coming soon as well. There was a testnet outage on the 21 February and I want to say thank you to all the operators who participated and got Testnet back up pretty much on their own, minimal, um, participation from the foundation, from Anza. So kudos to you all. Um, the summary of what went on in that outage is in this pull request. So I'll put this in the chat. I think there's someone here to discuss either Alex or punkage.
00:09:09.970 - 00:09:14.894, Speaker F: So yeah, I'm here, I can talk about it. I don't think Alex joined.
00:09:15.794 - 00:09:16.154, Speaker A: Great.
00:09:16.194 - 00:09:16.370, Speaker E: Yeah.
00:09:16.402 - 00:09:23.114, Speaker A: So pankaj, if you want to give us a rundown of what the outage, why the outage occurred and kind of details about what the fix does.
00:09:23.274 - 00:10:13.236, Speaker F: Yeah, sure. So the outage was figured because of a bug in the cache, it was triggered by a feature activation. There are certain features in the system which can impact or change the behavior of runtime. So activating that, those features mean that we have to recompile the programs before the next epoch when the feature is active. Otherwise the behavior of the program will change and it's inconsistent, basically when you load the program. So starting 117, we added a functionality where before we reach the epoch, few slots before we reach the epoch, we start recompiling the program using the new feature set and storing that in the cache. The exact bug was that if the program was not already in the.
00:10:13.236 - 00:11:26.654, Speaker F: So we built the list of programs to be recompiled using the current cache, and if the program was not already in the cache, it will not get picked as a recompilation candidate. And if that got loaded between those two instances when we picked the list and when we actually reached the epoch, that's when the bug was getting triggered. So this fix basically doesn't, it just uses the environment to see if the current and the next environment are different, and then it compiles the program with the correct environment instead of using that list as a guideline. So the PR is already merged to master and 118, we are thinking about 117, whether to merge it there or not. The bug can only be triggered if one of those features is activated, otherwise the bug cannot be triggered. And currently we own all those features, so we can control basically if mainnet can be impacted or not. So the decision is whether to backward the PR to 117 and make a release and let everybody upgrade, or just wait till 118 and activate those features at that time.
00:11:33.174 - 00:11:48.590, Speaker D: I mean, not to be flippant, but there's often this accusation that oh, someone can turn off Mainnet. And since this issue exists, it is the case that solar labs now can just turn off Mainnet. They can just enable a feature that will, you know, invoke this. So I think it just, for optics.
00:11:48.622 - 00:11:49.302, Speaker A: It would be good to get a.
00:11:49.318 - 00:11:52.054, Speaker D: Fix into Mainnet, just so that we can say that's not true.
00:11:52.214 - 00:12:01.964, Speaker F: Makes sense. The PR already exists, we're just debating whether to merge it or not, but if we decide that that's the right thing to do, we can just merge it and make another release.
00:12:08.184 - 00:12:09.524, Speaker A: Any other questions?
00:12:14.384 - 00:12:32.004, Speaker D: I mean, I don't want to put too fine a point on this, but this is kind of exactly the situation where the larger validator said it now is aware of an issue where a single entity can take down Mainnet. It may be our responsibility to take this patch whether or not Solana Labs decides to put it into their software. We're just putting that out there.
00:12:37.424 - 00:12:44.964, Speaker F: The PR exists for the backboard and it's all green, so we can probably just merge it and make a realize out of it.
00:12:46.864 - 00:13:27.634, Speaker G: I just want to add in here. This is really why we need a security council or some sort of multiseq to hold feature activation keys. Most keys are held by one engineer and there are constantly situations where, you know, we're mid upgrade between versions. 50% have upgraded from, you know, even a patch version 100 1722 100 1723, which, you know, maybe 23 has a different implementation of a feature. And one person, any, you know, whoever has that key could just trigger it and hold the network. So this really raises the importance of transitioning all feature activations into a multisync and away from individual or even individual entities controlling.
00:13:30.694 - 00:13:51.414, Speaker A: I do want to add that that work is ongoing. So I think Anza teams and firedancer teams aware of this and it's sort of like once Anza gets even close to main net, this is going to be a hard requirement, right. We can't just have one person with the ability to activate a feature. And I think all parties are aware.
00:13:56.354 - 00:14:02.414, Speaker G: Do we know how long the current backlog of features is? All of those are currently key to keys owned by one party.
00:14:05.954 - 00:14:06.826, Speaker A: Well, go ahead.
00:14:06.930 - 00:14:13.734, Speaker E: Yeah, just a moment. I'm checking. It's in the ballpark of between three and six months, but I'll have an actual number soon.
00:14:15.514 - 00:14:16.226, Speaker A: Okay, cool.
00:14:16.250 - 00:14:18.814, Speaker G: That's come down. I thought it was 18 months a while ago.
00:14:19.234 - 00:14:28.214, Speaker D: Yeah, you can run Solana features, um, to run mainnet and just see how many are inactive. That should be your rough estimate.
00:14:29.834 - 00:14:31.626, Speaker A: Just so anybody knows that they can.
00:14:31.650 - 00:14:33.094, Speaker D: Check this anytime they want.
00:14:44.214 - 00:15:13.854, Speaker A: You need to have a later version of the software. So if you're looking for 118 activations, you need to be running 118 on the Cli. There's a question about TD's. I prefer to do this in discord. I don't think it's relevant to the group.
00:15:29.394 - 00:16:02.634, Speaker E: Best guess, I'd say we have six months of. Of features in the queue right now. We activate. Yeah, it's two or three per week, one per epoch. And we try not to do weekend activations. Obviously we can go faster than one per epoch, but the idea there is that if there's a problem, we want the debugging to be simple and straightforward. The ones that are in the backlog right now could certainly be rekeyed around a multi sig.
00:16:02.634 - 00:16:34.494, Speaker E: If we were going to do that, I wouldn't want to rekey the next one that's in the queue, but we could give ourselves a buffer and say that starting two months from now, new features will all be multisig or something like that. Yeah, I'm all in favor of a better approach and any work that people are doing to drive that forward is appreciated. There are ongoing efforts with Fire Dancer foundation and Anza, but obviously competing against other priorities for people's time.
00:16:39.034 - 00:16:53.874, Speaker G: Thanks, Bill. Yeah, I think that'd be really awesome. Even if it's a multi sequence, just like, you know, train to yourself and you know, one other person on that, Stevie or something, it's already better. So yeah, we're really cool if we can get that going.
00:16:55.854 - 00:16:57.838, Speaker F: Well, is there, would there need to.
00:16:57.846 - 00:17:09.794, Speaker B: Be any code changes to make the key with the repeat if you wanted to point that to like the squads multi sig, even if it's just only other employees.
00:17:12.854 - 00:17:13.942, Speaker D: I think change it to.
00:17:13.958 - 00:17:15.554, Speaker G: A PDA by the mark.
00:17:18.473 - 00:17:34.533, Speaker E: Yeah, but I think it could be pretty straightforward. I don't know. I don't want to commit to anything without looking at the code. I don't think it's a substantial code change. I think the change is more if the organizational change is the more complex part.
00:17:39.193 - 00:17:40.133, Speaker B: Thank you.
00:17:44.654 - 00:17:51.754, Speaker A: All right, thank you, Will. Thank you, punkage. Any other questions about testnet? Otherwise they're going to move on.
00:17:56.854 - 00:17:57.634, Speaker B: Cool.
00:17:59.774 - 00:18:43.874, Speaker A: All right, switching gears, we had a validator educational workshop on the past month. Sorry I can't remember the exact date, but it is up on YouTube. The topic was basically discussion about what operators do when their node fails. It sounded like the general consensus was a backup validator is a good idea and highly recommended for mainnet operators. The sort of details in the discussion, I think really helpful got into details about, well, what happens if the primary node is not reachable and you can't copy over the tower. How do you decide what to do in those situations? So, really good chat. Thank you to Chris from Chainflow for suggesting the idea.
00:18:43.874 - 00:19:14.594, Speaker A: And yep, Max put the link to the actual video in the chat. So thank you. Always looking for new topics. So if you have a topic that you're interested in you want to hear more about, please message me. Otherwise I will come up with something from March 20 and message it before that date hits. So yeah, again, anybody have any ideas, feel free to mention them now or I will check in discord for ideas as well.
00:19:18.094 - 00:19:18.870, Speaker F: One question.
00:19:18.982 - 00:20:06.724, Speaker C: Didn't that call, if I remember correctly, you guys mentioned there was a way to do backups where there's like persistent storage running in the cloud fairly cheaply for a couple dollars a month, but there's no need to start paying cpu unless you need to go over to that. But I think Tim and Zan, you both mentioned that there's a lack of documentation and R and D experimentation around this. We're actually in the process of onboarding a new DevOps engineer who has some cloud experience. So I was thinking this might be a good opportunity for us to get involved. Is there any specific, like, requests, I guess, from the community for R and D on this? Or is it kind of just what you mentioned in that call and then a matter of, like, adding it to the docs?
00:20:07.944 - 00:20:30.980, Speaker A: Yeah, I mean, personally, I think that would be great. I sort of defer to will and Anza about if that's right, to put in their docs, but I think it would be a huge win to have just some idea of what to do as a being able to leverage the cloud is a hot backup that doesn't need to be on all the time, right?
00:20:31.012 - 00:20:37.184, Speaker C: Yeah, it sounded interesting. I've been waiting for the recording to go back, to go online so I can go back and listen to it and I'll do that now.
00:20:39.764 - 00:20:43.704, Speaker A: Very cool. Yeah. Well, what are your thoughts on that, or anyone else from Anza?
00:20:49.264 - 00:21:25.004, Speaker E: So we've hired a person that's going to be working on docs as part of their responsibilities. That's Rex, who will hopefully meet him in due course. So I don't want to speak for Anza, but for me personally, I generally like docs that are functional examples rather than just documentation. So internally, I will advocate that we should be willing to publish these sorts of things, not as this is the right way, but this is one viable way as a way to get people started on, you know, whatever their own solutions are.
00:21:27.304 - 00:21:28.644, Speaker A: Yeah, Zen, go ahead.
00:21:29.744 - 00:22:23.434, Speaker D: I think part of what you're going to have to do is a bit of a wider answer, a bit of a wider question, which is assuming that, you know, this would be handled by a cloud provider, because I don't know, I'm not that familiar with how all the different services offer on demand instances, but assuming I know aws does, and that's the example I used years ago, and that's what led to this discussion. And in that framework, you have to also pick a cpu configuration that works. And that was always part of the challenge. I could get it to work. But in a couple of months, I had to think about rejiggering it to a new cpu type because at that time, two years ago, things were advancing rapidly enough that the cpu you needed changed pretty frequently. That's perhaps a wider question you might have to answer in doing something like this. How do you do it so that it's viable longer term, and how does a person keep that up to date so that it stays viable?
00:22:29.214 - 00:22:53.334, Speaker A: Good feedback. Yeah. So generally, I think I'm supportive of this as well. If it doesn't make sense on the ONS aside, or at least, you know, not in the short term, it might make sense just to have Max, your team, make a write up and then have it amplified by the foundation. Definitely something that, you know, we want operators to be aware of and know about. Discover.
00:22:54.514 - 00:23:01.854, Speaker C: Oh, yeah, it sounded a lot cheaper, certainly, than running a whole other piece of hardware. So, yeah, it's something that we'd be interested in.
00:23:03.034 - 00:23:37.654, Speaker A: Sounds good. Right. Moving on. Changing topics a bit, checking the notes. Okay, so in the community led call yesterday, there was a pretty good discussion about timely vote credits. For those that were there, I don't think we need to get into all the details that we got into yesterday. The for background, this is the SIMD for timely vote credits.
00:23:37.654 - 00:24:13.470, Speaker A: SIMD 33. The. Well, maybe I'll let Zan sort of give an overview or a brief description of this, but the general TLDR is that timely vote credits enforces some time limit for voting. So if you're voting on slot a, you can't just vote 32 slots or however many slots later. And if you do, you will incur a penalty on your vote credits. So I'll put that link in the chat. The discussion on this change is happening in the salon tech discord.
00:24:13.470 - 00:24:43.314, Speaker A: In vote timely vote credits, there's also discussion happening in the Solana staking alliance. Discord. Quick summary here. There was a test cluster created, and Zen Tetsu did a write up of sort of the results and his findings at that test cluster. And from there, I'll kind of move over to either Michael or Zendetsu to kind of give people a state of what's going on right now.
00:24:45.574 - 00:25:43.164, Speaker D: Yeah, a lot of people out here probably weren't that meeting yesterday, so I don't want to repeat a lot of what was said, but we did have a great discussion and we, the documents you linked are the most up to date stuff that we've got so far, except that on the other discord, whose name I can never remember, that one has my proposal for what the vote proposal would look like. So if anyone has the comments there, I'd appreciate those. I think that I had also promised that I would create a tool that would allow people to see, kind of historically speaking, for past epochs, how the TVC change would have impacted their vote credits relative to everyone else, which is one of the most important inputs into what you actually earn in staking rewards for your stakers, the other being your commission. And I will do that. That hasn't been done yet. That's probably the next thing I'll do. And I almost kind of forgot that I was going to do it, so I'm been reminded now, and I'll get to work on that.
00:25:43.164 - 00:26:00.384, Speaker D: I think that most people will find that most people get a little bit better credits, and some of the effects of modded validators will be reduced. That's what I hope those will show. Michael, you have anything to add?
00:26:01.444 - 00:26:50.684, Speaker G: No, I think we really went over the cluster mostly yesterday. I don't think we need to go into that too much again today. Broadly, it seems to have, you know, shown that this change is workable and safe to be activated on kind of the process side of things where we are. I just shared the link to your discord message in the chat. So the next step is basically, you know, whenever you're ready in the next few days to post your official proposal, so to say, on the governance forum. Forum dot solana.com. And then we'll have a discussion period over a week or two, and then we'll do a staggered snapshot and then do a vote like we did in October.
00:26:57.584 - 00:27:54.662, Speaker A: Awesome. Any concerns or questions about the plan? Ashwin is on the call as well. I don't know if you want to add anything there, Ashwin, but no, just listening. Okay, so if there are no thoughts or feedback there, to me this sounds like a big win for the community. So, you know, at least from my perspective, I'm very happy that Zentesu did all this work and the whole community as well, kind of did the work to support this change. So very cool to see Ashland's mic's not working.
00:27:54.768 - 00:27:55.454, Speaker B: Cool.
00:27:59.674 - 00:28:17.974, Speaker A: Yeah. And Ashwin saying that from ons aside, he's ready to activate on testnet when the vote succeeds. Sounds good. All right, any other thoughts or points of discussion before we end it?
00:28:21.454 - 00:28:42.114, Speaker D: Well, one thing I would like to state, if there's anybody that has concerns about the TBC feature, please post them, because I've only really ever heard, you know, encouraging or supportive comments, and I would hate to get blindsided when a vote occurs with issues that we didn't get to discuss ahead of time, when people are really concerned about it. So please, please post if you have concerns.
00:28:45.654 - 00:29:28.134, Speaker A: Yeah, I want to echo that. I think, I think it would be a good paradigm for governance, at least personally. If the vote is not where we figure out people's opinions, that would, to me, seem like a failure of governance. We should really find out about it before the vote happens and at least know that people are concerned about something. So again, if you're concerned, please be vocal about it. All right? Leave it at that. So, yeah, the next call will be in two weeks as normal, but then the plan is going forward.
00:29:28.134 - 00:29:50.984, Speaker A: The next Solana foundation call will be a month after that, and the community led call will follow the foundation call. I'll make that very clear in the announcements going forward and probably change the name as well just to make it clear. Okay, cool. Thank you, everyone.

00:00:01.800 - 00:00:36.054, Speaker A: Pretty light updates this week. We've got a couple speakers here. So Chris and team from Dialect is going to talk about their new feature release to track slot features. So he'll give you the lowdown on that and just generally what dialect's doing. And then Brandon is here from inflect. He's working on a project to help benchmark some Intel CPU's and see if we can get some, some more insight into how intel is performing on a Solana validator. So he'll talk a little bit about what he's been doing and have some time for questions after that.
00:00:36.054 - 00:00:58.744, Speaker A: So let's dive in. First thing, network updates. There aren't too many updates to give right now. Pretty much the same as last time. We're working on getting quick out. The sort of the remaining items are the security audit. Whenever that's finalized, it will be out.
00:00:58.744 - 00:01:44.680, Speaker A: One of the big milestones in order to get it out is to get Testnet completely on 1.11. No timeline on that yet, but once 1.11 gets on Testnet, we can more reliably put quick on main net. So no definitive timelines yet, but working on it, we're getting closer. Also in the delegation program. For all those participating in the delegation program, we announced last time, the metrics requirement for the delegation program. I'm going to send out an update today with a new dashboard that you can check to see if you are reporting metrics, as well as a new updated spreadsheet that you can check to see if you currently are not passing the the metrics check.
00:01:44.680 - 00:02:04.764, Speaker A: So be on the lookout for that. We just have to run it today, but it should be out sometime today. Any questions about all those? Nope. Okay, well, then I'll hand it off to Chris and dialect to give a little intro about what they're working on and the product they just launched.
00:02:07.584 - 00:02:38.616, Speaker B: Thanks, Tim. Hey, everybody, this is Chris from dialect. I'll keep this very brief. Would love to tell you all a little bit about what we're building and then how that relates to the Solana feature updates that we announced yesterday that we worked with Solana foundation with on and also with Brian from Triton. So just for a couple minutes. Oh, I also have. We've got a huge storm here in New York today.
00:02:38.616 - 00:02:57.936, Speaker B: I don't know if anybody else is in New York. Hopefully I don't lose power. I've also got two members of the team here. I've got Kevin and Alexi, who actually did the main work here in the integration. So everybody say hello to Kevin and Alexi. Cool. Okay, so I'll just share my screen briefly.
00:02:57.936 - 00:03:21.794, Speaker B: I'm going to just give a couple minute background on what we do and then hop right into it. Let me bring up screen share. Ah, getting an error. Why is that happening? Let me just ring off and hop right back on.
00:03:38.314 - 00:03:43.774, Speaker A: Yeah, should be enabled. Hopefully he fixes the error.
00:03:58.454 - 00:04:04.798, Speaker B: Hey everyone, just going to give this. Can you hear me okay?
00:04:04.966 - 00:04:06.234, Speaker A: Yep, hear you fine.
00:04:06.614 - 00:04:22.722, Speaker B: Terrific. Let me give this one more try. 1 second. All right, I think that worked. Can you all see this?
00:04:22.898 - 00:04:23.974, Speaker A: Yeah, we see it.
00:04:24.354 - 00:05:04.996, Speaker B: Great, perfect. So what we're building with dialect is a smart messaging protocol for dapp notifications and wallet to wallet chat. And our vision is basically to build a new kind of messaging protocol on the Internet. For the last, what, 20 to 40 years, depending on how you measure it, email has been the primary identity in the Internet. But key custody and web3 and crypto in general introduces a new kind of identity, which is your wallet or your key pair. And it's very exciting new design space and what we want to do is enable messaging. It's just kind of a quirk of history that email, which is the primary identity in web two, is also a messaging protocol.
00:05:04.996 - 00:05:48.808, Speaker B: So dialect. We launched in early March and our v zero of our protocol is fully on chain messaging. We now offer both on and off chain messaging. Everything knows between key pairs. And we're powering Dapp notifications and wallet to wallet messaging for 15 or more of some of the most loved projects on Solana and also powering inbox experiences in some of the biggest mobile wallets on Solana. So we recently went live with Slope and you have like a full native mobile inbox experience for receiving notifications messaging with other users. So in the same way that a business will own an email address that it messages these users with with notifications, promotions, information, all of that.
00:05:48.808 - 00:06:24.976, Speaker B: In web3 we want to build a similar kind of foundational protocol. So ADAP owns a key pair that it messages with. What you see here is our main site and we offer some reference implementation. We're fully open source developer tooling, so we have reference implementations. Everything is available on our GitHub that power messaging experiences. Just going to authenticate with my wallet here and you'll see we have a twitter like DM experience for messaging and so I can click through. I think this is one of our team members and I can say message and this one is fully on chain.
00:06:24.976 - 00:07:03.330, Speaker B: The purple bubbles mean fully on chain and obviously with network performance recently this has been great. I can see that there's a status success there. However, we feel that notifications are really the dominant use case for messaging today. We think chat is probably a little farther off. So in the same inbox experience, I can also receive notifications. And so I can go to any number of the 15 or so Dapps across the ecosystem and sign up to receive notifications, and then they'll get delivered to that same inbox. And so what we launched yesterday and that we're really excited to support our Solana feature updates.
00:07:03.330 - 00:07:51.320, Speaker B: And so Brian from Triton and Jacob from the Solana foundation recently reached out to us and said, hey, we'd love to see if dialect can power sending messages and notifications to anybody who wants to hear about future updates with Solana. So we spun up this little part of our site here. It's just like a sub URL on our site, and users can opt into the wallet notifications, which this is what we mean when we say using the wallet to wallet messaging protocol. But we also support, as you can see here, we support a lot of the favorite web two channels. So you can sign up and enter your emails. I can do Chris, I can submit my email and I won't do this right now, or maybe I will. Let me just see if I get that email.
00:07:51.320 - 00:08:42.674, Speaker B: You just get a verification code, and there it is. Let's plug this in eight 2299-582-2995 and I click submit. And now I'm basically anytime there's a feature update for Solana and get into a little bit how we implemented that, I'll get both an email and a direct to wallet notification. I'm just going to stop there. There's all kinds of neat stuff that work on our roadmap. The main thing, okay, maybe I'll add one more thing, is it's not merely enough to implement messaging in Web three. We actually think that to help shepherd in broad adoption in web3, we need to build delightful and interesting new consumer experiences to help bring on those first hundred million or billion users.
00:08:42.674 - 00:09:28.960, Speaker B: We're working on something we call smart messaging. Just to get very concrete very quickly. Smart messaging is something unique you can do in web3 that you can't do in web two, because you carry the same authentication with you everywhere, because you authenticate yourself with a key pair and you carry that between every dap. There's a world in which we can build an open standard for messaging where you can not only read the message, but you can take action right in the message. And so any one of these inboxes that we're building and the developer tooling that we're building it for, or building it with, we're basically building like an extension of a link preview. So a link preview gives you a rich image and a lot of other information that you can parse and read based on a URL. In web3, you can also add a button.
00:09:28.960 - 00:10:03.634, Speaker B: And so one thing we're particularly excited about is the smart message, and that means I can get a message into some web3 inbox from an NFT exchange saying so and so has placed a buyout request on your NFT. And right there in the message I can click accept it and sell. And then, same for some of the core foundations in Defi, if you're at risk of liquidation, you get a warning message. You can do a quick deposit. So that's just something that we're really excited about. That makes web3 messaging more interesting and potentially more delightful for users than web two. So that's what we're up to.
00:10:03.634 - 00:10:22.734, Speaker B: I don't know exactly what the smart message equivalent would be here for Solana validator, Solana updates, or developers or validators or any of that, but we were really excited when Brian and Jacob reached out, and we're happy to build this. So yeah, I'm happy to stop there. Any questions?
00:10:23.674 - 00:10:30.094, Speaker A: There's a question in the chat, essentially, around encryption, of the messages, if they're encrypted on chain, or if they're plain text.
00:10:30.914 - 00:11:08.444, Speaker B: So it depends on the use case we support full end to end encryption today. The challenge, however, is not every wallet chrome extension supports encryption. So we've been working actually closely with Solana Labs to extend the wallet adapter spec to make sure that there is an encrypt and a decrypt method exposed by the wallet adapter. And in that scenario, then every single message can be encrypted. But the way we've gone about it is for user to user messaging. We encourage folks to do end end encryption. It just limits which chrome extensions they can use, which wallets they can use for DAP notifications.
00:11:08.444 - 00:11:42.204, Speaker B: For example, take the buyout request for the liquidation alert. That information is already available on the blockchain. You can already see that an account is at risk of liquidation. And so it's just a human readable form of something that's already public information. And you save at least for on chain messages, you save about 40 bytes of overhead per message by leaving them unencrypted. And most projects that we've integrated with have been fine with that, however, we just want to build toward a future where everything is, by default, encrypted. There's just a little bit of coalition building and standards adoption that needs to be done in time for that.
00:11:42.204 - 00:11:51.804, Speaker B: Tim, I think you might be muted.
00:11:52.664 - 00:12:16.876, Speaker A: Any other questions for the team, is what I was asking. All right, well, thanks, guys. And I appreciate, or not appreciate, I suggest everyone take a look at the tool they built. Super useful for validators to know when updates are happening, when feature activations are happening, just to keep up to date in the ecosystem. So thanks, Chris. Thanks, Dialette. Thanks, the whole team.
00:12:16.900 - 00:12:17.864, Speaker B: Thanks, everybody.
00:12:19.404 - 00:12:25.624, Speaker A: Cool. All right, I'll kick it off to Brandon now to talk a little bit about the intel work he's been benchmarking.
00:12:27.084 - 00:13:05.774, Speaker C: Hey, guys. Yeah, so I guess to just kind of give a little bit of overview, Brandon Stanley. I work currently for inflect, helping kind of manage and run the Solana server program from a provider level. Prior to working for inflect, I worked at Equinix Metal and helped with kind of the technical implementation of the Solana server program with that specific provider. In my time there, I worked a lot with some of the major rpcs and a couple of validators and just seemed like there was a really huge preference to be on AMD. And more specifically, it seems like it's coming around now. Kind of the Zen three Milan based hardware seems to really kind of have everyone's attention.
00:13:05.774 - 00:13:52.412, Speaker C: But one of the core goals of the server program seemed to be to help build a redundant and diverse network, which seemed like a pretty big risk to have a huge chunk of that running off of a single manufacturer. So that kind of led me to ask the question, why is no one using intel? And just to travel down that road, I went and got access to some iselac systems and just did some really basic benchmarking. So all I'm doing right now is using the Solana benchmark or cluster benchmark utility, which I know has some flaws. It isn't necessarily a like, for, like, test. Just to be really clear, the information I'm planning on putting out isn't necessarily definitive. This is exact performance you're going to get. I'm really just looking to do more of a litmus test.
00:13:52.412 - 00:15:11.104, Speaker C: Right. Is there significant performance gains on this versus something else? Is it somewhat equal and kind of give some information back to the community about other potential solutions that that could work? In my kind of initial testing, I found the ice lake systems to be very much on par even with the Milan based systems, specifically the 70, 513s that I've been testing, and then actually, in certain cases, getting significantly better, on order of 15% to 25%, increased performance over those Milan systems. So at that point, we reached out to intel directly and asked them to kind of help validate with the ice lake systems. They've put a lot of architecture work into the chip to try and make it much more performant for cryptographic type functions. And I just wanted to make sure, I guess, that I was running the right tests and I was seeing the right results. And that's led to a bit of a partnership where they're doing a very deep dive into not just kind of the results that we're seeing, but what we can do to actually tune these chips, whether it be a BIOS settings, a number of different ways to really maximize the performance that we're seeing out of the intel side of things. It really seems to be bearing fruit at this point.
00:15:11.104 - 00:16:20.192, Speaker C: I was holding off on jumping on this call just because I wanted to come in with some defined reports and actual values and be able to make a strong case with hard data. But as you can imagine, working with a large OEM like intel, things just move a bit slower at times. And they have protocol and procedures around putting out white papers and making sure that it's peer reviewed and validated. But, yeah, I guess I really wanted to come here and just, I guess, start putting that message out that it seems like the ice lake systems run very well, run salad very well, I should say, and kind of get some feedback from the community as to what sort of benchmarks would be valuable to the community. What things and tests would you guys like to see that would actually be worth us building out a more robust testing protocol around? It's really tough with constantly changing versions and trying to get something that's somewhat clinical, get a like for like, test that we can run across all systems. But my hope is to be able to really kind of expand this program out, not just to intel. Amd.
00:16:20.192 - 00:16:42.344, Speaker C: I've done some work with arm in the past to see what we can do there and if there's any options, as well as just new versions, and then potentially even looking to building out some sort of community space where we can start sharing information about specific configurations, bios tweaks, and just start to kind of quantify some of the community knowledge that's out there.
00:16:43.804 - 00:16:59.644, Speaker A: So a couple things in the chat I'll jump in with real quick. Blake says he's run intel from day one and found the performance to be pretty on par. So that's a good data point. Artemis Cloud, I guess, is asking what's the best way to contact you.
00:17:00.504 - 00:17:19.500, Speaker C: Yeah, if you just want to either hit me up in discord. I'm Brandon Dash inflect. I'm in the Solana discord group. Or if you want to send me an email at Brandon Branden flect.com, both would be awesome ways to kind of get in touch with.
00:17:19.632 - 00:17:27.424, Speaker A: I'll just add that in the chat. Let me find your discord here.
00:17:30.084 - 00:17:31.464, Speaker C: I'll shoot it to you.
00:17:32.804 - 00:17:33.676, Speaker A: Got it.
00:17:33.820 - 00:17:34.584, Speaker C: Sweet.
00:17:35.804 - 00:18:05.284, Speaker A: Okay, so Brandon's email and his discord handle is in the chat. Lucas has a question here. Run AMD and Intel RPC clients. Run slot. Subscribe other same data centers. Oh, okay. I guess just a suggestion here from Lucas to try running AMD and intel RPC clients in the same data center and have subscriptions on both AMD and intel and see what the performance looks like.
00:18:06.504 - 00:18:46.294, Speaker C: Yeah, I think that's an awesome approach and it's definitely somewhere we want to get. There's some technicalities, right, with doing this around, making kind of a like, for like test whether that be, you know, the amount of traffic we're throwing at it, kind of the environment that it's in, the amount of stake that's on it. There's a number of things that are kind of a pain. So I, I'm all for any options we can, suggestions, I should say, on, on ways to test this in a systematic way. Definitely keeping things in data center makes sense. Cool.
00:18:46.754 - 00:18:48.378, Speaker D: Can I chime in here, Tim?
00:18:48.506 - 00:18:49.574, Speaker A: Yeah, go for it.
00:18:50.394 - 00:19:02.774, Speaker D: Brandon, quick question for you. The results you're seeing, what is the base clock that you're like? Are you seeing any discrepancies between lower base clocks versus higher base clocks on the newer generations?
00:19:04.054 - 00:19:54.696, Speaker C: Base clocks, actually I haven't played as much with the previous generation intel, so I don't have great data points on that. And all of the systems I should say that I've been testing are bare metal systems with BIOS access. So we're putting everything in like a performance mode where it really kind of flexes that clock speed to kind of whatever the maximum that the chip can handle from a thermal standpoint or a TDP standpoint. So the base clock is only sits there while it's running idle and then it kind of maxes out to whatever it's going to allow it to based on the configuration. So on the ice lakes running at 32 cores, we're seeing roughly, actually very steadily about 2.59 GHz is kind of where those operate and kind of level out at. So I've been running most of these tests for a minimum of 2 hours.
00:19:54.696 - 00:20:34.734, Speaker C: I've done some for up to 24 hours just to make sure we fully heats up the systems and kind of let them settle in. And I can get you the exact model number of that processor. I'm a little limited in what I have access to, at least at this stage. If we can get additional community interest, I think that builds kind of a business case for budget and reaching out and touching more processors, potentially utilizing that relationship with intel to get access to some stuff. But my goal is to really stay agnostic. I don't want to lean on them for access to anything, just from the standpoint of make sure there's no bias. Does that answer your question?
00:20:35.074 - 00:20:48.654, Speaker D: Yeah. What about on the RPC side? Have you tested on the RPC side as well as the validator side? Because I know it's Tim Cooker. If I'm wrong, isn't it more single core focused?
00:20:51.094 - 00:20:57.394, Speaker A: Yeah, I mean, different characteristics depending on what type of request you're making to the RPC, but yeah.
00:20:58.414 - 00:21:36.654, Speaker C: So from the RPC standpoint, I'm just working directly with some large rpcs. I didn't really ask if I could drop names in here, so I'll just leave it at that for now. And we can definitely put more information out as we get some of the feedback. But we've provided a number of these systems to kind of community members to go and do their own performance testing. Again, that's not going to be super definitive, like hard numbers. Right. But just as a kind of a quick gut check of does this line up with the testing that we're doing, are we seeing similar results? Hoping in the next week or two to kind of have some better information from the RPC community on how these are, how they're working.
00:21:36.954 - 00:21:37.474, Speaker A: Got it.
00:21:37.514 - 00:21:40.690, Speaker D: Thanks, Brandon, for your help. Really look forward to seeing your results.
00:21:40.882 - 00:21:41.434, Speaker A: That's awesome.
00:21:41.474 - 00:21:49.972, Speaker C: I've heard that from a number of people. It's kind of fun to work on something that I get to nerd out on and people, people seem to enjoy the results of.
00:21:50.108 - 00:22:03.252, Speaker D: Yeah, it was one of my first questions actually coming into the community is why are we all AMD focused? I own a data center myself and have access to a lot more intel than I do AMD, so this is super exciting for me. So greatly appreciate it.
00:22:03.428 - 00:22:33.214, Speaker C: Yeah, no, and if there's a reason for it, like, let's document it, right. Let's work and figure out what the solutions are. But that was kind of the weirdest thing for me coming into it was that I just couldn't find any reality data to support it. And then as I dug a little bit deeper, it kind of seemed like a lot of the information was hearsay, and it was based off of, you know, couple year old hardware, which, you know, in this world doesn't hold up. Anybody else have questions? Anything else I can help with? Feedback?
00:22:35.714 - 00:22:40.242, Speaker A: Blake said he's going to reach out to you with some more data points since he's been running an intel system.
00:22:40.418 - 00:22:41.746, Speaker C: That'd be awesome. Thank you, Blake.
00:22:41.850 - 00:22:59.586, Speaker A: Yeah. Yeah. Any other questions? All right. I guess we'll end it there, then. Thanks, everyone, for joining. Thanks for turning on your videos and seeing everybody, and see you all in two weeks, I guess.
00:22:59.650 - 00:23:00.294, Speaker B: Bye.
00:23:00.594 - 00:23:00.994, Speaker A: Thank you.

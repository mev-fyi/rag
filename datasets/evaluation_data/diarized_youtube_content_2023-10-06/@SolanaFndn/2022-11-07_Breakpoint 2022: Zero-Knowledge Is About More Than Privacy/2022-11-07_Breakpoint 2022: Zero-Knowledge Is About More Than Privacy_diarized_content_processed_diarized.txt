00:00:04.480 - 00:00:47.634, Speaker A: Hey, guys, how's everyone doing? So today we have a pretty distinguished panel of cryptographers and ZK builders really honored to introduce Don Beaver, head of cryptography at Jump Crypto. Joret, core contributor to light protocol. And we've got Yannick from Elusive, so he's the co founder of Elusive. So I want each one of you guys to introduce yourselves. Let us know how you got into crypto, how you got into the ZK space, and what led you to developing this kind of new technology.
00:00:49.334 - 00:01:21.862, Speaker B: You pick an order, don't start. Thanks, aid. So I got into crypto a long time ago when I was doing my PhD. It was kind of breaking news at the time, and back then, crypto meant cryptography. Not so much cryptocurrency at the time, although there was plenty of thinking about cryptocurrency. I got really intrigued by this branch of cryptography called multi party protocols, which is essentially secret ballot elections. And it overlaps a lot with the zero knowledge topic that I think we'll talk about a little more today, which is looking at computations, making sure they're either executed correctly, and.
00:01:21.862 - 00:01:56.410, Speaker B: And also making sure that you can show that they're executed correctly after the fact. In those days, cryptography is a little different than now. It was a much more theoretical place to be, but it's still intellectually incredibly fascinating. I think the first time I started writing papers was probably sometime in the nineties and had pretty much a relatively academic career before jumping into kind of more applied things over the years, eventually ending up in the last year at JMP doing very applied cryptography and hopefully moving the world of zero knowledge into real implementation. That's it.
00:01:56.522 - 00:01:57.258, Speaker A: Awesome.
00:01:57.426 - 00:03:18.528, Speaker C: Hi, my name is Jord. I started out in crypto in 2017. First of all, I was very fascinated by icos back then and really got me really motivated to look into all these blockchain projects. And what actually got me to stay were like, the ideas about these decentralized systems and in particular decentralized autonomous organizations. And that led me to really work towards being able to build such protocols myself. And over the years going towards that, I got really hooked on what I just found was the most interesting thing, the most interesting problem to solve, which was really missing for mainstream adoption, which is privacy, which got me towards zero knowledge proofs. So I worked a bit on private voting prior then to leading and realizing that this was not going to be actually usable by anyone, which led me towards looking to implement this on Solana and looking to implement a more general platform such that not only private voting is possible at scale, but other applications as well.
00:03:18.528 - 00:03:49.904, Speaker C: So these are kind of the origin story of light protocol, which we started out last summer, first building a proof of concept, then open sourcing the first proof verification in the beginning of the year in January. And we're live on Mainnet since May this year, and completely open source and looking to work towards this vision of a completely private ecosystem on Solana.
00:03:51.364 - 00:04:51.396, Speaker D: Yeah, hi, I'm Janik, the co founder of Elusive, and my origin of getting into cryptography is through university. So studying computer science and math, you hear about elliptic curves and actually multi party computations. So it's kind of cool to sit on stage with Don Beaver, who's already written papers about those topics when I wasn't even born. So, yeah, we have multiple generations of cryptographers here, really. But. But seeing elliptic curves and encryption algorithms using elliptic curves, I got interested and started studying math next to studying computer science. And after meeting with our co founder Nico, who for some years has done crypto and distributed systems research, I decided to fully commit to cryptography.
00:04:51.396 - 00:05:54.794, Speaker D: And then we together got into CK space. And from our political belief system we realized that the best energy is spent on building privacy solutions basically on the blockchain, because there are many pride minds building this, but not enough pride minds. So we decided to build it on Solana and have, similarly to what charit and his guys are doing, built multiple proof verifiers already, aren't yet open source, but have been audited by some great auditors and plan to move into mainnet next month with both our privacy protocol that really isn't just a privacy protocol, but the first protocol of its kind that uses zero knowledge proofs both for privacy and also for decentralized compliance and our general purpose, serial knowledge proof verification, virtual machines. That's all I have to say.
00:05:55.694 - 00:06:16.584, Speaker A: Nice. Nice. I mean, as Yetik mentioned, it's an honor to have Don here, someone who's been in this space for so many years studying zks and doing research on that topic even prior to crypto. So maybe, Don, you can give us a history of how did zks come to be? What's the history behind this piece of technology that everyone's talking about in crypto?
00:06:16.734 - 00:06:57.590, Speaker B: Yeah, let me see if I can riff on this a little. Kind of three stages of it, the first of which I wasn't there for at all. This brilliant couple of researchers, Shafi Goldwasser, Sylvia McCauley, then at Berkeley, kind of were riffing. They were in graduate school, they were riffing on this idea of, how would you play mental poker? How would you play poker over a phone and pretend, you know, someone dealt the cards, and the other person on the other side would say, oh, you know what? I want to draw, too. They worked on this problem for a while. It's a problem that Manuel Blum suggested to them, fascinating thing. At the end of this, they kind of said, well, we got a way to do it, but we don't know exactly how to show that this interaction was done correctly.
00:06:57.590 - 00:08:08.000, Speaker B: And this kind of led them to be inspired to come up with this notion of, how would I tell somebody over the phone that I shuffled the cards correctly, I dealt them correctly? And that led them into the theoretical aspect of knowledge proofs. And at that point, it kind of burgeoned into a very theoretical space. The space was, hey, what could an alien come down and tell us that we really couldn't do ourselves? What could an alien tell us about some brilliant theorem in the universe and us being merely human? Polynomial time algorithm, people with weak laptops, how could we check what an alien could try to convince us of? And in those days, very, very theoretical days, it was to say, oh, look, you could produce proofs of these incredibly complex things that are beyond our own means to produce, but we could be the auditors and figure out how to check those proofs from aliens. That was kind of the second phase. There was a long and rich theory, rich phase of looking into the theory of what could you do here. Then, more recently, in the last decade and a half or so, everything got scaled down. And the fascinating thing about how everything got scaled down is that it got scaled down to something that is practical.
00:08:08.000 - 00:09:01.458, Speaker B: So instead of aliens showing something to us as mere humans, now it's computers running polynomial time computations, trying to be verified to something that is incredibly, incredibly weak, a tiny little checksum of, like, a medium program. A medium program. So instead of, like, a giant alien intelligence coming and trying to explain something to a human, you've got a human level laptop data center trying to produce something that's checkable by a very, very weak computer. And what's great about that scaling down from, like, exponential to poly poly down to log time sort of thing, if you get too nerdy about it, is that at this scale, you can start to look at computations that you want to land on a blockchain somewhere. Solana, you don't want to pay the expense of doing the computation. All you want to do is say the output of this computation was x, y, z. And now at that scale, you can check them very quickly.
00:09:01.458 - 00:09:55.504, Speaker B: And that, I think, is one of the most fascinating aspects of this. The other obviously fascinating aspect of this, which is huge, which I let the co panelists over here talk to as well, is the privacy, which is also fascinating. It's not merely the fact that you can scale things down to a place where you can check complicated calculations and not be lied to, where you can audit them in super fast time. It's also that you can audit them in a private manner, almost for free as well. So both of these have come to kind of real fruition, you know, in recent years, and we're seeing the impact of it right now because it's a great way to scale out blockchains in ways that otherwise are, you know, they're not exponentially expensive, but they are somewhat prohibitively expensive. We get them down to a scale where things actually run really, really fast. So I'm very excited to see that third phase of zero knowledge and verifiable proofs coming into fruition.
00:09:56.444 - 00:10:28.634, Speaker A: I love that story. It starts out with people wanting to play poker over the phone, and it leads to a 25, 30 year kind of academic endeavor. And I think it's kind of applicable because poker today, you still really can't play poker on chain without zks, hopefully unlocking that ability. So maybe a good question is, what's the difference between verifiable knowledge and zero knowledge, and how are people using that today?
00:10:30.014 - 00:11:05.038, Speaker B: I'm happy to jump in to start with, and you guys are really the privacy you guys want to talk about? I'll talk about the verifiably a little bit. So zero knowledge has two parts to it. It's got an interactive proof part of it, and it's got a privacy part of it, and you can mingle the two, which is great. One of the initial benefits of having the verifiability of it is that even without the privacy, you can land correct computations. If you've got a million step calculation, you can condense it kind of like you do a checksum. You add up all the digits on your credit card and they add up to 73. And if you transmit it and you don't get 73 on the other side for the sum of the digits, you know, you'll say you'll find out something is wrong.
00:11:05.038 - 00:11:53.456, Speaker B: Well, you can take the verifiable computations the same way. Do a million step computation, land that computation on a chain somewhere and say the output is, you know, 73 or whatever it is, x, y, z, but you don't have to repeat the entire million step computation. So there is a verifiable scaling compression side to zks that is incredibly exciting because that's the part that actually makes it possible to get efficiency where there wasn't efficiency before. So you can really, really just do your calculations off chain and then do a really quick verification check on chain. So the idea of figuring out what calculations can you do, really long calculations, but what calculations can you verify really quickly is really critical to this. And there's been a ton of study on this in recent years for how to, like, boil long million step calculations into three step calculations. Get those correctly on the chain.
00:11:53.456 - 00:12:05.364, Speaker B: Now, wonderfully, you can also actually add privacy in there as well. And I think, you know, that's definitely what excites all of us on the stage. And I should turn this over to people who love the privacy as well.
00:12:06.464 - 00:12:37.486, Speaker C: Yeah, exactly. So I mean, I think in general, like, transparency on blockchains is sold as a feature. Right. In general, like, it's great. Everything is democratized, everything is transparent. But if you actually think about it, like business in the web, two, in the real world is not conducted always transparently in public. And that has good reason, because you don't want everything to be public.
00:12:37.486 - 00:13:20.426, Speaker C: Right. So zero knowledge proofs are very interesting because you can basically, you can make it very easy to verify that the statement is true without actually revealing anything about the statement itself, just that it's true. Right. And so with this, you can potentially build applications which are just as cryptographically verifiable and sound as the blockchain itself, but without actually revealing the data which is being used. So you know for sure everything is correct, but only the people themselves have ownership over their data and can actually verify it.
00:13:20.610 - 00:14:08.414, Speaker D: Yeah. And it's basically two terms you can think about. It's computational asymmetry, that's basically verifiable computations, and it's informational asymmetry. So you have a computation environment, the blockchain, where you want efficiency, and for that reason, you want to outsource the computation out of the blockchain and have basically two parts of the computation, the generation of the computation and the verification on chain, that's the asymmetry. And for the privacy, that's the same thing. Now, in my computation environment on chain, I could perform my computation, but I don't want to do that simply because then all my secrets will be leaked. So there we have the informational asymmetry that's all powered by zero knowledge proof.
00:14:08.414 - 00:14:32.834, Speaker D: So it's basically the verifiability is the main property, and privacy is a property that you can use or not use, depending on your focus, what you want to do. And that's really the beauty, because zero knowledge is about way more than just providing privacy, it's about changing the world. Yeah, yeah, yeah.
00:14:32.914 - 00:14:55.298, Speaker A: That's a really good point. A lot of people think zero knowledge is only focused on privacy, but it has so many benefits in terms of scalability that you can use. This question is for Jordan and Yannick. I want you to tell the audience a little bit about your experience implementing zero knowledge verification on Solana. Maybe Jorah, you can lead us off.
00:14:55.426 - 00:16:04.138, Speaker C: Yeah, awesome. Yeah, that was a really interesting journey, because, I mean, the Solana runtime is so constrained both in compute and in memory, that the way actually we started out building this was we just took a cryptography library and tried to run it on chain, and of course it immediately blew up like nothing worked. And so we started to basically get into it, profile it, see? Okay, what can we make work within these constraints? And back last year, it was just 200k compute units. Right now you can go up to 1.4 million, which makes things much easier. But we started out really with that. So we really put like, for our proof verification, which features like a pairing and some multiplications and additions before took like 1500 steps, which is actually deployed right now, which we really split into these small chunks, which we just execute over a lot of transactions right now.
00:16:04.138 - 00:16:30.296, Speaker C: So with the bigger compute budget, that got much easier. And I actually rewrote a version where you actually can see the algorithm in its actual form and just save state at right sizes. But, yeah, and I'm sure we can like do much better further optimizations on there in the future and make it run less transactions.
00:16:30.360 - 00:17:34.860, Speaker D: Yeah. So we were actually quite happy that Solana allows development with rust. So what we did to solve the issues that Troy just described is we've built an interpreter in rust that basically is a macro that then uses the different computation steps. So you have all kinds of multiplications, additions, field arithmetic, elliptic curve operations for your serial knowledge proof verification. We took this complex computation and put our interpreter around it, and this interpreter then automatically splits it into the packages that the chain can handle from compute budget, from memory perspectives. And we've applied some additional optimization. So, yeah, batch verification depending on network throughput and optimizations in dead scenarios and zero knowledge proofs always tie together with building some accumulator structures on chain.
00:17:34.860 - 00:18:13.234, Speaker D: Right. So you need mercury trees, you need to build them, and you need many insertions into those mercury trees. And those mercury trees have also computation intensive hash functions. And, yeah, so we've also built some interesting functionality around that, around queuing commitments to be inserted about dynamic batching based on network through throughput to really bring down the cost to basically, on high throughput days, zero. So, yeah, awesome.
00:18:15.654 - 00:18:38.834, Speaker A: I guess this is for everyone. But what do you think are the biggest limitations or bottlenecks for widespread adoption for zks across crypto right now? Where should we be focusing? Where should developers in the ecosystem be focusing to help this technology kind of proliferate and kind of start taking advantage of the scaling properties that zks can offer?
00:18:40.134 - 00:19:07.872, Speaker B: Happy to jump in. Yeah. So what Yorit and Yannick are talking about here is really the core of it. It's people rolling up their sleeves and actually getting down to implementing the zero knowledge. And I think this is actually the most exciting part to be working in right now. Plenty of theoretical results. There are not very many truly practical algorithms, implementations, I want to say not algorithms, plenty of algorithms, not too many really great implementations.
00:19:07.872 - 00:19:50.544, Speaker B: And so when it's actually, you know, writing the code and getting this, you know, rubber on the road, that's where we find out what the pain points are. That's where we figure out which algorithms are better than the other algorithms. That's where we actually kind of bring this into real life and real practice, and we start getting the benefits of scaling computation the same way that here has been announced. Scaling up storage. How do you scale up storage? You create merkle trees that can, in a short string, map a very large piece of storage, and you figure out fast ways to do that. What we're working towards here in practice, and in algorithms as well, is to work towards a world where you can take large computations and condense them into something short. And I think that the work that you guys are doing is really at the core of all of this.
00:19:50.544 - 00:20:12.924, Speaker B: Lots of people trying to implement this, trying to compare what goes the fastest and then running with that and using the pain points that you, when you try to implement it, that's really where you come to the really interesting topics to work on, both from implementation and from, you know, algorithms, discovery, theory, practice, you know, across the board. That's what generates the interesting problems in the right directions to work on.
00:20:13.544 - 00:21:19.110, Speaker C: I agree. Like, in addition to what don just highlighted, I think what is really lacking is the developer experience. It's very hard to actually build on these very few libraries and primitives exist in some constrained systems, and languages only allow you to write quadratic constraints, which leads to very interesting workarounds you have to do to actually encode more complex computation. So I think this is another very interesting area to focus on to actually have higher level languages which are maybe even proof of system agnostic, which you can compile down to these different proof systems such that you have built a stack of these different layers which might even take advantage of like optimizations in systems like LLVM. Right. I know that there are some projects working on this, so that's another really interesting point to focus on.
00:21:19.222 - 00:22:31.150, Speaker D: Yeah, and the big issue really is the more complex calculations we want to put into the proofs, the verification part stays constant time, but the proving gets more complex, just is bloated. And for that reason we might need different solutions for that. So what we also started a bit of research and development in is for, for example, when doing signature verification, we on curve 250 519, for example. So instead of implementing the ShA hash function directly in the zero knowledge proof, we only need to put the important stuff in the zero knowledge proof and can perform hashes publicly if the messages are publicly by default, and don't need everything in the zero knowledge proof, and run all computations on the hardware that are required. So they are required and optimal to run on. Right. So basically, thinking about building recursive proofs and finding ways to arithmetically prove statements in order to outsource computations outside of zero knowledge proofs, I think we need some sort of hybrid solutions in that sense.
00:22:31.150 - 00:22:31.794, Speaker D: Yeah.
00:22:33.794 - 00:23:05.794, Speaker A: I totally agree. I really like your point, Jord, about more developer tools is going to help everyone in the ecosystem start building this stuff more. We need someone to build the next anchor for ZK stuff. Right. I want to throw it to you, dawn, and talk a little bit about we had this week Kevin Bowers from jump. Talk about fire dancer and what the fire dancer team, a research team at JMP is working on. It's been awesome to see all of the success that they've been having and how excited the community is behind that.
00:23:05.794 - 00:23:27.094, Speaker A: I want you to drop some alpha for these guys on Project Cyclone. That's another research team at JMP that's focused on ZK and not just theoretical, but actually it's applied research. So they're doing hardware acceleration, they're doing a bunch of work on the software side as well. So if you want to give some people a little background on that.
00:23:27.254 - 00:24:25.254, Speaker B: Sure. Yeah. So in addition to, you know, this whole, you know, usability stuff, which is extremely important, you know, what does it mean to have constraints? What does it mean to boil them down into a particular system? You have at the very bottom, bare metal level of all of this elliptic curve calculations going on like crazy tons of really nasty arithmetic that kind of almost fits within, you know, current cpu's and GPU's. That's where everything boils down to. It's like signatures and encryption. These are the basic tools that you run into when you're trying to prove that this large set of constraints are all satisfied, that this calculation you made was done correctly, that an audit would come out to say, yes, it's all correct. So cyclone, for example, is one of our projects at JMP where we have looked into, really the depths of how do you do as fast as you can, either in FPGA or actually in software, how do you do these elliptic curve calculations? And it brings in a ton of different ideas from different areas, things like looking at fast Fourier transforms.
00:24:25.254 - 00:25:13.454, Speaker B: And Kevin Bowers, as you mentioned doing, did work on this ten years ago that was actually really quite useful here. That cuts things off just algorithmically by, cuts things down by maybe a 10% factor. So you can take a bunch of tricks like this. And I think, as Kevin was saying yesterday and the day before, these games at the bottom, bare metal layer are all about premature optimization, which is a little bit of heresy, but they're about optimizing every single branch of every single computation you can to get the lowest latency and the highest throughput that you can. So we've been looking very intensively at this, and cyclone is a multiscaler multiplication package that does things on FPGA's in rather fast ways, which a large team of people really worked on for a long time. And I think we're very proud of that. And hopefully it can be used across the board for anybody who wants to implement these proofs as well.
00:25:14.314 - 00:25:23.354, Speaker A: Okay, well, we're running at, you know, they're signaling time. I want to thank our guests for coming out. This has been a great panel. Thank you, guys.
00:25:24.454 - 00:25:26.166, Speaker B: Thank you, Saeed. Thank you all.
00:25:26.230 - 00:25:26.494, Speaker A: Thanks, guys.

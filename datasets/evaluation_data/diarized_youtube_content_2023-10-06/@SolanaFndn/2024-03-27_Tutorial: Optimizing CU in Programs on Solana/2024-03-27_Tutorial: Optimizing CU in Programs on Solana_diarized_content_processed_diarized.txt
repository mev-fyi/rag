00:00:03.400 - 00:00:44.740, Speaker A: Hello everybody. Today we're going to talk about compute unit optimizations on Solana, especially in programs. This is currently a hot topic because many people have problems like landing their transactions on Solana. And so I think it's a good time to talk about how it actually works and how you can optimize it in your programs. So every block on Solana has a capacity of 48 million ceus, and this is another 12 million CU per write account. So if you have like a big Defi project and everyone wants to write to your account, it will be anyway blocked at 12 million cus and one transaction can have a maximum of 1.4 million cus.
00:00:44.740 - 00:01:44.994, Speaker A: If you exhaust the limit that you requested, then your transaction will just fail. And currently some cus don't really cost anything extra, but the default cost is actually 5000 lampards per signature. This originates from the beginning of Solana, where the feeling was that the signature verification will be always the most expensive thing in the transaction. But with all the stuff going on now, like with p nfts and games and all that stuff, this of course isn't true anymore. So today I'm going to show you how you can optimize your programs for CU, or in particular how you can analyze your CU to optimize it yourself. So there are a bunch of benefits if you optimize your transactions, because like a smaller transaction will have a better chance to get into the block actually, especially with the current scheduler implementation, because if everyone just spams like 1.4 million CU transactions, then the scheduler doesn't really have a way to figure out beforehand how many transactions he can fit in.
00:01:44.994 - 00:02:29.920, Speaker A: But the blocks are actually packed by the used in a transaction and not by the requested cus. And then currently also everyone is requesting way more fees than they actually need because after a certain point it doesn't really help much to increase your fees anymore. So yeah, it also makes your programs more composable. I'm going to talk about this later. When you do a CPI, a cross program invocation in another program, then you also need to pay for the cus of this program, of course. And if they are not optimized, then it makes it harder for you to call their programs, of course. And yeah, by default when you request to use for your transactions, it will be at 200,000 ceus and the maximum, as I already said, is 1.4
00:02:29.920 - 00:02:59.084, Speaker A: million. But for a simple transfer, for example, you only need like around 300 cu. So you can set your compute limit also in your transactions as you create this instruction. And then you add it into your transaction. And then you can also request priority fees, which is one calculated microlamperts per cu. So if I request 300, then it will be 300 micro lemperts with my transaction cost extra. And then you can just add them to your transaction like this.
00:02:59.084 - 00:03:30.916, Speaker A: And yeah, you can find the compute budget code here in case you want to read about it yourself. Here you can see all the limits of a transaction as well. You can measure the Cu of certain parts of your program. And I want to quickly show you all the other resources we have. So we have a guide about how to use priority fees on Solana. Then we have the guide how to optimize compute usage on Solana. This is basically what we're going to do today, but we're going to look at it into more detail in the program itself, in the repository.
00:03:30.916 - 00:04:04.496, Speaker A: And then we have also the block optimization guide on the Solana network. Let's jump into it. This is how you can calculate or print the compute units that your program currently costs. This is a macro. You can also copy it from here, or you just check out the CU optimization repository under Solana developers. What it basically does, it just locks the sole compute units that are currently used in the validator before and after a code block. Then you can use for example, chat, GPT.
00:04:04.496 - 00:05:01.216, Speaker A: And you just post your logs in here and will calculate your, the complete units that, yeah, per block, per code block. And yeah, this is how you use it. So now we go through all the different optimizations, how you can do optimization, logging, data types, serialization, PDA's, closers and functions. And then in the end comparison between native and anchor. And then I will show you how you, the best is if you analyze it and optimize your program yourself, because all programs are different, but some of these things should give you a nice guidance at least. Okay, so the first thing we're going to do is here you have this, you can see this macro again, I just copied it into here, but maybe tost will also actually release it as a crate later then very easy to use. So we're going to start in the anchor part, and I'm going to go here through the program.
00:05:01.216 - 00:05:33.282, Speaker A: And we're going to start with allocations. You can see every function. I always wrote the complete Cu that this whole instruction costs. And then I have written down all the cus for each of these transactions here. And if you want to run this yourself, you just do anchor run detach. And the detach is nice because it will actually give you the signature here. If you use detach, then your validator will continue running in the end.
00:05:33.282 - 00:06:07.102, Speaker A: And you can just put the instructions here, the signatures, and then you can look at the output. And here you can see exactly all the cus that each of the calls cost. And then you cannot put them in chat GPT for example. Or you can calculate yourself, of course, it's just like something that I did. Okay, so let's start with the first thing. So this, it costs 109 cu to just increase u eight counter. Then here you can see already that logging is pretty expensive.
00:06:07.102 - 00:07:00.194, Speaker A: So just logging this little string here, compute units, costs already 200 cu. But then what becomes super expensive is actually if you want to lock a public key, and especially also if you concatenate strings, this is very very expensive and you should try to avoid it or just don't lock it off in the best case. But yeah, this part here is super expensive because it does a base 58 encoding of the string. And you can instead use the syscall lock on the pub key, which is way cheaper. So this calls the syscall Solana lockpupkey, and this one only costs 260 cu instead of 11,000 or 12,000 if you do it yourself and then you concatenate it with another string. So here's another one. If you just cache the pub key before and then call log.
00:07:00.194 - 00:07:39.896, Speaker A: So if you already loaded it, then it's only 200 cu. Then here you can see that the concatenation is expensive. So if I have a string and I concatenated with the pub key, then it already is like 360 cu. And now another thing that I found quite interesting is every allocation also costs cu. So if I have a vector and I push more data into it, then it will cost more cu. It is way cheaper if I directly create the vector in just one call. What's also interesting is that if you use smaller data types, you will also save SEO, because smaller data types are less bytes that need to be allocated.
00:07:39.896 - 00:08:30.160, Speaker A: And this of course also costs less cu. Here you can see the comparison between an I 64 or U 64, which have the same size, and the U eight. It's almost half the Cu that this costs. So it's a good idea to always use the smallest data type that you can use, which is a good thing anyway. But I think many people just default to u 64, for example, and it's way better if you just use u eight if you can. Okay, the next thing we're going to look at is the increment. So here I just did a loop and I incremented the counter 240 54 times and I just added one and I wanted to figure out if different math operations or error handling on math operations actually changes the CU this didn't turn out to be the case like someone told me, like that.
00:08:30.160 - 00:09:14.106, Speaker A: Checked math is very expensive, but it looks like I couldn't really figure out if there's any error, any difference between these. If I just increase the counter or I use checked add with a match or with an NWAP, it didn't change anything. The only thing that did change something is that if you have an error and you handle the error. So if you're in the error case, then this costs a lot more. CEO so I'm going to show that example later here. We didn't learn much then. Another thing that I tried out here is if you have function calls, if you use a closure, for example, or if you use a function, the function is up here, it's just increasing the counter by one as well, or if you use plus equals one.
00:09:14.106 - 00:10:12.090, Speaker A: In these cases, the only thing that I found very surprising is that the function call is actually faster than the closure and inlining here. So that part I couldn't really explain, but it looks like it is not a big difference if you say closure or a function call or inline okay, the next thing I did is I used a zero copy account. And you can notice that when you use zero copy, the serialization is way cheaper because usually it's your Bohr serialization. The Bohr serialization part is very expensive, and if you use zero copy, this is way cheaper. Zero copy has many other advantages as well, because you avoid running out of stack space, which is only 4, you use the heap space instead. What this does though is if you do simple operations on the heap, it's slightly more expensive than on the stack. So with everything it's a trade off.
00:10:12.090 - 00:11:19.770, Speaker A: But if you use zero copy account, it will be be on the heap and you can directly interact with the memory, and the same will happen if you box your account, if you use a normal account. So if I now for example have this update here and I box this account, then this one will also be calculated on the heap, and then the performance will be the same no matter if you zero copy or Bosch serialization. But the borderization is way cheaper here you can see when this account is boxed, the CU increases to 3600 instead of the 2000 we had before. I recommend you also, if you have compute intensive functions in your program, that you also try it out yourself. You just add this macro here and then you run it with either zero copy or bores sterilization in anchor. It's a bit hard to figure out how much the board actually costs because you don't have a function call. But it's all in these macros, like with all the checks as well.
00:11:19.770 - 00:12:15.180, Speaker A: If I make this a sign up, for example, then the signer check will also be somewhere in anchor done. So you can't directly see it in native, where it's a bit easier to profile this, but you can just make it a signer or an account, and then you can check the cusp before and after. For example here you can see the difference in the serialization. So here the initialization of the normal account, which has this counter data here, which just has some random data like a pub key to u, this big struct here, which is another u, four s and pubcies. And you can see that the difference here between these is the bigger the struct becomes, the more expensive becomes the serialization here. So in this case it's 6300. And when I use zero copy, it always stays at 5020 in this case.
00:12:15.180 - 00:12:49.274, Speaker A: So yeah, it depends on your structs. If you have bigger structs, more complex structs, then it may be worth it. Looking into zero copy. Then here I just have a little comparison between, if I like set data that is bigger and set data that is smaller. But the difference here was very small actually between the U 64 and the U eight. So that is not super interesting. If you have bigger structs and more data that you pass into your program, though, this might become a difficult difference.
00:12:49.274 - 00:13:53.636, Speaker A: Now I have an interesting one. This is just init with PDA instead. Because if you use PDA, then of course internally, what anchor does? It checks the size, it checks the program owner, and in this case it also, it needs to find the PDA address. So it takes the seats and it does find PDA by a find program address by seats. And depending on the bump, actually it needs to do multiple iterations on this, which can also be very expensive. So that's, I think we're going to see in the next example here for the PDA's like what Anker does internally. By default it is does find program address with the seats, of course, which makes sense because it needs to go through all the different variables, all the different bumps, until it finds PDA which is not on the curve in this case for counter, for example, in combination with our program id, this was very expensive.
00:13:53.636 - 00:14:33.916, Speaker A: So you can see it did multiple runs and it actually landed on the bump, 248. So it starts, I think at 254 and then goes backwards. And for every iteration it needs to do the calculation again. So if you directly put the bump in here, like the 248, if you know the bump, this becomes of course way cheaper. So. But yeah, and to do this, what you would do is you would just save the PDA directly in the account. So if I go to this PDA account here, you can see that in this case I was saving the bum directly in the counter data.
00:14:33.916 - 00:15:25.836, Speaker A: So here you can see here I have the bump field here, it's a u eight and I just put it in the account when I initialize it anyway. So here you can see when I initialize the PDA somewhere here on initialize, I think, I don't know, I do it somewhere, somewhere I just put this bump directly into the account. And then if you do this, then you can take the bump from this account here directly and then you save the cus. So you can see without setting the bump directly here, if I just use bump, then anchor will do it automatically. But if I set the bump because I saved it earlier, then this goes down to 1600 Cu. So you can see that with pdas you can actually save a lot of cus in the program. Then the last thing here is CPI.
00:15:25.836 - 00:16:19.506, Speaker A: So you need to keep in mind that every time you do a CPI into another program that you then actually use the CU of that program. I mean, you need to pay for the CU that you are performing in another program. So here, for example, for a simple transfer, it costs 2200 ceus on another end. If you directly, instead of transfer, using the transfer, the system program to transfer, but you directly interact with the lamp words in the account, then this only costs 250 ceus. So whenever you can do this then, because if you're owning the program, the account, then this is also way cheaper. Now the next thing we're going to look at is we're going to look at the comparison between native and anchor, because many people say that native is way better than anchor, which is not true in all cases. Anchor has a lot of benefits that it gives you.
00:16:19.506 - 00:17:09.942, Speaker A: It does all kind of checks for you and you should only use the native program if you actually know what you're doing and if you know enough about security, because anchor does a lot of security checks for you. For example, if you have a signer and you want to be sure that there's actually the sign up, then in anchor you would just say, hey, this should be a signer account, and it does the checks for you in the background. So it also checks that account. PDA is for example owned by your program, and that not someone just puts in another account which has the same data structure or the same account discriminator, but they pretend to be an account of your program, but actually they are not. And then they pretend that the data that they put in the account is actually in your program. And this can be very dangerous. But native has a bunch of advantages as well, because you can do actually everything that you need, only what you need.
00:17:09.942 - 00:17:56.350, Speaker A: And this of course saves you a bunch of time and also space. As you can see here, I deployed a simple counter program, and in the native program it was only 48,000 bytes, so it only cost zero three sol. And a simple counter program on anchor actually costed already 260,000 bytes, which is bondbound eight sol. So it's also like a cost evaluation that you do here and an anchor, if I did a simple increment and a counter it cost 200 940 ceu on the native, I could get it down to 840. And it's just a simple signup check. On anchor was 300 cu, on the native it was 103 cu. You can definitely do a bunch of optimizations here.
00:17:56.350 - 00:18:56.756, Speaker A: So I also added a native example here to run the native example it's a bit more inconvenient as well, like an anchor. But here you need to first cargo build, then you do anchor deploy, and then to use yarn test detach, and then you get basically the same as you had in the anchor program. You can also use the same macro here. Here you can see that an empty function call just cost 240 ceU. And without logging we're just increasing the counter here it costs 296. And when we add this logging here, in the end of the counter account then we are already at 844. So yeah, so I just wanted to show you that you can use the same native and anchor, and if you do the checks yourself properly then you can probably write more performance programs in native actually.
00:18:56.756 - 00:19:33.304, Speaker A: So you can see this is the signer check. For example, this is the owner check, this is a signer check. So here, in case I do account it's not signer, then I panic here. And an interesting thing is that if you panic, so as soon as you panic or you have any error checking in your program, this also costs a lot of cus. Most of the times you probably don't care, because if your transaction fails you don't care but you want some logging about the error. But this is still something that you need to keep in mind. So yeah, please go ahead and check your own programs like read through the guides.
00:19:33.304 - 00:20:10.090, Speaker A: There's also a nice article here from rare skills about compute units that you should look at. It helped me a lot. I took some of the examples from there and yeah, check your programs yourself. Analyzing is always better than just optimizing blindly. So it's always better to do a test before, do your optimizations and do a test after because many things here they appear a bit random. Like for example, when I did these comparison checks between increasing the counter and I used the zero copy account and the Bosch serialized account. The zero copy account was slower.
00:20:10.090 - 00:20:49.950, Speaker A: It took me a while to figure out with some help that it's actually slower because the operations are done on the heap and not on the stack. So yeah, you can't be sure without analyzing it yourself. So please try it out and make your programs more performant. And because smaller transactions will be easier to get in the block, they are more composable. And yeah, optimize your programs. And if you have any other examples, please feel free to also open a pr here or yeah, write comments if you think I did something wrong here, or if you have like a better idea on how you can optimize stuff. Yeah, beside that, thank you for watching and see you guys next time.
00:20:49.950 - 00:20:50.206, Speaker A: Bye.

00:00:06.520 - 00:00:55.684, Speaker A: So last night I did some work and I decided to write a Solana program that demonstrates some of the limitations that you might encounter while programming on the blockchain. Solana is a very fast blockchain. It's able to confirm your transactions relatively quickly, and it's also fairly cheap to do so. There are some downsides, however, in terms of what your restrictions are when you're dealing with programming on the blockchain. One example of something that can easily affect you is the size of the stack. So for this example, I wanted to talk about a program or a contract that I've been interested in designing for some time but haven't really had a chance to. And we'll kind of go through this exercise together while we're try to build out a simple marketplace.
00:00:55.684 - 00:01:44.794, Speaker A: So I have two copies of a struct here called marketplace borsch and marketplace. There are only two differences between them or one difference between them. Marketplace Borsch uses the Borsch deserialization protocol to load in the bytes of this object, whereas this marketplace uses a zero copy implementation to load in the database. What this essentially does is it makes a view over the account data and allows you to access the fields using the struct interface that I find here. What the marketplace contains is really simple. There's the user, which is the pub key that owns all of the offers in the marketplace. And the offers are just a list of the different things that that user is trying to sell.
00:01:44.794 - 00:02:11.884, Speaker A: So as an example, an offer meant here, this could be some NFT that I own. Like say this is my marketplace, I own some NFT. The buyer mint here could be like USDC, it could be sol, it could be BTC. But this is just the currency in which I'm willing to take for what I'm offering. The offer amount. If it's an NFT, it'll just be one. But in general, this could be any amount of size.
00:02:11.884 - 00:02:47.304, Speaker A: This is pretty similar to what you might see on a traditional order book, but there is no match strict matching algorithm implemented here. This is just kind of a list of things that I want to sell for a certain price. So this would just be like essentially the price I'm asking. Price the user is asking. What the marketplace is, is just a list of 256 of these offers. So let's do some math here to see how large this actual object is. I'll open up a Python terminal to do that.
00:02:47.304 - 00:03:53.428, Speaker A: So if I open Python three, all I need to do is calculate the size of this offer object and multiply that by 256 I know that there's two public keys, so that's 32 plus 32, and there are two eight byte amounts. So that's eight plus eight. I multiply this by 256 and I get around 20,000 bytes. Oh, I also forgot to add the user public key. It's pretty negligible compared to the rest of the large list of offers. But this becomes a fairly, I mean, if you're used to normal programming, this is like a negligible size object, right? This is tiny, but on the Solana blockchain this can be kind of dangerous, because one of the limitations is you only have 4 stack available, and I can just show you how ridiculously constrained this is by showing an example in this program. I have a number of instructions here.
00:03:53.428 - 00:04:12.682, Speaker A: I'll just go over all of these quickly. So we kind of know the different types of things we're trying to check here. The first one is called stack. This is just going to be me blowing up the stack. In the Solana runtime you have 4 kb. If you load more than 4 kb, your program is going to complain. There's runtime.
00:04:12.682 - 00:05:01.054, Speaker A: The restriction in Solana is that you have 200,000 compute units, which are roughly correlated to the cycle costs of individual instructions in BPF. This isn't an exact mapping, but this is another limitation that the runtime enforces in the virtual machine that runs, and every operation you do will incur some compute cost. If you exceed this 200K limit, that will cause some issues. There's CPIs really the main thing here. I didn't demonstrate one of the features. Most likely you won't encounter it, but you have a CPI depth of four. What this means is that if you have a program that makes a CPI, do a program that makes a CPI to a program that makes a CPI to another program, that's as far as you can go.
00:05:01.054 - 00:05:58.400, Speaker A: So the stack depth of the CPI is sort of how many layers deep you are from the first program that was invoked in the instruction. The other more important limitation that I'm going to demonstrate in this program is that you're limited to allocating 10 kb for any account that you make a create account call to. So max allocation of createaccount is 10 kb, also quite small. It's really, really easy to break that limit. This zero copy is just an implementation of an instruction that gets around that stack limitation. So as mentioned before, it's possible in rust to, to make a view over a set of bytes, rather than copying that set of bytes to load a struct into. And lastly, there's a transaction size limitation.
00:05:58.400 - 00:07:39.174, Speaker A: This I think is set to 1232 bytes, and if you exceed this, your transaction won't even hit the network. And so for this exercise I'm just demonstrating an example where I'm trying to send a vector not unlike the echo program. However, if the number of bytes I send makes the transaction size increase over this transaction size limit, it won't even hit the network in the first place. What this should also tell you is that in that echo program that you guys are writing, there's a limitation to how much data you can send, because past a certain point it will exceed the size of a single transaction. Are there any questions up to this point? Could you repeat that last part? Still get more iterations or not at all? There's a reentrancy attack. So the question is that with a stack depth of four, if there's a reentrancy attack, whether you could still get that, I don't know if I fully understand the question, but my understanding of how this stack depth works is your transaction has a series of instructions, and each instruction that you execute cannot exceed four. So in the scope of one instruction, when that's being executed, that transaction tree can only hit four deep in terms of CPI's.
00:07:39.174 - 00:08:18.904, Speaker A: Yeah, Richard? Oh, that's a good question. I actually don't know the answer to that. Yeah, I'll do some research on that after the fact, but yeah, that's certainly really interesting. Yeah, good question. I'll make a mental note. Okay. With that, I'll move on and try to compile this program for the first time.
00:08:18.904 - 00:08:53.584, Speaker A: The first thing I'll do it looks like something here is breaking. Yeah, I didn't implement this here yet, so let's delete that. Ok, so before I do anything, I'm going to compile the program without the stack breaking so I can execute some instructions. The first one I'll demonstrate is the runtime. This instruction is really, really simple. It takes in a max iteration parameter, which is a use size. I'm going to write a for loop between zero and that max iteration, and every time I is a multiple of 1000, I'll just log how many in units are used.
00:08:53.584 - 00:09:33.606, Speaker A: By the way, this is a really useful function in the Solana SDK. What this will do is it will print to the log buffer essentially how many compute units you have used so far. It will print the amount of remaining compute units. So if you're writing a program that is really compute constrained, it's useful to use this as a sort of trace to see how much you're spending and how much buffer you have before you run out of compute. So this is a really simple program. The only thing that's passed in from the client side is just this max iteration parameter. And like I said before, all of this stuff is commented out because otherwise the program is going to break.
00:09:33.606 - 00:10:23.142, Speaker A: I'll demonstrate that momentarily. Okay. Notice that like even in these errors, or even in the initial compilation, there are some lines here that already strike me as a little odd. If you guys can see the text here, I know it's a little bit small. Let me maybe increase this a bit. Okay, yeah, that's somewhat readable on the screen, there's something here that says that the stack offset exceeded the max offset of this size. Right.
00:10:23.142 - 00:10:43.374, Speaker A: This is 4. That number seems kind of familiar. Let's try to see where we saw that before. Right. I think I ran a python script a while ago where I did exactly this. Hmm, yeah, that seems pretty close. 20,512.
00:10:43.374 - 00:11:26.142, Speaker A: Looks like there are a few extra bytes here. I guess that makes sense. There are other stack variables involved, but it seems like the majority of the stack offset is caused by this number here, so that's something to take note of. Luckily, if you look into the processor, that particular function is never called like that marketplace borsch is never deserialized in any way whatsoever. So this program is not going to fail immediately when I run it. But the first thing I'll do is I will test out the function with the runtime. So let me open up that JavaScript file with my client and just quickly demonstrate how that works.
00:11:26.142 - 00:12:51.634, Speaker A: It's a very simple program, not unlike the clients you've been writing for your project. I think that code is an acceptable size runtime simple, simple, simple instruction I take in a number of iterations, which is just taking some number, converting it into little indian bytes, and then writing or creating the transaction instruction with no keys. Because this instruction takes in no account data, and the data that's passed in is the instruction index, which is one concatenated with that eight byte string corresponding to the number of iterations, runtime is invoked through the CLI. This CLI is implemented quite simply. The first argument that I pass in is going to correspond to the index of the instruction, and if that index is equal to one, I'm going to add this runtime instruction to my transaction, and at the very end I will send that to Devnet and log out the explorer link where we can analyze the logs. So I think I have not uploaded that program yet, so let me do that real quick. That's concerning.
00:12:51.634 - 00:13:40.168, Speaker A: To make this easier on myself, I also didn't include the program id as command line argument. I just hard coded it into this script to make the demo run a little bit more smoothly. So I'll insert that here, and then I'll run node index js with instruction one and the number of iterations I'm trying to do. So let's say I do something simple. This is just a sanity check. 100 iterations should be totally fine, and it returns a success. If I go to the explorer link, we see that I have plenty of compute remaining.
00:13:40.168 - 00:14:07.640, Speaker A: I have like almost the full 200k, right, because that's the maximum. Okay, so 100 is clearly fine. Let's up that to 10,000. Okay, that's not a problem. Seems pretty. Okay, I have like 145k remaining that tapers off fairly quickly. It seems like this thing is actually not, it doesn't support as many operations as you might hope to.
00:14:07.640 - 00:14:35.804, Speaker A: And we can sort of try to escalate this by increasing this number massively. So let's try to go to 40k. Let's see how much remains after doing this. Oh, so it already failed when I hit 40. And we can see from the logs about where that happened. Okay, great. So we can see these numbers, like quickly just going down to zero, and we see that the program here returned error, that the texture might be a little bit small.
00:14:35.804 - 00:15:16.128, Speaker A: Let me increase the size of this. Okay. A little bit more. So all this is doing is it's logging every time that iteration number is zero modulo 1000. And we can just see these numbers slowly declining over time, and eventually it just hits zero and the program fails because you're only allowed 200,000 computers, units just to sort of like represent the scope of this. Right, that was 40,000 iterations. Like your computer can do this instantaneously, but the Solana runtime is very limited because you're trying to have a blockchain that can support a lot of transactions very quickly.
00:15:16.128 - 00:15:59.334, Speaker A: So you're very compute bound. This is oftentimes like a huge limitation on a lot of programs that you're running. So you need to be a little bit like somewhat aware of your cycles when you're writing these programs, because it's really easy to just run out of this and we can sort of isolate exactly where it failed. So let's just make a quick vim file. Right, so this is like around 35k, because for every 1000, it'll print something. So around 35,000 loops were done and this thing just failed. So in reality, like, you don't have a lot of buffer room here.
00:15:59.334 - 00:16:44.868, Speaker A: When you're writing programs, the compute limit is something to keep in the back of your mind. The ways to go about this are to potentially stage your data over the course of many transactions. If you know that you're working on something that's very compute bound, ideally you have things fit in a single transaction because that allows you to have atomicity. But if you're willing to design around that, then you can break things up over the course of several transactions, and that can prevent you from running out of compute. So this is a pretty serious limitation that should be in the back of your mind whenever you're building more sophisticated systems on Solana. Okay, so we demonstrated the runtime, and we know that it should work with 100. Right.
00:16:44.868 - 00:17:44.884, Speaker A: The sanity check that we did earlier is the 100 is like there's no problem in doing so, right. When you get to 40,000, maybe you have some problems, but at a low number there's nothing that goes wrong. But now I'm going to go into the source code and blow up the stack. Okay, why is this breaking? Okay, so just going back to the logs again after compilation. If you guys remember, last time we only saw like two messages that indicated like we had some problems with our stack. This time we see a few more. So that should already be setting off some alarm bells.
00:17:44.884 - 00:18:37.358, Speaker A: Last time all of those instructions were happening in the state file where we're deserializing, serializing and deserializing this. But here we see one that also occurs in the processor file, and this is code that actually will get executed. So that should already set off some alarm bells. Let's try to deploy this program again and let's go back to our JavaScript file. Or I can just do it from here. We verified that earlier. When we run instruction one with 100 durations, there should be no problems whatsoever, given that everything was working properly.
00:18:37.358 - 00:19:06.414, Speaker A: But this time when we run it, we'll see that it will fail. It says program failed to complete. Let's go back to our explorer and look at why this one failed. If we look at the logs, it says we have an access violation. This is a consequence of the stack overflow. When we have a large stack object allocated. In this case, large is super relative, like 20,000 bytes is really, really not that much.
00:19:06.414 - 00:19:45.538, Speaker A: But if we allocate it on the stack in this lantern runtime, it will brick every single instruction that you have. So again, this is a serious limitation. And this is partially due to the fact that when you use borscht, all of the data will be copied into its own buffer, which can be kind of dangerous when you're working with stack variables of large size. So the main workaround around this in the solution is just don't copy all that much. Try to be really conservative when you're working with stack variables. And really the right solution here is to try to do zero copy deserialization. And that's what I'm going to demonstrate next.
00:19:45.538 - 00:20:30.734, Speaker A: So I'm going to comment out all this code recompile and upload. And while this is going, I'll discuss a bit of how this zero copy works. The code is copy pasted from somewhere else. If you want to use it, you can just copy paste it from here. I don't expect anyone in this room to be an expert in rust, so if you find code that works, you should just use it. This is the paradigm that almost everyone that I know who works in Solana or build stuff on Solana does. You find code that is effective at doing what you're trying to do, and you just use it.
00:20:30.734 - 00:21:10.208, Speaker A: It's open source. I implemented this trait called zero copy. This is part of there's a library called Bytemuk that allows you to just sort of make views on top of data without copying it. There are some helper functions from bytes, and there are some traits zeroable and pod. This refers to plain old data. As long as you have these traits implemented, which is as simple as doing derive and putting these in here, there are some potential features that you'll need to work around with. I would recommend just looking at the documentation if you struggle with this, but I have a trait here to make some of this stuff a little bit simpler.
00:21:10.208 - 00:22:00.196, Speaker A: This is not strictly necessary. I could always just inline this inside the marketplace struct, but these two functions will look load the data from the account info into a struct that I can just access the fields directly. And this allows me to do so without explicitly copying all of the bytes from the data field in the account info into a new object. And I implement the zero copy trait for this marketplace struct, which looks identical to the previous one, as mentioned before. So this marketplace Porsche and this marketplace look exactly the same. The only difference between these two is that the second one implements traitsearable and pod, as well as a zero copy trade. So when I try to load this in and when I try to deserialize it, I'm not going to blow up my stack.
00:22:00.196 - 00:22:43.230, Speaker A: Things are just going to work as intended, and the instruction is not going to break. And I will demonstrate that. So this zero copy, even though it's ordered second, inside this file in the processor, it corresponds to instruction index three. I just uploaded the program and this takes in no arguments. So I should be able to run this program just by invoking node on instructionindex three and we'll see what happens. Great, that worked. If we look at the result here, it says that we assign marketplace to this user.
00:22:43.230 - 00:23:34.204, Speaker A: Right? Again, the idea behind this marketplace really simply was to grab a user from the accounts and assign that user to that marketplace. There are a lot of checks that are missing here. In reality, if you're trying to build the system out, which I think could be a very feasible product, would be to actually make the user assigner before doing this. And you can add in a lot of checks as necessary to make sure that all of this is possible. But yeah, it was really easy to just using the interface load in the marketplace object and assign the user. And because we're looking at a view of the data, there's no need to explicitly serialize after the user's been copied over. There are, however, some very minor nuances with how this bytemukthain works, and this might be a gotcha, potentially.
00:23:34.204 - 00:24:06.724, Speaker A: So this marketplace uses repl, which will align all the objects as they would be in a c struct. One consequence of this is that things will be aligned in eight by chunks. So some things that might seem somewhat intuitive, like if I had a boolean here called isinitialized, and this is a bool. I'm not 100% confident that this is going to happen, but I'm fairly sure. Oh, I guess it's not potable. Let's try u eight. Hmm.
00:24:06.724 - 00:24:38.374, Speaker A: Okay. I mean, I guess, I guess these are things that are just going to break potentially, right? Because like this u eight type is a single byte, and this marketplace is expecting itself to have like an eight byte alignment. So there are going to be some issues that arise when you don't have objects that comply with the size constraint. So if I made this like a u 64, which is eight bytes, it will no longer yell at me. I think it's also possible to like, put in like a list of eight u eight s. I think so. Maybe not.
00:24:38.374 - 00:25:17.686, Speaker A: There are definitely things that you can do here. Let's try like zero. There are definitely things you can do to sort of make this object sort of fall in line. So when I have like eight of these in a row. Now it actually follows the like eight byte alignment. So there are like tiny things you have to worry about when you use this byte muc object. If you don't want to be concerned about like these annoying memory issues, you can just make everything eight by line.
00:25:17.686 - 00:25:57.746, Speaker A: Yeah, sorry, could you repeat the question? It's a little hard to hear. I think the total size of the struct has to be eight bytes. I'm not entirely sure. Yeah, of course. Yeah. So I think, correct me if I'm wrong, but I believe the question is whether the size of the object needs to be a multiple eight bytes. To my knowledge, and how I've always gone about this, is that whenever I use bytemuc, I just make sure that the size of the object is multiple eight bytes, because I just don't want to deal with any of these memory issues.
00:25:57.746 - 00:26:51.064, Speaker A: You're paying a very, very small cost in terms of rent if you allocate a few more bytes and you save yourself the pain of having to debug through memory issues. So I would always recommend you do so. Are there any other follow up questions? Yeah, is there like an analog to something like Patrick packed? Yeah. So the question is if there's an analog to something like attribute packed in these struct, in these structs, and the answer is that you could, there is a repr pact that you can apply to these objects, and I think this will allow you to sort of represent this in a packed format. But I think that bytemuk is not very happy with this attribute. Notice how the pod starts highlighting up. I think it has to do with the fact that when you're viewing this data with this particular package, it is looking for a particular byte alignment.
00:26:51.064 - 00:27:44.378, Speaker A: What I will do next, demonstrating the byte mug stuff a bit, the next thing I'll do is show you the CPI limitations. This is something I actually learned fairly recently. It's not entirely obvious upfront that this is a limitation, but when you allocate an account, there is a certain maximum size that you can allocate. And if you try to allocate an account in line like with a CPI, and you exceed that size, the entire transaction is going to fail. In this really simple instruction, all I'm doing is I'm making a CPI call with some size variable that will be the size of the account that's being allocated. All it's doing is just allocating that struct and assigning it to this program. And the way in which I invoke that is that this is instruction index four or three, or two.
00:27:44.378 - 00:28:35.354, Speaker A: Two. It's index two. So when I run this against that and I pass in some object of size 100 as we did before, there should be no problems whatsoever. If I go to 9000, there aren't going to be problems at all, because we haven't exceeded the limit. But the second I exceed that limit to something like 12,000, then I'm going to need an error or different error. The Devnet has a lot of rate limiting issues, so if you try to hit the network too many times, this is often a problem that you'll encounter. Okay, so this time it just failed.
00:28:35.354 - 00:29:36.154, Speaker A: I tried to allocate an object with 12,000 bytes. We'll see what that looks like in the logs after I paste the transaction here. So in the logs it says that create account data size is limited to 10,240 10 kb in inner instructions. So the consequence of this is that any kind of inline or like in program CPI to create a count cannot exceed this size, which means that there is a maximum size of your PDA's if you try to allocate them in a single instruction. I believe that there is a way to allocate PDA's of larger size over the course of multiple instructions, but that to me is not very well known. I am not familiar with the interface to do so. So for the most part, if you're trying to allocate PDA's, it's recommended to keep them under ten k, because if you don't do so, you'll come across this issue where the runtime has a limitation that prevents you from exceeding this maximum allocation size.
00:29:36.154 - 00:30:46.524, Speaker A: So when you're designing programs, this becomes a constraint as well. If you want to make very large accounts PDA's, it becomes quite difficult to do so. The cleaner interface to do that would be to use a normal key pair and allocate it with createaccount outside, inside the client code, and then use that allocated client, use that allocated account in the program and modify it. In the example I have here, that is what I did for the marketplace object which had 20,000 or so kilobytes, or it was 20,000 or so bytes here, this is already pre allocated, and if I open up the JavaScript file where I do this, we'll see that this is instruction four. I call createaccount, with the size of that object to sort of preemptively oh sorry, that's not the right one. Is that the right one? This is the one I call createaccount, with the size of the object to sort of preempt anything that could happen with that allocation. Okay, so the next thing I wanted to go over was transaction size limitation.
00:30:46.524 - 00:31:26.224, Speaker A: I believe that's the last instruction that I implemented. This will also be kind of a hint for those of you struggling with instruction zero on the echo project. So this instruction is called tx. It takes in a data vector of just arbitrary bytes, and then what the program will do, which you might find somewhat interesting, is it will just take the buffer and take those bytes and copy it into the buffer. I even have a little hint here that this is just echo, right? You're taking that buffer and copying those bytes. Cool. Pretty simple.
00:31:26.224 - 00:32:34.374, Speaker A: So if I wanted to run this with say, oh, by the way, the way that the CLI works for this instruction is I pass in the size of the vector, the amount of data I pass in, and then when I run the actual instruction or when I compose it, I just add random bytes into a list. So what it will do is it will log a string of random bytes, and the size of that string is equal to the size that is passed in from the client side. So let's just demonstrate that real quickly. This is instruction index four, and if I wanted to log a buffer of size 50, that should be no problem whatsoever. We see that this entered our program and it logged some random jumbled byte string. Easy enough. There become clear limitations though, when we increase the size of the input to something like 1000.
00:32:34.374 - 00:33:31.802, Speaker A: So if we wanted to log a string or copy over a string that was larger than 1000 bytes, what's going to happen is that the program is going to fail, or, sorry to be more exact there, it doesn't even hit the program. We get an error log here that says the transaction is too large. This is the number of bytes in the transaction. When you serialize the object, it serializes down to about 1300 bytes, but the maximum transaction size is limited to 1232 bytes. So in this particular example, the limiting factor of what caused your transaction size to grow too large was that data input that we passed in this particular instruction takes in a vector of bytes, and that byte vector had too many entries in it. And the transaction is not only the bytes itself you have to pass. In all the public keys that are involved, you need to pass in the signatures.
00:33:31.802 - 00:34:19.344, Speaker A: There's a bunch of metadata that's encoded in this transaction. And even though it's densely packed, there are still clear limitations to how large this thing can be. In this case, the thing that pushed it over the edge is the actual size of the data that's passed in, like the data for the instruction. But oftentimes the limiting factor is the number of addresses you can use. If you're working with accounts, every single public key that you're going to be touching in your program needs to be part of that transaction, and those public keys are 32 bytes. So just to do, like some quick python sanity check, we have 1232 bytes total, and each transaction is 32, or each public key is 32 bytes. This would give us like a naive division of 38.
00:34:19.344 - 00:35:20.174, Speaker A: But obviously the transaction contains more things than just the public keys itself. You have to include all the transactions as well as signatures. So realistically, this number is a lot lower than 38. The limitation here is, very clearly, when you're designing programs, you want to be really careful about the number of different accounts that program is going to be operating on, because it's possible that if you exceed a certain number, there's no way that a client could ever interact with that particular program. So that sort of covers the main limitations that I think you might encounter when working with Solana in the runtime. These are all design like when you're designing systems, these are all things to think about, because each one of these can sort of make or break the success of a particular program when you're thinking about how a user might interact with things or how efficient something might run. To give kind of like a really naive example that I haven't really implemented yet, let's think back to this marketplace object.
00:35:20.174 - 00:36:13.744, Speaker A: Suppose I wanted to build like a de facto matching engine between two marketplaces. I have, say two users, each with kind of a list of offers, and I want to see if any of these offers cross each other. In the case that it does, you can do some averaging, maybe, and decide like a fair price between these two users just by looping through these objects. These objects have 256 entries. And if I were to do this naively with an n squared algorithm, that will blow past what we determined to be the max iteration iteration limit. When we took the iterations, that was around 35,256 squared is greater than 35,000. So you have to be more efficient, and you have to think a little bit about how to design these systems in such a way that you can avoid blowing through any of the limits that the runtime provides or enforces when you deploy smart contracts.
00:36:13.744 - 00:37:01.044, Speaker A: I think that's all I really have for this lecture. I'll share all of this code so you guys can have access to it, and you can run and test for yourself if you're interested in sort of pushing the limits of some of these constraints. Before I end, are there any more questions from the audience? Yeah. Yeah. So the question was whether macros like Sol law compute unit, this function I have here, whether that uses compute units. I believe the answer is yes. There is a file in the runtime or in the Solana repo, the public GitHub repository that has a list of all of the compute costs of different operations.
00:37:01.044 - 00:37:38.104, Speaker A: I believe that logging the compute cost does map to some number. I don't know exactly how much it is, but I believe it's quite negligible. Are there any other questions? Okay, given that I received no more hands, that'll be the end of this lecture. Best of luck with the rest of project one. I'll be walking around to help with that. And sometime in the afternoon, we'll announce over Discord we'll have a discussion about designing the exchange. Booth, thanks so much.

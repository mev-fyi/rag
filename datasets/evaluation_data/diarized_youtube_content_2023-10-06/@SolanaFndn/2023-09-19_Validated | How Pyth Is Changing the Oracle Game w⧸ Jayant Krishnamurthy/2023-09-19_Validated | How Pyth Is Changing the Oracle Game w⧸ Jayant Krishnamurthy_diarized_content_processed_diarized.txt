00:00:04.520 - 00:00:06.302, Speaker A: Jan, welcome to validated.
00:00:06.478 - 00:00:08.374, Speaker B: Hi, Austin, thanks a lot for having me.
00:00:08.534 - 00:00:51.624, Speaker A: Glad we can get you today. There's been a bunch of news in the world of PIF that I want to talk about. I want to talk about the role of high frequency oracles in general, the professionalization of blockchain infrastructure, the sort of weird world we find ourselves in of tradfi, prop trading, shops, getting involved in building infrastructure and blockchain as well. We've had Kanav on previously as well from JMP, and I know Pip has some spiritual origins within JMP as well, but I wanted to start out with just a scene set on the landscape we find ourselves in now. What is the impetus for pith and why do you think we needed another oracle in blockchain?
00:00:52.204 - 00:01:27.424, Speaker B: Yeah, absolutely. Happy to take that. Just to take a big step back. An oracle is a piece of technology that brings data from the outside world onto the blockchain. And this is basically solving a fundamental problem with how blockchains work, which is that by default, there's no way for an application that runs on the blockchain to access data from the outside world. So if you want to build a contract that depends on a market price or the weather or something like that, you need some other system to help deliver that price onto the blockchain. Oracle has basically solved that problem.
00:01:27.424 - 00:02:18.340, Speaker B: People have been building oracles for a number of years now. Pith is not the first oracle that's on the market, but Pith was actually a reaction to how oracles have been built in the past. When we started the project, we looked around at different oracles and realized that, first of all, existing oracles don't pay their data providers for the access to the data. So the way oracles worked before, PiP, is that the oracle would basically operate a number of different nodes, and those nodes could basically scrape the web to retrieve data, and then they would take that data that they scraped from the web and reported onto the blockchain. And you can see why this is an attractive design for building an oracle, because from a technical perspective, it's pretty elegant. There's a lot of data on the web. You can access anything and put it on chain.
00:02:18.340 - 00:02:54.766, Speaker B: So you can see why people decided to do that. But the problem with this is that valuable data isn't going to be publicly available on the web. And coming from a financial market background, one of the things that you know is that financial market data, like prices, low latency connections to Nasdaq or whatever, are very, very expensive. So that financial market data is high value, and it's not free. And so if you want to get that kind of data onto the blockchain, you need to have a different solution. So Pith was basically built as a reaction to that observation. And so those oracles, we'd call them third party oracles, right? It's third parties who put the data on the blockchain.
00:02:54.766 - 00:03:45.640, Speaker B: Pith is a first party oracle where the owners of the data are actually the ones who report that data to the blockchain. So Pith has a network of over 80 data providers right now, which includes some of the biggest traditional finance firms. These are names you've probably heard of, like Virtue Tower. Some of the big crypto exchanges, like Coinbase, Binance, all provide their data directly to two pith. This gives PIP access to data that other people don't have. For example, PIP has real time us equity prices, which you can't really get anywhere else. That was one of the things that inspired the design of PIP and was one of the things that we really wanted to get right when we're building this oracle, we just knew that without the data providers, like the owners of the data on board, there'd really be no way to get this data in the long term.
00:03:45.640 - 00:03:54.552, Speaker B: And we knew that this financial market data was super important for blockchain applications. So we really wanted to make sure that there was a way for that data to arrive on chain.
00:03:54.728 - 00:05:07.382, Speaker A: Yeah, I think that's an interesting history of how these sorts of protocols end up getting built out. I think one of the pieces to dig into a little bit more here is data in financial markets has historically been considered pretty proprietary. Now, there's all sorts of compliance reasons that these firms hold onto the data, but they also hold onto the data because it's partially considered to be something that can be useful for some form of competitive analysis. You can use that model data to create back testing models to see how an algorithm you wrote in 2023 would have performed in 2018 or something along those lines, and do some forward projections based off of that stuff. One of the pieces, I think, that a lot of people don't understand, and I want you to kind of walk us through here, are the incentives that make PIF work, because it's very easy to look at pith and say, look, this is data being provided largely by really large financial institutions. Historically, these institutions don't really do things altruistically, so they must be getting something out of this in order for them to be willing to participate in it. The assumption there is they're getting something out of us, right.
00:05:07.382 - 00:05:36.454, Speaker A: In some way, this enables front running, this enables trading ahead of markets, that there's some ability that these large financial institutions have to use this data for things other than price improvement, let's put it that way. But that's not really the way pith is set up. So I want to walk through a little bit of how that incentive structure has been built out and why all these data companies and large financial firms that usually very publicly go to war with each other are collaborating on something like PIF.
00:05:36.914 - 00:06:21.724, Speaker B: Yeah, for sure. One of the things that I think has been really interesting about Pith is actually the network of data providers. And HFT firms are very secretive and competitive, and they don't usually work together on a project. It's actually been very surprising and impressive that these firms have all agreed to jump on pit. Now, the reasons that they do this are they obviously differ per organization, but I think there's basically two, which is, one, they have a stake in the network. One of the cool things about crypto generally is that you can use tokens to provide incentives for people to participate in certain things. A big chunk of the PIP tokens have basically been allocated as grants to data providers to encourage them to provide this data.
00:06:21.724 - 00:06:54.994, Speaker B: That's one of the reasons they do it, is they just own a piece of the network. And the second reason is actually, for a lot of these firms, the data is a found resource. It's not something that they're currently monetizing and then suddenly piss those up and they're like, oh, we can make money from this. That's interesting. If you're Nasdaq and you're already selling low latency feeds, fine, you're already monetizing your data. But if you're an HFT, you can't actually resell the Nasdaq data that's licensed by Nasdaq. You're not allowed to redistribute that.
00:06:54.994 - 00:07:20.064, Speaker B: But as an HFT, you actually have price data because your trade prices are actually owned by you. And currently you're not monetizing that. You're tracking it for compliance reasons, as you mentioned. But there's no money associated with it. In some sense, for a lot of these firms, it's a found resource that they have this data that's valuable. And so they're like, oh, well, we can contribute to pit, then maybe we'll make some money from in the future.
00:07:21.064 - 00:07:51.874, Speaker A: What is that long term play in their minds? Because there's one thing to say. They can think about this as something that's not harmful for them. But opportunity cost is real. It's not trivial to run blockchain infrastructure. A lot of these firms probably don't have any experience building stuff on Solana before, let alone keeping validators up. Basically, why, out of all the opportunities of things they could do, was signing up to be a pith data provider or something on their list.
00:07:52.614 - 00:08:28.564, Speaker B: So I think actually, one of the other motivations that a lot of these firms have is that they're interested in crypto and they wanted a way to get involved in crypto, right. Because they see all the stuff happening in crypto and they're like, oh, we want to do something, but they don't really know what to do. Trading in crypto is hard. There's a lot of compliance obligations and things like that that these firms have to deal with. And Pitha's actually been kind of a, a little foot in the door to kind of get their feet wet and just figure out, oh, this is how I hold a wallet and, oh, this is how I sign a transaction. So I think a lot of firms have actually, that's actually been a val. It's like a hard thing, but it's a thing they want to learn.
00:08:28.564 - 00:08:31.504, Speaker B: So they are excited to do it in a weird way.
00:08:32.004 - 00:09:28.144, Speaker A: So in terms of the process of how this works, right? So in a traditional oracle system, maybe they're scraping data from a website, they're getting data from some sort of people who have an economic reason that they need to add oracle data to a chain. So maybe they need a specific feed, and that feed isn't something that the oracle supports. So they might pay to bring that data sort of on chain and then consume it themselves or anyone else on the chain might be able to sort of consume it. So when you're looking at data coming in from pith, it's a slightly different model because you have basically permissioned data providers. And my understanding is there's some sort of weighting algorithm that goes into how those various prices are incorporated. Can you walk us through a little bit of that logic of taking data feeds from all these different people and ending up the end of the day with one number that you see on chain that says USDC is worth $1 today?
00:09:29.004 - 00:10:18.008, Speaker B: Yeah. I think this touches on one of the fundamental questions about how you're going to build an oracle, which is, do you have a single source of data or do you have a blend of multiple sources of data? And there's a trade off there, because if you have a single source of data, you could, obviously everyone can go and see the binance price, for example. They can report that on chain, and you can see that everybody agrees on the binance price, and so it's correct, and then you can use it downstream. The problem with using a single source though, is that it's much easier to manipulate the price on a single exchange or something like that. Or there could be reliability issues like what happens if that exchange has downtime? You don't want that to cause downstream downtime in your defi protocols. Pith has actually been built as a blended source. Oracle.
00:10:18.008 - 00:10:57.668, Speaker B: We basically take the prices from all the different data providers, and we have an algorithm on chain so that the data providers are basically reporting these prices onto the blockchain continuously by sending transactions. There's a program running on the blockchain that implements a little algorithm that robustly combines the prices. And when I say robustly combines them, what that means is that no single data provider or small group of data providers can move the price by themselves. They have limited influence over the price. And basically what that ensures is that the protocol can't be attacked without a large number of people participating.
00:10:57.836 - 00:11:09.564, Speaker A: Yeah. So is that just a flat weighting system, or do you say that the price coming in from Jane street is more important than the price coming in from another firm?
00:11:10.624 - 00:11:31.684, Speaker B: Right now it's a flat waiting system. We have thought about doing a more variable system. It's just you get into these tricky cases where you're trying to limit the influence any one person can have. You don't want to upweight anyone too much. It just ends up being a little bit hard to decide what the right way to do the waiting is.
00:11:32.414 - 00:12:22.014, Speaker A: So it's interesting that the oracle problem is very similar to the multisig governance problem, where it's hard to figure out what a reliable way to weight the various actions of various folks are in an ecosystem. The default in most blockchains is token based weighting. And that has its own problems because you have a 16 z that bought a bunch of the seed round token of a specific thing. And there's been a few instances where they've actually voted very heavily and some would say thrown a vote, others would say executed their contractual obligations as holders of tokens to direct and steer that protocols. Future development. And that's a contentious sort of thing in the crypto world in general. There's networks like Solana where the voting is actually entirely done at the validator level and users don't even vote at all.
00:12:22.014 - 00:12:50.746, Speaker A: But the comparative stake weight of the validators is what actually initiates the voting. So what have you guys thought about over the long term? Like, I assume the goal is to bring more and more data providers on, but eventually you're going to have a system where maybe Coinbase is data provider and finance is a data provider and the volume of data they're providing is 100 x what another provider is bringing. And also, how do you work about communicating discrepancies in pricing to consumers of data?
00:12:50.930 - 00:13:12.530, Speaker B: Well, Coinbase and binance are actually data providers already, so it's not in the future. But so the thing here is that you could provide lots of data for lots of different feeds or different assets, right. And if you support 100 x more assets, that doesn't actually cause a problem because you can still be sort of uniform weighted within the single asset, right?
00:13:12.562 - 00:13:12.946, Speaker A: Yeah.
00:13:13.050 - 00:13:25.994, Speaker B: So I don't think it like, I don't think the fact that binance or Coinbase necessarily has, like, a bigger reputation necessarily means that they need to get more weight in this particular algorithm. Because you're kind of optimizing for robustness.
00:13:26.694 - 00:13:41.566, Speaker A: Yeah, I guess maybe apart from robustness, though, there are worlds where the volume moving through binance is so much higher than the volume moving through a third tier exchange that only services two markets.
00:13:41.590 - 00:13:42.390, Speaker B: Yeah, I got you.
00:13:42.502 - 00:13:52.350, Speaker A: Implicitly, should one assume that the binance data is more reflective of what market price is, or is that the wrong way to think about it?
00:13:52.542 - 00:14:24.974, Speaker B: Certainly if you have exchanges where theres more volume going through them youd expect those to be more representative of the market price. The way that pith accommodates for that right now is that a lot of the data providers on pith are trading firms and things like that who are basically, theyre hfts. They have some alpha signal that tells them what the price is. That signal is actually a function of the market prices on a bunch of different places. It includes things like volume and things like that. So we get that for free in some sense, just because of who the data providers are.
00:14:26.394 - 00:15:12.744, Speaker A: Pith initially launched on Solana, and now it supports something like 30 different blockchains where it publishes data, too. And I want to get into the transition from operating on Solana Mainnet to pithnet at some point, too, because I think that's very interesting. But one of the pieces that a lot of early folks who are consuming pith data had to sort of figure out how to use were these things that were called confidence intervals that were coming in with this data that was a new fee that they hadn't had access to before from other blockchain oracles. So can you kind of walk us through a little bit about how confidence intervals are built and also how Defi engineers should be thinking about consuming data that has this, as opposed to just your traditional standard? Here is one price, here is $1 value.
00:15:13.524 - 00:15:51.336, Speaker B: One of the unique things about pit is that in addition to every price, we also produce a confidence interval. And the reason we do this is because any given asset actually trades at different prices, at different venues around the world at any given point in time. It's not realistic to say that there's a single price for the asset. There's really a probability distribution over prices. We just wanted to provide a way for downstream protocols to consume that uncertainty and use it to protect their users in different ways. Now, there's many different ways that you could incorporate the confidence interval into your protocol. It depends on your protocol itself, and it's something that users have to think about for themselves.
00:15:51.336 - 00:16:16.342, Speaker B: It's not something where we can tell you what to do. But, for example, one thing you could do is you could say, look, I have a price. I'm a lending protocol. Let's say the confidence interval is really wide. Maybe I'm not going to liquidate a user unless the upper bound of the conference interval, you know, is below the liquidation price or something like that. The point is just you can incorporate the uncertainty of the price into your protocol and there's different ways to do it. Yeah.
00:16:16.398 - 00:16:53.454, Speaker A: And I think the uncertainty bans are interesting because it's a good way of saying how accurate the PIF network thinks a specific data feed is too. Right. This is something you see all the time, and the difference between accuracy and precision in measurement, too. And error bars are really important when you're looking at all sorts of types of data sets to figure out, is this price movement statistically significant or not? Or even though the reporting is the same as the previous interval. Oh, wow. The confidence interval jumped two standard deviations. That's meaningful even if the price has not technically moved.
00:16:53.454 - 00:16:57.570, Speaker A: So it's very interesting to see how people can actually incorporate this stuff.
00:16:57.722 - 00:17:36.552, Speaker B: That's totally right. And one of the cases where I think the confidence intervals have really proven their value is in cases where there's an asset that is trading on multiple exchanges, except the prices on those exchanges have diverged for some reason. So this has happened actually a few times in the history of PIP. Now, where we've seen maybe an exchange suspends withdrawals, or there's some sort of crisis going on, and people just don't know how to value the asset and different people are doing it differently. And so one of the things that happens in that situation is the confidence interval winds up. So that's a way that protocols. But that's like a concrete kind of situation where protocols can use the confidence interval to kind of have some smarter behavior.
00:17:36.728 - 00:18:07.164, Speaker A: Yeah, that's interesting. So what is the sort of, we talk about pith as a high frequency oracle, and that high frequency can mean a few different things, right. It can mean that there's a very constant published feed of updates. It can also mean that the data itself is fairly fresh. So how do we think about measuring sort of how old a price is in a blockchain oracle, what do folks usually been used to working with and what are we looking at today with something like Pif?
00:18:07.664 - 00:18:43.282, Speaker B: So I think we should distinguish frequency from latency. I think people tend to conflate like a fast oracle and they don't specify whether they mean latency or frequency. So latency is basically how long does it take for the price to go from the exchange or whatever the original source is through to the users of the protocol. And frequency is just how many of those updates do you get per second? You could have a system that has high latency and high frequency, or you could have a system that has low latency but low frequency. So you can have any combination of those things. And people still think about this super clearly.
00:18:43.458 - 00:18:58.666, Speaker A: Yeah, this is your classic example of you can achieve transfer speeds of several terabytes per second if you drive a semi truck full of hard drives from one city to another. But your latency is very high on that data retrieval.
00:18:58.810 - 00:19:33.954, Speaker B: Right, right, exactly. So for pit, we actually try to optimize both latency and update frequency, and we've done some measurements of this. So the end to end latency of where you measure basically what is the price on the underlying exchange, and then you measure what is the PiP price. And now you have two time series of prices and you can correlate these two time series and see what the latency is between them. We've measured that end to end latency. It's two to 3 seconds, and then we do basically one update every 400 milliseconds.
00:19:34.294 - 00:19:37.262, Speaker A: How does that compare with the speeds of other oracles?
00:19:37.438 - 00:20:00.844, Speaker B: Hip does a lot faster than other oracles. I think that's maybe not surprising if you have used other oracles on other blockchains and you look at the actual configurations of those assets they're scheduled to update once every ten minutes or something like that. Right. So it's not even like we're in order of magnitude faster. I'm probably more than order to magnitude faster on like, most of the dimensions. Right. Latency and frequency.
00:20:00.844 - 00:20:07.344, Speaker B: So yeah, we're definitely doing, I guess, I know, it almost doesn't even make sense to compare.
00:20:08.844 - 00:20:53.180, Speaker A: Yeah, yeah. So I want to get into a little bit of the technology and architecture that's underpinning pith here because like, I think what you're saying makes a lot of, a lot of sense that like, oh yeah, we can have both oracles that have less latency and they have a higher frequency of data publishing, but that stuff doesn't come free. Right. As we sort of know, looking at networks like Solana and compared to Ethereum, like, Solana's steady state is 5000 transactions per second. Ethereum steady state is about 14. But there are a lot of trade offs that go with making a network faster. So like, walk me through a little bit of the architecture about how PIF is able to achieve these sort of throughput speeds for oracle frequency data and latency.
00:20:53.180 - 00:20:56.704, Speaker A: And then also, what are some of the trade offs that come with those decisions.
00:20:57.004 - 00:21:31.324, Speaker B: Yeah, so pith has gone through a couple of different iterations and we knew when we started out building pip that we wanted to build an oracle that was optimized for latency and frequency. Right. Because again, coming from a trading background, we know that those attributes are important for data. The value of your market. Data decays as a function of latency and it decays pretty rapidly. We knew those attributes were important. That was one of the reasons why we chose to build pit on Solana in the first place was because Solana is a blockchain that's optimized for latency and transactions per second.
00:21:31.324 - 00:22:00.644, Speaker B: Actually, the primary way that pith achieves a lot of these properties is that we use Solana. Um, and it's, it's been great. I mean, you know, I've actually been really impressed with the, with the Solana blockchain, the more like Pip has expanded to other chains. Like, I come back and I'm like, you know, I started on Solana and like, actually Solana is really pretty good. It's really pretty fast. Like, it's quite impressive. And I don't know, I've just gotten more impressed as I've looked at other stuff.
00:22:00.644 - 00:22:36.250, Speaker B: But, um, yeah, so we knew we wanted to be fast. We started building it on Solana. Then last year, basically we realized that theres a lot of people who were building on other chains beyond Solana and we didnt really understand how the whole crypto ecosystem was going to play out. Maybe theres certain types of blockchains that are better suited for certain types of applications. Were not really sure. We thought that, look, if you want to be an oracle, like an infrastructure provider, our goal is really to provide those prices to everybody. It doesn't make sense to be an oracle on just one chain.
00:22:36.250 - 00:23:17.534, Speaker B: You really want to provide the prices to developers, no matter what technology is the right choice for them. So we went on this journey of, how do we go and go from just being a Solana oracle to being an oracle that works everywhere? As part of that, what we did is we basically created Pithnet, which is an instance of Solana. It's like a separate Solana network that we use to provide to combine the prices, do that price aggregation stuff we were talking about earlier, and deliver the prices from there to other blockchains. Again, the way that we get the high frequency and low latency in that case is we use that same Solana technology.
00:23:18.594 - 00:23:43.000, Speaker A: Yeah, I want to talk a little bit about that evolution from running Python mainnet to running it on Pithnet. So walk me through a little bit of why that decision was made. Because you guys were. And now there's a few, but you were the first ones to take the Solana code base and say, we love this thing. We actually want to deploy it in a private side chain instance.
00:23:43.192 - 00:24:19.694, Speaker B: Yeah, basically. Again, this is part of our journey into being this multi chain protocol. We had this idea that we wanted to be multi chain, and our initial way of doing this was thinking, okay, we'll just do it on Solana and we'll bridge it over to other chains, and that will work. But we started talking to people building other chains, and they just thought this was weird. They're like, so my layer one now becomes another layer one. And it just ended up being a really hard conversation. And so we decided that it would make more sense to basically have a network that the data providers ran themselves.
00:24:19.694 - 00:24:47.194, Speaker B: You're already depending on the data providers. Now the data providers run the nodes of Pipnet as well. It's a permissioned app chain. That way there's no additional trust assumptions or anything like that. It just seemed like developers preferred that model over. Now, having the Solana validators in there, that's why we ended up making that decision. I think there have been some other things that have been good about making that decision.
00:24:47.194 - 00:25:06.434, Speaker B: One is that we can really, really scale up the number of feeds that we offer, because the gas on this chain is effectively free. We just give it to ourselves. So that really lets us do a lot of transactions. Solana is very cheap, but you start listing hundreds of fees, updating every slot, and the costs can add up.
00:25:06.814 - 00:25:21.384, Speaker A: Yeah, that makes sense. Um, so at this point, like, have you guys done any optimization to that runtime to fit your needs, or are you basically just using the raw protocol binaries, like in your own ecosystem?
00:25:22.044 - 00:25:56.594, Speaker B: We actually just rolled out a network upgrade, sort of soft launched it, where we actually made a change to the validator itself. In our initial version of this, you know, multi chain protocol, we were basically taking these prices on Pitnet, and we're kind of sending them in individual little batch payloads to other chains. So we take five price fees, put them together to a message, and then send it through warm all to other chains. And this was fine, it worked. But one of the problems is that sometimes you want to use two different feeds at the same time. You have ten feeds in your lending protocol. You need the price of all of them.
00:25:56.594 - 00:26:27.404, Speaker B: And so you want to use bitcoin, you want to use ETH, they're in different messages now you got to put both of them on chain. It's more expensive. There was just some cost considerations there. There was also some network bandwidth considerations where we're bridging prices from Pitnet to other blockchains using wormhole. And there's some bandwidth cap on wormhole, and we send a lot of data. We want to be able to send multiple updates per second for 300 different things. It adds up again.
00:26:27.404 - 00:27:24.316, Speaker B: We had a cap on the number of messages we wanted to send. So we were sending one update per second previously, and we wanted to bring that down to 400 milliseconds. But we couldn't do that without putting way too many messages into wormhole. What we ended up doing is we ended up modifying the pipnet validator so that it actually constructs a merkle tree of all the pip prices on every slot. So we put this into the validator because you want something that's able to look at the global state of the blockchain, which is hard to do with individual transactions. You could imagine having the merkle tree be like an account on Solana, but then doing the updates would end up locking the entire chain state every single time you did it, which is not something we wanted to do. So we just put that Merkle tree computation into the validator itself, and then now we just send the roots of that merkle tree to other chains using wormhole.
00:27:24.316 - 00:27:44.334, Speaker B: And that lets us actually do basically, now you get one wormal message, and it has conceptually all the prices in it, and so it lets us increase the update frequency. It's actually much cheaper on target chains. It's somewhere between 30 and 90% cheaper, depending on how many prices you're doing in one update. So that's been a pretty big win for us.
00:27:45.234 - 00:28:00.574, Speaker A: That's really cool. I'd love to dig in a little bit more on that. So how does that retrieval work? Let's say I'm on ethereum or avalanche, and I want to consume a price feed, but all I have is this Merkle route. Where am I actually going and fetching the data from?
00:28:02.154 - 00:28:35.254, Speaker B: So if you're on a different chain and you want to basically put a pith price update onto your chain, you basically need to get two things. You need to get the root of the merkle tree from wormhole, which has these wormhole signatures. You can basically prove it's valid. And then you need to get the merkle proof for each of the individual prices that you want to put onto the blockchain. And those merkle proofs are actually stored on Pitna. So there's a rolling buffer of those merkle trees where you can extract the proof from the merkle tree. There's this circular buffer of those trees on pitnet.
00:28:35.254 - 00:29:09.686, Speaker B: Basically what you do is you say, okay, I have the current wormhole tested Merkel route. It's for this slot. Let me go to Pitnet and look up the merkle tree for that slot, and then I get the proof, and then I package all that into a message. And then you can just send that message to the target chain. Now, that process seems a little complicated, and it is slightly off chain. Oh, it's absolutely an off chain process. But, yeah, if you're an end user, you probably don't want to be contacting both of these different services and interfacing with them or whatever.
00:29:09.686 - 00:29:25.044, Speaker B: Yes, basically there's some software you can run. It's just a web service that connects to both wormhole and Pipnet and basically does all the glue for you. You just hit that web service and you say, look, I want an update for these speeds, and it'll give you the binary.
00:29:25.204 - 00:30:18.576, Speaker A: Yeah, got it. So how do you think of, like, one of the questions we've been sort of exploring a bit on this show is like the evolution of DeFi and blockchain from, like, DeFi 1.0 is like basic AMM single functions where everything is 100% on chain. Now, we see that DeFi 2.0 there's a little bit of more flux in there. So whether it's a real world asset protocol like Homebase, which is tokenizing actual real estate somewhere, or even Credx, which is doing credit facilities and loans in developing markets, these things now are pulling more data from things that are off chain and they're relying more on the dumb human part, for lack of a better term. The dumb contracts, the paperwork, the courts, the legal system when something goes wrong.
00:30:18.576 - 00:31:09.944, Speaker A: So what are you guys, when you're architecting pith, most of this happens on a coordination on pithnet, which is sort of, for lack of a better word, a permissioned proof of authority style network. But then when you're talking about someone fetching a price from a root to then bring it onto their chain themselves, that's not running that whole experience, not going through a wormhole. If you think about chain of custody, for lack of a better term, you leave blockchain for a component there to get information and pull it back. So talk to me a little bit about what you guys think is the ideal ratio of what needs to be on. Not necessarily ratio, but the ideal distribution of what needs to be on chain, what doesn't need to be on chain, and sort of where, like, what areas are true trust and safety issues and what areas are just like. We actually don't need a blockchain for this part. This is just an API.
00:31:10.284 - 00:31:47.734, Speaker B: Yeah, yeah. This is a great question. It's actually something we've been thinking about a lot because of. Blockchains are really good for some things, but they're really bad in other things. The performance of a blockchain relative to running a computer somewhere is way worse. I think there's a whole interesting engineering game of how do you get systems to operate at the performance levels of off chain systems while still having the security and verifiability guarantees of the on chain systems. That's what pith has been doing.
00:31:47.734 - 00:32:27.248, Speaker B: This touches on something we haven't really talked about. But pith has this new design for an oracle, where it's a pull oracle. What that means is that pith generates, through this process of the merkle trees and wormhole, it's generating these off chain payloads, these off chain data payloads. Now, look, there's a chain of trust for those off chain payloads. If you look at any given off chain payload, it actually came from Pitnet and you can go look at Bitnet and see what prices went into it. So there's a full auditability trail for each of these things. But we're generating these payloads and they just sit there off chain.
00:32:27.248 - 00:32:55.924, Speaker B: Anyone can grab an off chain. They're not maybe useful there but they sit there and then we make it user's responsibility to grab those payloads and put them on chain when they need them. Right, and the reason we did this. So you want to go use some protocol that needs the bit bitcoin price. You could take the payload, you put it onto the blockchain, you say this is the current bitcoin price. We can validate that full chain of trust on chain. Theres a pip contract that can say yes, the wormal signatures are valid, yes the merkle proofs are valid.
00:32:55.924 - 00:33:34.090, Speaker B: That proves that this data came from Pitnet. And I know that on Pitnet everythings auditable. We can verify that and then you can go use your downstream protocol. The reason we went with this design is because it's a lot more efficient than doing everything on the blockchain. The alternative design, actually a number of oracles have already done this on other blockchains is you continuously update the on chain press. In order to do that, pith would have to basically send the transaction to say, ethereum. Every single time you want the bitcoin price to update, that's the send a transaction.
00:33:34.090 - 00:33:59.894, Speaker B: And that's a very, very expensive thing to do, especially if you want to do a lot of updates per second or you want to do a lot of different assets. That's just not a smart way to build the protocol. And that's how we ended up at the place where we are, where we're basically optimizing for. We have a design that basically gives us better performance while still retaining the same security and auditability guarantees.
00:34:00.554 - 00:34:06.818, Speaker A: So how does a user, or how does someone then initiate a call for a price update?
00:34:06.986 - 00:34:38.727, Speaker B: Yeah, so Pip has a contract that lives on. We're on 30 different blockchains right now. So there's a contract that lives on those blockchains. And that contract has a function basically that you can call where you give it a binary data payload and it takes that data payload and it verifies it. So it says, look, is it signed by wormhole? Okay, here's the Merkle route. Here's the Merkle proofs. Are those valid? And if everything checks out, it says, okay, this is the price that's in this payload and it just saves it on chain.
00:34:38.727 - 00:35:09.362, Speaker B: And then anybody can basically read the current price out of that contract. The way that users pull the price on chain is they basically call that function on the contract with the right data payload, and you could get the data payload from one of these web services. And this web services, the pit data association runs an instance of this web service, but it's completely permissionless. The web service is just connecting to the Pitnet peer to peer network and it's connecting to the wormal peer to peer network, and it's just gluing some of the data together. You can go spin up your own one of these too, if you want.
00:35:09.538 - 00:35:17.214, Speaker A: Yeah. Interesting. That's a really interesting solution to the problems of updates here.
00:35:18.554 - 00:35:40.284, Speaker B: I think we're going to see more protocols being built at this with this creative combination point of off chain and on chain. Actually, if you go back in time, there were some dexs that had off chain orders that were signed and then could be executed on chain. And I actually think some things like that are good ideas that you'll start to see coming back as people really try to get the performance to improve.
00:35:41.024 - 00:36:23.174, Speaker A: Yeah, I was going to say there's a lot of hybrid oracle, excuse me, there's a lot of hybrid exchanges that are launching where components like the order matching is centralized, but then you actually have to sign with your ledger to actually transfer, to execute and fulfill the order after the fact. So there's a lot of interesting models for there. As this gets going. You mentioned you guys support over 30 different blockchains. Now, I assume a bunch of that 30 is made up with various L2 solutions on ethereum as well. Yes, from Pith's perspective, each of those l two s is basically an independent blockchain at this point. It's not like there's no.
00:36:23.174 - 00:36:41.334, Speaker A: I think one could assume that because these things are all thought of as being in the ethereum ecosystem, there would be some ability to publish to one and then proliferate out onto the others. Did you guys kind of explore that sort of architecture at all, or is it just easier to publish to each one as if it's functionally an independent chain?
00:36:41.994 - 00:36:48.138, Speaker B: Yeah. So pith is on a bunch of different l two s right now. Run herbitrum. Optimism.
00:36:48.306 - 00:36:48.746, Speaker A: Yeah.
00:36:48.810 - 00:37:38.626, Speaker B: Pits treats these basically as independent chains. We don't really care that they are, in fact, ultimately rolling up to Ethereum. And the reason we do this is actually because the pull architecture, one of the advantages of it is that it lets you treat basically any consuming chain uniformly. So you don't need to have a specific way to communicate with any given blockchain. So there's really no benefit in knowing that they roll up. So because we're generating all the prices on Pipnet, there's one piece of technical infrastructure that is taking all the prices from data providers, combining them, signing them, making sure that you got these verifiable payloads. And that piece of technical infrastructure is shared across all the different blockchains.
00:37:38.626 - 00:38:15.564, Speaker B: And then you have these payloads and that's the common interface that all of the different L2s or ethereum or cosmos chains share. That actually really simplifies the process of extending to other chains because what you need to do is basically develop a contract that understands how to verify those payloads. That's a relatively simple thing to do. You don't have to have infrastructure for that blockchain where you know how to send transactions and you don't even have monitoring or whatever because of that architecture, we could just treat all these chains uniformly and it just works. I guess.
00:38:15.644 - 00:38:31.744, Speaker A: I assume that there would be more tooling available to mean that you could publish to, for example, one optimism chain and then it would connect into all the other op chains. But that's not really something you guys are seeing today as possible.
00:38:32.324 - 00:38:55.054, Speaker B: No, I don't think that that's possible. I mean, I think it requires bridging in some form. And depending on how your roll up works, that bridging could actually take a long time. If you look at the optimistic roll up bridging, I think some of them have a latency of seven days to go from the l two back to the l one, and then you have to go from that l one to another l two. There's actually quite a few steps involved to do that.
00:38:55.514 - 00:39:12.564, Speaker A: I want to talk a little bit about. Most oracles have either a business model that depends on people paying to publish data, or they have a token or some component for that. What is the model that pith is looking for long term sustainability on?
00:39:13.184 - 00:39:49.090, Speaker B: So pit actually has a monetization model today that's live. So with the pull oracle, every time someone puts one of these price payloads onto the blockchain, they actually pay Pip a small fee. So that fee right now is a placeholder. It's like one way or the equivalent on whatever blockchain you're on. But that's something that governance, Pip, governance in the future will be able to control. And so the idea here is basically the users of the oracle end up paying for it. And as the user of the Oracle, you're already paying some transaction fees and things like that.
00:39:49.090 - 00:40:01.904, Speaker B: So you're definitely willing to pay to do the thing that you're doing. And so this just gives Pip, a way to basically collect a small amount of revenue from each user and as usage grows, you can expect those fees to accrue to something meaningful.
00:40:02.524 - 00:40:58.636, Speaker A: Yeah, I want to dig into this a little bit more because there's this thing going on right now in the bear market and this is across all ecosystems. But the one I'm most familiar with is the problem on Solana, where there's beloved open source tooling that is critical to the operation of a lot of protocols. But it's not really things VC's want to invest in. There's a potential to add a fee at some point or something along those lines. Lines. But some folks are scared from a regulatory standpoint or some people just say, hey, the fees we could add are still not really enough to keep us going. What do you think it is about oracles that have made it so that DeFi protocol creators or other people who are actually using the data? Of all the things out there, this is one of the few things in blockchains this and RPC calls that people find are actually worth paying for.
00:40:58.636 - 00:41:26.184, Speaker A: I guess I sort of expected that at this point we would have more oracles that were actually being created by the protocols and they would basically say, look, we're at DYDx, we're really big now, or we're uniswap, where we're a big protocol. We can roll our own solutions at this point and not actually continue to pay oracle fees. How do you sort of see oracles as maintaining their place in the market over the next few, well years.
00:41:27.884 - 00:42:03.670, Speaker B: Trey? Well, theres a lot in that question. I mean, I think for that first part, theres sort of a classic public goods funding problem for a lot of things. And its not clear that youre going to have a good solution to that problem. It just really depends on really the specifics of what youre building and whether theres a way to actually monetize. Right. So a lot of open source software has this problem and I don't know if there's a good way around that in general. Now for oracles in particular, I think a lot of oracles actually fell into this public good problem.
00:42:03.670 - 00:42:28.814, Speaker B: If you look at some of these oracles that do these push updates on other chains that you have that problem right there. I mean, once the price is on the blockchain, it's free for everyone to use. And Python Solana actually does this. Right. Python Solana is kind of running a push model oracle and it's really difficult to monetize that. Right. Because the price is there, I mean, you could just use it, like, why? There's no reason to pay pith in order to use it.
00:42:28.814 - 00:42:57.174, Speaker B: So I think you kind of have to. The way to solve a lot of these problems is you have to kind of get creative with the design of the system so that there is actually a place where you could monetize. Right. And so I've been harping on the pull oracle a lot, but the pull oracle does solve this problem. That's another one of its benefits. There's actually a lot of benefits to this design. And so that actually gives us a place to do the monetization.
00:42:57.174 - 00:43:52.090, Speaker B: And then there's a question of, okay, well, is that monetization sort of sustainable in the market? Right. Like over time, as other people enter the market, where do the fees paid to Oracle end up as a function of overall transaction value or transaction fees or something? Obviously, it's a little bit early to say how that's going to play out. I mean, this market is very, very new. But if you go and look at traditional finance for an analogy, you'll see that market data fees tend to be about 20% of the revenue of most big exchanges. Right? So we're kind of using that as a rule of thumb in our head to say, look, presumably those markets are somewhat rational. There's clearly some value being placed on data in those markets. If the data weren't worth 20%, they'd probably charge less.
00:43:52.090 - 00:44:04.310, Speaker B: I don't know if 20% is the right number, if it's 25 or 15, but that's our ballpark number that we're using in our head. I don't know. I think it might just play out like that. Right.
00:44:04.502 - 00:44:44.674, Speaker A: So as you kind of look at like the space of oracle data. So pith right now, what is the like? It is a set of data that's available for different types of pricing. There are other types of oracles out there that are designed to bring in arbitrary data. Like switchboard is one example of that. How do you think of like, as this whole space evolves, there's going to be more and more need for custom data feeds. And those custom data feeds might not be terribly custom. It might be like, hey, we need to bring in the price of this COBOL futures on chain and currently there's no feed for COBOL futures.
00:44:44.674 - 00:44:54.834, Speaker A: How are those sorts of things decided by the pith data association in terms of what types of price feeds are supported, or is that more demand based at this point?
00:44:56.334 - 00:45:58.230, Speaker B: Yeah, I think there's a design space for oracles, which is like, there's maybe two axes, which is like, is the data sort of publicly available? Versus like, is it proprietary? And then the other axis would be something like, is there a single source of that data? Versus like, are there multiple sources of it? Right. And so if you think about what Pyth is focused on right now is we're really focused on the proprietary multi source case. Financial market data is in that quadrant and is probably the most valuable thing in that quadrant. So that's our real focus area. But that doesn't mean that the oracle that you build for that part of the quadrant is the one that you want for other parts. If you really do want data that's publicly available on the Internet, maybe the web scraping solution is a really good solution. So we're not really even competing in that area.
00:45:58.230 - 00:46:15.394, Speaker B: And I think solutions that other people have built there are actually pretty good. Right. So that's just not the thing that pit this for this proprietary multi source data that is financial. And we think a lot of the really valuable data is there, which is one of the reasons why we're in that quadrant.
00:46:17.714 - 00:47:25.150, Speaker A: Yeah, I guess the thing I would say is there's a lot of proprietary financial ish data, like energy markets, you could think of as an example of something like that. The scope of, and I'm sure you know, with your previously working at jump, the scope of what one can trade for financial gain using proprietary data is nearly endless at this point. So how do you guys kind of think about what that scope is? You could see a world where, okay, the treasury rate should be something that's brought on chain that's not necessarily proprietary. You look at something like energy markets, that is at that point, there's not one public data feed you can get the price of energy from. But how much of the work for pith is running ahead of where the current DeFi and crypto markets are and how much of it is tracking? Like, what are people building? I'm thinking about all the new attention that real world assets are getting nowadays and folks looking to do things like bring all sorts of tokenized funds on chain as well.
00:47:25.342 - 00:48:08.674, Speaker B: Yeah, yeah. So I think for us, like, the good thing about pith is that we have access to a lot of this data, right? Like if it's a thing that someone can trade, like some of the pit data providers are trading it, you know, some of the dip fit data providers are probably the biggest market makers for that thing, so we can definitely get access to those prices. And I think, you know, advantage of like, the first party design and all that. Um, in terms of actually putting it on the blockchain. Like, look, if you have access, it's not that hard to actually turn on the price feed, right? Like, actually getting access to the data is the hard part. Um, so for that, we actually tend to be somewhat reactive. And if people show up and they're like, hey, I want this treasury on chain, we go, oh, okay, yeah, we could do that.
00:48:08.674 - 00:48:53.844, Speaker B: And then, like, we'll go turn it on. Right. Um, this can be challenging for some types of financial assets that, like, don't quite fit into the, the current price speed model. Right. Like, this doesn't tend to be a problem right now so much because people basically want things that work, like cryptocurrencies, like they want things that trade twenty four seven and things like that. Um, but, you know, you can have, like, features that expire at a certain point in time, and then you need to roll them and you need to decide, like, oh, how do I want to manage the feed for the December 23 future and the January 24 future, and when does the 23 one disappear? There's some logistics around the traditional finance markets that tend to be a little more complicated. And currently we don't really handle those types of assets, but at the same time, nobody really wants them.
00:48:53.844 - 00:49:12.954, Speaker B: Right, bit of a tangent, but the point is, for a lot of things that people want, it's pretty easy for us to list them. And then some of these more esoteric things I think are probably in scope, but we'll start working on it when people actually seem to want it on chain.
00:49:14.054 - 00:49:45.034, Speaker A: So at this point, pith has been live for a while. And you guys started out on Solana, you expanded to all these other chains. Now, what have you guys kind of learned over the last year or so of operating pith in a bear market? Are there things that came up that ended up being problems or something you had to address that you guys hadn't thought of with the massive volatility we've seen over the last twelve months, or just bear market activity in general, changing how people are consuming and using the protocol?
00:49:46.134 - 00:50:33.064, Speaker B: Yeah, it has definitely been an interesting journey. The bear market has definitely been one part of it. I think we've definitely seen a lot of cases where you have assets where they're trading at different prices on different exchanges, or there's a lot of volatility. I'm thinking about the USDC DpEG earlier this year. There's definitely been some incidents there. I think we actually haven't had any problems for those things? It's been a good test of the infrastructure and things like that, but things have actually operated pretty smoothly through all of that, all that volatility. I think there has been some trends in the bear market that I think are definitely noticeable.
00:50:33.064 - 00:51:13.452, Speaker B: One is that it seems like a lot of people are getting very interested in trading on the blockchain and using defi over centralized exchanges. So I think you've seen the emergence of solutions like perps and stuff like that, that all run on chain, and you see a lot of growth in those markets relative to using a centralized exchange. So I think that's been something. We've seen a lot of pip users end up building those kinds of things. And so that's been interesting. That's been good for us because those kinds of protocols do want really low latency and high frequency feeds. So that's been a trend.
00:51:13.452 - 00:51:47.650, Speaker B: Another thing that's been interesting has been to see kind of the. Just the differences between different blockchains, as PIp has. We started on Solana and that was really the first blockchain I ever programmed for. Right. So that's kind of where my head is at in terms of how blockchains work. And then it's been very interesting to kind of go and be like, okay, now we're going to work on Ethereum and go look at how things work over there. And I think there have definitely been some pros and cons, I think, of basically every ecosystem.
00:51:47.650 - 00:52:15.910, Speaker B: That's been an interesting set of lessons. I mentioned this before, but Solana is really, really fast and cheap relative to other chains. It's truly, truly shocking. And there's other chains that advertise themselves as cheap. And actually Solana is 100 x cheaper than this. And the things that bit is doing on Solana mainnet, they just won't work here or they'll be really, really expensive. So that's definitely been one thing that I've noticed.
00:52:15.910 - 00:52:52.564, Speaker B: Another thing is you go to Ethereum, and there's actually a lot of infrastructure on Ethereum that you don't really have elsewhere. And this actually touches a lot of different parts of the stack, like custody and multisigs. Those kinds of things tend to just be built on Ethereum because it's first. Or we were looking for a solution to basically run an off chain service, like a keeper service. There's a lot of keeper services on Ethereum because they've had a lot of time to build there. I don't know, it's just been interesting to compare and contrast the ecosystems like that.
00:52:53.464 - 00:53:15.724, Speaker A: Yeah, that is really interesting. It's always fun to talk to folks who have that broad based perspective of having built the same, if not a very similar thing on lots of different software implementations and lots of different blockchains and seeing, oh, we have to do it this way on this one because of this reason. It's very interesting to hear and see that work.
00:53:16.224 - 00:53:57.908, Speaker B: Yeah. The third thing that I think has really been interesting for me, or maybe a mindset shift or something, is you really have to design your software differently in the crypto world in general because it's like, it is so the security and the reliability are so, so important. So in web two. Right. Look, before I worked on pit, I was part of a startup. We did some national language processing. We ended up building the calendar, assisted in Microsoft out, and it's an NLP system and it's like, look, you have some bugs in your software, it's like it doesn't return.
00:53:57.908 - 00:54:34.914, Speaker B: The right event is not the end of the world. You don't need somebody gets a bad user experience, not the end of the world. Whereas in crypto it's like, look, you have a bug in your software and there is millions, hundreds of millions of dollars at stake, and that's just a very, very different world to develop software for. And so one of the things that's definitely been interesting for me is really internalizing what it takes to build software to that level of quality and that security and reliability standard and thinking about the practices that you need to basically ensure that you never have a problem. Basically.
00:54:36.374 - 00:54:44.914, Speaker A: Well, hey, thanks for joining us today on validated to chat a bit about pith and the future of this. I really enjoyed the conversation.
00:54:45.934 - 00:54:47.214, Speaker B: Thanks again, Austin, for having me.

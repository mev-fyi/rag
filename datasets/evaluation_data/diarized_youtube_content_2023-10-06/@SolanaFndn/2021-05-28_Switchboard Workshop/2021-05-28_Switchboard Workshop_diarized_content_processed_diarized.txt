00:02:03.124 - 00:02:22.772, Speaker A: Hi everyone, sorry about that. I got a little tongue tied in the beginning there. My name is Mitch. I am a co founder of Switchboard. You can reach out to me at Mitchwitchboard XYZ during this chat or at doctorblocks on Telegram or Discord. And now we'll get started. So anyways, a little bit about myself before we dig into it.
00:02:22.772 - 00:03:45.090, Speaker A: For the past four years I've been an engineer at Google. For the first two years I was on the Google Wi Fi team, focused in home network security and focused on vulnerabilities on the Google Home device and general home network attacks. For the next two years I led a team on app engine where we focused on VPC network security between app engine and the rest of Google Cloud. But during that time, me and my friends started looking into scalable blockchain solutions and we really came and looked at Slana closely and saw that this is the real scalable solution to bring blockchain into the scale of the Internet. So we started looking at building, but when we started building we actually noticed that a lot of primitives on the blockchain were not yet available. After careful examination, we've looked at a few solutions and decided to build a oracle solution on the Solana blockchain because we did not see a viable solution yet at the time when we were building our own other applications. We also realized that many other oracles on other chains have focused explicitly on financial time series data rather than generalizing all forms of data.
00:03:45.090 - 00:04:29.404, Speaker A: So Switchboard's goal is to provide an oracle generic to bring a breadth of real time information to Solana. We want this to be community curated as well to not have any single entity controlling what the content of these data feeds are. Which brings us to our mission here. Switchboard is building a decentralized, community curated oracle network on Solano. Switchboard is a data type and data source agnostic solution and we will let the community decide what goes on chain. Great. Now that we have our mission out of the way, we'll go over a brief architecture overview of what we're building like and how to use switchboard.
00:04:29.404 - 00:05:09.788, Speaker A: And it's very simple. It only takes about three or four lines to actually call one of our data feeds and then publishing your own data feed as well, which will go through actually posting your own accounts to host your data feed and running your own oracle. Great. So now let's look at our architecture overview. Currently on Devnet we have a single switchboard program which hosts and is a parent of a number of aggregator account different account types. We'll be talking about two account types specifically right now. One account type is known as an aggregator, which holds all the information pertaining to a data feed.
00:05:09.788 - 00:05:46.724, Speaker A: Like the sources and aggregators would be pulling from. Like let's say this is an aggregator for the bitcoin price. We could say getting a BTC USD spot price from Kraken, Binance and Bitfinex. It'll hold all of those jobs and it'll hold configurations like how often this aggregator can and should be updated. Then there is a fulfillment manager account type which is responsible for authentication and authorization of oracles and which oracles are allowed to respond to. Which aggregator. Moving on from there, we actually host an NPM module that makes it very easy to interact with our API.
00:05:46.724 - 00:06:43.714, Speaker A: And let's take it from the top here. Let's say that you as a consumer of switchboard, comes to our data feed listing and doesn't see the sole USD aggregator listed on our supported feeds. Well, it's actually very easy to go and build this yourself using our module. You can go and create a new data feed account that is a child of our switchboard program. You can load it with a number of jobs like the Kraken USD, like the price of bitcoin from Kraken, Binance and Bitfinex. And once those are all loaded, you can call update, which will make an agreement between the fulfillment manager and an aggregator, and it will choose a number of oracles to fulfill your job. And then it will send all of those results into the aggregator and make an informed decision on what we believe is the correct price of bitcoin.
00:06:43.714 - 00:07:09.334, Speaker A: Great. Now that we've gone over the architecture here, I'm going to stop and look at the chat for any questions. Are you still working at Google or is this your full time occupation? I have stopped working at Google about two months ago, yes, sorry about my throat. I choked on it and then I lost my place right in the beginning of my slides. So I am all right. Sorry about that. And we can keep digging in from here.
00:07:09.334 - 00:08:00.600, Speaker A: Okay, so I'll be checking back to see if there's any more questions on this architecture because I know there is a lot of details in this slide here and we'll be following up in the discord too. Great. So now I'm going through some examples. Our first example here will actually be a simple hello world application that takes one of our data feeds from our Explorer page, passes it to an example program which just prints the current results to the Solana log. Let's go look at the explorer here we can actually see that we currently support the top 20 cryptocurrency pairs versus the US dollar. So we're actually supporting more. We're hoping to have the top hundred crypto pairs on our site in the next month or so.
00:08:00.600 - 00:08:39.502, Speaker A: And we also support some more non traditional data like the basketball 2021 results. Like we have the number of wins for this current season for all the current NBA teams. And we want to support all of the major sports legislation in different country economic stats as well. And we're going to be making this as expansive as possible to keep the widest breadth possible. So let's go examine one of these data feeds. We had at the top, a very simple way to just copy the price of this data feed so you can use it in your application. And we can see the current results from all of our oracles reporting on this data feed.
00:08:39.502 - 00:09:02.404, Speaker A: We have oracle jobs to fetch, python, Kraken, bitstamp, FTX and Binance and a number of others. And you can just click here to look actually at the job definitions. And we have all of the information on these job definitions in our documentation. So the documentation is right here. You can see all of this at Switchburg XYz. I will post a link in the chat here. Excuse me.
00:09:02.404 - 00:09:28.388, Speaker A: Perfect. And let's see if there's any questions here. Can I make my Twitter match rate in oracle? Yes, you can make anything in Oracle. And we can actually talk about how you can pass private API keys into an oracle without actually exposing into the blockchain at the end of this talk. Great. So I think this is full screen still. So great.
00:09:28.388 - 00:09:59.774, Speaker A: Now let's actually walk through a run of this example. Let's look at the program we're going to be running before we actually get to running it. This is a very simple program. We're going to be taking the first account in the transaction that we're going to be running in this program. We're going to parse out the aggregator state and then we're going to be getting the current results from this aggregator and just print that to the Solana log. Very simple, four lines. So let's look at a run of this program.
00:09:59.774 - 00:10:46.072, Speaker A: We're on our Explorer page. We copy the address of BTC USD aggregator, put that into our law into an environment variable, and then we run that program I just showed you which has already been posted for this example. Once we confirm this transaction we will have a link to the block explorer and then once this is finalized we'll see the logs here. Great. You can see it's very easy to get the most recent result from one of our aggregators on chain, simply three or four lines. Let's see if there's any questions here. The sports you side what? So I'm curious about the sports side of it.
00:10:46.072 - 00:11:37.854, Speaker A: What would that allow to do? Could you explain it can be applied to real life application? Sure. Let's say you want a transaction contingent on, let's see, winning the next game. You can post a program on chain to make sure that this is enforced by one of our oracles or any type of sports betting application is what comes to mind for me at least very interested in the sports component of this. Can you say more? Yeah, we're just planning on supporting a number of stats for a number of sports and ultimately this is going to be driven by the community. If you post something in our discord or Telegram, we're happy to look into supporting it first party. But if anyone wants to support themselves, we're going to give an example, like a very simple example on how to actually support your own data feeds without actually having to host anything first party or by us ourselves. So I'll be getting to that very soon.
00:11:37.854 - 00:12:21.594, Speaker A: Okay, great. I will exit this example. Great. That was the first demo. Now let's get to something a little more involved which is actually configuring and posting your own data feed on switchboard. What we'll actually have to do here is will have to post your own aggregator account which is a child of our switchable program, your own fulfillment manager account and then set up the authorization configs required to make sure that no random node can just join your fulfillment manager and give you untrusted data. Then we'll actually go into running your own oracle and then calling update on your data feed.
00:12:21.594 - 00:12:49.144, Speaker A: So we have this example posted here. Copy this link for all of you so you can see it in the chat. And we have very nice directions on how to set up this example. So you can set up any data feed you want yourself. And let's go back to the document here. Great. So let's go over the first part of this example where we post all of the account types to make your own data feed function.
00:12:49.144 - 00:13:54.158, Speaker A: First off, we need to create a data feed account to actually hold the jobs that need to be fulfilled when we call update. Then we have this helpful function called add feed job which will allow you to easily specify the oracle job that should be performed by this aggregator. And there can be any number of oracle jobs per aggregator up to the specified limit because we are limited by the Solana computation limits per program run, this job will actually fetch the BTC USD price from binance us and then parse out the price. And this price syntax is something called JSON path syntax and you can actually look at our documentation on how to specify JSON path. Then we need to post a fulfillment manager which will control which oracles are signaled when an update is called and if they are allowed to be signaled. And we are going to require full authorization and authentication mechanisms for this fulfillment manager. Let me describe what each of these authorization settings do.
00:13:54.158 - 00:14:56.392, Speaker A: Heartbeat auth required means that an oracle to join this fulfillment manager needs specific permissions to join by the fulfillment manager owner. So no random oracle can just join any fulfiller and update and respond to any random aggregator. This usage auth required is specifically to control how many aggregators are using an oracle at the same time. If you don't actually set this usage auth acquired setting, then any number of aggregators can use your fulfillment manager and possibly dos your oracles. So you'll want to set both of these settings until an incentive mechanism is built to make sure that people are responding accurately and in a timely manner and frankly telling you an accurate response for your data feed. The next up here is actually setting up the data feed configurations. Data feed configurations here are the number of confirmations which are the number of jobs that we actually need to succeed before we report a result.
00:14:56.392 - 00:15:44.992, Speaker A: So we collect an aggregate of a number of jobs, but right now we're only posting one job. So we want the confirmations to accept a round to be equal to one. But realistically, when we're setting up an aggregate for a price pair, you'll probably want three or four sources to set a price. So you'll want to get the source from binance, US, FTX, Kraken, and have at least four or five sources before you accept a round. And we will be taking the median of all those sources to figure out our round result. Then this fulfillmentmanager pubkey specification will actually link this fulfillment manager to your data feed. And then these authorization accounts that are being created here pertain to the authorization settings that I mentioned in the fulfillment manager configs above.
00:15:44.992 - 00:16:32.204, Speaker A: And let me check for any questions on some of these configurations here. Did you have any prior blockchain development experience before this? Yeah, we experimented with a number of DeFi projects branching off from Ampleforth before this, where we actually started getting curious about Oracle solutions before moving to Solana. Yes, some of the team has prior solid experience exactly LDAP's great. It seems that Chris is handling some of the questions here. I will move on. So great. Now that I have explained the setup for this example here, the next steps are actually for the example runner to run your own node and then to actually call update on your data feed that you've just posted.
00:16:32.204 - 00:17:39.682, Speaker A: So let's look at a video of all of these steps being performed in this top window I am running example two a where we'll be posting our aggregator and fulfillment manager and configuring our authorizations. Let me fast forward a bit because this example waits till the transactions are finalized to actually print the next step. So now the aggregator is posted, the fulfillment manager is up on Devnet, and now we are waiting for the authorization accounts to be posted as well. In this bottom window we are actually going to be posting our oracle and we're going to be linking it to the fulfillment manager that we have just spawned now. And we need the authorization key for the authorization settings that we just specified in example two a before. So now our node is up and we are going to call update on this data feed in this top window now and we'll just wait for that to happen. Great.
00:17:39.682 - 00:18:17.552, Speaker A: And in the bottom window you can see that the price of bitcoin was just what we just got this aggregator request to be fulfilled and the results of this aggregate request is $38,752. And then this result will be ported back to the aggregate and we will wait for the aggregator to receive the response from the oracle. Let's just wait for that to happen because it takes a few seconds here. There you go. You can see the new aggregator state with the new result from the oracles. In this example we only had one job, so we only waited for one success. And anyone can call this aggregator to fetch that result now.
00:18:17.552 - 00:19:07.714, Speaker A: Fantastic. Let's check for any questions on this step. Yep, Chris is still surfacing, so perfect. So the next part here is actually pertaining to private information you might want to list in a job. So we realized that some people will want to create oracles for services that aren't publicly available or that might require an API key. So for these specific services we have developed a feature called variable expansion where an oracle job can specify a pattern in their either HTTP get request or in their headers of their HTTP get task. And we will actually allow oracles to replace that pattern with any private variable list in their configuration.
00:19:07.714 - 00:19:58.142, Speaker A: Let's actually look at our getting started guide. In this example we have some endpoint on coinbase that requires an API key. What an oracle will do is for any pattern that is surrounded by the bash variable syntax, it will check a config file that it loads for any job variables. If for a specific job there is a key match, we will replace this key with a value in the configuration. We see that this API key matches a variable in this configuration, so API key will be replaced with ABC 123. In this case, for a node to actually specify a configuration file, all it needs to do is to mount a volume like this. It's fairly simple.
00:19:58.142 - 00:21:04.016, Speaker A: So you just specify a simple JSON file in your oracle that you're using for your aggregator and then mount the volume for your configuration and fantastic. That's the demo of switchboard. The next steps are to start building here. We have published feeds at the link I showed above, or you can also use explore switchboard XYZ, a number of getting started guides and a rust crate to parse the aggregator states. And if you want us to host anything specific or have any questions, please contact feedhelpwitchboard XYZ. The next steps here we're also looking for volunteers to run additional nodes and support extra feeds. And if you have any feed recommendations, we want this to be community curated, so please reach out on Discord on Telegram for whatever you'd like and we'll be eventually moving to a DAO model where the community can on chain vote for any changes we want on any aggregators we posted.
00:21:04.016 - 00:22:28.924, Speaker A: So if you're interested, please reach out on Telegram or Discord or message me at doctor blocks directly and we'll be taking questions. Now what are the main issues that switchboard could be could encounter when implemented? I would say that not too many aggregators should be using a single fulfillment manager entity just to make sure that we're not overloading the nodes that are fulfilling requests. Because we're aware that a lot of these APIs that we're going to be fetching from like Binance or Kraken have rate limiting constraints and we want to make sure that we are hosting enough nodes off chain to still fit into the rate limiting requirements for these sources that we are fetching from. So as long as you have a very specific set of nodes fulfilling a certain aggregator, you will not reach these problems. But as you scale you should make sure to have enough nodes and distribute the request as much as possible to not hit those rate limiting issues when encrypting the job variables. When not in use, add much latency to the entire process. No, the job variables file is actually only loaded on startup, so if that is a feature that would be requested, I'm sure we can look into that as well.
00:22:28.924 - 00:23:32.144, Speaker A: Can you call 50 to 60 accounts at the same time? How does that work with websockets? Natively added so I believe you're asking if we can update 50 to 60 aggregators at the same time. If these are HTTP tasks, that might hit some of the rate limiting constraints that we've talked about, unless you have separate fulfillment managers for each aggregator. But for websockets, for any websocket sources, those are pushed and not pulled. So if you want to call update on 50 different aggregators that are fully supported by Websocket feeds, and that wouldn't be an issue at all. Coinbase bot sold at $40 and can't dump it, and the user said downtrend has ten days. Would any more nodes when more nodes help the Oracle deliver faster? Not specifically. The nodes just offer a replication mechanism to verify the integrity of information.
00:23:32.144 - 00:24:39.494, Speaker A: So having more nodes we might be able to distribute requests so we don't meet those rate limiting limitations as much, but I don't believe it would make it any faster. Great. All righty then. I think that's yes, we are hiring, so please feel free to reach out on discord if you're interested in contributing to our project here. I'm confused because the code that is running is done on the server side and updating on a feed. Are you calling seven different nodes each time? So those nodes are the oracles, and we have a number of nodes to fulfill an oracle job every single time we call update to make sure we have proper replication in place. So we are signaling seven different nodes each time when we call an update? Yes, but they are fetching the same jobs to make sure that the answers are as minimally centralized as possible.
00:24:39.494 - 00:27:00.834, Speaker A: The discord is at Discord switchboard XYZ great. All right then, well, thanks for coming to the workshop and if you have any questions, feel free to reach out to me, feel free to reach out to hdaps and happy to help you start building. So thanks so much. It.

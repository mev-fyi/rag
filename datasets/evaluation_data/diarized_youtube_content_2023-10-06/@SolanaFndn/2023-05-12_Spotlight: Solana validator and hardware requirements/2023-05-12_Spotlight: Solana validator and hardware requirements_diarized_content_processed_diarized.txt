00:00:00.320 - 00:00:17.394, Speaker A: Hello, everyone. GMGM. I'm Nick from the Solana foundation dev rel team. And today I'm joined with guy from Latitude sh. He's the CEO and founder over there, as well as Tim from, also from Solana Foundation. Tim is the validator community lead. How are you gentlemen doing today?
00:00:17.974 - 00:00:18.510, Speaker B: Doing well.
00:00:18.542 - 00:00:19.514, Speaker C: How are you doing? Good.
00:00:20.614 - 00:00:40.814, Speaker A: Awesome. Thanks for having me. Absolutely, absolutely. I'm super happy for our conversation we're about to have. We're going to talk all about the hardware side of running validators on the Solana network. So let's go ahead and just dive in. And I guess the first thing I want to clarify, and maybe, Tim, you can take this one, is what's the difference between a validator on Solana and an RPC?
00:00:41.194 - 00:01:21.374, Speaker B: Yeah, sure. So as far as the code paths go, there's not a ton of difference. A validator is confirming blocks, a RPC is also confirming blocks. The difference really is that a validator is voting and an RPC is not. So, as in Solana, you have to pay some sole for each vote that you cast. You can choose to turn your validator off in non voting mode, and then it's essentially an RPC. Typically, you don't want to have a voting validator also be an RPC, because the specs for that and the load that RPC has to handle is a little too much to also be a high performing voting validator.
00:01:21.374 - 00:01:35.624, Speaker B: So really, it's just a couple command line arguments that you change makes. The two have different purposes. One is to handle API requests, and another is to actually participate in consensus and vote on blocks.
00:01:35.924 - 00:02:04.192, Speaker A: Okay, yeah, that makes a lot of sense. And since you mentioned the difference in the hardware requirements that a provider might want to actually give to their customers, or a validator that's running a validator wants to actually use. Guy, since your company does provide infrastructure and bare metal servers, can you talk a little bit about general hardware specifications that you generally recommend for running Solana validators and for rpcs?
00:02:04.368 - 00:03:14.564, Speaker C: So, like Tim said, you cannot mix one another, right? You are either running a consensus validator or an RPC that are serving API requests. And so basically you have the same type of cpu. You are looking for high frequency cpu and new generations. Most of the operators for both of the RPC and validators are using AMD third generation cpu's. There are a lot of tries to use old generations of AMD, like the second generation, which they could meet the frequency that is right now about 2.85, but they start falling behind. So CPU's for both validators and RPC.
00:03:14.564 - 00:04:36.934, Speaker C: New generation third generation of AMD is the recommended stack for drives for both validators and RPC operators should use NVMe fast drives. PCIE four is the recommended ones. And memory, that's what changed the most. So for consensus validator, the minimum, the borderline is 128. There are many operators still running that kind of spec using Hyzen cpu's which can support the maximum of 128. But the recommended would be 256 gig for the validator and for the RPC. As you have to serve requests and you have to index the three indexes that Solana has today, you have to have more memory in the machine if you want to serve the requests faster.
00:04:36.934 - 00:05:30.114, Speaker C: So you need at least 500 gigabits of memory if you are providing these requests for specific program ids on Solana. But if you want to index everything that Solana has, you should go over that. So once you're a terabyte of ram would be the recommendation. So, yeah, so what I see is the RPC providers in general, when they want to provide the whole thing, they just use 1 tb machines. And when they want to provide to specific programs like only magic Eden, you can, you can use 500 gigabit machines.
00:05:30.774 - 00:05:45.574, Speaker A: Okay, so in that specifically, to clarify, when you mentioned the memory, you specifically are talking about the ram of the machine, not hard disk space, because hard disk space is not really super important for running a validator since everything is more or less stored in the ram.
00:05:45.734 - 00:06:20.660, Speaker C: Yes, that's correct. The validators use RAM disk to store the accounts. So they, there's, there are two things there. They are the memory. The RAM memory is more performance. And second, when, if you, if you store accounts in disk, you, you burn your, your disk in one year or less because it's, yeah, I bet it's too heavy. Yeah, yeah.
00:06:20.660 - 00:07:09.726, Speaker C: But for operators that have less than 200gb of ram, they usually use drives. And it's okay if it's an NVMe fast drive, they will not have much impact on performance, but they will certainly be burned in a year or so. On the RPC side, you have to have more space because you are providing at least two epochs on Solana. So you have to store more data there to serve these requests.
00:07:09.910 - 00:07:11.770, Speaker B: You mean hard disk space there, right?
00:07:11.942 - 00:07:14.002, Speaker C: Yes, hard disk space. Yeah, yeah.
00:07:14.058 - 00:07:29.614, Speaker B: Great. Well, after going through all those specs, can you talk a little bit more about why bare metal on Solana versus a virtual machine, a cloud provider? Like why do providers have to go with bare metal, I should say, or highly recommended.
00:07:30.234 - 00:08:33.734, Speaker C: Yeah, sure. So the virtual machines that are used, they are used in hyperscalers, AWS, GCP, azure. And these hyperscalers, they use cpu's that has a lot of cores, because they are doing virtualization on those machines. And when they do virtualization to optimize, they throw a lot of cpu cores so they can handle more workloads and more virtual machines for each hypervisor they are running into. Right. And when you have cpu's without like 128 cores, something crazy like that, you have lower frequency. So I see a lot of people trying to run there, and they are falling behind the network because the frequency is not enough.
00:08:33.734 - 00:09:15.054, Speaker C: It's just a cpu that has a lot of cores and it's not optimized for Solana, but for a general use case on web two or even other chains. So. Yeah, and there's another thing too. Intels used to run virtualization better than the AMD. And a lot of people that try to use intels, even the newest generation, they are having a really hard time to keep up with the network. I am not sure why.
00:09:15.174 - 00:09:16.790, Speaker A: Oh, interesting, interesting.
00:09:16.942 - 00:09:42.324, Speaker C: Yeah, I'm not sure why if someone came to a conclusion on that, but if it just don't work, and even for other blockchains, high performance blockchains, intel is not just being a feat. So. Yeah, and the hyperscalers are using intel because they are better for virtualization than I am.
00:09:43.344 - 00:10:01.930, Speaker B: Yeah, I will say there are a couple groups working on experimenting more with Intel. I think the Solana community is kind of gone to amds and solidified there. But I don't know, over time, if people have gone back and tried the newest, latest chips. So just to give people other options, maybe experiment there.
00:10:02.122 - 00:10:03.834, Speaker A: Yeah, it'd be interesting to see that.
00:10:03.994 - 00:10:38.176, Speaker C: I saw some conversation about testing on arm as well. Right. That could be really interesting. Arm is really powerful and they have high frequency cpu's. They can handle a lot of cores, even with high frequency cpu's. But I think Solana needs to change a bit the coding to support arm. But yeah, that would be interesting to see if it worked someday.
00:10:38.280 - 00:10:54.630, Speaker A: So the general consensus is, right now at least, is AMD over intel with lower thread count, but a higher core clock frequency and a large amount of ram to be able to process all the transactions that a validator is actually processing, then.
00:10:54.782 - 00:11:31.394, Speaker C: Yeah, and there is this new AMD gen four chip coming out, which will be really interesting to see the validators running these chipsets. AMD introduced a chip that has 16 cores and it can go up to 4.1 GHz. It's just massive amount of power. So that'll be really interesting to see how the performance of these validators are compared to current AMD gens.
00:11:32.054 - 00:11:52.644, Speaker A: Okay, cool. Yeah, so let's go and shift gears a little bit. We've been talking about the machine specs itself. I'm kind of more curious also about the, about the actual infrastructure side of being a provider. Like what sort of bandwidth requirements do you recommend giving to validators and rpcs?
00:11:52.944 - 00:13:33.160, Speaker C: When you set up a machine that is a volume violator or an RPC, they will use 15 terabytes of traffic, egress traffic every month if they are not. Yeah, just to keep up with the network they going to use 50 terabytes and the bandwidth there will change based on stake for the consensus validator and base it on request for the the RPC nodes. So for a validator that has 1 million Sol staked, we saw like the range would be 150 terabytes month to 300 terabytes per month depending on the location where the validator is located. Interestingly that the traffic varies based on stake and location. So the average validator would use 80 terabytes when they have between 102 hundred k stake. So that's the average. And for the RPC, like I said, 50 terabytes would be the minimum to keep up with the network.
00:13:33.160 - 00:13:47.124, Speaker C: And it can go up to 400 terabytes a month depending on how much this RPC is being requested on API calls.
00:13:47.704 - 00:13:53.364, Speaker B: Can you talk a little bit about the pipe size, how much bandwidth you need to run a validator as well?
00:13:54.264 - 00:14:58.206, Speaker C: Yeah, so the recommended would be ten gig NAIC interfaces. When we are talking about 100 terabytes egress traffic every month. This is about 300 megabits of sustained bandwidth the whole month. Right. But you can have peaks. So during huge mint on Solana or some events that can cause peaks or even to handle attacks on the blockchain, you have to have all the validators with a lot of throughput to handle this kind of thing. So the minimum there would be actually not the minimum, but the recommended would be that all validators run with time gig interfaces that are not restricted.
00:14:58.206 - 00:15:11.034, Speaker C: Right. Because you can have ten gig interfaces connected to the machine, but you can have the provider rate limiting this interface on the egress.
00:15:11.734 - 00:15:32.754, Speaker A: Yeah, I guess that makes a lot of sense. I never considered the bandwidth differences and the actual amount of data being ingressed and egressed out of a validator depending on how much stake it has. That's an interesting data point. Are there any sort of concerns about the physical locations and the bandwidth provided based off the physical locations of the machines themselves?
00:15:34.414 - 00:17:01.134, Speaker C: Yeah, I see that federated are usually one to set up their notes close to the majority of the stake. So they are always looking for east coast, us, Europe, western Europe, and in Japan. Those are the places that I see most developers going. Yeah, I think when you set up the node too far away from these taking pools, you can skip a lot of blocks and pack the performance of your validator. So I see a lot of nodes in New York. Actually, when the validator is concerned about getting stake from staking pools, they want to be, they not, they don't want to be in cities or data centers that are much, that has a lot of stake concentrated. They want to be in closed cities and nearby data centers there to get the staking pools, to get stake from the staking pools, but not be really far away from the rest of the network.
00:17:01.134 - 00:17:27.894, Speaker C: So the surrounding areas from Ashburn, like New York, Dallas, Chicago, in Europe, there's a lot of stake in Frankfurt. So I see notes in London and regions there and in Japan, I think everyone just set up in Tokyo.

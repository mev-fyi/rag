00:00:28.394 - 00:01:19.982, Speaker A: Hi. I work with beautiful. Wow, look at this. We have a lot of familiar faces here. Hi, Zach. How you doing? Welcome. Well, this is actually fantastic, and it's such an honor to be presenting at Solana Lisbon.
00:01:19.982 - 00:02:14.682, Speaker A: And I think what's even more amazing is that I think I recognize about a third of the crowd here, which shows just kind of what kind of community Solana is. And I feel so lucky to have been part of this so far and to be building switchboard and bringing so much utility to Solana and for all the builders here. It's amazing to be building the future of Defi and web3 with all of you. But before we dive into oracles, let's take a step back and actually look at the current state of the blockchain's ecosystems and how things are progressing and what direction the Solana community is actually moving into. So starting with the big picture, smart contracts have allowed us to decentralize, secure, and trade just about any asset type on chain. One click. The blockchain has become a new medium for anyone to become a banker, artist or trader.
00:02:14.682 - 00:03:06.484, Speaker A: Across censorship resistant markets. The broader ecosystem has given birth to daos and the rise of dapps like micropayment platforms, reputation systems, lotteries, prediction markets and p two p marketplaces. And of course, the explosion of nfts. Then Solana has come into the picture, which has allowed us to actually scale these blockchain applications with cheap costs and high transaction throughput. But as blockchain grow to that of web scale, bridging data from the web has never been a more critical piece into unlocking the next wave of applications. Oracles help us accomplish just that, making high integrity information available from the Internet onto the blockchain. However, current oracle solutions have a few limitations.
00:03:06.484 - 00:04:14.874, Speaker A: For example, existing oracle systems incentives are statically set regardless of downstream use cases. You can't customize oracle rewards and stashing mechanisms based on the use case of a data feed. So how could somebody trust an oracle that only has a stake of $100,000 when it could be supporting an AMM with billions of dollars locked in pools? Beyond that, most oracle solutions have a centralized control over what parties are allowed to be an oracle operator, and data sources are vetted by a centralized group. This goes against the ethos of the blockchain and why all of us are sitting here today. Can we allow the future of applications to have a centralized source of trust, of selection of data providers where we can't ensure oracle operators are properly incentivized? To tell the truth, I'm not confident we can trust any centralized source to make decisions that are right for all consumers. That's why we built Switchfor. We enable any developer to create their own customized data feed.
00:04:14.874 - 00:05:35.194, Speaker A: I'm going to find the right side here for this we enable any developer to create their own customized data feeds, configuring everything from data sources to oracle redundancy levels to update intervals to incentive models. We put the power of data feed creation and curation in the hands of the developer, which brings us to our mission, which is to enable the community to bring 1 million data feeds on chain by making all data on chain and off chain reliable, accessible and composable for the world. Now, how are we going to accomplish this mission? We can break this down into three core goals that we aim to fulfill. First is flexibility and composability. From ReST APIs to Websocket sources to HTML pages to on chain accounts, we can ingest, parse and transform the data and make it readily available on chain with as little as a few clicks. You can take data from sports platforms, census data, or something like the current price of tungsten cubes and put it on chain. Next is feed personalization.
00:05:35.194 - 00:06:30.084, Speaker A: As the publisher of your own data, you can configure oracle redundancy rewards and slashing as well as update frequency to ensure oracles are properly incentivized for your use case switchboard also offers an native incentivized curation pipeline. No longer will you have to rely on a centralized party to decide what data sources are reliable and which are not. In short, switchboard is the blockchain's gateway to a high integrity Internet. So before we go into our v two incentive models, let's review switchboard v. One. If you wanted to create a personalized data feed, you would need to do multiple steps. One is to create your own fulfillment manager, two is to onboard or run your own oracles, and three is to manage feed updates yourself in switchboard v two, this is all managed for you.
00:06:30.084 - 00:07:22.998, Speaker A: So with that, let's take a look at our preview of switchboard V two. And that screen I was showing is the entry gate to our data pipeline for actually getting new data on chain. Users will be incentivized to actually categorize and label data from the Internet, and ABIs to be used by publishers to bring data on chain in three clicks. And let's show how this is going to work. Now here we have a few people set in the community that have pre populated our store, labeling a few APIs from the common crypto APIs like crack and coinbase and so on, as well as a few sports APIs and NFT floor APIs. So here we can see that this user is trying to make a crypto price feed. We can look at this pre curated solusd price feed that has already set up multiple sources to pull this data from.
00:07:22.998 - 00:08:25.110, Speaker A: You can have the whole details here and you can add this to your cart being ready to publish as your own data feed. You can also bundle these and batch them in a single publishing model. So if you want to add some sports data feeds as well for your application, you can do that in three steps. Here we just show an example of looking at some of the NFT floorplaces too and we're going to add a second component to this bundle before we go and publish. Now we are on the next page where we're actually fine graining the sources you're using for your publishment. So if you don't trust that's a hubby or Kraken, then you can remove that from your data feed so you can select what sources you actually want to be pulling based on your trust model for your application. Before we actually take the next steps for checking out a feed, you connect your phantom wallet to process the payments and what this payment will do is it's going to be used to distribute a payment model for all of the oracles and updaters resolving your feed we have one final step to make final modifications to your feeds before you go and publish and then may go and press checkout.
00:08:25.110 - 00:09:30.632, Speaker A: Now this screen is a bit interesting. What you can actually do is you can specify the length of time that you want your feed to be updated for because as the publisher you are the one sponsoring this feed and paying for it to be up and live for a certain amount of time. You can also specify the reliability which specifies the minimum stake required needed by oracles to actually resolve your data feed updates so you can choose your security model which affects the price point. This also modifies how many oracles need to be used for each update. So you can specify your redundancy levels as well and we give you a summary of how much this is going to cost for the total duration of your feed at the bottom here. So we go and press checkout and you'll see that this will be transferred to a switchboard escrow wallet to make all of your accounts that you need for your data feed and this will publish your data feed account to a pub key. You will get all of your jobs that have been associated with your data feed published as well as well as permissions to use something we call an oracle queue and a crank and I'll review what those are in a minute.
00:09:30.632 - 00:10:16.344, Speaker A: And once this is up this data feed will automatically start being updated by matched oracles. So you don't have to do any selection of oracle groups, you don't have to find sponsors for your data feed. This is all automatic. Now we go on the block explorer and we get the pub key of our data feed. We copy this and we go to our terminal and we fetch the state of our account and we get the latest value here. And now we have to wait to get the current state and we see that the soleusd price feed that we just created is already being populated without any extra steps or infrastructure from the user. So anyone can go collect data from the Internet and publish their own data feed and automatically be matched with oracles and updaters for your data feed.
00:10:16.344 - 00:11:40.118, Speaker A: Let's go back to the presentation here. Now how did all these steps actually work to get your data feed automatically matched with oracles and updaters? So you as the publisher that visited our website are the one to actually create these data feeds. And on checkout these feeds are sent to an associated crank and an oracle queue that will be the ones to actually resolve all your requests. Every time an oracle wants to a data feed wants to update there will be a set of crank turners incentivized to be popping new elements ready to be updated from this data feed crank and once that update is triggered this data feed will collect n oracles from an oracle queue and from there they will be woken up with an anchor event by oracles that are listening on a websockets for an aggregator update event type and if their pub key matches the update event they will respond with the results in the job and they will take the median of the job and return that into the data feed. And once the minimum number of oracles have actually responded, we mark the result that's received as confirmed. And that's how we actually go through these update rounds with these automated update calls. Now let's talk about the incentive models for v two.
00:11:40.118 - 00:12:38.264, Speaker A: We have four main Personas that people can act as in switchboard v two we have curators who are incentivized to populate the switchboard catalog with high quality data. The more a curator sources are used in published feeds, the more they are rewarded. Then we actually have the publisher which we just showed the flow here and publishers are the ones that are creating data feeds. They reward curators for their work at the time of publishing by giving a certain percent of published funds to all of the job curators. They fund an escrow that's going to be paying out the oracle operators as they make their updates, and crank turners as they request updates for a data feed. And as I just mentioned, the crank turners are the ones actually constantly trying to move that crank. And if there's any data feed that has a timestamp that is beyond the current Oracle Solana native timestamp, Oracle will pop that queue and trigger the update and they'll receive a small reward as well.
00:12:38.264 - 00:13:43.534, Speaker A: Then Oracle operators are rewarded or slashed with a certain scale of the distance of the round median based on the oracle's reported value at the time of an accepted round. So right now, let's talk about how far we've come since we actually launched in April. During our v one, we did lots of outreach to the community to see what types of data they wanted supported on chain. Since that time, we've supported 120 data feeds live on chain and we still continue to support those. And with Solana's cheap costs, it's been economic for us to actually do 2 million feed updates per day. At this time we operate about 3% of Solana's main net traffic with all of our feed updates and with our reliability standards and SLA's that we've been keeping up. We formed strong partnerships with ten core ecosystem projects and have about 20 mainnet users that we know of in the growing Solana community and the v two that we have just presented in this presentation will be live November 22.
00:13:43.534 - 00:14:14.764, Speaker A: We'd also like to give a special thanks to some of our partners that have really helped us improve and build this amazing product, and a special shout out to step finance, aver hedge finance and solrise who are being added to this list as we speak, and all the other amazing teams that we are just beginning to begin our path with. Also, a special thanks to Brian Long and Linus and the rest of the RPC pool team for their many hours of support and optimizations for our high throughput needs. And thank you all for your time and interest in switchboard, and we hope you integrate soon.

00:00:04.840 - 00:00:06.805, Speaker A: Brian Long, welcome to Validated.
00:00:07.105 - 00:00:09.673, Speaker B: Hey Austin, how are you doing?
00:00:09.729 - 00:00:10.881, Speaker A: Well, how about yourself?
00:00:11.033 - 00:00:13.965, Speaker B: Great. Yeah, thanks for having me on. This will be a lot of fun.
00:00:14.265 - 00:01:13.865, Speaker A: You know, every once in a while Ray will just sort of, our producer Ray will send me a message that's like, hey, we've never done an episode on this thing that feels like a really base level foundational topic that we should probably talk about. And RPCs came up as one of those that, you know, RPCs are pretty core and fundamental to how users interact with blockchain. And anything that's core and fundamental to how people actually get data onto the blockchain to send transactions is kind of a topic worth, worth diving into. So I really can't think of anyone better than you to have this conversation with. You know, you were there in the trenches in, you know, late 2020 and early 21, when folks were still running RPCs using active live validators in production. People were calling get program accounts and causing giant skip rates on the chain because using a production block builder as an RPC service, not really a great idea. But back in those days, what did folks know early on the network was worth barely anything.
00:01:13.865 - 00:01:29.505, Speaker A: So I want to start at the beginning and at the high level and then we'll get into some of the juicier details as we get into it. But what is an RPC Service? What does Triton1 actually run and do? And how is that ecosystem built out?
00:01:29.905 - 00:02:21.755, Speaker B: Yeah, yeah. So at its like most basic level, an rpc is the web3 equivalent of the cloud. And when you're using your application on your phone or your browser, your phone is then talking to a backend data server and that data server is powering the application. It's a high performance database. And what's unique or interesting though about say web3 as compared to a web2 cloud is that the web3 cloud is standardized. And so that means that the different backends can be exchanged as needed. Maybe one is faster than another, maybe one is closer to the user versus another.
00:02:21.755 - 00:02:49.135, Speaker B: So that backend is interchangeable. It might be in a web2world. Imagine if Facebook and X shared the same backend data platform and then you could actually share a friend list between the two platforms. So the RPC standard allows web app developers to build on top of a very consistent computing infrastructure in the cloud.
00:02:49.295 - 00:03:13.561, Speaker A: Yeah, so I want to dig in there a little bit more because I think one of the things people often think of is, oh, this is blockchain, there's no cloud required. My Programs just execute on this decentralized virtual machine. And that's kind of what the validators are doing. So what's the RPC side actually responsible for? And why do you think the cloud is like the right analogy there?
00:03:13.743 - 00:03:59.305, Speaker B: Yeah, it's mostly the read layer. So reading data, and you had even kind of referenced this in the beginning in your introduction, but you don't read data directly from a validator. You read data from a node that is optimized for reading, might have special database indexes, special performance characteristics that just make it better to power an application. And so that's, I guess, what makes it different. It is a part of the blockchain on Solana. The standard RPC node for Solana is a validator on the inside. It's a validator that's actually voting internally.
00:03:59.305 - 00:04:23.865, Speaker B: It doesn't broadcast the votes out to the cluster, but it's voting and it's trying to figure out which fork is the best fork and which data to show the user. And all of that is then wrapped with a query layer on top of it so that users can then come in and make a request to read the data. And so, yeah, it is still a part of the blockchain, but it's in a node that's been specialized for reads.
00:04:24.245 - 00:04:41.891, Speaker A: Yeah. So when an RPC server is going through and saying, okay, there's a new block just occurred, it is receiving shreds from Turbine, it is actually building and validating blocks itself. And then it's just storing it differently or what's going on under the hood.
00:04:42.083 - 00:05:13.149, Speaker B: It's exactly the same. So it's receiving the shreds through Turbine, it is replaying transactions to make sure the hashes are valid and the blocks are valid and then storing it locally in a database, just the same way that a stake node will. And then just that different piece is that when a request for data comes in, the RPC nodes will have special indexes that are not included on the full validators.
00:05:13.317 - 00:05:13.757, Speaker A: Yeah.
00:05:13.821 - 00:05:17.485, Speaker B: So, you know, that's the big difference. Again, it's about read performance.
00:05:17.605 - 00:05:47.685, Speaker A: Yeah. So I want to get out to the systems level view in a second. But sticking on like what is actually happening on that rack in the data center, that's like running on our PC server in this instance. So you mentioned that it's basically a full Solana validator node on the inside, and it's got this additional wrapper around it. Do these systems tend to be heavier and more intensive than a normal Solana validator, or are there functions that are not taking place that normally would be taking up a lot of system performance.
00:05:48.625 - 00:06:41.605, Speaker B: Yes, the RPC nodes have to do all the work that a validator does, plus support the reload. And so the hardware requirements are dramatically larger. We were able for the longest time to run 512 gigabyte RAM servers. And now to be honest, we're getting to the point where a terabyte, if you really do want to support all the indexes and everything else, that yeah, terabyte's kind of normal now, but you don't need that much RAM to run a validator. So CPU requirement is also higher. We need faster CPUs, we need more RAM. And then lately we've gone to running like four separate NVMEs or storage drives inside the servers and where in the old days we could get by with one.
00:06:41.605 - 00:06:55.187, Speaker B: But now just to maximize the input output, the read write inside the server. So down on the bare metal we actually have to have different devices to be able to maximize that throughput.
00:06:55.331 - 00:07:01.695, Speaker A: So how many requests is one of these RPCs actually handling at a given second?
00:07:03.035 - 00:07:23.001, Speaker B: Thousands per second. That will vary dramatically based on this specific RPC request. Some are very heavy, so you couldn't run thousands of those on one single machine. Others are extremely light where it's no problem to run thousands on a single machine.
00:07:23.073 - 00:07:23.545, Speaker A: Right.
00:07:23.665 - 00:07:31.485, Speaker B: And yeah, but there are definitely limits. And there we just scale out by adding multiple servers.
00:07:31.825 - 00:08:13.375, Speaker A: Right, okay. And sort of when we're talking about what makes a call heavy or light, I guess there's probably two different types of data calls primarily that you deal with. One is for live data or like up to the minute state by state data that you know, oh, I'm going to do a transaction on Jupyter and I need to get a bunch of data to be able to form that. And we'll go into how that side works in a minute. And then the other type is probably those sort of like deep historic questions like I want to know everyone who owns, let's say like a degen ape or something along those lines. So like those to the user may seem like pretty similar calls, but I'm guessing they're handled in pretty different ways by the RPC server.
00:08:13.775 - 00:08:26.967, Speaker B: Yeah, yeah. The case of a jupyter swap, let's say there you want up to the millisecond timeliness, basically up to 400 millisecond intervals. So sub second accuracy.
00:08:27.071 - 00:08:27.663, Speaker A: Yeah.
00:08:27.799 - 00:09:08.931, Speaker B: And so that will be reading data directly off of the RPC node that you're talking to. It will be in RAM to be able to give the response as fast as possible. And for something that might be going back and looking for a history of degen apes all the way back to the beginning, that data will be held on an archive. And archive storage is just generally slower by its nature. And so something like that might take a little bit longer. And where your Jupiter swap should be able to run very fast because we're looking for sub seconds data accuracy there.
00:09:09.003 - 00:09:49.325, Speaker A: Yeah, yeah. So let's zoom out from that one unit in Iraq that's you know, running a Slana validator in the inside. It's got a query layer wrapped on top of it. It's got a bunch of extra compute and RAM and storage to be able to, you know, interface with these transaction requests, these data requests very quickly. How does the data actually then get to the RPC server? So I open Soulflare Backpack Phantom. A bunch of data just populates in the wallet. Where is that actually coming from? How in the flow do we get from a UI in a wallet or a request button on Jupiter all the way to a transaction in the blockchain?
00:09:50.785 - 00:10:27.789, Speaker B: Yeah, so it's complex. Yeah, it's definitely complex. But when you open your wallet, your wallet sends a message to the RPC server. Hi, I'm Austin. Please show me my recent transaction history. And then that will hit a special index on the RPC node to get all the signatures for your address. And then that index will include the transaction signatures and then your wallet will make follow up calls for each one of those signatures to get the details right.
00:10:27.789 - 00:10:38.065, Speaker B: So a single action of opening your history in your wallet could trigger probably 25 or 50 separate requests.
00:10:38.225 - 00:11:17.023, Speaker A: Yeah. It's funny when you think about how complicated it is to just be like, oh, when was the last transaction I did? That's actually a pretty complicated thing under the hood. Yeah. So I think a lot of people also think of RPCs, not necessarily in the way we've been talking about them so far, which is on the data layer on sort of answering not even questions, but delivering basic information about, you know, how many tokens do I have in my wallet? What's the, you know, what are the recent transactions I had. Let's talk a little bit about the sending side of things. So people often will have this idea of, oh, I tried to send a transaction, something didn't work. Ah, it's my RPC's fault.
00:11:17.023 - 00:11:21.103, Speaker A: Like what is the actual role of the RPC? When I've decided I want to take.
00:11:21.119 - 00:11:47.657, Speaker B: An action, everything is the RPC fault. Right. Yeah, my Internet went off this morning and I blame the rpc. It's just. Yeah, it's knee jerk. Yeah. So writing a transaction is really just a matter of getting the transaction delivered through to the current leader so that it can enter their transaction queue and be processed.
00:11:47.721 - 00:11:48.251, Speaker A: Yeah.
00:11:48.393 - 00:12:27.439, Speaker B: And we've dealt with some software bugs, to be honest. A lot of the problems that we saw earlier this year were due to implementation issues with quic. And so transactions that were being sent by an RPC node were not able to actually connect and get delivered to the leader. And so the Anza team has done amazing work to go through, identify what those problems were and then continuously issue incremental improvements. So every, every patch that comes out, there's something that's just a little bit better about transaction delivery.
00:12:27.527 - 00:12:28.151, Speaker A: Yeah.
00:12:28.303 - 00:13:32.703, Speaker B: And so even the, what I would call regular or normal, just the typical transaction delivery is flowing much better today than it did say at the beginning of the year. And then there's another pathway that transactions can take and that is actually a high priority pathway to go through a staked validator. And so there, what the RPC node will do is it will receive the transaction from you and it will send a copy to the leader, but then it will also basically send a copy to a friend of a validator friend. So it's just like saying to your buddy, your buddy who's got a contact to say, hey buddy, could you send this message for me? And then they'll deliver it for you. And so that's. A lot of people may have heard of stake weighted Quality of service swqos. We really, really, really need to form the Solana Ad Hoc committee for naming things.
00:13:32.799 - 00:13:33.287, Speaker A: Yes.
00:13:33.391 - 00:13:38.159, Speaker B: And come up with a better name for that because it's a mouthful.
00:13:38.247 - 00:13:38.655, Speaker A: Yes.
00:13:38.735 - 00:14:39.095, Speaker B: And, but the idea is that there's now a privileged route so the, you know, going through a state validator and the emphasis is very much on the quality of service. So just knowing that you're going to send a transaction and it will actually get delivered to the leader with the normal RPC transaction delivery, it can bump into network contention on one of the network ports on the validators. And that's kind of where the problem is. But by using stake weighted quality of service, you can go around that and. Yeah, yeah, so that's really the job of the RPC node and also the RPC provider is to just make sure that your transaction gets delivered to the leader. That doesn't mean it will land. So that's a different question and a different discussion, but from the RPC point of view, it's just delivery.
00:14:39.555 - 00:15:20.231, Speaker A: So I think there's one way you can look at this, which is to say why do we have RPCs involved in transaction sending at all the schedule for the Solana leaders, it's determined in epoch in advance. The IP addresses are obviously known in epoch in advance as well. Why is my wallet not just sending transactions on to the next leader? Like why do we need an RPC service in the middle there? Setting aside the advantages you get from something like stake weighted quality of service, but like pre stake weighted QoS, for most of Solana's existence it did not have that what was necessary about the RPC in that part of the transaction.
00:15:20.383 - 00:15:29.333, Speaker B: Honestly, it was convenience that it was just easy for an app developer to send it to the RPC node. The RPC node already had that logic built in.
00:15:29.509 - 00:15:30.013, Speaker A: Right.
00:15:30.109 - 00:16:24.075, Speaker B: You know, following the leader, knowing who the leader is and sending it, it just made it easier for the front end developers to focus on front end logic and not have to worry about backend logic. And so mostly for convenience, many traders will, will try to save that network hop. So they won't go through an RPC node, they'll try to go directly to the leader that presented issues. Because what happened then is you had so many bots that were all going to the same leader at the same time that it would cause network intention problems. And then that's why stake weighted quality of service came about, to be able to focus on quality delivery and maybe not let the spammers, you know, abuse the leader and the network.
00:16:24.375 - 00:16:31.263, Speaker A: Right, and this is where stake weighted quality of service comes in. And those sort of reserved priority connections you were talking about.
00:16:31.439 - 00:16:48.221, Speaker B: Yep, yeah, exactly. Yeah, yeah. So the stake validator will have the ability to connect to another staked validator to deliver a transaction with better priority than an unstaked node or an anonymous node coming in from a bot.
00:16:48.333 - 00:17:04.565, Speaker A: Yeah, right. And this is, you know, when we talk about priority, this is actually separate from any sort of priority fee or tip you're attaching to the transaction. This is just the path that transaction is taking is of higher priority. That doesn't necessarily make it more likely to be included in a block though, right?
00:17:04.645 - 00:17:38.555, Speaker B: Not at all. It's all about delivery. And if, if the, the leader on Solana was a really hot nightclub in New York and there's a big line outside the nightclub with people waiting to get in, what we do is we can walk you to the front of the line, introduce you to the bouncer, you may have A new best friend with the bouncer. We can get you inside the club. We do not take you to the bar, we do not buy your drink. You have to leave your own tip. And yeah, so it's just purely about delivery.
00:17:38.555 - 00:17:47.645, Speaker B: Everything after that is the quality of the transaction. And that is completely unrelated. A lot of people get confused, but they're completely different things.
00:17:48.825 - 00:18:25.229, Speaker A: Yeah, that is a piece I think people get very confused on is, oh, if I'm sending through this prioritized path, why is the transaction not getting included? Or conversely, if I'm paying a tip, why is the deliverability not guaranteed? So you actually see people who really care about landing transactions. Let's say something where you have professional trader and then arbitrage or liquidation event, they're going to you and they're saying, hey, Brian, I would like to, to, to buy RPC services through a staked validator. That's like kind of what they're looking for. And then they'll be adding tips to that as well.
00:18:25.397 - 00:18:38.705, Speaker B: Yeah, so. And one of the mistakes that they make is not being able to dynamically adjust their priority fees. Yeah, yeah. The local fee markets are working well right now.
00:18:39.075 - 00:18:42.019, Speaker A: And so you're the first person I've heard say that.
00:18:42.107 - 00:19:34.915, Speaker B: Yeah, it's. I mean, it's. There was a very long time where they were not working well, but now what we see is that they are actually working. So during a big event, maybe it is a big liquidation event or a really big market move, the traders, liquidators, anybody else is running an automated process, will dynamically raise their fees and in some cases dramatically, you know, exponentially. And so it does require then the app developers to have a much better understanding of what is the current market or what is the current fee for this, this account that I'm trying to write to. And then they need to be able to dynamically adjust fees as well. So where we've seen trouble is where the teams did not have dynamic fees in place.
00:19:34.915 - 00:20:00.427, Speaker B: And so a big market event would happen prior, the required fee to land a transaction would spike, but their fees were still too low so they wouldn't get in. And so that's been new. And that's because the fees are starting to work. It didn't work before. None of this stuff mattered before, right? Yeah, but now it's working.
00:20:00.621 - 00:20:26.835, Speaker A: Interesting. So the RPC servers are involved in the observability side for local fee markets as well. I know that was something that was initially not in the software package and it was something people were having to do externally. Or build their own tooling for. And then it was brought in. So in a situation like that, what actually has to change for you as an operator when there's like a new core piece of the RPC service that's been added?
00:20:27.335 - 00:21:22.705, Speaker B: Yeah. So the. And there's a particular method, an RPC method, it's called get recent prioritization fees. And that's what an app developer can use in order to get an estimate of the fees for the market that they're interested in or the writable account that they're interested in. So for us, the initial implementation was easy because it just appeared in the Anza software and we ran it and that was great. But then it became obvious quickly though, that that initial implementation was good, but didn't consider other factors that were in place on the network, in particular jito. So what would happen is, imagine a hot trading pair like SOL usdc and the traders are using the JITO software.
00:21:22.705 - 00:21:53.323, Speaker B: When they submit a bundle through jito, they will pay a JITO tip, but they will not pay a priority fee. So the priority fees are zero. And. But then what would happen is when you would make a call to that RPC method to say, okay, what are the fees for this particular account? The fees would actually show a zero because everybody was using JITO to do that particular trade because they were protocol.
00:21:53.379 - 00:21:57.963, Speaker A: Fees, they were non protocol fees, they were fees paid outside of the protocol spec.
00:21:58.059 - 00:22:26.335, Speaker B: Yeah. Yep. And so the original implementation of that method would return the minimum fee required. That's all you'd get is what was the minimum fee? Well, it was zero. Well, that doesn't tell me anything. Right. And so what we did is we submitted a patch to the onslaught implementation where the person who is making the request can say, hey, I actually want to see FEES at the 50th percentile or the 75th percentile or the 25th.
00:22:26.335 - 00:23:01.171, Speaker B: They can pass in a percentile, so now they can get above the minimum and then. And get a much more accurate look on where their fees should be. And so that was a case where we, you had asked Todd, like, how hard it is for us, you know, so we, it was easy in the beginning, but then we realized, oh, wait a minute, the implementation wasn't quite right. It didn't think about these other factors. And then. So for us, then it was the little bit hard work of saying, okay, how would we patch this to make it better? Yeah. And then submit that back to Anza.
00:23:01.171 - 00:23:08.375, Speaker B: They haven't merged it yet. Maybe this will be a nudge to remind them that there's a PR waiting for them.
00:23:11.475 - 00:23:32.977, Speaker A: But in this model, it's not like your servers are calling out to the JITO relayer and asking for the recent tips. Right. So like, walk us through a little bit. Like, in that sort of a situation, how are you sort of looking at the fees then if they're not on chain? Are you saying there's just a few that end up being reflected on chain?
00:23:33.121 - 00:23:52.977, Speaker B: Yeah, yeah. It's rare that 100% of the transactions for a certain pair will go through jito, so there's usually enough traditional transactions with priority fees that if you say I want this at the 50th percentile, you'll get a good answer.
00:23:53.121 - 00:23:53.617, Speaker A: Right.
00:23:53.721 - 00:24:19.035, Speaker B: And for our RPC nodes, we do also bring in some patches from jito. So JITO has bundle simulations and some other special RPC requests that they provide. So we actually bring those into our servers and so our trading clients can use those and then they can query JITO just like they would query the other transactions.
00:24:19.375 - 00:25:10.177, Speaker A: Yeah. So in the model that you guys and most RPC providers run, it's very different than sort of a validator as a service business. Right. Like if someone comes to you or they come to block daemon or someone and they say, hey, I want to run a validator, but like, I don't have the technical chops, I just have a bunch of sol that I want to stake directly. And so can you run a validator for me? You're provisioning one piece of dedicated infrastructure for them and you may have hot backups and all these other types of things going on, but at the end of the day, they have a validator identity and that is the thing that they're attaching tokens to. How does that work on the RPC side? Most people who are users have never even gone in and attempted to change the RPC service their wallet uses. They just go with whatever the default is on that.
00:25:10.177 - 00:25:22.803, Speaker A: So walk me through a little bit of that implementation side of if I'm jupyter and I'm trying to buy RPC services from you versus I'm a trader and I'm trying to buy RPC services. How does that structure work?
00:25:22.899 - 00:25:39.295, Speaker B: Yeah, so many of the larger teams will have their own fleet of servers. They're dedicated, and we spend most of our time working with clients on bespoke installations, optimizing certain indexes and things like that just for their application.
00:25:39.735 - 00:25:44.991, Speaker A: So like, an NFT trader might want the database set up differently completely than the liquid token fund.
00:25:45.063 - 00:26:22.485, Speaker B: Yeah, yeah, exactly. So For a front end application which would be jup AG would be your wallet, something like that, that you as a Solana user would see that implementation is distributed around the globe. So we want to have an RPC server near all the users in three different regions. Asia, North America, Europe. We do not yet have a strong presence and by we I mean the greater we. Solana. Yes, we being Solana, we do not have a great presence in the southern hemisphere yet.
00:26:22.485 - 00:26:56.943, Speaker B: Certainly one of the objectives to carry the chain forward. But the idea for the RPC deployment is we want those front end services to have multi regional global deployments so wherever the user is they can get a server near them. Yeah, for traders it's completely different. So traders might have something set up in Tokyo because they want to DO Centralized exchange versus decentralized exchange ARBs and so they want to be able to go against the Binance servers in Tokyo.
00:26:57.079 - 00:26:57.575, Speaker A: Yep.
00:26:57.655 - 00:27:35.305, Speaker B: And so there what we would do is we would set up dedicated servers for them in Tokyo that are as close as we can get them to AWS to be near Binance. And then similarly another hotspot there would be Amsterdam for more of pure decentralized exchange trading. And so the challenge then is to optimize latency for the trader. What's the shortest path from their trading machine to the RPC to a stake node to the leader? Yeah, so yeah, we're optimizing for different things if it's front end or back.
00:27:35.345 - 00:28:08.367, Speaker A: End, which is hard because like in a traditional, in a traditional like high frequency trading environment you know where the exchange server is. And so you're co locating your execution systems and you still have to figure out oh how am I going to get the trade logic done Fast. But here you may have your RPC server and your staked validator right next to each other, co located next to like the Binance data center but the leader is you know, getting built out in Ontario or something at that particular moment.
00:28:08.551 - 00:28:56.595, Speaker B: Yep, yep, yeah, exactly. So yeah, so there's always a trade off there. Yeah, but we do still offer co location for defi but it's just not quite as clean, you know, like you're suggesting with your question. Not quite as clean as centralized finance but we know where the sweet spots are. And so if it's just purely decentralized trading, trying to run atomic arbs on the different exchanges on Solana, you probably want to be in Europe for that. Amsterdam or Frankfurt would both be very strong locations. But if it's centralized, decentralized, then Tokyo, leaning into Binance being located, there might be a smart strategy.
00:28:56.595 - 00:29:07.791, Speaker B: And so yeah, there's, you're just kind of maybe playing the odds a little bit. You know, where am I probably, where am I probably going to be more successful?
00:29:07.863 - 00:29:51.199, Speaker A: Yeah. So back in like 2021 there were something around 600 nodes running on the network that it peaked probably around 2,400 nodes. And I think we're at probably 1800 today. Those move around, right. They're not always in the same spot. And things like Turbine are basically stake weighted tread distribution to some extent in the topology that it builds out. So how much have you found yourself over the years responding in physically moving your infrastructure as stake concentration changes in the number of nodes on the network change? Like how much micro optimization is actually necessary in a business like this?
00:29:51.287 - 00:30:09.631, Speaker B: It's a great question. We're dealing with that right now. And there's another aspect to that which people doesn't come to top of mind, but it's always there is. Are there any undersea cables currently cut? Yeah, right.
00:30:09.663 - 00:30:10.839, Speaker A: In Tokyo right now there is.
00:30:10.887 - 00:30:54.065, Speaker B: Yeah. Right, right. And so what that means is that in Tokyo the round trip latency for from a server in Tokyo to the Jito relayer in Frankfurt is just under 250 milliseconds round trip. And if we're talking, I mean we talk about 400 millisecond block times. Right. So to send a transaction with that kind of latency between Tokyo and Frankfurt, your throughput is extremely low. So we've actually been moving a bunch of RPCs out of Tokyo and it kills me to do it because we want this to be decentralized, we want equal global coverage.
00:30:54.065 - 00:31:07.013, Speaker B: And the reality of the situation right now is it's just super difficult in Tokyo. And even the validators that are located there do not perform as well as other validators do on the cluster.
00:31:07.149 - 00:31:13.155, Speaker A: Right. And at that point right now, this is just because there's a tera switch cable that's out.
00:31:13.855 - 00:31:25.591, Speaker B: I'm not sure whose cable it is, but. Yeah, but there are disruptions. And so what happens then is the Internet will dynamically route around that. But sometimes it takes the long way.
00:31:25.703 - 00:31:26.355, Speaker A: Right.
00:31:28.775 - 00:31:56.325, Speaker B: And the long way is not always the. Well, it's never a straight line. So. Yeah, interesting. And the, and we've seen that elsewhere too. We also know that in the far reaches of the Southern hemisphere, whether we're talking about South Africa or New Zealand, it's a very similar issue with just global network latency. And that route from New Zealand to South Africa has Just got to be insane.
00:31:56.325 - 00:32:01.449, Speaker B: I've never tested the latency there, but it's got to be pretty big.
00:32:01.537 - 00:32:29.035, Speaker A: Yeah. So when we're talking about latency as being a really big factor here, what percentages start to make something meaningfully different? If you are talking about something like Tokyo or South Africa, are they out of bounds for being viable based on the stake core distribution by 10%, or is it they need to be 50% faster before that would be something that's more viable.
00:32:30.495 - 00:33:04.355, Speaker B: We're seeing the stake move around so fluidly these days that people will move stake for, I don't know, 10 basis points and it doesn't take much. So a validator who's trying to be brave and do the right thing for the cluster by maybe putting their node in South Korea, they're probably struggling and that they're finding a little bit harder to show the same kind of return that a validator in Amsterdam would show.
00:33:04.515 - 00:33:05.051, Speaker A: Interesting.
00:33:05.123 - 00:33:27.523, Speaker B: And so, yeah, with very, very fluid and dynamic stake movement, it doesn't take much. So, yeah, yeah. This is one of those things that I'm most concerned about on Solana that I think we need to deal with. And we can deal with it. I'm still an optimist, but it's like, okay, this is a challenge that we.
00:33:27.539 - 00:33:42.383, Speaker A: Need to take seriously that the benefits of latency reduction are very high. And so there's a strong economic incentive to reduce latency, which could lead to people being more geographically co located.
00:33:42.559 - 00:34:06.315, Speaker B: Right. Which makes the user experience worse. And so if somebody in Tokyo, a user in Tokyo is having to talk to a node in Frankfurt, that's just always going to feel slow. I always hear from our team in Latin America how slow it is down there, just because of the latencies coming up from Brazil and Argentina.
00:34:06.775 - 00:34:53.455, Speaker A: Yeah, it's interesting because on Ethereum, I don't know if it was ever implemented, but there was a proposal for something called correlated slashing, which was designed to basically punish clusters of validators that go offline at the same time. And it's kind of interesting to think about. I'm not a big believer that sticks work in decentralized networks. You really need carrots. But it would be interesting to look and see if there was some proposal at some point to actually have basically reward reductions. Even if you're saying people move stake for 10 basis points, it does not have to be a dramatic effect, but it'd be interesting to look at something where you actually start inscribing a bit of co location penalty, at least on the on the stake side.
00:34:54.235 - 00:35:02.435, Speaker B: Yeah. Solana foundation has done a great job of trying to address that just with their own stake delegation program.
00:35:02.555 - 00:35:03.163, Speaker A: Yeah.
00:35:03.299 - 00:35:26.635, Speaker B: And so they will limit the amount that they'll put into any specific data center. And Marinade is also great about doing that as well. They're very aggressive, actually, on making sure that they. They push stake across as many data centers as possible. And so there. Yeah. The stake pools, delegation programs.
00:35:26.635 - 00:35:41.275, Speaker B: That's one good way to approach the problem. Beyond that. Yeah. It gets tough because. Well, we saw with Hetzner. Right. If you remember a couple break points ago.
00:35:41.575 - 00:35:57.575, Speaker A: I do. This was what. This was before break point 2022 and before the collapse of FTX and about, what, nine and a half percent of the stake just, like, instantly went offline.
00:35:57.695 - 00:36:22.241, Speaker B: Yep, yep. Yeah, yeah. Hetzner had been emailing people for months saying, we do not support crypto on our hardware. And people ignored the emails. And then finally Hetzner followed up on their promise and said, you know, we're going to cut you off. And then they did it. And in that particular case, you could look at that and you actually could blame the operators.
00:36:22.353 - 00:36:22.713, Speaker A: Yes.
00:36:22.769 - 00:36:47.469, Speaker B: And you could say you were warned, you did not take action. But I'm concerned about then other cases, like ovh, they had a fire in a data center and six months later they had a fire in a different data center. But you can't point a finger at a validator in a case like that. Right. Because it's a good provider. They just had the misfortune of having a fire.
00:36:47.617 - 00:36:48.133, Speaker A: Yeah.
00:36:48.229 - 00:36:57.141, Speaker B: And so it feels to me like it would be harsh to say that I'm going to punish a validator because their data center happened to catch fire.
00:36:57.333 - 00:37:25.885, Speaker A: Yeah. I think people, like, also, most people haven't actually ever been to a data center and they're very hard to get into for, I think, very obvious security reasons. But for anyone listening, if you have the opportunity to go, you know, someone who might be able to get you in, it's a fascinating experience to actually go in these places and see how they operate. And you think, oh, fire in a data center. You're like, I think a lot of people think about, like a warehouse with like a bunch of server racks. And like, that is not what these data centers like. It is.
00:37:25.885 - 00:37:35.477, Speaker A: It is densely packed and just you can really see how even a small disruption somewhere can really knock the whole thing offline for a while.
00:37:35.621 - 00:38:03.735, Speaker B: Yeah, yeah, yeah, yeah, yeah. I brought my kids into a data center and just to give them, let them see what it was like, and it was, you know, the impression that they left with. They were. They were still pretty young at the time, but the impression that they were left with is that once you go inside the Internet, it's actually pretty cold because the air conditioning is. They really try to keep those servers cold because they are generating so much heat. Yeah, yeah. The Internet is a cold place.
00:38:04.275 - 00:38:41.849, Speaker A: There's this quote. I forget who it's from, but it's. It's some Russian writer, but it's like, you know, bureaucracy. It's all just papers and forms, and the Internet's the same way. It's all just cold rooms and a lot of cable. And I think this idea of the cloud and these ideas of globally decentralized distributed infrastructure, we forget that it's actually physically there. And you go to a factory that is making something, and there's something very human about being able to see cars coming off of an assembly line or even semiconductors getting manufactured, these big robots flipping stuff around.
00:38:41.849 - 00:38:50.481, Speaker A: Like, you go into a data center and, like, except for the noise and the temperature, you really have no idea what you're looking at.
00:38:50.553 - 00:38:51.953, Speaker B: Right, right.
00:38:52.009 - 00:38:52.689, Speaker A: Very interesting.
00:38:52.777 - 00:38:55.641, Speaker B: Yeah. Yeah. It was a really boring tour, other than being cold.
00:38:55.793 - 00:39:18.651, Speaker A: Yeah. It is both fascinating and completely banal at the same time. So I want to talk a little bit now about some of the work you guys have been doing. It's not directly on the RPC layer, but is really focused on a lot of these things we've been talking about, about decentralization, data accessibility. And this is the old faithful project. So. Yeah.
00:39:18.651 - 00:39:22.371, Speaker A: Can you walk us through a little bit of how this came about and what the project is?
00:39:22.523 - 00:39:32.265, Speaker B: Yeah, yeah. So. And for us, too, as a company, our philosophy is very much to have open standards, open APIs, and open access to data.
00:39:32.395 - 00:39:32.973, Speaker A: Yeah.
00:39:33.109 - 00:40:19.863, Speaker B: And the Solana archive going way back to when Solana Labs was running it. In the beginning, they had their RPC fleet running inside of Google Cloud, and when it came time to store an archive of the transaction history, it made sense that they would just store the Data in Google BigTable because that's where the servers were. And our friend Trent is famous for saying that every bad decision was the right decision at the time. That was the right decision then. But it became the bad decision once the servers moved out of Google Cloud. And then what was left behind was an archive that was trapped behind, basically a paywall with Google.
00:40:20.039 - 00:40:47.443, Speaker A: Yeah. And just for folks who maybe don't know a bunch of history here, Solana famously runs very poorly in the cloud. You pretty Much need to run these things on bare metal instances. But in the early days when they were experimenting and standing up the network, that was not necessarily obvious at the time. And so a bunch of stuff were run in the cloud because that was the best practice of, you know, Web2. And quite frankly, a lot of Web3 at the time, even today is still run in the cloud.
00:40:47.579 - 00:40:57.469, Speaker B: Yeah, yeah. And when I started running my validator, I was running in the cloud. And that worked for a while. Worked until it didn't work anymore. So. Yeah. Yeah.
00:40:57.469 - 00:41:35.355, Speaker B: So then the servers move out into bare metal, but the archive is still in bigtable. And bigtable's, it's a private service offered by a private company. And at the time, Solana Labs had the only copy. And then we raised our hand when they said, hey, would you guys like to have your own copy of this? We said, absolutely. And because, you know, we want to have more than one party responsible. And so we were the first to kind of, you know, have an independent snapshot of Google BigTable archive. And then, of course, other RPC providers went on.
00:41:35.355 - 00:41:45.063, Speaker B: So now there's at least a handful of us that have a copy of the archive that we each independently maintain. So we're not dependent on each other.
00:41:45.179 - 00:41:45.855, Speaker A: Yeah.
00:41:46.015 - 00:42:10.915, Speaker B: And. But the problem then is that for, you know, it's great for us because we've got a copy, the other RPC providers have a copy, Solana has a copy. But you, as an independent researcher, you don't have a copy. And in order for you to get the data, you have to go through a gatekeeper, and that sucks. And we're one of the gatekeepers, and I think that sucks. Right?
00:42:11.015 - 00:42:11.707, Speaker A: Yeah.
00:42:11.891 - 00:42:39.985, Speaker B: You know, that it just. It seemed wrong. So we thought that the. What we need to do is we need to get a copy of the entire archive hosted in a place that is accessible to anybody. And I should pause for a minute too, because I. There's. Whenever we hear phrases in blockchain about data availability, everybody has a different definition of what that means.
00:42:39.985 - 00:43:39.895, Speaker B: And so I do feel that I need to explain when I'm saying data accessibility or data availability, that here I'm talking about the data just merely being available to download. That doesn't mean that it's stored in a database with fast indexing and it's highly performant, and that you can run a query against it. It just means that you have the data available to download. And we thought that that was really super important that the community have a resource like that and that if they chose to spin up their own data center and download the data and make it fast with indexing and all this other cool stuff that they could do that and they wouldn't have to go through a gatekeeper like us. So that was the idea for Old Faithful and the choice was made to put it on filecoin. That doesn't mean that it's the only choice. I know that there's been conversations to do something similar on Arweave.
00:43:39.895 - 00:44:08.775, Speaker B: The file format that we used is actually S3 compatible. So people could download it onto any S3 compatible storage platform and be able to use it and access the data that way. And yeah, so that was the mission. That was Old Faithful. So happy to say that we finished that up earlier this year and it's old-faithful.net if anybody wants to see the website and get a little bit more detail on it.
00:44:09.395 - 00:44:33.755, Speaker A: And so this data, now these archive files that are up there, as you mentioned, this is not sort of in like a Dune dashboard queryable state. So like, you know, folks who are actually excited about this and using it, are they basically going up and they're pulling in the entire archive off of IPFS and filecoin and then they're loading it into their own data management processing system.
00:44:34.535 - 00:45:02.365, Speaker B: Yes, but data management processing system here it means a professional quality environment. It's about 300 terabytes of data, including the indexes. And of course it's always growing, it's never shrinking. And I mean, unless you happen to have 300 terabytes laying around at your place. I know, I don't. It's still not something that we could just easily do as an at home hobbyist.
00:45:02.525 - 00:45:06.385, Speaker A: You of all people, I thought would have 300 terabytes just lying around your house.
00:45:06.685 - 00:46:00.815, Speaker B: Actually some of my co founders do, but not me. No. Yeah, and yeah, so it's still a big hairy database. It can be done in a way though, that the indexes themselves are about 30 terabytes. So hey, if you've got 30 terabytes laying around, you could actually just download the indexes and do some queries locally and then that will give you a pointer to where the data is living on Filecoin. And then so you don't have to download 300 terabytes, you just need to download the 1K that you're looking for. Yeah, and that was a part of, I think the genius and the inspiration that went into the design of this thing is that the indexes are stored separately with pointers back to the car file format.
00:46:00.815 - 00:46:03.303, Speaker B: It's a Special type of archive file.
00:46:03.479 - 00:46:12.303, Speaker A: And so this data, when we're talking about this, this is not the state of Solana. This is effectively what we call the ledger data, correct?
00:46:12.439 - 00:46:47.923, Speaker B: Yeah, it's a transaction history. So it's a transaction. I send you one USDC that gets recorded in a transaction that will deduct one USDC from my account and then add it to your account. But no, it's not showing, like, current account state history, replayability or any of that stuff. We're going there, by the way. We are going in the direction that people will have much easier replay of that history. So you could see an account state at any point in time, but the data by itself doesn't support that.
00:46:47.923 - 00:46:50.643, Speaker B: No. So it's just the history, and the.
00:46:50.659 - 00:47:09.267, Speaker A: Thing that goes into the state is just the state change. Right. So if you're looking at like a full transaction on a block explorer that might say, you sent me from your wallet address to mine this transaction payload, and the effect was one USDC was moved from your ATA to my ata.
00:47:09.331 - 00:47:10.431, Speaker B: Yeah, yeah.
00:47:10.543 - 00:47:31.599, Speaker A: But on the ledger, like on the actual. Sorry, not the ledger, on the state of Solana, on the thing that's on the RAM or the nvme, in the. In the. The accounts database, all you would see there is the one USDC change. And on the ledger, that's where you have that sort of historical record of what went into creating that state change.
00:47:31.647 - 00:47:46.435, Speaker B: Yeah, exactly. Exactly. Yep. The transactions are what mutate the state. So the current state lives on the validator transaction is used to mutate and to give you. You'll have a new state after it's done and.
00:47:46.555 - 00:48:00.667, Speaker A: Yeah, and one of the interesting things with Solana is it is one of the few networks that is built this way. At least it was at the time. It's become more standard now. Where you actually separate out what is the ledger data from what is the state data.
00:48:00.811 - 00:48:18.981, Speaker B: Yes. Yeah, yeah, yeah, yeah. And from a programming point of view, it does, I think, allow a developer to do more with their programming and just to think of state machines that way. And it's a different approach, but it is a very powerful approach for sure.
00:48:19.093 - 00:48:23.805, Speaker A: Right. It's also why a Solana validator does not need 300 terabytes of storage.
00:48:23.925 - 00:48:28.301, Speaker B: Exactly. Yes. Yeah. Because it's only going against the current state.
00:48:28.453 - 00:49:26.105, Speaker A: Yes. So going back to that 300 terabytes of storage, historically, the ledger has been used for exactly the type of things we're talking about. It's been places where there's call data, there's other Things about how a transaction was built, all these types of things. But earlier this year there was a pretty major change to what's being put into ledger data, which is what we all know and love as state compression. So there was a whole debate about whether state compression is actually compression or not by a lot of people who didn't really understand compression or state. But I know that this is obviously a big component that RPC providers and servers like yourself really had to deal with, which was a pretty much new usage for historical state. And it put most of the transaction data processing, offloading onto the RPCs.
00:49:26.105 - 00:49:34.281, Speaker A: So how was that process? How has it been, you know, nine months later? Walk us through compression from the operator side?
00:49:34.393 - 00:49:51.457, Speaker B: Yeah, yeah. And it goes back now what, a couple of years when Metaplex first started with compressed NFTs. And I forgot what paper or what year Jari did his paper with Solana Labs. And Was that like two or three years ago?
00:49:51.561 - 00:49:52.649, Speaker A: I think it was 22.
00:49:52.737 - 00:51:03.017, Speaker B: Yeah. Okay, two. And the Metaplex picked that up to then try the compressed NFT standard and then they led the effort back then it was us, it was Metaplex, us, Genesis, Go, some other providers, Helium, they came along as well and all contributed. So it was definitely a community effort there to try to build DOS API. It's hard. My spicy take on that is the accounts are not really compressed, they just get moved and they get moved to a different place where you have to pay to read it. And there's another conversation there about the economics of that storage, but just talking about the technical aspects, the way that it works is the software that the RPC provider runs has to read through that historical account state and then be able to rebuild or build an index that's running on the side, you know, whether it's in Postgres or some other database software.
00:51:03.017 - 00:51:49.173, Speaker B: And then the user is searching that index to see their compressed NFTs. This also then connects back to Old Faithful and why we thought it was important because in order to have and to create that index of compressed NFTs, you must have the ledger history and you must be able to walk through from the beginning for any tree, any Merkle tree, to be able to walk through the transactions from the beginning. And so yeah, everything is connected. You know, we're the DOS API implementation completely depends on that data accessibility piece that previously was, you know, with gatekeepers. So.
00:51:49.349 - 00:52:02.625, Speaker A: Right. And so have you seen that the gigabytes per day of the ledger has gotten. Has gone up since state proper state compression launched?
00:52:04.565 - 00:52:38.601, Speaker B: Okay, I haven't looked at the data that way, like to say, you know, I mean, and there is a limitation for the number of transactions or cus in a slot anyway, or a block. So, you know, once we hit the point of block saturation, it didn't really grow. It's kind of the same. The interesting thing there is that, and Talking about compressed NFTs is that it was so incredibly cheap to mint a new NFT that we started to see all of these scam and spam NFTs coming into our wallets, right?
00:52:38.633 - 00:52:39.205, Speaker A: Yes.
00:52:39.635 - 00:52:53.855, Speaker B: And so each of those has then contributed to creating accounts into the DOS API index. And so now we might have easily a couple terabytes of data in that index. And most of it is spam.
00:52:55.075 - 00:52:56.635, Speaker A: Yeah, interesting.
00:52:56.755 - 00:53:13.795, Speaker B: And so we definitely have seen an accumulation that way when you make something really cheap, you're going to get more of it. And in this case it was the spams and the scams that ended up taking most of that data along with all the other good stuff too, of course.
00:53:14.095 - 00:54:08.029, Speaker A: But this kind of brings up an interesting question where, you know, people often, when they critique Solana's goal of hitting a million transactions per second over the next two years with Fire Dancer, they're like, oh, think of the state growth. And the answer in the state growth is like, we can probably figure that out. Right on the state side, there's actually a lot of good economic models about hot and cold state and ways you can do this differently. And you know, there are, there are reams of Anatoly threads on state growth and why it's not that big of an issue. But the thing people are not maybe talking about is ledger growth. And the idea that now if you take a step back, if you go to a traditional Web2 system. I had a friend who worked in the observability team at Etsy for a few years and they threw out, I think he said, 99.98%
00:54:08.029 - 00:54:48.955, Speaker A: of their log data. They only saved a little bit of it because that was really the only stuff they needed. And if you look at like the high frequency trading firms, they have legal requirements to keep a ton of data for a number of years. And it is a hundreds of millions of dollars a year operation just to store all that data that's necessary. We don't really have a model now where it would be acceptable for Triton or Helios or someone to basically throw out a bunch of data that says, hey look, we know this stuff is spam, so we're just going to get rid of it do you think we need a new model to address that? If we're actually seeing hundreds of thousands of transactions per second coming through a network like Solana.
00:54:52.095 - 00:55:17.925, Speaker B: I'm going to look at that from two different facets. One facet was just purely storing the transaction ledger history. I think the reality is there is we kind of need that forever. That you do. Even though the validators are constantly validating the account state, we know the account state is correct because they're voting on it. The votes are valid. We've got block ashes to prove it.
00:55:17.925 - 00:55:34.211, Speaker B: That part is good. But just for visibility for people to know, okay, what did happen in the past that we probably always need that full ledger history. It can be stored on more glacial storage formats, so it doesn't have to be fast.
00:55:34.283 - 00:55:34.895, Speaker A: Right?
00:55:36.355 - 00:56:13.809, Speaker B: That part, yeah. My answer there is yeah, we kind of need to keep that. But we could just find more affordable ways and easier ways to store it. When we talk about indexing and I'll use again, I'll go back to the example about compressed NFTs and the scam NFTs and stuff. They're when they pay a fee, they being the scammer, when they pay a fee to write a transaction, they are only paying to write the transaction. They are not paying a single lamport towards the cost of indexing it or making it available to read.
00:56:13.977 - 00:56:14.641, Speaker A: Right.
00:56:14.793 - 00:56:18.365, Speaker B: So what that means is it's a reader pays model.
00:56:18.665 - 00:56:19.353, Speaker A: Yeah.
00:56:19.489 - 00:57:04.555, Speaker B: And there is where you can start to do some exclusions and filtering so that a wallet may make a choice that they want to not show certain scam NFTs that they've, they've been able to prove that these are scams beyond a reasonable doubt and they're just not going to show it to a user. Or a user may opt in to certain things that it wants to, that they want to see and the, or even an application. So if it's a drip house, a great application, you know, they only show their assets. Right. And so for them they would only need to index the drip trees. They don't need to index all the trees.
00:57:04.715 - 00:57:05.415, Speaker A: Right.
00:57:07.955 - 00:57:24.951, Speaker B: But then an exchange like say Tensor, they have a completely different requirement where they actually need to do a lot more, but they would still know that when they're bringing of, you know, a class of assets into their exchange, they at least know which IDs they're listing.
00:57:25.103 - 00:57:25.623, Speaker A: Yeah.
00:57:25.719 - 00:58:06.655, Speaker B: And so there I can easily see that just based on a reader pays model and a reader demand is where you would get some of that natural selection. And then because there is no guarantee that when you write a compressed nft there is no guarantee that it's going to be shown to any user anywhere. And that model actually kind of works. So if anything we probably just need to educate people a little bit more on, you know, this is a reader pays model here and that people will pay to read things that have value to them and then they will filter out the rest.
00:58:06.995 - 00:59:04.311, Speaker A: Yeah, interesting. Have you. I mean, I guess at some point you could even think about and on chain fund for that sort of thing like a. Because there's not a model right now. So with a reader pays model, I guess implicitly someone is your customer who is not necessarily your user. Right. Like in the case of like if I don't know which are which wallets you provide RPC services for, but if you're providing RPC services for Phantom, Phantom's Europe, I may want to view a compressed NFT that is in my wallet, but either Phantom has done filtering on it or Phantom just decided, hey, that we don't want to pay for this and there's no actual model for me as a user to say, actually I'm willing to pay 10 cents a year to make sure this piece of data is always available and I want to look at it.
00:59:04.311 - 00:59:14.635, Speaker A: Right. But the other model is interesting too about a place where a collection could say, hey, I want to make sure that all major RPC services always have my collection available.
00:59:15.215 - 01:00:14.117, Speaker B: Yeah, yeah, exactly. Those are both valid approaches and we're not at that point yet. A couple terabytes of data, honestly it's not that much and to my knowledge everybody is indexing all of the compressed assets and. But if we were to then look down the road 10 years from now to where, you know, if transaction volume increases, the number of compressed assets increases dramatically and we're just storing a whole lot more in those indexes, there will become a point to where it's just no longer economical to store data. Scam NFTs from 10 years ago, there's just not relevant. But yeah, those would both be, I think, legitimate ways to look at it. We're not there yet, but that's probably the direction we're heading.
01:00:14.301 - 01:00:46.705, Speaker A: Interesting. So you guys now run infrastructure for more blockchains than just Solana. I think there's some SUI work that you guys do. There might be some work with some other networks as well. How much of the work of building RPC services for Solana translates to these other networks and how much is this sort of a method of engineering that you're applying but these are fundamentally very disparate problems of, you know, RPC services for Sui versus RPC services for Solana.
01:00:47.005 - 01:01:16.741, Speaker B: They're completely different. Yeah, yeah, they are completely different. So there's. Other than at the load balancer level, you know, to where we have a request coming in, all the requests are going to the same load balancers, but then looking at where they're. They're destined, they'll go to different back ends. And so, yeah, we just treat them all separately. We're a wormhole guardian, so for wormhole, we're running well over 25 different chains and we treat all of those independently.
01:01:16.741 - 01:01:18.505, Speaker B: So. Yeah, yeah.
01:01:18.845 - 01:01:20.587, Speaker A: How many people do you guys have at this point?
01:01:20.661 - 01:01:48.503, Speaker B: We're over 15 right now, globally distributed. And so we do truly offer 24, 7 coverage with people in Latin America, Asia, Europe. I'm the only US person in the company and the two other co founders. Linus is originally from Sweden, now splits his time between Sweden and India. And then Marco from Holland and splits his time between the Netherlands and Portugal.
01:01:48.599 - 01:01:55.271, Speaker A: So it's pretty impressive. You guys can run 20 different networks with 15 people.
01:01:55.343 - 01:01:59.275, Speaker B: Yeah, it's a lot of work. Yeah.
01:02:01.455 - 01:02:05.767, Speaker A: Well, Brian Long, thank you for joining us today on Validated.
01:02:05.871 - 01:02:07.655, Speaker B: Yeah, this was fun. This went fast.

00:00:04.520 - 00:00:06.150, Speaker A: Sriram, welcome to validated.
00:00:06.302 - 00:00:10.558, Speaker B: Hey Austin, great to be here. Really excited to have a conversation.
00:00:10.686 - 00:00:59.184, Speaker A: Yeah, I'm excited for this. This has been a long time coming to set the stage for folks. Today we're going to be talking about restaking, liquid staking networks that come out of the principles of restaking. And this is something that's really come up, I would say, as a main idea in probably the last six months, and it really has centered on the Ethereum community. But there's nothing about restaking as a concept that is protocol specific. But this is seen partially as, I think a solution to some of the problems of actually scaling and launching L2s and roll up networks, especially when we've seen the throughput of many of those be a lot less than folks were hoping. It's also been talked about as a solution to what are now quite low staking yields for ether.
00:00:59.184 - 00:01:40.424, Speaker A: As the native asset staked on the network in a high interest rate environment, it is no longer a capital efficient place to store an asset you may want to put to use. And so restaking has talked about as something that is potentially lower risk than DeFi, with potentially higher yield rewards than you'd get through something like Defi. So I want to really talk about the concepts today, how we got here, what these things look like in the future. And we'll obviously talk a bunch about Eigen layer, which you know, of course, course you are one of the main people behind, but also try and keep this applicable to other solutions and the sort of category as a whole. So I want to start out today just with what may be a bit of a deceptively simple question, which is, what is restaking?
00:01:40.844 - 00:02:54.046, Speaker B: I think the word restaking caught a lot of imagination of the DeFi people, but really I think what I would say is an accurate description of what we're building is generalized programmable staking. What it means is when you're securing a network, like any proof of stake network, what you're doing is you're putting up a bunch of stake money which is controlled by the network, making a promise that you are following some validation logic correctly. That's how a proof of stake network is secured. Now, one of the problems that we were running into my prior background is I was an academic at the University of Washington, Seattle, where I ran the UW blockchain research lab. We had a whole bunch of new consensus protocols, scaling techniques from our lab, but also generally from the academic community. There were hundreds of really good ideas in the space, and pretty much none of them could find the light of the day. Why is because there are maybe five major layer one protocols, and unless you are a core dev in one of them, it's impossible for you to bring a new protocol to any of these systems.
00:02:54.046 - 00:04:02.480, Speaker B: These systems also have strong considerations of backward compatibility. So you can't just take a protocol and then snap it on top of some other chain. That's simply not possible. So all of these together made it impossible for somebody who had all these ideas, even had core and systems built to be able to deploy it anywhere in production. So we invented the mechanism of restaking as a way to empower these innovators who were actually coming up with all these cool mechanisms and protocols, to actually have a place where they can deploy and innovate on new ideas. So, in fact, the core driving value behind our protocol eigen layer is open innovation, which is basically permitting anybody else to come in and build new and interesting services. The existing blockchains provide some room for this, which is if I'm okay with the consensus mechanism, if I don't need access to reprogram a whole distributed system, I only need to program at the level of the virtual machine, then you could of course, go and do it in a blockchain like Ethereum or Solana.
00:04:02.480 - 00:04:52.590, Speaker B: But if I actually wanted to do something at the level of the consensus protocol, at the level of the distributed system natively, then you need to actually start your own proof of stake network. And that's what restaking was intended to solve. It is you can think of it as universal or general programmable staking. When you stake, you make a promise that not only that you're validating one network correctly, but you're validating a set of networks correctly. And if you fail to do the validation of any one of those networks correctly, then you may be liable to lose your stakeholder scope of restaking. Particularly the word restaking came to be because you're staking in the core l one protocol, but also using the same stake across other things. But there's nothing in the core concept of the system to only allow this architecture.
00:04:52.590 - 00:05:05.328, Speaker B: It is generalized programmable staking. You can actually stake a token that is not restaked. You can stake any kind of an asset and make a promise across a set of networks that you're actually validating them correctly.
00:05:05.496 - 00:05:41.400, Speaker A: Yeah, so I'm really curious on this. And sort of one of the themes of the last two years, I would say, on ethereum, is like, oh, maybe cosmos had it right along. And it's funny to hear sort of from the l two and the roll up centric model to what you're talking about with basically programmable derivative networks. It's very similar to the original sort of cosmos vision of a network of networks connected through a series of bridges and interoperability. And this was the whole IBC vision. And something about that never quite worked. Right.
00:05:41.400 - 00:06:26.804, Speaker A: Cosmos never had a breakout moment where it was incredibly successful, even though it sort of had all the building blocks to be successful. I'm curious, as you're thinking about the need for networks with new consensus models. Are these niche networks, in your view, from the academic background you were working on? This isn't like a knock at Cosmos or anything like that. But most of the cosmos specific applications now that have found product market fit are for a pretty niche issue. It's something like, we need a proof of authority network that's also compatible with other types of things and, you know, for issuing carbon credits like Regen network or something like that. It's not like we're building a general purpose cosmos network.
00:06:27.264 - 00:07:22.206, Speaker B: Yeah, I think there are two questions here. I'll try to answer both of them. One question is, how does something like restaking an I layer compared to the cosmos vision? And the second one is, is it specific to, you know, very narrow, application specific things, or, you know, is that the only place where you would actually need the power of, like, programming directly the distributed system? So, to answer the first question, I think there are two values that we hold here at Eigen layer. And what are the values? Is, as I already mentioned, open innovation. We want people to be able to customize and run arbitrary networks. The other value is shared security. Why is shared security important? You can let people innovate all you want, but say, oh, you know, like the cosmos idea was, hey, I give you an SDK now you can go build whatever network that you want.
00:07:22.206 - 00:07:51.768, Speaker B: But when you build that network, you need an asset to stake. You need a group of validators. You need to incentivize them. And they're doing this all for just your own network? Yes. So this massively raises the floor for when you can actually launch a new innovation at the kind of like the full stack. So if you think about, like, these two axes, I would say Ethereum and Eigen layer. So Ethereum and Cosmos started on two opposite trade offs.
00:07:51.768 - 00:08:39.206, Speaker B: Yeah, Cosmos started off on open innovation at all layers of the stack, but no shared security. Ethereum started off with chat security at the DAP layer, but no open innovation at the core layers of the stack. But you have shared security for all the Dapps, then you can see that the L2 is a progressive deepening of the innovation landscape. Layer tools basically said, now I can reprogram the virtual machine, not just the app. Now I can reprogram the virtual machine, but still maintaining shared security. So you can think of ethereums, like core values centered around shared security, and then a progressive deepening of innovation. And Cosmos is starting from, like, open innovation all the way through the stack, and then a progressive deepening of shared security.
00:08:39.206 - 00:09:19.922, Speaker B: So, for example, interchange security and what is called replicated security, mesh security, these are all mechanisms to share security across multiple different networks. Yeah. So it is a convergent evolution. But the main thing that we enable at Eigen layer is shared security and arbitrary open innovation. That is, to me, then, endpoint of this whole game, which means shared security means I have a common security base that I can support, arbitrary number of networks, so that the cost to run a new network is not high, because that's what actually enables many people to come and deploy new networks on top.
00:09:20.098 - 00:10:10.404, Speaker A: Yeah. So I think there's a piece I want to get into here around the theoretical operation versus, like, the practical operation of a lot of these systems. So one of the things we have seen historically is that networks that have higher validator operator costs have a harder time getting adoption. Right? And I work for the Solana Foundation. I know this, right. That, like, it is more expensive to run a Solana validator than it is an Ethereum validator. And that when you look at periods of high volatility, like after the collapse of FTX, for example, the network lost a number of validators because people just made an economic, self interested choice and said, I don't believe this thing will be worth enough money in the future to make it worth running today at a loss.
00:10:10.404 - 00:11:10.616, Speaker A: And you sort of shifted the burden here for when you were talking about a new network from saying, instead of having to pay $3,000 a month to run validators for three different networks, that each cost $1,000 a month, from a computing standpoint, I'm going to put assets up. But there is still a cold start problem in that situation, too, where you now basically have to have yields of a network sufficiently high enough to support the opportunity cost of doing that. I'm curious how you think that plays out from a practical standpoint. Um, if we're basically because the knock on Ethereum, the knock on Solana, let me start. There has always been, the validator requirements are high. The, the knock on Ethereum has always been, it is very expensive to get enough ETH to build a block, even one block per day, one block per month. You need it at the very minimum, 32 ETH.
00:11:10.616 - 00:11:52.274, Speaker A: And you realistically need thousands of ETH to be able to actually be a block builder. And so there's a world where you can say that's more open in the sense of you don't have an ongoing cost to run the thing, but the entry barrier excludes 99% of the population, because most people don't have enough money, let alone enough free money to do it. So I'm a big believer that there is no such thing as perfect architecture. Everything is a series of trade offs. So to end this in a question, what are the series of trade offs that you have intentionally made both on the positive and negative side, in the economic design of how this stuff will actually work when it gets released out and you see people building on the network.
00:11:52.854 - 00:12:54.044, Speaker B: The idea is that several kinds of applications can be supported on the amount of decentralization. So the question is about the amount of decentralization and economic security that is actually needed for different applications. And one of the architect, the core architectures of Eigen layer is that that is not internalized into Eigen layer, that is externalized to the protocol. So a protocol may come in and say, hey, I need like 50 validators, each of who have staked 100 ETH. That's a requirement that a protocol coming in can say, or a protocol can come in and say, I need 10,000 validators, all of which who have at least one ETH, this is completely up to the protocol building on top of Eigen layer to decide. So instead of externalizing this, this is in fact one of my complaints about blockchain architectures, is blockchain architectures have to internalize this. And now if I have to come in and I have a consensus protocol, which actually works on 10,000 nodes, I have no way to build it.
00:12:54.044 - 00:13:34.072, Speaker B: But thats really what Eigen layer is intending to solve is now you come and you as a protocol make the decision, rather than me as Eigen layer trying to make that decision. So you have a group of nodes, you have home stakers on Ethereum, who are running into 5000 to 10,000 nodes. You have professional operators, maybe 50 to 100, who are highly professionalized. Depending on the use case, you can lean in on one side or the other. You could even exclude, for example, all the whales and the top operators, and only use home stakers and distributed operators. Using a subjective mechanism of your own choosing, totally. Eigenlight is a double opt in marketplace.
00:13:34.072 - 00:14:11.436, Speaker B: So, you know, as a staker have to opt in, the service also has to agree to you opting in. So that basically means you can kind of like slice and dice the trade off not at the level of eigen layer, but at the levels on top. So that's a core design principle that we adopted to solve the problem that you're mentioning, which is there is always a trade off. And instead of us making the trade offs that the system's building on top, they can make these trade offs because they're the ones who have to actually deal with the complexity of, oh, I can't deal with 10,000 validators, or it's too expensive, or it's too little externalized to protocol spelling under.
00:14:11.620 - 00:14:45.060, Speaker A: Yeah, I guess, like this is where I think it's a very interesting concept. And for me, there's a few pieces of it that I think are going to cause more problems, maybe than some of the ways you're talking about it, which is when we talk about like a few components, one is the sustainability of these networks. I think over the long term is a bit of an open ended question. Right. One of the biggest knocks coming from the Ethereum community is on inflationary rewards as being something that is not good.
00:14:45.172 - 00:15:27.764, Speaker B: So let me just go back to first principles and see why the trade off cuts correctly here. If you look at the cost of the basic knock that you mentioned, which is Ethereum guys talking about, hey, how about the inflation cost? So I call this the cost of capital. Yeah. So if you want $5 billion of economic security and you have to pay a 10% APR, you're talking about basically paying off $500 million worth every year. Yes, this is exactly what Eigen Layer is designed to solve. The problem that is designed to solve is there is two fundamental cost to run a distributed network today in a proof of stake manner. One is the cost of capital, and the other is the operational cost.
00:15:27.764 - 00:16:22.226, Speaker B: The cost of capital is basically amortized across many, many, many networks. So that's the way we solve that with Eigen layer. So imagine there are 100 networks, each of which can sustain $100 million of staking with their own free volume. Yep. Now, if you aggregate all of these hundred networks into a common staked pool of $10 billion, which is the current stake on Eigen layer, for example, you can actually get, you know, each of them to attack any one network out of these 100 networks, you need $10 billion, rather than needing $100 million to go and attack any one network. So you're getting the power of pooling the security across all these systems so you don't have to pay for $10 billion by yourself. You're paying across all these networks to gather enough to sustain this large restrict pool, but you're gaining the benefit of shared security.
00:16:22.226 - 00:16:51.620, Speaker B: So that's number one. So the cost of capital is not specific to your system because you're sharing it. In fact, this, I think, is the core principle of why Ethereum or Solana themselves work. Because if you question this premise, Ethereum or Solana should not work. Why? Because it's just a bunch of apps which are sharing a common pool of security, and they're paying up enough fees to sustain this pool of security. And we've seen Ethereum adopt, have enough fee volume to actually sustain it. And over time, Solana might.
00:16:51.620 - 00:16:59.984, Speaker B: That's really the core principle on which proof of stake protocols already operate. Eigen layer just makes it much more flexible and programmable.
00:17:00.664 - 00:17:32.846, Speaker A: Yeah, except you're moving to a different state. Right. And I think this is the piece that I think, for me, people always talk about, oh, like a five out of seven multisig means that you have so much resistance to someone being compromised. And the flip side of that is a five out of seven multisig is also a three out of seven brick. Right. If you can destroy three of the keys, you've now effectively bricked all the money. And so when you're talking about these models, where it's like, oh, you have $10 billion of economic security across all these protocols.
00:17:32.846 - 00:18:31.088, Speaker A: You can flip it the other way, too, though, which is that one of the slashing event on one of those networks can now destroy security on other networks. So you are building a much more interdependent both on the positive side and the downside. And I think that's the piece that, like, for me and for a few others, like, I put out just a call on Twitter that said, like, what are your dreams and fears for restaking? Not eigen layer specific, but just in general. And most of the comments were actually concerned around creating interdependent economic systems that a network doesn't actually have sovereignty over. And I guess the best analogy here is, like, in the Ethereum space, there's been a very intentional and careful decision made to say that l two s are designed to fail, and that doesn't mean that we want l two s to fail. But the failure of an l two is not existential to the state, state of Ethereum. And there's all sorts of, I think, quite bad decisions that were made because of that.
00:18:31.088 - 00:18:58.868, Speaker A: Like Ethereum is incredibly expensive, and most people don't trust l two s the same way they trust the l one today. But that is like an architectural decision made to preserve the integrity of the Ethereum l one. I'm curious how you think about that sort of risk. Not necessarily back to that staked ether, although of course that could be slashed. But of those other networks that are now on a shared security, they're basically on shared fractional security, I think is probably a fair statement.
00:18:59.036 - 00:19:07.984, Speaker B: But that's exactly the same security that apps on Solana are on or apps on Ethereum are on. Yes. Okay, so just, I agree with you there. Jump to a common point.
00:19:09.604 - 00:19:16.540, Speaker A: We're creating more interdependency and more layers as opposed to like if you're building an app on Ethereum, it is secure.
00:19:16.612 - 00:20:09.874, Speaker B: So why is this interesting? Is like, I think you asked a question earlier about Cosmos and whether it's only suitable for niche networks. So without understanding what is the unlock, it is not possible to answer whether something is useful or not and whether it's worth taking certain trade offs. If you look at web development back in 1995, the way you develop an application on the web is you have to build your own server, you have to build your own applications on top, identity, payments, databases, and then you build whatever end user app that you want. You want to ship books, that's a book website. But you need to do all of these other things in order to build your own bookstore in 2024. That's absolutely not how you build these systems. What you would do is you would go to AWS cloud.
00:20:09.874 - 00:20:59.550, Speaker B: Then you would go and use a bunch of SaaS solutions software as a service solutions. These SaaS solutions sit and run on the cloud, and they are built by highly specialized infrastructure builders. Whether that is a snowflake, whether thats a MongoDB, whether that is oauth, whether that is stripe, very specialized deep customizable protocols focusing on one specific thing, just payments or social auth or databases, whether thats SQL or NoSQL or whatever other things. And then applications, end user applications build on top. That's the architecture of the cloud. That's exactly the architecture that Eigen layer is intending to create in crypto. What do we mean by that? We have a common source.
00:20:59.550 - 00:21:56.368, Speaker B: So the dividing line between cloud and crypto is decentralized trust. Without decentralized trust, you cannot, there's no point, just go back to the cloud. So if you have a common source of decentralized trust, on top of which people can build highly customized, powerful solutions like secure multi party computation, fully homomorphic encryption, AI core processors, proof of identity, proof of location, SQL databases, all kinds of interesting things. Then end user applications can be built concatenating these services. That's really the goal or vision of the types of systems that we're building. You know, the question is not about whether when you were asking earlier, these cosmos applications only succeeded in niche use cases. What was happening was for each application I had to derive a lot of customization through the chain.
00:21:56.368 - 00:22:41.440, Speaker B: So for example, Osmosis, which is a Dex, had to figure out how to do threshold encryption because they wanted to prevent mev in the mempool. Now if you think about it, preventing mev in the mempool is very useful for osmosis as a DeX, but it's not unique to osmosis. Lots of applications could use a service like threshold encrypted mempools in the Eigen layer worldview. What happens is threshold encrypted mempools becomes a service built on Eigen layer that you can just attach to as an application, some other application, like. So that is the vision of what we are building towards. And it's highly customizable, just like the software as a service is highly customizable. Specialized systems, but they can all interoperate.
00:22:41.440 - 00:23:18.332, Speaker B: A typical web application incorporates like 20 SaaS services in the backend. Yeah, that's exactly the same thing that we envision is consumer applications will come and incorporate a whole bunch of, we call them avss, actively validated services. This is the equivalent in our view of the software as a service evolution. People will build highly specialized systems that take advantage of the whole power of the distributed system. Exactly what you need to build a threshold mempool. Exactly what you need to build fully homomorphic encryption or an AI co processor or a SQL database or any of these things that we really need to unlock crypto. That's what you get.
00:23:18.332 - 00:23:25.262, Speaker B: What is the benefit related to what is the cost? I'm happy to go back to the risks and costs, but this was a question that was not answered earlier.
00:23:25.428 - 00:24:03.848, Speaker A: Yeah, totally. And so I think the piece that's interesting for me is we have a few groups that are doing this already. Aztec is doing this, Rose is doing osmosis is doing this as well. The problem I think this is baked into the worldview of Avss that you're talking about is an assumption that we can trustlessly bridge state between networks and basically hand off logical processes. Units back and forth. We still seem to be very far away from a world where you can actually truly trust a bridge. So how does that part get solved.
00:24:03.896 - 00:24:52.496, Speaker B: To sort of unlock? That's why Eigen layer is not, is a different viewpoint from the cosmos worldview, which is distinct sovereign networks which are bridging across each other. If you had ten functionalities on ten distinct trust zones, when you compose across these ten functionalities, you're as good as the worst of the trust of all those systems. That's not how Eigen layer works. I think the way Eigen layer works is Ethereum is the common source of trust for all of these systems. What do I mean by that? Each of these systems may have subsets of stake, but essentially what happens is, when you're interoperating between all of them, they are settling back to Ethereum. In some sense, Eigen layer is just a turbocharging of the L2 era of Ethereum. Ethereum is the source and settlement layer for all of these avss.
00:24:52.496 - 00:25:10.392, Speaker B: So each of the AV's runs some kind of distributed computation, and then they. They go back to Ethereum, and they settle on Ethereum, and they interoperate on Ethereum. So what this does is everybody first has a common source of ledger that they're actually reading from. They're not sovereign trust zones just running on their own.
00:25:10.488 - 00:25:10.816, Speaker A: Right?
00:25:10.880 - 00:26:05.420, Speaker B: And Eigen layer provides very sophisticated crypto economic accounting, which is. I know. So, so then what is the difference between, like, let's say, an optimistic or a Zk roll up and a system built on Eigen layer is. It is an optimistic roll up with immediate crypto economic guarantee. So what. What do I mean by that? You basically have settlement back on Ethereum, and then you can actually, uh, you know, know, after the challenge period, whether it's correct or not, but within the challenge period, I already have a large amount of economic security backing it, a measurable, known amount of economic security backing it, so I can move value up to the economic security backing it within the fraud proof period, beyond the fraud proof period, I can move infinite value. So this is how we solve the problem that you're laying on, which is absolutely a major problem in the cosmos worldview, because Cosmos started as this idea of community computers, which is, hey, my community.
00:26:05.420 - 00:26:35.626, Speaker B: I have my own blockchain, but I look around, I don't see any community computer other than maybe a region network or something, which is actually maybe a distinct community. Other than that, it's mostly functionality computers. Yes. Oh, mine is a Dex. Mine is like a perp and so on. And now most users can't just use one of those things, so they're using a bunch of these things. Because they're using a bunch of these things, they actually take the composition risk through these bridges, through the different sovereign trust zones.
00:26:35.626 - 00:27:19.400, Speaker B: This is what eigenlit is designed to avoid, is you have a common source of ledger. Every different service that is coming up settles back to Ethereum, and then in Ethereum everything is reconciled and interoperates. So that's the view, these zones. So you can think of all of these as some kind of like, you know, side chains or crypto economic side chains or crypto economic roll ups on top of Ethereum. So because Ethereum brings you the common view, you can actually, and all of these systems will fork. If Ethereum forks, they're all relativized to Ethereum itself. So you get pretty similar trust assumption as L2s, rather than the same trust assumptions as sovereign trust zones.
00:27:19.400 - 00:27:20.000, Speaker B: Yeah.
00:27:20.072 - 00:27:42.634, Speaker A: So tons of follow up questions I want to get into, just for the benefit of audience. I think we should spend 30 seconds to a minute on teasing out the difference between the execution layer, the settlement layer, and the data availability layer within the system you guys have built. Because I think a lot of times settlement and DA layer get conflated in crypto Twitter speak.
00:27:43.694 - 00:28:25.912, Speaker B: Yeah, so Eigen layer itself doesn't have. Eigen layer is just a series of smart contracts. On Ethereum there is no, when people are building on top of eigen layer, they can choose what valve to settle, where to use, data availability, what other kinds of. And I think this, this time variant like execution zone, settlement layer, data availability layer is not something that I think characterizes the set of things one wants to do correctly. There is a lot more things that are actually happening. For example, I want to do a two factor authentication by a distributed network. Is this execution? Is this data, is this none of these things.
00:28:25.912 - 00:29:17.614, Speaker B: It's basically the existing blockchains are limited to do a very small number of things, endogenous verification of self consistent statements. That's all a blockchain can do. But to actually have a system that is usable, you need lot more things. And this is fundamental to the Eigen layer worldview is the set of things that are needed to actually make blockchains broadly viable, are not offered by any existing blockchain. That's a core thesis. We need a lot of different kinds of services with decentralized trust to be built in order to actually have these systems to serve the set of use cases that we imagine that they will serve. So whether that is bridges, whether that is oracles, whether that is more data availability, whether that is more long term data storage, whether that is AI inference, whether that is fully homomorphic encryption blockchains dont have this.
00:29:17.614 - 00:29:59.204, Speaker B: Thats a core view. So to answer your question on where is the data availability layer, what is the settlement layer? When you're building each of these systems, you do have nuanced trust assumptions. And this is why building an AV's on top of Eigen layer is not something we're encouraging every end user developer to do. This is why the mental model of this is very similar to SaaS, where to do it. Really hardcore SaaS service, you need to understand the cloud architecture in and out. You're really designing how all the nodes work, how you're doing replication, what is your redundancy system. All of these things need to be understood by people building these AVss.
00:29:59.204 - 00:30:35.290, Speaker B: The people consuming these AVss need to just have a simple interface to understand and interoperate across these AVss. So that's the, that's the view there in terms of these different layers in, in our worldview. Because everything is settled back on Ethereum. Ethereum is the settlement layer, because Eigen layer itself is just a contract on Ethereum, right? So there is nothing else. So any other system which is building on Eigen layer is also building on just the ethereum's final ledger. So in that sense, everything is settled on Ethereum. But things like data availability on Ethereum.
00:30:35.290 - 00:30:54.908, Speaker B: The data availability on Ethereum is not enough. Like it's only in tens of kilobytes per second. Eigen layer itself has a service called Eigen da, which is optional to use, but it's useful to scale the data availability throughput to ten megabytes per second. That's 80 megabits per second. Because I think people confuse the bits and bytes in this space a lot.
00:30:54.996 - 00:31:30.976, Speaker A: They do, yes. So I'm curious though, because the sort of vision you're outlining, where there's many small subservices, they all are able to interact via one central ledger system. I think that's a system a lot of people have talked about before, and a lot of different visions. I think if you talk to the optimism folks, they would say, well, that's optimism, right? You can have multiple op stacks, and they can do different things, and they can all inter communicate through the optimism system. I think if you talk to folks on Solana, they say, that's just Solana. We actually don't need layers to do this. We can do this through committees and subsets and, you know, all these types of vendor network.
00:31:31.000 - 00:31:46.924, Speaker B: The thing that I think, like both of these things miss the bullet visions miss is the only thing that can be verified on Solana or on an optimism roll up is execution that can be verified by the layer one. Yeah, and there are lots of things that are not executions. Like think of a threshold encrypted mempool.
00:31:47.044 - 00:31:47.324, Speaker A: Right?
00:31:47.364 - 00:32:11.870, Speaker B: Okay, let's to be very concrete, okay, I want to, I want a group of nodes which order transactions, but when they are encrypted and then they share the decryption key only after the thing is done. And then. So I want to build this. What do I need to do if I want to build it on optimism or on Solana? I have to start a new group of nodes. I have to get them to stake. I have to write slashing conditions. This is exactly what eigenvector is designed to solve.
00:32:11.870 - 00:32:24.954, Speaker B: So I think the scope of programmability people have in mind when. Because a blockchain only verifies endogenous, self consistent claims. Yes, and there are lots of things which are not endogenous, self consistent claims. And that's what Eigen layer is designed to solve.
00:32:25.734 - 00:33:12.686, Speaker A: Yeah. So let's talk a little bit about that common ledger layer, because there is currently no real plan in the Ethereum space to make that ledger cheaper to access. Right? Like a lot of the additional work that's being done now is on blob data space. And that, that's ephemeral. That is not designed for settlement, that is designed more for DA. How does it get to a point where something like your model of a two factor authentication code sent via decentralized blockchain network, how does that become affordable, for lack of a better term, like these modules, I think we all agree that like very interesting, useful modules, how does the economics of that turn into a place where a network can actually afford to use these? If it's settling through Ethereum, yeah, that's.
00:33:12.710 - 00:33:48.754, Speaker B: Where I think your question of where is the data availability, where is the settlement matters. All these services write their state claims back onto Ethereum because Eigen layer is a series of contracts on Ethereum. Writing state claims, one of the cheapest things to do. It's not an expensive thing at all. The main cost is incurred by writing data back to Ethereum. That's why Ethereum has a data scaling roadmap. I contest whether it is enough, and that's why we are building eigenvalue our goal is to scale it to Ethereum's.
00:33:48.754 - 00:33:52.374, Speaker B: With down sharing, it'll scale to 1.3 megabytes per second.
00:33:52.494 - 00:33:53.714, Speaker A: Still not much.
00:33:54.214 - 00:34:18.644, Speaker B: Not much. And our goal is we'll be in gigabytes per second by the same time. Interesting. So that's Eigenda is as close as you can get to Ethereum trust while not writing to Ethereum. So that's a clear. So you're on the right set of questions here in the sense that it is important to have scalable data. It is not important to have scalable set.
00:34:18.644 - 00:34:33.864, Speaker B: The settlement is already scalable because you're only writing settlement claims. So it is important to have scalable data because that's the one that actually scales with the amount of transactions that you do. Settlement is just one claim about all these different things that you're doing. Yeah.
00:34:33.904 - 00:34:40.880, Speaker A: Although you do trade off a lot of latency for lower settlement costs. Right? I mean, that's right, that's right.
00:34:40.912 - 00:35:16.174, Speaker B: But that's exactly what the crypto economics does, is lets you give instant confirmation with a certain amount of economic guarantee. Imagine there's 10 billion staked on Eigen layer. Now I can give you a guarantee which is that like, if my claim is wrong, I'll get slashed on Ethereum and lose 10 billion. Yeah, that's good enough for pretty much a lot of applications. So that's. This notion of refined confirmation latencies for different quality of service at different latencies is an inherent thing that Ethereum was built for. Ethereum has the longest chain, which if you just look at a block that immediately gives you a certain amount of confirmation.
00:35:16.174 - 00:35:54.078, Speaker B: It's not finalized. There's another layer of finalization. But what Eigen layer does is add even more layers on top. I can run something like a Solana consensus protocol on top of Eigen layer and get you like a 500 millisecond confirmation at $10 billion economic fidelity, or maybe 50 billion when if we do get there, and then that eventually settles to Ethereum and you get the full Ethereum security at that point. So you have this like multilevel multiple levels of like, confirmation, multiple levels of latency at different timescales. Different timescales. You can have different confirmation fidelity at different latencies.
00:35:54.078 - 00:36:06.166, Speaker B: And the main goal, one of the main goals of Eigen layer is to improve the economic security of instant confirmation, which is absolutely one of the problems that we're intending to solve. Yeah.
00:36:06.350 - 00:36:18.034, Speaker A: So do you see Eigen layer as an Ethereum project? Because in your talking about this, there's nothing that says this couldn't also be deployed on Solana or bitcoin or any other network.
00:36:18.754 - 00:36:54.524, Speaker B: Yeah, I mean, the core idea is it is a mechanism to extend staking to all kinds of systems. And so therefore there is nothing fundamental about the idea itself. That is Ethereum only eigen layers. Goal itself is as a protocol. As a company, even our goal is to build the coordination engine for innovation. So that's the goal. But one of the reasons we chose Ethereum and continue to be an Ethereum centric project is coordination requires convergence.
00:36:54.524 - 00:37:53.180, Speaker B: Imagine I'm building a coordination system and I'm on a different coordination system and you're on a different coordination system. It becomes then we are not coordinating. To us, coordination requires convergence. And we looked at where is the largest source of convergence? And on Ethereum also where is the largest system which is actually aligned to these values, the systems for coordination systems for open permissionless innovation at all the different layers, we felt bitcoins, for example, not aligned with these principles. Bitcoins like digital gold, one and done. We are. And Ethereum's cultural ethos is very much rooted in how do you build systems of coordination? How do you build permissionless innovation? And if you go back to 2019, when Ethereum committed to the L2 landscape, many people thought it's the craziest idea to say that, hey, execution is the only thing that matters.
00:37:53.180 - 00:38:34.052, Speaker B: And Ethereum is committing to this idea that execution is going to be outsourced. What a ridiculous. Even I thought like that, even though I'm a innovation, Maxi. But it is this commitment to principles over expediency that we like in Ethereum. And that's why we're building on Ethereum, and particularly the particular principle of permissionless innovation. Not only that, because there are projects that say, hey, we know what's best and we are going to build it. And the problem with that is there's only one thing that can be, even if you take all the communities input in building that feature, there's only one feature that can be shipped.
00:38:34.052 - 00:38:56.424, Speaker B: There's only one consensus protocol. You cannot have 100 consensus protocols in a given blockchain. So this ethos we saw already reflected in Ethereum. So part of the reason we doubled down, but I would say the most important reason is coordination requires convergence. And we're just estimating where is convergence happening.
00:38:56.584 - 00:39:16.374, Speaker A: Do you think there's a future where modules, for lack of a better term, on Eigen, can be used on other l two s and roll up solutions? Because I think there is a little bit, yeah, because there is a little bit of a, like, we need a new standard, and now we have 13 standards. That famous XKCD comic?
00:39:16.994 - 00:39:34.194, Speaker B: Yeah. So Eigen layer is not a roll up. It is not competing with the roll ups. In fact, it's completely complementary to all the existing roll ups. And that's because, you know, we're not building an execution environment. Like, you know, arbitram, optimism, polygon. Like, we're not at all in the execution environment.
00:39:34.274 - 00:39:38.464, Speaker A: Game supplying decently might be right.
00:39:39.124 - 00:40:10.974, Speaker B: No, but they're using one of these other systems. Either they're using a polygon, they're using an optimism, or they're building their own. Like, I'm building a move virtual machine, or somebody wants to build a c level virtual machine from this podcast. Please do reach out to us. But the core idea being that we are not building those systems, and therefore, for example, the data availability is completely complementary to the systems that these other, like, rollups have built. So they can leverage us for data availability. They can leverage us for instant confirmation on their roll ups.
00:40:10.974 - 00:40:26.406, Speaker B: They can leverage us. So Eigen layer is just like our worldview, which I stated with the SaaS. Thing is, people hyper specialize in what they produce. And Eigen layer, hyper specializes in supplying decentralized trust. We don't do any of the other things.
00:40:26.550 - 00:41:06.794, Speaker A: So I want to dig in a little bit on, like, how that works mechanically. Right? Like in web two. I wouldn't say web two invented the API, but, like, web two standardized around the API as being that that program interface. So if I am running a web two, you know, boring e commerce site, and I want to process credit cards, I just pull in the stripe API. It's authenticated. The data is sort of as handled by them. What's that model for? You know, if I'm an application or I'm building a network, and I want to say, hey, I want to pull in this, you know, encrypted mempool system, walk me through, like, technically, mechanically, how does that actually work?
00:41:06.954 - 00:41:40.328, Speaker B: This is a superb question. Is something that, you know, I think about a lot. We don't have yet a standard for this, because we are trying to understand what set of solutions can even be built before you know, what to standardize on. But the, the way all these services work, so. But I can walk you through, like, how one would build and deploy service like this today. Suppose you want to build an encrypted mempool or a secret sharing system where you want to distribute a secret on many nodes. What you would do is you come in and build two things on Eigen layer.
00:41:40.328 - 00:42:13.174, Speaker B: One is a contract we call an AV's contract. An AV's contract sits on Ethereum and talks to the Eigen layer contracts. This contract does three things. Registration, which means admission control, who can stick into your system, what set of node operators are you going to allow, and so on. Basically, registration number two is payments, okay? You know, they, they operate into your system. You need to make sure that they're getting paid. You know, it can be over a kind of a slow time scale, weeks rather than every block, I need to be dripping payments.
00:42:13.174 - 00:43:19.492, Speaker B: The third one is so there is registration, there's payments, and then there is slashing. These are the three things that sit on an Ethereum smart contract. These are lightweight, registration happens one time, payments happen on a slow time scale, weeks, slashing hopefully never happens. These are the three things that sit on Ethereum. What is your actual software? Is you ship a container, a node software that any operator that is opting in has to download and run outside of the Ethereum blockchain and Ethereum smart contracts. So now you can download and run like it can be written in rust, it can be written in whatever it may require specialized hardware to run like it may want a GPU, it may want a trusted execution environment on an AMD or arm or intel. So you can specify all of these conditions in your opt in conditions and say that people only having these things can opt in and they opt in and they run this stuff off chain.
00:43:19.492 - 00:43:30.024, Speaker B: And what happens usually is. So when you're designing this AV's actively validated service, right now, this podcast is called validated. So actively validated service fits.
00:43:30.524 - 00:43:33.384, Speaker A: We are the original actively validated service.
00:43:35.164 - 00:44:22.104, Speaker B: Very active. Also here the actively validated services are now the person building the actively validated service has to think about, oh, what is the at? What freak is the service? Havoc. So it's not a chain. So that's the first thing. An actively valid service need not be a chain, right? It is just a thing that it is a service that has a certain input and output, and this output needs to have certain trust or fidelity that this output was done correctly. Whether that is coming from the assumption of decentralization and collusion resistance, it could be coming from economic security, it could be coming from some kind of social slash ability. But whatever the thing is you need.
00:44:22.104 - 00:44:56.792, Speaker B: But each person building a service needs to think about these things for themselves. So when you build a service, you think about these things. You have a model where you're seeing that. For example, if you're building a chain. The chain may report to Ethereum at some periodic frequency, maybe every hour or whatever. But if you're building a service which is for consumption, like you said, among Ethereum, l one and all the L2s, or maybe even all through the crypto world. So there is a model in eigen layer where the root of trust is sitting in Ethereum.
00:44:56.792 - 00:45:25.504, Speaker B: But the usability of these services doesn't have to be restricted to only Ethereum or its layer tools. It could actually be bridged and used all across like other systems. So, but inside. So when you think about that model, I need to have a reporting mechanism where I report the state of my system. Oh, I did these 3000 AI inference things, and these are the results of these, or the hash of the results of these AI inference things. And I'm committing that back to Ethereum. Right.
00:45:25.504 - 00:46:49.798, Speaker B: Because that's what I need to open up to know that, yeah, I know this service ran, and then this is the results, and that is the current model. And we're building some unification model across these different kinds of avss that report back to Ethereum, a service called Eigensert, which is basically just a mechanism to aggregate all of these certifications so that if there are 500 services and each of them want to write an update to Ethereum, as you guys say here, Ethereum doesn't have enough block space for that. So we'll aggregate all of those commitments into a single commitment that you can then write back to Ethereum. That's the way that the whole AV's ecosystem works. And this is where I think your question is really, really interesting. And I think over the next two years, you're looking to actually solve it, because our view is these kinds of AVss are actually what you would call as a verified or insured API calls. When I'm making an API call, I need to have two things that, oh, this is the output of the API call, but also, what is the trust claim backing it? Is it a certain amount of economics? Is it an assumption on some kind of decentralized trust? Because when you're composing these API calls across many different systems, you need to understand transparently how trust is flowing through these systems.
00:46:49.798 - 00:47:33.022, Speaker B: Because at the end, the composition of these API claims is only as good as the worst, the weakest link among these different systems. We think a lot about being the zone of decentralized trust. How do you actually calibrate? And we are coming up with standards on economic safety. Imagine I'm making a call, and this call has like $100 million of economic safety backing it, which means if this call goes wrong, you will be able to slash and uniquely redistribute $100 million to the affected parties. So we call these insured API calls. And so we're thinking a lot exactly about this question, but I think it is going to be super important for us to understand and calibrate this in the coming couple of years.
00:47:33.158 - 00:48:32.634, Speaker A: Yeah, I kind of appreciate the way you've kind of walked through the problem space. One of the things I wanted to get your views on are sort of the concept of replayability, because with obviously like take any blockchain ledger, there is an open source software system out there that anyone can download and verify the ledger from Genesis and replay the system. And that is, you know, even on a network like Solana, which is more of a weak subjectivity network where you don't actually need to go back to Genesis to validate the next block, there is still the ability to go back to Genesis and validate all the blocks. When I'm dealing with something like stripe, there's no assumption of that at all. And there's an assumption that it's a very centralized provider that is a dictator of approved decline on this credit card with the AV's is how do you think about the interplay between replayability and decentralization and the accuracy of that outcome?
00:48:34.414 - 00:49:18.134, Speaker B: Great question. So firstly, what requires infinite replayability and what doesn't is something that we need to be very careful and considerate about. And I actually am on the opposite side of this debate relative to a lot of, let's say, ethereum folks, in the sense that imagine I'm playing a game and there is a token system on the blockchain which allocates some amount of token to the winners of the game. It's very important that only the winners of the game get those tokens. It's important for me to replay the history, to know this guy won the game and therefore got the tokens.
00:49:18.304 - 00:49:20.254, Speaker A: But you don't necessarily need the game.
00:49:20.714 - 00:49:49.028, Speaker B: Yeah, exactly. So what needs to be evanescent, like what's, what claims need to be replayable, you know, is computer architecture. It is not like, you know, ideology. And, you know, our view is some claims will never need to be replayed beyond. They need to be replayed through the challenge period. Because I need to make sure that like somebody is not claiming to win the game and they actually. Unlike the stripe scenario where they can make arbitrary claims, that's the piece I.
00:49:49.036 - 00:50:22.354, Speaker A: Want to dig in a little bit. Because if we're dealing with now, as you mentioned, very specialized compute, very specialized networks, maybe this is something like fhe, I sort of, as the recipient, you know, I throw my data up to a black box. The data comes back down with an answer. You know, in, in a centralized system, I can say there's someone who's metaphorical neck, I can choke if there's a problem, which is my lawyer can go after their company for a lot of money that doesn't exist in decentralized systems. So. And, you know, normally we think about this as well. We have the blockchain.
00:50:22.354 - 00:50:35.734, Speaker A: We can just verify the signatures and call it good. But if we're doing things that you're talking about, but much more, you know, specific, how do you think about verifiability? Not over the long term, but just on the short term of. Is an answer actually correct?
00:50:36.294 - 00:51:02.082, Speaker B: Yeah, this is super important. So that's why we realized that this is a central, fundamental problem. To build crypto economic systems is to actually have the ability to do two things. One is to challenge and slash the guys. So that becomes verifiable. But to be able to challenge and slash the guys, we need the data to be available relative to whatever computation is being done. That's why we built Eigenv as a core service for the ecosystem.
00:51:02.082 - 00:51:28.500, Speaker B: This core service has to scale. This core service has to scale. Solana, you guys talk a lot about scalability, but we also talk about scalability. But on eigenvalue, the scaling is horizontal. As you get more and more nodes, you can actually scale the data throughput linearly. Just to give a sense of these numbers. The launch throughput of eigenda, it's not yet on main net, but coming up in the next couple of months, the launch throughput of eigen DA is ten megabytes per second.
00:51:28.500 - 00:51:48.760, Speaker B: But the minimum node requirement is only 0.5 megabytes per second. So anybody with 0.5 megabits per second can join the network. They are only downloading and storing, like, a portion of the blob. But the blob is distributed across many, many nodes, so that even if a large fraction of nodes go away, you can still reconstruct every bit of data. So that's the kind of core principle of eigenda.
00:51:48.760 - 00:52:40.546, Speaker B: And this is exactly the reason that. The reason that you laid out is the reason why we built eigenda in the first place. Because to have an ecosystem of services which can all be verified transparently, we need the ability to slash, but also we need the ability for challenges to actually have access to this data and a challenger is a permissionless role. So anybody can come and be a challenger and you can actually go and slash the notes for misbehavior. That is how we get the insured API property that I stated, which is that when I'm giving you an API response, it is signed by the majority of validators and there is a certain amount of economic insurance that each abs can take from the common pool. So you know that if this API is wrong, then I will be able to slash and distribute this amount of money. So this is the complex crypto economic accounting that Eigen layer protocol maintains.
00:52:40.546 - 00:52:41.374, Speaker B: Yeah.
00:52:41.714 - 00:53:27.316, Speaker A: So I kind of want to give you, this is always my question when I'm talking to anyone about these sorts of things, is let's walk through the doomsday scenario, which happens every three to four years, which is an 80% tank in the market. Right? This is, you can set your watch by it at this point. Right. This, this is a, I can guarantee you sometime in the next ten years, 80% of the Ethereum market cap is going to drop. In those, in those models and situations, suddenly you go from a, in your example, $10 billion of security to $2 billion of security. How do you think about dynamic security? Because the core assumption here is that ether will be valuable. And I think that's probably a reasonable assumption, but it is not something you can guarantee.
00:53:27.500 - 00:53:27.884, Speaker B: Yeah.
00:53:27.924 - 00:53:29.020, Speaker A: It's outside of your control.
00:53:29.092 - 00:53:32.756, Speaker B: This is a very. Yeah, absolutely. It's completely exogenous to what we're doing.
00:53:32.860 - 00:53:33.148, Speaker A: Yeah.
00:53:33.196 - 00:54:47.278, Speaker B: This is really, really why the two things have to be matched. When you're looking at economic security, which is the, what is the nomination or denomination of economic risk has to be matched with the denominational economic collateral. This is where we think, when we play out the eigen layer thesis, that there is a strong posture network effect between the monetary premium of ETH, the asset, relative to the use of ETH in securing eigen layer as a collateral. Because if ETH is the primary denomination across all these different roll ups to actually measure economic activity, you are selling bored apes, but bored ebs are priced in ETH and so on. So you actually have items which are denominated in ETH, then the cross volatility risk, which is exactly what youre talking about here, is actually minimized. But if you are actually denominating a lot of risk in USD, maybe the right source of staking is not ETH. The right source of staking is you have to stake bonds and other instruments which are directly correlated to the unit of denomination of risk.
00:54:47.278 - 00:55:44.454, Speaker B: So our thesis is neutral relative to that. But we do think ETH is likely to accrue a lot of monetary premium, especially given that ETH can now be used across all these systems that we are building for. But basically there's a cross matching of the unit of denomination and the unit of collateral, because if you don't have it, you're exactly subject to. Now, if you're using USD and USD is the unit of risk and you're using ETH as the stake, then because of the cross mismatch, you have to actually have in the 80% collapse case, if that's the worst case that we're estimating, you'd have five x more stake relative to a unit. This is also the reason why we think native tokens of various bridges and such are not good for economic safety. Because if ETH has 80% volatility, these other things have 99% volatility attached to them.
00:55:44.994 - 00:56:10.054, Speaker A: Yeah, this is where I think there's a real sort of mushroom trip moment where you can sort of be like, but why would any of this increase ethers value? Right? And this is actually one of those things where we've sort of taken it as an assumption that you can't build something more valuable than Ethereum on Ethereum. And I think that's a very bad assumption to make.
00:56:10.794 - 00:57:20.948, Speaker B: I would agree with you completely that you can't. When I hear that, it makes me like, do you see the roads out there? What's the value of the roads? What's the value of the gold carried on the roads? Yeah, but I think there is. There are at least certain dimensions in which this thesis has some value, which is the Internet, native assets like bitcoin, Ethereum, and maybe Solana, if it finds its place there. The Internet native assets have a degree of social consensus, sovereignty that, you know, real world assets don't because you can't fork them. You can't do various things. Even for this, I'm actually little worried about how tightly eat the asset is tied with Ethereum the blockchain, because, you know, I can't fork eat the asset without forking Ethereum the blockchain. All other blockchains, I think, didn't adopt any fundamentally different philosophical approach.
00:57:20.948 - 00:58:06.204, Speaker B: They adopted different technical approaches. But the coupling of the native asset with respect to the chain actually makes it difficult. For example, like, people talk about whether Ethereum's forkability is controlled by the Ethereum community or it's controlled by circle. And I think it's a valid, valid question, because what's happened is the forkability of the assets tied to forkability of Ethereum, the blockchain, and the ethereum, the blockchain mixes all these assets into, like, one, you know. Yeah, one blend. You know, it's a blender that mixes all these assets into, like, this ties them all together in this tight wrap that if one of them pulls and the other pulls in the other direction, the whole thing can explode. And so.
00:58:06.204 - 00:58:42.236, Speaker B: Yeah, but the core thing here is that eat the asset has a degree of social sovereignty that, like, simply, and I don't like even calling it social sovereignty. I call these systems self enforcing coordination systems. The rules of what eat. Right. Because, you know, they're just like, you know, the rules of what who should have eat are self enforcing. Like, nobody else has to come and enforce it. And I think the self enforcing nature is nowhere more obvious than when we all sit around and watch a hack in horror.
00:58:42.236 - 00:58:48.444, Speaker B: Yeah. Being not able to actually do anything about it because the genie is out of the bottle and we have no.
00:58:48.484 - 00:59:33.154, Speaker A: Control, which is actually, again, this is another psychedelic mushrooms moment. There's actually complete control. The Ethereum community could unwind every single hack if they want to. There's this myth of the immutable ledger, and the ledger is only as strong as the community will. There's these moments where it feels very similar. Forgive me for a terrible analogy, but it feels very similar to the end of the cold War, where we're like, there is one thing you have to do to prevent communism from taking over Europe, and it is only this one thing, and then the cold war ends, and everyone's like, huh. We really didn't need to do, like, the dominoes theory was totally wrong.
00:59:33.154 - 00:59:54.986, Speaker A: Like, all these ideas were totally wrong. You see this play out with weapons of mass destruction in Iraq and the invasion of Iraq. There's these ideas that get in people's head that they just keep repeating like they're somehow true. And I think this is, you know, this is one of those, too. That feels to me like, you know, we. We could reverse all the hacks. We've just, yeah.
00:59:54.986 - 00:59:56.106, Speaker A: Chosen that. It's.
00:59:56.170 - 01:00:10.218, Speaker B: I think this is a really, really interesting question I've spent an endless hours thinking about. So I have something to add here. The. The first thing is, a self enforcing coordination system works because there is a pre agreement on the conditions of coordination.
01:00:10.266 - 01:00:10.894, Speaker A: Yes.
01:00:12.204 - 01:00:51.026, Speaker B: And the pre agreement on the conditional coordination for Ethereum was code is law, and this basically enforced that. And it was broken once with the DAO hack. And people became very averse to, oh, if I actually go and unwind some other things, then basically the coordination system itself fundamentally breaks. Because what are we coordinating, if I can? So this is when people talk about sovereign blockchains or something like I get a little worried because your sovereignty is from my viewpoint, it's capriciousness. Like, you will do whatever you want. Like, then what am I incarnate?
01:00:51.090 - 01:00:53.330, Speaker A: Sovereignty is my totalitarianism.
01:00:53.522 - 01:01:30.214, Speaker B: Yeah, exactly. Exactly. From my point of view. So our view with eigen layer, and I think like the original view of Ethereum itself, was to build global systems of coordination. So when you're, and to build a global system of coordination, you need binding conditions on which you're coordinating. And if these conditions can be manipulated capriciously, then the system doesn't work. And so this is the kind of worry from the other side, from the Ethereum community, why people are worried a lot about like, oh, I don't want to revert a coordination mechanism or revert a consensus, for example.
01:01:30.214 - 01:02:51.124, Speaker B: But there's also, even if we decide to change it and we can reinitialize ethereum, the problem is a reversion of a block, for example, would mean some of the people, because state propagates through the ecosystem in these composable state machines. So any downstream consequences propagated to places that you cannot control. And so this limits the revertability of a blockchain like Ethereum is because you have downstream consequences of some other person. Some other person, they got their e, they moved it around, it's now you have to invert all of it is may not be possible. So that is, I think the, but somebody is going to come up with a system which actually kind of can have a self enforcing coordination system which allows the power. The pre agreed condition is if we can socially agree it's a hack, we will revert it, because that kind of a system is not yet there because of state contamination, the downstream state contamination that follows through. Now where do you revert? And what happens to the other guys who got food? Coinbase gave out a few billion dollars because they trusted your block.
01:02:51.124 - 01:03:04.676, Speaker B: A bridge like, you know, or a tornado or some other thing, like all of these have downstream ripples that are hard to control. And so that's, that's something. But you know, I'm on both sides of this debate.
01:03:04.820 - 01:03:12.636, Speaker A: Yeah. I mean, I've been saying for years, I think the hardest problems ahead for blockchain are not technical, but they're, they're human.
01:03:12.700 - 01:03:59.974, Speaker B: Absolutely agree with. I absolutely agree with you, Austin, on this, and I'm glad you said this, because, and Tony says, like, all the problems in blockchain have been solved. I'm like, maybe technical problems, but the fundamental problem, we have blockchains. We claim these are great systems of coordination and global settlement and so on, including Ethereum. Like, I'm from the Ethereum side. I'm not happy with these systems yet, because they are not, to me, top most principle in any of the systems is karma. And karma means basically, you get what you deserve, and a hacker getting away with somebody else's money is simply not in any reasonable system of karma.
01:03:59.974 - 01:04:18.212, Speaker B: And therefore, in fact, the thing that offends me the most is the only reason that a hack is revertable is to the extent that we go and ask federal and other players to actually step in, which means we built an awful system here that cannot self regulate. Yeah.
01:04:18.388 - 01:04:22.224, Speaker A: It's the weirdest form of off chain slashing when you call the FBI.
01:04:22.884 - 01:04:47.004, Speaker B: Yeah. And because there's nothing else to call here, the system has no ability for me to do it, and I think we have to do better. So I absolutely agree with you that the most fundamental problems here are absolutely not technical. They are like a more fundamental philosophical level. We have to untangle the mess there to actually build better systems. Yeah.
01:04:47.624 - 01:04:52.164, Speaker A: Well, thiram, I've kept you a while. Thank you for joining us today on validated.
01:04:53.024 - 01:05:01.384, Speaker B: Really appreciate it. For those of you who want to follow along what we're doing, we're at Eigen Layer, Eig and LA. Yeah, thank you. Awesome.

00:00:03.160 - 00:00:53.434, Speaker A: Okay, hi everyone, I'm Felix Willem. I'm a security researcher at Jump and part of the security team working on fire dancer. In this talk, I'm going to highlight some of the work our team has been doing to make fire dancer as secure and reliable as possible. Before diving in, I want to give a shout out to my coworkers, Mark and Jonathan, who contributed a lot to this presentation. Mark is the lead security engineer on filancer and responsible for most of the cool stuff shown here, so full credit should go to him. So I hope all of you saw Dan's talk yesterday and you have a good understanding of the current state of development and what we are trying to achieve with Filancer. But for those of you who missed it, the very short pitch for file answer is that it's a new independent Solana validator designed to improve the ecosystem, robustness and performance.
00:00:53.434 - 00:02:06.834, Speaker A: It's developed in the open and you can check out the code on GitHub. So the firelancer engineering team is also doing a technical deep dive later today at 04:15 so if you're interested in all the great work the team has been doing, you should check that out. It's actually in the event area, so number three on the location plan. So go there and check that out today in the afternoon. So when you think about a second independent validator implementation for a blockchain like Solana, from a security point of view, there are a couple of big opportunities that make this work very interesting, but it also has some challenging aspects that make this harder than your normal security program. So on the opportunity side, introducing a second validator to Solana and keeping its tech stack as independent as possible from the main labs validator is a clear security win when you think about the diversity of the network, its supply chain and all the components that it relies on. So if you have a blockchain that relies on a single implementation stack, it's very exposed to vulnerabilities or backdoors in its supply chain and dependency stack.
00:02:06.834 - 00:03:35.514, Speaker A: So that includes third party libraries, but also the standard library of the language you use to implement it, and even bugs in the used compiler. So once your network is running multiple different implementations, these type of attacks are still a big problem, but they stop being an existential risk, which is just a big win from a security point of view. Writing a validator, a new validator from scratch also gives us the opportunity to start with a secure architecture, so it's always hard to bolt on security to an existing monolithic application after it's already running out in production, but being involved early on in the development stage makes this much easier. Finally, we can also learn from the experience of other validators, be it the Solana labs team or like other chains. What approach worked well for them from a security point of view? What made it difficult? What bug classes are they worried about or continue to fight against? And what would they do differently if they could start start from scratch? On the other side, a project like Filancer also has some security challenges. So Firelancer has to closely replicate the behavior of the main Solana labs validator, and not doing so is a security issue. So we also have to support the full feature set of the protocol, and if some of that functionality is hard to implement or correctly or securely, we still have to do the work.
00:03:35.514 - 00:04:29.554, Speaker A: This compatibility requirement also means that we can't simply review fire dancer code on its own. We also have to keep in mind how the labs validator works and make sure we are in alignment with them. Many of you will know file answers written in C C doesn't offer the memory safety guarantees that you get from languages like rust or Golang. So bringing and so reducing the occurrences and the impact of memory safety vulnerabilities in the file answer code bases actually one of the main goals of our security program. And finally, and I don't think that's like, specific to firelancer, it's just a property of like, a lot of the development in these areas is development velocity. So firelancer is a project that moves really fast. We have a large engineering team full of talented developers who write a lot of code.
00:04:29.554 - 00:05:40.706, Speaker A: So we need to find a way to keep up with the development speed without slowing them down, just scaling up our headcount to insane levels, or introducing blockers and stopping the project from moving forward. So the two main strategies we are using to address these challenges are shown on this slide. So first, we design for defense and depth. That means we try to to push for and implement architectural decisions that reduce the impact of vulnerabilities as much as possible. And second, we are operating as an embedded security team to collaborate with the engineering team across the whole development lifecycle and find vulnerabilities as early as possible and get them fixed. So let's take a look how we apply these two strategies to fire dancers, starting with defense in depth. So one harsh reality of security engineering that you're going to realize if you spend more time in the space is that all software will have a security vulnerability sooner or later.
00:05:40.706 - 00:06:29.264, Speaker A: So if we assume that bugs are going to exist, then we need to find a way to limit the impact. And the graphic on this slide shows like a really simplified way you can think about, you can think about a vulnerability in your code base. So in a project like Filancer, this could be a classic memory corruption bug in your C code base. It could be a logic issue in your SVM runtime, or a missing check in some business logic. And so you start with the vulnerability, and an attacker wants to turn this into an exploit in the case of a buffer overflow, like a common goal for such an exploit would be arbitrary code execution. So an attacker tries to run their own code in the context of the vulnerable process. Other exploits could be restricted to data only attacks.
00:06:29.264 - 00:07:22.954, Speaker A: For example, maybe you just want to bypass a signature check or corrupt the status data of a specific account. And mitigating memory safety issues in c to prevent these attacks is a pretty well studied problem, and recent years have seen a large arsenal of hardening techniques and compiler features to make the life of an attacker as hard as possible. And firelancer is following industry best practices here and just enables the stuff that we can profit from. However, mitigations like mitigating the step between vulnerability exploit have two important limitations. First, often they don't prevent exploitation, they just make it harder. And second, a lot of these logic bugs that we are nervous about, they can't really protect you from that. They're good at making buffer overflows harder to exploit, but they don't really help you with logic bugs.
00:07:22.954 - 00:08:11.234, Speaker A: So today I want to concentrate on the right side of this graphic, the step from exploit to compromise. So an attacker isn't really interested in remote code execution in your process. They want to achieve a certain goal. And if you target a validator, your end goal is probably something like compromising the validator, signing keys, gaining persistent access to the system, or modifying the results of a transaction or block, and prevent an attacker from doing that. Even if we miss security, vulnerability is the main goal of our defense and debt strategy, and we make use of two closely related approaches here to achieve this. These approaches are tile isolation and operating sandboxing. So let's talk about tile isolation first.
00:08:11.234 - 00:09:19.024, Speaker A: Tiles are a core building block of fire dancer, and tile isolation is a natural outcome of its architecture. So the left side shows a really simplified overview of fire dancer's transaction inquest pipeline, consisting out of four different tiles. So you take in network traffic, you pass the quick packets, you get transactions out, you verify the signatures of these transactions and you de duplicate them. These tiles can be run in parallel, and each tile has a very clearly defined single purpose. So quick tile is responsible for processing incoming quick traffic, forwarding the encapsulated transactions into the verify tile, and then the verify tile performs this high performance signature verification. The interesting thing here is that each of these tiles runs in its own process and a trespass, and they communicate through high performance shared memory interfaces. And this is very difficult to your typical monolithical blockchain validator that just uses a single big process and doesn't have like clearly separated boundaries between the different parts of the implementation.
00:09:19.024 - 00:10:05.998, Speaker A: And while this architecture, the multi tile architecture, was developed to satisfy the performance and reliability goals of firelancer, it also gives us some nice security properties. So from a threat modeling perspective, we consider most tiles to be compromised. This means that we consider the shared memory interface between two tiles as a security boundary. And to give you an idea how this helps, think about a bug in the Qwiktile. QWik is a complex protocol. It has to perform a lot of parsing of untrusted network data, and this is a hard problem, and we might end up with a bug that allows an attacker to execute it on arbitrary code. When processing a malicious quick packet in a monolithic architecture, this would be an instant compromise.
00:10:05.998 - 00:10:46.274, Speaker A: The attacker could backdoor your system, potentially take over the whole chain. If they do this just against multiple validators. But in fire answer, the attacker's abilities are actually limited to quicktile. So quick can't simply flip the signature check of incoming transactions, for example, and all the data that leaves the quick tile is considered untrusted. So an attacker needs to find an additional vulnerability to do any actual damage. They might be able to degrade the performance of the validator, but without a bug in the verify tile, they should not be able to break any of our core security requirements. Of course, they still have code execution in the Linux process.
00:10:46.274 - 00:11:52.580, Speaker A: So how do we prevent them from fully compromising the underlying system and achieving the goal? And this is where our sandboxing infrastructure comes into play. So the goal of sandboxing is to isolate the tiles from the underlying operating system. By enforcing the principle of least privileged. Tiles are only allowed to access resources and perform system calls that they need for the job. And because tiles in Filanza have a very clearly defined purpose, and almost all the code in fire dancer is developed by us, we can really strip down the permissions. The way we do this, and this is very similar to the approach used, for example, by the Google Chrome sandbox, is to put tiles into their own Linux namespaces to provide them with a limited view of the system and prevent them from accessing most of the file system, the network, or any other process running on the same system. Namespaces provide a first security boundary, but they still can be bypassed if an attacker has a kernel exploit that can be used for privilege escalation.
00:11:52.580 - 00:12:48.154, Speaker A: So the big remaining attack surface in the kernel that is reachable from tiles is the system call interface. And to protect against this we make use of Seccom BPF, which is a security mechanism that allows us to perform very fine grained filtering of system calls before they are processed by the kernel. So we can block tiles from doing system calls that they shouldn't do. And the cool thing about filance's architecture is that it makes the system call filtering extremely powerful. So this slide shows the system call policy for the pack tile, which is responsible for block packing. And as you can see, like looking at this policy file, the only system calls this tile can actually do are write system call to two hard coded file descriptions used for error logging, and Fsync, which is also used for error logging. None of these system calls actually provide any significant attack surface to an attacker, making it very difficult to break out of the sandbox.
00:12:48.154 - 00:14:25.264, Speaker A: The team is actually working on like even increasing that or improving that further by introducing like an additional logging tile, which would allow us to run most tiles or many tiles in fire dancer without access to any system calls at all, making this like a very strong sandbox, very hard to escape. If you're interested in this, one of the cool things in the file answer codebase is actually Mark's policy compiler, which turns the readable policy file shown on this slide into the actual BPF filter program that is run by the kernel. It's inspired by similar tools used by Chrome, and you can check it out at the link on the bottom of the slide. So our defense in depth strategy can help us to reduce the impact of vulnerabilities, but it still requires a lot of work to secure the code to secure the remaining attack surface. And of course we also want to reduce the number of vulnerabilities as much as possible. This is where our embedded security program comes into play. So we try to think of fire dancer security work as ongoing collaboration between the engineering team and the security team, instead of devs writing the code, throwing it over the wall, and then getting an external audit waiting for a nice looking PDF report, we try to engage earlier with the team, provide advice on architecture mitigations and areas of improvement to make this as secure as possible as early on, and two of the main building blocks we are using as part of this effort I want to talk about today are the self serving fuzzing infrastructure and regular internal code reviews.
00:14:25.264 - 00:15:52.652, Speaker A: So fileancer makes use of a dedicated clusterfuzz instance running continuous coverage gated fuzz testing on the code base fuzzing, if you're not familiar with, is used to automatically detect crashes or error conditions that indicate vulnerabilities in our code base by basically stress testing the code exposed to untrusted inputs. Fuzzing is kind of the gold standard in the industry to automatically identify vulnerabilities in complex c software, and we make heavy use of it as it allows to scale scale almost purely with computational resources, of which we have a lot. Instead of scaling purely with headcount, security engineers provide fuzzing harnesses, which you can think of as like a special version of a unit test for security critical components. But we also rely on developers to add fuzz tests for newly developed components. New fuzz tests contributed to the code are automatically picked up and executed on our dedicated infrastructure, giving developers a really quick feedback loop to see if their changes triggered any new problems. The code coverage achieved by these fuzz tests is actually one of our core metrics to assess production readiness of a new component, and the goal is that all components are fuzzed heavily before we go into the next stage of our manual security review process. Fuzzing is great at finding bugs, but it will never be able to find all the bugs.
00:15:52.652 - 00:16:56.014, Speaker A: Our experience actually has shown that there's only a partial overlap between the bugs found by fuzzing and the ones found by code review. So the next building blocks we rely on are manual code reviews, and the goal is to identify bugs that are a tooling miss, and we concentrate on components that are high risk or highly exposed. And I think the important point I want to make is that bugs are not actually the only outcome of these reviews, most important one. Instead, we use the stuff we learn as a feedback mechanism to feed into the rest of our security program. So this could be things like improving fuzzing coverage, the introduction of static analysis checks to identify variants of a buck class, or even larger scale refactorings to design our way out of a complex attack surface. So all of the things I talked about is stuff we have been doing for the last months, and we will be continuing to do so in the future. But I also wanted to give you a bit of a heads up for how we're going to move forward with our security program to get Frankdancer and the full fire dancer ready for mainnet launch.
00:16:56.014 - 00:17:40.674, Speaker A: So regardless of the quality of a security team, at some point you hit the limit to the amount of work you can do with a finite set of resources. So we are planning to scale up our efforts further on our way to Mainnet. As a first step in this direction, we are planning to engage some of the top security companies in the industry to perform external security reuse of these finished components. This will allow us to identify blind spots that we missed and provide additional security assurance. We will also be following the leader of the Solana Labs validator and are going to announce a bug bounty program in the coming months. We plan to launch a bounty for components that are running in testnet and increase rewards before we move them to Mainnet. So if you are interested in that, stay tuned for further updates.
00:17:40.674 - 00:18:24.524, Speaker A: So I hope this talk gave you a good idea about the work we do to make file as secure as possible. Before I wrap up, I want to give the usual disclaimers. Firelancer is still alpha software and very much in development. While we have made a lot of progress on the security side of things, there's still a lot of work to do. With that being said, please make sure to check out the file answer presentation by the engineering team later today in the event specific days. Number three to learn more about some of the engineering marvels that are hidden inside this code base. I'll be around for the rest of the conference, so if you see me and have any questions on the security work we are doing, please come talk to me in the next days.
00:18:24.524 - 00:18:25.544, Speaker A: Thank you very much.

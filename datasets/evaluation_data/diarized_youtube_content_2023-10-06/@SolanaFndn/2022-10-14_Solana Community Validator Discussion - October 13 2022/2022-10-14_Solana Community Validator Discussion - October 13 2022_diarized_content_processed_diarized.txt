00:00:00.920 - 00:00:44.214, Speaker A: All right, welcome everyone. This Valley Day community call is at a different time to hopefully get more people in Europe and Asia on the call, hoping as we go, the world will get out a little bit more, but tenants a little low this time. So anyway, hoping for the best. Let's get into the agenda for today. As always, we've got some validator updates. Zantetsu is going to talk a little bit about his timely voting proposal, where it's at, and I'm assuming ask for some support. And then at the end I want to have a discussion a little bit about monitoring and alerting for validators.
00:00:44.214 - 00:01:18.134, Speaker A: Just seeing if we can come up with either documentation or just share some knowledge about the best way to help everybody get alerted when something goes wrong so that the cluster can ideally get restarted in a timely manner. More timely manner. All right, so first update here. You might have seen the announcements. You might have seen the announcement. 1.13.3 is now recommended for main net beta for all validators.
00:01:18.134 - 00:01:39.454, Speaker A: So even if you're previously on 1.10, now's the time to upgrade to 113.3. As always, do it when there's less than 5% delinquent stake. And the big win here is that quick is on by default. So if we get everyone up to 113.3, we are on quick. It's a great milestone there.
00:01:39.454 - 00:02:17.264, Speaker A: For test it, 1.14.5 is recommended. No major changes there over previous 1.14 versions, just some documentation and some fixes, but also upgrade there again when the stake is below 5% delinquency. Wanted to just make a note about the cluster restart on the 30th. If you missed it or, you know, we're delinquent. Weren't there, the cluster restarted just under two weeks ago.
00:02:17.264 - 00:02:43.924, Speaker A: There's information about it at this link. Solana.com News 930 22 Solana Main Nippet outage report so if you're not sure exactly what happened or why it happened, you could check that out. A fix was released on 110.40 and was adopted by the cluster. So ideally that specific edge case shouldn't happen again. I just want to say thank you to all.
00:02:43.924 - 00:03:32.196, Speaker A: Excuse me, thank you to all validators, operators, RBC operators who were, you know, part of the restart. We're there from the beginning, and we're part of the group that got the cluster going again. Yeah, I'm just going to leave it at that. If you want more details, check out the report here. Also want to know I had an educational workshop that I did yesterday. We had about, I think like seven or eight attendees, but would love to get more people in there, you know, if you're not sure on certain topics or if you want a specific topic covered, or if you feel like you can teach some of these topics. Happy to hear from all of you.
00:03:32.196 - 00:04:17.084, Speaker A: I'm planning to do two more workshops at the same time, 10:00 a.m. Pacific on October 19 and October 26. After that, I'll sort of assess attendance and what we did or didn't cover and see if we can do more going forward after breakpoint. But just want to test these couple workshops out for now. Again, if you have any feedback, feel free to dm me, it's in the invite for this meeting. Or feel free to set up one on one meeting with me and we can talk over some ideas missing the chat here. Okay, yeah, good on that.
00:04:17.084 - 00:05:00.904, Speaker A: So yeah, now I want to give some time for Zantetsu to talk about his timely voting proposal, assuming his mic works. So take it away. Yeah. Looks like you're having trouble with audio. He wants to keep his voice anonymous, I think. Okay, yeah, he's going to leave and come back. Maybe we'll come back to this.
00:05:00.904 - 00:05:38.316, Speaker A: Any other topics people want to discuss or bring up in the meantime, while Zen Tetsu checks his audio setup? Questions, thoughts? No. Steve, where are you based out of us central time. Oh, okay. So just an idol. Just, just hitting my stride. Yeah, I've gone the other way. I start going to bed at like 930 now, so yeah, I should do that.
00:05:38.316 - 00:06:48.294, Speaker A: But especially with daylight hours shrinking. Yeah, yeah, it's harder. Let's see. I'll give Zan another couple seconds, then we can hopefully talk about this soon. Just echoing, saying a huge thank you to all the validators and operators who got everything working again two weeks ago. So awesome to see. Hopefully Zen Tatsu's mic's fixed.
00:06:48.874 - 00:06:50.482, Speaker B: Okay, what about now? Can you hear me?
00:06:50.578 - 00:06:51.370, Speaker A: Yeah, we can hear you.
00:06:51.402 - 00:07:14.838, Speaker B: Okay, I guess took a restart to fix that one. Okay. Sorry about that. Well, I'm not sure how many people were there for the previous presentation I gave on this topic, but I gave a pretty lengthy presentation on this before. Is it possible? Oh, yeah. Awesome. So that is the pull request that I created.
00:07:14.838 - 00:08:09.092, Speaker B: So the status is that I actually finally got around to implementing it and now it's kind of waiting for review. There was an early implementation that I did that was a little bit more hacky. It was trying to sort of repurpose some bits that already existed in the tower data structure, but I was advised that doing it in a cleaner way would be better. That involves changing the actual vote account structure so everyone's vote accounts will have a little bit of extra information in there to track the latencies. And anyway, that implementation is complete from my perspective and is in the review, and I'm just kind of waiting to hear back from Solana Labs about it. I have been continuing to gather, you know, most epics, I gather statistics to show what the effect would be. I don't know if I can share my screen or not.
00:08:09.092 - 00:08:15.292, Speaker B: I've never, I don't know if I've done that in this UI on this computer before I can stop presenting.
00:08:15.388 - 00:08:17.004, Speaker A: Give it a try. Yeah.
00:08:17.044 - 00:08:17.340, Speaker C: Okay.
00:08:17.372 - 00:08:27.124, Speaker B: So I can say, there we go. Uh, I probably shouldn't share my actual.
00:08:27.944 - 00:08:28.352, Speaker A: About.
00:08:28.408 - 00:08:36.684, Speaker B: Oh, I'm sorry, I'm not. I'm not very good at this. Let me see. Share this space about. Let's share my entire screen.
00:08:38.864 - 00:08:39.336, Speaker A: I don't know.
00:08:39.360 - 00:08:40.324, Speaker B: Can you see that?
00:08:41.704 - 00:08:44.808, Speaker A: Not yet. No. No.
00:08:44.856 - 00:09:24.258, Speaker B: It says it can't do it. I don't know. I'm sorry. Not well prepared. But. So I have been tracking, there's a different GitHub issue that I have opened against Solana Labs, where I actually, I've posted links to it before in the discord, where I actually post updated data about it. And, you know, the data continues to show that we have one very significant lagger, and that's Vimdi, the famous Vimdi, who, no one knows who they are, really, but my suspicion is that it's somebody who's professionally paid by investors to get the best possible returns on their particular large body of stake.
00:09:24.258 - 00:10:03.342, Speaker B: That's my guess, because I know that they've got some other techniques they're using. They do restarts without ever having any downtime, which I wish we could all get the benefit of their knowledge there, but they don't really share information with the rest of us. But ViMD gets crushed by my changes, crushed down to one of the worst performers from the best performer. And, you know, in my mind, that is an indication that the change will do what it's intended to do. If you look at validators app for VIMD, you'll see that they are always lagging their vote. Their vote distance is always high because they're essentially always voting three to four slots late, and that gets heavily punished. I'm not sure what else to say about it.
00:10:03.342 - 00:10:47.294, Speaker B: I mean, I've posted about it numerous times in discord. The stats are out there. I can repost them if anybody needs me to do that in the discord. The changes is waiting, and I'm hoping that we'll get some groundswell of support behind it. I know that there are a lot of people who have spoken to me in DM's and expressed their support for it, because I think we all want fair, and we all want fair mechanisms for evaluating validated performance and thus turning into voting credits that reward what we think of as good behavior. And I think this change does that. So does anybody have any questions about the motivation or the implementation or the expectation of what will happen or what the process will be?
00:10:48.314 - 00:10:54.050, Speaker A: I've got a couple, actually. So I'm curious what you're saving in the vote account in order to keep this.
00:10:54.162 - 00:11:22.292, Speaker B: Sure. So in the vote account, there's a data structure in the tower that stores what are called lockouts. So it's essentially an array of up to 32 elements. Each element stores the slot that was voted on. Okay. And the confirmation count of that slot and those two values turn into the Solana method for tracking votes and achieving what's called lockout. On a slot where.
00:11:22.292 - 00:12:16.488, Speaker B: I'm sorry. Yeah, where you've essentially, by voting on a slot, you have then committed to not voting for slots on a different fork for some number of slots. And once you've achieved 32 confirmations by your own votes, on votes you'd previously cast. So if I vote on slot a and then vote 32 times beyond that on that same fork, then slot a will pop off the back of my lockout structure, and then the entire cluster will calculate that same effect the same way. Because every validator is evaluating votes in the same order at the same time, because of the way that the blockchain works, and thus that those credits are awarded equally by everybody, it's counted the same, and the credit goes into your vote account. And if you use the Solana Vote account command, you'll see it'll list the credits that you've earned progressively as the epoch goes forward. And also you'll see a history of the credits that were earned for previous epochs.
00:12:16.488 - 00:12:54.830, Speaker B: And your credit earnings are what sort of rank you related to other validators, and thus give you a slightly more, slightly less of the overall, you know, inflation rewards. So the new addition is a parallel data structure. My original change was to take that lockouts and reuse some of the bits that were in the confirmation count, since confirmation counts can only go up to 32, but they were using a four byte data value. There was like, that can hold for 4 billion. So there's plenty of available bits. So just kind of like you use some of those bits to store another number, which was the latency of that, of that slot that was voted on. But reusing bits was kind of frowned upon.
00:12:54.830 - 00:13:47.702, Speaker B: So instead, adding a new data structure to the vote account at the very end, that is another 32 value array, where each value is a mirror, is in lockstep with what's in the lockouts array. So the lockout array is recording that slot. If it's got 32 values in the array, maybe at index 17, it's recording that you voted on slot a. Then in index 17 of this other array in that same slot, it'll put the latency at which that particular slot was voted on. So when a vote arrives, we know what slot it arrives in because you can look at the slot history, syspar that's available and you can say, okay, well, this is now slot, you know, slot m. And this vote is for slot m minus two. So this has an additional latency of one.
00:13:47.702 - 00:14:38.654, Speaker B: It could have been in slot m minus one, but it's one, you know, it's one beyond that. So, so as votes arrive, it is evaluating the distance between the slot that that vote is arriving in and the slot that vote is voting on, or slot or slots, and recording those in a data structure that's parallel to the tower, keeping and keeping those tunes in sync so that as votes pop off one, they pop off the other. As they're, you know, added to one, they're added to the other. And if you have any lockout in the lockout structure, you can look at the same index in this other structure and you'll find the latency of the vote at that slot. And then when it pops off the back, instead of rewarding one credit, it looks at the latency that was true for that slot at the time that it was voted on. And it rewards credits based on the latency instead of just one. So it's up to n where it starts at a number such as ten, and every time you have an additional latency, it drops down to nine, then eight, then seven.
00:14:38.654 - 00:14:43.854, Speaker B: So I hope that rather long winded answer gets. Gets you the information you need.
00:14:43.974 - 00:15:01.582, Speaker A: Yeah, yeah, I think so. And then the other question I had, which I kind of got there was, I know there was, excuse me, some discussion before of giving you partial vote credits. You know, like if you are lagging and let's say you're six or seven slots behind, you get some fraction of.
00:15:01.638 - 00:15:26.922, Speaker B: Oh, yeah, yeah. That's the way that, in fact, it's. There's two tunable parameters. There's the maximum number to award, which is what you get for having the least possible latency. And right now I've set that number to ten, like, and that's based upon data that I've been gathering for a long time and analyzing, and that seems to be like the sweet spot. And then every vote app that every time. So if you have the minimum possible latency, which means you vote immediately in the slot, after that you're voting on.
00:15:26.922 - 00:16:20.082, Speaker B: And in fact, if you look at Valeries apps like we're doing great, like, it used to be that many of the votes were two, three, four, you know, latency. And now you can look at a lot of graphs that are like bouncing between zero and one, which on that graph is basically saying you're either voting as fast as it would be physically possible, like in the directly, in the next, in the next slot, or with one slot delay. And many validators are achieving that. Most validators are achieving that, which is what makes the lagging so much more obvious now when it's being done. But, but you know, if you, if you vote with one to three lag, then you get full credits, you get ten credits, but then once you go beyond three, if you are not four lag, you get nine credits. At five lag, you get, you know, eight credits. And so, and so it's a fairly, I mean, that's, I think that's fairly generous already because it still awards you credits, three or four all the way out to, like, what's effectively two or 3 seconds of delay.
00:16:20.082 - 00:16:55.146, Speaker B: And in fact it tails at one, so it always rewards at least one, so it never goes to zero. So no matter how late you are, the reason for that being that you don't want to ever discourage voting. You want voting to happen even if someone's very late, it may be as possible that their vote will matter in some way. It'll push some, you know, some stake weight beyond the critical threshold it needs to be at in some bad network situation. So you're always at least rewarded. And I think that, you know, it seems unlikely to me that anyone would ever not cast a vote just because it'll only get one credit. I think that votes are cheap enough and easy enough to cast that as long as they're worth one credit, they'll get cast all the time.
00:16:55.146 - 00:17:40.855, Speaker B: But most people are going to be earning the full credits because most people land within that, you know, within that three vote threshold most of the time. And in fact, if you look at, and I haven't really drawn pretty graphs of this. But if you look at the numbers and kind of squint your eyes, you can see that, you know, all the ships are being risen. Like, the water's going up. Like the average, you know, the average shape is kind of shifting up a little bit because almost everyone is pushing up slightly in their total credits, which basically means that it's flattening a little bit, is taken from the top and distributed, averaged out, so that it flattens a little bit. Which means that validators such as my own or some of the others that are achieving higher will actually get bumped out a little bit. And that's the benefit of everyone else.
00:17:40.855 - 00:17:44.803, Speaker B: It's not a lot. It's like a 0.4%, but it's a little bit.
00:17:47.924 - 00:17:55.220, Speaker A: Cool. Yeah, those are all the questions I had, but, yeah, thanks. I'll look over the PR more. I think it's, you know, I think it's the useful proposal and I hope.
00:17:55.252 - 00:18:10.772, Speaker B: Yeah, the PR. I don't. I mean, I mean, I submitted a PR a long time ago and it's just not been. Any comment on it. I don't know. I'm in this uncomfortable situation of wanting to be, you know, like, aggressive and like, but also not wanting to piss anyone off. So I just kind of wait, you know?
00:18:10.868 - 00:18:11.340, Speaker A: Yeah.
00:18:11.452 - 00:18:19.154, Speaker B: And believe me, waiting and not being aggressive is, is hard for me. So it's been cool.
00:18:20.134 - 00:18:30.806, Speaker A: All right, well, any more questions for Zantetsu? No. All right, I guess.
00:18:30.870 - 00:18:53.722, Speaker B: Wait, hold on a second. So, Sam, legends asked, does this mitigate the validators mods? I touched on that briefly. It doesn't mitigate them. What it does mean is that any mods will, which induce latency or cause unnecessary latency, are going to be impacted. And there are a couple that are impacted in that way. Number one is Vindi. And we know they get crushed so hard they like going to.
00:18:53.722 - 00:19:15.018, Speaker B: There's no way they continue what they're doing because they're going to go from the number one to like almost the bottom, number two and three on the sort of like vote credits earners. They get crushed down too, to varying degrees. Some a little bit. Leapfrog. Only a little bit because leapfrogs, they're lagging a little bit. But honestly, the lagging isn't that bad, but it's enough to sort of knock them down a little bit. And then Steakhouse gets crushed pretty bad, too.
00:19:15.018 - 00:19:49.726, Speaker B: Now, there are other mods, as we all know. I run them and some other people run them, but those don't get impacted negatively because they don't lag. They just don't. If they did, they would get impacted negatively. Like, there's no way for them not to be because the all votes are kind of the same way. If their votes were landing late, then they would also be, you know, negatively impacted, but they're not. So, uh, there's that, and then there's, like I said before, it, it does slightly sort of flatten the curve so that the top, the peaks, you know, the top validators are going to retract a little bit in their API and everyone else is going to sort of like bump up just a little bit.
00:19:49.726 - 00:19:53.074, Speaker B: Um, yeah. So I hope that answers your question.
00:20:01.274 - 00:20:40.218, Speaker A: Yeah, another comment in the chat soul plays is saying that it looks awesome and yeah, hopefully the PR gets merged. So good. Yeah, I think just, you know, being vocal and MB validators for support, and I'll try to see if I can help grease the wheels in the background as well. Any more questions for Zantetsu? I want to spend a little bit of time. Okay, there's another question. Why use fixed for slot lag and not the slot for determines consensus?
00:20:40.306 - 00:21:21.412, Speaker B: Quite sure I understand that question. If you mean the slot that, like, happens to get what slot you are at when you happen to get popped off the back of your lockout structure, I mean, that's like the 32 slots later or more like that at that point. Because, I mean, what we're trying to, what we want to do is we want validators to vote quickly and accurately. Like, that is the perfect thing to do, is to vote very accurately. That is to say, if we never had any forks, because everyone was always kind of like blazing long on the exact same fork and we never had a fork, that would be beautiful. And if everyone was voting super fast so that, like, transactions were confirmed as quickly as possible, that would be beautiful. But sometimes those things can be a little bit of contention because, because you can't always vote.
00:21:21.412 - 00:22:03.174, Speaker B: Some people will receive packets a little later than other people, and so there's not always going to be as fast as you want it to be. And it's just naturally the case that forks are going to happen because sometimes packets get lost, and that's just the nature of the system. So what you want is to encourage, like, validators to find sort of the best sort of balance. And that's what this attempts to do by making sure that latency is a factor in rewards as much as voting accurately. And it may be the case that voting a little faster and a little bit less accurately is better than voting a little bit more accurately and a little bit slower. I don't know. We'll find presumably over time, we'll kind of find the right ratio, the four slot lag.
00:22:03.174 - 00:22:46.314, Speaker B: I don't know what you mean by that, but the reason for that initial period of, like, three slots where you get full credits is just because there was some concern that validators that are kind of far away in the network might be disadvantaged if they're just naturally a little slower to get their votes in just because they're so much further away. We don't want to discourage people from operating validators in those locations, so we want to give a little bit of grace period. And I think that three slots, I think it would be very hard to really lag productively within three slots because you're taking a chance that you won't land within three. You might land in four, and as soon as you have that risk, you're going to lose some amount of your credits, and it's going to be counterproductive to intentionally lag at all. I hope that answers that question.
00:22:48.854 - 00:22:52.966, Speaker D: Sorry, can you hear me? Can I chat?
00:22:53.070 - 00:22:54.234, Speaker B: Yeah, we can hear you.
00:22:55.894 - 00:23:24.424, Speaker D: Yeah. So my question was more around a fixed four slot lag would mean that if consensus hasn't been sorted out by that point, you start reducing credits that validators earn even when consensus hasn't been confirmed post that point. Does that make sense?
00:23:25.324 - 00:23:37.064, Speaker B: Okay, I not sure I understand exactly what you mean, but I definitely did consider, like, what if instead the first 66% got full credit and anyone who was late got less credit, and then that would, of course, encourage.
00:23:37.604 - 00:23:38.574, Speaker D: That's what I'm thinking.
00:23:38.644 - 00:24:25.424, Speaker B: But that gives a natural advantage to validators that have more leader slots. If you have more leader slots, you can land your own votes guaranteed every time, which means that you'll more, and also bigger validators contribute more to that 66%. So if I, with 2% of stake weight, not that I have that, but someone who has 2% of stake weight lands their votes, they're going to immediately prevent. There's, you know, 2% of the remainder is kind of like now not going to be able to achieve that. There's only 66% that can get in, and the more bigger validators there are, the more likely they are to sort of get the most credits by more often crowding out smaller validators. It's hard to explain, but if you kind of think about it, you know, a big validator letting their vote is like, able to take a large amount of that space that's available in that, in that slot.
00:24:26.364 - 00:25:12.346, Speaker D: So the one thing around that that I was, that I was thinking about was when the slot that 66% of the validators have voted on, that slot could potentially have 100% of the validators voting on it. So the view is that when 66% have reached that slot, sales slot two, then you should get. Everybody should be able to vote on that slot, so nobody would be restricted with credit. But I hear your point about the guys with a lot of leader slots will be able to get a zeros, but that would probably be the case anyway. And they will.
00:25:12.530 - 00:25:32.866, Speaker B: No, no. That's actually a very interesting idea. I mean, I like the idea in that it doesn't create any kind of. It is sort of like says whatever they're never going to achieve. If you can achieve what everyone else can achieve, then you get the credits that everyone else gets. You know, if you can be there in time, the same time that's in 60, 66% demonstrated it was possible, so you. But you should be able to get it by the time they do.
00:25:32.866 - 00:26:12.208, Speaker B: But I think there is still a little bit of the factor of, like, you know, leaders have a little bit of advantage there. And I think it also does push some of the more disadvantaged to more distant validators that, you know, like, are always going to be on the margins. Like, if 66% is all in Germany, then all the Germans are going to get all full credits, and everyone else is never going to kind of get there in time or very or less frequently. And the way this works, 1% difference is enough to make a significant difference in APY. Like, that's 1% is the difference between, like, the top validator and, like, the 10th validator in APY earnings. So it's like a very small margin and it's an interesting idea, though I hadn't thought of it. So let me think about it more after this meeting is over.
00:26:12.296 - 00:26:12.640, Speaker A: Okay.
00:26:12.672 - 00:26:32.214, Speaker D: Because it could be. It could be 66% plus one slot or. Because it just, it just means that if you and you could give half credits to the guys who go above that 66% so they still earn, but it's just definitely not in their advantage to do that. That's all I was thinking anyway.
00:26:36.234 - 00:27:25.444, Speaker A: Good. Michael's got a comment there as a alternative to do 66% or four slots, whatever happens later as an idea. Yeah, yeah. Good thoughts. Any other questions for Zentetsu before we want to take a little bit of time to talk about the restart and just ideas or thoughts on how we. We decrease the time for next one? So let me just bring this page up one sec. All right.
00:27:25.444 - 00:28:04.012, Speaker A: Okay. Yeah, so a couple things for discussion here. Basically, my overarching goal is if there's ever another restart, hopefully there's none. But, you know, there could be. We want to reduce the total time of the restart. Obviously, I think the. Everyone would probably agree the biggest time sink for the last one.
00:28:04.012 - 00:28:59.324, Speaker A: Excuse me. The last one was just getting everybody there and getting to that 80%. I don't remember exactly how long it took, but it was on the order of hours. Right. Once we decided that we were going to do the restart and we were waiting for 80% to get online, it took quite a while. So these are some questions I had. Have any of you made operational changes since the outage? Are there any best practices you have in place for monitoring or learning that you think maybe other people could benefit from? And like I just said, if we ever have another restart, how can we make it go by quicker? So, anybody have thoughts or ideas here? Generally just want to bring it up so that we can work on ways to educate and improve for next time.
00:28:59.324 - 00:29:49.204, Speaker A: Michael, if you're on and available, I know that you added a tool to help out with this, so if you want to mention it on the call, that would be nice. I don't know if you are there, so I'm commenting, or. Lane, should I call you Lane, are you. There you go. There you go.
00:29:49.244 - 00:29:50.076, Speaker E: Can you guys hear me?
00:29:50.140 - 00:29:51.224, Speaker A: Yeah, yeah, yeah. Hear you.
00:29:51.304 - 00:29:52.680, Speaker E: Hey, no, no, Michael's fine.
00:29:52.712 - 00:29:53.088, Speaker A: Sorry.
00:29:53.176 - 00:29:56.256, Speaker D: Yeah, so kind of zenot a little bit.
00:29:56.280 - 00:29:59.164, Speaker E: When you were just chatting, I just heard you mentioned my name.
00:30:02.384 - 00:30:02.992, Speaker B: What you.
00:30:03.048 - 00:30:09.044, Speaker E: Said about tool for the monitoring, the restart. Do you mean the website tracker or the alerting?
00:30:09.424 - 00:30:14.056, Speaker A: The alerting, yeah. So I think you added a feature, stakewiz, to help people with alerting.
00:30:14.120 - 00:30:58.786, Speaker E: So, yeah, I mean, I don't know if it would really be helpful in a cluster restart situation because it depends on delinquency. And when the cluster halts, usually RPC knows don't report delinquency, but, yeah. So Stakewiz has alerting for delinquency and commission changes, which are kind of geared towards stakers, not validators. And for delinquency, the minimum threshold on the website is 15 minutes, which isn't really useful for operators. But after the restart, we added an option for a pager duty integration, which is kind of a like on request. It's not accessible through the UI. So any validators who would like to have that set up can reach out to me and I can add them.
00:30:58.786 - 00:31:21.794, Speaker E: And then basically after I think it's three minutes delinquency. They'll get an alert pushed to their pagerduty. And pagerduty is really useful because it'll send you a push notification on your phone, but if you don't respond, then it starts calling you and just making a lot of noise so you really can't miss it. But beyond that, after doing that.
00:31:23.654 - 00:31:23.966, Speaker A: To.
00:31:23.990 - 00:32:03.516, Speaker E: Take it kind of a step further, I actually added page integration to Watchtower so you don't have to go through stakewiz or any third party. You can do it yourself. So Solana Watchtower is the integrated monitoring tool that comes with the Solana codebase and in the binaries as well. And that's something I think most people should be running in addition to whatever other custom alerting people have. And that's something you run on a separate server, not on the validator. So if your validator crashes, Watchtower will still pick it up. And Watchtower basically polls RPC and checks for delinquency, but also checks for transaction count advancing and these kinds of things.
00:32:03.516 - 00:32:40.404, Speaker E: So Watchtower actually would pick up on a cluster resort. And so, yeah, I added page duty into Watchtower. So I think that's probably what I would recommend people do. It's in master. I don't know if it's been back that has been back ported because it's not critical and core engineers generally don't backport non critical stuff into the production branches. So you'd have to check out master probably to get it. But yeah, and then you can, you can just run up like run a vps, create a small like bash script to run the Watchtower command and run it as a human file, as a system D service.
00:32:40.404 - 00:32:52.884, Speaker E: That's what I do. And then it will alert you. And that can integrate with page duty, but also with Slack and Twilio. So you get SMS's and telegram. So that's what I'd recommend here.
00:32:53.544 - 00:33:18.414, Speaker A: Yeah, I think Watchtower is great and probably underutilized cluster wide. I feel like a lot of people don't know about it or just maybe haven't messed with it too much. So, yeah, awesome. Adding pagerduty to that. I've also been working with Ben from Cogent crypto a little bit on adding some more docs around it, so hopefully we just get more awareness out there. So. Yeah, appreciate it.
00:33:18.414 - 00:33:58.454, Speaker A: Yeah. Any, anything else people want to share? Talk about? I think my goal going forward and sort of to help shore up things for the next time is just to have more direct lines of communication with highly staked validators. Right. We have some channels, but I feel like for some of them, they may not be pinging people quite as hard as we want them to be pinging them. So setting up channels where that's a little bit more enforced, a little bit more obvious who to talk to and make sure that they get alerted when something goes wrong. And then just also talking with a lot of these validators to see what their monitoring setup looks like. Right.
00:33:58.454 - 00:34:13.294, Speaker A: If they have some monitoring in place and some alerting in place, but maybe nothing for critical outages like this. Something we want to talk to them about. Yeah. Zantesa, go ahead.
00:34:13.914 - 00:34:54.755, Speaker B: Yeah, I was really, like, gung ho about this. As is often the case after the event occurred, I had all this energy about it, but it's kind of dissipated, which I think is part of the problem that everyone, after the emergency is over, you kind of, like, lose focus. And that definitely happened with me. I've got a lot of other things I'm doing, but I certainly thought about the critical nature of this problem during the event. And it just feels to me like we could get so much bang for the buck just by making a very easy service for people to use. It has to be so branded easy that people would have to almost avoid using it in order to not use it. And if the foundation nudge people in that direction, and if it was, like, super easy to use, then I think it could have.
00:34:54.755 - 00:35:27.754, Speaker B: It could move the needle, like, I think that it could. It let a lot of people sort of become aware of a situation that they otherwise weren't monitoring. And if they don't have to be the ones to set up all the complex monitoring and someone else does it for them, and all they have to do is make their device available to be pinged by one of several methods to let them know. I think it could have tremendous benefit in those downtimes, which the other problem is that we always hope that there's never another downtime. So it's like, you know, the goal should be not to have them, which makes preparing for them sometimes feel like, you know, like, do we really need to do that? You know, we're never going to crash again.
00:35:28.694 - 00:36:00.974, Speaker A: Yeah, yeah, yeah. I completely agree. And setting up for this meeting, I was going through notes and things, and I almost forgot that the restart happened two weeks ago. Right. Like, so much stuff happens in a week or two in Solana universe that you sort of forget that a restart just happened. So, yeah, I think, like, keeping that momentum is really important. And I'm trying to do that by talking about it here and just by having meetings with different validators to make sure we don't forget about some of these things.
00:36:00.974 - 00:36:05.934, Speaker A: FP Lee, if you want to chime in as well.
00:36:07.394 - 00:36:17.286, Speaker C: Yeah. Hey, folks. Yeah, so I think I second everything that has been said. I mean, not to take anything away from the work that Michael has done.
00:36:17.310 - 00:36:17.470, Speaker A: Right.
00:36:17.502 - 00:36:19.030, Speaker C: But it's, it's quite a process.
00:36:19.102 - 00:36:19.286, Speaker A: Right.
00:36:19.310 - 00:36:33.262, Speaker C: Like, we just heard about it. You know, you've got to set it, you've got to ping him. You've got to set up this manual thing. You've got to run a bachelor vps. And it's like, I think for many values, the eyes sort of glaze over, perhaps, and maybe, maybe it shouldn't. But fact of the matter is that it does. Right.
00:36:33.262 - 00:37:07.064, Speaker C: And I think one of my other thoughts is that, you know, this, what, what Michael here is building is really a public good. And it feels like it's a bit unfair, you know, for all of this. I mean, it's great that he is doing it, but, you know, it feels like this should be bigger than, you know, big. Bigger than sort of any, any single validator, any single person. And that's kind of what, that's, that's kind of what we're trying to get at with the, you know, with the alliance, which is that, you know, let's, let's build up public goods together. You know, that, that helps to make staking, you know, better overall. Yeah.
00:37:09.704 - 00:37:58.114, Speaker A: Yeah, I agree. And I think Michael in the comments, had an idea about a one click Watchtower deployment tool that would be, I think, super useful. I'm usually against that click and deploy setup for validators because it just usually leads to less sophisticated, less knowledgeable operators. But in this case, Watchtower is such a small and straightforward thing to run that I think it's perfectly fine to just make it that simple, to click something and get it going. So I like that idea. Can we measure downtime response in terms of time taken? This could then be used by staking community to assess validators capability. Yeah, I mean, I think we do measure that.
00:37:58.114 - 00:38:26.006, Speaker A: It's something that we usually mention in the sort of the post mortem, but, yeah, it's up to the individual staking communities and stake pools, et cetera, to decide what to do with that. Yeah. So blaze sort of seconds that as well. Yeah.
00:38:26.110 - 00:38:32.078, Speaker C: I think for fundamentally, there is a bit of a, like, there is a bit of an information asymmetry.
00:38:32.126 - 00:38:32.310, Speaker A: Right.
00:38:32.342 - 00:38:39.814, Speaker C: Because validators, you guys, especially dedicated validators, the one that jump on this call know everything in and out.
00:38:39.854 - 00:38:40.078, Speaker A: Right.
00:38:40.126 - 00:39:01.504, Speaker C: And what about the regular staker that's just coming from finance or something? It's like, are they really going to dig into these response times and stuff? Highly unlikely. Is that ever going to move the needle in terms of I'm going to stick with this guy versus that guy. Do they even know this information exists? I think that's a tall order.
00:39:02.924 - 00:39:03.236, Speaker A: Yeah.
00:39:03.260 - 00:39:32.764, Speaker B: The thing I'm always kind of hoping is that we all know that there's some pretty big whales out there, and I think we all know that, like, some of the larger validators have some pretty big whales behind them. I'm always kind of hoping that, you know, that they'll take some stake away for an epic or two just to, like, send a message to the validator that, like, you need to respond better, but that never seems to happen. So if there's big guys who have huge capital behind their, validators aren't taking it seriously, I don't think we can really expect little, small, small stakers to even notice.
00:39:36.704 - 00:40:11.264, Speaker A: Yeah, I do think it is hard as a just beginner user of crypto and Defi to know even what is going on with any individual validator. I think some of the validators in the community do a good job of putting a lot out there and creating website and having content, but a lot don't. And I think most people just go for top Apy and, yeah, that's the problem we're always trying to solve, is just make stakers more knowledgeable about what's going on. Yeah, go ahead.
00:40:12.684 - 00:40:46.484, Speaker C: Yeah, so I had another question. So I believe during the outage, there was a bit of a discussion talking about whether validators should force this. Take the roughly 20% of validators that remain offline. Not 20%, but the super minority. And I think that conversation never really went anywhere because people were unable to coordinate. And I'm thinking in the future, if something like this happens, what. What should the validators do?
00:40:53.104 - 00:40:53.824, Speaker A: Go ahead, Michael.
00:40:53.864 - 00:41:28.490, Speaker E: Yeah, so now I just want to clarify. Don't think there was any discussion about forced destaking during the outage. I posted a tweet and a comment on discord afterwards about forced staking the validator that caused the outage. I don't think there's would ever be a suggestion that we should force D stake a super minority or which super minority, you don't really know until the cluster is restarted, who hasn't responded? Because that would be a very dangerous precedent. So I just want to like to be very clear, like, it's forced restaking.
00:41:28.522 - 00:41:29.294, Speaker A: Is a very.
00:41:31.034 - 00:41:38.644, Speaker E: Big step to take, and something has to be taken very carefully just for, like, being a little late to a restart, isn't it? Reason to force, de stake someone?
00:41:42.344 - 00:41:49.764, Speaker A: Yeah, I'd agree with that. There could be, you know, technical reasons why they can't get online or, you know, a lot of other extenuating circumstances.
00:41:50.144 - 00:41:56.488, Speaker E: Sorry, I just saw in the comments that might actually be what Lee was referring to.
00:41:56.616 - 00:42:40.950, Speaker A: Okay. Yeah, yeah. So through the delegation program, we do keep track of validators who are very delayed for restarts, and we have kicked people. People out in this last restart and previous restarts, but that's not quite the same as the cluster deciding to de stake a validator or a set of validators. Right. That's more like the foundation as a delegator is deciding not to delegate to certain validators who we feel like aren't performing well. All right, well, yeah, I think.
00:42:40.950 - 00:43:12.256, Speaker A: Good discussion. Any other thoughts or ideas people want to bring up? No. All right, well, thank you for all the people in the Americas who stayed up late. And we'll be back to the normal time next week, 11:00 a.m. Pacific time. So I'll see you all at the normal time next week and then back to this time in the. I'm sorry, not next week.
00:43:12.256 - 00:43:30.184, Speaker A: Two weeks from now. Back to this time, two weeks after that. Yeah, every other week we're going to do the late one or late for the Americas, early for Europe and Asia. Cool. All right, bye, everyone.

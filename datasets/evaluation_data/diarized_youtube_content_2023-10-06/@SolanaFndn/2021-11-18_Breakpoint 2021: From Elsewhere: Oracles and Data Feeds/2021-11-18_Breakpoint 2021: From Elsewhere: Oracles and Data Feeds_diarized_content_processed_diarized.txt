00:00:12.040 - 00:00:13.830, Speaker A: All right, how you guys feeling?
00:00:13.862 - 00:00:14.582, Speaker B: How you doing?
00:00:14.718 - 00:00:52.214, Speaker A: Doing great. So just to get right into it, oracles are not new. They've been around as a concept for a while, suffered massive manipulations and attacks in some of the early days. We're talking about pre on chain, even the first applications that we're trying to bring data in from the real world onto something that's a trusted environment from a trustless environment. So we'd love to just start out with quick little intros from you guys about yourselves, the projects you're contributing to, and then we'll get into some of the real questions we're here for.
00:00:52.654 - 00:01:20.504, Speaker B: Cool. So, hi, I am Mitch. I left my job at Google last year to start switchboard, which we are calling a community curated oracle, where we allow people to generate their own data feeds, choose their own sources, and let people bring the long tail of data on chain. And we want to build a massive store of information. We want to let people connect a generic data bridge from the Internet to the blockchain.
00:01:20.664 - 00:01:21.176, Speaker A: Great.
00:01:21.280 - 00:01:42.524, Speaker C: Cool. I'm Hendrik. I work at jump trading, or jump crypto, and we're co contributor to Piv network, Piff Network's price oracle built in Solana blockchain, which aims to bring first party data right from the source. So where the prices get created, meaning the exchanges, the traders on chain as fast as possible and the highest fidelity as possible.
00:01:43.384 - 00:01:53.484, Speaker D: Yeah, I'm Chris Hermita. I'm one of the co founders of Switchboard, along with Mitch over here. And we're doing our best to build the long tail data on Solana and make that accessible for developers.
00:01:54.384 - 00:01:55.232, Speaker B: Awesome.
00:01:55.408 - 00:02:03.724, Speaker E: Hey, guys, I'm Kanav. I'm the president of Jump Crypto. I've totally lost my voice, and I work with Hendrik on all the stuff that he talked about.
00:02:04.024 - 00:02:37.962, Speaker A: Excellent. So let's get right into it. There's many ways to get data on chain. There's many ways to orchestrate that coordination to make sure that the thing that's actually representing something on chain reflects the off chain reality. Both of the projects you contribute to are taking very different approaches to getting that data on chain. The nature of who can provide it and then what, actually, those mechanics of how it's either verified or distributed on chain. Hendrik, do you want to start and give us kind of a quick overview of how pith works and those decisions in architecture?
00:02:38.138 - 00:03:28.474, Speaker C: Absolutely. PIV essentially consists of one major group of participants, which is right now price providers. And these are essentially the most important players that essentially create the price. So price components come from exchanges, from traders that report their trades and they push the real time data right into Solana at the highest frequency as possible, which is Solana slot time, which varies between 405 hundred milliseconds. So essentially there's price feeds on chain that reflect, for example, BTC, USD, and these component providers will stream their view of the world essentially right onto chain. Where is it then aggregated into a price. And I think what's quite special about PIF, also into a confidence interval.
00:03:28.474 - 00:03:44.484, Speaker C: Everyone also reports confidence because what is a price? A price can vary a lot. Like markets can be super wide, there can be a huge spread, there might be a mid price, but actually you can't really trade at this price. And we're trying to reflect this view of the whole world as well.
00:03:45.024 - 00:03:51.880, Speaker A: So when you say you're talking about price feeds, what kinds of price feeds are actually, is PIF contributing onto chain?
00:03:51.992 - 00:04:03.592, Speaker C: Yeah, currently it's price feeds on equities and on crypto. Yep. So essentially mostly USD pairs and crypto pairs being bridge on chain.
00:04:03.728 - 00:04:06.280, Speaker A: So Mitch, tell us a little bit of switchboard and its decisions.
00:04:06.392 - 00:04:39.822, Speaker B: Right. So switchboard takes an approach where we just want to let anyone plug in a public API from the Internet and take a quantitative piece of data from the Internet, be able to transform it however they want, and bring that on chain. We are not specific towards price, and we don't have the proprietary sources like pith does, so we might be a little bit behind because we are using public sources like you can go in the binance.com API and get a source from them. We also allow you to get websocket information as well, so you can be a little bit faster with that whole operation. And then. Yeah, that means.
00:04:39.878 - 00:04:48.634, Speaker A: Yep, totally, of course. So when we're looking at something like that, do you consider yourself an oracle, a data feed? Do you see a difference between those two terms?
00:04:49.054 - 00:05:14.916, Speaker B: So when we are creating an oracle, I imagine that as a bridge to any off chain data, and we are just trying to make it generic for any piece of off chain data. So I see those as synonymous. Got it. Yeah. And when we actually have this, we have a set of oracles that will report the same value. We have. Each oracle take the median from multiple sources that are mapped to a single data point, which we call a data feed.
00:05:14.916 - 00:05:27.632, Speaker B: And then after all, the oracles decide what the truth is and our current setup is the median, we take the median of oracles results as well. So you would need to corrupt 51% of the sources or 51% of the oracles to edit the result.
00:05:27.748 - 00:05:54.064, Speaker A: Got it. So sticking with switchboard for a second, when you're talking about bringing data on chain, what is that sort of, is there a verification process for that? Like if I'm providing a feed for an arbitrary set of data and someone's providing a feed for what is ostensibly that same arbitrary set of data, does the developer pick one of those to go to? Does the system automatically create some sort of. This one's right, this one's not right.
00:05:54.144 - 00:06:31.642, Speaker B: So in our v two model, we are actually letting data consumers publish their own data feeds and they can actually choose each individual source they trust in their data feed. And with that, we are letting people actually choose the incentive model on how much oracles need to stake, how much they are rewarded, and how they are slashed. Since we think that it is unpredictable for an oracle provider to actually know the downstream use case, and the person actually that's consuming the data should choose the slashing mechanisms that the oracles will have repercussions to make sure their incentives are aligned with the maximum incentives of your application.
00:06:31.818 - 00:06:54.170, Speaker A: So Hendrik, you guys chose a bit of a different model that coalescing of multiple data coming from multiple providers into one data point that is done on chain, that's done in a system where the user is not picking, oh, I want the data from this provider, but they're getting one. Like, tell us a little bit why that decision was made and sort of your thoughts on that architecture and approach.
00:06:54.322 - 00:07:40.126, Speaker C: Absolutely. I think the thought behind this model was primarily on preventing staleness and getting the most transparent and up to date prices possible. So if you look at, let's say, third party price sources, let's look at Google Finance, for example, there's some price moving happening, there's delay in price feeds. Public APIs are limited, but at the same time there's also the point of maybe coming from jumps roots in traditional finance of licensing the data fetching arbitrary APIs. You don't know how the price is composed, but obviously it's also the property of whoever is providing this API. And pushing this on chain might come with certain legal implications. So with PIV, the core is to get the data from the source and have the source provide the data itself.
00:07:40.126 - 00:08:10.448, Speaker C: And that means the source is taking that right from the exchange. There's no, let's say, magic math or inertia being put into the price. It's the straight price from the market, including confidence. So you prevent, let's say, intransparency. Just on a panel yesterday, we were talking about bridges and trust. And with each party you introduce in between, it's more layers of obfuscation of what's moving, what additional math has been applied to the price versus the actual source? And the source can be a lot. The source is where you can actually trade it.
00:08:10.448 - 00:08:52.384, Speaker C: In the end, the price is an indication of what you can buy and what you can sell product of price and confidence. So in a lot of cases, this might also be on chain data, actually. So for example, the serum market, there might be a coin that is not listed on centralized exchanges, but is traded actively on serum and maybe by a couple parties, OTC. So the OTC traders would report their prices straight into the feed. And the on chain contract, actually like serum, would also report its price into PIF, where it is aggregated. So you always have first party data and you know exactly where it's coming from, and you know it's straight from the source. No, like layers of obfuscation or parties in between that are, let's say, not aligned or involved.
00:08:52.384 - 00:09:01.472, Speaker C: Like often with oracles, you have people fetching APIs, you have a price source that makes up the price, someone fetching the price, and then the chain, we take out the middle piece essentially.
00:09:01.608 - 00:09:40.854, Speaker A: So in looking at like, this is kind of another, another component of architecture design. Somewhere in piffling the project is choosing what kinds of data feeds you're adding and what kinds you're not, whereas with switchboard you are letting the user put anything in. Tell us a little bit about that decision process there. I guess the question I'm trying to get at here is data has to be of a certain quality to be usable and you've removed any sort of gatekeeping function from that. What do you see as the advantages of a model like that? Not the advantages necessarily, but the different use cases that will come from that kind of data feed.
00:09:41.994 - 00:10:34.786, Speaker B: The main difficulty with not making a generic is that it really limits who can be an oracle, because then if you actually want to get these really custom pieces of data, you have to build your own adapters, or at least in the classical sense of oracles. In this model, even if you are hosting your own data, you can host your own API and just plug that in with the ubiquitous type of language that we've built. So we have a whole system, instead of actually having external adapters where an oracle provider needs to make a really niche set of what they're configured to actually feed, they can just have a set of API keys and the code will be static. So it makes it really really simple to pick up new Oracle providers if you make this language as static as possible. So it's really a way to just lower the barrier for getting people to run an oracle.
00:10:34.890 - 00:10:53.894, Speaker A: Got it. So kind of you have. In your role as president of Jump Crypto, there are a huge number of very powerful known and unknown firms that are contributing data to pip. Talk a little bit about how that was able to be achieved. These are companies you normally don't see collaborating on anything.
00:10:54.554 - 00:12:25.364, Speaker E: Yeah, it all comes down to establishing trust between mutually distrusting participants, and that's the magic that blockchain has given us as a new means of resource coordination, as participants in the system are able to engage with the contracts according to the rules specified, regardless of who's deploying the contract right in the code. And that ability to export trust to a chain like Solana has unlocked positive sum games where only zero sum games existed before. And so a lot of our competitors in the traditional space we don't always have the warmest feelings towards, have now come into the fold and are helping us build what we think can be a really critical piece of tooling and infrastructure for crypto. Additionally, I'll say in our conversations, trying to walk a lot of these major institutions through the mental models and through the necessarily technical requirements to pull something like this off, it's really just very exciting to see really smart engineers and engineering organizations have their first interactions with private keys, with sending transactions to a peer to peer network that unlocks entirely new mental models for a whole new suite of engineers that weren't in this space before. So that's been one of the quite exciting outcomes from our perspective there.
00:12:25.404 - 00:13:07.110, Speaker A: Nice. I, in my own personal experience, have been using an unnamed fintech app, and I've seen the price of something that I've been tracking go up 10,000% and I've hit sell, and of course, the transaction gets reversed by the clearinghouse in a few days, and you're just where you were before. That's a very centralized approach, because these things are running through clearinghouses that are run by companies that have delays, that actually have the ability to go back in time and change an order. Even if the app told me that I was able to sell something for an astronomically inflated price, they'll reverse that in the future. So you can't do this in blockchain. This isn't the way things are built. This isn't the web3 ecosystem as it is now.
00:13:07.110 - 00:13:37.114, Speaker A: It's possible that someone could build some sort of system like that in the future. But talk about how people who are actually building with these, whether it's a fintech app, whether it's anyone that has to deal with data that is inherently coming from a source, that even if you are dealing with a 51% situation, even if you're dealing with institutional grade data providers, there is the potential for something to not be reflected because it's inherently coming from off chain. What should developers be thinking about when they're using any sort of oracle data?
00:13:37.934 - 00:14:30.772, Speaker E: Yeah, I can go. So that exact problem is one of the big motivations behind confidence intervals. In pit, you'll often see very sophisticated data sources print the 10,000% inflated prices due to technological bugs. No engineering organization is prone to failure. And the strong benefit of having independent pricing from dozens of major institutions is that you're able to get a sense of the dispersion of pricing and make decisions based off of that. And so if you see a flash crash on binance or Coinbase goes down for a couple hours because of exchange overload, or retail broker X prints the price at 10,000% above mock price, you're able to see your confidence interval widening out. And you're able to either alter and pause settlements.
00:14:30.772 - 00:15:03.624, Speaker E: You're able to widen the price at which you're offering liquidity on your protocol. Particularly important for guys that are offering things related options or automatic pricing amms. And that then becomes a pretty core component of how you use this data. There is no reversibility. You can have reversibility. In fact, I think synthetix in its current implementation has a six second clawback, where the price kind of reverts if the trade goes against you. And that's the contract, the staleness of the feed.
00:15:03.624 - 00:15:11.264, Speaker E: And so systems like that can be engineered. But I think paying attention to the dispersion and the quality of the data is critical.
00:15:11.764 - 00:15:12.544, Speaker A: Yeah.
00:15:14.244 - 00:15:14.580, Speaker B: Yeah.
00:15:14.612 - 00:15:16.020, Speaker A: For me, either of you.
00:15:16.092 - 00:15:57.412, Speaker B: Great. Okay. And I'd love to. I think this actually comes down to reputation of sources that you use, at least for switchforward, where people are actually the ones choosing this. We are building a curation pipeline where people are actually incentivized to get highly reputative sources in this switchboard catalog for people to use in their data feeds. And if their sources are actually reputative, then they get better rewards because more people will be publishing them in their data feeds. So we have a model where people who actually catalog and categorize the web get positive kickbacks the more they're used and trusted by the community.
00:15:57.412 - 00:16:19.124, Speaker B: So that is a mechanism we're trying to remove these distrustful sources from being propagated in people's data feeds. But yes, if it's already being used in somebody's data feed and it's already being published on chain, it does add some risk that they could tamper with the price. But we also have a min and max reported value from all the sources and all of the oracles. So you can get some idea of confidence as well.
00:16:19.584 - 00:16:21.204, Speaker A: Yeah. Are you worried?
00:16:21.824 - 00:16:46.964, Speaker D: Oh, no. The other thing I was going to add is just leaving it up to developers to make the model fit within their security thresholds and with their specific applications. Our prices and the default indexes may be good for some users, but we don't think it's going to be good for every developer. And with switchboard v two, we leave it up to the developers themselves to publish the feed or publish the index, or publish whatever they need on chain that fits the specific needs of their application.
00:16:47.264 - 00:17:17.324, Speaker C: Yeah. And I also think just really, projects making use of like price data is not just a single dimension. Price data is multidimensional. We've brought up confidence, we've brought up the price component itself, but there's way more to it. Like in the traditional equities world, we have corporate actions where there might be a stock split, and generally in crypto we have the notion of supply. Let's imagine a coin sees the success of all the dotcoins going on right now and decide to do a coin split on some protocols. That's not possible.
00:17:17.324 - 00:17:48.330, Speaker C: But I certainly think something like this might happen. And this is something that, for example, if you're running a futures exchange like derivatives exchange, you want to definitely take care of, because otherwise the price goes down by ten x and you will not do what to do with it. So really looking at the multidimensionality of data, and I think that's also why we're approaching this in a very purpose specific point, like a price feed for equities, prices might look different than a weather feed on chain or a sports like match outcome feed would look like in the future.
00:17:48.442 - 00:18:42.784, Speaker A: Yeah, I also love that because we are seeing real world versions of this. Right, keep a nucypher when you're seeing combinations, and for lack of a better terms, mergers going on in the space, there's only a time before that becomes more and more common. So you mentioned a model where people are rewarded for providing high quality data. Are you concerned about the first mover advantage? Are you concerned that the people who are first to publish to the network, and you see this, in any sort of ecosystem, the people who are first there, there's a set of arbitrary advantages that come with it. The first oracle that publishes on chain is the most used oracle. And the switching costs are sometimes hard. If you're doing a system where you're asking people, oh, what, what data would you like to use? Who's the most trusted? Are you concerned about them always picking the same one? Is that desirable? Does that increase trust? Does it decrease trust?
00:18:42.944 - 00:19:29.714, Speaker B: So I want to clarify the difference between people curating the Internet for job sources and actually people publishing data feeds that are being supported live on chain. When we're talking about people categorizing the Internet, we just are rewarding people for, for bringing these certain jobs, what we call jobs on chain, into a data feed that people can use. And if they're the first mover, that's actually beneficial. They are populating this catalog that anyone can use. So it's not that someone's publishing a specific data feed that's going to be publishing a certain set of sources that other people are just going to use and trust. It's about building that categorization and catalog that anyone can use. And if someone's the first mover to categorize binance and FTX in a really well formatted way, that people can use, I think more power to them.
00:19:30.854 - 00:19:40.034, Speaker A: All right, how many oracles do we need? I joke, but it's a real question. Yeah. Unbounded.
00:19:40.574 - 00:19:56.306, Speaker B: We want to make a bridge to the Internet. That's the goal of oracles. It should be per usage for prediction markets. They talk about a single season, you know, you might need over 200 feeds for every game. You know, you, it's unbounded and it's infinite. It's going to keep growing.
00:19:56.490 - 00:20:43.284, Speaker E: Yeah, I think there's definitely a market for purpose specific oracles, and I think the special tool, rather than the swiss army knife is probably the right choice for extremely high value transactions. So, you know, you've kind of seen this approach for financial data, for web data, you know, running wasm with some zero knowledge proofs inside a browser probably ends up being the best approach. If you're looking at, I don't know, sports betting outcomes and other data sets, that's probably a better tool that's better specified to bring that in. If you're looking at the job style stuff, that talking about something like switchboard makes all the sense in the world. There's room for a lot of different architectures, and you got to pick the right tool for the tasks that you're trying to get at.
00:20:44.664 - 00:21:13.334, Speaker A: Where do you see this space evolving? Give us. I mean, no one can say anything intelligent about probably more than three years in the future, but what's that stuff you're just starting to look at now and see, oh, this is the place oracles are going. Arbitrary data coming on was not something most people were talking about a few years ago. Confidence intervals is not something people were talking about a few years ago. These are new tools that most developers haven't even started using and integrating into their dapps. What are you looking at now for the future of this stuff?
00:21:14.434 - 00:22:06.864, Speaker D: I think a big thing is just what's going to happen with the future on chain activity versus off chain activity. This is just pure speculation, but my bias is I think you're going to see a lot more activity happen on chain in three years than you see today. Because of that, the nature of oracles are going to change. You're going to be referencing a lot more, integrating a lot more on chain data, for example, and maybe mixing that with the off chain sources as part of that. So an example would be if you're building a pricing index in the future, I think a lot more pricing indexes will rely on both dexs as well as centralized exchanges to create that composite index versus solely one or the other. And I think any oracle, at least certainly one, as generalized as switchboard. We're looking at not just off chain data, but also ways to integrate on chain data as well, and leave it up to the developers themselves to have this easy to use solution to fit their data needs for their application.
00:22:08.644 - 00:23:00.514, Speaker B: Yeah, yeah. So now I got a little more to it. You want to go? Thank you. So I actually very much agree with Chris, and in that sense, where I see more trade is actually moving on chain, I think a focus in the future is going to be real world activity, like weather data being a very important source that we're still always going to need in oracle for, and especially with NFTs, especially for event based ticketing. I think that we're going to see a lot of oracles around more ephemeral events, so sports, data, concerts, events like this. I think we could have oracles surrounding when things start, when things end, what was the attendance of this event, things like that. I think ephemeral based events and anything attached to NFTs will always need some sort of oracle backing them.
00:23:01.134 - 00:23:35.824, Speaker C: I also agree on the point of on chain data, and I think just looking at how things are going, we were talking about bridges yesterday, we're entering a multi chain world, where this information is not just present on one chain, but multiple components to price, multiple components to the outcome of certain events, is distributed across multiple chains. I see bridges playing a large role in the oracle world, not just in bringing information from the oracles to other chains to be consumed, but also bringing information in to be then combined into new prices.
00:23:37.404 - 00:23:38.904, Speaker E: I was going to say what Hendrik said.
00:23:39.564 - 00:24:20.806, Speaker A: Excellent. We're looking at price data. We're looking at arbitrary data. What's missing here, I don't mean arbitrary data can encompass a lot of things, but what are the kinds of data that either something can be derived from price, from a confidence. I guess what I'm thinking about is, like a social sentiment is in some ways like a price feed, and you can have a confidence interval in something like that. Right. The polling dials that are done for politician speeches, where they're dialing all that information in, are there ways you can bring that sort of high fidelity information on chain for things besides pricing or just data points? More soft data, subjective analysis.
00:24:20.980 - 00:24:51.630, Speaker B: Right. This was actually something that we've been discussing before. Let's say that you want to have a work of art or like a book on chain. You know, you want to ensure that integrity of that is always maintained. It's a little hard to have oracles come to agreement on something that's not quantitative. So there are mathematical operations you can do, like Lichtenstein distances on different byte strings and just choose the result of a set of oracles that has the lowest Lichtensteen distance to everything else. And that's something we've been exploring.
00:24:51.630 - 00:25:05.630, Speaker B: But it's a little hard to implement because those types of data can be dynamically sized. And with Solana, you have to actually take account size into consideration. Yes, but there is a possibility, and if we have a set allocation in bound, that's something you could do.
00:25:05.702 - 00:25:10.126, Speaker A: Great. Well, I think we're out of time here today, but thank you all so much for joining us.
00:25:10.190 - 00:25:11.414, Speaker B: Yeah, thanks for having us.

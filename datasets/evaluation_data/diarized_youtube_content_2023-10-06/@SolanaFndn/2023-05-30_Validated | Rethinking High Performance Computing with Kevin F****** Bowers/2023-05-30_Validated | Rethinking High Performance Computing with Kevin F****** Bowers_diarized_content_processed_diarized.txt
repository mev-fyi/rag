00:00:08.360 - 00:00:40.426, Speaker A: I'm Austin and this is validated today. I'm speaking with Kevin Bowers, the chief science officer at Jump Trading. Kevin and his team at Jump are the brains behind firedancer, an independent validator client for the Solana blockchain. If you're not quite sure what that means, you're not alone. We'll get into it in a minute. Here at validated, we usually focus on big ideas in crypto conversations, steeped in broad themes, with takeaways for everyone in the space, regardless of your preferred chain, regardless of your level of expertise. This episode is a little different.
00:00:40.426 - 00:01:45.832, Speaker A: In fact, its not really a crypto episode at all, its more of a computer science episode that unfolds like a heros journey into the world of high performance computing. Kevin is the protagonist, and time after time his call to adventure is can we make this computer go faster? As you'll see, Kevin is in many ways a computer science iconoclast. After a long exposition of his unconventional career trajectory, he gets into the process of building firedancer and what it means for the Solana community. If you're inclined to listen to this episode, you probably are already aware of why having a second independent validator client for Solana is so significant, but this is a point that we don't explicitly touch on in the episode, so I'd like to spend a moment addressing this. Validator clients are the actual software subsystems that blockchains run on every computer around the world. Validating blocks for Solana or any other blockchain is running a validator client today. Every network except Ethereum and Bitcoin has a single validator client, one version of the software that everyone runs, no matter if the network has 75 validators or thousands.
00:01:45.832 - 00:01:56.444, Speaker A: But this can cause big problems when something goes wrong. In fact, Ethereums multiple validator clients is the only reason the network survived two major incidents in the last few weeks.
00:01:56.944 - 00:01:59.144, Speaker B: But this episode really isnt about building.
00:01:59.184 - 00:02:33.334, Speaker A: A validator client, its about the 1% of computer science focused on making things as fast and efficient as possible. The kind of fast where the amount of time it takes electricity to get from one part of the chip to another is meaningful, and just how different this is from the kind of software engineering 99% of us are used to. If you havent heard our last episode with David Hoffman of Bankless, I encourage you to go back and listen to it. These two episodes highlight some of the most fundamental differences between Ethereum and Solana in terms of how they approach system architecture and software engineering. This is another big one. So settle in.
00:02:43.614 - 00:02:46.118, Speaker B: Kevin Bowers, welcome to Validated.
00:02:46.286 - 00:02:47.614, Speaker C: Oh, thank you for having me.
00:02:47.734 - 00:02:55.686, Speaker B: I'm excited for you to be here. You are the most requested guest that we have gotten in the six months or so we've been doing the show. Okay.
00:02:55.710 - 00:02:58.834, Speaker C: That's kind of surreal from my perspective, but okay, cool.
00:02:59.254 - 00:03:32.622, Speaker B: Folks. I think in the Solana community, in the blockchain world, they know you as the guy behind fire dancer, which is the new validator client that jump is building. We'll get into what all those kind of words and details mean. But before we kind of get into the work that you're doing now and building on the Solana blockchain, I want to start out with, how did you get into the space of high performant computing? Walk us through a little bit of the journey from college to where you are now today to then actually building an open source validator client for the Solana blockchain.
00:03:32.798 - 00:03:36.406, Speaker C: Okay. You asked me to start at college because it goes back further than that.
00:03:36.430 - 00:03:38.434, Speaker B: All right, let's go back to the beginning.
00:03:39.274 - 00:04:22.594, Speaker C: When I was really, really young, my dad worked as a programmer at a utility and would, on Saturdays, go into work and basically get me out of my. His mom's hair would take me in and just basically sit me down and tell me to be over there in front of a terminal and not touch anything. But I did touch things. It was an old IBM mainframe, and I, you know, spent a lot of time drawing ascii art and whatnot on that computer system. And, you know, you can imagine me as like a five year old trying to read IBM systems manuals and not understanding what the heck it was. But what I knew I wanted to do was essentially make the computer do the kinds of things that were in some of the first movies that had computer graphics, which would be movies like Tron. Fast forward a little bit.
00:04:22.594 - 00:05:01.198, Speaker C: There was a thing, again, through my dad's work, where they offered people to get discounts on buying a personal computer. And since they had a lot of deals with IBM, it was an IBM PCjR. And the PCJR was nominally pc compatible, but it really wasn't. It was missing a lot of features and whatnot. And that meant almost all the video games and whatnot I wanted to play didn't work. And so I started hacking the video games with things like, you know, Ms DOS debug and so forth, and figuring out how to, you know, make it do, and it'll start to operate right. And so I had some success with that.
00:05:01.198 - 00:05:31.862, Speaker C: And then fast forward a little bit when we start getting into college and so forth. I was initially interested in doing computer architecture and microchip design and things like that. That was my predominant area of interest. And took a year off school to kind of do back to back internships with intel. That was mostly just because I want to do the co op program, but they wouldn't let me do the co op program. They didn't have enough summers to do the co op program. So I just took some time off and, you know, worked for intel, doing some work there on the microchips.
00:05:31.862 - 00:06:10.270, Speaker C: And one of the things I concluded when I was there was that Moore's law was going to essentially run out of steam before my career was going to run out of steam. So I essentially pivoted into an area that was closer to maybe my native interest, which is essentially physics. I've always been a bit of a closet physicist there, and pivoted, study more signal processing, electromagnetics. And so then when I went to grad school, I was doing a PhD thesis that was basically computational physics. And in doing that thesis, I needed to solve really big math problems on computers. But I was a grad student. I had no money, so I basically had crappy computing systems to work on, and I wanted to get my thesis done in a reasonable timeframe.
00:06:10.270 - 00:06:58.636, Speaker C: But I also had all this experience from when I was growing up, hacking on computers and making them solve problems really fast and, you know, getting more out of them than people would kind of expect. And so the same thing essentially happened. I think the big thing there was I had a fellowship, and they had a little set aside saying, hey, if you're doing an experimental thesis, we have some money set aside, so you can buy, essentially, equipment for doing your experiments to get your thesis done. Now, doing a computational thing, the closest thing would be like, well, you can go buy a computer with that. So essentially, I had fellowship money set aside for buying a fast computer. So, doing what any self respecting grad student would do, I bought a what would be classified as a gaming rig for doing my PhD thesis at that time. This is also, I used to play a lot of video games, but I essentially stopped playing video games at that time because nothing really worked well on Linux at that time for video games.
00:06:58.636 - 00:07:25.728, Speaker C: And I was doing all my thesis work in Linux. And so I was never, you know, so much a hassle to reboot and go back into Windows or whatnot and dual boot, but had the system, and there's a dual core system now. This is back in the Pentium three. Era. The processors were cartridges that were on PCB's and so forth. And so I had a p 3802 of those cartridges in it. It was a really badass system for the time, but it was basically being used by doing my thesis.
00:07:25.728 - 00:07:55.528, Speaker C: But the big experience I had with that was I got it and then was like, okay, I can now do my thesis twice as fast because I have two cores. And so I'm just staring at the computer, like yelling at it to go parallel. And it didn't do anything. And so I started looking at the various libraries around. What could I do? Openmp was a thing at the time, but it was not open sourced. And I didn't have any money for licenses for software like that. Your other libraries out there that really weren't designed for doing the kind of computing I wanted.
00:07:55.528 - 00:08:30.468, Speaker C: But the closest I could find was MPI. And I found the books around MPI to be completely misleading. They would show you these examples, like, okay, here's your problem, and here's how you kind of write an MPI thing for it. And you read it, you think you understand it, then you go try to write your problem with it, and you discover that you didn't actually understand anything they were saying. And so it took me about two years to get the conceptual mindset around how you actually properly design stuff for parallel and whatnot. A lot of that's very related to the kinds of same challenges that go on in a decentralized system. But the upshot of all this is I wanted to get my thesis done fast.
00:08:30.468 - 00:09:18.144, Speaker C: It was in the first dot boom, and so I wanted to graduate and get out. And so I was heavily incentivized to figure out how to get as much computing done on that system as possible and make all that stuff work. And I did. So at the end of the thesis, things went pretty well, essentially, in that era. If I kind of go from that era forward, if you look at the overall motif, it was I was trying to solve these really hard scientific problems that needed a lot of computing power, and I got really good at making computers solve them fast. And then as things progressed in my career, people cared very deeply about my abilities to make computers run fast and what I was specifically the scientific problems I was solving with them. So immediately after I got done with my thesis, essentially, I was being encouraged to go down a path of being a professor at a large research institution.
00:09:18.144 - 00:09:59.744, Speaker C: So I went off to Bell Labs, and there at Bell Labs, I was once again in this kind of area, theoretical, computational, using computers to solve problems really fast. But Bell Labs then immediately collapsed on me. It was a fairly traumatic first career experience. It also completely derailed me from that trajectory. So what happened next was I kind of concluded the private sector was really high risk for the birds and went off to Los Alamos, which was relevant to a lot of the thesis research I had been doing anyway. And there they were, very happy. I was doing supercomputing class problems on essentially this gaming rig that at the time, literally was under the crib in the apartment we had out in Contra Costa.
00:09:59.744 - 00:10:28.310, Speaker C: And so they're like, hey, here's a real supercomputer. Why don't you go do things with the real supercomputer? And so I started doing things with the real supercomputers there. And the big secret to all this is everything is governed by this tyranny of Amdahl's law, where, you know, you have these codes, they're written, they're really slow, they're not. Well, they're not paralyzed. But speeding up any one thing doesn't help. If you have, say, ten things, you're running in parallel, and you speed up one of them, you don't get any faster. You speed up the second one, you don't get any faster.
00:10:28.310 - 00:10:49.792, Speaker C: You speed up the third one, you don't get any faster. You speed up the fourth, 5th, 6th, you still don't get any faster. Eventually you get to the 9th, you still not any faster. But you speed up the 10th thing, all of a sudden, you get 1000 fold faster. And, you know, things go through the roof. You got these hockey stick moments and kind of performance. And what you can do with these systems was qualitatively wrong and qualitatively different from what people could do before.
00:10:49.792 - 00:11:24.632, Speaker C: And so when I was there, due to various bureaucratic issues, I had kind of nothing to do for about the first two years. And so I just started writing some really, really fast codes for the kinds of problems that were relevant to the work I was supposed to do there. In doing those, the big thing that you really care about is radically decentralizing the codes. You can't afford to, to have a central thing. And this is one of the conceptual things I was having with the MPI models in the past. You can't afford to wanna scale to a million cores. You can't have one core making a decision for all those million cores.
00:11:24.632 - 00:12:01.252, Speaker C: You don't have the bandwidth to communicate the information to them. That one core doesn't then have enough information to make good decisions. That one core, even if it has good information to make those decisions with the bandwidth, does not have enough compute capacity to make those good decisions. And so when writing these codes, a lot of it was, how do I get rid of communications? How do I get the data flows optimized, how to make sure the information is the right place, right time. The thing that I often kind of point out when you look at those systems, like one of the things, this actually occurred after I was at Los Alamos. But the code I was designed turned out to be really suitable for the world's first computer to break a pedaflop. And I can go through the basic economics of it.
00:12:01.252 - 00:12:44.568, Speaker C: But skimming through all that to make that system appear was a several hundred million dollars exercise for all institutions involved. It only lasted about three years, and not because it broke or anything else like that. It's just the economics of these things are that after about three years, there's enough progress traditionally in the super chip designs and whatnot, that you can just buy a new system, and it's cheaper to do that and operate that system than continue to run the old system. And so if you look at that and then you say, okay, I want to get the most out of the system. The system has, that one had on the order of 100,000 cores. In it, you got 100,000 cores. You want to get things running well on that, and it costs you several hundred million dollars to build.
00:12:44.568 - 00:13:19.964, Speaker C: A lot of what people are taught is just absolutely wrong. Everything they're taught is wrong. The entire economic like, you are in a regime where the machine time is more valuable than the people time, if you can get 10% more out of the system, it's easily worth tens of millions of dollars to you. You can afford to actually get down into the details of the hardware, get down into the details of how it operates. And the thing here, because that Amdo's law effect, it's not 10%. You get these hockey stick moments where you're able to do radically more with it. So in doing this, I was figuring out how do you radically decentralize how to optimize the data flows, how to get really fast? That became a pretty big deal.
00:13:19.964 - 00:14:06.750, Speaker C: Shortly afterwards, the opportunity came up at a hedge fund that was interested in also exploring problems in computational physics, computational biochemistry. They wanted to design custom microchips for doing essentially protein folding calculations. And oddly enough, mathematically, protein folding calculations look very similar to the kinds of calculations that I was doing my PhD thesis and doing at Los Alamos. And so, you know, I was this weird person that had a background in chip design. I had a background in high performance simulations and parallelization and so forth. And so it was this kind of very unique opportunity did there, did that figured out, you know, a lot of algorithms, parallelization, instruction set formats, all sorts of details about that, had a good deal of success there. And, you know, in that I was living in the New York area and was getting a little bit burned out on the New York area.
00:14:06.750 - 00:14:42.278, Speaker C: And that's around the time jump came along to me and said, hey, you know, can you make our computers fast? And they're kind of secretive. So maybe in an act of hubris, my response was, I think so. But, you know, that was kind of a guess. But beyond that, they were in the Chicago area, and I was kind of looking forward to getting to a better work life balance than I was having in the New York area. So, yeah, so I've been out here, and it was a, I think, very fortunate time because the commodity stacks and what they were being designed to do, the way they were being optimized, they were at their limits, and there was a lot of slop in the trade.
00:14:42.326 - 00:14:45.270, Speaker B: Could you just define what we mean by the commodity stacks at the time?
00:14:45.462 - 00:15:32.266, Speaker C: So if you're at a trading firm, the trading firm, it's essentially buying server class hardware from big vendors, pizza boxes, they're putting them in racks and data centers, they're cabling them up with networking equipment. The way they're structured is the market rewards heavily, being first to bring new information to the market and make the market more efficient. If you're not making the market more efficient, the market will be either between indifferent to you or actively punish you. So when you're doing this, the market doesn't care. Who makes the market more efficient is just a manifestation of the fact that if I want to go buy shares of a stock, I don't care who's selling them. To me, a share is a share. And so when you're setting up these systems, you are in this death match between all the other people in the market, and you want to be there faster.
00:15:32.266 - 00:16:07.372, Speaker C: And this is not new. This is not even electronic trading. You can go back and you just look at ye olde timey videos of people shouting at each other. You know, you go back far enough. Being a tall, loud person was a substantial competitive advantage at being able to trade in a market. Then as things moved towards we're going to use phones and so forth, being able to dial fast became a competitive advantage. As things moved more towards click trading, kind of environments, things like that, okay? Some of those fast Twitch gamer skills become a prioritized, but a lot of this stuff is heavily automatable.
00:16:07.372 - 00:16:37.720, Speaker C: And so eventually those give away to people. Talk a lot now about how AI is going to automate people and all that. That's already happened in finance. So all of a sudden it's like, hey, I can replace a lot of this functionality with fairly simple stacks, like just write some things in Perl and Python and whatnot, and it will just do its job. But your competitors can do that, and your competitors can take the next step. The next step, they're going to rewrite it in a c and whatnot. Well, you take the next step, they're going to go lower level and they're going to do c and assembly language.
00:16:37.720 - 00:17:21.084, Speaker C: They're going to take the next step and put FPGA's in ASIC. And so around the time I showed up, the commodity stacks on pizza boxes based on essentially kind of vanilla C style code were at their limits for what was doable. And things were starting to head bump against the speed of light. Limitations that are just pervasive everywhere, that are just terribly ignored by traditional areas in big technology and whatnot. Like the entire ethos that goes behind cloud computing is very much believes the speed of light is infinite, and it's just wrong. So as you're getting into these things, you're all of a sudden starting to replace the tech stack, but you're at a divergent point. The divergence being what is driving the vendors like an intel, a vendor like Adele or whatnot to develop their tech stack.
00:17:21.084 - 00:17:50.312, Speaker C: They're essentially catering to the cloud computing market. They're catering to essentially lots of embarrassingly parallel jobs that aren't particularly latency critical. They want to have good power density, they want to have elasticity in their load and whatnot. And a lot of the features they're adding to their stack are very clever in that. And almost every single one is counterproductive for our needs. And so it's either we stick on commodity technology and then eventually get disrupted out of business, or we start developing our own technical stacks on top of that. And so that's where you start seeing the divergence.
00:17:50.312 - 00:18:19.440, Speaker C: And it was pretty fortuitous for me because again, that background of figuring out how to squeeze all the latency out of systems to get good scale, how to get right down to the metal and make things run very fast, and when you're also operating at the incredibly large scales, nothing works right. Debugging doesn't work, right? You can't do printf style, it will destroy your log. Like, nothing works. And so a lot of those expansion were very useful. Like, okay, the best solution in distributed systems is like, design them. So they're incredibly robust. And so that became very useful here.
00:18:19.440 - 00:19:11.982, Speaker C: And we've been able to surf that down to the point where everything is right at the limits of speed of light. Everything is at the limits of Shannon information capacity for moving information across links. Now, this is the environment now where essentially Solana shows up and asks me, from at least my perspective, the same kind of question, which is that, like, we have this complicated distributed system that we've put together. And there's an old aphorism I like to say is that inside every complex system is a simple system that worked. And so things get built on top of that, layered on top of that, but then looking at saying, hey, we really want to make this system a high performance, a reliable system, a well documented system and all that. Well, this is just from my perspective, something that I've done before that we've jumped done before in the trading context, I've done in the high performance computing for scientific computing context and so on and so forth.
00:19:12.078 - 00:19:59.640, Speaker B: You know, one of the things that really strikes me kind of about your background and just other conversations we've had previously on this stuff is the world pushes people to intense specialization nowadays. It's like, I'm going to be this one thing and this is the job I'm going to do. But, like, throughout your career, there's a whole thread of, like, I wouldn't have been able to do this stuff in software if I didn't have this hardware background, and I would have been able to do this stuff with hardware if I didn't have this software background. And there's that very interdisciplinary nature while still in the high performing computing environment that I think is just worth mentioning because so many people nowadays are forced to pick, like, oh, I just work on this one small component of this much more complicated system. Have you found that to be sort of something you intentionally cultivated, or you're just naturally curious?
00:19:59.752 - 00:20:23.264, Speaker C: That's a really insightful observation. If I go back to grad school, I had mentioned I had pivoted away from doing computer architecture to something a little bit more general and more kind of physics y, but still within the engineering departments. So when I went off to grad school, it was pretty clear that I was being encouraged to study laser physics. And laser physics is very cool. There's a lot of stuff I love about.

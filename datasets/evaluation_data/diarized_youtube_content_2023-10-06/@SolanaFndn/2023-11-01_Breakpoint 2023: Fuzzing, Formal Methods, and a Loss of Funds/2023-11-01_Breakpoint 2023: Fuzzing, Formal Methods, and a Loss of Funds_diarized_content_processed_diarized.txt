00:00:03.760 - 00:01:03.434, Speaker A: So today I'm going to be talking about a couple techniques that we think are really interesting for Solana security research in particular, fuzzing and formal verification, kind of as a prelude to this. There's actually a cool lots of funds bug that I wanted to talk about, but unfortunately, we're still. Yeah, anyways, yeah. So kind of the reason for this talk is, I think, you know, in 2022, there was a lot of money lost. I think, you know, most recently, mango lost quite a lot. I think a lot of protocol teams are thinking about, how can we make Solana security safer? And I want to take this presentation to just talk about some of these cool techniques that we've used. When I tweeted about this, actually, a lot of teams reached out and asked, how can we implement fuzzing on Solana? And I think there's a decent amount of misconceptions when it comes to how you actually fuzz protocols and what it actually does.
00:01:03.434 - 00:01:32.594, Speaker A: So when most people write fuzzers, they think this is what happens. So you write a harness, you write your fuzzer. You find the instructions that you want to test. You write your. Your framework, you run it for potentially billions of times, and then you find a bunch of bugs. And I think that's one story. But more accurately, when you're actually writing these fuzzers, I think it's a constant feedback loop.
00:01:32.594 - 00:02:14.664, Speaker A: And really, the underlying reason for this is that fuzzers aren't as powerful as people might think. So you write a harness, you run it, you have to debug the crashes. But then I think the most important step is the last step over here, checking coverage and seeing how far did your harness actually get. The way fuzzers actually work is this mutation process. I think this is the core of the fuzzing pipeline. Generally, you select a test case, you apply some sort of mutation, and you come with a new test case. Um, you know, some.
00:02:14.664 - 00:02:46.194, Speaker A: A brief, you know, mental model for how this actually looks in practice. You know, assuming you're running at 1000 executions per second, you probably get 86 million executions per day. You know, somewhere in that ballpark, maybe like 100 million, maybe a billion. But really, you know, this is not infinity, right? And these are quite simple mutations. If you. You know, if you're using cargo fuzzy, and you take a look at the actual fuzzing framework, what I have here on the right is the actual mutations. So, for example, sometimes they erase bytes.
00:02:46.194 - 00:03:19.674, Speaker A: They insert a byte. But one key thing is that there's no actual structural awareness. So the fuzzer doesn't have any knowledge of what your program does. It's kind of looking at it at a complete black box. I think another really important thing is you have to know what you're fuzzing for. So, for example, if we're fuzzing something that's written in web two, one really easy thing is malloc and free. So if you malloc a piece of data and you write to data past the end of that malloc region, that's an immediate asan validation.
00:03:19.674 - 00:04:13.244, Speaker A: Another good example is with the Solana interpreter, or the Solana BPF, you have interpreted versus jit behavior differences. I think where it gets really tricky is when you have a smart contract protocol. What does fuzzing actually mean there? What are the invariants that we actually want to test for? You can broadly say we keep all your tokens safe, but that's not super meaningful in the context of a program that's pretty hard to define. I think that's one of the key issues that you run into when you're trying to fuzz. Generally more business logic, heavy smart contract applications, it's actually quite difficult to define what you're trying to fuzz for. As an aside here, actually, for people who are using cargo fuzz, you don't actually need a lot of the traditional sanitizers. So if you use the S none flag, that means you can disable asan, which gives you approximately two x boost on your fuzzing performance.
00:04:13.244 - 00:04:39.418, Speaker A: Ok, I know that was pretty boring. Let's talk about some fun stuff. I'm in a game called does it crash? The way this game works is I'll give you some code, a fuzzing harness, and hopefully we get some audience participation here. But you tell me if it crashes. The first one should be pretty easy. We define a loop fuzzer harness, pass an integer x. If X 7331, we panic.
00:04:39.418 - 00:05:14.434, Speaker A: The question is, if we run it for a million times, can the fuzzer find this bug? Yeah. Amazing. I mean, thank God, right? If it couldn't find this bug, then we should probably give up on fuzzing entirely. Yeah, I think it found it almost immediately. Amazing. Okay, this one's a little bit more complicated. What about this one? So we pass in a data buffer, we do some stuff to it, not super meaningful stuff, and then if the length is greater than 4096, we panic and we give up.
00:05:14.434 - 00:05:37.594, Speaker A: Yeah, we do crash as well. Yeah, good point. It does depend on the input length. And actually that kind of leads into the next one. Ok. We have this input we add U 64 to it. And again, this is like all in default cargo settings.
00:05:37.594 - 00:05:58.644, Speaker A: We have a data buffer. We don't actually use the U 64, but we append a U 64 to it. Does this crash? I mean, we surely would hope so, right? I mean, it's like exactly the same code as before. We just add an extra U 64. Yeah. So we actually don't crash. And that's pretty surprising.
00:05:58.644 - 00:06:28.584, Speaker A: That's pretty bad. The reason for this is because when you run libfuzzler by default, you have a max length limitation of 4096 bytes. So if you see before we check the data length and we compare it to 4096, obviously that's a magic number, a little bit contrived. But in this case, we added a single U 64, and our program no longer found the test case. And this is actually pretty important. This has resulted in real world bugs not being found. So I took this quote from a Google product zero post back in 2021.
00:06:28.584 - 00:07:16.844, Speaker A: The context here was they were fuzzing a relatively well used cryptographic library. Essentially, if you pass in something that was larger than this fixed size, you overwrite the stack. It was like a trivial stack corruption. And this library was used in a bunch of different places. And the reason here was they just had a max length limitation. I think that the takeaway here is that there are a lot of these edge cases when you're fuzzing that you don't really think about. So when you're writing if I was case, I mean, this length restriction applies to all of your input data, right? If you're passing in Solana transactions, for example, or if you're trying to spoof Solana or harness Solana transactions, there is this hard coded 4096 byte limitation that's like up to four Solana transactions.
00:07:16.844 - 00:08:10.706, Speaker A: And if you're doing it naively or if you're doing it in a way that you don't really understand what the fuzzer is actually doing, you can really easily run into these edge cases where you think your fuzzer is doing a lot more than it actually is. Okay, this one's really fun. Does this crash? We take two integers and, yeah, we compare them against two other numbers. Anyone want to yell it out? I mean, I sure would hope this crashes, right? Quite a. Quite a simple test case, actually. The answer is no, which is kind of crazy. When I was writing this presentation, I was trying to find examples of trying to find example test harnesses that would illustrate the difficulty or edge cases.
00:08:10.706 - 00:08:40.778, Speaker A: And when I came with this, I was actually quite surprised. And to actually understand why this isn't crash, we have to take a look at, unfortunately, a bit of internal. So this is an image from binary ninja, which is a popular decompilation library. Um, you know, opened up the or w w we decompiled the actual fuz, the, the actual fuzz target. And this is the code for the relevant code. So zero x one ca three is, uh, 7331. And then 1337, uh, corresponds to xerox 539.
00:08:40.778 - 00:09:18.096, Speaker A: Right. So you can see here this, you know, mirrors it pretty, pretty closely, um, internally. The way fuzzing works is that when you reach a test case that has interesting data, you increment something. So, for example, in this case, it's the sanitizer curve trace. Yeah, it's like these sanitizer prefixed function calls. So, intuitively, if you want to tell the fuzzer that some test case is interesting, you need to reach one of these calls. The tricky part here is actually that the way this code is compiled, both of these branches happen at the same time.
00:09:18.096 - 00:10:13.744, Speaker A: So what you'd probably want to do here is you'd want to check if the first branch is true. Like if x is equal to 7331, you save that data and you tell the fuzzer that, oh, this is an insightful test case, that we want to continue to iterate on this. And that's generally how you do it when you want to construct more complex test cases as a whole. In this case, because we take both branches at the same time, the fuzzer has no intermediate state, and it doesn't actually know, like when one of the arguments is right or when the other argument is right, it has no way of telling the difference. And yeah, this leads us to a really surprising edge case where we have this, admittedly, like, super simple harness. And like, if we go back to the original example, I mean, we're literally adding one extra branch, right? You know, we pass in a second integer, and we really, really hope this should crash if we're testing our, our smart contract with it. But in this case, it doesn't crash.
00:10:13.744 - 00:10:40.386, Speaker A: Okay? If we do this, it does crash. So in this case, you can see we do an extra function call, and then this does what you'd expect. So with the extra function call, you increment coverage again. And then this tells the fuzzer that this is like an important test case, that we should save it somewhere. And in this case, the way the fuzzer probably actually mutates, this is, it generates a test case with x equals seven, three, one. And then it saves that. It's like, oh, this is interesting.
00:10:40.386 - 00:11:15.932, Speaker A: And then it continues to fuzz off of that and it generates the one, three, seven later. Kind of as an aside. Actually, an interesting thought experiment here is this data, like the let mute x zero in the for loop is actually really important. And if you don't have that there, this actually does not crash either. And the reason for this is a little bit complicated, but essentially kind of the summary is that again, it's about intermediate states. So if you only pass in a data vector. Oh, sorry, I guess this one doesn't crash, but this one, yeah, so if you don't have this stuff at the top, it doesn't crash either.
00:11:15.932 - 00:11:55.076, Speaker A: And again, it's about intermediate states. Right? So if you don't have this loop, then the fuzzer has no way of knowing, like when your data length varies. That or, sorry, it has no way of knowing that the variation in data length is important in this case. However, you know, when the data length varies, we iterate a different amount of times. And that gives the fuzzer some sort of feedback that, ok, when we increase the data length by zero x 100 or 256, this is a more interesting test case and we should save it and then continue to iterate on it. On the other hand, if we don't have it, the fuzzer is just blindly throwing in data and it really has no idea. Is a test case with length 100 interesting, or 500 interesting, or 1000 interesting.
00:11:55.076 - 00:12:34.124, Speaker A: And as a result, it makes it really, really difficult for it to generate this 4096 magic number. Um, yeah, I think hopefully this illustrates some interesting edge cases, uh, and behavior and fuzzers. Um, I think a lot of times this is a lot less intuitive than people think. Okay, now that we got through that, I think it's interesting to talk about where fuzzing actually works, right? So generally a rule of thumb is you want isolated, well defined components. Um, you know, one example would be a key data structure, right? So for example, I think ellipsis does a really good job of fuzzing where they use sokobon. That's their core red black tree data structure. A couple of reasons why this is effective.
00:12:34.124 - 00:13:00.232, Speaker A: One, it's like relatively small target, so you can run it very fast. It also has a very well defined error case, so you can compare, for example, ellipsis's red black tree implementation against a known good red black tree implementation. And that lets you decide if you have an error or not. Validator upgrades. This is another really good one. All changes when you upgrade the validator should be feature gated. This is something that we've been working on, and I'll be talking about a little bit later, one that makes a lot of sense as well.
00:13:00.232 - 00:13:26.924, Speaker A: And I think other people have fuzzed, such as fuzzing lab, I think is the RBPF Jit. Right. So this is again, a very well defined error condition. The JIt should behave exactly the same as the interpreter. Okay, I'm gonna make this a little bit light. Originally I was planning to make this validated upgrade, fuzzing like a really technical piece, but I think probably a little bit boring. Kind of the core idea here at a high level is we want to differentially fuzz slot versions before upgrades.
00:13:26.924 - 00:13:57.924, Speaker A: So when you upgrade the validator, you need to make sure that 1.16 is exactly the same as 1.14 modular feature gates. And this is really important because otherwise, if you upgrade, then you might have a chain split. I think there's a lot of things that make this a really nice target to fuzz. One thing is that when you think about Solana downtime, most of these errors are triggered by, I think, known transactions. I don't think there's people who are, or there's not that many people, hopefully, who are maliciously trying to take the spawn network down.
00:13:57.924 - 00:14:38.414, Speaker A: A lot of these are, I think most of the downtimes have happened accidentally. And that gives us some nice conditions, because that means that when we fuzz, we can also try to focus on things like known transactions. We can take the existing set of transactions and then try to mutate them and then use those as a corpus for are fuzzing. I think the second really nice property is that there's a very clear error condition. We know immediately whether something is good or bad, because we just compare the results at a high level. We generate mock transactions, we execute those transactions against different VM versions, and then we ensure identical output. I think this is a little bit high level.
00:14:38.414 - 00:15:23.428, Speaker A: There's a couple of pretty interesting or difficult questions that you have to answer here. So if we're thinking about how we actually write this fuzzer, one question is, how do you actually interact with the VM? And this is actually surprisingly difficult. Right. So if you think about it, like, some interesting things that you probably want to do with the VM are you want to invoke syscalls, you want to modify account data, you want to potentially mess with different flags on the syscalls, you want to call it with potentially large pieces of data. But if you're just generating RBPF programs to do this. This is actually like basically impossible, right? I think it's like essentially impossible that you could generate a valid RBPF program, deploy it, and then run that program. And that program does interesting syscalls and generates some valid state that you want.
00:15:23.428 - 00:16:04.324, Speaker A: And this is actually a pretty difficult question. The way we solve this problem was that we deployed kind of a harness program that does the sorts of interactions that we want. But I think this is a relatively open question for other people who might want to fuzz. I don't know if people want to fuzz it, but for other people who want to fuzz the slot of validator as well. I think the second really important question that you have to answer is where in the execution stack should you write your harness? So in general, if you think about this trade off, if you write it, if you harness more code, that means that you're executing more things, you have a higher chance of finding bugs. I think, on the other hand, it means that your harness runs slower and that you can run less test cases. There is this trade off here.
00:16:04.324 - 00:16:26.080, Speaker A: Yeah. Anyways, results we found, I think we started running this a couple months ago, already found a pretty cool bug, which is nice. And then some motivating examples that we found as we were writing the fuzzer. Yeah. So three bugs here. I put the PR numbers if you want to take a look. Ok.
00:16:26.080 - 00:16:55.718, Speaker A: Formal verification. Generally you want to prove things about code. I think we've done a lot of work with formal verification. We work with squads. In this presentation, I just want to talk about some examples for how you would actually want to prove something and maybe make it a little bit more interactive. I think one big caveat with formal verification that I would say is that you always need assumptions, and those assumptions can be pretty dangerous. Whenever you're writing your verification framework, you always need to assume something.
00:16:55.718 - 00:17:37.716, Speaker A: So you can either assume the behavior of the VM, you can assume the behavior of the compiler, that rust works correctly, or you could assume the correct behavior of frameworks like anchor or SDK that you want to stub out. I think the unfortunate issue is that there are bugs, and we found bugs at all levels of abstraction. So when you're formally verifying something, it's important to keep in mind that there are caveats that exist. Anyways, let's talk about how you can prove something like token transfer. Uh, this is something that we did with Solana Labs. Pretty interesting, more of a thought experiment, because I think transfer is, you know, relatively well known there's, you know, almost definitely no bugs there. Um, but I think it's a good example for how you can prove something that, you know, you probably want to define nice security properties about.
00:17:37.716 - 00:17:51.750, Speaker A: Um, so one way to do it. You know, we have the mint. The mint should be equal. The amount should be greater. You know, we should have enough funds, um, and that, you know, we should not overflow. Right. So this is, you know, potentially one harness that we could write.
00:17:51.750 - 00:18:11.786, Speaker A: Um, but that's actually not entirely it. Right. So, actually, uh, we. We also need to make sure that the accounts are initialized, um, which is, you know, maybe a foot gun. I think the. The tricky part of verification is that you need to be very, very accurate with what you're proving. Um, in this case, you know, our initial hypothesis, our initial harness, or our.
00:18:11.786 - 00:18:25.036, Speaker A: Yeah, our initial, uh, proof is, like, not actually entirely accurate. Right. So we forgot to initialize the counts. Um, okay, so this is actually the. The final thing that we. That we wrote. Uh, as you can see here, it's.
00:18:25.036 - 00:18:46.564, Speaker A: It's quite complicated. Um, a lot of this complexity is due to, uh, a couple things. Handling of multisig accounts, for example. So, you know, you have token transfer, but you can also have a multisig account sign that transfer, and that forces you to deal with, you know, uh, potentially unbounded amount of account infos. Um, and then there's also some complex handling around expectations. Decimals. Don't have much time here, so I'm gonna leave it at this.
00:18:46.564 - 00:19:08.020, Speaker A: But if you're interested, you should find me after the talk, and we can talk a little bit more about our thought process and how we went around verifying this. Okay. Lots of funds. I wanted to talk briefly about salon 2023 hacks. I think other people have already talked about this. I'm probably gonna make it light. I think some interesting takeaways.
00:19:08.020 - 00:19:43.094, Speaker A: One, there's been no more account spoofing. And I think that that's a testament to slam developers really understanding and using these frameworks properly. We don't have dumb issues, or, I mean, I call them dumb, but we don't have issues such as missing owner checks. I think mostly these issues are business logic related exploits, which I think is good because it shows that Solana, as a chain, is safer to write on. That being said, I think it's also important that when you're writing a protocol, you have to think about these. You have to think about a broader class of exploits. And it's important to understand where things can go wrong.
00:19:43.094 - 00:20:33.404, Speaker A: The last point is I think the amount of risk has decreased and I think this is because or one hypothesis is that protocols have improved mitigations. If you look at protocols in 2022, people were kind of flying by the seat of their pants and they had billions of dollars in protocols that let you withdraw all the money immediately. I think one thing that changed that's really promising in 2023 and hopefully its takeaway if you're like a protocol developer is that there are ways you can limit this and really there should be no way to withdraw $100 million from your protocol in one go. There needs to be a rate limit somewhere. You should be using time weighted average prices for oracles to prevent manipulation. But really at the end of the day we shouldn't let hackers get away. Withdrawing $10 million or $100 million in 5 seconds, really ridiculous.
00:20:33.404 - 00:20:40.424, Speaker A: Okay, that was pretty much it. I think we're right on time. I'll be over there if anyone has any questions.

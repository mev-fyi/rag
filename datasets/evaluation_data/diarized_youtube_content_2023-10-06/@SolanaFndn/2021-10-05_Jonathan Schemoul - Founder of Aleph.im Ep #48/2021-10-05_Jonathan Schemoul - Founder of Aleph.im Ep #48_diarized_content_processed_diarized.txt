00:00:10.120 - 00:00:19.854, Speaker A: Hey, folks, this is Anatoly, and you're listening to the Solana podcast. And today I have Jonathan Shamul with me, who's the founder of the Aleph Ion project. Really awesome to have you.
00:00:19.934 - 00:00:23.486, Speaker B: Thank you very much. I'm really happy to be here today.
00:00:23.590 - 00:00:32.154, Speaker A: Cool. How did you, you know, like, we usually start these, like, with a simple question. How did you get into Crypto? What's your story? What's the origin story?
00:00:33.654 - 00:01:30.872, Speaker B: Well, into crypto, it's a long story. I started way back in time, a bit on bitcoin, then I stopped because it was only money back then, and that wasn't the end game for me. And then I came back into Crypto in 2015, 2016, and I started doing a bit of development because I saw that I really wanted to be part of web3 to do nice things with it. So I've started developing as an open source developer for a few projects. One of these is the Nulls project, which is chinese blockchain layer one. I'm not really involved with it anymore, but working with them as a community open source developer, I saw that there was some missing links somewhere that you couldn't decentralize all the stack with just a layer one, at least not the one that they were building back then. So that's how the lf Iam project is born.
00:01:30.872 - 00:01:45.704, Speaker B: And for me, besides that, I've been developing for a lot of companies before in the IoT space and also for big banks some time ago. So I've been a developer for a lot of years.
00:01:45.864 - 00:02:04.844, Speaker A: That's great. I mean, that's a great background. So the thing that you're focusing on with Olive is this idea that web3 is just a small part of the piece, but you still need UI front ends, business logic, and things sitting that's on top of the blockchain. Can you, like. Yeah, how does that work?
00:02:06.744 - 00:02:33.676, Speaker B: The idea is that, okay, now you can have smart contracts on solana. That's great. You can even do way much more than, like, just money on smart contracts. That's great. No, you need to have a front end, so you need to have storage for that front end. And that's not all, because a smart contract, a program, doesn't have all the data that you need. So you will need some kind of indexing to get history.
00:02:33.676 - 00:03:06.960, Speaker B: You will need a backend for that. Most of the DeFi applications that we see have some centralized backend behind them. They're running on AWS, sometimes on dedicated servers or stuff like that, but it's still centralized. If a government and we just saw something about it today, wants to shut down the DeFi protocol that is organized like that. They can with Aleph. I am. What we are trying to do is decentralize the last mile because for that last mile, most projects are using AWS.
00:03:06.960 - 00:03:39.884, Speaker B: So we need to decentralize AWS. So we provide storage as in file storage for the front end files, database storage, because most applications are just databases. And also an equivalent to like Amazon Lambda where you start small functions that will be launched on a decentralized cloud where there is place for them and will get you a return value. And this can be written in any language and can access the web and also RPC from blockchains. Here, Solana.
00:03:39.964 - 00:03:40.316, Speaker A: Got it.
00:03:40.340 - 00:03:41.012, Speaker B: Obviously.
00:03:41.108 - 00:04:06.436, Speaker A: Super cool. So this is the storage mechanism. Um, does it guarantee consistency? Like how's it decentralized? Like, like what happens if you nuke it? You know, like Yellowstone blows up the current set of servers from olive, like, get destroyed in the, in the volcano. Well, how do, how do I like move, switch? What state do I lose? You know, those are the hard, hard distributed systems. Questions?
00:04:06.500 - 00:04:34.988, Speaker B: Yeah, yeah, it's a really good question. So a lot of the time is not a blockchain at all. We don't have a blockchain. There are no already we just accept messages from blockchains. Like all the supported blockchains are accepted on the network. That means that a message that is signed by an Ethereum address is accepted on the network. A message that is signed by a Solana address is accepted on the network, all our network.
00:04:34.988 - 00:05:08.616, Speaker B: Hence the name im instantmessaging. The whole system works with messages on the network. Those messages are organized by channels, just like you would go on telegram channels and get the history of them. And the network keeps track of those messages. And when you start a new node, you get the history of messages not directly from the other nodes. You will connect two blockchains to specific smart contracts. On blockchain, look at past events.
00:05:08.616 - 00:05:29.720, Speaker B: For example, on Ethereum or on Solana, you look at past events for the synchronization of the network and you look, okay, there's all these events. Okay, let me ask the whole network what those messages were. Then you Resync, and when there are missing parts, you leave them apart and then you get a view on the channels, on the messages.
00:05:29.832 - 00:05:42.210, Speaker A: So you write your software, your lambda hook, as if it's reentrant, right? So you're kind of recording your progress potentially on Solana as you're processing it for the lambda.
00:05:42.242 - 00:06:45.832, Speaker B: It's a bit different here I was explaining how the network works for the messaging on the global state. For the state of your application, you could either get your state from a blockchain here, Solana for example, all the indexing effort that we are doing is using Solana as a source of synchronization for these lambda. But then you can have multiple kind of volumes because since it's Linux micro virtual machine, everything is a volume. So we have local storage volume that is local to the running host. And then the lambda can then issue messages on the decentralized database of the left Im project or on the storage and then resting to the local file system and then issue messages etcetera. And we are also working on another kind of file system that is distributed where any lambda can write in it on the other receive the changes, which is kind of tricky.
00:06:45.928 - 00:06:55.896, Speaker A: So is the database that, the Aleph distributed database, is that byzantine fault tolerant database like, is it designed with that in mind?
00:06:56.000 - 00:07:40.522, Speaker B: Yeah, the idea is that when you send a message on the network, it gets stored by all the other nodes that are interested in your channel. And then there are synchronization nodes that go and write ashes of that data and signatures inside messages that they push on blockchains so that when overcome they can synchronize it and replicate all the data. So that even if one part of the network gets totally disconnected, you can have one part that gets reconnected to the other either through the peer to peer network, through blockchain, through apfs. We have multiple kind of different connectivity solutions so that they can reconnect on Resync.
00:07:40.618 - 00:07:53.274, Speaker A: So the olive database, if it's byzantine, fault tolerant, I mean doesn't that make it a blockchain? Like isn't, is there a token? Like is it, is a crypto economically like fault tolerant?
00:07:54.094 - 00:08:21.126, Speaker B: Yeah, so we have a token, but the token is living on multiple blockchain, Ethereum, Solana and a few others. But those are the most used today. We have a token. You need a token for your data to stay there. If you don't have any more, your data gets garbage collected. But we don't have a blockchain because we go and write on overlayer ones. So we are technically a L2 database plus computing plus storage.
00:08:21.190 - 00:08:31.798, Speaker A: But the data store, like the Olive distributed database, what is that backed by? Or is that, can I pick my own blockchain to use it as a common interface or something like that?
00:08:31.846 - 00:08:50.969, Speaker B: Well, currently it writes on Ethereum. We are working on making it write on Solana. For this we need our indexer to be super powerful and that's what. So we will get it rating on Solana very soon. Basically you can write on multiple blockchains and use it as a source of proof.
00:08:51.041 - 00:09:02.489, Speaker A: Got it. That's pretty interesting. So it really doesn't have its own blockchain and you're just using the fault tolerance of the chains you're connected to.
00:09:02.641 - 00:09:03.569, Speaker B: Exactly.
00:09:03.721 - 00:09:17.364, Speaker A: Awesome. Yeah, that's really cool. So the other challenge I think is like how do you deal with like domains and the web and like where do you run these executed nodes? Like how do you connect all those pieces?
00:09:18.184 - 00:10:07.050, Speaker B: It's a really good question to connect all the pieces together. We didn't develop some really fancy stuff like proof of space and time and things like that, to like verify that the data is really stored. We are using something much more low tech, which is just quality control. We have core channel nodes, which are the controllers of the network, which need to keep some Alef have stakers on such economics, and they are verifying that other core channel nodes are behaving well and that also the resource nodes are behaving well. And then the resource nodes are really doing the work of storing data, providing computing, etcetera. And they are continuously controlled by the core channel nodes.
00:10:07.162 - 00:10:19.370, Speaker A: That's great. So they're like, basically like a tokenized health check. Yeah, I can spin this up and they can continuously monitor whether this computation is making progress. Right?
00:10:19.442 - 00:10:19.922, Speaker B: Exactly.
00:10:19.978 - 00:10:33.158, Speaker A: Is that verification? Is that programmable? Can me as an app developer, can I kind of code up my own app specific health checks or like an interface or something like that?
00:10:33.306 - 00:10:36.894, Speaker B: It's a really good question. That's what we are working on. Exactly.
00:10:36.934 - 00:10:41.274, Speaker A: Right now I'm licking all the features, my imagination.
00:10:41.814 - 00:11:09.052, Speaker B: No, no, no worries. Well, it's really interesting because to understand if an application behaves well on one host, you need to understand what the application is doing. So yes, we will give some kind of health check, which is kind of a unit test of all the app should work. So you will be able to provide unit tests for your app, basically.
00:11:09.148 - 00:11:19.584, Speaker A: That's really cool. What about domains like actual DNS? Yeah, I'm asking all the hard questions.
00:11:21.124 - 00:12:04.694, Speaker B: So these questions will be answered if I explain how we handle access to this virtual machine. Because for DNS, for just ipfs, there is already quite a few solutions. That's not an issue. But then if you want to make a domain point to one micro vm, you want your micro VM to be able to serve your data how we do. First the load balancing, because that's the important question. For load balancing we have two ways. One, which is a regular cloud load balancing which could be blocked by government, could be censored, because that's what can happen when you have centralized point of control.
00:12:04.694 - 00:13:05.594, Speaker B: We will run it ourselves and a few of our partners might run some of the cloud load balancers that basically you can just point your domain to the cloud load balancer and then the cloud load balancer will create certificates and stuff like that. It will work. We will run one instance, Ubisoft will likely run another, unlike many other partners. Well, for Ubisoft it's not sure, it's just some talks about it, but perhaps other partners could run cloud load balancers that would go on point on specific micro VM host to see where your app is running and point it to them. That might work. Now, what happens if a government says this Dapp shouldn't work, this domain shouldn't work? Then you have two solutions. You either put the front end inside ipfs and use some ipfs gateways, etcetera, and then the back end is on the VM network.
00:13:05.594 - 00:13:56.044, Speaker B: Then it could not. But then what happens if your government blocks the specific DNS inside the micro VM global Aleph shoud whatever. Then we have decentralized load balancing that comes into play. The idea of the decentralized load balancing is that your browser will connect to the IPFS network using leap peer to peer JavaScript libertopeer find pilef nodes running, contact them directly, then ask Pilf node what micro VM hosts are running this software and then you can contact them directly. So we are working on a JavaScript library that will do all this work on the client side so that you can have your front end in ipfs that will then go and find all the backend hosts that could answer your request.
00:13:56.204 - 00:14:22.820, Speaker A: That's super cool. You guys are working on some really hard problems. So I think it should be fairly easy to kind of have a basically resolver that points to ens in the system that's fairly straightforward. And basically you should be able to use any kind of name system coming on any blockchain.
00:14:22.972 - 00:14:23.860, Speaker B: Yeah, clearly.
00:14:23.972 - 00:14:49.340, Speaker A: Do you think that this is something that browsers are starting to recognize as standardizable? Is there a future where you think this technology could start percolating to the UI level where the end user can pick, you know, blockchain based DNS resolver that links to that starts kind of like connects all the pieces right from the human human to this decentralized web?
00:14:49.412 - 00:15:24.890, Speaker B: I think that's something that could come. I think that those that could really help in this is a Mozia foundation. I think that they would be the one to talk with. We aren't in talk with them because we don't really take that step right now. We have a lot on our plate. But, but, but in the future I'm pretty sure it's the way to go and we will connect to any effort in that area and we will recognize it. I know that for ipFs, for example, IPFs, IPNs, there are some efforts on some browser extension that you can install to have it, et cetera.
00:15:24.962 - 00:15:36.454, Speaker A: Do you guys have, how does certificate chaining play in with us? What happens if I need to have a cert on my service and things like that?
00:15:36.754 - 00:15:38.250, Speaker B: Certificate on your service?
00:15:38.362 - 00:15:41.266, Speaker A: Yeah, like, you know, like verisign or whatever.
00:15:41.370 - 00:15:43.994, Speaker B: Well, we use the one that everyone.
00:15:44.074 - 00:15:47.618, Speaker A: Uses which is let's encrypt the effort.
00:15:47.666 - 00:16:05.410, Speaker B: Yep, yep, exactly. Yeah, we're using this one and we use the discovery with a content so that, so that we switch to a specific content when let's encrypt connects and then we serve this content and then we get a valid certificate and we can serve the good content.
00:16:05.562 - 00:16:07.682, Speaker A: Yeah. Can you unpack that a little bit? Yeah.
00:16:07.858 - 00:16:57.668, Speaker B: Well, let's encrypt has multiple ways to certify that you have a certain domain. For subdomains of Aleph Sh and Aleph cloud. It's easy. We are using wildcard certificates for custom domains that you could make point to your content directly. What we do is that you put a key inside your DNS to say this is the virtual machine that should be mapped to that domain. Then you do a cname to our cloud load balancer. And then the VM hosts, when they get a request for this one, they go and check the DNS to see what vm they should serve and they generate a certificate using let's encrypt for that domain and they start serving it.
00:16:57.836 - 00:17:34.230, Speaker A: Oh man, this would be really cool. But if we could have like an ENS where in my Ens registry I set my let's encrypt domain and then I run a local DNS server on my home machine where I run my browser and point that as the resolver, you could kind of tie these knots together. Yeah, it could get, that's really cool. So what happens if these instances die? Where do you guys get more hardware? Like how does that process work?
00:17:34.302 - 00:18:02.406, Speaker B: Well, an instance can just stop. Then. Then the load balancing system will find another instance to run your code. Then what happens when an instance get a request for a code that doesn't have for the micro VM network. I mean, it goes on the network checks. Okay, what is the database entry that is in front? It takes the database entries. Has there been any upgrades to it? Okay, I get the upgrades.
00:18:02.406 - 00:18:34.904, Speaker B: I subscribe using websocket to the upgrades of this database entry. Basically because it's a document database entry. And then it looks okay, so this is the root fs that I should load. Do I have it? I have it. Could I use it? If not, I download it from the network, I apply that root fs. Where is the code? Okay, what volume does it need? And it builds in retrins it and it gets you the answer for a cold call. Start with no root fs or whatever.
00:18:34.904 - 00:18:51.432, Speaker B: It can take a few seconds, but in general you use the same root fs as others. So you can get a cold start. If you don't have the code, it's less than a second. If you already have the code of the application, it's like 150 milliseconds for a cold start.
00:18:51.568 - 00:19:05.424, Speaker A: Got it. And is the coordination to decide where to start this particular instance, does that occur over like the underlying chain, like Solana or Ethereum or whatever?
00:19:05.504 - 00:19:52.896, Speaker B: So again, that's something that we are working on at start. It's on the cloud load balancer. So the cloud load balancer are semi centralized for that. The idea is that each micro VM running node that starts running one will register a message, which is a database entry with a reference to say I am running this one. And then the cloud load balancer looks at the uptimes of the available micro vms and say, okay, this micro VM has it ready, I'm forwarding it to it. And then if there is none, then it will just route it to like a random one that has a good uptime. And then this one, the next time can be chosen automatically because it is already serving it.
00:19:52.896 - 00:19:57.390, Speaker B: If there is a lot of requests, it will provision multiple ones.
00:19:57.502 - 00:20:35.774, Speaker A: Interesting. Got it. And you anticipate that you'll basically be able to move. If the underlying chain is cheap and fast enough, you should be able to move the coordination and kind of like, hey, start this instance, pull this volume. This would be really cool with like Arweave backed storage volumes because you could almost then see the lifetime, the lifecycle of the application as its business logic is evolving. That state is very useful to developers or being able to go back to a checkpoint effectively at any given time too.
00:20:36.274 - 00:20:51.242, Speaker B: Well, right now we are using our own storage engine, which is IPFS compatible. But in the future we will allow to choose over storage engine and we will also develop gateways with Arwi, Filecoin and others.
00:20:51.338 - 00:21:25.534, Speaker A: Super cool. I used to work at Mesosphere, so I don't know if you heard of them, but like our D two IQ now this was like a kind of Kubernetes competitor, like trying to build this like the decentralized operating system using mezos as the jobs kind of queue engine. There's a lot of similar challenges there. And this is really cool that you guys are building this in a decentralized web application that's kind of hosted in the mythical, the real cloud, right?
00:21:25.654 - 00:21:41.854, Speaker B: Yeah, well, there is a saying like there is no cloud, it's just over people computers. And here it's really over people computer. So it's pretty good because then you don't trust those computers because you know it's over people computers.
00:21:41.974 - 00:21:52.328, Speaker A: How do you guys ensure the integrity of the computation itself? Like, how do I know that the virtual machine, the execution environment that's running, isn't malicious?
00:21:52.456 - 00:22:45.634, Speaker B: It's a really good question. So there is multiple questions there. How can I ensure that this computation isn't returning a bad result because it knows who is on the other end? The load balancing system ensures that you don't really see who is in the other end, so you don't know who is making the request, so you don't know if it's a quality control call or if it's a real call. So it goes back to your question of the testing of the application, and there is another one there, which is the question of the secrets, because you might need secrets if you want to do push notification based on a smart contract event on Solana, let's say, because that's something that we are working on right now thinking about it.
00:22:45.674 - 00:22:46.774, Speaker A: That's super cool.
00:22:47.514 - 00:23:29.762, Speaker B: So like, you will need secrets, you will need to store a secret to being able to go back to this device and send this device a notification. So you either store secrets in the local storage of the instance, but then if the instance dies, you can't get it back, or you try to get shared secrets between multiple hosts. We are working on it. We don't have a total answer on that. What we are working on is using threshold cryptography, so that multiple hosts defined by the developer can handle these secrets. And then you go back to a question of trust, which is problematic by threshold cryptography.
00:23:29.858 - 00:23:41.470, Speaker A: Is this like an NPC to compute, or are you guys thinking like BLS or schnorr aggregation more like you encrypt.
00:23:41.542 - 00:23:45.246, Speaker B: Something that can be decrypted by multiple private keys.
00:23:45.310 - 00:23:45.974, Speaker A: Got it.
00:23:46.094 - 00:23:52.894, Speaker B: And then if they want to send a message, it needs to be signed by at least X of Y.
00:23:52.974 - 00:23:54.694, Speaker A: Right. Got it.
00:23:54.854 - 00:24:37.174, Speaker B: Because this microvirical machine can also send messages on the network, and these messages on the network will be database entries that in the end might end up also on chain using oracles or whatever, because this micro vm can read from on chain data. And the idea is that work, we are working so that they can also write on chain as well. So then you might need some kind of trust somewhere. So one developer could say, I trust this us, but they need at least to do that calculation three times, let's say. But it's a bit problematic and we are still working on it. It's not finished yet. So.
00:24:37.334 - 00:24:58.554, Speaker A: Yeah, I mean that's a really hard problem. Yeah, really cool. Yeah, the secrets thing is really challenging. What do you guys, I guess, what's your vision for this? You guys are tackling on some really hard problems. You get all of them done in the next, you know, year.
00:24:59.214 - 00:25:00.554, Speaker B: I hope so.
00:25:01.294 - 00:25:05.982, Speaker A: And like, what happens then? Like what is the vision for, for all of.
00:25:06.118 - 00:25:33.622, Speaker B: Well, here we are only speaking about a few crypto issues. We aim at bigger than just the crypto ecosystem. What we really want to do is decentralize the web. So getting bigger, way, way bigger, that's the goal. We are working with a few bigger partners. We are part of the Ubisoft entrepreneur labs, for example. We want to have a lot of hosting partners in the game that start providing resources.
00:25:33.622 - 00:26:38.124, Speaker B: So that I want it to be as easy as spinning up AWS server or whatever you would just spin up vms on the network. I want it to be as easy as using Firebase, using Amazon Lambda, etcetera. And we have another big project going on, which is the indexing on Solana, where we are indexing data for a few protocols. Current iradium, we might have another already soon. Well, I can't say the name. We are working a lot on Orca, on port finance right now, and a lot of others actually, that I can't really talk yet, but the idea is to have all this data available, have all these data feed coming up, so that you can have events based on them, and also do off chain computation and things like that. I really want DeFi to be totally resilient, because until it's totally decentralized, you can't stop DeFi when it's totally decentralized.
00:26:38.124 - 00:26:45.678, Speaker B: You can't. And if there is only the smart contracts that are decentralized, you can still stop it.
00:26:45.836 - 00:27:24.278, Speaker A: Yeah, that's definitely a fair point. I think the UX issues around building also just push notifications and all these other things for projects are really hard to overcome if it's a decentralized project, because who's going to host those servers to connect to mobile and everything else? Yeah, you guys have a lot of work set out and it's pretty exciting. Um, what do you wish, uh, what do you think is missing? Like if you guys had like another, somebody else was building this other piece that you think is missing in the web3, what would it be?
00:27:24.366 - 00:28:25.848, Speaker B: What is missing today in the web3 is a fuse of all this. We are trying to tackle this, but we have so much on our end. So this is a big issue. Is a fuse for developers, is a fuse for users? Well, a fantom is already doing a great work on that and on Solana, but yeah, this and also I think that there is some kind of breaks between the in defi if you want to move money into the real world, it gets hard really fast because there has been some kind of complication that have been put in place by regulators, by bonds, by whatever. If we could just get all these parts simpler, it could be great. Like some kind of link between fintech and crypto that would work everywhere in the world, including Europe, USA, et cetera, it would be great. There are a lot of people working on it, but that's something that is missing as well.
00:28:25.936 - 00:28:42.444, Speaker A: Yeah, identity and like having those easy ramps. Still, still hard. What about DNS? Just straight up resolving. Do you think that's tackleable from a web3 perspective?
00:28:42.784 - 00:29:22.496, Speaker B: The issue is the way DNS is done. DNS protocol is great, but it implies centralization points, a lot of centralization points, which are problematic. Then you would need another standard than DNS. But if you have another standard on DNS, then you have the issue that the network right now is not done for it and the browser don't understand it, etcetera, on operating system don't understand it. So we would need gateways for that. I think it's doable. It's definitely doable, but it's a lot of work.
00:29:22.496 - 00:30:17.464, Speaker B: And you would like have, you would need multiple root servers and even virtual root servers like what you said, local DNS server that will resolve your request. It could work if, let's encrypt could understand it in the same way it would work. Or we could even have something different than the root certificate that we have today, because with blockchain we already have private keys, we already have signature. So if you sign your content with your private key, then you can verify it on the other end. And you don't really need all these change of certificates that are here today. So that could also be another solution. But it would need another way because right now we like have root certificate, children's certificate, etcetera.
00:30:17.464 - 00:30:30.616, Speaker B: And it all goes back to like central authority. The whole DNS on certificate system today goes with authority. And with blockchain we are trying to remove authorities.
00:30:30.760 - 00:30:55.744, Speaker A: Yep, yep. Do you guys see this as becoming developer facing or maybe someday eventually, kind of like client facing? I want these decentralized applications running for me, like kind of my own instances or is this always going to be here? Here I am, you know, team orca go to this domain. And as a user, it's a good question as well.
00:30:56.524 - 00:31:39.104, Speaker B: It's always the issue, like between hosted components, locally run components, and kind of pragmatic on that at start, I would really like to like, everything runs inside my browser. Everything works. That's great. In reality, you have mobile phones, you have tablets, you have computers, you have a lot of range of devices that can be running all the time. So real peer to peer application can't really work that well unless you like, go and say, okay, while you are waiting for me, please send it to my friend that will forward that data for me. Etcetera. On blockchains are really helping.
00:31:39.104 - 00:32:26.660, Speaker B: There is that we have a centralized authority, which is the blockchain that you can trust and that can hold data for you and can even hold it encrypted for you or store it on LF, IAM, whatever, and only you can decrypt it. So I think that a mix between the two would be good, like self hosted data on remotely hosted data on a decentralized cloud. A good mix of the two could be good on the efforts by the lib peer to peer team with the GRS script, lib peer to peer, and there are a few others. Like that helps because once you have access to a peer to peer network directly from your browser, you can cut middlemen, you can't cut central authorities, etcetera. If you have a blockchain that serves as a central authority, what kind of.
00:32:26.692 - 00:32:36.930, Speaker A: Loads have you guys seen or been able to test this out? Like in terms of like, you know, users requests per second, kind of websocket connections per second?
00:32:37.042 - 00:33:35.954, Speaker B: It depends because when, when it's per server, that's not that much of an issue because, because the micro VM supervisor just forwards like the request to the underlying software. If you don't choose a local persistent volume, the supervisor can run as many instances of your program as needed and then it can spawn up multiple one even inside the same supervised cluster. And then the network, if it sees that this one has issues ending the request load, it can load new ones. So I don't think that there is really a limit on the request per second for that. So it's not really the issue that we have. And then on the database part same. If you access one API server and you give it 500,000 requests per second, it will go down because it's a server.
00:33:35.954 - 00:34:08.418, Speaker B: If you target multiple API servers you are good. So that's also where the decentralized load balancing helps. Because if you use a cloud load balancer, obviously even this cloud can go down. But if you contact a peer to peer network to know what host can answer, then you can contact multiple hosts. And all our core channel nodes, we are currently 54 of them are also API servers that users can connect to to get the data which will be certified by a core channel node.
00:34:08.546 - 00:34:18.778, Speaker A: Cool. As a whole, how many, I guess, do you have an idea of how many users per second or humans per second have you guys served in some peak times?
00:34:18.906 - 00:34:34.184, Speaker B: We don't, because we don't store matrix currently. We should, we don't have it because we didn't want to like have any kind of log or whatever on the users, but we could make it, we should add it. That's actually a good point. We will.
00:34:35.444 - 00:35:15.748, Speaker A: Yeah, yeah, yeah. I mean like I think it's, you got to be really aware of privacy and how that impacts some applications. But really interesting to see this works. Caching is like another one of those things like basically having a distributed cache around the world for often query data. And this is an issue that I think doesn't have a good solution. In web3 right now. You do all this work, set up a purely thin client that's loads from code, only, talks to the chain and then you got to go fetch assets.
00:35:15.748 - 00:35:23.476, Speaker A: And if you're using centralized cache. Yeah, like they can basically inject.
00:35:23.540 - 00:36:18.696, Speaker B: Yeah, that's the main issue here. The good part is that if you also randomize where the request of the users go, if there is one bad actor, it will only inject bad data once in a while, you don't even know where. And once there is a quality control it will detect it. So that can also be a solution. It's not a silver bullet either, but it can definitely help. So like for Solana, what we are doing right now for radium, for example, is that we have an indexer that talks to multiple RPC of Solana and then get the transaction history, store it inside a level DB inside the micro VM and then index the data and then we can get that on the pools, latest trades and stuff like that. And the idea is that if there is too much request on one indexer, it will start another index or another index, or another indexer, et cetera.
00:36:18.696 - 00:36:26.024, Speaker B: So that when you do a request, it will route it randomly to multiple hosts that have the same index.
00:36:26.184 - 00:36:27.684, Speaker A: How fast is that?
00:36:29.104 - 00:36:33.442, Speaker B: Not fast enough currently. Well, it's fast enough for radium.
00:36:33.608 - 00:36:34.398, Speaker A: Okay.
00:36:34.566 - 00:36:35.954, Speaker B: It works really well.
00:36:36.614 - 00:36:46.914, Speaker A: Radium gets some, a ton of hits. I mean like some of their idos have seen, you know, half a million requests per second peak.
00:36:47.374 - 00:37:21.376, Speaker B: So for the radium data, it under like all the trades, whatever, it unders it pretty well. We don't get behind blocks in the indexing, so it works well for serum. It's a bit more problematic because you need to like watch their even queue all the time. I really hope they will have some kind of logs in the future. I think that they are working on it, so that would really help us to be able to get history even when we aren't watching their event queue.
00:37:21.480 - 00:37:50.050, Speaker A: Yeah, sorry. Not have a million per second, half a million total, which is quite different. But yeah, they see some really good traffic. Cool. I mean that's really cool. I think really hard part, I think in designing these systems is one is the problem is difficult. But then once you build the first version of it and you start hitting real traffic, there's a lot of parts that fit together that break under load.
00:37:50.050 - 00:37:59.518, Speaker A: So what is your debugging? How do you guys actually monitor, like debug pagerduty? What do you guys use as a team right now?
00:37:59.566 - 00:38:21.072, Speaker B: Our team is still small. We are growing a lot right now. We are like ten developers. A few months ago we were only three. A year ago I was alone. So we are growing really fast and we are putting all this into place right now. Everyone monitors and checks what happens on, unlike helps.
00:38:21.072 - 00:38:40.684, Speaker B: There is Hugo who is on the micro VM side, Ali who is mostly on the indexer side, myself who is looking at everything. But we are putting real stuff in place right now to have it because we are a growing startup, so it takes time to get everything in place.
00:38:41.264 - 00:38:46.096, Speaker A: Yeah, for sure. Do you envision a pagerduty team for.
00:38:46.120 - 00:38:57.714, Speaker B: This, I think that we will need one. Once we have more applications that are using it, we will need one. So yes, if you have advices on that, I'm really happy to get them.
00:38:58.214 - 00:39:33.356, Speaker A: I mean, this is just part of life. It's not complicated, it's just work. This is, I think that response team, I think is a difficult thing to set up in a decentralized community. If you guys are building like a decentralized network with providers that are supplying hardware and all this other stuff, those are the folks that we found to be really responsive and have a lot of stake in growing this. How do the economics work for all the people? Actually supplying the hardware and bandwidth is such a.
00:39:33.420 - 00:39:55.244, Speaker B: So again, the resource node economics aren't live yet. We are working on them. The core channel nodes. Economics is already there for like a year now. It's spread. It works well for the core channel nodes. You need to have like 200,000 Aleph to start a node and 500,000 Alif staked on a node so that it can start to run.
00:39:55.244 - 00:40:29.276, Speaker B: And then all the node operator get a share of a global envelope daily for all the nodes. And all the stakers get a part of the envelope. For stakers, the more nodes active, the bigger the envelope for staker is. But then for each node, they will earn a bit less if there are more nodes, because the global envelope. So it helps stakers grow the number of nodes that are active. So that's for the core channel node. For the resource nodes to get storage or computing on the network, there is two ways to get it.
00:40:29.276 - 00:41:12.454, Speaker B: One that is already live, which is hold x amount of rf and get that amount of storage. Hold X amount of rf on like have the ability to start one vm with x, a megabyte of ram, Higgs, virtual cpu, et cetera. And then the multiplier. And all that gives you the total count of micro virtual machine that can be running on your network based on your balance. The good part with that is that partner project could use a lending protocol to borrow Aleph while depositing their own token to get service. And they would get the service for free, just paying interest in their token inside the borrowing protocol.
00:41:12.494 - 00:41:13.214, Speaker A: Got it.
00:41:13.374 - 00:42:05.174, Speaker B: So that's a way for protocols to get it, but it's quite expensive because they don't directly pay for it. So for this way of using it, the LP IAM network is paying for them from the incentive pool, which is like right now it's one fifth of the supply and we are changing it in the next few months, we'll change a bit of economics. It will be nearly, nearly half of the supply that will be dedicated to pay for that. Because since you lock a part of the supply, then you can release a bit inside circulating because of this new use. So that's for the old XRF tokens. And then there is another way that isn't developed yet that we will likely use Solana for because it's fast enough for micro payments in that area. It's like pay per action, like pay x Aleph per gigabyte per month.
00:42:05.174 - 00:42:30.514, Speaker B: You as a provider, you can say, I am okay to be paid at least that much. And then users will say, I want my data to be replicated at least four times and I'm okay to pay at most that much for this. And then it gets divided by those who provide service and the payment is done as micro payments. And same for the micro Vm. You pay per se, pay per hour, etcetera.
00:42:30.594 - 00:42:56.746, Speaker A: Got it, got it. That's really cool. Well, this has been awesome to have you on the show. I mean, we got into like, I think the really deep, deep tales of how Aleph works. So I had a blast because it really reminds me of the, you know, the spending, working on the stuff for centralized systems. It's really cool to see this kind of built ground up for decentralized ones as well. So appreciate the work you're doing.
00:42:56.746 - 00:42:57.122, Speaker A: Thank you.
00:42:57.138 - 00:43:01.938, Speaker B: Jonathan, thank you very much for having that call. It was really great talking with you.
00:43:02.026 - 00:43:08.454, Speaker A: Awesome. And good luck to you guys. I mean, startups for blood, sweat and tears. So just keep, keep working on the vision. You'll get there.
00:43:08.994 - 00:43:10.426, Speaker B: Thank you very much.
00:43:10.610 - 00:43:11.814, Speaker A: Cool. Take care.

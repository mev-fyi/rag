00:00:06.720 - 00:00:41.434, Speaker A: Awesome. Yeah. Thanks, everybody, for joining. It's great to see those of you with your webcams on. Thank you to those of you guys who kicked off the community led spontaneous roundtable in my absence a couple weeks ago. Appreciate that. And, yeah, I just kind of wanted to take a little bit of time today and just, you know, reflect and say thanks to everybody for a pretty amazing year.
00:00:41.434 - 00:01:36.864, Speaker A: It's been like, I don't know, it's been a hell of a ride, I think, for me, for everybody, you know, and the growth of the network, the challenges that we've been through, the learnings that within the foundation team and on the Solana lab side, and everybody on the community, it's just really been incredible and humbling to see, like, everyone come together. Right. There have been incredible challenges and victories and triumphs and tears and. Yeah, we couldn't, couldn't do this without you guys. I know I say that all the time, but, you know, it's true. I mean it like, and I know we can't keep everybody happy all the time. Right? That's kind of the nature of this beast, right? This is, this is your network.
00:01:36.864 - 00:02:48.894, Speaker A: So it's just really great, you know, to see so many of you guys taking, taking ownership and, you know, kind of taking pride in helping to run the network and helping curate resources and, you know, applying pressure where needed on both the foundation and the validator community to, you know, keep everybody doing their best. So just onward to bigger and better things. One thing I did want to call out, which I think was just pretty cool announcement, we just announced this a few minutes ago on Twitter. We've got a blog post that went out. Thank you to Andrea on the foundation team. I'm not sure if he's here on the call for helping to organize some of this, but the foundation has made donations to a carbon offset program to make the entire Solana network infrastructure, validators and RPCs carbon neutral for all of 2021. Thanks, igor.
00:02:48.894 - 00:03:50.094, Speaker A: So, yeah, I just kind of wanted to let everybody know that the Solana network already has, relative to other larger, more, I'll say, more traditionally flavored blockchains already has a very low energy consumption footprint, the vast majority of which is driven by the validator and RPC infrastructure. And so we. The foundation recently released sort of an energy usage report for the Solana network. It came out, I don't know if someone has a link to the, to the blog, if you wouldn't mind posting it in the chat for if anyone missed it. So in addition to sort of highlighting the already low usage of energy by the network. In addition to that, we are committing to keep the network itself entirely carbon neutral for the foreseeable future. So this year that was done by purchasing carbon offsets directly from the Solana foundation.
00:03:50.094 - 00:05:28.904, Speaker A: Going forward, what I hope to see is, and we're going to have some more community discussions about the right way forward here in early 2022, are basically various initiatives and programs that could be really driven by the community to help incentivize both validators, RPC operators, as well as wallets and dapps and individual users to optionally make a contribution to offset any energy usage associated with a particular transaction or the operation, the ongoing energy consumption of a particular node. One idea that I had, and this is not binding by any means, it was just something I've discussed within the team and would love to hear some other thoughts from the community as we start to flesh this out, is this idea of effectively a verifiable address on chain to which any token distributions or transfers into this address can be verified to be associated with either carbon removal or carbon offsets. So, you know, if you deposit $1 or one sold or whatever. Hey, thanks Mike. Take care. Merry Christmas. If someone, either the foundation or a validator or user, deposits a certain, you know, any amount of tokens into a particular address, that they can be verified that that equivalent amount is going to go ultimately to either carbon removal or carbon offsets.
00:05:28.904 - 00:06:57.834, Speaker A: And so what this does by moving that initial contribution on chain would be to, again, like, provide verifiable history of any particular donations, either by foundation or any other entity. So one thing we could possibly do with that is if a particular validator is interested in, say, offsetting the energy usage of their node or any particular service could, say, earn some green badge NFT or energy carbon neutral NFT that is programmatically generated or issued based on certain contributions to a validated on chain address. People could choose to then adjust the delegation strategy potentially based on presence or lack of presence of, say, energy offset nfts. If you wanted to have something like a carbon neutral stake pool, for example, then we'd have some verifiable way to inform a particular part of a delegation strategy. Again, none of this is binding, this is just early stage ideas that we're still kind of thinking about. But yeah, just kind of wanted to put that out there. So I'll pause there.
00:06:57.834 - 00:06:59.414, Speaker A: Yeah, Zantetsu, a question.
00:06:59.874 - 00:07:30.214, Speaker B: So two things. First, just want to remind everyone there may be people here that are not validators. Last time we had an impromptu meeting, a reporter came in. So I think everyone should speak freely and no one should avoid any topics. But just choose your words carefully because reporters like to sensationalize anything they can. So that's a reminder to everyone. But second of all, the carbon neutral, you said that the foundation already paid to offset all of Solana's validators energy usage for 2021.
00:07:30.214 - 00:07:31.234, Speaker B: Is that what you said?
00:07:31.934 - 00:07:32.622, Speaker A: Yes.
00:07:32.758 - 00:07:37.194, Speaker B: So is that something you expect to do going forward, or. That was sort of just for 2021.
00:07:37.854 - 00:08:48.864, Speaker A: So we're committed to keeping the network carbon neutral going forward. What I hope to see, sort of what I was just sort of brainstorming a little bit earlier is like, what I'd like to see is carbon neutral initiatives that are a little more, say, driven by the community, or if there are incentives, either social, financial, or out of altruistic for node operators or RPC operators who want to offset their own equivalent emissions. And again, it's different for every operator, and depending on what country you're in or where the energy comes from, it's a hard problem to solve. But what I would prefer not to see is to say, okay, well, the foundation is going to do this unilaterally, and we're just going to continue to throw money at this problem year after year. That's certainly not my goal. I'd like to see some sort of, I don't know, movement in which the community is engaged and has their say and involvement in making and helping to make this happen.
00:08:50.804 - 00:09:08.804, Speaker B: Yeah, because it's an interesting issue. Because, of course, it's great. I mean, I think it's great you guys did this. It's wonderful. But of course, then if individual validators, that was going to be one of their sort of differentiators, then they no longer have that differentiator because now it's kind of blanketed for everyone. So I don't know, there's a little bit of, you know, give or take there.
00:09:09.264 - 00:10:47.254, Speaker A: Right. Yeah, no, that's a fair point. You know, that was sort of what I was maybe alluding to this idea, and I think this actually part of a broader sort of, I don't know, technical addition that I hope to see in the Solana ecosystem soon, which is this sort of idea of like, effectively like, delegated nfts, which I think some people like, have seen these as like certificates. Right? So say you complete an online course or you complete some training, and the issuer who runs the training issues, you an NFT that says, oh, you've, here's proof that you completed such and such a verification or whatever. So for like educational credentials, for example, this is an NFT that is one not transferable, but also not directly purchasable by the recipient. It's issued to you or delegated to you by some third party. So one of the ideas, so if that piece of the stack comes together, and I think there might be a couple of teams already working on this, we could kind of tie that to, oh, if a validator chooses to offset their equivalent emissions by doing something unchained, say making a contribution to a particular address that's verified to use the funds in a certain way, for example, then maybe there's a smart contract that delegates a non transferable NFT to that validator that says, yes, this validator has paid x amount and therefore it has offset its emissions for the year.
00:10:47.254 - 00:11:27.264, Speaker A: Anyone who might choose to do that gets that NFT. If the foundation, say, covers the difference, then the network remains carbon neutral. But those validators who chose not to participate may not get any, I'll say, social or state delegation benefits associated with having pony it up themselves. Again, just an idea. None of this is binding. There's obviously a lot of intricacy there that still needs to be worked out. But I just think it would be kind of a cool model to see and really put that onus into the hands of those who really own and run the network, which is you guys.
00:11:35.764 - 00:12:27.504, Speaker B: So another thing, I think it's a great idea to have that concept and use it in other ways. Like we've often talked about maybe some kind of fund that larger validators can contribute to that somehow helps offset voting fees for new entrants or small validators because, well, recognize the, or a lot of us recognize the inequity of voting fees that are mostly going to large validators and mostly paid by small validators. And maybe there could be, this could be another mechanism for something like that, is all I'm saying. It may have a myriad of uses to have some mechanism for setting up these kinds of funds that have, because, you know, if you do that, generate that, if you make that donation, it's nice to get, and then you can sort of like at least show that you did it because you have the NFT that demonstrates that it was done. Unless you just want to be anonymous, which is even more altruistic. But anyway.
00:12:29.324 - 00:12:50.154, Speaker A: Yeah, definitely. Yeah, I think there's really a ton of applications for this. Yeah, this like delegated, non transferable NFT idea. Right. And it can go well beyond just particular validators. But you know, you guys are always on my mind. So this is what I tend to focus on.
00:12:50.154 - 00:13:32.098, Speaker A: One idea that we've sort of kicked around a little bit is like effectively a whole series of delegatable nfts that represent certain performance benchmarks or certain participation things. Right. I'm thinking about the foundation delegation program in this case. Right. We've got a whole matrix of requirements, and certain requirements are needed to get a certain amount of stake and more requirements for other stake. And if each of those requirements, say, was boiled down to either the issuance or removal of a particular NFT. Right.
00:13:32.098 - 00:15:01.314, Speaker A: Oh, you got the voting credit NFT, you got the data center decentralization NFT, or the low commission NFT or whatever, that these might be issued and removed by the foundation and any other person, anyone can create an NFT and send it to you or delegate it to you. But I was sort of envisioning like, oh, instead of having to parse through certain metrics, dashboards, if people or certain the community understands the ways in which these nfts are added or removed could inform, perhaps I'll say, more intricate delegation strategies enacted by third parties or other stake pool operators. Say, oh, filter by everyone who has XYZ NFT and not this one and other on chain metrics, for example. It just might be an interesting way to do some of this, almost sort of like indirect analytics on chain to filter out certain people or certain nodes based on really any arbitrary criteria. So I think it'll just kind of be interesting to see how this unfolds and how the community might choose to, you know, apply this to securing the network. Cool. I'm going to stop talking now.
00:15:01.314 - 00:15:09.074, Speaker A: Stephen, would you have a few minutes to talk to us about some of the tech milestones?
00:15:11.054 - 00:15:11.794, Speaker C: Sure.
00:15:12.334 - 00:15:17.064, Speaker A: So we've got Stephen Akritch here, who's one of the senior Solana labs engineers.
00:15:18.964 - 00:16:08.388, Speaker C: Yeah, I just wanted to give some updates on the stability fixes and things that we're looking at. The main, or one of the main problems is we see that, you know, when we get the block size is too large, right. There's too many transactions or too much work that can cause, you know, forking and higher skip rate and. And basically instability overall. So we shipped the cost model already, right, in 1.8. That puts limits on the block size for certain operations. We're still looking to tweak that either in the overall limit or where we see transactions are taking up a longer time than we expected them according to their, to their cost.
00:16:08.388 - 00:17:41.069, Speaker C: So that should kind of clamp down when the timings on the block replay are good, then we should see less forking and bad behavior in the network. And the rest of it is. So when we have these idos, we're seeing, essentially the problem is that transactions that we don't want on the chain are there instead of transactions that we do want. So basically giving validators a better way to control what transactions land in the block by way of stake weighted kind of quality of service logic in banking stage right. So when we form the block, we'll try to pick transactions that come from higher stake weighted nodes than those like that are outside of the network. And then also we identified some optimizations to like how votes land in blocks and affect validators, what we call tower, basically their vote account, how, how their vote account progresses. So we can, once a validator has been on a fork, you can possibly modify the vote logic to return to what identifies the main fork and start routing blocks faster.
00:17:41.069 - 00:18:31.336, Speaker C: So we can't wait too long to root blocks or problems begin to happen. The other part of that is just pure optimization. If we can speed up the transaction execution for those kinds of blocks, right when we're getting flooded, then we can clear more of them quicker. And then the other part of that is the economic side of it. So, increasing fees for those transactions that are taking a really long time, but also possibly means decreasing fees for transactions that are cheaper. And then some other stuff sort of not related to stability that's coming in 1.9 is just like the ability to handle larger account set.
00:18:31.336 - 00:18:38.544, Speaker C: So a couple of things we have there, incremental snapshots. So right now, everything is a full snapshot.
00:18:38.584 - 00:18:38.736, Speaker A: Right.
00:18:38.760 - 00:19:25.514, Speaker C: When you download snapshots, the entire account state at the time. So if the account state doesn't change much since a previous snapshot, then potentially you could just download like a diff kind of state, which would be smaller. And then also the ability to keep the accounts index on disk instead of in memory all the time to reduce memory usage. That should also help for stability, because those times where the basically the tip block to the root block become large. Right. Developer has to keep all that state in memory. And so if we can have more memory, then we can handle larger fluctuations in that distance.
00:19:25.514 - 00:19:31.874, Speaker C: Okay, that's it.
00:19:35.174 - 00:19:49.488, Speaker D: I had a quick question for Stephen. So you had mentioned transactions that we don't want. Were you referring or were you thinking about bots, like the Defi bots that are forwarding straight to TPU?
00:19:49.616 - 00:19:50.768, Speaker C: Yeah, exactly.
00:19:50.936 - 00:20:35.344, Speaker D: Okay. And so the idea is that that type of traffic is going to go through different channels, I guess. So they could set up their own RPC nodes and send through RPC, you know, as in the more traditional manner. I also could see an issue there where these are big capital groups, they've got plenty of equity and capital. I could actually see them setting up some super nodes. If you go down this path of stake weighted transactions, I can see FTX. I'm not going to pick on anybody, I retract that.
00:20:35.344 - 00:20:49.664, Speaker D: But I could see some of the bigger firms setting up super nodes as validators just to get that stake lift. And I'm just curious to see if you guys thought about that.
00:20:52.924 - 00:21:25.514, Speaker C: I think we thought about it. I'm not sure that necessarily. I mean, if you run a validator with a large stake, you kind of control that amount of block production anyway. So it's hard for us to really control what they do with it essentially at the end of the day, other than trying to convince people to be fair and balanced and equivalent to it to everyone, you know? Equal to everyone. So. Yeah.
00:21:27.334 - 00:21:37.304, Speaker D: Yeah, okay. Yeah, I was just. I'm curious to see how that plays out. But I certainly like the idea about keeping the bots off the TPU because they are pretty disruptive.
00:21:38.164 - 00:21:57.784, Speaker C: I mean, essentially the stake is like the ownership percentage of your network, right. So if you buy into the stake, then effectively you kind of. It would be fair for you to control that percentage of block production essentially is. There's kind of a view of it. So.
00:21:58.554 - 00:22:02.174, Speaker D: Yeah, interesting. Okay, great. Thanks for all the work you put into this.
00:22:04.274 - 00:22:27.710, Speaker A: Thanks, Stephen. Any other questions or comments on that or anything else, go for it.
00:22:27.822 - 00:23:15.314, Speaker B: So do you think that the end game is eventually. We have some kind of, almost like the Linux kernel scheduler for programs on the blockchain where, you know, across blocks a given program has a certain budget as it uses up and other programs that, you know, haven't gotten a chance get a higher priority or something like that. So that really heavily, you know, accounts that are like programs, I'm talking about program accounts. Like when a program gets executed many times, then it kind of uses up its budget and then it becomes deprioritized for a while and other transactions can sort of take, you know, take higher precedence. I mean, do you think, I mean, I understand probably in code that's probably a lot to keep track of not knowing how many programs they're going to be and how much memory you'd have to dedicate to even keeping track of all this information. But is that something that you think could eventually happen?
00:23:20.874 - 00:23:58.156, Speaker C: I guess that's I don't know. This is necessarily about a per program thing, because there's nothing about a certain program that is fundamental about choosing one versus another. I guess so. I mean, we do limit the single users, a single writable key pair. Right. We have, we have limits already today in the cost model, that limits rights to a given account. So that limits what a certain payer would do.
00:23:58.156 - 00:24:16.184, Speaker C: Of course, you can create as many payers or keys as you want. So it kind of depends on what, how the, but it does allow for more efficient execution. I guess if you, if you shard those key pairs, I just mean, like.
00:24:16.224 - 00:24:32.844, Speaker B: Looking five years down the road, I just wonder if we're going to look back and say, oh, yeah, we ended up doing this. I should say you ended up creating a system that very much parallels all of the same considerations that are in kernel process scheduling and all those things making their way in.
00:24:33.864 - 00:24:37.044, Speaker C: Yeah, it's definitely a good comparison, I think.
00:24:48.164 - 00:24:51.584, Speaker A: Stephen, it looks like there's a couple questions in the chat from eager as well.
00:24:56.924 - 00:26:07.304, Speaker C: Do you prioritize, increase the transaction cost for a particular program? Potentially. I mean, as I said, doing things on the program level doesn't make sense to me necessarily, just because you can have many different users calling into a same program and you don't really know what the value of a certain program is giving you at any one point. It's more five of a, you know, you know, I guess, you know, the cost of a program and then you have to weigh that against the economic cost of executing it. Right. So, I mean, I think we're definitely, we're definitely having talks about periods of, you know, in periods of congestion, increasing fees for more on the account level than the program level. I guess so certain users that are using too much of the, of a given resource. Right.
00:26:07.304 - 00:26:13.444, Speaker C: Or a given account, then increasing fees for that, for touching that account.
00:26:24.964 - 00:26:59.954, Speaker B: Sorry, can I ask one more question? So we all know about that 50,000 tps sort of number that gets floated around. Do you feel that these changes are logically reducing what we should consider that number to be like? Is it really true to say 50,000 tps? If, you know, since that metric was last measured, the algorithms have changed to a degree where, you know, obviously it's a much, it's a very complicated issue because t is one letter, but it actually represents so much about, you know, how different transactions can behave. But would you say that it's accurate to still say that 50,000 tps is achievable?
00:27:01.814 - 00:27:15.494, Speaker C: Well, yeah, I think you already said it. The t depends on the t. Right? So there's a thousand x range, you know, from the most expensive transaction to the, to the least expensive. So.
00:27:17.794 - 00:27:23.614, Speaker B: So was that t original t like assumed to be the cheapest transaction then is, I guess the question I'm asking.
00:27:24.394 - 00:28:03.754, Speaker C: That'S what the original benchmarks are for. Yes. Yeah. In an ideal world you have like an industry standard benchmark or something that would give you a range of standardized transaction workloads or something that you could compare against. But yeah, that didn't, doesn't exist as far as I know. So I think most, most chains and white papers and things I've seen quote the cheapest transaction possible.
00:28:06.154 - 00:28:35.710, Speaker B: So would it be a bad idea for us to start disseminating that information to users? Because people ask this all the time on the discord, I thought I could do 50,000 tps. Is it a bad idea to say, well, actually it can do 50,000 of the cheapest transactions, but practically speaking it's going to be less than that? Or does that send the wrong message? If we're being honest and it compares unfavorably with other blockchains that aren't as honest, and maybe that's not just you, that maybe to everyone that question, my.
00:28:35.742 - 00:29:11.716, Speaker D: Take on that is, it's aspirational. That's our goal. And we're still in beta. We're only running ten threads when we're packing these blocks. I think once the block packing stuff is all sorted out and everybody feels good that hey, we've got this nailed, then ten quickly goes to 20 or 30 or whatever we can handle on the fastest hardware. And so that's how I've been talking to people about that is, that's where we're going. And it's a pathway and a journey to get there, but we're going to get there.
00:29:11.716 - 00:29:12.824, Speaker D: This is working.
00:29:14.244 - 00:29:21.864, Speaker B: So I didn't know that it was, I didn't realize that validators self limit in the number of threads they use in this way. So that's interesting information to me. Thank you for that.
00:29:23.044 - 00:29:24.664, Speaker C: It's less than ten, actually.
00:29:25.934 - 00:29:31.594, Speaker D: Oh, that's news. Thought it was ten.
00:29:33.854 - 00:29:35.034, Speaker C: Two to four.
00:29:38.094 - 00:29:38.874, Speaker D: Cool.
00:29:57.874 - 00:30:32.626, Speaker A: Awesome. Well, thanks guys. Appreciate the discussion. As always. We're about at time, but you know, everyone's on discord always, right? I apologize for the late notice on the meeting today. I apparently broke the scheduler bottom, but I'm going to try to do a better job of making sure the announcements for the meetings go out earlier. But going forward, I mean, and historically, except for last time, every two weeks at this time, we'll be here.
00:30:32.626 - 00:30:53.834, Speaker A: Meetings will be recorded going forward, so this will be the last one of the year, so. Yeah. Thanks, everybody. Thanks for knocking 2021 out of the park. Happy New Year. Happy New Year. Happy holidays, everybody.
00:30:53.834 - 00:30:56.726, Speaker A: Happy holidays. See you next one.
00:30:56.870 - 00:30:57.214, Speaker D: Thanks.
00:30:57.254 - 00:30:58.354, Speaker B: Happy to be here.
00:30:58.894 - 00:31:00.246, Speaker D: See you later. Happy holidays.
00:31:00.270 - 00:31:05.954, Speaker A: Thanks so much, everybody. Bye, everyone. Happy holidays, guys. Bye. Bye. Bye, guys. Bye.
00:31:05.954 - 01:17:16.714, Speaker A: It. It. It.

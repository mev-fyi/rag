00:00:00.440 - 00:00:34.364, Speaker A: All right, thank you everyone for joining another validator community call. It's great to see everyone. I want to start off this call by saying that thank you, or saying thank you to all the validators, RPC operators and engineers that got the nonce feature out this week. It sort of wraps up the restart that happened recently and gets the feature back out there for end users. So appreciate all the hard work getting updated to the correct version so we could, we can get the feature activated. So thank you everyone. A couple of announcements.
00:00:34.364 - 00:01:04.586, Speaker A: So as part of that rollout or sort of an anthogamous issue, there was a liveness issue that was caught in 110.25 related to quic. So 110.26 rolled out, which disables quic by default. It's not enabled by default, I should say. And so that is currently recommended for Mainnet beta. Very shortly we will roll out 111.0
00:01:04.586 - 00:01:56.374, Speaker A: for Testnet. I'm not sure of the exact process yet, so stay tuned for how much of Testnet we recommend to use 111.0, but just a heads up there that it will be recommended for testnet pretty soon. Let's see anything else? The other thing to be aware of is there was some kind of back and forth in the delegation program, questions about when people will get onboarded and why no one's been onboard in the last couple weeks. That's a communication issue on my part, so I apologize there. The main thing that I didn't communicate very well is that. Yeah, the main thing I didn't communicate very well there is that the engineers regularly review how the cluster is doing and are very aware of the health of the cluster as a whole.
00:01:56.374 - 00:02:46.274, Speaker A: So if there's ever a time period where they're not sure about onboarding the 25 validators and how that might affect performance and overall stability of the network, they're going to be cautious and not want to onboard new validators at that time. So I'll do a better job of just updating regularly when that is or is not the case, so that everyone is aware of what's going on. Yeah, that is all. I've got kind of a special guest today, so we've got Stephen Akridge joining the call today. He has been working on the quick updates and he's got sort of a state of the network that he's going to do. So I'll turn it over to Steve if he is here to go over those changes.
00:02:49.094 - 00:03:34.604, Speaker B: Okay. Yeah, I was just going to talk about the quick updates. As Tim said, there was a couple issues that we found. So we disabled quick by default, except for if, I think if you pass the flag, still enable it, but probably don't do that. I think we have the fixes almost ready. So some were those, those liveness fixes, others were just kind of general performance optimizations. Like there was a bunch of ports that were like a bunch of ports that we were binding to that we didn't necessarily need to be binding to.
00:03:34.604 - 00:04:32.328, Speaker B: Others were like we were blocking on streams in the server. So maybe a better, give us better performance if there's multiple outstanding streams coming into the validator. Another one is we needed to weight the total number of outstanding streams by stake weight. So that gives us, that allows us to kind of control this, the throughput into the validator by stake weight, because a more highly staked validator will have more streams to be able to send outstanding before it gets like an ack back from the server, which tells it then it could send more streams and thus more transactions in terms of like time. Yeah. Good.
00:04:32.416 - 00:04:44.744, Speaker A: There's a question from Sen Tatsu in the chat. If you could read that or just sort of rephrase, that'd be great. I can read it out, actually.
00:04:44.904 - 00:04:47.880, Speaker B: Yeah, I see. The immediate benefit to using quick, is that the one?
00:04:47.992 - 00:04:50.844, Speaker A: Yeah, yeah. So what would the immediate benefit of using quick be?
00:04:53.464 - 00:06:00.466, Speaker B: Yeah, we're hoping this, you know, we limit the throughput into the validator in terms of like number of transactions per second. So, you know, if clients kind of exceed those limits into the validator, then they get dropped there, another connection would be dropped. And hopefully that connection dropping is faster than the whole processing, transaction flow that we had before where we were just looking at things over UDP. And, you know, there's some other, there's some other benefits. One is just the client gets an ack back, right. So it doesn't, doesn't benefit you to, you know, keep sending the same transaction over and over again because you know that it's been kind of accepted by the server. So there's no kind of incentive to just keep spamming the same transaction over and over again.
00:06:00.466 - 00:06:42.328, Speaker B: We can also do like more control flow based on that, right. People send duplicate transactions. We can drop the connections. We can drop connections for other kind of abuse type scenarios. Not all of those. That's probably more of this follow on feature, right? We don't, we're not handling like all the potential abuse scenarios right now to punish bad actors, but that could be a change in the future. There's lots of things, there's a quick issue.
00:06:42.328 - 00:06:50.484, Speaker B: I think that was open initially. That covers, I think, the main benefits.
00:06:55.544 - 00:07:08.544, Speaker A: So there's a couple more questions. Will the majority of space be dedicated to non state? Going through stake nodes first, incurs more latency? Maybe some explanation there. I'm not quite sure what the questions getting at.
00:07:12.404 - 00:07:55.664, Speaker B: Yeah, right. Right now we have more space dedicated to staked in terms of like overall bandwidth and like outstanding streams, the streams I was talking about earlier, so, but this kind of things are fairly tunable and I don't think that the first kind of go around of constants in terms of like total number of connections and also the total number of like outstanding streams will be like perfect for the first time. So that's probably, that'll probably be something to tweak once we see the kind of real world usage.
00:07:57.564 - 00:08:03.784, Speaker A: Great. Next one. Does it become easier to exhaust validator resources by filling them up with quick connections?
00:08:07.654 - 00:08:47.164, Speaker B: There's a total number of quick connections. The connection itself is pretty lightweight, so it shouldn't be, it should be pretty easy to reject the connection, manage the number of connections. And then we're also hoping that if there's a DDoS kind of scenario that, you know, external hardware has the potential to kind of handle those, those connection abuse scenarios, kind of even external to the, to the validity.
00:08:49.984 - 00:09:50.558, Speaker A: There's a question about when will quic be turned on? I think the standard response there is when it's ready to be turned on. But just to give you like a little bit more insight into the thought process and kind of rephrasing what Stephen said, I think there's a lot of parameters that need to be tuned first before the rollout is definite and we message, hey, all the validators should turn quick on. So parameters like he's mentioning need to be tuned and played with before quick is rolled out to the masses. Yeah. And Zen Tetsu has a question about his hammer script that he wrote. Stephen, I'm not sure if you're aware of that, but Zantetsu essentially implemented a client that would send a lot of transactions to the testnet cluster to try to more appropriately emulate real world conditions. I think there was some talk internally of that happening at the same time as internal tests.
00:09:50.558 - 00:09:56.614, Speaker A: So just needs to be coordinated a little bit more. But maybe you have more thought on that.
00:10:00.354 - 00:10:38.564, Speaker B: Yeah, I think as long as it's coordinated with our testing, would be nice to leave that. I think I brought up internally to try to have us run that test. I don't know. I don't know if that stress testing refers to only that client or you want to run different, different parameters with that client to kind of see. Yeah, I guess. Is it public like the times that we run the art test? I'm not sure if that's generally known or not.
00:10:38.724 - 00:10:55.204, Speaker A: I don't think it's made public, but, you know, we can make that public or coordinate on the back end if it makes sense. Yeah, maybe. Zentesu, if you're available with the mic, you could talk a little bit about thought process behind the script.
00:10:56.944 - 00:10:57.844, Speaker C: Right now.
00:10:59.304 - 00:11:01.512, Speaker A: Yeah, I guess what your intention was.
00:11:01.568 - 00:12:29.486, Speaker C: Yeah, the basic idea was I just wrote a client that it tries to simulate transactions. It has randomization of, there's many instructions that can be run in the actual program that do things like do n number of program derived address calculations or create a bunch of accounts or just a bunch of randomized work. The idea being just almost like a fuzz test, just do a bunch of transactions of varying types of complexities that are randomly generated to try to cover many different shapes of transactions and also many transactions being run at the same time. The goal was just to try to ensure that, and I'm sure you guys already covered this to a large degree. I'm only trying to contribute what I can, where I can, but the goal was to try to make testnet actually do a lot of work, as much work as possible so that when releases are done there, if we have a baseline that says, oh, like if I'm watching how my script's working and saying, oh, I'm able to do 400 transactions per second, but all of a sudden with this release, I'm down to 200. Maybe that's a red flag, or, you know, or maybe other issues arise and are noted because the load on testnet simulates conditions that reveal, you know, problems that wouldn't have been revealed otherwise. I know you guys do like a daily stress where you kind of like take half an hour and do a bunch of stuff and, you know, of course don't want to interfere with that either, or anything that's being done on Testnet that has other value.
00:12:29.486 - 00:13:28.602, Speaker C: But I just thought stepping in and adding something that could try to make testnet work more like a real network doing real work could help the soak of software versions on Testnet before they hit main net. I can run one or two instances of this at a time. I was trying to gather other people to see if they could also run instances, because if we have, I can only send so many transactions per second, but if we had ten or 20 instances of this running, we could be hitting Testnet with thousands and thousands and thousands of transactions, transactions per second from many locations if we wanted to. But my script doesn't use quic. So I think what it does is it queries the leader schedule, finds the leaders, and then directly sends transactions to their TPU ports. And now I'll have to modify it to maybe use quick instead. So there probably will be some time before it's ready for use again on Testnet if we want to make sure that it's testing quick and not other, you know, regular TPU port stuff.
00:13:28.602 - 00:13:36.214, Speaker C: But anyway, that's a basic summary of what I have, and it's open source. It's on GitHub. I can post a link to it if you want.
00:13:38.074 - 00:13:45.294, Speaker A: Yeah, yeah, that'd be great. I think coordination like you mentioned is necessary, but it would, I think it would be useful if engineers agree.
00:13:48.034 - 00:13:48.418, Speaker B: Great.
00:13:48.466 - 00:14:33.424, Speaker A: Any other questions for Stephen or about updates in general? All right, a couple more things I wanted to plug, so I've been doing some one on one validator calls with just random people who have reached out. If you want to chat, you just want to say, hello, this is who I am. This is my validator. Or if you have a specific question, feel free to use that link I put in the agenda. It's a 30 minutes slot to, you know, one on one call. But if you want more time, we could figure that out as well. Just want to get a better idea of who you all are and what you're interested in, so feel free to use that.
00:14:33.424 - 00:15:31.534, Speaker A: One other thing I want to mention. So there's been some questions I've seen in either validator support or, or in MV validators about downloading snapshots. I added some sort of a more put together view of getting snapshots and the process there. There were some questions about, if I download a snapshot and it's slow or it's disconnecting, what do I do? So I kind of coalesced some of the responses to that question in this link, especially if you're having downloading speed problems. There's a flag that you can use called minimal snapshot download speed that can be useful also. Some people, like lane, I believe, just downloads the snapshot directly. So there's some discussion in there about that as well.
00:15:31.534 - 00:16:04.750, Speaker A: In general, if you want to contribute more to this doc, let me know. I appreciate any contributors, any help adding more to it? I want it to be useful for everyone. Let me know if you have any thoughts or questions there. Cool. Any other questions before we, we call it a day? Okay. Cool. Well, thank you everybody, and look out for updates on 1.11
00:16:04.750 - 00:16:06.334, Speaker A: for testnet. Talk to you all soon.

00:00:12.120 - 00:00:12.392, Speaker A: Cool.
00:00:12.392 - 00:00:56.504, Speaker B: So my experience with rust actually became, at my last job, I was at Dropbox, and we worked on compression, and we, like, built this thing about using standard libraries with our own allocators to run, like, in this little type safe sandbox. And that was really cool, but it really didn't sink into me until I started this project. And I spent two weeks writing c as, like, a good little C developer. I had 100% branch coverage, and I was making pretty good progress until I needed some external libraries. And I was like, oh, man, I'm gonna have to download this stuff and build it and write make files. So I decided to try rust. And then a weekend, I was ahead of where I was, and that was the moment for me.
00:00:56.504 - 00:01:16.164, Speaker B: Like, holy shit, this is amazing, right? Like, this is a language that is as fast to see, gives me all the modern type safety of Haskell, and it works, right? So it was kind of my awakening to rust. So, like, do you guys have a moment in your life when you guys like it finally click that? This is like, the coolest thing ever?
00:01:16.584 - 00:01:57.270, Speaker A: I think. For me, the reason that rust really clicked with me was not because of, like, the speed or anything that came a lot later. Like now. Now I care a lot about writing perform rust code, and, like, that's something that I find really interesting in rust. But, like, the thing that originally got me is because before Rust, I was a c hash developer, and c hash is just nothing but runtime errors. Like, just whatever you do, just like, you can't even list the number of runtime errors that, like, the simplest operation can throw in C hash because there's, like, this dynamic type that it's completely untype checked, and there's, like, weird string manipulation, runtime stuff. And it's not like some languages, like, they, people use these all the time in C hash.
00:01:57.270 - 00:02:29.134, Speaker A: So I was like, I was actually thinking not liking programming in general because I had to deal with this bullshit. And Rust was a welcome relief from bullshit. It is a impressively bullshit for language, I'd say. And, like, the ergonomics, like you were saying, like, not having to deal with these make files and having this very ergonomic package management system, and, like, the type safety and the null safety, that kind of thing, that's really, like, what clicked with me originally. And the speed was, like, a lot interesting coming later on.
00:02:31.034 - 00:03:07.622, Speaker C: Yeah, kind of the same thing for me, I guess speed was mostly a post hoc rationalization of why work on Rust now? Say, oh, well, it's very fast and it's really easy. To work with, really easy to audit and so on. But I think when I first got involved with Rust and started learning it, I think that it made me, like, programming again, because I had gotten into a situation where nothing was looking good and I didn't want to have to resort to writing Haskell or something. Haskell's great.
00:03:07.758 - 00:03:09.874, Speaker A: Haskell has plenty of its own bullshit.
00:03:11.494 - 00:03:46.730, Speaker C: But Rust has kind of combined my mental programming model, my procedural thinking, with just really good performance, and I really liked the concepts. Obviously, when I first got involved in Rust, it looked a lot different. It didn't really have a like. It still had a garbage collector and all this other stuff inside of it. So it's changed over the years, and it's become more elegant over time. I think that's part of the reason why I like it so much, is that I saw it improve and become much better than it was originally. I guess if I saw it now, I'd just be like, oh, that's a really nice language.
00:03:46.730 - 00:03:52.654, Speaker C: There's lots of really nice languages coming out. I think it's great. Russ got this momentum.
00:03:54.934 - 00:04:37.688, Speaker D: For me. I dabbled in a whole bunch of different programming languages over the years. A lot of C, C, Haskell, and Python, really. And every time I'd be using, I've tried my hardest to just choose only two languages on a project to be able to say, okay, if I want to do this high level stuff or something, I'll do it in Python. If I want to do, you know, functional type of stuff, I'll do all that in Haskell. And if I really need to do low level, high performance, then I'll switch it over to c. And I just got burned so many times on those, the cross language transitions.
00:04:37.688 - 00:05:00.946, Speaker D: It's really, really tough, especially when garbage collectors are involved. It's really not composable that way. And then if you. And then where C plus, where it's no garbage collector but also no safety, that's also not very composable. And that all of a sudden now your Python program crashes. And it wasn't supposed to be able to crash. Right? It's like Python.
00:05:00.946 - 00:05:27.754, Speaker D: It's supposed to be a property of it. But you did this plugin in C. And so now it does. And so, yeah, so for me, rust was just a huge breath of fresh, fresh air, and that I could look at it and say that I could just do this just huge part of the whole software stack all in one language, to not have to keep switching and dealing with those awful impedance mismatches.
00:05:28.294 - 00:05:58.598, Speaker A: I think the thing about Z is that it's not that it's completely unsafe, it's that it's safe, but the safety is a complete lie. Like it has all of these things to make it like, possible to write something that like, is kind of safe and like it looks safe. And like, in the simple cases it is safe, but then, like, you try and do anything remotely complex with it and then, like, actually not seg fault. That's even, that's the worst thing. It's like it's something other than a seg fault that you don't even notice without like 100% test coverage. And even then, probably not.
00:05:58.686 - 00:06:01.366, Speaker D: How about undefined behavior though?
00:06:01.430 - 00:06:02.074, Speaker C: Yes.
00:06:04.654 - 00:06:38.448, Speaker D: In your program. And it just, it just rolls over in the compiler that you're using. But it says in the language definition that if you have an integer overflow, that's undefined behavior and your compiler is allowed to do anything, anything at all. And maybe it doesn't in the current compiler that you're using, because it's a sensible thing to do, is not crash your program because you have an integer overflow and then you upgrade your compiler and then all of a sudden it does crash or crashes off in somebody else's small library because they had subtle integer overflow. Super annoying.
00:06:38.496 - 00:07:26.484, Speaker A: I mean, the Linux kernel, like, they disable the optimizations that rely on null pointers being undefined behavior because there was like a bug where they created a pointer to a member of this random pointer that they were being passed and then they checked that point of a null. And then, so the compiler was like, oh, you just create a pointer to a member that means it must not be done. And then, so they remove the null check and then like you can just like bypass it and get like pseudo permissions with like very little effort. So, like a lot of unfair behavior. Like, I think the thing about rust, like where C, you can get these charlatan fraud abstractions with Rust, like, you have this unsafe and you, as long as the unsafe is correct, the rules of rust, everything building on the unsafe is also correct.
00:07:26.524 - 00:07:26.652, Speaker D: Yeah.
00:07:26.668 - 00:07:36.004, Speaker C: So rust actually has abstraction barriers that expose safety as a first class concept because at the language level, unsafe is a first class.
00:07:36.044 - 00:08:00.014, Speaker A: Cause I almost think that's like rust. My favorite concept about Rust, because even Haskell, which has like amazing ability to create abstractions, like the thing, it has to separate the unsafe, unsafe things, is the word unsafe in function names. Like unsafe perform IO, which is basically just like create nasal demons at this point in my program.
00:08:02.554 - 00:08:14.974, Speaker D: That'S a fact. And there's one of those in the prelude. So you pretty much can't avoid it. As even a brand new Haskell developer, if you try to read a file, you're going to do an unsafe operation that'll definitely bite you a few years later.
00:08:17.954 - 00:08:23.002, Speaker B: Yeah, Greg and I built the Haskell project when we were sick of sea. It bit us.
00:08:23.098 - 00:08:51.774, Speaker A: Yeah, yeah, I think, yeah, Haskell has lots of good things about it. It also has lots of ways to shoot yourself in the foot. I think, like a lot of languages more nowadays are working out better ways to avoid you shooting yourself in the throat. Rust is one of these. But then of course there are some languages that just like have all new and interesting ways to shoot yourself in the not to, not to shit on other languages, not to make this like a cult thing.
00:08:55.554 - 00:08:58.774, Speaker B: You guys did an awesome blog post. Why Rust?
00:08:59.514 - 00:09:09.186, Speaker A: Oh, you guys did. I don't think it was it Friday. Thought it was Dimitri who did that one. Do you guys remember it was Dimitri? Yeah.
00:09:09.210 - 00:09:10.192, Speaker D: Okay. Okay.
00:09:10.288 - 00:09:26.284, Speaker B: So I'm like, I'd like to know where you think, like Rust has for me improved a lot of the ergonomics of programming. Like where do you think you can still like do better? Like what are. Now is your chance to shit on Rust.
00:09:29.024 - 00:10:23.234, Speaker A: So the big one is like, there's a lot of things that, like, there's no reason that Rust shouldn't support doing things on stack, but currently just limitations of language. You have to do it on the heap. So for example, these things probably seem quite obscure if you are not deeply embedded in programming, low level rust stuff, but I feel like I hit them all the time. You can have constants that are associated to implementations of traits on types, which is already an obscure feature, but then you can't use that as the length of an array. So that means that you end up with having to create. For example, you could have static strings that are fixed length on the stack and then concatenate them at compile time, but instead you have to do all this work at runtime. We do a lot of work in Webassembly.
00:10:23.234 - 00:11:02.234, Speaker A: We have to compress the size of a program as much as possible. A useful thing to be able to do is, for example, concatenate like static associated strings together to create this long string at compile time, rather than having to do this work at runtime, having all these different strings and then concatenating them together like on the heap. So now we have to have an allocator better to do that in the compiler. And there's no actual reason that rust shouldn't be able to do this as far as safety is concerned. It's just, it's not supported in language right now. And of course, the other one is infiltrate, which is one that I think a lot more people run into on more regular basis. It's less of a niche for.
00:11:02.614 - 00:11:03.750, Speaker D: So what about infiltrate?
00:11:03.782 - 00:11:20.380, Speaker A: What would you want? Right. So, a lot. So I don't think you can yet return infiltrate from a trick, from a function in a trait, for example. So, like, you, if you have free functions or inherent functions, which is like functions that are already defined on one exact thing.
00:11:20.422 - 00:11:22.544, Speaker B: Like an existential type in haskell.
00:11:22.664 - 00:11:24.536, Speaker A: Exactly, yeah. Existential, yeah.
00:11:24.720 - 00:11:34.824, Speaker D: So what is an existential from a trait? Like, does that mean the traits could implement any two different trait implementations, could return two different iterators?
00:11:34.904 - 00:11:46.372, Speaker A: Yes, exactly. So should it be able to. Yeah. So the mental model you should have is that there would be like an associated type, and then that associated type will be different in the different information implementations.
00:11:46.428 - 00:11:48.956, Speaker D: And, like, you have to specify that in the trade.
00:11:49.100 - 00:12:23.008, Speaker A: Right. So there's two different designs. There's one design where you have an explicit associated type, and then you do type whatever equals inventory, or there's the other one where it just has, like an implicit, like, it just creates an associated type for you. But either way, that's the mental model, but it's not actually implemented yet. And that you run into that quite often because I thought, I find that lots of methods in rust are not inherent. Most methods in rust are trait methods. And so, like, the fact that you can't return input trait from trait methods actually is a very common problem for you to run into if you want to do stuff on the stack.
00:12:23.096 - 00:12:37.564, Speaker C: I agree with both of those, and I think that it's kind of nice that in terms of language features that we're really running into that we don't have. These particular two happen to also be, like, in development, and we should see them.
00:12:38.924 - 00:12:39.784, Speaker A: Absolutely.
00:12:40.324 - 00:12:43.156, Speaker D: These rust developers must love you.
00:12:43.180 - 00:12:46.132, Speaker A: And that he's complaining about something that.
00:12:46.148 - 00:12:47.504, Speaker D: Was released a month ago.
00:12:48.364 - 00:12:50.340, Speaker E: Sounds like you're talking about consternaris.
00:12:50.372 - 00:12:52.844, Speaker A: Yeah, there's this gross hack.
00:12:53.004 - 00:12:55.780, Speaker E: So it's titanom and generic array.
00:12:55.932 - 00:12:56.664, Speaker A: Yes.
00:12:58.964 - 00:12:59.924, Speaker C: It'S very painful.
00:12:59.964 - 00:13:09.834, Speaker E: Consternaris. Tomorrow, they're really bad, but you can use them today and they work with no stir.
00:13:09.954 - 00:13:12.122, Speaker A: This is true. You can't, uh, you can't use it.
00:13:12.138 - 00:13:14.066, Speaker B: For strings, though, because the strings, the.
00:13:14.090 - 00:13:16.814, Speaker E: Length, you can't use strings are instead.
00:13:17.834 - 00:13:20.106, Speaker D: So string, two way straight string itself.
00:13:20.170 - 00:13:22.414, Speaker E: Is instead, because it means lobatic.
00:13:22.954 - 00:13:26.454, Speaker A: Yeah, right. Well, no, no, it's like string. Like, so if you have a stack.
00:13:30.534 - 00:13:33.194, Speaker D: Generic array, if you use.
00:13:37.534 - 00:14:07.474, Speaker A: But so I have got this repository of concatenating strings that compile time using extremely gross hacks and unsafe and constant functions. But as I said, you can't use it with traits. We had a design where we wanted to have this trait implementation where you have a constant string and then it just concatenates the compile time, and you have this very ergonomic way to create very efficient code, but which we originally were doing with a procedural macro, which is another thing that is like a feature that's sort of upcoming.
00:14:08.694 - 00:14:11.862, Speaker E: You should be able to use const option for that.
00:14:11.918 - 00:14:49.064, Speaker A: Yeah, exactly. And there's other const folding things like, so we have like a hashing algorithm, and I wrote a version of that that runs at compile time by, instead of branching, you're not allowed to branch. So I had all of the different possible outcomes of that calculation in an array, in a constant array, and then I index into that array, so it calculates all of the possible outcomes and then chooses the one. Like with indexing, except it creates a 8 million% slowdown compared to doing it normally. So it's not really feasible to do a compile time because your compile time is blow up by like 8 million%.
00:14:51.914 - 00:15:00.562, Speaker C: That actually, not to step on the moderator, but like, that kind of makes me wonder, in parity situation, how much unsafe code do you end up resorting to?
00:15:00.658 - 00:15:32.430, Speaker A: Right. Actually not that much in parity itself. A lot of it is still not necessary. They used to be very early on, before even I joined, like, unsafe everywhere. Everything was like very much unsafe because, you know, squeeze out the most performance, get unchecked is so much faster than it is because it was c developers who like, they love this snake oil, this placebo optimization something. Seems like it should be faster.
00:15:32.502 - 00:15:34.454, Speaker C: I don't need to do a runtime check of that.
00:15:34.534 - 00:15:34.910, Speaker A: Exactly.
00:15:34.942 - 00:15:36.246, Speaker C: I don't want to panic.
00:15:36.430 - 00:16:07.590, Speaker A: Exactly. Panicking, slow, panic, being slow. You don't want to do that. I mean, undefined behavior is very fast. To be fair, one of the guys who worked for us, when he joined, he removed a lot of the unsafe, and since then, we've been removing more and more, and now most of it is unsafe. There's a few unsafe hacks in the deepest bowels of the stuff that need to be faster and actually can't be optimized. Right now, for example, we have a hashing algorithm where we have to concatenate through arrays together.
00:16:07.590 - 00:16:20.030, Speaker A: But instead we put two arrays in a struct, which is replic, and then we transmute that to an array because that is like legitimately significantly faster. So yeah, there's like, there's not that.
00:16:20.062 - 00:16:24.954, Speaker B: Much like I was like, booted all of that code in one day.
00:16:25.414 - 00:16:26.794, Speaker A: I wish it was one.
00:16:28.174 - 00:16:35.286, Speaker B: This is great. I'll just guess, you know, unions from like buffers that are pull off the side socket, right?
00:16:35.350 - 00:16:37.594, Speaker E: Yeah, this is gone.
00:16:39.734 - 00:17:28.104, Speaker B: That was a fun experience. So my next question is related to safety. Coming from like CE and Haskell, I actually find that modern day type systems don't add that much over just simple c. Is this typedef the same label as this? I know, like we use the, we use all these features a lot, but for 99% of the use cases, you can kind of get away with that. How do you guys, like, actually use these higher level type abstractions that you see that they can prove actual meaningful? Like parts of the code? Like these types of abstractions are designed to give you some certainty, some guarantees. Like where do you guys see the impact of those?
00:17:29.604 - 00:18:04.230, Speaker D: I see them as convenient ways to start when you're writing code that you maybe don't know a whole lot about the library. I'm just kind of thinking of generic array specifically. That that was really great too. You know, we wanted public keys and signatures in their different lengths and we didn't want those types mixing at all. And so we wrote those with generic array at first. And so we were taking advantage of this higher level type system. And maybe it got me out of a jam or something a few times here and there.
00:18:04.230 - 00:19:01.806, Speaker D: But then as I got, you know, more and more knowledge about what was all going on, I would actually wrap those with very simple types and get rid of the genesis generic array, actually just have a struct that you can use. And again, kind of getting to basic type check. So, yeah, I kind of see it as a useful safeguard for when you're, when you're playing, you know, actually there's a lot of things with, I guess, structure and art really, right, is that if you have a lot of structure, you can just sort of like, you can just sort of change it around and do these kind of like, you know, algebraic operations and just sort of see what happens. And that's cool. So that's a really good use of types and structure. And if you actually know it precisely what you want, then all of a sudden maybe the types don't quite match up to that nuanced, nuanced niche of what you really need.
00:19:01.910 - 00:19:05.270, Speaker A: I think what you're getting at is the idea of type driven development where.
00:19:05.302 - 00:19:07.474, Speaker D: Like, you build out the type we were talking about.
00:19:08.274 - 00:19:15.334, Speaker A: Yeah, right, exactly. That concept comes from Idris. Although the name comes from Idris, the concept exists.
00:19:17.434 - 00:19:29.658, Speaker D: Sounds like he's ready for that Curry Howard question. He was on the plane, I think when you threw that out there. He was joking about asking questions up here about the Curry Howard correspondence.
00:19:29.746 - 00:19:30.698, Speaker A: I don't know, you guys were going.
00:19:30.706 - 00:19:37.594, Speaker B: To build on using the python, the, you know, like this contest where everybody says every other character.
00:19:46.174 - 00:19:46.486, Speaker D: Yeah.
00:19:46.510 - 00:20:29.104, Speaker A: So about types, I feel like they're really okay. So there's the two arguments for like, complex type systems. There's the ergonomics argument and then there's a safety argument. The safety argument. I feel like you can get a lot just from strong versus weak type systems rather than static versus dynamic. So like, for example in C, if you multiply an int and a long together, I actually don't know what you get, but this is the point, right? There's like all of these foot guns you can get in C by like multiplying unsigned integers by integers and like smaller integers by larger integers. And there's like a lot of C programming guidelines.
00:20:29.104 - 00:21:27.264, Speaker A: Basically, it's just telling you a lot of C programming guidelines is like how to avoid the traps that this language lays down to for you. Rather than sort of telling you how to write good code, it's just telling you how to avoid writing bad code. Whereas like a strong type system, like rust, where you can't multiply like images of different sizes together, because like the answer would be not very like be not intuitive. And so it just like tells you it can part time. And then there's the ergonomics argument where, for example, the build builder APIs, where you have these, these like complex strings, like something dot something dot something dot something, where you can like return like this very complex type by. So say, for example, you want to have something where you can have this list of things to execute. You can of course have like vector box trait objects, but that's quite efficient.
00:21:27.264 - 00:22:08.970, Speaker A: So instead you can have this like builder API that builds it up as a tuple, and then you return this like very complex type has like a nested tuple of a list of all of the things you want to do. Like the futures API does this. So like all of the things you want to do are in the type of the future. And so if you had to write that, then it would be extremely inconvenient. And C has auto, but that only works with variable definitions, and it doesn't work for so many other places. And yeah, having the bidirectional type inference makes that a lot nicer to use those. What I see is being two arguments for the stronger type system.
00:22:09.042 - 00:22:43.982, Speaker C: For me, I guess it's just purely code reuse, really. That's the thing that I don't like about less rich languages with less rich type systems is just having to repeat yourself and having to invent the invariants of your code every single time you write it and study and understand how it relates to other parts of code. It's just, I think you really need generics. I could take a weak type system. I could take with. If I still have generics I can put up with.
00:22:43.998 - 00:23:14.664, Speaker A: It's like, it's having. These abstractions will also be able to be able to know, basically that these things will still work. In python you can do very complex things, but like generics, and they take any type, but there's no way to know that it actually works until you try it with all these different types. Whereas in something like rust, you can know before you call it, you know, the definition time that this thing will be correct rather than a call time.
00:23:14.824 - 00:23:20.364, Speaker B: So this like, brings up, like, the next point I wanted to make, or do you want to.
00:23:20.824 - 00:24:08.844, Speaker D: I just kind of wanted to maybe defend alternatives to rust. And that we talked about earlier, that the one thing that we really loved about coming to rust is that there's very few surprises that, you know, you actually. What you wrote is that's what happens pretty much, and not a lot of gotchas, but specifically about generics. And I kind of going back to what I think, I believe it was Elon Lance Taylor had talked about from the go language. So Ian, Lance Taylor developed the. What was the elf linker, the super fast one, the second one that came. What's that? The gold linker.
00:24:08.844 - 00:24:44.522, Speaker D: Thank you. Who said that? Thanks. I was just thinking, this guy Jack in the room is probably the other guy that would. Might know that. Yeah. So he wrote gold. And then I think he had considerable influence, maybe, on the gold language design about generics, specifically saying that it kind of creates this awful modularity problem in that you create this generic and you haven't really generated the implementation of that because there's an infinite amount of implementations of this generic, and you kind of don't know where to put it.
00:24:44.522 - 00:24:53.674, Speaker D: Should you put it in the person that uses it, that actually provides the type, especially in the case if you're going to create a shared object.
00:24:53.754 - 00:24:53.994, Speaker B: Right.
00:24:54.034 - 00:25:20.464, Speaker D: You actually have a concrete thing. You're going to distribute that where should the implementations of these. It would have to be in the color the user of it. But that means that you're now duplicating this across everyone that instantiates the exact same generic. And so I think their argument against it there was to say that we don't know how to solve that problem. Well, so we're just not going to solve it right now.
00:25:20.884 - 00:25:22.492, Speaker A: That is Rust's solution is to not.
00:25:22.548 - 00:25:33.144, Speaker D: And Russ's solution was maybe not. It was to go for it and hope for the best. And you get this nice concise code, but you still have that problem that gotcha.
00:25:33.564 - 00:25:40.836, Speaker A: I mean, there's really only a gotcha as far as like creating more space on the disk, which I feel like is a pretty good trade off.
00:25:40.900 - 00:25:41.868, Speaker D: Systems developers.
00:25:41.916 - 00:25:43.324, Speaker E: Yes, absolutely.
00:25:43.364 - 00:25:53.904, Speaker D: This is definitely a real issue. If you're using a systems language that doesn't have a garbage collector that you know, that maybe you'd want that kind of control.
00:25:55.404 - 00:26:29.352, Speaker A: This is certainly a problem that we've been running into with our webassembly work, because webassembly, especially on the blockchain, like for smart contracts, it's essentially the same as embedded development, a lot of the same restrictions. And so we have run into this exact thing of like, yeah, generics can produce a lot of code bloat and like, I feel like there is some like request for like monomorphize generic. So you still use the generic thing and then, but at compile time you specify that you want to use dynamic dispatch rather than static dispatch rather than in the source code. So definitely defining it, which would be good for.
00:26:29.408 - 00:26:39.084, Speaker D: Yeah, so I think that's kind of the Java solution was to push it to the runtime and then, you know, that conflicts with rust zero cost abstraction.
00:26:39.664 - 00:26:42.496, Speaker A: I mean, you still choose, like, you can choose to have the zero.
00:26:42.640 - 00:26:44.016, Speaker D: Yeah, if you can annotate it.
00:26:44.120 - 00:26:55.164, Speaker A: But I feel like there's really only. You don't really have much other choice. Like either you generate monomorphized code for each one, or you generate one piece of code that, like, uses function pointers.
00:26:55.204 - 00:26:58.184, Speaker D: There's, I mean, punt on the whole thing that go.
00:26:59.044 - 00:27:08.276, Speaker A: Yeah, exactly. Go solution is the same as rust solution, except the monomorphizer is the person writing the code. It's like it's not the compiler anymore.
00:27:08.340 - 00:27:19.084, Speaker D: Exactly, exactly. Okay, so you need like whole programs optimization.
00:27:19.504 - 00:27:23.544, Speaker E: So it's more like you have like a build server or something like that.
00:27:23.584 - 00:27:30.568, Speaker D: Right. So you can't distribute cache, you can't distribute a shared object on its own, and you have to postpone that decision.
00:27:30.656 - 00:27:49.578, Speaker E: It's more like the concrete types given a particular version of the compiler and given the parameter, generic parameters, right. Are identifiable by hash. So it's more like you can content address. Yeah, so long as everything is the same across the board.
00:27:49.626 - 00:27:50.290, Speaker A: Right.
00:27:50.482 - 00:28:01.066, Speaker E: Same compiler version, same generic code, same generic parameters. I think the rust compiler can do that with hash.
00:28:01.170 - 00:28:02.266, Speaker D: Okay. Yeah.
00:28:02.290 - 00:28:06.134, Speaker A: I mean, there's no way to make, turn that into a shared object that's then used by a download.
00:28:09.754 - 00:28:10.210, Speaker D: Like a.
00:28:10.242 - 00:28:12.854, Speaker B: Personal help for somebody trying to write a linker, right?
00:28:13.154 - 00:28:13.842, Speaker D: Yeah.
00:28:13.978 - 00:28:22.054, Speaker A: Writing linkers is like infamously, unbelievably difficult. Like linkers are just a very difficult program to write in general.
00:28:23.074 - 00:28:25.014, Speaker D: What do you think, Jack? They hired.
00:28:27.674 - 00:28:30.534, Speaker A: As someone who's never written linker? Maybe they're actually pisses.
00:28:33.914 - 00:29:06.206, Speaker D: Magic for sure. And I think, you know, one of the spaces in between in that design space is that you can do the link time optimization. So like in LLVM you would rather than compile all the way down to machine code, you would just compile down to LLVM bitcode, which is basically, you know, still kind of source code, and you pass that around in something that really looks just like a shared object. Yeah. And then it's the loader, the runtime loader, that kind of sees that. Hey, this isn't an elf objective, this is LVM bake code. And so then can do those sorts of transformations.
00:29:06.206 - 00:29:14.342, Speaker D: But that's like pretty darn recent, that's like the last maybe five years is where they're kind of still working on working out the kinks there.
00:29:14.438 - 00:29:45.764, Speaker A: Do you know something crazy that Luigit does? If you call a dynamic library with Luigit, it will work out which functions are really small and it will inline assembly code from the dynamic object and then like rewrite it so that it's no longer taking arguments off the stack like before. Like it's like the crazy, like based on like a certain, it will like inline the assembly, the pre compiled assembly code. Because Mike Paul is a crazy person.
00:29:50.864 - 00:29:57.484, Speaker D: That's a lesson in software engineering, right? If you trust the one smartest person in the whole world and then he decides to go do something else.
00:30:01.784 - 00:30:05.764, Speaker A: Is still very impressive. We still have a very impressive project.
00:30:07.224 - 00:31:04.516, Speaker B: My next question again regarding type safety. I was really impressed with just blown away, really rust solved memory safety and threat concurrency, which was I didn't even think was possible with the types of before it actually like used it. It's like, holy crap, this is awesome. But these days, like, especially our projects, we're faced with writing programs that have an immediate financial impact if there's a bug. So, like, I still haven't seen like a clear proof of a property using like any proving language, including like, or like one of the recent proposal ones that actually demonstrate a property that I can trust to save my money to prevent like a financial ruin in that contract. What do you guys think? What are your thoughts on that? Do you see a type system solving that problem at all?
00:31:04.700 - 00:32:18.938, Speaker A: I mean, dependent types solve that problem, but I think this is actually something that's been on the minds of quite a few people at parity recently, because we are trying to push right in smart contracts for Webassembly. We have web assembly smart contract platform called Covan. It's not the technology, but I call it that, don't listen to me. And I think that what is sort of coming to the forefront of a possible method to solve this, in my head is something how spark versus Ada works, where like, there's these contracts that you can write in Ada, and they're enforced at runtime in Ada, and then Spark will just basically go through your program and prove that none of these contracts will be violated at runtime, which includes stuff like out of bounds indexing. So it's essentially just like you write your whole program to panic if something is wrong, and then you run this program, that proves that it will never panic. That's essentially the idea. And this is how aircraft guidance systems are written, using Ada with Spark, or spark that is built on top of Ada, whatever you want to call it.
00:32:18.938 - 00:32:32.994, Speaker A: And I feel like rust, which is quite a very similar language to Ada in many ways, could go down the same path sometime in the future. Again, a lot of the same guarantees that Spark offers. What do you think?
00:32:33.894 - 00:32:36.914, Speaker D: Contract oriented programming, like isol style?
00:32:37.494 - 00:32:41.654, Speaker A: It's kind of halfway between contract oriented programming and dependent types.
00:32:41.774 - 00:32:51.742, Speaker D: Okay. And should you, the programmer, have a good idea of whether that's going to be executed at runtime or statically? Have an intuition.
00:32:51.918 - 00:33:19.334, Speaker A: So the answer is that it will always work. Okay, so you could write it to be always executed at runtime, or you could write it to never be executed at runtime. Like, you would pick one or the other. That's how it works in Ada, at least. Like it's always runtime if you just compile it with a regular compiler. But then if you run like this spark thing on it, it just proves that it will never ever ever panic. And then if it will never ever panic, then it will just compile it with none of the runtime checks.
00:33:20.054 - 00:33:45.054, Speaker C: Kind of reminds me of this kind of trend that we have in high assurance cryptography where we're trying to automatically generate code that is formally proven to execute correctly. We often want to act, we often do this, and then we look at the code and we can't read it. And so. Well, okay, I guess you can download.
00:33:45.094 - 00:33:45.674, Speaker E: The.
00:33:47.384 - 00:34:16.516, Speaker C: The proof of the verifier, the prove that the code is generated, and hopefully everything's okay with that. Whether that proving system is correct, doesn't have bugs in it or what version you should get of it or whatever. And it's kind of an interesting alternative is writing clean code and then proving that it's secure instead. Yeah, that's important from a crypto perspective, perhaps as well, it should be said.
00:34:16.540 - 00:34:34.764, Speaker A: That like this spark code is like, you couldn't write a large scale, like full program because it's just incredibly restricted, like Misera C as well, it's another similar project which is like how NASA writes c, and it's incredibly restricted, like, you can't use pointers basically, I think, at all.
00:34:34.804 - 00:34:37.144, Speaker C: Do they use animated tools to check them?
00:34:37.444 - 00:34:40.008, Speaker A: The. I don't know. I don't know. I out think it's just like they.
00:34:40.016 - 00:34:41.376, Speaker E: Just have a reviewer go through the.
00:34:41.400 - 00:34:44.200, Speaker C: Whole PDF to make sure that every single rule is being.
00:34:44.312 - 00:34:57.952, Speaker A: At one point that was, well, I mean, this is the thing that you see because like cs, so like it has all this like legacy and like we have, we, the compilers are very trusted where something new and like Rust is like so untested that they have.
00:34:57.968 - 00:35:04.426, Speaker B: 100% branch coverage and static analysis. We'll like, we'll do a good job of identifying a lot of those problems.
00:35:04.450 - 00:35:06.414, Speaker A: Yeah, true. But I think aliasing.
00:35:08.194 - 00:35:09.570, Speaker E: Aliasing bugs.
00:35:09.722 - 00:35:54.104, Speaker A: Aliasing, yeah, aliasing bugs. But I think like just the runtime checks, like Rust's index out of bounds, things are not enough. Like I was talking to a guy at the European Space Agency who said that he wrote like rocket guiding code in ADA, not spark, and it was like it had a bug in it where there could be an index out of bounds. And ADA did exactly like it maintained memory safety. It panicked. That was caught by a sort of supervisor program which did exactly as it should, which is restart the program, but it got exactly the same input again, panicked again, and then it just ended up in this loop of runtime panics. And then eventually the rocket fell over and died unexpectedly.
00:35:54.104 - 00:36:09.256, Speaker A: No, one was killed. This is like an unmanned rocket. But like, this is the kind of thing where like, I think that the just having panic if it fails is not enough. Like, you need to have very strong guarantees at compile time that you can, like, formally verify.
00:36:09.440 - 00:36:20.564, Speaker E: So I think you've all talked about it overflow. So does that mean all of your rust code in the three projects are all using the check types, the check methods for.
00:36:22.804 - 00:36:26.356, Speaker C: I don't think I ever use unchecked. Yeah, I mean, I've never.
00:36:26.500 - 00:36:29.464, Speaker A: Cool. But I'm just curious.
00:36:30.004 - 00:36:33.100, Speaker D: But it's an object where algorithms and data structures.
00:36:33.132 - 00:36:35.308, Speaker C: No, not in the crypto stuff.
00:36:35.356 - 00:36:38.184, Speaker A: It's just you always use, like, don't check that.
00:36:39.764 - 00:36:42.024, Speaker C: Not, no, not check that.
00:36:44.364 - 00:36:53.954, Speaker A: Yes. Right. Like, you use specific ones that don't have. This is exactly how it works with us as well, because most of the crypto stuff is like, supposed to work. Yeah.
00:36:57.854 - 00:37:28.134, Speaker D: So I guess I have maybe a more pragmatic view compared to formal languages. And maybe this comes from my experience of all the work that Anatoly and I did in Haskell for Qualcomm and that we, we had, you know, we built all this software and it was, we did a lot of stuff in the type system and it worked really, really well. Except for that we were the only two humans in the group that knew what was going on.
00:37:28.754 - 00:37:30.454, Speaker B: What's that, 30,000?
00:37:30.914 - 00:37:32.626, Speaker E: There was a couple others across the.
00:37:32.650 - 00:38:11.530, Speaker D: 30,000, but 20 or 30 that we were working with, if anybody wanted a different feature, they would have to go through us. And that's kind of a shame, right? Or I'm so maybe a little more jaded too, about. I looked at the proof of quicksort in Agna. It just kind of proves that it will generate a sorted list. And I was thinking, oh, you know, the average complexity of quick sort is. What is it? Is n log n or something? No, no.
00:38:11.602 - 00:38:12.654, Speaker A: Couldn't tell you something.
00:38:12.954 - 00:39:12.568, Speaker D: But merge sort and Tim sort are a little better. In the best case and average case, I'm like, well, can I have those? And like, no, this is what we have the formal proof for. So I think if you're going to go down, down that route, you have to be really, really, really certain that you got your algorithms and data structures just perfect, and that's where you're going to keep them. And then you can take this next level of polish to say, okay, let's try to find those very last bugs. And that in the meantime, you're really going to get a lot better. Bang for buck with I think branch coverage is really just the best is that you have a test and you're checking all of the edge cases to ensure that all conditions are checked. And yeah, there's a couple, you know, like Boolean type of issues where you can miss that mis coverage there.
00:39:12.568 - 00:39:32.944, Speaker D: But the ROI is just so good in rust and all the rest of the safety guarantees in rust that make that branch coverage meaningful as opposed to a c where you can look like you have 100% coverage and in fact you don't at all because you have this undefined behavior.
00:39:33.104 - 00:39:52.226, Speaker C: Another really nice feature for generics is writing tests that are generic over these concepts and you can get into the algorithms and not have to worry about the objects themselves and how they work and move along. And kind of test driven developments helped a little bit more. When you have access to types like.
00:39:52.250 - 00:39:54.442, Speaker A: That, what do you think about tools like quick check?
00:39:54.578 - 00:39:55.574, Speaker E: Quick check?
00:39:56.274 - 00:40:58.784, Speaker D: I don't like quick check, actually. No, it's a quick check written by John Hughes Haskell version. Yeah, the Haskell version of, and it's been ported to every language basically because I guess a lot of people do like is property based checking. So if you write your test in this form that says, usually it's something along the lines of, if I do this operation, it'll equal the result of this operation for all x, and then it goes and generates all of those different x's and tries to find the edge cases that'll fail. And my experience there is, well, this first, if you actually leave it in its naive form, you're going to keep generating all of these random cases for it, going through the exact same code path 90% of the time. And it just makes your test suite very long. And all you really want is to catch those edge cases which is already identified by the branch metric most of the time.
00:40:58.784 - 00:41:14.852, Speaker D: So again, coming back to, I think that branch coverage versus line coverage, branch coverage is so incredibly meaningful that you can just have these couple very fast running test that gives you almost exactly the same guarantees that you would get from quick check.
00:41:15.028 - 00:41:32.412, Speaker A: I guess that's what tools like AFL, like, these fuzzing tools, they're like similar to quick check where they generate lots of data and then try and like convert that large amount data to like a smaller set that causes the same bug. Yeah, except they, it's amazing. Like what's the, what's the other one.
00:41:32.428 - 00:41:37.408, Speaker B: Is the Google generates, generates an image.
00:41:37.456 - 00:41:37.928, Speaker A: Yeah.
00:41:38.056 - 00:41:48.152, Speaker B: So it's like it's basically verifying JPEG parser and it generates a JPEG randomly, like effectively figures out what the opcodes are in the beginning for it to.
00:41:48.168 - 00:42:31.004, Speaker A: Be a valid JPEG, we were fuzzing like the WaSM implementations like V eight and Spider monkey, which is Google's and Mozilla's WASm interpreters, actually WASM jit compilers to like work out whether or not we can use the blockchain. So we were fuzzing them. It would like generate like these valid wasm files after a very long time. And we like found cases where it would like, a small file would cause an unbelievably long compilation time, which is like, not, you're not, you can't have that on the blockchain at all. It needs to be a linear. It either needs to be linear or you need to like use gas on the compilation process, which you don't want to do. So it makes everything slower.
00:42:32.264 - 00:42:40.684, Speaker D: Yeah, I was just thinking, we've all been talking for about an hour. Can I really want to hear from.
00:42:42.144 - 00:42:57.164, Speaker E: Testing your branch coverage metric? Yeah, I'm a little skeptical of branch coverage. It's sort of a false certainty coverage. But your program can still go up at runtime just based on different input. Might take the same control.
00:42:57.744 - 00:42:58.536, Speaker D: Absolutely.
00:42:58.600 - 00:42:59.056, Speaker E: Yeah.
00:42:59.160 - 00:43:00.544, Speaker A: Definitely incomplete. Yeah.
00:43:00.584 - 00:43:08.392, Speaker E: So the state of the art nowadays in CNC community with this sort of testing is combining fuzzing with sanitization.
00:43:08.528 - 00:43:17.404, Speaker D: Okay, so you guys familiar with sanitizers? Extremely. I actually worked on the LLVM team for three years and worked on porting the sanitizers to the on back end.
00:43:17.724 - 00:43:18.704, Speaker A: What do you got?
00:43:22.964 - 00:43:39.340, Speaker E: Yes, it's combining fuzzing techniques with either working with Asan or MSan or Ubsan or TSAn. Pick your flavor one at a time. I think that's probably more important than strict branch coverage.
00:43:39.412 - 00:44:40.684, Speaker D: Okay, so I guess two things here. One, I say branch coverage better than line coverage is really a very key thing in that if as a manager or leader, something, you tell your coding, your team that you want to have 90% code coverage or line coverage, it's really, really easy to achieve 90% line coverage. But 90% branch coverage is actually very difficult and far more meaningful that you've actually exercised 90% of the code path. So from a management perspective, that's kind of the view I'm looking at there. But now, from the sanitizer's perspective, being in rust. So one, actually, one of the. Maybe the biggest reason why I'm in rust, and maybe I should have explained it to the start, is that having worked on, on the address sanitizer, the thread sanitizer, the UB, the undefined behavior sanitizer.
00:44:40.684 - 00:45:09.804, Speaker D: It really made me think about how much easier life would be to just code and rust rather than be required to have 100% branch coverage and run all three of those tools and still not quite get the same level of guarantees. And I worked in the embedded space where running the address sanitizer would cause it a three x memory overhead. And that was the good one.
00:45:09.844 - 00:45:11.516, Speaker A: That was the right.
00:45:11.660 - 00:45:53.102, Speaker D: You run the thread sanitizer, and it's kind of memory mapping the entire address space is a huge, huge amount of overhead there. And then you look at actually in the address sanitizer, that three x overhead, what is that? It's actually putting these landing pads on the outside of every memory location and saying that if you go and write to one of those memory locations by accident, then you must have had an out of bounds error. Well, what happens if you actually overshoot that thing, then that is still missed. And so rust just catches all those at compile time, including the thread sanitizer ones, which is the tool that I just never want wanted to, to run, honestly.
00:45:53.158 - 00:45:53.754, Speaker B: So.
00:45:56.654 - 00:46:00.674, Speaker A: I've never used thread sanitizers. Yeah.
00:46:01.294 - 00:46:29.894, Speaker D: So I was in the embedded system, and I was using these tools to run chrome. So building the whole chrome browser and running that in the embedded space. So that was a huge application. And so they even have the three times overhead of the address sanitizer was very difficult, and you'd actually end up just debugging problems related to having a bigger file instead of the problems that the address sanitizer was supposed to find. So. And then the thread sanitizer was just ten times worse.
00:46:32.354 - 00:46:34.734, Speaker E: I had a user.
00:46:35.954 - 00:46:37.466, Speaker D: Were you boulder last?
00:46:37.530 - 00:46:38.634, Speaker E: I was a boulder last time.
00:46:38.674 - 00:46:41.522, Speaker D: Okay, cool. You presented just before me.
00:46:41.578 - 00:46:42.174, Speaker C: Yeah.
00:46:43.634 - 00:46:55.890, Speaker E: So if you tried writing asan on your rust code basis, not even surprised by it, does it? I have, yeah. A lot of popular crates do not use.
00:46:56.042 - 00:46:58.334, Speaker D: That is not unsafe code.
00:46:58.954 - 00:47:00.066, Speaker E: It's unsafe code.
00:47:00.130 - 00:47:01.614, Speaker D: Okay. Yeah, yeah.
00:47:02.314 - 00:47:04.094, Speaker A: It's also like unlock.
00:47:04.874 - 00:47:10.154, Speaker B: There are three cargo flags that just warn you when you're pulling in unsafe packages.
00:47:10.814 - 00:47:17.714, Speaker A: There is. So you can do things on your crate to warn where there's unsafe code. So you have to deliberately do allow unsafe and certain things.
00:47:22.134 - 00:47:24.674, Speaker B: They can fix it with graphene, I guess.
00:47:26.214 - 00:47:39.084, Speaker A: I mean, that's the beauty of rust. You can't fix that with graph. In C, you make a make file transitively for the white list.
00:47:41.024 - 00:48:00.472, Speaker E: So, Greg, on your slides, when you're talking about Solana, you mentioned that to help you not duplicate data and duplicate work, you would shard, you would split work up. And I was wondering if you could comment on kind of. That's a hard problem.
00:48:00.608 - 00:48:01.316, Speaker D: Yeah, yeah.
00:48:01.440 - 00:48:07.812, Speaker E: I was wondering if you could comment on that as much as you're willing or comfortable to, and maybe how you use rust to help you solve that problem.
00:48:07.908 - 00:49:35.944, Speaker D: Okay, so what I had said is that there, that is the sledgehammers of scaling solutions to do any kind of horizontal data partitioning, sharding being one of them, and that we have deliberately chosen Solana not to go down that route because it, it adds a lot of software complexity and security implications. So every shard would need to have a separate set of mining resources, watching it, making sure that that shard is valid and true of any kind of horizontal partitioning. So lightning network as well. So you'd have to understand that if you only have this fixed set of resources to verify the blockchain, you're now either having to add resources or split those resources up, making if you have a proof of work chain, for example, making you more vulnerable to a 51% attack. And so we have chosen to not take on any optimization that might have implications on the security model, with the exception of choosing to use, I guess, proof of stake rather than a proof of work, which of course is a very different security model, but has that original premise that saying that you basically can't do optimistic currency control without it. So, and I guess I misunderstood then.
00:49:36.484 - 00:49:42.740, Speaker E: Would it be possible if you go back to that picture or to the slide? Is that okay? There was a picture where you had, like, I thought you were sharding.
00:49:42.772 - 00:49:46.528, Speaker D: Maybe I misunderstood something. No. Yes.
00:49:46.616 - 00:49:48.584, Speaker E: Yeah, you were talking about data and I assume you're.
00:49:48.664 - 00:50:25.536, Speaker D: Yeah, no, so, yes, I was really trying to keep this under ten minutes. Failed so badly. And I really noticed that when I got to this slide. So, so these are, these are all validators except for that top one is the leader node, and this is, these guys are organized in a logical tree. And so this is not charting at all. This is just the leader needing to get the block out to all the validators. And so that way they could validate all the transactions and send that, their validation vote back up to the leader.
00:50:25.720 - 00:50:29.164, Speaker E: So you were distributing, you're distributing the work, the validation?
00:50:29.824 - 00:51:04.510, Speaker D: No, actually, not at all. So we split up the, we split up the block. But you don't value validate the split up block. You actually, that's what all these kind of crazy arrows are between the validators, is that which. So if you follow this white line, for example, this is taking, say, half of this block, sending it to this validator, and it goes and it sends its half over to that validator as well as down to this next level, which will send it to its peer. And so all validators end up being able to reconstruct these original block and validate that full block.
00:51:04.622 - 00:51:05.062, Speaker A: I see.
00:51:05.118 - 00:51:05.886, Speaker E: I understand.
00:51:06.070 - 00:51:06.942, Speaker A: Cool, thanks.
00:51:07.038 - 00:51:07.834, Speaker D: No problem.
00:51:09.374 - 00:51:09.838, Speaker E: Sorry.
00:51:09.886 - 00:51:10.406, Speaker A: Quick question.
00:51:10.470 - 00:51:13.154, Speaker E: How do you determine membership within the.
00:51:13.574 - 00:51:32.986, Speaker D: Different groups that's done over a gossip network? So that's separate. So there's this like n squared communication that's happening, coordinating who's actually participating in the network. And then they also organize this form, this logical tree to efficiently pass the data through this data plane.
00:51:33.050 - 00:51:38.498, Speaker E: So it's self organizing, randomized every now and again?
00:51:38.666 - 00:51:40.014, Speaker D: Yeah, absolutely.
00:51:41.074 - 00:51:41.618, Speaker A: Yep.
00:51:41.706 - 00:52:07.634, Speaker D: It's based on stake, really. And you know, there's kind of this feedback too. If there's, if these guys down here aren't able to perform well enough, that they're not able to validate it fast enough, or they don't have that gigabit connection, and we can get that two thirds majority without them in sub second finality, then they'll get kind of booted down to the bottom there. That's why it's a treat.
00:52:12.134 - 00:52:22.458, Speaker E: A bit suspicious that no one complained about compiled times yet. But my question is, I guess compile.
00:52:22.506 - 00:52:31.506, Speaker D: Times or link times? I'm sorry. Parity's got this massive, massive amount of crates, and so I can see how link time would be particularly problematic.
00:52:31.610 - 00:52:36.694, Speaker A: I think the link time is mainly a problem if it's like incremental compilation, which we do use.
00:52:37.474 - 00:53:03.670, Speaker E: At some point our build dependency graph wasn't as optimal as it is now. But my question, I guess, is mainly directed Sean, which is, to what extent does rust makes it harder to write cryptocurrency, particularly with stuff like side channel attacks and memory location and just the compiler trying to be smart.
00:53:03.862 - 00:53:17.614, Speaker C: So thankfully I've been able to avoid having to deal with side channel attacks because the crypto implementation work that we've been doing, we're replacing code that's written in c, that is full of variable type.
00:53:18.394 - 00:53:19.850, Speaker A: And so I can just say, oh.
00:53:19.882 - 00:53:22.334, Speaker C: Well, it's written in rust is better.
00:53:22.914 - 00:53:25.530, Speaker A: It's exactly as shit as the exact code.
00:53:25.642 - 00:53:27.054, Speaker E: It's a little more prettier.
00:53:27.474 - 00:54:52.460, Speaker C: But I think rust does need cost generics so that you can write some elliptic curve stuff and keep track of magnitudes of wind sizes and things like that. You have the field elements like that in certain cases when you're trying to eke out performance, but I found that you can get pretty good performance out of just the basic operations and not having to worry too much about doing cost generics and sophisticated types and stuff like that. Yeah, actually writing crypto code in rust was pretty, pretty fun. In zcash, we do a lot of multicore stuff because we have to split these fast Fourier transforms off into multiple threads and do all these multi exponentiations and stuff. And it's really nice to be able to just hand this off to libraries that can maximize the use of the user's machine, not have to worry too much about memory safety and issues, reuse heap allocated objects, and do all these kinds of things. Very nice, actually, especially the multicore side. I think that's something that a lot of crypto work that's done in general usually just focuses on single core performance because they're trying to make constant time things.
00:54:52.460 - 00:55:29.148, Speaker C: But we've been able to write and explore crypto and rust in the context of multicore stuff and batching and all that kind of stuff, and we've had a lot of success with it. Actually, I have, a long time ago, and I wasn't happy with it at that time. Now I'm very happy with Rayon, and I hope to move all of our stuff to rad. But right now we use a mixture of like scope threads in futures and things like that. Hopefully move it all into rayon.
00:55:29.316 - 00:55:36.024, Speaker A: Do you mind if I ask if side channel attacks may be a problem? It's just that you haven't got around to making constant time.
00:55:40.324 - 00:56:33.928, Speaker C: It's mostly a performance thing. The most expensive part, part of constructing these proofs that we do in zcash are these multiexponentiations, and they're over very large elliptic curve groups. And so we need to use multi exponentiation algorithms that are really fast, and those are variable time and they are to variable memory access and cache stuff and all that kind of thing. So it'll be a challenge to approximate that performance while still having side channel resistance, I think. So that's. It's mostly performance thing, just trying to keep the performance, because right now, I mean, we spent a couple years getting our proofs down from 40, from 40 seconds down to like 2 seconds. But if we were to throw constant time into the mix, we'd lose most of that, probably.
00:56:33.928 - 00:57:30.316, Speaker C: So the interesting thing is though, that we've kind of tackled this problem a little bit by rearranging the way our protocol is designed. So these proofs require this expensive operation that needs to be parallelized but we've redesigned the proofs in the way that it's constructed so that the proofs don't handle secrets for our particular construction. Well, they handle, not secrets that would allow you to steal money from the person. If you were to violate, do a side channel attack or something like that, you could compromise their privacy with a side channel attack, because the proof has all this private context, but it doesn't have the authorization to spend money, for example. So we've split out that authority in the construction in such a way that we aren't as worried about the variable timeliness of the ZK stark proof generation code. It's not as critical. It's something to definitely tackle in the future.
00:57:30.316 - 00:57:38.174, Speaker C: And I've started working on, on constant time versions of all this stuff, but I just don't know if it's going to end up being too slow or not.
00:57:39.914 - 00:57:42.214, Speaker B: Is this all in the Belmont repo?
00:57:43.754 - 00:57:45.242, Speaker A: Which, the constant time stuff?
00:57:45.298 - 00:57:47.594, Speaker B: No, your CK snark board.
00:57:47.674 - 00:57:47.986, Speaker A: Yeah.
00:57:48.050 - 00:58:29.526, Speaker C: So Bellman currently is a library for doing ZK snark, constructing ZK snark proofs, and we're actually hoping to split it up so that, that I have a different library doing ZK snarks. And Bellman is mostly about doing the circuit, the arithmetic circuit stuff that we end up having to do in various proofing systems, not just ZK snarks, but things like bulletproofs and so on. Bellman doesn't have the elliptic curve cryptography implementation, these special curves that we use in snarks, that's in a different library pairing. And, yeah, we're just splitting this all off into pieces that we can reuse.
00:58:29.550 - 00:58:30.862, Speaker A: And people can use.
00:58:31.038 - 00:58:56.714, Speaker C: I haven't published my current work in progress, constant time stuff, because actually I have, and it's full of bugs. If you go on my. If you go on my GitHub profile and you type HSDF and then there's this long, just like, because I smashed my keyboard because I didn't want anyone using this library. So, like, what should I call this reply repository code? Do not use. That's where my current work in progress.
00:59:02.334 - 00:59:23.694, Speaker E: Another one for Jack. So you mentioned that you were doing some interesting stuff with webassembly in your clients, and webassembly is pretty new technology. The tooling is very limited, and it's very nice that when you also can target webassembly, but there's a lot of risk you in there, and could you talk about some of that risk, why you took it on some of the challenges?
00:59:23.774 - 01:00:02.682, Speaker A: Right. I definitely agree that, like WASm is new technology and untested in many ways. Technology. The reason we chose it is because we needed a virtual machine target that was fast and that could be compiled to from existing languages because we learn our lesson with ethereum and solidity. Solidity crap. The tooling is crap. It's very hard to write bug free code in solidity because it was never intended to write bug free code in solidity.
01:00:02.682 - 01:01:03.554, Speaker A: It was intended to be JavaScript that runs on the blockchain you could make so you can make a decision as to whether or not that was a good idea. So we wanted to have something where it would be like a sort of rallying point for multiple different languages and really like building our own. All of that would be a false errand. But really the only thing that lives up to that would be either taking an existing architecture like Arm or X 86, and then just emulating it on the platforms that are on our X 86. But the problem with those is that they're quite hard to verify that they're correct. You'd have to run them inside of a sandbox to prevent them from blowing up. Whereas webassembly is already built so that you can very quickly, in linear time, scan over the whole of a webassembly module and check that if you compile that down to the machine code, that it won't jump into a function that it doesn't control, that it won't set fault, or that it won't cause undefined behavior.
01:01:03.554 - 01:01:16.334, Speaker A: Like these are all things that are built into the design of webassembly already. So it solves a lot of the problems that we already wanted solving for a blockchain virtual machine.
01:01:17.074 - 01:01:19.454, Speaker B: Do you guys run these without memory protection?
01:01:19.754 - 01:01:53.978, Speaker A: We do not, no, we run them with memory protection right now, but the web simulation, so that you would not necessarily need to do that. At the moment, we don't compile it to machine code at all, we just interpret it. We actually compile it to this intermediate language, which is faster to interpret. It's kind of like a midway between compilation and interpretation. Like our guy, my boy Sergey, he implemented that very small guy. There's actually a different webassembly interpreter that does the same thing of compiling to an intermediate step, which is like significantly faster than our interpreter. We have no idea why.
01:01:53.978 - 01:02:29.286, Speaker A: So who would have liked this, like one week old newsletter trying to work out how the hell there so far? Yeah, we're not compiling to machine guide yet. I don't know if that helps you. There is actually an article written by me. I'm going to plug myself. That sort of explains why we chose webassembly, and it should be on the Polkadot blog any moment now. It's not quite there yet, but it's currently on my blog. But I don't know, I don't have an old business card or a thing.
01:02:29.286 - 01:02:34.918, Speaker A: I can tell you about it later. Okay, cool.
01:02:35.006 - 01:02:42.994, Speaker B: Do you guys wanna hang out? Drink beer, eat pizza? Any party thoughts?
01:02:46.114 - 01:02:51.174, Speaker A: I mean, at this point I've been up like 4 hours. I don't know if there's any thoughts at all.
01:02:52.194 - 01:03:35.894, Speaker D: I am definitely a fan of rust. Like I said, I've actually studied programming languages pretty much my whole career. And actually as I transitioned between languages, it's usually because I kind of got in my head, I'm going to, going to go build my own language this time. And then as I'm googling, as I'm googling that, reminding myself of that 100 point checklist of what it takes to actually launch your own programming language, I end up finding some language that already implements it. And that's kind of how I found rust this time around. And right now I'm not looking for another programming language. I'm really happy here.
01:03:35.934 - 01:03:37.094, Speaker B: It's like the sweet spot.
01:03:37.134 - 01:03:40.634, Speaker D: It's the language I think that I would have written myself.
01:03:41.534 - 01:03:44.354, Speaker C: So now you can start learning your own procedural macros.
01:03:47.254 - 01:03:49.114, Speaker D: Good stuff, good question.
01:03:50.294 - 01:03:58.674, Speaker E: So after trying to convince everyone that I talk to about rust, the one thing that keeps running back at me is failure. On Malloc.
01:04:00.834 - 01:04:06.370, Speaker B: You can, what are your compilers without an allocator? You can compile without an alligator.
01:04:06.402 - 01:04:11.282, Speaker A: You can still fertilize that? Yeah, like there's nothing to stop.
01:04:11.338 - 01:04:13.226, Speaker D: This is the one thing I'm trying.
01:04:13.250 - 01:04:15.418, Speaker E: To convince one person and keeps telling.
01:04:15.546 - 01:04:18.174, Speaker B: Lua, but Lua, yeah, yeah.
01:04:38.734 - 01:04:42.674, Speaker A: And it's an uncapture, really.
01:04:44.254 - 01:04:46.754, Speaker D: I am assuming that Malak will succeed.
01:04:51.854 - 01:05:16.512, Speaker A: Malaki succeed, which is actually a problem. So we have like this constantly running parity node in our office and once every few weeks, because it's quite a small box, it's just with like some public box that we've got verifying it, it'll just like come up with like the windows. Like parity Exe has stopped working and it's got all these like memory things in the background. Like it is a genuine thing that I feel like rust could deal with better, but it is. They're working on it. They are working on the allocator API.
01:05:16.688 - 01:05:31.516, Speaker B: There's an allocator library that we wrote for the compression stuff we did at Dropbox, that it's open source, you can Google for it. And that was that. Basically solved that problem. We were able to run in constant time without any allocation.
01:05:31.580 - 01:05:32.676, Speaker A: No system calls.
01:05:32.780 - 01:05:50.204, Speaker D: Cool. And now we're calling in Lua. It's actually when you're embedding Lua that the C API actually has a runtime or a hook that you can hook into and say that if it does fail, then you can actually go outside of Lua and go free up some memory.
01:05:50.624 - 01:05:54.184, Speaker E: At least they're catching it rather than just being killed.
01:05:54.264 - 01:05:54.648, Speaker A: Yeah.
01:05:54.736 - 01:06:05.604, Speaker D: Kind of specific to a dynamically typed programming language. And that you can kind of catch it and still do something useful outside of it. So I don't know how that really.
01:06:13.834 - 01:06:15.986, Speaker A: You can do it if parity abort.
01:06:16.050 - 01:06:17.334, Speaker E: We do have like a super.
01:06:20.914 - 01:06:35.226, Speaker A: I don't know if this is like, we've already gone too far, but, like, zig actually handles this exact thing. It also handles stack overflows, like, in a way that works hard time. It's really impressive. It's still like super research. Don't use zig. Don't use. It's like.
01:06:35.250 - 01:06:37.402, Speaker E: It does handle, like, these available allocations.
01:06:37.498 - 01:06:40.154, Speaker A: And staggering twice as well.
01:06:40.614 - 01:06:53.310, Speaker E: Yes, but what I predict is that basically every single line in your screen program can fail. I don't think that's true.
01:06:53.342 - 01:07:04.334, Speaker A: I don't think that's true. Like, you fail at allocating a frame. And like, the way that you prevent, like anything, like any fail is like, it's just.
01:07:04.374 - 01:07:04.518, Speaker D: It's.
01:07:04.526 - 01:07:28.234, Speaker A: It becomes like, not turing incomplete because you can still infinitely loop, but, like, you don't. You can't infinitely allocate memory. Like, there's like a maximum amount of memory your program can ever allocate on the stack. That's how it solves. It still does have like, panics and backtraces, but, like, it has a lot more tools to avoid than.
01:07:30.954 - 01:07:31.586, Speaker D: Closing word.
01:07:31.610 - 01:07:33.810, Speaker A: Sean, you good? Drink?
01:07:33.842 - 01:07:34.454, Speaker D: Beer.
01:07:37.594 - 01:07:38.474, Speaker B: Thank you guys so much.

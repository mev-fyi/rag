00:00:03.440 - 00:00:03.648, Speaker A: Hello.
00:00:03.648 - 00:00:40.815, Speaker B: Hello. Hey guys. My name is David and I'm from Tencent Cloud. So happy to be here to present to you guys. And Tencent Cloud is a worldwide cloud computing services provider and it's happy for our team to be here and present to the Solana Ecosystems. So we are based in China and our international team is headquartered in Hong Kong. So maybe a bit of background introductions to you guys about Tencent.
00:00:40.815 - 00:01:14.295, Speaker B: So Tencent is the largest public listed company in China and we also built two of the largest social media platforms in China, so called WeChat and QQ. So for WeChat we have about 1.3 billion monthly active users and for QQ we have about 5 millions. So that's where we're coming from. Right. With the social media platforms, we also built games around it. So perhaps you guys have played Honors of kings and PUBG mobiles.
00:01:14.295 - 00:02:10.605, Speaker B: And we also invested into 300 gaming studios worldwide, including Riot Games and also Epic Games. So all of these applications, games and social media are actually built on Tencent Clouds. And we went international about five years ago and not only we are serving enterprise, we are also serving consumers worldwide now. So only in the international markets, we have about 1.2 billion users worldwide now. So on the one hand we serve those consumers with retail products and on the other hand we connect enterprise with those consumers we have in the international markets. So where we are, right, so we are the international team, so we serve anywhere outside of mainland China.
00:02:10.605 - 00:03:12.345, Speaker B: So currently we have about 21 regions and 58 availability zones worldwide. As for myself, I look after the strategies for international markets. So if you guys are actually from some of the other regions, feel free to talk to me about more info in the local markets. So as I said, Tencent is a very diverse company. So when we actually extracted the technology capabilities from the Tencent group and output it to the various industries, we work with all of these different industries worldwide, name it, be gaming, social media and finance. But actually in Web three we work with most of the leading players now. So we work with most of the top crypto exchanges, we work with gamefi projects and also work with different sets of service providers like wallet solutions and staking providers.
00:03:12.345 - 00:04:26.635, Speaker B: So maybe focus back onto Web3. Right, so in the international markets we have about over 200 products and services, but for Web3 we actually categorize it into three tiers. Cloud, Security and innovations. For cloud, we provide cloud computing services and infrastructures to empower different blockchain applications for securities, we provide user safety and also fraud preventions to protect the different applications and for innovations we bring immersive customer experience and also super application capabilities for different applications. So in the following time let me perhaps give three product use cases specifically for Web3. So the first one we have is the Super Application platform. It is basically a very low code technical framework that can be easily embedded into any applications and then transform it into a super applications.
00:04:26.635 - 00:05:49.335, Speaker B: Think of WeChat, right? And also what Telegram is doing now, it's basically attracting the different applications into one super app and it enhances the ecosystem growth in the longer term. So one of the Web3 leading gaming technology companies is actually working with us with these products. So basically they integrate this framework into their existing applications and that allows the different GameFi projects to transform their existing GameFi projects as mini apps and they get embedded into these grand super app applications. And the different functions that were supported in the mini program applications framework are different wallet systems and NFT minting capabilities and also cross chain capabilities. The second product I would like to maybe intro to you guys is our full sets of Media Services SDKs. So the client we are working with is actually one of the top three centralized exchanges in both spots and derivatives. This client built their live streaming and also video on demand platforms 100% on Tencent Cloud's media service SDKs.
00:05:49.335 - 00:06:55.019, Speaker B: So with these products they actually built the most vibrant online crypto communities that have attracted thousands of Kols to share their insights and perspective on their live streaming platforms and allow the platform to acquire more users across the globe. The last product use case I would like to pitch to you guys is actually the cloud computing infrastructures. So we are working with one of the top three staking providers worldwide. These providers, they are European based, they have about US$5 billion asset under management. So basically we provide GPUs and CPUs for them to run the different blockchain nodes. For example in Solana, in Ethereum, in Celestia, in Polkadot, you name it, all of the mainstream tokens. So with our infrastructures they're able to uphold the same 99.9%
00:06:55.019 - 00:07:54.205, Speaker B: uptime and also we support them to cut their running IT infrastructure costs by about 50%. So that would be a wrap to my introductions for Tencent Cloud internationals and also some of the product use cases we have. I'm happy to introduce you guys to Beware Labs. So together we are building some products for the Solana ecosystems. The solutions are a archive data service and also in the future we are building some RPC node service only tailored for the Solana builder ecosystems. The solutions are easy to employ, it is very cost effective and is 100% tailored for the Solana builders. So next on let me invite Cosmic from Beware Labs for introducing more about the Beware Labs and also the new product launch.
00:07:54.205 - 00:07:57.085, Speaker B: Thank you all and let's welcome Cosmit.
00:08:13.785 - 00:08:52.841, Speaker A: Hello everybody. First, thank you David for introducing me. I'm happy to see you here at Singapore and I hope you're having a great time. My name is Kosmin, I'm part of Beware Labs and today I would like to present you our archive solution which enables data availability for solar builders. My presentation is going to be a little more technical, but bear with me. First, let me give you some context about Pure Labs. We are focused on providing one of the highest performance infrastructure for Web3 services while also having one of the best prices on the market.
00:08:52.841 - 00:09:44.615, Speaker A: We focused on growing our business horizontally, meaning that we serve a lot of networks and we have very quick integration times. We can accept new ones, we can expand our services a lot faster. But in order to get to the next level, we decided to agree an acquisition offer for Alchemy. So I think together we can improve the Solana ecosystem and the Web3 ecosystem as a whole. Let's talk about the main two problems that we tackled in this solution. First one, the data availability. I mean you can get access to this data, but you either have to use a provider that already got access to it and you have to pay it, or you can ask for Solana foundation to give you and give you access to their BigTable instance.
00:09:44.615 - 00:10:05.755, Speaker A: In case if you don't know the Solana historical data is stored in a Google instance, in a bigtable instance and it has like around 1.5 petabytes of data. And once you get access to it, you will find out that it costs a lot to move it away. The egress traffic, it's amazing.
00:10:05.795 - 00:10:06.655, Speaker B: It's huge.
00:10:07.525 - 00:10:56.671, Speaker A: It will take you around 130k to migrate the data to another storage because you have to use Google Tools, you have to use Dataflow and Dataflow only allows exporting data to Google Storage. And if you want to store 1.5 petabytes of data in Google storage, it goes to around 60k or 90k for the storage and egress traffic. It's the rest of it, it's like 40k. We managed to lower the cost with a lot more 30k by using Tencent's cloud infrastructure, like cloud object storage for cold storage over a longer period. And we built our own internal syncretic programs that move the data around. They're built in house.
00:10:56.671 - 00:11:26.673, Speaker A: So we get a lot, we got a lot. The price was lowered a lot. Let's talk about deliverables. First you get access to data. Of course it's publicly available, it's a 10 cent bucket. And you also get data syncing mechanism. Once you get your data you have to keep it in sync because the Solana network, it's a very high throughput network and is generates a lot of data.
00:11:26.673 - 00:12:02.851, Speaker A: So you have the mechanism to keep it in sync and the data. And you also have some infrastructure automation tools like Terraform scripts just to make it easier for you to spin up your nodes and everything. And once you get access to the data, you can deploy your own cluster to serve data from it in house. You can build RPC services, you can build indexers or anything you'd like. It's the world, it's your imagination. But first we have to talk about storage. As I said, Solana is a very big network and it has a lot of data.
00:12:02.851 - 00:12:28.429, Speaker A: So we had to use Tencent cloud network storage as a cold storage in order to lower the cost and have a long term storage. But there is a problem with that. You can query it and if you want to serve data you have to query it. So in order to fix that we have a HBase cluster. It's the edge based cluster. It's a distributed system, just like bigtable. It's open source and anyone can use it.
00:12:28.429 - 00:12:57.451, Speaker A: You can host your own and be fine. So you ingest the data from Cloudwave storage into HBase on demand. You can build cache systems, everything you want. You can use the whole data. If you want to have the whole 1.5 petabytes of data, you can manage that or you can adjust just a few blocks, ranges, everything you like. The first process of syncing the data was to get all the data from the BigTable into cloud.
00:12:57.451 - 00:13:45.329, Speaker A: So we used BigTable as a data source and Densing cloud object storage as a destination source. We then built our cluster of programs, we call them syncrs. It's a distributed system, It's a cluster of multiple machines, meaning that we process the data distributely and in parallel on each machine. After we sync the data, we have to keep this in sync. And we know that Solana nodes have a thing called Gezer plugin. That Geyser plugin can export the data from the blockchain directly from the node without having to use some standard RPC calls. So we get the data from the Solana node that runs a Geyser plugin.
00:13:45.329 - 00:14:31.349, Speaker A: We read that and we upload it in Cloud Object Storage to keep the archive in sync. But as I said, you have to query it. And if you want to use only these two part of the solution you'll get some delays because you have to upload it in COS and then Cloud object storage and then you have to download it from Host and load it into your HBS cluster. And that takes time. But we know that Solana nodes are able to communicate with BigTable. So all you have to do is basically create an adapter that mimics Google BigTable's interface and you connect the Solana node to it and Solana node will think that he's talking with a bigtable instance. But in reality the adapter writes and reads to your HBIS cluster.
00:14:31.349 - 00:14:55.315, Speaker A: You can then connect Solana Lite RPC node like the one built by DexterLabs. We use that one. Thanks guys. And you can serve data from there. The last process is ingesting the data from the original data from the Cloud AWS storage. You have to sync your HBase and then connect the LiveSync into process state. This is how the final architecture looks like.
00:14:55.315 - 00:15:38.357, Speaker A: On the top right corner you have a Solana node communicating with the live syncing process. On the lower right side, the live syncing process absorbs the data into cloud object storage. And on the left side you have the initial archivesyncing process that uploads the original data into cloud object storage. In the middle you have the adapter and ingestor seeker that update your HBIS cluster. But if you want to use all of this, if you want to use the product, you don't need all of this. You initially, just initially need the ingestors to sync the HBIS cluster with the data that you want. You can then throw it away, don't need the synchros anymore.
00:15:38.357 - 00:16:18.387, Speaker A: And you need a Solana node with an adapter. Hook it up to HBiz to your HBitz cluster and you can then maybe build a cluster of Solana Light nodes or whatever you like to serve data from there. Finally, we have some deployment automation like Terraform scripts. You can deploy your own Solana node, your own Solana Light node and the HBIS cluster just by running some Terraform scripts with different configs. They will do the spin up intense and so you don't have to think any about all of the complicated stuff. That was all. I hope this product helps you.
00:16:18.387 - 00:16:32.235, Speaker A: And if you have any questions, feel free to contact us. Check out the GitHub. The repo is publicly available. There are multiple repos and feel free to we will be next stage if you have any questions. Thank you.

00:00:01.480 - 00:00:54.104, Speaker A: I'm going to give a talk about something I've probably talked with Anatoly about since 2019. I think at Devcon in Japan in 2019 was the first time we kind of talked about localized fee markets. Obviously, that's sort of something that's really big in Solana now. But one thing to kind of think about in the future is how do you optimize those? How do you make those better over time? So I'm going to talk about this. This is joint work with some folks at Bain, and we've spent a lot of time kind of thinking about how fee markets could look. And I think Solana is one of the best test cases for fee markets over the next coming years. So to get rid of the obvious fee markets with fixed relative prices, relative prices means price of compute versus price of storage are relatively inefficient.
00:00:54.104 - 00:02:07.372, Speaker A: And basically, this talk is talking about a framework to think about how to dynamically optimize fees within a network. So before we give an outline of it, why does this matter for Solana? As many of you have probably observed, local fee markets have been extremely amazing for the network. They've figured out how to sort of spread demand in a lot of different ways. But one question is, how do you actually do the load balancing across these local fee markets? So one way of thinking about Solana's fee markets is that you have a multi dimensional fee system where you have a set of arbitrary resources, and your resources are each Solana program. In some cases, validators effectively can charge for other services on top of that, such as proof generation. But one important thing to think about is what fee structures only work on Solana. And one interesting thing is the tight coupling between the execution parallelism and the actual execution of a program means that you can incentivize a lot of very different fee markets in Solana.
00:02:07.372 - 00:02:56.744, Speaker A: And I think one example is this notion of multi proposers, multiple proposers for censorship resistance. It's a lot easier to actually do that in Solana than it is in Ethereum. And I think that's the type of stuff that all the math in the next slides is really talking about. So keep that in your mind when you're thinking about this. Okay, so why are transactions so expensive? So in reality, and I think this ecosystem in particular, understands this the most. You kind of have this notion of, I have a calculation, I have a utility, I have a cost. So I have a bunch of cpu's, I have a bunch of bandwidth, there's some utility from the calculation, there's some cost in a one dimensional gas market, I just say everything costs three units versus, if I look at the utility minus cost of the previous section, it sort of should be four.
00:02:56.744 - 00:03:47.894, Speaker A: The problem is, I'm sort of implicitly only subsidizing the CPU correctly. I'm not actually charging you for the bandwidth. And in some sense, the two dimensional market is a lot more efficient where I charge you for each component separately. Okay, fundamental assumption here is orthogonal resources should be priced separately. All right, what is a resource? Well, let's think about the different things that go into every Solana program, or in reality, every blockchain contract. Well, anything is, everything is metered. And in some ways, this is a distinct difference between, say, cloud computing and blockchains, is that you actually really do have fine grade metering and fine grade cost measurement.
00:03:47.894 - 00:04:38.684, Speaker A: In Ethereum land, there's this current separation between storage and compute. And of course, in Solana, you kind of already done that, so it's maybe a separate thing. But compute, memory and storage, they all have different fees, different opcodes, different execution environments, sequences of those, and most importantly, compute on specific cores. So, as I mentioned earlier, you can think of a Solana program, how its execution, how you map accounts to how the program actually charges fees as something that's very unique to Solana that you can't really do on Ethereum. So let's now go into what the model is. We have a vector of resources. A transaction is an element in this vector.
00:04:38.684 - 00:05:17.278, Speaker A: And you can sort of think of this as a matrix. Each entry denotes the amount of resource I consumed by transaction. J. We have a vector which tells you which transactions are included or not included within a block. And we have a notion, a very simple notion, of the linear quantity of resources consumed by block matrix multiplication. Now, imagine that we have a network that has a target resource consumption. How much work do you want the validators to do per unit slot? One way of measuring this is the deviation of the linear resource consumption from a target.
00:05:17.278 - 00:05:58.348, Speaker A: So the target b star is how much work you want the validators to actually be forced to do. Ax is how much work they have to do, and you want to kind of minimize that difference. And a simple version of this, and I think in Solana becomes more complicated. You don't have a single b star, but you can think of b star in Ethereum as 50 million gas transactions have to satisfy this notion of a limit. You can't ever do more than a certain amount of resource. And that this notion, this kind of upper bound b is higher than b star. And one way of thinking about this is that we have a notion of prices, a price per unit of resource.
00:05:58.348 - 00:06:35.944, Speaker A: And the simple way of measuring the cost of a particular transaction is just take the inner product of the prices and the resources used by a particular transaction. Okay, very simple, econ 101. If you're exactly at the target, don't change any prices. If we're above the target, increase prices so that basically demand goes down. So this is this idea of, if I'm causing, if we, the users are causing validators to actually do significantly more work. Well, we should probably, the validator should increase the price on us. That's what the second bullet is.
00:06:35.944 - 00:07:21.624, Speaker A: The third bullet is the opposite. If the validators aren't making enough money relative to demand, you can lower the prices. There have been a bunch of proposals. One of the, this is actually a proposal that was common to what sort of issue anatoly brought up in 2021 as well as Vitalik in 2021. So there's sort of this interesting thing that people have sort of looked at pricing rules like this, which say, okay, well, I have this function. It's positive, always, and it targets this ax B star, does this work? And that's sort of what we'll talk about. So, intuitively, these update rules are solving some type of optimization problem.
00:07:21.624 - 00:08:19.914, Speaker A: They're sort of doing some type of gradient descent looking thing. But the real question is, if you're designing the network, if you're designing an application, if you're making an application that is using these update rules, you need to have a good understanding of how this behaves, how your program behaves, or how your network behaves. And this is sort of the designer question of how do I choose an update rule? Okay, now we get to the resource allocation problem. So imagine you have the network designer, that means salon of core devs, and they determine sort of this ruling for transactions in the block. They also determine some notion of how prices are, are computed. You can think of the network designer, the person who is assigning gas fees for each resource, as defining a loss function for this program, which is, you know, the idealized thing is you're exactly at the target all the time. That's not really possible, right? So you might relax that slightly.
00:08:19.914 - 00:09:20.634, Speaker A: Another thing you might say is, what are kind of the constraints on the things that you're willing to price? And one very important piece is that you need to think about how MEV interacts with these kind of prices. So what that means is that in this model, we sort of consider some notion of a relaxation. We allow sort of prices to be adjusted slowly. So a transaction can be, the idea of a transaction being included with a probability less than one refers to the idea that it gets included one every one of our XJ blocks. So you can think of this notion of the total utility of the system as the utility from the users who are getting some utility from getting their transaction processed, plus the utility from the validators. Like they actually need to earn sufficient fees to cover their costs jointly. You can think of them as getting this utility qj.
00:09:20.634 - 00:10:11.454, Speaker A: Of course, in practice you don't know q. So you need to solve this problem in a way that doesn't actually take advantage of what the exact utilities are. But the key thing that is somewhat surprising is that you don't really need to know q to arrive at an optimum. So the sort of naive version of this problem you would write is I have the utilities of the users and the validators q. I have the allocation, which is how I distribute the transactions x I have this loss function, which is sort of this cost inherent to the system. You could think of this as the validator cost, program cost, subject to this idea that I have this linear measurement of resource cost. So the goal is really to maximize the utility of included transactions while minimizing the sort of externalities placed on the network.
00:10:11.454 - 00:11:05.124, Speaker A: And you can think of this utilization y as sort of the resource usage of the transactions. X is the set of allowable transactions. Okay, in theory this sounds great, but in practice the Solana client can't solve this problem because I need q, right? I need to know what the utilities of the users are. Does this mean we give up? The answer is no. So one interesting thing that you can think about is that we can actually get rid of the user utilities by thinking of everything in terms of the utilization. So we can reformulate the problem in terms of how much programs are actually using and adjusting resource prices to those at some level. This comes from the fact that block builders are assumed to be rational and selfish, which generally they're probably more rational and selfish than the average user.
00:11:05.124 - 00:11:59.656, Speaker A: And what we can do take advantage of for that is we can sort of decouple this notion of utilization of the network versus user utility. And what you find is this sort of notion of dual problem works. So the goal is we have this function, we're going to construct this function g g takes prices and returns. How good the network is working in terms of like how well it's distributing allocating resources to different programs. Again, there's this constraint and every time you relax the constraint, you're charging the network a fee. And the idea is you want to minimize the network fee. It turns out when you write this function, and this is in our paper, you actually can write this in terms of something that only depends, that separates the network cost versus the cost to transaction producers.
00:11:59.656 - 00:12:39.264, Speaker A: And the key is that we don't really need to optimize the right hand as well. We only really need to optimize the network costs while choosing prices that make sense, like gas in general, gas prices. So now we have this dual problem, which is maximizing the sink, minimizing something else, with, of course, the relaxation to convex hull. We get the same optimal value by this relaxation. So that's good. And the idea is that the network in general, like the Solana client, could be running this code every block and optimizing these prices. There's no unhidden variables here.
00:12:39.264 - 00:13:45.324, Speaker A: So, suppose we have a minimizer, how do we know it's optimal? Well, we get something that looks like gradient descent. So you could think of this kind of resource allocation problem as something where the network, the client, can do gradient descent on every step, it can optimize its prices, and you will, you get some guarantees that it is close enough to the minimum. So what are these prices we charge? So, the prices that actually work the best are those that exactly counter the marginal cost of network. So the idea is this loss function measures the marginal cost to the average validator, and the prices need to adjust to that marginal cost. The second thing is that the optimal prices maximize this thing, regardless of the choice of utilities minus the network clause. The nice thing is, this could run just like gradient descent. It actually does look like sort of what's called mirror descent.
00:13:45.324 - 00:14:24.204, Speaker A: And the network can effectively determine these dynamic prices quite easily. These can actually be kind of computed from previous blocks. And like I said, you can kind of use a projected gradient descent method to find them. These are some examples of update rules that you may want to add in a positivity constraint. And this update rule that's proposed by Anatoly as well as Vitalik, you can analyze it and show that it does converge. It actually converges more slowly than you might expect. Okay, so I gave you a bunch of math.
00:14:24.204 - 00:15:18.496, Speaker A: Maybe you didn't want to see any equations today. Totally fine, I understand it's early for everyone who's jet lagged like me as well, but what does this look like? So, here is a simulation of a bunch of different feed structures, and how, basically, how well the network responds to a spike in demand. And what you can see is that when there's a spike in demand, in the multi dimensional fee scenario, that's the orange pulse. You can see that the multidimensional fees sort of respond with much lower variance. For the end user, on the other hand, the 1D fees, when there's a spike, have this kind of chaotic behavior, and the fees are never able to recover. And for the end user, this is actually worse ux, if they really, really have higher variance in their fees. The key thing is, all of this is hiding one thing, which is the choice of this objective function is hard.
00:15:18.496 - 00:16:17.734, Speaker A: And in Solana, I think there's a lot of differences in how you would choose that. So in the sort of per contract, per program state market, you can kind of think of this slightly differently. You define a sort of program level utilization of different resources, whether it's cpu bandwidth, storage, et cetera. And you can also add a sort of notion of how often a program is reentered, how often is called, and have that affect the gas price. The intuition is that if a program state is never touched, the fees are small, just like the current local fees market. And if they are touched, it increases linearly. Now the question is, how do we allocate fees to all the different programs? An NFT mint, like we saw earlier with DRIP, might actually need very high spike rate because it causes so much in terms of externalities, a Dex might not.
00:16:17.734 - 00:17:13.164, Speaker A: These program fees are also a good way of capturing fairness, which you can't really do in a modular blockchain, which is one of the key things. I think that is the reason dynamic fees are very important to take advantage of in a sort of monolithic architecture. And like we have this optimization problem earlier, we write the same thing, but with this sort of local market demand. So the key thing I want you to take away from this is that in Solana, there is this amazing landscape to take advantage of these local fee markets. And these local fee markets are things that you can write this sort of simple gradient descent type of thing that will lower variance for users. We saw that sort of notion of, you have this huge spike in demand. Multidimensional fees are able to kind of ensure that the variance in fees for the average user is down.
00:17:13.164 - 00:17:31.104, Speaker A: And I think this is the type of thing that in Ethereum, people are very slow to adopt, especially in kind of a modular world, where every little roll up has its own fee market. And it's very hard to solve this optimization problem there. So with that, I think that's it if you want to read the paper.

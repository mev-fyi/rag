00:00:09.840 - 00:00:46.834, Speaker A: Hi guys, my name is Honeck, I'm the lead of integration at Jomp. The second half of this workshop will be covered by Samir, who's the lead of technology. So today we'll be covering integration as a publisher on the Piff network. And we'll also be deep diving into the piff code and how you as a publisher can code to the PIF client. So for the summary today we'll be covering what is PIF. I know Mike did a really good job today of covering what PIF is, so I'll keep that quite high level. And then we'll be looking at how the PIF aggregator works.
00:00:46.834 - 00:01:31.894, Speaker A: We'll be covering at high level again, what aggregation and confidence is. I know Jay will have a separate workshop based on the white paper so that we'll dive into a lot more detail tomorrow. We'll be covering what Devnet, Testnet and mainnet environments are. And we'll also be looking at the PIF integration and conformance process. We'll be looking at RPC nodes, how a publisher can publish data on chain and also connectivity. Towards the second half of the workshop we'll be looking at the core infrastructure. So Samir will be deep diving into price and product accounts, what the PIF TX and PiFD components are, and how you can code and publish to the PIF network.
00:01:31.894 - 00:02:36.564, Speaker A: And then towards the end of the session we'll have a quick q and a for anybody that has questions. So what is PIF? PIF is a price oracle on the Solana blockchain that aggregates publisher data, allowing consumers to consume that data and develop decentralized apps. As highlighted earlier, publishers can publish data for every slot, and the approximate slot creation on Solana is between 400 to 600 milliseconds. Once a publisher responds to a callback and publishes data, PIP then publishes an aggregate price and confidence for each product on each Solana slot and on the network. We're currently publishing data aggregated data across crypto equities and effects. To the right here you can see an example of BTCUSD, and towards the left you can see a number of different product keys. Each product key is associated with each individual publisher, and the product key has to.
00:02:36.564 - 00:03:08.124, Speaker A: The publisher key has to vary depending on the environment. So a publisher would have a publisher key for Testnet and Devnet, which would use TESOL. However, for mainnet they would have a unique key, given that that's a live environment and that will be using live Sol as gas. Towards the right here, you will see status. I know it's quite small. You probably can't read that from where you're sitting. But the status refers to what, what sort of data the publisher is actively publishing.
00:03:08.124 - 00:03:54.414, Speaker A: So if the status is trading, then that is live data that the publisher is publishing on chain. If it's unknown. Unknown normally stands for whether the publisher is down for maintenance, or whether the publisher is down for any other issues, such as connectivity issues, or if their RPC node is done, et cetera. And there is a third status called halted. We normally recommend that publishers don't use this status, given that that status usually only should be used if a symbol has stopped trading on the market. And next to that you'll also see their price, individual price and individual confidence interval. Moving on.
00:03:54.414 - 00:04:32.132, Speaker A: So, a quick summary. I know Mike covered this earlier. We've onboarded 40 plus publishers over the past year. Past six months, actually. Given that we've only been live in mainnet for six months, there's been a number of different consumer dapps that have integrated onto the platform, and then we've got 55 plus price feeds, and that's across a variety of different symbols within crypto equities and FX. So what is aggregation at high level? So an aggregate price. PIF aggregates prices submitted by individual publishers.
00:04:32.132 - 00:05:27.544, Speaker A: For example, if one publisher publishes a price of BTCUsD, at other publishes that price at 42.24 200. Sorry, Piff would combine that prices, that price those prices into an aggregate price of 42 100. There are certain metrics involved in terms of aggregation itself. Say for example, if there was an aggregation full of seven publishers, if one potential publisher was to publish a price which is way off market, the PIF algorithm would actually pick this up and look at the median of all the other publishers that were pricing for that particular slot. So it wouldn't be thrown off. Ultimately, if there was one publisher publishing an off market price, and that will obviously, we'll look at that in a lot more detail when Jay goes over the white paper tomorrow.
00:05:27.544 - 00:06:29.544, Speaker A: In more detail in terms of the aggregation itself. If a publisher doesn't respond back to callbacks and they fall behind by 25 slots, they are automatically removed from the aggregation. So this can be intentionally done. So if a publisher chooses not to respond onto a callback, it may be the case that they're down to maintenance. On the other hand, if they intentionally don't respond back and they're having some sort of unknown issue, such as an RPC node issue or a connectivity issue, it may be the case that we need to obviously dig into this in a lot more detail and find out what the exact issue is there. So along with the price, publishers also need to publish a confidence interval which acts as a price precision and uncertainty. So for example, if a publisher was to publish a price, they can potentially calculate their confidence by using a calculation of bid minus ask, which is a spread divided by two.
00:06:29.544 - 00:07:31.920, Speaker A: Let's for example say if BTC was published at 42k, if they were to publish a confidence of $50, they are ultimately saying that the price of 52k that was published is either below or above by $50. The calculation can vary depending on what type of firm it is. If it's an exchange, they may potentially want to use the top of book spread to calculate the confidence metric. However, prop trading firm may base it on their executed trades. So here's a comparison between the two. So if an exchange was to look at the top of book best bid at 1025 for Tesla stock and the ask was 1035 for Tesla stock, they would report a Tesla price of 1030 with a confidence metric of $5 above or below. A prop trading firm, for example, maybe base it on their executed trades.
00:07:31.920 - 00:08:12.006, Speaker A: So if they bought a Tesla stock at 1027 and sold it at 1025, they may across two different venues. So as an ARB trade, they may report the test price of 2025 minus or above by $2 depending on when their last trade was. They may want to widen their confidence. So it totally depends on when their last trade was actually executed. There is a medium article that goes into detail on different types of calculations that can be used by publishers. So yeah, you can directly access that on the PIF network. So moving on to publisher integration.
00:08:12.006 - 00:09:20.504, Speaker A: So we usually ask publishers to integrate firstly on Devnet just to test connectivity and ensure that they can access our RPC nodes. We normally allow publishers to access our RPC nodes for the ease of coding to pivot cells, which normally requires just requesting a source IP which we can have Triton one whitelist on our behalf. Both Testnet and Testnet use testsol in order for a publisher to publish data onto the network and both environments, Testnet and Devnet can be accessed via our RPC nodes. When a publisher does successfully connect to Devnet, we ask publishers to move onto Testnet, whereby they would have to carry a 72 hours conformance. And there's a number of different alerts that we normally track and log within that conformance. So as you can see here, there's a screenshot of a actual log which has been extracted. The main alerts that we look out for is a zero or super tight confidence.
00:09:20.504 - 00:10:14.044, Speaker A: Obviously, if a publisher is publishing zero, it's quite clear that they haven't got a confidence calculation in place. Again, if they're publishing a super tight confidence, it could be the case that yes, they haven't got their calculation in place, but it's very likely that, you know, for example, for BTC, we can see here that it's 0.03. It's very unlikely that an exchange would have a super tight spread of 0.06 for BTC USD. So these sort of alerts are flagged and we normally sort of deep dive into that once, you know, once such error occurs. The other thing that we also look out for is if pricing is off market by 10% or above from the overall aggregate. So we can see here that we've got the aggregate price, we've also got the publisher price, and then we've got the price difference between the two.
00:10:14.044 - 00:11:27.244, Speaker A: Of course, if there's a big difference, again, that would be flagged within the alert and it's something that we would need to investigate in a lot more detail. And then finally we would also look at uptime on an hourly basis. If a publisher is continuously being disconnected, it could either be an issue with the RPc node itself or it could be an issue with the code. So once a publisher has successfully connected to Devnet and Testnet and completed their testnet conformance, we normally refer publishers to a third party null provider, given that a dedicated RPC nod is required for Mainnet. Again, as mentioned earlier, mainnet does use real salt as gas and any additional symbols that we enable at a later date or permission at a later date. Sorry, would need to go through the same conformance process just to minimize the risk of any sort of error or any sort of bad data leakage into Mainnet RPC nodes. So RPC nodes, a validator would need to be employed as an RPC node.
00:11:27.244 - 00:12:35.894, Speaker A: There are minimum specs that are required if a publisher wishes to use a private node. So cpu must be of 16 cores, ram must be of 256gb, and disk space. It depends on how much transaction history is required. It's not mandatory that a publisher has disk space as part of the RPC node, given that we are actually tracking logs and also creating a historical tool on the pith network website whereby publishers can actually go into the logs themselves for any sort of timeframe, whether that's over a week or over the course of a month. And again, this tool should be added to the site in the weeks to come. This will obviously give metrics in terms of if a publisher is live in Mainnet, if they're continuously being disconnected, or if there's any underlying issues with their pricing, they can actually deep dive into the logs themselves through the site itself. As highlighted earlier, we do actually refer publishers to third party node providers.
00:12:35.894 - 00:13:30.974, Speaker A: The key benefit here is that a publisher, a node provider, would actually maintain and manage the node on behalf of the publisher. It would actually help maximum uptime. So if, say, for example, a publisher was to run a private node themselves, if that node was to go down, obviously it would call or disruption. They won't be able to publish data on chain. However, if there's a third party that's managing the nodes on their behalf, that third party will have more than one node in the event of Fallover, which of course will prevent any sort of disruption. Again, our approved node providers provide 24/7 support around the clock. So if there are any sort of issues with the nodes during any sort of time zone, there is someone there to look into that in a lot more detail and make sure that you're back up on the network.
00:13:30.974 - 00:14:14.884, Speaker A: And lastly, the nodes are actually tested by our software engineers. So there have been publishers in the past that have actually explored the market and looked at nodes that may have not been actually tested with PIF's code itself. Yes, it's possible, but the fact that our approved RPC node providers have been tested with Pif code just gives that peace of mind that it's a plug and go solution. So now we'll be moving on to the PiF architecture. I'm going to hand over to Samir. He's going to deep dive into PIF D PIf TX, how that acts as a proxy, and he'll also look at the account structure as well. Over to you.
00:14:14.884 - 00:14:17.852, Speaker A: Cheers.
00:14:17.908 - 00:15:03.064, Speaker B: Thank you. Harnick, how are you doing? My name's Samir. I currently run jump liquidity technology, but I've been intimately involved in pith since we started dealing with it at jump. So I wanted to go a little bit into a relatively high level overview of the pith architecture. A lot of what I'm going to discuss is also documented on our GitHub repositories and in our git book as well. To start with, what I wanted to look at is the account layout in Solana. So as hopefully most of you are aware, Solana is based on the fact that you have accounts that you can store data in, and pith uses these to store all of our publisher metadata and product metadata as well.
00:15:03.064 - 00:15:46.796, Speaker B: So we start with the mapping account. The mapping account is largely a linked list of product accounts. We store links for every product account in the base mapping account, and then from, if we run out of space in a mapping account, we will link to a second one where you'll find the second list of products and so on. The mapping account links to, say, a set of product accounts. Product accounts contain product information and metadata, and from there, a product account has a link to one or more price accounts. Currently we just have one price account per product, which represents the market price or our sort of fair value of that given asset. But in future we might add other series for a given product.
00:15:46.796 - 00:16:41.194, Speaker B: For example, if we had options, a price might represent open interest or volume or some other time series. So on the right hand side, I have just shown the c struct that represents the mapping account in this case. So we always start off with every one of the pith accounts starts off with the pith magic number and version. We use these to help people determine that they are using the right library to look at the right piece of code. And if we, for example, change the structure itself, like we add a field or change the meaning of something, we would increment the version. So that you should always be checking this when reading the account off. Solana going a little bit into the product account, again like the c structure shown here, then the first part of the product account will actually link to the price account.
00:16:41.194 - 00:17:22.898, Speaker B: So this references the first price account for that product. And again, right now we just have one price account. And then the second part is actually a variable set of metadata that gives you information about the product. Each one of these strings is a key value pair that tells you exactly what this account references. So in pith currently, none of these are strictly defined in the oracle or in the code as required. These are just part of the expectation of what you will see on chain. The symbol field is a unique key that we use to separate products from each other.
00:17:22.898 - 00:18:12.746, Speaker B: Generally, it should not be relied upon to identify a product, but simply something that can be used as a unique identifier. To identify a product, you should use the other pieces of metadata. For example, in this case, this is solana, the solana spot pair. We will always print the asset type, we will print a description, we will print the base value and the quote currency that will tell you exactly what this is for. And equity will have a similar set of information that will, for example, give you the NYSE symbol, the Nasdaq symbol, so you can identify an equity. If we have other assets on pith we will put in appropriate identifiers for those particular markets. So the price of count is probably the most interesting thing, or at least the one with the most number of fields we have.
00:18:12.746 - 00:18:46.880, Speaker B: Price account is really the thing that most people are interested in. So we start with some metadata associated with the price. So we always have the price type. Currently we just have one type which is called price, and really this just means the value of the asset. We also have an exponent field, so all prices on pith are stored as int 64, so sine 64 bit integers. And to convert that to a floating point type, you must multiply that by ten to the power the exponent. For most crypto, the exponent on pith is minus eight.
00:18:46.880 - 00:19:34.276, Speaker B: So everything is basically the integer price times ten to the minus eight. We also have the number of component prices and the number of quoters that make up the aggregate here. So the number of component prices is the total number of people, of publishers or quoters that are permissioned to produce a price on chain. And the number of quarters that make up the aggregate is the number of quarters in the current aggregate. We'll also show you the slot of the last price that we published, as well as the slot of the current price. You're able to tell how old the current aggregate is. The next set of fields are more interesting in terms of these are actual data that people will use on chain.
00:19:34.276 - 00:20:07.074, Speaker B: We start with the time weighted average price and confidence interval. These are actually structures themselves. If you dig into them, they're actually a pair of InT 64 exponent by themselves. We have an interesting field that we've recently added called Min publishers. What that says is the aggregator will not consider a price valid unless the minimum number of publishers have been met. This is currently set to three for all products on mainnet. It's set to a lower value on dev and testnet, just so we can see pricing when there are fewer numbers of publishers active.
00:20:07.074 - 00:20:46.484, Speaker B: Of course, the most interesting value here is probably the aggregate price, which is at the bottom. This is the pc price info, the structure of which is actually at the bottom. So the price info gives you the aggregate price, which is what most people will be looking at. But aggregate price by itself is actually a combination of several fields. There is the price itself, the confidence interval, and the status. All three should be used together to determine whether or not the price should be used. You should always be checking the status of a price as well as the confidence interval to essentially figure out is this price valid, and is this midpoint where I expect it to be.
00:20:46.484 - 00:21:43.220, Speaker B: And the last piece of the structure is actually the data structure we use to store to store quota pricing on chain. And this is how we are able to aggregate prices from multiple quotas in one place to go through how the aggregation actually works. So say we have slot one on Solana, so we have two quarters, for example. We have a price of one has a price of ten, and one has a price of 20. We're going to use a very simple just average aggregation here. So what you will see on chain at the end of slot one is that we will have stored in that component section the quote for a and the quote for b. And then at the start of slot two, the first transaction sent to pith, sent by quarter a, will actually trigger the aggregator to run, and it will now produce an aggregator price, in this case the average of ten and 20 in the aggregator slot.
00:21:43.220 - 00:22:20.058, Speaker B: It will mark the aggregator as trading, and it will say the aggregate slot that this was produced for slot two, which is where we are right now. At the same time, quarters a and b are now producing some new prices. Those are simply stored on chain and they will in turn be used in slot three and so on and so forth going forward. So a little bit about the individual components of pith. You'll find all of these components in the pith client repo. These are all currently c. So pith and pith admin on the left hand side are command line utilities that we use to administer the chain itself.
00:22:20.058 - 00:23:07.584, Speaker B: For example, we use them to add symbols, permission and depermission quarters and change metadata on chain. They connect directly to Solana using an RPC node. PiFD is a proxy quarter that accepts bespoke JSON RPC and publishes to Solana using a combination of a RPC node and PIF TX. This is typically used by quotas that are not written in C PIF. A dedicated quota on the other hand, will usually connect, will use the pith client library directly and talk directly to an RPC node and to pith TX to actually send transactions on chain. And finally, Pith TX is used to optimize transaction submission into Solana. And that's something I'll go into a little more detail on the next slide.
00:23:07.584 - 00:23:52.532, Speaker B: So why do we have PFTX? This is the thing that we actually get a lot of questions about. So we use this to optimize transactions sent to Solana to try and guarantee that they get into each slot. So usually if you just use an RPC node, when you submit a transaction to one, it will send that transaction via UDP to the current slot leader. There is a good chance it will miss. That transaction will fail to enter the slot simply because the slot leader has moved on, or because the slot leader did not hear the transaction that happened, in which case the RPC node will attempt to retry that transaction until it works. But we don't actually want to retry market data transactions. We always want the latest data.
00:23:52.532 - 00:25:05.508, Speaker B: We don't want to keep retrying and publishing old data, and we also want to maximize our probability of getting into each slot, which is why we wrote Pith TX. So Pith TX will connect to an RPC node, it will receive data from pith client publisher such as Pithd, and it will connect an RPC node to receive the location of slot leaders. And then every transaction that comes in, every request to publish a price, will actually be sent out three times from Pith T, one to the last leader, one to the current leader, and one to the new next leader. So we're continuously following the slot leaders around the Solana network. This way helps us maximize the probability of a given transaction entering the network and being printed. A secondary function of pith Tx for people who are running this in their own infrastructure is that it puts the piece of PIF that publishes arbitrary UDP data on the outside of their corporate network. Generally, people don't want something that needs to listen to arbitrary, essentially like every possible Solana Solana leader, and as well as publishing arbitrary UDP to a whole bunch of places across the Internet on the inside of their corporate firewalls.
00:25:05.508 - 00:26:07.710, Speaker B: So people typically run this somewhere in AWS and then connect to it over a nice, well protected TCP connection from within their infrastructure. So just going a little bit into how you might quote via pith client. So Pithclient is a client library currently written in c, and generally the expectation is that direct quoters will build and link against this library in order to publish prices to pith. And publishing, as Harnik mentioned, is done on a callback basis. The pith client code is attempting to track the current slide and when it will be generated on Solana in an effort to maximize the probability that your transaction will enter each slot. So when it detects that a slot is about to be created, it will run a callback. And the callback in this case is this is the second one from the bottom, which is the on response pc price schedule.
00:26:07.710 - 00:26:59.848, Speaker B: You'll receive this callback, provide your price into it, and then the pith client will immediately send that out via an RPC node and pith TX. So quota will implement that. And that's a large extent. Simply how you quote the other callbacks are required so that you can, for example, receive product metadata, so you can identify which products are associated with which products on your quoting side, you can also use this, the other callbacks to receive prices from the network and to receive metadata updates. One of the last the last on response here is actually particularly important. For example, for some reason we might change the exponent for a given asset on the network. So if we change the exponent from like eight to ten, for some reason, that means all your prices, the integers that you're submitting for your prices, must be offset by that new exponent.
00:26:59.848 - 00:27:36.778, Speaker B: So this is unlikely to generally change. But it is one of those things that we have added code for. If we have printed, for example, the wrong exponent, or if an instrument's tick size, for example, changes, so that we need to change the exponent to represent the new price. Accurately quoting from pithd is a little different. It's a bespoke JSON RPC API. The details of that are actually in the websocket document in the pith client repository. But pithd is really used for coders that are not using C or don't want to link against the library.
00:27:36.778 - 00:28:21.494, Speaker B: So if you're writing in any other languages, so it acts as a proxy and you'll generally just send it JSON and receive JSON from it. So the first example is just simply sending a price into it. The second value is being, is getting a price back from pith. So this is a relatively simple service that we use so people can have, can immediately connect to pith without having to write any code that links against any particular library. So for consuming data, we actually have a number of possibilities. We have several client libraries written for off chain. We have a rust crate node, JS library, Python.
00:28:21.494 - 00:29:11.174, Speaker B: These are all in the respective respective package repositories for each language. We can use the rust crate for on chain if you're writing a smart contract in rust. And we also have a neon library that allows smart contracts to use the neon evm layer. There's a docker container that actually contains fully compiled versions of pith, the pith client libraries, the oracle itself, and the command line utilities. This is useful if you want to spin up your own version of the oracle on dev or Testnet, or in a private Solana instance and just see how it works, publish your own prices to it. And of course more information can be found online. We list all our client libraries on the pith network docs, and we are continuously adding and updating libraries as time goes on.
00:29:11.174 - 00:30:18.878, Speaker B: So that's the end of the high level presentation. I did want to give an opportunity for people here to ask questions. I think Harnick and I will be sticking around afterwards for some time if you don't want to ask on stage. But next, does anyone have any questions regarding either the publisher architecture or quarter architecture or the technical architecture? Okay, so I think the question was how do publishers get feedback on the quality of their pricing in terms of the aggregation? Right now, what we do publish is whether or not a publisher is included in the aggregate. The off, if you like. The quality feedback is being provided via a metrics page. So we're currently working effectively, if you like, on off chain metrics that will run through how publishers were included, how their prices compare to both the values on pith, and how they compare to values on other markets.
00:30:18.878 - 00:31:09.114, Speaker B: So this will be provided as effectively a end of day report for individual publishers. So the metrics page, which should be online hopefully within the next week or so, will give publishers detailed feedback as part. A lot of this is actually explained in more detail in the white paper, which Janet will be covering tomorrow. But as part of the staking and slashing for quarters going forward, this will be maintained on chain using quality metrics that will be immediately made available to publishers. But at this time, this is not part of the protocol. Excellent. And to assume by everybody's silence, that means everyone's ready to publish the pith without any further questions.
00:31:09.114 - 00:31:53.328, Speaker B: Just as a note for all potential coders out there, we do go through a conformance period. Where we go through, we show you how to publish. There's plenty of examples online. All of our code and examples are public on the PIF client repo and we run, if you like, that quality analysis in dev and Testnet to make sure people are actually publishing the correct prices. One of the things to note is it's one thing to simply connect to the library and just get things going. But there is a large set of operational concerns when people are publishing prices, especially for things like crypto that you are publishing valid prices at all times. There are often market transients.
00:31:53.328 - 00:32:31.754, Speaker B: There are places where the price can change very rapidly, where if you're, for example, publishing data that you, you have from a local book, that liquidity might dry up and suddenly your prices go crazy. Like all of these can affect the, can potentially affect the aggregate that pith is producing. And we want to make sure that publishers are making the best efforts to publish valid prices. So this is why the pith aggregate contains is not just a price, it is the triple of price, confidence interval and status. And all of those things tell you how good this price is when you're trying to use it on chain.
00:32:33.094 - 00:32:33.874, Speaker A: Yes.
00:32:35.214 - 00:33:37.962, Speaker B: So the question is, is there any plans to move the signing code from outside pithy into client libraries? So in the context of the components, PitHD is really is considered part of your publisher, so it really belongs on the inside. And the reason the signing code really has to exist inside 50 currently is because it does all the Solana work for you. It signs your transaction. If you want to take over that responsibility, we recommend you use the pithclient library directly. There's absolutely a possibility that we could write almost like a hybrid, where we do some of the work in a library and some of the work in pithd, but it kind of negates the purpose of pithd in the first place. But yet generally that's what pith TX, on the other hand, does not require your keys. So pith TX is usually what exists off your network, outside of your infrastructure, and it can be considered insecure.
00:33:37.962 - 00:34:43.509, Speaker B: It actually just receives a signed transaction, just forwards it over to UDP. Question is, if a publisher has more than one price per slot, do they publish multiple transactions or multiple, or one transaction? So going back to, for example, quoting via pith client, you actually only get the opportunity to publish one transaction, you get that callback once per slot. So that's why we have a weather callback mechanism rather than a push mechanism for this. So however, if you did publish multiple transactions, you would actually just end up burning, you'd end up, one transaction would effectively get overwritten by the next one, and you just end up burning some sol there. So at the end of the day, the latest one will win, but we are attempting to minimize the excess gas usage. Hello, is this the right talk to talk about gas fees?
00:34:43.581 - 00:34:46.621, Speaker A: That depends on the question.
00:34:46.677 - 00:35:42.420, Speaker B: Depends on the question. So the question is, how much are gas fees going to go down in the future, because they are currently high. So there are two pieces to that. One is the fee charged by Solana, which is something I believe we are working on itself to reduce that overall. However, there is also how pifclient actually uses, effectively uses transactions to minimize gas fees. So we actually just released today as part of Jumps publishers a new version of the PIF client, and this is actually being merged into our mainnet codebase that will batch transactions sent out to sent out to Solana. This gives us roughly right now we're seeing roughly an eight times reduction in gas fee.
00:35:42.420 - 00:36:33.076, Speaker B: This assumes that you have eight prices to update per slot. So there's a small change to how consumer or how publishers need to actually compile against the pith client. We will be documenting now that we've released this on behalf of jumps publishers, we're basically running it through a beta period, make sure that everything is clean and that we effectively conformance test Jmps own publishers. Once that's all good, we will be writing up exactly how other publishers will be able to do this. Anyone using pithd will simply get this functionality for free, since it's just built right into the pithd proxy. So that should hopefully result in a significant decrease in gas fees just from the PIF publishers. For those publishers that are publishing enough names to be batched, enough names at high enough frequency to be batched.
00:36:33.076 - 00:37:33.428, Speaker B: If you're publishing one name every 10 seconds, this will have zero effect. If you're so question is, do we have to do any extra implementation if you're using pithd? No, if you are using the pith client library, there's a small change in the API to enable batching. Hello? Oh, again? Yeah, so the question is like how does the batching actually work, really? So for the, if we're attempting to publish multiple transactions in one slot, these implicitly would have been transactions that would have been published in one slot anyway. So transactions across multiple individual products, they would have all hit slot 20, for example. So instead of submitting 20 transactions, we simply batched them into a single transaction. So the net effect on the oracle is identical. In fact, as part of the batching code, we didn't change the oracle at all.
00:37:33.428 - 00:38:13.148, Speaker B: Like there is no release to the on chain program to enable batching. This is simply a client side train to add multiple transactions into one. Solana call. Sorry, I couldn't hear you. Yes, the batching will be implicitly available in pithd and just be turned on by default. So the newer versions of pithd just simply dropping it in should result in batching. So the question is, do we have a timeframe for the batching? Yes, it's actually already active.
00:38:13.148 - 00:38:49.060, Speaker B: We turn it on to mainnet today for jump publishers. It's already committed to the pith code base in git. It's in our main branch, but we haven't done a release as yet, since we're still making sure that it does the right things. As soon as we have this. We hope to have this ready for public use by the end of the week. Okay, so the most common reason is that you are publishing a transaction with a slot that has already entered. What we see is most quarters.
00:38:49.060 - 00:39:43.816, Speaker B: Actually, what we request is that most quarters actually run with some level of high availability when publishing to to PIF, for example, jump runs two publishers out of two disparate geographic locations, and they're actually competing against each other. And each one of those failed transactions is when one of the other quarters gets there after the first one. So they're both publishing the same price, they're vertically publishing the same transaction, but they've already been entered, so those fail. So in theory, you should see 50% of our transactions coming from jumpski fail at any given time. Since before quarters, in theory, are publishing exactly the same set of data, there are other reasons they can fail. So we've been as defensive as possible inside the pith contract code in an effort to prevent accidents. And if we see a price, for example, we run into, we run any kind of integer arithmetic issues.
00:39:43.816 - 00:40:34.072, Speaker B: One of the things you may be aware of is that Solana doesn't support forming point arithmetic and BPF, so we've had to write our own version of this. However, reimplementing this kind of thing can always result in bugs, and we've been as defensive as possible about the results from any of those operations. So really, anytime, if we see something strange, if something looks like an overflow, we just discard it and wait for the next transaction. Do we charge them in the future? Do we plan on charging fees for consumers? I am going to leave that one for the white paper discussion. So I think any answer I give is probably safer dealt with tomorrow. Awesome. Great.
00:40:34.072 - 00:40:34.640, Speaker B: Thank you very much.
00:40:34.672 - 00:40:34.944, Speaker A: Thank you, guys.

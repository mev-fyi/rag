00:00:08.240 - 00:01:02.688, Speaker A: I'm Austin, and this is validated today. I'm speaking with Yanik Schraddha, co founder of Elusive, a zero knowledge based privacy enabling protocol and developer framework for Solana. The subtext of this entire conversation is the problem of scaling privacy, not from a computational standpoint, but a regulatory one. As weve seen from the tornado cash sanctions, privacy preserving technologies for decentralized systems can run into compliance issues, particularly in the absence of clear regulation. But if blockchain is going to scale to billions of users with everyday use cases like payroll and savings, privacy is a prerequisite for adoption. And of course, if privacy protocols are non compliant, then adoption at scale is impossible. Elusive has developed a system where folks from both sides of the privacy debate can meet in the middle, in turn, hopefully preventing scenarios like what happened to tornado cash and its users through community consensus.
00:01:02.688 - 00:01:58.344, Speaker A: Elusive is making it possible to flag illicit actors on blockchain and grant temporary decryption authority to third parties, all without compromising the privacy of its honest actors. Naturally, we get into the mechanisms of how this works. In this episode, Jannik describes the process of reverse engineering a practical privacy product from a metaphor of an ideal, trustworthy guardian. But of course, what is or isnt considered illicit is tied to political and ideological agendas. Apples privacy policy in China is very different than that in the United States, so we spend some time wrestling with questions of how human judgment still plays roles in trustless systems. Elusive is pushing the crypto community beyond the simple binary of private versus not private, and this gets into grayer, more human areas of compliance, safety, privacy, and, quite frankly, political science. If you're a regular listener, you'll know this episode as all of my keywords.
00:01:58.344 - 00:02:16.900, Speaker A: As always, send us your thoughts and suggestions to validatedalana.org dot. Let's dive in. Yannick welcome to validated.
00:02:17.052 - 00:02:18.828, Speaker B: Hey Austin, thanks for having me.
00:02:18.916 - 00:02:24.628, Speaker A: Yeah, I'm excited to have you here today and to dive into the topic of privacy in the context of blockchain.
00:02:24.796 - 00:02:35.220, Speaker B: Yeah, sounds good. Also happy to be on validated. Have been a fan of all Solana podcasts from the first episode of proof of history and stuff like that, I guess.
00:02:35.372 - 00:03:29.594, Speaker A: Love it. So I want to kind of start out today high level, and then we'll get into some of kind of the more details as we kind of go through this when we think of blockchains. The main pioneering factor of a blockchain architecture going back to the days of bitcoin was this idea of a fully public ledger that anyone in the world could independently verify is true that you didn't have to trust one sort of central institution to say, this is the state of the world. Everyone could independently verify that a transaction between you and me had in fact, taken place. And that was largely the idea of what both the security and decentralization of original theses of blockchain came from. So how, given that view of the world and that original sort of founding principle, how do we bring something like confidentiality and privacy into the world of public ledgers?
00:03:29.934 - 00:04:38.500, Speaker B: Great question. I think what would make sense at this point is start to dissect what confidentiality, privacy and stuff like this means, right? On a very abstract level, when we talk about privacy, we mean that the individual that has some information remains the custodian of that information. And for us in the blockchain space, but also for companies in the, I guess, private messaging space, we look at transactional privacy. So having two peers in a transaction that need to exchange something that could be a message or could also be some monetary value, and those transactional systems can have privacy in the form of confidentiality and anonymity. And, yeah, I guess the best way of conveying that to everyone is confidentiality means if I send a postcard to you, both of us have some scheme which we can use some encryption to encrypt the message of the postcard. So the person delivering it, the person seeing the postcard, isn't able to identify what message we're exchanging. That's confidentiality.
00:04:38.500 - 00:05:27.302, Speaker B: And anonymity is the second part of privacy. And anonymity would mean we as parties, might want to stay private, and most often we would also want to have a confidential information exchange. But anonymity in this letter or postcard analogy would be, is a sender can be anonymous. If I just put the letter on the way without specifying the sender field on my letter, and you, as the recipient of my letter or message being anonymous, would just be me posting my message into the newspaper or sending the letter to everyone in the neighborhood. Right? Then nobody would know who the recipient should be. So that's the privacy we're talking about. And we want to structure this privacy in a bit more complex way, not through having to manually write stuff on letters, but with cryptography.
00:05:27.302 - 00:05:30.550, Speaker B: But the core principle remains the same, I guess.
00:05:30.702 - 00:06:16.522, Speaker A: Yeah. If we go back to your post office analogy there versus the newspaper, I think as long as there's been a mail system, there has been governments trying to read your mail. That's sort of a classic battle between any sort of information that can be sent in a way that others can't read it, and a state or another actor that has a desire or an interest in reading what that actual content of the message is. And we scaled it up to blockchain. And that's a little bit of where we're at today with this stuff. But even the basis of the Internet, the original Internet, was a fully open system that was meant for exchanging journal articles of peer reviewed, open source science. And today we have all sorts of technologies that have been layered on top of that to make these systems private and secure.
00:06:16.522 - 00:06:35.130, Speaker A: But a lot of those privacy systems, I don't think SSL, the certificate system that you use to verify that your bank's website is actually your bank's website. Most people don't think of that as a privacy technology. They think of it as a security technology. But in your mind, is there any difference between privacy and security when it comes to these sorts of things?
00:06:35.282 - 00:07:12.248, Speaker B: Privacy itself results in security and safety, and I think that's also true on a personal level. Right? You want to be safe. That's one reason why you want to stay private, isn't the whole truth, but part of it. I think, from a technical distinction, I wouldn't really differentiate there simply because those really base level protocols and systems can be used for anything, right? So you can be private. And through being private, there is no eavesdropper that can steal your message. That then results in safety. I think that's the connection here.
00:07:12.376 - 00:08:10.612, Speaker A: So the government as an actor here, right? If you have a roughly democratic government or a mostly democratic government, like we have in somewhere like the United States or most of Europe, those governments do from time to time, say we have an interest, as representatives of our civil society, to be able to see into certain types of communications. And this battle goes everything from a warrantless wiretapping by the NSA to, on the other extreme, Apple refusing to create software to break into a suspected terrorist's phone, there's a spectrum there, right, between things that we say are probably not okay. And I'd say assisting the NSA in warrantless surveillance of millions of us citizens is probably not okay. And then you have on the other spectrum, something where there are folks on one side of the political spectrum that might say, well, Apple honestly has a moral duty to help the FBI break into an iPhone. In your view, where should blockchain privacy technology come down along that spectrum?
00:08:10.748 - 00:08:53.458, Speaker B: Yeah, I'd like to attempt to differentiate there. So regarding communications. So I think we have been seeing this approach since cryptographic protocols have come into existence, but especially in the recent years in the US, we've seen the earn it act and have seen similar legislature attempts, or even successful legislature in the EU and UK. And what becomes evident, I think, with this legislator is that what they are talking about is we need laws to protect children, some specific reason. And protection in that sense means undermine end to end encryption. Right? A couple of years ago, that was counterterrorism. Nowadays, it's mostly child protection, CSM, something like that.
00:08:53.458 - 00:09:35.964, Speaker B: And the problem with that is, on the one hand, it's devious because it's a foot in the door tactic. Right. At the point at which we undermine this end to end encryption, it can be utilized by anyone to filter whatever they want and identify private messages. So authoritarian governments would like this technology. And in our democracies, I think if we allow for things like that, there's a high probability that in a couple of years, we might end up in a more authoritarian system. So I think we need to be very cautious there. And I'm 100% against any undermining of messaging and I guess, regulatory efforts in that direction.
00:09:35.964 - 00:09:49.416, Speaker B: Blockchain space, as I said, I want to have a bit of a more differentiated opinion there simply because I feel like what we're talking about here is something different. Right. We're talking about financial transfers.
00:09:49.520 - 00:10:00.414, Speaker A: Well, I do actually think that blockchains are not actually tools of financial transfer, they are just messaging protocols. Right. Because at the end of the day, tokens don't actually move on a blockchain. We're just reassigning ownership.
00:10:00.494 - 00:10:51.482, Speaker B: Yeah, yeah, definitely. The issue really arises with the systems built on top of that. Right. I think it becomes more of a question of the individual applications, which might tie into also the question, should privacy be built into the blockchain by default, or should it be added on top of it? But what's important for me is that for financial activity, for example, there has been a different history of surveillance, I guess, than for message exchanges. Right. Also, exchanging a message versus sending $500 million in an untraceable, unidentifiable way, I think, are two different things. I think what we always need to look at are concrete applications, simply because if we don't separate them enough, new problems can arise from a regulatory standpoint.
00:10:51.482 - 00:11:19.794, Speaker B: So if we say blockchain itself doesn't do any finance, so therefore everything should be completely private, untraceable. Since it's not a finance architecture, that's not a problem, because anything can be done with tokens. Right. I think that is true to some degree, but of course, brings the issue with we can never apply regulation to such architectures if all they're doing is relaying network traffic.
00:11:20.334 - 00:12:04.386, Speaker A: Yeah, I hear you, but I think there's a difference between saying blockchains should be seen as a messaging protocol and blockchains cannot be governed by any regulation. Like net neutrality is a form of message regulation, as are common carrier designations. I guess in my view, what's more interesting and nuanced here is separating the messaging layer from the application layer from the perspective of regulators. But I want to move on and get into how elusive actually works in its end state. Obviously there's a few different phases for how that rollout works, but elusive is something that's built on top of an existing layer. One blockchain. In the case of Solana, what is the goal there from a privacy standpoint? The same way that the Internet is not necessarily built on privacy.
00:12:04.386 - 00:12:27.004, Speaker A: We've had privacy built on top of it. As you mentioned before, there are some networks that are trying to do privacy from default, and we'll get into some of the technical both advantages and trade offs to thinking about that as an initial platform. But something like elusive or light, what are these types of systems building that are going to provide different avenues for privacy than standard instruction sets on blockchain?
00:12:28.624 - 00:13:32.450, Speaker B: I think the interesting use case on Solana really becomes full composability with existing transparent applications. Full transparent smart contracts that supply anything from on chain gaming to DeFi to building a new financial system. And all of those applications can be equipped with optional privacy. And this optional privacy can vary in its degree, right? The protocol might only require some confidentiality, or the protocol users will want or need anonymity. And so I think having those systems in place on the ledger allows for different kinds of implementations, rather than having everything hidden by default allows for new kinds of applications and efficiencies. I think that's important because not every single transaction needs to be a full homomorphic, encrypted state transfer, I guess only a subset of transactions. And I think that ties into the general direction Solana is moving, which is efficiency.
00:13:32.450 - 00:13:33.214, Speaker B: I guess.
00:13:33.524 - 00:14:06.772, Speaker A: If we look at the existing Internet today, there's a sort of strange mix of both private and non private information. We sort of have three tiers, I'd say. On the public Internet today, there's fully public information, which is just the stuff that either flows unencrypted or is just accessible to anyone. Anyone can go to the New York Times website and they can read data off of it. Or if you're running something that's in a public channel. That stuff is public by default. And then there's this sort of like, middleman privacy situation.
00:14:06.772 - 00:15:30.898, Speaker A: And that could be something like our connection here on Riverside, right, where we are connected via a secured connection between computers, but there's a middleman sitting in the middle, a cloud service that is also able to sort of decrypt that information and share it. Another example would be your bank, right? Your. Your connection to your bank may be private, and then the place that you send money to after you connect to the bank may also be private, but the bank is sitting in the middle and has sort of full information flow. And then there's like your classic, like, iMessage, right? Like your classic end to end encrypted messaging service, where even Apple, as the intermediary, you know, with some exceptions, based on how you set some stuff up, cannot read the messages that are going back and forth between it, even though it's software that they themselves have built and designed. Signal would be another kind of application of this. So as a parallel to all of that, how do you view Elusive's role within the blockchain privacy stack? And how is it different from other privacy enabling protocols like tornado Cache is probably the most famous example of this, and we did a whole episode on this, but the way its obfuscation works was via a mixer. Over at elusive, you've built something different which allows users to grant decryption authority to third party entities in certain circumstances, which, again, in theory, protects both the protocol and its user base from a tornado cache, like fate.
00:15:30.898 - 00:15:32.786, Speaker A: On the regulatory front, yeah.
00:15:32.810 - 00:16:54.566, Speaker B: So, I mean, I think it makes sense to quickly run down the state of elusive and also the vision. So the state of elusive at the moment is us being a smart contract, or rather program, I guess, on the Solana blockchain that users can use through an SDK and therefore direct Dapp integrations to gain privacy. And how that works under the hood, as you described, is as a sort of middleman, but a trustless middleman, because it's fully automated middleman that lies on the blockchain. And so users are able to basically turn any kind of normal token into a private token by locking them, essentially, or placing them in the smart contract. And the smart contract then allowing the user to cryptographically transfer this token to other users of the smart contract without any trace, or the user at some point, then being able to move funds again out of the smart contract. So you can think of it as a c cash on Solana itself. What that means is you can use this C cash just to move funds into it and at some point out of it, and then you have funds that have untraceable origin, again, I guess to some degree, but you could also leave them in that system and exchange it in that system itself.
00:16:54.566 - 00:17:30.364, Speaker B: So that's the privacy application of elusive. But yeah, as I said, that's basically C cache on Solana and therefore would just be, yeah, we are building what others have already built on their own, which is not what we are doing. So it's only a small subset of what we are doing. And what we're focusing on mostly is combining this privacy technology with something that allows us to not only provide the user with privacy, but also with safety in the regard of being safe from a regulatory compliance standpoint. So we want to combine both of those things.
00:17:30.864 - 00:18:03.084, Speaker A: Yeah, so let's talk a little bit about that, because most folks who are building zero knowledge for the focus of privacy technology on blockchain are not thinking about it from the perspective of safety. They're thinking about it purely from the perspective of privacy. What brought you and the team of elusive to be thinking about this in a different way and talk to me a little bit about that process of figuring out where you as a founder draw that line and say, this is roughly the right trade off to make between privacy and safety.
00:18:03.204 - 00:19:21.108, Speaker B: I mean, I've always done computer science and math, but there was some period of my life, I guess, after school, where I studied law. So coming from that background, I think I've had a unique perspective to not only think about stuff from a cryptographic and cypherpunk perspective, but also try to have a more realistic view on privacy, I guess, and potential implications of absolute privacy, I think. So what we are trying to achieve basically is provide full privacy to the normal, honest user, honest actor and have everything be decentralized and permissionless. Because if that weren't a focus, if we were just to say, okay, let's build privacy using zero knowledge technology and slap some web two compliance on top of that, we could just build some web two protocol. Doesn't need to be a blockchain protocol then. So it's a permissionless approach and also distributed approach to compliance and offering privacy by default and based on some consensus rules in some limited amount of time, would be able, through zero knowledge proofs, MPC attempt to do some checks or screening of transaction flows.
00:19:21.276 - 00:19:58.818, Speaker A: Yeah, so we like to think of blockchains as like fully automatic Turing machines that don't require any sort of human judgment, but that is not really the case. Right. All software is built by humans, at least today, and that software is built with a certain amount of intentionality to it. So where I guess, like, from. From this kind of mix of backgrounds for you, right. Where it's like technical blockchain and products, but also like interest in law and like, an understanding that, like, unfettered privacy can at times be detrimental. I think that alone is a fairly controversial topic to some folks in crypto, that there should be any compromises on privacy at all.
00:19:58.818 - 00:20:15.414, Speaker A: Was that an idea that you sort of originally had, that then as you started doing more work, both in privacy and sort of in law, you decided didn't make sense? Or is that sort of an idea you've always questioned before you sort of got into building stuff on blockchain?
00:20:16.034 - 00:20:48.518, Speaker B: Yeah. I think it only really came when thinking about this new paradigm of privacy. Right. Deeply thinking about and reasoning about implications that such a system has. Let us come up with that. So I think when you say it's a controversial thought, I agree on crypto, Twitter, it might be partially controversial. But even amongst cypherpunks, there's this notion that we live in a world where there is regulation, and in our lifetimes, there will never be no financial regulation.
00:20:48.518 - 00:21:53.418, Speaker B: Right. So we need to find some middle ground if at some point, we want to build a monetary system that could replace the system, the traditional finance system we're currently stuck with. So the threat that I personally recognized, or that we recognized, was that if we strive for a system in which we, let's say, have some sort of Monero ccash as the world currency, we don't have any financial intermediaries, we have no cash, nothing like that anymore. And we fully strive for that architecture with all energy. We might at some point, force people, and I guess specifically governments, to choose between this and the alternative. And the alternative would be the most possible scenario for all of us, which would be some sort of surveillance central digital currency. So I think having this fully binary approach, binary plane, saying no, we are not moving any step closer to the other side, I think, in itself is quite dangerous.
00:21:53.418 - 00:22:23.524, Speaker B: And so if we want to build systems that, I mean, on the one hand, appeal to the mainstream, I think we should be very careful with something like that. So I don't think it's too controversial. There will always be room, I guess, for less compliance oriented protocols and teams. But if you're thinking about big mainstream applications, we cannot have this approach of being 100% anti government and anti regulation. That's why we need a more balanced, more realistic approach.
00:22:24.544 - 00:22:48.378, Speaker A: Yeah. So on a practical level, how does elusive achieve this? Because I think one of the things is that you can look at a lot of these systems and you can say, theoretically something here is going to give more optionality, but how does that actually show up? How do you bring those ideals into the actual product development? How does that compare with some of the other systems that are out there today?
00:22:48.506 - 00:23:36.654, Speaker B: Yeah, let's just walk through the individual approaches we've seen so far. So I guess the first approach has always been something in the way of full user controlled compliance, I guess with something like viewing keys. So the protocol gives the user the ability to create some viewing keys they can share with third parties. So with a regulatory body that inquires those viewing keys, something like this, of course, is, I guess, fruitless in the sense of that it cannot do anything against illicit finance. Right. The illicit actor tends to be uncooperative. So this user control free and key system is interesting for providing additional optional auditability when thinking about tax purposes, for example, but not illicit finance.
00:23:36.654 - 00:24:48.138, Speaker B: And that's the big elephant in the room. I guess the next approach goes into the direction of imagining the system I outlined, which is having, for example, a smart contract or just having an optional privacy system. And then the approach would be okay. In this optional privacy system, we want to keep all elicit actors out of the system before becoming private, before entering, before opting into privacy, or we want to at some point of interacting, prohibit them from interacting with other users or moving their funds out of the privacy system. Right? So that would fall under the, a headline, I guess, of we could call it deposit or withdrawal screening. So the way to do that is let's take the OFX SDN list and map that on chain. And then when depositing or withdrawing or transferring funds, just check is the sender that somehow cryptographically is able to prove that some funds originate from some other address on this list or not on this list, either through just simple smart contract checks or through more complex proofs inside of zero knowledge proofs, which seems as a good solution, I guess.
00:24:48.138 - 00:25:33.308, Speaker B: But the problem of course, with blockchains like Solana becomes speed, right? So we don't need to wait for a settlement like in the Swift system, I guess we have instant settlement. So the illicit actor will always be able to move their funds faster than they will be possibly identified as an illicit actor. And also additionally linked on chain with some consensus by Oracle, for example. So that doesn't work, I guess if we have a practical look at it and also comes with another problem. It's inherent centralization effect. Right? If we have a smart contract that relies on a blacklist, we need to be fast, need to rapidly update it, and that results in centralization. And another approach you might have heard of is so called user configurable privacy pools.
00:25:33.308 - 00:25:54.734, Speaker B: So that just means instead of having this blacklist fixed on chain, the user, the SDK, whatever, could decide to select a subset of users when moving funds, exiting whatever to prove to be part of or not part of. But at the end of the day, suffers from the same problems as withdrawal screening. I guess.
00:26:00.414 - 00:26:54.412, Speaker A: One of the things here in the design of all these systems is at the end of the day, the only person who can truly sign off on something is a regulator or a law enforcement entity. And one of the challenges that we've seen repeatedly is when there is a lack of clear standards and a lack of clear instructions from regulators to abide by. Decentralized systems seem to be the ones that get hurt the most in this arrangement. Right. So there are many, many, many cases of many, many large international banks either intentionally or unintentionally facilitating money laundering and transfer for drug traffickers, for terrorists, for all sorts of groups. And largely what happens is there's a process and investigation, there's a slap on the wrist, there might be a fine, but largely the enforcement is, it seems like it's social. It seems like there's a stern talking to with some folks at the bank.
00:26:54.412 - 00:27:52.324, Speaker A: And at the end of the day, that's something that's just passed along as like, oh, okay, fine. You sort of contrast that with the immediate and fairly aggressive sanctions placed against something like tornado cash. That setting aside how likely something like that is to actually get through, it's an incredibly different approach to what that sort of human level compliance looks like. Do you think there's a level at which systems that are truly decentralized can ever provide regulators significant enough certainty that they don't fall into that sort of trap? Because at the end of the day, it seems like what the person in the government office wants is another person to talk to, to figure out, like, you've done a bad thing, don't do the bad thing again, here's what we want you to do. And that's not possible in a network that has potentially hundreds, if not thousands of different contributors that are all writing code and configurating their own privacy.
00:27:52.654 - 00:28:49.266, Speaker B: Yeah. So really the issue becomes we removed the financial intermediary. And in a traditional finance system, this financial intermediary was also the, I guess, accountable party. So that's really, I guess, sort of the idea that the direction where we come from then with our protocol, I mean, the idea for us is with other protocols. What we've seen is this problem of illicit actors being too fast, right? And therefore being able to facilitate money laundering. And what we want to do is we want to basically extend the time in which an illicit actors flow of funds could be identified after they've sent the transaction. So we can start by imagining just an ideal world situation where we, I mean, not an ideal world since we still face the issue of illicit finance, but a world in which we are not alone against the threat of illicit finance.
00:28:49.266 - 00:29:43.470, Speaker B: We have what we can call the Guardian, which is an imaginary actor that is fully trustworthy and cannot be compromised, right? So we have this, this actor and with this actor on our side, we can say, okay, we run completely permissionless private transactions on the blockchain. But what we do is we give the Guardian a key pair the Guardian can use to look into the transaction. So every transaction becomes encrypted and the Guardian can look into the transaction. So for the Guardian, every transaction looks like our normal transparent transactions. For the rest of the world, they remain private. And that's not an issue because the Guardian is fully trustworthy. And then we can task the Guardian with looking for all sanctioned addresses if they have sent transactions and identify the linked addresses if they have, I don't know, received some relevant amount of funds.
00:29:43.470 - 00:30:40.784, Speaker B: And then the Guardian could publicly tell the world what happened, right? And so the issue now isn't anymore. If at some point in the past an illicit actor has sent a transaction and one week later they are being identified, that's not an issue anymore because at the moment of identification the Guardian can just look through all transactions and find the ones linked and report them, therefore removing privacy and therefore not having the situation that tornado cash faced, which was all funds being mingled together basically. And yeah, I mean, it's not only difficult for the user but it's also difficult for the regulator, right? Because you have possibly a large amount of illicit funds and honest user funds. But this situation wouldn't happen with this architecture because the Guardian can just outcast basically the illicit actors removing their privacy and all other actors remain private.
00:30:41.084 - 00:31:42.734, Speaker A: So even in a world of a perfect guardian that is incorruptible and has full information and will respond to appropriate inquiries appropriately, there is still the question of who accepts an inquiry as appropriate. Right? So your classic example here is Apple's privacy policy in China. Is very different than Apple's privacy policy in Europe or the United States, right? They will hand over data to the chinese government at will. So at some point, the Guardian has to decide what is a legitimate request from a government or law enforcement entity and what is not right in the jurisdiction of one country. A legitimate request, maybe we would like to see all data transfers related to our citizens in another jurisdiction that may be totally against the laws and regulations of that country. So how does the guardian, or how does the network in this case decide which requests are worthy of complying and which requests are not?
00:31:43.314 - 00:32:30.964, Speaker B: So for us, the guardian is just being replaced by a decentralized multiparty computation network that can perform those more or less stupid computations in a minimal, trustworthy way. But the decision what actually constitutes as illicit activity, I guess, has nothing to do with the guardian itself. The guardian just follows commands. So we can can just outsource this decision to some other distributed body. And the idea behind that is make it distributed. Because if we make it distributed, we can have a more thorough process of reacting to governmental inquiries or reacting to, let's say, a reporting of our on chain analysis firm identifying the addresses of some hacker. So we can have a more thorough process.
00:32:30.964 - 00:33:52.220, Speaker B: Simply because we have extended time, we don't have the constraints that the other solutions have faced with. We need to move as fast as possible and prevent the illicit actor from transferring the funds. Because that's not an issue in that architecture. At the moment of identification, it becomes transparent what happens. So we can set increased consensus requirements on the identification itself, and also through the technical implementation that we have more nuanced approach of stating what an illicit actor is, right? So if we go back to the imaginary guardian, the Guardian could just report making all transactions of the illicit actor transparent. But what the Guardian could also do is could simply state the fact that a transaction has been sent by an illicit actor, right? So the illicit actor would still be somewhat private, but at least completely isolated from all honest actors, again, preventing the tornado cash situation. And so we can have a lot of varying degrees of what we do once we've identified an illicit actor, right? And so we can have varying consensus requirements, lower consensus requirements for just flagging the suspicious activity, and super high ones regarding actually removing the privacy entirely.
00:33:52.220 - 00:34:09.620, Speaker B: And in between, there could be something like electing some third party that could look into the actual happenings of the flow of funds, right? So this distributed body could vote on giving some third party insight, but no one else, into the flow of the transactions of some specific actor.
00:34:09.812 - 00:35:10.962, Speaker A: Yeah, I think that's like when we're kind of talking about this stuff, I think that like that comes down really to the, to the key, which is like any type of system that has the ability to compromise its privacy to respond to certain types of requests. Its attack vector is the compliance piece, right. It is the question that an actor with a sufficiently large enough gun can force the entity that is sitting in the middle that technically has the keys to do any sort of activity. And I think this is where, when folks think about privacy and blockchain, the current understanding is so binary, right? It's either it is private or it is not private, because crypto doesn't really like to deal with the messiness in between. It doesn't really like the fact that like, I mean, you saw this with Ledger, right? Ledger has always had the technical ability to update the firmware and steal your private keys. That is something that's always been technically possible. We have just trusted them not to do that sort of thing.
00:35:10.962 - 00:35:56.590, Speaker A: And folks in crypto are very uncomfortable right now with the idea of trusting anyone who has the technical ability to do something and just has a policy that says they're not going to. I guess I'm curious if you see that as an idea that can survive the mass scale adoption of crypto or are a lot of the folks who are sort of like privacy absolutists going to have to compromise a little bit on not necessarily the tools they use, but the tools that get adopted for blockchain for the sake of mass adoption? Do we need those sort of fungible intermediaries that do require at some level, trusting an organization or a protocol like elusive that can technically decrypt privacy over something that can't as something required for adoption?
00:35:56.742 - 00:36:59.890, Speaker B: Yeah, that's obviously something we are very passionate about. And luckily our technical architecture allows us to almost remove all trust. So what I'm saying with that, want to say with that is through the blazing, the guarding, with a multi party computation network, we can have this network run on a dishonest maturity assumption. So that's the first trust reduction. Instead of trusting one single entity, we only need to trust that there's one single honest node in this network, right? So that becomes the best trust assumption you can have because the alternative would be all members of some organization are dishonest. So that's from a technical level, the base assumption we have, I guess compared to your normal blockchain, that has byzantine fault tolerance, which would be honest majority as an assumption. But still that would be problematic, right? So imagine we have this powerful computational network where I only need to trust that there's one single honest node that.
00:36:59.890 - 00:38:45.196, Speaker B: So technically, what each node has is a key share, right? So it doesn't share this key share with the others. That is my trust assumption, which is fully reasonable in the moment. But ten years from now, is it still reasonable for me in the moment to believe that then the network is adequately configured in an honest way? Right? So our approach here is some other solution we've devised, which is running so called epochs. And in each epoch, what the network does is destroy all key shares and generate new ones, and then migrate a subset of the encrypted transactions to the new key shares. And with this epoch based guardian decryption key process, a beautiful new property emerges, which is you only need to trust that in the moment there's an honest node for your privacy to be guaranteed ten years from now, simply because no one is able to decrypt anything anymore after your current epoch has passed, right? So depending on how large this epoch is, if it's one month, one week, whatever, after that time has passed, it's impossible, if there was one honest node in this computational network, to decrypt your transaction, right? So that greatly decreases the required trust from the user. And then only the question becomes, within one epoch, I want to have as little trust as possible as an honest user, and that would be the trust against this voting body. But what's beautiful with having those computations of the network be separated from this voting body is that we can have, I guess, transparent surveillance, right? So if the government decides to surveil your bank transactions, they can just do so.
00:38:45.196 - 00:39:17.724, Speaker B: You won't be informed of that. But if this voting body would turn compromised and reveal some transactions or flag transactions, you would be informed of that. The world would be informed of that, which introduces new, interesting, I guess, game theoretical tokenomics, because then you can look at how can we design this global community that decides who is an illicit actor, because now the community itself becomes fully accountable. So, yeah, I guess that lies off the core of how we can minimize trust.
00:39:18.024 - 00:40:03.526, Speaker A: So, looking at sort of the future of what privacy solutions look like on chain today, we don't really think of privacy as an overhead layer on the Internet the way that maybe 15 or 20 years ago we did. Encryption used to be expensive. Now it's functionally free. At web two scale, how long do you think it is until we start to see similar dynamics play out in web3? Right now, zero knowledge transactions are much slower, and they're more expensive from a computational standpoint, than simple transfers on every blockchain. How far away do you think we are from this stuff being functionally free or just as easy to integrate into solutions as a certificate is? Or end to end encryption is today?
00:40:03.700 - 00:40:53.708, Speaker B: So, in the last few years, we have seen great acceleration in the development of both the core crypto traffic protocols, seeing major speedups, but also the tools for developers. Right. Abstracting away as much of the hard cryptography that's also potentially very dangerous is very important, because if that wouldn't be done in our web two world, I guess you wouldn't see encrypted databases. So that's also very important. And I think those systems, those layers, that's also, I guess, our work are put in place right now. And within the next five years, we will have zero knowledge technologies. Whether they are zero knowledge proofs or full homomorphic encryption, multiparty computations really doesn't matter.
00:40:53.708 - 00:41:00.800, Speaker B: We will just have zero knowledge technology everywhere. In our iPhones, on our blockchains, in our money, I guess.
00:41:00.912 - 00:41:08.344, Speaker A: Well, I look forward to that. Hopefully not too far. Distant future. Janik, thanks for joining us today on validated.
00:41:08.464 - 00:41:10.644, Speaker B: Yeah, thanks for having me. It was a pleasure.
00:41:14.184 - 00:41:23.304, Speaker A: Validated is produced by Ray Belli with help from Ross Cohen, Brandon Ector, Emira Valiani, and Ainsley Medford engineering by Tyler Morissette.

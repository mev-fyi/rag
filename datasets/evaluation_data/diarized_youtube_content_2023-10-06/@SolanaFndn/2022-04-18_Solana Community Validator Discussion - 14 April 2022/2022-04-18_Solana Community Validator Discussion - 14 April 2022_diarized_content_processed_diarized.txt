00:00:02.560 - 00:00:32.444, Speaker A: Welcome everyone to the Solana validator relations call. Thank you for joining me and taking the time. A pretty light agenda today. We've got Alex, who will be talking a little bit about the server program. Then once he gives that update, we've got some, some updates about the validator from Anatoly. So special guest today giving an update on the state of the validators. So Alex, why don't you get started and then we'll have totally take it away.
00:00:33.224 - 00:01:12.294, Speaker B: Hey everybody, I'm Alex. I know I've seen many of you before, mainly been running the server program with the foundation, as well as doing a bunch of other bd related activities over there. Two quick things. One, we have been working to upgrade a large percentage of the server fleet that's in the server program to support 512gb for RPC. And that is actually actively rolling out. And there are servers becoming available as of this week. So I know that's especially important for the RPC providers on this call, but there anybody who wants servers that have that specification, you can get them.
00:01:12.294 - 00:02:12.172, Speaker B: The other thing that I just want to throw out there is something to start thinking about is that there are, and I know Dan has kind of talked about this, um, there are multiple, uh, other opportunities to generate revenue coming for people with your skillset who run validators. Um, specifically things like neon running like a neon proxy, um, that uh, you know, might actually tie into an RPC directly or validator directly. I know some of this stuff is still sort of in the works as far as like what the exact specifications are. Same thing with like Genesis go and like decentralized RPC networks and whatnot, and any of these things. If you need servers to support those use cases, you can access those servers for the server program. Basically anything that is in service of supporting this Lana network, the program, we can make servers available for you for that purpose. So I'm your guy to hit up.
00:02:12.172 - 00:02:24.234, Speaker B: If you have questions about that on Twitter, you can dm me. I'm also on Telegram too, if people want to talk. But yeah, just if you have questions or have ideas or any concerns, please let me know anytime.
00:02:26.254 - 00:03:11.484, Speaker A: Thanks, Alex. One more thing I'll mention is that Kronos just won the hackathon recently and Chronos is working on task scheduling on validators. So that should also unlock some potential other models and revenue that you can employ on your validator. All right, now, Anatoly is going to give an update on the compute unit bug and other validator network updates. So go ahead, Anatoly. You might be muted. Yeah, still not hearing you.
00:03:30.424 - 00:03:31.564, Speaker C: What about now?
00:03:32.504 - 00:03:33.324, Speaker A: Yep.
00:03:34.924 - 00:04:23.200, Speaker C: Chrome doesn't google me. Doesn't like Safari, I guess. Yeah. So this awesome engineer, Christian cam, I think is his last name, cCam on discord. He discovered this bug in the cost model, where transactions were sometimes counted multiple times with regards to how much block space, or compute units are going to use in a block. So first of all, what are compute units? This is basically our kind of raw estimate of how much time a transaction is going to take when it's being processed during the replay part of the validator. So when a validator receives a block from the network, they have to replay that block.
00:04:23.200 - 00:05:10.956, Speaker C: So they run through all the transactions in a multi threaded manner. And there's a certain amount of compute that each transaction takes because some may take more cycles, some may take some lock more accounts, some read more data, some write more data, some do more CPI calls or more instructions. All those things end up as time. And we funge all of this together into this one unit called a compute unit. And we can't have those blocks take more than 400 milliseconds, because if blocks take more than 400 milliseconds and the slot time is 400 milliseconds, then the network gets slower and slower and eventually falls over. Not quite. They'll actually start skipping blocks and continue struggling along.
00:05:10.956 - 00:06:12.084, Speaker C: But it's a behavior that isn't very great for the network. So the way the cost model works is it estimates as it's filling the block, how much space has been used. But sometimes when it submits a transaction into this block, the banking stage, when it's processing transactions, it gets an error. Some of those errors are basically benign, that currently the banking stage can't take this transaction because it's already processing a transaction that's using some of the state. So because it's expecting parallelization and you're trying to submit another thing that will have to be contentious with what it's currently doing, it rejects it. And in that case, we were adding the compute cost when we were adding the transaction, but not removing it when that error was caught. So that would effectively reduce the effective block space available for processing.
00:06:12.084 - 00:07:01.814, Speaker C: So during some bot activity, you saw this kind of get hit over and over where a lot of the transactions being submitted were touching the exact same accounts. So you get these exacerbated moments where all of a sudden you have small blocks that were produced, being produced by validators replace taking its normal amount of time, but for whatever reason, and we don't even see a ton of traffic, like the 20 gigabits that you normally see during an NFT drought. But for whatever reason, you still see this like TPS drop. So that was the reason for that TPS drop, was that constant double counting on across multiple fronts. There's a couple bugs there. The major one, we hot patched it as fast as we could. Tao is still working on a second fix and there might be a third minor fix.
00:07:01.814 - 00:07:46.084, Speaker C: So that's the main issue for that particular bug. Don't build your own runtime ever. It's the worst idea. It's the largest surface area of what users will touch. And I guess if you want job security, that's one way to get it. So the main thing that we're getting really close to is the 1.10 release with quick main problem right now, unlike Mainnet, that's been like a very well known problem, is that during an NFT drop, you have sometimes bots generate like almost 20 gigabit worth of data that they're submitting and they're spamming the network.
00:07:46.084 - 00:08:26.540, Speaker C: And this effectively, like imagine you're running an auction and the, the person stuffs all the participants in that auction with their friends, so only their friends get to bid. And you effectively can't run a real fair auction because only, only one person and their friends are bidding, right. So all the prices would be artificially deflated. So even if we had a fee market, we can't really. It wouldn't be an effective fee market because the only bidders in this flood of traffic are going to be these bots. So the first major fix for this is going to roll out in 1.10, which is quic.
00:08:26.540 - 00:09:27.694, Speaker C: It's quic as fancy UDP. It's got guaranteed that the source is valid because it does TL's and TL's encryption. To validate that, the source and receiver, they're all using the right encryption keys. It has the same properties of UDP where things can be arrive out of order and you can multiplex over a single UDP port. So it's got a bunch of really nice stuff on top of it, which makes it like, I think, usable for our environment because we still really want that ability for real time data and traffic coming in from market makers, from financial applications to be kind of submitted in a stream like you would expect on an exchange. So that will be enabled alongside a UDP. So we're going to see both kinds of traffic and that's funneled into the SIG verify stage at the validator and gets processed and then kicked off to the cost model and to the block producers.
00:09:27.694 - 00:10:20.578, Speaker C: Once it's live, though, we can expect all the RPC nodes to then start switching to quick, and we should see where performance works where it doesn't, and fix those bugs. In the meantime, there's two more changes that are coming. One is that onquick, because we now can validate the sources, we can actually have guarantees that if the source has half of a percent of stake, that the 99.5% cannot starve them and prevent them from sending transactions to the leader. So that would make sure that when we do run an auction, that everybody gets proportional representation in that auction, that it can actually bid for block space. And then the second part is the actual auction, the fee market. So it's complicated on Solana, because Solana is a parallel runtime.
00:10:20.578 - 00:11:41.862, Speaker C: So it's very simple in Ethereum, because when Ethereum transaction runs, it locks the entire state so it can modify any part of the state. So here we actually run multiple concurrent auctions at the same time. And if you had one really important NFT drop, that NFT drop, the maximum compute units it can use is 12 million, even though there's 48 million of actual effective block space, because 12 million is the most that a single thread can take, and that single thread can't exceed 400 milliseconds. So in that environment, we need to sort these transactions into these buckets where there is contention, and then no bucket can exceed 12 million. And therefore, people bidding for that single bucket, those fees shouldn't impact anyone else. And for that to be true, we need to make sure that when a block producer, the leader, is actually looking at all these transactions, that they can consider a wide range of proposals, right? One for the NFT drop coming in from all the people that want that NFT drop, but then also from payments, serum markets, mango markets, et cetera. So that kind of like bucket filling algorithm Tao's working on, and I think it's about halfway done.
00:11:41.862 - 00:12:49.974, Speaker C: And I think maybe probably six weeks, like next release 111 is when it'll be out. So in combination, right, if we have this stake weighted QoS and quick, we can guarantee that proportionally by stake, everybody gets to submit transactions. So when a validator starts doing this bucket filling algorithm, they do this when they build a block, but also when they forward transactions to the next leader. So a stake weighted node that's receiving transactions from its RPC's that it knows and trusts, it can start creating these buckets and then proportionally start sending to the next leader some transactions from Bucket one, which is the massive NFT drop, but then also from the rest because it knows that the leader cannot possibly fill its block with more transactions from that bucket one. It knows the cutoff. So that allows us to actually serve all kinds of users across the same, the same block in the same network. Obviously something that's complicated.
00:12:49.974 - 00:13:21.404, Speaker C: We'll probably have bugs, so we'll, you know, I hope not. But we should be able to iterate and like fix these and like, you know, have monitoring and totally appreciate everyone that's been monitoring the network like a hawk and like figuring out that when we have a TPS drop, it's not actually from 20 gigabits worth of spam. It was a different issue. Like having all these eyes on the chain has been awesome. Couldn't be here without you guys. I see there's some questions.
00:13:22.504 - 00:13:26.080, Speaker A: Yeah, densetsu, sorry, say that wrong.
00:13:26.152 - 00:13:44.924, Speaker D: Go ahead, that's fine. Would you agree that testnet hasn't really provided the level of soap needed to prevent these bugs? I mean if testnet running real transactions, it might have been noticed that this problem occurred there before that introduced it to mainline.
00:13:45.364 - 00:14:36.654, Speaker C: Yeah, Testnet has been great in terms of us like dumping twice as many validators on it, equal stake weight and stress testing it and seeing that we can handle the forking under load and all this other stuff. It's really great at a lot of things, but it's really bad at actually real world application like simulation. That's really hard to do because you need the devs and the consumers of those products to use the same behaviors. But because there's no economic incentives, nobody wants to, nobody wants to spend the time. I think maybe the foundation could like add some economic incentives for your bug bounties or something like that, or grants to really start building sophisticated benchmarks for the Tasna. That might be pretty, that might be helpful.
00:14:40.524 - 00:14:41.864, Speaker A: Any other questions?
00:14:44.884 - 00:14:54.904, Speaker C: Yeah, it sucks that it took two months for us to find this. Just unfortunate. Murphy's law, right? And Murphy's. Murphy's economically motivated.
00:14:58.964 - 00:15:18.994, Speaker E: I do know that some of the apps are actually now looking at Testnet as a, for just that purpose to start stress testing their own apps. Mango guito have inquired. I think we're going to see more of that. They may already have the incentive that they need. But of course if the foundation can give a boost, that's helpful too.
00:15:22.734 - 00:15:29.242, Speaker A: Yeah, I think it's definitely something the foundation's interested in and should be doing. So I'll work with Dan on that.
00:15:29.358 - 00:15:56.574, Speaker D: Can I point out that it, I don't know, it, it has both good and bad aspects for Testnet validators because if there's a lot of load put on Testnet they may find that the systems they're using aren't sufficient. Like it could be that a lot of testnet validators are getting by on absolute minimal hardware and once they start falling behind or not being able to vote or whatever they could put more pressure on them, which is of course what you kind of want. Difficult for people that are already oftentimes in a very difficult situation to begin with.
00:15:57.104 - 00:16:44.654, Speaker C: Yeah, we should, but we need to see what happens, right? Like we need to design the software such that when it's overloaded and like the systems are stressed that it can automatically back off and figure out how to do that. You know, obviously there's like we've added some rudimentary switches where if your notes are falling behind by such a large amount that when you're making a block you only include votes. So the stuff like that already exists. But like we need to see like these, especially in the low memory systems, like if there's a lot of forking, in theory things should still run in constant memory, but sometimes we see that actually jump up pretty high. So we need to know where those bugs exist and what actually triggers them.
00:16:45.034 - 00:17:13.106, Speaker D: Yeah, I was more talking about the fact that on test set a lot of, you know, a lot of them are kind of competing to be at the front of a queue and if, you know, they may start to find that they can't stay close to that front as there's load on testnet because their systems are fast enough which is going to increase their cost of operating in that, which is obviously better because we want testnet to have that function. It's just something to consider for those, you know, those, those members that are waiting to get into mainnet with foundation stake, they may find things even more difficult going forward for that reason.
00:17:13.290 - 00:17:13.926, Speaker A: Yep.
00:17:14.050 - 00:17:26.674, Speaker C: I would personally like to see testnet run on the worst hardware that it can maintain. So we know like what those limits are. We can actually like see it where, how do we like push it to the edge.
00:17:27.574 - 00:17:39.954, Speaker D: But the problem is that some people are going to run bigger, better hardware so they can have better performance, so they can get close to the front of that queue. So there's an incentive for people to actually do not what you said, but in fact run the best hardware they can.
00:17:42.144 - 00:17:46.324, Speaker C: Yeah, that's true. Should probably figure out what those incentives should be.
00:17:48.304 - 00:17:53.324, Speaker E: Oh it potato net and it's erased to the bottom. So you can do this on the cheapest possible hardware.
00:17:53.624 - 00:18:33.194, Speaker C: Exactly. Because knowing if we have insight in that even under extreme load with, like, things hitting swap and everything else, that it's still stable or doesn't stable enough. Right. That it doesn't like, create so many forks that it has no hope of catching up. If we can actually know that the system is stable under those conditions. That's really insightful. It should in theory, but in practice, the wrong lock at the wrong time could cause that load to increase faster than you can process it.
00:18:38.494 - 00:18:56.434, Speaker A: All right, any other questions? Okay, I guess we'll call it then. Thank you, Anatoly, and thank you, everyone, for joining, as always. This will be up on YouTube as well, so if you want to check it out later. All right, bye, everyone.
00:18:56.894 - 00:18:59.934, Speaker C: All right, goodbye.
00:19:00.014 - 00:19:00.834, Speaker A: Thank you.
00:19:01.134 - 00:19:01.934, Speaker C: See you next one.

00:00:00.320 - 00:00:55.924, Speaker A: Let's just jump in. Yeah, so, yeah, I'm one of the Steves on the lab team, I think we. I can't see the full guest list, but it looks like it's all lab sequel. So I know everybody here anyways. But yeah, we're going to be talking about a panic that was observed on Mainnet beta last week, I guess, kind of, yeah, we'll talk about the identification problem process, how we debugged, like root caused, get to eventually the patch to fix it, and then maybe some learnings going forward, like how do we avoid doing this, given that this was like number two on 1.14 in two or three weeks? So, yeah, starting out, the identification problem was actually pretty straightforward, at least from my seat I woke up to. Nice GitHub issue here from Michael Lane.
00:00:55.924 - 00:01:17.132, Speaker A: So Slanadet validator 1.14 panic. So for those who aren't weren't aware, we've been trying to upgrade mainnet beta to 1.14 for several weeks. And so this was pretty clear cut. The 1.14 validators panicked and the 1.13
00:01:17.132 - 00:01:55.224, Speaker A: validators did not. So that's pretty good signal that something is wrong with 1.14. And yeah, like I said, I think people convened on discord, figured it out pretty clearly. And then you can see this full panic message here Michael provided, but just for the. I guess as part of debugging, it's nice to be able to see things on our own machines and have access to full logs, metrics, ledger, etcetera. So luckily we had some machines that were running both versions. And I have the, actually have the logs stashed here from that day.
00:01:55.224 - 00:02:23.944, Speaker A: So grepping here. So this is the 1.13 log from this day, so there shouldn't be any panics because 113 was running without issue. Large log file. Okay, cool. And then versus 114. Oh, 1.14,
00:02:23.944 - 00:03:21.084, Speaker A: rather, you see the same panic. So replay stage must exist, and must, must exist in progress map. So this is actually a panic that I'd seen before. So actually I kind of knew what was, what was going on with this one, but we were discussing. But essentially the, this panic is the symptom of a consensus mismatch, and that the node identified that it had voted against, it had voted against the rest of the cluster, and so it went back and purged the slots that it had voted deviantly on. And then I guess the state was not correct or how it thought it'd be after that panic. So just displaying the 25 lines before the panic, this is always a good idea to see what led up to the panic.
00:03:21.084 - 00:04:16.476, Speaker A: This is kind of that behavior I described here. If you've read through replay stage, when we detect that we are not with the rest of the cluster, we purge the slots that are deviant and all descendants of the divergent slot, and then we try to repair and replay. So here's the loglines of purging those slots. I guess in doing so, we deleted a slot that we expected to be there in another chunk of the code. So this is actually a point of discussion on this GitHub issue behind whether that panic is good or whether we should fix that. In some ways, this panic is good because we're in a bad state, but it's also the symptom of a worse behavior. And I guess that worst behavior is this logline here.
00:04:16.476 - 00:04:32.534, Speaker A: Oops. Should have seen that coming. So this logline from the cluster slot state verifier, cluster duplicate confirmed slot with hash. So basically this is saying.
00:04:34.474 - 00:04:34.882, Speaker B: This is.
00:04:34.898 - 00:04:57.310, Speaker A: A hash that at least a majority of the cluster has observed and voted on. But I guess I'm wrapping here. Let's get that. But we had a different hash. So this is kind of that. This is the lead up to that behavior that I mentioned. You know, we're divergent from the cluster, and so we can't proceed forward.
00:04:57.310 - 00:05:37.462, Speaker A: And so this is like the step right before we begin purging that slot. In this case, it was the one ending in 896. So, yeah, once we identified that, the kind of, you know, we've done this a couple times, we kind of have a good process. And it's in the same way before as, like, wanting to see the logs on our own machine. We also want to see if we can reproduce the behavior with Solana ledger tool. And so kind of the first step, call it assembling a ledger, but essentially just get a. Get a ledger setup so that we can replay this diversion slot very quickly.
00:05:37.462 - 00:06:10.164, Speaker A: And so doing that, you know, if you've run ledger tool or validator, you know, you need the three pieces genesis bin, that never changes. So you always have that laying around. You need a snapshot, and then you need the shreds in rocksDB to replay. So in this case, I think I had. My machine had created a snapshot fairly recently. Maybe that one wasn't it. But any case, we needed to get to like, 896, I think, what, 75, 896.
00:06:10.164 - 00:06:31.504, Speaker A: I think this might have been the snapshot. I had the full snapshot. So I was 67, 386. So, like 12,000 slots away. But with the incremental, I think I was only 75, 782. So actually I got really lucky here. I was only like 100 some slots away.
00:06:31.504 - 00:07:11.436, Speaker A: But any case, the idea here is that we're going to be replaying this. We want to replay the single slot in a tight feedback loop later on. So I went ahead and created a new snapshot here on the snapshot here at slot 895. And the important thing to remember here is if you want to replace slot x, you need a snapshot at slot x minus one, because the snapshot at slot x has the transactions for slot x already reflected. So if your problem slot was 896, so we need to make it at 895. And actually, I guess. Oh yeah.
00:07:11.436 - 00:07:52.100, Speaker A: So with that snapshot, I guess I'm not going to go into that, the actual commands, because I already have them, but those are actually kind of, this process is also documented here in this wiki. I've typed up gradually over past months or however long, but the actual commands to do so are here, I guess, talking about. Yeah, this part here, collecting the ledger. So getting a snapshot. So yeah, we can make sure that one gets sent out as well. So yeah, with the ledger we were able to replay. So kind of next steps we're running verify.
00:07:52.100 - 00:08:32.254, Speaker A: So I ran verify, Solana ledger tool verify. That is, I ran it with one version, the good version, which in this case is 113.6, and it created the incorrect hash. I guess I'll just fire one of these off and let it run in the background for people that haven't seen this tool. So you just pass, you pass the tool a path to your current ledger. And I guess I'm already in this folder, so I just want to do it here and then halt that slot. I have a bunch more slots than I need.
00:08:32.254 - 00:09:03.334, Speaker A: I only care about playing this one, so I only want it to do this. And this will actually take a while to run, so I'm not really going to pay attention to it, but just showing you that the commands here are pretty straightforward. Yeah. So with that, that's kind of covered here. So this is a separate GitHub issue I spawned out to cover this consensus mismatch and running verify on the two versions. I had the. Let me blow this up.
00:09:03.334 - 00:09:34.358, Speaker A: So we had the hash from 1.13 and then the hash from 1.14.13. And as you can see, they differ. And these also match the hashes that were initially reported. I think the. Oh, sorry, the first slot here for 896. So that's the G's, that's the GS one that 1.13
00:09:34.358 - 00:10:02.734, Speaker A: and the cluster reported, whereas nine n is the one that was produced by our 1.14 divergent nodes and then also recreated in ledger tool from there. There's kind of a process. So, yeah, we know what slot is. The, is the issue now. So we want to go figure out what the transaction is that's causing the problem. And so this is a step that I kind of also have called out here.
00:10:02.734 - 00:10:52.884, Speaker A: But what I do is for the, for that slot that caused the, that caused the divergence, I will go out and I'll print the account hash for every account that was updated in that slot. So this patch here, it's like a five or ten line change in the accounts DB code and runtime. But, yeah, pretty simple here. Just if slot equals fail slot, run through the account hashes that were updated in the slot. Just dump them out to a log and then run that free trojan. You diff the files, and with that, you'll get the, the hashes that were differing. I think I killed my thing there.
00:10:52.884 - 00:11:13.122, Speaker A: Oh, yeah. I think I might even have these saved out. Oh, yeah. So, like the, so this updated account. So, essentially, this is like that log file I talked about. Oh, yeah. So here, here's these, these updated accounts.
00:11:13.122 - 00:11:37.794, Speaker A: So I have that for 1.13 and 1.14. So if I dif those and then 114, what did I. Oh, extra f. Yeah. So here there's showing the diff. There's, like, only a small number of counts.
00:11:37.794 - 00:12:23.104, Speaker A: This is good, right? There's a finite number of counts we can hone in. If you guys have looked at enough of these hashes, you'll know ninjas Zantetsu. He's a leader. But in any case, with these accounts, the next step where you can hone down is another ledger tool. Command is slot. And with that, you can get the printout for all the transactions in a slot. So, ledger, I think I need to go one up ledger.
00:12:23.104 - 00:12:57.602, Speaker A: All right. So, yeah, okay, I'm in the right path. So I'm printing the slot here. There's not a ton of info there, but if I pass up the verbosity, I'll get the full printouts. And with that, this prints out all the transactions, which includes all the accounts. So from there, I can just diff, or I can just grep. Again, I think I had it in the terminal earlier, but these were the two different accounts.
00:12:57.602 - 00:13:17.630, Speaker A: Ninja and this other one. Oops. So, grepping there, and I see there's just one account. So that's another good sign. There's only one account that touched it or only one transaction. Sorry, only one transaction that touched this account. So we know that this is the one that did us in.
00:13:17.630 - 00:13:51.814, Speaker A: And from there we can just increase, show some text before and after and get the signature. And then with the signature we have the transaction. And that's kind of what's going on here. So looking at the log, found the transaction, we can go look up an explorer and we have this. So from here we. This is kind of where things get. So, yeah, up until this, things are pretty straightforward.
00:13:51.814 - 00:14:43.810, Speaker A: We're just kind of following instructions from this wiki here. So nothing too crazy, just kind of plug and chug until you get to the last transaction. So this is kind of where things get interesting. And this is where kind of the domain knowledge of who knows what comes into play. So sometimes, you know, like just as a lab site engineer or working more on like, the validator code, not the runtime, the runtime is a little bit of a black box. So like, you know, it could be the runtime, it could be something outside. So kind of in previous iterations and this one included, sometimes we'll ask Alex or Alessandro or whoever's around to take a look.
00:14:43.810 - 00:15:27.224, Speaker A: That happened in discord here as well. And that's kind of covered in these GitHub comments. But essentially we asked Alex here, like, hey, can you take a look? He did his thing. I can't actually speak to exactly what logging he added, but essentially in his comment here, he was able to prove that the transaction had a difference before going into the runtime. Namely, I think this Lamport difference here. Yeah, these two values are different. So the starts with here saying is the Lan ports heading into the runtime.
00:15:27.224 - 00:15:45.324, Speaker A: So with some debugging, he essentially proved that it was something prior to the runtime, which helped narrow us down from there. I'm actually going to tag Tawin, who can kind of speak better to kind of the next steps and diagnosing the exact root cause here.
00:15:48.104 - 00:17:06.346, Speaker B: All right, thanks, Steve. This is very helpful. So once we nailed down all the way to the transactions, the banking transactions, that causing the hedge mismatch, and Alex being able to confirm this happened before the runtime with ledger tools and with snapshots, what's pretty obvious, we can just put some more long lines into it and debugging through it. And it helps to narrow down the actual bug, which is a compute budget instruction flag that's not being consistent between 13 and 1414 has a correct behavior, but 13 is not. In nutshell, the issue is if you request heap frame along with the any fraudization fee and the compute limits in the same transaction, that request heap frame will ignore the prioritization fee in 13 but not in 14. So therefore some validators will charge prioritization fee for the transaction and the 13th were not. Hence the balance difference.
00:17:06.346 - 00:17:59.954, Speaker B: As you pointed out earlier in Alex slide, looking into the code change that seems to be causing from a previous like six months old PR that did the feature activation cleaning and the cleaning somehow produces inconsistency. So we put in the PR feature gated to make sure anything amend that beta that 14 and beyond would mimic thirteen's behavior, which is incorrect, but at least consistent until the feature gate is activated when the 13 is retired from an. So that's what we have.
00:18:03.134 - 00:18:03.998, Speaker A: I guess.
00:18:04.166 - 00:18:06.114, Speaker B: Time for questions.
00:18:19.894 - 00:18:47.182, Speaker C: Hey Tao, this is Brennan here. I've got a question on this. Yeah, so I'm curious, like is the runtime and some of this surrounding like fee paying stuff is a little bit of a black box to me as well. Is this kind of an obscure happening or like a rare occurrence? I guess, because obviously we didn't see this January 14 just blow up instantly. So it must not be something that's happening all the time.
00:18:47.318 - 00:18:48.750, Speaker B: Indeed, indeed.
00:18:48.942 - 00:18:49.310, Speaker A: Yeah.
00:18:49.342 - 00:18:53.022, Speaker C: So what, can you talk about that, like why it's rare kind of the conditions to happen?
00:18:53.078 - 00:19:11.714, Speaker B: Yeah, yeah. The bug is such a way that it only triggers when, so there's three instructions for compute budget set from request a heap frame and set the prioritization fee and set the unit compute unit limits.
00:19:12.974 - 00:19:13.714, Speaker A: And.
00:19:15.614 - 00:19:30.274, Speaker B: It only happens when the request heapframe ended setting with a prioritizing fee, both present in the same transaction. It never had the prioritization fee is something new.
00:19:30.614 - 00:19:30.990, Speaker D: Yeah.
00:19:31.022 - 00:19:43.964, Speaker B: So it never has had an issue before. And the people barely set both together. And that particular transaction, as he brings out on the screen has three of them all together and that's the trigger of the bug.
00:19:47.104 - 00:19:48.648, Speaker C: I see you got it. Thanks.
00:19:48.816 - 00:19:49.564, Speaker B: Yep.
00:19:51.904 - 00:20:21.212, Speaker A: This comment there too. Like um, so yeah, like we, we have saw this when we were trying to push 1.14 to Mainnet. Um, will and like some of the, like the SRE info folks, like we do have things in place to try to catch these before we ask validators to update, namely like the canaries. So, you know, if Mainnet's state, like right now, mainet is stable on 1.13.5 or six. So we have nodes that are running 1.14,
00:20:21.212 - 00:21:02.154, Speaker A: we have nodes that are running master. We also have individuals running various versions, people off tip of master or whatever. So we do try to get some coverage on later versions, but in this case, this is pointing out a shortcoming, that we don't necessarily have every permutation, nor could we possibly have every permutation of transactions. I think that's something that got re brought up as a topic of discussion. How do we get a better load and how do we get transactions like this on testnet so that we catch these things on testnet and not on Mainnet?
00:21:06.574 - 00:21:34.936, Speaker C: Yeah, that's a good point Steven. I'm curious because my understanding in this case is the 1.14 behavior is maybe closer to what we want, but it didn't match consensus. And so consensus is always what wins. But the 1.14 is kind of what we want. And so it's a weird one in that if we had unit testing on this, it would probably tell us, yep, this is, this is good, this is what we, we want, but it doesn't match consensus obviously.
00:21:34.936 - 00:22:09.904, Speaker C: So then it breaks. So you almost need like a, you know, last stable version versus current tip testing if, if you want a more contrived like deterministic pass fail signal, uh, in like a CI or something like that, which I don't know if we have any hooks for something like that, or if we have desires to. If we're saying, hey you know what, canary testing and seeing like the real load of the clusters is just the best way to go to get mass coverage, but also prioritize coverage over whats actually happening. Yeah. Curious if we have any plans for some more contrived test harness stuff.
00:22:13.004 - 00:22:48.114, Speaker A: Yeah, I dont know of anything concrete now thats come immediately from this and the other issue, but your first point, you hit the nail on the head. Exactly. 1.14 has the behavior we want. So Taos patch essentially disabled the change on Mainnet and then once Mainnet gets to 1.14 will enable the feature gate which will re enable the actual feature. So yeah, kind of a goofy one in that where we're turning off the better behavior to match what we previously had.
00:22:57.514 - 00:23:06.134, Speaker C: I've got one other question, but it's not really directly related to this issue. So I'll cede the floor to someone else, let someone else get some airtime. If there are any other questions.
00:23:10.034 - 00:23:52.700, Speaker D: Not a question, but yeah, your comment about our testing's approach to testing in general. So the thing is, why this is so hard to test for is because these are the things that don't arise naturally or only in very, very specific cases. So in other words, even if we replay on actual meshadeta it can take months, even in this case sometimes half a year for a single transaction to trigger this.
00:23:52.732 - 00:23:53.304, Speaker A: Right.
00:23:53.924 - 00:24:21.084, Speaker D: And probably we have had consensus spatial issues which never, never to get any actual consensus failure in the sense that we updated quickly enough. But now that we're taking things slower, there's more time for the network to diverge on these things. So this is also kind of factoring into this.
00:24:23.744 - 00:24:24.312, Speaker A: Yeah.
00:24:24.408 - 00:25:10.110, Speaker D: So how can we improve the situation? It's really tricky. One more unit testing is not going to make it because like I said, these are the things that nobody ever thinks about. You're not going to write a test for the unknown unknowns. Fuzzy testing might be possible in some cases, but in general it's the same problem. It's hard to get into the wheel like the corners, you can imagine this cleaning a room and there are always corners, the dust and the dirt collects. It's hard to get into that. This is kind of our problem.
00:25:10.110 - 00:25:44.494, Speaker D: Yeah. So in general we currently rely mostly on revenues and just thinking things through, but obviously there's really prone to human error. So yeah, I would say that's, that's one of our toughest problems to figure out how to. This not only goes for consensus failures, also for security issues in general.
00:25:47.314 - 00:25:47.650, Speaker A: How.
00:25:47.682 - 00:25:55.494, Speaker D: To improve the approach to software engineering in general so that these things happen less often.
00:26:07.374 - 00:27:04.184, Speaker A: Yeah, agreed. Also as a, you know, as folks might have noticed, you know, you now need at least one approver on GitHub to push prs through. So that was another happened, you know, as a result of this issue is that we tightened down the GitHub push rules a little bit. So the idea here is to get at least 4 seconds out of eyes or you know, granted somebody can just fire ship it but you know, hoping that everybody on the team is not just firing ship its without looking at things. So. But you know that, that works to some level. But you know, as Alexander pointed out, you know it's, we, you know we can't, you know, these are kind of unknowns you know, we don't know what we don't know.
00:27:04.184 - 00:27:46.494, Speaker A: So you know there's just a ton of cases but yeah it is good stuff. So yeah, more eyes on the code is never a bad thing I guess. Any other questions? I know I flew through the ledger tool thing steps pretty quickly but as Brennan pointed out. Thanks for sharing that. I do have a lot of these steps called out in this page. This is in the Monorepo wiki. And then this debugging consensus failures page.
00:27:46.494 - 00:28:36.014, Speaker A: This even includes I guess some other log statements I didn't really cover. Like in this case we kind of, that panic told us exactly what slot or almost exactly what slot I think. Yeah, 903. So this kind of tells exactly what range to look at. But if there's a failure that doesn't. Some of this other information in here is good, like looking up when your last new route was and then actually this guy here. So I mentioned that log, what our version has, that's actually a log that's typically accompanied with this one, the drop the vote slots.
00:28:36.014 - 00:29:35.884, Speaker A: And if we go back to their, we'll see a bunch of these, this vomit of we'll spare looking through that. But those drop vote slots, those pop out from block store processor. So when we're reading a block and we see that somebody voted against the way we did, we are saying from our point of view those votes are invalid until we've realized that we're the ones that are different from the cluster. So these log statements, drop vote slots will get omitted. So those, when you see a large incidence of those, those will be typically accompanied with this one. The, but our version has. So those are both kind of indicative of a failure.
00:29:35.884 - 00:30:13.184, Speaker A: I personally look for this one just because it's less, you know, it's less text as you can see. And then also like you will see these drop vote slots on occasion in a valid state. You know maybe somebody is, you know there might be one random validator, maybe their mods aren't quite working right or you know, I can't think of any good scenarios now but you know, previously Jito, they had a few divergences before they shift. So like. But yeah, I guess if there's no other questions we can just end it.
00:30:13.684 - 00:30:58.494, Speaker E: I have one last question. So yeah, since you have taken the effort to get all the ledgers to reproduce the bug and I wonder if it's valuable to have these ledgers and the, the rocks db everything stored in the Google cloud or something so that we can basically next time when we try to release we can rerun verify. At least this problem never shows up again until we get rid of 1.13. Maybe people are going to change this computer budget instruction something later again and then try to run they may forgot thing so we, we can run this to prevent at least the same thing doesn't happen again.
00:31:00.194 - 00:31:02.934, Speaker A: Yeah, we, we hypothetically could um.
00:31:03.674 - 00:31:11.294, Speaker E: Maybe this is only apply applicable to this situation. When the code changes, the hashing may changes but we still have to.
00:31:12.794 - 00:31:19.882, Speaker A: Yeah, I mean I think for this one and probably the other consensus failures we've, when, when we've seen not just.
00:31:19.938 - 00:31:22.680, Speaker E: Uh, blindly compare the hashis.
00:31:22.712 - 00:31:22.928, Speaker A: Right.
00:31:22.976 - 00:31:33.684, Speaker E: Maybe the code change. Yeah, the hashes should be, should be the same as long as 1.13 is still the majority of the mainnet.
00:31:35.264 - 00:32:07.274, Speaker A: I mean. Yeah, so we added some unit tests and when we see the failures like this, we add a unit test. So, you know, we would catch this at compile time, which is better, but kind of, you know, echoing some of the sentiment before, like, you know, these things are like pretty, pretty obscure. Typically, these are pretty obscure parts of the code base. So, you know, we write it, we write a unit test like, you know, on a stable branch, nobody's going to break this again. And we have the unit test going forward, but, you know, it's okay. Yeah.
00:32:08.054 - 00:32:19.654, Speaker E: So for, is this a pattern that whenever we add a feature for unit test, we, maybe we are expected the hash with your feature on, with your feature off to be the same?
00:32:20.674 - 00:32:25.050, Speaker A: I mean, I'd say the hash is like a higher level, the bank hash is like a higher level state or.
00:32:25.082 - 00:32:27.866, Speaker E: The account, or whatever account state you are changing.
00:32:27.890 - 00:32:28.450, Speaker A: Yeah, exactly.
00:32:28.522 - 00:32:32.374, Speaker E: You expect the account state to be the same with your feature on and off.
00:32:34.994 - 00:32:45.544, Speaker C: Well, I think in this case exactly the opposite. Essentially, there was no feature. And so the feature polarity controls which hash we should be expecting, essentially.
00:32:46.564 - 00:32:47.020, Speaker E: I see.
00:32:47.052 - 00:32:47.972, Speaker C: Yeah, but.
00:32:47.988 - 00:32:48.116, Speaker A: Yeah.
00:32:48.140 - 00:33:08.624, Speaker C: How, rand, I think to your point, like Steve, I want to say you ran this with the change to verify the fix. So at a minimum, that manual work is a nice way to give us confidence. Hey, this is done. And the question is, okay, do we really need to regress against it all the time? And how complicated is that? And it's probably in some cases maybe it makes sense and in other cases maybe not.
00:33:09.644 - 00:33:24.756, Speaker A: Yeah, that's right. Tao verified against the ledger and we actually almost had a misfire. Almost had to roll a dot 15 day after 14. So that was a good thing we did test, but, yeah, cool. Yeah.
00:33:24.780 - 00:33:53.404, Speaker B: Also in general, for the features seems to be, at least lately to the PR review, whenever you add a feature, we do require what recommend at least to have a unit test with the feature on and the feature off for scenarios to be tested. Then is later down the road when the feature being activated and code associated with the feature gates to be removed, those unit tests should be updated as well.
00:33:54.704 - 00:33:55.484, Speaker E: Yeah.
00:34:02.044 - 00:34:36.984, Speaker B: But the point of replay the ledger after the fix makes total sense. It's not necessary to replace exactly the same measure for all the future release, but for the particular pr that if we didn't replay, it's going to introduce another bug. So once everything is done and packed up and rerun whole thing again against the ledger that early, reproduce the issue to confirm everything's actually good. It's always a good practice in my mind.
00:34:38.604 - 00:35:06.703, Speaker A: Yeah. And actually, I guess I just remembered we actually kind of got that for free this time. So I think we were pushing the change in on like a Friday or something. So, you know, we weren't going to ask people to upgrade, but Michael Vines had updated a node and let it run. And then I think after the fact that maybe it was Bazaad who reported that a 1.14 node had forked, an unpatched 1.14 node had forked off again over the weekend.
00:35:06.703 - 00:35:27.944, Speaker A: Meaning one of these transactions that was crafted with these instructions had occurred again, but Michael's had not forked off. So that was a pretty good sign that, you know, we. That the fix had actually patched the bad behavior without breaking anything else.
00:35:33.924 - 00:36:01.894, Speaker D: I want to add two more things. So the reason why we don't use entire letter replace instead of unit tests is because they're like way too heavy, especially mainnet beta records. And we are working on that. But it's a fundamental problem. It's not realistically going to change that much. So we will always rely on.
00:36:03.634 - 00:36:03.970, Speaker A: The.
00:36:04.002 - 00:37:07.912, Speaker D: Issue being boiled down to unit tests afterwards and that being integrated into test suite. But as Stephen already pointed out, that only covers the very specific issue, so that that one won't occur again. But something similar to that could still happen. And even a lecture replay might not help you there because such a transaction might never have been recorded. And the second thing is, what just came to my mind about the question what we could be doing. It's actually what we're doing right now, sharing our knowledge. And I think there would be even more value if we don't only talk about the debugging of these problems, but also like go more into the root causes of what behavior and what practices led to these.
00:37:07.912 - 00:37:22.244, Speaker D: What wrong assumptions triggered us to code it in this way, in a different way. And what the learnings from the past were in the sense of.
00:37:24.464 - 00:37:25.048, Speaker A: That these.
00:37:25.096 - 00:38:22.616, Speaker D: Often occur in patterns. So for the last two months at least, the pattern was pretty clear. It was just in the sense that these were both seemingly trivial prs, which only did some cleanup and then had catastrophic effects down the line. So that's why we increased our review policies. But they are way more complex classes of things which usually lead to consensus failures that everybody should be aware of, and I don't think we have like this a place to share our knowledge about such things yet. It might be an idea to introduce that somehow. Maybe a wiki page, maybe more quotes like this.
00:38:22.616 - 00:38:23.764, Speaker D: I'm not sure yet.
00:38:36.204 - 00:39:02.064, Speaker A: Yeah, agreed. Knowledge sharing is always good. Actually, Will and I are looking at something. I won't give too many spoilers, but we might be trying to set up some knowledge sharing calls with some frequency, but because we'll hear more about that soon. Yeah, I guess. Any other questions or comments? I'm also happy to.
00:39:02.224 - 00:39:26.184, Speaker C: I have one question. I think this question is for you. And yeah, again, apologies, because it's a little bit orthogonal, but since we talked a lot about ledger tool today, I'm curious, why is ledger tool slow? Like assuming that you're running it on server grade hardware, why does it not process things as fast as say the normal validators going through slots? Is it doing a lot more stuff in the background or what's the story?
00:39:26.224 - 00:40:20.918, Speaker A: There's one issue that I have a pr for, so I have a little hack to make it work faster for me, but that obviously doesn't help everybody else. But one aspect right now is validate. Well, a good chunk of our validators run with accounts in memory, with verify. Right now we added some guardrails to avoid clobbering the validator process. So you could imagine if you're running your validator with custom accounts path, say like mounts accounts, and then you start a ledger tool command with accounts at mount accounts. Those two could easily collaborate each other. And we don't have like any mechanisms to like differentiate that, you know, one is using it.
00:40:20.918 - 00:41:07.744, Speaker A: Like, you know, we don't have like a file lock or anything like that. You know, like maybe we should, but like there'd be a lot of pitfall, you know, you, if you had in a subfolder, you know, like the file lock wouldn't work. So like essentially, yeah, Ledger tool has some guardrails to prevent you from killing the validator. So right now, I guess one speed up that you can get is by running things in accounts in RAm, in temp fs. I have a pr that decided I don't want to go with, so I have a second pr that will probably work on that immediately after this to try to get something reasonable again. But that should be a good speed up. But yeah, similar to.
00:41:07.744 - 00:41:20.904, Speaker A: It's kind of like the pain. Like when you start a validator, you only unpack a snapshot once, so it's a one time pain, but when you're running ledger tool, you probably notice it more because you're re executing things ten times.
00:41:23.724 - 00:42:05.308, Speaker C: Yeah, I'm curious because I tried with having the accounts in memory and some of the funny hacks to get that to work, and it definitely speeds things up, but it's still a far cry from the speed of the normal validator, even when I'm running it on the same hardware. I'm curious if there's anything fundamental. Hey, it will be slower because we've got this extra guardrail or extra logging or some extra process running, or if it's really just, hey, it hasn't been a priority, but there's no real fundamental reason why it couldn't be, you know, 400 milliseconds per slot, for example, processing, because even after the snapshot, I'm not seeing it quite, quite run at speed.
00:42:05.396 - 00:43:02.384, Speaker D: One fundamental difference is that the validator is running continuously, and so everything is warmed up at that point. All the caches, all the heuristics. The thing is also a lot more fine tuned, the parameters have into it and so on. And if you run the replay tool, you not only have to do all the loading things, which is similar to the cache updates, but you also have to again, warm up your caches, tune the use case and so on. All these things which just naturally take time to occur. So because you're always running very short amounts of time, you never get into the point where you can run at full speed, so to speak, because it takes such a long time to get to full speed.
00:43:07.444 - 00:43:33.934, Speaker A: I'll say Brennan, maybe we can chat more about this after too. But I think there was a significant improvement. I think 1.13 might be slower than 1.14. I think as with a. I think in 1.13 there's like a cleanup step for accountsdb that happens like every ten or 15 seconds, and that would stall things out.
00:43:33.934 - 00:44:13.624, Speaker A: 1.14 has the accounts background service, which I think does that more that cleanup more continuously. There's probably not going to find it in time for this call, but I was looking for logs, but there is actually a line that is emitted by block store processor, which is what ledger tool uses. That tells you how many transactions you're processing per second. That should be a lot faster because you have all the transactions in front of you. You're not waiting on any network. It's just literally as fast as you can do it.
00:44:13.624 - 00:44:34.264, Speaker A: And like it is significantly faster. At least with 1.14, I don't know, I'll find the logs, just so I'm not scrambling for them on this call, and then maybe I'll post it in discord as proof that, yeah, we do have this speed up.
00:44:36.644 - 00:44:37.300, Speaker C: Gotcha.
00:44:37.372 - 00:44:37.596, Speaker A: Yeah.
00:44:37.620 - 00:44:38.464, Speaker C: Thank you both.
00:44:41.664 - 00:45:00.544, Speaker A: All right. Any, any other questions, comments, etcetera? All right. We'll take that as a no. So. Yeah. Thanks, everybody, for joining, for all the questions and conversation. Yeah.
00:45:00.544 - 00:45:14.474, Speaker A: I know it's good to have more people know how to do this, but hopefully we don't have these that often either. So a little bit of a double edge here, but, yeah, I guess we can call it there. Yes. Jacob, you were doing the recording. Do you have to hit stop or let.

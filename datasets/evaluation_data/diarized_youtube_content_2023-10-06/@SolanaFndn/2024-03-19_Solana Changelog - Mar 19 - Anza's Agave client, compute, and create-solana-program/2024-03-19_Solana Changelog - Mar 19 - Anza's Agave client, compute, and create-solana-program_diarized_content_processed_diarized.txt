00:00:03.880 - 00:00:09.434, Speaker A: Welcome, everyone, to this week's Changelog. My name is Jacob, and I'm joined today by Nick. How's it going today, Nick?
00:00:09.734 - 00:00:12.914, Speaker B: It's going well. It's going well. I'm excited for another changelog, as always.
00:00:13.214 - 00:00:56.264, Speaker A: Yes. And for the first thing that we're going to talk about, we're going to talk about agave again. So this is just kind of like a quick info about agave, if you didn't see. We also talked about this last week with the Solana lab, Solana validator client repo. They've basically forked it over to the Anza team because the Anza team is the core protocol developers over at Anza building agave, and they've now have it all under the agave repo. So this is kind of just a new name, new branding, roughly the same team, same core protocol engineers. This is a different client validator client than firedancer, but it is just another validator client.
00:00:56.264 - 00:01:25.080, Speaker A: Moving on to the next topic of discussion, I wanted to talk about increasing block space on Solana. I'll lay down the groundwork so that people understand the current problem today. What we have is we have a compute cap limit of 48 million. And what that means is every time you make a transaction, whether or not it have a compute units usage of 1.4 million or 300 for a simple transfer, it counts towards this overall capacity.
00:01:25.080 - 00:01:28.562, Speaker B: And specifically, that cap is per block, for clarification.
00:01:28.698 - 00:01:59.044, Speaker A: Yes, per block. So if you have a lot of transactions, you especially, like right now, where there's a ton of transactions going on in the network, you could potentially hit the block space cap and your transactions could potentially be dropped. So there's a lot of different discussion going on about how to fix this. One of the things that Toli is mentioning here is just aggregate, aggressively increase it and see how it can handle the load. Uh, what do you think about this, Nick?
00:01:59.744 - 00:02:46.922, Speaker B: I think much like anything in life, there's always caveats. Like, you don't get the full picture of, of, like, all of the, the options that can be pursued. I think potentially increasing the block space, maybe not aggressively to the point of an outage, hopefully not. But definitely increasing block space to some extent, I think could be interesting. But I definitely think that there should be things that go on before that, like better optimization of compute usage per transaction. So, like, right now, the default that, like, if you, if you do not manually request a specific compute usage budget for a transaction, you get like, what, 250k or 1 million, you get like some really, really high amount that most transactions don't use that by default. They have tons of wasted compute unit budget.
00:02:46.922 - 00:03:26.918, Speaker B: So when all of these transactions go through and they're not using the exact or a reasonable amount for their transaction, but they're requesting a higher amount, you get all of this extra basically noise and wasted compute usage budget inside of every single block. So you just get a bunch of wasted block space. So I think if we had a better sensible default for like an average transaction or even removing the defaults, you have to like force set one, um, to have like a reasonable actual compute usage for your transaction. I think that is like a knob that should be tweaked before aggressively increasing block space. But that's kind of like my, my thoughts here.
00:03:27.086 - 00:04:01.598, Speaker A: Yeah, I completely agree. We definitely need to have better ways of requesting the right compute. And there also needs to be more information about how to optimize your compute on your specific program because people are just blindly writing code because they don't know what the after effects are. Also, as you said, we get basically free compute. If you have right now it's per instruction on a transaction without using the compute request call, you can get 200k for free of compute units per instruction on a specific transaction.
00:04:01.726 - 00:04:02.742, Speaker B: Adds up quick.
00:04:02.878 - 00:04:52.572, Speaker A: Yeah, we can increase the block space, but if nobody's actually trying to actively lower the amount of compute units, it's going to be like increasing the number of lanes on a highway with cars being free and gas being free. It's not going to help is what's going to happen. There's a lot of takes and controversial takes on that with cars being expensive. But if they're free, I think we can all agree that it's just going to get filled up without any hesitation. The same thing is that it should definitely, in my opinion, if we were increased block space, it should definitely come with a caveat of economic back pressure so that the users are made uncomfortable, forcing the developers to optimize their programs better.
00:04:52.708 - 00:04:54.260, Speaker B: Yeah, yeah, I agree with that too.
00:04:54.412 - 00:05:20.808, Speaker A: So I think this is a good thought and a good experiment of like how can we increase block space? There's probably a lot of things to go before it, but in the future, maybe this year we might see this increase, but also we will likely see everything else beforehand. On the topic of block space, I wanted to quickly jump over to one of the resources of the week.
00:05:20.976 - 00:05:22.464, Speaker B: Oh yeah, this week guide.
00:05:22.584 - 00:05:55.122, Speaker A: Yes. So if you're interested in how to use priority fees on Solana to help get you into that block space, because it's highly contentious, right now there's a guide on Solana.com developersguides exactly on how to use priority fees. And you can see here it even goes into like requesting that specific compute limit and how much to request for, like a simple transfer. So simple transfers are 300 compute. That's how much you request. So definitely check out this guide if you're interested, to learn more for commits.
00:05:55.122 - 00:05:56.474, Speaker A: What did you see this week?
00:05:56.594 - 00:06:26.634, Speaker B: Yeah, there's a couple of interesting ones from this week. There's some focused around getting the Anza clients called agave up to speed with the name change and getting all those sorts of tweaks going in. But there was this one interesting one on tiered storage, and it was actually specifically the commit message or the pr message here that talks about the cold account versus state compressed accounts, and how that idea going forward is going to be a little bit different from what we've talked about in the past. So just wanted to bring that up.
00:06:26.754 - 00:06:48.466, Speaker A: Yes, it's something about state compressed accounts for cold accounts. They're doing all this work around tiered storage. I still think this is a agave client specific implementation detail. So it's separate too. Yeah, it's not required by consensus, but it's an optimization on the validator client.
00:06:48.610 - 00:06:50.074, Speaker B: And we love optimizations.
00:06:50.194 - 00:07:07.614, Speaker A: Yes. Moving on to the other resource of the week, we have something from Loris, which is the create Solana program. Nick, I know that you've been working a lot on the create Solana dapp. Can you explain a little bit how this resource works and then how it could potentially work with create on a dapp in the future?
00:07:07.994 - 00:07:34.174, Speaker B: Oh yeah, absolutely. Yeah. So shout out to Loris from Anza like amazing Dev. He built this really interesting tool similar to the vein of create salon adapt, which we've talked about a couple of times. You have a single simple Cli that you could run using any node, Js, Npm package, pmpm, yarn, whatever. You could run this CLI tool to help you generate a program or a front end. This particular one, and you can even see my comment there on the screen.
00:07:34.174 - 00:08:26.212, Speaker B: This particular one from Loris is geared towards actually generating the rust code and the interfaces and the clients for a rust program itself. So create salon adapt great for generating a front end with the supported front end frameworks, but Loris's tool creates create Solana program does. The other side of generates a really composable stack for the rust on chain program side. In the future. We're looking at ways how we can better integrate both of these together for create slot adapt specifically, instead of us doing the current methodology that we're doing for generating the rust programs, the goal is to be able to use this, which is going to be way more flexible and maintained for the rust side of things. It'd be really interesting to combine both of these together. All these developer tooling improvements are going on the ecosystem.
00:08:26.212 - 00:08:27.448, Speaker B: It's going to be awesome.
00:08:27.636 - 00:08:50.564, Speaker A: That'd be really cool. One thing I just thought about, could this potentially make it easy to bring a bunch of compute unit optimizations to your program too, including easy ways to log pub keys, easy way to basically do the entry point while at the same time keeping the front end connections the same. Is that a possibility with this?
00:08:51.104 - 00:09:02.178, Speaker B: Yeah, I would think so. It would depend on how the rust code itself actually gets generated in output. But definitely, that's definitely something that we could look into and talk with the Anza team about. That'd be really cool.
00:09:02.346 - 00:09:11.042, Speaker A: Yeah, that would be really cool to have. Especially making it easier for people to do compute optimizations is how we're going to win long term.
00:09:11.218 - 00:09:39.920, Speaker B: Oh, yeah, absolutely. And then speaking of long term, go for it, Nick. Yeah, speaking of long term is the Solana program GitHub organization. You can see Loris and Hannah there as the people. This is a newer GitHub organization that Anza team is working on setting up. You can see the Create Solana program listed right there. Some of these very common Solana program library programs, the SPL programs that you know and love.
00:09:39.920 - 00:10:15.916, Speaker B: You've got the memo program stake program address lookup tables. So basically what's happening with this repo is a lot of the SPL programs and how they're maintained. They're currently under the Solana Labs GitHub organization, and Solana Labs has been maintaining them. But with this Solana labs Anza split, and you've got the firedancer team doing all their amazing work. There's more and more organizations that are working together to maintain all of the programs that are so common on the Solana blockchain itself. This includes a lot of the programs that are currently enshrined in the protocol itself. Those programs are being migrated to BPF programs.
00:10:15.916 - 00:10:38.654, Speaker B: So that way they're not tied with the runtime itself, with the actual validator code. They're just standard programs. Like you can see the system program right here. All of these are being moved from slowly but surely from enshrined programs that are deployed with the validator versions to just BPF programs. And this Solana program GitHub organization is going to be the home for all of these programs.
00:10:39.194 - 00:11:01.692, Speaker A: Yeah, this will be really cool, especially when they do do that move to BPF. So that fire answers had a lot of time spent trying to implement these native programs on Solana. If they're just all VPF in all one single location, we can definitely make it easier overall for new clients to implement these native programs.
00:11:01.788 - 00:11:03.388, Speaker B: Absolutely cool.
00:11:03.436 - 00:11:42.316, Speaker A: Moving on to this week's stack exchange user reputation leagues. We can see the top people here were John and Whitesell and Breeze Wang for this week. If you don't know about stack Exchange, we said this many times in the changelog. It's a place where you can help out new developers learning how to build on Solana, but only just new developers on their single question. But all future developers looking at that question or googling that question. It's so that you don't have to have people going into discord and accelerating the development lifecycle of all developers in the future. So definitely, if you're interested in helping out, please do.
00:11:42.316 - 00:11:55.540, Speaker A: And the simplest way you can help out is just upvote good questions and answers. You don't even have to answer questions, just upvote good questions and answers. And it helps us out a lot moving forward. The space on stack exchange.
00:11:55.692 - 00:12:12.356, Speaker B: Yeah, if you're like most devs, when you go to Google things on Google, trying to find some issue, some error you run into, find the solution, a lot of times you'll end up at stack exchange, just upvote the questions and the answers that you actually got good value from and did help you, and that helps the whole stack exchange ecosystem be even better.
00:12:12.540 - 00:12:18.990, Speaker A: Yes. So that's about that we have for today on the changelog. Thank you for joining us and we'll see you next week.
00:12:19.132 - 00:12:20.014, Speaker B: Bye bye.

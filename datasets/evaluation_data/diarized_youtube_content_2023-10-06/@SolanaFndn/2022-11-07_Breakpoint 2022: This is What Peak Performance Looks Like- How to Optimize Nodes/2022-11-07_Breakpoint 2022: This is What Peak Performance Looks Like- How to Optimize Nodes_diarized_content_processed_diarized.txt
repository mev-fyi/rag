00:00:09.400 - 00:00:36.174, Speaker A: All right, good to meet you guys. My name is Josh New Roth. I work for a company called Anchor. We're going to talk about node today, so I want to do a quick audience poll here. How many of you have ran a Solana node yourself? Okay, good amount. Good. And how many of you are just curious, like, how nodes run some of the challenges, maybe you don't know that much.
00:00:36.174 - 00:00:55.234, Speaker A: Awesome. Okay, great. And then I'm just curious, how many of you provide node service as, like, a commercial offering? We got a few of those guys. Awesome. Okay, great. So you can talk about optimizing nodes here and what really peak performance looks like in our experience. Let me give you a little background on anchor.
00:00:55.234 - 00:01:27.906, Speaker A: We are primarily, we're an EVM based RPC provider. Since then, we've expanded into liquid staking. We were first to market on Ethereum liquid staking, compete with lido on that. We do gaming, SDKs, a lot of developer tools. And last year we got into, and we had a lot of clients coming to us in 2021 asking us to support Solana. And so we started this journey of figuring out what it would take to build on Solana at scale and offer that to our developers. So we began to do that, but it wasn't an easy journey.
00:01:27.906 - 00:02:15.914, Speaker A: So we have an RPC for Solana. It's the fastest growing, was pretty, pretty, we had a lot of errors early on, a lot of bugs, but recently, we've grown, like 500% over the last three months because we fixed a lot of the issues that were on our RPC. And that's kind of why we got invited here to do the talk today. We do the main net, the Devnet, archival support, and we focus on geo distribution. And we're lowest latency in many emerging markets like Brazil, India, et cetera. So that's what we do. I'm going to talk a little bit about, like, Solana and what are the, what are some things we need to consider as a community here? So, as you guys all know, Solana is really probably the fastest layer one out there right now.
00:02:15.914 - 00:02:59.128, Speaker A: Current transactions per second are 3300. Now, obviously, theoretically, Solana promises 60,000 transactions per second, but right now we're hovering around 3300. So there's this kind of trade off that we get when we, as a layer one blockchain, when we do these higher transactions per second. Ultimately the node hardware needs to be better and have more resources in order to perform at that kind of level. So in many cases, you know, you look at, like, other layer ones. I, compared to here, binance smart chain started at 20 transactions per second. They forked Ethereum.
00:02:59.128 - 00:03:49.478, Speaker A: Now it's grown to 200, give or take. It goes up and down a little bit. Ethereum is limited at 25. But these chains need a lot, those other chains need a lot less on the node infrastructure in order to run that. So as a community, we basically have a trade off here by having that higher transactions per second. We need a lot more resources on our servers in order to support that kind of high transactions per second. So there's this whole debate that many of you are aware about right now over, like, how much decentralization do we need? Should we have? But ultimately, there's some challenges that kind of come into this play, because if the nodes are harder to run, they use more resources, they get a little bit more, less people are going to run them effectively.
00:03:49.478 - 00:04:32.094, Speaker A: So, like Ethereum, you can run from a raspberry PI basically, right? You'll never run a Solana node on a raspberry PI. Many of you guys know here. So talking a little bit about that. So generally, Solana hardware needs about seven times the hardware that, like other EVM chains need, which introduces a lot of complexity. So last year, as Solana started booming, all the DeFi, the NFT summer, all of these kind of movements started really putting a lot of traffic in a load. And I think a lot of you remember the RPC issues that we saw as a space last summer, in 2021, I mean, like a year ago last summer. And since then, it's gotten better.
00:04:32.094 - 00:05:42.072, Speaker A: But there's a couple reasons it's gotten better. It's by no means perfect. So the first thing is that the Solana server program was really a game changer for this community. So I want to talk a little bit about that and recognize them because it was helpful for us and was helpful for other RPC providers. So effectively, because of the pandemic, there was a huge chip shortage, which still is in somewhat in effect right now, but it was very, you know, 2021. It was really, really bad. If you were trying to get a server that met Solana's specifications, you were looking at like a six to eight month lead time minimum, right? So what the Solana foundation did is they went out and they worked with all these different data center providers to make servers readily available to this community, right? So they went out, they signed long term contracts, they worked on getting the right specifications, and then they made those available on a month to month basis to RPC providers like ourselves or individual developers, right? So I think that this single handedly really changed the game, not just for Solana, but for many other different chains.
00:05:42.072 - 00:06:34.338, Speaker A: Because up until this point, a lot of the data center providers out there, even the cloud providers, were really, really skeptical of web3 use cases because miners for a long time had really abused server providers. Recently, you probably heard about, I mean, this happened a couple days ago. The whole situation with Hetzner banning the validators, which they have long talked about doing, just not that many of us are paying attention to it, but that's really because they got abused from the Chia protocol on their disks. Right. And so a lot of these providers were these bare metal server providers. These data center providers were very, very skeptical of working with any web3 companies. But this program really made them pay attention to the size of the market for us.
00:06:34.338 - 00:07:00.994, Speaker A: Right. What I started seeing kind of after this program was launched, after Solana started getting these servers for this community, is all these other providers started coming into the market and building specific web3 teams to address Solana and other chains as well. So it's really, really amazing opportunity. These are just some of the logos. I've talked to all these providers. We personally work with latitude a lot. They're great.
00:07:00.994 - 00:07:37.274, Speaker A: Zen layer's VP told me that web3 is the fastest growing for them. Same with vulture. OVh now has a web3 team. They're all trying to figure out how to support the needs of our ecosystem, which has been really amazing that they're giving that kind of focus. So let's talk a little bit about the hardware, and then I'm going to talk about optimizing software here in a bit. So if you're not familiar with these components, this is like a standard server. The Solana official documentation.
00:07:37.274 - 00:08:11.978, Speaker A: You can see the official docs here. 16 core, 256 gigs of ram, NVMe one gig network. Pretty common for a server, but that was really based on like 18 months ago. And since then, the needs of the hardware to really optimize your node have increased dramatically, I'd say. And so now we're looking at an even bigger set of requirements. So I'm gonna talk through these here and give you guys advice, especially if you're trying to run a node, maybe work with an RPC provider. These are all things that you need to know.
00:08:11.978 - 00:08:50.310, Speaker A: So generally, like on the cpu, we see intel and AMD are usually the most common options. We tested intel early on. It does have the performance, it does work, but we saw dramatically better performance with the AMD third gen cpu's. And it's not saying that intel can't be better than that. But for the kind of the cost performance trade off, usually in our experience, AMD was really the way to go. The other thing is too, the clock speed is very, very important. So I would not run Solana on anything less than like 2.8
00:08:50.310 - 00:09:11.532, Speaker A: GHz. That's really like a bare minimum. It needs to really be more like like four, to be honest. But you can run it at 2.8 and then the multi core is very important. So if you're familiar with other chains, like EVM chains, they run mostly on like single threaded. But Solana does benefit from like the multiple cores of multi threading.
00:09:11.532 - 00:10:14.972, Speaker A: And then with the Ram we started out at 256. You might be able to still boot a node at 256 gigs of ram, but if you're doing any kind of high traffic, you're going to need up to 1 tb, right? So 512 is kind of the new minimum, you know, and that's going to keep growing over time. So all these tests are done at 650 requests per second over not just one client IP, but, but hundreds, right? So that's kind of what it looks like for an RPC provider. Or if you're building your own node to support this network, and then, and then on the disk you absolutely need nvme storage, you need at least two drives, you could maybe get away with one. We use four in raid zero. I'll talk in a second about why that's important. But the actual network stats, I just pulled these off our monitoring portal, receiving 200 megabits per second, sending up to 300 megabits per second within that one gigabit per second recommendation there.
00:10:14.972 - 00:11:17.404, Speaker A: If you look at these requirements, the average person is really not going to be able to run one of these nodes in their home. And that's what we see in other chains. Right? The decentralization you could run, I wouldn't recommend it, but you could run an ethereum validator from your house. I know some people that do, I don't personally do that, but you really need to be running these kind of requirements in a professional data center or some cloud provider. What we need to think about as a community is like, what things do we need to do to improve the decentralization? So if people are not able to run these in their homes, how can we work with managed service providers, data center providers, cloud providers, to really improve that decentralization, to get more nodes on more networks in more places? All right, so to kind of go into the network side where you host your Solana node matters a lot. In fact, a very lot. And there's a couple reasons for this.
00:11:17.404 - 00:12:21.234, Speaker A: So, as you guys know, blockchain is peer to peer technology. So the nodes, both the validators and the RPC nodes are all talking to each other in the peer to peer protocol. And so because as I mentioned here, you need that one gigabit per second kind of connectivity between to the network that starts mattering a lot when you're, when you're using your node. All right? So if you think about it, a node that you operate needs to talk to a node that someone else operates through that system, and that receiving and sending of the bandwidth starts to factor into that. So what ends up happening here in the BGP, in the, the layer three Internet services, is if you're next to a cluster of other Solana nodes, you get benefit. You get a lot of benefit from that. But if you're in kind of one of these edge markets, it's going to be really hard for you to stay at block height and for your node to perform, which in my personal view, is a huge issue for our community.
00:12:21.234 - 00:12:47.024, Speaker A: Right? So here are some of the best locations. Us east, we have like Virginia, Ashburn, Virginia. It's like the, the headquarters of the cloud. You got aws there, you got Google cloud, all the others, right? New York, Atlanta, all locations where nodes perform on Solana really, really well. West coast is reasonable. Solana does a lot with Google Cloud. Google Cloud has a lot of regions over there, too.
00:12:47.024 - 00:13:52.170, Speaker A: Singapore, reasonable. Europe, reasonable. But as we start thinking about bringing Solana to India, to South America, even to Southeast Asia outside Singapore, it becomes very, very difficult to keep a node at block height. We are constantly trying to optimize the network between our nodes in those locations. But what we really need to do is just get more people running Solana nodes in those locations, which will ultimately improve the performance of the network and the distribution of network, it will help your node out, too, but it will also help us just as a general community for that decentralization and that distribution. So one of the things that my customers ask me all the time, and you guys probably have the same question, is, why is Solana more expensive than, say, ethereum or some other network? So here are some of the challenges we face as a node provider in this space. There's such little documentation on best practices.
00:13:52.170 - 00:14:25.230, Speaker A: We've been lucky to kind of share information and forums like this with other providers, like Triton one and others. But most of what has been learned, I think from my understanding, is just in, like tribal knowledge. It's trial and error that people have done. It's not documented on the discord or the official documentation. So what we can do is we can start documenting this stuff on the community space, is to do better and to share knowledge. Also, the hardware keeps increasing. Like I said, best practices, server specs.
00:14:25.230 - 00:14:57.226, Speaker A: I think we don't have a lot of information on that. There's also issues. Solana for its archive data, for its historical data, the Solana foundation uses Google Bigtable, which is great, but there's some issues with connecting to that. We fix this, I'm going to provide you to a link to a pull request where you can get our code to do that. It's very simple. Every time Solana has had outages, as we've all been aware, that comes back to the node providers. We have to recover those nodes very quickly, which is hard.
00:14:57.226 - 00:15:41.844, Speaker A: And sometimes, in some instances, our data, our historical data has blocks missing when that happens, and we have to go and manually backfill those. As I already talked to you about the geo distribution, the geo distribution of peering issues comes in, and that plays a fact. And then the updates are frequent, which is awesome. Love that. We have a lot of updates, but we have to stagger them because the nodes take a long time to restart, so it uses more DevOps resources. So for all those reasons, Solanza, we have to end up passing that cost off to our customers in order to at least break even or make money on a chain like Solana. I want to talk a little bit about the cost of supporting archive data, the rough cost.
00:15:41.844 - 00:16:33.234, Speaker A: So to run a bigtable instance with any kind of meaningful traffic volume, it's really going to cost you about $8,000 per month that you're going to be paying to Google Cloud to do that, just in comparison to other chains. With Ethereum, go Ethereum under $1,000, you could run a server that has every block indexed right there. With Aragon, less than $250. Something you might not know if you're not in the EVM space, is that there's multiple node clients for Ethereum, and some perform better, others for different things. So Aragon is like a rising star in the community and does really, really well with handling that archive data. So I think there's more solutions we could do as a community in this space. Now to talk about some of the principles of optimal performance on the software side, we've already covered network and hardware.
00:16:33.234 - 00:17:12.064, Speaker A: Solana tends to be, from the node perspective, generally stable. But what ends up happening is because of the speed of the chain if you're trying to bring nodes to block height, they really can't be receiving traffic while doing so. So it's very difficult. It's very hard to bring a node all the way to block height so it's usable while it's also serving any kind of traffic. Of course it could. There's many types of requests that can be still served while not at block height, but you need to turn off traffic when that node is recovering. And so this can be done with a very simple script.
00:17:12.064 - 00:17:59.566, Speaker A: If the node isn't at block height, stop sending traffic to it, let it recover, test the block height again, and then resume sending traffic. That is what you're going to need to do to really serve traffic. And then, as I spoke to you earlier about having four NVMe disks in raid zero, if you can have a bigger drive on your node, you will definitely not need to make as many archive recalls, those kind of expensive archive recalls to Google Bigtable, which helps out a lot. So a general rule is 1 million slots, 750gb of disk space. So we personally, on our local nodes, use like six or seven terabytes of data just on our Solana nodes. So we don't have to always be going to the archive nodes or the archive service to, you know, to do that. So I want to have a few minutes for Q and A.
00:17:59.566 - 00:18:49.318, Speaker A: So where do we go from here? How do we get better as a community at supporting our nodes? And I think, you know, a lot of these principles still apply to the validator community, not just the RPC community, because, you know, we get better node clients, we get better performance, especially on the hardware side, that does impact our validators, too. One of the things, or one of the concepts that has been really, really valuable in the Aragon node client is the RPC daemon, or Daemon is run separately from all the peer to peer processes. And we've seen really good performance off that. I don't think that's implemented in the Solana node client, as far as I can see, but we think it would really help if we could get there as a node client. So that's my recommendation to the Solana team to do that. And we also need to start seeing alternatives to bigtable. So right now, if you want archive data, the only option is to use bigtable.
00:18:49.318 - 00:19:43.854, Speaker A: I actually love bigtable, but it's using 80 terabytes, which is costing us eight grand a month. And we'd love to be able to run that locally without having to query bigtable. And so I think getting the support from the Solana foundation on both those things would be very helpful to node providers, very helpful to our community. And then think about it. One of the things we've been working on with other chains, specifically with binance chain and a few others, polygon avalanche, is this whole concept of side chains. So, you know, as we continually scale Solana, we're already really at the hardware limits at 3300 transactions per second. So as we grow as a community, as more people come into the ecosystem that is only going to go higher, how do we keep scaling with that effectively, we might want to start thinking about, you know, offloading some of that traffic to a Solana side chain.
00:19:43.854 - 00:20:35.384, Speaker A: That's just a recommendation, I think future focus, like for the future Solana roadmap, that we might start wanting to look like as a community. Okay, so one of the things, if you run a node and you can't, if your connection to bigtable drops, you can go to the GitHub for Solana Labs, go to pull request 26217, and we have a fix. It's just a simple one line code fix that will help you. It has not been merged yet into the official repo, but you guys can use that if you want to get better performance on that archive service. So that's what I wanted to talk to you about. We're excited to keep supporting developers in the Solano ecosystem and beyond, but I'd love to leave it up for Q and a. If anyone has any questions about the RPC service around performance, please come up and ask a question.
00:20:35.384 - 00:20:43.074, Speaker A: I think you have to go to the mic.
00:20:48.534 - 00:21:02.722, Speaker B: Hey, thanks for all the insight. So do you guys publish performance data of your nodes like a graph over time? How many slots you're behind or ahead of the rest of the chain?
00:21:02.838 - 00:21:17.922, Speaker A: We have it internally. We're working on an external tool that's going to make it. It's an open source monitoring service for nodes that we're going to publish to the community. So it's not available yet, but we do collect that internally. So, you know, it is a hard chain to keep up with, but it's.
00:21:17.938 - 00:21:31.682, Speaker B: Just, we've been trying, you know, all the guys out there, quick node, alchemy, Genesis go, and it's kind of crazy. They're always running behind, and then our apps are like flip flopping, old state, new state and stuff like that, right?
00:21:31.738 - 00:21:44.970, Speaker A: Yeah, yeah. Like I said, there's a lot of issues that as node providers we're all dealing with. So I think the recommendations here can help us get better as a community. But yeah, we can absolutely publish that and we have a tool to do so.
00:21:45.042 - 00:21:45.898, Speaker B: That'd be awesome.
00:21:46.026 - 00:21:46.734, Speaker A: Awesome.
00:21:49.194 - 00:22:01.484, Speaker C: How do you measure the latency of your RPC nodes and how do you publish, like how behind are you in processing those blocks through the RPC call?
00:22:02.144 - 00:22:04.328, Speaker A: Sorry, really hard to hear you.
00:22:04.416 - 00:22:09.824, Speaker C: Okay. How do you measure the latency of your RPC service?
00:22:09.904 - 00:23:00.460, Speaker A: Yeah, yeah. So we do measure our latency of our RPC service. What we do is we do a combination of different calls, both like stuff that regular node and the archive service will do. And we use little monitoring networks for, from Google Cloud, we have little scripts running in Digitalocean AWS. And then we just look at the latency across all of our user and client data as well. And we have a formula for pulling that together to show it. So keep in mind that when you look at a Solana latency RPC that is testing the latency from a point a, which might be if you're running, I don't know, you really want some neutral data on that because it would be very easy to skew that data if the RPC provider is running the test in their own data center or something like that.
00:23:00.460 - 00:23:05.584, Speaker A: So you really need some beyond one point to test the latency.
00:23:06.524 - 00:23:21.204, Speaker C: Thank you for that clarification. I do have a follow up question. From the moment a block was produced and the moment that blocked block was usable by an RPC server, how do you measure that latency?
00:23:21.544 - 00:23:40.564, Speaker A: Yeah, we have a tool for doing that, but we also have an enterprise service that we do where we have a special focus on exactly that, on making sure the accurate data is relevant to those users and most up to date. Yeah. Okay, one more question. I think I'm gonna get chased off the stage.
00:23:40.864 - 00:24:12.608, Speaker D: Yeah, thanks first a lot for the, this presentation, and I really appreciate that you were emphasizing the problem of decentralization. And I would like to have like a sense of the future that you can imagine. For example, you were like saying that we can use side chains like afterwards, but could it be like possible in the future to like if there is like a problem of decentralization, that to lower down like the requirement for like running a road, a node so that I can route, I can run a node at home, for example, is that possible to imagine or not?
00:24:12.736 - 00:24:50.944, Speaker A: It would require. So the question is, what is the future of a potential side chain? So one of the things we've been working on with Polygon is the supernets avalanche with the subnets and then binance application side chains, which we were the majority contributed to. So really what the concept of side chains is, is we might say NFTs are going to be broken off into their own side chain. Gaming traffic broken off into its own side chain. And then those side chains will have a set of hardware that can run those. So what we would want to look at is can we bring down the hardware requirements on the side chains? And that would really help us with that decentralized effort.
00:24:51.404 - 00:24:53.268, Speaker D: And on the main chain, is that possible?
00:24:53.436 - 00:24:54.012, Speaker A: I'm sorry.
00:24:54.068 - 00:24:55.864, Speaker D: On the main chain, like on.
00:24:56.444 - 00:25:04.934, Speaker A: It's going to be hard, I think, you know, a lot of re architecture, but probably not for the foreseeable future. All right, thank you all so much. Enjoy the conference.

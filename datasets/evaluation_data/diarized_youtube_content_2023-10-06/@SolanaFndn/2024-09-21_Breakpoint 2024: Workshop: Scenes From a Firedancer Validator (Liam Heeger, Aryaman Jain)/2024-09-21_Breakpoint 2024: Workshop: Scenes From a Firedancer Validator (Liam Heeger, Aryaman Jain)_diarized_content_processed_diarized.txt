00:00:03.840 - 00:00:29.695, Speaker A: Hello, everyone. I'm Liam Heger. I'm a blockchain engineer working at Fire Dancer. Today I'm joined by Aryaman Jain, another engineer working on the team. This is the Fire Dancer team's last Talk of Breakpoint 2024. You've hopefully had your fill of talks from us, but now it's time for the dessert. For our last presentation, we'll be showing off the full Fire Dancer client.
00:00:29.695 - 00:01:31.155, Speaker A: But before we get into that, we're excited to announce again that the full Fire Dancer validator client is live on testnet. That is to say, this is the full Firedancer client. Written purely in C, contains no Rust code, and by extension shares no code with Agave. Firedancer node is staked actively participating, consensus and producing blocks. We'll get into the specifics of how we got to this point, but first let's touch on what Fire has been up to on testnet just the last few months. We've gone from not operating on testnet at all to building tens of thousands of blocks and voting on over 10 million blocks, all the while growing to 1% of stakeholders. Continuous uptime has gone from a few minutes to several days, and similarly, runtime discrepancies between Fire Dancer and Agave used to appear once a day and now appear less than once a week.
00:01:31.155 - 00:02:04.155, Speaker A: All this has come together in just the last 12 weeks. Over the last two years, though, we have built dozens of components into fire, from networking to runtime. We've been extremely busy engineering, integrating and testing all these pieces. It would not have been possible to get where we are today without the village of engineers, staff and external partners working on Firedancer. But enough of that. The goal of this talk is to show you that we indeed have a functional Validator client and that it performs well on testnet. So let's get into that.
00:02:04.155 - 00:02:46.305, Speaker A: There are two acts to today's presentation. The first act will show you proof that Fire Answer is behaving as a good validator client on testnet. To be a good validator, the node must be able to vote on blocks in a particular manner and produce blocks when it is the leader. We also stipulated that having a usable RPC interface is crucial to the function of Validator, as that service fulfills many functions for operators. The second act will show off Fire Dancer's performance in two different environments. First, we'll show off a few interesting blocks that Fire builds on testnet. Second demonstration will show what Fire is capable of when pushed to the max.
00:02:46.305 - 00:03:27.635, Speaker A: Those experiments are run on a globally distributed cluster composed exclusively of firedancer nodes. So without further ado, let's look at how our validator is performing on testnet. This site may be familiar to a lot of you. This is validators app by BlockLogic has a plethora of useful information about Solana Validator set. This information is useful to both operators and stakers alike for determining the effectiveness of any given validator. Here you can see our testnet Validators page and just a note, there will be QR codes throughout the presentation linked to many of these things we're looking at here. Don't worry if you miss any of them and there will be a final QR code at the end with everything in it.
00:03:27.635 - 00:04:04.417, Speaker A: If you scroll down on our page there are four charts for our validator. Each of these charts describes an important metric for all validators on the Solanov network. Two rows of charts match up to the two measures that define an effective validator. Let's look at that first row. Here we see two metrics, root distance and vote distance. You can think of these metrics as both as slightly different measures of how far behind the latest block we are. Effective validators have a lower route and vote distance and are therefore closest to the tip of the chain.
00:04:04.417 - 00:04:45.387, Speaker A: They also vote for as many blocks as possible. Not only does this ensure the validator is contributing in a healthy manner to consensus, but it also means that they are voting at the necessary cadence to earn as much of the voting awards as possible and at a sanity check. Here are those same statistics up against several of our peers on testnet. The hypothesis is that if we are ineffective at participating in consensus, we should have metrics at least on par with or better than our peers. So there we are. Towards the bottom of the list and above and below the Fire Dancer validator are healthy agave nodes. I'll leave the final judgment up to you on how similar they look.
00:04:45.387 - 00:05:21.685, Speaker A: I'll give you a second, but to me they look pretty similar. So let's look at the second row of metrics. The bottom graphs tell us how the fire denser validate is performing when it is the block producer. The left graph measures the percentage of our nodes missed opportunities to produce a block during our leader slot. The right graph is similar, but it shows the rate at which the leader after S was skipped. The top line in both graphs is the cluster average skip rate. Missing many blocks or being the cause for someone else to miss their blocks leads to less block space availability for the whole cluster.
00:05:21.685 - 00:06:08.555, Speaker A: It also can result in reduced profitability for the validator or other cluster participants. For those reasons, it's also good for these numbers to be as low as possible. And again, I'll give you a second to look at this, but if you look at some of our peers, you can see we're pretty much in line with their current skip rates. Okay? And so you can see we're doing pretty well. So there's one last metric we actually have to look at here, and this is vote latency. Vote latency is the number of slots between when a validator has generated a vote transaction and the slot that it's actually included in. In a block validator that's voting late is not keeping up with consensus.
00:06:08.555 - 00:06:53.257, Speaker A: This results in their votes being less valuable for resolving forks and finalizing blocks in a timely manner. And again, for this metric, latencies closer to one are always better. Last, on the critical items for validators at rpc, here's a video of the Solana Explorer connected to the RPC service within our Fire Answer validator. Normally the site is connected to the public RPC endpoint where we've redirected it to our node to demonstrate its capabilities. You can see that we're populating all the information that's pretty interesting to most people, from cluster statistics to block and transaction information. Just for fun, we also tried Solana fm, another Solana Explorer. You may have noticed some missing information on both sides.
00:06:53.257 - 00:07:31.139, Speaker A: This is because the RPC service is not perfect yet. We're still working on RPC support and only recently started really putting it through its basis. So based on these three markers of a good validator, you can see we've done a pretty good job so far on all of them participating in consensus and block production in an effective manner. And we serve data for the node that is useful for end users. Now let's dive into those performance demonstrations. Up first are three demonstrations of large blocks Fire built on testnet. All three of these blocks were built by sending transactions to a specific type of a specific type to Fire's transaction ingest service.
00:07:31.139 - 00:08:20.685, Speaker A: While we are the leader, the purpose of this test is to demonstrate Firedancer can perform well while running on an existing protocol and on existing clusters with majority Agave and Frankendancer nodes. I'll show you both transactions per second and compute units consumed per second for these blocks. Quick refresher Compute units are a resource that transactions request and are consumed whenever a transaction does something. Salon block producers have limits on the size of blocks they can produce. For example, the maximum number of compute units the block can consume. Is capped at 48 million or about 12820 million per second. So with our transaction generation script, Fire built this first block a few weeks ago with just under 36,000 transactions.
00:08:20.685 - 00:09:01.165, Speaker A: Almost entirely composed of what we are calling basic transactions. These transactions don't really do anything beyond request the minimum compute units, set a price for the transaction and pay the fee to the block producer. Despite not doing anything, these transactions still consume some number of compute units. This is because these transactions still invoke the compute budget program twice. This block summary page only shows the compute units consumed by smart contracts, not the total for the transaction. So let's look at one of the transaction detail pages. As you can see, the transaction consumed 300 compute units, 150 for each GIPU budget instruction.
00:09:01.165 - 00:09:41.899, Speaker A: We can get the transactions per second of this block by taking the total number of transactions and multiplying by 2.5. This is because blocks on Solana, as you guys may know, are 400 milliseconds. This brings us to just under 90,000 transactions per second for a block containing mostly basic transactions. Same mostly as we're still actually including many vote transactions and other transactions that users have sent us. Next we try the same tactic with the token program. The token program is used everywhere on Solana where tokens involved. It is also token accounts themselves also account for most program drive accounts on mainnet.
00:09:41.899 - 00:10:22.805, Speaker A: In this test we did transfers performing the same calculation. For this block of token transfers we get just under 19,000 transactions per second. Take note of how many compute units were consumed. Just under 4400 compute units. Lastly, generate a block full of nanotoken program transfers. Nanotoken is an experimental, highly optimized variant of the token program written in Rust. It's been developed by Kevin over at Temporal and there will be a link to his GitHub repository at the end of the presentation.
00:10:22.805 - 00:11:12.573, Speaker A: So if we run the numbers again, you can see this blocked in an effective TPS of 54,000 transactions per second. And each of these nanotoken transfers only consumed 48 compute units. Recall, token program transfers took over 4,000 compute units, whereas nanotoken consumes just 48. It's a massive reduction in the number of compute units consumed for what is effectively the exact same behavior. Now pair that up with the fact that token program is the most invoked program on mainnet and hopefully you can see for yourself the amount of transaction throughput that is being left on the table. Here are the final numbers from those experiments. Please note these are individual samples and are not continuous block reduction Rates possible on testnet.
00:11:12.573 - 00:11:51.025, Speaker A: They're single blocks built at one point in time. So you look at the results, something strange does show up here. We'd expect that compute units per second scales directly with transactions per second. Oddly, this doesn't seem to be the case. This is largely due to Solana's cost model overvalued computer and underweighting the cost of increased account access. Lastly, testnet is a very adversarial environment for validators trying to make large blocks like this. The cluster is actually larger than mainnet and has many less capable nodes, more delinquent state and high skip rates.
00:11:51.025 - 00:12:41.215, Speaker A: It's a hard place to pull off an experiment like this as we not only had to make Fire Dancer perform well on testnet, but also pull our punches to work within the constraints of weaker Agave and Frankendancer nodes. In that sense, this is also a test of Agave and Franken Dancer on Tesla. Okay, now onto the final performance demonstration. This last demo is conducted on a globally distributed test cluster composed solely of Fire Dancer nodes. Before I hand it off to Arman to do the demonstration, I want to spend a moment discussing the test cluster. Clusters composed of 12 servers located in New York, London, Frankfurt and Singapore. Each machine has a dual socket Intel Xeon with a total of 80 cores and 512 gigabytes of RAM.
00:12:41.215 - 00:13:19.613, Speaker A: For realism, these nodes are placed in similar metropolitan areas to the rest of the Solana validator set. Machines are networked with a dedicated optical fiber network on a jump global network. This gives this cluster unique characteristics that are not seen on the public Internet. To illustrate some of that, let's look at some of the metrics of this network. Here I'm running a set of tests from one node of the cluster to the other. This first test is a bandwidth test and the latter test is a P test. The results we get contain a lot of information, but only two metrics concern us today.
00:13:19.613 - 00:14:00.115, Speaker A: Jitter and paint time. The jitter of a link is simply the mean difference between packet arrival times and their expected arrival times. Put another way, jitter is the measure of how unpredictable the time of packet's arrival is. Ping time or round trip time is the time it takes a packet to go from one machine to another and then back again. Bing time is analogous to distance traveled on the Internet. Low jitter connectivity is essential for distributed applications like Solana, as any jitter that is introduced to the network induces more latency. So here are those Bing times we measured that are laid out on the map.
00:14:00.115 - 00:14:39.935, Speaker A: You can see the interim metropolitan area round trip times around three orders of magnitude smaller than the intercontinental ping times. The jitter measurements are another three orders magnitude smaller than those intra metro peak times. To illustrate the magic of this difference, let's zoom in on the map. The variance in packet arrival times on these links is less than 1 microsecond to 4 microseconds. In 1 microsecond, light can travel 200 meters. What you're seeing here is the venue we're in. 200 meters is roughly a distance from here to the center of Suntec.
00:14:39.935 - 00:15:14.385, Speaker A: But let's zoom out and once more. In comparison to the JUMP mobile network, the jitter between my laptop and a server in France was on the order of 660 microseconds. And that time light travels 120 kilometers. And let's zoom out one more time, one last time. Compared to the total distance light has to travel over the Internet from one continent to another, it's incredibly small variance. Dare I say, negligible. Alright, with all that out of the way, I'll hand it off to Ariman to present this last demo.
00:15:17.765 - 00:16:00.395, Speaker B: Thank you, Liam. Before I dive into the details of the demos, let me quickly go over the setup. We will be running 10 validators and two transaction generators. The cluster is set up such that there is one leader in London and nine followers across the globe. This is done largely to be consistent with the configuration that Frank and Dancer showed off in the previous talk. The transaction generators are set up to create transactions whose account accesses maximize parallelism as much as possible to push the runtime to its limits. The validators have been parameterized to have maximum block level compute limits 50 times larger than Solana mainnet.
00:16:00.395 - 00:16:46.973, Speaker B: We have disabled the transaction cache and at the transaction rates we will show our machines cannot meet the memory requirements to retain that number of transactions. The network has 5 gigabits per second of bandwidth between nodes and is thus unburdened by large transaction loads. This is not the largest demo setup we have ever constructed. In the past we have set up 100 node clusters with 100Gbps links for the wide area network and 25Gbps to each host for all of the demonstrations. The followers are configured identically, each with 32 CPU cores assigned to the runtime. The leader was configured similarly, except the cores allocated to the runtime are variable depending on the demo scenario. We will be showing you four scenarios today.
00:16:46.973 - 00:17:27.805, Speaker B: A small note, the demos are pre recorded and not live. This is not for a lack of wanting to show you live Demos rather, doing them live is complex and time consuming and it would involve a fair amount of waiting around on your part. The first demo will show us handling 1 million transactions per second of basic transactions. These basic transactions are identical to the type Liam described for the first test net block. Okay, let's start with the first demo. Here we will show you the leader coming up and starting to keep up with 1 million transactions per second. On the left is the leader node, having just started from Genesis.
00:17:27.805 - 00:18:15.185, Speaker B: Right now it is only processing one transaction per slot. I also start up our RPC service so we can start receiving transactions from the transaction generators. Next, I am going to start up this handy script which will show us the TPS numbers averaged over the last five seconds. When it starts up, it shows us two transactions per second as expected. Finally, I will be starting up the simple transaction generation scripts on the right which will generate over 5,000 transactions per second of traffic per node, which is why we have two and send it to the leader. They start up by creating and funding accounts and then start sending basic transactions. We will slowly see the TPS numbers go up in the middle pane as the initial transactions start going through.
00:18:15.185 - 00:18:50.471, Speaker B: As promised, the generators are producing over 1 million transactions per second combined. You can see this on the right. We will wait a little bit and the numbers are already up to over 900,000 transactions per second. As you can see in the middle pane. We will let this run for a few more seconds for everything to start running at capacity. If you can bear with me for a second There, we have 1 million transactions per second being produced by the leader node. You can see that in the middle pane onto the full cluster setup.
00:18:50.471 - 00:19:31.385, Speaker B: Now we have the leader node on the left and the nine followers in the grid on the right handily synced up. You will see the leader running and the followers connected and keeping up. We do all the same setup here as we did for the leader. We now start up our scripts to measure the transactions per second on the leader and the followers off screen. The transaction generators have already started and the transactions start landing slowly. You will see that from the measurements going up on all the panes. An important thing to note is since the leader and followers are not synced up here, there is a slight difference in when the scripts print the metrics, but by and large the numbers are the same.
00:19:31.385 - 00:20:04.275, Speaker B: It takes a few seconds for us to hit the desired numbers. As the Fire Dancer clients need to warm up and the traffic starts to reach all the nodes, you will see that the numbers have Increased in all the panes and in sync. We will wait just a few more seconds. Bear with me once more and there we have 1 million transactions per second being produced by the leader and being handled by all of the followers. And that was our first demo. Here's a zoom in on the numbers from the leader. You can see the 1 million transactions per second being produced.
00:20:04.275 - 00:20:49.785, Speaker B: Handling this many basic transactions is critical to establishing the maximum capacity of fire dancer. The second demo shows fire dancer handling over 1 billion compute units per second using the Memo program. The Memo program is a simple Solana program that like token program consumes several thousand compute units right onto the demo itself. The setup remains the same and you will see our script is started up again but with a little twist on the leader. We measured compute units per second, a good measure to show the amount of compute activity happening. The followers continue to show the dps, but this is not meant to be a showcase for that and is not optimized for it. On the left you will see the compute units per second climb up to over 1.2
00:20:49.785 - 00:21:04.977, Speaker B: billion per second. You'll also see that the followers keep up with the leader as the slot numbers continue to increase in log step. And that is our second demo. 1.2 billion compute units per second. Here is a close up of the.
00:21:05.001 - 00:21:06.169, Speaker A: Measurements from the leader.
00:21:06.337 - 00:21:51.705, Speaker B: Compute unit throughput is one of the primary limiting factors for Solana. Based on the existing protocol limits, this is almost 10 times the amount of compute activity possible on Solana mainnet. The third demo shows an interesting metric which is 3.5 gigabits per second of block space when handling no OP programs with fixed size payloads. No OP program is an SBPF program that does nothing excepting arbitrary data in the transaction on our now familiar setup. I would like to draw your attention to the block space per second metric shown in all the panes. As the generators start, the numbers start going up and you will see them increasing right about now in all of the panes and they go up to over 3.5
00:21:51.705 - 00:22:40.145, Speaker B: gigabits per second. The followers and leader keep up and remain in sync while handling all of that traffic. Here are the highlighted block space rates on one of the followers. Block space throughput is critical for data availability solutions on chain proof systems and for handling large transaction payloads such as NFT Mint events. Fire Dancer provides an excess of this block space bandwidth which is necessary for both bursty high demand events today as well as for the future growth of the chain. Finally, we will be demonstrating Firedancer validators handling over 500,000 transactions per second of Solana virtual machine executions. Using the aforementioned nanotoken program, we once again have our trusted setup of validators running with the generator starting up.
00:22:40.145 - 00:23:30.843, Speaker B: Notice that with the Nano Token setup we see one additional transaction landing during the setup phase, giving us three transactions per second. As the generators reach maximum capacity, we see the TPS numbers climb up and you will see them approaching 500,000 transactions per second both on the leader and the followers. We let it run for a couple of seconds to show that all the transactions are being handled at that rate. Zooming in on the lead validator shows the 500,000 transactions per second of Solana virtual machine executions. In an earlier slide we showed packing a block on testnet at around 50,000 transactions per second with nano token transactions. And here we see a 10 times increase on this Fire Dancer cluster. Based on these demos, you can see that we have done a good job of optimizing and tuning the performance of the Fire Dancer client.
00:23:30.843 - 00:23:39.735, Speaker B: This is not to say however, that there is no more room for improvement. We are hard at work optimizing even more. I will hand the stage back over to Liam now for some concluding remarks.
00:23:42.675 - 00:24:25.667, Speaker A: Thank you Ariman. You've now seen the first glimpses of what Firedancer has to offer. We showed you that the Fire Validator is a parity of the Solana protocol, executing blocks, voting on them and even producing its own blocks. We also showed what the Full Fire Desk client that the full Firedancer client can perform both on testnet and at scale in a cluster. Before we finish up, I want to thank the wonderful people at BlockLogic, Solana FM, Solana Labs and KB for their tools and programs. We showed today this presentation and for that matter, Fire Answer would not be possible without the community of builders on Solana. What's next for Firedancer? Well, we still have a lot of work ahead of us.
00:24:25.667 - 00:24:54.709, Speaker A: Firedancer is not ready for general use of production and still needs many more features, optimizations, audits, etc. Before we ready. That being said, we do have one last surprise before we head off the stage. Here's a list of nodes currently participating in Gossip on Solana. Mainnet seems to be one node that has this weird version number attached to it. That is the full Fire Dancer client. Yes, you heard that right.
00:24:54.709 - 00:25:38.301, Speaker A: The Full Fire client is live on mainnet. It is in a non voting mode, but it is doing everything that the testnet validator that you just saw also does. So we've been running in this mode on and off in mainnet for almost two months with and without that special version number. Here's a video of that mainnet node running in the terminal window. Note this is just a node passively participating in the network. It is not voting or producing blocks, just listening on Turbine and replaying blocks in real time. And lastly, here's the Explorer running against the Fire Dancer mainnet nodes.
00:25:38.301 - 00:26:01.075, Speaker A: RPC Service It's a pre alpha version of Fire. It's largely unaudited and in many places the code needs a lot of refinement. So a long journey ahead of us to get it into production for testing and hardening to operate a quality of life improvements. So that's all from us. This Breakpoint sites and tools we referred to in this presentation are available at the QR code on the screen. Stay tuned for more from us next year.

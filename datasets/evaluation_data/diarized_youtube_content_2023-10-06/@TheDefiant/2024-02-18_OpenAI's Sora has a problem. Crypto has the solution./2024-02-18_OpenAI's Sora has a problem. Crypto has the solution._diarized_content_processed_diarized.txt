00:00:00.330 - 00:00:35.240, Speaker A: So OpenAI yesterday, Thursday, February 15, unveiled Sora. Here it is on the screen. Sora. It's kind of like Titbt. It's a generative AI model that can create video from text. So you give it a description or even a still image, and Sora can create a 62nd movie like scene with multiple characters, different types of motion and backgrounds. It's pretty amazing.
00:00:35.240 - 00:01:55.006, Speaker A: I really recommend going through the website and seeing all the examples of video that they give. I'm sure if you're on Twitter, you've seen the past couple of days people tweeting these videos out, a couple of pirate ships in what looks like to be a cup of coffee, this incredibly realistic looking tropical bird, this underwater life that looks like it was created with kind of paper, I guess, and so on. It's just super realistic. And if this can be created with just a prompt like chat DPT, it's pretty mind blowing. So what does this have to do with crypto? Every day, as we know, billions of images and videos are shared across the web. But as we're seeing these AI tools means that the line between reality and fiction has blurred even further. I mean, these images, if you can just create them with a prompt, are pretty mind blowing.
00:01:55.006 - 00:03:19.302, Speaker A: They look extremely realistic, so they raise a critical question about authenticity, copyright, and trust in digital content. Deep fakes can become a real threat to personal security and even national security. So how do we know for sure that, for example, the image of a president making an announcement is real or generated by AI? In an example that's close to crypto, how do we avoid others using celebrities likeness to scam people out of their money, for example? So that's where blockchain comes in. At its core, blockchain is a distributed ledger that records transactions across multiple computers, ensuring that once a piece of data is recorded, and this is crucial, it cannot be altered retroactively. So when an image or video is created, it can be registered on a blockchain, along with its metadata, including details like the creators time of creation and location. So this registration can create a unique digital fingerprint. The blockchain can take all of this information and use encryption to create a hash, and this becomes unique to the image.
00:03:19.302 - 00:04:19.434, Speaker A: This hash is then immutable and can serve as a certificate of authenticity so that anyone anywhere can verify the provenance of a blockchain registered image or video by comparing its hash against the blockchain record. This would be an ideal scenario. There already exists an off chain version of this, and it's an open standard that's made to secure the provenance of digital content. It's called the Coalition for content Provenance and Authenticity, or C two PA, and it was formed through an alliance between Adobe Arm, Intel, Microsoft, and Truepic. It's pretty interesting. This C two PA standard allows publishers, companies, and others to embed metadata in media for verifying its origin and related information. So c two pa isn't just for AI generated images.
00:04:19.434 - 00:05:03.374, Speaker A: The same standard is also being adopted by camera manufacturers like Sony news organizations like the BBC and others to certify the source and history and provenance of media content. So what's super interesting, and I had no idea, is that chat GPT started including this c two PA metadata just since this week on February twelveth. So this just happened. And you can use this site called content credentials. It's contentcredentials.org to verify if an image was generated by Chattybt and Dali three. It's really interesting.
00:05:03.374 - 00:05:49.986, Speaker A: I had no idea you could do this, but I just tried it out. I generated a cat, of course, the Internet's favorite animal, through Dali three and went to contentcredentials.org to see whether this site could verify that it was in fact created by Dali three. So I just saved this image to my desktop and I dragged it here, and there it is. It says, issued by OpenAI on February 15, 2024. So this is really cool. So you can use this to verify whether the image you're looking at was created using AI.
00:05:49.986 - 00:06:50.590, Speaker A: I think this is really cool. But I also think that this C two PA model could work a lot better if that metadata that is saving and the digital signature it uses to verify the content were stored on chain. So C two PA could use its metadata and store that on a blockchain. And that would ensure that the provenance cannot be tampered with or altered down the line. In the end, C two PA is great, but it is a centralized organization, it's a handful of companies control it. I would assume all of this information is stored in servers which can be hacked, they can go down, they can be stolen, it can be leaked and tampered with. So not very secure.
00:06:50.590 - 00:08:19.770, Speaker A: So I think this type of coalition would work a lot better if it was storing its information again on chain. It would also mean that anyone can verify the authenticity and history of digital content by checking its C two PA metadata against the blockchain record. And then the fact that if this process didn't rely on a single centralized authority, it just would improve trust among users of the platform and people wanting to verify this kind of content. We could even go one step further and automate royalty payments to artists using smart contracts, but that would probably be still a ways away as we know how hard that's been even with NFTs. But it would still be a really cool implementation of an on chain content verification system down the line. So interestingly, I tried making a simple edit to this cat image I made with chat DPT and look what happened. So I just went to online paint and drew hearts over the cat and then went back to this page and dropped it here and it says no content credential.
00:08:19.770 - 00:09:57.800, Speaker A: So what happened is that just by making a couple of very simple surface level edits to the photo, this website, which can check for metadata credentials, couldn't detect that the original image was an AI generated image and that it was later edited. So there's definitely limitations to how far these credentials go. I think the way that things will evolve is that everyone will just assume that images and video without an authenticity certificate can be fake. So I think these proofs could even extend into the legal realm where only verified images can be used as evidence while others can't. We need a widespread providence standard for content, ideally secured on chain so that the public can regain trust in media and other content creators, and so that creators can protect their IP. I think it's great to see that large platforms like OpenAI, Sony, the BBC and Adobe are starting to implement these standards, but they need to be made a lot more secure and trustless by pairing these open standards with an actually open registry like a blockchain, to verify the provenance of this content. So I'm sure things are headed that way.

00:00:04.410 - 00:00:38.642, Speaker A: Nicholas Leoshan is the global lead for Linea, which is a new CKE EVM rollup by consensus roll ups play a crucial role in scaling Ethereum as they reduce computational load on the main network by processing transactions off chain. The two prominent roll ups currently available are CK roll ups and optimistic roll ups, and linear is the latest CK rollup to launch. In our conversation, we will explore how linear sets itself apart in the already highly competitive Ethereum layer two landscape. But first we'll begin our conversation with an introduction to linear by Nicholas.
00:00:38.786 - 00:01:25.314, Speaker B: What we're launching right now is what we called Mainnet Alpha, and it comes after many, many years of research. So we started to work actually on rollups five years ago as a part of our work in research for the Ethereum protocol. Back then we were working on term two with the idea that we will be having proof of stake and scalability. And proof of stake was solved, kind of, I would not say easily, but came faster. And we were there with auto scale and multiple options were looked at and at a point, roll ups were seen as the best solution for item scalability. So we started to work at this in basically 2019, saying, okay, hey, that's how we want to do it. We think it's the right solution.
00:01:25.314 - 00:02:04.482, Speaker B: And more and more we're convinced that it was right solution. At the beginning, roll ups were very specialized because we thought, okay, it's slow, it's complicated, so we need to have very specialized roll ups. So we started to work actually on payments, only then anonymous payments, this type of stuff. And then we said, okay, but let's try to do Zke EVM, which is, let's try to be able to interpret the bycode of the EVM, the native bycode of the Ethereum protocol. And let's try to put that into a system of zero knowledge in order to use this to scale. And actually we saw it's possible. So that's right, and it's all right.
00:02:04.482 - 00:02:08.594, Speaker B: So we need absolutely to do a business out of this. And that's how linear was created.
00:02:08.642 - 00:02:13.762, Speaker A: What is it about linear that's different from other CKe EVMs or CK rollups?
00:02:13.826 - 00:03:13.722, Speaker B: Yeah, so if you speak about ZK rollups without mentioning ZkvM, the key point for us, we are a ZkVM working at the bytecode level. So it means that we're interpreting the bycode as it is compiled by existing compilers. So people using the existing tools, people developing today on ethereum layer one, can use linear directly without any change, or with more say, very minor changes. It's a key point because it means that the knowledge that the developers have already, they know solidity, they know other tools that compiles to veer, it's going to work outside of the box. They don't need to learn new languages, they don't need to learn new tools when they want to audit their product. All the teams that can audit layer one code can audit layer two code. We won't have all the things that we learned on layer one.
00:03:13.722 - 00:03:45.278, Speaker B: And we discover new way to do things that we should not be doing. This is known already. That's the AVM. We know how to audit this, we know what is secure, we know what is not secure. So we are leveraging all this so we're not the only one working at the bycode level. And our view on this is actually very good because it's a very important thing for decentralization. So the fact that other people are doing like us, working at the bytecode level means that as an application, as a developer, you're not locked to linear.
00:03:45.278 - 00:04:18.126, Speaker B: If you think that we're not working well enough, if you think that the linear does not evolve properly, you can move somewhere else. You won't have to relearn everything, you won't have to change your code, you won't have to audits all over the place. You can basically migrate. So it's a key element of a centralization not being locked in by something. We see it as a key point. It includes the fact that the EVM, it's not something that we define, it's defined by the eternal foundation. And we're just following the specification done by others, like others people implementing this type of ZKVM are doing.
00:04:18.228 - 00:05:40.774, Speaker A: Would it be fair to say that what linear does is it's a roll up, and just like simplifying it very much. Roll ups are layer two chains, which means that they take some of the processing and computation out of the layer one chain. For Ethereum does that outside of Ethereum, and then rolls up all these transactions and confirms it on the Ethereum chain. But it speeds things up because you don't need to be confirming every single transaction as they happen. You roll them up and there's these two main technologies that do this right now, it's optimistic roll ups and zero knowledge roll ups. And then zero knowledge EVM roll ups are using the same coding language as Ethereum itself to allow developers to build on these roll ups. So that allows it as much flexibility as Ethereum does for developers to build on these chains.
00:05:40.774 - 00:05:43.654, Speaker A: Is that kind of a good summary?
00:05:43.782 - 00:05:45.114, Speaker B: It's absolutely correct.
00:05:45.232 - 00:05:53.210, Speaker A: Awesome. Between CK rollups and optimistic rollups, why did you decide to go with Ck?
00:05:53.290 - 00:06:28.062, Speaker B: So the Ck one is the most trustless solution. All the knowledge is on the layer one because we put on the layer one the way to verify that a state change is correct. And if the layer one says that the state change is correct, then we're done. And that's basically simply about this. The fact that everything is there on the layer one for everybody to see and anyone can verify the change, that's the most secured way of doing things. So that's why we went for this solution.
00:06:28.226 - 00:06:36.902, Speaker A: Zero knowledge roll ups allow for anyone to verify on chain each transaction and optimistic roll ups don't.
00:06:36.966 - 00:07:07.960, Speaker B: So the main idea of the ZK roll up is someone is going to create a batch of transactions, a sequence of transaction. That's why we call it the sequencer. It's going to say, okay, for this sequence of transaction, I'm going to change from this state to this state. There will be a change of state. And this change of state can be sent to the layer one. And the layer one will do two things. The layer one will verify that the change of state is correct.
00:07:07.960 - 00:07:48.130, Speaker B: Using a proof for this, verifying a proof and will store all the data conducting from this state to this other. So anyone can recreate the state. And the fact that once it has been proven, you know that it's valid means that there's a huge simplicity in how you use it. It's there. I don't have to think about maybe there will be a fraud in the future. Can I be sure that someone is going to create a fraud proof? If someone is not available, what can happen? You don't have all this. It's all on the layer one.
00:07:48.130 - 00:07:51.250, Speaker B: It's finished. That's the main idea of this.
00:07:51.320 - 00:07:55.282, Speaker A: Okay. And instead optimistic roll up. Don't do this.
00:07:55.336 - 00:08:24.718, Speaker B: Optimistic roll up. You're going to update the state on the layer one. But you rely on this idea that maybe the state is not valid, maybe the change is not valid. So you expect that someone will detect that the change is not valid and will send a proof that the change is not valid. It means that there's a period of time, usually one week or, well, we don't know. You don't know if the state is fine or not. You expect that if the state is not correct, someone will show up and will say this is not correct.
00:08:24.718 - 00:08:42.946, Speaker B: But you need to wait one week and you need to think about all the edge cases, which is what if nobody appears? What if there's a side corner case, edge cases, whatever. So incentivization to not doing a fraud always is something that disappears totally with a ZK roll up.
00:08:43.048 - 00:09:08.474, Speaker A: Got it. Okay. In terms of usability, I think one of the main issues for roll ups has been the delays in withdrawing and getting funds back on Ethereum or to the roll up. How does linear work in that sense?
00:09:08.592 - 00:09:21.690, Speaker B: So it's like all the K roll ups. Once the proof is returned on the layer one, then as we know that the state is correct, we can transfer the funds.
00:09:21.770 - 00:09:23.442, Speaker A: Okay, and how long does that take?
00:09:23.496 - 00:09:47.426, Speaker B: So that's an interesting question. Ultimately it's very fast question of minutes. In practice we're still in an alpha release, so we did put a delay on it in order to be sure that nothing bad is happening. So today it's configured at 8 hours. But this is something that is a part of an alpha release, the training ways that we put to secure the system, and it's not something that will last.
00:09:47.548 - 00:10:14.866, Speaker A: Got it. Okay. And speaking about the alpha release, would be great to get some of the result and metrics that you've seen in the test phase. The whole point of these roll ups is to allow Ethereum to scale. So what speed times how many transactions per second are you seeing so far?
00:10:14.968 - 00:10:43.850, Speaker B: Yes. So it's a very interesting question. So we add on our testnet, so in around six months, and we started in January where we permissioned testnet. So actually 300 people were allowed to join. So it was very successful, but it was 300,000, 300,000 people. And then in end of March it become permissionless so anyone could participate. And we saw a huge increase of adoption immediately.
00:10:43.850 - 00:11:36.694, Speaker B: And at the end we have today 47 million of transactions executed on our testnet with five, five millions different addresses. So that's what we got, which is absolutely huge. A key point is one of the difference that you see on the layer two and on the layer one is you have transactions that are usually more expensive in terms of gas. So the way we configured our system for the testnet is with the capacity double of ethereum mainnet. So we add 40 million gas per block every 12 seconds. The main idea of this is we're writing the data on girly, and girly is a test network. So if we write too much data, nobody else than us can actually use girly.
00:11:36.694 - 00:12:09.654, Speaker B: And it's a test network, a little bit shared, so we can't go crazy that much. Okay, so that's a limitation. I will come back a little bit on that later. But this point that on layer two you have transactions with more gas. It's something that is very, very interesting for many use cases. A lot of people are limiting either the functionalities, either the safety of a system, because they want the transactions to be very cheap. But as on the layer two, we are much cheaper than on the layer one.
00:12:09.654 - 00:12:42.478, Speaker B: Many things that are too expensive for the layer one becomes a nonissue in the layer two. So that's one point. Another point that is interesting. And we mentioned how the roll ups were working. When you have a roll up, you write the data on the layer one, which means that if you have a lot of operations, you're going to use the layer one a lot. So you will use it much less that if you are doing the operation of the layer one. That's why we are basically 15 to 25 times less expensive than the layer one.
00:12:42.478 - 00:13:22.766, Speaker B: But it's 2025. Basically, you can kind of maximum scalability that you can get. However, that's where the layer two and the layer one are working together. There is a lot of work happening in the layer one around data sharding the EIP 48 four. And all this will make the roll ups much more efficient. And the technology that is used by the layer one is simple enough that the layer one should be able to scale all the time. So we will always have a story of, okay, we're a little bit limited even in the rollup by the layer one, but the layer one is going to improve and then the roll up will be fine, there will be more use cases, the layer one will improve again and so on.
00:13:22.766 - 00:13:24.202, Speaker B: So we'll have this unless toy.
00:13:24.266 - 00:13:50.214, Speaker A: Okay, so you said 5.5 million addresses and 47 million transactions. And in terms of gas, you mentioned that roll ups are somewhat limited by Ethereum layer one, in that the maximum reduction is between 2025 times around 20.
00:13:50.332 - 00:14:15.610, Speaker B: Exactly right now. And it's quite key to know that the EIP 48 four four will change this in the next months. And that layer one has many opportunities to do even better. So it's really something that is going to have a huge potential for long term improvements. And the limits are not known yet. So we're at this stage.
00:14:15.690 - 00:14:28.998, Speaker A: This is EAP 14 four, you said 484-4484 sorry. And can you remind me what this EAp was about? Like, what will it unlock for layer twos?
00:14:29.034 - 00:15:06.990, Speaker B: What it unlocks is the capacity to have much more data returned by the layer one. And it's quite important because a way to kind of work around this layer one cost, what we call the data availability, is to put the data somewhere else. And when you do this, you have a dependency on the layer one and on this somewhere else, and your system is as secure as the least secured elements. So you're playing games. So the fact that the layer one can improve, it's a huge benefits for the rollups and for the global security of the system. So that's why I'm pushing for this.
00:15:07.060 - 00:15:19.038, Speaker A: Very interesting. And you said right now, the level of improvement that EIP 4844 could bring is still unknown.
00:15:19.134 - 00:15:58.782, Speaker B: It's the limits at alt mode, yes, because as it's basically what you're requiring with this new architecture. And it's really an evolution of Ethereum that we saw. With all this work happening on Ethereum two, the modularity of the system is the main idea is we put the execution on the layer two, and the layer one becomes a consensus and data layer. And being a data layer is something much simpler than being an execution layer. And it allows the data layer to scale. So it means you want to scale reasonably. You don't want to go too crazy immediately if you don't have a need, but you have a lot of potential, say, oh, there's more use cases, let's add some data.
00:15:58.782 - 00:16:00.446, Speaker B: And that's what layer one will be doing.
00:16:00.548 - 00:16:31.878, Speaker A: In terms of the focus for linear, you said that before you had started to work on payment specific roll ups, and then you decided to go in this direction. That's kind of more generalized, but still, are you having a specific focus on different areas of web three? Say, will you hope that more DFI applications are built on linear, or is it nfts, or are you just going after any and all use cases?
00:16:31.974 - 00:17:01.486, Speaker B: So we think that it's quite important to be very generic. And if you try to say, okay, this is Defi, this is gaming, this is NFT, you're missing some opportunities to have links, actually. So you can perfectly imagine NFT, they have some value. So there's a part of the defi ecosystem, you've got nFt in the games. So there are links between this. I mean, you can go crazy. You can imagine that you can do a flash loan to get an NFT that you will do in a game, that you will use in a game, and that's it.
00:17:01.486 - 00:17:50.386, Speaker B: You will pay back in a single transition. So there's a lot of things that you can do, and we don't know everything, like the flange loans, for example, from the fact that you can loan something just for a single transaction and use it with crazy amounts. It's something that was technically possible in 2015 from the very beginning of Ethereum, but nobody has thought about it. And if we allow multiple use cases to be there in a single roll up with huge scalability and performances capacity, I'm pretty sure that people will find ways to do some strange interactions that we are not thinking about right now, but they will actually make a lot of sense in the future. Like flash loans today we will get with some stuff. So it's really important for us to be able to have all type of use cases and all type of application.
00:17:50.488 - 00:18:52.338, Speaker A: Instead of being very specialized parcel the decentralized real estate trading platform is making it easier to get exposure to global real estate. Through city indices, you can trade the price change of popular US cities and easily access over 5 million properties with just a few clicks. With leverage up to ten X, you can go long or short and begin trading real estate in ways you never have before. Join today to start building a diversified real estate portfolio. We've mentioned here that there are many other roll ups and layer two solutions being built. What's your vision? Or how do you think these chains will interact in the future, if at all? Or do you think there will be one that has concentrates most of the volume and users? Or do you think there will be a lot of interaction between many of these chains?
00:18:52.434 - 00:19:17.018, Speaker B: Yeah. So there's a perfect future that is a little bit difficult to get. That is called the multi proofer. And for this I need to explain a little bit how we do the proof. I mean, basically to do a proof you need to use very advanced cryptography. Basically, most of the time that is less than ten years old. And cryptographers usually when it's less than 25 years old, they think it's a little bit dangerous.
00:19:17.018 - 00:19:51.562, Speaker B: So we're using very advanced technology and it brings a risk. That's one point. And I think we need to be very transparent. It's very advanced, maybe it will be broken later. We don't know the subcomponents that we're using. We're using advanced hash functions that are technical component that is absolutely key. It's something that is a little bit brittle, and it's not only this like we're implementing the EVM, so it's not something that is final, it's not something that we're not going to touch it.
00:19:51.562 - 00:21:03.194, Speaker B: And again, a common approach in cryptography is you do this and if nobody touches for ten years and uses it, but it does not have to be modified, then you can trust it a little. But here the EVM standard is going to change. Many things are going to change. So not only we're using advanced tools, but we're using advanced tools with moving targets, and we're changing things. And okay, you can say, look, I've done audits, look, trust me, you can say all this, but there's a perfect cooperation scenario which was actually proposed by Vitalik, which was saying, hey, actually all the ZKVMs are using very different technologies, which is good because the probability that one all these technologies break at the same time is very low. And for a single roll up, instead of having a single roll up, a single zero knowledge technology, we could have a single roll up building on multiple zero knowledge technology. So when we want to change the state of a roll up, instead of having one proof, we come with multiple proofs, one per technology, and we say, oh, we have four proofers with different technologies.
00:21:03.194 - 00:22:19.258, Speaker B: And if three proofs are valid, then we can consider that the state update is valid and we can do it. And this way, if you don't have an issue with free provers out of four, you're comfortable that the update is valid. And this is a very interesting cooperation point, because we're still motivated to invest in different technologies, but we're interested as well to cooperate in order to make the global system very secure. And it's very similar to what you have at the layer one today. In the layer one, the Ethereum foundation pays a lot of attention of having multiple implementations of the layer one protocol, and they try to have all those implementations with something like between 20% to 40% each, so they don't have too much importance. And that's exactly a kind of perfect future for the EVM, for the ZKVM, which is, yeah, we have multiple implementations and we're cooperating in order to allow more transactions in order to make the system much more secure, instead of hoping that there are no issues in the technology that we're using.
00:22:19.344 - 00:23:23.342, Speaker A: That's really interesting. Okay, so would it be that in this future, all the CKE EVMs will work similar to how Ethereum implementation work? There's different Ethereum clients, but they are all confirming the same transactions, they're all part of the same network. So in this future, for CKE EVMs that you're seeing, it would be the same, like all CKE EVMs would be part of the same network, which means that they would have to work with multiple proofs, like they would all have to prove the same chains like the same transactions, they basically have the same database of transactions that they all agree on. And that means that applications built on one will also be useful on others. What would the consequences for users be in that future?
00:23:23.476 - 00:23:53.842, Speaker B: From this technology, you can do two things. You have actually three options. One is you continue to have competing networks, but they reuse the technologies of others. So you still have independent networks, but they are more secure because they cooperate in order to implement exactly the same standard at the same time. So we can have this multiprover approach. That's one future. Another future is we can have a single network.
00:23:53.842 - 00:24:15.918, Speaker B: Why not? It's possible as well. And another one is, oh, but now that we have basically a standard defined ultimately by the term foundation, and we have multiple implementation, we can push this technology to the layer one to facilitate the scalability of the layer one natively as well. So all this is possible. We will see.
00:24:16.004 - 00:24:26.830, Speaker A: Okay. But in essence, what you think would be better is for all the CkevMs to work together rather than compete.
00:24:26.910 - 00:25:19.410, Speaker B: So competition is very good in terms of performances. I think it's very important and it makes the system much better. Like the way I see it, even if we're using different technologies, all those technologies are new and there's a lot of improvement for performances in terms of speed, in terms of cost, everywhere. And it's always the same thing. If you're alone and you say, oh, I'm 20 times faster than the layer one and there's no competition, just let's stop there. I mean, it's incredible already, but if you have people saying, oh yeah, but I can do 20 times faster, 25, 40 times faster, then you're going to push a little bit the envelope. I think what's going to happen is the overall progressing and the competition to be the fastest will make the system much better because people lack to be the first, and that's pretty good.
00:25:19.410 - 00:25:36.822, Speaker B: However, I think we can say, yes, that's a useful competition, but there has a lot of potential for cooperation, which is now that we're basically as fast as the others because we're running one after each other, well, we can actually cooperate not only on the speed, but on the global security of the system.
00:25:36.956 - 00:26:26.102, Speaker A: I want to get more details on the level of decentralization for linear. Obviously, this is a really important point when doing anything on blockchains. So there's different points that people will look at when using a layer two. One is just the number of validators, the number of nodes involved in the network. The other one is a sequencer so if you could go down kind of the different points for linear on these issues.
00:26:26.236 - 00:27:13.606, Speaker B: Exactly. So I think all the roll ups have exactly the same story, which is you start with something that is centralized and then you decentralize it. And why? Centralization at the beginning is because of a complexity of a proof system, because of a complexity of a technology. At the very beginning you won't say okay, yes, in theory anyone can send a proof and if a proof is valid, there's nothing to think about. Okay, yeah, but maybe there's a security issue in the proof and we are not totally sure. So what do we do? And the way it is solved is to say actually no, at the beginning, not everybody can send a proof. It's controlled by people that are known like basically consensus in our case.
00:27:13.606 - 00:28:35.034, Speaker B: And there's a kind of trust which is involved, which is okay, I trust that consensus will not go too crazy. So there is a proof and there's a security which is oh, we can't have too many people updating the system and it's obviously not acceptable, basically as simple as this, but it allows to have a first deliverable which is oh look, this proof working, we've got this scalability, performance improvements, there's a lot of things. So it's a multiple step thing. And from this what you want, you want to minimize the trust and maximize the decentralization, which is very correlated. It's not fully correlated. So the point is, thanks to the proof, once the proof system is I would say proven enough and maybe we need these multiprovers at the point you can say okay, you can trust in the proof, but given the complexity to produce a proof, it's still limited to a set set of factors. And what you want to get from there is okay, actually the proof is not only the proof is stable, but actually many people can participate in the proof generation.
00:28:35.034 - 00:29:08.220, Speaker B: You don't need a crazy amount of resources. That's the first step. And the second step is oh, and as well, it's not only when we're deciding to create this sequence of transactions, anyone can participate, anyone can create a sequence that will be sent to approver and the approver will send this to the layer one. So that's a path that we need to take. Today we are in this situation where there's this little trust that please trust us on this. But clearly decentralization is the next thing that we want to do because we need to remove this trust. So we've got a roadmap on this.
00:29:08.220 - 00:29:39.446, Speaker B: We want to show that the proof system is sound, so we've got a very long specification of it. There will be a work on formal proof it. Formal proof of it. There's a lot of work there. There will be a work as well on having everything open source so anyone can check. And then there will be a work on allowing everybody to participate with progressive steps in control. That's how it's going to work.
00:29:39.548 - 00:29:42.786, Speaker A: What's the timeline for these phases?
00:29:42.898 - 00:30:00.478, Speaker B: It's in quarters. It's a technical thing, so we need to spend the time that we need to spend on this. There's no doubt on that. That will be a driver for us. But we don't want to deliver something in 2029 that's not doable. So we will be much more aggressive than this.
00:30:00.564 - 00:30:18.302, Speaker A: When you open up the network for anyone to be able to participate in validating the proofs, what would the incentive be for other participants?
00:30:18.446 - 00:30:21.982, Speaker B: I don't understand your question. I'm joking.
00:30:22.126 - 00:30:22.820, Speaker A: Okay.
00:30:26.250 - 00:30:31.510, Speaker B: It's a very good question, but it will come exactly with a decentralization. I don't have the answer yet.
00:30:31.580 - 00:30:52.686, Speaker A: Okay. Yeah. All right. And then about your launch or launch and plans to grow the ecosystem. I read about an ecosystem investment alliance. If you can explain what this is about.
00:30:52.788 - 00:31:26.370, Speaker B: Yeah, sure. So globally, of course, Ethereum is about builders. And the question for you is how you're going to facilitate the life of the builders on your system. So we think first by having a ZkVM so they can reuse all this knowledge. It's the first thing. Something else that we've done as well as a part of a testnet is the work on the quest. So we created a program where people could actually try the applications.
00:31:26.370 - 00:32:29.606, Speaker B: All the Dapps that were installed on linear as a way to maximize the link between users and apps, because it's something to be deployed on linear, but they give them how are going to be used. And we really want to maximize this. So it's something that we really worked on is, okay, how can we incentivize people to try all the apps that are around? So we add this system of quest and apps were used, presently used. I mean, that was incredibly successful. And another thing, I mean, we are in a market where money is expensive, so how can we facilitate the contacts? So the idea of this fund is this alliance is people can basically, people building a linear will be put in touch with people well known in the linear ecosystem. So investors will understand exactly what those builders want to do. They will be able to see the advantage immediately, will be much more efficient and there will be as well synergies between this, which is actually the last point in terms of how to make builders successful.
00:32:29.606 - 00:32:59.302, Speaker B: What we want as well is to maximize the possibilities of cooperation. I mentioned this example of a flash loan between NFT and game, which is maybe a dream today. But if we maximize the cooperation between builders, we may have application being built with the idea of reusing features from others. So that's what we want to do. So there will be a lot of work around maximizing cooperation on linear. That's an important value for us.
00:32:59.356 - 00:33:16.006, Speaker A: Okay, so when you say that you're connecting builders with investors, are you working with external funds in crypto funds or what investors are participating?
00:33:16.118 - 00:33:34.558, Speaker B: There's a long list. I don't want to pick up some of them. Like it's good for relationships. It's better to. But there's a wall list available on linear website already and projects can apply immediately. There's a, a big button somewhere saying, oh, apply for funds. I think it's as simple as this.
00:33:34.558 - 00:33:38.670, Speaker B: And they can describe what they do and how they want to get in touch with investors.
00:33:38.750 - 00:33:51.666, Speaker A: Do you have an existing ecosystem of Dapps already building on linear? And if you can kind of share a bit of the earliest dapps you're.
00:33:51.698 - 00:34:18.890, Speaker B: Seeing, again, I don't want to give names because that's for cooperation. It's always better. But yes, we've got more than 100 applications installed on linear today, so it's already big and it's going to be much bigger in the near future. There's all types of Dapps oriented, defi oriented, gaming oriented, NFT, all this. I think, as we said, it's quite key to have all this type of applications.
00:34:18.970 - 00:35:01.198, Speaker A: Arch is a crypto asset management platform that helps you maximize returns with diversified and gas efficient investment strategies. Chasing yields doesn't pay off. Instead, the Arch token classification standard, or ATCs, maps and classifies crypto assets to give you the best of web three in seven products grouped by three categories, yield, bearing, index style and risk adjusted portfolios. Learn more at the link on the description and about yourself. We've done all this conversation and all I know about you is that you're leading linear. But I'd love to learn more about kind of your background and how you came to be where you are today.
00:35:01.284 - 00:35:39.162, Speaker B: Yes, so my background is on distributed systems. I worked on distributed systems forever. I worked a lot on distributed databases in the past. I arrived at consensus to work on the research for Ethereum two. That's how I joined this space and that's why basically all this story around, oh, how can we do scalability? Or not this, not this, not this, oh, collapse. It's right. So I led the research team of consensus for a while, and this team was working on many different things.
00:35:39.162 - 00:36:14.850, Speaker B: We were working on formal verification tools. How can you prove that something does what it says it does both for the Ethereum protocol and for smart contracts. We worked on cryptography, which is obviously very useful when you want to develop. We worked a lot on the Ethereum protocol itself. It's proof of stake and the merge, the team was working on the merge at consensus, was working in R D, and the scalability that led to rollup. And it's important for us because again, there's this path. There's a fact as well when I'm saying, okay, we want to do a formal proof of our ZKVM.
00:36:14.850 - 00:36:41.946, Speaker B: That's all those links that we're using when we say, oh, we're going to decentralize the roll up. That as well will be done with a team in RNd that we are working on the term protocol. All this will be leveraged and that's how we will have a lot of, I would say, synergies and maximizing as well. Again, cooperation maybe between layer one, layer two, because we have this deep understanding.
00:36:42.058 - 00:37:00.498, Speaker A: About kind of the longer term vision for linear and layer twos more broadly. Where would you like to see it go? What would the ideal outcome be for linear, say, ten years from now?
00:37:00.584 - 00:37:35.342, Speaker B: Something that is interesting to mention, I mean, I would say more short term is in terms of performances. There's a lot of work on the layer one. And I mentioned, oh, they need to be able to send more data. There's a lot of work. And we spoke about the competition between all the layer twos around. Basically the proverb, oh, my prover is faster than yours. This type of story, I think we should think as well about the importance of a client, because if you want to execute a lot of transactions, well, you need to execute them quickly.
00:37:35.342 - 00:38:18.540, Speaker B: It's not only generating the proof quickly, you need to execute them quickly. So there's a kind of, when I joined actually term six years ago, everybody was competing on the consensus protocol saying, oh, my consensus protocol is faster than everything else and I will create a blockchain that will be ten times faster than Ethereum. And it has not happened. It does not happen. Why? Because at the end of the day, executing the transaction is expensive and you can do the consensus as fast as you want. If you're not fast, enough. And the execution itself, which is a very computer science thing, there's no cryptography, there's no fancy stuff, just executing the transaction and it's already very complicated actually.
00:38:18.540 - 00:38:57.926, Speaker B: So it's something that is going to be a challenge, I think, more than people anticipate for the next year. We do have at consensus a team implementing a client Bezu. So obviously that's something that is quite useful and that will be quite important. So it's really, I would say, a short term thing and globally, and I mentioned this stuff, which is basically six years old, and that's exactly this. I mean, six years ago people were saying, yes, scalability, thanks to consensus. And I think that we now have the solution. So my point of view on this is we still have some work to do.
00:38:57.926 - 00:39:47.874, Speaker B: We need to improve as clients. We need to do this faster, proof. But it's a problem that is about to be solved, which means that now people can basically leverage the fact that they can have many, many more transactions. There won't be spikes of activities like in the past. Transaction will be very cheap and it opens many use cases and I don't even know what will be those use cases. Again, generic collapse is useful because if you speak NFT and so on, but maybe there will be new ideas. So that's what I see is we're going to build a tool that other will be able to use to do things that I don't know yet what it will be, but I'm happy to see what will be happening.
00:39:48.012 - 00:40:52.218, Speaker A: Interesting what you were saying that before, six years ago, the discussion was around how to scale blockchains at the consensus level, which you think is very hard to do. So the solution appears to be that the way to scale blockchains is not at the consensus level, but on layer twos using roll ups. So this is what you mean, that the problem has already been solved. To you, this is kind of the end state for scalability, even if there's a lot of work to do on the layer two front and improve different things to make them even faster and more usable and so on. But to use it clear that CK roll ups are the solution for ethereum scalability?
00:40:52.394 - 00:41:36.310, Speaker B: Yes, for two reasons. So the first reason is the big issue that we had in the past when people, for example, were thinking that consensus protocols were the solution is on a blockchain. If you don't have zk rollups to verify the execution, you need to re execute the transactions. And if you have thousands of nodes participating in the blockchain, which that's what you want. For security reasons and decentralizations, it means that all those thousands of nodes will be executing the same transactions to verify that it's correct and that the miner is applying. So that's why you're limited. I mean you need all type of nodes all over the place to execute all these transactions.
00:41:36.310 - 00:42:23.626, Speaker B: So when you already do 50 tps, it's already crazy at this level. And that's why consensus was the wrong solution, because the problem was not having the consensus. The problem was just executing all these transactions on thousands of nodes. And the way roll up solves this is to say, hey, we're going to decorate. The fact that you verify the execution and the fact that you execute executing remains expensive, but it will be done by the sequencers who can be iron machines. And these ion machines can by definition execute much more transactions. But it means it's still fully decentralized because as a node you will receive the data.
00:42:23.626 - 00:42:53.534, Speaker B: But instead of having to execute all these transactions to verify, you will just give me the proof. I'm just going to check the proof and checking the proof. It's a few milliseconds, whatever the number of transactions. And that solves this issue of I don't trust. But the only way to verify is to do everything myself. Here you don't have to do everything for yourself, you just have to verify the proof. That's why it's an incredibly good solution for scalability.
00:42:53.662 - 00:42:57.922, Speaker A: And what do you think is missing in the roll up space?
00:42:58.056 - 00:43:06.518, Speaker B: Decentralization. I think it's a fair you ask a question. It was a very good question. So we're going to get there. That's the work that remains to be done.
00:43:06.604 - 00:43:28.618, Speaker A: Okay, but in terms of having all the pieces that you need for mainstream adoption, like getting roll ups to be as fast as they can, to have the user experience be as good as it should be. In terms of that, what do you think is missing?
00:43:28.714 - 00:44:02.090, Speaker B: The ZKVM. It's about having the same user experience as on the layer one. So if you're happy with the layer one, you will get it on the layer two as well. That's a key advantage. And of course we actually have some issues with the layer one today. The biggest one in my opinion, is all the complexity of managing your accounts. We're saying to people you're going to manage your accounts yourself and oh, if you lose it, you lost your phones, oh, bad luck.
00:44:02.090 - 00:44:47.826, Speaker B: There's a lot of complexity, which is okay, every time you want to sign something, you need to use your account. And if you want to send the equivalent of $10 or the equivalent of $20,000, it's the same operation. Or you need to get into very complicated stuff. That's an issue. So to me what we allow with roll ups is because we're lowering the gas price, a lot of solutions around account abstractions become possible. And this is not something that is directly at the roll up level, like it's something that the roll up enables. You could do that at the layer one level, but it's just incredibly expensive.
00:44:47.826 - 00:45:35.938, Speaker B: While equal abstraction at the layer two level is something you don't care. It's so cheap that you don't care. And that's why we have actually more gas used in the layer two, is because people start to use this type of technologies and it changes totally the user experience. So first, in terms of safety, you can, with account abstraction, manage differently different types of phones without having 20 different accounts. You can potentially sign with your phone for small amounts, all this becomes possible. You can manage account recovery in a simple way without having to add ten layers. You can as well have applications that will pay for the users because it's a part of a contraction.
00:45:35.938 - 00:46:02.330, Speaker B: So all this becomes possible. And I don't need to say that it's a roll up thing. It's something that is possible thanks to roll up, but it's something clearly for us at cleaner, a contraction. We're very strong believers of a difference it makes as it really creates a much safer environment for users and a much more easier to use for developers as well as the users don't have to pay for transactions.
00:46:02.490 - 00:46:20.358, Speaker A: In the past bull run, the gas cost and kind of the congestion of Ethereum was a big issue that I think kept a lot of new users from coming to Ethereum. Do you think that rollups will be able to solve that in the next bull run?
00:46:20.444 - 00:46:47.210, Speaker B: Yes, with the layer one, it's a cooperation game again. We need the roll ups to do their work and we need the layer one to allow to write more data. Okay, so it's happening. I mean, I'm not asking or complaining. It's really like it's arriving. The EIP 44 48 for four is planned for end of the year. So it's a cooperation.
00:46:47.210 - 00:47:00.658, Speaker B: Like we really need this layer one to do things. But with the layer one adding more data availability and the roll ups adding more execution capability. Yes, the bull run will be, a.
00:47:00.664 - 00:47:20.230, Speaker A: Bull run will be smoother. Awesome. All right, super interesting conversation. Nicholas, thank you so much for joining me. If our listeners want to start experimenting with linear. Where should they go?
00:47:20.300 - 00:47:54.210, Speaker B: They should go on linear build. They will have all the information, the testnet is there and they can play with all the applications this week. The main net is for Dapps who are setting up everything and it will be open next week for everybody to play with everything on Mainnet. So the two systems are available. They can play right on testnets. Partners can install only now, immediately. And they can call us, builders can call us to install their applications and next week everybody will be able to use it.
00:47:54.280 - 00:48:24.254, Speaker A: Awesome. So today is July 11. So next week at EBCC, everyone will be able to start using linear. Okay, very cool. All right, Nicholas, thanks again for your time and for the chat. Yeah, super interesting insights and viewpoints on layer twos and scalability and ckevm. So I really appreciate it and thanks again.
00:48:24.372 - 00:48:24.860, Speaker B: Thanks a lot.

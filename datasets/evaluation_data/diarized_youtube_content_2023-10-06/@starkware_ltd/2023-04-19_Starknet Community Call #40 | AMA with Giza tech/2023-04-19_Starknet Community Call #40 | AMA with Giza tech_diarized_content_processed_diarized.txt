00:00:00.810 - 00:00:20.320, Speaker A: I think we can go live now on YouTube. And that's it. We're live. So, hello, everyone, again, welcome to the 40th committee call of Starknet. I'm Henry, and I'm joined today by the team at Giza Tech. Hey, everyone.
00:00:20.850 - 00:00:22.318, Speaker B: Hello here.
00:00:22.484 - 00:00:30.840, Speaker A: All right, maybe let's start with a. With a short introduction. What is Giza Tech? Is it a collective? Is it a company?
00:00:32.250 - 00:00:38.390, Speaker B: Absolutely. Maybe we can even pull up the slides, if that would be helpful.
00:00:38.550 - 00:00:39.660, Speaker A: Even better.
00:00:40.510 - 00:00:41.260, Speaker C: Sure.
00:00:49.310 - 00:00:52.222, Speaker A: There's a bird in the background. That's quite soothing, actually.
00:00:52.276 - 00:00:54.030, Speaker B: It's a coworker.
00:00:54.450 - 00:01:04.030, Speaker A: Nice. We're getting close to the time when we can work outside again. All right, Francis, your screen. Yep. So the floor is yours.
00:01:04.110 - 00:01:04.690, Speaker C: Perfect.
00:01:04.840 - 00:03:33.518, Speaker B: Cool. So Giza is a team, a collective, an interdisciplinary, cross functional squad that gathered around a vision towards alternative vision towards the collective development of AI. When we say collective development of AI, we are talking about something that is opposite to, or in contrast to the arms race imaginary of sort of like corporations locked into competitive escalation games with each other, or like nation states locked into a similar competitive, sort of tragedy of the commons type of situation. But the prospect of actually designing a coordination game that could provide a non zero sum game environment where we can actually develop artificial intelligence in the open by rewarding independent contributors and facilitating learning transfers and ushering in a much less fearful vision of an AI future. And we are doing this by bridging two worlds that we think have fundamental synergies. One of these worlds is obviously AI, and which sort of like Fran, has extensive knowledge and experience in which we can dive into later, and web three, which also fran, but also ourselves. We are protocol designers since more than six, seven years, where the reason that we are occupying or inhabiting the web three space is because we believe in this unique value of web three to facilitate civilizational developments, like civilizational efforts, in a much more optimized but also convivial way than traditional corporate, sort of like competition based zero sum games.
00:03:33.518 - 00:05:01.182, Speaker B: So by merging these two movements of AI and web three, we think that we can get to a place where we can achieve certain objectives and reach a sustainable ecosystem that provides both utility, but also sustains rewards for those who are contributing to that ecosystem. Maybe we can move to the next slide and the next one. Even so, in order to actually achieve this vision, we need to get to a certain point where we're able to serve these AI models on chain and we're able to draw inferences from these AI models, which means that we're able to provide the data availability and the data pipelines for handling these inferences effectively. And on top of that, we need to be able to monetize model usage so that we can sustain and rightfully reward the contributors that are going to be building and serving these models on chain. I think, Fran, you can pick this up from here and introduce a little bit of the tech stack and the details from there.
00:05:01.236 - 00:05:44.874, Speaker C: Sure, of course. Okay. So from here, things are going to get a bit more technical. Also, I'm Fran, one of the co founders of GiSA as well. I'm more part of the tech part of GISA. So in GISA, we are focusing on filling this gap between monetizable models and how people is deploying these models. For this, we are taking this simplified approach that you can see in the slides where we take any train model that is trained in your laptop or in the cloud, in Google Cloud, AWS, whatever place.
00:05:44.874 - 00:06:59.490, Speaker C: We take these models in any framework as well, like Tensorflow, Pytorch, hacking phase models, secretlearn as well. We take these models, standardize them into a common framework, this called onyx, that is a standardized way to represent train models where all the operations, the graph, the computation graph, the weights are always represented in a same way. So it can be a standard. So what we do is we take this standard representation of the trade models as input, and we fit it into one of what we call the Giza transpider. That is an internal tool that we build in order to convert this standard representation of the models from the computation graph, the operations, the weight into its Caio representation. So basically, we are converting the whole model into a chao program to later on have these verifiable inferences for the models, and we deploy these models as carrier programs into starnet. So basically, that's the way we are decentralizing on one side the models, and also the infrastructure for doing the inferences.
00:06:59.490 - 00:07:31.478, Speaker C: So how does the tech stack looks like? We have two main components, basically. One is the protocol and the other one is the platform. Sorry. The protocol is where we deploy the models. And after we convert the models into Kyo programs and we deploy into starnet, they are deployed on top of the protocol. And that's where we do the hosting and monetization of the models. And on top we have the GISA platform.
00:07:31.478 - 00:08:18.522, Speaker C: That is where we do all this transpiration. Like, we take the models as input, we do the transpiration, and we have several features in the platform. For example, we're offering like a model registry where people uploaded models. It's not just uploading your model and transpile them into a carrier program and deploying. It's like a complete, let's say decentralized cloud to call it somehow on a centralized platform. Where we take these models are storing this model registry where we have different kind of models, like for example this one for translation, this one's for risk assessment, and different versions we have this versioning monitoring everything in the platform and from there we can deploy into the protocol. Easy.
00:08:18.522 - 00:09:16.122, Speaker C: I'm familiar way for people like building on AI to have something very similar to what they have in other products in the web. Two ecosystem while working on AI like Sagemaker or Vertex from Google, and on top of the platform we offer different features. For example, one of the features we will offer is Githa notebook. That is where people can develop their models and use them for training different solutions. For example, we offer this notebook environment where people can easily use their most common libraries for getting data interacted with data from start net, from Ethereum, whatever place, train their models and once they are trained easily integrate with the model registry and later on deploy on the protocol. But also we offer different other services. Like for example, we are also looking into ways how to obfuscate all the models that we are transpiring.
00:09:16.122 - 00:10:17.170, Speaker C: And this is like something we are working closely with one of our partners, that is Osama, and how to provide this fully monorphic encryption for the weights while they are deployed on chain and also like providing more scalable solution on top or privacy preserving solutions on top, like with gisaltry for building this higher throughput solution for more custom needs from clients. Apart from all of this, we also have built in monitoring for these models, how they are performing, what kind of data they are taking in when they are deployed on the protocol, the kind of performance, if there is any kind of consent or misuse of the models. And yeah, that's the two main components. Everything is based on Starnet as you probably can guess. Moving on, this is actually more detailed.
00:10:17.590 - 00:10:47.260, Speaker A: Can I ask a question? And I'm sorry if it's, maybe it's a very basic one and I have my own answer, but I'm curious to hear yours. Recently I talked with somebody who told me AI and blockchain don't go together. Blockchains are a constrained environment. There is no way you can execute a model. And why would you want to execute a model in the open in the first place? So why do AI on blockchain make sense?
00:10:49.550 - 00:11:46.654, Speaker C: Yeah, I think this comes to all the recent things that are happening actually in the collective way for building AI. We've seen, for example, very recent releases from OpenAI where they release GPT four or GPT-3 they're offering their services, but we don't know what is happening actually behind it. So we are making queries or sending text to GPT four, but it's actually GPT four being executed underneath. We don't know, actually. Right. It's like it could be another model or even a person answering. So with this way, like building the open, we can have this way for making the models available, the weights available, because also this is a problem as well in terms of centralization of these models where people, for example, OpenAI controlling the whole amount of big models and weights so anyone can access it.
00:11:46.654 - 00:12:12.454, Speaker C: So the only way for people to interact with is using APIs. So we are centralizing even more the usage of AI. And with this way, what we want to provide is these foundations models in a clear, transparent way where we can have the weights, the models themselves. Bingo. Burnett. And also accessible to anyone, so we can use whatever way we want. That's the main point.
00:12:12.454 - 00:12:15.638, Speaker C: I don't know if Jem or Renz wants to add something.
00:12:15.804 - 00:12:25.100, Speaker A: Yeah, what I love in your answer is that it's very AI centric. It answers the need from the people building AI's perspective, which is great.
00:12:25.470 - 00:12:59.670, Speaker B: Maybe I will give the counterargument not counter, but from the web three perspective. So I think it's a great framing of the question in the sense that why are we working in this constraint environment, not only for AI, but even for rest of business. Right? I guess Mastercard could have had a similar approach, or Sotheby's could have had a similar approach, looking at blockchain and say, wow, it's such a constrained environment, why would I even settle?
00:13:00.650 - 00:13:03.480, Speaker A: They do, they don't do anything meaningful there.
00:13:04.090 - 00:13:06.582, Speaker B: I think Visa is quite actively looking.
00:13:06.636 - 00:13:10.140, Speaker A: At, they're actively doing pocs, that's for sure.
00:13:11.070 - 00:14:42.230, Speaker B: But in the sense that blockchain definitely grew out of those expectations, both in terms of scale and also in terms of exploiting its competitive advantages, such as composability and being open source and verifiable. So I think there is definitely an impulsive sort of reaction that one has towards a constrained environment. But the additional benefits that comes with building in the open and this collaborative nature of building in web three, it starts adding up to a really massive competitive advantage, especially with these things like composability and interoperability. And I think towards the future where we discuss about both when scaling becomes much more not even a question anymore thanks to the likes of Starknet, but also where we move towards different visions of artificial intelligence, where public models can interface each other and we can articulate different, even visions of how artificial general intelligence could look like in a more public and swarm intelligence direction. So I think web three has a lot of necessary components for alternative visions for AI.
00:14:42.570 - 00:15:37.634, Speaker A: And I agree with you, web three is great for aligning incentive and this ecosystem, the AI ecosystem needs alignment of incentive. I do think the traditional blockchain are still not made to handle this kind of workload. Right? But validity proof having the ability to prove code fundamentally changes this equation because well, first of all you will get better networks like you mentioned Starknet. But validity rollups will get better and will be able to handle much more work than their counterparts who need to be replicated. And everybody does the same job. But also validity proof actually allow you to distribute the workload. They allow somebody in their home to train a model or execute a model and just supply the proof to the network that fundamentally changes what you can do with the network.
00:15:37.634 - 00:15:53.374, Speaker A: And now you can start actually having meaningful heavy payload be executed off chain and verified on chain, which makes things like AI on blockchain possible, which you couldn't before. Exactly.
00:15:53.492 - 00:16:28.170, Speaker C: That's one of the main purposes. Totally. Also like with recent work, like what is happening with Madara, all these efforts towards l three and decentralized provers and GPU serated provers like the one that lambda class is building, also like ways for improving the scaling efficiency of the sequencers with mlier also from lambda class. I think they are very good approaches for handling this heavy workload towards also this decentralization of AI.
00:16:28.830 - 00:16:29.580, Speaker A: Definitely.
00:16:32.110 - 00:18:42.834, Speaker C: Okay, so now maybe moving forward to this technical architecture that we are seeing in the slide, this is basically a bit more low level to the tech stack and this shows how the different pieces on our tech stack interoperates between themselves. Here we can see what I talk about from the model registry perspective where everything from the platform level is connected to the model registry where people can develop their models and they can store the trained models in the registry and afterwards be directly deployed on Starnet or do verifiable inferences using the instruments. Pilot and instance Pilot as we discussed, is going to be one of the key pieces, like for converting these models into care programs and also connecting with the different solutions or services that we will offer through the platform. But also once we deploy the model with all these composability features and interoperability that also Jim mentioned when we have these models on chain. Like for example, now when we deploy these GISA models into starnet, we can have this full composability and interoperability which also enables, like for example, don't rely on Oracle for doing these inferences because now for example, one of the approaches to do AI in the blockchain is, okay, I have my model that is deployed on AWS or Google Cloud, and in a microservice I do inferencing and these inferences are sent out to my oracle of choice, like Chainlink or whatever, or imperial or whatever oracle, and gets consumed from the protocol, these inferences. But this is like not very reliable way for doing AI in the blockchain because what happens is your model goes down in the web two part and your protocol is heavily relying on that. So now with our approach, we can easily decouple from that in the way that models are going to be smart contracts themselves.
00:18:42.834 - 00:20:00.410, Speaker C: And you don't need to rely on the usage of oracles for having this functionality in your protocol. Maybe it's for DeFi or on chain gaming, whatever it is. And also we are also giving this marketplace part, that is where we are giving ownership to the people that is deploying the models for Giza, because it's not just about transpiring models, deploying them on chain and that's it. But it's also to empower the people that is building on AI because now, for example, they don't have any kind of way to monetize the work they are doing. For example, in the case of hiring phase, like yes, you can build models in open source, contribute to communities, but actually the people is not benefiting from putting in the open these models, all the big companies that are using these models. So with this way, when we want to provide this ownership to people is okay. Now that people are deploying these models in top of the protocol, they can control who can access the model, who cannot, and also take a fee on the inferences these models are performing to provide this monetization of the usage.
00:20:00.410 - 00:20:50.390, Speaker C: So one of the other pieces that we have is the runtime. And what we are doing is building our new Onyx runtime. Onyx is like heavily interoperable. There are different flavors for Onyx. We have one on c, one rust in different languages to perform this high throughput inference because it's like heavily thinking for doing inference, this Onyx framework and what we are now doing is implementing a new runtime for Onyx that is based on Ko. So, which means that with this runtime we can have verifiable inferences for all these models that are supporting Onyx. That is basically every framework from machine learning.
00:20:50.390 - 00:21:18.422, Speaker C: Now what we recently did is open sourcing this framework, this runtime, so people can contribute. We are doing this also with Olidus in order to also incentivize contributors. Like we have already built many different features inside this framework. We have quantization for the models in eight bit. We implemented tensors implementations in Ko one. Also like this is everything in Ko one. Now there's no ko zero.
00:21:18.422 - 00:22:44.894, Speaker C: We already migrated everything. So we have already tensor implementation so people can interact with NDRIs easily. In Ko one we have real soft Mac activations that is very common also in the mail part, in Kro, convolutional layers, dense layers, and more things that we are implementing. And also now everyone can also contribute to this and participate in this new community that is going to be built around ML in Cairo and also around one of the other things that we wanted to discuss about is about use cases, as you probably may think. Okay, this is very good, or yes, I like this, but where can I use these capabilities for GiSA? Right? So we are focusing in different verticals for using GISA. One of the main ones that we are having very good interest is DeFi and gaming. And for example on DeFi we are experimenting with different protocols to build use cases for risk assessment, for how to assess the risk of the underlying assets, for example deal or bolts, for example under collateralized loans.
00:22:44.894 - 00:23:45.990, Speaker C: That is something that different protocols also in starnet are exploring. So we're also looking into helping out these projects to assess how much under collateralization they could provide to a specific request for an address. And this is going something that we are starting to build models for not only ourselves, because we are only like the infrastructure providers or the protocol providers, but people to build these models that can put in the hands of the protocols to enhance their services. Basically we are also like automated asset management strategies as well, like for DeFi. But also there is very good prospects in the on chain gaming side. Like we're talking with many talented people from the starnet ecosystem to build on chain games. One of the very interesting use cases is around npcs.
00:23:45.990 - 00:25:21.918, Speaker C: We are looking into different games that are being built to provide these non playable characters to enhance the gaming experience of these games. Like for example managing inventories for the games or having some kind of trading agent that can interact with the players playing the game, but also more into the infrastructure side, like going to contributing Dojo, the game engine for Starnet. And in this site we are looking to implement a new component that is for agents or npcs to actually easily interoperate with the rest of the components that are being implemented. Also we are exploring different verticals like security and decide on how to empower or enhance these different areas, like for example in security monitoring of smart contracts or fraud detection and so on. But now we are more focused on the DeFi and gaming side. So how are we going to actually implement all this vision and roadmap for Gisa? Now we are in the foundation phase. Right after the foundation phase we are building with different partners and protocols in the starnet, but also in theory ecosystem to provide this use case that I mentioned earlier.
00:25:21.918 - 00:26:05.362, Speaker C: We are building together very focused on providing this value to these protocols as well as we are like iterating on our products, building our community around the framework so people can also build their own models using the Onyx Cairo runtime, deploy builders models in Cairo, deploy them on Starnet and build their own verifiable inferences. Also, the next step will be our public release. That is okay. Now we finalize or working with our different partners building the product. Everything is ready. The community building models is getting attention and now we are going to progress to a public release. That is okay.
00:26:05.362 - 00:27:15.542, Speaker C: The protocol is ready and the platform, it is also ready. So we will open up to everyone so they can upload their models, use the platform to use the model registry, deploy the models into starnet, perform verifiable inferences from there, and yes, start growing the platform and the product itself. And at a later stage, we will open up all the functionalities of this open economy that we were mentioning at the beginning where we can have this ownership of the models, we can have this monetization of the inferences based on the usage that we are performing with these verifiable models. We are going to also scale up with our own l three working on the weight obfuscation and many more features that we have in the backlog. So that's it. Yes, feel free to drop any question or anyone in the chat. You can scan this QR if you want to link to the repository of the framework, the website, Twitter and so on.
00:27:15.542 - 00:27:17.990, Speaker C: So yes, feel free to reach out to us.
00:27:18.140 - 00:28:00.674, Speaker A: And for the people listening, feel free to ask questions either on YouTube or on Twitter. We'd be more than happy to answer them. I actually have a question for you guys, so thank you for your presentation. This is really interesting. I'm really curious to see the intersection of, well, the intersection of AI and web three. My question is the following. For a lot of domains, the blockchain started with asking things like, oh, what can blockchain do for finance? How can we help make finance better with blockchain? And not a lot of things happen in that direction.
00:28:00.674 - 00:28:40.980, Speaker A: There's not many banks, not to say none at all, using the blockchain today, but there were native users who had a need for finance services and weren't served by the traditional system. And so they started building these products and eventually using them. Where do you see traction coming from in the AI blockchain world? Do you think it will start with people in the AI industry who have a need that they don't have answered that will use the blockchain? Or do you think that blockchain people building projects on the blockchain have a need for AI and they will start using Giza? Does that make sense?
00:28:41.750 - 00:29:02.540, Speaker C: Yes, makes sense. We think that the second option is the more we are looking for in terms of white protocols, looking into having capabilities for AI and enhance their products, like as I mentioned in the Defi space or gaming site.
00:29:04.350 - 00:29:12.670, Speaker A: Yeah, and it makes sense in your slide. It shows like a lot of those use cases, I love it, are about how do we make existing blockchain apps better or more powerful.
00:29:13.490 - 00:30:24.750, Speaker C: Yeah, totally. For example, I always like to think about this. The web three space is like how web two was ten years ago in terms of use cases and possibilities, because now, ten years ago, any company in the web two space was using AI or ML for anything, and now it's being used everywhere. But until anyone figured out how to do it in a scale or on a reliable way, there was no way to do it. And now I think that we are at this stage where web three protocols or projects, they don't have any way to have these enhanced capabilities, but now they can because of the technologies that we can leverage using starnet. And this will open up to very new use cases for many areas. Also, in the second part of the question that is, how do you see traditional use cases? I think there is a big necessity in highly regulated markets or companies like think of traditional banking.
00:30:24.750 - 00:30:58.080, Speaker C: I've been working in traditional banking on AI for some years and there is a lot of restrictions for using specific algorithms because you can actually audit these algorithms or what they are doing. So now that we can have verifiable inferences, if you can provide these companies to a reliable way, they can provide inferences. But along with these inferences, you can provide us a proof that these inferences being done by this model is going to be a huge benefit for all these companies.
00:30:58.770 - 00:31:46.782, Speaker A: Yeah, I worked a bit in the insurance industry and there's the same kind of challenges. Say you want to evaluate an insurance claim with an AI, you have to prove that you actually, I mean, when you can't just say, oh, the algorithm said that you have to prove that you use the same algorithm for everyone, you use the same criteria, not even to talk about the fact that people would accept an AI judging or whatever, but if you want to do it, you have to prove that your AI reached that conclusion. And this is hard if the people on the other end can't execute the algorithm, and it's hard if it takes a lot of resources. So being able to prove that you evaluated it using the same algorithm as everyone, the same algorithm everyone agreed upon is really important, actually.
00:31:46.836 - 00:32:32.480, Speaker B: Funny story is that I got the text message at 330 a. M. From my mom last week, and she said she couldn't sleep with a thought in her head. And I tend to try to communicate my work quite extensively with my family and she's very receptive to that. And she was texting me about, I guess, her own problems that she's encountering in the world where insurance premiums are rising as you are growing older. And then at one point, if you're not able to pay these ridiculous premiums, they just put you out the door. Even if you were a customer for all your life.
00:32:32.480 - 00:33:22.560, Speaker B: And she was asking, wouldn't a smart contract based solution sort of be an open and fair way of providing this as a sort of public infrastructure for people? I said, mom, what is going on? Let's talk tomorrow. But I thought that it is very much at the disposal of smart contract systems to become more receptive to data, to be even more probabilistic than deterministic, to be able to extend the use cases of web three beyond its current sort of limited scope? And I think AI is going to play a very key role in that.
00:33:23.810 - 00:34:03.830, Speaker A: Interesting. All right, so I have another question, actually. So when we're talking about AI, I think I'm not an AI person. I had fun a bit with it a while back, but a long time ago, and it was anyway, in other contexts. But I think most of the stack today for people doing ML is in Python, is that correct? So how do you prove Python? Because in order to prove stuff, you have to have your code be provable. And that's why we need Cairo. Right, Cairo.
00:34:03.830 - 00:34:20.000, Speaker A: Giving you the ability to prove that you executed program, not just smart contracts, arbitrary programs. How do you do ML in Cairo? Does it mean that you have to rewrite everything from Python to Cairo? You mentioned onyx. Can you talk a bit about it?
00:34:21.170 - 00:34:57.654, Speaker C: Yeah, actually that's a very good question. We are not trying to replace the work people is doing in Python. For Kero, what we want to do is, okay, let people code in Python using whatever they think is best. Like do their feature engineering, their model training, everything in python, they build the model. But actually, when you finish doing your training for your model, you have a file. That file represents basically your model. And what we do is just take that as an input, let people have freedom on how they want to build their model, and we take that as an input.
00:34:57.654 - 00:35:11.322, Speaker C: We convert it into this Onyx format that is supported by almost every framework and we take care of the rest. So you just give it a model, we feed it to the transpiler, we convert it into Cairo, and we deploy it into starnet.
00:35:11.466 - 00:35:25.010, Speaker A: So you're saying that when I design a python model, I can then output it to this format, which is Onyx, which is not something you guys came up with. It's a general purpose format, and then you take Onyx and convert it to Cairo.
00:35:26.170 - 00:35:27.878, Speaker C: Exactly. That's it.
00:35:27.964 - 00:35:31.478, Speaker A: Wow. I had no idea Onyx existed. This sounds great.
00:35:31.564 - 00:35:32.200, Speaker B: Yes.
00:35:32.890 - 00:35:53.130, Speaker C: ONS is very much using production systems because it's heavily optimized for running high throughput inferences for models, and it's like actually run for production. And when you are running cloud architectures for production, and it's just leveraging this format to support a new runtime that is, in this case, kerrow.
00:35:54.370 - 00:36:31.130, Speaker A: Nice. Super cool. All right, I have another question, but it's kind of weird, but let's try. So there's a lot of talks about AI and Agi and the big bad computers coming to eat your kids and everything. Basically, people are worried we're going to give consciousness to computers by plugging AI into the blockchain. Aren't you afraid you're also giving them money? Okay, my question is, to put it differently. People are afraid of AgI, but at the end of the day, Agi as means to communicate stuff.
00:36:31.130 - 00:36:42.720, Speaker A: By plugging it into the blockchain, potentially you give it money, resources, which is more tangible, it allows it to interact with the world in a different direction. My question makes sense.
00:36:44.690 - 00:38:21.438, Speaker B: Yeah, it totally makes sense. I think blockchain can be understood as also more than money and more like the immediately fear reflex could be around autonomy and self executing smart contracts being AI and so on. But actually, first of all, we are designing the protocol with safety in mind, where community is going to have oversight in how the protocol is operating. The community is going to decide on in an open manner which models are against the constitution of the protocol itself. And zooming out. I think if we have to compare web two's approach or the corporate approach towards artificial general intelligence versus a web three approach towards artificial general intelligence, one would be defined by the type of competitive escalation game that, say, google and Microsoft or OpenAI are looped into, or United States and China are looped into. And web three would be defined as building in the open, interoperable frameworks of models with public utility that are derivating and facilitating learning transfers and forming community.
00:38:21.438 - 00:38:49.160, Speaker B: So I think the most dangerous thing about AGI is to bring AGI to a humanity that is locked into a narrow, competitive framework. And the remedy towards that is to establish new game mechanics and new outcomes around creating AGI in the open. And I think web three and Giza is doing exactly that.
00:38:50.890 - 00:39:23.546, Speaker A: That's nice. I guess there's a parallel to be made between how software was developed 20 years ago and how software is developed now with open source. Right? I mean, 20 years ago, everybody would design their own software, and it was very proprietary software, everyone doing its own things, and everything was siloed. And then open source happened, and open source gave us, I don't know, Wikipedia, Bitcoin, Ethereum, Starknet. And now there's a similar parallel into training models, I guess.
00:39:23.668 - 00:40:18.062, Speaker B: Right? And the money element that you mentioned is also so critical in that it is providing to open source these type of value systems that are able to sustain focused work for much longer periods of time without actually dissipating into kind of unmaintained sort of repositories and so on. But actually people sustaining their lives and their careers and their community, doing what they love to do thanks to this financial sustainability aspect. And we take that very seriously at Giza as well, so that we can actually usher in a paradigm of ecological development of AI where people can actually sustain their well being independently. You're on mute, Henry.
00:40:18.206 - 00:40:19.470, Speaker C: You're mute, Henry.
00:40:19.550 - 00:40:30.680, Speaker A: Nice. Yeah, good catch. I don't see any questions, so I don't know if there are other points you wanted to mention, otherwise we can wrap it up.
00:40:34.330 - 00:40:35.480, Speaker C: Nothing else.
00:40:36.090 - 00:41:01.440, Speaker A: Wonderful. All right, so, Chamfran Renj, thank you for being here. I wish you the best in your Giza journey for people who want to know more. It's following on Twitter gizatech and then there's a link to your website, I guess. Another question, maybe. I don't think there's a live product we can use yet. When can we expect that?
00:41:04.310 - 00:41:12.900, Speaker C: Good question. Hopefully by the end of the year you can start seeing something or testing something.
00:41:13.430 - 00:41:14.642, Speaker A: Super cool.
00:41:14.776 - 00:41:38.380, Speaker B: Actually, to add to that, if you have a great idea about how AI can enhance smart contract capabilities and potentially serve a use case, we have a type form in our website that you can go in and fill and we could get in touch depending on how competent you are.
00:41:39.470 - 00:41:49.614, Speaker A: So that's for people who have a project and for people to use the platform. But do you plan on having, I don't know, pilots with other ecosystem companies before the end of the year?
00:41:49.812 - 00:42:51.360, Speaker B: Yeah, actually this is our roadmap for this year is to prove the utility of aipowered smart contracts. And the way we're going to do that is to establish high value partnership with industry leaders, ecosystem leaders in various fields like gaming, DeFi, arts, DSI and so on, to work on proving those particular verticals. So again, if anyone has. We are very much open to contributors because it is impossible for us to prove every possible use case. So what we will do is to matchmake these use cases with partners and the grants that they are able to allocate towards this direction with the contributors. So if you reach out to us and if you're passionate about bridging these two worlds, then we can possibly find a way to get you a grant or something.
00:42:51.970 - 00:42:52.910, Speaker A: Wonderful.
00:42:54.050 - 00:43:03.350, Speaker C: Also is open source. So we are very open to these contributors to build models. Right now in Krawan, you can actually build them.
00:43:03.500 - 00:43:09.000, Speaker A: Super cool. All right, well, gentlemen, thank you for your time.
00:43:09.610 - 00:43:10.758, Speaker C: Thank you so much.
00:43:10.924 - 00:43:12.070, Speaker A: I'll see you soon.
00:43:12.220 - 00:43:13.140, Speaker B: Thank you for having us.

00:00:05.060 - 00:00:22.920, Speaker A: So next up, I want to invite Joey Krug to the stage from Augur to speak about sort of the other side of Dexes, a very important component that's oracles. This is going to be an overview of the importance of oracles, the challenges they face, their history, and, yeah, I'm very excited to hear about this. Welcome to the stage, Joey.
00:00:26.220 - 00:01:27.596, Speaker B: Thanks for having. So this is the first talk that's not really too much about Dexs, although it's still a little bit about Dexs. So we're going to go over what an oracle is, the history of Oracle's kind of current approaches, and what the future of the Oracle landscape looks like. So it's not the oracle of Omaha. It's the problem of how do you get real world data into the blockchain in a secure way? So how do you know that the weather in San Francisco is 72 degrees and that somebody didn't just make that up and submit it on chain? And so if you look at why are these useful? My favorite use case is prediction markets. They're betting markets on kind of future events. Other use cases are for margin calls in various decentralized trading apps, things like derivatives, things like DyDX, Makerdao, cdps.
00:01:27.596 - 00:02:02.060, Speaker B: They're liquidated based on the price of ether, which, of course, comes from an oracle. And so pretty much almost all the main defi apps use or touch oracles in some way. Even if you're not using them directly, you're probably built on top of somebody who is. So it's a pretty huge thing in the space. It's also a huge systemic risk because it's probably one of the most for most apps in the space right now. It's probably one of the most centralized areas in crypto. So the kind of history with them started with really three projects.
00:02:02.060 - 00:02:47.320, Speaker B: The first one is very classic trusted third party. So a person named Edmund Egger in 2014 came up with this idea called reality keys. Basically, the idea is you sign a message with a private key and then on chain you verify the message. These face lots of problems. They can be easily bribed, hacked, you can pay them to be dishonest, you can coerce them or force them to report something. And it has kind of all the same problems any traditional trusted third party would face. The next one was also in 2014, when Vitalik published a kind of off the cuff blog post for this idea called shellingcoin.
00:02:47.320 - 00:03:23.668, Speaker B: It was really just one of those initial use cases for Ethereum, kind of like a thing with some sample code written in serpent to get people excited about what you could do with Ethereum. And the idea for shellingcoin is basically, you ask a bunch of people a question. An example might be how many inches of rain fell in a certain location. And basically everybody submits a value, and anyone within a certain percentile range gets a reward. He called these tokens shells, hence the name shellingcoin. And by default, this system has no staking mechanism. So kind of out of the box, it doesn't really have a civil prevention mechanism.
00:03:23.668 - 00:04:14.490, Speaker B: And even if you add one, basically what ends up happening is the richest actors determine the truth, and successfully lying kind of costs the attacker nothing. Because the system is reward based. There's no slashing conditions, no punishment for bad behavior. So somebody else basically published a different idea around the same time called truthcoin. And for this idea, the idea is you basically ask a bunch of people the same question, and you ask them a bunch of other questions as well. Then using principal component analysis, you basically bifurcate people into truth tellers and liars based on a big covariance matrix created from users in the events that they voted on. So you might have, like, a row being an individual user and the columns being specific events that they voted on and the values being what their vote was.
00:04:14.490 - 00:05:01.860, Speaker B: And so by default, the system has a staking mechanism built in, and there's different branches. And the idea is that if you have a question about, say, politics, it might go in the politics branch. If you have a question about sports, it goes in the sports branch. If you have a question about ether prices, maybe it goes in the crypto prices branch, and so on and so forth. The problem is, without branches, the system doesn't scale, because everyone has to report on everything. With branches, the system essentially slices the security model by a factor of n, because each branch is its sort of own universe. And so you can envision that if there's some asset that you're staking and the asset is different for each individual branch, you're basically decreasing the security model by splitting it up across these different universes.
00:05:01.860 - 00:05:47.750, Speaker B: Has some other problems, too, like principal component analysis, turns out, actually isn't the most effective way to kind of distinguish between people who are being honest or reporting with the consensus and people who aren't. Simple clustering algorithms perform better. They're cheaper and easier to understand. But the other big problem is that it's vulnerable to a bribing attack called the p plus epsilon attack. And this was published by Vitalik, I think, in 2014 or 2015. And the idea is basically that you can promise people that if they're dishonest, say you'll lose $100 for being dishonest. You can promise them that if you force them to report something inaccurate, you'll say, I'll pay you $100.
00:05:47.750 - 00:06:29.710, Speaker B: And in the case where that inaccurate vote wins, I'll just pay you a small amount extra profit. And so your financial incentive is basically to be dishonest, because worst case scenario, you make a small profit and make up for whatever loss you would have made. Best case scenario, you get your money back plus a small profit. And so that's why it's called a p plus epsilon attack. And the only way to really combat this is to add forking to the system where you kind of split the network into multiple universes. You can envision one universe said ten inches of rain fell, another universe said eleven inches fell. And so if you look at current approaches to the oracle problem, there's a bunch of them.
00:06:29.710 - 00:07:05.530, Speaker B: They generally kind of fall in a few different buckets. So there's things like oracle lies and various variants of that. These are systems where you're generally trusting some m of n set of parties that kind of differ in various ways. Second one is something called TLSN. It's something that nobody actually uses, but it's interesting, so we'll go over it briefly. Trusted hardware is another category where you're basically running stuff on things like intel trusted hardware modules. The next is like shelling coin, but souped up a little bit.
00:07:05.530 - 00:07:41.344, Speaker B: Then you have something called Claros Auger uniswap. And then there's two others that we'll go over briefly at the end. One of them actually just published a paper like a week ago, which is pretty exciting, and we'll talk about that briefly as well. So subjective accracy is this idea. It's also published by Edmund Egger, who came up with the first kind of trusted third party oracle mechanism. And this idea is, you know, will it rain in San Francisco? And you have no explicit oracles. Instead, what happens is after the event, there's two universes.
00:07:41.344 - 00:08:36.360, Speaker B: Yes, it rained, and no, it didn't. And so you can envision, say, you had a betting market on this, where there's like yes and no outcome shares. Afterwards people have yes shares, and people have no shares. And after the event happens, his theory is people should just value the one that actually occurred more so if it did rain, the idea is that people would be willing to pay roughly one ether or one die or whatever for the guest universe. Shares. The problem is it's a great idea in theory, but it would be a mess to deal with in practice. Nobody wants to denominate future defi products in things like did it rain in San Francisco? And then you would have this long chain of events where you might have to check the history of did it rain in San Francisco? Did it rain in Houston? What was the closing price of Apple on last Tuesday? And you would have to do this to kind of figure out the chain of custody for your money.
00:08:36.360 - 00:09:41.870, Speaker B: So it's kind of like a nice economist idea, but it doesn't really work in practice because nobody would actually do this in consensus terms. It lacks finality. The next one is TLS notary, which is an idea that sounds good, but it's not actually that good. So the idea is there's a system called TLS notary where in theory you can basically do like an SSL handshake with the website and form a proof that you got data from that site. The problem is that the person who created the proof can be malicious and they can provide an incorrect proof, and so it's not really very useful in practice. Other problem with it is it uses tls one point one or lower, MD five and Shaw one, all of which have various pretty serious security issues with them. So it's another one of those things that might work for small amounts of money, but you probably shouldn't trust it to secure millions of dollars.
00:09:41.870 - 00:10:44.366, Speaker B: TLSN, not to be confused with TLS notary, is very similar, except it allows you to provide a proof to someone else and they can check it and verify it. And there's not really a way for you to maliciously modify the proof. So if a site is running a TLSN server, you can basically get an assurance that I can prove to you that the site gave me a certain result. The problem with this is it requires custom web server that basically nobody runs and that almost nobody's likely to run it. And it only works for things with clear existing APIs that are kind of already on websites that are relatively constant and not changing. So this is the one that's cool idea, but nobody uses trusted hardware is the idea where you take something like Intel SGX and you have that prove that you ran some computation. In this case, it's probably fetching a result from some website or doing something to get the oracle result.
00:10:44.366 - 00:11:17.126, Speaker B: And then you submit that to a smart contract. Smart contract verifies it. Usually what people do is they have SGX basically create a private key within the trusted hardware module and then sign a message with that key. Then the smart contract can just verify the message signature. It's a lot easier than verifying the SGX proof itself. That's kind of a clever hack. The issue with this is intel requires you to get a license or key that they sign with, and they can turn it off at any point.
00:11:17.126 - 00:11:58.714, Speaker B: So it kind of has the classic trusted third party problem. They can also turn it off for legal reasons if you read the terms of service, which is quite likely to happen, in my view, for a lot of the things people are using DFI apps for, especially if they got any kind of sizable scale. If, for instance, there was 100 million in derivatives volume on DyDX on a daily basis, and they started using Intel SGX for their oracle, I think within a year intel's lawyers would stop that. The next approach is basically a souped up version of Shell and coin. So it's basically kind of a beauty contest approach. This comes from John Maynard Keynes. He had this concept called a beauty contest.
00:11:58.714 - 00:12:38.590, Speaker B: It's like an actual economics term. What it means is it's very simple. You're basically just picking what you think other people will pick. So the example is, will it rain in San Francisco? You have people stake some collateral on yes and no, and finality is determined by whichever side has more capital staked. In most of these systems, there's no or limited ability to challenge things afterwards. There's not forking, so there's not really a penalty to being dishonest, assuming you can kind of bulldoze or steamroll your way through getting some sort of outcome. And so the p plus Epsilon attack vulnerability also exists here due to no forking.
00:12:38.590 - 00:13:49.868, Speaker B: Claros is a project, I'm not sure the current status of it, but they're using sort of beauty contest approach with specialization, and trying to figure out if there's ways to create oracles that are subjective. What Auger tries to do is fix problems with the beauty contest approach by basically having an economic bond called rep, where you're posting that as collateral, and traders and market creators in augur are basically paying for insurance that the markets will resolve correctly. And if you're a reporter, the idea is you get penalized for reporting inaccurately. And so if you report honestly, you get trading fees and any rep from dishonest or inaccurate reporters. If you don't report, you don't get any fees. One of the main innovations of auger is it doesn't require splitting security into end slices like truthcoin. And the way how is it switches from a model of reporting on everything to disputing? So you can envision a question like, will it rain in San Francisco? You have a first report where it could just be a centralized person just throws a report on the market and says yes or no.
00:13:49.868 - 00:14:37.040, Speaker B: And then there's n number of rounds of disputing where people successively stake higher and higher amounts of collateral on either side. Eventually, if it disputes a bunch and a large amount of the rep supply is locked up in a specific market, then the network can actually fork into different universes. So you can envision that there's a universe. If the market became very contentious over rain, you can envision a universe where yes, it rained, another universe where no, it didn't. That's just a diagram, basically of what I just said. And so if you look at Olgar, the reason it has a separate token is the main reason is forking. That's kind of the only technical reason why it needs one is if the network forks into multiple universes.
00:14:37.040 - 00:15:25.036, Speaker B: You need the ability to basically have supply exist in multiple universes. And so you can't get that assurance from forking, say Ethereum. You could, if you can convince the entire Ethereum network to fork over your dap that I think that's unlikely these days. And so the way the kind of incentives work out is if you're dishonest, the forks that you voted for should have a lower value kind of going forward in the marketplace. The idea being that people are not going to want to use a system that doesn't reflect reality. So markets in that system would be created less frequently, and the market should kind of value that set of reputation lower than in a system that actually reflects reality. The other piece is with forking, it kind of forces the whole network to participate.
00:15:25.036 - 00:16:07.344, Speaker B: So you don't just have a tiny subset of the network. In a system like auger, everyone's required to participate in a fork. If you don't, you actually lose your rev collateral. And so if you think about how to reason about security of oracles, the simplest kind of naive model is to assume that the value of things backed by an oracle, the value of the assets that you're staking, should be worth more than the assets you're securing. So if you have a million dollars staked to secure some network, there should be less than that in collateral that you're securing. In practice, there's a few tax factors that mean that it should actually be a few times higher. That's kind of a longer conversation.
00:16:07.344 - 00:16:48.940, Speaker B: The auger white paper goes into details why, and there's kind of a derivation for why that's the case. But the punchline is you need to compensate Oracle's appropriately such that the stake is worth enough to make it worth actually using and participating. Otherwise the security model falls apart. And I would say today in the space, almost nobody's actually doing this. Most people are just kind of hand waving the problem and having one oracle that's centralized or an MFN multi sig sec secure their entire network. I think at some point there's going to be some attacks there where that starts to fall apart. One big open question in the oracle space is parasitism.
00:16:48.940 - 00:17:41.280, Speaker B: So the idea is if you have an oracle result, say it's for the rain market, what prevents somebody else from just using that result? Embedding a bunch of money on like a side market and not paying the oracle. And that's a really big tax factor that nobody really has a good solution to. There's some incentive not to be too parasitic. You don't want to kill the host in the sense that you don't want to attack a system so much that the result actually ends up being incorrect because you're basically going to lose capital yourself. But it's still a pretty major problem that nobody's really quite cracked. But I would say the first step for oracles is right now, most systems aren't secure against even known collateral. So meaning if there is $100 million in compound that oracle is probably not secure for that number.
00:17:41.280 - 00:18:24.424, Speaker B: And so the first step would be making it secure for that. Maybe later on people can try to figure out ways to solve the parasite problem. And so if you look at the kind of future of oracles, the first step is to at Auger, we're actually going to publish a paper pretty soon that formalizes our oracle framework into a more generalized framework that can be used for more than just prediction markets. Another area of research is research on how do you create oracles on subjective things, things where there's not a clear right answer. I'm not sure if that's actually possible, but it's an interesting area to look into. And then the last two are kind of new oracle systems. One is uniswap style price feeds.
00:18:24.424 - 00:19:02.156, Speaker B: So this is where you take like Uniswap trading history and you use that to create some sort of a price feed. Now, that's not really useful for short term things if you're trying to get the price of an asset over an hour. I wouldn't trust uniswap for it. But if you're trying to get the price of an asset maybe over a week or maybe even 24 hours, it's more feasible. I think. I think the better way to do that is using a t wop instead of a VWAP. So, time weighted average price, meaning that the price is sitting at $10 for some asset, and it sits at that for 6 hours, it's probably a pretty good sign that the asset is actually worth that.
00:19:02.156 - 00:19:47.304, Speaker B: Otherwise somebody would have arbitraged it. But if you're doing it based on volume, that's a number that's very easy to manipulate. And then the second one is this thing that came out about a week ago. It's called deco. It's a decentralized oracle, similar to sort of the TLS notary family, but it solves a lot of the main problems with them, where you don't have to trust the proof author and you also don't have to run specialized software on the server. So it should work with basically any website, and you can prove to somebody that you got a result from that site and that you didn't modify it or tamper with it. And that's a paper that just came out a week ago.
00:19:47.304 - 00:20:28.250, Speaker B: You can find it on archive.org. And I think that's pretty cool. It uses some sort of zero knowledge proofs to do that. Then the last is, if you look at kind of like Starquare in particular, they could use their tech to create decentralized oracles for in particular on chain data. So if you envision taking a bunch of trade data from a decentralized exchange and using that to create a proof that the VWAP or the TWAP price over a certain time window was x, and creating that very succinctly, I think is an interesting use case for oracles as well. And that's it. If there's any questions, feel free to ask.
00:20:32.380 - 00:20:37.484, Speaker A: So yeah, if there's any questions, just go over to that mic and ask there.
00:20:37.682 - 00:21:19.110, Speaker C: Hi, you mentioned on the last slide about subjectivity versus objectivity. We've seen with Auger that there does exist a gray area kind of between those where the answer is objective, but based on the nuance of the language of how the question was asked, that can create a misunderstanding. I'm curious to hear what aspects or updates of the auger platform that you feel will address that or improve the clarity? Or if not, do you think it's sufficient just with the current process and that this is something that the market will naturally evolve on its own?
00:21:19.480 - 00:22:16.392, Speaker B: Yeah, it's a good question. I think it's something that people need a little guidance in terms of how to actually solve that problem. I think one way to start to address it is to add things like multiple sources for a market. So if you have a market on, say something like a sporting match outcome, sport event outcome, it would make sense to include maybe three sources for that and take the mode of them or something like that. That's like one simple approach towards solving that problem for context. The problem is people might make a market on, say a soccer match and say that the result should be available on ESPN at midnight, and then ESPN doesn't post the result until 03:00 a.m. What do you do? And that's the sort of problem where if you're building a system that's relatively deterministic, you can't really just say, well, we can just wait till 03:00 a.m.
00:22:16.392 - 00:22:54.890, Speaker B: Because then people who staked on something at midnight are going to lose their capital even though they reported what they actually thought the accurate result was. And so I think the answer is kind of redundancy. It also adding more clarification and wording to markets and questions to make them more specific. And then the last one is in v two of auger. From the trader perspective, people will be able to basically bet on whether they think a market is invalid ahead of time. So from the user standpoint, you can effectively kind of by default hide markets where there's a high probability of it being invalid ahead of time.
00:22:56.700 - 00:23:32.836, Speaker D: Hi. I really like your talk. Thank you. I have a couple of questions. First of all, you talked about tls, and twice at the beginning you talked about TLS, and then in the end you said something about tls and snarks. Right? So what is the problem with TLS? For example, if I can settle market with a SSL signed message from CNN.com, so what would be the vulnerabilities with this kind of settlement? And can you explain? I just missed the second thing.
00:23:32.836 - 00:23:58.750, Speaker D: You talked about tls with snarks. And the last question is about SGax. So if I have SGX on the processor, where's the inputs going to come from? What do you mean by SGX? The code runs on SGX, but if I'm collecting them out of rain that went on some certain day, then I need some external sensor, right?
00:23:59.440 - 00:24:32.900, Speaker B: Yeah. So I guess the first one is the SGX question. And the way that works is basically, you basically write code that fetches a result from a website and you run that all in the trusted compute module. And then within SGX you basically sign a message that you then broadcast on chain and so on chain. You can verify that according to SGX, it did a HTP request to some website, got some result a and that's what you have on chain.
00:24:33.960 - 00:24:38.730, Speaker D: Then you could just send the original message. Why do you need the SGX component of it?
00:24:40.620 - 00:24:46.330, Speaker B: Because if you just send the message from the site, there's no way to verify that you actually got it from that website.
00:24:46.800 - 00:24:48.248, Speaker D: The SSL certificate.
00:24:48.344 - 00:25:26.490, Speaker B: Yeah. So this gets to your first question about SSL. And so the reason that's the case is the way the SSL handshake works. You can't just by default out of the box prove to somebody that you got a piece of data from a website. There's basically a few vulnerabilities there that make it actually difficult to do that. It's really easy to fake a piece of data when you're doing that. And so the solution to that is, the final solution that I mentioned to that is this thing called deco, where you're basically creating a zero knowledge proof that you got the data from a website.
00:25:26.490 - 00:25:51.360, Speaker B: And so you can basically prove that on your machine. You use an HTPS request, did an SSL handshake, got the result from the site, didn't modify it, and then you broadcast that thing on chain and you can prove it. That's kind of how you would actually do it in practice. But the punchline is you can't just take a regular SSL handshake and send that on chain.
00:25:51.940 - 00:25:53.090, Speaker D: Okay, thanks.
00:25:56.100 - 00:26:56.372, Speaker E: Hey, thanks for the talk. As formulated in this presentation, it sounds like the Oracle problem is mostly reasoning about abstract economic costs of lying, independent of any sort of physical connection between what's happening on the chain and what the data the oracle is reasoning about. But it seems like ultimately there are also physical security assumptions. So even if you have some sort of tokenized oracle, people hold those tokens with keys. And I'm wondering if you know of any approaches which are actually just trying to create a direct physical connection by, for example, having in the San Francisco rain question lots of tiny, tiny raspberry pis scattered around San Francisco with individual keys which are registered somewhere, constructed such that although it might, independent of questions of whether you could ever pay for that, it would be very hard, with little notice, to go to all the raspberry pis, take them over and control the answer to the question, does that make sense?
00:26:56.506 - 00:27:37.170, Speaker B: Yeah, that makes sense. I haven't heard of anybody doing that? Mostly because the decentralized application space is in such an experimentation phase. There's not like anything where people are regularly speculating large amounts of capital with a specific oracle result that's not in the virtual world. Like the only examples today in the DeFi space where you might want to have a recurring oracle feed would be things like what's the price of ether? Or something like that. Nothing's taken off yet where you could get the result in the physical world like that. I think if there were, for instance, billions traded on weather futures on top of Ethereum, maybe that's something people would start to look into.
00:27:37.860 - 00:28:06.860, Speaker E: And a second related question, since no one else has come up yet, are there any attempts to enforce, although it seems like a very hard problem, but a sort of logical structure or consistency between answers in oracles? So reasoning not only about reputations of particular reporters or whatever on questions treated in the abstract, but on questions treated in the concrete. Like if you said yes to this logical implication, you must also accept this one, or it's inconsistent.
00:28:07.840 - 00:28:47.480, Speaker B: People have done stuff like that in the way that they've phrased a question to an oracle. Nobody's created an oracle system that has that baked in at the protocol layer, though, in general, if you look at Auger in particular, the way people create questions is they actually specify the possible outcomes ahead of time, which can run into error if you don't think of all of them ahead of time. But it's a way to force a sort of logical consistency. But there are some where people know created logic questions like the ones you mentioned and phrased that as part of the question to the oracle network.
00:28:47.820 - 00:28:48.570, Speaker E: Thanks.
00:28:50.700 - 00:29:17.440, Speaker F: Thanks for your talk. I want to ask regarding the subjective approach and the usage of the ability to fork as part of the incentive model. Isn't there a risk that the more users you have of the oracle, more application using it, and then other applications relying on that, applications that eventually the cost of forking relies on other factors, not necessarily the correct answer of the oracle.
00:29:19.220 - 00:29:22.580, Speaker B: Meaning like it's too expensive to fork or what do you mean exactly?
00:29:22.650 - 00:29:34.968, Speaker F: Or there are now other factors, factors related to the applications that use the oracle, which may be okay with a wrong answer because the cost of forking for them will be much higher.
00:29:35.134 - 00:30:26.630, Speaker B: Oh yeah, I see what you're saying. So the way the kind of incentive game is structured is it's less about the application that's using it and more about whether you've staked some valuable asset on one of the outcomes. And so if you look at Auger in particular. There's actually empirical data for this. The most disputed market on Auger had very little trading volume, and some of the most traded markets have almost no disputes. And so there's not like a huge correlation between what demand there is from an application and what people will take seriously from an oracle standpoint. And I think the main reason for that is if you look at Auger, the way it's structured due to these dispute games, it's more about what you as a reporter think the right answer is than what specific application is doing with that answer.
00:30:26.630 - 00:30:28.804, Speaker B: Thanks. Cool.
00:30:28.922 - 00:30:32.450, Speaker A: So thank you so much for your talk. Yeah, let's give a hand.

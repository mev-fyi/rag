00:00:03.600 - 00:00:17.236, Speaker A: Welcome to my talk. My name is Laolu Shiroku. I'm co founder and CTO of Lightning Labs, working on bitcoin for, I guess, maybe eight or so years, something like nine, you know, lightning for like seven or so of those as well too, working on some new things called Tara. Get into a little bit later in the talk as well.
00:00:17.258 - 00:00:17.396, Speaker B: Right?
00:00:17.418 - 00:00:32.156, Speaker A: So the title of my talk is basically starts on bitcoin, right? So kind of like exactly what it looked like to actually get starts on bitcoin itself. You know, how do we do it? You know, what's the kind of path to gain mindshare? How do we actually develop the technology itself to actually get on the OG blockchain itself? And also maybe even where a lot of these stuff was actually, how about applies in the first place?
00:00:32.178 - 00:00:32.364, Speaker B: Right?
00:00:32.402 - 00:01:11.536, Speaker A: Because remember, Eli's talk in the beginning, you talked about kind of like his talk in 2013 or so, which is actually at a bitcoin conference. And now this kind of full circle back to, okay, well, how do you actually get this back to where it was kind of like inspired by individuals to get things going? So first, talk about why starks in bitcoin. Kind of like, why do you think it's a good idea itself? I'll kind of COVID what I talk as far. Kind of like a multipronged kind of ecosystem integration approach as far as getting mindshare and kind of like get metroids and technology first talk about kind of like have the Starks application, the bitcoin PHP network itself, kind of like things like instance sync and also kind of like Blackhead or sync lite clients on the full node as well. Introduce you something called Taro. So this new thing we're working on in Lightning labs kind of like ways get weights, like represent assets on top of bitcoin, then also actually even send them on top of the lightning network as well to work on mass and collectibles. And then I'll talk about ZK.
00:01:11.536 - 00:01:25.736, Speaker A: Taro is kind of like the bigger thing than the talk as far as integration starks into Tara itself as a way to actually get sort of more hexagons and sarks themselves, and also kind of have a software dry run with the way that target works. And I'll get into that a little bit later. So first, why starks on bitcoin?
00:01:25.768 - 00:01:25.916, Speaker B: Right.
00:01:25.938 - 00:01:53.844, Speaker A: I probably don't even need to explain to you all the benefits, but obviously privacy, because today the entire graph is fully public, right? You basically have all the values, you have all the distraction graph as well, too. And that's not really that great of a thing, right. There's something called competitive transaction, which is deployed into something like liquid, but that only really gives you input and output value amounts that are hidden, right. You don't really actually get the entire transactional graph, because at that point you basically still have a lot of what's going on. You can see who's sending to who, but you don't necessarily see things like the value themselves, right. Which still a lot of is actually being leaked out. You also get information like compressing the transaction graph as well.
00:01:53.844 - 00:02:19.864, Speaker A: Because now on this point, you don't necessarily need to basically pull the entire thing. You can have a sort of like a snapshot of the transaction graph itself, which obviously is really good. One of the big things, obviously scalability, right? So one of the great things about structs, you basically get this sort of like amortization as far as getting more bytes, get more transactions in a given byte, right. It can have, maybe the proof is like 200. So, but that's maybe like a million transactions together. That's obviously a big thing, right? That's always like the main motivation of the light network itself. As far as doing something off chain to actually get more transactions with a given byte.
00:02:19.864 - 00:02:48.656, Speaker A: I can have a channel open. Maybe it's been open for three or four years. Maybe I've done thousand transactions in that. But that closes on chain. No, really, nobody really knows about that, right. Obviously the big thing there is kind of like logging, scaling as far as getting, having savings in terms of batching, which is obviously good for scalability, efficiency, utilization, so forth, things like that as well too. And I think one other thing I remember in the past when things like structure come up, people were like, okay, well, these very large things on chain, can we actually handle that in the bitcoin blockchain network itself? I think one thing most people don't realize, most bitcoin transactions are actually somewhat large now, particularly when you have things like multi sig, you have SAP script, you have things that are doing things like measuring multiple inputs.
00:02:48.656 - 00:03:24.932, Speaker A: For example, if you click on this one, I probably should have CXID. This is the bitcoin transaction has like 200 inputs, which is basically something like consolidation. It's actually six about kilobytes, which is like somewhat big, right. I think in the past we're like, oh, bitcoin transactions like 200, 300 bytes, but not anymore. So you actually have a lot more things on chain. But the main thing is, okay, well, can we use those 65 kb, basically have more and more transactions in the chain itself, can we actually impact these things and get more scalability that way as well? And obviously one thing as well is basically transparency, right? And one thing is in the past, like things like Sox came out back in the day and people were like, oh my God, the CRS, or I guess what they call the SRS now. That's trust set up, right? That's basically like a bad word in the current land, right? But these structure, great, because you have that transparency and you don't actually need the trusted setup capability itself.
00:03:24.932 - 00:03:41.812, Speaker A: And I think there are a lot more kind of understandable and other things like some of the pairing based protocols that get a little bit more in the moon Matthew territory and so forth. So that's kind of like a motivation as far as why do this stuff in the first place. I've been thinking about this for a bit of time. In terms why exactly have we not really seen that much activity amongst booker developers in the space itself?
00:03:41.866 - 00:03:42.084, Speaker B: Right.
00:03:42.122 - 00:03:57.404, Speaker A: I think part of it is a little bit kind of like them not really, maybe keeping up with the, the metro things like tangible technologies like my Cairo and stocks and things like that as well too. I think another part of it is that maybe they'ren't really sure if these things are ready or not yet. Maybe they have a metric model, but maybe it's been the past like seven years or so. We haven't really keeping up with a lot of the new changes.
00:03:57.442 - 00:03:57.596, Speaker B: Right.
00:03:57.618 - 00:04:14.132, Speaker A: So the question is, okay, do we think it's ready right now? Basically go into bitcoin next? Let's say we had handwave softworks, whatever else, we can do this right now? I would say probably not, right, but I think that's okay. But I think the main thing is basically to allow you to keep up with a lot of the innovation, basically so we can get more mind share, we can get more practice. We can also actually see exactly how these technologies can be integrated in the future itself.
00:04:14.186 - 00:04:14.404, Speaker B: Right.
00:04:14.442 - 00:04:41.956, Speaker A: So with questions like how can we do this stuff as far as building sitement and getting more practical hands on experience in the system itself, I would say kind of go from the outside in. So basically don't start directly at the, don't, don't start doing the software to basically change the court of know. Can we actually do things on the outside? So can we do things like the PDP network, higher layers like lightning things like taro stuff that also overlay on top of the system itself and then get more experience? These sort of like bitcoin applications to then eventually kind of actually map onto the stark realm in some eventual software hand wave some sort of way basically.
00:04:41.998 - 00:04:42.156, Speaker B: Right?
00:04:42.178 - 00:05:03.652, Speaker A: But I think the main thing right now is I think there's kind of like a gap between the current maturation of the technology versus people's perception of it. And I think this talks about kind of like closing that gap and also getting people excited. Some restaurants happen in real life. First one thing is basically like lines, right? So people know, like on bitcoin you basically don't want the headers. And this is objective because you can actually check all the power on the headers I think is great for some like that, right? And there's really cool project called Zero Sync. You don't know about it. Definitely check it out.
00:05:03.652 - 00:05:43.292, Speaker A: I'm putting on my contributor hat. Usually I'm the one making projects and dragging people, but obviously going to be contributor zero sync, which is really cool. And basically what they're trying to do, they're trying to actually use Stark and Kyo to actually give you sort of like instant sync on the bitcoin network itself, right? So one flavor is something like client to basically download all the header state and catch up with the chain tip. Effectively instantly, right? And the main thing here is you're actually verifying what's effectively like a very long hash chain, right? From Genesis all the way to this initial block, everything points back to the previous header. Previous header has the correct pow, which means verify very quickly. Does difficult adjustments to afford things like that as well too, right? And the main state function here you basically have like the header n minus one, which the genesis header, the next header. And they say, okay, well, applying these two together, we can then move forward to the next header itself.
00:05:43.292 - 00:06:03.092, Speaker A: And this is a really cool thing because you can actually then compress the entire, you can say just like at least pow. Like client verification state, something that's very, very small. All right. And the other cool thing about bitcoin itself, like headers are actually only 80 bytes or so. So all the entire headers over the past ten plus years of bitcoin, it's only 60 megabytes. It's not really that much data that actually needs downloads to get things going, which is pretty cool, right? So this is something that you can do. You say, okay, well, I don't start proof itself.
00:06:03.092 - 00:06:35.288, Speaker A: I get like that last header and also Genesis block and I can just start to join the PWP network and then do so immediately. But obviously you still want to get all the power headers because you still want to do things like maybe explicit merkle proof verification for something like that itself. This at least lets you catch the network and move forward a lot more quickly. Other cool things in this direction are something called ln channel graph bootstrap. So I'm not going to explain. Ln is a high level, basically, you basically have this sort of like authenticated data structure, which is like the graph of all the channels in the network itself, right? And one thing people today, they always explicitly verify, okay, well, this thing was actually in a block. And they do that either via Merkel proof something in the future working on itself, or they maybe just have a TXX basically look the proof of directly within that itself magic.
00:06:35.288 - 00:07:11.756, Speaker A: You can instead download basically like a state route of the LN graph as presented by an individual with the ability proof that every single item in this state root itself is that there's valid transaction itself. Then at this point you can then go and just download the individual channels basically and the proof about the channels along with the market inclusion proof, or actually download the entire blob as well and then verify everything matches up there as well too. And there's also some other kind of like applications to things like bit 150, which is a way you can do like clients on bitcoin. But I'm not going to get into that right now. Another really cool application would basically be a cyber intransic it in stuff for full nodes as well too. So the prior thing I just talked about is basically for light clients. In that situation, you're only verifying the header proof, which is basically a pal thing, right.
00:07:11.756 - 00:07:19.916, Speaker A: You're not actually verifying the validity of any of the chain transitions, which is actually things spending something in the usexo set itself. And also the LV, every single input is actually valid as well too.
00:07:19.938 - 00:07:20.124, Speaker B: Right?
00:07:20.162 - 00:08:02.972, Speaker A: But this is basically another type of, you can say proof that you can do. You can basically start with this chain state, get the new block and then say, okay, then we're going to the next chain state, right? And what you see on the top right here, this is actually some code from zerosync. This is written in Kyrue zero. And the main thing is you basically have the chain state, which is obviously the block height, the pal things like that as well too. But the cool thing is they have something called a utrexo root, right? And what Utrexo is basically like a commitment over the Ugxo state for bitcoin, right? It was designed basically to sort of have some very elegant structures as far as the way proof scale over time, things like that. But at a high level, it's basically like a forest of complete binary merkel trees, basically, right? So rather than have one single proof, you have a bunch of these proofs together, or you have a bunch of these trees together other, and you can do things as far as kind of merging them and moving them over to basically do things like optimize for kind of the access pattern utxos, which is that utxos typically die young.
00:08:03.026 - 00:08:03.388, Speaker B: Right?
00:08:03.474 - 00:08:26.004, Speaker A: And one other thing, this is really helpful because now every single time you're accepting a new proof or new state transition, you don't need to say okay, we're verifying. Look up in this five gigabyte plus data set, basically the next Utxo to make sure it's unspent. Instead, every single block actually has an inclusion proof into the Utxo set, basically. So it's proving that it was actually prior and unspent output. And this lets you do things a lot more efficiently. And the cool thing about this, let's say you basically have something approved like this. You have the next header state, then also the Utrechto route, right.
00:08:26.004 - 00:09:22.164, Speaker A: At that point you can actually start validating the next block instantly the next block as soon as it's available. Because every single block actually contain inclusion proofs into the Utxo commitment itself, you don't necessarily need the entire Utxo set, right? And the big innovation, something at Utrexo, is that full nodes don't need to maintain the Utxo set once they have the root of it. And you can actually do things like whenever you verify the inclusion, you can also efficiently do a deletion from the UX side as well too. So now rather than dealing with some, like in the future 100 terabyte Utxo state, you basically trade off bandwidth of the inclusion proofs for your own memory and thing itself, which is really cool, right? And so one other thing with this is that ultimately do something like this basically, which is like an incremental stark proof over the entire chain history itself actually. Then need something to be written more in Kyra, right? So eventually you basically need bitcoin script itself to actually be written in Kyra, right? So the way your sync works today, it's able to do blockchain due to header validity. It's able to do Merkle tree inclusion things are transactionalization things like that as well too. But it's really missing kind of like the actual input validation being okay, well op checks verify things like that as well too.
00:09:22.164 - 00:09:38.110, Speaker A: In order to get to that realm, you actually need mostly a complete bitcoin script implementation in Cairo, which is something that I think is definitely feasible. We've written about the language. I work on something called BCD, which is actually a bitcoin implementation in go as well too. I think that'd be a really cool project, something that hasn't really kicked off yet, but I think we can starting to get more activity in that area as we go.
00:09:38.720 - 00:09:39.084, Speaker B: Cool.
00:09:39.122 - 00:09:50.568, Speaker A: So that was just kind of the PDP stuff, right? So we talked about like clients talked about full nodes, how we can actually get things like instance sync and also use that itself to actually prove out Cairo and then also get developers more excited about things that they can do in tangible manner.
00:09:50.584 - 00:09:50.716, Speaker B: Right.
00:09:50.738 - 00:10:12.164, Speaker A: So I'm going to talk about something called Taro. So what's Taro? Taro is something that we announced. I think it was bitcoin Miami last year or so. We're working on development right now. The next version is two, which is coming out in like a month or so. But what it is, it's basically like a way to actually represent assets on top of bitcoin itself, right? So rather than do something like maybe people are familiar with things like counterparty, whatever else, they have opportunities. Basically you sort of need to scan the entire chain or to actually know what the current state of the assets is.
00:10:12.164 - 00:10:52.368, Speaker A: Instead, you basically have sort of like proof providence for every single asset itself, right? So the asset is basically a proof that asset was created at one point in the past, basically. And every single transaction beyond actually follow the rules of the system properly, basically, right? So once again, you kind of like have the station function, you have the asset, then basically witness, then you have a new asset, basically you can verify that over and over again, right? So one of the worst questions coming up is like, okay, well, how do you actually have unique asset ids in the system like bitcoin, right? Because you don't really have a global address space or contract has anything like that itself. But turn out there's something called BiP 34, which basically ensures that Coinbase outputs are always unique within the chain itself. So something happened, man. I think it was like 2011 or so. There's actually a duplicate coinbase output. It actually overwrote the entry in Google databases which were like, oh, basically you need to make sure these are always unique, but you make them unique.
00:10:52.368 - 00:11:00.484, Speaker A: You basically put the block height of the block header itself in the coinbase output to make sure you actually have something that can never repeat from the point of view. Of the canonical chain itself.
00:11:00.522 - 00:11:00.724, Speaker B: Right?
00:11:00.762 - 00:11:38.204, Speaker A: So what we do, we can basically leverage that. We just have something called the Genesis outpoint, which is basically the first input in the transaction that's actually minting, basically that's creating this new asset itself. And you basically have some other data. You have the outpoint, the tag, which is basically the name, the hash of the meta, which is like, that can be like a pdf or a latex file, have like image or something like that itself, an alpine index, and then asset type itself, right. And this basically lets you have a sort of unique asset id within the system itself. There's some other details around, kind of like the tree structure we use. It's called like a merkel, some sparse merkel tree, which basically combines the ability of a sparse merkel tree with also Merkel sum aspects as well too, meaning that let's say I have a bunch of leaves and I have like five things of five that then adds up to basically 25 in the root itself.
00:11:38.204 - 00:11:53.284, Speaker A: This is really cool because now you can actually validate the supply of something. I can show you that. Okay, well, if I was meant to not commit to an asset any longer, I used to have 25, now I have 20. You can verify that stuff very easily. Has some other cool properties as well too. And this system also supports normal and collectible assets. Collectible assets, what people call nfTs, but that's a really bad name.
00:11:53.284 - 00:12:19.916, Speaker A: So collectible is just much better. You have to explain the acronym of what you're trying to describe to somebody. And one of the really cool thing about the way this works is actually very like client friendly, right? So the issue about some of these other ones, as far as the way things like operate, work, or referrals, in the past, they weren't actually like client friendly because you have to basically scan the chain for every single operator and output because you're actually applying that to your own state machine internally. But something like this, basically I say I have an asset, I give you the proof of the asset. Once again, that's explicit right now. We'll talk about how we can move that in the future. You say, okay, well, this is my asset I can root for, and I can do things like that itself.
00:12:19.916 - 00:12:54.548, Speaker A: And the way it works right now, we actually also have a scripting system within Taro itself, which is actually just another instance of the taproot VM itself. So this is really cool because now, rather than individuals needing to learn some entirely new application paradigm, I have different tooling or different signatures or whatever else, it basically just looks like bitcoin. It's kind of like bitcoin within bitcoin. And that's some other cool properties which can get into in a little bit as well too. And yeah, you can do things like verify the supply of different assets. And you can also do kind of like things like auctions, swaps, batch transactions as well too, because it's all in the bitcoin application model, as we'll see in a second. All right, so I made this on like a 50 inch monitor, but it looks like they can render somewhat.
00:12:54.548 - 00:13:04.168, Speaker A: So this is basically like what tower is, which basically a series, like nested Merkel trees itself, right? So at the very top you have the bitcoin block header, which basically has the merkle written, has the Merkel transaction of all the transactions in the block.
00:13:04.184 - 00:13:04.364, Speaker B: Right.
00:13:04.402 - 00:13:42.112, Speaker A: Then you basically have each of the individual transactions. One thing that taproot did actually, taproot actually added another level of a tree, which is basically a mercury app syntax tree, where you basically have a bunch of different scripts in the leaf, basically. Okay, I'm going to reveal the multi sig script or the premium script, some other script on like that as well too, right? So ask, you say, okay, well, we have the structure, commitment structure. In the place of the tap trip tree, we're going to add another commitment, basically, which is the thing on the right base, which then commits to the tap tree, which is kind of like the root of the tash, basically. Then from that you have a bunch of individual scripts, right? But then within those scripts, we can then also have this tower commitment itself. Right? The top level, it has basically like a version. It has some magic by, so you can detect it easily.
00:13:42.112 - 00:14:21.444, Speaker A: We need to do a bunch of things as far as to make sure everything's actually be unique as well too. And then you actually have the assets themselves and there's two layers of trees. Once again, this is an SMT, so you can view this kind of like a merkelized key value lookup store, right? The first level is basically the asset ids, which is like, once again, this is like beef wherever else. The next level is then like the actual individual utxos, right? So once again, you have utxos that are sort of like deferred in a sense because it's thin like a bitcoin, but actually there's another tree. And then that Utxo itself, asset Utxo, which we call like a TLV particular serialization format, then points to a previous witness, which is another asset. And that's how you verify things today, right? So let's say I was going to prove to you I have something like USDC or something like that in my bitcoin apple itself. I would show you this series of Merkel proofs from the very beginning, from that top level thing.
00:14:21.444 - 00:14:52.556, Speaker A: Then you say, okay, well, everything checks out. Now you have that thing, we can move forward. We can actually have this be this work as is right now. One thing is know, if you look at the way the proofs work today, they're actually explicit proofs, right? So I need to basically show you what, know, three or four levels of merkel tree inclusion proofs, right? Which gets kind of large, particularly once you have either a bunch of assets or a bunch of things in the transaction level itself. So the goal is to say, okay, well, can we actually compress that stuff down basically together to something that's a little bit more smaller and does actually need to grow over time? Because one of the thing with this, and I think it's in the other slides that over time, because you actually need to add a new asset every single time you're doing transactions, this file starts to basically grow over time.
00:14:52.578 - 00:14:52.764, Speaker B: Right.
00:14:52.802 - 00:15:19.972, Speaker A: The thing is, it's nothing going to be larger than the actual bitcoin blockchain because this is basically a subset of the transaction graph in the bitcoin blockchain. But maybe some uses will actually be prohibitive because thing starts to get a little bit too large. And this is basically what proofs look like today. This is like the Taro code. This is basically someone like decoding a proof. And you can see some of the information I talked about just now as far as the asset, the name of the asset, the inclusion proof in the Merkel tree itself, and then also the SMT inclusion proofs. We also need to do exclusion proofs on the top level because, for example, we need to make sure that you're not cloning an asset in this transaction itself.
00:15:19.972 - 00:15:44.510, Speaker A: The way we do that. We say, okay, well, give me an exclusion proof that either this thing cannot commit to an asset because actu needs to be paid your Capricorn. We have also have a canonical commitments group within the tap square tree itself, or it does commit to assets, but not that particular assets that you need as well. That's why you also need the inclusion proofs. And this is basically what a proof looks like today. Like I was saying, it's basically she's inclusion and exclusion proofs and can get kind of large in this setting. Once you have a lot of assets, a lot of coins and they also need to repeat this every single time you're doing a new state transition as well.
00:15:44.510 - 00:16:20.216, Speaker A: As mentioned, this actually has some issues as far as scalability, right? Because if you're looking at something like a collectible, you're basically doing one to one every single time. Over time, the proof size basically starts to grow linearly with the number of fractions that you actually have, right? So it starts out fine in the beginning. Maybe it's like 300 bias. If you kilobas megabytes, once you get to gigabytes, then starts getting a little bit prohibitive as well, right? And the other thing as well, collectibles are a little bit easier because you can actually just do those linearly because you can't actually split them. It's always kind of like a one to one thing, but every time when you have something like normal assets, you then also have inputs and outputs in the setting similar to bitcoin itself, right? So let's say I have two inputs. Well, I inherit basically the history of those two inputs as well too. And then that goes and goes into the genesis asset, similar to Genesis block.
00:16:20.216 - 00:16:53.844, Speaker A: So that can get like large over time, right? But the one thing at least is that in this setting, because all of them are coming from the actual same common ancestor, there is some redundancy. And the proof you can actually reduce over time to make things a little bit better. And I was mentioning a little bit earlier, earlier, this is still bounded by the actual growth of bitcoin chain itself, because this is a subset of transaction graph. So it's not going to grow bigger than bitcoin. And I think today maybe the graph is like 480gb or so, including some of the major indexes as well, right? So that's like one thing here. And one of the things you can do over time is sort of like a way of doing probabilistic validation, right? Verification. So basically, imagine I had all these state transitions where we keep these profiles and I have like a mercury of that itself, right? Similar to something that I think we're all talking about here.
00:16:53.844 - 00:17:17.612, Speaker A: You can then do like samples, okay, rather than me verify these thousand stations, maybe I'll do ten or so or something like that. And I'll do kind of like a random sampling system to basically have some sort of sounded boundness where I can say, okay, well, this thing is fine because I verified enough for them. Solution asset. Let me move on and spend my time elsewhere, right? Another thing you can do, you can actually use another level would basically level of the inputs, right? So imagine if rather than like bitcoin actually having explicit inputs, basically like input 1234 basically had a commitment to all the inputs themselves.
00:17:17.666 - 00:17:17.884, Speaker B: Right?
00:17:17.922 - 00:17:59.656, Speaker A: Now that you have a commitment to the input and also that commitment in the input is also a miracle sump commitment. So it commits over the semi all the input values within the system itself. So you can easily verify the input commitment and the output commitment verify the same value. But then you can then say, okay, well, rather than verifying all the inputs, I'll just do one level here and do the sampling and challenge game again and then keep going like that as well. So that's kind of like some short term things or midshall long term things that protocol run into some ways you can get around that using various tricks. And so here we are, zk taro, like why do we actually care about this thing? Well, the main thing is basically using recursive starks to actually reduce the proof size to what's effectively something that's more constant and more available to be being distributed and actually used properly, right? You can say there's kind of like levels of station function. One is basically saying, okay, well, the previous asset applied to new witness gives you a new asset.
00:17:59.656 - 00:18:31.024, Speaker A: But then once you repeat that over and over again, you give all the assets to the tree. Then you go on to the level and you say, okay, well here the previous tower and the new tower route basically. And that leads to this new route. Basically you want to say, okay, everything else has been done properly, right? And one other thing here is kind of like two layers to prove itself. The first layer is, okay, well let me prove that this structure commit was actually included in my tap script tree, in the output, in the Merkel tree itself, and then in the header and then so forth, that basically says, okay, well, this thing exists. Then the other thing is basically to verify that, okay, well, the situation was done properly, which is basically saying that there's like a valid asset witness that if you have these particular rules, lets you kind of actually do the spend properly.
00:18:31.072 - 00:18:31.428, Speaker B: Right?
00:18:31.514 - 00:19:07.448, Speaker A: The other thing as well is then you can actually then do that layer for the prior input. So imagine you basically have the initial proof. Well, you'd go backwards or forward, but this is example of backwards. You have the initial proof, you say, okay, well all this stuff is valid, then I'll do that for the prior one and verify the prior one and so forth, basically, right? Then the end result is actually like a single proof basically, which is the asset itself. The proof basically states that there is a transaction on chain that was created, it has an answer from this particular transaction, which actually created the asset itself. You have a few transactions and transfers and all this probably used properly, and you have a sneak state suggestion in which you say, okay, boom, this is my asset, and that's how you're going to go forward. So now we're getting to kind of like the bulk of it, which is exactly how would that actually look like concrete fashion.
00:19:07.464 - 00:19:07.596, Speaker B: Right.
00:19:07.618 - 00:19:30.472, Speaker A: So I think I have three different events, which is first, basically, okay, we'll have kind of first class dark primitives, right? So as I mentioned a little bit earlier, you do have to prove some actuals of bitcoin within this proof itself. You need to prove the header, the merkel tree, the transaction itself, the tap script tree, and things like that as well. So we can't actually change that. What if we can focus on what we can change, right, which is sort of like this commitment. So the commitment has a magic, a version and a tree. Right, but let's say we actually have a different version in the future. That true.
00:19:30.472 - 00:19:55.676, Speaker A: Can actually use more stark friendly primitives, right? Rather than use something like star two, we can use Poseidon tip five, rescue hash, whatever else, and do things that are little, a bit more approval within Starkland, rather than actually inheriting everything else that we have alongside of it itself too, which is really cool. The other thing is, well, you don't necessarily need to keep the tabscript vms we have right now. That could just be the arbitrary chiroproag basically based on the program hash, and then a series of public inputs as well too.
00:19:55.698 - 00:19:55.932, Speaker B: Right?
00:19:55.986 - 00:20:10.464, Speaker A: And the cool thing about this, you can actually then still retain all the other aspects of the system as far as the mounts, the tag field, things like that as well too. But some of those can be all, or some be zero knowledge, or maybe you just really care about the computational integrity part of it to basically show that they think you've been moving forward and everything has been done properly.
00:20:10.512 - 00:20:10.724, Speaker B: Right?
00:20:10.762 - 00:20:35.816, Speaker A: And in this case, the witness. Now, is that, okay, well, everything else was done prior, in the past done correctly, but then also this new state is also done correctly is now as well too. And you can say in bitcoin, you can say the public input is basically just the public key. Let's say you do something like public key optexic, basically. And that's how it is right now. That'd be a similar thing. But then you also want to also specify, okay, well, where am I fitting the coins, the asset to in this case? That can be something that's going to be output from the program itself as a current program output, which is then the public inputs.
00:20:35.816 - 00:20:55.136, Speaker A: That's one way. This basically say, okay, well, fuck it, we don't need to deal with anything else from the bitcoin layer below that can all just be redesigned to basically be a lot more friendly to the proof system itself. And maybe that's a little bit further off, but that's one way you can do it. At least now the other way is, okay, well, let's say, okay, well, Tara self is still a new system. It's not dead. We're still evolving and we're still trying to make sure what's happening. There's not like a final version.
00:20:55.136 - 00:21:04.852, Speaker A: It's also not a mana yet. So I'm testing right now. We made it this year. This is, okay, well, let's just keep everything exactly as it is. Silly young protocol. We're still doing everything right now we're actually just like doing the stark proofs on top of the existing proof itself.
00:21:04.906 - 00:21:05.124, Speaker B: Right.
00:21:05.162 - 00:21:19.212, Speaker A: So what this means is that rather than saying, okay, well, we're going to redesign the entire commitment. We're actually going to prove what we would execute anyway in the stark itself. And as I mentioned a little bit earlier, say the way it works is the actual scripting them within the tarot VM. It's actually an instance of the taproot VM, which is tap script itself.
00:21:19.266 - 00:21:19.484, Speaker B: Right.
00:21:19.522 - 00:21:29.004, Speaker A: So this would mean, once again actually implementing bitcoin script itself in Cairo. And then rather than just saying, okay, well, this is some other return program, we're actually proving proper execution of what would be a bitcoin script itself.
00:21:29.042 - 00:21:29.196, Speaker B: Right.
00:21:29.218 - 00:21:53.280, Speaker A: And the way bitcoin script works, you can say that a program is satisfied. We passes the final execution if there's a single element on the stack left, and that element is 10 one. So we say, okay, well, we have the tapper key, which is like this top level thing exists a tap script commitment in that key, which if you apply to witness to, would lead you to final stack state of zero one. And also this new tap word key as well too. And this is something that's really cool. And like I mentioned, we have this project called Zero Sync. It has all the primitives.
00:21:53.280 - 00:22:24.476, Speaker A: It has like ECSA has shard, two has ripmd. All of them has on Kyo, but doesn't really have all of the existing bitcoin VM and also all the new softworks in 2013 as well, too, right? And something like this, you would eventually also want kind of like Chiro built ins for performance purposes as well too, right? Because you're going to be doing a lot of hashing. You have these different signature operations as well too. And there's probably also some challenges around kind of like representing the stack structure in the immutable environment. But I know that people have a bunch of different things in Chiro one and better syntactic trigger to basically hide some of the immutability from the actual programmer itself. That's one basically. Okay, let's keep it as is.
00:22:24.476 - 00:22:56.650, Speaker A: We'll debate, just run ZK tower in parallel with the normal tower as well, I'm thinking. So works and they can. Okay, oh, I don't know if I mentioned earlier, but you can actually send these assets over lightning, which is really cool part because you get like low cost PM channel network part of it as well too. And then this is like another version, you can say, well, let's just kind of like add suction. Cairo is basically like a new Taro VM version within the system itself, right? I mentioned a little bit earlier there's a few different versioning systems. Today we have a script version like what's kind of like a script key, which is basically governed by the script version itself. Today, version zero basically says, okay, well, apply the topic of VM rules to taro itself.
00:22:56.650 - 00:23:48.172, Speaker A: What we do is we basically take that kind of tower station, then basically map onto a virtual bitcoin transaction that has like an input and an output which isn't really real, but we can actually reuse all the functionality of bitcoin environment. Say, okay, we're going to value that this is as though it was something like this itself, right? And the cool thing we can say, okay, well, tapa have something called the leaf version. So in addition to basically the top level version on like the op one, op two, which is basically cyber version, there's also a leaf version, meaning that every single leaf also has a version that can say, okay, I can use that to actually add additional functionality to the bitcoin itself. In this case, we're actually in Taro land, right? So let's say we add a new leaf version that says, okay, leaf version. I think CD is the current one, something like that. This basically then can now allow us to actually sort of test run what would be an eventual software for something like starks. We're actually in Taro land itself, right? So we can say hypothetically, we can create some sort of op stark verified type opcode, right? And this opcode would basically fashion as those actually in bitcoin itself, because it's actually in the same environment itself.
00:23:48.172 - 00:24:18.932, Speaker A: But then we actually now are able to settle out the constraints of the current system as far as not being able to pop from the stack. People know, familiar with kind of like the way software work on bitcoin itself. And the cool thing here is then you can say, okay, well, we now are able to have this verification system work, but the verifier doesn't actually need to know about the conditions of what it's proving or it's being verified. It can only put the public hash as well as public inputs as well too. And in bitcoin there's something called like an annex. Some people think it shouldn't be used and maybe think it's broken, somewhat undefined basically. But the idea was, okay, let's say you're adding something like starks in bitcoin itself.
00:24:18.932 - 00:24:31.044, Speaker A: The way bitcoin works right now, you have something called like a Sigop cost. You can say okay, well every single block can have a certain amount of byce, a certain amount of sigoff costs within itself. And you say every single signature is 50 sig option like that, right? But then question, okay, well, how do you price the resource consumption of something like a stark proof itself?
00:24:31.082 - 00:24:31.188, Speaker B: Right?
00:24:31.194 - 00:25:10.724, Speaker A: So the idea was, okay, well you would put this thing in the annex. You can actually statically pop that thing off and examine it basically, and then compute some sort of resource cross function that maybe is a function of the actual proof size rather than trace length there that can be used potentially say okay, well how do you actually have this thing work, but not maybe consume all the bitcoin blocks in all the state within itself, right? This is like one way you can do it as well. You can even do it in a way that allows aggregation across several blocks itself. Something similar to the Schnor Singh issuers half aggregation. Future directions contribute to zero sync development. Get more bitcoin script validation in there, do software stuff, get the inclusion proofs in there, investigate Cairo built in. So accelerate these things as far as shot twos like p operations, things like that as well too.
00:25:10.724 - 00:25:30.300, Speaker A: Then start to implement the chiroprenes within Cairo itself at the TLV SMT serialization, things like that as well too. Another cool thing with this, if you assume you have something like this, you can actually then do ZK, sort of like bridging between taro and other systems as well too. For example, maybe someone has something like USCC, they want to have approved the basis to suspend that thing and then you basically verify them on the taro layer and do the other way around as well too.
00:25:30.450 - 00:25:30.764, Speaker B: And.
00:25:30.802 - 00:25:48.910, Speaker A: Yeah. Any questions? I think I have time for questions. Cool, thank you. Yeah, I had 20 minutes. I see what I did.
00:25:49.760 - 00:25:50.484, Speaker B: I.
00:25:50.642 - 00:26:08.736, Speaker A: What is the advantage of using Utxo? The advantage of using Utxos versus accounts, the account model. I think the Utxo has some advantages in that it's parallelizable because you already have explicit sort of like dependencies in the chain.
00:26:08.768 - 00:26:08.916, Speaker B: Right.
00:26:08.938 - 00:26:18.216, Speaker A: Like transaction a bit specifically depends on transaction B or something like that. You don't have a shared state, so therefore you can validate things a lot more easily. I think the other thing as well is that you have a lot less storage.
00:26:18.248 - 00:26:18.396, Speaker B: Right.
00:26:18.418 - 00:26:20.972, Speaker A: Because in this case the storage is basically just the output scripts themselves.
00:26:21.026 - 00:26:21.244, Speaker B: Right.
00:26:21.282 - 00:26:43.750, Speaker A: The output scripts can then commit to other things that you can then reveal. You can say transaction time itself, so you don't need to deal with basically having all the storage and things are a lot more parallelizable. I think also the application model is a lot easier to analyze because you don't really have arbitrary like calling over the contract race. You can basically look at the actual thing itself. Depending on how you do the constraints, things are just a lot more constrained. Therefore it's easier to analyze. And then you have paralyzed ability gains and unfannability gains as well.
00:26:43.750 - 00:26:47.430, Speaker A: Yeah.
00:26:57.320 - 00:26:59.540, Speaker B: How does data work in tarot?
00:27:01.560 - 00:27:02.084, Speaker A: Good question.
00:27:02.122 - 00:27:02.276, Speaker B: Yeah.
00:27:02.298 - 00:27:21.724, Speaker A: So it's not actually an op return. I don't know if I can go back back. Maybe not. But with the way it works, you have a commitment basically, and the commitment is to that particular asset, TLV. And that data doesn't actually live on chain that lives in what we call sort of like universe servers, which themselves are this sort of series of trees that commit to that basically use the previous outpoint as like a key in a merkle tree itself.
00:27:21.762 - 00:27:21.916, Speaker B: Right.
00:27:21.938 - 00:28:02.296, Speaker A: For example, let's say average transaction, I can look at the previous outpoint in that key, basically input being spent. I can say, okay, well, this is the actual data that I can use to validate. So you can say the data is actually stored mainly entirely off chain with the intent of there is in order to actually, with your NASA itself, people need that data to be available in order to verify it themselves. If they can't obtain the data, then they can't use the asset, they can't verify it itself. So this kind of like, it's like an off chain system that you commit to everything on chain that looks bitcoin like, but then you would fetch the data from elsewhere for example, let's say you had an asset, I want to interact with it, I just need to fetch that initial proof, the gentler's proof, and say, okay, well, this thing was created, has these particular rules, and I can go forth and verify everything else. How that can work for applications where the use case is payments each ETF.
00:28:02.328 - 00:28:04.750, Speaker B: So you earn each.
00:28:08.480 - 00:28:09.864, Speaker A: Application like Defi.
00:28:09.912 - 00:28:14.830, Speaker B: Where you have like shared and you might like.
00:28:17.760 - 00:28:23.136, Speaker A: Yeah, good question. So I mentioned a little bit earlier, you don't have the shared state, but you can kind of have dependencies referencing your transaction.
00:28:23.168 - 00:28:23.364, Speaker B: Right.
00:28:23.402 - 00:28:27.824, Speaker A: So your transaction would depend on maybe transaction one and two and three, basically. And you would need those together in order to be validated.
00:28:27.872 - 00:28:28.036, Speaker B: Right.
00:28:28.058 - 00:28:37.332, Speaker A: And there's some people that have ideas where it's like right now you basically have a Utxo set which is keyed according to the output, which is Txid, and the output itself, maybe you may need also another index that's basically based on the script itself.
00:28:37.386 - 00:28:37.604, Speaker B: Right.
00:28:37.642 - 00:28:45.596, Speaker A: Because otherwise the issue is right now that you can at least spend a Utxo one time in a block. So if you have several transactions, depending on that same contract, the same script, they can't really to each other.
00:28:45.618 - 00:28:45.756, Speaker B: Right.
00:28:45.778 - 00:29:07.300, Speaker A: But you have some other identifier which would be another index within the system itself, you can say okay, well these three are actually referencing this particular script. We can bundle them together basically. So now we have that dependency recomputed and execute them all at once. Any other questions? Cool, great, thanks so much.

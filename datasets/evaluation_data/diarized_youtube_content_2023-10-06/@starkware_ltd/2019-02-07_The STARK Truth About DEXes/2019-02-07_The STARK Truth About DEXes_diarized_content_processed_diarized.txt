00:00:05.590 - 00:00:59.080, Speaker A: Please take a seat. The first talk is on the Stark truth about Dexs by Eli bin Sassan thank you very much. So today I'll be talking about or telling you about the Stark truth about Dexs. So my name is Aliban Sasan. I'm chief scientist in the east of Starquare, and Starquare is a startup, we're about one year old, located mostly in Israel, raised $40 million of funding, two equity rounds, and a sizable grant from the Ethereum foundation. We have a team of 20 team members. Most of them are engineers, and most of those who are not engineers are actually around here sitting.
00:00:59.080 - 00:02:01.196, Speaker A: So feel free to come up and talk to us. And today I'm going to describe a little bit our alpha that will deploy in roughly two months, by the end of Q one or beginning of April onto the Ethereum testnet. It will be a scalability engine for Dexes. We've been working on this thing with Zero X and it's been very helpful. So the talk is going to have three parts Starks as a scalability solution in general for general things. Then we'll discuss Dexes for a little bit, decentralized exchanges, and then we're going to apply the general principles of Starks as a scalability solution to Dex settlement and describe Stark Dex. So while we are not currently hiring in the Bay Area or San Francisco, Zero X that we've been working with are for this very project.
00:02:01.196 - 00:03:03.280, Speaker A: So if you have protocol developers who are interested in a very interesting line of work, I urge them to reach out to Avio or Remco from Zerox. So let's talk about Starx in general as a solution for scalability. For this, we have to describe the scalability problem as it appears in blockchains. So the old world that we're familiar with, the one comprised of banks and pension funds and so on, trust in the integrity of the system is an assumption. We assume that the system is maintained with integrity, and the banks don't just go off with all our funds immediately upon deposit. And when it comes to verifying the integrity of the system, we mostly rely on a bunch of human experts to whom we delegate the task of checking the correctness of the system. So we delegate accountability.
00:03:03.280 - 00:04:02.092, Speaker A: Now, the new world that we're all familiar with already, the one ushered in by bitcoin, has a different principle, don't trust verify. And there is this very nice principle I'll call inclusive accountability, which means everyone should be able to verify the integrity of everything that is happening in this world using standard computational means, like a laptop. So, by now, we're all familiar with the fact that there are these networks of nodes that are tracking and verifying every aspect of the correctness of the system. And permissionless blockchains want to maintain this principle of inclusive accountability, which is sort of similar to the principle of direct democracy. So we want everyone on earth to be able to verify every aspect of the system. But this beautiful principle raises two challenges. The first one is privacy.
00:04:02.092 - 00:04:36.216, Speaker A: Everyone now sees each and every transaction, and that's bad. And the second one is that of scalability. In order to maintain this principle of inclusive accountability, you can't increase the throughput of the system without the risk of excluding some people from it. And I want to focus on scalability. So, by now, you know that zero knowledge proofs could be really helpful in solving the privacy issues, as already done by zksnarks in zcash. And you could use ZK starks. They even don't have a trusted setup.
00:04:36.216 - 00:05:05.688, Speaker A: You could use them to do similar things to help with privacy. That's not the focus of this talk. I want to talk about the scalability, which is the s in starks. So, let's talk a little bit about the scalability of networks. Here we have a nice plot, and basically what we want to do is we would like to push the throughput of the network, let's say the number of transactions or operations per block. We would like to push it to the right. That's good.
00:05:05.688 - 00:06:10.670, Speaker A: But at the same time, if everyone's going to verify this, we're also increasing the number, sorry, the amount of computation. And while we have at our disposal pretty impressive computational resources on the cloud, nevertheless, blockchains have decided to make a distinction and decide that the amount of computation that can go on chain that's in the green area must be small enough to allow this principle of inclusive accountability. If we move up to big servers, then only a very small proportion of humanity would be able to verify what's going on. So that's why things are limited in computation. Okay, so this is the scalability problem. That's this barrier between the green and the gray area is exactly where we bound the amount of computation, be it in block size on bitcoin or gas limit in Ethereum. Okay? These are all measures that are there for the same purpose, to help maintaining inclusive accountability, which is a good thing to have.
00:06:10.670 - 00:07:01.096, Speaker A: So in order to address this, you can use starks. Starks are a special kind of proof system. They come from the vast family of proof systems, zero knowledge proofs, succinct proofs. And the main thing about starks, in addition to them being transparent, that's the t. There's no trusted setup. The second thing that you need to know about them is scalability, which means that as the throughput grows and the prover is generating a proof for the correctness of the system, the running time of the prover scales nearly linearly or quasilinearly in t, and the verifier time scales polylogarithmically in t, which is exponentially smaller than t. And the point in a proof system is that you don't have to trust anything about the prover.
00:07:01.096 - 00:07:30.084, Speaker A: Everything you need to know, or all your trust, is just about the verifier. And as long as the verifier operates correctly, you don't care if the prover is working on the cloud, if it's using faulty hardware, if it's closed source. You don't care who's executing the prover. As long as there is a proof that the verifier checks. You can trust it because of the math in crypto. So here's what things look like. We add two entities to the world.
00:07:30.084 - 00:08:42.808, Speaker A: There's a prover, that's the blue plot, the light blue plot, and as you can see, as the t goes up, the proving time scales up, but very slowly, or, sorry, it almost follows the computation time, but it's a little bit more. And the main thing is that the verification time is exponentially lower, which means that without breaking the inclusive accountability threshold, or the block limit or the gas limit, you can put in a lot more of computation through attaching a proof to it. And the further you go out to the right, the bigger the scalability factor, which is the ratio between what a naive replay computation would have taken. That's the blue plot, and the amount of computation that the verifier is doing. Now, starks come from this bigger family of proof systems, and there are quite a few of them. I just want to mention three that are now deployed in blockchains or soon to be deployed, and I want to compare them to starks. So most of them appear or appeared in the context of privacy.
00:08:42.808 - 00:09:29.624, Speaker A: And the first one I want to discuss is bulletproofs, which is a really good privacy solution. It's also transparent, no trusted setup. While it's very good as a privacy solution, it's not so good as a scalability solution, because the verification time scales at least linearly with the amount of computation. Another kind of proof which has succinctness is the snark, like as in zcash, and again in zcash, it was introduced as a privacy solution. You could also use it for scalability. The drawback there is that there is a trusted setup. It's not transparent, and the amount of computation needed to generate this trusted setup also grows linearly with the amount of computation.
00:09:29.624 - 00:10:36.928, Speaker A: The third one, which will be deployed on coda, is the recursive snark, which has a trusted setup, but a small one that doesn't scale with the computation and compared to a stark. The other issue with it is that the amount of computation scales worse than in a stark with a computation size. So the amount of computation you could feed or verify is not as good as in a stark. So because of all these reasons, even though we at starkware are familiar with these other solutions and think they are very good for their own applications, for privacy, and for other things, we still believe that for scalability, starks have an advantage. So now the second part I want to tell you a little bit about decentralized exchanges. So an exchange from a 30,000ft view has three parts to it. In the first part, the exchange collects orders from the traders, buys and sells, and sort of manages this thing.
00:10:36.928 - 00:11:23.068, Speaker A: Then there's a second part, which is the matchmaking part. You take the different orders and you sort of tie them to each other and match them up. And the very last part is the settlement. That's the crucial part, where the assets are actually swapped and exchanged. And when you discuss decentralized exchanges, there's a spectrum of how much of these three things are being done on chain versus off chain. But all things that are decentralized exchanges will have this thing in common. The settlement phase is done completely on chain, and Starkware's first solution is going to solve scalability in this part of decentralized exchanges.
00:11:23.068 - 00:12:04.670, Speaker A: Later on, we'll also try to attack other issues with the previous parts of an exchange. So I'm going to focus today on speeding up settlements and dealing with a scalability problem as it applies to the settlement phase of decentralized exchanges. Now, out there. Most of the trading done today is done on centralized exchanges, but we're also familiar of the decentralized exchanges. Let's see the differences between them. A centralized exchange, more aptly, could be called a custody maintaining exchange. It's an exchange that has control of all the crypto assets that are being traded on it.
00:12:04.670 - 00:13:10.684, Speaker A: While a decentralized exchange, the important or defining property of it, is that custody of the crypto assets are always in the hands of the traders throughout the whole process. That's the big difference. When you come to settlement, most of the settlement in a centralized exchange is done only on the books of the exchange and doesn't appear on chain, whereas in a decentralized exchange, all settlement is on chain. And because of that, the number of transactions that show up on the blockchain as a result of settlement in a centralized exchange is much, much smaller than the actual number of trade that occurs on the exchange itself. Whereas in a decentralized exchange, there's perfect equality. Every trade that settles in the decentralized exchange must appear as a settlement somewhere on the chain, and this causes an issue of scalability. So the advantages of decentralized exchanges are well known.
00:13:10.684 - 00:14:18.516, Speaker A: The first and biggest one is that now, because the exchange does not hold custody of the crypto assets, there's no central honeypot of crypto assets that could be tempting either to external thieves and hackers that want to attack it from the outside or to internal embezzlement. Okay, so there's no potential for a mount Gox like implosion on a decentralized exchange. The other thing is that a decentralized exchange does not assume the counterparty risk that a centralized exchange would assume. So, for instance, if you look at a 51% attack, and the decentralized exchange is only handling crypto assets, a 51% attack would rewrite the history and may rewrite the trades, but the exchange itself was not affected. So a different order of trades was settled, but the exchange was not exposed to this attack. The traders were, but not the exchange. And because there's no counterparty risk, it also makes for a more streamlined and fast process of listing new crypto pairs.
00:14:18.516 - 00:15:08.388, Speaker A: And, you know, crypto pairs are coming up all the time, and new crypto projects are there. So a decentralized exchange should have an easier time putting them up. Nevertheless, the total volume of decentralized exchanges is only 1% of the total volume of centralized exchanges, and that's not a lot. And there could be several reasons for that. But one, and the one that starcore would like to help resolve, is the one that's related to scalability. Currently, each transaction, when it settles from a decentralized exchange, costs somewhere between 102 hundred kilogas. And this already implies an upper limit of roughly three transactions per second on the Ethereum network, because there is a block every 10 seconds, and a block has at most 8 million gas.
00:15:08.388 - 00:15:54.288, Speaker A: If you take those numbers and divide them by 200,000, you'll get to roughly three transactions per second. That's a hard upper limit on the number of transactions that could settle per second, even if all of the resources of Ethereum were diverted towards settlement of trades. Okay, and I'll be focusing on Ethereum because most of the crypto to crypto trading done is done right now. There. It's also the most streamlined in order for decentralized exchanges to operate. So for an exchange to attract customers, it's very important for it to have a lot of liquidity and a lot of you want a lot of assets to buy. You go to the marketplace because you want there to be a lot of things to buy.
00:15:54.288 - 00:16:29.944, Speaker A: And once you don't have that, then you get much poorer liquidity and much fewer customers and so on. So we want to help resolve that. So how will our stark deck solution look? Remember, there's the on chain part and there's the off chain part. So somewhere later on, you'll see the prover off chain and the verifier on chain. First of all, let's start with the current solution. The way it works is that decentralized exchange is sending the transactions to the Dex contract. And the Dex contract verifies signatures in all parameters of the trade and then checks them and sends them to the storage.
00:16:29.944 - 00:17:07.284, Speaker A: So you can see the gas meter pumping up as these trades are being settled. There are three aspects of the gas cost. There's the transmission of the trades, there's the computation of checking them to be correct, and there's the storage updates that all cost gas. But the main thing is that the total gas cost scales linearly with n, with the number of transactions. So this is our solution. We're going to put approver out there off chain, and a verifier on chain. And there's also going to be a data set that will maintain the account system, and it's going to be represented by a Merkel tree.
00:17:07.284 - 00:17:57.860, Speaker A: So now our decentralized exchange sends the transactions to the prover, and the prover is going to process them and check that they are correct, and prove later on generate a proof that this is correct. And then if they're correct, also update the data in the Merkel trees. So you take these end transactions, you process them, and at the end you send a proof on chain. The proof is now verified. So there's the transmission cost of the proof, there's the computation of verifying it, and there's very little storage changes because you only update the Merkel root of the new state. So now the amount of gas is just logarithmic in n, in the number of transactions, because that's exactly the kind of scalability that starts give you. So, let's take a deeper look at what happens inside the prover.
00:17:57.860 - 00:18:48.600, Speaker A: So let's sort of zoom in into a transaction. So, here we have Alice and Bob transacting, or maybe because it's starks, this could be Aria and Braun. So they have signatures, and they're selling sapphires for diamonds. This thing goes into the prover node, and you check the signatures. If they're all correct, then you update this little table, which is the execution trace of the computation. All steps of the computation must be accounted for. So you check the two signatures, you discard them, and then you take the data, and you update the Merkel route, and you take the result of this update to the Merkel route and bring it back into the computation and put it record it in your execution trace.
00:18:48.600 - 00:19:18.732, Speaker A: So that's the first line. This was for the first transaction. Now you do it again. So now we have Cersei transacting with Daenerys, and once again, you send it, you update it, you get the picture. You have end transactions, each one of them now accounted for in the execution trace. And now comes the tricky part. There's going to be some math error correcting codes, cryptography, whatnot.
00:19:18.732 - 00:19:47.596, Speaker A: You generate a proof and you add the Merkel route of the new state to it. And now it's ready for shipment on chain. It's shipped on chain. You pay your transmission fee, and once again, there is a little bit of math in the verifying of the contract. And then this gets sent to the storage, and you're done. Okay, so this is what we're going to do. Now, I believe we have time for one more thing.
00:19:47.596 - 00:20:31.398, Speaker A: So, I will show you a demo. And now, how do I make this thing grow? Good. So, about three months ago, we showed a demo in which we used a wasm prover and awasm verifier inside the browser on a smartphone to generate and verify proofs. So, we still have that capability, but we want to show you something new. We want to show you a peek of what will go into the alpha. So, for that, we need a verifier that will sit as a smart contract, and we did that. So, we have a verifier written in solidity that we'll now access.
00:20:31.398 - 00:22:03.842, Speaker A: And I just want to. So, wait, I will just. So what I'm going to show you now is inside the browser. I'm going to run metamask and access the node, an ethereum node in Ganache, which is going to be running the verifier smart contract that's going to be on chain, and we have off chain, both inside the laptop and also on the cloud, a proof service from which we can get the proofs. So now let's see how this looks like so we can generate a proof, for instance, for computing the 1000th number inside, in the Fibonacci sequence, and then we can upload this thing and verify it. First of all, let's say in wasm, but we can also go to Ethereum. And so I'm going to open a metamask client that will be talking to the ganache node.
00:22:03.842 - 00:22:40.444, Speaker A: Good. And now we're ready to verify it in solidity. So I think it is asking us to confirm transaction. Good. And it verified for a price of 1.7 million gas. So what happened was the ethereum node that's running here inside the laptop has executed the smart contract that verifies this proof of a Fibonacci statement and paid 1.7
00:22:40.444 - 00:23:09.112, Speaker A: million gas. Now we can also upload another proof. This one is for computing 8000 invocations of a Peterson hash. Each trade being settled is roughly 250 invocations of a Peterson hash. So this will correspond in the full system that we will deploy again in the alpha that we'll deploy in two months. This corresponds to verifying roughly 50 trades. So let's verify this again.
00:23:09.112 - 00:23:52.084, Speaker A: We need to pay the gas cost in metamask. Just 1 second. So now the verifier smart contract is running inside our ganache node on this laptop. Okay, so verifying 50 trades, the analog of that, or verifying 8000 merkel. Sorry, 8000 Peterson hashes, is roughly 5.5 million gas. The gas limit is 8 million, and this is already a significant fraction, but it does fit inside a block.
00:23:52.084 - 00:24:22.464, Speaker A: Now I want to show you the effect of scalability. So this was 50 trades, and this now will correspond to 500 trades, which is much more. Sorry, the first one was for 30 trades. This is for 500 trades. And I want to show you the gas cost. So we increased the payload by a factor of times 16. So if things scaled linearly, you would have to pay a gas cost of 16 times 5.5
00:24:22.464 - 00:24:52.844, Speaker A: million, which is way over the block limit. You can have your own guess of how much is it, the gas cost going to be here, but it's not going to be that high. Good. So it went up by 20% to 6.7 million gas. So this corresponds to verifying 500 transactions, not 30 transactions. And again, this is running on a real ethereum node inside this browser, 6.7
00:24:52.844 - 00:25:39.562, Speaker A: million gas for verifying 500 transactions. Now I want to go back to. So let's tie this back to the scalability of starks, right? So because of the linear cost of verifying transactions on chain, you're abounded by the gas limit of 8 million at 50 transactions. 50 trades. I first showed you something that corresponds to verifying 30 trades at a cost of 5.5 million. And then I showed you that if you go up to 500 trades, verifying them goes up only by 20% to 6.7
00:25:39.562 - 00:26:25.366, Speaker A: million. Now we already estimate that in our alpha we'll be able to handle within a single block more than 10,000 trades. And we can even generate proofs for these things. And that's how stark scalability is going to be applied to settlement of decentralized exchange trades. Summarizing, the current decentralized exchange world maxes out at 50 trades per block, even if a block is devoted only to settling trades. I showed you already, and this is of course work in progress. So numbers will go down by several numbers, gas costs will go down, everything will go down.
00:26:25.366 - 00:27:12.440, Speaker A: But at the current snapshot we're now, I showed you that we can do the analog of settling 30 decentralized exchange trades at a cost of 5.5 million, or roughly 180k gas per transaction. Or I showed you something that gives you an amortized cost of 13.5 thousand gas, which is ten x better than what you'd get already on the current solution. And if we deploy with or when we deal with batches of 10,000 transactions, then the gas cost per transaction is 800. And we believe things will become better. So I just want to wrap up and say I gave you a snapshot of where currently Starquare is.
00:27:12.440 - 00:27:37.310, Speaker A: We're working fast. We incorporated just one year ago. We'll be deploying our first alpha in two months. We're eager to take on ourselves challenges not just of decentralized exchanges, but other scalability and also privacy problems. We have a very serious and dedicated team. We're going to be here throughout the conference. Please come and talk to us.
00:27:37.310 - 00:28:30.862, Speaker A: Thank you very much. We have time for one or two questions. What was the size of the proofs that you have to submit on chain? Yeah, so the smaller one, which was for the 8000 Petersons, was 45 kb large and the larger one was 60 kb large. Okay, and what would you expect on the 10,000? I'll have to guess that will be definitely less than 100 kb. But you know what, let's say, you know what, definitely less than 150 kb. I'm trying to extrapolate in my head. Do you see gains there and the group size continuing to be? Yes, we believe we'll see.
00:28:30.862 - 00:28:40.100, Speaker A: I mean, first of all, if you compare these numbers to the numbers we even present in three months before, you'll see they're already lower and we expect this to continue going down. Yes.
00:28:45.250 - 00:29:23.846, Speaker B: So I have a question related to the computation, the time it takes to generate the order verification approved. Because honestly, to me, the Dex is really about fast on chain settlement. You choose a kind of applications that requires on chain settlement time, because a lot of high frequency traders want to settle the token so they can start another trade. So just my question is, for all this, what's the delay? And also there are two delays. One you had to wait for. You get a 10,000 transaction to batch them. Then the second, once you have the 10,000, you had to do the verification, the computation.
00:29:23.846 - 00:29:35.534, Speaker B: Just want to get an idea. What's your thought in terms of the delay? Pretty much, I call it on chain settlement time. Unfortunately, Dex is not an application that can sacrifice that time. It's good application.
00:29:35.732 - 00:30:35.374, Speaker A: So first of all, there's a difference between the Dex is already doing this, sort of telling their customers this is what's going to happen, and they can say so immediately, and customers already are relying on that. And then you do have to work through the settlement, but you can operate with a little bit of delay there to generate these proofs. As you can see here, we basically took a blockchain bound and turned it into an AWS bound. So it means if you give us enough cores, there is a limit to how much you can parallelize this. But it's very, very, I mean, the lag time, theoretically, it really looks like logarithm of n. So give me enough cores that are fast enough, and I can probably trade, sorry, settle 10,000 transactions within a few minutes. 10,000 transactions is pretty much quite a lot.
00:30:35.374 - 00:30:46.360, Speaker A: I need a lot of cores and pretty fast ones. But this has nothing to do with stuff that you have on chain, which is the main barrier here. Okay, let's thank the speaker again. Thanks.

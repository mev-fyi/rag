00:00:04.840 - 00:00:38.498, Speaker A: All right, we are live now. We're just going to make sure that all of our technical facilities are up and running. I'm going to do a quick check on Twitter to make sure I can hear me. Okay. Check, check. Okay. And it looks like Twitter now does have video, which I didn't realize.
00:00:38.498 - 00:01:26.294, Speaker A: So you guys all get to see our lovely faces. So if you've joined us, thanks for joining us. Today we're going to talk about Blobstream, Starknet, and the milestone that the dev community of Starknet, the open source ecosystem, along with some of the exploration team members have, have hit. You know, it's been an amazing project and an amazing integration with both Herodotus and Celestia. It's been an interesting architecture to come up with, and we can talk about some of the roadblocks and snags and how we've moved past them. So Blobstream Starknet itself is an implementation or a re implementation of some of the solidity code bases on Ethereum layer one. It's a one way messaging bridge from Celestia to Starknet.
00:01:26.294 - 00:02:04.424, Speaker A: The original way that we had conceptualized coming about this, it was about the same time that Celestia had talked about migrating fully to Blobstream X. And I'll let Diego talk a little bit about the difference between blobstream X and blobstream. And so we ended up going the route of using heritotus. So to start today off, I'd like Diego to maybe give an overview of what a traditional celestia roll up looks like, what it needs to commit to, and then we can talk a bit about what, what's been accomplished in blobstream. So, Diego.
00:02:05.924 - 00:02:27.474, Speaker B: Yeah, absolutely. So obviously the traditional way, quote, unquote, you build a celestial roll up depends on one, whether this roll up has a canonical bridge somewhere, aka it's settling to some other underlying layer.
00:02:27.514 - 00:02:27.714, Speaker A: Right.
00:02:27.754 - 00:03:13.442, Speaker B: That's the case with what we're trying to accomplish here with Starknet. L three s, for example, they settled to Starknet, for example. And then there's sovereign roll ups, which we're not going to talk about today. And then the other difference is whether you are doing a secret roll up or an optimistic roll up. Right? In the case of Star net, we all know it's a ck roll up, um, or validity roll up, uh, and in the traditional way. Right. Um, broadly speaking, without thinking about starting it, but just thinking about ck rollups for a second, uh, the way you essentially build a celestia ck roll up or validium slash celestium, whatever you want to call them.
00:03:13.442 - 00:04:13.654, Speaker B: Um, is, uh, quote unquote straightforward. Like, the idea is very simple. You just move from posting your state diffs, or broadly speaking, your data or batch data for your roll up. And instead of posting it to Ethereum or to the same network that you're using for settlement, you would post it to celestia. There's obviously minor issue here if you just do that, which is that posting data to celestia makes it available. But there's no way for the roll up system, and thus for the underlying user to know whether this data was made available or not. They could run a celestial like client and they could verify that, but there's no way for the roll up system itself to basically know when it should proceed with a badge or not, et cetera.
00:04:13.654 - 00:05:24.136, Speaker B: And that's where the use of blobstream comes in. Blobstream being the data attestation bridge that you can use to essentially build these constructions, these palladiums with celestia. Da. And what Blockstream does is a data attestation bridge, is that it lets you bridge or transmit messages from Celestia to some other network. Right? The original implementation was written in solidity, and it had some caveats, let's just say. And eventually, instead of launching the first version that was built by a team member at Celestialabs, we launched instead Blobstream X, which is the same thing, is blobstream in terms of functionality and what it does. But instead of submitting a long batch of celestial headers and verifying a bunch of signatures, it uses Ck to verify all these celestial signatures with one proof.
00:05:24.136 - 00:06:26.300, Speaker B: It's more efficient, it's more portable, let's say. And this was built by the team at succinct. But yeah, like traditionally, it's very straightforward. You post your data to Celestia and then you take whatever your settlement contracts are and hook those up to Blobstream so that whenever your settlement contracts are verifying a batch and a validity proof for your roll up, you also verify one way or another, whether the batch data for that specific proof was posted on Celestia or not. The obvious reason why we're here is to talk about how we migrated or built a version of this for Startnet, given that blobstream was built in solidity and thus we had no way of easily porting this to startnetting. But yeah, sweet.
00:06:26.332 - 00:06:34.504, Speaker A: And then that transition to blob stream x moves all of the signature verification off chain right into that snark.
00:06:35.284 - 00:06:46.476, Speaker B: Correct. It's, if I recall correctly, it's plonkey three circuit. And then the proof gets wrapped into grot 16.
00:06:46.660 - 00:08:17.004, Speaker A: Awesome. Okay, so that kind of ties in nicely to the problem that we had with Blobstream starknet and something that we'll talk about a little bit later today, which is Grau 16 is currently blocked on a syscall that basically needs to be implemented in our protocol stack that Marcello has some cool alpha about later. But we couldn't go the full direct integration of basically mimicking the succinct platform for proving those gross 16 circuits, which would lead to a clean architecture of basically just having exactly what Blobstream X does on l one and port that to l two. So since that infrastructure is already stood up for relaying and proving those block header batches to l one, we essentially needed to appeal to the l one and get the information and the data commitments from l one where it's already doing the work. You know, it's the same data commitments that need to be proved on l one as l two up to l two. So that's where we needed Herodotus to come in. And we basically use Herodotus storage proofs to prove what's going on on the l one and prove the storage slots that reflect the actual data commitments for the Celestia blob blob stream ex on l one, where it's actually already doing the work up to l two with the storage proofs.
00:08:17.004 - 00:08:45.264, Speaker A: And it's a pretty cool architecture. There's a little bit of latency built in just because we do have to route from l one to l two. But overall, Herodotus storage proofs have unblocked us, at least in the short term until that syscall comes about. Marcello, if you could maybe talk about how unique architectures like this come about and how, uh, the storage proofs facilitated, that'd be awesome.
00:08:45.724 - 00:08:52.060, Speaker C: Sure. So thanks for giving the introduction. Maybe first I'll talk about what even makes storage proofs possible.
00:08:52.172 - 00:08:52.652, Speaker A: Cool.
00:08:52.748 - 00:09:44.114, Speaker C: So first of all, like, let's remind ourselves how blockchains are constructed. So whenever we verify the consensus, okay, we run that litecoin at the end of the day just agreeing what is the latest state route, which eventually gets committed to the block hash. In the EVM, we have like opcodes that allow you to access the block hash, and as long as you trust that block hash, it also means that you trust the body later set of Ethereum. And that block hash in a sense, commits to the full history of the chain, because there is like a full linkage. And also the block hash is a hash of a block header, and the block header contains the stateroot. So now that said, it means that as long as you have enough compute to, well, run a bunch of hashes, you can verify the inclusion of either any piece of data ever present on Ethereum. And by piece of data I mean from state accounts, receipts, block headers, pretty much everything that was ever seen on the chain.
00:09:44.114 - 00:10:25.386, Speaker C: And that's like the idea that makes storage proofs possible. But there is one caveat. It's really expensive to do it, especially directly on chain. So this is why we use ZK to basically do this heavy computation off chain and then on chain does verify the proofs of doing so. And now why, how this is applicable to L2. So like I said at the beginning, the full commitment to the history of the chain is this one block hash. So what if we can send using the canonical bridge, this one block hash to some L2, and then given the capability, the computational capabilities, let's say start method, also like we can verify this proof directly there, we effectively make L2.
00:10:25.386 - 00:10:56.084, Speaker C: It's not just like some platform that derives the security of layer one, but kind of an extension of layer one because it gets access to its own state. So that's what storage proofs do. And now how this is applicable in this context, whenever blockstream x proof gets verified on layer one, we don't have to re verify it on L2 because we can just use the fact that hey, this proof has been verified on layer one. So let's just access the result of this verification on the L2. That's basically where we stepped in.
00:10:58.884 - 00:11:53.610, Speaker A: Awesome, awesome, cool. Well, at the end of the day, blobstream starknet is essentially a tool to enable l three. We do still need to have an integration. And I just talked to Elias at Kakarot, so we'll be doing the fine tuning of the integration with those guys over there. But yeah, I want to talk a little bit more about the broad scale application of blob streams, Darknet and l three s in general. One of the things that we obviously need is some of the things Diego mentioned, which is, okay, now we have a commitment to a state route that reflects a state diff. But how do we prove it? How do we prove that the Starknet OS actually ran the right computation? Some of the cool work that's been done on the Herodotus side, especially is the Chiro verifier.
00:11:53.610 - 00:12:25.874, Speaker A: If you look instead of the perspective of the actual blobstream Starknet contract and move out to the actual app chain itself. The app chain itself will need to run the Starknet OS and re execute all the transactions and come and output. Two things, an execution trace to send to the stark prover and the state diff to basically post to Celestia. We need to tie those things together. Um, so Marcella, do you want to talk a bit about the Chiro verifier and how it plays into all of this?
00:12:26.254 - 00:13:14.234, Speaker C: Sure. Um, so yeah, I mentioned proofs already and like you know, with ZK we can build cool stuff such as for example ZK rollups, because what the ZK rollup is depending on the model, but effectively we have some runtime that either relies or not. On some ZKVM we run some computation and part of the computation is also writing and reading to some state that we manage. And this is a ZK roll up. But the bottom line is eventually just some proven computation. But of course when we have the trace, we put it into some prover, we get the proof, but this proof has to be verified. And as of today, the only existing on chain verifier for stock proofs generated by stone, by the stone proverb was existing on l one and was implemented in solidity.
00:13:14.234 - 00:13:55.044, Speaker C: So, well how do you build layer three? Right, because you have to verify also these proofs on starting in that case. So that's effectively the work that we did. So we got some inspiration from the implementation in Cairo zero of Sagerifier, which is used internally by sharp to do recursion. We re implemented the same logic in Cairo one, of course with a few caveats, we changed a little bit the architecture, but yeah, now effectively you can take any kind of program such as for example instruction, pass it through stone, prove it, take the proof, verify it on chain, and you have the usual logic and abstraction behind the fax registry and so on. So that's what we recently built.
00:13:55.944 - 00:14:22.514, Speaker A: Amazing. And yeah, that'll obviously be one of the crucial pieces to actually implement this in an entire app chain stack. So it's awesome that that's available today. Some of the things that's not available today, but that are super interesting is some of the equivalency services that, that Celestia has been working on. Diego, I wonder if you could talk a bit about maybe the future of blob streams, darknet or architectures that this can potentially go.
00:14:24.254 - 00:16:18.174, Speaker B: Yeah, so I mean, now that blobstream stagnet is like a thing, right. The community has done a great job at bringing it essentially to fruition, right? And we have a way to relay or read these data commitments from Blobstream X on layer one on Startnet. And we already also have the integration with stacks like Madara that simply read and write data using SLSC light node. The missing component here, to make this essentially a full end to end implementation, like you mentioned, would be to essentially verify, right, that the data posted to celestia corresponds to the state diffs, or, well, the commitment to the state diffs that goes into stagnant OS. And then in that case, there's like, as far as I know, there's like two ways that you can go about it, right? One way is to take your roll up program, which in this case is starting at OS, and you would add whatever necessary modification you need to add in order to essentially ingest the Celestia blob commitment to your data, which is your state divs and inside of Stargate OS, verify that whatever commitment you have for your data, be it for celestia or for anything else, matches the commitment of your data that is used internally on stagnant OS. That's the poseidon or Pedersen tree, if I recall correctly. That's one way to go about it.
00:16:18.174 - 00:17:43.757, Speaker B: The other way in which you could finish this integration without having to modify stockinette OS would be to essentially prove equivalency of the commitments that startnet OS does your data, but essentially at the settlement layer or at the settlement level per se. So the previous approach does everything essentially inside of the roll up. And you could think about it almost like aggregating proofs, if you will. It's in a certain sense simpler to think about or reason about, because now you just think about it as like, okay, I modified madara, I modified starknet OS, or added this verification. And I use blobstream with my settlement contracts, which would be something like a piltover, right? And now you're good with the other approach. You would, for example, spin up your madara chain, right, to write batches of data to Celestia, read them. You would still use piltover, you still use blobstream to verify that the data routes to which you committed your data to are available on Celestia, right? But then there's the missing piece from step one that you could have done on Stargate Os.
00:17:43.757 - 00:18:57.234, Speaker B: And the way you do this is by proving equivalency between the two commitments, right? The Poseidon slash Patterson tree for stagnet and the celestial blob commitment. And what you can do is prove this off chain, right? So you would run this with whatever logic you want, right? You could. Currently the work that has been done by cnode at Celestial has been in risk zero. But you could perfectly do this as well in Cairo, right? Like Marcello mentioned, you could run for example, a stone prover, and you could write this equivalency service as a carrier program, run it off chain, verify it on chain. And you would just hook that into the logic of your settlement contracts so that you know that, that the sequencer slash batch poster, whatever you want to call the node that posts data, has made the data available. And that way you don't have to essentially get your funds frozen. That's the security assumptions of the lidiums.
00:18:57.234 - 00:20:08.950, Speaker B: With this different approach, you would still obviously, in the same way that an l three does, you would still run this computation off chain. But it doesn't require modifications to start net OS. It does obviously require having to like one, write this equivalency service either in Cairo so that it can be verified with the Herodotus integrity contracts, or, or program circuits, if you will. Or it would. Or in a similar way to the, I guess like Blob stream on Starknet V two, it would require the b and parents like the syscall to be able to efficiently verify route 16 proofs, because the current implementation of the equivalency service is built with resero. And you would wrap those proofs into Grau 16 as an example. And yeah, like, it's hard to say which one is better.
00:20:08.950 - 00:20:27.174, Speaker B: Ultimately, to make that decision, both of these have to be built right, and then you have to do some benchmarking, take into account infrastructure costs, gas costs, etcetera. But the options are plenty, basically.
00:20:27.334 - 00:21:06.904, Speaker A: Well, that's interesting because, and I'm glad you mentioned Piltover, because Piltover is a project that spun out of Blobstream starknet, just because it's an obvious part of the app chain stack. So Piltover is part of the Twitter thread announcement. I encourage you to go check it out. What it is is it's the core contracts basically transposed to Cairo. But one of the things that those will free us up to do is experimentation. Those will essentially let us basically not be locked into. This is exactly how the update state function works for these app chains.
00:21:06.904 - 00:21:58.654, Speaker A: But here are five different ways the update state function can work in the Chiro code for these app chains. Pick whatever is right for your customizable app chain. So especially devs. Listening to this call open source devs, we definitely love some contribution on Piltover, but all of those different varying architectures that Diego said, we can basically have a trait that has an overall description of what needs to be done in that update state and then be able to implement it in a variety of ways. Cool. I mean, that's kind of the last thing I had. Do you guys have any other topics or pieces of conversation or questions or did we leave anything open ended? What do you think, fellas?
00:22:00.954 - 00:22:22.474, Speaker B: I mean, I guess it would be interesting to chat about like, well, why, why would someone build a stagnant l three, right? And like why valydium, I guess, right? Like that's, that's something that maybe we might be missing from this overall conversation, right? Like what does this all accomplish really? Right?
00:22:22.854 - 00:23:19.124, Speaker A: Yeah, that's kind of like first principles, right? Like, what are we even doing here? Yeah, I've gone back and forth about that a bunch in my head. I mean, you know, the stock answer is customizability, hyper throughput. You're always going to get some pushback from cynics that like, well, just use a database, you know what I mean? But I do believe, I mean you are maybe lessening the trust assumptions as you walk up the stack, but you still get, you still gain you security and trust from, from the stack beneath you in, you know, anything you're doing in blockchain. So I see value in it there with, you know, customization, the security gain and. Yeah, hyper, hyper throughput or hyperscale. What do you guys think?
00:23:22.504 - 00:24:40.734, Speaker B: I mean, I think for, for like once you can essentially build your application that you would have otherwise built on Startnet, but as your own roll up or validium, you're still part of the starting ecosystem. There's a lot of things that you can experiment with. Hopefully once we have versions of this that can be run on testnets. Like there's like the low hanging fruits, right? Like having like a Kakarot l three or Kakarot palladium, right on top of starknet. I think if when you combine the sort of like provable vm paradigm of like Starknet, right, with the verifiability and overall like cost reduction that like things like Celestia afford you, you can actually, you have more room to experiment. I say this as somebody that before working at celestial Labs, worked as a smart contract developer and I worked on an application that was on the l one. And it's always bothersome when you're thinking about what you're going to build and you're like, wow, this is so cool.
00:24:40.734 - 00:25:30.926, Speaker B: It's going to be so dope. And then you realize, oh, it's going to cost way too much money, or not just to develop or deploy it, but more. So who's going to use this if each interaction is like $200? And that's with low gas fees, obviously. L two solved this issue of overall gas fees on the Ethereum ecosystem. But when you have things like l three s or palladiums, where you're no longer posting data to Ethereum, even after AIP 44, which has done a good job at like, reducing fees, you're now talking about like, essentially like almost like zero fees, right? And the. In my opinion, the good thing about this combination is that you're. You're building l three set.
00:25:30.926 - 00:26:16.014, Speaker B: Like, are verifiable, right? Like they actually have proofs, right. There's no dangerous games that are being played with like, trust assumptions and. Yeah, I mean, I'm overall excited to see not just things like Kakarot, like experiment with like the Lidiums and starting l three s or. Well, the lidiums that are l three s. I don't know, the wording gets complicated, but things like Giza, things like Dojo, et cetera, especially like on chain games, like provable on chain games, really like, I feel like benefit from like this overall scheme that or architecture that's being built with Madara and the lidiums for sure.
00:26:16.054 - 00:26:39.864, Speaker A: There's almost like if you build it, they will come thing where we don't even know the coolest things that will be built on an app chain yet once it's here. Dojo and cartridge have thrown out crazy ideas just like an entire autonomous world in an app chain, on a click of a button, that kind of stuff. If you build it, they will come.
00:26:41.004 - 00:27:23.062, Speaker C: Yeah. Maybe one more reason to build layer three, in my opinion, is that like Diego you served, whenever you have an application, deploy like L2. It's kind of natural to transition to NL three at some point, for many reasons. I think in my opinion, the most notable reason is that suppose that you build something amazing, but someone else also did something amazing, which is getting a lot of traction, let's say on layer one, driving up the gas piece, and it also affected, right. Eventually. And, well, it also runs on the same sequence or if it's running both applications on the same layer too, you kind of run into the noisy neighbor problem. And with like a layer for you working complete isolation, you can settle whenever you want.
00:27:23.062 - 00:27:33.754, Speaker C: When gas is cheap, you basically control your stack. And I think that's super valuable because you can abstract so many things from your users, from your users. Just because of that, it's probably worth it.
00:27:35.374 - 00:28:31.054, Speaker B: No, absolutely, absolutely. And I mean like there's, there's a bunch of other stuff that like started coming into my head, right? Like, like oracles, like pragma, right. That are, if I recall correctly, building all three. So let's start in it, right? And a lot of like applications that like benefit from not just the provable VM or Cairo VM, right. But they also benefit from like cost reduction, but more importantly like verifiability. Like I think that's like the reason why without trying to like be biased, like you would choose something like Celestia Da or you would choose like alt Da. That's not essentially an AWSs three bucket that ten people sign over like you, you want to have at least some form of like, like security guarantees if you will.
00:28:31.754 - 00:29:09.704, Speaker A: Yeah. And as far as the use case of some type of control over your roll up stack and not running into the noisy neighbor problem, it seems to me like that's basically been proved out. You have things like Dydx, Paradex, these things that have created massive amounts of volume that they don't have to worry about the noisy neighbor. The only thing this is doing is basically opening that stack to anybody who wants to deploy it. Yeah, just pretty powerful. Cool, cool. Anything else you guys have?
00:29:11.644 - 00:29:50.478, Speaker C: I think maybe it's worth to talk about. Also the verification of the graph 16 proofs on Stocknet. I think we didn't cover that. But yeah, there is a project called Garaga, which we have the pleasure to be contributors to as well. And yeah, basically soon, I think around the summer there is a chance that this will be available on Startnet. But also maybe here I could say something pretty weird. But actually today it's even possible to already have blockstream X in my opinion, because you can prove the execution of Garaga, which requires some hints.
00:29:50.478 - 00:30:01.474, Speaker C: You can prove it. You can just prove it with stone and then verify like stone proves on Startnet, which is also potentially like an interesting architecture. And you can batch those together, which is even funny.
00:30:02.254 - 00:30:41.634, Speaker A: Okay, let me, let me ask you a question. Okay. So one of the things that gross 16 opens up is that cleaner architecture of basically verifying the succinct X. Diego, if you don't mind muting or maybe I can do it. So basically verifying the GrOS 16 proof of succinct X platform, which is what, what is it called Grok. No, there's some solidity library that does it for l one. It basically auto generates the function verifier.
00:30:41.634 - 00:31:28.664, Speaker A: Thank you, thank you. On l two, if we unblock this pairing, we can essentially do this function gateway, which is Succinct X's, succinct's platform in solidity, where anyone can go auto generate a function verifier for graph 16, and then they can basically prove whatever their circuit is proving. That's actually what Blobstream X is, actually one implementation of a function verifier in the succinct gateway. So maybe, Marcelo, can you walk through like originally, what we were thinking is that once that graph 16 gets unblocked on Starknet, we would just implement it in Cairo. But if we did it with this way, what would that architecture look like?
00:31:28.844 - 00:32:12.576, Speaker C: I mean, as of today, it's changing a bit because there is a new built in being added to Cairo, which is very specifically like modular arithmetic. And this is not yet supported by stone, I believe. But that's a good question to some starcore folks. But yeah, like this version was possible from what I recall, to just prove it with normal Cairo. Then you throw it into stone and voila, we have a stark proof that proves the verification of the graph 16 proof. So that was possible. But I think right now with this new syscall, just to be directly, there is no need to wrap it, but it's maybe going to enable lower latency.
00:32:12.576 - 00:32:22.724, Speaker C: But the question is also going to be around the cost, because maybe it would be the case that it's still cheaper to verify a storage proof. A storage proof really depends.
00:32:23.204 - 00:32:24.660, Speaker A: Interesting. Cool.
00:32:24.852 - 00:32:35.704, Speaker C: But you can also aggregate, right? You can generate a start proof that verifies the truth execution of many graph 16 proofs. Yeah, there is like a lot of designs that can be used here.
00:32:36.044 - 00:32:37.064, Speaker A: So you said.
00:32:37.644 - 00:33:38.194, Speaker B: Yeah, I just wanted to add one thing to think about, right. Is that. So there's like this, like v two, right, of Blobstream X, where you were verifying the already existing blobstream X proof on Cairo through grot 16 and grog and whatnot. And obviously that has the benefit of now it shares the same proof as the Ethereum version, et cetera. But there is also the possibility, I'm not saying it's a simple task, but you could build Blobstream X or the logic underneath blobstream X, which is tenderminx as a Cairo program. Given that blobs, if you were to put side by side blobstream and blobstream X. Like the main difference is how you verify that data commitment or a batch of headers is valid in v one.
00:33:38.194 - 00:34:13.224, Speaker B: It's like you have to loop through signatures and verify all those in blobstream X. You verify this, like garage 16 proof of the planky three proof or, sorry, planky two proof and that's it. Right. So you could in maybe like a b three or b 2.5, I don't know, you could try to build tendermin X, right, by using Cairo. And that way you no longer need to wait for this pairing. You could verify it with integrity.
00:34:13.224 - 00:34:46.794, Speaker B: But another thing about tendermin X, right, is that like it's, it's, yeah, it's used for blobstream and that would help a lot with blobstream X. But because tenderminx is proving tendermint consensus, right, you could, for example, use this for other applications that might want to talk with other, or interact with other cosmos space. Like chains, right? Or, or chains that use tendermint under the hood, basically. I think that's like worth exploring in the future.
00:34:47.374 - 00:35:12.954, Speaker C: Yeah, definitely. Like Cairo is pretty powerful. It's a GkVm. You can do quite a lot of stuff with it. So literally nothing prevents you from implementing a program that just verifies a bunch of signature and then call it consensus verification. I guess you can do it. The question is, what's going to be the benefit of that? Like probably you avoid going through graph 16, so you don't need to generate a graph 16 proof, which probably takes a while.
00:35:12.954 - 00:35:18.830, Speaker C: You just go directly through a stark. Yeah, there's a lot of possibilities.
00:35:18.902 - 00:35:21.614, Speaker B: The question worth, you know.
00:35:21.654 - 00:35:21.870, Speaker A: Yeah.
00:35:21.902 - 00:35:23.318, Speaker C: Is it actually worth it?
00:35:23.486 - 00:35:24.234, Speaker B: Yeah.
00:35:25.894 - 00:35:44.174, Speaker A: Let's build it. Let's see. Sweet, sweet. This has been an awesome conversation, guys. Yeah. I want to thank, I want to thank Marcello for joining, I want to thank Diego for joining and thank both you guys for, for helping with the integration to where we're at. There's obviously a lot of exciting work to be done.
00:35:44.174 - 00:36:06.542, Speaker A: Like we've, like we've kind of just talked about a lot of avenues to take, a lot of code to write. So if you are listening to this and you're a dev, we would love to have you. The repo is GitHub.com, keep Starknet, strange, blobstream, Starknet. And you can also find us on Twitter or on telegram. So yeah, once again, thank you guys. I really appreciate it.
00:36:06.542 - 00:36:10.954, Speaker A: This has been awesome and have a great afternoon or evening.
00:36:12.174 - 00:36:12.958, Speaker C: Thanks.
00:36:13.126 - 00:36:15.634, Speaker B: Have a good one. Bye.

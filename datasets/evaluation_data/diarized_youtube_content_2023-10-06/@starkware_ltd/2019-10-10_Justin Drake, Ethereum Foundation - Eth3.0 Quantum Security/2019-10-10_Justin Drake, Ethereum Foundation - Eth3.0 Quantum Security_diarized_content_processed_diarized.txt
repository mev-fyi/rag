00:00:00.330 - 00:00:37.720, Speaker A: Hello. Okay, so I'm going to talk about Ethereum 3.0 and specifically quantum security, which is the main focus of Ethereum 3.0. So we want to try and protect ourselves against better versions of these machines here. Okay, so I'm going to give a quick intro, and then the talk will be organized in three parts. One basically talking about if one today and how it's vulnerable to quantum computers, and then e two kind of baby steps towards protecting ourselves against quantum computers and e firm 3.0, eventually reaching quantum security.
00:00:37.720 - 00:01:31.358, Speaker A: So this is kind of the high level of progression in the blockchain space. We've had good reasons to move to a new system, and I believe that quantum security will be kind of a very good reason to move from e two to e three to do the upgrade. It might even be something that bitcoin people would agree with as well. Okay, so I guess in quantum computing, you have neven's law, which is kind of the equivalent of Moore's law. And it says that computational power kind of grows doubly exponentially. So it's kind of even stronger than Moore's law. And there's also a bunch of people who think that quantum computers is all hype and they'll never be scalable.
00:01:31.358 - 00:02:08.002, Speaker A: And right now, we're at this point where the line is flat, so it's very difficult to tell. But it is possible that at one point, things will shoot up, and we have to be conservative. We have to assume the worst case scenario. And so we're going to just assume that neven's law will hold. Okay, so what is the narrative that we have? Well, basically, the narrative is we'll have Ethereum 3.0. It's going to be a quantum secure upgrade, and there's going to be stock stocks and lots of stocks. And why stocks? Well, one is that it's kind of a flexible construction.
00:02:08.002 - 00:02:43.778, Speaker A: It's kind of one tool to rule them all. You can do pretty much everything with them that we're interested in. Kind of the lean and resilient cryptography, consolidation of assumptions, mostly only building on hash functions. And then they also, as I mentioned this morning, are quite old, so you have the Lindy effect. And also the performance is good. So they have relatively fast provers. And their major downside is that the proofs are large.
00:02:43.778 - 00:03:44.874, Speaker A: But as I'll try to argue later on, data is cheap. So this is not a problem for us, especially in the longer term. Okay, so we want to protect ourselves against quantum computers in the long term. So let's make some investments. And basically, we made this large grant, and the goal was to, one, try and introduce star friendly hash functions, because with the current hash functions that we have, like ShA 56 or even Blake or Sha three, they're very much difficult to work with. And we want to try and come to a point where everyone uses the same hash function as the common building block to try and encourage network effects and things like that, and also encourage more review of the one specific hash function that we're building upon. And there's a big focus in the grant on performance.
00:03:44.874 - 00:04:24.610, Speaker A: So, actually, part of the money is like performance bounties. So the faster you can go, the better. And there's also a huge focus on open source. So we want all the code that is released to be released, for example, under the MIT license or some other license. And we also want kind of lots of third party audits and review. And so all of this is part of kind of moving towards production readiness for potentially powering Ethereum 3.0. And there could be billions, hundreds of billions of dollars at stake.
00:04:24.610 - 00:05:13.070, Speaker A: Okay, so when we made the grant, stocks were only plausibly quantum secure. But very recently, Alessandro and his team basically came up with a proof that actually they are quantum secure. One of the downsides here is that the proofs are slightly larger. So they're already large. They're getting larger if you want to protect yourself against a quantum attacker in that specific model. And I've tried to ask a few people what the concrete constant is like, how much the proofs are going to increase. And I still don't have a satisfactory answer, but it's expected to be a small constant, maybe on the order of two.
00:05:13.070 - 00:05:48.220, Speaker A: One, theoretical practice. Okay. I think it's more like two, but we'll see. I could be wrong. Okay. And when we made the grant as well, Starks had this fantastic property of universality. And I'd say maybe this is not so much of a competitive differentiator nowadays, because now we have lots of options with all sorts of different trade offs if you want universal it.
00:05:48.220 - 00:06:33.020, Speaker A: So stocks fall in the first category, where the setup is just this hash function. You just need to choose your hash function. But now there's all sorts of other setups, class groups, RSA groups, powers of taU, and they all have different trade offs. So the one unique selling point of stocks in this framework is the quantum security. And this is kind of a confirmation that picking stocks for quantum security was a good decision. Okay, so where are we right now with e one? This is not ef one, this is bitcoin. But Peter from bitcoin says 30% of the bitcoin supply is at risk of a quantum computer.
00:06:33.020 - 00:07:33.710, Speaker A: So he looked at the available public keys and he did some statistics. And, yeah, basically the reason is that if you reuse an address and the public key is known, then a quantum computer could recover the private key, and then your funds would be at risk. And I'm kind of expecting, actually, that the situation on e one is worse than 37%, partly because the account model might encourage more reuse than the Utxo model. But I don't know. I don't have a number to share. And another complication in e one is that contracts might be kind of really hard to migrate. So if you think, for example, of a long running auger bet that's meant to last 20 years or 30 years, I don't know how to address these contracts.
00:07:33.710 - 00:08:57.480, Speaker A: And one option is to do some sort of governance intervention where we say if the worst comes to the worst and we see really old addresses becoming attacked, we could say any funds that are, let's say, at least ten years old and haven't been touched will just burn them. But then this is not great because there'll be false positives, it'll be controversial, and it's not something that we want to encourage. There's also the problem of inertia. So we're here today in a, quote, vulnerable position relative to maybe 1020 years in the future, and the current public key infrastructure that we took two decades to set up. So I guess starting to think about it today and acting now is a good hedge. And just to give you an idea of the time frames of all, if you look at, for example, the NISt post quantum security competition, which some people argue was started too early because it didn't include some of the more recent constructions that still kind of stretches many, many years. And in the context of blockchain, there's additional friction to doing updates related to governance and things like that.
00:08:57.480 - 00:09:28.930, Speaker A: Okay, so this is my point. Data is cheap. And basically the idea here is that you have Nielsen's law, which says that bandwidth will grow 50% every year. And that's kind of consumer bandwidth, which is fantastic and especially good for snarks. And one of the reasons why we have this is that data is very easy to work with. Data is fungible. A byte is equivalent to any other byte, so you can do a lot of parallelization.
00:09:28.930 - 00:10:12.058, Speaker A: And if you take a 200 kilobyte stock proof today, that will only be the equivalent of 3.5 years. So that's great news. And so one of the things that we have done in e one is kind of take this into account. So ef one is already five years old, and so there's five years of Nielsen's law that has kind of accumulated, and so a little adjustment was due. And so we have this EIP 2028, which says if you want to put data on the blockchain, you only need to pay 16 gas per byte as opposed to 67 gas per byte. And one of the characteristics of hardware is that computation is actually no longer scaling.
00:10:12.058 - 00:11:07.780, Speaker A: So even though Moore's law is still technically true, you still have a doubling of transistors per unit area. The computational gains are not following Moore's law. And one of the reason is that power density is so high that you would melt the chips if you try and push more performance. And so you have a plateauing of the sequential of the computation. And this chart kind of shows the sequential computation relative to Nielsen's law, which kind of shoots up. So my prediction is that we'll see more data repricings in the future, and we could even have a kind of automatic repricing over time, where the cost of data just decays automatically over time. Okay, so, eve two, what are we doing relative to quantum computers? And it turns out we're doing kind of a bunch of things, and I'll just kind of go through them.
00:11:07.780 - 00:12:00.946, Speaker A: So, one interesting thing is that we have this kind of emergency post quantum apocalypse infrastructure. And the idea here is that you have the traditional key infrastructure based on BLS, which is not post quantum secure. And if quantum computer comes up, we can just cancel all of this and use the backup infrastructure. And this is kind of. The analogy is similar to this image here is the Svalbard global seed vault. Basically, it's a place in the world where there's seeds, agricultural seeds, from all over the world, and that's kind of a backup in case, for example, of an atomic apocalypse, you can kind of recreate humanity. And that's kind of the same idea here.
00:12:00.946 - 00:13:08.262, Speaker A: And so what we're doing is we're using lamport signatures as a backup. And the cool thing about the construction, which I'll show soon, is that it's backwards compatible, so it can be integrated with any existing signature scheme on bitcoin, on e one, anywhere. And the way that it works is like this. So, basically, you have your seed that you use to generate lampport secret key and a public key, and then you hash the public key, and then you get your traditional non quantum security signature scheme, and then you kind of use that as normal. And then if the worst comes to the worst and you have to discard the right part, then you can just reveal the Lamport public key and show that it matches the non quantum public key. And this hash is quantum secure. And then you can just use your lamp secret key to do a one time signature to migrate onto a new platform.
00:13:08.262 - 00:13:50.760, Speaker A: So what we would do, like in practice, if we have to use this, is we'd shut down e two, and then when e three is ready, we'd have a transition mechanism for validators and users to migrate to the new system. Okay. And just so that for those who don't know lamport signatures, which might be very few of you, it's so simple that I'll just show it. So, basically, you have your secret key, which is just 32 byte numbers, and you have two times 256 of them. So the idea is, when you want to sign a message, you sign the hash of it, which has 256 bits. Each bit can have two values. So that's why you have the a and the b.
00:13:50.760 - 00:15:05.550, Speaker A: Your public key will be the kind of the hashes of the a's and the b's. And then if the message that you're trying to sign has, in a specific bit position has a zero, then you reveal the a, and if it has a one, you reveal the b, and that's the signature. Very nice. Okay, so second idea in if two is multi hashing. So we kind of want to encourage applications to read the Ethereum blockchain, and we want to encourage people to do it in a way which is friendly to zero knowledge proof systems. And so right now, everything we do in EEF two is based on shatter 56, which is amazing in all respects, except one respect, which is that it's not stock friendly or snark friendly. And so we're putting all this effort, right, to try and design a lower arithmetic complexity hash function, which would kind of be inferior to shutter 56 in all respects, except this stock friendliness.
00:15:05.550 - 00:15:55.502, Speaker A: And traditionally, you have blockchains. They'll just choose a hash function and they'll run with it. And we kind of want the best of both worlds. And so why not both? Why can't we just use both? And it turns out that we can use both. And it's an idea called multi hashing, where basically, in, for example, your headers, you'll have block hashes, and you'll have your state route, and you basically compute your block hashes using two different hash functions, and you put both in the hash function and same for the roots. And so if you're building an application which needs to read the Ethereum blockchain, then you can just use whichever you want, whichever is most appropriate. So if you want, like, really strong security, you'll just use shutter 56.
00:15:55.502 - 00:16:24.386, Speaker A: Or if you want speed in the plain text, you'll use shutter 56. But if you want to do something more fancy with knowledge proofs, you'd use the other hash function. Okay, so this is the challenge. It's already been discussed. There's all these families and flavors of hash functions. Looking forward to the competition and the winners and the winner. And one thing that I actually only realized yesterday, maybe the starware has kind of changed.
00:16:24.386 - 00:17:15.730, Speaker A: Their tactic, is that actually now the thinking is that the stock friendly fields are actually prime fields, not the binary fields. And the main requirement, as I understand, is that they have high to identicity. And so that means that we can plausibly design a hash function which is friendly to both starks and the snarks, which is amazing, which is fantastic. And it's great in the context of multi hashing, because we don't need three functions, we can just use two hash functions. But it's also great in general that there's collaboration possible here. Another thing that we're doing in ef two is that we're making addresses longer. So right now, they're only 160 bits.
00:17:15.730 - 00:17:44.580, Speaker A: And the classical pre image resistance for that would be 80 bits. But it turns out there's. Yes, collision. Sorry, collision. Yes, replace pre image with a collision. So there's this result from 2017 where actually you can do slightly better with a quantum computer, maybe even down to n over three. And you need to take into account all the possible weakenings that I found.
00:17:44.580 - 00:18:31.114, Speaker A: And you also need to take into account that 80 bits of security has actually been breached in practice, if you look at the bitcoin blockchain. So routinely, the bitcoin blockchain will produce block hashes with 80 leading zeros. There's more than 2000 of them, and this is a record that has 91 leading zeros. So I just avoid 80 bits of security going forward. And so we'd use kind of addresses which are 250 bits long. Another idea is kind of witness compression. So what is the problem here? So, basically, one of the big design decisions in e two is stateless clients.
00:18:31.114 - 00:19:13.642, Speaker A: So the idea that the validators don't store state, they only store kind of very small state routes. And that kind of means that when you make transactions, you need to specify the state yourself, the data, and you need to specify all the Merkel branches. And there's kind of this deep nesting that's going on where you have the beacon chain, you have the shard. In the shard, you have execution engines. In the execution engines, you have dapps. In the daps, you have accounts. And so we're basically expecting that for one unit of application data, you're going to have ten units of Merkel proofs.
00:19:13.642 - 00:20:02.218, Speaker A: So that's quite a big overhead for applications. And so one neat idea here is the idea of witness compression. You just take all the Merkel proofs and then you string them down into a snark, for example, and you can potentially get much lower overhead. I mean, I must say here, snarks might be more appropriate, at least in the short term, because they're so much smaller. Another idea in if two, I guess almost done with if two is that we're not opinionated on the signature scheme. So if you want to go directly to, for example, a quantum secure scheme, you don't have to pay the cost of ECDSA, which is currently enshrined in e one. So there's no minimum 21 gas that you need to pay for EC recover and whatnot.
00:20:02.218 - 00:21:22.070, Speaker A: You can just go straight to the quantum stuff if you want. And then the final idea, which is a little crazy but still interesting, is the idea of a quantum canary. So can we have a special contract on the Ethereum blockchain, which would reward anyone who can prove that they have a quantum computer? And so that would give us kind of an early warning that we really needed to get moving and do a transition to something secure. And we can even calibrate the problem in such a way that the quantum computer would not be able to fully break the system. But it would be kind of a strong warning that we need to get moving. And this trigger could be made visible for contracts, not just the consensus. Okay, so eve three, what are the paths that we need to upgrade? So in phase zero and phase one, all the parts kind of share this one peculiarity, which they're basically built on BLS signatures.
00:21:22.070 - 00:22:23.980, Speaker A: So we have these BLS twelve 381 private keys, and we use them for aggregate signatures. We use them for Randall, and we use them for proofs of custody. And one of the reasons we're leaning on BS twelve three one is that it's very friendly to MPC. So what we mean by that is that you can have a single validator which is actually controlled by a pool of different people. And you can have, for example, two or three multisig, effectively on all the constructions that we have in e two. So if you want to run a validator, which requires 32 e and you don't have 32 e, then that's one way to kind of decentralize the validator itself, which at the consensus layer, is an atomic entity. And then in phase two, we introduce vds, which is a different cryptography, which is based on a group of unknown order, specifically an RSA group.
00:22:23.980 - 00:23:14.490, Speaker A: Okay, so what I'll do is I'll just go through all these four and explain kind of what our current thinking is. So, for aggregate signatures, these are the constraints that we have. So we want to have batches of signatures of size, let's say 1024, and we want to have 128 batches per block, and each block comes every 6 seconds. And this is kind of totally possible to do with BLS signatures. And it's one of the, if not the key reason why we're able to have so many shards. So we have 1024 shards. A lot of, you know, the reason it's such a high number is thanks to BLS aggregation.
00:23:14.490 - 00:24:23.946, Speaker A: And so how could we try and mimic that with stocks? So, one idea is just to have lampport signatures at the bottom layer. We batch them into groups of 1024, and then we take those stocks, and then we batch them again. So one of the things that we'd need here is one level of recursion in the stocks, which, as far as understand, is something that is possible. But there is still one kind of open problem, is, how do you have MPC friendliness? The dumpled signatures are not super MPC friendly. And so if that's something you want to work on, that'd be great. So, the other kind of construction that we have is randal. And the idea here is that you want to have some sort of pseudo random function that is associated to validator identity, and we use BLS.
00:24:23.946 - 00:25:44.810, Speaker A: But here's another idea which actually doesn't use stocks at all, and I'll explain how it works. So, the idea is that the validator has a seed that they computed locally at random, and then they just keep on hashing it and hashing it and hashing it, and then they commit to the 1024th hash. And basically, you have this hash onion, and every time you want to provide a random kind of looking number to the blockchain, you just unpeel one layer of the hash, and you can prove that it matches the commitment. Just because the blockchain can do the hash. So you basically unpeel these layers. And the reason why this satisfies the MPC property that we want is that it turns out that the hash functions that we're designing to be snark friendly are also, to a very large extent, MPC friendly. So a big cost in the MPC is going to be the number of rounds of communication, and the number of rounds of communication is basically going to be the circuit depth.
00:25:44.810 - 00:26:51.790, Speaker A: Thankfully, it's quite a lucky coincidence that we will be able to do this. And because you only need to unpeel a layer of the onion rarely, let's say, on the order of once every seven days, then it's okay to have a very small number of layers. Okay. So another key construction that we have in Ethereum, and we use it to basically address the data availability problem, is the idea of a proof of custody. So the proof of custody, what it tries to achieve is that it wants to make sure that you have a piece of data and you haven't kind of outsourced the downloading of the data to someone else. So you have the data, and the way that the construction works is that you meant to pick a secret. Well, there's a secret which is attached to your identity, and you're going to do this mixing process.
00:26:51.790 - 00:27:38.014, Speaker A: So you mix the secret with the data. And so one way to do that is you have your secret, which is, say, 32 bytes, and then you chop the data into 32 byte pieces, and then you xor every single piece with the secret. And then what you can do with Starks is then you can create a starks, which says, I know the mix. So basically, I'm in possession of this mix, which is consistent with the hash of the data, which is what you'll be signing over and consistent over the secret. So, yeah, you can get proofs of custody, which are kind of non interactive. Right now. I need two.
00:27:38.014 - 00:28:16.326, Speaker A: They're interactive. So that's an added kind of bonus here. So you get both quantum security and non interactivity. And then kind of the final construction that needs to be upgraded is VDF. So instead of using RSA groups, we kind of use permutation polynomials. So you can imagine the square function or the cube function in the finite field. It turns out there's this asymmetry between the polynomial and its inverse.
00:28:16.326 - 00:29:18.330, Speaker A: So there's an asymmetry between taking a square root, which is computationally intensive, versus verifying that you have a square root, where you only need to do a single square. And so you can use that kind of gap between the prover and the verifier to basically squeeze the verification time relative to evaluation time. And then you use stocks to get this exponential gap. I'm going to move forward because I don't have much time. But the short of it is that vdfs based on stocks have really, really good properties relative to RSA, especially in the longer term, kind of under the ten year timescale. And I briefly mentioned this, that as a bonus, you can use stocks to simplify the protocol. So as a design heuristic that I have is like, if Cryptography doesn't work, I'll try crypto economics, and more often than not you will find a crypto economic solution.
00:29:18.330 - 00:29:48.118, Speaker A: But here's kind of the reverse, where if cryptography does work, you want to really try and avoid the crypto economics. And the reason is that the crypto economics comes with all sorts of complications. It comes with interactivity. The security model is slightly weaker, and you need to worry about economic incentives. And so if you can do cryptography, it's really great. And there's these two other constructions which right now are based on crypto economics rather than pure cryptography. One is the data availability and the other one is header checks.
00:29:48.118 - 00:30:40.400, Speaker A: And it turns out we can do those non interactively with Starks, which is fantastic. And that's it. Thank you. You mentioned somewhere in the middle that you like to use the same field for both stars and start. But aren't you afraid that if you have like binary subwoofers there, then you will have the. Okay, so I think he's asking, if you have very high toadicity, does it make it easier to solve the discrete logarithm problem? Is that the question? Yeah. Okay, well, I mean, in practice, I think you don't need that high to add the city.
00:30:40.400 - 00:31:09.108, Speaker A: So I think the curve used on e one right now is like two to 28. Thank you, Barry. And then there's BlS twelve, 381, which is two to 32. And then there's the other one, which is BS 377, which is 40 something. Yeah. So these are kind of routinely used by snark people. And it allows you to get billions of gates.
00:31:09.108 - 00:31:44.620, Speaker A: So that's for practical purposes sufficient. So, so long as this two to the 40 does not break, allow discrete log, then I guess you're fine. What's the, I guess it's a similar, it's a similar thing, right. So roughly the number of gates in your circuit we picked like very large. Okay, I think our time is up. Let's thank all the speakers of the session.

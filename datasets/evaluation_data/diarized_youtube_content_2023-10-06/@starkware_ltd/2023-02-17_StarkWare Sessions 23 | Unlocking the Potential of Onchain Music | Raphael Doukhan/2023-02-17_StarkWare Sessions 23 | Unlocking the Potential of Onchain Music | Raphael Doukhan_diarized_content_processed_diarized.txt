00:00:03.460 - 00:00:57.184, Speaker A: Hi everyone, I'm Rafael Ducan, one of the web three software engineer at Revelator, a company where we are building digital assets for the music industry. And I'm also part of Cosmic Roses artist collective, based in Tel Aviv. By the way, tomorrow we organized the after party of the after session, so I hope to see you there. And a few weeks ago we launched Waziz Lab, where we are working on, on chain music tools for the music industry. It's not working, but it's working. Thanks. Okay.
00:00:57.184 - 00:01:49.456, Speaker A: So many startups in the music space, they are working on the distribution part and the publishing part. And where I'm working at Revelator, it's exactly what we are doing and I think it's great. They are changing the industry, so they are creating music as token. But today I'm going to talk about music as a program, as a Ko program in my case. And today, a song is a finite object. It's an object that each time that you are listening to a song, it's exactly the same, okay, of course you can have different version of the song, you can have the club edit, the COVID the remix, of course, but at the end of the day it's the same. Each time that you are listening to a song, it's the same one.
00:01:49.456 - 00:02:39.228, Speaker A: But why? We don't have an object composed of constants and variables. The constants, for example, can be like the structure of the song, the melody team, et cetera. And those variables can be like the BPM, the tension profile, the key. So I said, okay, we can make music on chain to make like generative music. So the song lives beyond the creator and beyond the creator. So before to talk about on chain music, you have to make the distinction between audio and Midi. An audio file is a format like MP3 wave that capture the actual song.
00:02:39.228 - 00:03:44.752, Speaker A: And MIDI is a format where you capture a bunch of events about the song. And what is amazing with Midi, that we can represent it as a JSON object. So here, for example, you have a note event with different details about the song, like the duration, the duration ticks, the pitch, the tick, so at which time is it in your song and the velocity. And this is just one example, but MIDI can capture much more events. Okay, so to represent music on chain, I said okay, let's first try to represent a JSON object on chain. So I did a Javascript script that take a JSON object and generate from this JSON object a Cairo smart contract. And in the first part of this Cairo smart contract here is a bunch of nested structs that represent the interface of my JSON.
00:03:44.752 - 00:04:49.080, Speaker A: And the second part is a retrieve object that will just build up from the struct, from the bottom up and return my object. And with that we can just represent any kind of JSON object on chain. So we can represent MIDI, but we can also represent like 3d objects or even machine learning models. And then when I finish to represent music on chain, I say, okay, let's maybe add some variables, because I want that a song is not a finished object, but an object with variables. So here users can interact with the smart contract and do some midi manipulation. So for example, the tempo, the duration, the transposition of the pitch and the velocity. So what are the use cases with that? But before let's listen to it, this is the original song.
00:04:49.080 - 00:06:01.932, Speaker A: And then after on chain media manipulation, and this, like, this media manipulation was done on chain. Of course, what are the applications that we can have? Of course we can think like about a composer that composes song for their fan base, and their fan base that owns some utility tokens and some nfts can have more personalized music. So the music lives beyond the creator. But one of the most exciting field is for on chain music, for on chain games. I don't know if you know Casey Westcott, a developer and an amazing musician in this darknet ecosystem. And he's working on the music for the Willans game, the music, music background of the Rims game. And he used what I did just to represent the music of this video game on chain.
00:06:01.932 - 00:06:48.850, Speaker A: And what is interesting with that is that the music of this video game change with the action that you are doing in the game and the nfts, and so the skins of the creator, of the character. Sorry. So the music evolves in the game. So yeah, I think with that we can just create a new era of music where the music is not a finite object anymore, but just lives beyond the creator and beyond the creation. Thank you. If you have any questions, I'm happy to answer. Sure.
00:06:48.850 - 00:08:00.590, Speaker A: So it's really important to understand that we don't render the song on chain. Of course, what we store on chain is the data structure, the bunch of events in my MiDI file, and then we retrieve, in this smart contract, we retrieve the object. So the JSON media representation, the Midi JSON representation, and then we can use it in Ableton or in any kind of. Yeah, exactly. So we take the information on chain, we can do some MiDI manipulation on chain, and then we render it off chain in your video game or in your Ableton logic pro. Any other questions? Thank you.

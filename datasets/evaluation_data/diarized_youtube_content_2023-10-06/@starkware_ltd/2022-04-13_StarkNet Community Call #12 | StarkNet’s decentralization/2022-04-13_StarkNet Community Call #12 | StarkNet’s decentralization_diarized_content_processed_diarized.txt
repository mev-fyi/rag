00:00:00.410 - 00:00:22.830, Speaker A: Let me just start the zoom, the YouTube live. All right. And we're now live also on YouTube. So let's get started. Noam, if you want to talk, it would be also ideal if you can connect on Discord. Okay, so let's start with our twelveth community call. Welcome everyone.
00:00:22.830 - 00:01:26.230, Speaker A: I'm happy to see that many people all connected. We have 129 persons on Discord and about 40 on YouTube, which is pretty cool and the topic for today. So as you know, usually on our community call we welcome community members to present their project, talk about what they do on Starknet, and then often we talk about the roadmap of Starknet. It would be very cool to talk about the roadmap of Starknet today because there are a lot of things happening, especially around fees, but we're not going to talk about that today. Today we have Ohad with us and we want to discuss a topic that is less related to right here, right now, and how you build your applications on Starknet right this second and that is more focused on the medium to long term. Today we're talking about an important topic. We're talking about decentralization.
00:01:26.230 - 00:02:16.978, Speaker A: So ohad, I know you prepared a presentation, so I'm just going to activate the screen sharing for you. So you will be able to present and if you want to see slides, you will be able to see them on YouTube. Ohad, if you can also share the link to your slides on Discord, then people who are in discord and want to show your slide would be great. So today we're flying a bit on a higher level than usual and we're discussing important topics. It's time we have the serious talk. How do we decentralize? And I want to mention that this discussion has started right? Oad, you posted a bunch of posts and a bunch of Twitter posts. So you posted a bunch of posts on discourse and you posted a bunch of polls on Twitter.
00:02:16.978 - 00:02:57.590, Speaker A: And I want to underline that we need your input in this discussion, all of you, whether you're users of Starknet or deving on Starknet, we want to have your opinion on what works, what doesn't, what does decentralization mean, and things like that. So we're doing a community call, but don't wait for a community call to get involved, react to this post, answer these questions, please voice your opinion. It's very important for the long term health of the network. And with that presentation, ohad, the floor is yours.
00:02:58.490 - 00:03:02.120, Speaker B: Everyone. You can hear me, right?
00:03:03.690 - 00:03:05.590, Speaker A: I can hear you on Zoom.
00:03:08.510 - 00:03:11.660, Speaker B: Not on discord. I'm also on the community call.
00:03:12.030 - 00:03:16.140, Speaker A: My discord seems frozen, so I'm going to restart it.
00:03:16.510 - 00:03:23.546, Speaker B: Yeah. And also, how do I screen share and how do I use the chat? I'm sorry, it's the first time here and I'm.
00:03:23.738 - 00:03:28.510, Speaker A: It's all right. So you screen share on Zoom.
00:03:33.750 - 00:03:36.420, Speaker B: Okay, screen sharing on Zoom is easy.
00:03:37.430 - 00:03:42.226, Speaker A: There you go. So you screen share on zoom, and if you have a link for your.
00:03:42.408 - 00:03:45.090, Speaker B: Yeah, I send it on slack.
00:03:45.450 - 00:03:57.110, Speaker A: Okay, so I need you to authorize me to speak in the discord. I just raised my hand, you should be able to say, hey, go ahead and respake.
00:03:58.730 - 00:04:08.060, Speaker B: I don't see a request. You are here now. You don't need me. You're a big boy.
00:04:08.430 - 00:04:29.940, Speaker A: No. Okay, cool. Before we start, I just want to mention again we're going to post the links to the slide in the chat. If you want to ask questions, you can ask them in the YouTube chat and in the community calls channel. I will monitor it and make sure that we answer the questions.
00:04:34.970 - 00:04:40.380, Speaker B: Okay, can you all see my screen? Can I start?
00:04:43.070 - 00:04:44.220, Speaker A: Yes, you can.
00:04:47.950 - 00:05:21.800, Speaker B: Okay, so it's great to be here. First time in the community call. I'm Ahad, I'm product manager at Starquare. Work a bit with ENRi and a bit with other people. And for the last several months I organized a decentralization research in Starquare. And we had a lot of internal debate and a lot of discussions, not only about how to do it, but also and mainly about what we want to achieve. So this is like the agenda today.
00:05:21.800 - 00:06:14.674, Speaker B: We'll explore what we want to have from the decentralization protocol and most notably why we can't have it all. We want to get a lot of feedback, and I don't know if people are talking in the discord, but potentially I'd love to have some discussion about what people think that is required and what their opinions are. And then if some time remains, we'll take some potential requirements and see how to build really a decentralization scheme around them. Obviously, all the presentation will refer to three posts we have in the shamans. I invite you all to read, tell me what a bad author I am, and then continue read and ask me questions. So let's get into it. Okay, so first of all, we want to decentralize darknet.
00:06:14.674 - 00:07:00.482, Speaker B: So this is like a bit big world, but let's discuss about what we for sure want to do. So first of all, we want to decentralize both sequencer and prover, right? If we decentralize the sequencers very well, but have only one proverb or vice versa. It's not really a decentralization. Secondly, provers are always limited to proving transactions that the sequencers agreed on. So we don't want to let provers the ability to reorganize transaction unless they really must. And thirdly, this would be like a proof of stake protocol. We don't want proof of work and number four, which is not really what we want, but like the scope of the discussion.
00:07:00.482 - 00:08:06.060, Speaker B: Obviously in a proof of stake protocol, especially leader based, we need some randomness to determine who is the sequencer, when. For simplicity, we assume that the randomness origin as well as the algorithm based on this randomness is out of scope. We just say, okay, we have a list of sequence cells and this is like a given. Okay, so if I discuss the general layout here, so we have the l two transaction senders, data sent transaction to the mempool. We'll have sequencers with a proof of stake BFT protocol that would agree on sequence of blocks and sequence of transactions. Then we'll have provers that would be in charge basically to echo those transactions to the stock prover, which would submit proofs to the stock verifier on chain as well as updating the stalknet call contract. So this is like the main division between what sequencer do versus what provers do and what is the lifespan of the transaction in the network in general.
00:08:06.060 - 00:08:11.658, Speaker B: Any questions so far? I tend to be a bit, yes.
00:08:11.744 - 00:08:33.714, Speaker A: There is a question. There is a question actually on YouTube. So Ezekie is asking why do we need to have a decentralized prover? Can't I run a prover on my machine and provide a proof? In other words, do we really need a consensus mechanism? Couldn't we just have a race to whoever publishes a proof as soon as he has one?
00:08:33.912 - 00:08:48.298, Speaker B: Okay, so when we say decentralization mechanism for the proverb, we mean that we need more than one proverb. If we have 1000 sequencer and one proverb, and the proverb say, look, I.
00:08:48.304 - 00:08:53.130, Speaker A: Go home, sorry, you're not on discord anymore.
00:08:54.910 - 00:09:04.080, Speaker B: What happened? I'm in discord. I'm right here. You see my screen? I'm talking.
00:09:08.130 - 00:09:23.250, Speaker A: You don't appear on my discord. This is weird. Okay, you know what, let's proceed. At least you're on YouTube and people can hear you there. So people on discord, if you can't hear Ohad, jump on YouTube. There's some weird glitch here, some black magic.
00:09:23.670 - 00:09:31.350, Speaker B: I'm sorry. Yeah, my discord is right here. Shall I leave and rejoin?
00:09:33.370 - 00:09:47.180, Speaker A: I'm not sure if it's just me or if it's not sure if it's just me, or if it's everywhere. So, people on discord, can you confirm whether you can hear Ohad or not?
00:09:49.630 - 00:09:50.380, Speaker B: Hello?
00:10:02.270 - 00:10:06.020, Speaker A: All right, let's proceed. We'll. We'll see.
00:10:08.230 - 00:10:26.330, Speaker B: Okay, I'll just rejoin the voice channel. Oh, great. Discord. I hate you. I officially hate you.
00:10:32.560 - 00:10:36.350, Speaker A: All right, so you should click on community call here.
00:10:37.520 - 00:10:38.364, Speaker B: Cool.
00:10:38.562 - 00:10:40.504, Speaker A: And maybe become a speaker.
00:10:40.552 - 00:10:41.052, Speaker B: Hello?
00:10:41.186 - 00:10:44.124, Speaker A: Yes, now this works. Okay, now I can hear you.
00:10:44.242 - 00:10:52.108, Speaker B: Great. Was my answer to that question this all satisfactory, or shall I expand more on why we want to decentralize provers?
00:10:52.204 - 00:10:53.680, Speaker A: No, I think it was good.
00:10:53.830 - 00:11:54.468, Speaker B: Okay, so let's get back to the presentation. So what is left to decide? So, first of all, I ignored here, like, the two important questions, which is, first, how is the chain of blocks being built? Right? Say that I'm the sequencer now. And then here is the second one, what Henry is doing with his time slot. And secondly, and this refers to the YouTube question, who are the provers and how are they chosen? Like, if sequencer automatically also approver, shall we allow several provers to work on proofs for the same thing in parallel? How do we decide from where to where? The blocks teach proverb proofs, et cetera. So this high level description might make sense, but it leaves out the crunch of the design. So let's get to the specific requirements. And this connects really to a shaman post I had, I think, almost two months ago.
00:11:54.468 - 00:12:34.720, Speaker B: And if you want to go back to it and add more to the discussions there, please do. But let's repeat on here. So what we want, we want to be permissionless, meaning that anyone can stake and anyone can participate. And this would allow us to say, okay, anyone can be sequencer approval. This is, of course, a must, but we also want to have sufficient de facto decentralization. Like, if we say that anyone can join, but the protocol stops to work. Well, when it has about above five sequence cells, it's not really decentralized, right? So here we have the question of what is sufficiently the fact of decentralized.
00:12:34.720 - 00:13:12.764, Speaker B: I had a Twitter poll around it. It got eleven votes. When I ask, okay, say that we have a proof of stake chain. Anyone can join the staking pool, anyone can participate in sequencing. But what is the number of sequencers, the factors that you'll feel comfortable with? And as you can see, like eleven votes is not much. If you have any opinions, I'd love to hear them now or later in any platform you'd like. But you can see that even in those eleven votes, it's bit uniform between people.
00:13:12.764 - 00:13:36.070, Speaker B: So we are not really sure what is the requirement and what the target. And as we'll see, if we say, okay, we must have at least 300 sequences. It has its trade off. We can obtain it, but it won't come for free. Okay, now is another good point for questions or comments about this poll. Anything?
00:13:36.920 - 00:13:53.900, Speaker A: Yes, just a sec. Yes, there is a question in the YouTube chat where Kartek is asking. It's linked. It's not exactly that, but he says, how many provers do we need? Should it be ten or do we need 100 plus? How does it impact proving efficiency?
00:13:55.920 - 00:14:35.912, Speaker B: I think that. Okay, so first of all, we indeed have a debate here, right? Whether decentralizing the proverbs above a minimal number is crucial. As I ask here, what is more decentralized, right? Network with 50 sequencer and 50 provers or 200 sequencers and ten provers. And the reason I say it is because by design, provers can't reorder transactions. They can only attest proofs to whatever the sequencers agree on. Unless no one submits a proof. And then potentially there are escape hatches to revert the order.
00:14:35.912 - 00:14:56.720, Speaker B: So this is why, like one or two provers are not sufficient. Later we'll see. Okay, sequencers agree on a bunch of blocks. Then we say, okay, the next proverb would prove this bunch of blocks, the next proverb after it would prove the next bunch of blocks, and so on and so forth. So we don't expect povers to walk on parallel on the same proof.
00:14:59.780 - 00:15:22.564, Speaker A: Something I wanted to mention also when you guys are asking, so what is the correct number of poover there? Is it ten, 100,000? I don't think there is a good answer to that. There's no. Oh, this is a good answer. This is the right answer. It really matters. This is why we're asking your opinion. There's no right or wrong characters.
00:15:22.564 - 00:15:46.210, Speaker A: What the community considers enough. This is something new. There's no, like, blockchains in general are relatively new. And what we consider enough, we as a community is enough. So it's important that you guys voice your opinion. What do you think about that? We don't have a better answer than you do.
00:15:49.860 - 00:15:55.090, Speaker B: Any more questions? Shall I move on? You're the YouTube guy.
00:15:58.440 - 00:16:30.824, Speaker A: So there's a question on YouTube saying, can we run the sequencer locally for low latency RPC call? That's more related to a full node. But I think there's a broader question here of what it means to be a node in Starknet. Like if you're just verifying the proof, or if you're also collecting transactions, aggregating them and sequencing them, I think you presented it a bit earlier. Like what are the different roles?
00:16:30.872 - 00:16:48.290, Speaker B: Yeah, right. So the sequencers get transactions from the mempool. You can view them as like, they're somewhat equivalent to minus on Ethereum, right? They are the generators of new block. Obviously anyone even now can have full nodes without being able to add more blocks to start it.
00:16:49.320 - 00:16:56.052, Speaker A: What sort of hardware would be required to run a sequencer? Probably big.
00:16:56.186 - 00:17:43.456, Speaker B: So I think it's too early to commit to specific hardware, obviously. I imagine though that the hardware requirements eventually would be nontrivial, just because we want to build very fast network. And the magic of validity roll ups is that unlike say Ethereum or Solana or any other blockchain really here you can say, okay, I have ten 2000 sequence cells with supercomputers and crazy machines, but still I can verify the proofs on the raspberry PI and make sure that everything was well executed. So if we say that the sequence cells are raspberry PI, we give up the biggest leverage we have here. So expect sequencer to be non trivial.
00:17:43.648 - 00:18:41.450, Speaker A: Yeah, I totally agree with you in a way. What validity rollups allow you to do is to do with execution what is done on proof of work networks with security. You delegate it to specialized directors that any actor can join this cohort of specialized actor. But as a simple validator in the network, you don't need to run all the security of bitcoin. You can just verify that it's correct here you'll be able not to compute all the execution, but verify that it is correct. It seems like just like you don't want to say in a proof of work network, hey, here's the maximum amount of ashes we want to be able to process at a given time. You want this to be flexible so that the more security people are willing to pay for, the more security the network has.
00:18:41.450 - 00:19:09.920, Speaker A: The same thing here, the more capacity people are willing to pay for the network to handle. We want the network to be able to accommodate for this. So there's no way to limit this, but to go back to the specific point. So it means that running a sequencer and improver will probably be something that is similar to what mining is today. So it's going to be a specialized endeavor that's going to be relatively expensive. And require specific machines.
00:19:10.260 - 00:19:14.640, Speaker B: Henry, I stopped hearing you double. So one of us is not on discord anymore.
00:19:16.420 - 00:19:39.640, Speaker A: It looks like I'm still on Discord. It looks like I'm still on Discord. You're not on discord anymore. Oh my. Okay people on Discord, if you don't hear had anymore you should join the YouTube link, it's going to be way easier. I'm going to take a look. If there are some questions in the community call channel, there's none.
00:19:39.640 - 00:19:44.284, Speaker A: Okay, so we can go on if you want.
00:19:44.482 - 00:20:15.824, Speaker B: Yeah, I log into the start network. Okay, I'm back to the discord. I hate discord. I'm sorry. Okay, so the next requirement we want to have is fast l two finality. And before I say what is this requirement? We need to understand what l two finality means. So let's go back to the life of the transaction.
00:20:15.824 - 00:20:58.690, Speaker B: This is like a bit different slide to highlight a bit different point, but it's essentially equivalent to the slide we saw before. The user sends a transaction, it's get to a sequence cells, I decide to include it in the stream, it gets to starknet, it changes the state. Then you wait for more transactions. After waiting for more transactions, there is a proof, the proof is submitted, state updates happens and like transaction is considered fully final only after step five. Only after we waited for more transactions and we proved they are working together and we updated the state. And this might take several hours. Now several hours is obviously much better than optimistic roll up for example.
00:20:58.690 - 00:21:44.496, Speaker B: But it's not an acceptable time frame for a lot of applications, right? The system would be totally unusable. If we say to you okay, you want to withdraw, you must wait 5 hours. There is no way around that. So what l two finality means is that we want to have some guarantee. Obviously it would be lower than a full finality, but we want to have some guarantee, say optimistically, even after the first block with our transaction in, it got approved that our transaction will get there. Meaning that unless something really unexpected happens, indeed in a few hours, it would for sure be final on l one. Right.
00:21:44.496 - 00:22:30.370, Speaker B: We need it for interoperability, for fast withdrawals, even with time sensitive issues like voting for example. Right. If the voting closes 2 hours from now, I want to be sure that my vote is included because otherwise the sequencer can trick me, pull the transaction out of there. And when it would get to l one, I would see that my transaction isn't there. So some sense of l two finality is without a doubt important. And here we have another debate, like is having 1 second finality, is that much better than having like 20 seconds or even 1 minute finality? Obviously it can be a few hours, but what's the trade off? Zell, any questions so far?
00:22:38.610 - 00:22:40.240, Speaker A: I'm monitoring it.
00:22:40.690 - 00:23:21.910, Speaker B: Okay, I'd move on. In the meantime, the next requirement is that it's inexpensive and inexpensive here, meaning regarding l one usage. Right? So like Starknet is not in the air. It's built over Ethereum, and we can use Ethereum as some kind of like public board. For example, you could imagine a protocol when each sequencer commits on l one to the hash of the new block or even to the transaction. It's included in his block, right? And then, okay, it's in ethereum, it can't be reverted. But if I, as a sequencer transmits to l one, the data of all the transactions I'm going to include, obviously this is like crippling.
00:23:21.910 - 00:24:12.494, Speaker B: We lose a lot of stalkness potential because we overuse l one, and we cause a lot of overhead and a lot of gas cost to the sequencers. So we would like to be as modest as we can with respect to our transactions that appear on l one as part of the protocol. Okay, next requirement is to be lightweight. What I mean by lightweight, it's close to inexpensive, but it's a different perspective. So by lightweight I mean, okay, we have starknet. Let's assume the current state starknet is decentralized, we have no decentralization, and all the starcore sequencer is doing is to process starcore transactions. Now obviously when we will add the protocol to decentralized, it would have some kind of consensus, right.
00:24:12.494 - 00:25:08.560, Speaker B: We'll have to prove that everything behaves according to the consensus. So some kind of inefficiency will appear during, due to this decentralization. This is inherent, but we want to keep it to a minimal amount as possible. Like for example, if you look on Solana, much more than 50% of the transactions they have is around the consensus. So what happens? They build this network that can contain say 2000, 3000 tps, but the factoid includes only say 400 or 300 tps of real applications, and the rest is dedicated to the consensus. So obviously, the less room we live for the real applications, the more expensive sending a transaction on becomes. So far so good.
00:25:10.710 - 00:25:30.534, Speaker A: Yes, so far so good. Okay, so Bartek is asking, what if the sequencer commits to a transaction, but the prover cannot prove the transaction, and it has to be. Yeah. How do you provide an escape hatch for that?
00:25:30.572 - 00:26:02.494, Speaker B: Yeah. Okay, so this kind of disaster is handled on two levels. First of all, there is some consensus mechanism on l two. As we'll see, other sequencers should either provide signature to your block like signature based BFT, or they build on top of your block like longest chain BFT. Obviously, if sequencers see that your block is shit, they wouldn't provide signatures or they wouldn't build on it so it wouldn't get included in what the proverb is going to prove.
00:26:02.542 - 00:26:13.966, Speaker A: So this is like, it would already mean that this is a consensus attack on starknet that somehow consensus failed because the sequencers decided to include a bad transaction.
00:26:14.078 - 00:27:08.280, Speaker B: Yeah, so first of all, this obviously doesn't say it won't happen, it just means that the attacker needs like 51% stake in order to execute this attack. But obviously if the sequencer commits to a bad transaction, the proverb would try to prove it because this is the protocol, and then the poverty wouldn't prove it. And then we'll say, okay, the poverty didn't prove it. We'll have some mechanism to gradually open the opportunity for more and more provers to participate. This is like a low level point that we debate internally exactly if and what intermediate steps would be. But at the end of the road we'll say, okay, all the provers, this is last call, prove it. If one of the managers to do it, we say okay, we heavily slash all the provers that didn't participate in the game so far.
00:27:08.280 - 00:27:47.410, Speaker B: If none of the provers know how to prove a transaction, then we heavily slash all the sequences that were involved in this kind of attack so it won't repeat and the state would indeed revert. Because in the end we rely on security of being able to prove and not on the consensus for the correctness. But having a finality on l two means, okay, you are open to a disaster where like 51% of the stake operates to exclude your transaction, but in order to do so, 51% of the stake in the system will get slashed. Right? So it's still high level of finality in reality.
00:27:49.270 - 00:28:17.610, Speaker A: Thank you. There is another question. So one, I think is the question, let me read it exactly. Is there some research paper talking about POS proof of stake in a roll up, or is it exactly the same as on ethereum? I think here the broader question is, do we need some kind of specific proof of stake algorithm, or can we take something off the shelf?
00:28:20.770 - 00:28:57.606, Speaker B: So indeed we can take something out of the shelf. And one of our suggestions is tendermint based, but taking something out of the shelf would never be enough, because decentralization for Zika roll up is unique in the sense that you have this extra roll of provers and the security comes from it. This is like a fails to requirement six as a cure. As a theorem. It means that even if you have 51% stake attack on the network, in a regular network like cosmos, you say, okay, the security assumption is that such an attack wouldn't happen. Starknet is an l two. So we say, okay, those transactions might happen.
00:28:57.606 - 00:29:22.000, Speaker B: And if this is the case, we can't allow the attackers to do whatever they want. We need to have escape etches. We need to handle it in the proverbs level. But we also need to make sure that if you have a sequencer that claims that the proverb didn't prove the claim and the proverbial that claims. Yeah, right. But the sequencer claim can be proven that we sort it out in a sensible way. One way is to say, okay, any proverb can outright to prove it.
00:29:22.000 - 00:29:26.260, Speaker B: And assuming we have enough proverbs, it's good enough.
00:29:27.830 - 00:30:14.850, Speaker A: Cool, thank you. There was an earlier question also, are there plans to keep the sequencer fairly decentralized? For example, with something like rocket pool or lido or will you let the market decide? I think maybe, I'm not sure that exactly is that, but there are some delegated staking services where people can delegate their stake to have it. Stake to have somebody else stake it for them. Is it something that we can imagine? I mean, if it's proof of stake based, to take turns in being a prover or a sequencer, can we imagine smaller player taking parts of these without setting up a huge infrastructure?
00:30:16.790 - 00:30:18.100, Speaker B: Sorry, say again?
00:30:19.590 - 00:30:32.998, Speaker A: So say today, for example, when you're a miner on ethereum, it doesn't make sense to solo mine. You join a mining pool if you.
00:30:33.004 - 00:30:46.460, Speaker B: Want to have stake delegation, I guess. Okay, we just mined the sequencers, but the assumption is that every sequencer has a lot of stake for many individual persons that delegated stake to it.
00:30:48.290 - 00:30:55.710, Speaker A: Okay, cool. And then there's another question. On what basis sequencer pick a transaction from Mempool.
00:30:58.210 - 00:31:30.250, Speaker B: Currently there are no restrictions. We're just thinking about how to handle consensus. Namely how you can be sure that this transaction will get included if the sequencers tell you that it will get included. We are thinking about Mev, obviously. I guess this is what this question refers to. But those kind of thoughts, like, if you have any ideas, we would love to see and hear all sorts, but internally they are not yet concise enough to present them like this. It's only research in its beginning.
00:31:31.870 - 00:31:34.220, Speaker A: Okay, cool. Thank you.
00:31:35.150 - 00:32:09.542, Speaker B: Okay, so the next point that I want to have, like, we have all those great requirements. The pain point is that we can't have it all. It's sort of like choose two between having very fast and very strong finality. Being lightweight and have tons of active sequences. And why is that? So let's say we have very fast and strong finality. Very fast and strong finality connects to, okay, we have block times of a few seconds. So very fast means, okay, after one block, we know for sure that this transaction would be there.
00:32:09.542 - 00:32:51.426, Speaker B: We can't allow to have, say, longest chain based block. When you say, okay, even if this block is accepted, maybe some other chain would get to be the longest. So very fast means that one block includes the stations from all the sequencers to agree that they agree to this block. And if this block gets reversed, they'll flash, et cetera, et cetera. This is like what very fast and strong finality means when you come to implement it, as far as I know. And then if you say, okay, I have a protocol that requires each sequencer to get stations from other sequence cells, it means that either you don't have that much, many sequencers, at least not sequence cells that are active in the same time. Right.
00:32:51.426 - 00:33:52.962, Speaker B: We can say, okay, each day we sample 30 sequence cells, but if I'm, the sequencers need to attest signature from thousand other sequence cells in a convoluted protocol with superlinear communication complexity, it wouldn't be extremely lightweight, right? And if I say okay, I want signature based or like attestation based finality, and I want to be extremely lightweight, it just wouldn't work with 500 sequences. So this is how we see it in terms of requirement. Obviously, we don't need to sacrifice completely anything here. Even if we say okay, very fast and very strong can mean wait 2 minutes, then it can work, right. If we say okay, 30 sequence cells are enough, it can work. If we say okay, we allow the network, the protocol to take, I say 20, 30% of starting capacity, it can walk. So we don't need to totally kill one of those requirements.
00:33:52.962 - 00:34:23.060, Speaker B: But we'll have to settle on something. This is at least how we view it. But we are far from being the world expert in staking and consensus protocols. So if you see an error in this argument, please tell me. And assuming there is no error, I had another Twitter poll with a lot more votes, so I guess many of you actually participated. And if that's the case, thank you. And I asked basically what is the most important.
00:34:23.060 - 00:34:47.130, Speaker B: The real agenda was to see which option gets the least amount of votes. And this is the option that I would say to myself, okay, maybe we can try to think on sacrificing it, but I doubt that the poll readers understood the full context that you now have. So I think this is another great point to stop for questions and comments.
00:34:48.750 - 00:35:13.298, Speaker A: Let me check. Okay, discord definitely stopped working. I can't get any feedback. I can't even access the chat so I don't know what to do. I do see the questions on YouTube, so keep them coming there. If you have questions in the audience, please let us know. In the meanwhile, ohad, I have a question for you.
00:35:13.298 - 00:35:37.990, Speaker A: You mentioned you had these polls, so here we can see your handle. What can the community do to give you more feedback? To give more feedback about the decentralization discussion? Should it be voting on Twitter? Should it be interacting on post? How can the community get more involved in this discussion?
00:35:38.490 - 00:36:42.350, Speaker B: Posts on Twitter are not like the universal tools of the world, right? It's just to make people more aware. It's not how we expect to have a deep dive discussion. So first of all, we did have this wrong direction. A lot of spoilers this first post here, which basically says what I said so far, it explains the requirements, it says why we can't have it all, and it begs for feedback for discussion about more aspects. So far it received one short yet very appreciated feedback of what about Mez and eight requirement. But if you have any kind of prioritization between those requirements or you have some new way of thinking to explain how we can achieve all of those requirements combined, I think comment on the shaman thread would be the most efficient thing to do. Also, feel free to dm me, but then other people wouldn't see your awesomeness.
00:36:43.570 - 00:37:09.910, Speaker A: Very cool. Okay, so DSI is asking what do we mean by decentralization in a roll up? Whatever sequence does, it can't corrupt the state, right? So I think here the question is why do we even need to decentralize starknet? Yeah, is it necessary?
00:37:11.770 - 00:38:02.360, Speaker B: I agree that the correctness of all the transactions come first and foremost from the poofs, and even being with one sequencer wouldn't allow the one sequencer to run anything invalid. But for real economical use cases, it's highly important that no transaction is being censored. For example, let's say I have an economical system and it's valid. All the transactions there are valid, but it has some kind of like lending market or perpetual trading or any other kind of market and there are no oracle updates. Why? Because the one sequencer there decided that oracle prices is a bad thing and you want to freeze the asset prices there forever. Right. So this kind of system, even if all the correctness is proof, obviously wouldn't make sense.
00:38:02.360 - 00:38:29.710, Speaker B: And as long as you have centralized system, even if it's in zk roll up, you must trust the sequencer. To some degree. I agree. It's much less trust than on Ethereum. And personally I also think that this is the reason why we can say, okay, 30 or 50 sequencers are enough for start net. Well, maybe for l one, I would say we need more than that, but those are gray areas. Like this is for the community to decide.
00:38:31.270 - 00:38:38.340, Speaker A: Perfect. Thank you. And there are no other questions.
00:38:40.230 - 00:39:30.306, Speaker B: Okay, so if that's the status, we can get to the second part of the talk, which refers to the other two posts we posted in the shamans, which is like getting to gist of concrete suggestions to how to actually decentralize. So if I wanted to look on the decisions from high level, we have sort of like two main and somewhat independent decisions. One decision is if we go with signature based l two consensus, like tendermint. If you have other candidates out there that you think would be more fit than tendermint, we would love that. To hear about them. We chose tendermint not because we extremely appreciate its theoretical efficiency, but because we know cosmos uses it. So we say, okay, there is some stack we can use.
00:39:30.306 - 00:40:23.038, Speaker B: Maybe we create other proof of stake protocols that we can use. We are not biased towards tendermint anyway. And all we want to have some longest chain based delta consent. This means that each sequencer choose of previous blocks he wants to prolong. And this means that there are some trade offs, right? Even if the sequencer really generated the block with your transactions, maybe it wouldn't get prolonged by other sequencers and it would get abandoned. So this is like the first decision and the second decision is, is being a prover a must for a sequencer? Is the protocol forces each sequencer to also participate in the proving phase? Or do we say, okay, we have this l two consensus. It continues to generate blocks.
00:40:23.038 - 00:41:02.942, Speaker B: And whenever a prover wants to prove what has been done so far, it can say, look, I'm volunteering to do this job. Obviously it's not volunteer. The protocol need to make sure it's compensated. But we say, okay, it's okay to be a sequencer without being approver. So those two questions are totally independent and the results can be mixed and matched. Just to show you the two most far alternatives, we took one combination, which is signature based, with forcing each sequencer to be the proverb, and we posted them on shamans. And we took also another one, which is longest game plus volunteering.
00:41:03.006 - 00:41:03.730, Speaker A: Proving.
00:41:06.070 - 00:41:07.540, Speaker B: Makes sense so far.
00:41:08.230 - 00:41:54.370, Speaker A: Does it's kind of like trying to mix Pokemon. It's fun to take attributes and you see what comes out. I have a question. So you're saying that the question is whether we want people to be able to be sequencers but not provers? Or is the role basically bundled? Is there a downside to also being approver when you're a sequencer? It sounds to me like being a sequencer would require a lot of hardware. Equipment like high hardware requirement. Proving also requires this. But once you've gone all the way to having a sequencer, how much bigger of an overhead is it to run approver?
00:41:54.950 - 00:42:47.458, Speaker B: So if we say okay sequencers would run all the transactions sequentially, then actually being prover is overhead. Because proving a computation is also always more complex than just run it. But this line of thinking is a bit naive, because when we talked with flashbots, the first thing that said okay sequencers wouldn't just be able to barely keep up with sequential executing. They'll have to paralyze and build those supercomputers that check the best mev options. And if you factor that, then improving is a lightweight job compared to it. I think the most not appealing aspect of being a prover is that you are exposed to slashing. So say that you are the hero that volunteered to prove transactions between ten and 11:00 a.m.
00:42:47.458 - 00:43:10.602, Speaker B: And a protocol expected to submit a proof by say, 02:00 p.m. And then on 130 p. M. Just before you're about to finish, you had electricity failure and your computer was shut down. And now you wouldn't be able to submit the proof in time. So obviously the protocol wouldn't be satisfied. You'd probably slashed a bit from it.
00:43:10.736 - 00:43:14.940, Speaker A: Couldn't you run a proof that you ran a proof up until 80%?
00:43:15.470 - 00:43:39.650, Speaker B: No, proof is like either you do it or you don't. So obviously being approver is like it has more risks than being a sequencer, right? Because if the same thing would happen to you, and you're only the sequencer, so worst case scenario, you lost potential block rewards if you were the proposer, or like nothing really major happened if you were in the proposal. But if you are the prover and it happens to you, exposed to splashing.
00:43:41.030 - 00:44:30.814, Speaker A: Cool. Thank you. And now that's a bit of more general question, but there's a lot of questions floating around, like how intensive it is to run approver. And I guess for a network like Starknet or Starkx, we're talking about big base loads. So this requires a lot of proving time. But my question is basically the following. Once we have the capacity to verify a proof inside another proof, how crazy is it to imagine that I do a single transaction and I use roll ups? I mean, I use ZK proofs not necessarily for scalability, but also for privacy.
00:44:30.814 - 00:44:40.002, Speaker A: For example, how crazy and how far fetched is it to imagine that I generate a proof on my cell phone for a single transaction?
00:44:40.066 - 00:45:27.030, Speaker B: Yeah, generating a proof on your cell phone for a single transaction is very feasible. I think maybe it would take the smartphone a couple of minutes to do it, but I don't think it's that hard. Problem. Obviously, to be 100% sure, it's better to ask the engineering here at stockware. I never tried to do it, but I guess it's not that hard. The real issue with proving transactions one by one, even when you have this recursive proving, is that in the end, if you look back at the flow of transactions, maybe you save a lot in step four. But in the end of the day, when you update the state in step five, you pay a transaction for every underlying poof.
00:45:27.030 - 00:45:39.474, Speaker B: So the 5 million cost of the poof can be shared and composed between how many poofs you want. But in the end, each poof is like a poof or a state update. And this state update wouldn't be split.
00:45:39.522 - 00:45:51.706, Speaker A: I think, or unless you have everyone do their proof separately, and then you aggregate them into a proof, and this proof is the state of that anyway, then you can think about a lot.
00:45:51.728 - 00:45:53.358, Speaker B: Of, you can do a lot of things.
00:45:53.444 - 00:46:07.442, Speaker A: But my question, I guess was more. And you answered it was more like, is proving necessarily something where you need a supercomputer to run for hours? The answer is no. There's a wide spectrum here, and you can imagine proving stuff on yourself.
00:46:07.576 - 00:46:14.454, Speaker B: The factor to be not more stronger than the sequencer. I think it's just about the risks, not about the hardware you need.
00:46:14.572 - 00:46:15.880, Speaker A: Interesting. Thank you.
00:46:17.290 - 00:46:22.150, Speaker B: Any more questions before a deep dive into the summary of those two suggestions?
00:46:25.570 - 00:46:29.362, Speaker A: No. Olgu is saying shalom. But that's about it.
00:46:29.496 - 00:47:02.220, Speaker B: Okay, so let's start with longest chain and volunteer proving. Everything is documented in very detail in the shamans. So what happens here? Each sequencer can offer a new block on top of some other block and sequencers ideally should build on top of existing longest chain that they know how to prove. So blocks are accumulating on l two, according to this. This is, for example, like six sequences, I'm sorry. Each had a different time slot. So you can see how Shan can be built.
00:47:02.220 - 00:47:54.570, Speaker B: It has very low overhead, right? Because there is no consensus rules beyond enforcing that each one proposed the block at time. He should have proposed a block. So it can be lightweight with many sequencers, but we lose on the fast finality, right? Because even if sequencer number three tells me, here is the block, enclosed your transaction, and in the end it's not in the winning chain, it gives me nothing. So I need to wait several blocks before I can be even somewhat sure that my transaction would get in there. And now what happens? So, okay, this is how blocks are accumulating on l two. And then comes the proverb, the heroic proverb that says, okay, we have your sum blocks that accumulated since the last proof, one, two and four. Okay, I'm sorry, it's obviously one, two and four, not one, three, or.
00:47:54.570 - 00:48:32.770, Speaker B: And he says, okay, I'll prove blocks one, two and four. But if all he would do is to prove one, two and four, you would have a problem, right? Because maybe block number four is malicious, right. The network still didn't build on it. The other sequencers didn't agree, and now it's already in l one, like in the committed state to be proven. So in addition to that, he would prove, okay, I know some blocks, say five and six, that agree with block number four. Why they agree with block number four because those sequencer chose to continue. So like block four indeed reflect some kind of wide consensus between the sequences.
00:48:32.770 - 00:49:06.002, Speaker B: Obviously, the constants would be much more than three blocks to prove and two blocks to see that they're aggregated after it. But this is just to shrink it all to one slide. So he sent a commitment to l one, saying like, this is the block I'm going to prove. This is the status. And now all the sequencers telling to themselves, okay, he would probably prove this block. We will build on top of block number four. They can commit to the next proof in the chain before this one finishes its job.
00:49:06.002 - 00:49:34.422, Speaker B: They don't wait for the proof to end before they commit to a new stuff on l one. So if I look on how the state of the first look from the l one perspective. So let's say we start with like state a is being proven. State a is say, what happened here before block one. And then I commit to a state b. Let's say state b is the state at the end of block four here. So I send my commitments to the l one contract.
00:49:34.422 - 00:50:03.462, Speaker B: Now the l one contract awaits to the proof of state b. And then Henry continued like l two continues to build on top of me. Henry say arrives to block ten and he tells to l one. Okay, I want to prove block ten. So now the network in the state is like, okay, state a is proven and state b and c are committed. Now let's say that the proof to b arrives fast, meaning I committed to block four. I prove b four, no problem.
00:50:03.462 - 00:50:28.026, Speaker B: The state is updated. It remembers that b is proven and c is committed. Let's say that I didn't send approv to block four. No problem, anyone can do it some constant time after me. And if they do it, the l one contact within fail that. Okay, state like block four is indeed valid and someone proved it. But Ohad was malicious.
00:50:28.026 - 00:50:53.458, Speaker B: Ohad didn't prove in time. So I'll slash Ohad and I'll move forward with my life. And the worst case, that's cap edge that Baltic referred to earlier is what happens. Like a lot of time passes and the provers are silent. No, proof never arrives. So now the contract would say, okay, it's been like two days or I don't know any other concept we'll come up with. No one proved block b.
00:50:53.458 - 00:51:31.794, Speaker B: I infer that block b is malicious. I go back to state a is proven. I'll heavily aden and read that promise, like to build something on top of b. And crucially, notice that all what you do really is causing latency from l two to l one. Because if somehow how Andrea and myself had like 51% attack and we caused this issue to happen, the rest 49% knows that it's invalid. They can continue to build on l two, they can continue to update the state. It just isn't committed to l one.
00:51:31.794 - 00:51:50.200, Speaker B: And at the end of the day, after this time period happens, everything would just say, okay, we'll fastly update l one to catch up with what happened in l two in this state. So the power of the poverty series is very limited by design and I talked too much. I'll stop now.
00:51:51.290 - 00:52:03.100, Speaker A: It's all right. Perfect. Thank you. I actually missed a question before Kartek asked, can the sequencers be slashed as well? If they don't include a.
00:52:07.890 - 00:52:38.120, Speaker B: Protocol, nothing enforces sequencers to include transactions. And according to this design, they even don't sign on. So like the only confirmation that you have that the transaction is included is that you have some full node, you see? Okay, Ohad indeed included this transaction, indeed, many sequencers built on top of Ohad. So now you have some kind of assurance. It's somewhat slow and somewhat weak, but you have some kind of insurance that this transaction would get there.
00:52:39.370 - 00:52:46.090, Speaker A: Sounds like being a sequencer, you have to have a big machine, but there is not a lot of constraints.
00:52:48.510 - 00:52:51.210, Speaker B: I mean, that's the case also in Ethereum.
00:52:52.190 - 00:53:06.830, Speaker A: You mean to run a node, to run a minor? Yes, to run a minor, yes, you're right to run a minor. But to run like a staking node, it's a bit different. You have to have some kind of warranties.
00:53:08.930 - 00:53:27.590, Speaker B: I mean, in this design, if you don't propose a block, for example, or you propose a block, that it's invalid. You just don't receive anything on your money, right? Because you get compensated and like the transactions are final only when this block is actually included, right in a proof. So if you did a bad job, you are not earning anything from your stake.
00:53:28.170 - 00:53:41.562, Speaker A: Okay, cool, thanks. Go ahead. Let me see if there are questions on YouTube. No question related to the discussion right now.
00:53:41.696 - 00:54:27.366, Speaker B: Okay, so let's look on the other conjecture of decision, which is like first we want signature based protocol and we want every sequencer to be a tour. So what happens here? Sequencers agree between themselves on transactions ordering via signature based consensus. Again, sendermint is just to show that such things have been done outside. Maybe there are better protocols that are not. Sendermint and sequencers need to provide signatures on block only. If they show, they'll know how to prove them and how we enforce it. We enforce it because we say, okay, says that like Henry, myself and Bartek, our questions ask are the sequence cells.
00:54:27.366 - 00:55:03.654, Speaker B: We had some signatures. All the three of us provided signature shells for a block. And now it's like above two cells of the stake. So this block enters to the chain in 10 minutes, 20 minutes, hour. Some new fresh randomness will determine which one. For myself, Henry and Bartech will be the proverb for this block and potentially this block and some blocks that came before it. So really when we generate signature of the proof, we know that there is a chance proportional to our stake that the protocol will tell us.
00:55:03.654 - 00:55:30.446, Speaker B: You are the proverb. Congratulations. So this is like another type of protocol. It has very fast finality, right? Because after one block, you see that the block is there, you see the transaction is in the block, you see the signatures. So you know, okay, if now there is any kind of reordering a cell of the stake is flashed. So it's very fast and very strong finality. But when you try to do it with many sequences, it wouldn't be light white.
00:55:30.446 - 00:56:22.042, Speaker B: So we have to compromise on one of the other aspects. And if I say, okay, we have this consensus and we have the provers and that's it, we actually turn into a liveness problem. Because what you do is like half of the stake suddenly disappearing. In the previous suggestion, it wasn't a problem, right? Because we say, okay, even if half of the stake is disappearing, the network would advance two times slower and long term, the participants would get more stake and be able to increase their percentages and will be all right. On l one cosmos, for example, it's not an issue because they just assume it wouldn't happen, right. Consensus is their security assumption. They have some kind of slashing in case stake is leaving the system slowly.
00:56:22.042 - 00:57:05.514, Speaker B: But if in one instant half of the stake goes down, they're like they're stuck. And we want to keep alive, right? We want to be able to be alive even if someone executed the 51% attack and then he shut down all of his computers. So this edge case, which isn't really bothering us in the previous suggestion, suddenly cripples the entire design here. So one potential solution for it, and I say potential with like asterisk. Asterisk, asterisk, because this is something I came up with. Everything you've seen here is like a lot of debates and discussions inside starcore is somewhat mature. This is like, okay, I have this problem, I need to solve it for the post.
00:57:05.514 - 00:57:37.122, Speaker B: I have a day, so I came up with this. But potentially there are other alternatives. So what happened is that I say, okay, how we can do it. We can do it in the following sense. The longer pastime between proof submissions and attestations that someone is going to submit a proof, the less stake would be required from the l two in order to agree on what to advance the state. So like in the happy flow, the stake is alive. You require two third of the entire stake on each block.
00:57:37.122 - 00:58:20.486, Speaker B: But if, for example, it's been three days and no one submitted the state update, then we started to expect, okay, something is really messed up with the l two sequences now, for example, 60% would be enough and all the rest are slashed. Potentially even those that did participate are slashed a bit to just prevent them from delaying the proof according to their choice. This is like a very extreme solution to this problem. I'm sure that potentially there is a better one. Again, I invite you warmly to participate in discussions on how to solve it in a better way. Yeah, that's all the material I had, but I'd love to have questions.
00:58:20.588 - 00:58:37.210, Speaker A: Comments Kel says yes, there are two questions. So one is Donovan asking when we say noit lightweight in your previous slide, I think, does it mean compared to Ethereum or Solana.
00:58:38.910 - 00:58:45.050, Speaker B: What percentage of the network capacity is dedicated to the consensus?
00:58:45.550 - 00:58:56.270, Speaker A: So it's not related to hardware requirement to be a sequencer. It means that it will take up a large bandwidth of the network capacity just for the network to be able to maintain itself.
00:58:56.420 - 00:59:13.262, Speaker B: Yeah, let's say that each block of Starknet has like 100 million chiral steps and some part of the block correctness is not only the transaction correctness, but also proving that this block was indeed produced by the protocol.
00:59:13.326 - 00:59:14.030, Speaker A: Correct consensus.
00:59:14.110 - 00:59:18.566, Speaker B: Agree on. So would it be like half a million or 20 million out of those.
00:59:18.588 - 00:59:31.820, Speaker A: 100 million kyro, which would change the equation quite a bit. And then Henri Berger is asking what will be the incentive to run a sequencer or approver, since it requires a non basic hardware spec.
00:59:32.270 - 00:59:52.738, Speaker B: So obviously if you participate in the protocol, you are staking some token, you have rewards. Maybe we'll have a block reward like Ethereum. Maybe it would only be fee from transactions, but it would be very similar to Ethereum in this regard.
00:59:52.904 - 01:00:13.820, Speaker A: Yeah, I mean, if some people commit some hardware to basically run the network and people pay a fee, there's some place where it works, right? Where people pay enough fee to cover the cost of running the network. So even just the fee should work.
01:00:14.190 - 01:01:00.150, Speaker B: Yeah, maybe like we work with some economics expert to see exactly how to build something that makes sense from economical perspective. For example, if we decouple sequencers and proverbs, there is another interesting question, right? Maybe there is a transaction that pay a lot of fees, so the sequencer would like to include it. But it's also very heavy on the proverb because for example, it has like 100 L 212 one messages that the proverb would need to pay the gods for. So we need to make sure the transaction is included only if it makes sense for the entire system to have it and not to accept transactions. That sequencer says, okay, I gladly accept it because I'm not approver, and then approver would get fucked.
01:01:02.590 - 01:01:27.280, Speaker A: That's interesting. Yeah, that's really interesting. I like the fact that we can reuse some part of what was invented before in the blockchain space. And for others, it's just a new paradigm. It's new roles, new roles new tasks and things like that. It's really fun. Yeah, let me check.
01:01:27.280 - 01:01:53.286, Speaker A: Okay. Does Starkware plan to take a person from the fees of Starknet? Will they just benefit from wearing their own prover sequencer? I would say to that question that right now we run the network and we don't make money from it. Running the network is actually a cost to us because there is no fee, and it will remain a cost for some time, even when we will have.
01:01:53.308 - 01:01:56.538, Speaker B: A fee next month. We'll just take the minimal amounts that.
01:01:56.624 - 01:02:32.200, Speaker A: Exactly. We're mostly implementing the fees right now, so that fees are there, but making it profitable to run sequencer is not right now the objective. And as for what is the role of Starquare in the long term future of mean? You can see Starkware as some kind of scaffolding for the network. We're here to get it up and running. We'll obviously be involved in the development, but the network will be fully decentralized. So.
01:02:35.370 - 01:02:36.440, Speaker B: I don't know.
01:02:37.770 - 01:02:54.540, Speaker A: I think there are futures where Starquare for sure doesn't take a percentage of the fee of the network. And once the network is decentralized, will it be Starquare's decision? Probably not.
01:02:55.010 - 01:03:03.760, Speaker B: Yeah. Elon Musk could buy 9.2% of darkness, maybe.
01:03:06.370 - 01:03:18.900, Speaker A: Okay, I hope that answers the question. And there are no other questions on YouTube for now. And discord definitely stopped working.
01:03:19.690 - 01:03:21.800, Speaker B: Yeah, I gave up on it a while ago.
01:03:24.970 - 01:04:06.740, Speaker A: All right. I don't know if you have other slides or if not, very cool. Okay, so there were a couple of somehow unrelated, not unrelated question, but a bit different question that I want to tackle. I'm happy if you stay around for two more minutes to correct me if I say something stupid, and then we can close the community call. So in the beginning of the call, and the SI was asking, I was wondering, does the verifier and Starknet core contract communicate together? And later he said, what are the differences between the verifier and the Starknet core contract? I thought the verifier was a unimutable, smart contract on Ethereum, but it seems that it's not.
01:04:12.330 - 01:04:45.966, Speaker B: The verifier is what verifies the proofs and Starknet contract. It uses the verifier. For example, the verifier verifies proofs generated by the sharp. It could also verify Starkx proofs. Starknet core contract manages the state of Starknet, obviously to update the state. It asks the verifier if this state update is justified. But it also, for example, manages a repository of pending l one to l two messages that weren't yet consumed by l two or l two to l one.
01:04:45.966 - 01:04:54.098, Speaker B: Messages weren't yet consumed by l one. So it does like the application level to connect all the dots there.
01:04:54.184 - 01:05:31.470, Speaker A: And you know, also when we say the verifier, there is a verifier on Ethereum, but the proof, being mathematical, can be verified by anything, really. I mean, we use a verifier which is smart contract on Ethereum, but it can be verified by a node locally. It can be verified by any kind of other program that is programmed to verify this. Think I don't have anything to add on your explanation. Thank you. Okay, so look, thank you a lot for your time. Ohad, thank you a lot for the discussion.
01:05:31.470 - 01:06:15.146, Speaker A: I want to state again that this discussion is very much opened and we need your input. Your opinions are welcomed and necessary, so don't hesitate and comment and get involved in the forum. And we have one last question. Since the network will work in proof of stake, how will you ensure a decentralized distribution of nodes and token? I'm not sure I understand the question. If it's proof of stake, how do we make sure the stake is decentralized? Basically, I think that.
01:06:15.248 - 01:06:41.700, Speaker B: Yeah, this comes from, obviously it's being sequencer would be profitable then more than one people would like to be a sequencer. If you have a case where anyone can participate in a proof of stake, but only Henry does, then I guess it's not that profitable. And Henry is like, I don't know the english word for it, but he's losing his. So.
01:06:43.050 - 01:07:18.474, Speaker A: Yeah, but that's a good question, which remains open. And if you have good suggestions for it, don't let it comment on the forum. All right, let's wrap it up. Thanks again, Joanne, for your time. And thank you everyone who stayed up until this time to listen to our call. We'll have the following community call in two weeks. It's probably going to be a bit chaotic because we have a hackathon in Amsterdam right after Devconnect in two weeks.
01:07:18.474 - 01:07:50.458, Speaker A: So I think it's going to be a pretty short call of me going around the hackathon and asking questions to teams and having people say hello on camera. But it's going to be fun. And then we'll have a more regular community call in four weeks. If you have a project that you want to present, don't hesitate and reach out. We'll be happy, happy to have you. And that settles it for me. Thank you for your time and enjoy your day.
01:07:50.458 - 01:07:51.290, Speaker A: Bye.

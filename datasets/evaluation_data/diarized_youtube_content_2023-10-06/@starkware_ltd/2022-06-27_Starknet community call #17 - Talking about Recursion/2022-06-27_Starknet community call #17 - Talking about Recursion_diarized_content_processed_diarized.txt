00:00:01.210 - 00:00:32.958, Speaker A: Hi, everyone. So I see people are starting to trickle in, which is good. Today, we don't have any visual support to go with the presentation, so it's mostly going to be a discussion here with Aviu, Shah and Shah about recursion, a specific speaker, a conference.
00:00:33.134 - 00:00:39.282, Speaker B: We have a clear one speaker, so I'm probably doing some advertisement, but it should be good one.
00:00:39.416 - 00:00:47.080, Speaker A: Perfect. All right, so you have one Shah with you, right?
00:00:48.010 - 00:00:51.318, Speaker B: Two shahas now. Before I had one, now I have two. Yes.
00:00:51.404 - 00:00:52.370, Speaker A: Wonderful.
00:00:52.530 - 00:01:03.580, Speaker B: We just wanted to make it easy for everyone, so we took the two engineers to the same. No, I'm joking. But this is how we split the effort here.
00:01:05.730 - 00:01:43.062, Speaker A: You know what? Let's start the community call. So welcome, everyone, to our community call. Sorry, you'll have a way to catch it up later on. Actually, I'm not sure it's going to be recorded, so if one of you, I know some of you sometimes record it, if you can record it and then share it in the channel, that would be very valuable. Please. So welcome to our community call. Today's topic is going to be a recursion.
00:01:43.062 - 00:02:27.520, Speaker A: So to give a short intro about recursion. Recursion is something we've been talking about for a while. We released a blog post called Fractal Scaling about it a while ago, but I think your talk in Prague was really an aha moment for a lot of people. It made things a lot clearer. I think a lot of people thought, oh, wow, I didn't think about that application or that one. And some community member were curious to hear more about it, which is why we're talking about it today. So thank you, first of all, thanks for coming.
00:02:27.520 - 00:02:43.050, Speaker A: And today we're four people on the call. So there's me, Henry, we have Avi, who on the call, and we have Shah. And Shah. Can you guys say a few words about what you do at Starkware, please?
00:02:44.780 - 00:02:46.580, Speaker C: I'm an engineer.
00:02:46.740 - 00:02:47.780, Speaker B: Starquare.
00:02:47.940 - 00:02:52.200, Speaker C: Worked on ecosystem in Starknet and skyhock.
00:02:52.700 - 00:02:55.690, Speaker B: This is the.
00:03:00.140 - 00:03:08.350, Speaker D: Name Shah Samoha. I'm working as a software engineer on the shelf proverbs system for almost two years.
00:03:10.240 - 00:03:12.976, Speaker A: Super cool. And I view your head of product.
00:03:13.158 - 00:03:15.170, Speaker B: Yeah, hi, I'm here as well.
00:03:16.660 - 00:03:34.280, Speaker A: Very cool. So I'll start with the first question. Is it random or is it something that was consciously chosen that both people working on the two ends of recursion are both called shah. So it's kind of a recursive naming system or it's random.
00:03:36.620 - 00:03:38.840, Speaker C: Yeah, I think it's random.
00:03:39.660 - 00:03:59.456, Speaker A: Okay, cool. So maybe we can start the call with a small introduction. Avi, if you can introduce in like 5 minutes, if you can give us a very summarized version of what recursion is and how we started working on it, that would be great. Please.
00:03:59.558 - 00:04:36.764, Speaker B: Yeah, I think I will only speak 5 minutes, because you have the creators here, so it's better to give them the stage. I will do to my presentation basically what Ricardian is doing, which is I already processed it once or twice. So now instead of taking an hour and then 20 minutes, we'll just take 5 minutes, which is also the basic concept. So it's nice analogy. So what we want, maybe I will start slightly differently than what I did in the presentation. I will start with the goals and note with what recursion is, and then I will explain it on a very high level, and we can go and.
00:04:36.802 - 00:04:38.044, Speaker C: Deep dive into it.
00:04:38.162 - 00:05:30.488, Speaker B: What we wanted to achieve with recursion are basically two main things, and we achieve few more things with it. But the two main things we wanted to achieve is we wanted to increase the capacity of what we can prove. You can think about in a given time frame, or using a given gas cost, and reduce the latency of how much time it takes us to prove those things. And this is basically the main goal that we are trying to achieve here. But there are many other nice benefits that we can touch during the call of recursion. So what is recursion in the context of proofs? It basically means that so far you were all used to the following concept. You have a program, you write it in Cairo, you prove it, and then you verify the proof.
00:05:30.488 - 00:06:30.048, Speaker B: And that's how you know things are working. Normally, running the proverb takes some time, which is somewhat related to the original computation time. So let's say 100 x or 1000 x over the computation. And verifying is very, very short. You can think of it as if it's not too complex, then you can think of it as a log t, of a computation of length t, and if not, it's practically close to a constant time. And what you do with recursion is you take the verifier, which is by itself a program, and you're not using it as the last step, but instead you prove the running of this verifier program as another step. So instead of verifying a proof, you can verify the verifier verifying a proof, and you can continue with this on and on.
00:06:30.048 - 00:07:46.628, Speaker B: And because we said that the verifier runs in time much shorter than the original computation, then also proving the verifier typically takes much less time than proving the program that was originally targeted. And this beautiful advantage is something that we can use to now increase our capacity and increase latency. Increase capacity because if before we were limited by t steps, so now we can take those t steps, generate one proof, and now we can prove those t steps by proven the verification of this. So it's only lock this step which is much much smaller. So to the same imaginary box of t steps, we can push many smaller boxes of lock t steps. And we can basically prove many programs where previously we could prove only a single program. And latency is reduced by the fact that you can prove many of such programs in parallel and then take any two proofs that are the outputs of the first proving step and proving the verification together, which cause everything to be run much nicer in parallel.
00:07:46.804 - 00:07:47.496, Speaker E: And that's it.
00:07:47.518 - 00:07:54.748, Speaker B: I think those are like my 5 minutes. I don't know if it was crystal clear, but let's dig into it with the experts we have here.
00:07:54.834 - 00:08:10.610, Speaker A: No, that's great. It is very clear. So if I can ask. So you mentioned Shahar Papini and Shaha Shamoha are both working on the two ends of recursion. Could you guys give us a rundown of what these two ends are?
00:08:11.540 - 00:08:43.450, Speaker C: Yeah, the first end I'm working on, I'm Jacob Papini, is actually writing Cairo code that verifies stock proof. It's basically Cairo code. It verifies some mathematical things like evaluating the polynomials and doing these miracle proofs, all the stark things. So this is one side writing the carrot code that verifies itself.
00:08:44.860 - 00:09:00.940, Speaker A: This is equivalent. So this end, sorry for cutting you off. So this end is equivalent to what the verifier is doing currently on solidity. Right. So it's basically writing a smart contract that does the same thing on Starknet. That is done on Ethereum.
00:09:01.020 - 00:09:26.552, Speaker C: Actually it's not a smart contract. Yes. Today we have a verifier written in solidity, we verify written in c, and then we have a verifier written in Cairo. It's written not as interesting contract, it's just written in Cairo code which can be used in Starknet contract, but also in a lot of other places like in sharp. Yeah.
00:09:26.606 - 00:10:18.570, Speaker D: So I'm Shahra Samoka, I worked on adapting Sharp to use this tag verifier that is written in Cairo, such that if sharp until now could take some Cairo logics, pack them into a single proof and send them directly to the blockchain for verification. So now instead of sending this proof to the blockchain, it can create a verifier program written in Cairo, feed it with the proof as an input, and send it back to itself with a program that wants the verification of the original proof. So now Sharp has the recursive feature of sending verifier job to itself.
00:10:20.940 - 00:11:08.100, Speaker C: I also want to make some small distinction here. Note that even today sharp, without recursion, it can still prove a few programs together. It does so, but just because Sharp has a Cairo logic called the bootloader, which can just call different Cairo programs from one big Cairo program, which is the bootloader. So it was able and Shah Samocha added the feature that it can also not just run kyro programs, but verify. Call this Cairo verifier and verify a lot of programs and treat them as if they were just programs running on sharp.
00:11:08.260 - 00:11:45.460, Speaker A: Okay, I think I understand. So correct me if I'm wrong. Basically, sharp up until today was a Cairo program that had a bootloader that was able to load other Cairo programs and then aggregate these into one bigger program that gets proven and the proof gets sent to Ethereum. And what you're doing now is instead of loading these programs directly, you're loading a new program, which is a Cairo verifier, and you're feeding the programs directly to this verifier.
00:11:47.240 - 00:12:17.490, Speaker D: Not exactly. I think that in the old setup, like take multiple Cairo logics, whether of the same or no, wrap them into a single proof and send it to the blockchain, to Ethereum. But now instead of sending this proof to the blockchain, we can create a new verification program that is written in Cairo and send it back to sharp to be later merged with another.
00:12:20.620 - 00:12:36.110, Speaker C: Bootloader. In a lot of places right now it's also verifying proofs of other bootloaders, but also still on the leaf of this big recursion tree, it's in every node in the recursion tree, this bootloader appears basically.
00:12:36.560 - 00:13:04.080, Speaker A: Well, that's really interesting. Okay, so you can basically send a program, generate a proof for it, and then send that proof to another carrier program that generates a proof that he verified that proof. Right. And you can do this various times and it shrinks the proof size every time. And so it saves verifying time and resources on the other end. On ethereum.
00:13:04.240 - 00:13:04.612, Speaker E: Yes.
00:13:04.666 - 00:13:26.316, Speaker A: Right. Where do we stop? What is the criteria you guys have in mind when you sent it? Once you generated a proof, and then you send it a second time, why does it make sense to make it? I don't know. I'm just giving a random number. Why does it make sense to do this two or three times and not 203,000 times?
00:13:26.498 - 00:13:37.552, Speaker D: Generating proofs take time, so you pay for that with latency. If you don't want the jobs to have too much latency, you have to at some point send it to the.
00:13:37.606 - 00:13:39.970, Speaker B: Yes, I think it's worth explaining a little bit more.
00:13:40.900 - 00:14:12.524, Speaker C: I think I want to say that like Ville mentioned, there are two reasons why we want to occur in one is just making small improves, but the other is also for making them in parallel. If you think about the goal of making them in parallel, you get straight away what kind of recursion you want. Pretty much. You want to take the smallest parts you have and proving these small batches and then aggregating them together. That is from the parallelization side, I.
00:14:12.562 - 00:14:14.510, Speaker B: Think that today.
00:14:16.640 - 00:14:43.908, Speaker C: With regards to the proof side, we treat it more or less as a constant because they don't change all that much. Log squared on these kind of ranges is pretty much the same. So it doesn't really pay off. I think to just prove a verification of one program, we don't really do that. Do you want to answer?
00:14:44.074 - 00:15:10.750, Speaker A: So it's more for parallelization. Understood. And so parallelization can be used view in your talk you gave the example of having different jobs coming from different apps. Or if tomorrow there are various starknet chains, you could imagine having various app chains sending their job. Can you use parallelization when processing a single chain also?
00:15:11.460 - 00:15:15.600, Speaker B: Yes, definitely. So did you guys speak a little bit about sharp?
00:15:20.320 - 00:15:22.332, Speaker A: But the refresher would be useful for sure.
00:15:22.386 - 00:16:33.216, Speaker B: Yeah, I think it's worth mentioning. So sharp stands for shared prover and the basic idea is that it can take different jobs where every job stands for a Cairo program and some input. And typically this input is just a list of transactions. So you can think of sharp as a machine that can take a logical machine that can take many different jobs. They can be different in the input to the same program, but they can also be different in the program itself, and it creates a single proof for many, many different jobs. So sharp doesn't really care if you feed it with one batch of Starknet transaction and another batch of stark x version three transaction, or if you feed it with five different batches of Starknet. From the sharp perspective, he will take any list of jobs up to some limit and will unite them to a single proof.
00:16:33.216 - 00:17:20.300, Speaker B: And that's what it does. To answer your question, even if it's just darkness running on top of sharp. And let's say every block is a separate job for sharp because it has different inputs of like a set of transactions. From sharp perspective, it will take every block, prove it separately, can be done in parallel if there are many blocks waiting, and then unite those proofs in a recursive way until it will reach a single proof. And then we'll submit it to chain. So you will enjoy parallelization and increase in speed, like reduced latency. Even if it's a single app, it doesn't prevent it from being used.
00:17:20.390 - 00:17:28.500, Speaker C: It's a single app, but with a lot of transactions. And even if they are dependent, it doesn't matter because they can prove it independently.
00:17:29.240 - 00:18:04.268, Speaker B: Yeah, that's an important point. I wanted to make one more comment on me, if I may. Maybe it's not clear, but the verifier program that Shah wrote has some basic size in Cairo. And then also, correct me if I'm wrong, Shah. But it also has a cost that varies with the size of the proof. So this cost will get lower by the level of recursion. But there is still a fixed cost of some chiroprom that represents this verifier.
00:18:04.268 - 00:18:08.770, Speaker B: So it won't get infinitely small.
00:18:09.220 - 00:18:13.424, Speaker C: It doesn't really shrink more like it converges to this constant.
00:18:13.472 - 00:18:14.070, Speaker E: Yeah.
00:18:14.760 - 00:18:18.048, Speaker B: That's one extra comment I wanted to say about the previous discussion.
00:18:18.224 - 00:18:18.950, Speaker E: Yes.
00:18:22.640 - 00:19:21.170, Speaker A: Okay, very cool. Makes sense. Thank you. I'm curious about how did we get started working on a recursion? Because from an engineering standpoint and from a mathematical standpoint, it's a fascinating topic. I mean, validity proofs in and of just themselves are fascinating, and recursive validity proofs are fascinating. But I find it really interesting that here we're really talking about concrete stuff, right? Reducing costs, reducing latency. When did you guys start working on recursion? When did it first come to your mind that, oh, we could have recursive proof? And when did it jump to your head that, yes, we need recursion for that? Is it something that was in the air for a while? Did you start working on it straight at the beginning? How did you guys actually implement this thing?
00:19:22.260 - 00:19:24.096, Speaker E: Well, first of all, I think that.
00:19:24.118 - 00:20:08.000, Speaker C: The idea of recursion was known to us from the very beginning. It's like a theoretical result, and that was known and other people were doing collision for other systems. Yeah. So it's not something that we invented in a way, so it wasn't in our minds all the time. And I think when we first thought about the CPU or Cairo, we said, gerry, computation it will be great for recursion. It will allow us to do recursion. So this was also in the back of our minds, though I think it stayed there for a lot of time without actually starting the work on version.
00:20:08.000 - 00:20:14.770, Speaker C: Why did the work on version start? Because. I don't know, we had time.
00:20:15.140 - 00:20:25.648, Speaker B: Yeah, I think it's a very good question, and I would also be very curious. When did we start working more? I don't know, maybe it was shatter initiative.
00:20:25.824 - 00:20:34.010, Speaker C: It's more like I wanted to work on crust and people didn't want me to work on crust, but they gave me other things to work on.
00:20:34.620 - 00:20:38.136, Speaker B: But I want to explain a bit more on the context. It's important to understand.
00:20:38.238 - 00:20:38.890, Speaker E: So.
00:20:40.640 - 00:21:14.340, Speaker B: I heard people talking about recursion as early as I think, over four years ago. I remember one talk from one of the solidity creators, Christian Reich or something, some long german name, apologize, I cannot pronounce. And he was mentioning recursion even back then. But it was a theoretical concept. Over the years, other systems implemented recursion, but we haven't. And one of the reasons that now it's much easier is because of Cairo. This is what chaka was mentioning.
00:21:14.340 - 00:21:32.680, Speaker B: The fact that we have Cairo makes our ability to implement recursion and even more be flexible with recursion, like much, much greater ability than what we had before. We don't have to deal with all of kind of nasty stuff or with less nasty stuff.
00:21:32.750 - 00:21:32.984, Speaker E: Yes.
00:21:33.022 - 00:21:41.740, Speaker C: And we can do also a lot of optimizations that aren't really very hard to do without this general computation, which is chiral.
00:21:43.680 - 00:22:16.490, Speaker A: Okay, understood. So what you mean is that in the beginning it was theoretically possible with proof, but writing proofs was difficult in and of itself. So thinking about recursive proof was a very higher level of difficulty. But now, once we got Cairo and we got the ability to write general purpose programs that are provable, it draw the line together much closer. And so Shahaz, you mentioned you wanted to work on crust, which is Cairo over rust, right.
00:22:18.140 - 00:22:20.890, Speaker B: It's out of scope. How much time do you have?
00:22:22.220 - 00:23:09.448, Speaker A: Okay, so you'll have to come back. Sorry, but okay, let's not talk about crust for now. And so you focused on recursion when you started focusing on recursion. Because I think we're talking about performances. But obviously recursion is also what I found fascinating with proofs is that it's the first paradigm where I see two chains talking with each other. When Ethereum validates a proof of Starknet, it understands to a certain extent what happened on Starknet, right? It's able to verify it without talking to a human. Having recursion really opens up the door to having a multilayer cross chain communication system.
00:23:09.448 - 00:23:40.260, Speaker A: So there's the engineering side of having lower latency, lower cost. There's also the product size side of it of having various change interacting with each other. When you started working on it, it seems like obviously you took it from the engineering side more than the product side. But can you talk about a bit about the difference? Once we have something that allows to have a more efficient sharp prover, how far are we to having Starknet chains that settle on Starknet?
00:23:40.840 - 00:24:30.832, Speaker B: You're talking about a concept that we sometimes call layer three. I think it will be an outcome of this recursion in the following sense. Right now we have a Cairo program that represents a verifier. We probably need to do some changes for it to be deployed on Starknet. But once we do those changes and you have a Cairo verifier on Starknet, you can now run sharp proofs against this verifier. What that means is that you can take Starknet or Starkx or practically any other Cairo program and verify it not on ethereum, but on Starknet directly. And what do you get by it? So first of all, verification will become much cheaper than on Ethereum because it's starknet.
00:24:30.832 - 00:24:33.376, Speaker B: So data is cheaper, computation is cheaper.
00:24:33.408 - 00:24:33.990, Speaker E: There.
00:24:34.440 - 00:24:42.532, Speaker B: Those are great benefits to verify proofs, except that if you have two systems that communicate over Starknet, then the communication.
00:24:42.596 - 00:24:44.200, Speaker C: Cost itself is cheaper.
00:24:44.940 - 00:25:10.992, Speaker B: But I want to dive a little bit deeper. It's actually an idea that I first heard last year on ECC from Shakar here. It was about different vms. So one interesting concept is that maybe I'm diving very deep. So if it's over the head, tell me.
00:25:11.126 - 00:25:12.530, Speaker A: No, please. That's perfect.
00:25:12.980 - 00:26:01.900, Speaker B: Okay, so here is a question. We got a lot a year ago. Why don't you run native EVM and instead you go with Cairo? And I think that by now this question is more or less settled. But let's say that tomorrow morning someone comes and you say, I understand Starkx, I understand Starknet, but I want my own VM. Why? I don't know. Maybe because you want to prove EVM steps, or maybe because they want to prove some whatever orbit VM or, I have no idea, mips or whatever VM they have in mind. So what they can do, I don't promise it will be efficient, but it will be more feasible, is that they can implement their VM in Cairo, like every state transition of their VM in Cairo.
00:26:01.900 - 00:26:40.316, Speaker B: And then they can use the verifier that we wrote in Cairo to verify those proofs. And the reason I find it interesting is because now you can have different environments on Starknet. The basic environment still operates on Cairo, but maybe you have a different environment that is for example EVM compatible. And people deploy their smart contracts that speaks EVM and whenever they want they go out of this ecosystem and they speak to the other ecosystem with some messaging system. So kind of an environment where you separate different execution layers. But at the end of the day.
00:26:40.338 - 00:27:15.380, Speaker C: They can all communicate with each other. I think it can be interesting concept. I just want to mention that another way to use it is maybe zero knowledge. You can't really use stock and zero knowledge because the prover is someone else and you can't give him your personal information. But you could do it yourself. If you have this program that needs to have zero knowledge inputs, you can prove it yourself and on stock and just have the verification of this program and you keep your zero on knowledge.
00:27:15.540 - 00:27:55.424, Speaker A: I mean you're assuming that people can prove things themselves so that there's a prover that they can use. So if they can use it, then probably there are also various sharp providers also. But yeah, I also think that this is also another question I wanted to ask you guys because we can go into the performance side, we can go into the multi chain side. This also opens up the door to having client side proofs. Right? So people could do, you could use this for privacy reasons for a bunch of stuff. Right? I could generate a proof on my phone and have starknet, a sharp process verify it on Starknet.
00:27:55.472 - 00:27:56.772, Speaker E: Right, right.
00:27:56.826 - 00:28:06.600, Speaker B: As long as you have proof system that matches this verifier, you can use it to prove your own stuff on cyclone.
00:28:07.660 - 00:28:57.960, Speaker A: This is really interesting. What I find fascinating with these systems is that it seems like in some way it mimics the architecture of the web today in the sense that it allows systems to specialize and separate. You can silo them, but you also have a unified layer at the bottom for them to communicate in exchange. Anyway, thanks, that's a great insight guy. So can I ask in concrete terms, where are we standing now? How far along are we with the development of recursion? And we're not asking for commitments here, we're just curious where you guys are and what are the next steps you guys are looking for in the development of recursion.
00:28:59.740 - 00:29:25.788, Speaker D: So we already have a working POC version of the recursive shop that actually absorb every data that's sent to sharp on mainnet and prove it by itself and settle it on gaily. It's really an early stages, so we don't have the numbers yet of the improvements, but we have a working version of this.
00:29:25.894 - 00:29:36.660, Speaker A: So wait, we already have a recursive proof that settled on going to. I'm going to quote Louis here. Did you tweet?
00:29:40.360 - 00:29:54.920, Speaker B: Normally on the engineering side, we wait a little bit longer before we tweet, but I do want to stress it a little bit more. It's not just an environment on Testnet. It's an environmental testnet that basically executes whatever production sees. Right.
00:29:54.990 - 00:29:55.944, Speaker C: Mimics it.
00:29:56.062 - 00:29:56.730, Speaker E: Yes.
00:29:57.360 - 00:29:59.390, Speaker B: It's a mirror environment, basically.
00:30:00.720 - 00:30:09.152, Speaker A: Okay, so you mean. So it could take what is today managed by sharp and execute it like in this POC. You could execute it.
00:30:09.206 - 00:30:10.688, Speaker E: Right, right.
00:30:10.854 - 00:30:23.860, Speaker C: We are executing it, yeah. We have another prime system, a system that mirrors all the inputs from the build system and just uses recursion. And it's running right now.
00:30:23.930 - 00:30:24.164, Speaker E: Okay.
00:30:24.202 - 00:30:28.260, Speaker A: So it's basically like. It sounds like it's right around the corner.
00:30:29.720 - 00:30:41.320, Speaker B: It's not very far. Most of the questions that are delaying it are us being more cautious. Maybe you want to talk a little bit about the audits.
00:30:44.160 - 00:31:10.384, Speaker C: We did an internal audit of this. This is the first step just to make sure that everything looks sound and okay. And there are a bit of mostly documentation changes that need to be added. But after this, I think we are considering making an external audit.
00:31:10.512 - 00:31:37.208, Speaker B: Correct? Right. Yeah, I'm not sure. I think there are a few things that are getting. There is some technical issue in adding another built in which is not related to recursion. And then there is a 28 days delay on upgrading everything on Mainet. And there is an external audit that maybe will happen in par. So I think practically we are looking at between a month and two months before it's running on Mainet.
00:31:37.208 - 00:31:44.348, Speaker B: That's the not committing on exact timelines, but ballpark, that's what we are looking.
00:31:44.514 - 00:31:56.112, Speaker C: I think that kinetic is working on another improvement will make it a lot more efficient. And I think it's also around the corner. So maybe we would wait for it as well.
00:31:56.166 - 00:31:56.384, Speaker E: Yeah.
00:31:56.422 - 00:32:06.548, Speaker B: So, Emily, I think you can not officially. Timeline is months or two before it's running in production. And I think it's also worth talking about the roadmap for the.
00:32:06.714 - 00:32:16.650, Speaker A: Definitely, yeah. So what's next? So in the next two to three months, we'll probably have it on Mainnet for sharp. What's next?
00:32:18.220 - 00:32:24.040, Speaker B: A lot of things you want to talk about. Kinetic improvements and the scheduler and the plans.
00:32:27.920 - 00:32:48.480, Speaker D: So basically sharp faces the problem of online scheduling. Like it gets Cairo jobs to prove, but it doesn't know how many jobs it will get. And it wants to make as largest proof as it can to be set alone chain because that results in a lower cost per transaction.
00:32:49.620 - 00:33:05.210, Speaker C: Yeah, I mean it has a freedom to choose which jobs to prove together in recursive jobs. And this freedom, if you knew all the things we get in the future, it may be easier, but it doesn't. So we need to make some.
00:33:05.820 - 00:33:34.690, Speaker D: So in the old version, sharp had to choose which job to pack with another to a single proof. But now it has another decision to make. You need to choose which jobs to take into a proof, and whether to send this proof to the blockchain or send it to recursion back to itself. So the online scheduler become way more complicated than it was before.
00:33:36.680 - 00:33:39.296, Speaker C: Yeah, I mean it sounds like it's.
00:33:39.408 - 00:33:54.084, Speaker A: More complicated, but it's also easier because in one case you have to choose which job you pick before proving. And in the other case, even if you take too big of a job, you can always reduce it down the line to fit the actual proof.
00:33:54.132 - 00:33:54.730, Speaker E: Right.
00:33:55.900 - 00:34:11.710, Speaker C: There are also deadlines for jobs, so you need to be careful when you match them. Maybe you only have two jobs right now, but one has a big deadline, the other has small deadline. So, do you?
00:34:14.020 - 00:34:14.770, Speaker E: Yeah.
00:34:15.380 - 00:34:56.860, Speaker C: Okay. And I wanted to talk about the improvement that kinetic vocal just mentioned. Basically it relates to the hash function. A big part of the stark protocol is miracle proofs. Now the miracle proofs are using hash that on one side we want to be efficient in modern architecture, x 86 in our computers, because eventually there will be proverb that computes tons of hashes on things. You want it to be fast. But on the other hand, this hash function will also be run in the Cairo verifier, which is written in Cairo.
00:34:56.860 - 00:36:01.440, Speaker C: We wanted to be efficient in Cairo as well, so the verification in Cairo wouldn't be very expensive. We don't really have a hash function that is good for both, but we noticed that we can combine hash functions, because if you look at the mercury tree for top layers, the proverb needs to do less of these hashes. And in the bottom layer he needs to do a lot more. But the verifier only checks a single path, so they're equal to him. So if we mix this, if we say the lower layers are friendly to x 86 to cpu, and the upper layers are friendly to Cairo. Then we get a good something in between, which this would make the proverb not a lot more experiment in the same order of magnitude. And the verifier would be a lot more cheaper.
00:36:01.440 - 00:36:07.284, Speaker C: Maybe ten times, something like that. Yes, the estimation is ten times.
00:36:07.482 - 00:36:10.870, Speaker A: Wouldn't this mean that you need to change your prover also?
00:36:11.800 - 00:36:14.596, Speaker C: Yeah, approver is modified. Yes.
00:36:14.698 - 00:36:20.272, Speaker A: Okay. So you need approver for higher layers and approver for the ones that get settled elsewhere.
00:36:20.336 - 00:36:24.504, Speaker C: No prover, just a configuration you can call it.
00:36:24.542 - 00:36:55.228, Speaker B: I think that's part of the power of Cairo. Right. So you change the program, but from the prover perspective, it just knows that this hash function is implemented in Cairo or built in. And this hash function is also implemented in Cairo. Built in. It's basically you change the program and now the prover has some configuration on what is the amount of hash function from type a. Let's say type a is fast to compute low to prove, and type b is flow to compute fast to prove.
00:36:55.228 - 00:36:57.056, Speaker B: And it just makes the tool in.
00:36:57.078 - 00:37:09.284, Speaker C: A way that is optimized. Avil, you are talking about proving the verification, right? Yeah, but also proving the initial program. It needs to use other c plus.
00:37:09.322 - 00:37:09.524, Speaker B: Plus.
00:37:09.562 - 00:37:11.704, Speaker C: Proven needs to change as well.
00:37:11.822 - 00:37:12.936, Speaker E: Okay. Yes.
00:37:13.118 - 00:37:44.850, Speaker B: And I think over time, by the way, I think that over time we will continue to touch this place in a sense that for now we know to optimize some specific hash functions and we have a built in for pedersome in particular. But in the future we might add more built ins for hash functions that enjoy from both like faster computation and shorter time to prove. So it might be the case that we will even further optimize there.
00:37:48.040 - 00:38:21.180, Speaker A: While you mentioned built ins, can you talk a bit about that? A few months ago I asked you how many built ins will we get? Will we get thousands of built ins? Like putting aside the fact that they're really specific and hard to produce, would we get in starknet like thousands of built ins? And you mentioned. No, there's a cost to them, so we won't have a lot of them. But from what I understand now, it changes a bit with recursion, right?
00:38:21.250 - 00:38:22.508, Speaker B: Yeah, it's a very good.
00:38:22.674 - 00:38:25.740, Speaker C: Also the adaptive layout.
00:38:25.820 - 00:38:30.464, Speaker B: Let's maybe start by you explaining what a built in is, why it's important.
00:38:30.662 - 00:38:48.368, Speaker C: A built in. Okay. Bunch of polynomial equations that verify something. We have an error for Cairo that verifies Cairo instructions that their execution is valid. We have an error again, a bunch of polynomials.
00:38:48.464 - 00:38:52.848, Speaker E: For Pedersen we have an error for.
00:38:53.034 - 00:39:38.070, Speaker C: Ketchup and for rain checks et cetera. And we can take all these bunch of equations and throw them into one big system, one big air that verifies both. This is it. So we can imagine that we have a cpu component that has caro instructions and it's alongside another error that has Pettersen instances and alongside another ketchup instances maybe. So we have a lot of things living in the same error. So we can verify 16 pearsons and 32 Cairo instructions and four catch ups in the same.
00:39:39.900 - 00:39:57.388, Speaker A: That's an orable comparison. Right. But you're talking cpu. So it's kind of like if Cairo was a specific chip and for specific operations it would send instructions to another component which would be for example a graphical card. Right. And these would be the built ins.
00:39:57.554 - 00:39:58.396, Speaker B: That is true.
00:39:58.498 - 00:40:12.528, Speaker C: It's like hardware. You can say everything is in our computer, everything is an integrated circuit. And in the arrow world it's a bunch of equations but they're all living together in the same box.
00:40:12.614 - 00:40:24.948, Speaker A: So when you're doing a Pedersen or basically it's like if you were calling a graphical card on your computer, it's sending to another chip basically in your computer.
00:40:25.114 - 00:40:42.270, Speaker C: In a way yes. It's worth mentioning the way that these parts communicate and they are communicated through memory, through the car of memory. So yeah, basically it's like if you had the real world component that talks to memory, then it would be very similar.
00:40:42.880 - 00:40:43.630, Speaker E: Yes.
00:40:46.160 - 00:40:49.070, Speaker B: That was about built in. Yeah, that was about building.
00:40:50.080 - 00:40:50.636, Speaker E: Cool.
00:40:50.738 - 00:41:32.152, Speaker D: What is, and actually the recursion feature also give us an improvement that is specific to buildings. Until now, each building that we wanted to add induced a lot of constraint on the solidity verifiers, which make it more complex. Now no matter how many builtins we have in our original logic, if we only prove a Cairo verifier program on Ethereum, we only need the built ins that we need for the Cairo verifier program. We don't need all the original built in that we use for the original logic.
00:41:32.296 - 00:41:32.604, Speaker E: Yes.
00:41:32.642 - 00:42:00.160, Speaker C: If we think about the recursion tree of programs that prove verification of other programs, then the solidity verifier only needs to verify the top. The root of this tree, which is its layout, is a lot more, maybe thinner, consistent. We know it looks like it's basically verifying some program and not maybe all the diversified programs you have on the leaves.
00:42:02.280 - 00:42:02.980, Speaker E: Yeah.
00:42:03.130 - 00:42:24.300, Speaker B: The point is that today adding a building to the verifier can be very ugly, meaning complex the verifier and increase the gas cost by a lot. And we don't want that and with recursion we can stop doing it for every building that is not used by the recursion step, which is amazing.
00:42:24.450 - 00:42:37.264, Speaker A: It basically allows solidifying the lower part of the stack so the solidity verifier and not touch them anymore. And push building built in development some layer above, right?
00:42:37.382 - 00:42:39.488, Speaker B: Yeah, almost not touching them.
00:42:39.574 - 00:42:40.210, Speaker E: Yes.
00:42:41.060 - 00:42:48.150, Speaker A: Wow, that's really interesting. Okay, that was my question about built ins.
00:42:51.640 - 00:43:53.764, Speaker C: I want to mention maybe a plan we have on the works for the adaptive layout. Right now we have a specific set of layouts which says, basically says which built ins are in this proof. And what is the ratios? I mean for every Cairo instruction we have four pedersens or something like that. And we have a specific set and the schedule needs to choose the best one. And a lot of time it makes a lot of unused things a lot of waste because if the best layout we have doesn't use like half of the Petrocens in this layout, then they are going to waste. We are still paying for proving them, but we're not actually using them. So we have this concept of an adaptive layout that we can choose any combination we want on runtime for our layout.
00:43:53.764 - 00:44:01.608, Speaker C: We can say these programs only use this much person and this much instruction.
00:44:01.704 - 00:44:02.620, Speaker E: So we'll.
00:44:05.200 - 00:44:33.540, Speaker C: Play with the error on the fly and decide where all the columns and ponos go. And then we have this layout and the verifier will also be dynamic and know, okay, I can play, I can move these columns and I dynamically know this error and I can verify it. And this leads to a lot of cost savings in the usage of built ins mostly.
00:44:35.640 - 00:44:57.804, Speaker A: This is really interesting. Thank you. I just want to mention that we have about 180 people listening to us. I see no questions in the community calls channel. So I'm pretty sure everyone is a specialist in recursion and understand everything. In case some of you have questions or have things that they don't understand, please ask questions, it's important. We're here for that.
00:44:57.804 - 00:45:40.440, Speaker A: So you can ask them in the community calls channel and we'll be happy to answer. Okay, so thank you for this technical deep dive. It's really interesting. Wanted to ask something more like. Okay, so now taking a step back, where do we go from that to being able to use recursion and recursive functions easily in Starknet? When will it be as easy to deploy your own starnet and have it settled and verified by a public starknet as it is to do it with? I don't know, geth or cosmos?
00:45:43.020 - 00:46:26.890, Speaker B: Good question. There are a few steps here. I don't think any of them will take too long, but the first thing to do is first take out recursion to be live. Then probably we need to adapt both the verifier in Cairo and sharp to work with Starknet. So that will be the next step. And once this is done we will follow by adding both Starkx and Starknet to be able to run on top of Starknet as an error three. So this is on the technical roadmap for the next six to nine months.
00:46:26.890 - 00:46:45.884, Speaker B: And then the only thing that you would need, obviously people could write their own whatever SDK to deploy Darknet, but the only thing that you would need, if you really want to deploy everything and run everything by yourself, then you would also need a prover that you could run against it.
00:46:45.922 - 00:46:46.556, Speaker E: Right.
00:46:46.738 - 00:46:52.768, Speaker B: That's something that I don't know what the timeline to release, but I'm pretty sure it will also be available at some point.
00:46:52.934 - 00:47:06.404, Speaker A: Yeah, for sure. We talk about the decentralization of Starknet. Having an open source prover, I mean having a prover that anyone can use is a prerequisite for Starknet to be decentralized. So it will probably come along with that, right?
00:47:06.602 - 00:47:07.350, Speaker B: Yes.
00:47:08.840 - 00:47:32.620, Speaker A: Okay, cool. Okay, so it's not too far in the future. So within the next few months we're going to see the first recursive proof to have efficiency gains. Then within the next year, hopefully we'll see the first l three emerge. Where do you see this going? Like five years down the line? What do you think the landscape around Starknet and validity roll ups look like once we have usable recursion?
00:47:34.340 - 00:47:36.800, Speaker B: Five years ago there was no starcore.
00:47:37.380 - 00:47:42.464, Speaker A: I know five years is a long time, but that's what makes it interesting.
00:47:42.662 - 00:47:44.050, Speaker B: For a year and a half.
00:47:50.340 - 00:47:50.704, Speaker E: I.
00:47:50.742 - 00:48:21.788, Speaker C: Hope Starcraft will be decentralized by then and you will have your approver and it will be on track like it will be used and the major changes will be. I know some protocol changes and built in Dow decisions. I think that this year and a half is mostly about centralizing, making everything easy for developers, for users, making it comfortable. It's hard to see past that.
00:48:21.954 - 00:48:23.608, Speaker E: Yeah, I also think that.
00:48:23.794 - 00:49:28.996, Speaker B: Interesting if you want like more further prediction, right? So let's say in the next year or so we are working very hard towards decentralization, which means it's not just opening the proverb, it's also creating some leader election or consensus mechanism on top of Starknet, releasing a sequencer, working on peer to peer for full nodes. It's a lot of work, it's not just open sourcing some code. I think once this is done and out there it will be interesting to see what path people are taking. Is it running layer threes that are like forks or replications of Starknet or Starkx? Or will people actually take the path of writing their own Cairo programs for different operation systems? This is more far up to the future, I think Cairo can be used in many ways and Starknet is a layer that we try to make both decentralized and very flexible. So yeah, who knows, but that will.
00:49:29.018 - 00:49:30.260, Speaker C: Be interesting to watch.
00:49:30.410 - 00:50:02.270, Speaker A: Yeah, for sure. I'm looking forward to, I hope one day Starknet or validity proofs can be used to enable easier cross chain communication. Like if Starknet is able to understand, to have a storage proof of what happened on a chain and then on other chain and serve as a kind of. Not sure if it's a hub in the middle or what it is. And I know there are way more complex things around that than just recursion and storage proof, but I'm really curious to see what could happen with that.
00:50:02.720 - 00:50:38.312, Speaker B: I can mention that there are a few projects that are working on all kinds of implementations of light client of other chains in Cairo. So once you have that, let's say you have a light client implementation of bitcoin or something that knows to verify Solana consensus and state to some extent. Then when you deploy it on Starknet, if it gets information from the external world, it can verify the same way that light clients do. And on Starnet those kind of things.
00:50:38.366 - 00:50:41.196, Speaker C: May be feasible and then you can.
00:50:41.218 - 00:50:42.510, Speaker B: Get what you mentioned.
00:50:44.080 - 00:51:05.970, Speaker A: That's really cool. Atomic swaps cross chain settled trustlessly, for example. Okay, look, we're about to reach the hour and I've asked most of the questions I had. I propose we wrap it up. Do you guys have something else you wanted to mention or to discuss?
00:51:07.140 - 00:51:15.110, Speaker B: Yes, it's a lot of fun to speak with so many people about these topics, which I considered exotic, maybe not rightfully so.
00:51:17.160 - 00:51:38.670, Speaker A: I think the community is really interested in engineering in general and engineering at Starquare in particular. So it was a pleasure to have you. Thanks a lot, Aviyu, Shaha. And Shaha, it was really enlightening and it's super interesting to see how these things we use every day get developed. So thanks again.
00:51:39.680 - 00:51:41.070, Speaker B: Thank you very much.
00:51:44.420 - 00:52:20.560, Speaker A: So to all of you listening, thank you for your time. See you in two weeks. I'll try to make a fixed time next time and to commit better to it and find a way to be both on YouTube and on Discord. In the meanwhile, I hope you enjoyed the call and don't hesitate to ask follow up questions. Sometimes these things take time to percolate, and we'll try to answer them once you guys answer these things. So thank you again for your time, and until next time, bye.

00:00:02.200 - 00:00:17.897, Speaker A: Okay. Hi. And great. So I'm very glad to be here. Thanks for coming. I'm going to be talking about fries and stocks over all fields via the elliptical fast Fourier transform. I will define many of the things that I say.
00:00:17.897 - 00:00:34.843, Speaker A: This is joint work with Ellie, Ben Sassan, Dan Carmon and David Levitt, who are all stuck with. Please ask questions if you. If something's not great. Okay, great. So I am. Yep, wrong one. Oh, good.
00:00:34.843 - 00:01:01.635, Speaker A: Thanks. Great. So in this talk I will first tell us what FRY is, although I'm hoping that some of many of you know what it is. And I will motivate it from the fft. Then we will study what happened in FRY that made it work. And inside we will talk about these things called FFTs. And then we will see a variant of it based on elliptic curves called the ecfft.
00:01:01.635 - 00:01:25.645, Speaker A: And this is what going to enable fry, which by default just works over fields with some very special number theoretic structure. And it allows it to work over all five all fields, all finite fields. And then we see FRY overall fields. And I will say in one slide stocks how it works also for stacks overall. Ok, great. So the setting is Reed Solomon codes. So let's have a quick crash course on these.
00:01:25.645 - 00:01:46.377, Speaker A: Where we have a finite field fq, for example the field of integers mod q. And we have an evaluation domain alpha 1 up to alpha n. And we'll call that set l. And we have a degree bound D which is rho times n. And you can think of Rho as 0.1 or something. It's a constant N is going to be very big and the degree d is going to be rho times n.
00:01:46.377 - 00:02:21.541, Speaker A: And L is a subset of the finite field fq. So automatically N is also at most q. And the Reed Solomon code based on these parameters is the evaluations of polynomials of degree at most d at all these points Alpha 1 up to Alpha. So it. So if you can see there are n evaluation points and we get take polynomials of degree at most D and evaluate it at these endpoints. So the code words of this code are of length n and there are Q to the D of them, roughly these are Reed Solomon codes. And the encoding for Reed Solomon codes works as follows.
00:02:21.541 - 00:02:57.455, Speaker A: If you have data y1 up to yd, and remember d is like 0.1 N. So it's not. And we're going to now make it into a code word of length n. So you take your data y1 up to yd and you write it there in our graph, right? So we draw those points right above Alpha 1 and Alpha D. So and then what we look at is a polynomial P that interpolates this data, P of alpha I should equal Yi for all the I's going from 1 up to D. And we find this polynomial and then we evaluate it all the remaining alpha I points.
00:02:57.455 - 00:03:28.337, Speaker A: This is the Reed Solomon code. This is how you take deep symbols of data and you make it into n symbols of data. And this is a very common, I mean this is a very, very general and powerful code. And in our context this operation which I did is also called low degree extension. You had some amount of data one over to yd, and I extended it by fitting a low degree polynomial through this and evaluated at endpoints. So these are Reed Solomon codes, this is the setting which we're working with. And Reed Solomon codes.
00:03:28.337 - 00:03:59.559, Speaker A: The main use is their error correction property. If you have two distinct polynomials of degree D, they can only agree on d points. So this means that if you take two code words of the Reed Solomon code, they differ on 1 minus rho fraction of the points because either way I set things up, D is rho times. So distinct code words are very far apart from each other. So they look very, very different. Good and low degree extensions are very, very useful in theoretical computer science. So yeah, they're very useful.
00:03:59.559 - 00:05:03.637, Speaker A: And I will summarize it with two slogans, both of which are wrong when you write them as it is, but there's some quantitative way where you can justify it with some struggle. And so the first statement is that algebraic properties of the data can be sensed in the low degree extension. You had your original data and you extended it from D to n. And if there was some algebraic property of your original data, then it's its influence can be felt in the other values of the low degree extension. An algebraic property that can be sensed, for example, is that the polynomial vanishes at the point zero, for example, such a property can be seen or maybe the sum of all the values is 7. A property like that can be seen elsewhere. And the other slogan, which is even more wrong is that all properties are algebraic properties because, and this is because polynomials come from addition and multiplication and operation.
00:05:03.637 - 00:05:46.935, Speaker A: Any property can be expressed in terms of addition and multiplication. And yeah, so there's some quantitative aspects which go in how complicated and algebraic operation do you need to express your property? This is going to show up in this. But the high level message is that yes, you one can use low degree extensions to check properties of your data. And this is where they're so useful in across theoretical computer science in proof checking and such, and in stocks too. Good. So the problem I'm focusing on, which is what Fry solves, is testing low degree polynomial. And what is this? So we have given access to some function L on fq, and we are going to be sampling coordinates from it.
00:05:46.935 - 00:06:27.345, Speaker A: And we want to tell whether F is low degree or not. So what we want is a sublinear time way to check F. We want it to accept polynomials of degree at most t. If F is truly a polynomial of degree at most t. We want, after sampling F in a few points, to always say one, if it is truly a low degree polynomial. And one curious aspect of this model is that if you're going to sample F in only a few points and you're going to accept everything that's perfectly a polynomial, then automatically anything that's close to a polynomial also has to be accepted with very high probability, close to one. So this is, this is the completeness aspect.
00:06:27.345 - 00:07:03.365, Speaker A: The, on the other end, we want soundness. We want functions that are far from degree d to be accepted with very small probability at most 0.01. This will be our problem of testing low degree polynomials. And the reason I talked only asked to reject problem functions that are far from low degrees, because functions which are near low degree are automatically accepted, so you have no chance of rejecting those. So we're only going to be able to reject functions that are far from loading. And this, this problem, as written, is some kind of testing of low degreeness. And sadly, even though it's a very nice problem with the very clear definitions, it's impossible.
00:07:03.365 - 00:07:47.143, Speaker A: And the reason for this is that polynomials of degree d, until you see d values, you cannot, you cannot know for a fact that what you're seeing is not consistent with the polynomial of°D. Polynomials of°D can take any values you want at d given points. So after you have sampled d over two values, you cannot be sure that this is not a polynomial of °D, because there is a polynomial of °D consistent with whatever you saw. So this problem, as I wrote it, is impossible to solve. You cannot get this kind of completeness soundness guarantee by a verifier who just samples F. Great. And so instead we will be working in this model where there's a prover who helps the verifier.
00:07:47.143 - 00:08:17.177, Speaker A: Again, this kind of question has been studied very extensively. There are many formalizations of this model, IPs, IPCPs, IOPS, and so on, also of proximity, whatever that is. So I'm now going to Tell you the exact problem that Frye solves. And this is it. So this is the property testing with help problem. For low degreeness, we have a string F in sigma to the end. We want to test if F is low degree or if it's far from low degree.
00:08:17.177 - 00:08:52.029, Speaker A: And you have a verifier who is checking F. But there's also a prover available who's going to try to help convince the verifier of this. It claims that F is close to low degree. That's what property P is in this case. So the verifier can now ask questions of the proverb, and the prover then responds by writing some long thing down. And then the verifier is able to ask to probe, just like it probes F in a few locations, it can also probe F1 in a few locations, whatever the prover had written. And then based on that, it can decide to ask some more questions.
00:08:52.029 - 00:09:22.945, Speaker A: And then the prover writes some more stuff and the verifier queries that some more. So this is a big interactive operation between the prover and the verifier, and the prover at each stage is writing down a lot of stuff. And the verifier can probe randomly the things that it has seen. It may not want to read everything that the prover is written because that will take a lot of time for it. But that's why it's only going to be probing it in a few locations. This big model is called the IOPP model, and we're testing low degreeness in this model. That's what Fry solves.
00:09:22.945 - 00:10:04.353, Speaker A: I wrote down there, what's happening. There's a verifier who sends random questions, the proverb answers down. The verifier can query individual symbols, symbols, and the verifier at the end accepts and rejects. And we want if F has this property of being low degree, the pro, the verifier should accept with probability 1. And if F is far, then the verifier should accept with low probability. No matter what proverbs strategy comes great. And the things that we care about in this model is the verify runtime, the number of queries that it makes, the total answer size of all the proverbs of everything the prover is written down, the running time for the proverb, the number of rounds, the amount of soundness that you get.
00:10:04.353 - 00:10:29.219, Speaker A: Things like this are what we really care about. This governs the efficiency of things in this model. And so now I can tell you what Fry is. Fry is An IOPP for this problem. It is an IOPP for testing polynomials of degree at most D. And that's what the F, R and I are fast read, solvent, ipped. And iopp itself is interactive oracle proofs of proximity.
00:10:29.219 - 00:11:00.575, Speaker A: And then it stops there and it's super efficient, very clean and concrete. And this is what underlies stuff. And the soundness also is very clean and concrete. Good. So now I'm going to go into the insides of Fry, and then as we go inside, we will see this limitation that it only works in certain over certain finite fields. And then I will talk about how that can get addressed. The key ingredient of FRY is an algebraic sketch.
00:11:00.575 - 00:11:27.859, Speaker A: I'm using the word sketch to mean something like a hash function. It takes this finite field F. Sorry, it takes this function F over the finite field. This is supposed to be the thing that's supposed to be of low degree. And it takes a seed X which is some extra randomness, and it puts them together and it produces an F prime which is of half the length. And this F prime I'm writing as hx of F. This is what this is the algebraic sketch.
00:11:27.859 - 00:11:54.165, Speaker A: And it has some properties that will enable the FRY protocol. The properties are degree preserving, its local, and it's farness preserving. And these. So let me just say what they are very quickly. If the degree of the original function F is D, then this new function hxf has degree at most d over 2. Okay. When viewed as a, as a function over some domain in an appropriate way.
00:11:54.165 - 00:12:27.605, Speaker A: Look, locality is that each output bit of HXF can be computed from two coordinates of F. And it's also farness preserving. And this is the heart of this, which is that if F is far from degree D, then HX of F is also far from degree D over 2. So we've changed the problem instance from size from size N to size n over 2. And the degree parameter D has gone from D to D over 2. And in some way we have preserved every aspect that we want. Things that are in that are low degree stay low degree.
00:12:27.605 - 00:12:56.771, Speaker A: Things that are far from low degree stay far from low degree. And this is almost a reduction to a problem of size n over 2 with just a constant number of queries. The constant number of queries is captured by the locality. We just have to make a few queries to check the consistency of this F prime with F. And this allows reduction of your problem of size N to a problem size N over 2 and one can recurse. And so I'm not now describing the protocol Fry, but I can just say it in words. There's F has been written down.
00:12:56.771 - 00:13:29.259, Speaker A: The verifiers picks a random X which is going to be the seed for this for this algebraic sketch. It sends that to the prover and asks the proverb to write down F prime, which is hx of F. And then we keep doing this again and again. And in order to be able to keep doing this again and again, whatever this algebraic sketch was should also be definable on a set of size N over 2 and so on. Okay, so now we go into the insides of this sketch. So this is based. This algebraic sketch is based on whatever happens inside the fast Fourier transform, the same algebraic magic.
00:13:29.259 - 00:14:08.357, Speaker A: So it works when FQ has a large power of 2 multiplicative subgroup inside it. So this needs Q minus 1 to be divisible by a large power of 2, like 2 to the K in this case. And in that case N is equal to 2 to the K. And then this is enabled when L is the set of nth roots of unity, where N is this 2 to the K. So it's only going to be a protocol for Fry for the special evaluation domain. The nth roots of unity, where n is the power of two. Okay, and this limits what field support fry? And this is a bit of limitation for what we want to do.
00:14:08.357 - 00:14:59.195, Speaker A: Maybe there are some things, and as there are some cryptographic instructions that are naturally defined over certain FPS, it would be nice if we could set up our Fry and stacks over those FPS and things will become much more efficient in that case, rather than simulating another field inside this field. Okay, so what is this hx that works once you have all these? It's based on this squaring map that takes nth roots of unity to N over 2th roots of unity. Since N is a power of two, the N over 2 roots of unity also sit inside the field and squaring takes all the two to the nth roots of unity. Sorry, all the nth roots of unity to the n over 2 unity. So this is a nice, in a nice 2 to 1 map. And. And so now the syntax of what hx looks like, hx of f is going to be a map from L prime to FQ L prime.
00:14:59.195 - 00:15:35.805, Speaker A: I call the n over two unity. So a function defined in the N through is going to get hashed into a function defined in the n over two roots of unity. And this allows for the recursion because The n over 2 roots of unity are just like the nth roots of unity. When you hash them, you'll get the n over fourth roots, unity, and so on. So we have all these sets of roots of unity starting all the way from the 2 to the KTH roots of unity, all the way down to the 1th roots of unity, which is just the top level of size one. And this is how the. This is what the algebraic sketch does.
00:15:35.805 - 00:16:01.433, Speaker A: It takes functions defined on an Li and it gives you a function defined on li minus one, Sorry, LI plus one, which is of half the size. Okay. And it. Okay, and this is. And this kind of beautiful structure only exists in fields of fields where Q minus 1 is divisible by high power of 2, at least as written this way. Good. So.
00:16:01.433 - 00:16:39.845, Speaker A: So now let me tell you exactly what this algebraic sketch is. It is we have taken the function F if it is of degree at most D. Here is a proposal of what to do with it. This is the same algebra that happens inside F. You take your polynomial F of X and you write it as a polynomial X squared G of x squared plus X times another polynomial X squared H of X squared. So we have separated the odd and the even coefficients, and the degrees of G and H are at most D over 2. Then G and H, since they take X square as input, are naturally defined on the set of squares of elements of L, which is the N over 2 through unity.
00:16:39.845 - 00:17:02.765, Speaker A: That's L prime. And so we got two functions defined on L prime. And now we're going to take H X of F is now defined to be a random linear combination of G and h. It takes g +x times h. It takes G and H and takes a combination of them with this random seed X. That's what H x of F. And in general, so.
00:17:02.765 - 00:17:48.757, Speaker A: So this is how I defined it on polynomials of degree at most t. The exact version of this also works for all functions. This is the explicit formula for how to compute the hx of any given function F. You compute the odd part and the even part, G and H, and you take a random linear combination and the locality is already baked in, because you can see that G depends only on the values of F on, say, square root beta and minus square root beta. Okay? So if we want to do such a thing in all finite fields, we need a lot of miracles to happen. So these are not going to happen. But we will have to adapt what we ask and be a little flexible, and then maybe we'll be able to do so.
00:17:48.757 - 00:18:21.665, Speaker A: The action here, lots of things happen so that we had the nth Roots of unity mapping to the N over 2 unity in a 2 to 1 manner by this map X squared. And then you could do it again. The do it again is a real miracle. Yeah. You also need this bijection that takes polynomials of degree at most d and it puts it in bijection with pairs of polynomials of degree at most D over 2. Yeah. The odd parts and the even parts, where those functions, those polynomials of degree at most D over 2 are, you should view them as evaluated on x squared.
00:18:21.665 - 00:18:46.269, Speaker A: The very same map which gave you the two to one action up above. Yeah, so things were. Lots of things were happening. Good. Okay, so we will start with that, that last decomposition lemma that helped us. They're breaking into odds and evens, and we look for generalizations of that and try to simulate that in other fields in some way. So here is the original decomposition lemma.
00:18:46.269 - 00:19:19.933, Speaker A: Every function, every polynomial, can be broken into its odd and even parts. Similar. Very similar proof of that. Very similar to the proof of that. Every function can be written as a polynomial in x squared plus bx plus c plus x times h of x squared plus bx plus c, where g and h of degree at most d over 2. Yeah, why is that? By taking off the highest degree part and peeling it off one by one, you can, you can get a statement like this, or maybe writing it in the base X squared plus BX plus C. That may be a good summary.
00:19:19.933 - 00:19:52.793, Speaker A: Okay, so this is how one can do this. And this also is true, and it's quite simple. But there's another variant that's true that will help us a lot now is that you can also do it not just with the 2 to 1 map x squared plus bx plus c, but you can do it with the 2 to 1 map, which is a rational function a x squared plus bx plus c over dx squared plus x plus f. Such a map also is 2. Well, first of all, one, that's an easy check. And there is also a decomposition of polynomials of degree d into pairs of polynomials of degree at most D over 2 in such a way. So once you plug in denominators, things get messy.
00:19:52.793 - 00:20:28.715, Speaker A: But you have to normalize it by fixing it. You see, I have my fixing factor dx squared plus ex plus f to the d over 2 minus 1 at the end, that fixes it. And every polynomial of°D can be written as in this form, where G and H of degree at most D over 2 and vice versa. So this is a nice bijection between polynomials of Degree d and polynomials at most d over two pairs of them, with this rational function sitting in between, this two to one rational functions sitting in between. So this opens up our minds to more things. Yeah, so this is a nice, interesting example. It's a nice exercise if you want to see that every polynomial degree at most D can be written like this in a unique.
00:20:28.715 - 00:21:14.545, Speaker A: Okay, so FFT. FFTs are a generalization of this two to one map that we saw with x squared to more general degree 2 rational functions. Okay, so what we want is sets L0, L1, L2 all the way up to Lk, where the size of L0 is 2 to the k. And we have 2 to 1 maps psi0, psi1, etc. All the way up to psik minus 1, which are degree 2 rational functions. If we can find such a structure where all the LI's are subsets of FQ the same FQ, then such a thing will. Based on things that I've already said, the previous decomposition can enable an FFT like thing and can plug directly into frat.
00:21:14.545 - 00:21:46.945, Speaker A: So we need, we need this, we need this kind of thing to be sitting inside finite field. And it's a big algebraic miracle when such a thing happens. I think so anyway. So such things, just by looking out, looking around at random, we were not able to find such things, but we did find such things sitting inside elliptical. So I'm going to jump a little ahead. So we want big FFTs over finite fields and we find them inside ellipticals and they're not of size N, but they're of size square. They're not of size cube, but they're of size square root in every finite field.
00:21:46.945 - 00:22:12.235, Speaker A: And. Okay, so I am running out of time. These are how elliptical look and I will emphasize the main points now. So an elliptic curve always has it's. It's a set of solutions to some curve to some equation. And the number of solutions to that is always some number very close to Q. But it's in a big interval between plus minus of length around square root q.
00:22:12.235 - 00:22:50.367, Speaker A: So this is the hasi wave boundary is used very frequently. There is the bound of during, the result of during, which is much less frequently used, which says that every integer in that interval is achieved as the size of some elliptical. Okay, so we will take an elliptic curve size which lies in that interval, which is a multiple of a large power of two. There is always a multiple large power of two sitting inside that. Great. And we will take that. Okay, so you can ignore the last bit that gives you that gives us the substitute for the roots of unity of size 2 to the K that subgroup in there.
00:22:50.367 - 00:23:27.815, Speaker A: So we can take an elliptic curve now of psi whose size is divisible by a large power of two of about size square root q. And within that you can take the subgroup L0 of multiples of the subgroup of size exactly 2 to the K. And based on this, one can produce a sequence of subgroups within that, which simulates the roots of the N over 2 with roots of unity and N over 4 through unity, and so on, because I'm going to skip a little bit. These are the elliptic curves. We find a sequence of elliptic curves. Within each there's a subgroup. All these elliptic curves are defined over fq.
00:23:27.815 - 00:24:02.485, Speaker A: And within each of these ellipticals there's a different subgroup sitting of size 2 to the K2 to the K minus I. And there are degree 2 maps Phi I, which map any given EI to EI plus 1. And it's a degree 2 map of elliptic curves. It's not a degree 2 rational function. But by taking whatever map we got up there and projecting down to the x coordinate, we also get rational functions that have this property. So deep inside this seemingly unrelated section of algebra, the 2 to 1 FFTs that we wanted are. They're just sitting there.
00:24:02.485 - 00:24:34.135, Speaker A: Okay, so let me very quickly say how this applies to stocks overall finite fields. So standard stacks over with the usual fry. How did they work? They said take. I mean, they start with taking a problem and writing it in air. This is the algebraic intermediate representation. So we take, we encode general computations, or in terms of constraints on values taken on functions defined on zn, where n is, sorry, z, where n is z 2 to the k. And great.
00:24:34.135 - 00:25:11.775, Speaker A: And then we take zn and embed it as the nth roots of unity. And then. And then on this we do low degree extensions in fry, etc. And since n was a power of 2, we were able to do all this. So to do it over all fields, we started with the exact same representations, the exact same errors that we use to define the general computations one can also implement. One can also take those exact same representations and start with those. And then the zn that we have, we now embed not into the nth root of unity over fq, which may or may not exist, but we encode it into an elliptic curve group which is isomorphic to zn.
00:25:11.775 - 00:26:04.495, Speaker A: And such a thing always does exist using the same during result that we talked about. Then once we have our problems expressed in terms of functions defined on elliptic curves. We can again do things like low degree extensions and Fry, this time via the ecfft and this gives us stocks overall. I'm basically out of time wrapping up. We saw Fry over all fields by the ecfft. The ECFFT also gives us new representations for polynomials that allow for n log n time operations, additions, multiplications and degree computation simultaneously, which was previously only possible for very special FQs. This enables stocks overall finite fields and you will see in upcoming talk circustac, which is a really one can work with even simpler curves in a super efficient manner, which also leads to nice improvements.
00:26:04.495 - 00:26:10.275, Speaker A: Great. So there are two papers on this ECF 51 and ECF 52 there on our webpage. Thanks.

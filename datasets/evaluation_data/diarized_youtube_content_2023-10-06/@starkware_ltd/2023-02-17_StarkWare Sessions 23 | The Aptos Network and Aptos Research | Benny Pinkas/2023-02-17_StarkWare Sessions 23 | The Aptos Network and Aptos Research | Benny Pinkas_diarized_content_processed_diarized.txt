00:00:03.050 - 00:01:01.070, Speaker A: Hi everyone, my name is Benny Pinkas. I'm a researcher at Aptos Labs and I'm also a professor at Barryland University. In this talk I'm going to tell you about Aptos Network and also a little bit about the research that is done at Aptos. So the goal of Aptos Aptos is the layer one blockchain, and the goal is to create universal and fair access to decentralized assets for billions of people. And we believe that we have the team and the community and the resources to do that. A major focus is to give developers the right developer experience so that they can focus on building applications and don't have to worry about the infrastructure. And the research that we're doing is focused in giving these features to developers.
00:01:01.070 - 00:01:53.550, Speaker A: The developer experience should be intuitive, instant and inexpensive. I'm going to talk quite a bit about making it intuitive, and it's also instant, meaning that from the time you send a transaction until it's being finalized, it takes less than a second and it's inexpensive. The transaction fees are minimal and there's also a fee market. So if you want to give more importance to your transaction, you can make sure that it will be processed even if the network is busy. But we assume that this will only happen. We think that this will only happen at peak times because the throughput of the network is very large. I describe some of the things that make the user experience intuitive.
00:01:53.550 - 00:03:09.974, Speaker A: In most networks, your address is the hash of your public key, which makes it very hard for you to change your keys or to rotate your keys. In Aptos, we decouple your address from your public key. So this enables you to change your public key, change your crypto algorithms, you have crypto agility. You can have smart contracts that will enable you to get your key back if you lose it, and it gives you a lot of flexibility that you don't have in other networks, transactions have sequence numbers and they also have expiration times, meaning that when you submit a transaction, you can add to it an expiration time, so that if it's not executed by that time, it won't be executed at all. So this gives developers confidence about the time the transaction will be executed. The system gives wallets the option to show users a human readable rendering of the outcome of the transaction. So this enables users to see what will happen based on the transaction.
00:03:09.974 - 00:03:58.250, Speaker A: And this could be a good tool to fight phishing on the blockchain. There is support for authenticated and light client using mercury trees, which are implemented in an extremely efficient way. And there was a lot of effort on making them as efficient as possible. And light clients can consume part of the tree and authenticate it and don't have to consume the entire tree. The validators that achieve consensus, they also agree on time. So this gives you a meaningful concept of time throughout the network. And smart contracts can use this time as part of their execution.
00:03:58.250 - 00:05:16.080, Speaker A: When Aptos was designed, it followed the following core design principles. Move is the smart contract language, and I'll go deep into each of these principles. The system has upgradability and configurability from the start, so it can be constantly changed without any downtime. The system supports extremely high throughput and low latency, and the architecture is pipelined, so the different steps of the transaction are executed in a pipeline manner and the transactions are executed in a parallel way using a system which we call block STM, which is quite novel and I'll describe it in a minute. So the move programming language, it started in Facebook, Libra, DM and many of the original move team are working in Aptos. Move provides a terministic language so that you can be certain about the outcome of your smart contract. It supports metered execution, so it's fair.
00:05:16.080 - 00:06:18.414, Speaker A: Transactions are being charged gas according to resources they consume. It enables data flow between contracts, so one contract can use data from another contract, which gives developers a lot of flexibility in designing applications on it. It enables autonomous on chain accounts supporting multi user accounts or dows. And it's also a move prover that each program it moves being verified. But you can also ask the prover to verify different properties that you want to verify for your program. Move is also resource conserving or conservative, meaning that resources allocated to smart contracts and there are different measures to make sure that you don't lose them by not taking care of them or duplicating them, et cetera. A major feature of the system is that it is upgradable.
00:06:18.414 - 00:07:52.390, Speaker A: We know that the web3 scene is constantly developing and we also have the research team which constantly works on improving the system. So the system was built so that it can be upgradable, meaning that the algorithms can be changed with no downtime. This has been done several times in the testnet and has been stress test and very soon we're going to upgrade the main net the research in Aptoslabs right now the research team is composed of six researchers and growing the focus on the research is doing it to be practical first and only then to publish it. And we try to find impactful and useful problems in the current AptOS system that we can work on, and there are plenty of such problems here. We have several papers of the Aptos research team that were published in the last two years on areas relevant to Aptos, and I will focus on two of them, block STM for parallel execution of smart contracts, and naval, and task for ordering transactions, disseminating transactions, and ordering them. So if I want to describe what the research is doing, I'll first describe how transactions are being processed in Aptos. So this will be the journey of a transaction from being submitted to being executed.
00:07:52.390 - 00:08:35.940, Speaker A: So the system is composed of validators that achieve consensus. We have currently 104 of them and a light client. When it wants to submit a transaction, it communicates with a full node. It doesn't see the validators directly. It communicates with a full node, and the full node sends a transaction to the validators who achieve consensus, execute it, store the result, and send it back. So in more detail, here's the client, it submits a transaction to the full node, the full node, send it to the validators, and they disseminate it through all the validators. So this is quite complicated process.
00:08:35.940 - 00:09:06.462, Speaker A: And then the validators achieve consensus about the order of the transactions they received. Okay? And this consensus is based only on the metadata, not on the data itself. So this way it's more efficient. They execute the transactions, and then they write them to memory in batch, and afterwards they write from memory to the mercury, to the state in batch and back to the client. And this whole process takes less than a second.
00:09:06.596 - 00:09:06.942, Speaker B: Okay?
00:09:06.996 - 00:10:02.814, Speaker A: So each block takes less than a second. Now the research comes here. The part execution is based on the block STM protocol, which I will describe, and very soon it's going to also be here. The dissemination will be based on our task. So when transaction comes it first being disseminated between all the validators, then they order it, then they execute it, write to memory, and then commit and write back to the ledger. So actually we have these five steps, okay? And they're being run continuously. So continuously you disseminate, transaction, continuously order them, execute them, write them to memory, and commit them.
00:10:02.814 - 00:10:59.378, Speaker A: So the way this is implemented is implemented in a pipeline, and all of these things are being run together. So first you go through dissemination, which currently has one system. Soon it's going to be naval and task, and they continually send blocks between them. Then they order the blocks based on the metadata itself, metadata alone, not using the blocks themselves. And the latency is less than 1 second for ordering the blocks that we received at the last second parallel execution based on block STM and block STM itself received in experiments on our network, a throughput of 160,000 tps. Then batch storage in batches, and then putting it into the merkel tree, building a proof and sending it back. And this whole thing takes less than a second.
00:10:59.378 - 00:11:56.290, Speaker A: And it takes less than a second because these are different pipelines and things are being pushed from one step to the next. And they continuously run a little bit about block STM. So this is a system for parallel execution, which is based on STM software, transactional memory. It's an old paper from I think 98 of Nil, Shavit and Dantrito, but it's been adapted to the smart contract setting, where there are different features that enable to make it more efficient and more practical, so it enables to have deterministic parallel execution. So the order is going to be deterministic. It infers the parallelism without any interaction with the programmers. So the programmers don't have to write hints about what can be run in parallel to what everything is being done automatically.
00:11:56.290 - 00:12:38.190, Speaker A: The transactions can be complex, and still the system understands how they can be paralyzed and paralyzes them. It uses an opportunistic approach, and because it's running a blockchain, you get a lot of hints from the ordering inside the contract between contracts. When the parallel execution writes things to memory, it uses a multiversion data structure for the same location. There might be different versions written by different things that are being run. And immediately the system understands which version is the right one for each read. And this is some numbers. So this is the performance.
00:12:38.190 - 00:13:19.790, Speaker A: We have the number of threads. Down here you have sequential execution, more or less. This is an implementation with only two accounts, meaning that there's a lot of contention, there's less room for parallelism because they fight for the same sources. And here we have 100 accounts, and you can see this is the TPS, 100 accounts with 32 threads. They get up to 160 tps, where sequential work gets only to ten k TPS. And this is only for the parallel execution. But it's quite impressive.
00:13:19.790 - 00:14:24.100, Speaker A: And this system is in production a little bit about how the Aptos system is running. When Mainet started, it was the largest launch of an l one. There were many applications that started running on the system from day one. Many NFT projects, many people contributing on GitHub, different games that onboarding to the system, a lot of followers and large community. The system, the network has been running for three and a half months already, with no single second of downtime, peak TPS has been more than 2000 transactions per second and the average finality is less than a second for clients. The timeline the company started about a year ago. It started based on open source code from the Libra project.
00:14:24.100 - 00:14:54.720, Speaker A: Soon afterwards they deployed a Devnet and then a testnet, and Mainet was launched in mid October. And the first update to Mainet should come very soon. If you want to learn more about aptos you can go to these resources on Askme and the company is very open to interaction with people who are interested in using it and I'm open to answer any questions. There's still time for questions.
00:14:57.170 - 00:14:57.920, Speaker B: Yeah.
00:15:00.930 - 00:15:43.934, Speaker A: Are you giving your development towards hardware implementation? Are we giving the implementation towards hardware implementation? So I think the way I see it, and I'm not the architect, I think that we want the validator set. Okay, this is my interpretation. It's not the official, but my understanding we want the validator set to be as flexible and diverse as possible. And if you have only hardware, I guess we don't want all validators to run specific hardware because this will limit the options for validators. But this is my interpretation, not an official one.
00:15:44.052 - 00:15:44.720, Speaker B: Okay.
00:15:45.730 - 00:15:46.480, Speaker A: Yeah.
00:15:58.480 - 00:15:58.844, Speaker B: Okay.
00:15:58.882 - 00:16:16.100, Speaker A: So the question was about consensus and how it's done in less than a second and what's the committee size. So it's a proof of stake consensus between more than 100 validators. They all participate, they have different stake, each one of them.
00:16:16.170 - 00:16:16.452, Speaker B: Okay.
00:16:16.506 - 00:16:39.540, Speaker A: Obviously one has less than 1%, but the one with much more. But I think that's single digit percent for all of them. And they all participate in the consensus. And you have to read the papers or see the code. The code is open source. Questions?
00:16:40.330 - 00:17:04.670, Speaker C: Yeah, I was always wondering about transaction parallelization. If you want to do the best partialization, do you have some metadata for the transaction?
00:17:04.770 - 00:17:44.694, Speaker A: Okay, so the question was about parallelization. Okay. So the developers don't have to give hints to write which transaction can be paralyzed. The system understands this automatically or automatically, as they say, and then it's optimistic in the sense that it assumes that my transaction can run independently of yours. And most of the time it's fine. But sometimes my transaction reads information that you are reading and the ordering already put your transaction before mine. So the fact that it has been run before yours doesn't or in parallel to yours means that the result is not okay.
00:17:44.694 - 00:18:12.490, Speaker A: In that case, my transaction has to be rolled back and read what you wrote and continue from there. Now this is inferred in real time and the fact that this is done for smart contracts and the fact that the smart contracts were already ordered before. That gives the system a lot of hints to do this. Guessing in a more successful way, giving a better throughput.
00:18:13.390 - 00:18:17.778, Speaker B: Okay. You okay?
00:18:17.864 - 00:18:22.160, Speaker A: Thank you. Close.

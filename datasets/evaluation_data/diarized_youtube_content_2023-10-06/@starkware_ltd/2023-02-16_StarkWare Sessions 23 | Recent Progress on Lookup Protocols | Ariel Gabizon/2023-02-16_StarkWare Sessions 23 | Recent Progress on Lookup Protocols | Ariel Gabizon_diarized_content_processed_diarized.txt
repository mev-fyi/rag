00:00:00.330 - 00:00:32.070, Speaker A: You. Hey everyone, thanks a lot for coming. So I want to tell you about recent progress in what's called lookup protocols. So let me set the frame of what lookup protocols are. So let's look at an example. Say we want to do a check. Some x is in some range zero to two to the n minus one, like a range constraint.
00:00:32.070 - 00:02:39.160, Speaker A: So the more standard thing we're used to is decomposing that to low degree constraints. For example, the prover gives the binary decomposition of x, and then we prove that these bis are really binary in zero, one, and we prove that they sum up to x, right? So this is the standard way via low degree constraints to say, show that x is in a certain range, right? And this is a common thing we all use, we've all used, and this is going to take us n plus one o of n constraint for one range constraint. So the lookup approach says maybe let's try to do something different. So we have our table of legal values, right, the zero to two to the n minus one. In this case, let's maybe do some preprocessing stage on the table, and maybe after that preprocessing, we can get some protocol for checking that x is in the table that doesn't require to explicitly decompose the check to low degree constraints. And indeed, in a protocol that's been relatively popular in the last few years, Pluckup, it tells us we can do something like this in an amortized sense. So say we have m different x's that we want to check are in the table, so we can do it in o of m plus capital n constraints, where capital n is the size of the table.
00:02:39.160 - 00:03:56.000, Speaker A: So how you can view that is. Well, if the number of lookups I want to do is as large as the table, I can get lookups amortized in o of one constraints. So this was already very useful and used a lot in the last few years. But of course we ask can we get more? And theoretically, why there seems to be hope is I'm allowing you to preprocess the table. So maybe all the cost of the table size can be moved only solely to the preprocessing stage. And indeed in a very recent, I think, very exciting new sequence of works, this is happening. So after a preprocessing of the table, we can check that a part of the witness element is in the table in o of one constraints.
00:03:56.000 - 00:05:08.426, Speaker A: So we have in this very new line of work, actually starting from this work called calc and currently culminating in CQ, managed to get to this point where the number of prover operations does not depend anymore after preprocessing on the table size. Okay, in terms of the what, I'm done. So this is what I wanted to convey to you. There's a new, very exciting sequence of works where you can do lookups in a number of prover operations, not depending on table size. That's the what. And let me give you a little of the how. How are these protocols working? And the main technical component is something we've coined cached quotients.
00:05:08.426 - 00:06:20.094, Speaker A: That term wasn't explicitly used till the last paper in this sequence, and that's why that paper is called CQ. It's just short for cashed potions. So, to explain what that is, I need to do some recap of the KZG polynomial commitment scheme. So what is the KZG polynomial commitment scheme? We have some generator of a pairing friendly elliptic curve group. Think just hard, discrete law group, if you're not exactly sure what that means. And we have some setup phase, what's maybe very unpopular in this event, where we generate a string of group elements, where. What is this string? It's the sequence of powers of x for some random secret x nobody knows.
00:06:20.094 - 00:07:51.912, Speaker A: So this is the trusted setup that is viewed very scolded upon, maybe at this event. So we have the powers of some secret random x encoded in the group, as we have these group elements, where these are the scalars, the powers of the secret x. And now we can use this reference string to commit to a polynomial. What is the commitment of a degree D polynomial? The KZG commitment, it is simply f, the polynomial at this secret x encoded in the SRS times g times the generator. Right. And since just by linearity, you can see that if you know f, you can compute this element from the srs. And why do people like this? What does this thing give you? The cool thing that this gives you is that after you send somebody the commitment, if somebody asks you, hey, what is f of a? Where f is the polynomial you committed to in the past, you can send them f of a, and you can actually give them a really short proof.
00:07:51.912 - 00:08:26.950, Speaker A: Again, just one group element that this value f of a is the correct one. It's the f you had in mind in commitment time. You're not changing your polynomial after they asked you about f of a. So if you've seen this for the first time, it's a lot to digest. The two features you need to keep in mind for the next thing are these two. So Kzg has these two nice features. It's linear.
00:08:26.950 - 00:09:33.160, Speaker A: The commitment of the polynomial f plus g is the commitment of f plus the commitment of G. The second, more fancy property is, say I give you commitments to four polynomials, f one, f. So via pairings, you can check whether f one times f two equals g one times g two, just directly from the commitments. And you might be thinking, all right, I can see if I know pairings, I can see how I can multiply the commitments. But you're saying the polynomials are identical. So here, using this algebraic group model, this sort of strong cryptographic assumption, yes, we can actually conclude from the commitments that these products are a polynomial, are equal as polynomials. So those are the two properties we're going to use right now, the linearity of the commitment and the fact that we can do product checks.
00:09:33.160 - 00:10:12.070, Speaker A: All right, we have Kzg. It has these two nice properties. Now, let me give you a simple example of what the cached quotients technique does. I'm going to give you an example from the first paper in this sequence of works, calc. So again, if you look at that paper, you won't see this term cash quotients. It was coined in hindsight. All right, so look at the following scenario.
00:10:12.070 - 00:11:24.980, Speaker A: We have a vanishing polynomial of some set t. We've given the commitment to this vanishing polynomial to the verifier. We've given to the verifier a commitment to another polynomial of ours, f. And now what do we want to do? We want to convince the verifier, this polynomial f that I've sent you a commitment to. It is actually a commitment to a vanishing polynomial of a subset of t. If we want to get a little motivation for this, the intuition is, say my table is huge, my witness is less huge. I'm going to be using just a small subset from the table in my actual witness.
00:11:24.980 - 00:13:29.904, Speaker A: If I can do this from that point, I can sort of say, all right, I can run a lookup protocol, but I can run it on a smaller table of just the values I'm actually going to use after I manage to convince the verifier of this, that f is really a vanishing polynomial of a subset. The cool thing is, I want to do this in a number of operations that only depends on the size of s, not on the size of t. So the natural way to prove such a thing is the quotient polynomial zt divided by zs, which is exactly the same as the vanishing polynomial of t minus s. This is sort of a witness to the fact that s is a subset. Actually, computing zt minus s is going to take us order t operations, right? S is much smaller because t minus s is almost as large as t. The important point is that it's enough to compute a commitment to zt minus s because of these nice features. We talked about that once we have that, and we'll see the equation in the next slide.
00:13:29.904 - 00:14:19.010, Speaker A: But once we have just the commitment, we can check via pairings that f is correct. The second thing to notice is that the commitment to zt minus s is a sparse combination of commitments. We can pre compute these commitments. We pre compute these are what I call the cached quotients. And now let's see the exact details. So for each element in t, I'm going to pre compute the vanishing polynomial, the commitment to the vanishing polynomial of t minus just one element. Call this polynomial gi.
00:14:19.010 - 00:15:18.640, Speaker A: And now we have this result that says I can write zt minus s as a linear combination of zt minus I over I in S. So the cool thing here is that this is a combination of just s things, not t minus s things. This is the point. So we're going to pre compute the commitments to all of these gis. I'm going to show this last part a little fast, because I'm out of time. So this is the idea. The prover, after we've pre computed these commitments, the prover can compute in s operations the commitment to zt minus s.
00:15:18.640 - 00:16:45.070, Speaker A: And now, like I said, we can compare products of pairings. So the prover can just pair f with this PI, compare it to the pairing of zt with just like one. And we've proved that f is a vanishing polynomial of a subset in S operations, not t operations. All right, so thank you and happy to take a question. Yeah. If you know the coefficients of f, then f of x is a linear combination of x to the I of the powers x to the I. So you can compute f of x times g from x to the I times g as linear combination.
00:16:47.920 - 00:16:54.864, Speaker B: When does the g out of it.
00:16:54.902 - 00:17:23.896, Speaker A: Doesn'T need to get out. It's just you have that a times g plus b times g. If you just add them, you get a plus b times g. So this is an important component in Kzg that the x can be kept secret. And you can still do linear operations while it's secret. This is a crucial component. Yeah, you need to change the table by then.
00:17:23.918 - 00:17:32.156, Speaker B: The tour has to sort of break up. It's not like a one time enough trusted set up every time you need.
00:17:32.178 - 00:18:10.890, Speaker A: To change the table every time you change the table. Also, if it's the same size, you need to do in the current protocols. N log n preprocessing, where n is the table size. Yep. Well, I mean, since the. Since the prover efficiency doesn't really depend on the. You could, if you just take a subset, trim the preprocessed set that the prover needs to hold on to.
00:18:10.890 - 00:18:18.636, Speaker A: Yeah. So is it possible to do a.
00:18:18.658 - 00:18:27.000, Speaker B: Case that.
00:18:31.770 - 00:19:07.290, Speaker A: You'Re saying instead of what these Gis. I was committing to it over? What, you mean if you have many subsets you want to. Yeah. In this last scheme, Cq, it's nicely aggregatable. So. Yeah. So if you have like, 100 claims you want to prove, you can easily compress it to one multi proof.
00:19:07.290 - 00:19:27.680, Speaker A: Yes. So G is public and X is secret. Yeah. T is public and S is secret. Yes. Yeah, hi.
00:19:28.690 - 00:19:33.310, Speaker B: Are you aware of any postponed replacement for parents?
00:19:33.670 - 00:20:24.980, Speaker A: No. So this is why I was really surprised they let me talk about this, because so far, everything we've seen, you can swap your polycommit scheme for Fry. And I think this line of work, starting from Kulk, is the first one where, at least so far, we don't have a pairing alternative. And it's a very interesting question if you can get it, of course. Yeah. Well, the question is, if you have a protocol in dark to efficiently compare products of commitments. If you do, then, I mean, you need linear already of the commitment scheme and an efficient protocol for comparing products.
00:20:24.980 - 00:20:40.660, Speaker A: If you have that, then that's all you need. So it's a very interesting question. Yeah, I don't want to get the next speaker late, so maybe I should stop. Yeah. Okay. Thank you very much.

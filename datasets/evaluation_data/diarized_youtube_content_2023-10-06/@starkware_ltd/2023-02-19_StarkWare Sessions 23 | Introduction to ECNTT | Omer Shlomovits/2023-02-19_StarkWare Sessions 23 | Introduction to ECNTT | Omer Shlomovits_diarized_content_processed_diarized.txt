00:00:03.510 - 00:00:41.846, Speaker A: Welcome to my talk. So, my name is Omer, I'm the CEO of Finonyama. Basically what we do at a company is we're in charge of the hardware infrastructure to improve performance of zero knowledge computation, mostly provers. What it means in part is that we take or we look at or try to identify math primitives that can become bottleneck in certain ZK computations. And then we figure out a way to accelerate those. A couple of popular examples are the MSM, the multiscalar multiplication, and the NTT. So these are like the known ones.
00:00:41.846 - 00:01:19.842, Speaker A: And in this short talk, I would like to present kind of a new one, a variant, you'll see. So starting with the basics with the MSM and NTT. So MSM, I'd like to look at it as kind of like a dot product between a vector of scalars and a vector of EC points. And we have, the main algorithm that usually is being implemented is the pippinger or the buckets algorithm. And in hardware we have certain ideas on how to do that. We have one paper, the other papers. Of course, now with entity, things are a bit different.
00:01:19.842 - 00:01:49.274, Speaker A: So this is like only field operations. As you can see, there's this loop basically that needs to repeat n times. The most popular algorithm to solve the entity is the coolie two key FFT. And here again, when it comes to hardware, there are different ways to implement. We have one direction, there are obviously other directions. I want to focus now on the entity and try to represent it in a different way. Okay, so take this representation, which is in a matrix form.
00:01:49.274 - 00:02:29.590, Speaker A: Okay, so it's basically the same, just open it up. Now we have a vector of scalar of field elements multiplied by this matrix of tweedle factors, basically constants. It doesn't really matter. So now I want to introduce the ECNTT, which is very simply put, instead of vector of scalars, we have vector of elliptic curve points or group elements, same thing. And this is, I mean, if you look at it as a polynomial, so this is like a polynomial where the coefficients are elliptical points. Okay, so let's now edit to our table. And basically the software algorithm is the same.
00:02:29.590 - 00:03:20.982, Speaker A: So it's linear, it would work just the same if we do the, so it's the same coolie two k fft. But what I want to claim first is that in hardware this is less trivial. So I cannot just say, okay, same thing that worked for entity, in hardware, now going to work for EC entity. Why do I say that? Okay, so first in terms of memory, right? So an EC point can be represented as two or three field elements. So basically it's like two, three times larger in memory. But what's most important is that the basic operation being done in an entity is the modular multiplication, while in EC entity, the basic or what consume most of the computation is an elliptic curve addition. Okay, now this is a big difference because modular multiplication, we can do it very efficiently in hardware.
00:03:20.982 - 00:04:15.126, Speaker A: So today in entity implementations, in hardware, the bottleneck is mostly in the data transfer in their access to memory. While once we introduce this EC entity and move into elliptic curve addition, then computation become much more dominant. Right? Like each EC addition operation can be like ten x or even more or like order of magnitude more than modular multiplication in complexity, many more clock cycles. So it kind of shifts the focus. Another thing is that we can do a very deterministic computation when it comes to modular multiplication, which is not the same thing with EC edition, right? It depends on different factors and basically we need to work in kind of like an armor test time. Okay? So let's keep it as an open question, how this can be done in hardware. What I want to now go and try and do and try to convince you that this is actually important primitive as a standalone.
00:04:15.126 - 00:04:59.334, Speaker A: Right? So my first example is from Elio. This is a blockchain with privacy preserving applications, and they baked in basically a zero knowledge proverb inside of their consensus, in a way, to put it in simple words. As you can see, they launched recently an incentivized testnet, and our prover basically got to 50% of the network. So one way that we've managed to do that is the following. So this is basically the algorithm what Elio wanted hardware to accelerate. And when you run it very fast or with high throughput, you are able to get more credits or more tokens from the network. And without going into the numbers, like, I wouldn't have time to actually go step by step.
00:04:59.334 - 00:06:07.818, Speaker A: But basically we have like a setup or a pre processing phase and an online or runtime phase. And you can see that the main operations here are the usual entity and MSM. So one thing that can be done that we noticed is that we can actually extend or add some operations to move some things to the preprocessing phase, and then we are left only with a smaller size msm in the online phase, right? So basically, if I want to summarize, we take a computation that was supposed to be bottlenecked by two n size msm and two n size entity, and we replace it with only half size msm in the cost of just doing a pre computed EC entity. Okay, so you can think, I mean, there are several different reasons why this is way better when it comes to actually building an accelerator, right? Just one primitive, no need to go in and out or something like this. And it makes it much more easy to basically have everything inside of the hardware. However, you can say something like this is pre computed, I don't really need to accelerate ECNTT. So this is maybe one kind of motivation.
00:06:07.818 - 00:06:48.550, Speaker A: But let me give you another type of example where I actually need to run ECNTT in runtime significantly. So here I want to go to dunk sharding. And in dunk sharding, for those of you who don't know, there's this role of a builder. So this is the one basically, or it's part of data availability sampling. This is the one that needs to do some hard work, obviously to be incentivized in some way. But basically the hard work or part of it is to sample some field elements and then to provide some KzG evaluation, proof that all of these field elements are correct. So again, I don't have time to actually explain how this works, but this is something that happens quite often in dunk sharling.
00:06:48.550 - 00:07:31.762, Speaker A: And here we have the face Kovatovich trick that it's basically just like solving this really nice, which basically says that I'm using instead of l, I'm moving to index n. So if I have a polynomial with n evaluations, and I want to compute Nkzg proofs, the roots of unity. Right? So this is exactly what I can actually use this trick for. So you can think about it as you have few msns that needs to be computed at the same time. So like n times n size msn. So it's of n square, but using the fact trick, I can actually do the same in of n log n. Okay.
00:07:31.762 - 00:08:14.914, Speaker A: And in the process I do need to use Ec entities. Okay, so here I was too lazy to actually write down the entire protocol, but this is taken from the latest update to the paper by Sk. Again, there is some pre processing step, but I just want to point out that there are at least two steps, and I actually think there are three where you need to do this ecntt. Now remember that in software and there's a reference implementation, it goes really smooth. It's just the same algorithm, just replace the scalars with elliptical points. But in hardware it's going to be much more interesting, I suppose. Okay, finally, there are other applications.
00:08:14.914 - 00:08:46.718, Speaker A: So the latest lookup table paper the CQ paper is basically the cached quotient side. This is CQ, stands for Cq. This is actually computed using the same trick and therefore employing Ecntt. Although I have to say this is again done as a preprocessing step. So next steps. So first I want to kind of, I think it's a good introduction to know this is an Ecntt. Now that we are familiar, let's see where we can use it.
00:08:46.718 - 00:09:26.170, Speaker A: I think that the Alio guys, where they have this design in mind, basically to take entity MSM vector multiplication, all of the steps that you want harder to accelerate and you could have changed it into something which is just like small size MSM. Probably we're not aware of Ecntt and how this can be used. Maybe there are other places where this can be utilized correctly and be applied. And I think that, and at least what excites us the most is to implement it in hardware. So soon we're going to release an open source library that is based on GPU, a GPU library. Part of what it will implement will be this EcNtt. And of course we'll invite everyone to collaborate, use it and impact the roadmap.
00:09:26.170 - 00:09:35.194, Speaker A: That's it, yeah.
00:09:35.332 - 00:09:46.190, Speaker B: Do you have an idea of the degree from which it became instead of finger? Because I guess when you choose.
00:09:55.780 - 00:10:39.948, Speaker A: Yeah. So the question is kind of like when is it becoming interesting? Yeah, just to explain, in ZK, usually we are dealing with these huge vectors, and therefore entities of such huge vectors obviously require hardware and it's not necessarily the case here. So for example, I left in dunk sharding the parameter l and l might be small, right. And therefore we might don't even need to do it in specialized hardware. So that's kind of an open question. So I don't really know what's the kind of the critical mass when it's going to become interesting. I can definitely tell you that there is usage like Alio is a real world usage where you can, I mean, we didn't do the ECNTT in hardware, but at least it was useful.
00:10:39.948 - 00:10:47.810, Speaker A: So even if not for the hardware sake, just like for getting to know this primitive as its own. More questions?
00:10:50.820 - 00:11:06.230, Speaker C: This is a broader question. So you guys work with Aleo public. Can you talk more about what the experience is like and the benefits from. Really?
00:11:10.810 - 00:11:56.354, Speaker A: So as a hardware company, usually don't just build because we can build hardware size of a soccer field, right. So usually you have some constraints like area cost and also something you want to optimize for in the case of Alio, the goal was throughput. Basically you want to fit in as many proofs as possible per unit of time. In our mean, we took it as kind of an exercise. It was an interesting to analyze the algorithm and then implement it end to end in a GPU. I don't know, it's just like any other mining operation. We've been working with miners, data centers, retail, basically everyone mining pools just utilize their gpu at some point.
00:11:56.354 - 00:12:13.050, Speaker A: By the way, once you go all in like full gpu, you don't need the CPU, therefore you can actually run it on old Ethereum miners for example. So at some point it just became like everybody just were using their gpus. It was very fun to observe.
00:12:17.710 - 00:12:34.370, Speaker B: Yeah, I understood it makes ECNC make faster, especially improving. I didn't understand what it does actually when they keep moving, but at what.
00:12:34.440 - 00:13:07.850, Speaker A: Point of the right. So recall the first slide where I tried to make it very abstract. One approach in order to accelerate ZK proof is to identify bottlenecks. And then every time they are called as part of the protocol, you just move it to the hardware. I mean this is like a very simplified approach. And what's interesting about this AC entity is that at least in existing ZK proofs, you don't see it right now. I mean it's not a tool that we are using, and it's mostly something that at least we noticed.
00:13:07.850 - 00:13:49.034, Speaker A: Once you start to put more things into the hardware and then you see there are shortcuts. Maybe if I can use this stuff, then I can move some stuff to pre computation, or I don't know if I need to batch many, many commitments, or many kind of KZG commitments, then this can be deployed. But this is another kind of good question. Once we know that, how can we use it? CQ, I think done like a very. If you look at the CQ paper by Gabriel Etal, so you'll see they provide a very significant part of the paper to discuss how they are utilizing this thing, but they are using it at a higher level. They are using it at like the factory. Right.
00:13:49.034 - 00:14:05.190, Speaker A: So they already assume that this is being done by this offend login. Right. Okay, thank you.

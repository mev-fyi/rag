00:00:03.110 - 00:00:32.958, Speaker A: Good afternoon, I'm really excited to be here. My name is Kinera Segel and I'm part of the engineering team in stockware. I am the team lead of the team that is in charge of the sharp system. And this talk is about Sharp. So today I'm going to explain what is sharp. I'm going to talk about sharing a single proof, are using sharp. And eventually I'm going to give some examples of how one can use sharp.
00:00:32.958 - 00:01:20.130, Speaker A: So what is sharp? Sharp stands for shared prover. And we build this system on top of the stone prover. So stone Prover was out there, it was operating on mainet actually even before we had sharp. But after a while we understood that for our need for stagger needs, we want to have a single system operating with the stone prover. The motivation was actually the way that star protocol works. So the way it works is that the verification of the proof is logarithmic in the input size. So it makes sense to have many inputs sharing a single proof, because you can think about the verification size basically as constant.
00:01:20.130 - 00:02:18.050, Speaker A: So what is the input? The input for the system is something which we call Cairo jobs. Cairo jobs are basically executed Cairo programs. So it's like the execution trace of the programs. And as I said, this is a single system and different application sends different Cairo program, different logic to the same system. So let's talk a little bit about how we share the proof. So before sharp, as I said, we did have the stone prover operating on chain, and each application used its own prover. So we had like spot systems and nfts and perpetual, and each of them sends their own logic to the stone prover to be improved and eventually to be verified on chain by the solidity verifier separately.
00:02:18.050 - 00:03:26.300, Speaker A: And then we decided to join forces. So we had all the applications, all the different applications sending their logic to a single system, which we called sharp. So I would like to explain, how exactly do we schedule these jobs to the system? Okay, so first, in the first phase of the system, actually two years, sharp is operating for around three years. So the first two years what we had was linear scheduling. So we were getting jobs into the system and waiting for enough jobs to arrive. And then we batch them greedily. So first come, first serve, until we had enough jobs to send them to the prover, until we have enough jobs coming to the system, and then we send them to the stone prover as a batch, and we created a single proof for all of them together.
00:03:26.300 - 00:04:20.330, Speaker A: Then the proof went to the solidity verifier on chain to be verified on chain. And eventually, for each of the original jobs, we wrote some unique identifier on layer one that signals to the world, that's the way that the verifier signals to the world that the original jobs were verified correctly. So you can think about it as this is the hash of the input with the hash of the program with their output. And this is like the unique identifier to signals that the original jobs were proved and verified correctly. And this was pretty good. Like we operated like this for two years and the system was doing pretty well. So we could fit up to 128,000,000 Cairo steps on a single proof.
00:04:20.330 - 00:05:01.106, Speaker A: And this cost us 10 million gas. But as I said before, the motivation is to have more and more input on a single proof, because the verification is basically constant. So we want to have it as much cheaper on chain as we can. So we want to have many, many inputs as we can. But with this linear setup, we had a few limitations, and I would like to mention two critical ones. So first of all, it was the machine memory. So provers, to prove you need the memory and the memory is proportional to the input size, linearly proportional.
00:05:01.106 - 00:06:04.410, Speaker A: So if we would wait for more and more jobs to get into the system and schedule too many jobs into a single proof, we would need really heavy machines that are really expensive and much less accessible to be used. So that was a really heavy bottleneck. And secondly, was latency, because first of all, we needed to wait for enough jobs to get into the system, and then proving all of them at once would took a long time. So eventually, from the moment that the job arrived to the system until it got on chain, there were many, many hours. So because of these issues, we decided to move to the recursive scheduling. And this is the way the system operates in the past year. So what is the recursive scheduling? The same, we have jobs arriving to the system, but now we don't wait for many of them to arrive and then batch them together.
00:06:04.410 - 00:06:43.922, Speaker A: We send each job separately to the proverb, to the stone prover, to compute the proof for a single job. But this job, remember I told you it's the same amount to verify proof of a single input or multiple inputs. So we don't want to send these jobs on chain because it will be very expensive per job. So what we did is that we wrote the verifier in Cairo. So stack verifier is just a code. This code can be written in different languages. So we have one in solidity we have one in c.
00:06:43.922 - 00:07:38.518, Speaker A: This is just released today. One can write it in Python, whatever, and we wrote it in Cairo. So we send two proofs to the Cairo verifier to be verified on layer two. So now we have two verifications of these four original proofs, but these are also jobs. These are also Cairo programs that can be executed and generated as jobs. So now we send these jobs, these Cairo jobs to the prover again to be proved that the verification of the proofs of the original jobs were approved correctly, and we can do it again and again. Now we are left with two proofs instead of four proofs, and we can repeat this process until we get a single proof of the verification of the proof of the verification.
00:07:38.518 - 00:08:38.860, Speaker A: So and so, this is what we called the recursive tree. Its leaves are the original jobs and each step is the proof of the verification of the previous layer. And when this tree is big enough, meaning that there are enough jobs in the leaves, or when the jobs are waiting long enough, we send the last proof to the verifier on chain. And this verifier just verified that the last proof is valid. And again writes these unique identifiers of each of the original jobs to signal to the world that he verified that these original jobs were proven, verified correctly. Okay, so this is for the flow of the recursion. And maybe some of you wonder, why do we need that? Because it sounds a bit wasteful, right? We now compute many more proofs than before.
00:08:38.860 - 00:09:23.194, Speaker A: Actually, if you think about it, because of the way binary tree works. So for each job we have extra job to prove. And I can tell you from my experience that debugging a system in a recursive flow is much harder than debugging a linear flow system. So it sounds a bit wasteful, maybe for some of you. But actually this setup has many, many benefits and many surprising benefits. The combination of the benefits we get from this flow is pretty surprising. So first of all, even though we do more computation off chain, the cloud cost decreased, because now each chunk that we prove is much smaller.
00:09:23.194 - 00:10:16.370, Speaker A: So we can use much cheaper machines. And eventually, even though we do more computations, the cloud cost decreases. Secondly, the l one cost also decrease. And again, it's very counterintuitive, the fact that we don't pay on lower cloud cost, on having verification more expensive, but actually it's less expensive because now we remove this limitation of the memory of the machines, and now we can fit much more inputs into a single proof, because the moment a job arrives, we just start proving it. We don't need to wait for them and we don't have these heavy machines off chain that blocks us. So we can now fit up to 2 billion Cairo steps on a single proof. This is 16 times more than what I've mentioned before in the linear setup.
00:10:16.370 - 00:11:15.338, Speaker A: And this is just a choice we made now in the setup, in the configuration of our system on mainet for our needs. But this can be even much greater and the same 10 million gas for this proof. Now we have also shorter latency, which also very surprising, like we gain by lower cloud cost, lower l one cost and also shorter latency. How can it be? Because now we don't need to wait for many jobs to arrive to the system. The moment the job arrives we just start proving it. And we parallelize the work in a way that eventually makes it four times faster to go on chain. And lastly, we can now support much more complicated built ins in easier because now the jobs that arrive to the system, they are being verified by the Cairo verifier and not the solidity verifier.
00:11:15.338 - 00:11:57.066, Speaker A: So now we can add complicated built ins and verify them using the Cairo verifier. And we don't need to change the logic in the solidity verifier for that. So it makes our life easier. So recausion is really really powerful as I hope. Now you agree with me and let's talk. How can we use this powerful system with different applications. So imagine you have some application which implements some complex logic and you don't want to implement that logic on chain, or maybe it's not possible even to implement it on chain.
00:11:57.066 - 00:12:57.220, Speaker A: And so what can be done? You can write the logic in cryor. This is possible because Cairo is a language, you can write everything, every logic that you want, it's during complete and you can send these jobs to sharp. Sharp proves the execution of the Cairo program off chain and send it on chain to be verified and eventually writes the fact, the unique identifier on chain. And now the contract of the application on chain can just check that the fact is there to promote its state. Maybe some of you have stargnet on your mind. So that's how stagnet works, right? Instead of doing all the transaction of Starnet on chain, the stagnet OS sends the jobs that updates the state of the system to sharp. And on chain just promotes its state based on the fact that Sharp proved that these state updates is correct.
00:12:57.220 - 00:13:57.342, Speaker A: And there is another really cool application for sharp that one can use, which is storage proofs that if I will have enough time, I'll present now and if I want to manage to finish. So please, you are very welcome to check later on stage one. Herodotus and Alex from Stackware are going to talk about it. So what is storage proof? Imagine that you want to know the state of the blockchain storage at any point in the past, maybe from layer one or from some layer two. Think about the use case of voting. So you want to enable entities to vote based on some amount of tokens on some asset they had a few blocks in the past and this is something you can do from layer one. You can't from smart contract.
00:13:57.342 - 00:15:21.622, Speaker A: Check that a few blocks away some entities had some amount of assets. So how can it be done using sharp so you can create this structure. Think about a Merkel tree that in some way index the history of the blockchain from Genesis until the future until the present. And these roots that you see are just, they represent the ongoing history of the blockchain. And now in order to prove this history, in order to prove that you can update from root I to root I plus one, you just need to write the Cairo program that represent the fact that there exists a series of block that can lead you from root I to root I plus one. And now when you prove this entire history and it goes on chain using these identifiers of the state update, if you want to access some specific state, you can just go to the relevant truth and open it and check the state. And I just finished, so that was what we did in Starquare using the really powerful stone prover.
00:15:21.622 - 00:15:35.200, Speaker A: That was the system that we built. And I would really like to encourage you now that stone is out there to think about your needs and your perspective and use it in order to build your own powerful systems. Thank you.

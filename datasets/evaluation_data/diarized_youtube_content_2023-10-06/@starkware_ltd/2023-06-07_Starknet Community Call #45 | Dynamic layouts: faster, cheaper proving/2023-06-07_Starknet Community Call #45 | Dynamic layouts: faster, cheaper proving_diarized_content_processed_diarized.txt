00:00:00.170 - 00:00:18.720, Speaker A: Can see it on YouTube. I'm going to press go live. And we are now live on YouTube. So, hi, everyone. This is the 45th edition of our Starknet community call. And today I'm joined by David and Elon from Starkware. Hey, guys.
00:00:19.250 - 00:00:21.038, Speaker B: Hi. How are you?
00:00:21.204 - 00:00:58.910, Speaker A: So, today's topic is going to be. Well, I know when we do community calls, we often get different kind of stuff. We get people presenting their projects. We get people building on Starknet. And then from time to time, we also get people from Starquare presenting in depth what they're building for Starknet or, like, the backend, the stuff that you actually use every day but you don't really understand. And today is going to be one of those calls. Today we're talking about dynamic layouts, which is a bit of a foreign topic, I guess, for most people.
00:00:58.910 - 00:01:21.320, Speaker A: So we're going to explore this to the people in the audience. Feel free to ask questions. You can ask them on Twitter, you can ask them on YouTube. We'll be monitoring them, and we'll answer them once they come. Before we start talking about dynamic layouts, I'd like to hear a bit more about you, David and Ellen. So, David, can you start? What do you do at Stockware? And how long have you been there?
00:01:21.930 - 00:01:43.120, Speaker B: Thank you, Ellie. I'm David. I work in Stockware since 2018. I am the team lead of the built in team.
00:01:44.850 - 00:01:45.600, Speaker A: Which.
00:01:47.730 - 00:01:57.646, Speaker B: For a while, is working on the dynamic clouds. That's me. Alon.
00:01:57.758 - 00:02:00.062, Speaker A: Okay, very nice, Alon.
00:02:00.126 - 00:02:11.640, Speaker C: Hi. So, I'm Alon. I've been in Starper for, I think, about three and a half years. I work under David on the business team. I've also worked on several other projects within Starware in the past.
00:02:14.410 - 00:02:48.050, Speaker A: So you both have been here for a very long time. And I guess you must have seen quite a lot in the evolution of, well, the overall proving system that we have in place at Starkware. Right. Because to the best of my knowledge, it's one of the only proof production system that is live. I don't think there are many instances of people proving. So you've seen it rise from nothing, basically, to where it's curious. David, you mentioned you guys are working.
00:02:48.050 - 00:02:53.074, Speaker A: You're in the built ins team. Is that correct?
00:02:53.272 - 00:02:54.180, Speaker B: This is.
00:02:55.190 - 00:03:03.910, Speaker A: So can you. Can you explain, please, in a few words, what are built ins for people who are listening, who are new to Starknet?
00:03:04.330 - 00:04:02.410, Speaker B: Of course. Well, first of all, I assume that the audience has met Cairo, which is a great programming language, which is used to define statements that we want to prove. Now from these statements to actual proof, we have all this proving system which is based on a protocol called Stark. And you can think of the Stark as proving a virtual machine. We call it cpu, this virtual machine. And this machine is static, actually. It's like a chip that has a very specific circuit.
00:04:02.410 - 00:04:43.190, Speaker B: But the programs are like, they are dynamic. You have these programs that are written by the developers. They change in every proof. So we can think of them as loaded to the memory of this virtual machine. And the start protocol is proving the execution of the virtual machine on a given program. Now these programs.
00:04:46.330 - 00:04:59.580, Speaker A: If I have a laptop with a cpu, I can run windows or ubuntu on top of it. It's the same cpu. It's just what matters is what I load in the memory when I start executing it.
00:04:59.970 - 00:05:43.340, Speaker B: Exactly. And this cpu has native opcodes, right? It has addition, it has multiplication, it has memory access. But sometimes there are functions that, how you say it, sometimes you want to implement complex functions, right? What happens when you implement complex functions on cpus? It will always be less efficient than implementing them in hardware, right?
00:05:47.790 - 00:06:25.480, Speaker A: Instinctively, I would have thought that this is for Dom operations rather than difficult one. If we make the parallel with the silicon world. One example many people in the blockchain world are familiar with is shot 256 ashing. You used to be able to mine bitcoin, for example, with your cpu. And now it's very much, I mean, you can still do it, but it's not efficient because it's much much faster to do it. With ASICs application specific circuits. This is for relatively dumb operations, right? You're doing always the same thing.
00:06:26.730 - 00:07:28.060, Speaker B: Well, this is a great example. This chateau is exactly what I call complex because it's not a simple rotation or a simple addition or a simple saw, it is something that is more complex to define, to express. Okay, so this is a great example. It is exactly what built ins are for. An ASIC is exactly the hardware solution for shatu. You can also have cpus that have shatu specific opcodes that are called intrinsics in the intel design. So these intrinsics in the stark world we call them built ins.
00:07:28.060 - 00:08:20.934, Speaker B: It is operations that are not native to the machine, but we do implement them in the lower level, in the hardware. It's not really hardware, but it's the analog. This way we allow the program to use these specific intrinsic or built ins with the efficiency of the lower level, but with more logic that can be added in the programming.
00:08:20.982 - 00:08:35.570, Speaker A: Levin nice. Okay, so for some repetitive operation that are resource happy for a cpu you get this kind of shortcut where you execute it for much cheaper.
00:08:36.150 - 00:08:36.802, Speaker B: Exactly.
00:08:36.936 - 00:08:44.190, Speaker A: So these are what built hints are. Yeah, I tend to think of them as like external component to your cpu, but intrinsics.
00:08:44.270 - 00:09:21.790, Speaker C: So I think a good analogy that we like to use is memory maps devices. If some of you might remember how you used to communicate with monitors in the past, you just write to a specific region in memory and the monitor will display those bits on the device itself. So a built in operates in a technical sense, and just a little bit underhood, a little bit like this. We write to a specific region in memory where these specific constraints for the implementation of the start apply. And then we're able to perform these operations kind of externally to the cpu we communicate with it via.
00:09:22.470 - 00:09:39.510, Speaker A: Interesting. Cool. Okay, I think we've introduced nicely what are built ins. Now, can you explain a little bit how do you use these built ins right now in the proof system? And what is the layout?
00:09:40.570 - 00:10:55.770, Speaker B: Okay, these are two different questions. For the first question. For example, we have the bitwise built in. It's a built in that takes two field elements and returns the bitwise end of these two elements, the bitwise saw and the bitwise o. These three operations are very non native for algebraic circuits because they are very far from being related to polynomials over the field. This is why it is a bit inefficient to implement them, and that's why we need this speed up of doing it using a build date. On the other hand, they are very basic in programming languages and basic computations.
00:10:55.770 - 00:11:35.340, Speaker B: For example, we can use them for chateau. For example, we can use them for ketchup, for Blake, or any other modern hash function. Well, not every, but many. And so, using this shortcut, we actually developed many such hash functions, which are widely used in cryptography and many things that you want to prove actually.
00:11:37.630 - 00:11:38.570, Speaker A: Understood.
00:11:39.150 - 00:13:12.950, Speaker B: And the second question, I'll repeat the question, because it was a long time ago, what are actually dynamic clouds or layouts in general? Layouts in general. So this virtual machine, it has specific configurations. We can say some parameters just the same as cpus are different. So also this machine can have several static clouds which define the exact way that the cpu is defined. For example, one parameter that is defined there is the ratio of every built in, how much of the built in is being used in the machine relative to the number of steps. So in the static world where we define this layout statically ahead of time, we need to predict how much of each built in will be used in the future programs.
00:13:13.110 - 00:13:22.878, Speaker A: But I don't understand why you have to fix this. Why do you have to define in advance how many you'll need?
00:13:23.044 - 00:13:52.390, Speaker B: Okay, just like you have a specific number of registers in your CPU, and you have a specific number of ALU components in your CPU, and you can have up to as many threads in parallel in your CPU. All of these things are static.
00:13:55.370 - 00:13:59.434, Speaker A: Like the threads. I can use one or two, or.
00:13:59.472 - 00:14:36.310, Speaker B: I can instantiate one, reuse one, but they won't be really in parallel. If you only have, for example, eight cores, then you can't have more than eight actual processes in the same time. You will have them waiting for each other. Right. So such parameters are actually static in the definition of the machine.
00:14:37.130 - 00:14:37.810, Speaker A: Understood.
00:14:37.890 - 00:15:01.630, Speaker B: Okay, so if you write a program that uses more than eight threads, and you run it on a machine with eight cores, it will work, but it will be less efficient than a machine that is dedicated for this program, right?
00:15:01.700 - 00:15:02.320, Speaker A: Yeah.
00:15:03.970 - 00:15:22.930, Speaker B: The same way we have the layouts can match your program, but if it's not an optimal configuration, then it will still run, but it might be less efficient.
00:15:25.110 - 00:15:53.520, Speaker A: Okay, understood. I think the example that was given, we had the blog post a while back and not so long ago, but a couple of weeks ago, and one of the example that was given is that there's x amount of that much of a specific built in, and if you use less of it, it still takes some space. So it's less efficient, I guess.
00:15:54.690 - 00:17:03.890, Speaker B: Yes. A very analogous example is, for example, with this chateau asic that you mentioned. Assume that you have a program that is using many chateaus, right? So you will use a cpu that has some of its silicone dedicated for chateaus. But if the ratio of the chateau executions with respect to the other opcodes that are run, if it doesn't match the cpu, then what you'll have is that maybe lots of time this chateau component will be unused, for example, and then it will be less efficient.
00:17:06.410 - 00:17:06.678, Speaker A: For.
00:17:06.684 - 00:17:13.590, Speaker B: The same reason it will be in the virtual machine.
00:17:15.130 - 00:18:00.338, Speaker C: I think for us there is an even, it's kind of worse than just having an unused child two component, because in a normal cpu, when you think about an unused child two component, it just sits there and does nothing for part of the time. But we have to represent the entire trace. So for us, we have to copy the whole machine for every step of the trace, or for every number of steps of the trace. So if we have a ratio of chateau components, if you will, if we have a chateau designated for each 16 steps or for each, it's not going to be a chateau, it's going to be something that's more error friendly. But for each 16 or 256 steps, then we have to copy all of these every time. So this waste accumulates the more steps you make without using the component.
00:18:00.434 - 00:18:21.610, Speaker B: It's not just, I will say even more, if you don't use this chateau component in the cpu, then you could have used the silicone for another core, for example. Right. For another thread. But you don't because you have it dedicated for Chateau.
00:18:22.110 - 00:18:41.540, Speaker A: I remember a while back, I was asking somebody at stockware, okay, but built ins of these, right? And he told me, well, not really, because for each built in you add, it takes some space, and if you don't use it, I mean, it's nice to have, but if you don't use it, it wastes space, so it's not feasible, right?
00:18:41.910 - 00:18:42.660, Speaker B: Exactly.
00:18:43.510 - 00:19:00.090, Speaker A: But then eventually he told me actually things might change, which I guess is what dynamic layouts enable or not really. How did you come up with the idea of dynamic layouts? And what are these two different questions?
00:19:00.160 - 00:19:49.560, Speaker B: Again, I think these are related questions, unlike the hardware world, where in order to build the chip, after you write the program for it, then you have to physically build it. In our world, it's all programs, so we can actually, and we do, it's not in production yet, but it is going to be define the layout after we measure the execution resources of the program.
00:19:50.350 - 00:20:19.566, Speaker A: It's true. It's so weird when you think about it, but that's something I really find fascinating about proving, is that it turns a lot of assumptions you may have on your head. I feel like proving, the way you approach proving a problem is sometimes very different than how you approach running a program. You want to prove that you run it, but you approach it differently. Okay. And it's kind of the same with proving.
00:20:19.598 - 00:20:28.018, Speaker B: Yeah. For example, if you want to take a square root, then you only need to provide the answer and prove that.
00:20:28.104 - 00:20:47.340, Speaker A: Squaring it are the same. It's kind of like, yeah, I already have the answer, I just need you to prove that it's the correct one, no matter how I came up with it. Okay, nice. So dynamic layouts would be saying, oh, let's do a specific layout for that problem we're solving at that particular moment in time.
00:20:48.510 - 00:20:49.260, Speaker B: Yes.
00:20:52.910 - 00:21:22.994, Speaker A: Okay. And how to filter it on YouTube is asking, when we were talking earlier about, we're talking about wasting space, he says, which space are we talking about when we talk about wasting space? I think specifically fulfilltrade is a fairly technical user. So you can hesitate and give more specific answer. But from what I understood is we're wasting trace cells. Is that correct? Is that accurate?
00:21:23.042 - 00:21:30.870, Speaker B: Yes, it is correct. The analogy was silicone space, but in our case it's trace cells.
00:21:31.370 - 00:21:40.614, Speaker A: Okay, so for each built in that you want to include in the layouts, you use some space cells. So if you add them and you don't use them, then you're wasting trace cells.
00:21:40.742 - 00:21:43.340, Speaker B: Exactly right.
00:21:44.430 - 00:22:06.070, Speaker A: Okay. Dynamic layouts are about changing a layout for every time you want to prove something different. So how do you actually make this work? Does this mean that you need to have a program to create a layout every time? Does this change the verifier? Where do you start implementing this?
00:22:06.220 - 00:23:03.720, Speaker B: Yes, it does change the verifier. Actually, the verifier needs to be adaptive to the layout. Until now we compiled a new verifier for each layout. That's why it was static. And now we have a verifier that gets the layout as input. On the proverb side, what we actually need to do is first run the Cairo code like in a simulated environment, and measure the execution resources, and only after that compute the optimal layout for it. And, and then we can create the proof with that specific layout for that specific program.
00:23:05.450 - 00:23:11.820, Speaker A: Does this had a delay in the proof production process.
00:23:13.550 - 00:23:15.370, Speaker B: Not something noticeable.
00:23:15.790 - 00:23:35.250, Speaker C: So all of these steps are things that we had to do anyway, because running the program and then figuring out what the usages of the buildings and what the usage of the memory is is something you have to do even with constant layouts. So the only thing we're adding now is that you have to compute what the optimal layout for the program is. And that's a pretty simple computation. It's just technical.
00:23:35.830 - 00:23:55.062, Speaker A: Yes, nice. Interesting. And so if you have a dynamic layout, it opens what I was mentioning earlier, meaning you could have more layouts and you could select just the one that apply to your specific proof and use them appropriately. Is that correct?
00:23:55.196 - 00:24:21.710, Speaker B: It's not exactly. More layout, sorry, more built, yes, more built ins. And all the parameters are configurable in running time. So we don't have a small set of layouts that are possible. Actually, every set of parameters that you provide will pass at least up to some constraints.
00:24:23.090 - 00:24:33.060, Speaker C: To clarify, though, the verifier still has to be aware of all the built ins that you might use in the program beforehand because the constraints have to be coded into the verifier before you start running the program.
00:24:35.190 - 00:25:01.130, Speaker A: Okay, so you don't need to update the verifier as much as you did, because previously, when you added a built in, you would have to update the verifier. And when you change the weight of each built in, how much time you can use it for each layout, you would have to update the verifier. Now, you don't have to do this second part. You can use a different layout every time, but if you want a new built in, you have to update the verifier.
00:25:02.030 - 00:25:03.440, Speaker B: All right. That's correct.
00:25:06.210 - 00:25:16.580, Speaker A: You're on the built ins team. How many built ins should there be? Do you think there will be a lot, or do you think there's a point at which it won't be very useful to do built ins?
00:25:17.590 - 00:25:33.880, Speaker B: Well, it depends on the number of use cases. Actually, every use case can have its own built in. I think that the answer is that it will always grow and grow.
00:25:34.650 - 00:25:46.140, Speaker A: Interesting. Nice. And do you think how feasible it is, do you think for teams external at starkware to write their own built in?
00:25:48.670 - 00:26:28.520, Speaker B: At the moment, the proverb is not public. The proverb is not public, and the verifier is defined by stock. So at the moment it is not given to the public. But in the future, when the proven verifier will be open source and could be changed by the public, then yes, it will be possible.
00:26:29.530 - 00:26:50.800, Speaker C: We have found, though, that developing built ins sound leaf can be a very hard task. So if someone is trying to develop code that might require a built in, they should consider using simple built ins that already exists in the ecosystem before they try to develop one. It's analogous, again to trying to develop your own ASIC versus trying to use components that already exist on the web.
00:26:52.050 - 00:27:33.886, Speaker A: Fair enough, though I would say that for ASICs, it's a spectrum there. For some ASICs. The main cost of ASICs, I guess, is that you then have to finding a foundry and doing actually creating your own ASIC. It requires volume, it requires a lot of capital, but people can still get the skill to design their own ASIC. And to a certain degree, you could design your own, like it feels still like building your own built in is a bit, I believe, of capital to building your own ASIC. I don't know. Does that make sense?
00:27:34.068 - 00:27:52.980, Speaker B: I believe that everything that I can do, someone else can do. So if we can build built ins, then also other people can do it. Maybe it will take them time to learn the system. For us, it took time to build the system, but eventually it will happen.
00:27:53.590 - 00:27:58.760, Speaker A: All right, so Robert is asking, what happens if someone develops a malicious built in?
00:27:59.690 - 00:28:28.990, Speaker B: Well, it depends on the way that the proven verifile will be updated in the future, I guess that there will be audit for every update. You don't allow everyone to develop something that you need to trust very securely.
00:28:30.930 - 00:28:37.970, Speaker C: In general, running a malicious building would be like running unsound Cairo code. If you write a program that's not secure, then it's not going to be secure.
00:28:39.910 - 00:28:59.354, Speaker A: Yeah, but I guess it also depends on what malicious means, whether it returns something faulty or whether it alts the proving system. But I'm guessing that if there were a built in that crashes. Not sure I'm using the right word. Right, but that creates a situation where.
00:28:59.392 - 00:29:11.280, Speaker B: You can't prove, I think that malicious means unsound, that a malicious prover can prove wrong statements using this building.
00:29:11.810 - 00:29:38.200, Speaker C: So in the Cairo one, in the ecosystem that we are developing, where everything will be complete also, then you could also have a malicious building that doesn't necessarily, is not satisfiable, it can't run, and that's also a problem, which is part of the reason I think for the moment we don't allow external abilities and it will have to be solved if we run this building in the future.
00:29:38.810 - 00:29:59.450, Speaker A: Nice. Thank you. Okay, cool. Technically, I understand that this is a very, like, it's a very important step for back end, for proving. So what will that enable exactly? Like faster proving, cheaper proving. What's the outcome of dynamic layouts?
00:29:59.890 - 00:30:38.230, Speaker B: Yes, exactly. It will allow proofs that are dedicated for the statement in a way that there is almost no waste of space, which is very important for the total running time, for latency, for throughput, actually all the efficiency of the system. And of course it will lower fees.
00:30:39.050 - 00:30:49.450, Speaker A: Nice. Do you know when this will be live? Do you have a rough estimate of what timeline we're talking about here? Is it something you guys are starting to work on, or is it something that.
00:30:49.600 - 00:31:10.260, Speaker B: No, this is in very progress. Like, we are close to finishing it. I can't say the exact date, but it will be in 2023.
00:31:11.110 - 00:31:31.946, Speaker A: Nice. That's pretty cool. Super cool. All right, and what will be the impact of this on people writing Cairo one code? Like if I'm writing some code in Cairo one, do you have to pay attention to this? Will I have to change my code?
00:31:32.128 - 00:31:55.140, Speaker B: No, actually, as I said, different layouts can run the same code, and of course the dynamic layout also can run the same code, but it will be more suitable. Developing the Cairo one code is separate from the machine on which it will be running.
00:31:55.750 - 00:32:02.718, Speaker A: So it will have no impact on my workflow, my code, I will just rip the benefits from lower fees.
00:32:02.894 - 00:32:03.570, Speaker B: Exactly.
00:32:03.720 - 00:32:33.900, Speaker A: That's a nice deal. I like it. Cool on my part. That's most of the questions I have. I think this is clear to me now. I'm going to take a look if there's more questions. So Techac is asking, is it theoretically possible to compress the execution trace in some way that provers can still generate valid proofs? One way would be to provably decompress it.
00:32:33.900 - 00:32:42.974, Speaker A: So to compress the execution trace in some way that provers can still generate valid proofs. Is this recursion? I don't know.
00:32:43.092 - 00:32:44.240, Speaker B: I'm not sure.
00:32:44.850 - 00:33:14.300, Speaker A: I'm not sure. So Tekak, if you can reformulate your question or elaborate a bit on it, that would be very useful. But to me recursion sounds like something that would help. Do what you do. So Robert is saying, how is the verifier determining the number of built ins used in the contracts? How is that link happening exactly in the verifier? How do you tell them, hey, this is the layout we're going to use?
00:33:17.470 - 00:34:00.140, Speaker B: Um, depends which verifier you're talking about. I guess you give the verifier as input. This is the layout and these are the built ins. And this is what you should verify. And then it verifies it the same way that the static verifiers do. But now it has branches and parameters that are runtime instead of being static. That's all the difference.
00:34:02.030 - 00:34:08.394, Speaker A: Okay, I guess the question could be like how do you represent a layout in the verifier? What is it?
00:34:08.512 - 00:34:33.378, Speaker B: Okay, it has several parameters. They are all integers. You have ratios of all the built ins. You have component step memory step things that are very technical. It's just a list of integers actually.
00:34:33.464 - 00:34:38.920, Speaker A: Okay, so you just actually specify the actual number of things you're going to need, right, exactly.
00:34:40.490 - 00:34:48.200, Speaker C: But again, this is not something the user should ever worry about. It's something that when we run Cairo code, we input ourselves to the.
00:34:48.990 - 00:34:59.846, Speaker B: Yes, there is a function that gets execution resources and computes the optimal layout for these resources.
00:35:00.038 - 00:35:11.440, Speaker A: Nice. So feltroyd is asking how is the cost of a built in determined in terms of Cairo steps when one is calling it from a Cairo program?
00:35:13.970 - 00:35:15.440, Speaker B: Well it's the.
00:35:16.450 - 00:35:32.006, Speaker A: So I'm guessing, I don't know if he's referring specifically like the number of trace cells, which I guess just emerged from calling the building, or if he's mentioning the cost in gas in Cairo one. And I'm not sure you guys have the answer to that question.
00:35:32.108 - 00:36:10.226, Speaker B: Okay, I have the answer for the tracers question, because every built in actually has a very strict number of tracers that it is using. The same as a single Cairo step has 51 traceels that it is using. So bitwise built in, for example, uses a bit less than 300 pesos, if I remember correctly. That's the cost for the portal, for example.
00:36:10.328 - 00:36:30.714, Speaker A: Wait, so that's actually a ratio. Right. So if you know the built in consumes a specific amount of cells, and you know that a Cairo step is 51 trace cells, then in a way, you just have to divide the cost of your built ins by 51. And you know how much is a trace cell.
00:36:30.912 - 00:36:31.660, Speaker B: Right.
00:36:32.270 - 00:36:35.338, Speaker A: Okay. And then you can convert it to gas. Okay.
00:36:35.424 - 00:36:47.102, Speaker C: Felt the gas cost won't be derived exclusively from the trace house. If the building is extremely computationally heavy, we might have to factor that too. Exactly.
00:36:47.156 - 00:36:50.398, Speaker A: Sure. Can you expand on that a little bit?
00:36:50.484 - 00:37:08.002, Speaker C: Sure. If you try to run a function that's very heavy for the machine itself to compute, like a very computational intense hash function that deals with many field elements for the machine itself, then we might have to factor the cost of debt into the gas cost of everything, as well as the traces that it takes.
00:37:08.136 - 00:37:08.446, Speaker A: Why?
00:37:08.488 - 00:37:22.474, Speaker C: So, I'm not sure exactly how this is computed at the moment, and I'm not sure if we have completely decided on how to compute it. But you can't just take the ratio of trace sales and assume that this is going to be the gas cost itself.
00:37:22.672 - 00:37:34.654, Speaker B: Okay. I think that what Alon is saying is that we haven't defined yet how gas cost is defined, so we are not sure yet what's the answer to the question.
00:37:34.852 - 00:38:20.910, Speaker A: Okay, I think I understand. One thing that popped in my mind is that probably dynamic layout make gas metering for chiro one easier, because in the static layout world, you know that you're going to incur a cost for all the built in, and then you have to divide it amongst. If there's ten slots and only one person is in it, you probably want to charge her more than if there's ten that are used. Whereas if you can do a specific layout each time you run it, then you can just have the cost, which is closer to the actual cost of the building, rather than the cost of the possibility of needing that built in somewhere.
00:38:22.770 - 00:38:44.420, Speaker B: You are right that this will make the pover. This is a way to calculate the pover cost, but I'm not sure how the fees are actually taken at the moment, so I don't know the answer. To the user side question.
00:38:44.790 - 00:38:59.100, Speaker C: The gas cost, I'm pretty sure is computed only given the number of users. If you use ten built ins, then we don't factor in the fact that we have to embed it in something that has more villains in it.
00:39:00.990 - 00:39:22.414, Speaker A: We don't do it, but we don't do it for every time. But when we price the built in, we do. Like we take into account that the price is set by us, right? I think by Stanford. So we do take this into account the fact that there is some possible loss capacity or something. I don't think we price in this sense.
00:39:22.452 - 00:39:34.580, Speaker C: I think the price of built ins is going to be a bit harder to compute rather than easier because it depends on the optimal way to put them into the layout. It is going to be cheaper. So that's a good trade off.
00:39:34.970 - 00:39:43.000, Speaker A: Okay, cool. So it's going to be more complex, actually, not more simple. Okay, cool. But it's going to be cheaper. So who.
00:39:45.370 - 00:39:46.120, Speaker C: Cool.
00:39:47.130 - 00:40:02.878, Speaker A: Yeah, always. All right, let's see if there are other questions. I don't see any. Let me check on Twitter. And it looks like we don't have many other questions. We don't have any other questions. So I think we've covered everything.
00:40:02.878 - 00:40:07.680, Speaker A: Is there any specific topic that I forgot to mention and you guys want to talk about?
00:40:10.370 - 00:40:23.940, Speaker B: No, I only mentioned that it was very nice talking with you and it is still ongoing effort of many people that I want to thank.
00:40:27.770 - 00:40:56.462, Speaker A: Well, thank you for being with us today. And yeah, please, anytime you guys want to come present whatever it is you're working on or give more details, please don't hesitate. It's always good to have this kind of conversation. And likewise for the people listening to us. If you have further questions down the line, if you're catching up this call in a few days and we're not live anymore, send the questions our way. We'll make sure to give you the answers. These are complex topics, so good questions are always fun.
00:40:56.462 - 00:41:10.800, Speaker A: So don't hesitate. All right, David, Alan, thank you for joining me today and we'll see you soon. Thank you for the work you're doing on proving Starknet and looking forward to seeing the ship then.
00:41:11.570 - 00:41:12.830, Speaker B: Thank you very much.
00:41:12.980 - 00:41:15.050, Speaker A: All right, have a good day. Bye.

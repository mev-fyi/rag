00:00:05.240 - 00:00:21.390, Speaker A: All right, so next up we have David Vorak from Sia. He's going to be talking about decentralization and cutting edge cryptography. So here it's going to be about how new cryptographic discoveries introduced new trade offs. So let's give him a hand.
00:00:25.200 - 00:01:02.664, Speaker B: Thank you. So, yeah, I wanted this talk to. Good. Okay. I wanted this talk to be a little bit more philosophical. As we start to introduce new things like starks and snarks into the ecosystem, we should take a step back and ask, should we actually be doing this? What are the implications of doing this? And so from a super high level goal, I think we're all interested in these sorts of things for the purposes of decentralization. And so I'll be looking at a couple of things that we're doing from the lens of decentralization and as an overview.
00:01:02.664 - 00:02:31.028, Speaker B: The goal of decentralized projects is to empower the individual and eliminate trust in external parties. So for bitcoin being the prime example, you can take a blockchain, verify it, and you don't have to depend on anybody else to know that everyone else in the world is seeing the exact same thing as you are on the blockchain. And so we want to kind of ask the question, is there an external group that has power over me or can make changes to myself, my environment, my tooling, the stuff I depend on, the infrastructure against my will or without my consent? And so when we talk about decentralization, we're really trying to figure out all the different ways that people can, or groups or externalities can impact the way we operate. And of course, this ends up being a gradient. So you can have partial decentralization, or you can have full decentralization. And I want to look at the following four things from this lens, which would be trusted setup, rolling trusted setup, cryptographic complexity, which is just like, for example, snarks are very complicated. How does this relate to decentralization? And then things like novel cryptographic assumptions such as class groups.
00:02:31.028 - 00:03:30.460, Speaker B: So we're going to kick off with trusted setup. And for the purposes of this presentation, I'm going to strictly define trusted setup as a ceremony with end participants, where so long as one participant in this ceremony is honest and faithfully follows the protocol, then the result is absolutely secure. And so I'm specifically talking about the construction where we need one person in the entire ceremony to be honest. If we ask the question, is there an external group that can manipulate me or my experience? The answer is instantly yes. Whoever participated in the trusted setup ceremony has the power to if they all collaborate together, they can manipulate you. And it's for this reason that it's called a trusted setup. We do have to trust the group to at least some extent.
00:03:30.460 - 00:05:01.016, Speaker B: It's instantly not purely decentralized. And specifically, I would say that trusted setup has a super counterintuitive threat model. Normally when I hear people talking about trusted setup and asking like, is the zcash trusted setup secure? Are these other trusted setups secure? They're thinking about what would have had to happen, which people would I have to not trust in order for this trusted setup to be broken? And I think this is a very bad way to think about trusted setup. What we should be asking instead is what would it take for a malicious group to work together and convince everybody that they have made a trusted setup, which everybody believes the trusted setup is secure, when in fact the trusted setup is broken. And so really, when you're thinking about trusted setup and the security model inherent to it, you should be looking for underhanded strategies and like sneaky techniques that people or an adversarial group could be employing to convince the population or convince a group that a trusted setup is good. So a couple of ideas that we can apply, thinking from an underhanded sort of model, is you can cherry pick individuals. If you have 20 individuals who to the general public, seem trustworthy or seem at ods with each other, but you know, because you're backroom friends with all of them, that they are in fact willing to collaborate, you can cherry pick people.
00:05:01.016 - 00:06:25.220, Speaker B: And so a group of like 20 prominent individuals is not a convincing trusted setup ceremony, because out of all the prominent individuals in the world, the malicious group can cherry pick the 20 that they know will work together to create a malicious trusted setup. And we really can't tell if that has ever happened. Trusted setups can also do things like civil attacks. So if there's a trusted setup with 10,000 participants, unless I personally know all 10,000 participants, there's some question as to how legitimate was this? How many of those 10,000 people were actually real? Or even if they were all real, how do we know that the trusted setup software was not compromised or not backdoored? Did everyone, before participating in the trusted setup, look at the software, verify the software, download it in the correct way? Do they even have the expertise to do such a thing? And this kind of is just scratching the surface. We don't really know what types of underhanded techniques for trusted setups exist. It's not something that's been super well researched, and it could be future pondering on this issue could reveal some very nasty underhanded tricks that could be employed to manipulate trusted setup. So I think I'll go ahead and skip this slide.
00:06:25.220 - 00:07:17.732, Speaker B: Actually, I will cover this. So after you have a trusted setup, your trusted setup confidence can only decrease over time. Once you've chosen to trust a group of people, you can't re verify them if they cheated, you may never find out. As time passes, as distance grows within between the trusted setup ceremony and the present, confidence actually degrades over time. And as the groups grow, as you try and expand, your trusted setup ceremony looks increasingly fragile going backwards. So trusted setup also introduces these systemic issues. An ecosystem with multiple trusted setups faces an exponentially compounding degradation of security.
00:07:17.732 - 00:08:39.932, Speaker B: Basically, if we really blow it up and we say that our general stack depends on 10,000 different trusted setups, and each trusted setup we have 99.99% confidence in, that means that the ecosystem as a whole is almost certainly compromised, and just the whole ecosystem is bad. If it all depends on each other and one of the trusted setups in the ecosystem is broken, you really don't want to end up in that situation. So I don't like the idea of going piecewise from trusted setup to trusted setup to trusted setup, and deciding, okay, well, we looked really closely at the zcash one. The zcash one is probably okay, because now if zcash starts to become something that the ecosystem depends on, or if that trusted setup becomes something that the ecosystem depends on, that just has systemic implications, especially if you start to do that repeatedly with five or ten or 15 or 15,000 different trusted setups. So for all of these reasons, I think that just like point blank, trusted setup should never be considered acceptable. You only need one broken trusted setup in your general purpose ecosystem stack to erode the security of your entire ecosystem.
00:08:39.932 - 00:09:25.416, Speaker B: Especially if the trusted setup starts to get used as building blocks for higher level applications, which I think is almost inevitable once you have a primitive. People really want to build using it. People should build using it. And in the terms of trusted setup, I think that this just means the systemic risk gets out of control very quickly. And so I just underscore one more time, like a single trusted ceremony, static trusted setup should never, ever be considered secure, and we should just throw all of them away and view them as a research body and not as a set of applications. Thank you. Okay, so I'm going to move to the next one, which is rolling trusted setup.
00:09:25.416 - 00:10:36.656, Speaker B: So I'm going to define for this presentation a rolling trusted setup as a trusted setup where you can join at any time something like sonic. And once you've joined it, as long as you are honest or as someone else joins it, as long as one person in the entire history of the rolling trusted setup is honest and successfully participates in the protocol, the trusted setup from that point forward is forever secure. So this is obviously better than a static trusted setup, in that if I'm late to the party, I can convince myself that it's secure. Just by participating, we kind of move back into the model that bitcoin operates under, except that it does not give me any confidence in pre existing operations. So, for example, if we're doing something like zcash, actually, I think this is true of zcash. If the trusted setup breaks, you can have infinite inflation. If it's a rolling trusted setup and I join after the fact, infinite inflation may have happened before I joined, and therefore the entire system can't be trusted.
00:10:36.656 - 00:11:21.572, Speaker B: So you have to be really careful. And then people talk about combining something like sonic with turnstiles, which I won't get into, I would say maybe, but that's complicated. I don't like it. Generally speaking, you should not trust the rolling trusted setup until you've participated in it. And then once you've participated in it, you should treat everything that happened prior to you participating in it as completely broken. And I think that this severely limits the utility of rolling trusted setups. So generally speaking, similar to static trusted setups, I would strongly advise against them, but I wouldn't say they're strictly no good.
00:11:21.572 - 00:12:31.640, Speaker B: If you do more complicated, elaborate like rolling trusted setup plus turnstiles, plus some other overheads, maybe it's acceptable. So I won't say it as absolutely as I said it for a static trusted setup, but I do think that we should just trusted setup is just not a good idea. We should stay away from them. Okay, so that's probably like the harshest part of the talk. Now I'm going to be moving on to cryptographic complexity, which is for the purposes of this presentation, I'm going to be saying that it's a measure of how likely it is that a cryptographic system contains a mistake or unnoticed security vulnerability. So, for example, if a year from now, some researchers looking at Starks and just goes, oh, this has been broken the entire time, look at this mistake, and everyone kind of agrees, oh, man, Starks have been broken this entire time. So we're looking at how likely is it that someone finds this mistake in Starks in the future versus how likely is it that Starks, as they are today, are completely perfect, completely secure? All the proofs are ironclad, bulletproof.
00:12:31.640 - 00:13:31.612, Speaker B: So especially for larger papers, it's not uncommon for proofs to be found incorrect or the threat model to be widened, or some mistake in the execution of the crypto system to determine that it's been insecure the whole time and that we need to upgrade it. So I would say that this is similar to trusted setup in that it represents an opportunity for external parties to manipulate you. It's a way for someone to cause infinite inflation or to just cheat. And so we should be careful. With really complex crypto systems. Unlike trusted setup, though, with trusted setup, as you get further away from the ceremony, your confidence goes down over time. But with complex systems, as we get further away, as they get more review, our confidence in them grows over time.
00:13:31.612 - 00:14:32.976, Speaker B: And so this really complex, really what I would call initially, like, toxic ball of cryptography, over time, as we understand it better and we get more familiar with it, it can actually turn into something that we start to really depend on and can safely really depend on. And so, I guess, three big ways that you can chip away at the scariness of a complex crypto system is one increase review. The more people who have looked at it and failed to find a mistake, the better you feel about the system, and the more likely it is that it doesn't contain a mistake. And then you can build new analytical tools, things like formal verification. And so you can take, say, pieces of the proof or pieces of the system and just analytically produce, like, a clean computer proof that this is definitely correct. And then finally, you can get new mathematical techniques that give you confirmations. This thing that we proved one way, now we have two or three other ways to prove it.
00:14:32.976 - 00:15:33.092, Speaker B: All these sorts of things build confidence over time that our complex system is correct. And so definitely unlike trusted setup, I wouldn't say you should stay away from complicated systems. I think they're worth a lot of energy, and over time, they become less scary. And so the question then becomes, how scary is something today, and when should we be comfortable jumping in and using it? So I am just going to give. Oh, okay, I'm going to skip this slide. So I would say that most of the new cryptography that cryptocurrencies are considering is substantially under reviewed relative to how safe it should be. Just if you keep an eye on the headlines and the papers that come out and you see, oh, this ECDSA construction had a break in it, or you find, as researchers break things, I would say that cryptocurrencies are taking on.
00:15:33.092 - 00:16:20.644, Speaker B: We come back to the systemic question. A lot of systemic risk because they're using a lot of building blocks at once. They're using a lot of novel techniques at once. I think the risk is very high. And that if we're going to be considering running the entire banking system on this, we need to slow down a lot on how quickly we are accepting complicated cryptography into our toolkits. And so I think most of the new cryptography that's being introduced should really only be used in contexts where a full break would be considered acceptable. And so if you're using cryptography like starks to prove that there are a finite number of coins, you don't have infinite inflation, this is a good example of something I would be very afraid of.
00:16:20.644 - 00:16:59.920, Speaker B: And I would not consider that a production ready system just because of how new the cryptography is. So I'm going to call out starks specifically as probably being just strictly too early to be considered safe for production use. And like I said, this will change over time. The further we get along, the more people who get interested in starks, the more academics that review starks and don't find a mistake, the weaker that my warning becomes. So I definitely think that this is something that. A direction that we should be moving. And I'm, like, a big fan of Starks, but I would say it's too early to deploy them in production.
00:16:59.920 - 00:17:40.460, Speaker B: Bulletproofs I, like, really waffled on. I think I'm going to actually change what I said in the slide. I think they're probably not okay. And what I wasn't considering when I made the slide is the systemic risk. And so if we take multiple constructions that are as risky as bulletproofs, we really don't want all of them in place. And I think because you use lots of constructions, schnorr signatures, Schnorr threshold, things like taproot and graftroot. And this is at the bitcoin level, because we have so many just new cryptographic constructions that we're starting to put into production.
00:17:40.460 - 00:18:30.990, Speaker B: I do think that things as complicated as bulletproofs, I feel like it's likely that if we have ten different things as complicated as bulletproofs, the chances that one of them has a critical mistake in it are unacceptably high to run a banking system on. So, yeah, I'm going to say bulletproof is also not okay yet. Okay. And that brings me to the final phase of this talk, which is novel cryptographic assumptions. So the example would be, like, a classical example of a cryptographic assumption, is the discrete logarithm problem. So, I would say that novel assumptions should be seen as very scary. Mathematical assumptions often take decades, or even sometimes you get these problems or conjectures proven or disproven, like, 100 years later.
00:18:30.990 - 00:19:30.924, Speaker B: And a lot of times, the proofs that come out are very surprising. And so sometimes you get a very surprising result to a long thought, reliable conjecture. And so, for that reason, I would say cryptographic assumptions are scary. You should be really careful around them. And so I would call out class groups specifically as something that's, like, even if an assumption is many decades old, if no one's been looking at it, the age doesn't really count for anything. So you want to make sure that you're using assumptions where lots of very smart people have considered the problem for long periods of time, and you've had specialists with a decade of linear thought on trying to dissect an assumption and failing to come up with anything meaningful before you want to start depending on it. So, yeah, I would call out class groups is probably, like, even further away from than starks by a substantial amount from being acceptable.
00:19:30.924 - 00:20:03.690, Speaker B: And this is me not knowing too much about class groups, for what it's worth. But as a new assumption, something that didn't even have code written around it a few years ago, I think, is just, to me, it's very scary. And I think we should be avoiding things like class groups in our cryptography. And so this follows the same thing as the complexity. Over time, we can get more comfortable with it. If we get really lucky, someone will come out with a nice, clean mathematical proof. Hey, class groups are okay.
00:20:03.690 - 00:20:54.220, Speaker B: If you have a nice mathematical proof that the assumption is true, it disappears as an assumption, and then on the bad side, it might break. So I would say, just in general, cryptographic systems only gain in complexity. We only gain primitives if people are actively working on it. This is true whether it's like starks, whether it's class groups. And so even though some of the things I said were kind of discouraging or slowing down in the presentation, I just want to emphasize that I'm really excited about everything that's coming out. I think that all the energy going towards trusted setup aside, this new cryptography is really good, and I think in production, we should be slowing down and being more conservative. But all the energy that we're spending on research is, like, really well spent.
00:20:54.220 - 00:20:59.870, Speaker B: All right, I'm just going to jump to questions. I am out of time.
00:21:11.220 - 00:21:20.436, Speaker A: If you have questions, it would be great if you go over to one of the mics on the side. Yeah, it's too far. I can run into the middle.
00:21:20.538 - 00:21:32.120, Speaker C: I was just wondering, how would you define complexity? Because things tend to be complex at one point and then a couple of years later they teach them to undergrads.
00:21:33.180 - 00:22:19.300, Speaker B: Yeah. So for the presentation, I specifically defined complexity as how likely something is to contain a serious mistake. And so this obviously has an inherent assumption of how familiar everyone is with it, how much tooling is around it. So complexity doesn't necessarily mean that you can't have a thing with 900 parts. If all 900 parts are super well reviewed and analyzed and have been part of the toolkit for a long time. That's not complexity under my definition. My definition is purely a probabilistic analysis of how likely something is to have a mistake that we haven't found yet.
00:22:19.450 - 00:22:28.090, Speaker C: Thank you. My question is, I guess today we learned we live in a Cambrick explosion. Hey, I'm here on the other side.
00:22:28.700 - 00:22:29.464, Speaker B: I see you.
00:22:29.502 - 00:23:07.776, Speaker C: Today we learned we live in a Cambridge explosion. And I love this picture, basically. And I love competition, because this is basically the best thing what man ever invented. And still you say we have basically too much innovation and we should stall some of them in production systems, which I disagree, because in order to check all those crypto economic incentivization, we need skin in the game. We need people to fail and lose money and do whatever mistakes there are. So basically, we should encourage everybody to jump into the pool without knowing what's.
00:23:07.808 - 00:23:59.008, Speaker B: In the pool, basically, yeah. So I think of a lot of the stuff we're building as deep infrastructure. So I might make a comparison to, say, building a bridge or a skyscraper. And so if you're talking about a cambrian explosion of new bridge building techniques, and then you're essentially urging people to come cross the bridge before we know it can bear load. I think that this is very risky and irresponsible. And so I'm definitely not discouraging people from developing new bridge techniques, but we should be more confident in the math behind the bridge and the physics behind the bridge, and we should be load testing before anything of importance is using the bridge on a daily basis. And so, yeah, I think that would be my opinion.
00:23:59.008 - 00:24:06.440, Speaker B: It's not that I'm discouraging the innovation, it's that people should not use it until we've verified that it's actually not going to collapse.
00:24:07.820 - 00:24:09.400, Speaker A: There's a question over there?
00:24:09.550 - 00:24:42.480, Speaker D: Well, I think it's an impossible question to answer. Impossible problem. How you can trust a mathematical assumption, it will takes many years, I would say almost impossible. But we have this discussion in the context of post quantum cryptography. So where we are going to replace a current signature algorithm. And so, of course, we are afraid because it's a basic. And so what is proposed in this context is to do Ebrid techniques.
00:24:42.480 - 00:25:00.072, Speaker D: So when you do a signature, you do a post quantum one plus a classical one, so you have a backup. I don't know if we can do this with Stark, but in terms of agility and trying new things, it's a good way to move, I would say.
00:25:00.206 - 00:25:35.270, Speaker B: Yeah. So I think that comes down to systemic risk. I'm personally a big fan of the pre quantum, post quantum multi sig, for example, in bitcoin. I think it would be great if bitcoin had support for lamport signatures. That way, if quantum computers come out, everything breaks. We can just institute a soft fork that says no pre quantum signatures are allowed ever. If we know that most outputs also have taprooted hidden in them, a lampport signature, then people can still spend their money, even though this catastrophic failure has happened.
00:25:35.270 - 00:26:26.164, Speaker B: In terms of starks, you have to be really careful on what the failure mode is. So, for example, if your failure mode is that infinite inflation becomes possible and there's no way to go back. If you have 500 transactions in your history, and any of the 500 transactions could either be non inflationary or infinitely inflationary, the whole system becomes broken. So I think it's a good idea to try and balance having a failover. If this assumption fails, we all fail over to this new way of doing things. But you have to make sure that if you're going to be doing that, the failover is actually successful and there's not some critical meltdown that occurs. So I believe we're now out of time, actually.
00:26:26.282 - 00:26:35.464, Speaker A: So we are going to stay. Anyone who's here should probably stay here. We are ahead of the other room. Okay, so we're not out of time, but I don't know if you want to keep talking.
00:26:35.582 - 00:26:37.320, Speaker B: I'm glad to keep taking questions.
00:26:37.390 - 00:26:38.170, Speaker A: All right.
00:26:39.340 - 00:26:46.030, Speaker E: Do you have an example of an assumption that was relied upon for, and then that was broken after 100 years?
00:26:47.920 - 00:27:21.290, Speaker B: So I wish that I had the name of the paper. I don't know about 100 years. You'd probably have to go into the mathematical space. But in terms of cryptography, I know that there were. I don't have the paper on the top of my head, I believe some ECDSA schemes that were all thought to be secure and then like one paper came out and broke something like close to a decade of ECDSA work. So if you find me afterwards, I can pull that up for the 100 year one. I don't have an example off the top of my head.
00:27:23.260 - 00:27:33.980, Speaker A: I actually have a question. Do you know of any trusted setup that actually was compromised? Like any public, proper trusted setup?
00:27:34.480 - 00:28:52.070, Speaker B: So it's kind of a stretch, but NIST did that whole elliptic curve, random number generation thing, right? So some of the NIST stuff, which I would consider NIST published cryptography to be trusted, was actually backdoored, and they got it through the whole standards process. The difference between that and trusted setup is that that was really brazen, because if you get caught, you can just prove it and you're like, look, this has been broken. It's always been broken. Trusted setup doesn't need to be, that is much less brazen, because if you do the same thing in a trusted setup, there's no proof that the trusted setup was compromised, or it's very difficult to come up with a proof that someone has done this. So I would say if we've had backdoors at the NIST level, we will definitely have backdoors at the trusted setup level when trusted setup reaches international scale. And that's why stay away from trusted setup. So pardon my rudimentary understanding of the sort of underlying security here, but do trusted setups assume that the hardware on which the setup is being done is trustworthy? That's a great question.
00:28:52.070 - 00:29:34.412, Speaker B: It depends on the trusted setup model. For example, one of the things you can do is you can get like say, four processors from four different manufacturers and have them do a multiparty computation between each other. So if that's part of your trusted setup now, not only do your trusted setup participants have to collude, but also the processors have to collude. In short, the answer is yes. Ultimately, if you don't trust your hardware, the hardware is almost the ultimate trusted setup. And I think it's something that we're going to have to face more head on in the future. For example, the most popular hardware wallet ledger is closed source.
00:29:34.412 - 00:30:30.310, Speaker B: Is that really a great idea? I would say no, it's not a great idea. And I do think the hardware problem is a lot more significant. What is working to our advantage is that hardware is insanely challenging. Most super advanced cpu techniques can be explained in like a 30 or 40 minutes lecture, because going from something complicated to going to a perfect gate level implementation is just a process that humanity has not figured out how to do very well at this point. So the one thing in terms of trusted hardware that's running in our advantage is that designing a backdoor to put on a circuit is super nontrivial, just because hardware does not easy to make complicated hardware, but it's nonetheless possible. And it's something I say we should be a lot more concerned about.
00:30:35.900 - 00:31:11.968, Speaker E: One of your concern with the static trusted setup is that you could have a cabal of people who kind of collaborate. And the way you should think about it is what is the probability that such a cabal can form? What if you have a static setup where it's open participation for a period of time? So let's say for a whole year, anyone can participate. And you'd use, let's say, a censorship resistant platform like bitcoin to register interest as a participant. It would still be a static setup. And would that still be not trustworthy?
00:31:12.064 - 00:32:22.760, Speaker B: Yeah, so I would look at all the other underhanded techniques that could be used. For example, what's the technical barrier to participating in the trusted setup? If you want to participate in the trusted setup with an alternate set of software, let's say I don't trust the software that's being given to me. Is there a way to do that? Are we doing things like build system integrity? So, do we know that the trusted setup software was compiled with libraries that were trustworthy? So even if we have something like Gideon and deterministic builds, Gideon depends on libraries that come from Ubuntu. And especially once we get to the more international scale, we have to wonder, are these build systems trustworthy? And so I think that there is no silver bullet for trusted setup. There's no single technique that can give you confidence in a trusted setup. Purely because I think that if you really dive deep into all the underhanded strategies available, you find a lot of really scary things, and it seems like a ball of bad ideas.
00:32:25.340 - 00:32:29.340, Speaker E: It seems like this argument applies to many other things, not just trusted setups.
00:32:30.400 - 00:33:13.930, Speaker B: But the key that differentiates trusted setup from everything else is that we can't go back and check it later. So with something like starks, if we don't trust the build system for compiling our stark verifier later on in time, we can redo the build system, or we can use new techniques, we can go back, we can make a new verifier, and we can say, okay, these are still equivalent. We can go back, double check and reconvince ourselves continually that the system that we built does not have any issues with it, whereas with trusted setup, once the deal is done, you have no idea if there was an issue in the process later. And it's not something you can go back and double check.
00:33:14.860 - 00:33:18.710, Speaker A: Thank you so much for doing this. Extended Q a. Let's give you a hand.

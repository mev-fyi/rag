00:00:03.290 - 00:00:20.138, Speaker A: So I'm going to talk about fries. So fry, you all know, but there are many fries and so we'll see a whole bunch of things. Let's see where is. Great. So the plan for this talk is. So, first, high level overview of the setting. We're talking about interactive verification of some computation.
00:00:20.138 - 00:00:55.920, Speaker A: So thanks to Ale's talk, I am in the IOP model, so I can assume interaction and it later gets converted into non interactive arguments using everything that happened there. So then I'll talk about starks, how one argues about the soundness of starks. Those eventually get based on this protocol called Fry, which checks low degreeness of polynomials. And then we'll see a fancier version of Fry called Deep Fry, which has some advantages. Then we'll see another version of Fry, ecFry, which has some other advantages. So please feel free to ask me questions along the way. It's meant to be accessible to all.
00:00:55.920 - 00:01:25.430, Speaker A: Okay, great. The high level topic, I'll call it delegating computation. So you have a powerful computer, which we'll call the cloud. And you have a not so powerful verifier and they're interacting with each other. And we want to see whether you can offload some computation to the cloud and let it solve some problem for you. And how would you do such a thing? So you delegate computation. You have an algorithm a and it has an input x.
00:01:25.430 - 00:01:53.390, Speaker A: And the cloud did the computation and came back with the answer. It said the answer was seven. Great. But this is meaningless unless the verifier is also sure that the cloud did this computation. Correct. And so this is what the question is. How do you verify that a computation was done correctly? Okay, how do we even talk about proving? So, I will mention three words that you sort of saw in the last talk.
00:01:53.390 - 00:02:48.718, Speaker A: So, normally, if I do something and I show it to you, so I do some problem, I solve a problem that you give me, I can show my work to you. So I show you all the steps that I did, and you as a verifier can go through each and every step of mine and confirm that everything was done correctly and see that the answer was done. But this is of course not so useful in this context because it requires doing as much work as the prover did. So what was the point of this? So another nice solution concept is probabilistically checkable proofs. So these are quite amazing things that you would not conjecture to exist unless you saw one. And this says, not only should you show your work, you should also add hints in your work that helps me verify that this computation was done correctly, and it should help me verify it with just a small number of queries into this proof. These things are called probabilistically checkable proofs.
00:02:48.718 - 00:03:21.606, Speaker A: These are intensely studied in theoretical computer science. And the setting which will be most interesting for us is showing your work with redundancy just in the PCP setting. But we'll also have some rounds of interaction. So after you show your work, the professor will call you into his office and grill you about what you wrote, just to make sure that in that case, it's to make sure that you wrote it. But in this case, it's to make sure that there is truly a solution underneath. Okay, so this is the notion of proof. So the setting now is iopps.
00:03:21.606 - 00:03:54.280, Speaker A: There's another p in there. IOP stands for interactive oracle proofs. IOPP is interactive oracle proofs of proximity. So I will say what this means just as I define the setting. Okay, so this talks about sublinear time proof verification. So there's a proof of something, and we want to verify it in sublinear time, smaller time than it takes to write the whole thing. And the model is there's some long string f of length n, and the verifier is given access to this, and it wants to check some property of this f.
00:03:54.280 - 00:04:20.554, Speaker A: One typical property that we'll be talking about is f, is the evaluations of a low degree polynomial. For example, there's a prover. The prover is going to help convince the verifier that this string has that property. Verifier will ask questions. The proverb will write down some answers. These long answers are written down, and the verifier can then access certain bits of those answers. And the verifier only pays for the bits that it accesses.
00:04:20.554 - 00:04:51.946, Speaker A: It doesn't pay for the length that doesn't count in the proof. The verifier's running time does not include the length of the answers. Okay, so this is the model which work. This is the interactive oracle proof model. There's a proximity part, which is coming soon. And the goal here is to minimize the prover time, the verifier time, the total length of all prover responses. This is the kind of things that we're trying to optimize, okay? And so just in picture, you have approver, your verifier, and this f is written down, and we're verifying some property of f.
00:04:51.946 - 00:05:29.394, Speaker A: The verifier sends some question b, zero. The prover writes down in f one, the verifier sends another question f one sends another question b one. And the verifier prover writes down f two and so on. And the verifier can keep ask. The questions that the verifier makes can be functions of whatever queries it has seen so far. So at any point the verifier can query any entry of these fis that it has seen so far and base its next questions off of those good. And the desired properties we want out of this protocol is completeness.
00:05:29.394 - 00:06:13.774, Speaker A: So if f has the property, we want the verifier to accept with probability one. And since we're talking about verifiers who run in sublinear time, this verifier does not have enough time to read all of f. So automatically, when you have a sublinear time algorithm which has completeness, then any string f which is close to having the property will have to be accepted with property close to one. If you take an f which is truly with the property, and you just go change it in one location in sublinear time, you're not going to be able to tell this difference. So this automatically happens. So the completeness side of it has to say something. The completeness side cannot say that whenever f does not have the property, the verifier rejects with high probability, it has to say something milder.
00:06:13.774 - 00:06:56.802, Speaker A: So what it says is if f is delta far from the property, meaning it differs in delta fraction of the inputs, then the verifier cannot be convinced to accept the property more than something, some soundness of delta. The relationship between delta and s of delta will be a topic of intent study. Good. So this is the setup of the problem. So strings that have the property, the prover can convince the verifier that it has the property. And if the string does not have the property, then no matter what the prover responds, the verifier should reject with good probability. This is the interactive proof of that's why the proximity is in IoPP, because it only really tests nearness to the property.
00:06:56.802 - 00:07:25.500, Speaker A: It doesn't really test having the exact property. Good. So now I'm going to discuss starks in somewhat more detail. People who have been to the stark workshop where you did something about Fibonacci numbers. So this is going to be very familiar, except I'm going to open up some more details. Great. I will discuss a stark in the context of approver claiming that the nth Fibonacci number mod q equals seven.
00:07:25.500 - 00:08:03.640, Speaker A: So we know the Fibonacci numbers. We're looking at these numbers and we're going to prove that the nth one is seven mod q. Okay? That's what the prover has claimed. And now we'll talk about how the prover can convince a verifier of this fact. Okay, so how do you do it? You show your work. So this is give all the first n Fibonacci numbers, and then we'll add some checking friendly redundancy, and then we will send all this stuff to the verifier. Okay? And this will enable the proof that we talk about.
00:08:03.640 - 00:08:53.670, Speaker A: Good. And then there'll be interaction. Okay, so the prover has claimed that the n Fibonacci number is seven mod q. So what's your work? When you found that the nth Fibonacci number is seven mod q, your work is, you computed the first n Fibonacci numbers using the definition of Fibonacci numbers. The f of I is the ith Fibonacci number, and it satisfies the relation that f of I plus two is f of I plus one minus f of I plus f of I. Right? So maybe you show your work, take f, send that f to the verifier, and the verifier wants to check that f of I plus two minus f of I plus one minus f of I is zero for all eyes between one and n minus two. And then the verifier can take a random I and check that this holds.
00:08:53.670 - 00:09:26.226, Speaker A: Good. And that's it? Yeah. Okay. No, of course not. This is garbage. So for a sequence f to have this property, I mean, my proposal was to just check a random I and check that f of I plus two is f of I plus one plus f of I. A sequence of numbers is not the Fibonacci sequence, unless this holds for every single I.
00:09:26.226 - 00:09:45.640, Speaker A: Your claim about the nth f relies on every single one of these constraints holding, not most of them holding. This kind of analysis is nowhere close to true. So we'll have to do something else. So let's try something else. So we have f. This is the ith Fibonacci number mod q. This is the true f that we're working with.
00:09:45.640 - 00:10:14.586, Speaker A: So here is the augmenting the redundancy that helps us in checking the proof. We will take a low degree extension of this f. So f is a function right now defined on the integers one to three up to n, viewed as elements of fq. And we take the unique low degree polynomial that fits one to three up to n. Take that and evaluate the unique low degree polynomial of degree n minus one. That is, and evaluate it on the points one to three, up to eight n. So this is the low degree extension.
00:10:14.586 - 00:10:43.530, Speaker A: And we send this f. Okay, so it's the extension we had f and we extended it. Okay, and this is a degree n polynomial evaluated at eight endpoints automatically. There's some redundancy here because two different degree n polynomials, their evaluations on all eight endpoints will look very different from each other. Okay, so this is what's going to be the star of how to prove that this is truly the Fibonacci sequence. So the verifier wants to check that this holds for all I. Again, the for all is important.
00:10:43.530 - 00:11:08.180, Speaker A: It's not for most I, it's for all I. And the way it's done is by this. So this is the main trick of starks, which is, okay, you take the vanishing polynomial of the set where you want to confirm your constraints. So Z of X is defined to be product. Overall, I is going from one to n minus two of x minus I. And what we want. So one to three up to n minus two is related to that.
00:11:08.180 - 00:11:38.154, Speaker A: And here is the, in more detail, this is what we look at. So we'll define two new functions, g and h, defined on one, two, three, up to eight n. Again, they're based off of f. G is f of x plus two, minus f of x plus one minus f of x. So what we're wanting is that g is zero on one to three up to n minus two. That's what we want. So it's degree n, because f is degree n, it vanishes on one to three, up to n minus two.
00:11:38.154 - 00:12:07.750, Speaker A: If we truly wrote the Fibonacci sequence. So the crux is that g is then divisible by z of x. Because when you have a univariated polynomial that vanishes on a set, then it's divisible by the vanishing polynomial of that set. And since it's divisible, we can divide and consider g of x of x, which is g of x divided by z of x. And this h should be low degree, because we took a low degree polynomial divided by a low degree polynomial. What you got was a low degree polynomial. Not a rational function, a low degree polynomial.
00:12:07.750 - 00:12:29.386, Speaker A: Okay, and so this motivates the stark protocol. So the first round of it is, let's first check that f is low degree. F is supposed to be the low degree extension of it should be low degree means n. In this case, it's evaluated on eight endpoints. And you want it to be degree n. You want to check that h is low degree. H is some degree, based on this.
00:12:29.386 - 00:12:53.246, Speaker A: And it ought to be a low degree polynomial. And finally, check that f of n is seven. And these three steps together would convince you that what was written down. Is truly the low degree extension of the Fibonacci sequence. And if that's the case, then f of n, being seven, is confirming that the value was what you want. So this doesn't quite work. Because checking that f is low degree.
00:12:53.246 - 00:13:08.178, Speaker A: Is not something we can do. We're hoping to run in sublinear time. So you can only check proximity to low degree. And this is what fry does. And this is what the rest of the talk is. So the real way this works is you check that f is close to low degree. Not f is low degree.
00:13:08.178 - 00:13:32.026, Speaker A: But check that f is close to low degree. You check that h is close to low degree. But then you can't just check that f of n is seven. Because f itself, while it's close to low degree, might be wrong at the particular point n. So you should somehow check that the polynomial that f is close to that polynomial. Has value seven at n. And so the way to do that is by some little algebra trick.
00:13:32.026 - 00:13:55.858, Speaker A: You consider the function f minus seven divided by x minus n. And check that is close to low degree. So the combination of checking all these things. Convinces you that the n fibonacci truly is seven. So this is the high level sketch of how stocks work. And the soundness analysis is just if f is truly close to low degree. And h is truly close to low degree.
00:13:55.858 - 00:14:15.978, Speaker A: And f of x minus seven over x minus n. Is also truly close to low degree. Then look at the underlying polynomial. Say, capital f that's close to this f. And that underlying polynomial, capital f. The claim is that that is truly the low degree extension of the Fibonacci sequence. This is the claim that one makes, and it's easy to prove, given all these details.
00:14:15.978 - 00:14:51.610, Speaker A: Okay, so, ultimately, everything now relies on fry. This protocol that tests proximity to low degree polynomials. So the rest of the talk is about that. Any questions about this? Okay, so this was how the stark protocol is based on testing proximity to low degree. For more general computations. Encoding the constraint problem that you have as a problem about low degree polynomials. That's an art.
00:14:51.610 - 00:15:13.342, Speaker A: Which. Yeah, different. There are ways of doing that that's not of science yet. Okay, so how do we test closeness to low degree? So, now we can forget a little bit about the starks. I just will start with another clean question. You have a finite field f. You have an evaluation domain D, which is a subset of f.
00:15:13.342 - 00:15:47.658, Speaker A: And you're given access to some function f on D. Okay? And you have a prover who's going to try to help you get convinced that f is close to low degree. So if f is a polynomial of degree less than rho n you want to accept, there should be a way for the prover to make you accept. And if f is far from polynomials of degree less than rho n, we want to reject with high probability. Yeah, good. Far means the distance of f from polynomials. The fraction of points where it agrees should be at least something.
00:15:47.658 - 00:16:14.898, Speaker A: So that's a quantity that we can tune. Let's think of it as zero one, for example, zero one n, or zero one fraction. Other questions? Okay, and so now, this is the fry protocol from Bbhr. It's an elegant, fast protocol for this. It just has o of n prover work. The proof sizes are of n. This is as small as you could hope for.
00:16:14.898 - 00:16:49.440, Speaker A: It has very fast verifier time, very fast, very few queries, and only order login rounds. And all the constants in there are small. So it's really compact and practical. And the main building block inside this is something I'll call an algebraic sketch. And it does the following thing. So, if you're given a function f and a random seed b, this function f is defined in the domain d, then the algebraic sketch is a smaller function. It's a function on a domain of half the size.
00:16:49.440 - 00:17:18.840, Speaker A: We started with a function on a domain of size n. We made a function on a domain of size n over two. So it halves the length. It looks like that it takes b as the b is the seed to this. It's a random seed that goes on to the side, and it has three main properties. Property one is that it's local. Each output symbol of each evaluation of f prime depends on two evaluations of f.
00:17:18.840 - 00:18:01.346, Speaker A: It is degree respecting. If f is low degree, then so is f prime for every choice of b. And finally, it's farness preserving, which is that if f is far from low degree, then with high probability over the choice of b, f prime is far from low degree. These are the three key properties of the algebraic sketch that will underlie fry. So I won't tell you what the algebraic. Yeah, so, no, I'm telling you what the algebraic sketch is now. Okay? So I'll tell you what the algebraic sketch is.
00:18:01.346 - 00:18:32.960, Speaker A: It takes a function of size, and it makes it a function of half the size. And it itself is based on the fft, which. So it works in the case where d is the nth roots of unity, where n is a power of two. And it has a very simple description. Now, take your function f. Had it been a polynomial, a zero plus a one, t up to ak t to the k, we will break it into its od parts and its even parts. You write f as g of t square plus t times h of t square.
00:18:32.960 - 00:18:53.182, Speaker A: G is now a polynomial of half the degree. H is a polynomial of half the degree. And they are naturally. I mean, since you're only evaluating it on t square. And f was defined on the nth roots, g gets automatically defined on the n over two roots of unity. So you take gnh. So, explicitly, this is the formula for gnh.
00:18:53.182 - 00:19:34.244, Speaker A: And you can see that they're locals, because g at a point u just depends on f at the point square root u and minus square root u. So it's a concrete local property. And then the definition of the algebraic sketch is to take a random linear combination of g and h, g plus b times h. So, the algebraic sketch took in a function defined on all the nth roots of unity. And it gave out a function defined on the n over two athrots of unity. And it's a random function depending on the seed b. And once I have the algebraic sketch, I can describe what fry is.
00:19:34.244 - 00:20:04.924, Speaker A: Fry is in the first stage, which is called the commit phase, we take f and we take algebraic sketches. So, first, the original function f. We'll call it f zero. The verifier will pick a random b zero and ask for the algebraic sketch of f zero with b zero. And that's some function of half the size. Then again, the verifier picks a random b one and asks for the algebraic sketch of f one with b one. And it's of half the size.
00:20:04.924 - 00:20:30.176, Speaker A: And it keeps going on at each stage. The degree of this, if it started off as degree rho n, it would be rho n over two, rho n over four, and so on. So the degree keeps reducing, and at some point, it should become constant. And at that point, you're done. You don't have to check anything. At that point, you claim that the values are constant, and that's what it is. So if f is truly low degree, then each f I should be of degree less, of less than rho n.
00:20:30.176 - 00:20:59.984, Speaker A: Then each f I should be of degree less than rho n. I and the final polynomial should be a constant function evaluated at one of a row point. Okay, that you check by hand. This is what should happen in the good case. Good. So now, how can the verifier see that the fis that have been given are actually good? So this is the query phase of the protocol. We check for each I that fi and fi plus one are consistent with each other.
00:20:59.984 - 00:21:37.076, Speaker A: This is the local property of the algebraic hash sketch coming in. So each evaluation of f two depends on two values of f one. So you check that at a random point of f two. So that's what the checks are. In the query phase one picks, we check the fi and fi plus one are locally consistent and that ft is constant. So actually, in the real protocol, there's some subtleties in how you do this, but this is a good high level sketch at a very high level. Let me quickly argue why this is a good protocol.
00:21:37.076 - 00:22:26.360, Speaker A: Completeness is if f was low degree, then I already told you what the prover should write. The fi should be the true algebraic sketches, and everything will just work. The soundness is suppose f is far from low degree, then you want to show that the protocol rejects with good probability. This comes from the Farness preservation. Why is that? In a very high level and basically wrong, proof is there are two cases. Every fi plus one is close to the algebraic sketch of fi bi. If you wrote down each f I plus one as the honest algebraic sketch of the previous one, then the very last ft, then we got Farness preservation, right? So the f I plus one is basically equal to the algebraic sketch of f I and bi.
00:22:26.360 - 00:23:06.250, Speaker A: So if f zero started far from low degree polynomials, then f one is far from low degree polynomials, f two is far from low degree polynomials, and so on. And ft will be far from low degree polynomials, and then we will catch it. Then we will see that we are far from ft will be far from constant, which is what we are hoping it's supposed to be. So the verifier will catch it at the end. Case two is one of the fi plus ones is far from the algebraic sketch of fi and bi. So at one of those t stages, you lied, in which case the local check between fi and fi plus one will catch that. So this is at some very high level why this protocol should be sound.
00:23:06.250 - 00:23:30.784, Speaker A: Okay. And everything ultimately depends on the farness preservation. So the theorem about the soundness of. Fry. So it was in long sequence of works, each one improving on the previous. So Dan will be talking about a lot of these things that if f is delta far from low degree. Where degrees d is rho n.
00:23:30.784 - 00:23:51.140, Speaker A: Then, no matter what the prover does. The fry protocol rejects with probability, at least. Well, if you ignore this briefly, it's delta. And this is reasonable. If rho is small, then one minus rho to the half is one minus small. Which is basically one. And the min value will be delta.
00:23:51.140 - 00:24:15.580, Speaker A: Okay? But this factor is something which we hope should not be there. So, potentially, this result can be replaced with a delta over there. Which would then give you the optimal analysis of Fry. But we don't know this. And Dan will talk a lot about this in the next talk. And this is theorem about the soundness of Fry. Functions which are delta far get rejected with probability, basically, delta.
00:24:15.580 - 00:24:38.844, Speaker A: Okay, so now I'll quickly go through and tell you a few things about deep fry. How much time do I have? 5 minutes. Oh, good. Okay, so this is good. So deep Fry is a variant of Fry. Before one of these papers, it had more advantages. Now it has a few less advantages.
00:24:38.844 - 00:25:01.770, Speaker A: But this is a significant at least. There's a good qualitative aspect to it. Deep fry is a protocol that does more. It asks more from the prover. And it has a soundness that is slightly different from what happens with Fry. What it does, it asks the prover to give some evaluations of the function f. From outside the domain D.
00:25:01.770 - 00:25:21.150, Speaker A: So f is supposed to be a univariate polynomial. If it is a univariate polynomial. Then we can talk about evaluations outside the domain D. So we can ask for that. And that's what we do. So if it's truly a low degree polynomial. The prover can answer values outside.
00:25:21.150 - 00:25:51.316, Speaker A: And otherwise, if f is not a low degree polynomial. A cheating prover can make some values up. And pretend that they are the evaluations of this polynomial outside. But the verifier has no way of checking what a value is outside the domain. Okay, good. So this is the setting for deep fry. But there is a way of taking advantage of what if the prover claims some values of a polynomial outside the domain.
00:25:51.316 - 00:26:11.224, Speaker A: There's a way of taking that into account. This is the quotienting trick that I mentioned earlier. This is taking the function. If it claims that f of a equals b. Then f of x minus b divided by x minus a. Should be a low degree polynomial. And in this way, you can incorporate any additional knowledge.
00:26:11.224 - 00:26:28.324, Speaker A: That the prover gives you. About the function f. Into your treatment of f. And this gives you the protocol, deep fry. So I will just give you in high level what the protocol is, we start with the function f zero. In round I, we do the following. It looks a lot like fry, but this is the different part.
00:26:28.324 - 00:27:04.784, Speaker A: The verifier picks a random zi in fq somewhere from outside the domain. The prover gives you claimed values of f I of z I and f I of minus zi. And this gets incorporated into f. How do you incorporate it? By taking this quotienting trick. So, these claimed values say something about the function f mod x minus z I times x minus x minus of minus z I, which is x plus z I. And taking these values into account, you get a lower degree polynomial. Having incorporated this.
00:27:04.784 - 00:27:38.228, Speaker A: Then you run the algebraic sketch on that. And this is how the deep fry protocol works. So, it takes some additional information from the prover. And the query phase is exactly the same as before. And the crux of the deepfried protocol is that it has potentially better soundness, or it has better soundness based on a well known conjecture. So, error correcting codes. Amongst them, Reed Solomon codes, are these low degree polynomial codes.
00:27:38.228 - 00:28:06.820, Speaker A: That's the r in Solomon. So there's a conjecture called the optimalistic quotability of Reed Solomon codes. I will tell you what it is in a second. And assuming that deep fry has the optimal soundness delta without the min with the one minus square root rho, then min with the one minus square root row does cause a lot of problems. So this is a good theorem to have. I was just saying, one slide. What list equotability is actually just one picture.
00:28:06.820 - 00:28:39.484, Speaker A: All those red dots are an error correcting code. That's the Reed Solomon code. And when you draw a ball of some radius inside that, how many code words might you see? The radius of the ball. The maximum radius you can take while still being sure that every ball has very few code words, is the listic coding radius of read solvent codes. And there's a conjecture about this. So, this is a very basic question about polynomials and zeros and their combinatorics. And assuming that read solvent codes behave as well as all codes, which is.
00:28:39.484 - 00:29:19.464, Speaker A: I don't know if it's widely believed, but it's at least very intensely studied and conceivable it gives you a better soundness analysis for deep fry. Okay, now, in one slide, I'll just tell you what ec fry is or two slides. Sorry. So the fry protocol that I gave you required this multiplicative group of size two to the t, right? We needed the two to the t at roots of unity so that we could do this FFT transformation. So something special had to happen. We had a multiplicative subgroup of size two to the t. There's also a way of defining fry when you have an additive subgroup of size two to the t.
00:29:19.464 - 00:29:50.996, Speaker A: So when you're working in a field of characteristic two, then there are many additive subgroups of size two to the t. And you can again define fry in place of the x square map. You can use some other map, another two to one map that does something respects the additive group structure. But not every field has a multiplicative group of size two to the t. I mean, for a multiplicative subgroup of size two to the t, your prime must be such that p minus one is divisible by two to the t. That's some number, theoretically special thing. For an additive subgroup, it has to be characteristic two.
00:29:50.996 - 00:30:34.604, Speaker A: So not every field has this. And sometimes we would like to choose the field, because if you're, for example, setting up a stock for some crypto construction, that someone else chose the field for that crypto construction, that field may not be friendly, that may not have a multiplicative subgroup of size to the t. And it may make sense to try to do your stark proof over a field where that construction was defined. So it would be nice to have a fry over every field. And that's what ecfry is. It's based on the ecfffT. EC stands for elliptic curve FFT is FFT good? It's a new FFT based on elliptic curve groups in place of multiplicative groups and additive groups.
00:30:34.604 - 00:31:08.972, Speaker A: It's based on elliptic curve groups. And what's the advantage of elliptic curve groups? The advantage is that every field has them, and every field has many of them. And it has not just many of them. You get all kinds of them. So every finite field has an elliptic curve with a subgroup of size two to the t. Every finite field has only one multiplicative group and only one additive subgroup, but multiplicative group and additive group. But it has many, many elliptic curves on it, and one of them, and many of them, in fact, have subgroups of size two to the t.
00:31:08.972 - 00:31:48.330, Speaker A: So we can maybe use this subgroup to create to do fry okay. And miraculously, one can. So it's not a priority. Maybe intuitive, that things that you do with an elliptic curve over Fq should have any consequences for polynomials. It may have consequences for functions on the elliptic curve, but why should have any consequences for polynomials? But it does so using this in a sequence of two papers with Dan Carmo and Ellie and David Levitt we had defined an FFT for all finite fields. It's just an FFT in quotes because it doesn't compute anything Fourier. It's just an FfT like algorithm that can help you do things about classical problems.
00:31:48.330 - 00:32:21.008, Speaker A: You needed a subgroup of big size. The two to the t was the same as the number of rounds in the fry protocol where we kept halving. So we took n equals two to the t, and we had the n through roots of unity. So that's the t. Great. So the first result is that there's an ffto of finite fields. It enables fast algebra over finite fields.
00:32:21.008 - 00:32:44.030, Speaker A: And the second is that based on this, we can get fry for all finite fields and starks for all finite fields. And it implements the exact same air language that one is used to over any finite field, which was previously only possible over fields with special subgroups. You now get it overall, and. But this requires a pre computation of an elliptical. Okay, great. So. And now I'm really done.
00:32:44.030 - 00:32:46.350, Speaker A: Thanks.

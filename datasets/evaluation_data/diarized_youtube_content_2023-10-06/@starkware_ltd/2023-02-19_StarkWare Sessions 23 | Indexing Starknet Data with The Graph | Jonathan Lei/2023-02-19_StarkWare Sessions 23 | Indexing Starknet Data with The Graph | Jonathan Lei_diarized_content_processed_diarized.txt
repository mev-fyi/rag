00:00:03.370 - 00:00:17.360, Speaker A: So good afternoon everyone. Welcome to my talk about indexing startnet data with the graph. I'm Jonathan, the co founder and CTO of Zklan, a lending protocol on.
00:00:20.130 - 00:00:20.880, Speaker B: Okay.
00:00:21.810 - 00:00:56.062, Speaker A: So before we dive into the topic, it's a little bit more about myself. This is my GitHub profile, and I actually built and maintained starnet Rs, which is the Rust SDK for starnet. It's used by a lot of projects in the ecosystem, including the ones from startware itself. This one is like less known, but I also built starlight, which is CLI to written in rospool. You can curate data, you can deploy and actually interact with your contract and stuff like that.
00:00:56.196 - 00:00:57.678, Speaker B: And the next one is what we.
00:00:57.684 - 00:01:19.254, Speaker A: Are going to talk about today, which is graph. Our graph. No fault. And here's also my email address, so you can actually drop me a message if you have any question, or if you just want to say hi. Before we actually look into the graph, let's take a step back and see why is it difficult to index blockchain data?
00:01:19.452 - 00:01:23.302, Speaker B: And so there are a few challenges. The first one being you have to.
00:01:23.436 - 00:01:25.554, Speaker A: Actually handle the chain reoccurs in blockchain.
00:01:25.602 - 00:01:29.738, Speaker B: Blocks get reverted all the time. Thank you.
00:01:29.904 - 00:01:30.790, Speaker A: Blockchain.
00:01:30.950 - 00:01:59.502, Speaker B: Yeah. Okay, it works now. Okay, so blocks get reverted all the time. So if your index doesn't handle block reverse, it's essentially useless because it happens so often. Even with the centralized sequencer right now, we're still having sometimes like one to two blocks of reverse. It's not rocket science, but to handle it correctly and efficiently is kind of tricky. And the second one is limited programmability.
00:01:59.502 - 00:02:41.390, Speaker B: So imagine actually hard coding your indexing logic and Q reserving logic alongside your actual indexer. You will have to actually recompile the whole thing and redeploy the whole server every single time you change your indexing logic. And good luck trying to work around that issue with a dynamic, interpreted language, because you are going to get performance issues and it's not going to scale well. And last but not least, you also have this. Now you have an indexer server. You will have essentially new infrastructure to manage, and that creates a single point of failure. I believe most of us here don't really like having to manage our own servers.
00:02:41.390 - 00:03:25.610, Speaker B: It goes against the decentralized thing. So here's how the graph actually solves this problem. For those who are not familiar with the graph, here's how it actually works. So on the right hand side, we have users interacting with your dapp, and that's essentially sending transactions into the smart contract which will be emitting events. And this events will go into a graph node that's running and listening for the events. Once it receives an event, it will actually look for the corresponding event handler inside the indexing logic. And if it finds one, it will simply invoke and send the event to the indexing logic to get it to actually perform indexing.
00:03:25.610 - 00:04:23.066, Speaker B: And how it does it is that it has a set of APIs provided by the graph node runtime that allows the mapping logic to interact with the database. And on the other side you also have this. The app will obviously also be querying the data from the graph node. It does so via the GraphQL API, meaning that you can actually query what data you want instead of actually getting a fixed set of restful APIs. The way the graph actually resolves the problem of the challenges is basically that it actually uses a very generic and performant wasm runtime to handle the indexing logic. So instead of asking you to write it in any other language that's hard coded inside the indexer, you can actually use any language that gets compiled to webassembly. And with that you can code any logic you want inside of the indexing part.
00:04:23.066 - 00:04:55.978, Speaker B: And for the QE part you actually get graphql. So you can set up your own schema in a very flexible way. Well, it all works well, except one problem. It doesn't work with Starnet. And that's what us Zklan team has done here. We fog a bunch of ripples and make changes to make sure the graph node works. With what this is a diagram of our fog, and it's essentially the same thing as the previous one, except a few difference.
00:04:55.978 - 00:05:31.122, Speaker B: So you also have the user interacting with your smart contract here. And the smart contract will also be emitting events. And now a pathfinder will be picking up the events. But we have to use a fork here because we need the pathfinder node to speak a protocol called firehose. The firehose protocol is basically a message queue protocol that allows you to stream your event data over a GRPC connection. And now the event data actually goes into the graph node. We also have to obviously have to fork the graph node because we also need the graph node to understand the Stanley specific firehose protocol.
00:05:31.122 - 00:06:14.622, Speaker B: And the rest of the diagram is actually the same as before. You also have the indexing of the subgraph, you also have the database, and you also have the browser actually queuing data from the subgraph using graphQl. And I know this all can get a little bit abstract for those who are not very familiar with the graph. So here is a concrete example. So here we'll build a simple subgraph that basically just tries to find out who are transferring the most. It just tries to find out the number of transfers that's being sent from any address for a specific ERC 20 token. It isn't very useful, but it's meant to actually demonstrate what can be done with a subgraph.
00:06:14.622 - 00:07:02.542, Speaker B: So on the left hand side we actually have a graphql defined schema. So we are defining a single entity called transfer counter. It has the sender address as the primary key as id here, and it has the number of transfers recorded as count. And we also track the last time stamp of the last transfer. And on the right hand side we have a mapping. It's actually quite simple, it's assembly script and it's a subset of the typescript language that can be compiled to webassembly. And here we first load the transfer counter entity from the database, and if it doesn't exist we create a new one with a count of one, and if it does exist we simply increment it and then we also update timestamp and we persist the entity back into the database.
00:07:02.542 - 00:07:35.642, Speaker B: As simple as that. But do know that we are actually able to use something like event params from here. So you're not actually dealing with the raw event data. You don't need to be like event keys, event data and index access. There's nothing like that because there are types automatically generated for the events and for the course for everything that you can index. So you can actually do this, the code is going to be very maintainable and readable. And then once you compile this, deploy this, and then you can start using the subgraph.
00:07:35.642 - 00:08:49.250, Speaker B: Here's an example QE of such a subgraph and as we can see, we are able to actually apply custom sorting and filter logic. So we are actually asking the subgraph, hey, what are the top four senders of this specific token? And once we actually send this, I'm pretty sure you guys cannot see this, but this is an example response that comes with four transfer counter entities. So this is how a real subgraph actually works. And as you can see, the whole process, if you are familiar with the graph, as you can see, this is basically the same experience as the ethereum subgraphs because we have actually beyond the effort we just show on forking those node projects. We also fork the CLI and the supporting projects to make sure the whole experience is seamless and easy to use. However, it's actually not done yet. Today you can already start using it to index blocks index events, but actually for contracts that don't emit events you would need to index internal calls because starter is l two network.
00:08:49.250 - 00:09:43.720, Speaker B: You will also want to be indexing l one to l two messages, and these are not done yet but will be implemented in the future. And despite that, you can actually already start indexing. Today there's a quick start report that we've prepared that contains detailed step by step instruction on setting up the infrastructure. You can actually do a simple docker compose and you get everything up and running and you can install the fog two chain to actually start creating, compiling and using the stockness of graphs. And do know that there's one minor issue. We haven't actually updated this to reflect our latest changes, so this Chris Starguide will still be saying that it can only index blocks, but we'll updating that soon so there wouldn't be an issue. That's pretty much it from me and I will be taking any questions.
00:09:43.720 - 00:09:47.960, Speaker B: Thank you.

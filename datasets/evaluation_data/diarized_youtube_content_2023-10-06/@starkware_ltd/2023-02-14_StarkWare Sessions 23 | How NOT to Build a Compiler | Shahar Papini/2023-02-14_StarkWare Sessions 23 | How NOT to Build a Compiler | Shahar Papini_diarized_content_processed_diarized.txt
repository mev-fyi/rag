00:00:03.290 - 00:00:36.642, Speaker A: I'm Shakal Papini from Stalquel. I work on the compilers team and worked on Cairo. And I'm here to talk to you today about how not to build a compiler. The story of Bob. This story is based on true events, but all names, the characters, the incidents, everything is fictitious, so don't worry about shaming anyone. This is Bob. Bob wants to build a compiler for the Bob language.
00:00:36.642 - 00:01:10.462, Speaker A: This is an example for the Bob language, has a bub funk called Robert gets Bub object, etc. Bob grabs his favorite Dragon book, which is a classic compiler's book. In it it says that the compiler is a program composed of three parts. First part is a parser. This one reads source code and outputs syntax tree. Another one is a type checker. It goes over the syntax.
00:01:10.462 - 00:01:37.910, Speaker A: It checks all the types, adds type information onto the syntax. And third part is an emitter. It's a part that takes the tree and its semantic information and emits machine code. In the end, Bob built it and he was happy it worked. Nice compiler for the Bob language. Bob starts to write some code. Bob gets an error.
00:01:37.910 - 00:01:58.546, Speaker A: Missing semicolon on line two. He has semicolon in his language. All right, he fixes the error. He adds this semicolon, then he gets another error. Missing semicolon on line three. Bob is a bit frustrated. He doesn't want to fix every error one at a time, then gets the next one.
00:01:58.546 - 00:02:47.700, Speaker A: He wants all the errors at the same time. Okay, so Bob here is a good solution for this is to make an infallible parser. What does it mean instead of making maybe a classic parser, that whenever he has some syntax error fails and just bails out, he builds a parser that never fails. Instead of failing, the parser tries to recover from its own errors. It always returns a syntax tree. The syntax tree might be partial, might be missing some nodes at the middle, but also always brings some syntax tree along this partial syntax tree. He brings some accumulated syntax errors as it goes.
00:02:47.700 - 00:03:20.010, Speaker A: All right, so here's an example for this code we saw at the beginning. The syntax tree might look like this. It might have a function. Inside this function he has statements like call and call. Inside this call node he has the name of the function, the parameters list, and a node that was supposed to be semicolons is now just missing semicolon. So it's a partial syntax tree. It has a missing node.
00:03:20.010 - 00:03:46.930, Speaker A: All right, he does it. Bob now gets all the syntax error right away. And Bob was happy, has nice compiler. Bob starts to write some new code. He types this code starts to write Bobby B. And Bob forgets the name of his function. Oh no, Bob has no autocomplete.
00:03:46.930 - 00:04:32.826, Speaker A: Bobby sad. Bob wants autocomplete. All right, so Bob decides to add some IDE integration. IdE integration is the thing that highlights your code in your IDE does the autocomplete has got definition. All these nice features when you are developing in your code. So you get all these features from the IDE integration. And modern ides actually use a language server protocol, which is kind of a unified protocol for compilers to give access to ides to all kinds of features.
00:04:32.826 - 00:05:09.200, Speaker A: So Bob decides to write a language server for the Bob language that will also support autocomplete. All right, Bob writes a language server like a same person. He decides to reuse his compiler code. One of the things that have been done a lot in the past is rewriting all the, parsing all kinds of semantic information for the language server. But it doesn't make any sense. So he decides to share his code and refactor this compiler. His compiler is now no longer a single program.
00:05:09.200 - 00:05:48.566, Speaker A: Instead it's an API library that exposes all kinds of API regarding syntax and type info for his program. All right, he did it and it works. He can get all kinds of completions, nice completions for his Bobby object. And he was happy. Bob writes a lot of code in Bob language. Every time he autocompletes, all projects is type checked. Every time he processes this little tab for autocomplete, he needs to wait a few minutes because everything needs to get type checked.
00:05:48.566 - 00:06:16.198, Speaker A: That is how it was written at the beginning. Bob is sad. It's too much time. All right, Bob decides to use a query system. What does it mean? Usually when you type in the ide and start developing, code changes are very local. So most of the type information, the syntax information, most of this still is still relevant. It still doesn't really change.
00:06:16.198 - 00:07:03.762, Speaker A: Just a very small part of your program is changing. So we want a way to only recompute the things we need and to cache the things that don't change. This is where query system comes in. Basically bob takes compiler and breaks it into a lot of small query functions. Let's call each other, we cache these results, and when we have some small change or any change, the query system is responsible for updating exactly what we need. And let's see some example. Let's say this is how we break the compiler code example function.
00:07:03.762 - 00:07:52.494, Speaker A: Say we have this get function, semantic info. It gets a function and returns all the type info inside this function, what it returns, it gets. This one depends on the get function syntax, which for every function returns the syntax tree. And this function, get function syntax actually depends on get file syntax, which is a function that gets the syntax tree of the entire file. So this query calls this query, this calls this query. All right, what happens when bob adds some code? Right after this function, the get file syntax needs to be computed. Why? Because it depends on the file content, and the file content was changed.
00:07:52.494 - 00:08:24.874, Speaker A: So get file syntax is invalidated and needs to be recomputed. So it gets recomputed. Next one is get function syntax. The file syntax was changed, so the input to this function is changed, so it needs to get recomputed. But the return value of get function syntax actually returns the same as the previous value. So basically the output of get function syntax is essentially unchanged. Even though it was recomputed, the value it gave is unchanged.
00:08:24.874 - 00:09:09.850, Speaker A: So this is where the query system comes in and knows this function doesn't need to get recomputed because this input is exactly the same input. So this is how a query system works. And this keeps all the computation to only what we need and for other parts of the code that are not changed and don't need to be recomputed to use the cached values. All right, Bob's language server is a lot faster now. There's still some room for improvement, still not as smooth as it can be. So he looks again. Bob's code is somewhat inefficient when he needs to refer to language items inside his code, he uses pointers.
00:09:09.850 - 00:10:05.790, Speaker A: For example, when there's some Bob call statement which calls function, the representation inside his code has some pointer to the call e function. His expressions have a pointer to their type. Struct the keys for the queries. You just saw these small functions that call each other. The keys are also pointer. For example, the get function syntax, it got a pointer. And what does this mean? This means that when we need to compare such pointers, for example, if I want to understand if two types are equal, I need to do something recursive to dive into the values and decide are both structs is the first field of the same value, et cetera.
00:10:05.790 - 00:10:44.118, Speaker A: Or if the same function also I need to dive in to understand if it's the same thing. Also, when I hush, I need to hash them. If there are, for example, query keys, like I said, queries, we are caching caching queries by the input. So if the input is some pointing to a function, we need to compute this hash for this entire function, which also is recursive. Looks at all the fields. It might be expensive. Okay, so instead of using pointers to type, to function, to whatever, Bob decides to intern his values.
00:10:44.118 - 00:11:28.940, Speaker A: What does interning mean? It means he keeps a table of all the type instances he has seen. When he needs to refer to some type, he first looks it up in table searches. If it already exists. If it does exist, then he uses the index of the existing type to be used as a type id. If it doesn't exist, he allocates a new type on this big table and uses this as a type id. So basically now instead of using pointer to types, he uses this type id with the property. Also, the type id is very small, just an index, and it provides the identity of this type.
00:11:28.940 - 00:12:04.482, Speaker A: If we have two different type ids, they are definitely not the same type because we used interning. So this is like the identities he now uses for everything, not just types. He has function id, he has truck id, anything. And now comparisons and hashes are very fast. So Bob's language service is really fast now and he is happy. Bob now tries to build an analyzer for the Bob language. For some reason, he wants to have exactly 303 bub variables in his code.
00:12:04.482 - 00:12:30.858, Speaker A: I don't know why he builds an analyzer that traverses the syntax tree. His analyzers needs to handle all the kinds of syntax nodes he can see. Bob ifs, Bob fours, Bob latz, Bob jumps everything. And that's a lot of code, a lot of maintain a lot of complexity. Bob doesn't like it. Bob is sad. Bob adds a compiler phase to make it simpler.
00:12:30.858 - 00:13:35.890, Speaker A: What this compiler phase does is reducing the big Bob language into the simple Bob language. The transformation is taking things like Bob ifs and converting them to Bob jumps. Also, Bob fours are converted to Bob jumps. And instead of a lot of syntax nodes that are relevant for the high level language, simple bub is using very simple constructs, as little construct as possible to still stay expressive, but we want it to be as simple as possible. And after this translation to simple Bob, then only then simple bub gets translated to the Bob machine code with Bob instructions. So instead of going straight from the Bob language to machine code, he goes through the simple Bob language in the middle. The benefit he gets from it is now that his analyzer only needs to go through the simple Bob language.
00:13:35.890 - 00:14:11.066, Speaker A: And now instead of handling Bob ifs and Bob Forrest and Bob lets, the analyzer only needs to handle Bob lat. So it's a lot less code and it's easier to write. And he is happy. He's very happy. What about errors? Bob wrote a code with a mistake. He tries to use the Alice method in mean, who is Alice? I know Alice. Alice not found quickly, before anyone sees.
00:14:11.066 - 00:14:58.934, Speaker A: He tries to get autocompletions, but fails. The mistake he made actually made the type checking phase completely fail on this function. Again, the original design was as a single program, and type checking was allowed to bail if he had any error. But that also means that even we have some semantic mistakes in our code, then we get no semantic information for this function whatsoever. So Bob decides to refactor his typechecker. Now, when he has semantic errors, instead of just bailing, they try to corrupt as little information as possible. They don't fail the computation.
00:14:58.934 - 00:15:24.420, Speaker A: The computation still succeeds. You still get some partial semantic information. With as much semantic information as possible, type errors are propagated. It's kind of similar to what we did for the syntax. Okay, now Bob does it. It works. Bob quickly fixes the error before anyone notices and calls the bob method on its object, like it should be.
00:15:24.420 - 00:16:10.130, Speaker A: All right. Bob was happy, but who knows what kind of adventures lay ahead, what kind of bugs he will meet in efficiencies. Only time will tell. Okay, so this nice story was inspired somewhat, but by our efforts to write two compilers. We wrote the car zero, which wasn't planned at the beginning as a high level language. Instead, it was kind of assembly that we added and added and added to higher and higher features, but we didn't have this planning from day one. A lot of issues we encountered kind of resemble bobs.
00:16:10.130 - 00:16:48.960, Speaker A: Carl one was planned a lot better from scratch with high level compilation in mind, with model compilation, design with language server. So it encompasses a lot of things we learned from our journey. All right, any questions? I don't know. Microphone is on the way. Yeah.
00:16:55.070 - 00:17:09.746, Speaker B: Thank you. So, some parts of this journey resemble pitfalls and problems that the rust language also had. Is that a common experience with many languages, or is that something that you.
00:17:09.768 - 00:17:12.146, Speaker A: Shared specifically with rust because of the.
00:17:12.168 - 00:17:15.038, Speaker B: Common origins and orientation?
00:17:15.214 - 00:17:56.890, Speaker A: It's a good question. Like I said, a lot of languages don't really use modern compilation ideas in mind. And you can see it also, in fact, that they have separate language servers that are using different implementations. Now, a lot of modern things like C sharp compiler was really one of the groundbreaking, I think, that used a lot of these ideas, and this is, I think, one of the origins of these ideas. Kotlin compiler also uses similar things. Rust analyzer uses similar things. So not everything, but some things that are not necessarily rust.
00:17:56.890 - 00:18:10.120, Speaker A: Also this. Okay, thank you very much. Close.

00:00:00.490 - 00:00:21.678, Speaker A: Yeah. So I'm going to do that. And if I understand correctly, I'm going to speak around like 45 minutes or 50 minutes. We'll have a few minutes break and then another session of 45 minutes or so. Yeah, that's right. Okay. And just all those listening, I'd be very happy to receive and answer questions.
00:00:21.678 - 00:01:05.982, Speaker A: So I don't know what is the best way for me to see the questions, but please do ask questions. Okay, so a little bit about myself. I am one of the co founders of Starquare. I serve as the president there. And I'm a co inventor of the mathematical protocol of ZK Stark. Some of the core protocols used there, things like fry and deep fry, which a lot of this research I did with many of my co authors, many of them are at Starkware. And I want to tell you a little bit about the math behind Starks.
00:01:05.982 - 00:01:48.830, Speaker A: And the first session is going to be about what Starks deliver and a little bit of the taste of the math inside them. The second one, the second talk will be a little bit more deeper. Dive into the math. We don't need to assume much. Basically, we're going to assume that, you know what addition and multiplication modulu a prime, mean, meaning you take remainder from a prime. So if I'm adding two numbers, Modulus 17, I add them up as the numbers, and then I take the remainder from 17, and same thing with multiplication. So.
00:01:48.830 - 00:02:48.640, Speaker A: So what Starcore delivers and what Starks deliver is integrity. And integrity means doing the right thing, even when no one is watching. If you think about blockchain or a computation, or computation on a blockchain, this computation carries a lot of value, economic value or other value to its users. If you think about, let's say, the Uniswap protocol, it's a computer program, but people use it to convert funds and do market making. And we really needed to be operating with integrity, even when no one is watching. So what we're talking about is delivering integrity by using math. And this field of research, the way to do it, the way to reach integrity, or better forms of integrity using math.
00:02:48.640 - 00:03:52.420, Speaker A: This research started almost 40 years ago, around 1985, and a little bit later. And one of the goals that was articulated very well in this paper from 1992 by four brilliant mathematicians and theoretical computer scientists. I'm giving a quote of it. They found a way in which a single reliable pc can monitor the operation of a herd of supercomputers with powerful but unreliable software and untested hardware. So they said, we have a way to empower a very weak computer to monitor the operation and the integrity of a much larger amount of computation without needing to re execute that computation, and with no trust assumptions about the software or the hardware of this supercomputer. And essentially that's what we're implementing. So let's make it very concrete.
00:03:52.420 - 00:04:41.092, Speaker A: The thing we want to know that happened with integrity can be captured by a claim about computation. And here's an example of a claim. This is the kind of claim that startnet basically proves with every update to l one. The claim says, if you start your system at a state whose hash is the number x, well, I've seen 1 million transactions, and I processed all of them with a certain program p. This program could be the Starknet operating system, or it could be some other system of your choice. And I'm claiming that I reached a new state for the whole system. Why? So what we would like to do, as observers of such claim, we would like to know that the right thing was done.
00:04:41.092 - 00:05:51.204, Speaker A: Even if we're not watching, even if we didn't see and process all of those 1 million transactions, we would still like to know that the right thing was done and why is actually the correct state of the system. Okay, so we're in the business of verifying that such claims, when they are made, capture statements or computations that have been done with integrity. And what the math says via it shows that you can do apply a sequence of algorithms that can, in computer science language, it's called a reduction. And you can take your claim and sort of like, play with it like we often do with math, and convert it to other claims and other structures. And your end state is a very interesting thing. You end with something that looks like a Sudoku like puzzle, like this picture here that has a few numbers filled in, but mostly it's blanks. And the few numbers filled in are determined by the parameters of your statement.
00:05:51.204 - 00:06:16.392, Speaker A: So in our case, that's the hash of the beginning state x. It's the hash of the end state. Y. It's the program p that you use to process, and the number of transactions. Once you fix those four, you get Sudoku like puzzle. If you change the parameters, you'll get slightly different numbers in slightly different locations. And this kind of reduction was initially called a PCP.
00:06:16.392 - 00:06:58.640, Speaker A: It stands for probabilistically checkable proof, and it's a very fabulous construction in theoretical computer science. Okay, so we massaged and molded our claim and turned it into a puzzle. And now we're going to be asking the person who's making this claim to convince us that it's true. So how is she supposed to convince us? Well, she's supposed to solve the puzzle, and she is called approver. So she's supposed to submit a solution to fill in the numbers. That's the red part. And then we need to check whether the solution is correct.
00:06:58.640 - 00:07:55.436, Speaker A: And we're going to check the solution, and if we're satisfied, we are going to accept the claim. So think of this as some sort of form of receipt for the claim being made. And the interesting thing is, how do we go about checking it? Now, you would think that we would check all entries and make sure that this is a perfect solution. But the surprising thing is that you can actually do this very, very efficiently by lazily randomly sampling, like one constraint. And that's what the verifier does to verify whether we're satisfied with the claim. We're going to just sample one random constraint out of a very large number of constraints, very large number of them, and just inspect that one constraint and see whether this particular row has been filled correctly. So this is the process by which we're going to be using math in order to check claims of integrity about computation.
00:07:55.436 - 00:09:05.880, Speaker A: And there is magic here. So there are three aspects to this magic, and it gets better and better. The first one is that when the verifier is attempting to verify this proof, not only does she not need to read the whole proof, she doesn't need even to create this table in her head. There is a very efficient way for the verifier to toss a few coins and hone in on the entries she needs to read, read those entries, and then already know very quickly whether those entries satisfy the constraint that is associated with that row. So there's a very efficient process that completely circumvents the need to compute 1 million transactions. You just sample something quickly, you go to that row and you read the numbers, and it's pretty much as fast as just reaching those addresses in memory. You just specify the locations, and you don't need to do something that is as involved as processing the 1 million transactions.
00:09:05.880 - 00:11:01.020, Speaker A: The second amazing thing is that if the prover is attempting to prove a correct statement, meaning it is really the case that if you start from state hash x, there are 1 million transactions, and those were known to the prover, so that if you process them with a program p, you will reach a state whose hash is y. In that case, you can take those 1 million transactions and you can use them to craft a solution that satisfies all of the constraints, which means that when the verifier comes and samples a constraint, you very quickly gain confidence that it's all correct, like all checks that you make will make you happy if you're the verifier. And the most amazing part, and the part that also requires the deepest level of math and ingenuity, is the last bullet, which says that if the claim is incorrect, meaning you cannot reach the statewide where. There's also a version where maybe you can reach the statewide, but the proofer actually doesn't know of 1 million transactions that would lead you to the statewide. Well, in that case, no matter how you try to fill in the missing entries with numbers, you will not be able to satisfy more than 1% of the constraints. Which means that when the verifier samples and checks a single constraint, there's at most a one in 100 chance that the verifier is happy, even though the claim is false. And if you repeat this three times and you inspect three random constraints, there's only a one in a million chance that you are fooled to believe that the claim is correct, even though it's incorrect.
00:11:01.020 - 00:12:29.320, Speaker A: So you can very quickly sample and pull the integrity of this computation and work sufficiently well. So this is the technique, the amazing technique that was discovered in the by mathematicians that allows you to do a very fast verification of the integrity of computations. And the start protocol is a twist on the PCP. What it does is that instead of having the prover submit one solution and then leave the room, there is a very brief interaction between the prover first submits a solution, then the verifier presents a new soducco challenge to the prover, and the prover needs to fill that as well. And it happens three or four times, and at the very end, we check all of them together. So there is like a several round game in which puzzles are presented and need to be filled. But the basic attributes, the basic magic that says that you can sample a constraint very efficiently, that good claims can be proved as to satisfy all constraints in this new three dimensional sudoko, and most importantly, that false statements satisfy at most 1% of the constraints these things hold also with respect to a stark.
00:12:29.320 - 00:13:30.264, Speaker A: And that's how our system actually works. So I can summarize a lot of my research and also all of the work of startware as just removing two letters from the slide on the left. So we made something that was impractical through a lot of math in Junutu. We made it more practical, and after that, we also made it accessible. So Cairo and Starknet are a way to make this map and its power accessible to everyone, so that we have blockchains that are far more scalable and also can scale at different levels. And you can have parties running layer threes and their own secluded systems, and then also proving to the blockchain, so proving to all that they operated with integrity. So there was one phase of mathematical creation in which we came up with protocols that are more efficient.
00:13:30.264 - 00:14:03.368, Speaker A: And then there was another phase of engineering creation and creativity that led to things like Starknet, Cairo, Cairo, one, Sierra. And they're all about making this beautiful math, this beautiful and powerful math accessible to developers, sort of abstracting away almost all of the math and making it just something that you can use. So this is all about math. I also want to talk about blockchains, because darknet is something that works on a blockchain. So you could ask where.
00:14:03.454 - 00:14:40.068, Speaker B: I can ask a small question here, Ellie. This is great. It's great to have this put in context. And I remember, and I think a lot of people have this realization also that provable code is bigger than blockchain. Blockchain is one application of provable code. And I'm curious, I often joke that the only industry where people are paranoid enough to want to work with each other without trusting each other is the blockchain industry. But have you seen other interest, other areas of interest where having provable code has generated interest or.
00:14:40.068 - 00:14:47.830, Speaker B: So far? The world of distributed computation relies on trust, and it works pretty well that way.
00:14:48.600 - 00:15:50.120, Speaker A: Yeah. So that's a terrific question. So there's a lot of academic work and theoretical work on other settings in which you would really want proofs. You want to know them for authenticity of images, you want them for knowing that the government is operating with integrity. When it, say, samples, when the IRS, when the tax service samples individuals for tax audits, you want them in the world of banking and finances with respect to individual customers, you want them to prove solvency. There are many settings in which you could want them, but the reality is that practically in business wise today, the world solves such problems by other means, by using trust, relying on trust. So even though we all aspire to a world in which we use the higher level of integrity offered by mass, and you don't need to rely on human integrity.
00:15:50.120 - 00:17:19.892, Speaker A: Practically speaking, only blockchains care enough about it to bring it into their products today. So actually this is the next topic of this thing, which is even though in the early ninety s people knew about this thing, where a single reliable pc can monitor the operation of supercomputers. The question now arises, where is the practical setting in which you would want a single reliable pc that works very slow, but you really trust it? Where would you want to have this? Where does it arise naturally? And that's of course given by blockchains, right? Bitcoin is all about peer to peer network with no central points of trust, and you need a lot of math and cryptography in order to make sure that no one is violating integrity. And then Ethereum, on which Starknet operates and scales, allows you to deploy any kind of computation in any smart contract, which is necessary if you want to put verifiers. For instance, if folks are asking why isn't there a stark verifier on bitcoin today, well, the answer is that bitcoin just doesn't allow general computation, and you would need a fork to the bitcoin code in order to have an opcode that allows you to verify a stark. And that's not the case today. But ethereum is a general computation complete or turing complete.
00:17:19.892 - 00:18:21.184, Speaker A: You can put any computation on it. So you can also put a verifier, you can put this single reliable pc, the code of this single reliable pc on the blockchain, and now the blockchain can monitor on your behalf a herd of supercomputers. This realization that blockchain is this single reliable pc is something that I'm proud to say. I was probably the first academic to realize that general purpose computation really goes well hand in hand with blockchain. This realization came to me pretty much exactly ten years ago. It was May 2013, when I attended the blockchain conference in San Jose, that it dawned on me that this is a good match. And this was, I was, at the time working already for ten years, more than ten years, twelve years of research, some of it theoretical, some of it practical, and making such proof systems realizable.
00:18:21.184 - 00:19:08.920, Speaker A: And then in 2013, thank God, I found bitcoin. So the first application of general purpose computation proofs was in zcash. So I was a co founder of Zcash, alongside Alessandro Chiesa, who's also a co founder of Starquare and five other scientists. We wrote a paper that demonstrates how proofs can help you with privacy. And in 2018, Starquare, roughly five years ago, started. And it was the first to argue that proofs of validity of the kind envisioned already in 1992 can be really, really helpful for scaling blockchain. So now I want to give you a little bit of the lay of the land and some other cryptographic proofs.
00:19:08.920 - 00:19:30.480, Speaker A: And this will take the second part of this talk. Then we'll have a break, and after that we're going to dive a little bit deeper into arithmetization and the math of Starks. Maybe I can also pause here and ask if there are any questions so far before we go into this phase.
00:19:33.300 - 00:19:42.550, Speaker C: I don't see any questions right now coming up, but, people, you have a chance now to ask your question either on YouTube or here in the Q A section of the Zoom call.
00:19:44.600 - 00:19:55.030, Speaker B: Wait, there's a big chat in the YouTube thing? Let me check. So Fabio is saying, boss, everyone is on the other link. No, I changed, so I think this is fine.
00:20:01.440 - 00:20:07.580, Speaker A: It doesn't seem like there is a.
00:20:07.650 - 00:20:10.270, Speaker B: Question for now in the chat, so good.
00:20:12.720 - 00:20:57.070, Speaker A: Okay, so can you see my screen? Yeah. Okay. So in September 2019, I first gave the proof, sorry, this talk about the cambrian explosion of cryptographic proofs. And I said, look, here's the list of all the proof systems out there that existed. This was like four years ago or three and a half years ago. And then two months later, I did the talk again, and I had to add like five or six new systems. And of course, by now, there's just such a huge number of proof systems and implementations that I just can't survey all of them.
00:20:57.070 - 00:22:14.980, Speaker A: But what I did do very recently, when I checked stuff, this was a few months ago, I asked around, what are the proof systems that are deployed on blockchain? And this was two months ago. I don't think it changed much. And you'll see a whole bunch of systems, I guess most of them are being deployed on starks, on our kind of technology. There's a bunch that are built on things like halo and bulletproofs, and there's a bunch of others on Marlin Cross 16 and plonk. And what I want to do is show a little bit about what are these about these systems? Are they more about privacy or are they more about scalability? So you can use proofs for zero knowledge to shield things, and you can use proofs also to scale things up so that you can verify very quickly that a large part batch of computation transpired with integrity. And the situation is that most systems out there today use proofs, these cryptographic proofs, for scalability, not for privacy. There are a few, like Zcash and Monero Aztec that use them for privacy, but mostly it's for scale.
00:22:14.980 - 00:22:54.976, Speaker A: And there are like dozens of proof systems. But why are there so few that are deployed on blockchain. So, of course, theory to practice is a process that takes time. Existing systems are good enough for scale, and then you don't replace a winning horse so quickly. There's also this tendency of technology to standardize, right? We've seen this with network protocols, programming languages, et cetera. And also the bottleneck is not so much the proof for the verification efficiency. It's other things, productization, developer tools, integration, programming languages, and so on.
00:22:54.976 - 00:23:33.900, Speaker A: And so, and at least our effort in Starkware and Starknet is more on providing these things like products that developers can actually. Stark. Well, the best you can hope for in cryptographic systems is the combination of these aspects. And we're very happy to say that Starks have all of them. So you want a system that can offer you privacy or zero knowledge. You want something where you have scalability, which is defined to be that proving time is exponentially. Sorry, verification time is exponentially smaller than proving time.
00:23:33.900 - 00:24:16.588, Speaker A: You would want universality, which means you can generate these proofs for any computation, not just for bitcoin transactions, but for any game or any purpose that you want. You would like transparency, which means that it's very safe to set these systems up. In particular, you don't need any elaborate key ceremonies and things like that. And you would like the cryptography you're using and relying on to be very lean and battle hardened, used for decades over many, many different systems. You would like it to be post quantum secure. And the system that delivers this best is start the one on which we built our code. Now, okay, there are a bunch of systems out there, and they are different.
00:24:16.588 - 00:25:04.856, Speaker A: So how are they different? They differ. Well, okay, there are things that are the same. All of them use finite field algebra, meaning additions and multiplications, where you take remainder from a prime. None of them work over the real numbers or the rational numbers, or use elaborate matrices or things like that. All of them use finite fields, which means this addition and multiplication modulo of prime. That's the area of mathematics that they all use. And another thing is that they all rely on the existence of what's called polynomial commitment schemes, which means that there's a way to enforce the prover, to evaluate functions as low degree polynomials.
00:25:04.856 - 00:25:41.504, Speaker A: And we'll get to these aspects, but they differ in a number of things that we'll touch upon soon. So, first of all, what is arithmetization? In the next part of this talk, we'll go very deeply over arithmetization and then do some. We'll play around with it, but very broadly, speaking. Arithmetization is what's called a reduction in computer science. It takes one problem and it converts it into a new problem. So arithmetization takes problems about computational integrity. Like this claim.
00:25:41.504 - 00:26:57.372, Speaker A: Is it the case that the proverb has started from state hash x, performed 1 million transactions, processed them, processed them with integrity and reached the state y? That's what we want to know. And the reduction converts it into a new problem. And that new problem is about the relationship between a bunch of polynomials that should have low degrees. So after the arithmetization, what we have is instead of one claim about have you updated the state of the system correctly? There is a new problem that you want approver to solve, and it is can you please present four polynomials, ABC and D, of low enough degree of degree little d, such that if you plug those polynomials and numbers into the equation in red, the left side equals the right side. So you need to solve some equation about polynomials. And what you need to do is use polynomials to solve that equation. Okay, so we started with a problem that is all about computation.
00:26:57.372 - 00:27:31.630, Speaker A: It's very mundane, it's very much something we understand and like. And we ended up with some very mathy problem that involves low degree polynomials. And this is a very mysterious process, but it's very effective. Now I just want to say that Cairo and starknet, what they do is abstract all of these polynomials away from you. You don't need to know anything about them. The whole system automatically will generate proofs and do these reductions for you. All you have is a very ergonomic and safe programming language in which you write code.
00:27:31.630 - 00:29:05.956, Speaker A: There are some remnants of the fact that there is a finite field beneath. The most prominent example is that the native type of Cairo, at least of Cairo zero, but also Cairo one, is a field element or a felt. The reason you have this native type is because underlying the whole system of Cairo there are polynomials over a finite field and field elements are a very natural creature in this world. But other than that, Cairo basically abstracts away for you all of this beauty or messiness depending on how you think about it, about this math. So the different proof systems out there, they differ in how they exactly arithmetize, how they force the prover to commit an answer according to low degree polynomials and the cryptographic assumptions and primitives that are used in order to get low degreeness. Those are the main factors that differentiate among different systems. And let's do just a quick survey and see give some rewards to systems that operate better or worse according to some things and if we look at the cryptographic assumptions that underlie these systems, so on the left we have systems that only require collision resistant hash.
00:29:05.956 - 00:29:49.060, Speaker A: So as long as shot two or Blake are safe, you can prove that these systems are safe. All of these systems on the left. Okay. The only assumption you need to make is that the world knows of a collision resistant hash. If you do want to make a non interactive version of these systems, what is sometimes called a snark or a transparent snark, then you need more assumptions, the fiat, chameleon, heuristic and other things. But for this, if you're willing to do it interactively, all you need to know is that shot two is safe. It doesn't have a collision.
00:29:49.060 - 00:30:41.384, Speaker A: On the right hand side, the cryptographic assumptions require some more esoteric things, things like elliptic curve cryptography, knowledge of exponent assumptions and so on and so forth. So that's one of the differences. Basically, the post quantum security award goes to the systems on the left, because if you tomorrow have the large scale quantum computer, all the systems on the right get broken, but those on the left do not. So we're going to give the quantum resistance award to the trees, to the systems on the left. Then the way you enforce load agreeness, there's a bunch of different systems. In some of them you use commitment schemes, you use cryptography in order to make the proverb commit something. And then he is asked about what he committed to.
00:30:41.384 - 00:31:11.280, Speaker A: And there's one tree, the one that led to things like Marlin Ross 16 and plonk, in which you need to hide queries to the polynomial in advance. So you're like planting some seeds and hiding them, that these seeds are going to help you find out if someone is lying. And for this you need a trusted setup or a toxic waste process. And this limits your scalability. But that's another differentiating factor.
00:31:12.660 - 00:31:18.690, Speaker C: We have four questions. You want to answer them now? Just wait until you get to the end of this section to answer them.
00:31:19.540 - 00:31:28.836, Speaker A: Your call, because I didn't see them. Do you think if they are relevant to this material, then yeah, let's pause here. If they're more general, then we can get to the end. Yeah.
00:31:28.858 - 00:31:32.340, Speaker C: At least some of them are connected, at least from a previous slide that you showed.
00:31:32.420 - 00:31:35.850, Speaker A: Yeah. So please, whatever is connected. Yeah, very good. So please.
00:31:36.300 - 00:31:49.340, Speaker C: Yes, Pavel is asking on zoom, does halo allow snarks to be set up without trusted setup? Could you tell a bit about how similar and how different are halo and snarks from starks?
00:31:50.640 - 00:32:30.360, Speaker A: Yeah. Okay, here, this is a good slide to look at it. So you can see that Halo and bulletproofs, they sit in a tree that uses commitment schemes. And those commitment schemes do not need you to have a trusted setup. The only tree in this picture in which you need a trusted setup is the one that uses knowledge of exponent, where you have Marlin Rock 16, plunk. So Halo and bulletproofs and other systems, they don't require a trusted setup. And, yeah, that way they're called transparent, which is good.
00:32:30.360 - 00:32:35.390, Speaker A: So does that answer the question, or there was another part to the question.
00:32:35.840 - 00:32:55.440, Speaker C: We have more questions, but Pavel, let us know if that's answered your question here. But he has a different question he's asking. There are some ideas on ZK risk architecture. Does that mean that in the future we could have ZK CPU, along with classic cpu and GPU for provable computations, log into services, authentication, et cetera?
00:32:58.040 - 00:34:13.552, Speaker A: Well, I don't know what ZK risk means. I know that there is a team called RiSC Zero that are building ZK stark proofs for the RISC five processor and instruction set. Okay. This could give you zero knowledge proofs for any computer program that you can compile into the RISC five architecture. I'll say that this is something that is not new in the sense that in 2018, the white paper, the academic white paper that introduced the notion of ZK Starks, it in particular, also had reported a compiler from c to a virtual machine, not RISC five, something else called tiny ram. It was an academic grade, small machine, and theoretically, or academically, you could pursue that path already five years ago of converting programs into some machine code and having them proved at zero knowledge. It was not very efficient.
00:34:13.552 - 00:34:50.788, Speaker A: So, yeah, hopefully one day this will be more efficient. And just to state the obvious, you could apply this to any virtual machine. It doesn't have to be RISC five, for instance, you could generate ZK Stark proofs for Cairo runs. So we're not doing it right now. But it's technologically, it's easy to turn the stark proofs into ZK Stark proofs. That's the easy part. What is very tricky is to give you very good privacy on blockchains.
00:34:50.788 - 00:35:31.590, Speaker A: I'll just give you one example. Think about using an amm, right? Uniswap. Suppose you want to shield everything. Well, the whole way that Uniswap is written that the prices change according to information about what is going on there, right? Is it a liquidity provider? Are you going this way of the Uniswap bridge or the other way around. So if you make everything shielded away, it's not clear how are you going to build a uniswap in this world. Forget about the proofs. How do you make the statements such that you still have functionality and you don't limit and you allow privacy? That's the big challenge, right?
00:35:32.600 - 00:35:47.770, Speaker C: One more question from Pavel. How do we know that we can find constraints aromatization for any possible program? Does that work similar to np complete problems, polynomial reductions? Do we use the technique while trying to prove that some problems are NP complete?
00:35:48.540 - 00:36:33.832, Speaker A: Yeah, it works exactly like this. So already again, in the ZK stark white paper from 2018, we have a mathematical theorem there that shows that you can get starks for any language in what's called nondeterministic exponential time, which is an exponentially beefed up version of NP. Yes. So all you need to do is show it for one language. We showed it for basically the bounded halting problem. And then from that you basically get it for any language in any computation in this complexity class called next non deterministic exponential time. Awesome.
00:36:33.886 - 00:36:45.340, Speaker C: And the last question from YouTube from Dustin. How do you settle on the use of error correcting codes in starks? Are codes unique to starks versus other proof systems?
00:36:47.680 - 00:37:30.392, Speaker A: So this goes to. Well, yes and no. I would say that what appears across all different proof systems is the notion of low degree polynomials and commitment schemes to them. Now, low degree polynomials are also very deeply intertwined with error correcting codes. So you can get very efficient error correcting codes from low degree polynomials. But the way the different proof systems deal with enforcing low degreeness, which is exactly the slide we're looking at. Some of them, the error correcting codes, they're sort of more implicit there.
00:37:30.392 - 00:38:04.660, Speaker A: So they exist, but they are more implicit in the construction. What happens in starks? And not just starks, all of the systems on the left hand side, on the leftmost tree that you see on this picture, all of them very explicitly use error correcting codes based on low degree polynomials. And the ones on the right, they implicitly use the same attributes, the same error correcting properties of low degree polynomials, but they use them in a slightly different way, not just like with pure coding. I hope that answers.
00:38:05.080 - 00:38:08.036, Speaker C: Yeah, thank you, Ali. That's all the question for Matt. You can continue.
00:38:08.138 - 00:39:00.416, Speaker A: Okay, so the advantage of using commitment schemes that use the number theoretic assumptions is you get very short proofs. The ones on the left, they have merkel trees and very long proofs. So the award of the shortest proof actually goes to this red tree that requires a trusted setup. But famously, the Groff 16 system, for instance, you can have proofs that have less than 200 bytes per proof. So it's much, much shorter per proof than things in other truth. Now, one notion that is very important about enforcing low degreeness, and this will also play a role in our next talk, is that of a polynomial commitment scheme. And I'll go over it also in the next.
00:39:00.416 - 00:40:00.792, Speaker A: So what is a polynomial commitment scheme? It's a protocol. It's a game, if you want. So it's a gameplay between approver and a verifier. Approver needs to send some information that binds the prover to a particular polynomial, polynomial p of x. So a polynomial is a formal expression. For instance, if I say five x squared plus seven, that's a polynomial, and the degree of this polynomial is two, because the polynomial is five times x to the power two, and the power two is the highest power appearing in this polynomial plus seven. So the expression five x squared plus seven is a polynomial of degree two, and the polynomial commitment scheme, you specify a degree, and what you want is the proverb to send you some information that commits it to some polynomial of degree d, doesn't have to be this particular polynomial that I just mentioned.
00:40:00.792 - 00:41:11.776, Speaker A: The prover can commit to any polynomial she wants. Then the next step of the commitment scheme is that the verifier asks. After the verifier received the commitment, the verifier asks about the value of this polynomial that was pre committed on a certain point, let's say, on the point z. Now, the prover answers with the value of that polynomial, claiming, oh, the degree is low, and the polynomial I previously committed to has the value a at the point that you wanted to know about. And what we'd like to know is that if the proverb acted with integrity, meaning if he did actually commit to a polynomial, and the value of this polynomial, evaluated at z is the number a, then we want to allow the prover to succeed and prosper. But if something was wrong, if the degree isn't right, or if the value of this polynomial isn't computed correctly, and the prover has violated integrity, we would like to reject this. So this is what a polynomial commitment scheme is.
00:41:11.776 - 00:42:02.690, Speaker A: It's supposed to force provers into acting with integrity with respect to the evaluation of polynomials. And we would like you to have completeness, which means that when the right thing is done and the verifier always accepts, you want to have soundness, which means that if the wrong thing was answered, then you will reject. And there are other things they won't go into right now. So we can also ask what kind of commitment schemes are used, and systems on the left use things like fry. Well, stark uses fry. And then you also have inner product arguments used by bulletproofs in Halo. And you have things like the KZG commitment scheme for things on the right.
00:42:02.690 - 00:42:35.372, Speaker A: And there are different pros and cons. I'll share these slides later. But Fry gives you post quantum secure proofs over all fields, and all you need is a collision resistant hash. KZG commitment is very small, and you get things like addictivity, which I won't go into, but it's very useful. But you have trusted setup and so on. So there are trade offs. You can also ask what kind of finite field you can use.
00:42:35.372 - 00:43:23.290, Speaker A: And the tree on the left is unique and allow you to use any kind of field where those on the right need very large fields. And then there are also advantages of scalability and transparency that I don't want to go into. But jump to the conclusion and say that when I'm asked, which kind of proof system do you want to use? So I would say that for short proofs, meaning if you want your individual proof to be very short, you want to use a gross 16 system, but for everything else, you want to use a stark. And this ends our first part. I see it. Okay, let me try. Okay, good.
00:43:23.290 - 00:44:18.296, Speaker A: So prasha is asking, how do starks and Starknet render to hardware acceleration? What is the status today, and what will it look like in coming times? Okay, it's a very good question. So, right now, everything we're building is built so that it works very efficiently on just conventional hardware. And I mean, basically cpus with a little bit of memory. So, for instance, three years ago, we already submitted open source code for the ETH stark repository that the Ethereum foundation requested of us. And there we have code that generates the stark proof of 100,000 invocations of a stark friendly hash. And the proving time is less than 10 seconds. And a quad core with 16gb of ram.
00:44:18.296 - 00:45:19.996, Speaker A: Those were the parameters that we were asked for by the Ethereum foundation. We generate, in a very small number of hours on pretty standard computers on the cloud. We generate proofs for hundreds of thousands to millions of mints of nfts and hundreds of thousands of transactions. All of this on very standard hardware. Now, there's no doubt that massively parallel computation like that that can be found on gpus can help speed up things, because there are a lot of parts of the computation of the start that involve things like an FFT or computing a Merkel tree on pretty large amounts of information. So moving to different hardware can help with latency and also with scale. And further down the line, the same thing holds with dedicated hardware.
00:45:19.996 - 00:45:54.936, Speaker A: And there are a number of companies that are in the acceleration for ZK space. My opinion and the opinion of Starcore, the professional opinion of our experts, is that it seems a little bit too early to do this thing, because there's not enough demand for dedicated hardware. You probably want people purchasing tens of thousands of such things in order to make it worth your while. And we're not there yet, but we will be. But anyways, you will have hardware acceleration.
00:45:55.128 - 00:46:01.004, Speaker C: By the way, Prashant is going to be teaching the next session about Cairo VM architecture. Just so you know, Ellie as well.
00:46:01.202 - 00:47:06.536, Speaker A: Very good. Okay, Pavel, does does exist any sub exponential algorithm for elliptic curve that? Meaning there is something like index account for the discrete log problem on primes. And I think that's the main reason elliptic curves are preferable. How do you feel as a mathematician? Will discrete log on EC be possible to solve the problem in the future? Yeah, I mean there are a number of algorithms that are much more efficient for discrete log over primes. Yeah, I think the best things for factoring today, they're called the general number field c, and they use a lot of things like index accounting. You're right, there's less ability to do that over the elliptic curve groups, which is why they are used. So I'm not aware of index accounting for elliptic curves, but I confess that that's not my field of expertise.
00:47:06.536 - 00:47:59.140, Speaker A: Now, my own belief is that factorization will end up being in polynomial time, and if it is, then these things will be broken. So that's my belief. I'm not alone there, like some very famous number theoreticians like Peter Sarnak also believed that primes should be, sorry, not primes. I mean, factoring should be a problem that is solved in polynomial time. Okay, Eliel asking. Here's my question, considering the fact that the proverb creates a polynomial state, if I am not mistaken. What are those states? Are they the registers? Memory values for each program execution step? What values, types of values? Does the verifier need to verify hashes or submarines? That's a terrific question.
00:47:59.140 - 00:49:02.520, Speaker A: So what happens when you create a stark, is that you start by writing down execution trace of what happens to all the registers in your program. In the case of Cairo, part of its design is such that it has a very small number of registers. There are three of them, the allocation pointer, the FP, I forgot what it stands for, and the program counter. But you write down how all of these states evolve and then basically that. So, for instance, in Cairo, you would take like these three registers and write down the values that they have over each step of the computation. And then there are auxiliary values that you need to fill in, and you take all of this information and you compute a polynomial based on it. And as I think Nana said, a very good way to understand how this works is to do the stark 101 course.
00:49:02.520 - 00:49:31.520, Speaker A: And then you'll actually see how you take a very simple computation and create this for it. Okay, Prashant, do you have internal project going on on hardware acceleration on this direction? No, we don't. We're focusing only on software these days, so that's easy to answer. But I do know of many other teams who are building hardware. Right. FP is the frame pointer, thank you very much. So there's an allocation pointer, a frame pointer and program counter in Cairo.
00:49:31.520 - 00:50:28.566, Speaker A: Good. So let me now share my screen, and let's go to the next part. Can you see my screen? Yeah. Very good. Okay, so now my goal is to do a little bit of arithmetization exercises. And I want to explain, first of all, go more slowly over what arithmetization is. So it's a reduction from a statement or a problem about needing to convince someone that the computation was executed with integrity to a different problem about a relation between a bunch of polynomials.
00:50:28.566 - 00:51:06.120, Speaker A: So an arithmetization reduction would look something like this. Before you did the arithmetization, you have a claim prover makes, which you already all know, and then the output of this reduction, and this reduction is carried out by an algorithm. So it sort of translates it, or compiles it into, let's say, two polynomials. In some cases, it's more than two, that doesn't matter, but into a small number of polynomials. As you can see, these are polynomials in several variables. There are several indeterminates, and we're going to need to plug in values to these indeterminates. And there's also a degree bound, which is a number, D.
00:51:06.120 - 00:51:52.630, Speaker A: And the claim after this is that the prover is claiming, I know in this case, four polynomials, because there are four variables that I need to plug in. Right. If I look at the second step, I see that there are variables X-Y-T and w. So the verifier, sorry, the prover needs to come back with four polynomials of degree D and we can call them ABC and D. So that if you plug into the different indeterminates in the equations, these polynomials, the left hand side of the equation equals the right hand side. So there's a predefined equation and you need to solve it. But the way you solve it is you solve it with polynomials.
00:51:52.630 - 00:53:06.222, Speaker A: So we started with a problem about computation and we now have a new problem about relation between polynomials. And the core of scalability comes from this fact. If A-B-C and d do not satisfy this equation, then if you sample a number x and evaluate this expression at the point x, you will see the inequality with very, very high probability. And if we assume this theorem that when someone doesn't know a solution, then nearly all x's that you test would make you realize that the claim is false or the proof is false, then all we need to do in order to prove integrity is to apply the reduction. We take any statement, we apply the reduction and we ask the prover to give us access to the polynomials ABC and D of degree D. We only need him to commit to these four polynomials and we only need to ensure that they are of degree D. And then we only need Bob to evaluate honestly when he is asked about the value x.
00:53:06.222 - 00:54:05.180, Speaker A: And then what we do is we sample a random x and we accept Bob's claim if and only if the equality holds for this particular number x. Okay, so we have a new problem, which is how do we force Bob to commit to polynomials of degree D? And how do we then make sure that he answers according to the pre committed polynomials? If we can solve that problem, then we have a very, very efficient system for checking integrity. And that's our new problem. Right. We want to force Bob to commit to degree d polynomials and answer queries according to them. So my goal in this session is to show you how polynomials can be useful when you want to verify claims about very large amounts of computation without reexecuting that computation and without any trust assumptions. And that is what I want to achieve.
00:54:05.180 - 00:54:59.200, Speaker A: I'm not going to try and explain to you why it is that polynomials are very well suited to this task. And the reason I'm not going to try and explain you this is because I myself don't really understand it. There's a saying among mathematicians that says you never understand math, you get used to it. So I am used to seeing polynomials used in this way, but I don't completely understand why and whether you can do the same things without any use of polynomials by like I don't know, using derivatives or integrals or matrices or, I don't know, or Chat GPT or whatever other thing out there that exists. So I don't know. But I'm just going to show you. I hope you get a little bit used to how polynomials lead to succinct verification.
00:54:59.200 - 00:55:52.690, Speaker A: And we're going to do this with all kinds of very simple problems, and we're going to try to solve them together. And throughout this session, I will assume that we have an ideal polynomial commitment scheme functionality. Meaning, suppose we completely resolved and have this perfect object that is a polynomial commitment scheme. So how does this object look like? Alice can wave her wand. Alice will be the verifier and specify which finite field she's interested in. Does she want answers? Modulus 17 or modulus some other prime? So Alice will specify a field and a degree d. And the second phase is that Bob sends a polynomial of degree at most d.
00:55:52.690 - 00:56:27.070, Speaker A: And we're going to imagine there is this trusted party, we'll call it Tom, because he's trusted. And Tom will ensure that he receives from Bob a polynomial of degree d. And then Alice doesn't need to talk to Bob anymore. She just queries Tom about if she wants to know what is the value of the polynomial that Bob gave on a number a. She can ask Tom. And Tom is honest. Tom is going to answer the value of p of a.
00:56:27.070 - 00:57:20.984, Speaker A: So we assume that we have such collaborator, an honest collaborator called Tom, that ensures that everything works according with integrity. Now, a lot of the challenge with things like fry or KZG is to replace this ideal functionality, which doesn't really exist in the real world. And we don't want to assume that Tom is trusted. So how do we replace it with cryptography and protocols that will make it work, even though Tom doesn't exist. The first thing is we're going to assume that we have this ideal functionality for a polynomial commitment scheme. And now we're going to use, as we do this journey, we're going to need some facts from algebra. And the first one, there's a lot of notation here, but I'll go over it very slowly.
00:57:20.984 - 00:58:29.280, Speaker A: So, if you fix a finite field, which means you fix the prime that you're using for your operations, everything is, you take remainders from this prime, and you have any subset of this field that's called h. So we can define a polynomial that vanishes, or that equals zero exactly on the points in H. So to give you an example. And then what do we do? We just take the product of x minus a for all little a that happens to belong to H. So for instance, if I want a polynomial that vanishes on the points one, two and three, then that polynomial is defined to be x minus one times x minus two times x minus three. If you think a little bit about it, you will see that this polynomial indeed vanishes, or evaluates to zero on each one of the numbers one, two, three. For instance, the number one, because one minus one equals zero.
00:58:29.280 - 00:59:13.330, Speaker A: And if you multiply zero by any other thing, you still get zero. And the same thing happens with two and three. So we have a way to take any set of numbers and create a polynomial whose roots places where it evaluates to zero are exactly the numbers in the set H. Now we're going to use fact number one. And fact number one says the following thing. A polynomial vanishes on the set H if and only if you can factor this zh polynomial out of it, which means you can write. So a polynomial p of X has among its sets of roots the set H.
00:59:13.330 - 01:00:11.190, Speaker A: If and only if you can write p of X as the product of two polynomials. One of them is zh and the other one is the quotient polynomial p of X. So there's an if and only if in this story. And the direction that goes from right to left is fairly easy to show y. If you can write p of x as q of x times zh of x, then surely it will vanish on all points in H. And the reason is that we know that zh of x is defined to vanish on h, and it will just make sure that the rightmost side that is written on this line just vanishes. Okay, the reverse direction that it's an if and only if is slightly more elaborate, but I'm not going to prove it.
01:00:11.190 - 01:01:21.964, Speaker A: The second fact that we're going to use, and this is exactly where we're going to use the notion of error correcting codes is the following thing. If you have two functions that are evaluated on the same set s and their degree is less than d, and the set s is much, much larger than d, let's say it's 100 times d, then if they are not the same function, if f and g aren't the same, the probability that they agree on a random point a inside s is less than 1%. This follows from the fact that two polynomials of degree d that are different can share at most d values. They cannot have more than d values on which they agree that more than d values that they agree upon, they must be the same polynomials. And this is a generalization of what we know about lines. So, lines are polynomials of degree one, right? They could be written as ax plus b. So the highest degree there is one.
01:01:21.964 - 01:01:54.820, Speaker A: So lines are degree one polynomials. And we know that two lines cannot agree on more than one point. If two lines agree on two points, they have the same value at two different points. It means it's the same line, right? Two lines that are not the same can intersect in at most one point. And if you think about parabolas, these are like degree two polynomials. You cannot have two different parabolas that intersect at more than two points. If they intersect at three points, it's the same line.
01:01:54.820 - 01:02:26.140, Speaker A: It's the same parabola. Okay, so that's the second fact. And now we're going to play a game. Suppose that the proverb makes the following claim, the polynomial p, to which he already committed in the polynomial commitment scheme. He claims that vanishes on h in an Hour game. Let's imagine that the set h is really large. Let's imagine that the set h is of size a million.
01:02:26.140 - 01:03:17.750, Speaker A: So the proverb is claiming that there's a polynomial that he committed to, he entrusted with Tom, and it vanishes on 1 million points. And our challenge is to try and use the ideal pcs functionality and find a protocol by which we can verify this claim. So now I'm going to ask you, what is the protocol that you would use to make sure that this claim is correct? How do we check that a polynomial vanishes on 1 million points? And what you don't want to do is ask for the value of that polynomial at a million points. So can you do better, I wonder? Enri David Ganana, is it possible to allow participants to speak up?
01:03:18.440 - 01:03:21.270, Speaker B: Speaking, no, but they can write.
01:03:22.040 - 01:03:25.648, Speaker A: Okay, so where can they write? In the Q a or in the chat?
01:03:25.824 - 01:03:27.056, Speaker B: In the chat.
01:03:27.248 - 01:03:32.840, Speaker A: Okay, I want to see. So please write. If you have a solution, a suggested protocol, please write it in the chat.
01:03:34.380 - 01:03:39.290, Speaker B: So Elliot is saying you could create a function and test on some random points.
01:03:39.740 - 01:04:23.608, Speaker A: Oops, wait, I don't want to show the solution. Sorry. Okay, what is the protocol, by the way? You can ask Bob to send more polynomials to the ideal pcs functionality. How do we know whether. How do we know whether this polynomial p vanishes at all points h? Okay, let me solve the challenge. So here's the protocol. We're going to use fact one and follow the advice that pashon gave.
01:04:23.608 - 01:05:15.604, Speaker A: We're basically going to ask the prover to factor p and to factor this zh vanishing polynomial outside. So we're going to ask the prover to commit also to q in addition to committing to p, and we're going to ask for the commitment to q to be of degree less than D. It should be degree d minus h. And then what the verifier does is it samples a random a in the field queries, the pcs for two values. So the polynomial commitment scheme, or Tom, Tom, the trusted party, now has commitments to two polynomials. Basically, Bob sent to Tom two polynomials, p and also q. And Alice asks Bob for the value on a of these two polynomials.
01:05:15.604 - 01:06:00.548, Speaker A: So, she makes two queries and gets back two answers. And then she will accept, if and only if fact one is satisfied by these answers. So, if and only if she sees that p of a actually equals zh of a times q of a, that's what she checks for. So, let's analyze this simple protocol. So, even though h, we assumed, is huge, it's of size 1 million, Alice has made only two queries. That's all. She only asked to read p of a and q of a, and then she made h operations.
01:06:00.548 - 01:06:44.390, Speaker A: Why did she make h operations? Because she needs to compute zh of a and zh of a is. So the polynomial that vanishes on a set of size a million is a polynomial that could have a million terms in it. And she needs to compute this polynomial to evaluate it on a. So she does two queries, but she needs to compute many, many operations. So it's not that succinct. Yes, but the beautiful thing is that the probability of error is less than 1%, because, well, we assume that the field is large enough, let's say it's more than 100 times d. The probability of error is at most d.
01:06:44.390 - 01:07:20.096, Speaker A: That's the degree divided by the size of the field. So we have very, very good soundness. I'll just give you an example. In our world, in the world of Starknet, this field that we use is of size, roughly two raised to the power 252. So it's pretty large prime. It's a 252 bit prime, and the values d that we usually end up asking for are roughly like around, let's say, 1 million, or two to the 20. They're definitely less than two to the 30.
01:07:20.096 - 01:08:16.008, Speaker A: So let's suppose that they're two to the 30. So in our case, if we were to run this, the probability of error would have been at most two to the power 30 divided by two to the power 252. And that turns out to be less than one over two to the power 220. So your level of security would have ended up being something like 220 bits of security. So way safer than chateau or AES or these things. Now that's not the final soundness error that we incur, but it just shows you how powerful the use of polynomials is here, because let's see what happened here. Bob made a claim about 1 million values.
01:08:16.008 - 01:09:37.196, Speaker A: Instead of running or checking 1 million entries, we ended up making two queries and just reading, inspecting two entries and has a probability of error that is completely minuscule. The one thing we want to improve is that the number of operations the verifier needs to make is as large as the set h. But now we're going to use the third and last property of polynomials under algebra. This is the last property we need in this talk, and that in certain cases when h is what is known as a multiplicative group, there are certain sets h that even though they're very, very large, the polynomial that vanishes on this set h is very sparse. So for instance, if h is a multiplicative group, which is what we actually use when we build stark systems, then the polynomial zh that vanishes on the set h has only two terms. So the form x to the raised to the power that is the size of h minus one. And evaluating this polynomial you can do via repeated squaring and the number of operations, that is log of the size of h.
01:09:37.196 - 01:10:43.372, Speaker A: So going back to h, that is a million entries, log of h is 20. So you make two queries, you do 20 arithmetic operations, and your probability of error became very, very small. So this is an amazing display of succinctness. We have found a way to check the correctness of a claim referring to 1 million numbers. And instead of reading 1 million numbers, or inspecting 1 million numbers, or even doing 1 million operations, we make two queries, and we only do a number of operations, that is the logarithm of h, which is exponentially smaller. So we do 20 operations, make two queries, and our probability of error is extremely small. So again, what I wanted to show you in this talk is how using polynomials leads to very succinct verification of statements of integrity.
01:10:43.372 - 01:11:37.776, Speaker A: And here we have a first display of this. There's a statement of integrity about a table of a million numbers, and we can inspect its integrity with two queries and 20 operations rather than 1 million. So this is an absolutely amazing factor present that we are given by polynomials. Now let's talk about computation. Suppose that the claim being made is that p we're doing a rain check here. We want to know. Well, the prover is claiming that all entries that correspond to h are zero, one valued.
01:11:37.776 - 01:12:47.400, Speaker A: So they contain bits, right? We have a table with a million entries, and we're claiming that even though they could be arbitrary numbers in this finite field, all of them are zero one valued. So again I ask you, can you devise a protocol that would make, again, a very small number of queries and have very small error of probability? You're allowed to use the polynomial commitment scheme functionality, but you want to make a very small number of queries and have very small probability of errors. And if the polynomial p indeed takes on values zero and one on h, only zero and one, then you will pass. Whereas if that's not the case, then this will be revealed with very high probability by your protocol. So let's pause again for one or two minutes and see if anyone has a suggestion. Here's the protocol. What we're going to use is that let's look at this hint that I gave.
01:12:47.400 - 01:13:53.584, Speaker A: There is a polynomial c of y, and the letter c is because this is a constraint, it's a constraint. Polynomial. This polynomial has exactly two roots. This is a polynomial that vanishes only if Y has the values zero or one. So why is this important? If we replace y with a polynomial p of x, then we have something that is c of p of x, and c of p of x will have roots, will vanish on the set h if and only if p had zero one values on H. So thanks to this, we ask the prover to commit to p and to q using the polynomial commitment scheme, and we allow the degree of q to be. What the verifier does is it samples random a, and it queries the Pcs for both p of a and q of a.
01:13:53.584 - 01:14:48.736, Speaker A: And it will accept if and only if p of a times one minus p of a equals zh of a times q of a. And the efficiency again here is two queries only, a logarithmic number of operations, and the probability of error is only two d over f. Why? Because here's the proof. Let's assume that p is not zero, one value that Bob is trying to cheat. Then we know that p of x times one minus p of x cannot vanish on all points in H. If it cannot vanish on all points in H, it means that the polynomial equation that we're looking at, we don't have equality. It cannot be the case that p of x times one minus p of x equals z, h of x times q of x.
01:14:48.736 - 01:15:55.748, Speaker A: Why? Because z h of x times q of x, we know that it vanishes on h, but p of x times one minus p of x does not vanish on X, does not vanish on H. So we have two distinct polynomials, and the degree of these two polynomials is two d. And we now use the basic fact that if you have two distinct polynomials of degree, atmos 2d, there are atmos 2d points that fool you to think that they're the same polynomial. So our probability of error is 2d divided by the size of the field. Again, it's minuscule probability. So basically what we've now shown is a way to do range checking to check that a table with a million entries, all of these million entries are zero or one. And we do this check by making just two queries, a logarithmic number of error operations, and our probability of error is extremely small.
01:15:55.748 - 01:17:23.810, Speaker A: So again, we get succinctness about range checking, or type checking, with a very efficient protocol. Now, actually, part of the Cairo stark system has a very large number of what we call booleanity checks. So this type of constraint checking that numbers are either zero or one valued is an important part of the Stark protocol, even as we use it with Cairo in practice. So this theoretical game is not just a game, it's part of the constraint system that we have for our production grade system for Starknet. Now, I think the very large part, there's a way. Again, those who want to see how you actually craft constraints and use polynomials to argue about much more complicated computations, I urge you to do the stark 101, what's it called? Base camp, or the stark 101 exercise heroes, because there you will go through crafting constraint systems and checking that a computation of some fibonacci like number is done correctly. But I don't want to go through this because it's going to be a bit too complicated now.
01:17:23.810 - 01:18:33.220, Speaker A: So now we reach the last part that I'll discuss with you, which is, how do you get a polynomial commitment scheme in a world where you don't really have one? So the ideal functionality of the pcs was that Alice specifies a fixed field, and we agreed d Bob send the polynomial to this trusted party. Alice can query the trusted party and get the answer correctly and with integrity. So now we want something that simulates this, but doesn't have any tom in the picture, and we don't want to do the simple thing, but very inefficient one, in which Bob just sends all of the coefficients of p to Alice. Right, that's a simple solution, but it won't be succinct. In the case of the protocols we discussed earlier, you would have Bob sending a million numbers, whereas we want to make things happen with, like, two or three numbers being sent across. So we would like a protocol that would look something like this. Bob would send some commitment, some cryptographic commitment to Alice.
01:18:33.220 - 01:19:20.570, Speaker A: There's no more Tom. Alice makes a query, and Bob's answer that query and know the answer. The value of p at point a equals b. Now, Alice and Bob interact, and Alice will decide whether she accepts and likes what Bob has said or not. And we would like completeness, meaning if Bob was honest, and if indeed p of a equals b, then Alice will be happy. Whereas if b does not equal the polynomial p evaluated a day, their probability of success of Alice being fooled is less than something very, very small, like two to the power. -128 and then we want proving time and verification, and the number of rounds of the protocol to be very small.
01:19:20.570 - 01:20:09.832, Speaker A: We want it to work over all fields, and we would like it to have very lean crypto assumptions. So the fry protocol, also from the early days of starkware, gives you proving time that it's very efficient. It's linear in the degree, and the verification number of rounds is logarithmic indeed. It's also post quantum secure. And it even works for all finite fields. If you're familiar with KZG and plancks and a bunch of others, they only work over very large prime fields and even very specific ones. Fry works over and starts can be built over any field, binary fields, over the number 17, over anything.
01:20:09.832 - 01:20:46.668, Speaker A: And you can get much better efficiency this way. So what does Fry stand for? It stands for fast. That's the f. The second letter is Reed solomon, which means you're dealing with the error correcting code that uses polynomials. And the last part is IOP, approximately, which refers to the protocol, the way it plays out. So, in this protocol, the prover gives you oracle access to a proofer. It sends something like a USB, and then the verifier sends some randomness, and then the prover sends another USB, and the verifier sends more randomness.
01:20:46.668 - 01:21:09.896, Speaker A: And this goes on and on for a number of rounds. And at the very end, the verifier queries the oracles based on the answers read. There. She decides whether to accept or reject. And what the rye protocol does is it takes a problem of size, let's say a million. And the verifier sends randomness. And then you get the same problem of size, half a million.
01:21:09.896 - 01:22:04.280, Speaker A: And then this is invoked again and again, you get another problem of half the size and half the size again and again. And the laws of logarithms and geometric sums shows that the number of operations, until you reach something that is of size one, is the logarithm of the size of the table that you started with. And the overall work needed to be done by the prover is linear in the size of the initial table. So we get a very efficient protocol. I'm not going to go into the math of this protocol. I'll share some links to people who want to listen more to this part of the talk. I have a couple of lectures that I gave that give a little bit more detail about it, and I will share it with Enri, David, and Ghanana.
01:22:04.280 - 01:22:39.690, Speaker A: But I won't explain this now because I think I've spoken enough and it's complicated enough, this stuff. So with this, I end my talk again. Those who are interested about the math of fry, I will share some links with the organizer of the base cam, and they will be made accessible to you. And you can read more or watch more videos on this. So now I'm done with my math and happy to answer any questions.
01:22:41.340 - 01:22:43.880, Speaker C: Yeah, we have two questions in the Q A on zoom.
01:22:45.660 - 01:23:08.544, Speaker A: Okay. The Q A. Okay, quick maths question. Can any set of data able to be represented as a polynomial? Well, any set of numbers can be. And then if it's not numbers, if it's letters or ascii symbols. So you can just convert them into numbers and then. Yes, the answer is any set of numbers.
01:23:08.544 - 01:24:00.850, Speaker A: So anything you can represent with numbers, you can also represent with polynomials. Yes. Does prover and verify written in solidity on Ethereum, need to communicate in many rounds? That's a very good question. So there are two versions in which you can set up a start system. You can do it in the interactive version in which, let's say you have a smart contract on Ethereum that waits for a know, gets the next randomness from the block hash, sends that as randomness, and then gets the next commitment. And then you have an interactive version of stark interactive version of a stark protocol. What you can also do is use this thing known as the Fiat Shamir heuristic, and you can require that the verifier simulate basically what the blockchain would have done.
01:24:00.850 - 01:24:48.064, Speaker A: It's called the random Oracle model assumption. So there's a way to make the whole process completely non interactive and basically have the prover play out the interaction in front of the verifier and just present one proof, which you could also call a snark. Right. The letter n in the definition of a snark stands for non interactive, which means it's just one string of characters. So if you do this fiat Shamil transformation, you end up with something that is also a snark. And currently on our deployed systems, we use the snark version of Starks, which give you non interaction. But there are benefits actually to using the interactive mode as well.
01:24:48.064 - 01:25:38.720, Speaker A: You end up with more efficient proofs with lower gas complexity for verifying them. How can ZKP help for interoperability? That's a very good question. So suppose. Let's take an extreme example. Suppose I want to show on Ethereum that a whole bunch of stuff happened on bitcoin, so I could generate a proof that I know it's all about integrity of computation. I can put on Ethereum a statement that talks about a blockchain that has yay much levels of difficulty in its blockchain. And I can refer to a particular transaction or a number of transactions and show computations that happened there and prove to you that they happened with integrity.
01:25:38.720 - 01:26:05.000, Speaker A: And you can do this with respect to any layer two, you can do this with any layer one, and you can do this with respect to general computation that happened outside in the world. You can bring it over to the blockchain very efficiently. And if you have a ZK proof, a zero knowledge proof, you can also preserve privacy. You don't need to reveal anything about that when you're doing this thing, this on interoperability.
01:26:08.080 - 01:26:47.080, Speaker B: I have a question which is following something that I saw silv posting on Twitter, which I found was interesting. His take was that for the past ten years, we've used blockchains as a way to prove that something happened. So that's why often the knee jerk reaction was, oh, put it on the blockchain, then you're sure that it happened. And in a way, basically, proof, validity proofs give you another way of showing that something happened. Will validity proofs kill blockchains?
01:26:49.420 - 01:27:42.684, Speaker A: No, I think they will empower them, because what is the essence of a blockchain? The essence of a blockchain? You have this, let's call it a web of integrity, just like we have the World Wide Web, which is very useful for spreading information in an open way. Now, blockchains cast a web of integrity. There's like this network where the way blockchains work today is that everyone is like, a lot of nodes are re executing computations and you end up with something that's very trusted. There are also incentives for the validators and nodes to do the right thing. And the third magical aspect is that this is a protocol that's open to all. In fact, it's very inclusive. It invites people to bring on their computers and participate so that we all have this sort of ceremony that ensures the integrity on this web.
01:27:42.684 - 01:28:35.576, Speaker A: Okay? But because of the openness and inclusivity, you want to limit the amount of computation that is processed by those nodes because if you're going to increase a ten x that maybe someone's computer won't be able to stand up to that scale. And then she drops off and this happens more and more. And in the end you have like one big HAL 9001 computer that does everything for you, whatever, some Chat GPT monster that now decides everything and you need to trust it. So because of this, blockchains like bitcoin and ethereum, they say we need to limit the amount of computation. Okay, so you have this integrity web that is very trusted, but it's also very slow and for good reasons. It's very slow. The number of clock cycles it can do, if you think of it as a computer, is very limited.
01:28:35.576 - 01:29:30.940, Speaker A: So how do starks or stark net or zkps help with this? They say, okay, take this very trusted but slow computer. I'm now just referring again to the words of that beautiful paper from 1992. Think of it as this trusted slow pc. Think of the whole blockchain as this trusted and slow pc and use it to monitor many different supercomputers that you don't need any trust assumptions about them. And you can monitor their integrity and ascertain their integrity and be sure that they're doing the right thing even when the blockchain isn't watching. So now if you think about this like orb or stamp of integrity, what can you trust? So you started with something that's very small. It's all the stuff that, let's say the Ethereum nodes are executing as they're updating the state.
01:29:30.940 - 01:30:13.420, Speaker A: And now once you put the start verifier on it, all of a sudden you can have that stamp of integrity applied to anything that supplies a proof. And the beautiful thing is that this can even be done recursively with no loss or like negligible loss in soundness. So you could have these increasing, and that's the notion of layer threes and fours and fractal scaling. So, right, it's like you could start with this trusted core of integrity and by the integrity of math you can expand and extend it and scale it to global demand, which is precisely what starknet is going to do. That's our mission.
01:30:14.240 - 01:30:15.230, Speaker B: Thank you.
01:30:17.520 - 01:30:19.580, Speaker A: I see there's something on the chat.
01:30:22.600 - 01:30:24.116, Speaker C: The question in the Q A.
01:30:24.218 - 01:30:56.876, Speaker A: Yes. Seems like it's a good tool to monitor corruption in the. You know, I think everyone sitting on this talk agrees, and I want to say blockchains, at the end of the day, are technologies for the implementation of social functions. Now, what are social functions? These are protocols and registries that carry immense value. And that value necessitates broad social consensus. So money is a social function, right. It's a protocol.
01:30:56.876 - 01:31:39.572, Speaker A: It's a system. And its value necessitates that there's broad social consensus about its integrity. But there are other social functions. Election processes, governance in general, registries of land of marriage, social status, titles. These are all things that are of social functions. And currently, most of these social functions are administered by central parties. What blockchains do, I mean, thanks to Satoshi's amazing innovation, is to show that there's a different way to reach this broad social consensus regarding social functions.
01:31:39.572 - 01:32:07.480, Speaker A: That's what blockchains do. So what I think is going to happen, and I'm sure everyone here agrees like this, is the potential of blockchains. We could have better protocols for implementing social functions at the local levels, national levels, international levels, things that are just better for auditing, for financial transactions, for just the way we implement social functions.
01:32:08.700 - 01:32:17.000, Speaker C: Let me bring a question from YouTube. Dustin asks, any thoughts on starks for provable machine Learning, like limitations, challenges, et cetera?
01:32:19.100 - 01:32:53.604, Speaker A: Theoretically, you can apply it to any computation, right? So you can apply it to machine learning. And I must say, the way I think of it is somewhat like this. Machine learning is like this unbelievably amazing innovation, right? It's now like just transforming the world. Everyone's talking about it now proof systems are starting to trend. They're nowhere near, I mean, sadly for starting, they're not yet near the amount of hype. Rightly so, right? It's not on the same order of Chat GPT. Maybe we'll reach there.
01:32:53.604 - 01:33:36.150, Speaker A: Now. It's often very sort of tempting to say, oh, let's do something that uses these two things, right? That puts zks on the machine learning. It can be done. A lot of these machine learning things are extremely compute intensive. And then there's the question of who needs to prove what to whom? What is the setting, the business setting in which this makes sense? It can be done, but should it be done? And I don't know yet of a good answer to that. Like, here's a compelling business case where we need to apply zkps onto machine learning and a lot of users are going to pay for it and need it.
01:33:37.160 - 01:34:15.920, Speaker B: Actually, we recorded a community call with Giza. We're doing provable machine learning not so long ago. So for those interested, I highly suggest you check it out. And I recorded last week a podcast with Fran who is one of the founder of Giza, and he has a lot of interesting stuff to do. And counterintuitively, a lot of the demand for provable machine learning comes from legacy industry. Like for example, if you're an insurance company and you want to automate the processing of claim, you need to prove that you follow the specific process. And right now it's very difficult for them to do that with machine learning because they can't prove what's inside the box and that they indeed used a specific box.
01:34:15.920 - 01:34:19.490, Speaker B: So having provable machine learning is valuable to them.
01:34:20.360 - 01:34:22.070, Speaker A: I agree. That is interesting.
01:34:25.430 - 01:34:38.390, Speaker C: Question from Henner on Zoom. We're talking about transparency of CK stark tech, but we can see the details about transactions. For example, stark scan. Is this transparency just on l one? So on Ethereum mainet.
01:34:42.480 - 01:34:45.916, Speaker A: I'll defer to Enri, probably knows better. Sure.
01:34:46.018 - 01:35:30.136, Speaker B: I think that question is, and we mentioned it earlier in basecamp, but the way we use Starks in Starknet is mostly for scalability, not for confidentiality, for privacy. So this doesn't apply. There's no privacy on Starknet. And also Starknet is a public network, so everything that happens on Starknet, you should assume it's public. I think there's a lot of confusion around privacy and zks in general, because zks are a new concept. And when they first came up, the first thing people thought of was, oh, let's use this for privacy. But we're using them in a different way, so maybe eventually the meme will revert.
01:35:30.136 - 01:35:55.990, Speaker B: Though it is very interesting what you can do with privacy for that. Actually following stuff on privacy, there's another interesting question, which is about the intersection of starks, or I guess zero knowledge proofs and fhe fully homomorphic encryption. And the question is specifically does Starks allow fhe? Or is another type of cryptography needed?
01:36:04.500 - 01:36:53.404, Speaker A: So fhe, first of all, fhe and ZK, they sort of complement each other. They prove different things. ZK is about integrity, knowing that the right thing is done when no one is watching, and fhe is about having others operate on your confidence. It's like putting your stuff in a box on the cloud, and then allowing whoever is holding that to sort of manipulate the data according to your instructions without them actually knowing anything. Like what are you interested? Sorry. They know what the computation is that you're asking for, but they don't know what the values are that come out, and they send it back to you, and only you can open it. But that doesn't give you any integrity.
01:36:53.404 - 01:37:48.416, Speaker A: So, for instance, you could want to have data there. You could ask the cloud, please compute the mean of this data, and the cloud provider could actually send to you, let's say the maximum there. So ideally, you would want the cloud provider both to send you do fhe, and also give you a zero knowledge proof for integrity that the right thing was being done. So these are like, they're complementing technologies. Fhe is, I think, earlier in its commercialization, in the sense that it's a little bit harder. It uses different mathematical worlds. It uses a lot things like rings with errors and learning with errors, and it doesn't work so well, to, best of my knowledge, on finite fields.
01:37:48.416 - 01:38:18.184, Speaker A: They're actually suboptimal for that. So merging the two together is theoretically doable. But that's like, I would say people would know. We started with, like, ZK. Others are working like, there's a very good project called Zama team working on fhe. Another angle which generalizes ZK is called secure multiparty computation. It's a generalization of zero knowledge.
01:38:18.184 - 01:38:43.860, Speaker A: That's another very interesting angle that will probably also be deployed. And there are even more exotic things like indistinguishability, obfuscation, and stuff that is even crazier and wilder, but also harder to implement. Brilliant cryptographers have come up with, and in three decades, someone's going to implement.
01:38:45.800 - 01:38:54.360, Speaker C: We are already over the two hour mark, Ellie, just want to make sure that, do you have more, five minutes to answer two more questions, or do you have more things coming on your schedule?
01:38:54.860 - 01:39:44.440, Speaker B: Okay, I think actually the two questions are really good. To wrap up the session, Pavel is asking, is it possible to have a verifier on Darrow? I don't think anyone here has that answer, so I'm sorry, Pavel, but if you do find the answer, let us know. I'd be very curious to know if it's possible. And another person is actually asking a nice question to end this. So, Eli, thank you for being with us today. How do you see the next big step with ZKP? So Starknet is a major, like, it's one of the first iterations in production of provable code that manipulates millions of dollars worth of value. What do you see the next big step with the technology we're building at Starquare?
01:39:45.340 - 01:40:54.712, Speaker A: So I'll make the analogy with what happened with AI. The interesting thing is that it's now like transforming the world. Apparently a lot of the algorithms, and they're sort of basic, there's a lot of amazing engineering and it just showed amazing implications in the world. But theoretically it's based on very simple neural networks from the. This was a bit surprising to machine language experts. Now, why am I saying this? I think the next thing that will happen that will completely bring zkps and, well, I prefer to talk about validity proofs because it's not so much the privacy aspect, but everyone calls them zkps and blockchains with them, everyone will talk about it. I think it will be the things that are enabled by Starknet, because right now the demand for blockchain is very big, but it has very small capacity.
01:40:54.712 - 01:41:52.764, Speaker A: And you have just massive capacity on Starknet, both through just the layer two and then through layers three and four and so on. And this will get this immense flywheel thing happening, because again, social functions, their value increases as more people use them. Think about money, and why is the US dollar so valuable? Because everyone uses it and it's like this flywheel thing. So if you unleash the ability to deploy so many more social functions at many different scales and have them all interoperate, you get much more value, which brings more users, which makes the basis for this integrity web even broader, which brings more social functions and more interest. So I think we'll see this exponential growth in the dependence of people on these things. And it will end with people saying, as one of the speakers said here. Yeah, Prashant.
01:41:52.764 - 01:42:28.540, Speaker A: Right. It's a good way to get governments to monitor. So people will be demanding, wait a second, why are we entrusting these people in suits with things that sometimes they're corrupted the way they do it? We want it much more transparently, we want the protocol to be understood to everyone and then used by all. So I think that will be the big transformation. Not so much the technology. I mean that will then lead to you would need hardware and much more efficient systems and so on. But I think the next thing, again, like AI, is just that the world realizes this is a great technology to use.
01:42:28.690 - 01:42:37.100, Speaker B: So we have a great tool now people need to use it. A nice call to action to end base camp and to thank all of our viewers.
01:42:37.840 - 01:42:41.710, Speaker A: Thank you. Thank you, Emily, David, thanks.
01:42:42.880 - 01:43:04.100, Speaker C: Yes, thank you, all of you, for coming. Thank you, Lee, for attending this session. I'll send the email to all of you on basecamp with the resources. And we leave this video public on YouTube as well, so you can watch it on Starware channel. Thanks again, Henry, Ganana, Ellie, all of you. And I guess I'll see you base campus next week for the final session. Thanks, everyone.
01:43:04.170 - 01:43:04.880, Speaker A: Have a good day. Bye.

00:00:03.130 - 00:00:16.362, Speaker A: Kick off this panel right now. We're going to be chatting about data today about crypto data, specifically mostly on chain data. So I want to welcome our speakers. Maybe we can just start with David and very quickly introduce ourselves.
00:00:16.506 - 00:00:25.942, Speaker B: Sure. Hey, guys, I'm David Maihall, I'm a developer. I work on a project called Cryptostats Medicine. Are sites like cryptofees info and stuff like that and.
00:00:26.076 - 00:00:26.470, Speaker C: Yeah.
00:00:26.540 - 00:00:27.560, Speaker B: Good to be here.
00:00:29.770 - 00:00:34.070, Speaker D: Hi guys, my name is Patrick McCorry and I'm a researcher at Infura.
00:00:35.210 - 00:00:46.090, Speaker C: My name is Bartek, I'm a researcher for l two B and maker Dow. And I also co founded a data analytics company called Stalk and Flow.
00:00:46.590 - 00:01:04.030, Speaker A: And I'm Larry Ceramac, I'm vp of research at the block, and I'm going to be moderating this panel. So why don't we just quickly kick it off with a simple question. Why are you guys interested in data? Why are you guys running companies that operate with on chain data? And again, we can start with David.
00:01:04.390 - 00:01:41.638, Speaker B: Sure. I mean, the thing that got me kind of into the space was feeling like people always don't understand crypto blockchains. Probably most of us in the room don't have a full understanding. Nobody really understands it. Data is such a good tool to actually cut through all the bs, the marketing stuff like that, and really understand what's happening on these chains. So that's how crypto fees started, because I was like, man, if you look at the main ranking of chains was like coin market cap, but it's full of such crap. And I was like, well, there's like real fundamentals and we can use that as a lens to help understand crypto.
00:01:41.638 - 00:01:43.580, Speaker B: That's what gets me excited about data.
00:01:44.350 - 00:02:05.038, Speaker D: Yeah, I feel like I sort of have two hats in this. So if I just consider myself, I like to understand how the smart contracts work and then hopefully translate that to data. So for example, if someone says they support 5000 transactions per second or they use 1000 gas per transaction, what does it actually mean in the contract level at infuria? I mean, obviously infuria. Has anyone heard of Infuria?
00:02:05.054 - 00:02:05.298, Speaker B: By the way?
00:02:05.304 - 00:02:18.070, Speaker D: Do you want to raise your hand? Have you heard of infuria? Awesome. So infuria is quite popular for providing data to dapps and of course wallets like metamask. And so that's the other hat is sort know understanding how the data served to the end user.
00:02:19.950 - 00:03:14.266, Speaker C: So I guess I'm spending most of my day trying to analyze data from blockchain. And frankly, over the years we've just had a great panel on enterprise blockchains. People, a few years ago, they did not really understand, in my opinion, why we're building systems on blockchain. In my opinion, transparency is probably one of the main reasons today. It's just that we know that the data is out there, but very, very few people know actually how to read that. In a way, what we found over the years of working, let's say, at l two b, is that there is this big disconnect between what people claim and what's really happening on chain, right. So even though the data is on chain, it just happens that very few people care to check.
00:03:14.266 - 00:03:28.698, Speaker C: Right. And I think our responsibility is to actually read data from chain more often, because just the fact that data is available doesn't really mean that people are reading it. And that is a big challenge, in my opinion.
00:03:28.874 - 00:04:01.466, Speaker A: Yeah, I mean, just looking at what happened in the previous year at Alameda Celsius doing all bunch of really sketchy stuff on chain, and it really isn't just a meme that no one checks the chain. Same with a few on chain hacks that we had. Bridge hacks sometimes get found after a month of no one knowing. So how can we collectively, as a group here, but all of us as well, do better in actually spotting these things? And how can we improve the infrastructure so this doesn't happen anymore in the next few years? Yeah.
00:04:01.488 - 00:04:51.110, Speaker C: So I think that each one of us will probably have a different take on this because it's actually a hard problem. I think there are two related issues. One is that we collect on chain, like, a lot of data, right? And there's just no group of humans in the world that can possibly read that data. So we actually need machines to interpret what other machines are producing. And to do that, in my opinion, this is my personal take. We need to take it one step up from how data is actually recorded on chain, because right now the data is essentially encoded. And to make it more meaningful, we need to find better ways to decode it.
00:04:51.110 - 00:05:22.818, Speaker C: And by decoded, I mean not just going through standard API, because that's just not enough. We need to go way further than that. Right? So in other words, we need to find ways to make sure that we read the data, but in a meaningful way. And also we need to look at the source of data. And the source of data are smart contracts, right? So people are like assuming, hey, if there is a transaction or data on chain, that must be true, but they don't look at the smart contract that actually produced the data, very few people do.
00:05:22.904 - 00:06:03.134, Speaker B: Yeah, I mean, I'll back up what you said, that getting data on chain, the data is all public, it's all available, but it's hard to get data. And so I think the important way to kind of solve the problems you were mentioning is having the tooling to make it more accessible for people to come in and get that data. So far, I think the project that's done the best at opening this up to everyone is something like dune analytics or the other similar projects like flipside and stuff. Because now you let anybody, they don't need to query the chain. They don't need to do the hard queries that we're doing. They can just write some sql, make a dashboard. The lower that barrier to entry gets for people to be able to consume this data and build their own dashboards, whatever.
00:06:03.134 - 00:06:16.530, Speaker B: The more likely it is that someone built the dashboard that's going to show bridge transfers and they're going to look at it and be like, something doesn't add up here, and be like, oh wait, this bridge just moved some money that they shouldn't have moved.
00:06:17.510 - 00:06:39.690, Speaker D: I can also jump in here. So these guys have been making the point about how to parse the data. But in your example, when you talk about FTX and Ometa, the problem there is that the data is not available either. I like to think of everything as a bridge and a database. And if you think of FTX, you deposit funds into the system, but it's a closed source database. You can't read it, you can't audit it. You've obviously attempted to read that database.
00:06:39.690 - 00:07:07.640, Speaker D: And the issue there is that if you don't have the financial information, then you can't actually evaluate it. And that's why I've always been really bullish on sort of the roadmap, side chain roadmap, because you're going from a closed database to an open database where the data is available and then you can actually evaluate in real time are they solvent, are they commingling funds. And so we really just need to change that technology stack to make it easier to get that data available for them people to actually parse it.
00:07:08.810 - 00:07:27.066, Speaker A: But most exchanges of what they've done is completely not sufficient. Right. And they're just basically sharing their addresses and then combining those. Do you think we get there in the future where it's actually going to be possible to confirm more directly? I suppose, yeah.
00:07:27.088 - 00:08:03.640, Speaker D: I mean, I think we have historical examples. It's going to be our starkware now, aren't we? So if you consider like Starkx was a stark knife of e, one like DYDX, so rare, immutable. They're all public open databases, which are basically just facilitating exchanges. They support payments and swaps, and that's about it. And if you consider roll up as an SDK, as a narrative, someday, if you're a financial service, you could just kick start or deploy your own roll up, have your database open for someone to protect and use us all for your financial services. So I think it's really just about getting that technology stack there so then people could actually use that technology stack over a web, two closed source system.
00:08:07.610 - 00:08:48.740, Speaker B: I think you're suggesting kind of this cool idea of centralized, noncustodial exchanges and stuff like that. And that's certainly a super cool idea. But when it comes to something like FTX, if it's a truly just like centralized company, there's no way to actually be sure. A lot of exchanges were trying to do, like proof of reserves, which seems like some are better than others, but a lot of people made the point that you can have proof of reserves, but you can't show proof of liabilities. So if it's like you're trying to understand the data of a company, a company will always be somewhat opaque. The only way you can really have assurances is something that's on chain, a decentralized application that doesn't have that, you're not worried about the off chain components of it.
00:08:49.510 - 00:09:08.490, Speaker D: There is one point. So there are proof of solvency protocols from 2016 using Xero and all these proofs, but the last I looked at them, it takes a day to generate the proof. They're just not practical whatsoever. So you can sort of do it, but no one's ever going to implement. It's too hard. No, that does include liabilities. So it's reserves and liabilities, but it's impractical to implement it.
00:09:08.560 - 00:09:11.350, Speaker A: But who's providing the liabilities? Just an auditor.
00:09:11.430 - 00:09:20.720, Speaker D: It's business doing all these proof. I can explain it there. It's not worth upon them, but it's a 2016 paper by Joe Binau, so it's been there for like seven, eight years now.
00:09:22.370 - 00:10:03.014, Speaker C: I might actually add one more thing to that. I mean, obviously, we need data to be on chain to be able actually to analyze that. And we need to understand that data on chain is not just transactions. Let's take Starkx as an example and roll ups in general. There is a lot of data written as right now called data with the dunk sharding it would be written as data blobs, it will be even harder to interpret. And what we found at l two B when we tried to analyze called data for Starkx to be able to independently recreate the state of essentially any Starkx system, it took us weeks to properly interpret that. Right.
00:10:03.014 - 00:10:41.450, Speaker C: It's just not easy. I mean, the data is there, but obviously this is not as simple as going to doing analytics and going through a standard API. Assuming obviously the data is being decoded there. You need to be able to go deep into the smart contracts. And in this particular case, you need to go deep into the Cairo contract that puts the data out there. That's assuming that you do have a source code for this Cairo program. So all things considered, I think the data is out there, but there is a huge niche and a need for such efforts like we've done for l to B.
00:10:41.450 - 00:10:59.280, Speaker C: Right. And now the question is who's going to pay for it, how to actually fund all these efforts? Because it takes a lot of money to gather all the data. It takes a lot of money to decode all the data. And users, they seem to expect dashboards to be out there. Right?
00:10:59.730 - 00:11:35.542, Speaker A: Yeah. So that's a really good segue into just talking about kind of business models and how data exists in the market right now. So we have almost like most of the data providers in crypto right now exist under the web two model that we're used to in the traditional finance as well. I would almost say that you guys, LTB as well as crypto fees and crypto stats, it's almost kind of like on the web3 side of monetization, similar with DFI llama, maybe. David, can we talk about a bit about how do you view that? How do you view those differences and how do you think data eventually will be monetized in crypto?
00:11:35.686 - 00:12:24.982, Speaker B: Yeah, I mean, the thing that I'm kind of excited about with crypto stats as well as projects like l two bead and you mentioned DFI llama and some of these other info sites, is a lot of the data in web3 is still web3 data, but it still follows very much like web two business models. What's a web two business model? What does Google and all these companies do is take a bunch of data, you put it in a sandbox, you charge access to it, you try to build a wall around something. And where I think Web three really succeeds is getting rid of the walls. And instead of charging people to get into your castle, you make something open, you find some way to kind of build network effects, build something that's such a strong public good, that's irreplaceable. So I'm excited to see more projects. I think this becomes like not one project or one company. It becomes a bit of a stack.
00:12:24.982 - 00:13:14.838, Speaker B: You have kind of things that more at the infrastructure layer, things like the graph or other kind of data providers. We try to be with crypto stats as to be kind of like a trust layer normalization, like taking data from all these indexing data sources and providing some interpretation of it. And then the top layer is visualization or presentation. Are you going to show charts? Are you going to show lists? How do you communicate this data to users? And if crypto grows the way I think we all think it'll grow and hope it'll grow, it's going to be impossible for any one company to be really comprehensive with data. You're going to need some way that users can contribute. Some companies launching a Defi protocol, they should be able to come put the pieces together so that people can access their data in the same way. Right now, they would build a dune dashboard.
00:13:14.838 - 00:13:21.600, Speaker B: I think in the future there'll be kind of more open tools and open ways that projects can present their data to everybody.
00:13:24.050 - 00:13:44.258, Speaker C: So I think there are certain companies that are quite successful with that model that end users are actually paying for data. And I think nonsense is probably one of them. But if you ask, like regular web3 users, would you pay extra to see the dashboard? I don't think a lot of people would. Right.
00:13:44.344 - 00:14:10.950, Speaker B: I mean, I think if they did, you'd get undercut because the data is available, data is free. Again, there's good web two style products, and I'm not going to trash them because they're good projects. But I think over time, if the data is available and free, and the costs, I think infrastructure costs will trend towards zero as it becomes competitive. If you're trying to charge for that walled garden, I think over time you're going to get outcompeted.
00:14:11.030 - 00:14:54.454, Speaker C: Yeah. So having said that, if you kind of try to think who should pay for all the data, it seems to me that we should be slowly toying around with the idea that maybe access the data because we know that it costs. Right. The data is not free. I mean, it's out there, but to get it, it's not free at all. Maybe that should actually come from the security budget of all these systems, right? Maybe roll ups should pay data providers to actually make the data available so that they can actually convince their users that what they claim is actually what is happening on chain. And if they don't do that, they will be like a centralized exchange that does not really provide the proof of assets.
00:14:54.454 - 00:15:00.170, Speaker C: Right. I mean, those that do will have clients. Those that don't won't have clients.
00:15:00.990 - 00:15:28.230, Speaker D: Yeah, I mean, one thing I could step in with. So Infuria is currently working on this decentralized infuria network, and one of the projects is sort of motivated by your project, this decentralized status page. Could we encourage people to actually ping all the node providers, build a nice report and put it online and somehow reward them for that? So I know, I'm furious, definitely looking at how to support projects like that in a more web3 decentralized way, as opposed to centralized data pages that could lie or not lie.
00:15:30.250 - 00:15:49.420, Speaker A: When people are looking at different data providers, developers, but also just users. Patrick, how would you go about evaluating that? Obviously you might be a bit biased here, but what are some things that people should be looking at when looking at specific node providers, and what are some benefits and disadvantages of each?
00:15:49.870 - 00:16:48.778, Speaker D: When I joined Infira two years ago, I was actually trying to work out why they're useful. I was a bit like, why would someone use inferior for, and I think if you're using a node provider, there's a whole stack of different competitors. They're really just a load balancer. So if you're a DAP, you need to support, I don't know, 30 requests a second, 40 requests a second, as opposed to getting your own DevOps team, you can just hire a no provider to do that. One of the reasons why Infuria wants to pursue this new decentralized infuria is because obviously there's competitors out there, but in an ideal world, it would be good for me to sit here and be like, oh, well, you should use infuria and alchemy, use your competitor, and we can work together to actually support our users with this cocktail approach, where right now, as a web two model, you just can't do that. We can't really recommend your competitor and lose your profit. So yeah, that's definitely something that they're trying to fix, as in terms of trying to enable collaboration, so you don't have to worry about choosing between them because they're all working together, and then you can cross check the results.
00:16:48.874 - 00:16:57.762, Speaker A: Do you think that will also lead to better censorship resistance of these RPC providers and node providers if it eventually all kind of decentralizes more?
00:16:57.896 - 00:17:34.730, Speaker D: I think so, yeah. I mean, censorship resistance in this regard relies on geographical location. You need to be outside the certain sanctions of a certain country in order to serve a traffic. But even just on that, actually, so recently there was a blog post specifically about infuria claiming that they were censoring the tornado cache EF address. And actually there's going to be a blog post coming out to say that how you do the lookup with the resolver on the ENS domain is actually non trivial. And they actually made a mistake in the blog post because it wasn't being censored. So even just trying to get the accuracy of that sometimes is very know, convincing someone that you aren't censoring.
00:17:34.890 - 00:18:11.690, Speaker A: Right. Maybe another question for David. How do you deal with so many new blockchains launching? We now have so many different infrastructures, Solana, Avalanche, Cosmos, whatever, Polygon, so many different L2s as well. How do you deal with kind of parsing through that data, parsing through different infrastructure and then actually showing the data set in numbers that people understand. Is that really difficult? Is it resources intensive, what goes into it? Because that's what us as users never really see. But I can imagine because we work with data as well, it's a really difficult problem.
00:18:11.840 - 00:18:37.746, Speaker B: Yeah, that's definitely a challenge. When it comes to the newer chains and larger chains, a lot of the data that we use comes from the graph. The graph is very nice. It works on every EVM chain. You can kind of run the same subgraphs everywhere, but as you kind of get outside the EVM ecosystem, it gets tougher to find data. Sometimes you can run your own indexer, I think LTB, you guys run your own infrastructure for indexing it. Right.
00:18:37.746 - 00:19:12.800, Speaker B: But when it comes to when we want to get Solana data, it's really hard. It's not just hard for us. We've been kind of working with a team called Solana FM that runs like a block explorer and stuff, and we know that they have trouble keeping up with the chains sometimes just because Solana is just this fire hose of data. So, yeah, the newer chains, the chains that have a lot of data, that gets really, I mean, that's just going to be a challenge for the ecosystem to deal with because I think we all think there's going to be, as we figure out, scaling the amount of data is not going to slow down. That's just something we're going to have to learn how to deal with.
00:19:13.250 - 00:20:04.118, Speaker C: And it's not just about supporting new chains, it's also building community pressure, in my opinion, so that every dev knows that if you want to be trusted. And if you don't want to be trusted, why are you even here? Right? If you want to be trusted, just make sure that your contracts are verified, that other people can actually look at them. And I think Ethereum is actually doing quite a good job, right? And it's doing this because it's been around for years. But look at those new mean, you know, they copy VM, but they don't have such a vibrant community, right? So most of their contracts are unverified. Look at mean, it's like, you mean, it's a firehouse of data. And most transactions that I've looked at, at mean, I have no idea what they, I mean.
00:20:04.144 - 00:20:35.000, Speaker B: And I think that's a cultural thing, right? The Ethereum community is know, Ethereum community kind of emerged out of the bitcoin community. I don't know if that's controversial to say, but it holds a lot of those values of, I think, you know, the Solana community probably doesn't share all those same values. So the idea of like, oh, we're going to keep our code, we're not going to verify our contracts because it's part of our product. It's like an industry secret. They don't hold that as high because in web two you can keep your code closed source. Why do they need to?
00:20:35.450 - 00:20:48.442, Speaker C: Yeah, this is something they could never understand, right? I mean, we're building permissionless system and people, essentially we're asking people to trust the code, but at the same time, we're not revealing this code. It's like throwing money into the black box, isn't it?
00:20:48.496 - 00:21:19.478, Speaker D: I mean, just to jump in, just so we don't criticize everyone in the room. Not in the room, sorry, I mean, just all these projects, I feel like in the bitcoin Ethereum community, really at the heart of is the idea of trust engineering, where you're trying to define, measure and reduce trust as much as you can. And that's even part of just the whole roadmap, making Eve two minimal and building on top of it as layers. So this is your ultimate route of trust, where a lot of the new projects that come out, they don't really come from those ethos. They just see that Ethereum doesn't scale. They're like, okay, it doesn't scale. Throw the kitchen sink and make a scale as much as they can.
00:21:19.478 - 00:21:29.206, Speaker D: And I'm happy to see that approach because then you can sort of just do product market fail. If it works, it works. Maybe we're overthinking trust. Sorry, I know what? Larry wants to say something.
00:21:29.388 - 00:21:39.590, Speaker B: I mean, it works. It works until it doesn't. That's what we saw with like, oh, you know, it works. It works. And then, like, stablecoin aside, not only did the stablecoin not work, the stablecoin failed. The chain didn't.
00:21:39.750 - 00:21:47.920, Speaker A: So, yeah, we're running towards the end of the time. Do we have any questions from the audience for the.
00:21:53.480 - 00:21:54.816, Speaker D: Mean? I can ask a question.
00:21:54.938 - 00:21:55.496, Speaker A: Go for it.
00:21:55.518 - 00:21:59.240, Speaker D: So do you do all your data collection on excel or Google sheets?
00:22:02.540 - 00:22:49.992, Speaker A: We don't. So what the blog does, we have a dashboard, and effectively, we're kind of aggregating different data sources. So I'm pretty sure we actually use both of you guys l to beat as well as crypto fees. What we do, we just pipe it into our own kind of back end and then show we're basically kind of aggregating the data sources and then visualizing it for our users and then crediting the data source. We're going a little bit more in the direction of also getting our own data. But like you guys said, it's insanely capital intensive, and it's difficult to kind of make it work unless it's a company specifically built to support data. I think people just don't appreciate how difficult it is actually to do what t two guys are doing as a site.
00:22:49.992 - 00:22:51.272, Speaker A: It's really hard.
00:22:51.406 - 00:23:32.550, Speaker B: Yeah, I think that's why it's important to have kind of these open systems of getting data. I know when we talked to the block about why you guys started pulling crypto fees data, because the block was getting revenue data, and then new protocols are launching every day, and it's like, you guys have better stuff to do than to add the newest uniswap fork. And I guess we don't. That's our core offering. And when these forks come out, when people launch new projects, they come to us and try to get integrated. So I was saying that's how data scales is. You have kind of these public good data sources, and then companies like the block can be the presentation layer, can say, like, we're going to communicate this data in a good way and we're going to make it available to everyone.
00:23:33.080 - 00:23:43.850, Speaker A: Yeah, that's exactly what we tried to do, is just to kind of be the funnel for users to view all of it. And then you guys obviously are providing super important infrastructure for all of us.
00:23:45.820 - 00:24:59.632, Speaker C: Maybe I should also mention that if you're thinking seriously about analyzing blockchain data in a professional way, you kind of have to realize that indeed, this is a big engineering pipeline, right? It's not enough to have your own node and then get all the information from that node. Sooner or later you're going to hit the wall. And I think it makes sense to think about using data from professional data providers that will essentially supply you the data like, say, dune does, or tokenflow, which is like dune, but on steroids. And they are data engineers who specialize with handling big data. They might actually know databases that you've never heard of, but these databases are actually obviously not nodes, but they are made to handle terabytes of data, right? And they will expose those data sets for you, hopefully in a decoded way, so you don't have to write hundreds of scripts to actually interpret the data. And then you can focus your activity on actually analyzing the data and creating dashboards. And I think, in my opinion, this is the direction that the whole industry is going to move.
00:24:59.632 - 00:25:26.660, Speaker C: And the maturity of that pipeline will speak to the maturity of the whole ecosystem. Right? And this is why, in my opinion, Ethereum is still way ahead of competition, because it takes years. It's just not enough to launch a chain, right? You have to build that community eventually, because otherwise, well, you've got a chain, but there is no tooling, there's no data providers, there's nobody, and you will have to essentially get the data yourself from the node.
00:25:28.640 - 00:25:32.330, Speaker A: Cool. Well, thanks a lot, guys. Thanks a lot for all the time.

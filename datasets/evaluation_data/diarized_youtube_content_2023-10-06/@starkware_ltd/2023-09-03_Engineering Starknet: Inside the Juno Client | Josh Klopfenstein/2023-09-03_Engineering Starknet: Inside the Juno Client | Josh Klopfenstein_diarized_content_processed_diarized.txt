00:00:03.210 - 00:00:40.074, Speaker A: Hi, everyone, I'm Josh Kloppenstein, a software engineer at Nethermind working on the Juno Starknet client. We have it pulled up. Okay, there we go. Yeah. Juno is a full node that can sync the Starknet blockchain. I think now is a really exciting time to be working on a full node in a blockchain ecosystem, them like Starknet, because we get to take a lot of the innovations that have happened in the Ethereum ecosystem and in other ecosystems and bring them to Starknet, and we'll talk about some of those innovations today. Just a quick show of hands.
00:00:40.074 - 00:00:59.774, Speaker A: I'm curious, who has made an RPC request to an RPC provider like Infuria chainstack with Starknet? Okay, I think most everyone. That's great. If not, that's fine. You're in the right place. To learn more about how full nodes work, who has used Juno for that purpose? Has anyone used Juno? One, two. Okay, a few people. Great.
00:00:59.774 - 00:01:35.046, Speaker A: So if you have used Juno, this will be a great description of how Juno actually works under the hood. And if you haven't used Juno, then you're in the right place again. Hopefully you'll start using Juno after this talk. So just a quick review. What the role that full nodes play in a blockchain. They sync the blockchain, downloading the block's transactions and state in order to allow users, usually wallets and dapps, to access this data. They serve the blockchain data over RPC endpoints.
00:01:35.046 - 00:02:12.946, Speaker A: You can also submit transactions using full nodes, and then in most networks, those transactions will be gossiped and formed into blocks using some consensus algorithm. Those last two items aren't implemented in Starknet yet because it's still decentralized. And one of the goals of Juno is to actually lead the way on Starknet's path to decentralization by implementing those two features at the bottom. So, as I said, our ultimate goal is to help decentralize Starknet. Right now, Juno can sync mainet and Testnet. It implements 100% of the JSOn RPC spec, all the read write trace APIs. It supports reorg resolution.
00:02:12.946 - 00:02:46.202, Speaker A: On L two, we can track the l one head support DB migrations. So whenever new Juno version is released, you can just stop running the version that you currently have, start running the new binary, and continue syncing from where you left off. No need to resync. And finally work in progress feature that we have that we're really excited about is being able to query the database over GRPC. This would be a non standard endpoint maybe such things could be standardized in the future. It's tied to Juno's database layout, however. But this allows you to get really good performance.
00:02:46.202 - 00:03:19.900, Speaker A: So if you're doing something like indexing, come talk to us, let us know what you need so we can help Juno work for you. By the numbers. Juno can sync about 170,000 blocks. I think that's about the size of mainnet right now, in just 55 hours, resulting in a 49 gigabyte database. When we load tested the node, we sent 600,000 requests at 1000 requests per second, resulting in a 39 millisecond response latency. This is on a performant machine, so depending on the hardware that you have available, your numbers could vary. But this just demonstrates what Juno is capable of.
00:03:19.900 - 00:03:38.610, Speaker A: Okay, so now into the more interesting stuff. This is Juno's view of the world. Users interact with Juno. Usually the user, again, is a wallet or a DAP. But if you want to send a JSON RPC request yourself, that's just fine. Juno is capable of that. It accesses the local database to serve that data.
00:03:38.610 - 00:04:32.766, Speaker A: This local DB is part of the Juno node itself. Juno will download that data from this right now, centralized Starknet sequencer, and it will also track the l one head on Ethereum. An Ethereum node isn't required to run Juno, but if you do want to track the l one head, then you can do so using an Ethereum node and providing the RPC URL to do that. Okay, so just by way of warm up, if you submit a transaction to Juno right now, Juno won't store it locally, it'll just forward it onto the centralized gateway, because that is the only entity that can build a block in starknet right now, eventually in a peer to peer network. And once consensus is realized, then it'll actually have a local mem pool that it keeps track of, like in other blockchains. But the other direction is a little bit more interesting, which is what we'll talk about today, syncing a block. So now going opposite direction, syncing a block from the sequencer.
00:04:32.766 - 00:05:13.294, Speaker A: And we'll talk about four optimizations that Juno makes to make this process as fast as possible and achieve those numbers that I mentioned a few slides ago. Okay, so first, Juno will download the block and the state diff from Starknet. The state diff. Because Starknet is a validity rollup, Juno doesn't need to execute the transactions locally. The sequencer does that, and the state diff is just the result of executing the block on the local state. And this download and sync process you can divide it roughly into three stages. The first stage is just the download stage, where we download the block and the state diff.
00:05:13.294 - 00:06:05.674, Speaker A: Second, we do basic sanity checks on the block and the state diff. For example, checking that the block hash was computed correctly. And then finally we do full verification, where we apply the state diff to the state and ensure that the state route matches the state route that's in the block. And what's really cool about the way that Juno does this is this process is pipelines. So while we're doing full verification on block one and the state diff for that block, we're doing sanity checks on the next block and fetching the third block. And so you can imagine if we extended this table downwards, you'd be constantly adding new blocks and state div to the local database, which is a really nice optimization. Now, okay, the most critical part of a full node, in my opinion, is its local database, because the whole node is really a wrapper around the database and all of its functionality.
00:06:05.674 - 00:06:54.180, Speaker A: You can just think of the picture from earlier, is really centered around this database. And so Juno makes some interesting trade offs with the database that allows it to store as little data as possible while still maximizing functionality. So the first optimization that Juno makes during the sync process, we've already done verification on the block, we've already done verification. Now we just need to store the data in the database. The contract storages in most blockchains, in just about any blockchain, come in the form of a tree. You can think of the leaves of the tree as just being the values in the storage, and then the path through the tree is the key to those values. Even if you're not familiar with how state tries are usually laid out in blockchains, I think the optimization should make sense.
00:06:54.180 - 00:07:29.606, Speaker A: So we'll say that for a given block n that we're syncing right now. The leaves highlighted in orange for these three contract storages have been changed, and now we need to recalculate what the root of these trees are. And this is a very nice optimization. We do all of these. One of the benefits of not having to execute these blocks is that we can calculate the roots in parallel. So rather than going from contract to contract recalculating the root, there's no data dependency like there is when we have to execute the transaction serially. So now we can just do this in parallel.
00:07:29.606 - 00:07:56.674, Speaker A: And this resulted, I think, in about a 60% speed up when syncing one block on one of our benchmarks. So very nice optimization. My coworker who's here actually made this optimization. And in the GitHub review, I said that I was really jealous. I didn't come up with this myself because it was a very clever idea. I think it was definitely sped up the node quite a bit. Okay, now, so those roots of the contract storages that we just recalculated become the leaves of the main state try.
00:07:56.674 - 00:08:39.938, Speaker A: So you can think of two of those contracts as being these two leaves down here highlighted in Orange. Again, now, we need to recalculate the route of this main state, try to get a portion of the mainstate commitment. And so again, one way we can do this is to change one leaf, recalculate the route, then change the other leaf, recalculate the route the way Juno does this is it just changes all the leaves that need to be changed, and then recalculates the route all at once. So it recalculates the route lazily only when it needs to. And this again, resulted in a very large speed up when we implemented this. Okay. Fourth, and probably the most interesting optimization that Juno makes is using immutable try.
00:08:39.938 - 00:09:06.250, Speaker A: This idea was pioneered by Aragon in the ethereum ecosystem. And I think that it's quite a brilliant idea. And this is what enables it to just store 50gb of data for 170,000 blocks on the left. You'll see the one way of doing this, it's storing an immutable try. And we'll illustrate what this means. So you can see this example state try underneath, just a given block n. So this is the state at a given block.
00:09:06.250 - 00:09:40.502, Speaker A: And we'll say that this for the state diff we just received for block n plus one, that orange leaf has changed. And so now we need to recalculate the root. One way to do this is to just recalculate. You can think the subtree or its ancestors. So for block n plus one, we create this new subtree and just have pointers back to whatever values have not changed. And so this allows us to minimize storage. We're not copying any of the exact same data, but that subtree back here, these nodes right here are no longer used.
00:09:40.502 - 00:10:12.910, Speaker A: So the old data is no longer present in the current state tri. So those are, you can think of it as kind of dead weight. It does have some benefits. Like, we can roll back this block and we have the state trial already on disk, but it increases storage massively. And if starknet is successful, its state will be quite large. And so it's critical that we minimize this kind of dead weight, if you want to call it that, as much as possible, and give users the option to get rid of this dead weight so as many people can run nodes as possible. So what Juna does is we permit ourselves to mutate the try in place.
00:10:12.910 - 00:10:51.934, Speaker A: So when we sync a new block, you'll notice there aren't pointers back. We just mutated the try in place, or the try tree is the same thing. So now for block n plus one, we just have a single state try and we modify it in place in order to roll back. You'll think if block n plus one is reorged, then we need to be able to replay the block in reverse. So we store the value that the leaf previously held, and that's in that diff right there. But notice that's only storing the value in a single leaf, not an entire subtree. So this minimizes storage requirements quite a bit.
00:10:51.934 - 00:11:27.586, Speaker A: This is, you can think like an order of magnitude improvement. Okay, finally, to query Juno, this is kind of one of the last pieces of the picture. Users submit RPC requests and go to the local databases that we said before, it's pretty tough to read, but on the left side, you don't have to read the code. This is just for example sake. Using the JSON RPC spec, this is using Starknet js, you can just change the RPC URL that you're querying. And Juno supports all the APIs. It should just be a drop in replacement.
00:11:27.586 - 00:12:08.840, Speaker A: And then using GRPC, it requires a little bit more work because you need to be a lot more specific about what you want from Juno's database. But it allows you to get all the benefits of using, for example, protobuffs and for being able to take advantage of Juno's database layout directly. So if you need to iterate over all the leaves of the storage, try. Rather than using something like JSOn RPC, where you're kind of doing it indirectly, you can just access Juno's database remotely and just iterate over the database directly. So that is a feature that we're really excited about, kind of rolling out over the next few releases. Okay, finally, I don't really have time to go into this into much detail. You can ask about it during the Q and A if you're interested.
00:12:08.840 - 00:12:58.454, Speaker A: Juno will track the l one head on Ethereum by querying the Ethereum node and storing it in the local database. And finally, what we're really excited about again is decentralizing Starknet. Leading the way on Starknet's path to decentralization. Implementing P to P and Snapsync is probably top of mind for us right now, PDP especially, and then snapsync. Gradually over the coming months, Snapsync will allow us to dramatically reduce the sync times that nodes have to deal with and also hopefully decrease some of the size of the database since we won't need to store full history. Websocket subscriptions is something we've been thinking about adding. Let us know if you're super interested in us adding a certain endpoint and we can definitely consider it.
00:12:58.454 - 00:13:28.666, Speaker A: We definitely want to work with the community to make sure that Juno works for them. And then finally, more juicy optimizations coming up, parallelizing the state tri update. So not just doing it lazily, but doing these things in parallel could be an option for us. If you're interested in getting involved or want to reach out to us on socials, get in touch about a particular way you're using Juno that you think is interesting that we could serve you better on. Can use the QR code. It points to this URL here at the bottom. Just our GitHub repo.
00:13:28.666 - 00:14:19.422, Speaker A: You can find our discord and telegram there if you're interested. Yeah, so that's all that I have. Happy to answer any questions. Yeah, so the question is, if there's a p to P implementation timeline, I mean, we're working actively with other nodes and timelines can change of course. Hopefully over the next month to three months, we'd have some sort of experimental thing you can play around with as far as actually, and with the deprecation of the feeder gateway looming, then Starknet will have to start syncing using p to P. So before the end of the year for sure. Thank you.
00:14:19.422 - 00:14:26.938, Speaker A: Cool. Yeah. Another question. Thank you.
00:14:27.044 - 00:14:43.510, Speaker B: Can you say a little bit more about for your db, which one are you actually using? And have you considered offset as a separate postgres or cockroach DB as a separate DB service? Like more for more scalability?
00:14:43.930 - 00:15:14.416, Speaker A: Okay. Yeah, so right now we're just using standard key value store, using pebble from the cockroach team. We haven't really considered adding additional indexing features on top using something like postgres. We generally leave that to the people who specialize in indexing who build those services on top. But if you have something specific in mind, happy to discuss that more offline. All right, any other questions? All right, cool. Thank you all for coming.
00:15:14.416 - 00:15:17.090, Speaker A: I'll be here all day, so just catch me afterwards if you have more.

00:00:04.050 - 00:00:36.170, Speaker A: So I guess, hello, this hour is supposed to be a workshop on fees on Starknet. So what I thought we should do is to briefly go over what exactly the fee mechanism design consists of for starknet. Like maybe break it down into four sub questions and I guess discuss each of them. I don't have an hour long lecture in mind. We just thought, me and Noam, that we could sort of bring up the main points and then discuss. We can present two or three concrete problems that we're facing. But I think maybe we should start with the overview.
00:00:36.170 - 00:01:20.154, Speaker A: Does that sound okay? Okay, cool. So the way I think of it, the fee mechanism question consists of four main questions. First of all is, what are the protocol level resources? So Ethereum chose to unite all of the resources into just gas, even though behind the scenes there are actually many underlying resources. For example, bandwidth, storage, execution, they coupled all of that into gasps. So there's an obvious question of whether or not we try to do the same or not. That's the first question. Second is, after you define the resources abstractly, you should figure out some concrete way to convert starknet operations into these resources.
00:01:20.154 - 00:02:12.426, Speaker A: So specifically, Cairo is divided into atoms that are called lib funks. So you should somehow price every single lib funk into units of resources. So that's that. The third is the structure of the user bids. So if I'm a user and I want to send a stocknet transaction, I want to pay, I mean, probably I want to pay money for sending my transaction. What is the structure of the bid that I'm supposed to send? Do I just give like a maximum budget? Do I pay per unit? Can I ignore some of the resources? So what's the structure of the bid? And the last one is, what is the mechanism by which I can be charged for my bid? So if you look at something like bitcoin's first price, you're charged what you bid, right? It's pay your bid. If you look at 1559, you bid something, but you cannot be charged for your entire bid.
00:02:12.426 - 00:02:32.962, Speaker A: The semantics don't allow that. You can only be charged the fixed block price per unit gas. Right? So that's the fourth question. So I thought we can just roughly go over our thoughts on each of these four questions and present a concrete challenge that we're facing. And you're thinking about it. Nam, does it sound okay to you?
00:02:33.096 - 00:02:47.142, Speaker B: Sounds very good. And one thing I think it could be like a two way street. So feel free to stop at any point, ask questions, make suggestions. We're trying to make it as much a discussion and less of a lecture.
00:02:47.206 - 00:03:18.180, Speaker A: Yeah, exactly, less of a lecture. Okay, so what are the resources? I think we can list like four or five obviously distinct resources, so they would be execution for roll up. There's also proving there is bandwidth, there is storage. At least these four things are not obviously correlated in any strong way. So let me try and elaborate on what I mean by each of them. Storage is the thing that full nodes do if they want to maintain the state. Okay.
00:03:18.180 - 00:04:02.770, Speaker A: The more storage sales are initiated, the larger the state is, the more things you have to store. This is a long term cost. It's not something you can capture in just a single transaction, because if a user now requires the state to grow by x, it's a cost incurred on every full node, conceivably forever. So it's a very different type of resource than, let's say a one time execution event where everyone executes, discovers the effect and then goes on. So that's one execution improving. They seem to be correlated, but because of the way Cairo is designed, they're actually not correlated. And I'll give a few examples.
00:04:03.670 - 00:04:09.060, Speaker C: The VM gives us some metrics that captures all three of them together. Right.
00:04:09.910 - 00:04:13.442, Speaker A: Can you explain there is correlation between.
00:04:13.496 - 00:04:14.958, Speaker C: The proving and the execution?
00:04:15.054 - 00:04:15.518, Speaker A: Yes.
00:04:15.624 - 00:04:21.494, Speaker C: And the VM also while executing, can assert in what the storage will look like.
00:04:21.612 - 00:04:22.280, Speaker A: Yes.
00:04:25.770 - 00:04:30.950, Speaker C: We can make a single dimensional by just measuring some facts about the VM.
00:04:31.110 - 00:04:31.818, Speaker A: Yes.
00:04:31.984 - 00:04:58.180, Speaker B: So to begin with, the VM keeps track of the important resources, how many commands of this type, how many trace cells, how many calls to this function, and so on. So it can keep track of everything, of all these parameters. But we don't want to get like an arbitrary function that taking in, I don't know, twelve complexity measures and outputs. So we somehow need to actually combine them in a reasonable way.
00:05:05.990 - 00:05:30.920, Speaker C: There may be high demand on one, low demand on the other, et cetera. But the effect rate that prevails between the different resources, that's something the protocol has to specify. Absolutely. It's a decision on how much money you use the right cap.
00:05:31.090 - 00:05:32.050, Speaker A: Yes, exactly.
00:05:32.580 - 00:05:47.030, Speaker B: And also different resources are congested at different levels. So storage is very long term. Proof is at the level of the proof, sequencing is at the level of the block. And that's completely different skills. So you also have to take that into account.
00:05:47.640 - 00:06:28.172, Speaker A: Cool. So we listed some resources and I think instead of going into why they're not correlated, which we can delegate to a later discussion, I think the main question is it doesn't even make sense to combine them into one resource. And we think that the answer is partially yes. There is one special resource that we cannot combine with the other l two resources, and that's the l one gas. So Starknet, being a roll up, consumes l one gas. The price of l one gas is affected by the demand of the entire ethereum ecosystem, and for that reason, it's not natural to couple it into the resource that has to do with only purely l two things. So basically, we would like to have just two resources.
00:06:28.172 - 00:07:02.220, Speaker A: One is l one gas that encapsulates the entire consumption of all of the interaction with l one and all of the other stuff. So, proving execution, bandwidth and storage, at least at the beginning, just stick them all into one resource, which we will refer to as l two gas. Okay, so already it looks relatively simple. I mean, maybe as simple as you can hope. Does that make sense? Okay, cool. So as far as I'm concerned, we've covered this. We haven't really covered it because there is a very big question of what exactly l two gas is.
00:07:02.220 - 00:07:08.648, Speaker A: Right. How do you convert these different resources that are behind the scenes into l two gas?
00:07:08.824 - 00:07:48.936, Speaker B: Maybe I want to say another word about the difference between why do we really have to have this l one degas going mostly for call data separate from the l two gas? Because these two costs are really orthogonal to each other. You can have a very complex transaction that doesn't touch even l one call data, or the opposite. You can have a rather simple one that uses a lot of data. So these things are not at all correlated with each other, as opposed to all the other resources that are more or less correlated. Not in the extreme cases, but generally we believe that they will be mostly correlated. L one gas is completely different, especially once we have volition. So some transactions will not use it at all because they will keep their storage elsewhere.
00:07:48.936 - 00:07:57.710, Speaker B: So you can't really charge these efficient transactions for the l one cost of data, which are enormous relative to value.
00:08:05.300 - 00:08:12.444, Speaker C: And none of these. We didn't discuss how we charge the bandwidth technically.
00:08:12.492 - 00:08:37.660, Speaker A: We decided, yeah, so I think bandwidth should be measured in terms of sort of the payload, like the byte size of the transactions or of the blocks. And I think it makes sense to cap it. But I think as far as pricing goes, I don't think we're planning to explicitly include it. Maybe there will be like a protocol level limit that is orthogonal to pricing that just prevents blocks that exceed a certain size from being valid.
00:08:42.640 - 00:08:55.460, Speaker C: You mentioned that maybe you should keep this and you have the l one costs.
00:08:57.770 - 00:09:34.400, Speaker B: Yes. Okay. Right. But as a user, suppose you're using a lot of l one data, so we want to give you the ability to control how much money it will take because the prices go up and down. The idea is, well, you pay, so we estimate at sequencing time. We need to charge you for your l one data cost. So we do the best estimate possible, and we take that money when you are there.
00:09:34.400 - 00:09:55.000, Speaker B: And that's it. That's what you pay. You pay the estimate at sequencing time because you have to take it. But the point is, as prices go up, and now maybe you want some control over your transaction. You're saying I'm not willing to have my transaction run when you think that the data costs in l one are going to be 100 or something like that, so that gives you extra control.
00:09:58.560 - 00:10:32.200, Speaker A: Okay, cool. So now we've closer to covered it. So I want to move to the second question, unless anyone has any objections. There's not much to say here. It's more of just more or less arbitrarily deciding how we want to convert starknet operations into resources. It's very reminiscent of what Ethereum did. They had like a bunch of benchmarks running on a bunch of different operations, and then they just looked at hardware, which seemed reasonable, they looked at the resource expenditure and then they made up numbers.
00:10:32.200 - 00:10:49.980, Speaker A: And we think that's a pretty reasonable way to move forward. So we plan to do the same. As far as, what are the details? We haven't worked it out exactly yet, but expect it to start, like expect these benchmarks to start appearing in the upcoming months, I think. Yes.
00:10:56.500 - 00:11:31.388, Speaker B: So the real question is, you would like to measure exactly what congests you, what your bottleneck is, right. Because otherwise you just give everything for free or for cost or something like that. So you really want to measure as closely as possible what really is the thing that congests you. And of course, there are many different things that may congest us. We believe that most likely that the sequencer time will be the number one issue usually. But we want to make sure, especially for the worst case, to not be susceptible to denial of service attacks, that you pay for anything that can congest us even. Right.
00:11:31.388 - 00:11:39.650, Speaker B: So that's exactly the kind of thing that we need to measure separately and take, like the worst case, as long as it doesn't hurt the average case. Also.
00:11:46.910 - 00:12:18.358, Speaker A: The best way to shield them would be to have them think of as few resources as possible. So as far as they're concerned, there is only like a one dimensional market for starknet transactions that would be the first. And the second is to have a good combination of both a simple bid structure and a very convenient charging mechanism. So I'll give a bad example and then a hopefully better example. A good bad example would be the bitcoin user experience, where there is only one resource, it's bytes. That's all there is in the world. That's the only thing you need to bid on.
00:12:18.358 - 00:12:51.200, Speaker A: But when you post your bid, you may end up feeling that you overpaid it, because in bitcoin, the biding is first price. So you pay your bid, you have no idea what other people are bidding. So you just hope that you're not overpaying, but you may end up discovering that you overpaid, and then you go home. Set. So this, on one hand, at the resource end, it does a very good job of abstracting all the trouble away from users. But at the user experience, like in the sense of strategy, it doesn't do a very good job. Does that make sense?
00:12:52.370 - 00:13:15.062, Speaker B: Maybe try to be a bit more expensive. The whole point here is to shield the user. So except for the l one gas, which you have to pay, and we can't shield you from it, the l two gas, you just see a list. This operation cost you one. This operation cost seven gas. This operation costs 77, and you don't need to care where these numbers came from. It's our problem to make sure that they're not going to break the system.
00:13:15.062 - 00:13:55.542, Speaker B: Just like when you run Ethereum, you know that operation costs seven and that operation costs 77, and you have no idea why they chose it that way. But you're assuming that that somehow reflects their true cost, and the same thing will be true here. So we'll do the calculation once and for all and give you, this is how much each type of operation, each type of hash function and so on cost. And you'll take that into account when you build your program, because you understand the relative cost of different operations. We're not yet there. That's like the number four. Yeah.
00:13:55.542 - 00:13:57.160, Speaker B: There's another question. Yeah.
00:14:03.600 - 00:14:11.916, Speaker C: How much they want to pay for the fee. And the deviated from that. And approver has done the job of.
00:14:11.938 - 00:14:12.510, Speaker A: Like.
00:14:15.290 - 00:14:20.870, Speaker C: They want to pay the fees and that part satisfies. Then do we unbundle? Rebundle.
00:14:22.330 - 00:14:36.190, Speaker B: You don't start. So that's why we need to charge you at sequencing time. So we use the estimate for the gas fee, so we can do the charging at sequencing time. So the prover will not start proving your transaction unless it knows that you're willing to pay the price.
00:14:36.260 - 00:14:39.200, Speaker C: Did they also charge me my l one price, l one.
00:14:43.890 - 00:14:44.494, Speaker B: Everything.
00:14:44.612 - 00:14:52.274, Speaker C: My fee, the one you have to bring, encompasses my l one fee in it as well.
00:14:52.312 - 00:14:52.900, Speaker A: Right.
00:14:53.270 - 00:15:01.106, Speaker C: And let's say the component that I paid for it was $2. But now the cost of, by the time the generates proof and everything the.
00:15:01.128 - 00:15:43.830, Speaker B: Cost of working on, no, you pay according to our price estimate at sequencing time. We have to shield you away from this risk that maybe by then the price will go up. Okay, so there's going to be an entity at the beginning. Now it's going to be us, basically the centralized sequencer that is taking the risk. It may probably charge a little bit of money for taking that financial risk on itself, but basically you're paying now for money for gas, for future gas, sort of like an implied futures market for gas price. We'll always charge you according to the l one gas price estimate at sequencing time. Exactly.
00:15:43.830 - 00:15:51.390, Speaker B: Yeah, but tips are not for l one gas, only for l two gas.
00:16:12.830 - 00:16:13.146, Speaker C: Right.
00:16:13.168 - 00:16:15.238, Speaker A: Now, the latency from a user sending.
00:16:15.254 - 00:16:16.700, Speaker C: A transaction to.
00:16:55.530 - 00:16:57.580, Speaker A: I'm more efficient than if I.
00:16:59.380 - 00:17:35.420, Speaker B: The trade off is latency versus cost. So in principle we could put a proof every five minutes or something like that onto l one that will have low latency, but it will be very costly because proofs are costly in terms of actual money. We can always also wait for a week and only once a week, put things on the blockchain. And that will be high latency, but will be very cheap. And now the trade off, the point of the trade off is some kind of, it depends mostly on, let's say on the TPS or something like that. The more we have usage of our system, the more we can efficiently, from an economic point of view, decrease latency.
00:18:13.590 - 00:18:15.186, Speaker A: There is just one operator of the.
00:18:15.208 - 00:19:06.914, Speaker C: Whole thing, latency and speed, like giving the user the choice for the upper bound. But maybe the user should get some expression saying, I find getting l one finality after two weeks, that affects everybody.
00:19:07.032 - 00:19:43.694, Speaker B: Yeah, that has to be like a global thing, right? We're not going to have separate proofs for different latency desired latencies, going to be one proof. And the basic idea is we don't want, we want the added cost of the l one to be relatively small to your total fee, right. That's when it starts being efficient. So it's not going to be a major part of your direct fees. Hopefully that's going to be somehow amortized within the rest. And that's opposed to data, your own call data fees, which are your own right, and the latency doesn't matter.
00:19:43.892 - 00:20:07.840, Speaker C: So as more and more users onboard either keep price of your fee constant, and then the time can come down, or the fee is just going to reduce. Is there one that's better than the other?
00:20:07.910 - 00:20:09.330, Speaker B: Hopefully both. Right.
00:20:11.540 - 00:20:36.210, Speaker C: So proving takes roughly the same time as execution, the l one cost. But these are.
00:20:41.480 - 00:21:30.410, Speaker A: I think, a distinction that really helps me, that Noah made, is to separate between the marginal l one costs and the fixed l one costs. So the marginal stuff is the data availability, and that's not going to be reduced by virtue of having higher demand, because the more transactions, more l one data, you're not winning. There is a small hope that things will cancel, but putting that aside, you're not really improving any efficiency. The hope is to improve is to improve efficiency by making sure that the fixed cost is spread out over many more transactions. That's what's going to improve the efficiency. Yes. And if you compress, then maybe that will be.
00:21:30.410 - 00:21:33.690, Speaker A: Yeah, that's the thing I didn't want to go into, but. Yeah.
00:21:39.100 - 00:21:41.560, Speaker C: Because you don't know what compression.
00:21:45.120 - 00:21:55.170, Speaker A: But you could approach it from the reverse way and say that you don't post an l one state update until some threshold of information has been reached. So you could price like the reverse way.
00:22:03.380 - 00:22:10.320, Speaker C: Keep going along, and then keep a little stating. You need to keep compressing it to see if it's meeting the border.
00:22:11.320 - 00:22:54.320, Speaker A: Actually, something pretty similar is happening right now. Up until recently, we used to close starknet blocks even if they were relatively empty. And that resulted in quite a bit of wasted money, because when we send a starknet block to the prover, our computational costs are more or less independent of how much the block is full. So if the block is relatively empty, we're wasting money on proofs. And now we changed our policy so that we don't close blocks until they're relatively full. That's an example of this sort of reverse pricing, but it has a pretty big drawback that it makes the block times non constant. And we'll see later why that's a major bummer.
00:22:54.320 - 00:22:57.990, Speaker A: Security.
00:22:58.520 - 00:23:09.232, Speaker C: Not for any action, because if there's not enough transaction to be produced, and I use the transaction, but I will only get held by defront way after.
00:23:09.386 - 00:23:22.990, Speaker A: Yes, I think this is another, like a different way to phrase the trade off between latency and efficiency. If things are inefficient, then you have to wait. And that in a century, this is the security.
00:23:27.040 - 00:23:54.870, Speaker B: I think the idea is, no, we definitely want to shield the user. User doesn't have to think about all these things. We'll do optimization that we can to get the best trade up between security and cost. As a user, you just see your prices and the gas price goes up and down, let's say according to congestion mostly, but maybe with some kind of minimum price, and you only see that. So all this optimization, cost optimization, are definitely something we shield the user from right.
00:24:03.740 - 00:24:07.690, Speaker C: Back, basically and whatnot.
00:24:16.790 - 00:24:40.552, Speaker A: Yes. This is the plan. This is the plan. The plan is as soon as something reaches l two consensus, it's only a matter of time until it's proven on l one. So there is no such thing as people misspaid. So we revert the l two consensus because something else has to be proven. Yeah, absolutely, that's why I said that.
00:24:40.552 - 00:25:14.410, Speaker A: I think it's the biggest headache, this futures thing, this speculation, because maybe it'll be too severe, and we have to hope that it won't be. And we have to hope there will be enough demand for people who want to participate in the sort of speculative market, which is, I mean, we can hope that it will be true. If there's enough demand for Starknet, maybe.
00:25:14.480 - 00:25:25.990, Speaker C: You can, even though it's not.
00:25:28.130 - 00:25:45.780, Speaker B: You could do that, but I'm not sure the time constants make sense. Right? So ethereum can, the price can go up by a factor of maybe two within a minute, right? And we're talking about maybe an hour, so maybe we don't have enough. So maybe that's too quickly for us.
00:25:47.590 - 00:26:38.070, Speaker C: I agree that we just shield the user from all these complex dynamics, but in the worst case, when the network is basically not in the good path, and we have this two x kind of volatility, then it does make sense to make the user aware precisely for what you want to, exactly what will happen in an hour. We have a way for the proverbs.
00:26:40.060 - 00:27:04.160, Speaker B: So I think as a user, you basically are aware that you get l one finality, on the average within an hour, and the worst case within 10 hours. Okay? So you know, that's the situation. You usually get your 1 hour, but sometimes you are aware of it, that sometimes it's going to deteriorate, right? That's basically what's going to happen. And for that you get a simple fee mechanism and presumably also relatively cheap.
00:27:04.580 - 00:28:04.992, Speaker A: I also think on the reverse side of the coin, it's not exactly clear what it means to have the user aware, because at the end of the day, it's more of a question of do you allow the protocol in the protocol, do you allow the sequencer to charge whatever the user is willing to pay or not. Do you understand what I'm trying to say? Yeah. So it would be very nice and very simple if everyone paid the same price for a unit of l one gas in the same block. But the direction you're going in is a direction where there is a market on l one gas, which is something we would like to abstract away from the user because otherwise you now have two parallel markets. And we just wanted to have a market for the l two gas. So this would not be ideal. Okay, so, yeah, sorry, how is it made? I think this is mostly a question for wallets.
00:28:04.992 - 00:28:08.212, Speaker A: I mean, we have a relatively, I guess it's.
00:28:08.276 - 00:29:24.660, Speaker B: Are you asking about specifically like the f one, the future gas for l one, or like the general question about fees, which will come. Okay, let's first talk when we're centralized and then see what happens when we're decentralized. So when we're centralized, basically the sequencer, or sequencer and prover, which is now the same entity, takes the risk upon himself. Sometimes they will lose, sometimes they will gain. On the average we want to be even now, what happens when we're in a decentralized world where the prover now is this extra entity and maybe is not willing to take upon himself the risk of the price going up or down? In that situation we should have, and we tend to have an outside futures market where some other entity exactly wants to take that risk upon himself. So the prover will not take the risk. The prover will have an extra external party that is going to actually pay the actual gas fees at proof upload time.
00:29:24.660 - 00:29:42.550, Speaker B: And that external party is exactly the one selling these gas futures. So they will demand what they want. There will be like a market, so there's competition there. And then the prover is not at all at risk because the proverb just gets his actual fees reimbursed.
00:29:43.050 - 00:30:11.810, Speaker A: The way I think of it is there's going to be a piggy bank that's funded by the futures market. And when provers or whoever wants to post something on l one, they pay from the piggy bank. It's not an expense they have, and it's not economic calculation they perform, it's just there for them. That's what you hope the future market does, that it swallows this thing. That guy knows something about. Starks are here.
00:30:16.340 - 00:30:32.530, Speaker C: Right now. The sequence prediction, when we decentralize it, will the algorithm for making this prediction, will it be part of the protocol or does the sequencer get to choose.
00:30:32.600 - 00:31:19.258, Speaker B: The algorithm has to be part of the protocol because otherwise the sequencer can manipulate the system. So the protocol will have to have within it some call to an outset to a formal futures market. And the sequencer will have to basically buy, if you wish, this futures gas in this market, and people can bid in it. So it will have to be part of the protocol because otherwise you're completely right. Yeah. Some kind of futures market. So one can ask whether we want like a generic futures market and just connect to it or something that's essentially a futures market really more closely tied to the protocol, but we will have to have something like that.
00:31:19.344 - 00:31:19.980, Speaker A: Yes.
00:31:24.960 - 00:31:37.084, Speaker C: And price per gas changes based on Ethereum. So whatever the future market is heading goes away.
00:31:37.222 - 00:31:38.230, Speaker B: Yes, absolutely.
00:31:39.720 - 00:31:49.630, Speaker C: Why not internalize it and say that otherwise?
00:31:52.610 - 00:32:04.094, Speaker B: So one thing you can't let the sequencer decide on how much he gets paid for the risk. You have to externalize it in a competition. And the sequencer will probably be chosen according to staking.
00:32:04.142 - 00:32:04.786, Speaker A: Right.
00:32:04.968 - 00:32:10.690, Speaker B: So you need some kind of objective way to have the marketplace.
00:32:14.380 - 00:32:44.448, Speaker A: Okay, cool. So I guess we can move on to the structure of the bid. So let's start with what's not going to happen. The way bids are structured in bitcoin. So if you want to send a bitcoin transaction, you basically give it a max budget. This is the total amount of bitcoin you can spend. And then because bitcoin has more or less fixed semantics, the miner who's processing the transaction can see how much bytes you're using, divide and determine how much they get paid per unit, and then they can sort transactions by profitability.
00:32:44.448 - 00:33:19.564, Speaker A: Now for us, the semantics are not fixed because we have smart contracts. So this is not the way to go. We need every bid to at least bid on the price per unit of every resource. And more or less, what we want is to complete this in the simplest way, so the bid structure will be, you bid on the price per unit for l one gas, the price per unit for l two gas, and the max amount you're willing to purchase of each resource. And that's it. That's all there is to it. Okay, I lied.
00:33:19.564 - 00:33:44.890, Speaker A: That's not all there is to it, because what I didn't mention is the tips. And the reason I didn't mention the tips is that I want to sort of weave them into the discussion about question number four, which is what is the charging policy? So it's like, is it pay your bid? Is it something like 1559? But as far as the basic structure of the bid. Does it make sense? Yeah.
00:33:49.100 - 00:33:51.660, Speaker C: And the sequence of charges is at time t?
00:33:51.810 - 00:33:56.910, Speaker A: Yes. Okay.
00:33:57.520 - 00:34:02.590, Speaker C: And it's based on match, then we're hoping in the future market follows it, right?
00:34:03.920 - 00:34:12.780, Speaker A: Yeah. Are you concerned? Yeah. Agreed.
00:34:14.880 - 00:34:45.820, Speaker B: You, I just want to say, I mean, just look, futures market sounds like a big thing, and when it's decentralized, it's not a trivial thing. But just consider what is our futures market, let's say today, when it's centralized so our future markets goes like this. We see what is the current price on Ethereum and say, oh, that's our prediction for the future. We're not even doing extremely clever learning right now. And that's not a bad futures market, right? On the average, we're doing fine. It's about break even, right. And it's very little computation.
00:34:45.820 - 00:34:53.890, Speaker B: Okay, so you can have a futures market that is not that complicated, but of course someone takes the risk, right?
00:34:59.700 - 00:35:20.240, Speaker A: Yeah. Okay, so I guess we can get to the charging mechanism now. So I guess again, I'll start with bitcoin. In bitcoin, the user experience is very simple and somewhat unpleasant. You bid whatever you think is right, and then you pay whatever you bid. Maybe you overbid. That's your problem.
00:35:20.240 - 00:36:03.132, Speaker A: You lose money, other people pay less. Nothing you can do. One of the things that ethereum set out to improve is exactly this problem of strategic biding, and I think it had two main candidates. One of them is a variant of a first price auction, which is called second price auction, and another is something I think more sophisticated, which is what they ended up implementing, which is called 1559. So I think we should not discuss second price or uniform price auctions yet. Maybe we'll have time at the end. Instead, I'll try and outline what 1559 does and then what portion of it we want to emulate, because we pretty much want to emulate it as well as we can.
00:36:03.132 - 00:36:49.144, Speaker A: So first of all, the goal of 1559 is to eliminate any need for strategic biding or almost any need for strategic biding on the user's part. And the way they do this is instead of having the price discovery happen at the mempool level, they want to have it happen at the protocol level. What does that mean? What it means is instead of the miner in bitcoin deciding what transactions they want to include, based on the mempool, which has not reached consensus, it's not visible to anyone else. It could, for all intents and purposes, be secret. We don't want that. Instead, we will measure the demand and the supply is we said it. But we will measure the demand for a block space by looking at the size of the blocks that have reached consensus.
00:36:49.144 - 00:37:08.852, Speaker A: So how does that work? You need two parameters. You need a max block size, and you need a target block size. Okay. In ethereum's case, the target is exactly half of the max. And now the mechanism is very simple. If you're over, the target, price goes up. If you're under the target, price goes down.
00:37:08.852 - 00:37:33.212, Speaker A: This is a simple way to discover the correct price by taking into account the demand against the supply. So that's in a nutshell. 1559. Behind the scenes, there are two main subtleties. One of them is that this thing doesn't always work. Specifically, the concern is if there is so much demand that everyone is paying. Okay, I think I forgot to say.
00:37:33.212 - 00:38:27.916, Speaker A: Yeah, I forgot to say an important thing. The main, I guess, feature of 1559 is that every block has a fixed price per unit cast. And this is the thing that's set by the price discovery. Right? So if you submit a bid, and let's say you're willing to pay, like, infinitely much east for a unit of gas, and the price per block is 30, it's impossible to charge you more than 30. You can only be charged exactly the price per unit at the block. So this exactly eliminates any need for strategic vote for strategic biding, right? You want to buy a cucumber, you think, how much do I value the cucumber? You post your bid and then you get change. If you overbid, you receive the difference back.
00:38:27.916 - 00:39:13.656, Speaker A: This is very different from bitcoin, where if you really like cucumbers, you're going to pay a lot of money for cucumbers, even though other people won't pay as much. Right? So that's the base. Now, 1559 has a fallback to a first price, which is called the tip. And the fallback is needed when there is so much demand that the base price doesn't change sufficiently fast. Right? The base price, the price per unit that's fixed throughout a block, it changes as a function of block time. If the demand increases much faster than blocks happen, then the price change is not responsive enough and people are basically waiting. Maybe you bid 1000 per unit and you bid 50 per unit.
00:39:13.656 - 00:39:53.156, Speaker A: And from the protocol's perspective, if the price is 50, then you're equal, which is not good, because you're willing to pay more money to get included faster. So that's why they have the tip. The tip is supposed to be sort of. That's how they call it, a priority tip. It's supposed to be a mechanism that allows people that really, really want to get in despite the high demand, and they can move forward in line. So that's the first part. And the second part, which is sort of a macro peculiarity of 1559, is the fact that you can't pay the revenue from the fees directly to the validators.
00:39:53.156 - 00:40:35.476, Speaker A: It actually is burned. So the ethereum validators, even though they process transactions, and these transactions have marginal costs and fees that they're willing to pay, these are not profits that directly go to the people that process the transactions. And the reason is to prevent these people from colluding. So what do, I mean? If I'm a validator, I want to get paid as much as possible. So it's in my interest to drive up the base price as much as I can. It's easy for me to do that because I can include transactions from me to myself. These cost me nothing, but they inject fake demand into the protocol, which nobody else can know that is fake, and that would drive up the base price.
00:40:35.476 - 00:40:43.530, Speaker A: That would result in a very bad user experience. So Ethereum has this macro peculiarity. Noam, do you want to say a few words about it, maybe?
00:40:44.380 - 00:40:46.760, Speaker B: No, I think you described it. Okay, yeah.
00:40:46.830 - 00:41:20.020, Speaker A: Okay, great. So inside of this story, there is a hidden assumption that makes things work, that the block times are more or less fixed. Where is this assumption come in? Or what happens if this assumption breaks? So for increasing prices, there is no problem. Okay, maybe I should go the other way around. What is the setting we're in now? Let's suppose we're now in a setting where blocks are not closed every fixed amount of time. They're only closed when they're relatively full. So think of it as like an aquarium with water dripping in.
00:41:20.020 - 00:41:58.172, Speaker A: You don't switch the aquarium until it's almost full of water. Okay, so block times are not fixed, they're a function of the demand. Okay, so what happens now? If there is a lot of demand, then the aquariums fill quickly. They're switched quickly, so the price responds quickly. It increases quickly. So when you want to discover a price upwards, it works very well, even better than fixed block times. The problem is what happens in the other direction? The other direction is actually a big problem because maybe people bid up to a pretty high price and now the demand disappeared.
00:41:58.172 - 00:42:32.940, Speaker A: For example, there was an NFT drop, it was over. Or people realized that they don't care that much about nfts and they stopped showing any interest. And now everything people want to do on starknet is, God forbid, only buy cucumbers. So the price per unit gas people are willing to pay is very low now. But it doesn't help because we're still waiting for the aquarium to fill. And until it fills, the price is still the high price from before. So this is a problem because we either wait for the few people who are willing to pay a lot of money or we're stuck.
00:42:32.940 - 00:42:40.668, Speaker A: This is a pretty major disadvantage of this method, and we think it's going to be fine.
00:42:40.834 - 00:43:20.090, Speaker B: No. Okay, so let's see. Ethereum changes. The fees can go up or down by twelve and a half percent every block. So that's approximately 1% every second. And if you have standard block times, you do the calculation as they do, you see how much you're over or under compared to the thing. And because you have fixed block time, that's a good now when you're giving up on having fixed block times, as we want to do, at least in the beginning, because for extra efficiency, then you need to basically make sure that you're not counting extra under or over target for a block, but rather per second.
00:43:20.090 - 00:43:57.144, Speaker B: So for example, you can decide that you want to go up or down by, let's say at most 1%/second to be approximately in line with the ethereum parameters. Okay. And then if your block is 10 seconds, you can go up at most by 10%. If your block is, I don't know, 1 minute, then you can go down by now 60% or something like that, right. Because that sort of said that you had very low demand. That's why your block took so much time. Now probably if you're getting to the point of 60 seconds, that may give too bad the user experience because it's a large drop all at once.
00:43:57.144 - 00:44:02.360, Speaker B: So we're going to somehow limit the block time in a way that will make this acceptable.
00:44:05.270 - 00:44:09.026, Speaker C: After an increase in the l two gas price.
00:44:09.128 - 00:44:09.780, Speaker A: Yes.
00:44:13.340 - 00:44:15.096, Speaker C: How do they price their base when.
00:44:15.118 - 00:44:22.348, Speaker A: The demand is like going down, I think. I'm not sure I understood the question. Maybe. Can you repeat it?
00:44:22.434 - 00:44:24.808, Speaker C: So let's say the air to gas has decreased.
00:44:24.904 - 00:44:25.356, Speaker A: Yes.
00:44:25.458 - 00:44:33.548, Speaker C: And now my bid for the gas price has to be at least that, right? Yes, but the demand is decreased.
00:44:33.644 - 00:44:34.290, Speaker A: Yes.
00:44:35.300 - 00:44:37.200, Speaker C: So I overpay.
00:44:40.420 - 00:45:06.956, Speaker A: The whole point is that you never care about the price, you only value bid, and you will be priced accordingly. So this is sort of the whole point of this type of mechanism that you never think about the state of starknet. You bid what you're willing to pay. Worst cases you pay what you are willing to pay, but in the happy case, you will get a refund because that's not the actual price or you.
00:45:06.978 - 00:45:14.270, Speaker B: Won'T even be charged. Right. So what you're actually charged, that's the block price. Even if your own bid was much higher. Yeah, that's the whole point.
00:45:15.120 - 00:45:34.910, Speaker C: This problem that you mentioned was block getting stuck because the gas fees are too high for new transactions to happen. How can that happen? Because you just get new transactions that whatever was the earlier level, but there's no lower bomb.
00:45:40.710 - 00:45:44.920, Speaker A: You cannot include transactions that are not willing to pay the base price.
00:45:47.930 - 00:46:05.130, Speaker B: Even in ethereum you have the same problem. Suppose it was the speak. Now the price is, I don't know, $10 for something and you're willing to pay only one cent. You will have to wait until the base price goes all the way down. So that's maybe a factor of 1000. It can take you, I don't know, a few minutes. Right.
00:46:05.130 - 00:46:16.670, Speaker B: So anyway, you will have to wait until the base price goes down. Even though there is enormous amount of demand at very low prices. The protocol, by design, doesn't change the price immediately, it just goes gradually.
00:46:24.800 - 00:46:31.884, Speaker A: You bound the block time from above. It's just. Yeah, exactly.
00:46:32.002 - 00:46:35.180, Speaker C: In the end, it kind of ends quite as a dynamic.
00:46:50.170 - 00:46:50.920, Speaker B: Exactly.
00:46:51.390 - 00:47:14.258, Speaker A: In a sense, it's an interesting take on it, because what you have in this dynamic way, in this dynamic setting is you have a mechanism that is really good at dissipating congestion because prices increase really quickly, but it's not as good at dropping them to invite people back after the congestion has been lost. So Ethereum doesn't behave exactly in that way.
00:47:14.344 - 00:47:27.320, Speaker B: You want like an upper bound on block size anyway, just for validity, finality. Right. But making the prices not too jumpy is an additional reason why you want an upper bound now on block time.
00:47:36.330 - 00:48:11.936, Speaker A: So the problem there is if you say that the base price decreases with time, then it's. Yeah, but during this time where the price drops, there are no blocks being created. Then you're back to the world where the price setting is. The inclusion is based on the mempool. Right. You're no longer judging what the price should be according to things which have reached consensus. Yes, but the auctioneer can't be trusted.
00:48:11.936 - 00:48:23.150, Speaker A: So you don't know what the sequencer is doing behind the scenes. Is it filling up its mempool with transactions from it to itself and keeping the price high? You have no idea what's going on. Yes, exactly.
00:48:23.520 - 00:48:41.650, Speaker B: Your dilemma is within a block, are you allowing yourself to have variable different prices or not. If you're allowing that to yourself, then it's not that the price is fixed according to observable, agreed upon consensus thing. And if you're not, then you have exactly the problem between.
00:48:44.500 - 00:49:17.816, Speaker A: Okay, so I think I want to end with two threads. One of them is we said that we have this magic 1559 with variable block times. But in 1559, the ethereum version, we know what the parameters are. The parameters are max block space and target block space. Here there is no point in setting such a thing because the block size is variable. So how do you define, what exactly is the adjustment rule? That's one question. How do you define this variable 1559 formally? And nom will answer that because he made the formula.
00:49:17.816 - 00:49:22.396, Speaker A: So that's one. And the second is, maybe I'll start with it because it's going to be short.
00:49:22.498 - 00:50:20.176, Speaker B: Okay, so what would be the formula for that? So let me write it in a way that can be understood. So you're going to have basically an important parameter, which is r. Let's say, call it r, which is the percent change, max percent change per second. Let's say 1%/second and then you're going to multiply your price by something that look like e to the power of r times t times a number that goes between negative one and one. Okay, so what does that mean? So if your block time is t and you're allowing yourself x percent per second, then this is basically giving you how much is the maximum that you can change up or down. I'm putting that in the exponent. But e to something small enough is like one plus, that's something small, or one minus, that's something small.
00:50:20.176 - 00:50:43.510, Speaker B: And then you need a little expression here that basically if you're at zero and your target is something you want negative one, you want the price down to go all the way down. If you're at target, you want it to be exactly zero, nothing to change. And if you're at the top, then you want it to go all the way to one. And that you put in a linear, simple linear kind of formula that gives you that kind of thing.
00:50:45.630 - 00:50:51.246, Speaker A: Right? So it's like a flux based thing. It doesn't require block times to be fixed. Yeah.
00:50:51.268 - 00:51:05.230, Speaker B: And by the way, we wrote it like an e to the something rather than one plus x times one plus y and so on. And also in ethereum, they're sort of talking to do like the right mathematical way rather than almost the same easier formula.
00:51:05.310 - 00:51:38.510, Speaker A: Yeah. And this small change is motivated by a concrete problem. Or maybe not concrete, but hypothetically concrete. In ethereum, if you have empty blocks and then full blocks, and then the even blocks are empty and the OD ones are full, then the behavior doesn't exactly balance itself out. So strange things happen. The base price will drop to zero eventually. And if you go with the nOm's proposal, then it exactly cancels out, because e to the a times e to the minus a, they just cancel.
00:51:40.210 - 00:52:03.880, Speaker B: Mathematically, one plus x times one minus x, which what Ethereum does is slightly less than one. But e to the x times e to the minus x is exactly one. Not that important, really, because things do even out anyway, but just for mathematical elegance, and we sort of need that for mathematical elegance for the, once you have variable block times, it makes much more sense to write it this way.
00:52:05.130 - 00:52:45.150, Speaker A: What it's what you get when you take the limit of one plus something small to the power of something large. Okay, so I figured we should, I mean, I think we should be wrapping up. So I guess two things to say. One is a small anecdote about how Ethereum's 1559 actually was biting us in the ass for a while, and we were paying a lot of money for posting l one state updates. And then we changed it and saw with our own eyes that we stopped losing money. And the other is sort of where you can participate in these discussions. And maybe advisors suggest improvements to our thoughts.
00:52:45.150 - 00:53:15.678, Speaker A: So maybe the second one is easier. It's just on the community Forum, anyone can go. And we really read those things, so if you have any ideas, we would really welcome them. And for the anecdote, so it's roughly like this. We have a proving system approving service, which is called Sharp. And this thing takes care of handling all these recursive trees that take many small proofs and aggregate them into large proofs. But there is actually another important thing that sharp does.
00:53:15.678 - 00:53:50.022, Speaker A: Sharp is the thing that sends all the l one transactions with the data availability. And mildly speaking, there is a shitload of these transactions. There are really many of them, and they're very expensive. And up until recently, Sharp was sending many, many transactions in a very narrow time window. So it was basically flooding ethereum with demand. And the effect this had is that we were actually spiking the price for ourselves by sending it so quickly. So we were shooting ourselves in the foot.
00:53:50.022 - 00:54:21.630, Speaker A: And as soon as we spread out these transactions into, let's say, we were sending roughly 150,000,000 gas in like a minute or two, and then we spread it out to 15 minutes, and we saw a big difference in our own expenses. You can interpret it in different ways, but at the very least, it says that 1559 works tangibly. We saw the impact. We felt it in our wallet. Yeah, I guess that's all we have. Norm, do you want to add anything?
00:54:21.700 - 00:54:23.070, Speaker B: That's it. Well, thank you all.
00:54:23.140 - 00:54:24.400, Speaker A: Yeah, thank you.

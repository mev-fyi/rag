00:00:03.050 - 00:00:28.674, Speaker A: Hi, everyone. Welcome to Unchained, your no Hype resource for all things crypto. I'm your host, Laura Shin, a journalist with over two decades of experience. I started covering crypto five years ago, and as a senior editor at Forbes, was the first mainstream media reporter to cover cryptocurrency full time. Subscribe to Unchained on YouTube, where you can watch the videos of me and my guests, go to c. Unchainedpodcast and subscribe.
00:00:28.722 - 00:00:38.680, Speaker B: Today, Crypto.com is waiving the 3.5% credit card fee for all crypto purchases until the end of September. Download the crypto.com app today.
00:00:39.450 - 00:01:03.978, Speaker A: This is the fourth installment in the Why Bitcoin Now series, which takes a closer look at bitcoin in the context of larger macroeconomic forces such as the pandemic and geopolitical moves happening in crypto. My guests for today are Adam Back, the inventor of HashCash and the co founder and CEO of Blockstream, and David Shaw, the inventor of Ecash and the co founder and CEO of Elixir. Welcome, Adam and David.
00:01:04.154 - 00:01:06.658, Speaker C: It's great to be here, or nice to see you.
00:01:06.744 - 00:01:08.450, Speaker D: Yeah, likewise. Good to be here.
00:01:08.600 - 00:01:46.190, Speaker A: So just a quick note before we begin. I've been a little bit under the weather. I've managed to gather the fortitude to do this episode. Hopefully it will all turn out fine, but I just wanted people to know that's what was happening while I was trying to prepare for this. All right, so let's start with the first question. How did you both become enamored with the idea of digital currency at a time when that was something that wasn't even really on the radar of anybody in the world and the Internet wasn't even really a big thing? And why don't we start with you, David?
00:01:47.010 - 00:01:56.914, Speaker C: Well, sure. Well, in 1977, in the spring, I.
00:01:56.952 - 00:02:10.182, Speaker E: Moved to Berkeley to start my PhD in computer science. Well, I was transferring, actually. I had a Regents four year graduate fellowship at UCLA. But I decided that Berkeley was more.
00:02:10.316 - 00:02:16.662, Speaker C: My kind of place. So I moved to Berkeley and, know.
00:02:16.716 - 00:02:29.926, Speaker E: Really focused on privacy and trying to foresee how the digital world would play out. And I realized that privacy was a.
00:02:29.968 - 00:02:40.190, Speaker C: Key ingredient in that. And I started developing a few technologies to see where this would all go.
00:02:40.260 - 00:02:42.142, Speaker E: And the first one I started with.
00:02:42.196 - 00:02:50.690, Speaker C: Was actually voting, and which more or less immediately led to what's called mixed networks today.
00:02:50.760 - 00:02:57.878, Speaker E: And that's something I published in 79 as my master's thesis and then appeared in CACM in 82, I think.
00:02:57.884 - 00:03:02.774, Speaker C: But it's pretty well referenced work, and.
00:03:02.812 - 00:03:13.530, Speaker E: Many people have implemented this over the years. It was put it in the public domain, and it's the only real way that's practical at all to create what.
00:03:13.600 - 00:03:16.394, Speaker C: We call a large anonymity set, which.
00:03:16.432 - 00:03:21.822, Speaker E: Is the figure of merit in any kind of privacy system. Right. It's like, how many people are you.
00:03:21.876 - 00:03:25.854, Speaker C: Actually anonymous among, assuming that the bad.
00:03:25.892 - 00:03:28.542, Speaker E: Guys can see everything that everyone sends to everyone else?
00:03:28.596 - 00:03:31.738, Speaker C: That's the threat know, and we learned.
00:03:31.754 - 00:03:41.918, Speaker E: From Snowden now that that's the real threat model. So that was kind of where I started. I thought, yeah, this is really important. If the government can see who talks.
00:03:41.934 - 00:03:46.618, Speaker C: To who and when, then you don't.
00:03:46.654 - 00:04:09.766, Speaker E: Really have a basis for being a participant in a democracy. This could be kind of a chilling thing. And so then the next step to come to your question about money was, well, then I thought, well great, so I can participate in this upcoming internet thing, or the future digital world. We didn't know exactly how it was going to play out in the late.
00:04:09.798 - 00:04:14.190, Speaker C: 70S, but I'll need some way to.
00:04:14.260 - 00:04:17.694, Speaker E: Pay things and be paid to do things.
00:04:17.812 - 00:04:27.426, Speaker C: And if that payment system allowed the linking of who's paying who to be.
00:04:27.528 - 00:04:42.086, Speaker E: Recognized by people listening in on the network, then it would undo all of what we call traffic analysis protection, now called metadata Shredding. The hiding of who talks to who.
00:04:42.188 - 00:04:45.746, Speaker C: In the messaging system would be obviated.
00:04:45.778 - 00:04:55.402, Speaker E: It would be undone by learning who pays who, because then, you'd know anyway, so I thought, well, we need a payment technology that will work in this.
00:04:55.536 - 00:05:03.278, Speaker C: Privacy protective metadata shredding sphere. And so that's when, let's say in.
00:05:03.284 - 00:05:17.394, Speaker E: The early eighty s, I invented Ecash, which was a privacy protecting digital bearer instrument. And that's something that I don't think.
00:05:17.432 - 00:05:19.730, Speaker C: People have really recognized.
00:05:20.390 - 00:05:41.354, Speaker E: In some sense, you could call it bitcoin zero, but it has certain advantages over Bitcoin, in that of course there's very strong privacy that you couldn't break even with unlimited computing power. And then it also had the property that when you had this money, no one could take it away from you.
00:05:41.392 - 00:05:45.946, Speaker C: So nowadays you could change things on.
00:05:45.968 - 00:06:19.462, Speaker E: The chain if you really want to. Sometimes it happens, but with Ecash, there'd be no way to take money away from you, because you would have these digital signatures on, serial numbers that you chose at random, and no one would see them. Even if they had quantum computers or unlimiting computing power, they couldn't figure out which serial numbers you chose at random and have the signatures on, so you would be protected in the holding of your money. So it was a digital bear instrument. No one had ever thought of anything like that. That was a really big deal.
00:06:19.596 - 00:06:21.846, Speaker C: So that's how I came to it.
00:06:21.948 - 00:06:34.918, Speaker A: Okay, yeah, we'll dive a little bit more into e cash in a moment. Adam, what about you? How did you get into digital currency so early on, before anything like Bitcoin was on the scene?
00:06:35.094 - 00:06:42.478, Speaker F: So I started a PhD in 1991, and I guess the year before that I had a friend who's doing a.
00:06:42.484 - 00:06:47.162, Speaker D: Master'S degree, and this is at University of Exter.
00:06:47.226 - 00:06:50.030, Speaker F: We had a distributed systems group with.
00:06:50.100 - 00:06:54.358, Speaker D: Some parallel hardware, so lots of processors.
00:06:54.394 - 00:06:56.146, Speaker F: High speed interconnects, and it's a kind.
00:06:56.168 - 00:06:58.674, Speaker D: Of interesting challenge to program those things.
00:06:58.712 - 00:07:17.462, Speaker F: And that was the topic of my PhD actually initially was more about distributed systems. So I came to know about Bisensai and general's problems and things like that before other people who maybe heard about that topic first in bitcoin or cryptocurrency context. So in any case, my friend there.
00:07:17.516 - 00:07:20.806, Speaker D: Was trying to accelerate the RSA encryption.
00:07:20.838 - 00:07:43.742, Speaker F: Algorithm on these parallel hardware because at the time CPUs were a lot slower than they are now and even to encrypt messages was somewhat slow on a general desktop processor and that kind of thing. So I got interested in got to know the technology before the kind of the very interesting balance of power change.
00:07:43.796 - 00:07:46.066, Speaker D: Of being able to have end to.
00:07:46.088 - 00:07:55.038, Speaker F: End secure messaging that governments couldn't encrypt. And so so it wasn't long after that that PGP came out and PGP had that very interesting property.
00:07:55.224 - 00:08:03.254, Speaker D: I think the Internet itself brought a lot of kind of freedoms and more.
00:08:03.292 - 00:08:17.690, Speaker F: Direct participation, for example, in media and blogging and conversations. It's less hierarchical initially, some government friction and adapting to the concept that while they could maybe influence a large media.
00:08:17.760 - 00:08:20.502, Speaker D: Organization, it was very difficult to influence.
00:08:20.566 - 00:08:32.754, Speaker F: Millions of independent voices with their own views on things. And of course that's progressed a lot since the but from the interest in PGP I joined the Cipherpunks List, which.
00:08:32.792 - 00:08:35.026, Speaker D: Is basically a group of people interested.
00:08:35.128 - 00:08:37.010, Speaker F: In technology like that.
00:08:37.080 - 00:08:46.530, Speaker D: So Internet technology with some kind of privacy benefit or change in the balance of power.
00:08:46.600 - 00:08:48.470, Speaker F: So the kind of things that Snowden.
00:08:49.210 - 00:08:52.822, Speaker D: Came to blow the whistle on people were suspicious of.
00:08:52.876 - 00:09:08.666, Speaker F: And these were the kinds of people that were know, is the government really actually recording all this stuff? And there was a whole political battle about the banning of encryption actually, or the banning of export of encryption from.
00:09:08.688 - 00:09:13.706, Speaker D: Some countries, or discussion about countries banning.
00:09:13.738 - 00:09:20.494, Speaker F: Encryption software that the national security apparatus couldn't decrypt. And some of those things pop up.
00:09:20.532 - 00:09:37.314, Speaker D: Even decades and decades later. So it's kind of disappointing that that's still ongoing. But I think my view was that we have in laws and regulations, established rights, and it's a kind of natural.
00:09:37.362 - 00:10:05.246, Speaker F: Balance in society that for respect and privacy and personal independence and so forth, that you have various rights, but they become harder to enforce or eroded by the mechanisms of the Internet. So those are some of the things that David was talking about know actually to even hold on to the rights that you naturally assume and expect in the physical world. Some of those start to get eroded because ISPs are keeping logs initially for.
00:10:05.268 - 00:10:08.238, Speaker D: Service reasons, but once they're recorded, then.
00:10:08.404 - 00:10:12.640, Speaker F: People start to ask for access to the logs different law enforcement and so on.
00:10:13.270 - 00:10:21.806, Speaker D: I got interested in privacy technology and spent much of a time when I should have been working on distributed systems.
00:10:21.838 - 00:10:28.098, Speaker F: Actually reading all kinds of applied cryptography papers, including some of David Chaum's papers.
00:10:28.194 - 00:10:30.774, Speaker D: And implemented some of them.
00:10:30.812 - 00:10:35.526, Speaker F: In cryptographic libraries and actually implemented an.
00:10:35.548 - 00:10:40.390, Speaker D: Ecash library that implements David's Ecash protocol.
00:10:40.550 - 00:10:50.666, Speaker F: The online version, not the more complicated curtain shoes offline version, and also a related system by Stefan BRANZ, which is.
00:10:50.688 - 00:10:52.542, Speaker D: Just another variety of that.
00:10:52.596 - 00:10:54.058, Speaker F: So I implemented both of those systems.
00:10:54.074 - 00:10:57.198, Speaker D: In a library and there was a.
00:10:57.204 - 00:11:06.538, Speaker F: Great deal of interest in privacy technology, but all of the networks were operated by volunteers. So the cost of the servers, the cost of the bandwidth was volunteer.
00:11:06.714 - 00:11:08.658, Speaker D: And it was a big gap in.
00:11:08.664 - 00:11:12.514, Speaker F: The technology that there was no way to pay for anything. And as David said, as soon as.
00:11:12.552 - 00:11:16.054, Speaker D: You whip out your credit card and.
00:11:16.092 - 00:11:19.190, Speaker F: Pay for something, now all the privacy has been undone and gone.
00:11:19.260 - 00:11:24.038, Speaker D: So clearly electronic cash was needed.
00:11:24.204 - 00:11:44.350, Speaker F: So there's a lot of excitement about David's company digicache at the time, which was deploying the technology that he talked about some decades after he first published the blind signature paper. People wanted to see that deployed in some way or other and that was for a time deployed in a kind of demo server.
00:11:44.770 - 00:11:45.520, Speaker D: But.
00:11:47.330 - 00:11:49.406, Speaker F: I think bitcoin, which came very.
00:11:49.428 - 00:11:58.286, Speaker D: Much later, struck approached problem from a different angle, which is it was more distributed but less private and the reasons.
00:11:58.318 - 00:12:01.746, Speaker F: For the distribution or decentralization are sort.
00:12:01.768 - 00:12:05.118, Speaker D: Of censorship, resistance, survivability.
00:12:05.294 - 00:12:25.494, Speaker F: So it didn't depend for its viability on any group of individuals or companies, right? It would just keep operating as a fabric. So there's not really any prospect of the internet disappearing because there are so many different service providers and operators. And so it is with bitcoin that there are so many different companies offering integration services and wallets and doing mining.
00:12:25.542 - 00:12:28.394, Speaker D: And providing various infrastructure services.
00:12:28.512 - 00:12:30.426, Speaker F: So bitcoin becomes much more of a.
00:12:30.448 - 00:12:45.490, Speaker D: Fabric and so more survivable, but it's not as good from a privacy point of view. So with my kind of interest in applied cryptography, when I saw bitcoin and.
00:12:45.560 - 00:12:46.818, Speaker F: Started taking more of an interest in.
00:12:46.824 - 00:12:52.546, Speaker D: It, it struck me that now that it was here and it addressed sort.
00:12:52.568 - 00:13:02.946, Speaker F: Of robust survivability that maybe there would be some way to improve the privacy. And of course there have been incremental improvements over time. But I proposed something called confidential transactions.
00:13:03.058 - 00:13:07.366, Speaker D: Which is a way to encrypt the.
00:13:07.388 - 00:13:18.870, Speaker F: Values of the how many coins are being transferred, but still have it be publicly auditable. So it turns out you can do that using zero knowledge proofs and the challenge is to make it compact and efficient.
00:13:18.950 - 00:13:24.650, Speaker D: So that has been implemented in sort of related systems.
00:13:24.730 - 00:13:28.714, Speaker F: So like side chains to bitcoin, so kind of modular layer twos to bitcoin.
00:13:28.842 - 00:13:33.374, Speaker D: And some other systems. And there are a variety of privacy.
00:13:33.422 - 00:13:37.170, Speaker F: Technologies in surrounding cryptocurrencies which are interesting.
00:13:37.240 - 00:13:39.506, Speaker D: And I hope that one day as.
00:13:39.528 - 00:13:43.390, Speaker F: The technology matures, bitcoin itself will incorporate.
00:13:43.470 - 00:13:47.106, Speaker D: More strong privacy either in layer one.
00:13:47.128 - 00:13:50.470, Speaker F: Or in a layer two. So it's came at it from a.
00:13:50.540 - 00:13:58.422, Speaker D: Privacy technology perspective I think Bitcoin adds one other dimension, which was not something.
00:13:58.476 - 00:14:00.040, Speaker F: I was focusing on before.
00:14:00.350 - 00:14:03.146, Speaker D: I think that in the early to.
00:14:03.168 - 00:14:17.758, Speaker F: Mid 90s onwards, there are a lot of people interested to try and find a way to deploy electronic cash, either using Troms protocols or other protocols or independently, and finding it difficult, technically challenging to do that.
00:14:17.844 - 00:14:21.786, Speaker D: And so I was part of that kind of group of researchers like Hal.
00:14:21.818 - 00:14:26.114, Speaker F: Finney and Nick Sarbo and other people that were discussing those things.
00:14:26.312 - 00:14:37.682, Speaker D: One thing that Bitcoin adds that wasn't to my mind, the major concern at the time is a digital gold like aspect, right?
00:14:37.816 - 00:14:45.318, Speaker F: That it would have also some kind of monetary reform or return to a gold standard, but in a digital format. We were looking at it from the.
00:14:45.324 - 00:14:50.986, Speaker D: Point of view we need electronic money with strong privacy and bearer properties, but.
00:14:51.008 - 00:14:52.794, Speaker F: If that would have been denominated in.
00:14:52.832 - 00:14:55.914, Speaker D: US dollars or some other stable large.
00:14:55.952 - 00:14:57.562, Speaker F: Country currency, we'd have been very happy.
00:14:57.616 - 00:15:00.762, Speaker D: And felt that we'd achieved the objective.
00:15:00.826 - 00:15:07.120, Speaker F: So Bitcoin adding that is a new dimension and I think likely helped its.
00:15:07.490 - 00:15:09.440, Speaker D: Popularity and adoption as well.
00:15:09.970 - 00:15:49.514, Speaker A: Yeah, super interesting points, and we'll dive into some of these a bit more later. But one other thing I wanted to ask about those early days was, was there a sense at that time that it was kind of like an active group of people that were all working on this? Or did it? Have this feeling more of people that were kind of loosely connected on the Internet and then each of you were sort of tinkering on your own. I'm just trying to get a sense of the feeling during those days, whether or not it was something that felt like it was almost imminent, or if it really felt like, well, all these people are trying different things, but it's probably kind of far off.
00:15:49.552 - 00:15:53.182, Speaker C: In the future, maybe I could speak.
00:15:53.236 - 00:16:06.834, Speaker E: To that, Adam, because I think we're talking about two different time frames here. Totally right. Adam's talking about the 90s. I'm talking about I invented all this stuff in the late seventy s and published it in the early eighty s.
00:16:06.872 - 00:16:18.870, Speaker C: And I did another thing which was really fundamental, that opened up this whole discussion. Adam mentioned the crypto wars without calling.
00:16:18.940 - 00:16:22.614, Speaker E: Them that, but know, governments were in.
00:16:22.652 - 00:16:27.058, Speaker C: This mode, know, saying that you couldn't.
00:16:27.154 - 00:16:40.426, Speaker E: Export cryptographic software or that you couldn't in fact, they were putting secrecy orders on researchers in the United States. People I knew independently created ideas, and the government come to them.
00:16:40.448 - 00:16:41.802, Speaker C: You can't talk about that.
00:16:41.936 - 00:16:46.766, Speaker E: It's a national security. They're going to put you in prison if you talked about it.
00:16:46.868 - 00:16:53.314, Speaker A: Well, Adam, you have your famous T shirt. The RSA T shirt. Can you talk about that for a second?
00:16:53.352 - 00:17:01.780, Speaker F: Because that yeah, it's related to what David just so well, I was living in the UK at the time, and so.
00:17:03.510 - 00:17:07.278, Speaker D: Various countries had different export controls.
00:17:07.294 - 00:17:13.330, Speaker F: And regulations, but the US was the largest exporter of software, the nexus of a lot of Internet software development.
00:17:13.410 - 00:17:20.254, Speaker D: And so the fact that it had this non expert policy on cryptography was a concern.
00:17:20.322 - 00:17:33.254, Speaker F: It struck me as kind of silly because I set about making a very small program that would nominally be unexplortable and it's like three lines of perl code or something, so it's very small. And I made a T shirt. Substantive T shirts.
00:17:33.302 - 00:17:38.046, Speaker D: And there are people did other things with, know, like got a tattoo, know.
00:17:38.068 - 00:17:43.102, Speaker F: Put it as a signature line on the email and so so, and I think there was a law professor who.
00:17:43.236 - 00:17:44.526, Speaker D: There was a procedure where you could.
00:17:44.548 - 00:17:57.090, Speaker F: Ask if your software was exportable. So there was a law professor who was trying to fight this export regulation through the US courts, and he asked for approval to export this three lines of pearl, and they said he couldn't.
00:17:57.250 - 00:18:00.354, Speaker D: And it's also very anachronous because there's.
00:18:00.402 - 00:18:04.678, Speaker F: The very strong US free speech and.
00:18:04.684 - 00:18:08.834, Speaker D: It particularly applies to written to books.
00:18:08.882 - 00:18:19.580, Speaker F: You shouldn't ban books and things like that. And so there were people that put the PGP source code in books and freely exported them, but to do it electronically would have been illegal or something.
00:18:20.030 - 00:18:22.026, Speaker D: It struck me as kind of sort.
00:18:22.048 - 00:18:29.710, Speaker F: Of silly, but at the same time serious. It was hampering business and it was meaning that de facto, a lot of software wasn't as secure as it could have been.
00:18:29.860 - 00:18:32.046, Speaker D: So it was a way to sort.
00:18:32.068 - 00:18:41.566, Speaker F: Of put some political commentary on, you know, here's the de minimis thing that they would apparently consider to be unexploreable. So anyway sorry, continue with your line of thought there, David.
00:18:41.758 - 00:18:52.278, Speaker A: Well, but just to make clear for people, like, you printed it on a T shirt and then so if people flew internationally with that T shirt on, then they were breaking this law. Is that the case?
00:18:52.444 - 00:18:54.918, Speaker D: I don't know. I mean, if you can export a.
00:18:54.924 - 00:18:59.834, Speaker F: Book and you export a T shirt and it's a bit of a gray area, I guess, but at least people.
00:18:59.872 - 00:19:01.978, Speaker D: Thought it was an amusing kind of.
00:19:01.984 - 00:19:06.586, Speaker F: Way to protest something that they were quite unhappy about. It was a serious thing because it.
00:19:06.608 - 00:19:17.214, Speaker D: Was impeding internet commerce, basically, because people didn't feel they could trust encryption. And it was also pushing jobs away from the US.
00:19:17.332 - 00:19:19.002, Speaker F: Now, there were people in Europe rating.
00:19:19.066 - 00:19:22.318, Speaker D: Cryptographic libraries because their US counterparts wouldn't.
00:19:22.324 - 00:19:31.634, Speaker F: Be able to export them, or international companies setting up offices in Europe to do applied cryptography implementations and things. So it was quite the inconvenience and.
00:19:31.672 - 00:19:34.914, Speaker D: It eventually got overturned, but not before.
00:19:34.952 - 00:19:44.246, Speaker F: There were test cases and a lot of drama. So the crypto wars, as David called it, yeah, that was a real thing in the 90s.
00:19:44.428 - 00:19:46.614, Speaker A: So, David yeah, we interrupted your line of thought.
00:19:46.652 - 00:19:54.522, Speaker E: What were you going to let's let me just turn the big old heavy TV camera back to when this all.
00:19:54.576 - 00:19:56.362, Speaker C: Was really in play.
00:19:56.416 - 00:20:28.086, Speaker E: So as I was saying, a number of my colleagues and friends had secrecy order placed on them by the United States government, which made it a federal crime to reveal what they were researching, even though they weren't drawing in any classified sources. So that's a doctrine that's sometimes referred to as born classified, which we have as an official policy in the United States when it relates to nuclear weapons technology, that makes a certain amount of.
00:20:28.108 - 00:20:33.046, Speaker C: Sense to guess, but to apply that.
00:20:33.068 - 00:20:41.306, Speaker E: To cryptography seemed a bit out of. So I was a graduate sun at.
00:20:41.328 - 00:20:45.878, Speaker C: Berkeley thinking about liberty in the digital.
00:20:46.054 - 00:20:48.810, Speaker E: World and what it would be like.
00:20:48.880 - 00:20:52.286, Speaker C: Because it's a lot more kind of.
00:20:52.468 - 00:21:22.390, Speaker E: Bistable because if everything's digital you could spy on everything pretty easily. Or I developed these technologies that would allow you to protect your privacy so it could go sort of one of the two ways. But all the privacy technology was based on encryption and special kinds of encryption that I developed. So I really pioneered a lot of that stuff and I think that's what inspired the cipherpunk movement. I mean, that's what everyone says. But the other thing that I think.
00:21:22.540 - 00:21:27.834, Speaker C: Really is very significant is that this.
00:21:27.872 - 00:21:40.810, Speaker E: All could have gone a very different way, because the National Security Agency, which is our main cryptographic authority in the United States for protecting secrets, and breaking codes.
00:21:40.970 - 00:21:45.582, Speaker C: They got a new director and this.
00:21:45.636 - 00:21:55.378, Speaker E: Fellow came in and he started writing letters to all the scientific associations like the ACM and the IEEE, which are.
00:21:55.384 - 00:21:59.246, Speaker C: The main ones for computer technology, telling.
00:21:59.278 - 00:22:02.030, Speaker E: Them that they should not have conferences.
00:22:02.110 - 00:22:11.058, Speaker C: Or even sessions at conferences that covered cryptography because this was an illegal export.
00:22:11.154 - 00:22:16.038, Speaker E: And that he was going to throw the full force of the US.
00:22:16.124 - 00:22:23.354, Speaker C: Government at them and unbelievable penalties would.
00:22:23.392 - 00:22:26.326, Speaker E: Accrue to them because this was totally illegal.
00:22:26.438 - 00:22:38.800, Speaker C: And with my perspective at how important all this encryption would be to deciding which way the world would go and.
00:22:39.250 - 00:22:45.506, Speaker E: Being a relatively, I don't know, Berkeley young guy caught up in the whole.
00:22:45.608 - 00:22:49.006, Speaker C: Atmosphere there and everything, I thought, there's.
00:22:49.038 - 00:22:53.886, Speaker E: Only one thing to do, and that is to organize a conference on cryptography.
00:22:54.078 - 00:22:57.798, Speaker C: But to do it secretly, not to use the phone.
00:22:57.964 - 00:23:05.430, Speaker E: So I did it all by in person conversations and I mailed out invitations.
00:23:06.010 - 00:23:08.886, Speaker C: To a bunch know, basically a guy.
00:23:08.908 - 00:23:19.370, Speaker E: Named Len Edelman who was a researcher from the RSA name, he had a list of printout in those days. Me and my girlfriend sat in the.
00:23:19.520 - 00:23:22.446, Speaker C: Know and we cut those out and.
00:23:22.468 - 00:23:35.426, Speaker E: Glued them onto these envelope and we mailed these things out in the paper mail. So there was a conference and most people interested in the field came to.
00:23:35.448 - 00:23:38.206, Speaker C: It and it was in Santa Barbara.
00:23:38.398 - 00:24:10.486, Speaker E: I stood up there on the stage and thanked everyone for showing up and I announced that since they paid $100 or whatever, it was $80 for the registration fee, that now they were, that was a membership fee in a new international association for cryptologic research. International scientific associations are protected by the United Nations. And so there was a bunch of people in the front row who registered for the conference as private individuals, not affiliated with any institution.
00:24:10.598 - 00:24:14.414, Speaker C: But they all happened to live in Laurel, Maryland, which, if you know anything.
00:24:14.452 - 00:24:34.110, Speaker E: About the NSA, that's where they all when I said know, these people all turned green. That was it. It was over. I said, OK, we're having our next event will be in Udina, Italy, and here's Henry Becker, he's going to be the chairman of that. That'll be in the spring.
00:24:34.190 - 00:24:35.670, Speaker C: And it was over.
00:24:35.740 - 00:24:48.842, Speaker E: So the government tried to make cryptography born classified and they threatened these big organizations and that scared them because those bureaucrats didn't have a lot of skin in the game.
00:24:48.896 - 00:24:51.770, Speaker C: But I felt it was just too important.
00:24:51.840 - 00:24:57.734, Speaker E: So I risked spending the rest of my life in jail to set cryptography.
00:24:57.782 - 00:25:05.920, Speaker C: Free, which I did, and I'm very proud of it. And at that conference I published the Ecash paper.
00:25:08.530 - 00:25:25.166, Speaker E: And that association, by the way, is very robust and exists to this day. It is probably the only real organization in the field of cryptography. It publishes a journal through spring of Erlag. All of its proceedings are published.
00:25:25.278 - 00:25:28.906, Speaker C: It has three annual conference, three conferences.
00:25:28.958 - 00:25:39.254, Speaker E: Every year in different parts of the world, plus half a dozen workshops. So it's the International Association for Cryptologic Research, it's called, and it has enough.
00:25:39.292 - 00:25:41.946, Speaker C: Money in the bank to weather the.
00:25:41.968 - 00:25:58.734, Speaker E: Pandemic, even if it has to pay for conferences for like a year or two. If no one comes, it can afford that. So we resisted joining these other scientific associations, so it's maintained a very independent and robust position and done a great.
00:25:58.772 - 00:26:03.886, Speaker C: Deal to facilitate and build up the.
00:26:03.908 - 00:26:09.022, Speaker E: Scientific community in the field. So this was a pivotal thing.
00:26:09.156 - 00:26:20.760, Speaker A: It's so fascinating. I love that story. So in a moment we're going to talk more about Ecash as well as hash cash. But first, a quick word from the sponsors who make this show possible.
00:26:21.770 - 00:26:48.702, Speaker B: How much in fees are you paying for your crypto purchases? Crypto.com is waiving the 3.5% credit card fee for all crypto purchases, which means you can buy crypto with a 0% fee. Apart from your crypto purchases, you can also get a great deal on food and grocery shopping too. Get up to 10% back on Uber, Eats, McDonald's, Domino's, Pizza, Walmart and many more when you pay with your MCO Visa card. No card on the Crypto.com app.
00:26:48.702 - 00:27:00.530, Speaker B: Buy gift cards and get up to 20% back from merchants like Whole Foods, Safeway, Burger King, Papa John's and Domino's. Download the Crypto.com app today and enjoy these offers till the end of September.
00:27:01.510 - 00:27:20.750, Speaker A: Back to my conversation with David Schom and Adam back. So David, you did allude to this briefly earlier. You created the Ecash system, which had as its currency cyberbucks. How did Ecash work? And you can also explain Digicache.
00:27:20.930 - 00:27:22.380, Speaker C: Okay, well, that's a lot.
00:27:22.830 - 00:27:43.190, Speaker E: Yeah, it's kind of a lot of stuff. But if you go to Chom.com, scroll down, there's projects, and one of them is the Ecash project. And you can see there's a whole DigiCash museum there. And so you can see all about the history of it and pictures of the people and all this stuff. And you can see, interestingly, the banners.
00:27:43.290 - 00:27:50.050, Speaker C: Of the original cyberbucks accepting shops on the Internet.
00:27:50.390 - 00:27:52.338, Speaker E: And so there's a whole bunch of them.
00:27:52.424 - 00:27:54.402, Speaker A: Do you want to list some of those for people?
00:27:54.456 - 00:28:01.814, Speaker E: I don't really remember them off top of my but you go there because you can click if you hover over them, if you're on a laptop, then it'll show the name.
00:28:01.852 - 00:28:03.846, Speaker C: And if you click through, you can.
00:28:03.948 - 00:28:10.620, Speaker E: See like from the Wayback machine, what their homepage looked like. So you can see all people selling interesting stuff.
00:28:11.230 - 00:28:13.434, Speaker C: So the deal was if you put.
00:28:13.472 - 00:28:22.762, Speaker E: Up a shop and accepted Ecash, I would give you 100 cyberbucks. And there was okay, we just said, well, we're going to have a million.
00:28:22.896 - 00:28:23.654, Speaker C: It was limited.
00:28:23.702 - 00:28:32.720, Speaker E: So the idea of a limited issue was something that a lot of people had talked to me about because a lot of people feel that's very important to do. So we did that.
00:28:34.470 - 00:28:37.618, Speaker C: It was a pretty successful thing.
00:28:37.704 - 00:28:57.160, Speaker E: But I think Adam will recall this. Back in those days, it wasn't that easy to install the client software and get it to work. And everyone had different versions of different operating systems. And computers were very slow for processing all this. And we were using modems and all that back in those.
00:28:58.590 - 00:29:01.626, Speaker C: It wasn't easy for us to make.
00:29:01.648 - 00:29:13.600, Speaker E: It a seamless experience on your smartphone or something. It was really something you had to want to do. So it was kind of hard to compete with credit cards and all that.
00:29:14.050 - 00:29:18.170, Speaker C: As the Internet just accelerated.
00:29:18.330 - 00:29:29.022, Speaker E: But what we did license and build for different banks, also their own system. So the largest bank in Europe at that time was Deutsche Bank.
00:29:29.166 - 00:29:31.746, Speaker C: And I went over there and I.
00:29:31.768 - 00:29:42.214, Speaker E: Talked to their board and they were all excited about it and they decided to back us. And people say DigiCash failed. Well, it's not really true. It was taken down because they were.
00:29:42.252 - 00:29:45.686, Speaker C: Willing to invest quite a lot more money in it.
00:29:45.788 - 00:29:49.754, Speaker E: And the people who got control of the company didn't want that.
00:29:49.872 - 00:29:50.874, Speaker C: They wanted to kill it.
00:29:50.912 - 00:30:18.750, Speaker E: So it was a sad thing, but Deutsche Bank was a very tough customer. If you can imagine a German bank, the biggest bank in Europe. Their data center was in an old bunker. It was several stories underground and they wanted every kind of backup and recovery and everything. So we had to build all this stuff for them. We satisfied them, which I think is quite an achievement. So it was a very industrial strength.
00:30:18.910 - 00:30:21.282, Speaker C: E cash banking system, if you will.
00:30:21.416 - 00:30:35.794, Speaker E: That attached to what are called current accounts or regular consumer bank accounts. And there were shops that were accepting and in those days, of course, it was before the euro, right? It was Deutsche Marx. And so you could use Deutsche Bank.
00:30:35.842 - 00:30:39.340, Speaker C: Issued Deutsche Marks and buy things online.
00:30:40.350 - 00:30:46.890, Speaker E: So we made all that for them. It was all Deutsche Bank branded. And then we had Mark Twain Bank in the US.
00:30:47.040 - 00:30:49.002, Speaker C: Which offered US dollars.
00:30:49.056 - 00:31:04.546, Speaker E: And they were an international currency bank, so they had some other they could do various conversions. So that was great. And then we had Advanced Bank in Australia, which I think was like the number two or three bank at that time. Now it's been merged in. They were issuing in Australian dollars and.
00:31:04.728 - 00:31:06.898, Speaker C: We had bunches of people wanting to.
00:31:06.904 - 00:31:14.114, Speaker E: Use it and starting to use it in various countries. I think my congressional testimony in the US.
00:31:14.232 - 00:31:18.306, Speaker C: Is maybe noteworthy, but I also spoke.
00:31:18.338 - 00:31:25.718, Speaker E: To a bunch of other governments and visited many central banks around the world. And I told people at that time.
00:31:25.884 - 00:31:28.154, Speaker C: What I really told them was if.
00:31:28.192 - 00:31:31.482, Speaker E: Your country would take the initiative and.
00:31:31.536 - 00:31:39.594, Speaker C: Issue its money in e cash, you could be the electronic commerce leader of the world.
00:31:39.712 - 00:32:26.842, Speaker E: This would be a tremendous economic opportunity for your country. And that's what I was pitching when I had that chance to speak to those, because I was invited to a lot of central banks and Visa International and Citibank and all these I was sitting there in the boardrooms and meeting the executives. They'd come to visit me and all this stuff. So, I mean, there was a lot of interest in what we were doing. I have boxes of press clippings from those days. Because when I announced, I did the first e cash payment, the first worldwide web conference from CERN to Amsterdam, and then I wrote a little press release, and this guy sent it out from the company and The New York Times picked it up. And Wall Street, it was all over the global media in about 48 hours.
00:32:26.842 - 00:32:28.666, Speaker E: And there was so much interest in.
00:32:28.688 - 00:32:31.626, Speaker C: The idea that a number itself could.
00:32:31.648 - 00:32:34.586, Speaker E: Be worth money that I was interviewed.
00:32:34.618 - 00:32:36.106, Speaker C: In all kinds of languages.
00:32:36.138 - 00:32:39.786, Speaker E: I don't even know what languages. I have a whole archive of videotapes.
00:32:39.978 - 00:32:43.022, Speaker C: Those big old videotapes of TV shows.
00:32:43.076 - 00:32:45.698, Speaker E: Where I was interviewed. And there was so much interest in it.
00:32:45.784 - 00:33:00.038, Speaker A: Yeah. And let's just look under the hood and talk a little bit about Ecash. So I believe that blind signatures were one of the breakthroughs. Can you just explain that?
00:33:00.204 - 00:33:01.080, Speaker C: Yeah, absolutely.
00:33:02.730 - 00:33:05.266, Speaker E: There are many kinds of digital signatures.
00:33:05.298 - 00:33:08.498, Speaker C: Digital signature is a pretty general term.
00:33:08.594 - 00:33:10.002, Speaker E: These days in its usage.
00:33:10.066 - 00:33:14.886, Speaker C: But one type is blind signatures.
00:33:14.918 - 00:33:16.086, Speaker E: And I invented.
00:33:16.118 - 00:33:23.306, Speaker C: Them especially for payments and Ecash. Now, actually, I was hoping that they.
00:33:23.328 - 00:33:42.786, Speaker E: Would be used in a whole range of other applications to do with what I call credential mechanisms. And I wrote this paper that appeared. It was mentioned on the COVID of Scientific American. It was also on the COVID of the Best Journal of Computer Science CACM at that time. You can see it on my website. It's another one of the little project things there at but you know, I.
00:33:42.808 - 00:33:48.790, Speaker C: Created a whole concept for how you could use the mixing to have perfect.
00:33:48.940 - 00:33:52.946, Speaker E: Privacy in who you talk to and Ecash to make your payments.
00:33:53.058 - 00:34:05.658, Speaker C: And then the blind signatures could be used to basically prove things about you without revealing who you are. And so, like classic, say if a.
00:34:05.664 - 00:34:43.286, Speaker E: Kid'S at a bar and they want to or somewhere they want to get in, they want to say that prove that they're old enough or they have a driving license or they're from a different state or whatever, but they don't want to give their address and all this other stuff. Well, that's what you could do with a credential mechanism. You could prove exactly that you qualified according to whatever to one way, but you wouldn't have to reveal which way that was. You would just reveal the exact one bit that you were qualified. You give a signature that would prove that irrefutably I found a way that basically turned the databases that companies would have about you inside out so that.
00:34:43.308 - 00:34:54.410, Speaker C: Now you maintained your own information about yourself. And whenever they would normally ask their own database a query, they would have to ask you and you would prove.
00:34:54.830 - 00:35:08.826, Speaker E: The answer was correct. You give the answer and prove it was correct if you wanted to answer it. So that was a whole comprehensive thing. So blind signatures went a little bit beyond. I was hoping that Ecash would be like a Trojan horse. People would start using it for payments.
00:35:08.938 - 00:35:10.762, Speaker C: And they'd start to say, hey, wait a minute.
00:35:10.906 - 00:35:19.042, Speaker E: I don't have to reveal my identity to make payments, but if I want to, I can prove that that shop got my money. So that's pretty cool.
00:35:19.176 - 00:35:20.466, Speaker C: Maybe I could use that to check.
00:35:20.488 - 00:35:50.794, Speaker E: Out library books or maybe for these other things. And then the credential mechanism would kind of grow organically. And that's why I went to a lot of effort to publish it in these mainstream publications to try to really distill it and work with artists to get the concepts across and all that. The idea of a blind signature is very simple. In those days, we had carbon paper. I don't know if people these days know what carbon paper is. Yeah, we have carbonless carbon paper, I guess you know about that.
00:35:50.794 - 00:36:00.014, Speaker E: It copies through. So basically the easy way to understand Ecash, that's very close to the reality of it. The blind signature is that let's just.
00:36:00.052 - 00:36:02.782, Speaker C: Say I take a piece of paper.
00:36:02.836 - 00:36:04.174, Speaker E: And I write a random serial number.
00:36:04.212 - 00:36:05.602, Speaker C: On it that only I know.
00:36:05.736 - 00:36:13.122, Speaker E: And I put an envelope with some carbon paper inside or carbonless lining or whatever. I give it to my bank and.
00:36:13.176 - 00:36:16.446, Speaker C: Say, here, it's me. Take the money out of my checking.
00:36:16.478 - 00:36:19.558, Speaker E: Account and validate this with your special.
00:36:19.644 - 00:36:22.438, Speaker C: Worth one dollars stamp where it's like.
00:36:22.444 - 00:36:23.926, Speaker E: A signature that they can make, but.
00:36:23.948 - 00:36:25.810, Speaker C: On the outside of the envelope.
00:36:25.970 - 00:36:29.014, Speaker E: They return the envelope to me, then I can remove the envelope.
00:36:29.142 - 00:36:40.266, Speaker C: Now I have my own random serial number with the carbon image of their unforgivable worth of dollars stamp on it. So now I have this dollar, but.
00:36:40.288 - 00:36:41.978, Speaker E: No one knows the serial number.
00:36:42.144 - 00:36:45.598, Speaker C: And so I'm sure I have the money.
00:36:45.684 - 00:36:48.750, Speaker E: And so when I go and no one can take it away from me.
00:36:48.820 - 00:36:51.390, Speaker C: They can't screw with my account or anything.
00:36:51.460 - 00:36:53.006, Speaker E: So then I take it to a.
00:36:53.028 - 00:36:56.706, Speaker C: Shop and they say, that looks nice.
00:36:56.888 - 00:37:09.734, Speaker E: But we got to check that you haven't spent that serial number before. So they check with the bank. That's what I called the double spending problem in those days. And you hear a lot about it these days, right a minute. So the bank would then say, oh.
00:37:09.772 - 00:37:16.166, Speaker C: Yeah, that's our signature and we haven't accepted that number before, and so we.
00:37:16.188 - 00:37:21.100, Speaker E: Will honor this and put the money on the shop's account. But of course we have no idea.
00:37:21.470 - 00:37:26.774, Speaker C: Who the payer is. However, the user is very well protected.
00:37:26.822 - 00:37:31.806, Speaker E: So I didn't mention this, but that serial number, it's actually the result of applying a hash function.
00:37:31.908 - 00:37:45.822, Speaker C: So if the bank says, oh, we already saw that number, it's not valid, then the retail shop would say, oh, that's interesting. Can you please show me the number.
00:37:45.876 - 00:38:20.394, Speaker E: That when you hash, it gives you that serial number. And of course they wouldn't be able to do it. So only once they sign and say, okay, we'll accept it, then I give that hash pre image and then they know it's totally secured in that way. But the privacy is, let's say, asymmetric I was very happy with this in those days, it really worked well, there's something called the bank for International Settlements, which is the central bankers, central bank I visited and then I spoke there.
00:38:20.512 - 00:38:21.642, Speaker C: It's a whole thing.
00:38:21.696 - 00:38:39.554, Speaker E: And they promulgated they have a publication of those days called Definition of Criminal Use of Payments. And they listed them and they were very strident about it all. And it was basically extortion black markets and bribery. And so it turns out in any of those scenarios, if you used e.
00:38:39.592 - 00:38:45.666, Speaker C: Cash instead of a suitcase full of $20 bills, right? But if you used e cash, then.
00:38:45.688 - 00:38:50.406, Speaker E: No criminals would accept it because since you knew the serial number that you.
00:38:50.428 - 00:38:52.694, Speaker C: Created, you could always kind of tell.
00:38:52.732 - 00:39:04.762, Speaker E: The bank or the government or something, look out, these guys are going to be spending that. No blackmailer would take payment by check or no black market is going to accept Fed wire or these things.
00:39:04.816 - 00:39:07.530, Speaker C: So it was a way to protect.
00:39:07.600 - 00:39:12.106, Speaker E: The privacy of the individual. And we say unconditionally because the blinding.
00:39:12.138 - 00:39:20.506, Speaker C: And the blind signature is not just cryptography, it's what we call information theoretic.
00:39:20.618 - 00:39:24.594, Speaker E: Statistical security with unlimited computing power, quantum computers, whatever.
00:39:24.632 - 00:39:28.402, Speaker C: You cannot learn anything about what's blinded in there.
00:39:28.536 - 00:39:35.246, Speaker E: So it unconditionally protects. As a consumer your privacy was and.
00:39:35.288 - 00:39:41.074, Speaker C: The protection of your money that you held was perfect. But on the other hand it wasn't.
00:39:41.122 - 00:39:55.706, Speaker E: Really a suitable currency for paying bribes to politicians and things like that. So I felt it was a really superior form of money. And in fact, if we could get rid of paper money and switch to this we could get rid of a.
00:39:55.728 - 00:40:00.474, Speaker C: Lot of corruption and problems which are pretty big deal.
00:40:00.592 - 00:40:44.300, Speaker A: Let's also briefly just go over what happened with DigiCash. You did talk about that a little bit. It had offers of investment from places like Ing Investment. There was even a plan I think for Ing Bearings and Goldman Sachs to bring DigiCash to the stock market and Bill Gates expressed interest in integrating it with Windows 95. Netscape expressed interest, visa wanted to invest $40 million and none of these potential deals happened. And in subsequent reporting I guess some sources say that you wanted too much control and employees also felt you were too paranoid or greedy or stubborn and that's why these deals fell through.
00:40:45.710 - 00:40:54.846, Speaker E: That's our grape. Look, I'm doing this to make the world a better place. And that's why I put my life on the line. And that's what I've been working on.
00:40:54.868 - 00:41:04.734, Speaker C: All you know, I think it's really true that the powers that be wanted to kind know, stop this from being what it could have been.
00:41:04.772 - 00:41:05.426, Speaker E: And I really wait.
00:41:05.448 - 00:41:19.670, Speaker A: But when you say that, do you mean Microsoft and Visa and Netscape or what do you mean by the powers that be? Because they were interested know, using this and integrating it with their businesses or investing in it?
00:41:19.740 - 00:41:23.346, Speaker D: Well I mean what about policymakers, regulators.
00:41:23.378 - 00:41:25.202, Speaker F: Things like that I presume.
00:41:25.266 - 00:41:28.422, Speaker A: But I don't think they were the ones who stopped these deals, were they?
00:41:28.556 - 00:42:37.998, Speaker E: Well, I think one thing I'd like to say is that it's a testament to the significance of the ideas that I developed that there was so much interest and we had very serious conversations with a number of these organizations, it's true and we were represented by investment banks and so forth and so on. But if there was ever a scenario in which I felt that the potential of this was going to be taken forward and used to really plant that seed of privacy that I'd hoped for, that was the last thing in the world I'd want to do would be to stop that. When you start to really see we're invited into the corridors of massive power it's quite an eye opening experience. I spoke at a conference of central banks in Milan in Rome, and they told me that the airport was clogged up. We said it was like their private planes. I mean, they closed off avenues and.
00:42:38.004 - 00:42:40.666, Speaker C: We walked across a bunch of streets.
00:42:40.778 - 00:43:29.406, Speaker E: Police had blocked it all off. We walked right into the Vatican. It was only for us. They said non central bank had ever been even allowed to attend any of their meetings and have me speak there. People recognized the significance of what this was, but I'm not sure that anyone was really interested in the disruptive power of and it's not like I had a monopoly on this. As Adam mentioned, there were other kinds of blindable signatures that were contorted in a way that they didn't really fall under our control. I don't want to get too broad a perspective to answer to your specific.
00:43:29.508 - 00:43:33.490, Speaker C: Question, but what I would say is.
00:43:33.640 - 00:43:37.570, Speaker E: That just a little bit more generally.
00:43:38.150 - 00:43:43.858, Speaker C: If we want Cryptography to rise to.
00:43:44.024 - 00:43:51.206, Speaker E: Its potential, to make the world a better place for people, then probably. We need to do that in a.
00:43:51.228 - 00:43:56.818, Speaker C: Way that works in a more comprehensive.
00:43:56.914 - 00:44:05.914, Speaker E: Manner and is not more or less a guerrilla action on the side. And that's kind of what I've been really trying to do.
00:44:05.952 - 00:44:08.570, Speaker C: And that puts the burden on us.
00:44:08.640 - 00:44:10.542, Speaker E: To figure out how you could really.
00:44:10.596 - 00:44:14.222, Speaker C: Use this in a way that would.
00:44:14.356 - 00:44:25.010, Speaker E: Address legitimate issues of society and at the same time liberate people and human potential. This is the thing that will take civilization to the next level.
00:44:25.080 - 00:44:32.254, Speaker A: Yeah, it's interesting because that description of a guerrilla action on the side is almost a description of bitcoin.
00:44:32.382 - 00:44:49.490, Speaker E: But anyway no, not at all. I wouldn't say that. No. I'm a huge fan of bitcoin. I think bitcoin changed the whole landscape. I would say Ecash is bitcoin zero, bitcoin one is bitcoin made a lot of people rich, no question. And bitcoin two.
00:44:49.490 - 00:44:55.306, Speaker E: That's coming. And maybe it needs to be a little more hard to take down and.
00:44:55.328 - 00:45:00.138, Speaker C: A little more real privacy and maybe.
00:45:00.224 - 00:45:01.830, Speaker E: Integrated with some other features.
00:45:01.910 - 00:45:21.874, Speaker A: Yeah. So just to give people a sense of the timeline. So you left DigiCash in 1996. DigiCash went bankrupt in 1998. And meanwhile, right in the middle there, in 1997, adam sent an email to the cyberpunk mailing list about HashCash. So, David, do you want to dispute what I just said there?
00:45:22.072 - 00:45:24.718, Speaker E: I'm sorry, Laura.
00:45:24.894 - 00:45:25.634, Speaker F: Timeline. Right.
00:45:25.672 - 00:45:40.134, Speaker E: Such a pleasure of speaking with you, but I'm not sure I feel like I'm being cross examined. A lot of what you said has been said, none of it's exactly accurate, and what you said is not exactly accurate. I don't want to be put in a position to criticize any of this.
00:45:40.172 - 00:45:42.498, Speaker A: But, I mean, if I don't have.
00:45:42.524 - 00:45:45.894, Speaker E: The fact I didn't leave Digicache in 96 oh, you didn't?
00:45:45.942 - 00:45:46.346, Speaker A: Okay.
00:45:46.448 - 00:45:48.250, Speaker E: No. In 94. I don't know what you're referring to.
00:45:48.320 - 00:45:50.666, Speaker C: I mean, the hash cash was just.
00:45:50.848 - 00:45:56.910, Speaker E: Something that Adam developed as you know, to protect against spam by using computational cost.
00:45:56.980 - 00:45:59.598, Speaker C: And this was something that was Know.
00:45:59.684 - 00:46:01.806, Speaker E: Remember I mentioned the cryptography conferences that.
00:46:01.828 - 00:46:05.742, Speaker C: I created so years before Adam's mention.
00:46:05.796 - 00:46:11.982, Speaker E: Of that, it was Know, published by Dwarque and Noor at the conference.
00:46:12.126 - 00:46:13.314, Speaker A: Proof of work. Proof of work.
00:46:13.352 - 00:46:15.730, Speaker E: Proof of work for preventing.
00:46:18.890 - 00:46:19.254, Speaker D: Mean.
00:46:19.292 - 00:46:19.686, Speaker E: What do you mean?
00:46:19.708 - 00:46:23.954, Speaker C: That Adam wrote a letter to what I already years earlier.
00:46:24.002 - 00:46:31.670, Speaker E: I was there when know, Moni Noir was my co author on the offline ecash article.
00:46:31.750 - 00:46:46.480, Speaker A: Right, listeners, Cynthia Twark and Moni Noir wrote the proposed proof of work much earlier than Adam wrote the proposed hash cash to the Cyberpunk mailing list.
00:46:47.810 - 00:46:51.242, Speaker E: They presented it at the flagship conference.
00:46:51.306 - 00:46:53.726, Speaker A: I believe they presented it in 1993.
00:46:53.908 - 00:46:54.960, Speaker E: I was there.
00:46:55.330 - 00:47:03.570, Speaker A: That was the conference transition for us to talk about hash cash. That's all. And to show that all of these things were happening right around the same time.
00:47:03.720 - 00:47:04.658, Speaker D: That's all.
00:47:04.824 - 00:47:06.834, Speaker E: That's fine. It's really true.
00:47:07.032 - 00:47:08.146, Speaker A: Proof of work.
00:47:08.328 - 00:47:36.442, Speaker E: Let me say this. There were a lot of people, a lot of cypherpunks that I invited to visit us and work for us at Ecash. It was a very open company. We had a research component. So I had a lot of interaction with people. Like, Zuku was there for quite a while, and I worked with him. Yeah, try to help him develop his own competing systems while he was there under my employee on my nickel.
00:47:36.442 - 00:47:55.858, Speaker E: And I mean, later Zuku wrote to me he wanted to come to Crypto. He had no money. I said, sure, I'll pay for you to come. And I picked him up at the airport or whatever it was, help him out. Nick was there. Nick Sabo. It was a very open now we're.
00:47:55.864 - 00:48:08.346, Speaker A: Going to talk about hash cash. So, Adam, in 1997, you sent an email to the Cipherpunk mailing list proposing HashCash. What problem were you trying to solve and how did HashCash do that?
00:48:08.528 - 00:48:13.130, Speaker F: Yeah, so I was running remailer, so.
00:48:13.200 - 00:48:17.242, Speaker D: A way to send anonymous email and.
00:48:17.296 - 00:48:20.650, Speaker F: Communicate on Usenet discussion groups with Anonymity.
00:48:20.990 - 00:48:24.318, Speaker D: And as I mentioned earlier, the technology.
00:48:24.404 - 00:48:27.626, Speaker F: For these things was basically operated by volunteers.
00:48:27.738 - 00:48:30.238, Speaker D: So the problem or one of the.
00:48:30.244 - 00:48:35.790, Speaker F: Problems, as an operator of these things, it wasn't that expensive to operate in terms of bandwidth and server resources.
00:48:35.950 - 00:48:38.494, Speaker D: But it seemed that some people didn't.
00:48:38.542 - 00:48:41.726, Speaker F: Like free speech or ability to communicate.
00:48:41.758 - 00:48:45.206, Speaker D: Privately or anonymously and had taken it.
00:48:45.228 - 00:49:02.054, Speaker F: Upon themselves to spam through these systems. And it wasn't even commercial spam. It was just random numbers just trying to be disruptive. And we think because it was happening to multiple remailers, there were probably about 30 to 50 of them at various.
00:49:02.102 - 00:49:06.762, Speaker D: Times that the people doing this were.
00:49:06.816 - 00:49:12.554, Speaker F: Trying to annoy system administrators who operated Usenet servers.
00:49:12.602 - 00:49:17.614, Speaker D: So Usenet distributed discussion groups, and they.
00:49:17.652 - 00:49:32.786, Speaker F: Use a lot of bandwidth, like a university site or a big ISP, it would use enormous amounts of bandwidth. And so it would start to annoy the system administrators. If people were spamming through the remailers, the reaction would be maybe to block remailers or something like that. And I think that was what they.
00:49:32.808 - 00:49:38.086, Speaker D: Were trying to achieve. So it occurred to me that it.
00:49:38.108 - 00:49:41.640, Speaker F: Would be good if there was a way to combat this spam problem.
00:49:42.250 - 00:49:46.006, Speaker D: And because it was involving privacy, I.
00:49:46.028 - 00:49:53.338, Speaker F: Had to think about it in a different way because the usual anti spam technique, the system adam, can I just interrupt you?
00:49:53.424 - 00:49:58.566, Speaker E: I've heard you give the same presentation before, but I'm just mean but Dwark.
00:49:58.598 - 00:50:01.098, Speaker C: And Nor had already published proof of.
00:50:01.104 - 00:50:03.290, Speaker E: Work as an anti spam mechanism.
00:50:03.630 - 00:50:04.330, Speaker D: Sure.
00:50:04.480 - 00:50:13.274, Speaker E: And this was at the premier conference. Everyone in the field knew about it. It was published in the Springer lecture notes, and it was in every library, computer science library in the world, practically.
00:50:13.322 - 00:50:18.962, Speaker C: It's very widely disseminated. So why did you have to think so deeply about it?
00:50:19.096 - 00:50:22.738, Speaker F: Well, there's two things here, right? One is okay, but I have one.
00:50:22.744 - 00:50:25.890, Speaker E: Other question for you. I'm sorry, I know you've made some.
00:50:25.960 - 00:50:27.702, Speaker C: Look, I value what you were doing.
00:50:27.756 - 00:50:42.662, Speaker E: And I know it's tough to operate a remailer in those days. Were there also mixmasters? Were those running in those days the real deal? That was because you put yourself in a very difficult position knowing the linkings.
00:50:42.726 - 00:50:42.954, Speaker C: Right.
00:50:42.992 - 00:50:49.194, Speaker E: But if you had cooperated with us in a more open system using the mixing technology, you would have been maybe.
00:50:49.312 - 00:50:55.246, Speaker F: There were two generations. Brie Miller so Hal Finney wrote the first one, which was just a kind.
00:50:55.268 - 00:50:57.466, Speaker D: Of nested onion, but because it didn't.
00:50:57.498 - 00:51:07.214, Speaker F: Standardize the message sizes, you could say that that wasn't very good for passive traffic analysis, if you like.
00:51:07.252 - 00:51:07.754, Speaker E: I get you.
00:51:07.812 - 00:51:08.900, Speaker C: Yeah, I see.
00:51:09.430 - 00:51:22.822, Speaker F: The second generation was mixmaster. So I was running actually, it's backwards compatible, but I was running a mixmaster remailer for a few I mean so in terms of HashCash, I was not.
00:51:22.876 - 00:51:26.454, Speaker D: Aware of dwarf's paper until somebody sent.
00:51:26.492 - 00:51:35.386, Speaker F: Me a link to the publication a couple of months after I'd posted the source code for HashCash. And so some years later, I got.
00:51:35.408 - 00:51:37.610, Speaker D: Around to kind of writing a paper.
00:51:37.680 - 00:51:43.726, Speaker F: About the experiences of people using HashCash for various things. And in there I cited a number.
00:51:43.748 - 00:51:46.366, Speaker D: Of things, obviously, dwarf's paper, as I.
00:51:46.388 - 00:51:47.230, Speaker F: Was aware at that point.
00:51:47.300 - 00:51:50.558, Speaker D: But also there were some other related things.
00:51:50.644 - 00:51:53.134, Speaker F: I think in a way of thinking.
00:51:53.252 - 00:51:56.162, Speaker D: The sort of very invention of public.
00:51:56.216 - 00:51:59.026, Speaker F: Key cryptography with merkle puzzles is a.
00:51:59.048 - 00:52:00.498, Speaker D: Kind of proof of I mean, it's.
00:52:00.504 - 00:52:02.286, Speaker F: Not exactly proof of work, but it's related.
00:52:02.398 - 00:52:03.220, Speaker E: Very interesting.
00:52:04.630 - 00:52:07.078, Speaker D: If you look around, there's a lot.
00:52:07.084 - 00:52:18.214, Speaker F: Of linkages and reinventions in this space. So there have been other things where people have published something. There were, for example, client puzzles, which.
00:52:18.252 - 00:52:25.702, Speaker D: Was another kind of hash based proof of work by Ari, Jules and Breinard.
00:52:25.846 - 00:52:41.662, Speaker F: Probably also in one of the cryptography papers. And they were not aware of HashCash, for example. Right. So the original Dwarc and the Ore was using asymmetric techniques. So there's a lot of reinvention. Of course, I didn't publish it in academic paper, so I just published on a website. So fair enough, they wouldn't have been aware of it.
00:52:41.716 - 00:52:42.978, Speaker D: But just to say that there's a.
00:52:42.984 - 00:52:44.398, Speaker F: Lot of kind of reinvention.
00:52:44.494 - 00:52:53.374, Speaker D: And in my experience, the building things in an implied way sometimes brings together new ideas.
00:52:53.422 - 00:53:01.846, Speaker F: Right? Yeah, you can have an idea. Exactly. Right. That was the kind of general thrust of it.
00:53:01.948 - 00:53:12.166, Speaker D: I have done journal publications and things, but more in the distributed system space. So because it was a kind of.
00:53:12.188 - 00:53:16.940, Speaker F: Applied thing for remailers, I just put it on like a tech report on a website kind of thing.
00:53:19.070 - 00:53:20.460, Speaker A: Yeah, go ahead, finish.
00:53:21.150 - 00:53:29.374, Speaker F: Yeah, the idea there was to think about it in a way that could preserve privacy. So there are a few features about.
00:53:29.412 - 00:53:32.154, Speaker D: It that are privacy related.
00:53:32.282 - 00:53:42.274, Speaker F: So it has a timestamp, but there's some randomization of the timestamp so that you wouldn't reveal from a black box if you're looking at from the outside, see when the messages are going in.
00:53:42.392 - 00:53:44.786, Speaker D: You wouldn't reveal who's likely sender by.
00:53:44.808 - 00:53:57.078, Speaker F: Looking at the timestamp. So it had some features like that. So just the idea is to as the same as Dwarks in the kind of concept level, which is to create cost. That's the basic observation. Right.
00:53:57.164 - 00:54:01.914, Speaker D: The problem with commercial bulk sperm is it costs effectively zero.
00:54:02.112 - 00:54:07.898, Speaker F: But I think the advantage of that kind of system is that it's not.
00:54:07.904 - 00:54:13.490, Speaker D: As attractive because it's not respondable, but it's more scalable.
00:54:13.670 - 00:54:22.794, Speaker F: It doesn't require any infrastructure, really. You can just attach it to an email. And actually, much later in 2004, pal Finney kind of got a bit closer.
00:54:22.842 - 00:54:27.070, Speaker D: To assembling these different parts together.
00:54:27.140 - 00:54:30.420, Speaker F: So he used hash cash as the.
00:54:30.950 - 00:54:38.054, Speaker D: Proof of work, and he used a chorm blind signature based token server, and.
00:54:38.092 - 00:54:40.658, Speaker F: He assembled it in an IBM tamp.
00:54:40.674 - 00:54:42.866, Speaker D: Resistant secure processor that he ran.
00:54:42.898 - 00:54:44.386, Speaker F: So it kind of had the central.
00:54:44.418 - 00:54:48.034, Speaker D: Point of failure risk, but he introduced.
00:54:48.082 - 00:54:59.018, Speaker F: Mining effectively into the conversation. So he was using HashCash. I guess you can find the website online somewhere, somebody's archived it. So basically you would do some work.
00:54:59.184 - 00:55:03.594, Speaker D: You would send it to this IBM processor that was running in his server.
00:55:03.722 - 00:55:05.770, Speaker F: And it would send you back a chaun token.
00:55:05.930 - 00:55:11.934, Speaker D: And because of the kind of trustworthy computing aspect of this card, if you.
00:55:11.972 - 00:55:21.646, Speaker F: Assumed that he wasn't colluding with IBM, which would be a big stretch to say that they designed this card included with him. Right. So it's a serious piece of hardware.
00:55:21.678 - 00:55:24.354, Speaker D: That banks buy, and it can provide.
00:55:24.552 - 00:55:35.238, Speaker F: A kind of signature of execution so you can verify what code it's running with reasonable security. Not as much as the Bitcoin network because anybody can fully verify and you.
00:55:35.244 - 00:55:44.838, Speaker D: Don'T depend on this kind of trusted hardware sequence. But nevertheless, it's kind of interesting assemblage of parts.
00:55:44.854 - 00:56:00.202, Speaker F: So you could call that kind of Bitcoin 0.5, if you like, in the Bitcoin Zero without a proof of work. Well, he's got proof of work in there and he's bridging the technologies, right? So it's centralized.
00:56:00.346 - 00:56:02.254, Speaker D: It's got the strong privacy because you.
00:56:02.292 - 00:56:05.490, Speaker F: Get, in exchange for your work, a tron token.
00:56:05.830 - 00:56:07.346, Speaker D: And the scarcity is there.
00:56:07.368 - 00:56:09.250, Speaker F: So it's introducing digital scarcity.
00:56:09.590 - 00:56:11.458, Speaker D: And I think that Hal Finney and.
00:56:11.464 - 00:56:20.694, Speaker F: Nick Sappo and a few people were more interested in monetary reform. So returns to a gold standard or reestablishing, something like that.
00:56:20.732 - 00:56:27.398, Speaker D: So people were looking at the electronic cash problem from different directions, some from.
00:56:27.404 - 00:56:30.874, Speaker F: A monetary reform perspective, some from a privacy perspective. I was a little bit more on.
00:56:30.912 - 00:56:33.686, Speaker D: The kind of privacy bearer cash perspective.
00:56:33.718 - 00:56:35.738, Speaker F: I would have been okay with dollars.
00:56:35.824 - 00:56:38.250, Speaker D: Or any reasonably stable currency.
00:56:38.750 - 00:56:40.554, Speaker F: But then Bitcoin, if you scroll forward.
00:56:40.592 - 00:56:46.682, Speaker D: To Bitcoin, it loses some of the privacy, but it does plus or minus.
00:56:46.746 - 00:56:51.678, Speaker F: What Hal Finney's, he called it RPOW reasonable proof of work. So it basically does that but in.
00:56:51.684 - 00:56:54.078, Speaker D: A distributed setting, and the privacy it.
00:56:54.084 - 00:56:57.262, Speaker F: Loses is a side effect. I think most people who are involved.
00:56:57.326 - 00:57:01.742, Speaker D: Would like to establish a way to bring that back, but it's more technically.
00:57:01.806 - 00:57:13.362, Speaker F: Challenging to do that, as David would have a lot of experience in protocol design around to do that. In a way, you end up with bigger zero knowledge proofs or more cryptographic assumptions.
00:57:13.426 - 00:57:16.578, Speaker D: So Bitcoin is using actually quite basic.
00:57:16.754 - 00:57:22.700, Speaker F: Cryptographic assumptions, so it doesn't really do anything advanced with zero knowledge proofs and things like that.
00:57:23.230 - 00:57:28.502, Speaker A: For both of you, when did you hear about Bitcoin and how and what were your initial thoughts?
00:57:28.646 - 00:57:30.730, Speaker F: So do you want to go, David?
00:57:31.310 - 00:57:51.810, Speaker E: Well, I'd rather not comment on that exactly. I don't think I've done so publicly. Can we just go back before we answer that often asked question? Because I think it's a very interesting conversation about these early days. And one of the things that's colored my thinking, Adam, on this, and I'm curious on your thoughts on this, but.
00:57:51.960 - 00:57:56.214, Speaker C: Was really in the mid 90s, as.
00:57:56.252 - 00:57:59.686, Speaker E: I think you've pointed out, the computing power and the network connections and all.
00:57:59.708 - 00:58:05.334, Speaker C: This wasn't really up to doing a lot of stuff.
00:58:05.452 - 00:58:37.298, Speaker E: And the idea that you'd have all these servers running all around the world supporting payments, I think it was somewhat inconceivable to us. We were happy that we could get the client side to just make a payment in a couple of minutes, do an e cash payment, and that we could get the servers to be able to handle their side of it. So instead of having replicating that server, so to speak, many times. But what we did consider, and I.
00:58:37.304 - 00:58:39.934, Speaker C: Don'T believe it's ever been discussed publicly.
00:58:39.982 - 00:58:42.446, Speaker E: But several of us in the Digicache.
00:58:42.478 - 00:59:00.078, Speaker C: Company were working on a more distributed version of Ecash that was not somewhere in between. It's very easy to imagine distributing eCache.
00:59:00.114 - 00:59:26.082, Speaker E: In a simple minded way, right, where you say, well, we've got ten servers now, and if a majority of them agree that they all sign, and then they all check the double spending, and if a majority say it's okay, then it's okay. If you were to combine that with what I published as my dissertation at Berkeley, which was the blockchain, everything about blockchain except for the proof of work part.
00:59:26.136 - 00:59:26.740, Speaker C: Right.
00:59:28.870 - 00:59:31.038, Speaker E: Because that was a majority rule network.
00:59:31.134 - 00:59:31.682, Speaker D: Right.
00:59:31.816 - 00:59:41.638, Speaker E: So that's kind of what we were thinking of as a step to distribute this process, because there wasn't really the.
00:59:41.644 - 00:59:47.394, Speaker C: Resource to just I don't think at that point.
00:59:47.452 - 00:59:53.306, Speaker E: So that would have been something that would have been achievable to make them somewhat more decentralized, more in.
00:59:53.328 - 00:59:56.380, Speaker C: The classic BFT kind of.
00:59:58.750 - 00:59:59.594, Speaker F: I think.
00:59:59.712 - 01:00:02.958, Speaker E: I never heard anyone talk about it. That's on.
01:00:03.124 - 01:00:07.006, Speaker F: Yeah. So we greg Maxwell had a look.
01:00:07.028 - 01:00:10.446, Speaker D: At doing that as just just to.
01:00:10.468 - 01:00:21.266, Speaker F: Kind of make a know, like K of signers. And you can see in a straightforward way that should know if you can do a single blind signature, you can.
01:00:21.288 - 01:00:26.020, Speaker D: Make K of N inefficiently maybe more efficiently with some more thought.
01:00:26.390 - 01:00:28.774, Speaker F: And I think state chains, which is.
01:00:28.812 - 01:00:31.334, Speaker D: Another kind of Bitcoin layer two, is.
01:00:31.372 - 01:00:33.000, Speaker F: Contemplating doing the same thing.
01:00:33.770 - 01:00:42.214, Speaker D: I think Greg had some source code, but hadn't published it for the kind of threshold blind signature approach.
01:00:42.342 - 01:00:51.870, Speaker F: But I think the challenge and blockstream actually has a kind of federated blockchain, which is also K of N. So it kind of fits into our thinking.
01:00:51.940 - 01:01:01.886, Speaker D: For a layer two security. But the advantage for bitcoin itself in the layer. One is we published a paper on.
01:01:01.908 - 01:01:05.250, Speaker F: Sidechains and coined the word dynamic membership.
01:01:05.670 - 01:01:14.260, Speaker D: Signature because you could think of the proof of work as sort of evolving and signing in. Some way with the work.
01:01:16.230 - 01:01:24.838, Speaker F: The most work, the longest chain with the most work signing off. The majority of the work signing off. And each signature or each addition of.
01:01:24.844 - 01:01:26.694, Speaker D: A proof of work you can have.
01:01:26.732 - 01:01:29.010, Speaker F: A freshly anonymous participant.
01:01:29.170 - 01:01:31.898, Speaker D: So I think bitcoin stumbled across I.
01:01:31.904 - 01:01:37.654, Speaker F: Mean, nobody knows who Satoshi is or how he hit upon this, know whether he came at it from the Byzantine.
01:01:37.702 - 01:01:42.574, Speaker D: General'S fixed membership BFT protocols, or whether.
01:01:42.612 - 01:01:45.694, Speaker F: He started straight from anonymous proof of work.
01:01:45.892 - 01:01:49.802, Speaker D: But it doesn't have the membership challenge.
01:01:49.866 - 01:01:52.240, Speaker F: And something with a membership is never.
01:01:54.870 - 01:02:04.980, Speaker E: That'S the big breakthrough exactly, of bitcoin, and thank God that it happened. And it's a fantastic it's changed the world in a dramatic way.
01:02:07.770 - 01:02:19.050, Speaker A: Let's talk about bitcoin, because we're well over time and we're running out. How did you learn about bitcoin? When was that, and what were your initial thoughts?
01:02:19.870 - 01:02:23.946, Speaker D: So I learned about it in I.
01:02:23.968 - 01:02:34.842, Speaker F: Think it was like August 2008. Got an email from Satoshi nakamoto with the abstract and asking for the correct.
01:02:34.896 - 01:02:37.334, Speaker D: Citation for hash cash.
01:02:37.392 - 01:02:55.734, Speaker F: And I sent him a couple of other papers to look at, one of them being B money. And I looked at it in more detail, actually, when Hal Finney started posting his experiences, running it and understanding how it worked. So he posted some longer commentary on.
01:02:55.772 - 01:02:59.670, Speaker D: I think, the cryptography mailing list or the cyphunks mailing list.
01:02:59.820 - 01:03:06.194, Speaker F: I suppose for somebody who's spent much of his professional career working on applied.
01:03:06.242 - 01:03:09.986, Speaker D: Cryptography, like libraries and privacy enhanced technologies.
01:03:10.018 - 01:03:13.866, Speaker F: And things, the thing that will strike you initially, until you've become accustomed to.
01:03:13.888 - 01:03:16.826, Speaker D: It, is well, that hasn't got very.
01:03:16.848 - 01:03:19.258, Speaker F: Strong privacy assurances, at least compared to.
01:03:19.264 - 01:03:29.214, Speaker D: The previous systems, and that the security margin on a double spending is kind of 50 50, right? So you're sort of trusting that the.
01:03:29.252 - 01:03:34.846, Speaker F: Economic majority is honest to some extent. It depends on the aspects of the system you're protecting.
01:03:34.958 - 01:03:39.698, Speaker D: And so from the normal cryptographic kind.
01:03:39.704 - 01:03:41.986, Speaker F: Of asymmetric crypto, you typically have an.
01:03:42.008 - 01:03:45.550, Speaker D: Enormous benefit as a defender versus the attacker.
01:03:45.630 - 01:03:55.654, Speaker F: You're going to do some computation that takes a fraction of a second. The attacker is going to sit there for thousands of years with using up enormous amount of compute and probably going to fail to decrypt your message. So you're used to this kind of.
01:03:55.692 - 01:03:59.542, Speaker D: Enormous asymmetry, and Bitcoin is like, well.
01:03:59.676 - 01:04:06.154, Speaker F: It'S the good guys versus the bad guys. It's the fair fight kind of thing. It takes you a while to get over that, but then you reflect on.
01:04:06.192 - 01:04:18.334, Speaker D: You say, well, you know, on the other hand, it has proposed a novel new solution to the kind of dynamic membership, byzantine general's problem space. And as I mentioned, I was somebody.
01:04:18.372 - 01:04:20.546, Speaker F: Who'D read Leslie Lamport's paper while I.
01:04:20.548 - 01:04:22.746, Speaker D: Was doing my computer science PhD.
01:04:22.858 - 01:04:31.138, Speaker F: So something interesting and new in that space. And it's here, it's bootstrapped. You know, after a while it had a value and so forth when there.
01:04:31.144 - 01:04:33.154, Speaker D: Were exchanges, I guess, over a year.
01:04:33.192 - 01:04:36.318, Speaker F: In before there was a price at all. Right? Just people playing with it.
01:04:36.344 - 01:04:42.754, Speaker D: Start with the bootstrap story is kind of interesting, but the fact that it's.
01:04:42.802 - 01:04:45.382, Speaker F: Deployed and it's decentralized, so there's no.
01:04:45.436 - 01:04:49.386, Speaker D: Really identifiable nexus of a company or.
01:04:49.408 - 01:04:51.418, Speaker F: An individual that you would ask to.
01:04:51.504 - 01:04:54.202, Speaker D: Switch off a server or block something.
01:04:54.336 - 01:04:56.794, Speaker F: So I think it's an interesting trade off, right?
01:04:56.832 - 01:05:00.506, Speaker D: Because with the digicache and related blind.
01:05:00.538 - 01:05:06.362, Speaker F: Signature based protocols, you've got a very strong assurance that you can't selectively block.
01:05:06.426 - 01:05:13.742, Speaker D: Transactions, and the only thing that a party operating it could do is shut down, right?
01:05:13.796 - 01:05:20.914, Speaker F: They could say, Well, I refuse. I mean, I can't block anything selectively, so what do you want me to do? They're all indistinguishable to me, assuming that.
01:05:21.032 - 01:05:24.514, Speaker D: The sender wants privacy, whereas Bitcoin is.
01:05:24.712 - 01:05:31.926, Speaker F: Not so much in that vein, it's more that people are transacting. There's sort of pseudonymity. The coins are kind of pseudonymous. There's no kind.
01:05:31.948 - 01:05:35.842, Speaker D: Of wallet, identifier tracking it all. It's kind of imperfect.
01:05:35.986 - 01:05:38.518, Speaker F: But there's a de facto fungibility and.
01:05:38.524 - 01:05:43.686, Speaker D: Privacy and an assumption that there's an economic incentive that sooner or later some.
01:05:43.708 - 01:05:45.546, Speaker F: Miner somewhere will process your transaction, even.
01:05:45.568 - 01:05:51.994, Speaker D: If the first one chooses not to for policy reasons and plus and minus held up. It's a bit of a gray area.
01:05:52.112 - 01:05:56.686, Speaker F: There are companies that specialize in tracking coins that have been stolen, so those.
01:05:56.708 - 01:06:07.086, Speaker D: Ones are kind of a bit gray, but some of them move once in a while in small numbers. And there are mixes in the network doing kind of coin mixes or coin.
01:06:07.118 - 01:06:08.162, Speaker F: Joins and things like that.
01:06:08.216 - 01:06:14.670, Speaker D: So it's an interesting system in which to try and deploy privacy improvements.
01:06:14.750 - 01:06:16.614, Speaker F: So the Lightning network, which is another.
01:06:16.652 - 01:06:27.538, Speaker D: Layer two, has some mix like onion routing technology, and the layer one, coin joins and Liquid, which is a layer.
01:06:27.554 - 01:06:33.802, Speaker F: Two that my company Blockstream is working on, has confidential transactions. So a different kind of privacy, not.
01:06:33.856 - 01:06:38.918, Speaker D: Sort of linkability privacy, but privacy of the amount of value being transferred.
01:06:39.014 - 01:06:44.560, Speaker A: And David. What about you? Just briefly, we're going to move on to some other questions in a moment.
01:06:45.570 - 01:06:49.454, Speaker E: Like I said, I was pretty familiar with all the different aspects of it.
01:06:49.492 - 01:06:56.754, Speaker C: So I don't really comment on that. But what I could say, would like.
01:06:56.792 - 01:07:11.960, Speaker E: To say, I think, is that to Adam's point, I think now the technology is out there both on the bad guy side because of the quantum computers and all this possibly percolating. And then.
01:07:14.170 - 01:07:17.754, Speaker C: Some of the new stuff that has been done to speed up.
01:07:17.792 - 01:07:30.878, Speaker E: Mixing by pre computation very dramatically and to make real quantum secure BFT, those things can come together and create something.
01:07:30.964 - 01:07:35.914, Speaker C: That has all the real goodness.
01:07:35.962 - 01:07:48.258, Speaker E: It's much more definitive, a far higher barrier against being taken down and even by a national adversary. And the privacy, then you get the.
01:07:48.264 - 01:07:52.642, Speaker C: Full anonymity sets and you might have.
01:07:52.696 - 01:07:56.120, Speaker E: Also privacy in the messaging, who talks to who.
01:07:56.570 - 01:07:57.622, Speaker C: That's a great thing.
01:07:57.676 - 01:08:04.534, Speaker E: So I think there's another shoe to drop in this space, but I would.
01:08:04.572 - 01:08:06.406, Speaker C: Never want to be thought of as.
01:08:06.428 - 01:08:25.950, Speaker E: Someone diminishing the significance of Bitcoin. I mean, to me that is like this game changing, world changing thing. And technologically it's quite a complex beast. And I think it's pointing the way to different things that we could try to improve.
01:08:26.610 - 01:08:28.714, Speaker C: And I appreciate the way you're tackling.
01:08:28.762 - 01:08:31.054, Speaker E: It, Adam, this like, you know, trying.
01:08:31.092 - 01:08:33.714, Speaker C: To add things onto it to make it better.
01:08:33.752 - 01:08:35.678, Speaker E: And I think that's promising.
01:08:35.774 - 01:08:39.266, Speaker C: But one could also take it all.
01:08:39.288 - 01:08:40.002, Speaker E: To the next level.
01:08:40.056 - 01:08:45.526, Speaker C: And that's something that I think is also laura, your viewers should keep their.
01:08:45.548 - 01:08:54.040, Speaker E: Eyes open for something really dramatically different. I think there's room there to really take it to the next level.
01:08:55.610 - 01:09:27.138, Speaker A: So Bitcoin has gone from a value of nothing, basically, to currently having a market cap of over $200 billion. And meanwhile, we have this pandemic going on which is causing this economic freeze that has led to governments printing more money. And there's all kinds of other factors going on, like China launching its own digital currency and these other central banks eyeing the same idea. So when you look at these different forces, where do you think bitcoin is.
01:09:27.144 - 01:09:31.134, Speaker D: Headed next to the stratosphere.
01:09:31.262 - 01:09:34.660, Speaker E: Adam, did you recently say $300,000?
01:09:35.210 - 01:09:41.894, Speaker F: Yeah, I mean, actually there's been some recent discussion on a different track, which is this stock to flow model, which.
01:09:41.932 - 01:09:48.806, Speaker D: Is just a curve fit on previous year's price movement.
01:09:48.838 - 01:09:52.650, Speaker F: But actually the 300,000 comment was before.
01:09:52.720 - 01:09:56.326, Speaker D: Which was just you can't make predictions.
01:09:56.358 - 01:09:57.962, Speaker F: About these things, but just looking at.
01:09:58.016 - 01:10:01.626, Speaker D: The use case and the similarity with.
01:10:01.648 - 01:10:03.034, Speaker F: Digital gold, so I was just looking.
01:10:03.072 - 01:10:05.126, Speaker D: At, well, go look up the metrics.
01:10:05.158 - 01:10:13.018, Speaker F: Well, how much gold is there in the world? And people are not exactly sure how much physical gold there is in the world, but they have a rough idea. And so what's the market cap of gold?
01:10:13.034 - 01:10:15.466, Speaker D: And divide that by the eventual supply.
01:10:15.498 - 01:10:22.622, Speaker F: Of bitcoin and you come out with a number that's like 300 to 500,000 per coin. But then that depends on the gold price, which is also the moving target.
01:10:22.686 - 01:10:25.034, Speaker D: And of course, with all this pandemic.
01:10:25.182 - 01:10:38.634, Speaker F: Economic uncertainty, gold is typically a kind of macro hedge. So gold price is up, surprise, surprise, but bitcoin price is up too. And I have to suppose that while a lot of people have heard about.
01:10:38.672 - 01:10:44.470, Speaker D: Bitcoin, there's probably many people who haven't taken the plunge.
01:10:44.630 - 01:10:46.438, Speaker F: Bitcoin has differences to gold.
01:10:46.534 - 01:10:48.438, Speaker D: You can send it at a distance.
01:10:48.534 - 01:10:51.006, Speaker F: You can verify it. It has a lot of sort of.
01:10:51.028 - 01:11:03.882, Speaker D: More transactional value, utility value, I guess. So we'll see. I mean, I think it's certainly a very interesting experience to send some bitcoin.
01:11:03.946 - 01:11:12.926, Speaker F: I think in our company we sent bitcoin transaction, I don't know, like $100,000 or something. It involves multiple people decrypting and signing.
01:11:12.958 - 01:11:14.706, Speaker D: Different things and you end up with.
01:11:14.728 - 01:11:24.434, Speaker F: A small blob of text and you're like, wow, this is $100,000 of bearer money. It's just an amazing, phenomena right to contemplate. As somebody from a computer science background.
01:11:24.482 - 01:11:45.374, Speaker D: That'S really a very interesting artifact for the world. So as technologists, we're very enamored by the potential of this building block, I think, and what it can do for society to have kind of dependable electronic money. From a monetary reform perspective, of course.
01:11:45.492 - 01:11:48.174, Speaker F: It seems that the economic commentators are.
01:11:48.212 - 01:11:50.638, Speaker D: Saying that even though there's been a.
01:11:50.644 - 01:11:58.146, Speaker F: Lot of money printing, it hasn't translated into much price inflation yet. Obviously there's more money in the system.
01:11:58.328 - 01:12:08.018, Speaker D: But economic downturn has suppressed price inflation. People are not spending money, so the suppliers are having to coax people to.
01:12:08.024 - 01:12:13.462, Speaker F: Buy things by reducing prices to what they would do in a robust economic situation if you printed this quantity of money.
01:12:13.516 - 01:12:18.086, Speaker D: So we don't know if and when that will take effect.
01:12:18.188 - 01:12:20.154, Speaker F: I think the experience in Japan has.
01:12:20.192 - 01:12:23.814, Speaker D: Shown that countries can have low inflation.
01:12:23.862 - 01:12:31.462, Speaker F: Rates for a very long period of time. So some people are looking at the US, for example, as a major economic.
01:12:31.526 - 01:12:33.566, Speaker D: Factor in the world to say that.
01:12:33.588 - 01:12:36.430, Speaker F: Might be in the future. But I think more recently the US.
01:12:36.500 - 01:12:47.342, Speaker D: Has even said that it has an economic it's considering an economic policy of creating or targeting the creation of price inflation.
01:12:47.406 - 01:12:52.754, Speaker F: So I don't know. We live in interesting times, I guess is the thing we can say there.
01:12:52.952 - 01:13:36.350, Speaker A: Yeah. And just for listeners who don't know, I have mentioned this before on the show, but stock to flow is this ratio of the existing supply versus the new supply. So for instance, with bitcoin, it's relatively small, but actually it's still greater than the ratio for gold, but after the next having, it will actually drop below that of gold. However, one interesting thing is that somebody took that and applied it to the price of gold over the course of history and there was not a correlation. So then they felt that disproved the stock to flow theory. So we will see how this bears know. I'm not sure whether or not that will apply to bitcoin, but David, what about you? Where do you think this is all headed?
01:13:36.510 - 01:13:42.466, Speaker E: Well, I'm extremely optimistic about the mean.
01:13:42.488 - 01:13:48.754, Speaker C: All the trends that you mentioned, Laura, seem to indicate mean, if you're afraid.
01:13:48.802 - 01:13:53.302, Speaker E: To go places in person, you want something you can transact with online.
01:13:53.436 - 01:14:03.740, Speaker C: And there's a ton of crazy stuff going on with governments these days, so.
01:14:04.670 - 01:14:09.958, Speaker E: It must all be pointing in a very positive direction. But we're not seeing it right now.
01:14:10.144 - 01:14:13.854, Speaker C: That dramatically because as was said, people.
01:14:13.892 - 01:14:22.880, Speaker E: Aren'T really spending that much. So I think this bodes extremely well for the whole space bitcoin especially.
01:14:27.890 - 01:14:33.554, Speaker C: It's sad to have to I'd rather not think that something that I care.
01:14:33.592 - 01:14:36.354, Speaker E: About like bitcoin is going to benefit.
01:14:36.402 - 01:14:39.206, Speaker C: From all these bad things that are.
01:14:39.228 - 01:14:45.240, Speaker E: Happening to the planet. But in fact, yeah, I think it seems like it will really.
01:14:47.390 - 01:14:48.026, Speaker C: All should.
01:14:48.048 - 01:14:52.650, Speaker E: Be very positive for it, but yeah, I'm rooting for the planet.
01:14:53.550 - 01:15:00.554, Speaker A: Yes, I think we all are. And for humanity. So we can all go out and hang out.
01:15:00.592 - 01:15:04.862, Speaker E: Yeah. Ethereal next time.
01:15:04.916 - 01:15:05.520, Speaker C: Yeah.
01:15:06.370 - 01:15:20.162, Speaker A: Okay. Well, this has been so fun chatting and I really enjoyed learning about your early work in digital currencies pre bitcoin. That was very fun. Where can people learn more about each of you and your work?
01:15:20.296 - 01:15:45.354, Speaker E: Well, I would like to suggest people also could look at the xx network. We're live in beta and we've got a lot of good stuff running. And look at the white papers. That's really solid stuff. It's best stuff out there by far, I think. I'm very, extremely enthusiastic about it and we've got a lot of good backing, so please have a look at that. But if you want to know about the historical stuff.
01:15:45.354 - 01:15:49.158, Speaker E: Look@etchom.com and look at the Ecash Museum.
01:15:49.254 - 01:15:50.522, Speaker C: And different other things.
01:15:50.576 - 01:16:05.826, Speaker E: Multiparty computation, we didn't get a chance to talk about that's. Another interesting vector on all this, like kind of generalizing, the Smart contracts and the ICR and the history of it, if you're interested in all that. It's all up there. And I guess one aspect that I.
01:16:05.848 - 01:16:07.534, Speaker C: Would like to also draw your attention.
01:16:07.582 - 01:16:21.314, Speaker E: To is this kind of cryptographic technology can also be used in elections and voting and online voting and so on. And that is very much related to payments and messaging.
01:16:21.362 - 01:16:24.102, Speaker C: And I think this is an area.
01:16:24.156 - 01:16:25.880, Speaker E: Where I'd like to see a lot more.
01:16:26.490 - 01:16:30.950, Speaker C: I think there's a lot of potential there. And so I've been working on that.
01:16:31.100 - 01:16:31.766, Speaker D: For a long time.
01:16:31.788 - 01:16:34.986, Speaker E: And you can read about some of the stuff up on my site that.
01:16:35.008 - 01:16:36.330, Speaker C: I've been doing on that.
01:16:36.400 - 01:16:41.166, Speaker E: So we're making great strides in that. Actually. There will be some new work coming up very soon.
01:16:41.268 - 01:16:47.290, Speaker C: So, yeah, chom.com and Xxnetwork xx Network is the URL.
01:16:47.370 - 01:16:51.710, Speaker D: Yeah. All right. And Adam. So I have a personal web page.
01:16:51.780 - 01:17:02.946, Speaker F: On Cypherspace.org Cypherspace.org, which has, for example, pictures of the T shirt that you mentioned and various cryptographic libraries and things.
01:17:02.968 - 01:17:09.430, Speaker D: I've implemented over the years. And on Twitter, I'm adam three US.
01:17:09.580 - 01:17:11.286, Speaker F: And Blockstream, which is the company I.
01:17:11.308 - 01:17:16.470, Speaker D: Co founded some years ago now is Blockstream.com.
01:17:16.620 - 01:17:27.594, Speaker F: I think we were talking about the Dwark proof of work in hash cash. So I think that's been something that has been discussions about various times.
01:17:27.712 - 01:17:33.646, Speaker D: And so one kind of question I turn my mind to is, well, why.
01:17:33.668 - 01:17:36.186, Speaker F: Are people using HashCash for the proof.
01:17:36.218 - 01:17:38.430, Speaker D: Of work and not other proofs of.
01:17:38.580 - 01:17:41.274, Speaker F: So, you know, there's the client puzzles.
01:17:41.402 - 01:17:44.142, Speaker D: That Jules and Brainard produced.
01:17:44.206 - 01:17:49.006, Speaker F: There's the original proof of work by Dwark and AOR.
01:17:49.118 - 01:17:49.746, Speaker C: Oh, I see.
01:17:49.768 - 01:17:54.046, Speaker E: So the HashCash mechanism itself is the one that's prevailed.
01:17:54.238 - 01:17:54.690, Speaker D: Yes.
01:17:54.760 - 01:18:02.642, Speaker F: Well, I think there's a specific reason in hindsight. So at the time I did it, it wasn't used for that purpose. It was just used for one use stamps.
01:18:02.786 - 01:18:10.498, Speaker D: But the result is that you get a compact proof of work because it's fixed size, whereas the Dwark and they.
01:18:10.524 - 01:18:32.094, Speaker F: All were like broken asymmetric signatures. So signatures were low key sizes so that you could brute force them and create forgeries and things like that. So there's three variants. Two of the variants have progress. So you need like a poisson process for fairness, like a level playing field in crypto mining. The third one, which is based on.
01:18:32.292 - 01:18:35.666, Speaker D: In Dwarcan neor, is based on these.
01:18:35.768 - 01:18:43.266, Speaker F: Square roots in large prime fields. And there's an algorithm in that called Tenelli Shanks, which has some randomness, but.
01:18:43.288 - 01:18:46.674, Speaker D: It'S not clear if that's sufficient to.
01:18:46.712 - 01:18:57.802, Speaker F: Have a level playing field because there may be other slightly less optimal square root algorithms that the single fastest computer can tend to win. And that will be a problem again. And then the other side effect is.
01:18:57.856 - 01:19:01.434, Speaker D: That those systems have they're not as.
01:19:01.472 - 01:19:09.030, Speaker F: Easy to scale in terms of the difficulty. So with HashCash, the stamp was compute a million tries.
01:19:09.110 - 01:19:16.974, Speaker D: So 20 binary digits of zero at the front. But these days it's enormous, right?
01:19:17.012 - 01:19:21.374, Speaker F: It's 70, 80 leading zeros. And so if you scale some of.
01:19:21.412 - 01:19:26.386, Speaker D: Those kind of broken signature based schemes, you end up having to increase the.
01:19:26.408 - 01:19:35.566, Speaker F: Prime size or the fiat Shimmer transform size and you get enormous proof. So the proof of work might itself be bigger than the block of transactions.
01:19:35.598 - 01:19:37.378, Speaker D: You'Re trying to prove about.
01:19:37.544 - 01:19:46.358, Speaker F: Plus the fact that they're not Poisson is like a stumbling block, if you see what I mean. So anyway, that's sort of like in hindsight. So it's like a curiosity. Right?
01:19:46.444 - 01:19:53.194, Speaker D: Well, given that there were these parallel different variants, and the other one by.
01:19:53.232 - 01:20:06.126, Speaker F: Jules and Brainard is actually interactive, so it's approved with respect to a server. So that's not amenable to independent verification, let's say, to the audit function. I'm really glad we had a chance.
01:20:06.148 - 01:20:07.742, Speaker E: To speak about it. Thanks. That's so interesting.
01:20:07.876 - 01:20:08.560, Speaker C: Yeah.
01:20:09.970 - 01:20:17.986, Speaker E: Now I'm glad to hear that the proportion you took turns out to be the superior one. And congratulations on that.
01:20:18.008 - 01:20:18.958, Speaker C: That's excellent.
01:20:19.134 - 01:20:27.686, Speaker E: I'm going to mention that going forward, I was unclear I was looking forward to this chance. We've met before, but I wanted to ask you about this because I thought it was going to come up.
01:20:27.708 - 01:20:32.630, Speaker D: Yeah, I think it's also very simple.
01:20:32.700 - 01:20:34.998, Speaker F: So simple things win. So when I was designing it, I.
01:20:35.004 - 01:20:39.394, Speaker D: Was thinking about, should I introduce floating.
01:20:39.442 - 01:20:57.598, Speaker F: Point to make it harder to make an ASIC? So already I was thinking about spanners are very determined economically, they'll make Asics. So should I make it complicated? Should I involve memory? I looked at time memory trade offs, I was like, you know what, I think simple is better. So I kept it to a standard Sha One function at the time, so.
01:20:57.604 - 01:20:59.614, Speaker D: You'D be able to verify it even.
01:20:59.652 - 01:21:02.254, Speaker F: With a shell script, using a Sha one function. Right.
01:21:02.452 - 01:21:06.942, Speaker D: Anyway, simple wins. And it happened to have the Python.
01:21:07.006 - 01:21:10.782, Speaker F: Function, which I was actually determinedly trying to eradicate because it was a nuisance.
01:21:10.926 - 01:21:17.540, Speaker D: For spam purposes, but tenets be an advantage for distributed fairness or something like that.
01:21:19.610 - 01:21:41.850, Speaker A: I'm not going to even try to pretend to translate all that for my listeners, but hopefully the more technical ones will have understood and at least now we have an understanding of why your proof of work was perhaps more widely used than the original version. Okay, well, this has been so fun chatting with you both. Thank you both so much for coming on Unchained.
01:21:42.350 - 01:21:45.086, Speaker E: Thank you, Laura. This was great. I really enjoyed it.
01:21:45.108 - 01:22:13.090, Speaker A: Thank you again, thanks so much for joining us today. To learn more about the history of digital currency and David and Adam, as well as their various inventions, check out the show notes for this episode, don't forget. You can now watch video recordings of the shows on the Unchained YouTube channel. Go to youtube.com slash c slash unchained podcast and subscribe of today Unchained is produced by me, Laura Shin, with help from Anthony Yoon, Daniel Ness and the team at CLK Transcription. Thanks for listening.

00:00:00.090 - 00:00:16.670, Speaker A: You know, I'm not sure I've seen a dev ecosystem with so many new ideas come up so quickly since Ethereum itself, where with Ethereum itself, you know, this, it unlocked this whole universe of kind of a multi asset blockchain, smart contracts.
00:00:20.450 - 00:00:54.490, Speaker B: Hi everyone, welcome to Unchained, your no hype resource for all things crypto. I'm your host, Laura Shin, author of the Cryptopians. I started covering crypto eight years ago and as a senior editor of Forbes, was the first mainstream media porter to cover cryptocurrency full time. This is the March twelveth 2024 episode of Unchained. Polka Dot is the original and leading layer zero blockchain with over 2000 plus developers. And the Polka Dot 20 upgrade will be a massive accelerator for the ecosystem, making it faster, more secure and adaptable. Perfect for gamefi and Dfi to build, grow and scale.
00:00:54.490 - 00:01:13.134, Speaker B: Join the community at Polkadot Network Slash ecosystem Community Today's topic is what Eigen layer and restaking mean for Ethereum. Here to discuss are Sriram Khannan, founder of Eigen Layer, and Olaf Carlson, we founder and CIO of Polychain Capital. Welcome Sriram and Olaf.
00:01:13.262 - 00:01:14.606, Speaker A: Hey, thanks for having Laura.
00:01:14.638 - 00:01:17.410, Speaker C: Hi Olaf. I'm really excited to do this chat. Predict.
00:01:18.410 - 00:01:43.466, Speaker B: Yeah, Olaf and I were chatting a little bit before the show and he was saying he feels like he hasn't seen an ecosystem sprout up. Eigen Liar is one of the fastest ecosystems he's seen that sprout up since Ethereum, which is, in my opinion, quite a high compliment. So Sriwan, let's start with you, and let's just make sure the audience is all up to speed on what Eigen layer is and what problems it solves for Ethereum.
00:01:43.658 - 00:02:36.698, Speaker C: Yeah, absolutely. Eigen Layer is a mechanism that allows any developer to tap into the trust network underlying Ethereum. What is the trust network underlying Ethereum? People lock up a portion of stake ETH into a contract and then promise that they're validating the Ethereum blockchain correctly. And this is the root of trust of any proof of stake chain. And the reason this is trustworthy when people lock up a bunch of stake is that they are potentially liable to lose their stake if they misbehave. So even if all the stakers on Ethereum come together and try to attack the system, they know that they have a concrete parity in the form of laws of stake, which basically makes the system trustworthy. And what Eigenve does is to let developers who want to access both the stake and the operator network underlying Ethereum to be used for arbitrary new systems.
00:02:36.698 - 00:03:26.510, Speaker C: Anybody who wants to build a new decentralized protocol, which requires full flexibility in configuring and programming what the nodes in the network does, you can do it through Eigenve. Eigenvear is a system of smart contracts on Ethereum which basically allows people to build new kinds of services. We call AVss. Actively validated services. Actively validated service is any service that requires a decentralized group of nodes to actually do active work and validation to verify that they're doing the service is working correctly. So you can think of this know in the cloud world, you have the idea of APS application programming interfaces where you can kind of query an API and access the data. Think of how do I build APIs but with a trust, and with decentralized trust tacking them.
00:03:26.510 - 00:03:37.262, Speaker C: That's what an EVs is, that's the ecosystem that we're enabling. Is people coming and building new sets of actively valued services on top of the Ethereum Trust network by Eigen layer.
00:03:37.326 - 00:03:45.940, Speaker B: Olaf Polychain was a seed investor in Eigen layer. Why are you so excited about it? And what do you think the launch of restaking on Ethereum will mean?
00:03:46.470 - 00:05:03.326, Speaker A: Yeah, so I remember this goes back to the first time I met Shuram. I think we had about 45 minutes calendared off to talk, and we ended up speaking for, I think about 3 hours about the implications of Eigen layer. It instantly made a lot of sense to me. Where these node operators that are running staking nodes and proof of stake systems, they have these fixed costs they've already taken on, right? So if you're an Ethereum staker, you already have high connectivity, high bandwidth, you already have capital at stake, and you're running this node incrementally. Staking for services built in Eigen layer basically just means clicking a button and saying, yeah, I'll stake in this AVs service. In addition to staking the main Ethereum chain, and so the incremental cost for existing Ethereum stakers to add an Eigen layer service is extremely low. So you can think of Eigen layer in a sense as a two sided marketplace between the application developers that need security and the Ethereum stakers, or stakers really in any proof of stake system that validate those services.
00:05:03.326 - 00:06:05.934, Speaker A: So it felt like that side of the marketplace stood to benefit. Like it's just quite rational for them to stake and accrue additional value from what they're already earning. Staking Ethereum. Then when I think about, okay, what could you build. If you could have the economic securities of Ethereum without having to spin up Ethereum two, right, which today, in order to get equivalent security of Ethereum, you literally need to launch a crypto token and have it become worth half a trillion dollars and get that whole staking network online just for your one application. And it's actually something that I've helped lots of people do or attempt to do, and it's very hard. The idea that you could plug into a set of tools and sort of just jump onto the existing economic security of Ethereum to add that level of extremely robust security to arbitrary application logic that side of the marketplace.
00:06:05.934 - 00:07:30.930, Speaker A: It also felt like it makes a ton of sense that application developers are going to want to build secure oracles, more flexible oracles, like a whole suite of sort of middleware services that require extremely high security guarantees and unlock new types of application logic without having to spin up their own blockchain. I've since realized it's even further than that in that Eigen layer. Even if you want to spin up your own economic security system with your own native token, Eigen layer also allows you to do that, but initially bootstrap on Ethereum stakers while your token sort of grows in value. So it's pretty remarkable what Eigen layer unlocks. It's only expanded in my head as I've watched a real ecosystem emerge here around this. As we were talking right before the show, Laura, I said, I'm not sure I've seen a dev ecosystem with so many new ideas come up so quickly since Ethereum itself, where with Ethereum itself, it unlocked this whole universe of kind of a multi asset blockchain, smart contracts. And in those early days, we had things like crypto collateralized stablecoins, non crypto collateralized, like offline collateral stablecoins, early defi contracts, early NFTs.
00:07:30.930 - 00:08:14.502, Speaker A: All those things were emerging around the Ethereum blockchain. I'm seeing very similar, early, extremely promising ecosystem built around Eigen layer today. And since the system has gone live, it's really gotten a ton of traction very quickly. I think that there's over $10 billion now at stake in the Eigen layer system. I tweeted something like a year ago, if eigen layer works, it should absorb most Ethereum in existence. What I really meant more precisely was most Ethereum that's being staked in the staking system. I think we're well on track for that to happen because it's quite logical for both sides of this marketplace to participate.
00:08:14.646 - 00:09:06.986, Speaker B: Yeah, and my understanding is only a fraction of both of yours. But the more that I've been learning about it, the more I just keep picturing Eigen layer as enabling Ethereum to become this giant stack of decentralized software as service providers that all share the same security. And so it's just kind of like if you take the web, two Internet that we have now, and there's all these different services that you can sign up for, it would just be like that, but decentralized on Ethereum or something. So why don't we talk a little bit more about these AVs just because they are so central here. And I was curious to hear your thoughts around how they should be designed or even which one should be created or who decides? Or is it just let 1000 flowers bloom or what are your thoughts on that?
00:09:07.168 - 00:09:55.542, Speaker C: I'll give an analogy, I think just playing off the cloud analogy to start with. The first thing is we are calling these actively validated services rather than chains. When people thought about restaking, they were thinking like we're going to allow many people to build chains. But chain is one kind of an object which is its own ordered ledger. But really a service is much more general. And I think the right kind of analogy is like the software as a service on top of the cloud, right? So to one way to tell this discussion, if you go back in 1995 and if you're a web application developer, what you need to do is you have to build your own server stack, you have to build your own identity, you have to build your own payments, you have to build your own database, and then build whatever thing that you were building. Imagine you're Amazon building bookstore.
00:09:55.542 - 00:10:42.806, Speaker C: You have to do all these other things. And in 2024, that's absolutely not how you design a web application. It'd go to AWS, it'd go plug into one of the identity service like oauth. You'd go plug into a database service like MongoDB, you'd go plug into a payment service like stripe, and then build whatever website you want on top. Even that maybe you do something like Shopify. So you just have layers and layers of hyper specialized software services that are built, which is reminiscent of our own team open innovation or permissionless innovation in the crypto space. The idea that anybody can come and build a hyper specialized focused service and then end user facing applications concatenate a set of these services to provide the functionality they want to their users.
00:10:42.806 - 00:11:34.890, Speaker C: So that's the evolution of the web application development stack. And we see something analogous, empowered by something like Agiler is once you have a framework on top of which people can build very specialized services. These ABs now end user applications can concatenate a bunch of these services and then provide really interesting user experiences. So when people talk about in the modular blockchain paradigm, they say maybe there are like three modules, like execution, consensus, data availability. Our view is no, there are going to be thousands of modules hyper specialized to do very specific things. And when you have hundreds of modules, and another thing people ask in the modular ecosystem is, oh, is really an application going to pay a little bit of drip across all these modules? Yeah, exactly. That's how cloud works.
00:11:34.890 - 00:12:36.666, Speaker C: Like each web application uses 20 SaaS services in the back end and pays a drip of fees. And we have hundreds of unicorns in the SaaS economy, maybe thousands. I'm not doing the math here, but it is one of the most profitable venture investment sectors over the last 20 years. And the reason it is very profitable is because it's much easier to find who is the best person to build a NoSQL database for AI than it is to find which end user application is going to win. It's much, much harder to take a bet on that because this is hyper specialized, the best database guys building this service to offer to everybody else and to compare this vision with other visions of application development in the blockchain space. One other vision of application development is the app chain thesis, which is just integrate everything into the app chain. The things that I see happen there is for example, a project like Osmosis, which is a highly technical project which is innovated all across the stack.
00:12:36.666 - 00:13:24.058, Speaker C: For example, figured out how to do encrypted mempools as a part of its whole osmosis development, because they said we don't want MeV, we want an encrypted map. But actually encrypted Mempool is an awesome service for lots of applications, not just osmosis. So encrypted mempool should be a service running on Eigen layer. Now I can just plug and play across all these different services to get the end user experience that I want. So applications emerge as a consequence of interlocking across various services. And so that's really what we're super excited about is actively validated services being these hyper specialized focused services that you can concatenate to form rich end user applications. So that's kind of the broad vision.
00:13:24.058 - 00:13:33.374, Speaker C: I can also talk a little bit about what categories of these AVss are we seeing, what are approximate, what are in the long term so that might be interesting.
00:13:33.492 - 00:13:43.460, Speaker B: Yeah, why don't you go ahead and do that, actually, because I was going to ask you for more examples. I love that example about the encrypted mempool. That's amazing. But yeah, would be curious to hear about the universe of.
00:13:44.390 - 00:14:17.834, Speaker C: So, you know, we can put them into like four or five meta categories. And inside each meta category there's a bunch of categories. One meta category is roll up services. So Ethereum has a roll up scaling roadmap where roll ups are going to be a lot. What are the services that require decentralization that can augment the roll up scaling roadmap? So some people are confused whether Eigen layer is like in collision course with the roll up roadmap or not. In fact, it is actually turbocharging, I think the roll up roadmap. So one of the things we see is roll up services that can be built on Eigenve.
00:14:17.834 - 00:14:54.218, Speaker C: The first service we are building ourselves is Eigenda. When you're a roll up, you want to write data to Ethereum to make sure that anybody has access to the inputs and outputs of your computation so that they can challenge it or continue the computation on if you go away. So that's a data availability layer. So Eigenda is a data availability layer. We built on top of Eigen layer. Eigenda is launching with a throughput of ten megabytes per second. That is compared to Ethereum's upcoming upgrade called 4844 or Dankun is up 30 kb/second so it's a couple of orders of magnitude out there.
00:14:54.218 - 00:15:29.022, Speaker C: So that is an example. And then how Inda was built is basically take the Ethereum roadmap, dunk sharding, KZG encoding and all that stuff that is already there, and just build it right, because there is much more energy and interest in private markets to fund things, fund these kinds of services than Ethereum itself can necessarily do all the development in house. So that's an example I canda. But lots of other services that we see spring up. Like another example of a roll up service is bridging. Like I want to bridge from one. Fragmentation of roll ups is something we all talk about.
00:15:29.022 - 00:16:14.110, Speaker C: I want to bridge from one l two to another l two. How should I bridge? If somebody has locked up enough capital and promises that hey, I have this $10 billion of stake and I promise that this is the roll up state of this optimism, or opitrum or ZK sync, then I can use that to lock the state and move around like information across these LTOs at a much, much lower latency than even Ethereum. So bridging using crypto economic security. The third one is MeV. How do I handle MeV on these roll ups? Do I need a decentralized sequencer? Do I need some threshold mempool? What kinds of modulation can I do on Mev? And this is very application specific. There's no universal way to do MeV management. Sometimes you want first in, first out, sometimes you want auction.
00:16:14.110 - 00:16:42.342, Speaker C: Sometimes you want threshold encryption. Sometimes you want event driven actions like limit orders should be automatically executed. All of these are services coming up on Agon layer. So this is something we're very excited for. Then. Another category is watchtowers. Right? So you have these execution environments which can have faults, but you need a group of nodes which are watching and can trigger these fault alerts.
00:16:42.342 - 00:17:29.434, Speaker C: So they need to be incentivized, they need to be staked, and that can happen on that's Watchtower is a category coming up fast. Finality. Right now, a roll up sequencer makes a kind of pinky promise that, hey, it's final, it will get finalized on Ethereum, but I promise that I'm going to post this to Ethereum. But instead you could have like a committee, which is state, which makes that promise with an economic credibility, rather than just reputational credibility, which is what sequences are doing today. So, examples of categories on just roll up services, and I would say we didn't think of more than just the first one eigenda ourselves. The rest is permissionless innovations just coming out of the market, these kinds of ideas. So this is a meta category, roll up services.
00:17:29.434 - 00:17:52.654, Speaker C: Another category that we're seeing is what I call a coprocessor. A coprocessor is different from a roll up in that it's not a chain. Like, there is nowhere you'd go to a block explorer and see the order of transactions off that system. A coprocessor is something that is like a service. I'm on Ethereum. I call a service. Let's say I want to run an AI like inference protocol.
00:17:52.654 - 00:18:20.806, Speaker C: The inference protocol runs somewhere, and then the answer comes back with a certain amount of trust. And you can get trust from two kinds of things. One is zero knowledge proof that, yes, this is executed correctly. Or it could come from crypto economic assertion that, hey, I have like $500 million backing this claim. If this claim was wrong, you will be able to, whoever is receiving this claim will be able to flash and redistribute $500 million. That becomes very powerful. So Agilear helps.
00:18:20.806 - 00:18:56.358, Speaker C: The second category of coprocessors, we call them crypto economic coprocessors. A coprocessor that comes with a certain amount of economic integrity attached to them. And this could be. I want to do AI inference, I want to do SQL databases, I want to run arbitrary Linux programs, I want to verify zk proofs not on chain, but off chain. So these are the categories of things we're seeing in core process. I think this is one of the most interesting and exciting factors, because for the first time, we call these smart contracts. I think all of us alluding to this a little bit before when we started.
00:18:56.358 - 00:19:19.738, Speaker C: And if you think about how smart are they, they're rigid contracts, really. Like when you enter into a smart contract, they're very rigid. They're not that smart. Like this simple curve that uniswap started with x Y equals K, right? It's a very simple equation. It is not a huge amount of intelligence. It doesn't have access to the history of all the data. It's not using some complex machine learning to adjust prices.
00:19:19.738 - 00:20:06.122, Speaker C: But that's how contracts have to evolve. They have to actually bring smartness, whether that is databases, that is machine learning, AI protocols, whether that is running general purpose computation like a general Linux box on top of it. All of these are really needed for us to go to systems that are actually smart and rigid means if they say something that is actually right. And one way we bring rigidity to the system is that each of these claims are packed with an amount of economic security. So you know that either the claim is right, or you will be able to redistribute a certain amount of money. And that gives you very strong rigidity. So as long as you don't move more economic value than what the stake is, you actually have like unconditional correctness.
00:20:06.122 - 00:20:19.714, Speaker C: So that's a really powerful rigid mechanics by which you can now bring an arbitrary amount of computational intelligence to bear on these smart contracts. So that's a second category. I'll stop before going to the other one.
00:20:19.752 - 00:21:17.410, Speaker A: No. And let me also jump on to add a very specific example that I think is pretty compelling of how this could work. So with this, you can have smart contracts execute based on the secure output of a machine learning model. And when I say secure, I mean like Ethereum level security, right? Where you run a consensus algorithm to decide the output of this AI model. We all agree that it's correct, and it can be used to trigger financial logic. You can't just connect to private APIs and say, okay, this smart contract is going to manage a billion dollars based on how this private API tells it to. You really need this sort of economic security, where if you're managing a billion dollars in that smart contract, you need the output of a machine learning system to be validated, and you need it to be secure in the way that Ethereum is secure.
00:21:17.410 - 00:22:06.406, Speaker A: So a very specific way you could use this. We all know that the interface layer to talk to blockchains and smart contracts is not very good. We've all used metamask and fumbled around trying to figure out how to interact with a smart contract. Why did it fail? This gas market, it's all quite complex for your average person. Imagine instead if the end user could interact with their wallet using natural language, like a large language model. So let's say you have a bunch of assets on the optimism roll up, and you want to buy an NFT. On the arbitram roll up, you could say, hey, I want to buy this asset at this price, get it done.
00:22:06.406 - 00:23:14.214, Speaker A: And basically, Eigen layer, the security afforded by Eigen layer allows a service to interpret that language that the user wants and actually put together a series of smart contract signatures that gets that done. Right. So you could imagine the interface layer that we've all been using for years to interact with blockchain systems could, in theory, be reduced to natural language models. So the way you would interact with smart contracts is the way you interact with chat GPT, where you just, in normal language, layman's terms, say, I'm interested in buying this asset or making this trade. And in the background, there might be five or six different signatures that need to happen, or attestations, and we can get very high economic security that those things are happening in the correct way that the user intended. So the potential here is this is just one example, but I think just this example is a really big deal. It's sort of replacing the entire way that users interact with these systems, with natural language models.
00:23:14.214 - 00:24:03.270, Speaker A: And this, to me, would be a huge breakthrough in usability for your average person who understands what it means to type, hey, I want to buy this asset, and I want to use the bitcoin in my wallet. And the asset might be on ethereum, and you might have to then bridge your bitcoin to ethereum, sell it for ether, go onto a roll up, and then go buy the asset. Right? And the large language model can interpret your instructions and come up with a series of smart contract signatures needed to execute that and have it all validated by one of these Eigen layer ABS services. So that's just one example that I think would be like a seismic shift in the way people interact with blockchains and genuinely be like an order of magnitude improvement for the whole ecosystem.
00:24:03.430 - 00:24:34.914, Speaker B: Yeah, and what I like about that is that it addresses the issue of a lot of people. If they're not in crypto, they're not even going to know the difference between arbitram and optimism. They're not going to understand, why can't you use your bitcoin to buy that? NFT, that's on optimism. So hopefully in that future, people won't even know where things are located or whatnot. But I did want to ask, because there's a lot of talk about how now with all these different roll ups, there's also a lot of fragmentation. So do you guys see this as a way to address that problem?
00:24:35.112 - 00:25:27.110, Speaker C: Yeah, I think I was mentioning earlier that bridging across these roll ups would be done by some kind of economically secured bridges. And we're seeing many, many of those bridges come up. And what I think Olaf's adding here is those bridges could be triggered from natural language. When somebody says, hey, do this for me, and then those instructions are interpreted in a rigid way, that you're not just trusting some third party, but actually having consensus on the output relationships and then actually have that happen. So I think in some sense, the way I think about it is these will be different services. And then there is a kind of like a service that triggers other services, a UX service, which could be this NLP models, which will then go and trigger these. Now trigger the bridging, trigger this action.
00:25:27.110 - 00:25:29.510, Speaker C: That'd be like super fun to see.
00:25:29.580 - 00:25:32.326, Speaker B: NLP, as in like natural language processing or something.
00:25:32.428 - 00:25:34.710, Speaker C: Yeah, NLP is natural. Exactly.
00:25:34.780 - 00:25:38.086, Speaker B: And then I think you had another category you were going to talk about.
00:25:38.108 - 00:26:31.178, Speaker C: We have three more categories to talk about. Okay, cryptography category. You want to bring more advanced cryptography into blockchains. And why? Because right now blockchains are either verifiable and transparent, but don't allow for privacy. So you want rich privacy expressions in blockchain. And while also preserving verifiability, you need to have more complex cryptography, like secure multiparty computation, where you're distributing a secret across many, many nodes, and they all do computation portions of the computation and arrive at the answer without no one actually having access to the actual private information. You can have trusted execution environments, which are special hardware zones which are built with cryptographic integrity by intel and so on.
00:26:31.178 - 00:27:43.050, Speaker C: And you can actually require that validators or node operators actually have these networks of trusted execution environments, which augments other kinds of trust. You can have fully homomorphic encryption, where you encrypt the data, and then all the computation is done inside the encrypted space. So again, like amazing breakthrough technology, these kinds of things, we are seeing many, many projects building on idler with all of these types of fundamental technologies, and they used to exist in some way or the other, in other chains. For example, Oasis was a trusted execution environment chain on cosmos. The power of these services becomes much, much larger when they become composable across all the other kinds of things we are talking about. The evolution of the Aguilar ecosystem has been really interesting to watch, where we are already seeing people build an ABS that will serve other AVs, or only possible because other AVSs will start interacting with them. And of course, all of these are simultaneously are co emergent.
00:27:43.050 - 00:28:31.930, Speaker C: But it's exciting to see that, because now, oh, I can build a service that will help these other services. And now if I put these services together, it's a whole, it is something that will actually ten x the infra landscape of crypto. So this is another category, cryptography, I'll say another category is proofs, broadly laid out. Normally, we think of proofs as zero knowledge proofs or computation proofs, but there are other kinds of proofs you need to assertions that are verified. Right? For example, right now I'm doing this interview from the University of Washington in Seattle, and how do I prove to a blockchain that I'm actually in Seattle? This is called a proof of location. Until now, we talk a lot about blockchains being decentralized. And geography is a core aspect of decentralization, whether it's regulation or other reasons.
00:28:31.930 - 00:29:25.838, Speaker C: But how do we measure decentralization from a blockchain? And it's shocking to know there is no locus of decentralized measurement of decentralization today. And the first service measuring decentralization is coming up on I can layer called witness chain, which is a proof of location protocol, which basically what it does is it has a decentralized network already, the large decentralized network underpinning Ethereum, they send network pings back and forth to verify that you're close enough to other nodes which are also in the same zone, and concordance among the latencies from all the different measurement zones to actually establish. Okay, yes, Sriram is right now in Seattle, and this is a really powerful service. So as an example, of a proof. Another example of a proof would be approve of meshenhood. Like I want to prove to you that I have a unique iPhone device. It's not the same as any other device.
00:29:25.838 - 00:30:13.594, Speaker C: And these devices come up with this root certification. These can be verified on chain and then presented to other services. So this is another example of proof of mesh and hood. A third example would be I have some private data which is locked across many servers. Imagine like Olaf's building like a decentralized marketplace which wants to compete with Amazon and he wants to offer a discount for anybody who has used at least spent $1,000 a month over the last twelve months on Amazon. That's the customer that he wants to attract. How do I verify to him that that's actually the case that I have made these transactions with Amazon? I can log into the Amazon web server and I have know encrypted link with Amazon using this thing called TLS to do that.
00:30:13.594 - 00:31:24.680, Speaker C: But how do I certify this to a decentralized network? There are these really brilliant schemes called TLS, not fees, coming up where when I open my encrypted connection to Amazon, some node sits in the middle that I give authority to that kind of verifies the encrypted traffic and then later I can do a proof against that traffic that actually I had like thousand dollar of balance last month on Amazon. Another example of a really cool service coming up on ilair. So this is another category, proofs, and finally a category which is very special and unique to restaking an eigen layer is all these other services that I mentioned could have been built by anybody staking enough money and having enough node operators. The last category is what we call ethereal inclusion guarantees, which is it's about particularly the Ethereum l one blockchain, and I want to modulate. When you're validating the Ethereum l one blockchain, you have to make sure that the transactions you put in are all valid. But there is nothing that decides what transactions you put in and what transactions you don't. And there's no way for you to make assertions or promises about specifically what transactions you do put in.
00:31:24.680 - 00:31:59.922, Speaker C: For example, if Ethereum had this ability, a validator could say, hey, my blob is coming up in three slots, and if you give me an additional fee, I'll promise you that your l two like blob or whatever thing will absolutely be included three blocks down the line. I'll make sure of that. And I can make a promise like that about an Ethereum l one block. So this is what we call l one inclusion guarantees, or ethereum inclusion guarantees. Lots of interesting applications. Imagine I want to build a stable coin liquidation protocol. I have to make sure that liquidations clear as fast as possible.
00:31:59.922 - 00:32:22.460, Speaker C: But if the block proposers are already promised to take liquidations and enforce it, otherwise they'll get slashed, you will have a high rigid guarantee that actually those things will happen. So lots of interesting applications to modulate Ethereum l one itself. So that's another kind of meta category. So these are all the types of things we are seeing. It's a kind of explosion of ideas we're super excited about.
00:32:23.070 - 00:32:54.158, Speaker B: Yeah, it's super exciting. There's just as we've discussed, a lot of innovation that's happening. So in a moment we're going to talk about potential risks. But first, a quick word from the sponsors who make this show possible. Polka Dot is the original and largest layer zero blockchain with over 2000 plus developers and the anticipated Polka dot 20 upgrade will be a massive accelerator for the ecosystem. Upgrading the infrastructure with eight times higher transaction throughput and twice as fast block times. Perfectly tailored core time for the needs of every protocol.
00:32:54.158 - 00:33:47.602, Speaker B: Trustless bridges internally and into Ethereum cosmos near binance smart chain and revised tokenomics and the implementation of a token burn to reduce inflation. Perfect for Gamefi and DFI to build, grow and scale. With one of the most active crypto communities in this space, Polka Dot recently announced a partnership with mythical Games, bringing top games like NFT rivals with over 650,000 players and 43 million transactions to pave the way for Gamefi and the polka dot ecosystem. Get your web3 ideas to market fast with economics that work for you. Think big. Build bigger with Polka Dot join the community at Polka Dot network ecosystem community back to my conversation with Sriram and Olaf. So this has come up time and again, but one of the potential risks that people commonly call out is possibly rehypothecation more.
00:33:47.602 - 00:34:09.030, Speaker B: I guess it really relates to the security and then these cascading risks that can happen due to the restaking. But interestingly, I even see people saying things like this, crypto analyst Miles Deutscher said, quote, I see restaking as the next version of the DeFi ponzies. So I'd be interested from both of you what your response is to these concerns.
00:34:09.190 - 00:35:11.920, Speaker A: I'm sort of assuming that the underlying criticism there is that basically node operators now are staking in potentially hundreds of different proof of stake services simultaneously. And in theory there could be slashing risk across all 100 services. Again, in theory, because each service decides its own rules. It's an open marketplace, right? So as a staker, you get to decide what to opt into. And likely, I think the end state of this is that staking nodes select the types of risks they're willing to take on for AVSs and sort of define those risks very precisely and sort of auto join every AVs that lands within that risk profile. That I think is the kind of the end state of this marketplace. I do think there is risk every time a staking node is staking on a new system.
00:35:11.920 - 00:36:51.550, Speaker A: I also though think that there's a lot of work being done on sort of preventing slashing from operator error. So slashing in proof of stake systems is meant to deter bad behavior. And when I say bad, I mean somebody actively trying to hurt the system and sort of attack the consensus protocol and come up with an output that's different than what it should be. Now that interestingly though, the vast majority of slashing, and I would say like 99.9% of cases where somebody gets slashed, are in fact the intentionality is not really attacking the system, it's operator error of some kind, right? They go offline or their software is misconfigured or something like that. I do think there's a kind of big push that it's going to be accelerated because of Eigen layer to get software in the hands of node operators that can basically detect if they are going to run the software as intended, and can better tell the sort of, quote, intentionality behind those staking nodes. I do think this is going to be a very important part of the growth of the Eigen layer ecosystem is staking nodes feeling confident that they can stake on arbitrary abs that they've never heard of without risk, that there's going to be an attack in that system where all of a sudden they're out of consensus and therefore slashed, even though they had no intention of hurting that mechanism or being out of consensus in that mechanism.
00:36:51.550 - 00:37:41.262, Speaker A: I really think it's quite different than just endless rehypothecation, right? So like, okay, I'm going to stake ether, receive a bunch of tokens that represent that staked ether, and then stake that, receive a bunch of tokens that represent that. Then you're at a derivative of a derivative, and then I'm going to stake that. It's not really how this works. You're not sort of re hypothecating a derivative over and over and over and over. You're sort of just rehypothecating that core collateral over and over. It's sort of like I put up my house for a mortgage and take a loan. It's not like I then take that loan to buy a new house with a new mortgage, and I take that loan to buy a new house with a new mortgage, and I'm basically leveraged now.
00:37:41.262 - 00:38:11.826, Speaker A: So I think that in that particular quote, you said, laura, it's more about rehypothecation leading to leverage. Right. And that being at systemic risk, I don't view this as that at all. I think that there is risk, like I described, with staking nodes, like staking in 100 different systems. But I think the way to mitigate it, it's just a very different type of risk than a derivative of a derivative of a derivative. Adding leverage to a financial contract.
00:38:12.018 - 00:38:44.386, Speaker B: One question before, and maybe Srirami, you can answer this, is just in that scenario, like, if you do get slashed, it sort of feels like, well, then I don't really know what happens. Like, let's say you are staked in ten different things, and you get slashed, then how does it affect the security of the other systems that you're staked in? And then the other thing that I wanted to know about that is, if it's like every AVs is setting its own standards, then is the security of the overall system determined by kind of the lowest common denominator? Yeah, these are questions that came up for me.
00:38:44.408 - 00:39:13.018, Speaker C: Yeah, no, those are useful questions. One way to start from where Olaf left off, which is, I think, the type of risk, why is it fundamentally different, is slashing. Risk is endogenous. You control it as a validator. If you're not bad, you will not get slashed as long as the system holds that property, that if you're not malicious, you will never get slashed. That's a technical problem to solve. Like, how do you build a system which is actually the case? This is the same problem for ethereum itself or any proof of stake system.
00:39:13.018 - 00:40:02.598, Speaker C: How do you make sure that you're not getting slashed for just running the get node? Like, this was a big thing that the whole community was discussing, like a few months back. This was a very important problem, but it's a technical problem, so fundamentally, it's a different nature. And the way to think about it is slashing is an endogenous risk. You control that you will get slashed or not, because you're opting into these objective smart contracts on these various AVs, which specify what the slashing condition is. So you control whether you will get slashed or not. As opposed to if you actually take 100 x leverage instead of opting into 100 services, you're taking exogenous risk, something you don't control, like the market price moves 1% and then you will get liquidated. That's absolutely not the case on Eigen layer.
00:40:02.598 - 00:40:50.042, Speaker C: Eigen layer is a validation platform, and it's only meant to slash you if you're actively malicious. Why is there non zero yield in this system? It's due to an information asymmetry. If I'm a validator, I know I'm honest, so I'm not going to get slashed. You don't know that I'm honest, so you're paying for know covering these asymmetry of this information that I know I'm honest, so I'm actually willing to back it with a portion of capital. Now, going back to Laura's question, how do avss do know how much security or whatever they're getting? I think the right way to think about it. Restaking became a popular word, and it invokes a certain degen like defi type feeling to it, and it sounds like we have authentication, so people conflate that. But really, Eigen layer is shad security.
00:40:50.042 - 00:41:42.810, Speaker C: And shad security is one way to think about it is imagine there are 100 protocols, and each of which can afford, for the fee that they're paying $100 million of stake, 100 protocols, each of which can afford $100 million of stake. This is one world where they're all separate. They have separate pools of stake they're maintaining, and then they have these protocols. The second world is all of them pulled their stake together into a $10 billion pool, which is staked across 100 services. Now, the power we staked across 100 services, I argue that the second world is actually really much better, and the reason is to attack any one protocol. Now, it's the same fee across the two worlds because the same amount of stake and same amount of fees. But in the second world, to attack any one service, you need $10 billion of capital, and you know that you will lose $5 billion of it.
00:41:42.810 - 00:42:19.800, Speaker C: So there is a kind of hardening of security at scale. Like, as you get more and more security bundled together, you're just like, much stronger. The same reason why nation states have armies, not city states. And even across nation states, you pull together to form alliances. That's just with it. But one thing you lose when you're aggregating security like that is you're losing attributability, because maybe in the first world, one of them is Coinbase. And Coinbase says, hey, these other services maybe have 100 million stake, but I have 3 billion stake because I'm Coinbase and I'm running base.
00:42:19.800 - 00:43:14.650, Speaker C: Now, this was missing in what we call the first simple model of security, which is pool security, where everybody is just pooling together. There's no attribution, so we solve this by doing more complex accounting. On Eigen layer, we have something called attributable security. Attributable security is you have this common pool, everybody's validating everything together. But among this pool, I'm going to give a given service an attribution which says that no matter how many other services trigger slashing simultaneously, you will be able to, you as an ABS, will be able to slash and redistribute this much amount of money. There's an auction which actually sells these rights. So this means in the second world as Coinbase, you could still take out $3 billion of economic security while attributable economic security while still getting $10 billion of pooled security.
00:43:14.650 - 00:43:49.714, Speaker C: So you're simultaneously getting the benefit of attribution while also getting the benefit of pooling. So this solves this problem kind of completely, because now it doesn't matter what's happening to these other services. It's their problem to deal with. The Eigen layer like interface to an ABS is you tell me how much attributable security you want, and I'll give you that. And Eigen layer has to now maintain, do much more work to maintain this, what we call proof of solvency. It has to be solvent if all the EVSs simultaneously draw their claims. But that is what we maintain.
00:43:49.714 - 00:44:21.946, Speaker C: Eigen layer remains solvent even if all of the attributions are simultaneously requested. So you're now completely buffered across all these services requesting attributions simultaneously. So this is a kind of like a breakthrough that we made in the last six months on how actually Eigen layer attributions work. So the other thing that builds on top of this is now imagine you're building a bridge. Okay? You're building a bridge. A bridge may require anywhere between, let's say, $10 million weekly volume to $1 billion weekly volume. It's crypto.
00:44:21.946 - 00:45:07.502, Speaker C: There is 100 x variance between a bull market and a bear market and a good week and a pat week. So you may have like a variance which is from 10 million to 1 billion. So if you were just on your own, you would have to provision for the most demand that you would experience or miss out on that demand. If you only provision security for 100 million any week where there is volume more than 100 million, you're up like you don't have security to deal with it. In eigen layer in the pool security model, you can buy attribution on the go. Like you'd say, man, I'm getting more demand, so I'm going to actually go and pull more from the pool security, buy more attribution claims. I can actually now have 1 billion for this week and only 10 million for the next week.
00:45:07.502 - 00:45:44.470, Speaker C: So we call this elastic scaling of security, which is exactly what for compute, Amazon did is elastic scaling of compute, which is what the EC two is elastic cloud computing. And with elastic scaling of security, you get as much security as you want. And by having a common pool, you can kind of smooth out all the random variations. Because when BTC is going up, Saul is not, and when ETH is going up, something else is not. But having a common pool means we can average out across all these fluctuations. Each one buys the amount of security that they want. That's a really interesting dynamic.
00:45:44.470 - 00:46:38.330, Speaker C: There are other further more complex dynamics when imagine there is an application like farcaster using, let's say five AVss. It uses an oracle, it uses the data availability, it uses like AI core processor. And Farcaster is doing some kind of weekly volume of $1 billion. If it had these as separate pools of security, it has to go and buy this attributable security of 1 billion separately from each of these services. Because any one of those services, the Oracle, the data availability, the AI, any one of those services screw up, their money could be lost. So now in Eigen layer, because there is a lot of shared staking, the same group of nodes are sticking across many services. You only need to buy one x of that attributable security and say that any one of these services fails.
00:46:38.330 - 00:47:14.758, Speaker C: As long as you can assure me that any one of those secure services fails, you will pay me 1 billion. Now you're suddenly saving your insurance or attribution fee by five X as you're bundling many, many services. So there is an economy of scale, of attribution. There is like elastic scaling of security, there is the power of pool security. All of these are like foundational features that we've thought about when you're building the first universal crypto economic system of security. So instead of, I think a lot of people have this view that it's some kind of like a DGen platform. It's the exact opposite of being a pure Djen platform.
00:47:14.758 - 00:47:19.386, Speaker C: It is the sharpest system of economic security available today.
00:47:19.568 - 00:47:51.300, Speaker B: Well, that's going to be disappointing news to the Degens, who are following your points program and probably eagerly anticipating an airdrop. So I got to ask this. Will Eigen layer do a token? You guys have a points program, so just curious to know what your thoughts were when you went to design it. Like, why do you have a points program? Why did you design it the way you did? And what are you thinking when it comes to a token? And either of you can answer, because I know Olaf, you're an investor. I'm sure you guys discuss these things.
00:47:52.310 - 00:48:28.874, Speaker C: I'll take this and then let Olaf add something on top. The points represent the amount of eat you have staked and how many hours or how many weeks. So it's basically, eat hours is the kind of fundamental unit. It's just a measure of participation in the eigen layered system. And unlike many other point systems, which are arbitrary, it's just a very simple, clear measurement of how much staking contribution you've done into the protocol. So that's the eigen layer points. There's nothing mysterious about how these points are created or allotted.
00:48:28.874 - 00:49:13.034, Speaker C: It's a simple measurement. And why do we have the points program? As we build this protocol? When services come in and they want to demand stakers and operators, they want people who have committed deeply into the ecosystem. So that's a simple measurement. For example, AVSs, if there's over provisioning of security, they might choose only those who were around in the system for long enough. There's a simple measurement for it. And as we aim to decentralize the protocol in the longer run, obviously there is governance rights that is accorded to people who have actually participated in the protocol. And staking is one element of participation in the protocol.
00:49:13.034 - 00:49:22.160, Speaker C: So obviously, there will be stakeholders in the governance of the protocol as we go on, but we have not thought far enough to actually talk about.
00:49:22.790 - 00:49:45.960, Speaker B: Oh, really? Interesting. Yeah, because, well, actually, let's throw this in there as well. I'm sure you know, Kelpdow recently began allowing people to take their Eigen layer points and get liquidity out of them. So in a way, that is kind of right now the closest thing that we have to an Eigen layer token. So I was kind of curious for your thoughts on that.
00:49:46.970 - 00:50:11.086, Speaker C: Yeah, one of the things I like to actively discourage is people taking leverage on top of these LRTs. I said there's no leverage in the Eigen layer protocol, but you actually can take leverage outside of the Eigen layer. Protocol, go and deposit your LRT into a lending pool and then borrow against it, and then loop this several times.
00:50:11.268 - 00:50:17.540, Speaker B: Assuming that liquid restaking token for people who are wondering what that stands for.
00:50:18.790 - 00:51:49.374, Speaker C: And there are many protocols like Kelp and Etherfi and Puffer and Renzo and Rio, which are building these kinds of protocols, which are very useful actually, because they outsource management of how do I choose operators? How do I choose Avss? How do I do risk management? Like have a consistent, decentralized governance protocol? Each of them have their own thing, so you should do your own research before engaging with any of them. They are external to eigen layer, but it is a useful service. But while doing it, people are now the DGEn version of it is to actually go and take leverage on top of it, which is you take a liquid restaking token, which is potentially represents your e deposited in the protocol, and then go and borrow against it ETH, and then go and do this again and again. And if ETH to the liquid restaking token moves from one is to one to they'll get liquidated and lose their capital. Laura, you were asking me earlier, what do you think about people doing expecting this to be like a new defi yield? And is there any Ponzi nature to it? Eigenve is designed to have zero principal risk. If you actually staked and the operators ran correctly, you don't take any principal risk. But the way our space is, somebody figures out how to take principal risk, we're actually going and taking leverage outside the protocol and going and doing this thing.
00:51:49.374 - 00:52:36.586, Speaker C: This can be very dangerous. This is a very risky thing to do, because there's all sorts of reasons why, like a liquid restaked ETH will not be worth one ETH in the short term, even if it becomes equal to one ETH in the long term, there is liquidity crunches. Let's say there is a hack somewhere in their code, which they can even have an upgrade console and upgrade, but who knows? That takes a week. And within that, the thing will deep at all kinds of reasons why a liquid restaking token will not be equal to one e in the short term. So doing anything with this leverage on this is extremely risky. And when I'm saying eigen layer doesn't have leverage, it's in the Eigen layer protocol. When you stake across multiple services, it's the only risk.
00:52:36.586 - 00:53:03.080, Speaker C: It's the operator risk that Olaf already alluded to. But people are doing this stuff. This is very risky. We advise people not to do it in terms of just a representation for rewards, the points. It is not something we are encouraging, but by itself it doesn't create any leverage or anything crazy in the protocol. Of course these points may be worth nothing. That is the risk that you're taking when you're going and buying a point.
00:53:03.080 - 00:53:14.022, Speaker C: But that's a different kind of risk than actually taking these kinds of leverage risk, which you're thinking that you're not taking any risk and actually you may get lose all your capital.
00:53:14.166 - 00:54:27.700, Speaker A: Yeah. The only other thing I'll add is I know that sometimes in our space people get confused about product market fit and sort of economic incentives. Let's say you're building a social platform and it's post to earn, right? You might see a lot of people posting and you might think you have product market fit, right? But in reality you've added an economic incentive that is perhaps not sustainable or like short term oriented, where you in fact don't have product market fit. And I think it's very important to understand that a lot of these incentive models can increase the rate of growth of something that already has product market fit. This is like Uber saying, get your first ride free, right? Uber has product market fit. That first free ride is not the only ride people take on. Know after that they continue to use Uber because they like the service.
00:54:27.700 - 00:55:36.774, Speaker A: I do think sometimes in crypto I see like first ride free and then it's confusing to people whether anyone wants the second ride or not. So you can subsidize through these sort of incentive systems the growth of things that already have product market fit. However, these subsidies do not replace product market fit. And the one thing I'll say about Eigen layer is it's very, very clear that there's product market fit without any sort of subsidy system. Whereas like in a post to earn social protocol, you might see the behavior that's more like, say an axio infinity, right, where it's like, wait a second, are we subsidizing the growth of players in an awesome video game community or are people just kind of grabbing that first free ride and the moment their free ride is over, they leave the system? Right? So it's very clear to me that eigen layer is not reliant on any sort of incentive outside of just the usefulness of the service.
00:55:36.972 - 00:55:51.734, Speaker B: So one quick question then I did want to ask is you kind of hinted, I feel like it was sriram. Maybe you sort of hinted that potentially the points at some point would translate into being used for governance. Did you say that?
00:55:51.872 - 00:56:07.938, Speaker C: Yeah, it could mainly be used by abs to choose what stakers to opt in for a given service. It could be used as a mesh of participation in governance. We don't have a concrete roadmap on exactly all the ways that this could be used.
00:56:08.104 - 00:56:20.578, Speaker B: So I don't know if you remember back in the day, people got concerned that Lido's dominance could lead the LDO token to kind of be quasi governance token for Ethereum. So do you think a similar situation could happen for an Eigen layer token?
00:56:20.754 - 00:57:04.142, Speaker C: Yeah, so I think there is a fundamental difference between something like Lido and something like Eigenvear. Lido decides who the operator set is that actually can run Ethereum nodes. So imagine 100% of Ethereum stake went through Lido. Then the lido operator set is identical to the Ethereum operator set. Eigen layer has no such subjective judgment. Eigen layer just says, anybody who wants to stake and be an operator can be an operator. This is a very conscious decision that we took that the eigenvalue protocol only makes objective judgments and not subjective assignments to operators.
00:57:04.142 - 00:58:01.106, Speaker C: So that is a fundamental difference. So even if 100% of each stake went through eigenvalue, you don't have the same problem that Lido has, which is that they are deciding the operator set, whereas Eigen layer is not designing the operator set. An operator set decision is critical to decentralization, censorship resistance, other properties of the Ethereum protocol. And it's one of those things where the Ethereum protocol is not yet complete. And I say it's not yet complete because the protocol needs censorship resistance, but has no way of enforcing it inside the protocol. It is reliant on us shouting on Twitter and just canvassing people to actually get these properties. But I would say of that kind of a spectrum, Ethereum is the most sophisticated in the sense that it is actually not reliant on the operator set for safety at all, because if you violate safety, you will get slashed.
00:58:01.106 - 00:59:00.342, Speaker C: It is written in protocol, it's as rigid as it gets. So we're not trusting the operator set to maintain safety, which means like, don't double sign a block or don't sign an invalid block, you don't have to go. And nobody comes on Twitter and requests this because you know if you do it, you're going to lose your money, so nobody's going to do it. But there are some aspects which have not been internalized yet, because this is a new emerging area, and we have a new proposal for this called revere, which is a mechanism to penalize for censorship in Ethereum itself. But these are the things that we are actually like. We don't like this social herding that is necessary to actually make the Ethereum protocol work. Because is it a protocol, or is it like some philosophy that we all have to buy to actually, even though I'm very aligned on the philosophy, but we don't build a system assuming the participants are going to subscribe to a philosophy like that's not a rigid system.
00:59:00.342 - 00:59:39.182, Speaker C: A rigid system enforces its rules internally and self consistently. That I don't need to know this. So the way we think about it is, first, is like Eigleir does not impose any subjective considerations on the operators and operator side, which means we don't have the same problems that something like lido has. But also recognizing that Ethereum itself can actually internalize its constraints much better. And actually proposing. I gave a talk on this protocol called Revere in the censorship WTF workshop. But how do we make Ethereum better? So that's our two answers to that question.
00:59:39.182 - 00:59:45.154, Speaker C: In fact, one of our stated goals is the internalization of the Eigen layer protocol into Ethereum.
00:59:45.282 - 00:59:46.440, Speaker B: Yes. Okay.
00:59:46.810 - 01:00:23.326, Speaker C: Eventually, Eigen layer should be like a core part of the Ethereum protocol. It doesn't need to be something external. Of course, there's a lot of details that we are figuring out. Like all the things I mentioned today about attributable security, how do you account for this correctly? All of these need to be ironed out in the open kind of market, where it's at like an arm's length from Ethereum, where these experiments are. And eventually, as the results are solid and rigid. This is one of the reasons why many Eigen layers, like, oh, it's not re restaking or anything like I think Olaf mentioned briefly before. The reason is you need a single place which has the full accounting.
01:00:23.326 - 01:00:52.590, Speaker C: That's the right architecture. And right now, Eigen layer has full accounting. Eigen layer has minimal information interfaces to Ethereum, because Ethereum is not built with the idea that something like Eigen layer will exist. And now we're trying to kind of get Ethereum to kind of coevolve or maybe even just internalize it, because that can be like a single place of accounting for everything. So that's our long term stated goal, that something like Eigenve becomes something like enshrined into Ethereum.
01:00:53.170 - 01:01:27.654, Speaker B: I'll be super interested to follow that. So with our time remaining, I definitely want to talk about AI, because, you know, polychain has invested in things that are working with Eigen layer. And there's a number of different announcements of Eigen layer working with different AI projects such as alt layer ritual. You guys can kind of talk about any of this that you want, but yeah, we have limited time. But I did also just want to throw in know Sriram, you have such a background in AI as well, so would be curious to hear kind of on any of the topics that I just mentioned from either of.
01:01:27.772 - 01:02:35.534, Speaker A: Yeah, yeah. I'll quickly jump in to just know. We have invested in, I think, about a dozen projects building on Eigen layer already. I also anticipate that many of the projects in our portfolio that did not have a stated goal when we made the investment to build on Eigen layer will realize that Eigen layer is probably the best home for the service or technology that they're building. I'm looking for more projects building here because, as I said, I really think the ecosystem growing here is a sort of step function improvement on what exists today. It's like a real expansion on the types of things you can build just on Ethereum today. And when it comes to, more specifically, Laura, your question of this kind of AI, call it AI coprocessor, more specifically category, I talked a little bit about this replacing like a wallet interface with the language model interface, so that it just abstracts away all of this complexity that the end user has to deal with today.
01:02:35.534 - 01:03:24.154, Speaker A: We've talked about this abstraction for years in crypto, like for over ten years. Everyone knows these wallets are kind of a disaster. We finally have, I think, a possible path, right? And I'm not saying it's easy or it doesn't come with its own gotchas, but a possible path to a sort of natural language model. If you call your banker, you can say, I want to buy five shares of this company. And they say, okay, great, it's done right? It's like a language model thing in the background. There's all sorts of mechanisms that allow that to be possible, but the end user doesn't have to know what a market maker is or what exchange they bought it on or where the custodian is. And they don't have to ever interact with any of the low level systems.
01:03:24.154 - 01:04:20.446, Speaker A: So I do think that AI for abstraction is a big one. I think another one, though, is this fully homomorphic encryption. So you can imagine encrypting data and then sending it to an AI model to sort of compute on it and send you back the output. And interestingly, the AI model never knows what you were trying to figure out. It can sort of do math, for example, on encrypted data without you revealing the data to the model. So there's lots of interesting applications here, like, let's say you have a huge data set that you think will be predictive of prices, but you obviously don't want to reveal the data set because it's sort of your edge or alpha in the market. You can encrypt the data set, send it to third party to execute predictive computation on it, and send it back to you.
01:04:20.446 - 01:05:02.670, Speaker A: You pay them for the service, but also they don't get the data, so they can't take advantage of you sharing it in some way. I think that smart contracts just triggering based on the outputs of AI algorithms is going to be a huge category. And this language model wallet, I think, is like the first thing I sort of thought of. But I think people will come up with many, many more things would be built here. And it's sort of like a feeling I had with early Ethereum, which is I couldn't articulate in 2014 when I read the Ethereum white paper. Okay, well, it's going to lead to DFI, dows, NFTs, in this order and on these dates. Right.
01:05:02.670 - 01:05:23.282, Speaker A: But I did know that it enabled developers to express themselves in ways that weren't possible before. I do think that that intuition or sort of spidey sense is tingling for sure. And we're seeing these early application use cases, but I really think a lot will get invented over the next year that I have not thought of.
01:05:23.416 - 01:06:41.546, Speaker C: One of the quotes from Olash from way back, I think maybe 2017 was like, I think he said something like, the world's best investor in 20 years may be an old Tesla sitting and doing trades. Taking a view on that. Actually, one of the things I'm super excited about is sovereign AI, which is sovereign means, like self sovereign. It's an AI that is not running on behalf of anybody, but it's running on behalf of itself, becomes possible on blockchains in a way that's simply not possible elsewhere. For these things to exist by themselves and to actually undergo darwinian evolution, they need a few things. They need a fitness function. What's a fitness function on a blockchain is how much wallet balance do you have? And to be able to use the wallet balance to actually, say, trigger an AI computation or protocol that actually goes and does a trade, does an MeV action, does some other thing, and then increase the wallet balance.
01:06:41.546 - 01:07:12.326, Speaker C: So we're absolutely going to see, I think, sovereign digital AI. This is not robots like self constructing, like progeny. But it's just like a wallet and an agent attached to a wallet that is sovereign by itself. This has to happen. And my prediction is, this is two years up. In two years, we'll see this. And some of this is going to run absolute rampage by going and attacking wallets and extracting money and doing all kinds of crazy things.
01:07:12.326 - 01:08:07.554, Speaker C: So we are going to need to do AI sanctions before we know it. So sovereign digital AI is going to be a category. They're going to just be these agents that sit on blockchains and go. Some of them will provide useful services, others will try to hack to make money. And the thing is, we will lose control really quickly because these blockchains have all the properties needed for these AIs to actually live, not because you have sensitive resistance, you have immutability, like all these properties that make it possible for this to arise as its own category, but more fun, more practical, more nice things also will arise. And one of my favorite things is how do we trigger more open innovation in AI? This big fight that's going on at the center of AI is open source versus closed source. And there are big problems on both sides.
01:08:07.554 - 01:08:45.178, Speaker C: Open source, of course, there's one dimension of safety, which I think actually being open means you are more safe in a very fundamental sense. Imagine you go out to battle with this opponent, but you know the opponent's entire battle plan. Why? Because it's open source. Like, if an open source AI goes rogue, you know everything about it. And can you defend against something about which you know everything? Yeah, I think it's much, much easier. But the fundamental problems I see are basically open source has no fundamental incentives. Closed source has incentives.
01:08:45.178 - 01:09:50.930, Speaker C: Open source has permissionless innovation packing it. Closed source has no permissionless innovation. Can we create a new model which has both permissionless innovation and value accrual to the creator? Because my kind of highest principle in all of my kind of principles is, is the system have a balanced karma. Like, you do something, you contribute to the Commons, is the Commons giving something proportional back to you, then you will have an incentive to go and contribute more and more to the commons. But if I pollute the commons, am I getting slashed? Like, am I actually getting the negative feedback back from the Commons? So that's the two things that are needed to actually make this work. One mechanism we have thought about a lot is a new licensing mechanism, which is called PDL, permissionless derivatives license. And the idea is, unlike any other license, which usually talks about the creators rights and what rights are afforded to the commons.
01:09:50.930 - 01:10:52.246, Speaker C: The permissionless derivatives license attaches itself to a platform, particularly a blockchain platform, says, hey, I'm creating this new software, but I'm putting it up on a PDL on Eigen layer or on like a system on top of Eigen layer, for example. And what it means is now anybody else can come and create. So the PDL says anybody can come and create derivatives permissionlessly, but they also have to deploy the derivative on the same platform and attribute it. Okay, it's not enforced by in protocol. Eventually, maybe with FHe and other things, you can actually enforce it in protocol, but initially it can just be enforced by law. That this is what the license is, that anybody can create derivatives and post it on the chain. Now what happens is the original create, so the value, now the blockchain monitors how much usage of these models and value accrued, and it distributes it among both the source and the derivative.
01:10:52.246 - 01:11:48.490, Speaker C: And is it static, is it dynamic? Can we do complex value allocation across chains? All of these are interesting problems we have some ideas for, but the core thing is this license, the PDL license, the permissionless derivatives license, allows, for example, AI creators to come and deploy models and other people to create derivative models on top and have value accrual. Like pass through this sequence of derivations rather than only to one guy. It's basically like ties the two things correctly. You have value accrual and you have permissionless derivations. So it's a new model I'm very excited about, and we are going to kind of popularize this a lot. But this is an idea that could be really powerful for AI, where I think permissionless innovation and value accrual to creators is going to completely outrun closed source. Like, oh, we have this brain trust at OpenAI.
01:11:48.490 - 01:12:10.158, Speaker C: Yeah, it's true, but always the amount of innovation and ideas outside your organization far exceeds the amount of ideas you can capture inside any organization. So that's one direction I'm super excited about is can we actually turbocharge permissionless innovation for AI on platforms like I am?
01:12:10.344 - 01:12:32.746, Speaker B: Wait. And just to like, when you talked about that, I saw so many different ways that that could work. It could work for just open source, I guess AIs like developers working on things. But then you were talking about creators, so I didn't know if you also meant they're literally like artists or whatever. So it could really be the full range of all these different types of.
01:12:32.768 - 01:13:21.760, Speaker C: Creative, specifically talking about the AI model creators, people who create and train these models, they are deploying it. But exactly the same ideas hold for all kinds of other things, like media and even inputs into the models, right? So if you think about a model, a model is like the algorithm plus data and plus compute, right? Compute can be hosted on blockchain and accounted for. And we see many platforms starting to do it. Data should be hosted on blockchains and accounted for and attributed and create a mechanism for them to be owners of the models. And then model algorithms need to come together. So if you can coordinate all these sites on a common legible substrate, which is, of course, blockchains, and then you see this system seems to have a lot of power.
01:13:22.450 - 01:14:01.906, Speaker A: Yeah. Get ready, you guys, for tokens that allow you to own part of these sovereign AIs. Instead of owning, like, a share of a company that controls an algorithm, you have much clearer sense of exactly what you own if you own a token that represents a share, so to speak, of one of these sovereign AIs, and in fact, could potentially govern the AI as well. I totally agree, Shiram. This is going to be, I think, a very big category over the next couple of years, and something that lots of very unusual, I think outcomes will occur.
01:14:02.098 - 01:14:12.702, Speaker B: Oh, my gosh, you guys, I'm so excited. I feel like we barely scratched the surface. I had to ditch a whole bunch of questions. But, you guys, this was so fun. Where can people learn more about each of you and your work?
01:14:12.836 - 01:14:23.310, Speaker A: You know, I think the polychain website, you know, has all the information you could ever want to know about, you know, our organization. So you can just check that out.
01:14:23.380 - 01:14:35.940, Speaker C: From our end, you know, at Eigen layer on Twitter is the e I g n l a Y E r is the right place and also my name straight on Twitter at sriram Kanan. Both of these are good places to follow and track of what we're doing.
01:14:36.630 - 01:14:39.986, Speaker B: Awesome. Well, it's been a pleasure having you both on Unchained.
01:14:40.178 - 01:14:42.200, Speaker C: Thank you so much, Laura. Thank you.
01:14:43.930 - 01:15:16.970, Speaker B: Thanks so much for joining us today. To learn more about Sriram Olaf and restaking and Eigen Layer, check out the show notes for this episode. Unchained is produced by me, Laura Shin, with help from Nelson Wong, Matt Pilchard, Wanda Ranovich, Megan Davis, Shashank, and Margaret Korea. Thanks for listening. Unchained is now a part of the Coindesk podcast network. For the latest in digital assets, check out markets daily, five days a week with host Noel Atchison. Follow the Coindesk podcast network for some of the best shows in crypto.

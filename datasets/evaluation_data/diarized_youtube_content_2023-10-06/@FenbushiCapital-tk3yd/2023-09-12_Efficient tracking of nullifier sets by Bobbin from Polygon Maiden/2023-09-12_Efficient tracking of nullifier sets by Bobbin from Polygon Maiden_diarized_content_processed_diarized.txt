00:00:02.890 - 00:00:49.530, Speaker A: So next up, we have Bobbin from Polygon midnight. So I guess just a quick background on that. Polygon has been building a lot of things and one of the big initiatives that they have is building Midnight Ckbm. And Bobbin has been one key, crucial, I guess, player in sort of developing the KPMS and has been my pleasure to have Bobbin also join the talk and talk about efficient tracking of Nidafire. So I guess the stage is yours. Please take it over, bobby.
00:00:52.030 - 00:01:11.860, Speaker B: Thank you so much. It's a pleasure to be here and really appreciate the opportunity to talk about these interesting things. And I think the event is overall is great. I've listened to a few talks and looking forward to listening to some that I've missed as well. But yeah, can everybody see my screen?
00:01:14.790 - 00:01:17.400, Speaker A: Yes, I can see your screen. I can see your screen.
00:01:18.490 - 00:01:21.766, Speaker B: If I go into slide presentation mode. Is it still good?
00:01:21.868 - 00:01:23.158, Speaker A: Yeah, it looks good.
00:01:23.324 - 00:02:06.122, Speaker B: Awesome. All right, so today my talk is going to be about this efficient tracking of nullifier sets. And as part of that, I'm going to give a kind of a brief introduction. Very high level, probably missing a lot of details, but what are the nullifiers and why do we even need them? What are the problems that arise from kind of trying to use them, how we solve these problems in polymer mitin. And then I'll kind of give a very cursory overview of how other people are thinking about solving the same problems. So let's dive into this. So why do we need nullifiers? So, in one sentence, the nullifiers are needed to break linkability between senders and receivers and privacy preserving blockchains.
00:02:06.122 - 00:03:00.902, Speaker B: So the idea is that in traditional blockchain or any public blockchain, when you send something to somebody, everybody can observe that the transaction went through and who was the sender and who's the recipient in privacy preserving blockchains. For example, like Zcash is one of the first that pioneered this, or maybe even the first one that pioneered this. We want to kind of break this linkability, like knowing who or you shouldn't be able to know who sent the funds to whom, or who received funds from whom and so forth. So nullifiers is a tool that is used to do this and how they work. So in the context of nullifys, we usually think about like a utxob system or something that is close to UTXO. So Maiden, for example, is a hybrid between account and UTXO. Zcash as an example, is a utxob system.
00:03:00.902 - 00:03:51.842, Speaker B: But there you have this nodes that people send to each other and you can think of node as kind of like something that carries assets and has some spend conditions associated with that. And to break node can, there are two things that we can kind of reduce a node to. The first one is a node commitment, which usually is like a hash of a node in some ways and then there is a nullifier that basically also needs to be derived deterministically from a node. And it could be a different way to cache it or it could be derived in different ways, but basically it's a way to get kind of a blinded commitment to a node and then this gets recorded. And there are different ways to do it, but one of the ways to do it is to record them in different databases. So for example, whenever a node gets created, it gets recorded in this node database. This is how we do it in polygonmiden.
00:03:51.842 - 00:04:41.326, Speaker B: And then whenever a node is consumed, a nullifier for that node gets recorded in a nullifier database. So node database basically contains commitments to all the nodes that have been ever created. Nullifier database contains all the nullifiers of the nodes that have been consumed. And then the crucial property is that if we know a node commitment to a node, we should not be able to determine the nodes nullifier. So like if we know that something has been recorded in no database that should give us no information about a nullifier that this note would be reduced to. Now, the way this is used when, let's say we want to consume a node and there are two parts to this. One part is done by the user when they generate a CKP locally and send it to the network and the other part is done by the network.
00:04:41.326 - 00:05:34.258, Speaker B: And again, there are different ways to do this. So this is just one of those ways. So the first one, let's say we start with a node and there's a node database. So the user, when they run a transaction or prove a transaction like genuine ZKP, so as part of the ZKP that they would compute the node commitment, they would verify that this node commitment is present in a node database and node database could be represented by various data structures. In midn we use mountain range to do that. So you can think about node database as being merkel mountain range that the user has access to. And then they would kind of internally within, when they verify or prove a transaction, they would verify that a node is part of this merkel mountain range and that proves that the node that they're trying to spend has been previously created.
00:05:34.258 - 00:06:39.734, Speaker B: And then the other thing that they would do is that they would compute a nullifier and this nullifier would be the output of the circuit or of the GKP that gets generated or that gets generated. And one important property here is that the node database is a public input. So everybody knows the state of the node database, but a node itself is a private input. So by the time we get to the nullifier, like whoever gamifies the ZKP, they just know that there is some node that existed in the node database that reduces to this nullifier. But they learn nothing else, basically. And then what the network does is it takes the nullifier database as an input and then this nullifier that came from some GTP that the user generated and then they need to verify that this nullifier is not in the nullifier database and then they also need to insert this nullifier into nullifier database. So the next time this prevents double spend basically you won't be able to spend a node with the same nullifier twice because the database gets updated.
00:06:39.734 - 00:07:25.366, Speaker B: One of the outputs is this new nullifier database as part of this. So this is just part of what happens in transaction. This is by no means, there is a bunch of other things that need to happen but this is what is related to the nullifiers. So like user knows what the node, all the details of a node, they can build a nullifier to it without telling anybody which node the nullifier came from. And then the network verifies that nullifier hasn't been seen before and tracks it going forward so that a node cannot be double spent. So this works well and it's fine, but it does lead actually here's both the nullifier and nullify database are public inputs. So as I mentioned, this works fine, but it leads to one big problem that the nullifier set is infinitely growing.
00:07:25.366 - 00:08:12.650, Speaker B: And the reason for this is that to make sure that we kind of verify that a nullifier has not been seen previously, we need to have access to all nullifiers that have ever been created. In some context, this is not an issue. Like if your network is running at maybe under 100 TPS, that's probably not too big of a deal. The nullifiers are usually like 32 bytes could be compressed further or in some constructions that could take slightly more. But nullifiers are not huge, they're fairly small. For the purposes of this graphic here, I use 32 bytes. And so if you're only running at 100 TPS or less, this is not really a concern.
00:08:12.650 - 00:08:58.934, Speaker B: Your state will not increase. But if you want to have a really high throughput network where you are at one KTPS or even at ten KTPS, the notifier set grows to very large size. So like an example here, after ten years you are at ten or 100 terabytes if you do ten KTPS on average. And this basically means every year you add ten terabytes to the state, which is a lot. Now, this is one of the main problems that we want to solve. So let's talk about how we try to do it in polygonmiden. So in midn actually, to take a step back, we want to solve for a few different things.
00:08:58.934 - 00:09:52.630, Speaker B: The first thing we want to solve for is we want to have nullifier set being tracked by authenticated data structure so we can have non membership proofs. And this is important because for Mitan we're an L two and we need to be able to prove updates to the nullifier set to l one as well. And one of the ways to do it is if you have this non membership proofs, like if it's an authenticated structure and when you modify it, there is like a way to verify that the set of updates resulted in a new state of a nullifier database. And in general, it's useful for a number of other use cases as well. The second thing we want to have is constant nullifier database size at a given TPS. So one of the things that we don't like, it's a slightly relaxed condition. We don't want to have a fully constant sized nullifier set because you could try to do it, but it leads to some number of complications.
00:09:52.630 - 00:10:25.140, Speaker B: It also limits your anonymity set somewhat. But what we want to do is like for a given TPS, so if you're running at, let's say, one k TPS, you'll have a constant size nullifier set. It's not going to grow with time every year. There's not going to be additional nullifiers added to it or there will be, but the size will not grow. So that's one of the goals. But if the TPS increases, so your nullifier set will increase as well. So that's a slightly relaxed condition and I think it's a good trade off to live with.
00:10:25.140 - 00:11:08.186, Speaker B: The other thing we want to avoid is that we don't want to place any time limits on spending notes. So we don't want to say like if you didn't spend your note in the last year or last month or something like that, it becomes unspendable. So regardless of when the note was generated, you should be able to spend it. We don't want to sacrifice on that. And then what we want to also ensure is that there is minimal amount of work that the user needs to do to keep track and make sure that their notes become spendable, even if they are old and things like that. As an aside, in midn design, nodes are generally meant to be like a short lived object. So they're expected to be spent relatively quickly, like maybe within days, weeks or even months of the time when they're created.
00:11:08.186 - 00:11:44.940, Speaker B: And this is because we have this hybrid structure where you have accounts. And nodes are really not meant as a long term storage. They're meant to just carry assets between accounts. But on the off chance that somebody doesn't want to consume a node or is not able to consume a node for a long period of time, we do want to make sure that this is first of all, possible. And second of all, it requires the least amount of work that we can kind of like the less we can require users to do, the better. All right, so let's first look at one potential construction. So one is a sparse merkel tree, and this could be a compact sparse merkel tree of depth 256.
00:11:44.940 - 00:12:38.894, Speaker B: The way it will track nullifiers in this is a nullifier value and let's think of it as 32 bytes defines a path in the tree. So if it starts with zero, we go to the node on the left. If it starts with one, we go to the node on the right. And then we traverse kind of like the path all the way down to that leaf and then we get to the leaf identifying a specific nullifier and then the value in the node will indicate whether a nullifier is spent or not. So zero means the nullifier is not spent and one means the nullifier is spent. So if I go back to the previous slide, this actually addresses a lot of these things. So it's an authenticated structure, it has no limits on when the nodes could be spent and the work that the users need to do are basically the minimal possible.
00:12:38.894 - 00:13:39.950, Speaker B: But it does have one big problem, is that the size of this merkel tree, sparse merkle tree grows constantly. And there are some optimizations that we can do to like we wouldn't use the actual sparse merkel tree, we would use a compact sparse merkel tree to make this a bit more space efficient and there are other ways to compress things, but overall the size of this data structure would grow indefinitely. And this is the problem that we're trying to avoid. So our solution to this is that we'll have not a single nullifier tree but we'll have a sequence of these nullifier trees and we will break them into epoch. So you can think about many trees being created over time and we would say that the last tree will call it a current epoch. And then we'll also have this notion of the last two nullifier trees as being in the current window. And then again, the idea is that as one tree gets filled up, the next tree gets created and I'll define what filled up means in this case and so on and so forth.
00:13:39.950 - 00:14:40.814, Speaker B: So what are the key properties of this new data structure? The first one is that we only insert nullifiers in the tree of the current epoch. All the historical trees, like once they kind of become historical, once the epoch rotates, these trees are no longer updated, they become static. And then the nodes in the network only keep track of the last two epochs, which I defined as a current window. So as soon as the epoch becomes more than two epochs old, as the tree becomes more than two epochs old, we discard the tree or the nodes discard the tree and they don't need to keep track of that anymore. Now it does or and the other one is like f ox last for a fixed duration of time and there is no specific kind of duration that we've fixed right now yet, but it could be under order of months. So like six months could be a good time frame for an epoch. So if you think about it, a node needs to keep track.
00:14:40.814 - 00:15:26.766, Speaker B: About a year's worth of nullifiers was less. If we make an epoch shorter, it would be, let's say three months. Then the node needs to keep track of just half a year worth of nullifiers and so on and so forth. So it does introduce some new requirements. So the first requirement is that for every node we need to assign kind of or be able to at least determine the epoch in which that node has been created. So we'll call this creation time MC and each node it's actually not too difficult to do this and doesn't sacrifice much. And then the second thing that is kind of more difficult and more problematic is that we need to verify that node nullifier is not present in any of the nullifier trees with epoch that is greater than NC and greater than or equal to NC.
00:15:26.766 - 00:16:20.946, Speaker B: So basically, previously we only needed to check one nullifier tree. Now we need to check multiple nullifier trees. Now, if we go back to the original picture of how this works, there are some changes that we need to introduce here and I highlight those changes in bold. So first, if the nullifier has been spent or if the node has been created a long time ago, we also need to include past nullifier proof. So in addition to computing the node commitment, verifying that it's in a node database and computing the nullifier, we also need to verify that this node has not been part of any of the nullifier trees from the past nullifiers that are not part of the current window. We still get nullifier here. And in this case the past nullifier proofs could be private input.
00:16:20.946 - 00:17:01.006, Speaker B: They don't need to be public input. So the user just has those merkel paths. In this case, the proofs would be merkel paths for the sparse merkel trees. So the user just has those paths and they can provide them as private input into the circuit. And the ZKP will verify that for anything that is outside of the current window, we've proved that this node hasn't been part of that nullifier trees. And then what needs to be done on the node or on the network site is there is very slight changes. So the first thing we need to verify that nullifier that we receive from the user is not part of the nullifier trees in the current window.
00:17:01.006 - 00:17:48.194, Speaker B: So the two nullifier trees and then we just need to update the nullifier tree in the current epoch. So these are the main changes. And then again we get the new nullifier database. As before, these two inputs into what network needs to do are fully public. Now, what impact does it have for users and what complexities does it create? So first, if a node was created in the last two epochs, there is really no impact for the user, they don't need to do anything extra. And if you take last two epochs as being a year, if you create a node and this node gets consumed within a year, there is really no change for the user. Nothing else needs to be done.
00:17:48.194 - 00:18:33.278, Speaker B: If the node was created earlier, there is a couple of things that you need to do. First, you need to download and store non membership hooks against old nullifier trees. So let's say you have a node that is fairly kind of getting old and new epochs get created. Anytime a new apple gets created, you need to download a non membership proof for that nullifiers for the nodes that you kind of control and expect to spend in the future. Fortunately, this only needs to be done very rarely. So once per epoch, so like once every six months you may need to do this and it also can be delegated to someone else to do it. If you are not online, someone else can do it.
00:18:33.278 - 00:19:34.270, Speaker B: You would need to give up some privacy against this third party that will kind of keep track of these nullifiers for you because you will tell them effectively which nullifiers you're interested in tracking, but you don't give up anything else. So you give up privacy in terms of for tracking your nullifiers, but nothing else. They can't spend your funds, they can't kind of do anything else with your wallet, something like that. So there are some trade offs here, but I think they're fairly acceptable. Again, there is only one time that per app that you need to do updates and if you are not sure you'll be online, you can delegate this someone else. And there is an extra cost for verifying this non membership proofs as part of the proofs that you generate locally. So depending on how old your note is, if your node is like two years old will be four extra or I guess two extra mercury pass to verify if it's five years old, there will be like eight extra merkle pass to verify in your kind of transaction proof.
00:19:34.270 - 00:20:33.560, Speaker B: But it is not too bad compared to all other things like signature verifications and other things that you need to do as part of the transaction. This is actually not too bad, very small part of the cost. And then on the network side, the additional extra costs are very small. So the only extra thing that you need to do is do this extra check, verify this extra mercury path against the second nullifier tree in the current window. And this is sufficient for you to know because you verify the ZKP that the user sends you. So you know that user checked that or attested to the fact that the node they are spending is not part of any of the previous nullifier trees starting at the time when the node was created. And then you can very easily check that the nullifier is not part of the current window by doing this two Mercury cats verifications instead of one.
00:20:33.560 - 00:21:33.340, Speaker B: And this also very nice property of this setup is that the anemia set that you have is actually it doesn't get reduced. So the full history of your ledger is that an emitter set. So you don't have a fixed size Animeter set or like a very limited Animeter set. So in this setup that an emitter set kind of grows as the size of the network grows because from the standpoint of the network, they don't know if they're verifying a node or kind of processing a node that has been consumed in the last year, in the last five years, in the last ten years, or whenever else. All right, so just to wrap this up and highlight some other approaches that are out there and I'm not going to go into the detail and this is like some select alternatives. This is not like by any means a comprehensive set of alternatives. One interesting approach that recently came out from the Triton or Neptune team is this Mutator set.
00:21:33.340 - 00:22:33.878, Speaker B: One of the new things there is that using of the sliding window bloom filter for non membership proof. So instead of using sparse merkel trees and kind of this rotating epochs, they're using a sliding window bloom filter, which in some ways is similar to epoch based sparse merkel trees. But also there are some significant differences, especially in how they use a bloom filter. Polygon Zero, previously Mirror had this interesting approach where they use this liveness mask which can be compressed with using modified Hoffman coding. I think the page marks they got there is that each nullifier could be or each active nullifier and spend nullifier would require only five bits or something like that of storage. So it was very efficient in that. And then I think Zcash had some proposals of how they could have scalable nullifier sets.
00:22:33.878 - 00:22:59.480, Speaker B: And I think the proposal was about kind of sharding nullifier spaces and basically so that not everybody needs to store full nullifier tree. You only need to store parts of the nullifier tree. And that's how you would limit the size of something that a specific node would need to store on their system. So with this yeah, this is my talk. I think I managed to do it in 20 minutes.
00:23:01.050 - 00:23:17.946, Speaker A: Yeah. Thank you. Thank you, Bobby. So I guess just on my side, I had a few questions I wanted to kind of ask on the nullifier. So you kind of defined the epoch as I believe, half a year, right?
00:23:18.128 - 00:23:18.810, Speaker B: Yes.
00:23:18.960 - 00:23:28.442, Speaker A: I'm just kind of curious what's the considerations behind the epoch's length and also why do you decide that as a half a year instead of other timelines?
00:23:28.586 - 00:24:20.750, Speaker B: Yeah, so I think there are a couple of trade offs here that it's kind of a balancing act because the bigger the epoch you make, the more nullifiers a given node needs to store. So let's say if we're running at one KTPS, if you make an epoch half a year, then a node needs to store two epochs. That's roughly like close to 1 data that they need to store. And this is a stable 1 TB doesn't change with time, but it's still significant. So you may ask, well, do they need to store 1 TB? Can we make an epoch three months for them to store less? And then kind of the other lever that is pulling in the other direction is kind of convenience for the user. The shorter the epoch, the sooner you may need to download those extra proof. So if you spend your node in the first two epochs, you don't need to do anything extra, you don't need to worry about anything.
00:24:20.750 - 00:25:00.378, Speaker B: But if you go beyond the first two epochs, then there's some extra work that you need to do to download those non membership proofs and keep track of them. So it is kind of annoying. So the question is if there is sufficient infrastructure to make epoch shorter. So like on a safe side, I think a year is probably safe, at least in polygonmide and design where nodes are meant to be. As a short lived object, 99.9% of people should spend their notes within a year to move funds into their accounts. But if you make it like one week, for example, it would be very efficient from the storage standpoint of the nodes, there is very little data that you need to store.
00:25:00.378 - 00:25:21.902, Speaker B: But then it would create more inconvenience for the users where you need to make sure that every two weeks you download an additional storage proof. And not everyone logs in every two weeks and spends things within every two weeks. So it's just like basically a trade off between user convenience and how much data you want to store on your nodes.
00:25:22.046 - 00:26:09.342, Speaker A: I see. And I can also say that let's say the users are not spending anything and just leaving the funds and also the notes just sitting on midn, you did mention, although you said not much cost, but there's some additional cost of proving. Let's say that the nodes were from epochs that were two epochs ago, like more than two epochs ago. And I presume that every epoch that progressed forward the node have to create a new proofs. Or I'm not sure if it's like recursively, but some sort of new proofs. Right. So is there like a linearly increasing amount of cost the longer that the node is not touched?
00:26:09.486 - 00:26:45.440, Speaker B: Yeah, for the user the cost would be linearly increasing. But I should say that this cost is fairly small. So the constant size is small. So you could probably not spend your node for ten years and it still should not be significant cost as compared to a lot of things that happen as part of the ZKP circuit. So as I mentioned, for ten years you need to verify extra eight merkel paths which is if you compare it, it's probably less than 10% of what you would need to do to verify a signature, for example. Actually much less than 10% that you need to do to verify a signature. So it's not a huge amount of cost.
00:26:45.440 - 00:27:12.514, Speaker B: I think the more annoying part is that they need to kind of periodically download those merkel paths like once every six months. That's the more annoying part in my view. The cost is there but it's almost negligible. But the fact that you need to either log in once every six months and download that path or have someone else track this for you and then you kind of give up a little bit of privacy that's like the most annoying part of this design in my opinion.
00:27:12.642 - 00:27:43.198, Speaker A: Right, and then in that case the users who would have to agree to delegating that kind of like a half a year downloading. But then that things itself is like a bit of a UI UX challenges there. Right? Because then you kind of have to let users know that whether you want to delegate this or not. And if you do delegate then what is the kind of like the privacy aspect that may be a bit compromised in there as well.
00:27:43.284 - 00:28:16.422, Speaker B: Yes, exactly. So that's why you don't want to make the epoch too short. Because again, if you make it too short these problems become much more exacerbated. But I don't know if half a year is the right answer. Maybe it should be a year. And then it's something that I think we'll learn again with polygonmiden design specifically we're not expecting that notes should remain in polygonmiden. You have notes and you have accounts and notes are just like I send you a note and then next day you can take the note and move it into your account.
00:28:16.422 - 00:28:25.390, Speaker B: So you move funds into an account and at that point you don't need to keep track of that note anymore. But in some cases that may not happen.
00:28:25.540 - 00:29:02.102, Speaker A: Got you something that you haven't really touched upon during the talk. But I was curious to also learn a bit more was about the hardware managements around the node that are I guess hosting those notifier trees. Do you foresee that this would be basically just like a one big machine that is running this or do you foresee that you are also somehow trying to distribute some of the node hosting load across different machines across geographically so.
00:29:02.156 - 00:29:30.882, Speaker B: It doesn't necessarily need to be a big machine. So the issue here is mostly on storage side. So you can have a hard drive with five terabytes right now at the cost, I don't know, but it's like a couple of $100 or something like that. So it's mostly around maybe I'm underestimating you can get like a 1 TB hard drive for $100. Maybe five terabytes is a. Bit more expensive than that but it's not like a huge amount of cost. So you don't need tons of CPUs, you don't need anything.
00:29:30.882 - 00:30:17.620, Speaker B: It's basically storage. And I would say if you think at which TPS we are running so if you're running at one KTPS that's when you need like 1 storage, right? I think like Ethereum right now running at I guess like 15 to 20 TPS is already at close to 1 storage that you need. So it's not like hugely different and especially at the level of throughput that you get. So it is not going to be like a Raspberry Pi probably so unlikely to be a Raspberry Pi that you can run this node on, but it shouldn't be anything more than like a mid to high end laptop that you should be able to run this on.
00:30:18.630 - 00:30:34.838, Speaker A: Got you. Do you think that you would also prepare some sort of redundancy around the actual hosting of those data? As in you would have maybe some multiple people just hosting in case some.
00:30:34.924 - 00:31:27.640, Speaker B: Liveness for sure in a decentralized setting you would have multiple nodes and each of them have copies of these nullifier trees. So that's not something that in all honesty there might be somebody chooses to be an archive node type of thing where they store they don't even discard the previous nullifier trees and just store them and you can always go to them and ask for this nullifier. So maybe like another solution to that annoying problem that I mentioned is you don't need to download that. Somebody will give you this at extra cost later on because they will just keep those storage is not hugely expensive. Even you don't want everybody to have to have a hard drive with 50 terabytes, but some machines out there could have 50 terabytes available to them that store everything, all the historical notifiers and in that case it solves a lot of problems so it kind of gives this flexibility there as well.
00:31:28.010 - 00:32:06.580, Speaker A: Got you. And also in terms of the from the incentive alignments of those people who are running those nodes. Do you foresee that what Ben previously have mentioned that the bringback of the POW type of things or even maybe a parallel would be like something like a filecoin where the filecoins node operators also get some sort of file coins as incentive for them actually running their machines for storing that data. In a similar manner, I think.
00:32:08.470 - 00:33:01.842, Speaker B: There isn't a lot of extra work that the nodes need to do as part of just running the protocol as intended. So they should be compensated with fees that transactions. If you want to be able to process transactions and get fees for transactions, you need to keep those nullifiers, otherwise you won't be able to process transactions. So you kind of in a way are already compensated for storing those nullifiers with transaction fees. So I don't know if there needs to be an extra mechanism for doing this. I think, as I mentioned just like a minute ago, there could be extra incentives for somebody to store even historical data that you are not required to store by the protocol, like something that is outside the last two epochs and then charge extra fees for that. A node could say, I'm going to store the last 20 epochs and anybody can come and get the data, but you have to pay extra in terms of fees.
00:33:01.842 - 00:33:10.950, Speaker B: So there could be some incentive design something extra to what the base protocol, kind of like envisions to provide that convenience.
00:33:11.610 - 00:33:31.822, Speaker A: Gotcha. Okay, great. Thank you very much, Davin, for the great talks and explanations around the design space of nullifier tracking. And it was very honored to have you on today and looking forward to any new developments from Miten team as well.
00:33:31.956 - 00:33:34.718, Speaker B: Thank you for having me and thank you for great questions.
00:33:34.884 - 00:33:35.260, Speaker A: Thank you.

00:00:00.330 - 00:00:00.880, Speaker A: You.
00:00:02.850 - 00:00:36.360, Speaker B: So next up, we have shravan from LaGrange protocol. And just to kind of introduce a little, LaGrange Protocol is building storage proof solutions across L one and L two S. And some of you guys might have seen them presenting also at the SPC, but they recently released a paper about updatable vector commitment or something. So I guess we'll learn more about it during the talk. Feel free to take it over.
00:00:37.050 - 00:00:38.150, Speaker A: Am I audible?
00:00:39.050 - 00:00:40.266, Speaker B: Yes. I can hear you.
00:00:40.288 - 00:01:12.914, Speaker A: Yes. Thank you for the introduction, folks. I'm super excited to present our work in progress rec proofs. It's a merkle tree based vector commitment scheme which has updatable batch proofs. So let's start from the basics. So what exactly is a merkel tree? So a merkel tree is a data structure that lets you compute a commitment to an ordered sequence of values. Say you have values a zero to a 15 and a collision resistant hash function h.
00:01:12.914 - 00:02:25.050, Speaker A: In merkel trees, you compute a commitment by recursively computing the hash of the adjacent pair of values. So you would take a zero and a one, compute a hash of it concante and get the hash of it, and you so on do this for the other adjacent pairs. And once you have this, you kind of do this for this level of the hash values until you just end up with just one value, a single hash value. This single hash value is called as the root of the merkel tree. Merkel trees are ubiquitous and it has countless applications in blockchains and beyond. So in addition to just computing the commitment to an ordered sequence of values, merkel trees can help you prove that a certain leaf is in fact as a member of this tree. Say for the example you want to prove that a phi is a member of this merkel tree, then what you would do is you would give out these specific values which are highlighted in green, which is a four, the commitment clr and so on and all the way until to the top cr.
00:02:25.050 - 00:03:36.238, Speaker A: So once you have these green values, any verifier can take this and can reconstruct the path from the leaf all the way to the root and can reconstruct the digest of the tree. Given an unknown digest, a verifier can check if this reconstructed digest is indeed matches with what the verifier already has and can decide to accept or reject this membership proof. The main focus of my talk today is about updates in merkel trees and so on. So say that an arbitrary element changes in the merkle tree. So this in turn affects the proof of, let's say for this example. In this example it's going to be a phi. So whenever, let's say for example, eightwell changes by delta, all we need to do is take the membership proof of eightwell and recompute the path from eightwell to the root and in places where it intersects with the proof of a file, we just have to update those hash values.
00:03:36.238 - 00:04:54.502, Speaker A: So thus in logarithmic time we can update individual membership proofs whenever there's an update in the merkel tree. So we can continue to update all the way into the root and we can also recompute the updated digest in the similar fashion. So let's delve into a special type of membership proofs called range proofs. So a range proof is essentially going to essentially going to simultaneously prove the membership of multiple contiguous elements in the merkel tree. Say you want a single proof which says that a three to a eight is in fact in this merkel tree. So to do this, first you would give out the membership proof of a three which is going to be these values highlighted in green and you will give out the membership proof of a eight which is going to be these values which are also highlighted in green. So once you have this logarithmic size proof, what you can do is a verifier can take these proofs and the values ace a three to a eight and can check if in fact if this range proof is valid by reconstructing the hash paths all the way until the root.
00:04:54.502 - 00:05:47.020, Speaker A: So just like an individual membership proof, you can see if the reconstructed root is in fact is what you already know. If that is the case, you accept the range proof, else you can reject it. Yeah, range proofs are also updatable in merkel proofs and in merkel trees. So whenever an arbitrary element, a twelve changes, it is very similar to updating individual membership proofs. So let's say a twelve changes by delta you update the hash paths from a twelve to the root and the places where the green node intersects with the path of a twelve to the root. Those values of the range proofs have to be just updated. So once you update these values, you have the most up to date range proof which incorporates the change that has happened in position twelve.
00:05:47.020 - 00:06:27.990, Speaker A: The focus of the stock is more about batch proofs. So a batch proof is a single proof to open arbitrary elements simultaneously. So the key difference between a batch proof and a range proof is in batch proof it's going to be k arbitrary elements. However, in range proof it's going to be a consecutive set of elements. A crucial efficiency property which we want from a batch proof is it has to be smaller than k individual proofs. As a new way of doing batch proof is you can simply concatenate the individual membership proofs of k elements and call it as a batch proof. However, that's why we want this special efficiency requirement.
00:06:27.990 - 00:07:34.990, Speaker A: Existing approaches to batch merkle proofs are not updatable even when element in the batch changes or even when some other element outside the batch changes. Another thing which we touched in this work is aggregation. Aggregation is the process of simply combining multiple individual membership proofs into a single batch proof. So the more about what we have done in this work so we present updatable batch proof using recursive Snarks for merkel trees and our batch proofs can be updated in logarithmic time where N is the size of number of leaves in the merkel tree. And we generalize this idea to do something called as verify MapReduce style computation even when the data changes. Say that you have a bunch of leaves and you want to have some sort of predicate applied on top of these leaves. Then using our approach, you can compute a simple Snark proof which essentially says which can essentially attest to the predicate that was applied over these leaves.
00:07:34.990 - 00:08:25.658, Speaker A: Specifically, we show how to do this MapReduce style computation and two specific applications. One is how to aggregate BLS keys even when the data is changing and how do we do a notion of the digest translation. This essentially argues that the mercury computed using hash function, say sha two, five, six are perseid over the same set of values. You can compute a simple proof to say that these two values are consistent. I'll dwell more into the details of these applications later in the talk. But the key point to note here is we can have all of these techniques work even when the data changes. So let me start with notion of the naive batch proofs.
00:08:25.658 - 00:09:24.746, Speaker A: Say that you want to compute a batch proof for elements a two, a four, a five and a 15. So the most obvious approach, the nave approach to do is to just to concatenate the membership proofs of a two, membership proofs of a four and a five, and membership proofs of membership proof of a 15. So this is going to be a name batch proof, but however, it doesn't meet the efficiency requirement. However, I'm going to use this as a running example for the sake of illustration for the rest of my talk. Once you have these naive proofs, we need to verify if this batch proof is valid. Any batch proof verification algorithm broadly takes in certain set of inputs. These are first what is the digest of the merkel tree? Then let's set S be what is the subset of the claimed elements in this merkel tree and some characteristic about the tree.
00:09:24.746 - 00:10:01.334, Speaker A: In this case, it's going to be the height of a tree and some sort of auxiliary witness. So this is going to be the broad template almost. You need to verify any batch proof regardless of how they are constructed. And the verification algorithm should spit out if and only if s is indeed some subset of the merkel tree of L height and whose merkel root digest is C. And it should spit out no if S is not indeed a subset of the string. In this talk. For the illustration purposes, I'm going to present two algorithms.
00:10:01.334 - 00:10:50.406, Speaker A: The first one is the standard approach where you have individual membership merkel membership proofs. Using that as a witness, we can verify if the batch proof is in fact correct. And the second one is our approach. We use this approach in addition to the membership proofs, we also use something called as a node subsets which I'll specifically precisely define. Later we use additional witnesses to verify the same merkel batch proof. So in the standard version, what you're going to do is you have the a two, a four, a five and A 15 as a part of the batch and you have the individual membership proofs. First you check if a two is in fact is valid.
00:10:50.406 - 00:11:28.566, Speaker A: So you do this by reconstructing the path from a two to the root. And you can check if this reconstructed root is what you expect as a verifier. Then you also verify individually a four and a five by reconstructing the root and check if this is in fact valid. And you do this so on for the other members of the badge, in this case A 15. And you check if this in fact is the merkel route which you expect. So obviously this namely checks one proof at a time. Can we do better? Is what this book broadly tries to look.
00:11:28.566 - 00:12:36.910, Speaker A: So this inefficient batch proof, which is essentially a concatenation of all the individual proofs, can be made into an efficient version. All you have to do is to just take the verification algorithm and you can just simply snack it. So something like Grad 16 would give you a small batch proof. And this single batch proof is essentially going to attest to the fact that certain elements were part of the batch and these elements are part of the merkel tree which has some merkel root by just C and so on. However, the drawback of such approaches are so whenever there are changes to the elements in the batch are out there in the batch, you have to recompute this proof from scratch. And another drawback of these standard Snark based approaches are you also need to have an April bound on total number of elements that are going to be part of the batch. So whenever when your bound increases, you have to rerun the setup and have a fresh circuit for it and so on, which is an additional overhead in these approaches.
00:12:36.910 - 00:13:33.534, Speaker A: Our approach, a big picture motivation of our approach is how do we solve certain limitations which are there in the previous known constructions and what can we do better is what is a big picture motivation. So say S is the set of elements that are in the batch. So we define something called as a node subset. So a node subset essentially is defined with respect to the set S over which the batched elements are proved. So every node in the merkel tree is going to have this value called node subset. So the way it goes about is let's say that it's going to be a subset of values S, where at node v it's going to be the values that are part of the subtree which is rooted at v. I'll show this with a figure which will become much more clear.
00:13:33.534 - 00:14:42.950, Speaker A: So at the high level, what node subset does is it tries to have a set of values in each node and these values are going to be a subset of the set S and the values that are part of the subset are the ones that are present in that subtree. Yeah. An obvious example of a node subset is going to be the root, which is essentially going to be the entire set. S to see this in a little bit more detail, you can consider this figure where let's say that as I mentioned, the node subset of the root is a two, a four, a five and a 15, which are these elements inside the batch. And let's say you take the right subtree, the node subset of this is just going to be the A 15, as A 15 is the only element from the set S that is part of this subtree. Similarly, for the left one, it's going to be a two, a four and a five. And it does not contain A 15 because a two, a four and a five are the only elements that are part of this subtree and which is part of the batch.
00:14:42.950 - 00:15:58.078, Speaker A: Once you have this key thing to note here is in addition to having the merkel hash values nodes, we also have those node subset values in our construction. So the way we verify a batch proof navy in our scheme is first we are going to prune out the set of nodes that are of interest to us in this merkel tree. So these values are the ones that are from the root to all the way to the leaf that are part of the batch. So in this case, I'm going to iterate through an algorithm which is essentially going to look at all the nodes that are from the root and to values a two, a four, a five and A 15. In this example, when we start from the root, first we check if the merkel hash is indeed correct by hashing the left child and the right child. And we also check if the union of the node subsets of the left and the right make up the root. So in this case it's going to be a two, a three, a two, a four and a five union A 15, and we check this against the root and so on.
00:15:58.078 - 00:16:54.202, Speaker A: So we can do this recursively to all the nodes that is are of interest to us. And at each position we just make sure that the merkel root matches and the information about the subsets that is part of the node subsets are also indeed consistent. So we can do this all the way to the bottom. However, at the base case, the key thing to note here is we will have to check if the node subset of that specific leaf is in fact the content of is in fact the content of that leaf. And this is the only particular check which we have that ensures that the base case is correct. And you do this for all the elements that are part of the batch. So just like the way we made the standard nave merkel proofs efficient by Snarking, we use recursive Snarks to do this.
00:16:54.202 - 00:17:47.410, Speaker A: So I'm going to present you the circuit of how we do it. So it's going to take in the public input as the merkel digest c, the Bat subset S and the height of the merkel tree. And it's also going to take in witnesses. Two witnesses, specifically, one which attests to the fact that it's going to be the merkel digest of the right subtree, the node subset of the right subtree, and the height of the right subtree and a snark proof which says that this public statement with respect to the right subtree is in fact valid. And similarly for the left subtree as well. So the verification algorithm goes this way. First, we check if the height of the root is in fact is one above the height of its left and right child.
00:17:47.410 - 00:18:46.114, Speaker A: And we also check if the merkel hash value is in fact consistent. And we also check if the node subset of the right and the left tree, when they are put together is in fact what you expect at the root. At the base case, we check if the leaf data is in fact the node subset. And in the recursive case, we check if these are the internal nodes. In the recursive case, we check if the proofs that came in as the witnesses, the Pi l and Pi r, if those proofs are indeed correct. And we do this recursively for all the nodes of interest in the merkel tree. To see this a little bit more pictorially, recall that this is the tree I have which consists of merkel hash values and the node subsets of what I've been showing before.
00:18:46.114 - 00:20:05.994, Speaker A: The batch that is of interest to us is a two, a four, a five and a 15. So at each level of this tree, except the leaf level, we are going to have a Snark proof which essentially attests to the consistency of the values that are in that specific subtree. So in this case, I'm not sure if you can see the pointer in this case, this proof, Pi LLR is going to attest to the fact that whatever went inside in this subtree is in fact consistent and this is going to make sure that this subtree is consistent and so on. So we can recursively compute such narc proofs which is going to attest to the subtrees at which it's rooted and we can do this all the way to the top. And at the root you have the root Snark proof, which essentially is which acts as a batch proof for the elements a two, a five, a four and a 15. So we call this data structure as a batch proof data structure. Once you have this data structure, whenever there's an element that changes in the vector, changes in the vector, you can simply recompute the updated proof without computing from scratch, say a phi changes by value delta.
00:20:05.994 - 00:21:00.266, Speaker A: All you have to do is to follow the path from AFI to the root and update the witnesses and the Snark proof that is there in each specific node. And we can do this all the way to the top. And you can compute the updated batch proof, which is pi prime in this example. In this way you can update proofs in logarithmic time rather than recomputing everything from scratch. Key optimizations which we use are rather than using passing around subsets assets, we use set accumulation and we use a hash based set accumulation for efficiency reasons and we don't need specific properties from it. So a hash based set accumulation works perfectly fine for us. And we also have two separate circuits, one for the leaf nodes.
00:21:00.266 - 00:21:45.280, Speaker A: So, as you can recall, the computation and the leaf level was fairly simple. However, at the internal node you also had to invoke expensive Snark verification. So in our experiments, we actually break it down into two specific circuits, one for the leaf and the one for the internal. And we put them together in a manner that consists it's cryptographically sound and there are no scopes for attack. So this general idea of batch proofs, this idea can be generalized to perform Map reduced style computation. So let's say that you have a zero to a seven. These values are committed using merkel trees and let the commitment be c.
00:21:45.280 - 00:22:57.806, Speaker A: We can take the map values, we can map the leaf values based on some predicate that is encoded in the computation of Map and it returns the intermediate values to the level. The reduce operation takes these values together and spits out another value which can be further reduced all the way to the top. So at each level, the reduce operation is also attached with a Snark proof which essentially says that this reduce operation was done correctly over the data which has the merkel commitment at that specific root value, that specific node. And we can do this recursively all the way to the top. And in the end you can simply perform the reduce operation. This way you get the result of the MapReduce computation. At the same time, you also have a Snot proof which says that the merkel digest c is the digest of the values a zero to a seven and the computation was performed correctly and that is artisted using the Snark proof pipe.
00:22:57.806 - 00:24:15.166, Speaker A: So, to see this a little bit more in the context of a real example. Let's say that you have a smart contract with N memory slots and each of that has nbls keys. The goal is to compute the aggregated public key of a subset of people who have signed some particular message. And we also want to know that number of people who have signed so that we know that sufficiently many people have signed a certain message. A key thing to note here is this subset can change over such such computations are useful in emerging blockchains and so on. So the exact statement which we prove is APK is the aggregated BLS public key of T public Keys that belong to some mercury of N public Keys. And the root digest of that BLS public keys is actually c so say in this example, let's say that we have a merkel digest over the BLS public keys of a slot a zero to seven, and say position two, four and phi sign a specific message.
00:24:15.166 - 00:25:25.902, Speaker A: Then what we do in the map operation is first we compute the number of people have signed and at the leaf level it's just going to be the one and the key that was used to sign public key that was used to sign is G raised to the specific secret key and we can do this. And once you have mapped this value, you can perform the reduce operation at the successive levels. So in this case if you look at this specific example so since two keys have signed under this sub tree, so the count is going to be two and the public key that is going to be there is going to be the product of these two keys. And this is not proof at each level which will attest to the fact that this computation was done correctly. And you can do this all the way to the top, you can keep on aggregating values at each level of the tree and in the end you just have three people who have signed. So the count is going to be three and the product of these three public keys and it comes with a snat proof to say that everything was fine and everything was done correctly. So whenever a specific position in the vector changes we can update it by rerunning the path from the leaf to the root.
00:25:25.902 - 00:26:11.758, Speaker A: This way we don't have to recompute the entire proof from scratch. All you have to do is just perform login size updates to update any change that happens to this data. Another application is what we call as digest translation. Say that there are N values in a vector and you compute the merkel digest using hash function one. For example, it could be sha two five, six and you compute the merkle digest C two using porcelain based hash function. And we want a proof which essentially says that C one and C two were computed over the same set of values. Such proofs are useful in roll ups where it's difficult to prove membership over an expensive hash function like Shah.
00:26:11.758 - 00:27:08.446, Speaker A: However, you can simply attach a proof saying that, hey, here is the snack proof which essentially says that these values correspond to the same set of n values that were committed in the vector. So the exact statement which we are trying to prove here is mercury digest c one and c two correspond to computed using hash functions, functions h one and h two respectively. And these were computed over the scene and values. So just like the previous BLS key approach, you can first compute the merkle touches using the hash function h one. And the map operation in this case is going to just be an identity operator. It's just going to return the same value. And at each level you can compute the you have the result of the hash computed using the hash function h two and there's a snark proof that attests to this correct computation.
00:27:08.446 - 00:28:02.390, Speaker A: And you can have this all the way until the top. And essentially pi would serve as the proof that these were computed over the same set of values, but two different hash values, two different hash functions were used. So we performed a preliminary implementation of our approach using plonky two. So recall that the tree like structure of our approach makes it easy to parallelize. And we notice that our distributed version can be up to ten x faster than the sequential version of our rec proofs. The proof size is 45 KB. However, our aggregation is slower than standard merkel snarks, where by merkel snarks I mean that you use graph 16 and posted and hash function to prove that there's a set of elements that went inside the batch.
00:28:02.390 - 00:28:36.180, Speaker A: Our verification is up to 40 x faster than this approach, however, and we can update a single Merkel proof, the batch proof, in 35 seconds, and it is 43 times faster than Merkel Snarks, and it can be up to 135 times faster than Merkle Snarks. Whenever there is a change in the size of the batch, that triggers a new setup and a new circuit and so on. So here is the link to our paper. With this, I'll stop and take questions.
00:28:39.900 - 00:30:26.250, Speaker B: Hey Srivan, thank you very much for very well explained rec proof that you guys have published recently. So something that I also wanted to kind of touch upon, as you were kind of explaining how the rec proof works and how they kind of combine the leaf nodes and then sort of perform a snark on top. Of it. And then you kind of stack it up into an entire merkle tree with, at the end, a single snark that represents the entire batch. One thing I was kind of curious was like if I wanted to, let's say, reduce the amount of recompute that I want to do whenever I'm updating the batch, right? Let's say the BLS key example that you mentioned, whenever there's a new BLS signatures that is coming in, or that the validator sets have changed, that some disappeared and some popped up, for example, there's always some, I guess, a minimum bound of recompute that I have to do. Because if you follow back the trees, it's like, oh, I have to recompute this stock, then I have to recompute that stock, and so forth. I was thinking then, in that case, would it make sense, tell me if this is some weird idea, but would it make sense to have a tree that is non binary, meaning that you could have maybe more than two nodes within following the one node? Wouldn't that kind of save a bit more extra?
00:30:27.100 - 00:31:05.972, Speaker A: We are, in fact working on the generalized version of this. We are working on a KRE tree, MPTS, and other variants of this tree. And we are trying to get a good sense of how the performance compares. So regarding the stuff you mentioned about multiple updates coming in, you don't have to do each update sequentially. You can put all the updates together and you can just perform the Snot computation. Once you have you can do multiple updates simultaneously is the point I'm trying to make. You can also think about doing this for different branching factor and so on.
00:31:05.972 - 00:31:09.210, Speaker A: So that's something which we are currently working on right now.
00:31:09.900 - 00:31:15.844, Speaker B: And when you say, like, different branching factors, what kind of trade offs do you think you would be making with this direct proof?
00:31:15.972 - 00:31:40.640, Speaker A: So the work at each level could become more because you'll have to keep track of multiple things that are happening. But let's say the tree height could change, right? But at the same time, that's more realistic to what people use in the real world, like MPT tries and so on. So that will be closer to that. And yeah, this is how it's going to go.
00:31:40.790 - 00:31:50.644, Speaker B: Got you. And then is it also fair to say that the deeper the tree that you have, the more computer overhead that you may have?
00:31:50.762 - 00:32:25.628, Speaker A: So at each level you also have to do the key thing to notice here is at each level you also have a bunch of smart proofs coming in. So if your smart proof verification, recursive verification is a lot, then having a large branching factor has to be carefully thought out because you could have more than two proofs to verify that could come in. And that could be if verifying that snap proof is the primary overhead, then that could dominate the cost of doing it.
00:32:25.794 - 00:32:50.756, Speaker B: Got you. Okay, sounds good. I think that makes a lot of sense. And again, I'm looking forward to seeing your, I guess, explorations on multiple different versions of Merkle trees that you will apply rec proof on top as well. So, looking forward to that. Great. I think that's all from the questions.
00:32:50.756 - 00:33:01.004, Speaker B: And again, Shrabhan, thank you very. Much for the time and also explaining the recproof for us and yeah, looking forward to the future works. Thank you very much.
00:33:01.122 - 00:33:02.956, Speaker A: It was nice talking to you folks. Thank you.
00:33:03.058 - 00:33:03.450, Speaker B: Thank you.

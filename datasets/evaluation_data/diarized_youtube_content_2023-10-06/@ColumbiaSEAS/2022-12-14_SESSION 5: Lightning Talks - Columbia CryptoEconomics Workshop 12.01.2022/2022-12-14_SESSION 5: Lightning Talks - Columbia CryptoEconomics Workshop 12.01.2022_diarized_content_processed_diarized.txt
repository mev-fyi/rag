00:00:00.810 - 00:00:36.598, Speaker A: Okay, well, welcome to the lightning talk session. We will have ten talks. Each will target four minutes, maybe leaving 1 minute for questions, maybe one quick question. So, let's get started with Matt from Princeton. Okay, thanks. So, I'm going to talk about strategic mining and these reorg attacks with Mev. So let me start.
00:00:36.598 - 00:01:26.226, Speaker A: So it's okay if you don't know exactly what selfish mining is. So this was the first result that got me interested in the blockchain space. So there was this seminal work of a seer that showed a strategy that eventually got called selfish mining, that said, if you use this strategy to mine bitcoin, this is better than following the bitcoin protocol, as long as you have at least a third of the total hash power in the network. And they did their analysis. In the model where the revenue per block is constant, you get 6.25 bitcoin for every block in the longest chain that you have. And there's this much lesser known follow up work, but that I thought was super cool, that showed that actually the strategy that a Yalin Sierra found is almost the best thing you can do in the bitcoin protocol.
00:01:26.226 - 00:02:04.542, Speaker A: So if you have less than 32.9% of the total hash power on the bitcoin network, then it's actually in your best interest to follow the protocol. That's the most rewards you can get. And they also did this analysis in the setting where the revenue per block is constant. And as we saw Tim mentioned it in his talk, and it came up earlier with the sessions on meV, that's not the state of the world that we're in either, because the transaction fees will eventually dominate the block reward. So in bitcoin, eventually there's going to be no block reward, and transaction fees are supposed to take over. Those are just going to vary, like Tim said, from block to block.
00:02:04.542 - 00:03:17.018, Speaker A: And in turning complete cryptocurrencies like Ethereum, there's also meV, which I now learned is not minor extractable value anymore, but that will also vary from block to block, naturally. And that's what I'm going to talk about. And prior to the work I'm going to describe, it was just kind of like largely assumed or not really discussed that. Look, the miners are big players, they're risk neutral. If we can somehow get the average reward per block to be 6.25, then it doesn't really matter whether the block rewards vary or they're constant. And if I were to guess, I would say the possible justification for this is there is a true claim underlying here, which is that if you use the same mining strategy in both worlds and you're risk neutral, then you're going to get exactly the same rewards, right? So that intuition is correct, but the intuition that's missing is, I would say, highlighted by this at the bottom, which is just like when the rewards per block vary, you have a much richer set of strategic things you can do.
00:03:17.018 - 00:03:58.840, Speaker A: And so I'm just going to try and give one or two examples, depending on how much time I have, of what this is. And the main thing I would try to point out is that these two attacks don't even make sense when the block reward doesn't change from block to block. And the first one is saying that actually you need to worry about things like selfish mining, no matter how much computational power anyone has. So let me just give you the following example. This is going to be like math, but it's somewhat like math. So imagine that the block rewards are negligible. So either because you live in a world where mev on average is huge, or you're in the bitcoin future where there's no block, rewards and transaction fees are where you get your money from.
00:03:58.840 - 00:04:45.000, Speaker A: So say that the average reward per block is x, and say that you're not close to a 51% attack, so you have non negligible but very low hash rate. And now let's say. So this is something that might happen, right? The most recent block that got created, you didn't make it, and just because there's either a lot of MeV or there was a very high value transaction, it's worth 1000 times more than normal. So say that happens. That could happen. So what should you do? So, if you find the next block, what should you do? So what the protocol would like you to do is just be honest. And if you're honest, you're going to add that block to the longest chain, you're going to get your reward of x, and you're going to move on.
00:04:45.000 - 00:05:33.560, Speaker A: Another thing you can do is you can do what used to be called a fee sniping, is you could say, well, let me try to fork your block. And the math you would do in your head is you would say, well, I'm hoping that I'm going to find the next block. If I do, then I can successfully orphan yours, because I'll have a chain of length two to your chain of length one. And you can do some quick math in your head and say, you know, the probability that I succeed is one in 100. I have very low hash rate, but it's not zero. And I'm going to get 1000 times x if I succeed. And you should just do this, right? And so I would say any rational miner, as long as they have, in this case more than one in 1000 of the hash rate, they should try and do this.
00:05:33.560 - 00:06:25.462, Speaker A: There's even a third thing you could try and do, which is rather than rely on yourself mining the next block, you could say, well, whatever's going on, I'm going to myself take half of this super large reward and I'll write a smart contract to pay whoever builds on top of me the other half. And now I would say, not only do you win whenever you mine the next block, whenever the next miner happens to be someone who wants 500 x instead of being honest, then you're going to win in that case, too. Okay, so this is just an example. And hopefully you can see that sort of like the whole thing driving this is that there exists a block with value 1000 x. And that will not happen in the block reward model with no Mev. That can only happen when there's either MeV or transaction fees instead of the block reward. Okay.
00:06:25.462 - 00:07:15.210, Speaker A: And I'm done. Thank you. If the next speaker can come here. Did anyone have a quick question for Matt? No? All right, well, next up we have Jesson from George Mason. Okay, so thank you for having me. So I'm going to report some of the ongoing work on distributed consensus, both on theoretical side and empirical side. So this is based on two papers.
00:07:15.210 - 00:07:45.078, Speaker A: One is with my co authors from NYU and Chicago, Hana and Jugo. And another is with Jugo and Jenxin, who is also sitting here asking, will be answering all difficult questions. And so for the theory part, I'm going to just highlight some of the results. We know that BFT protocols typically assume that there are some byzantine nodes that may behave arbitrarily. And there's also those non byzantine nodes will just honestly follow whatever the protocol that's given to them. And as long as they do so, there's, the protocols will guarantee certain properties. Okay.
00:07:45.078 - 00:08:32.930, Speaker A: But we know that blockchains live in a trusted environment. So what do we mean that we need to get rid of this honest assumption and to incorporate that assumption that non byzantine nodes may potentially be irrational. And for economists, it's very reasonable to kind of think about rational players in this framework. But it difficulty comes to the fact that we know that some of the nodes are byzantine and they are going to behave arbitrarily. And if you think about if you are a rational player in a game that is playing with some crazy players and how can you actually reason about it? What is the right solution concept coming out of this? So luckily, economics offers some tools which we call ambiguity aversion. And so basically what this paper tries to do is to get rid of this honest assumption. Assume that non byzantine nodes are rational and also assume that they are ambiguity averse over byzantine node strategies.
00:08:32.930 - 00:09:26.120, Speaker A: And just to be more formal, we know, like if you look at the expression here, if you forget about the red terms for the moment, this is how traditional game theory, irrational players reason. In a game theory you would like to choose your, for a player I you choose your action. AI think with their belief about what other players are going to play and maximize your expected utility. But the fact that there are now going to be some byzantine nodes means that you need to take into account that your payoff may also be affected by the decisions and the strategies chosen by these byzantine nodes, because you don't know what they're going to do because they are unpredictable. So you're going to be thinking about the worst case scenario. Okay, so this is kind of the framework that we think is going to be helpful for economists to reason about BFT protocols. So what we do in that paper is to basically just set up a very simple game.
00:09:26.120 - 00:10:12.462, Speaker A: It's actually a very simple game. And just like there's nature, randomly selected leader, leader sends a message to the backups, backups forward messages among themselves. And then based on this message, everyone decide on whether they commit to a message or not. You can immediately see that this is not a complete description about most BFT protocols because there could be potentially, the game may be repeated many times, including view changes. And especially like those communications, the peer communication may happen occur multiple rounds. But the benefit of having just this very simple framework is allows us to characterize all equilibrium coming out of this game and to demonstrate the power of incorporating ambiguity version into game theoretical analysis. So I'm going to skip most of the game setup.
00:10:12.462 - 00:10:56.286, Speaker A: So I'm just telling you some of the implications coming out of this. The first finding is that whenever we incorporate rational behaviors into BFT consensus, there's always going to be multiple equilibrium. And especially there always an equilibrium in which the consensus just gets stuck. Okay, so if next time we see a chain get stuck, we know that's not too surprising because that is one equilibrium outcome. But of course, we also look for conditions in which the good equilibrium will exist. And we provide some guidance on what are the trade offs between the reward and penalties given to the rational nodes to make this successful equilibrium to happen. And also we talk up some of the implications of message losses, and actually they have a significant impact on the structure of the equilibrium.
00:10:56.286 - 00:11:51.734, Speaker A: Okay. And then just very quickly, I'm going to just tell you about some of the empirical analysis. We look into Ethereum slashing protocol, and the too long didn't read version is that Ethereum is fine. Okay. Initially what we look at is we want to understand how does the slashing mechanism in Ethereum work. Here's a lazy look into the Beacon chain explorer, and we can see one of the nodes here is actually being slashed because of doing this double voting. Okay, and this is good, but our question is, okay, but are all bad behaviors actually caught? Right, so if you are actually doing double voting, do you actually always get slashed? So initially what we did was just, we look into this explorer and actually, if you can see here, I just take some snapshot from the beacon chain explorer, and you can see here this validator is 2787.
00:11:51.734 - 00:12:22.042, Speaker A: And actually we find that he has two double votes. That's kind of a tautology. He has a double vote. But the fact is that actually, just until yesterday, he's not actually not slashed. So he's still very living happily. And also we can have some examples about surround vote. Our initial finding was that, okay, it seems that actually in our data sample, we find like more than 75% of those violations actually failed to be slashed.
00:12:22.042 - 00:13:05.334, Speaker A: So we thought this is a big news. So we kind of just tell the public and we tweet about these results and seek feedback from the community. And then here's the response from the community. Someone found that maybe mostly it's kind of an explorer bug. So here is the lead developer from Lighthouse, which one of the largest client of beacon chain, and then here's someone from Beacon chain, from the explorer themselves admitting that there seems to be a bug in their explorer. And of course, then from the Ethereum Foundation, Danny Ryan was telling us he seems to be not very happy with talking about our results. But anyway, but I think it's kind of a good dynamics.
00:13:05.334 - 00:13:45.714, Speaker A: We actually get very valuable feedback from the audience. So kind of the consensus coming out of this, what appears to be going on is that just as the kind of the motto goes, right, verify, don't trust. So it seems like the Explorer, at least in the beacon chain space, does not necessarily seem to be that reliable. And there's a lot of work we need to actually to improve on that. And if you just blindly trust the explorers, there's going to be danger coming out of this. So some of the ongoing work that we are looking at is we want to understand what did the explorer actually messed up. So there's a kind of result that actually just came out this morning and we actually verified the signature of those extra blocks.
00:13:45.714 - 00:14:31.420, Speaker A: And it turns out those blocks actually have wrong signature. So this kind of, again, so it's just kind of coming back to what we said is like ethereum so far seems to be fine, but there's still ongoing work for us to figure out what is actually going to be. What is actually going on to conclude is that explorers are not necessarily reliable, but we still want to understand how to improve explorers by understanding what is actually happening. Okay, so I think I'm going to stop here. Thank you. All right, if you have Theo come over. I don't think we have time for questions, but you can find the speaker after I have a PDF.
00:14:31.420 - 00:15:07.536, Speaker A: Sorry. All right. Hi, everyone, I'm Theo. This is going to be another transaction fee mechanism talk a little bit different. We're going to be kind of talking about how to design these multi dimensional fee markets. So, first, from this morning, from Unscar's talk, we know that kind of fixed relative prices can lead to quite bad inefficiencies. They also open up vectors for denial service stacks.
00:15:07.536 - 00:15:54.788, Speaker A: And so what I'm going to talk about right now is how to kind of, from optimization, get a framework for actually designing these multidimensional fee markets for different types of resources. And we mean resources very broadly. I think Anscar did a good job of saying resources can be anything from storage compute, like these kind of very course objects down to the opcodes or sequences of opcodes. The key idea in our framework is to essentially implicitly solve an optimization problem over the included transactions. And each transaction has some resource vector associated with it. So we denote that aj here, the prices then are going to come from convex duality theory. And where these prices, or where the update rule is going to come from is essentially what, as the network designer, we decide is our loss function.
00:15:54.788 - 00:16:41.344, Speaker A: So essentially, how unhappy are we with a current throughput? For example, if we take this loss here, which is just an indicator loss, it says unless I'm exactly at my target throughput, I'm infinitely unhappy. We get something that looks a lot like gradient descent. Obviously, this is a toy example, but you can imagine much more complex loss functions that allow you to kind of optimally trade off between resource usage. Okay, so what's the optimization problem? We call this the resource allocation problem. Essentially, it's to maximize the net utility so that q vector is the utility of each transaction minus the loss incurred by the network. And then this is subject to defining the throughput as ax. If you note that x is a zero one vector.
00:16:41.344 - 00:17:08.110, Speaker A: So that's just going to be the resources that are actually used by a given block. And then also x has to be in some set of allowable transactions. So s can include very complex things. So for instance, only one searcher can sandwich a transaction that could be included in s. It could be this very complicated set. We're going to use the convex hall of that just so we can apply kind of the necessary theory. But we'll see that this doesn't really matter.
00:17:08.110 - 00:17:48.872, Speaker A: Of course, this problem is not solvable in practice, because the network designer can't say which transactions are included or not included. The validators do this, obviously the utilities are unknown. And then when we take the convex hall, we allow fractional transactions, which doesn't really make sense from a block perspective. However, to solve this, we can actually use duality theory. If we look at the dual problem of this, we get a problem that's a minimization problem over prices. And the first term is kind of what I call the network term, and that ends up being the conjugate function of the loss function here. This is something that's a very rote thing in convex optimization, often enclosed form.
00:17:48.872 - 00:18:21.524, Speaker A: So you can think of it as like easy to evaluate the next term here if you look and kind of squint. This is essentially the block packing problem. So what is this? This is essentially choosing the transactions to include out of the allowable transactions that maximize the net utility. So the utility minus the cost, where that cost is essentially what's burned. So that goes to the network. I call this the transaction producer problem, because this is kind of a joint user and validator utility. And sorry to the game theorist, we don't really pull these apart and analyze incentives here.
00:18:21.524 - 00:18:57.708, Speaker A: But of course, lots of opportunities for future work. So what happens at optimality? Well, when we have the optimal prices, kind of the primal constraints are satisfied. But more importantly, what we have is that the optimal prices charge the transaction producers exactly the marginal cost faced by the network. And so that's the gradient of this loss function. Furthermore, this suggests an easy way to update prices on chain. We could just run something like gradient descent or your favorite unconstrained optimization algorithm. And we don't actually have to solve that block building problem on chain.
00:18:57.708 - 00:20:19.122, Speaker A: We can rely on essentially looking at the previous block, assuming that those blocks are packed optimally or almost optimally, and just saying, okay, which transactions are included in the previous block? What's their resource usage? And that gives us a way to compute the gradient. So kind of the key takeaway here is that when we're thinking about how to design these kind of multidimensional pricing mechanisms, one helpful way to do it is to, instead of kind of saying, okay, what should my pricing update rule be? Is to step back and say, what loss function should I have? So what the resources should be, what loss function on the throughput should I have? And then turn the crank through kind of standard duality theory and get a price update rule after that. And then we have a pre print of this on archive right now. And then I also have a longer version of the talk at Devcon. Thank you. All right, next up, we have Julie from. Yes, everyone.
00:20:19.122 - 00:20:49.422, Speaker A: Today I'll be talking about blockspace derivatives. And first of all, to begin, blockspace is a commodity. It's a commodity that Ethereum sells. But unlike with traditional commodities, there's not an active trade in derivatives on this. And then an important question to analyze is, why would we even need derivatives? Well, first of all, there are lots of financial applications of derivatives. But apart from these, there are some very real hedge cases that are useful for ethereum scaling. For example, Tim Roughgarden and Anstar talked about this before.
00:20:49.422 - 00:21:34.518, Speaker A: For layer twos, the pricing scheme is quite difficult because imagine all kinds of users entering a layer two, and they're paying for the layer two blotch space, which eventually has to be settled on the layer one, which is pictured here. But then the layer two can't actually accurately price layer one blockchase. And by introducing blotch based derivatives, they could do this. And there are many other applications that will be able to use such kind of derivatives. So then what's the problem with this? Well, first of all, guaranteeing actual blockchain inclusion is very difficult because blockchains are permissionless and decentralized. You can't control a large part of the validator set to be able to ensure that your transaction will be included in the next end blocks. And secondly, if you're going to cash settle the block space derivatives.
00:21:34.518 - 00:22:29.238, Speaker A: So based on, for example, the ERP 1559 base fee, this base fee is very manipulable. So since it depends on the last block, if the block is less than half full, the base fee will decrease, and if the block is more than half full, the base fee will increase. Therefore, people can manipulate the positions that they have if this is profitable for them. So a possible implementation of this is simply based on doing some math on the base fee calculation, making sure that the cost of manipulation, so cost of filling up the block to the match, which is a fixed cost, is less than the amount of profit that's available from manipulating this. And you can do this by issuing fixed amounts of block space derivatives that is strictly less than it would cost to manipulate. And this would ensure like a maximum secure supply. But even this is very difficult, because calculating the cost of manipulation is based on the actual gas demand in a block.
00:22:29.238 - 00:23:16.586, Speaker A: So if you want to do it for the next block, maybe it's possible. If you want to do it for very many blocks ahead, it's not possible. And if you do this incorrectly, people will manipulate and the chain will be congested, which has a lot of negative functionalities. And one hacky way to save this is by introducing a smart contract with a fill safe, where if you can prove that your toss manipulation is lower than the profit, you can simply pay that toss of manipulation to the smart contract and you'll be paid out the maximum amount for your derivatives. Then, an interesting part about base fee derivatives that put call parity actually doesn't work. The put call parity is very essential for hedging in many financial applications. But because the base fee is burned by ERP one five nine, the underlying is not there.
00:23:16.586 - 00:24:14.990, Speaker A: So there is like a cash flow mismatch, which needs a lot of financial engineering to work around. An actual lucky advantage of this is that in the case of where people would maybe deliver an empty block, thereby dropping the base fee, and in the case where they would be a full blot, and thereby rising the base fee, you can't profit from both sides, because one side is the profit is capped by the premium that the option sells for, and the other profit is just based on the option. So that's a lucky advantage of this. However, a bit disadvantage of it is that there will be much less liquidity, because market making in these kind of situations is a lot more difficult. And also, a question I've been analyzing lately is whether blockchain rifters that are cash shackled actually realize all value that's there. And if this is important, so first, examining whether this is important to realize all available value. Imagine that we have Ethereum as a domain where not all value is realized and we leave lots of money on the table.
00:24:14.990 - 00:25:23.474, Speaker A: Will there simply be another domain that does realize all value, and thereby they can distribute better, making sure that Ethereum basically becomes irrelevant as domain. So that would be an argument for us saying that we need to realize all value. And this is something that's not realized with cash fees because you have something called Trustmain MeV, which is very dependent on where you can actually include your transaction in a given block, because you might need to coordinate with other domains. And an example of this is you could, for example, be a market maker on a centralized domain and thereby guaranteeing your execution on a decentralized chain, decentralized domain and then doing some sort of arbitrage was very dependent on getting your transaction included. And where cash settled based fee derivative might not be sufficient. And also blockchain could be seen non fungible in this way, where it might be more important to have a certain blot space above others in certain cases. And the word that I've been going through now is block versus slot auctions in a proposal builder separation.
00:25:23.474 - 00:25:59.220, Speaker A: So blot auctions mean that you commit to the contents of your blot at the time of your bid. So that's what you see on the left hand side, you see a block full of transactions that have specific values, and slot auctions mean that you bid, but you don't actually have to commit to a specific block. So you can just leave it empty and just deliver the block whenever it's necessary. And this has much different effects on cross main mev because you can extract very much different value. Yeah. So these different form of base feeder with this. And that's what I've been talking about.
00:25:59.220 - 00:26:40.702, Speaker A: Thank you. Thank you. We have Augustino next from Colombia, Chris. Okay, so let me start. This is like following the minor extractable value, which is a topic that we have already seen in the morning, and front running risk. So before talking about minor extractable value, I want to mention why it arises. And the reason is exactly the fact that there are front running attacks.
00:26:40.702 - 00:27:22.174, Speaker A: So what is a front running attack? Suppose that a user, let's say team, is submitting a transaction and is upending some fee as usual in order to get executed. And then somebody's like Siamac for example, is looking at this transaction and say, okay, let me place the same transaction as team, but with a larger gas fee so that I will execute at the price that team should have executed. And then of course, after executing after, for example, buying, the price will go up. So team will execute at an unfavorable price because the price went up. And then CMA can close the loop by selling. So it's sandwiching team in its inflections. And of course, if there is a lot of competition to execute this front running attack.
00:27:22.174 - 00:28:29.090, Speaker A: That means that there is a large gas fee that will be generated, and this fee will be earned by the miners. And this is basically what goes under the name of minor or maximal extractable value, or the bad minor extractable value, because essentially, this is not really helping any price discovery or like market quality. So now, one of the ideas to mitigate this problem has been to introduce some private channel. For example, the flashbots is an example of a relay service, which is essentially a private off chain channel where users can submit transactions, like in a way, they submit these transactions directly to the validators. So the searchers in the searcher builder proposal separation are essentially constructing this set of transactions where they can append their own transactions without being spied, without being visible to others, and therefore they cannot be front rank. And the question is whether or not having these private channels is reducing or is mitigating the minor extractable value. And that's what we want to study in this paper, which I forgot to mention, is joint work with Regier and the Xiao.
00:28:29.090 - 00:29:25.270, Speaker A: So the idea is that, first of all, what can go wrong, or why users may not consider using this flashboard of private channels? And one of the main reasons is the so called execution risk. The idea is that it really depends on how many validators are monitoring these private channels. Right? If many validators are monitoring channels, then if you submit there, the validator will get the right to update the block chain, will basically be able to see your transaction, and therefore your transaction will be executed. But what could happen is that maybe these private pools are only monitored by a few validators, by a very small fraction of the validators. Which means that if the validator we selected to update the block chain is not really monitoring your private pool, then your transaction will have to wait for a long time to be executed. So you face this execution risk. And that might be a reason why you may consider not to submit your transactions through this private pool or through flashbots.
00:29:25.270 - 00:30:50.570, Speaker A: But what do you gain? Of course, what you gain is execution priority. The idea is that the transactions that are submitted to the private blocks will be executed first, and then all the other transactions which are like part of the public blockchain will be executed later. So if you want to be executed quickly and you want to be at the top of the block, then you would better use these private channels. So now, if you look at the data, we see that really there's a very positive correlation between front running risk, which is the probability of transaction being front run and how many validators are choosing these private pools? As we see that the probability of being front run goes up, then the usage of this private pool is also going up. Question is, okay, are these private pools really achieving their intended objective to mitigate these negative externalities coming from hike gas fee search? And one of the findings that we have is that this is not really what we see in the data, because if you look at the ratio between the US fee paid and the revenue that you get from front running, you see that after the introduction of flashbots, which is the bottom graph, this cost is going up. And one of the reason is that there is a lot of first competition, being arbitragers who want to use these private channels to front run users. And they are competing basically, for this first execution.
00:30:50.570 - 00:31:31.322, Speaker A: And this first ride till bid option is actually raising the gas fee, compared to the situation where there was no flashbot. So it's really not achieving the objective. And this can also be shown through a game theoretical model. Second question is, is front running risk being mitigated? That was one of the other idea behind introduction of flashbots. And what we see, first of all, when would front running risk be completely eliminated if all validators are adopting these private pools, right? If everybody's on this private pool, then I don't have to worry about execution risk, so I would use them. But what we see is that not all validators are adopting this private pool. In fact, a small fraction of validators, a fraction fuller than one, is adopting these private pools.
00:31:31.322 - 00:32:00.790, Speaker A: And as a result, the users may choose not to submit all these private pools, because they are worried about the execution risk. It really depends on how much they value reduction of front running risk versus how much cost they would incur from being front run. And what we see is that. Exactly. Validos will decide not to join these private pools precisely because they want to preserve Mev. Because they will be able to extract more value from the users if they are not using the flashbots. Right? Because if they submit transactions for flashbots, they will not be able to front run.
00:32:00.790 - 00:32:48.432, Speaker A: And that's like one of the findings that basically, neither front running risk nor gas research are being mitigated using flashbots. Thank you. Next up, we have Xin Yuan from flashbots, how to move. Great. Okay. Yeah. Mav and credible commitment devices.
00:32:48.432 - 00:33:10.410, Speaker A: What I'm going to tell you is not a talk, but a story, a fable, very simple story. So please follow. This is Kim. Meet Kim. Kim has a box, so this box allows him to delegate arbitrary actions. And it's common knowledge that this box executes him faithfully. Now, Kim wants to use this box to improve the efficiency of the games that he's playing with his friend mate Don.
00:33:10.410 - 00:33:40.132, Speaker A: So suppose they play the simplest game, a prisoner's dilemma. So then in the equilibrium payoffs, both of them get one, and in the best payoff, both of them get two. So King would want to delegate the box priority to the game begins in the following action. If Dong commits to being silent, then I commit to being silent. If Don doesn't, then I commit to betray. Okay, so then committing to this box, Kim is able to. We can see the extensive game tree on the right.
00:33:40.132 - 00:34:04.728, Speaker A: So both of them get the payoff too. Great. Now box makes the game work. So then there is some problem, right, but Kim wouldn't be so benevolent. Surely he would be much more rational. In fact, the dominant strategy for Kim to commit is to say, to delegate to the box, that if Don commits to being silent, then give me two minus epsilon after the game, then I commit to being silent. If Dong doesn't, then I commit to betray.
00:34:04.728 - 00:34:33.124, Speaker A: This is a rational move. But then now we see that the only payoff possible is three. One, where Don is indifferent between using the device and not using the device. Okay, so then, now suppose both Kim and Don can use that box. So now only three one and one three are the set of implementable payoffs. We are not sure if this is desirable though, right? Because it means that one of them is going to be indifferent between using or not. So now let's abstract away the person with the box call her C.
00:34:33.124 - 00:34:56.776, Speaker A: And then we call Kim and Dong a. And B. Very simple model. We have this box, which is a credible commitment device. So it feels natural to model this as a corporate game, right? Specifically, we suppose that ABC used the box to form collisions. We can draw the coalition payoff collision know in here, and then we. Okay, messing up my slides.
00:34:56.776 - 00:35:46.300, Speaker A: But you can see that the core of this corporate game, which is the only stable set of payoff functions such that no subcollation could profitably deviate, is one, one, two. Which means that a will get a payoff of one, b will get a payoff of one, and C, the person with the box, gets an extra payoff of two. Okay, so then we can see in reality that the core manifests itself. For example, Kim and Dong can both use the box and bid in the first price auction scenario, right? So we are all familiar with this. If Dong commits to silent, then I commit to silent. If Don doesn't, I commit to betray and then transfer coinbase to, which means that you bribe, you bid in the first price auction. So that's a problem.
00:35:46.300 - 00:36:23.044, Speaker A: There is no point in using the box anymore. The box is useless. The magic of the box has disappeared. We see that front running is a dominant strategy in the wrapped game. Okay, so then how about we generalize this? If we generalize this, we see that the box we have at hand is actually a permissionless, credible commitment device called crypto economic mechanisms. And then what we actually want to initially achieve with this box is to use it for coordination, for playing cooperative games. But there are some externalities that we use the box to form in coalitions.
00:36:23.044 - 00:37:01.760, Speaker A: Unlike traditional cooperative game theory setting, where coalition formation has no externality. Specifically, the externality in this scenario comes from all agents saying, if the other agent doesn't cooperate with me to achieve maximum social welfare state and transfer me all of the surplus welfare, then I will commit to making their lives most miserable. For example, leaving of the collision. Right? So this is a dumb strategy for each of them to commit to. Okay, so then we see that the externality is extortion or collusion. So we know we can model extortion as a function k ab for the profit that collision a can extort from collision B when they use the box as a collision formation device. We draw some formulas.
00:37:01.760 - 00:37:45.330, Speaker A: We see that each agent extort the best state of the mega collision minus the worst state of the extort, t minus your original payoff. And then what's special about here is that we actually can get an astral profit, which is the externality of collision B's formation. Right? Because collision B has a common knowledge. They know that when they want to deviate from your extortion, they have to pay this externality. Okay, so we know this equation. We discover that in this case, MeV is actually the maximum possible extortion profit by any sub collision, considering their externality of formation using the box. So we see, unsurprisingly, MeV arises as a result of using.
00:37:45.330 - 00:38:11.640, Speaker A: Of us wanting to achieve something using the box. So, one could also verify that assuming no innate collision formation cost we had, MeV equals maximum surplus welfare that is possible to be gained from the coordination. Which means that if we change the definition of price of anarchy to be the difference, instead of the division, MeV equals to the price of anarchy. So this is Kim. Kim has a box with MeV. The box is useless. Kim is sad.
00:38:11.640 - 00:38:55.910, Speaker A: And we are Kim. Thank you. Next up, we have Alex from EF. Hey, everyone. This might be even less than five minutes, but we'll see. So this will be probably less theoretical talk than some of the others we've seen. I just want to talk about this notion of the builder that we're seeing emerge in a lot of these crypto networks in particular.
00:38:55.910 - 00:39:33.792, Speaker A: Like Julian was just saying, there's this commodity block space. It turns out we can refine this block space in various ways. And what this looks like to the end user is these value added services. Some of them are pretty cool in some way. Mev is one of these, which, as we've heard, a lot of people seem to not like that. So double edged sword, pretty simple. So we have this block space, right? There's this thing that the protocol generates or creates, and it's very valuable, at least to the extent that, for example, on Ethereum, that people care about the state and want to make mutations to the state, they need block space for that because it's so valuable then.
00:39:33.792 - 00:40:19.552, Speaker A: Now there's sort of at least incentivizes, if not hosts, this desire for specialization. And we are starting to see this emergence of this thing called a builder that performs these tasks. When we talk about PBS proposed rebuilder separation, it's like a consequence of this fact. And it's like I said, these builders specialize in refining block space into higher value goods and services from just like sort of raw gas or whatever your protocol uses. Here's like a fun image just to really drive the point home. You start with this raw ore, which is refined maybe into some usable metal, which is further refined into metal money or something like this. Here's a very dense slide with a bunch of different ideas around taking this block space.
00:40:19.552 - 00:40:54.990, Speaker A: And you could imagine there's an off chain actor who implements these things. And again, are examples of refining block space in this way. So we'll just run through them sponsored transactions. One of them is the idea here is that rather than me as the user of the protocol, paying for the gas for my transaction, someone else pays for it. This is like a thing people usually want, especially those who are less technically inclined. They just want to make a trade on uniswap or something like this. They don't want to have to think about gas or having eth in their account to cover the gas and all those things.
00:40:54.990 - 00:41:48.684, Speaker A: Another one, this is a big one. People seem to really be into instant confirmations or like pre comps. The idea here is, for example, if I submit transaction on Ethereum today at like, l one, maybe gets into the next block, maybe gets into a few more blocks in the future, maybe it never gets into a block. It'd be better if you could provide harder guarantees around when exactly a transaction goes on chain. And something like a builder or l two, a sequencer can actually make this commitment for you, which is really nice. Another one, cancellations, retries, these are all sort of variations with the same theme. I might want to broadcast my transaction because it's convenient for me now, but maybe I want to wait for some events until it gets on chain, or maybe I want to have some retry logic or even cancel it if something happens again.
00:41:48.684 - 00:42:27.348, Speaker A: You could have some external actor who's applying your predicates against some stream of events and using that to add things to protocol that you don't get today, for good reason. This touches on Julian's talk, but like gas features and derivatives and things like, you know, if you have this builder abstraction, you can imagine them like selling block space in the future. This one is an interesting one, selling it in the past, which is basically a reorg. And that's all I'm going to say about that. But it's definitely theoretically interesting to think about account abstraction. This is a big one, if you follow the ethereum. Space is something we've been talking about a lot lately.
00:42:27.348 - 00:43:27.688, Speaker A: For example, with EIP four, three, seven. So again, it's just like abstracting different parts of the core protocol for people who want more flexibility. And again, I kind of alluded to one way to think about Mev is in this same setting where it's an extra protocol thing, but it's very much there. And then now you have something like a builder that is helping you either extract it. You might have heard of maybe smoothing, which is essentially saying if there is Mev, it's like very volatile and spiky, but you can imagine the protocol internalizing it somehow and smoothing it out, building it out over time. Maybe protection like flashbox protects is an example of this, maybe rebates, kind of the whole spectrum of things we hear about today. Yeah, builders can offer this and more generally, this is a bit of a more abstract point, but I think kind of if you follow research here, the direction we're heading in is this place where you start to see that there's resources the protocol provides.
00:43:27.688 - 00:44:00.132, Speaker A: And there might be these intermediate actors like builders, that are sort of intermediating them in more creative ways than just like, oh, I interact with the l one chain and that helps me do stuff. Again, just some ideas here. There's block level 1559. So rather than me needing to pay for the 1559. Priority fee or the base fee with my transaction, just someone must do it in the block generally. And a builder again, could do that. Another one is like we are introducing blob space with EIP four four four.
00:44:00.132 - 00:44:46.770, Speaker A: And so you can imagine again, having this indirection between roll ups, consuming blobs and the protocol providing them. What was this last point? Okay, I'm at time, but that's also my last point here. Great, thank you. Next up we have Francesco from EF. Here you go. Hi, everyone, I'm Francesco. I'm a researcher at the Ethereum foundation.
00:44:46.770 - 00:45:27.754, Speaker A: I'll try to give you kind of a quick overview of how we think, I guess, how sensory resistance works in Ethereum and some of the space ideas. It's a really large space, so it's just going to be some parts of it. So first of all, because it's this conference, but I think it's generally an important idea to keep in mind about sensory resistance. We should remind ourselves that it's kind of an economic property in some sense. So it's not possible to really have absolute inclusion guarantees. We have like a finite resource, this block space that Alex has told you. So we cannot have absolute guarantees.
00:45:27.754 - 00:46:09.670, Speaker A: If the whole block space is taken up for some amount of time. There is nothing that we can do. It's not possible to say, you know, with absolute certainty you're going to be included within this amount of time. So the kind of guarantees that we can give are generally more something that looks a bit more like if someone wants to prevent your transaction from being included for this long, they have to pay this much, or there has to be like this volume of economic activity going on in that time. So let's look into what kind of guarantees we actually have and what kind of guarantees do we have now and what we used to have and what we want to have in the future. So, first of all, let's go with the kind of most basic level. I send a transaction.
00:46:09.670 - 00:47:04.262, Speaker A: How much does it cost to actually keep my transaction out for one slot? And it used to be actually much cheaper to do this because slot for blocks used to be basically mostly full all the time before EIP 1559. But thanks to that, now we kind of have this slack. And so on average, there's going to be basically always, not always, but yeah, on average there's going to be extra space that your transaction can go in. So if someone wants to prevent your transaction to go in, and the proposer has no special reason to kind of aid them in doing that, the proposer is just naively dumping all transactions that they can into their block, then they basically have to fill up the block with useless transactions and basically pay for that. So they're going to have to pay base fee times the amount of space that is free. So quite expensive. But this changes a lot in this new paradigm where proposers are actually, proposers might still be naive, but they're outsourcing execution.
00:47:04.262 - 00:47:59.150, Speaker A: So in some sense, at the end of the day, the entity that decides what gets into a block is not naive, and this entity might be the one that's trying to do the censorship. So you can imagine basically worst case scenario, there's literally one builder that just is making all the blocks and they have kind of absolute power to do what they want with that. There's one builder, they're still competing, but they might be better than all other builders, and for them the cost is really not that high. So if they want to keep the same advantage over other builders, the same margin of victory, basically they only have to raise their bid by the priority fee of the transaction, which is not even the base fee. It's really like the smaller part. So you can raise your priority fee, but you could be in sensor and raise the cost a bit, but still it's quite small. It's only like a cost that you are paying and not this large amount of gas at the very least.
00:47:59.150 - 00:48:43.840, Speaker A: And just a small note is that actually this is the same cost that would be true if proposers were accepting bribes. So to bribe a proposer, you just give them the amount of money that they would get by including a transaction. So in some sense, we're kind of back to this. We are by default in this bribing model in some sense. So for multiple slots, everything is about the same, except that in this model where proposers are naive, which we're not in anymore, you would have that the base fee also rises exponentially. So not only it's expensive for one slot, but it becomes really prohibitively expensive if you want to do it for a bunch of slots in a row, and the other two, I'm just going to skip them. But it's basically just you do that for all the blocks that you want to keep the transactions out.
00:48:43.840 - 00:49:56.654, Speaker A: So the idea would be, how can we get back to this naive proposal economics, where it's really expensive and is it possible, and yeah, basically, if enough validators don't accept bribes, this is possible. There's this idea of inclusion lists, which roughly speaking, is that you basically allow your decentralized validator set to specify in some way what transactions they want included. And specifically there's this one kind of proposal way to do it, which is forward inclusion list because basically you can see that we have some slot and the proposal of that slot is specifying the transaction that they want included for the next one. And this turns out to be to have been nicer property than if you were doing it in other ways. First of all, the most important thing is that it's incentive compatible in the sense that you don't have any cost in making a list unless you happen to be the proposer of both blocks. If you aren't, then you're basically imposing some constraints on the next guy but not yourself, which it just makes things a lot easier. You have really good reason to make an empty list or basically to avoid your censorship resistance responsibilities.
00:49:56.654 - 00:50:31.150, Speaker A: And this kind of brings us back to almost to this naive proposal economics in the sense that as long as there's someone making an inclusion list, the next slot kind of goes back to those naive proposal economics. And yeah, I think be a time. So yeah, just get this one. Thank you. Amazing. We have Fahad next from Wake Forest University. Yep, the clicker.
00:50:31.150 - 00:51:18.854, Speaker A: Perfect. Thank you. So I just want to make a simple point and then use it actually to motivate a bunch of questions that I think deserve a little bit more rigor. So the specific point I want to make is that scaling can actually undermine security. Right. So scaling is not necessarily an unmitigated good in the sense that of course if you speed up the blockchain, you will get transaction activity faster and you'll in fact probably get it cheaper because fees will probably fall. But that's not the only thing that it might do.
00:51:18.854 - 00:52:22.214, Speaker A: It also of course has an effect upon the security of the blockchain. So in other words, we need to think a little bit more carefully about sort of what optimal scale is. Now, just to give you a flavor of why I'm saying that scaling can undermine security, I'm going to highlight one of the many ways to show this, which is I'm going to talk about here, basically what's sometimes called the single shard attack in a very, very simple framework. So if you imagine, for example, there's a set number of honest nodes, let's say n sub h, and there's a bunch of attacker nodes, n sub a. Now if you're just drawing to say, create one committee where the honest nodes exceed the attacker nodes, let's say by a lot, then say random selection is going to get you a situation where you're more than likely to have an honest majority. And in fact, you can get very close to one if the number of honest nodes is large relative to the number of attacker nodes. But of course, if you're going to, for example, shard the blockchain, there's not just one committee, there's essentially activity happening in parallel.
00:52:22.214 - 00:53:07.174, Speaker A: Right? And so if you want to think about, for example, there being s shards, and now you're drawing for each of those shards, really what you kind of have to think about is, well, what's the problem, that none of the shards are controlled by an attacker. Of course this is going to be, if you're sampling with replacement, it would be exactly this. But if you're sampling without replacement, it'll be close to that. And the main point, of course, is that sort of the weakest shard is not going to be like the average shard. And so the likelihood that an attacker gains control of, say, a single shard is actually going to go up as you increase the number of shards. So this sort of creates a vulnerability that you wouldn't have, for example, if you weren't doing this right now. That's not to say that sharding is bad.
00:53:07.174 - 00:53:45.646, Speaker A: That's not to say that scaling blockchains is bad. That's just to say that I think it's important to think about exactly what you want as the optimal scale, rather than say thinking about it as we should get as much scale as possible subject to technical constraints. Right. And more than that, I think there's really important economic questions here, which is, given the optimal scale, how exactly are you going to incentivize that? So on the previous slide, I said take the number of honest nodes as exogenous, but in practice they're not exogenous. You have to incentivize people to do things, and you might have to incentivize more people to do things when you have more shards. Right? So just to give a little bit of depth on what I'm saying here. So we've all heard about 64 shards.
00:53:45.646 - 00:54:27.522, Speaker A: It's not clear to me where that exactly came from. And I'm kind of wondering what the exercise was to try to figure out what the optimal scale was. But maybe more pressingly, if you fix that idea of, say, having 64 shards, how exactly is the incentive structure supposed to fit this? So Tim mentioned in his keynote that ether is now deflationary. But if you scale, the blockchain fees are going to go to zero, including the base fee. So it's not clear to me that ether would remain deflationary. Depending on how much you're scaling this and fees in general, then it's not clear how they're an incentive structure. They're an incentive for doing this if they're sort of driven to zero on the flip side.
00:54:27.522 - 00:55:17.896, Speaker A: So you could say, well, you use block rewards, but I don't know what the level of the appropriate level of block rewards are for these many shards. And the main thing here that I want to emphasize is that I feel like these are questions that deserve a little bit more focus and a little bit more economic rigor. And so for those of you from the Ethereum foundation, if you're interested in talking about these in detail, I would be interested in having that conversation. That's all I got. Thank you so much. Last but not least, we have Jason from portal. Okay, thank you all for having me.
00:55:17.896 - 00:55:56.512, Speaker A: So I want to start by shouting out thank you to Justin Drake for starting this line of research. Also, we're no longer portal, we're puffer. So I'm going to talk about stake pools and keep this very high level. So first of all, our claim is that current staking trends are posing an existential risk to Ethereum. And so I'm going to try and quickly answer four questions, sort of how we got here, why this is concerning and what are the next steps. So in a stake pool, as it accrues capital, sort of the opportunities to extract mev will keep increasing, which will result in attracting more capital and growing the stake pool. It's a very centralizing force.
00:55:56.512 - 00:56:41.680, Speaker A: So currently the top staking operation is consuming about 30% of a validator set. So this can lead to block reorgs, censorship, harming user autonomy, and ultimately a more fragile ethereum. So puffer, we're trying to build a stake pool ecosystem built on a foundation called Secure signer. So this is a remote signing tool that leverages trusted hardware to prevent equivocation, so to prevent slashable offenses. And this allows you to build sort of interesting stake pool designs. So first of all, it's permissionless participation via remote attestation. So we don't need to use governance to onboard new node operators.
00:56:41.680 - 00:57:35.412, Speaker A: We can lower the capital requirements to just one e because we don't have to worry about this extra collateral for slashable offenses. And we can expose liquid staking derivatives to solo validators as well to help incentivize participation and keep the validator set decentralized. And finally, because we're leveraging this trusted hardware, we're actually able to start enforcing MEV constraints within the signing tool. So this is taken from MeV Boost website and secure signer fits right in here alongside existing consensus clients. And if you're familiar with web three signer, we're kind of following the same spec system. The difference here is we can start whitelisting certain relays within secure signer to only allow blocks coming from them. So here is what a generic framework would look like, and I want to focus on.
00:57:35.412 - 00:58:47.192, Speaker A: So here we have a single validator key is assigned to the 32 e block, and this could be sort of partitioned amongst multiple validators, so like using distributed validator technology. And then we have the node operator collateral has to have at least one Eth, and then the remaining Eth would come from both the node operator and the seekers. And so we introduced this parameter, called the burst threshold, as a way to limit the amount of capital that a single pool can accrue to sort of enforce decentralization. And we introduce a smoothing factor that allows the MEV rewards to be either fully distributed amongst the rest of the validators in the pool or sort of kept themselves. And finally, the relay set is going to be a unique set per pool, ideally consisting of differing sort of MEV strategies and ethical considerations. And so where we're trying to go with this, so we're sort of going to parameterize it very arbitrarily here. But the idea is that there's a rich design space where we can tune these parameters to sort of get different outcomes.
00:58:47.192 - 00:59:24.450, Speaker A: So in this example, the relay set may include multiple different me strategies. And in the future we're trying to decentralize each of these validator instances amongst multiple secure signer instances. And here we chose a burst threshold of around 8% of the total eth pool, but can be sort of arbitrarily changed. And that's. Thanks everyone. That's it for.

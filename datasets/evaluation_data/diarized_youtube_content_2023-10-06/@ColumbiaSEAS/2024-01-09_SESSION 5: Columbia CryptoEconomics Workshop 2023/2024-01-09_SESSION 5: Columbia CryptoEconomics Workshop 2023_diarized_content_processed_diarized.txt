00:00:05.040 - 00:00:05.590, Speaker A: You.
00:00:07.880 - 00:00:25.460, Speaker B: Hi, everyone. We're going to get started with the last session of the day. Congrats for making it through. We have four exciting presentations. The first one is Christine from Galaxy. She's going to talk about the impact of l two fees on l one revenues.
00:00:26.600 - 00:01:07.636, Speaker C: Thank you. Hi, everyone. Yes, my name is Christine and I am working doing some research on this topic. The impact of l two fees on l one revenue. And in this very short talk, I'm going to be giving out just some thoughts, some theses, some questions I'm working on, and some data I'm trying to find. So really, more than anything, this presentation is like a sounding board, like throwing ideas out there and would love to get people's feedback from the audience and generally your help if you're a data whiz. So quick disclaimer before I start this presentation, nothing I say is for investment financial purposes.
00:01:07.636 - 00:01:50.870, Speaker C: It's just information. This is what I have to do because I am a galaxy employee. But anyways, so look at this chart. This chart shows kind of an interesting trend that more revenue from Ethereum is coming from l two s over time. Gas is the unit of computation on Ethereum, how we measure computational resources, how we allocate them. And for Ethereum blocks, they're limited. There's only so much gas that can go into a particular block, and more gas per block every single month is being used by l two s.
00:01:50.870 - 00:03:21.730, Speaker C: So this is a really interesting trend that points towards potentially a future where the primary purchasers of block space on Ethereum could be roll ups as opposed to end users. This is another kind of chart that probably many of you in this room have seen before from l two beat showing increasing trend in transaction activity in comparison to Ethereum. And of course, Ethereum is very limited in the maximum amount of transaction activity it can see because of its scalability limitations. But with all these new roll ups kind of launching in the last couple of months and years, and with more user activity slowly starting to migrate to these l two s, we are seeing this trend of increasing activity. So that leads to a lot of thinking of what we could see in the long term. And as I had said, based on those two trends, if we continue to project out long term into the future, five plus years out, what if all of block space, or the majority of block space is purchased by roll up operators instead of end users? And because roll ups have these scalability benefits for Ethereum, they're compressing, they're batching user transactions together. There's new use cases on Ethereum that are unlocked that wasn't possible before.
00:03:21.730 - 00:04:39.844, Speaker C: Consumer focused applications, decentralized public infrastructure, interesting applications around gaming that weren't feasible just directly on Ethereum, but could potentially be unlocked and create a lot more adoption for Ethereum. And in that future, Ethereum's block space becomes far more valuable, because suddenly the kinds of applications that can be powered from Ethereum as a DA layer faces so many more users. Instead of having applications that can really only scale for maybe thousands of users, you have applications that can be used by millions. And that makes Ethereum as a DA layer a lot more valuable, versus Ethereum as a general purpose blockchain that really can't do that much computation and can't function and can't scale that well as the quote unquote world computer, global computer whatnot. So this is a very kind of bullish and long term view of what could potentially happen on Ethereum that many people have talked about. And of course, these kind of bottom diagrams are oversimplifications. There's many different intermediaries that come in the mix between an end user and a roll up and a roll up.
00:04:39.844 - 00:05:33.656, Speaker C: And Ethereum, you obviously have wallets and things like shared settlement layers and stuff, but this is very optimistic. And one of the things that I've been thinking about a lot more is what's going to happen in the immediate term, like in the next couple of months and in the next year. How is the l two fees going to impact l one revenue, basically. And I see a lot of hurdles. I'm sure that many of these have already been discussed, probably at Devconnect or earlier on through this day, as other people have been presenting too, about a lot of the difficulties of building roll up technology. These are three that I kind of put up onto the screen, scalability, decentralization, security, interoperability. Interoperability.
00:05:33.656 - 00:07:11.340, Speaker C: And I would probably throw up. Also the user experience, like when you're moving around assets that are major hurdles for adoption in the short term, that are continuing to be worked on by roll up developers and different roll up projects. And as this is happening in the now, as people are trying to solve these pretty hard technical problems, you also have Ethereum core developers working on upgrades to actually make the cost of roll ups, to use Ethereum as a DA layer, as a data availability layer cheaper. So in the short term, when things like EIP 4844 are activated on Ethereum main net, you're going to see less revenue go to Ethereum, because roll ups in the near term are not the main platform where users are executing their transactions. In the near term, you're going to have a lot of users continue to transact primarily on Ethereum as opposed to l two s because of a lot of the sacrifices that you have to make for usability, for decentralization, for interoperability, the fragmentation of liquidity. So in the short term, what I foresee is actually a reduction in Ethereum's fee revenue because of these hurdles. And because of these hurdles, also being exasperated by the fact that, look, the fees that l two s generate, which in the prior couple of slides we saw, it was like about 16% of the total block gas, it's only going to go down because it's going to get cheaper.
00:07:11.340 - 00:07:52.324, Speaker C: So those are kind of two differing outlooks, long term and short term. Another kind of angle that I've been taking to this question of how l two fees will impact l one revenue is in the near term. We're also seeing a lot of DA competition, like pop up. Celestia launched this year near recently announced it was going to be a DA layer. Ethereum obviously is trying to optimize to become a DA layer a lot better with EIP four eight four. And I think one of the things that could potentially start to happen is a lot of roll ups. Consider these other DA layers as a way to increase their profit margins.
00:07:52.324 - 00:10:10.644, Speaker C: So because even with 4844, Ethereum is not the most highly optimized DA layer, you start to see roll ups. Consider, okay, what if I can have cheaper, if I can more cheaply post and finalize user transactions and post that data to, say Celestia as opposed to Ethereum? And I think that's kind of another trend, another piece of thinking that is being exasperated by different tools, one that I believe is being worked on by Caldera, where they are trying to make that experience switching between DA layers a lot more seamless. But there's trade offs that come with. So basically, to think about one of the most important things around DA competition in the near and the long term future as being the interoperability between roll ups and the composability between applications on those roll ups is being a really key kind of trend and a really key topic to focus on. And one of the things that I'm currently trying to flesh out a little bit more is if there's too many tradeoffs and if the liquidity of assets on different roll ups built on Ethereum becomes too fragmented across different DA layers, then you're going to see more of an incentive for rollups and applications to stay on Ethereum and for Ethereum to continue to dominate as the most valuable DA layer, if it is that there are many trade offs and lots of fragmentation and liquidity, and not a lot of interoperability by switching to different settlement NDA layers. So to the extent that a shared settlement NDA layer is really important for interoperability, you're going to see Ethereum continue to dominate. So that's like a core thesis that's also part of what I'm looking at and as a quick kind of summary for what trends and different topics that I'd like to get into but unfortunately don't have the time to.
00:10:10.644 - 00:11:07.510, Speaker C: So if you want to talk about it, please be sure to come find me after this talk is these are some of the metrics that I had shown earlier on in this presentation, some additional ones that I think will be really interesting to keep watching. And then we didn't really quite get into things like account abstraction, but I think it'll really change the game for who holds eth. What is the value of ETH? Will most people be paying for their transaction on l two s with Eth? Probably not. If a lot of these roll ups have things like account abstraction, native account abstraction, restaking protocols, a lot of what Sriram was talking about of how Eigen layer could be developed over the next several years will change the dynamics of l two to l one fee accrual. So yes, that's the bulk of my talk. Happy to take any questions if people have them. And yeah.
00:11:25.680 - 00:11:27.432, Speaker B: Let'S thank Christine.
00:11:27.576 - 00:11:29.230, Speaker C: Okay, thank you.
00:11:35.280 - 00:11:48.930, Speaker B: The next speaker is Matt from block native. He's going to talk about some tools that his team built together with the ethereum researchers to improve observability and access to mempool data.
00:11:50.980 - 00:12:15.080, Speaker A: Thank you, David, and thank you everyone for being here. It's great to be back. This is my second CCE and great to see a lot of familiar faces out there. I'm going to spend the next 15 minutes or so giving you all some real alpha. I'm going to show some product and capabilities that have never been shown publicly, and you all are going to be the first in the world to have access to them. So I really hope you check it out. We're really focused on this notion of observability.
00:12:15.080 - 00:12:59.060, Speaker A: This is what I'm going to be talking about. I'll go pretty quick. Observability is an existing term in traditional systems like cloud systems. It's the ability to see inside a cloud application as it's working to understand what the hell is going on? And basically it's like what is happening and why it is happening, which takes on all sorts of interesting new meaning in the world that we love, which is ethereum. What is going on inside Ethereum as it's happening now? Everybody in this room is relatively sophisticated. My guess is you have a pretty good mental model of what the inner workings of Ethereum look like. But we were tasked with basically building ether scan for mempool data, right? Just like we make it regular for regular users, we have access to on chain data via block explorers.
00:12:59.060 - 00:13:36.404, Speaker A: Let's make it for regular users to have access to pre chain and ephemeral data layers, which turns out to be a pretty gnarly problem and one that we at block Navin think about for a while. And we're finally ready to do some previews of what we're doing. So if this is a block explorer, the front of the watch, what we're going to talk about is the interworkings and the mechanism. And so this is going to be available right now at Ethernow XYZ. If you open that up right now, you'll see something, but I'll explain it to you. And it's a real time transaction explorer for the public mempool. Let me actually pop out of this presentation and you will be the first ones to see it.
00:13:36.404 - 00:13:57.388, Speaker A: So this is a real live demo, real live browser. Of course it's always interesting to do live demo, but we're going to be looking at the Ethereum public mempool. Now let's see if it's going to load as it should. Oh gosh. Always exciting to do real time live demos. Hold on a second here. Let's just try this again.
00:13:57.388 - 00:14:16.944, Speaker A: Ether. Whoops, not weather ether now. It's always fun. What should be happening here is all the mempool should be streaming in. Let's see, I'm on the wifi. I swear it worked just a second ago. Goddamn, this is super fun.
00:14:16.944 - 00:14:35.592, Speaker A: So basically what should be happening right now is it's working here. So it must be my laptop. So if you can plug your laptop in, that's great. Let's see here. Hold on a second, let me try this. This is the joys of doing a live demo. I think it's going to work now.
00:14:35.592 - 00:14:58.092, Speaker A: Let's see. Okay. Hey, look at that. Brave. Okay, so, browser issues. So what do we have? This is the face of Ethereum, as I like to say. We have 1000 Mempool transactions streaming into the browser, sorted by default by highest gas we can see the incoming transactions as we're watching, so we can select by newest first.
00:14:58.092 - 00:15:26.184, Speaker A: So this allows us to see what transactions are hitting the mempool in real time. On the right, we have some real basic visualizations that basically show the growth in the current block. And then when a new block comes in, the blue is the contents of the block, and the gray are the transactions that came in that were not included. That basically didn't qualify. The idea here is to show, and it's a little bit jumpy. So I'm just going to do newest first here. Sorry.
00:15:26.184 - 00:15:40.700, Speaker A: Do gas price here to show the liveness of the inner workings. Right. And so I'm just going to click on this tether transaction. It was received. It's pretty high gas. We can see the status is pending. I'm not clicking anything.
00:15:40.700 - 00:16:05.780, Speaker A: Both hands above the table. And when a new block is received, there it goes. It flips to confirmed. We can see the details of this transaction and we can see that it's gone from pending to confirmed in this journey. Right. But you'll notice something really important, which is that was basically at the top of the public mem pool. Right? But it is number eleven in the block.
00:16:05.780 - 00:16:29.096, Speaker A: What's going on? Well, if we click on the block itself, this is block number 9260. Look, 5% of that block is private transactions. And you have the action of block builders. This one was built by Rsync. We can see that as well. Basically manipulating order of the block. So we can see over here this little column, the sequence in the block.
00:16:29.096 - 00:17:17.736, Speaker A: And we can see the sequence is not exactly what you might expect to be like, hey, gas price ranked, right? So the first transaction right here is a very high gas price at 350. That was in the public mempool. Oh, here's one that was private. And the private one has a very stunted journey. It's just a journey, which is, it just pops into the chain, right? And so what's basically happening here is we're witnessing the birth of these blocks and watching and observing the manipulation. Now, I'm very lucky that that demo wasn't great at the beginning, but now it's working just fine because you'll notice that this private transaction was created by Jared from subway. Everyone's familiar with Jared from Subway, right? Well, there's this thing which is like, hey, I get it.
00:17:17.736 - 00:17:47.008, Speaker A: It's the whole mempool. It's all of Ethereum, but I need to be able to look at specific parts so you can filter. So, hey, I just click that little guy here. There's some filtering capabilities, and I apply, and you'll notice now it refreshes everything, and we can see just the transactions from Jared. There's a lot more I could show here, but in the interest of times, I'm going to skip along a little bit. But the basic idea is this is a new tool for it's public good. It's made possible by a grant from the Ethereum foundation.
00:17:47.008 - 00:18:33.116, Speaker A: It's aimed at y'all to basically build a better mental model of what's going on and start to use it for research purposes. But if you're a researcher, you'll realize there's a real challenge here, which is these are ephemeral experiences that you want to take out and analyze and get into. And we got you covered. So as part of all of this, we archive all of this data. And this is available right over here on the left with the Mempool data archive. What I'm going to do is flip back to my chrome, flip back to my browser, go back into slideshow mode, and that Mempool data archive contains three plus years of uninterrupted historical public mempool data. It's available now for research and non commercial use.
00:18:33.116 - 00:19:32.310, Speaker A: It's 37 months of data all the way back to November 2019. It contains no fewer than 16 and a half billion transaction detection events, 27 fields per event. And all told, it's about eight terabytes, so please don't try to download it to your browser. But the basic idea is it allows perfect replay of global public mempool conditions, and it's expressly for research purposes. This project actually came out of CCE last year where we were participating, and realized, hey, we have a lot of assets that we think are going to be really critical for informing the Ethereum roadmap. Looking ahead, largely because we see a significant proliferation of these ephemeral data layers, various classes of mempool data structures, various classes of things like private pools ofas and things like that, and we really viewed that it'd be really hard to do great research in this area without great data behind it. So this is why we're contributing all of that.
00:19:32.310 - 00:20:18.464, Speaker A: I could go into this case study, there's a lot of text here, but using the observability properties of this data set, we're able to help one of our partners realize that one of the MeV rebate builders were not giving rebates. And this is one of the big challenges that we see out there today. There's a lot of trust assumptions that get layered on top of the MEV supply chain, you don't realize that the person who you're giving to the OFA also runs a builder with maybe a backwooding bot. And so there's things you assume about who can see what and what they can do with it, and those assumptions aren't great. And so there's this old saying called don't trust verify, and that's what observability is all about. So some of the research that's been published is already out there. We certainly hope that you all dive in and just looking ahead, we think there's all these new tools which we're excited to produce.
00:20:18.464 - 00:20:38.110, Speaker A: Ethernow, XYZ, check out the Mempool data archive. There's all sorts of new research pathways, but more than anything, there's a ton of stuff that we have to do moving forward, and we block native are not going to be able to do it alone. And that's why we're here to help elicit support and engagement and collaboration with members of the ecosystem so we can tackle all these problems. Thank you very much.
00:20:58.570 - 00:21:11.494, Speaker D: Hey Matt, quick question on the mempool data set, are you indexing the first appearance of a transaction and that's that timestamp, or every single time one of your nodes sees the transaction and it's matching timestamp?
00:21:11.622 - 00:21:35.550, Speaker A: Very good question. The data set that we've made available is first detected across our global infrastructure. We have another data set which is even larger, which is all the global detections, but it's actually harder to work with. So if you're a researcher that's looking at sort of geopropagation and interested in how transactions move through the P to P network globally, we do have data sets that might be useful for that, but the data set that's available now is first detection globally.
00:21:35.630 - 00:21:39.682, Speaker D: Okay, awesome, thank you. And could we get access to the other data set?
00:21:39.736 - 00:21:42.802, Speaker A: Yeah, just contact me. You know where to reach me, but absolutely.
00:21:42.936 - 00:21:43.860, Speaker E: Thank you.
00:21:45.770 - 00:21:47.590, Speaker A: Awesome, thanks so much. Cheers.
00:21:52.170 - 00:22:02.090, Speaker B: Next we have Andrea from cowswap. He's going to talk about their new design for minimizing mev, originating from decentralized exchanges.
00:22:05.390 - 00:22:05.802, Speaker E: Yes.
00:22:05.856 - 00:23:08.394, Speaker F: Okay, thank you. Okay, so by now, I think we all know that there are two main problems with the arm design. One is sandwich attacks, which means that traders are exploited, and I don't think I need to discuss what they are. And the second one is arbitrage profit, also called LVR or lever, and which means that arbitrage exploit liquidity providers. And I do want to spend 1 minute explaining what it is, both because it will be relevant for my presentation and the next one, although I'm a bit intimidated because both teams, Yamak and Jesus, worked extensively on this topic, and I'll try to summarize it in one slide. So let's see if simple so the simplest example one can make to illustrate this issue is suppose there is an amm in which you can exchange ETH for USDC, and next to this amm there is also a very large and liquid venue, say binance, where you can also trade ETH for USDC. And the price of ETH is determined on binance.
00:23:08.394 - 00:24:00.266, Speaker F: And at the beginning everything is in equilibrium, meaning that the price of ETH on binance is this p prime, which is also the marginal price on the local amm. When I say marginal, I mean the price you would pay if you were to buy or sell an epsilon amount, very small amount of ETH. So in equilibrium, in the sense that nobody has any reason to buy on binance sell locally or vice versa, then the price on binance changes, it increases to p double prime. And of course someone will rebalance the Amm so that its marginal price becomes also p double prime, so that we are again in equilibrium. But what's the problem? That the rebalancing trade. So the trade that brings the initial state, the initial marginal price from p prime to p double prime, only pays p of x on the slide. So it pays a price that is lower than the price on binance.
00:24:00.266 - 00:25:11.862, Speaker F: So in some sense, the price on binance already increased to p prime, and for reason that has to do with the design of the amm. The AMm is still trading with the first arbitrator at a price that is lower than the correct price and therefore arbitrary, make a profit and liquidity provider lose money. This is LVR. The point of this paper is to take a solution that has been widely studied in the context of traditional finance and in the context of preventing certain issues arising with high frequency trading, namely batching. And first figure out how to apply to the context of decentralized finance, and then show that batching plus a specific AMM design can eliminate both LVR and sandwich attack. And by the way, this I think is a very interesting meta point here, because LVR and sandwich attack constitute probably 80% of MEV. And how many presentations, how many times you heard the word mev today? But mostly the context of the infrastructure, right? So how we change the way we order transaction or encrypt transaction to prevent mev? But it turns out that we can get rid of 80% of it by a different AmM design.
00:25:11.862 - 00:25:53.934, Speaker F: So at the application layer. So more precisely what do we do? First assumption is batching. So there is a mechanism that allows to enforce one price per token per block. Meaning that I have a system that if I have multiple traders trading on the same mm, they will all pay the same price, at least before fee. Okay, the paper, we have fees in the presentation today, I will ignore fees. Now, one way to enforce batching is to do it as an off chain component of the amm, a bit like cowswap, in which case you receive all your transactions as a form of intent and then you settle them peer to peer, if you can. And what is left, you take it as one big transaction.
00:25:53.934 - 00:26:12.902, Speaker F: And this big transaction is put on the amm. And the important assumption is that this amm can only be accessed by the batch, it's exclusive to the batch. Then you can think about, okay, if I know that this amm is accessible only by the batch, how do I design this amm? And we come up with a design that we call function maximizing amm.
00:26:12.966 - 00:26:13.242, Speaker E: Why?
00:26:13.296 - 00:27:01.706, Speaker F: Because this is an amm that with every trade, instead of staying on the same curve, moves up the curve, and why it's related to the batch. I will explain it in a second. Then the main contribution of the paper is to study this function maximizing amm plus batch in a model where there is again a big trading venue, say binance, where the price is determined. There are lots of arbitrage that are competing with each other. There could be noise traders. And to show that essentially competition between arbitrageure guarantees that fam always trades at the binance price, meaning that there cannot be any arbitrage opportunity left on the batch, else another arbitrage will come in and trade. So the only equilibrium is where all arbitrage opportunities are exploited, and therefore means that the FMM trade at the binance price.
00:27:01.706 - 00:27:35.990, Speaker F: This means that liquidity provider are never exploited. So LVR is eliminated and Sedwe's attack are also exploited. This is trivial within the batch, because everybody within the same batch traded the same price. It's also true across price, because anyone who will be trying to maliciously manipulate the price of f amm will be in fact creating an arbitrage opportunity for arbitrage, or that will come in and take it. So in some sense the attacks are prevented by arbitrage, or that will exploit this as an arbitrage opportunity. And finally, we perform an empirical analysis. We look at eleven uniswap v three pool.
00:27:35.990 - 00:28:24.180, Speaker F: And first we measure the return of providing liquidity there of an unconcentrated liquidity provision that we kind of simulate. Okay. And then we look at binance price data for the same token pair, and we use those prices with our theoretical result to simulate what would be the return. So what would have been the return of providing liquidity on this fam had it existed under the assumption that there are no noise traders trading on the F-A-M. So 100% of FM trades come from arbitrage that are rebalancing it to the finance price. And I will show you that list for the time period and the pools that we look at. It looks at f amm without noise traders already outperform uniswap v three.
00:28:24.180 - 00:29:13.518, Speaker F: The numbers are overall kind of small, suggesting that in general, if you have an F-A-M that also receives fees from oyster traders, that should always outperform uniswaptri. Okay, more in details. Actually, I don't have the timer, so someone has to help me. Okay, what is function maximizing amm with product function? So you can think of it as a price taking agent that is always trading for a given price. So to maximize the product of its liquidity reserves. Okay, this gives you a demand function. Okay, this agent, if you tell this guy that the price is p, is going to want to trade this amount as written here, and then you have to ask yourself, okay, now I want to trade with the fam.
00:29:13.518 - 00:30:17.906, Speaker F: Given that this fam has this demand function, what price should I announce in order to trade a given quantity? And this boils down to inverting this function. And then you get this pricing function. Okay, if you are familiar with the math of constant product amm, you will notice that the only difference with the regular constant product amm is the two that is there, okay? Which seems like a small difference, but in fact, it's pretty meaningful because it means that F-A-M moves up the curve every time. So this is graphically how an F-A-M will want to trade. And in particular, in the paper, we have a proof showing that FMM is what we call price clearing price consistent, meaning that the price at which the FMM trades equals the marginal price after the trade. So if I show up and make a trade at a given price, and then the other guys comes after me and makes another epsilon trade, the other guy will pay the same price I paid, and the FM violates python dependence. And because it can be exploited by splitting trades.
00:30:17.906 - 00:30:57.430, Speaker F: In particular, if you can split trades in epsilon amounts, you are back to the same pricing function of a regular constant product, amm. Now, the intuition has to do with the envelope theorem, because the difference between, when you're maximizing staying, if you have an epsilon trade, the difference between staying on the same curve and moving up the curve for vergemold trades is second order. Well, anyway, so more details are in the paper. So the theoretical model. Okay, I don't have a lot of time. Let me just give you a bit, the general framework that we build to study this problem. So we take time to be continuous, and there is a price of the underlying asset that is determined, say, on binance.
00:30:57.430 - 00:31:29.274, Speaker F: Now, at discrete moments. So every mu second a new block is added to the blockchain. And again, we are thinking about batching as an off chain component. So we are going to say, okay, in between blocks, you can submit a trade on the batch, and this trade will be executed when the next block arrives. And you can have a latency parameter gamma, meaning the batch closes just before the arrival of the next block. And the result is that. Yeah, because of competition between arbitrage.
00:31:29.274 - 00:31:55.794, Speaker F: Sorry, this was fast. All trades on fam happens at the binance price. PT. Actually, this is a mistake in my slides. The price at which FAM trades is the price on binance gamma second before the arrival of the block, meaning, which is the last moment in which arbitrageure can actually act upon information that they observe on binance. So, sorry, this wasn't written correctly. So, empirical exercise.
00:31:55.794 - 00:32:43.746, Speaker F: In my remaining 2 minutes, 3 minutes, two. Okay, now we take data from April this year to October this year. Why April? I'll explain in a second. We look at the top units for v three pools by trading volume, but then we exclude stablecoin pairs and also tokens that are not traded on binance. This essentially gives us two sets of token pairs, one that has ETH, BTC, Rad BTC, either traded against each other or against the stablecoin. And then there are like what we call a low volume pools, so other assets against usually ETH. Then we simulate the return of an unconcentrated liquidity position on this units for v three pool.
00:32:43.746 - 00:33:49.926, Speaker F: So essentially we say, okay, suppose that I started the period with some money. In this unconcentrated liquidity position, at the end of every block, we look at how many fees were paid out, and what is the distribution of liquidity in range at the end of the block. And then we impute how much our position would have earned in fees given as a fraction of the total liquidity, and the total fees that are paid. There is some degrees of approximation in this method that I'm happy to discuss later, but we have robustness check that shows that it should be kind of okay. And then we use binance prices and theoretical model to simulate how arbitrageure would have rebalanced an F-A-M had it existed, assuming no noise traders at all, and assuming that the FAM charges the same fee as the corresponding Uniswap v three pool, and then we compare the two. Now, the comparison essentially has two meaning here. First one is simply okay, we have a new AMM design we can check how does it perform relative to uniswap, at least this lower bound to its performance be higher if it also earns revenue for noise traders.
00:33:49.926 - 00:34:32.118, Speaker F: But the second one is more theoretical because FAM doesn't suffer LVR but also does not earn revenues from noise traders, while Unisoft V three suffers from LVR but also earns revenue from noise traders. So comparing the two is also a way to establish whether LVR is greater or smaller than revenues from noise traders on units of V three. So you might be just interesting in the question rlps on units of V three making money or not. And this will be a way to answer this question. Okay, these are the results. These are the most liquid token pairs. Positive means that FMAM does better.
00:34:32.118 - 00:35:23.914, Speaker F: Okay, and this is the result. So if you look carefully, there is one pool that involved USDT that it looks like uniswap does slightly better, but it's very close to zero. For everything else, our design does better. And this is instead the less liquid tokens and things are a little bit more all over the place. In particular, this matic seems to be uniswap outperforms our design, but in general, the numbers are kind of small, meaning that over these six months, the largest difference we find is 0.5%. So it's not gigantic. Okay, I can conclude amms are the centerpiece of decentralized finance, but they have problems.
00:35:23.914 - 00:35:42.580, Speaker F: We show that batching with this novel amendment design solves them, and we have this empirical exercise that quantifies the benefit and looks like significant in our view. Obviously there is a large literature short which many of the presenters have contributed, but I don't have too much time to discuss it and make justice to it, so I will skip it and just thank you.
00:35:43.590 - 00:35:49.460, Speaker B: Thanks Andrea. Any questions?
00:36:02.700 - 00:36:37.780, Speaker D: Thank you very much for the talk. Just to be sure about something, because usually when you provide liquidity on this kind of thing, you should also edge yourself against typically the change of price, even when you are doing with uniswap. So when you do that, you assume that that also I'm edging myself, because normally, yeah, you can edge yourself for this part, which is the rebalancing between the different price on the market, and then you cannot edge against the arbitrary.
00:36:38.920 - 00:36:58.010, Speaker F: The positions are computed without any hedging, but then they are subtracted to each other. So I'm really taking the difference between what I would have earned on this F-A-M minus what I would have earned on uniswap three. So to the extent that hedging is the same for both, which should be in fact, then it doesn't matter.
00:37:02.480 - 00:37:16.016, Speaker D: Because normally if you just look at what you already got on UswAP, you need to hedge. And here, is it true that the FMAM actually does this hedging already by.
00:37:16.038 - 00:37:56.620, Speaker F: Itself, fam still exposes you to risk, so you're not fully hedged, as in I have no risk because you are trading at the correct market price, but you are trading. In fact, in the paper we show that you are implementing as an LP, you are running a passive investment strategy with, in the case of the product, function, half of the value of your asset in one talk and then half in the other. So if the price changes, you trade at the correct price, but then the composition of your portfolio changes. So there is risk. You might want to get rid of it, in which case you can go out and hedge it fully because it's non systematic in this sense. You might want to hedge also the position on fam if you want, but we don't.
00:37:57.760 - 00:38:32.490, Speaker D: Thank you very much. Hi, thanks for the talk. So I was wondering if you have done any sort of empiric exercise with noise traders. Because. With noise traders, yeah, because in a lot of the papers you cited, the prospect of noise trading is a large contribution to the profits from liquidity providers on amms, because you get free noise trades and reverse trades without the price moving. So I'm wondering if you've done any empirical exercises with regards to that.
00:38:33.100 - 00:39:11.670, Speaker F: Yeah, it's an excellent question for the purpose of this paper, which would be like, put a number of what would be the return of providing liquidity to this hypothetical new mm design? We felt that we will have to make an assumption, say, oh, suppose that we have the same amount of noise trader as on Euriswap, or suppose that we have a fraction of one third of it, and any assumption we could think of felt very arbitrary. So we said, you know what, let's just provide this lower bound, which is okay, no noise traders, this is the return. Obviously if you have noise traders, it will be higher, but we don't really know. Yeah, so we prefer to do it conservatively this way.
00:39:14.760 - 00:39:23.400, Speaker B: Did you consider looking at any other models for. So did you consider looking at any other models for LVL, like addressing LVR.
00:39:25.660 - 00:39:26.936, Speaker F: Moving to any other.
00:39:27.038 - 00:39:34.696, Speaker B: Did you consider any other models before kind of writing this paper? I guess just would be interested in understanding. What do you think about the trash.
00:39:34.728 - 00:40:02.388, Speaker F: Bin of stuff we tried and didn't work? Yeah, you could think of doing a regular amm where everything is batched, but then essentially you get into problems that you never converge or it converts very slowly to one equilibrium. So yeah, there are some other design we tried and didn't quite work. We felt that this assumed that the objective function is moving up the curve and okay, let's write it down and solve it.
00:40:02.554 - 00:40:13.848, Speaker B: And if we don't consider just the ones that you tried, but also like others on the market, I guess would be interesting to understand kind of what do you think trade offs are?
00:40:13.934 - 00:40:44.920, Speaker F: So one will hear later that I think is quite related to what we do. Many others just essentially focus on LVR and leaves out sandwich attacks. Because I think traditionally sandwich attack have been studied in the context of how transaction are sent. So private mem pool and creative mempool, so on and so forth. So here there is one additional. So if you want, we bring this into the problem of amm design. For example, auctioning off the right to be the first arbitrary to rebalance the pool takes care of LVR.
00:40:44.920 - 00:40:55.670, Speaker F: Possibly, probably, but not sandwich attacks, because afterward you still have the problem of having different people transacting the same block facing different price.
00:40:56.440 - 00:41:34.124, Speaker B: We'll take one last question. Thanks so much for the talk. Really interesting. I have probably a very basic question, but want to make sure I can bring it to my team, because I find a very interesting result to bring LVR all the way to zero. So I understand that if you can prove that you get the binance price at the last time that anybody has a look before block execution is already created, then you bring LVR all the way to zero. But in this theoretical result, could you remind me exactly the proof of why you can prove why you get exactly the binance price?
00:41:34.262 - 00:42:27.984, Speaker F: Yeah, the point I want to make kind of strongly is that if you have many, many identical arbitrage or competing, you cannot have an arbitrage opportunity left unexploited, because else another arbitrage will want to submit the trade. Now what this means concretely, in a modern way, is very simple, with no gas, perfect information, and everything is nice, and means that the only equilibrium is one where really, the local price equals the binance price. Now, in a more complex environment where you have gas, it could be that there is an epsilon arbitrage profit left that the next arbitrage, or doesn't bother to take because it's sort of too small relative to the gas of a cost. So, in some sense. But the general point, you cannot have an unexploited arbitrage opportunity because anybody can trade on the batch.
00:42:28.112 - 00:42:49.290, Speaker B: Got it. Thanks so much. Thanks, Andrea. Thanks again for the last talk. We have Lud and Karthik from Sorella Labs. They are implementing a design with similar goals to what Andrea just presented, and they're here to tell us about their design and their project.
00:42:55.340 - 00:42:56.992, Speaker D: Hi, everyone, I'm Ludwig.
00:42:57.076 - 00:43:01.260, Speaker E: I'm Karthik. And we'll be talking about internalizing Mev leakage in amms.
00:43:09.280 - 00:43:10.590, Speaker D: You have to click on.
00:43:14.920 - 00:43:50.840, Speaker E: There we go. Okay, so, quick outline of our talk. First, we'll discuss the problem. I know Andrea dug into it in depth, but very quickly, go over the existing auction designs, one of which batch auctions, the other auctioning off the right to the first swap through the pool. And then we're going to talk into how combining both of these auctions results in a globally more optimal auction for all parties, and then actually how to implement this in practice. Yeah, so the LP predicament right now, lps are losing a lot of money. They're not having a good time on chain.
00:43:50.840 - 00:44:21.060, Speaker E: And the reason is LVR very quickly. LVR cost of information, we have price moving continuously on a deeper, more liquid, centralized exchange. On our dexes, price is changing in discrete block times, and there's always going to be the resultant arbitrage opportunity from that discrepancy that can only be executed by sophisticated players who are holding inventory both on and off chain. This has huge consequences to amms in general. One, it's not sustainable to LP if you're negative in expectation.
00:44:21.220 - 00:44:21.930, Speaker F: Two.
00:44:24.140 - 00:45:11.096, Speaker E: Neutral, sophisticated players are participating in a blind auction, whereas vertically integrated searcher builders are participating in a second price open auction. This is a pathway to builder centralization, which is a segue into censorship. Along with the lps, these swappers, so retail flow, are also not having a great time. It's very difficult to have execution quality on decentralized venues that's comparable to limited order books. And this is for a plethora of reasons, namely, MEV users are getting sandwiched left and right. Two, they have to pay high fees, so the actual gas of interacting with a pool is nontrivial, especially v three logic high gas. And also they have to compensate the underlying liquidity providers in some way.
00:45:11.096 - 00:46:23.344, Speaker E: Andrea touched on this earlier where you have this nuance in the fact that in the FMAm with that design, there's still a very small improvement over what's currently being implemented with univ three. And that's because the actual fee on v three in some cases is able to amortize the cost of informed flow over all orders and make lps profitable in expectation. But this is a bad model, right? Because that just means that the retail swappers are overpaying for their execution quality, which is unnecessary. The other thing is that large orders traded through a pool are going to incur a huge slippage cost that is due to the convexity of the underlying bonding function towards a solution. So any lever mitigating solution should be cognizant of the value leakage in the entire system as a whole. Right now, the adversely selected parties are the passive lps. But these sophisticated players competing for this xx arbitrage opportunity are in a competitive marketplace for block space, right? Essentially it's an all or nothing opportunity and the person, the sophisticated player who gets that transaction first is going to take the opportunity.
00:46:23.344 - 00:47:17.436, Speaker E: So all that value is leaking to the proposer, which is completely unnecessary. This is completely a function of bad application design. Additionally, with regards to mev, MEV is purely a matter of non commutivity of orders, right? If I have swap A and B through a pool, and the actual payoff of swap A and then B is different from B and then A. So now there's games that can be played in ordering, which then result in MeV sandwiches, backruns, et cetera. The other problem with regards to making sure execution quality is as good as possible is leveraging the hfts. So hfts have been in the game for a while, decades in traditional finance, and they are offering some of the best execution quality for trades in traditional markets. It's important to understand what their game is, right? They want to be profitable, amortized in expectation.
00:47:17.436 - 00:48:53.162, Speaker E: So that means overall their cost, they are going to price in the profit to become profitable in expectation in their spreads. And one of their major costs right now in these first come, first serve systems that we see in traditional finance is the latency infrastructure, latency R and D. Billions and billions of dollars are being poured year over year into making sure that we save milliseconds in these global radio networks because fiber optics was not fast enough. Right? So if you're able to instead pit these hfts against each other to offer the best execution quality, instead of competing against each other in first come, first serve systems, to be the first to transact on a user order, then we'll have a global frontier that's better for everyone involved. So how exactly do we improve on these systems? Well, we want to combine the batch auction and the x post auction to be the first to touch the pool. So as Andrea was mentioning his talk, the intuition behind why a batch auction solves LVR is that you necessitate that the actual underlying pool liquidity executes at this final price of wherever the entire batch clears at, right? So you can think of the underlying liquidity positions as just the LP's willingness, their intents to offer trades at specific prices. If you ensure that they execute where everyone else executes, then the arbitrager is also executing at the price of the underlying liquidity provider.
00:48:53.162 - 00:49:56.914, Speaker E: And in a competitive equilibrium, this will kind of convert to the true price. And the essential point is that you want limited order functionality because you want these hfts to be onboarded as easily as possible so that the UX is as easy for them to just price the assets, not worry about any v three math or stuff of this nature that is unique to DFI. But as Andre was also mentioning, when you just have the batch auction, lps are only even in expectation. This is assuming perfectly competitive equilibrium. Instead, if you want lps to be positive in expectation, you need to institute some fee. And in doing this now, the profit maximizing arbitrage clearing price for the sophisticated players is only to bring the amm price to within some fee boundary of what true price is, and to make better execution quality for everyone involved. Now you auction off the right to be the first to touch the pool prior to this uniform clearing and have that bid back to the lps that were adversely selected for offering the sell quotes.
00:49:56.914 - 00:50:59.550, Speaker E: So the diagram on the left, this is similar to Jason's paper, the diagram, except now the mispricing is getting reset every block, instead of only to a fee boundary, whenever price deviates within that fee boundary from centralized price. So the analysis there's been a previous narrative that the problems for retail flow and lps are orthogonal problems. This could not be further from the truth. Essentially, lps are more than happy to provide liquidity to retail trades, but they have to price in their informational disadvantage in the fee that is adversely selecting the retail trades that don't need to incur that same fee. So now if you are able to kind of close this economic system and rebid the value back to the adversely selected parties, then you're able to offer better execution quality to retail trades as a result, and also have market makers that can place their limit orders make sure the execution quality is as optimal as possible. And the lps also don't suffer the economic loss of LBR.
00:51:06.050 - 00:52:09.662, Speaker D: So now that we've discussed the theoretical framework, we can move towards a more practical implementation and a mental model for what we're calling lp boost. So, touching upon the desirable properties of the system in terms of a practically implemented one, you want to ensure that it's extremely low friction. That means that users and integrators don't have to bridge their funds, they don't have to move to an alternative app chain, and they don't have to lock up their funds in any form of bridge. You want to ensure full composability with any external application on the base chain. What makes blockchain so exciting is that there's this very free and open world computer that everyone can build upon and compose with. If you remove that, why not just trade on a more centralized venue? Sure, decentralization is a great point, but I think that's a very important component to the equation here. Additionally, you want to ensure that any system that you're building on top of this doesn't add any overhead in terms of computation, especially in terms of swap gas costs.
00:52:09.662 - 00:53:01.780, Speaker D: So you have to ensure that it is better than any of the most efficient current AMM implementations for a given swap. You also have to make sure that the system is trustless. So liquidity providers should never be exposed to any additional smart contract risk and shouldn't have to interface with anything else than the base AmM smart contract. Here it would be uniswap before. For example, the worst case scenario has to be at least equal to or less than the worst case scenario on the vanilla implementation of the amm. All swapper intents additionally have to be verified and enforced on chain, and any off chain component that you might rely on has to be truly decentralized. The consensus that might exist has to be permissionless, and people can opt in to participate in it.
00:53:01.780 - 00:53:55.190, Speaker D: So now, looking at a high level overview of how this could actually work in practice, what we have is somewhat of an extremely zoomed out view of our current implementation. So as Karthik mentioned, you have your users, you have your searchers that are submitting these transactions. But in reality they aren't actually transactions, they're just orders. They're just signed structs, eip seven one two compliant, or 1271 if you want to get fancy with smart contracts. And these are sent off to this network, to this peer to peer network. And this peer to peer network is composed of these execution clients that have a sidecar, and that sidecar integrates and piggybacks off of the Dev p to p ethereum based p to p system without having this external network. So it benefits from the same level of robustness, but also decentralization.
00:53:55.190 - 00:55:09.606, Speaker D: Now, at some point at which we've gossiped the orders and all nodes have sent the orders around, we're able to select the leader, and the leader can now form a proposal. And so that proposal will then be broadcast to the rest of the nodes, and all validators within the system would validate it, and then it would actually be submitted on chain. And so that submission is just a single transaction. So here, looking a tiny bit more in detail in the order propagation consensus, so as Karthik mentioned, you'd have a searcher that's listening to a centralized exchange price, also looking at the on chain prices, realizing that there's some opportunity to extract and sending off their meta transaction which composes their order. You could also imagine a user operating in the same flow, but just sending their regular order and not concerning themselves too much with centralized price. Interestingly, you also have the searcher that could act as a market maker as they see incoming orders within the system and realize that they'd very much be willing to provide liquidity. And so these sidecars, to add more detail, are specifically implemented as sidecars for the ref execution client, and they multiplex the Dev P to P RLPX session.
00:55:09.606 - 00:56:26.670, Speaker D: So you can add any number of capabilities in a very easy way by just using the baseline infrastructure that exists today, which enables far easier UX for integrators and people that want to run validators, because it's very similar requirements in terms of hardware. Oh, sorry, how do I. There we go, that was a bit fast. So, looking more into detail into a pool bundle here, for simplicity, it's a single one, but within our system, it's actually all bundles for all pools within our system into a single transaction for purposes of gas efficiency. So at the first point you have your sextex arbitrage, which is the person that has been selected by paying the most to the actual LP lps, they're bribing that value back instead of bribing it to the builder. They're now paying the LP directly, and then you have all of the market and limit orders that are cleared at that uniform clearing price with a very similar model that was explained before by Andrea. So now taking a look at on chain execution, how this actually works is that transactions are atomic, so you don't have to concern yourself with some external builder party, some additional trust assumption by some centralized actor, because they have no ability to manipulate that underlying transaction.
00:56:26.670 - 00:57:19.122, Speaker D: The worst they can do is delay it. But again, as the state of the pool is locked and the access is gated by that proof of consensus, well, the worst that can happen is you get executed next block, the underlying validity of the orders is maintained and we just have to rely on it eventually being included. So you can submit it to the mempool, and then once it's executed, it goes into the angstrom Hook Singleton, which is the entry point that verifies and recovers the signatures of the validators and checks that the threshold for consensus has been met. And then once consensus has been effectively proven, it goes to the actual pool manager here in this example for Uniswap v. Four, where it is executed. But the interesting thing here is that, as I touched upon, we want to ensure that gas is extremely efficient. Executing all of these orders as individual trades would be computationally inefficient.
00:57:19.122 - 00:57:52.020, Speaker D: You'd have to do the Amm math every time. But if we have this off chain system, why would we bother? We can compress all of the interactions within a single pool into a single swap. So now, any additional swap after the first or second one would only cost about 20 to 30,000 gas, because all you're doing is a transfer and an EC recover on the signature. So extremely low overhead. So that concludes our presentation today. Thank you all for listening, and feel free to ask any questions.
00:58:09.710 - 00:58:42.070, Speaker G: Hey guys, thanks for the thought. It was really nice. So I had two questions, actually. So, first of all, a design goal of yours is to reduce investments in latency minimization. And the question is, how important is price informativeness for users, do you think? And secondly, we see now that it's very clear that passive lps face these adverse direction costs. But what happens if we're in a world where it's not that clear who actually suffers adverse direction, whether it's the debts or the sex? It's not very clear. How would your system work in such a setting?
00:58:42.730 - 00:58:49.702, Speaker E: So the first question is, how much do retail traders want better execution?
00:58:49.846 - 00:59:00.238, Speaker G: How much do retail traders care about prices that are very up to date regarding time. So, do you care about prices on milliseconds or on seconds? Where is the cut off point?
00:59:00.324 - 00:59:43.642, Speaker E: Yeah, great question. I think that the profile of utility for retail swappers is something that isn't studied really at all. What I would say from using our intuition of traditional finance, the optimal range of confirmation is within that two to three second window. Right. And then with regards to the actual price updates, you essentially want to make sure that the underlying liquidity provider isn't overcompensated for the swap of the retail trade to mutualize the informational disadvantage. So with this system in place, with the LPS aptly compensated, now the actual fee of the pool goes way down for retail traders. So it's just better execution quality in that regard.
00:59:43.642 - 00:59:46.074, Speaker E: And the second question was, so we.
00:59:46.112 - 00:59:59.754, Speaker G: Assume now that there's like a set that has perfect liquidity, perfect price discovery and everything, and then it's very clear that you impose adverse selection costs on the LPS in a Dex. But what if this is not very clear, so you don't really know who suffers the adverse selection costs?
00:59:59.802 - 01:00:35.094, Speaker E: Yeah, it's a great question. So there are many ways to address this. I guess one would be adjusting the fee of the amm dynamic fees. But you don't have to this on chain, right. You can have any number of parameters that you have off chain. And then the actual consensus mechanism comes to what, based on these external variables, should be the dynamic fee of the pool at this time, given whatever the prior variables are. That also is an interesting point about a phase transition that I think will occur a few years down the line, where liquidity ends up going on chain.
01:00:35.094 - 01:00:53.602, Speaker E: Right on chain is the venue of price discovery, in which case I think we'll have a similar problem, except decentralized venues will be arbitraged to the decentralized venues as the batches decently kind of aggregate. So now price over here on finance is getting pulled down every 12 seconds to whatever the batch is.
01:00:53.656 - 01:00:54.066, Speaker F: Right.
01:00:54.168 - 01:01:36.122, Speaker D: To add to that, I think we're not only extremely far from that, but the added complexity. This system clearly benefits from amms today. Lagging. We have the hard work that is done by extremely sophisticated market makers on finance, and so they have to figure all of that out, right. Once you enter a realm where price discovery happens on chain, the system is not optimal, so to speak. More practically, this is focused on short tail, high volatility, extremely liquid tokens, stuff that market makers are willing to take inventory on, where there's large occurrences of volatility, longer tail tokens are less of a focus here. And I think an approach would have to be slightly changed.
01:01:36.122 - 01:01:51.970, Speaker D: But market making directly and dynamically updating and having to deal with the incoming toxic flow and figuring out who that might be is a far more complicated problem to do on chain, at least today. Here we know, because the price has been established by that venue.
01:01:52.390 - 01:01:53.300, Speaker C: Thank you.
01:01:56.730 - 01:01:58.854, Speaker B: We thank Luz and Karthik again, and.
01:01:58.892 - 01:02:00.120, Speaker E: They can take more.
01:02:07.950 - 01:02:30.142, Speaker H: All right, let's thank all the speakers from day one one more time. It was a great program today. I thought, okay, there was supposed to be. There we go. Good. So this is another event coming at Columbia next year, so I'll let you read that. As far as the closing remarks, just two things.
01:02:30.142 - 01:02:47.966, Speaker H: One, there's a reception now downstairs, same place where we had lunch that goes till 07:00 p.m. So I'll see you all there. Looking forward to more great conversations tomorrow morning. Very much hope you'll all come back. Remember, you need to get a new wristband tomorrow morning. You need to check in once again with security. So see at the reception.
01:02:47.966 - 01:02:49.520, Speaker H: And then tomorrow at 09:00 a.m.

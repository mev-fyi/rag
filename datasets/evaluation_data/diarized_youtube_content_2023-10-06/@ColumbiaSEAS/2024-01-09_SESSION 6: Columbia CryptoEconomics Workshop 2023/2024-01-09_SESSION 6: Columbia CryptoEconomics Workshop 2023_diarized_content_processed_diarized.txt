00:00:17.330 - 00:00:21.910, Speaker A: All right, good morning, everyone. Welcome to day two of Columbia crypto economics. Day one was awesome.
00:00:21.980 - 00:00:22.614, Speaker B: I thought so.
00:00:22.652 - 00:00:53.582, Speaker A: Very excited to have another one today. Agenda up here today we're going to have sort of thematic sessions. So we'll have sessions on PBS, on mev, gas markets, staking microeconomics, and staking macroeconomics. So five sessions with breaks in between in some quick housekeeping. No food and drinks in the auditorium. For those of you that weren't here yesterday, all the breaks are down on the first floor, exactly the same place you checked in. So including lunch will be there today.
00:00:53.582 - 00:01:20.890, Speaker A: The day ends at 430. There's no reception afterwards, but all the lunch and coffee breaks will be downstairs. And then you can see that the two exits and the restrooms are around the corner back there, for those of you that weren't here yesterday. And then I'm going to pass it off to Mike to run the PBS session. And while we transition, I'll let you read this slide, which is about another blockchain related event happening here at Columbia in May. So, Mike.
00:01:27.450 - 00:01:28.006, Speaker B: Cool.
00:01:28.108 - 00:01:29.960, Speaker C: Hey, everyone. Thanks for coming.
00:01:32.170 - 00:01:34.898, Speaker D: Oops, sorry.
00:01:35.004 - 00:01:36.940, Speaker C: Get a little sneak preview there.
00:01:37.790 - 00:01:38.250, Speaker B: Cool.
00:01:38.320 - 00:01:38.940, Speaker D: Yeah.
00:01:39.630 - 00:01:50.800, Speaker C: Today's session on. The first session is on PBS. We'll have three talks. Each will be 20 with 10 minutes for Q and A. So, yeah, let's start off with welcoming Kubi from Titan. Thank you.
00:01:59.130 - 00:02:55.660, Speaker E: Everyone. I'm Kubi. I'm the co founder at Titan. And Titan is one of the larger block builders on Ethereum. And I'm here today to talk about builders relays and their latency downs. So to start with, why does latency matter so much? Specifically, if we think about the transaction supply chain and the various actors in it, and also given the fact that we have 12 seconds in between the proposals of blocks, which from an HFT perspective is basically an eternity, let's dig into some details. To start with, I want to cover the case of CXDEX Mev, which essentially is something like this.
00:02:55.660 - 00:03:55.550, Speaker E: So on one hand, you have the uniswap price. So the price of a pool, which essentially stays consistent throughout the 12 seconds of the slot. And the reason is because the price is just based on the state of the pool in the previous block, and there's no way to actually change the price until the first transaction in the next block touches that state. On the other side, however, we have the binance price, which is a limited order book on a centralized exchange. And the price, as you can see, just fluctuates and moves all over continuously. And so from a value capture perspective. Essentially, if you want to capture the price difference between these different trading venues, your ev, or the value of the trade at, let's say t minus eight is going to be a lot lower than at t zero.
00:03:55.550 - 00:05:23.734, Speaker E: And that's just because the probability of you being right about the time of, or the price at the execution time is going to be much lower the earlier you are. So you want to sort of push the boundary when it comes to execution times to as close as possible to the proposal of the block, which is at t zero. So from a latency perspective, essentially you want to minimize that latency towards the end of a previous slot, and that essentially maximizes the value you can capture. So then let's look at another use case, which is atomic mev. And this type of MEV is essentially based on state changes that individual transactions trigger. And these transactions get continuously emitted throughout the slots or before the next block gets built. And so from a searcher's perspective, it is essentially each transaction triggering a state change, and then the searcher performing a simulation of this transaction and then performing some sort of graph search which is going to reveal the optimal path for arbitrage execution post the state change of the individual transaction.
00:05:23.734 - 00:06:58.110, Speaker E: And so again, you have these transactions coming in in real time throughout the slot. And the more time you essentially have for your searching, once the transaction gets triggered, the tendency is to lead to a more valuable solution, because you can just explore more paths that you are going through. So it might not be as latency sensitive as the Cx Dex arbitrage. But in general, what we do observe is that bundles that get sent towards the end of the slot, even originating from atomic arbitrage stretches, tend to be more valuable than the bundles that at the beginning of the slot. And that's just because you have more time to search for more optimal solutions. And so if we look at all of this from the perspective of a block builder, again, you have these transactions that are coming in in real time. From a value perspective, it looks more something like this, because even if the individual transaction does not carry mev, so we call this a vanilla transaction, they tend to have some sort of priority fee associated with a transaction, which just means that the more transactions get propagated or emitted during the time of the slot, the more the builder is essentially stacking up this priority v value, which then gets aggregated and counts towards the total block value.
00:06:58.110 - 00:08:28.220, Speaker E: But then also there are these searcher bundles, and from the perspective of a builder, like I just covered, the bundles that are emitted during the beginning of the slot, again start to increase in value towards the end of the slot. And this is both from the perspective of cx tech searcher bundles, but also from the perspective of mev bundles. And these bundles don't always get replaced, which means you also start stacking up value towards the end of the block from an individual bundle perspective. But then the individual bundles that get emitted later in the block also carry more value. So if you put all of this together, it essentially looks something like this, where the builder is essentially incentivized to wait as long as possible, because searches are going to wait as long as possible. And so the latency at the end of the slot becomes very, very crucial. And the takeaway really is that originally we're looking at the transaction supply chain like this, but the more realistic view is actually something like this, where you have users and searches originating value throughout the slots, but builders and then the actors post the builder, which is the relay and the proposer, you want to compress the time that it takes to essentially traverse through those infrastructure pipes.
00:08:28.220 - 00:09:34.748, Speaker E: Again, the takeaway here really is like minimum latency equals maximum value in terms of MEV. So then let's look at these MEV actors from an incentives perspective. And I'm going to limit this to the actors excluding the users. So if we essentially plot this on a graph where you have on the y axis the MeV capabilities and on the x axis the incentives, and here I use these terms somewhat loosely. If we look at the proposer, the proposer is maximally incentivized because the proposer currently gets the most amount of MEV. And that's just because of the nature of the auction, where like the MEV auction that the searchers participate in, most of the value is bid downstream to the builder. But then again, the builders participate in an auction at the relay level, and most of the value gets bid downstream there.
00:09:34.748 - 00:10:36.348, Speaker E: And hence the proposers capture most of the value. But then from an MEV capabilities perspective, by design PBS designed in such a way that the proposal is not very sophisticated and resourced. And so you have these actor that has incentivized a lot from a value perspective, but from a capabilities perspective is not very sophisticated. Then you have the relay that from an MEV capabilities perspective. And when I say MEV capability perspective, I'm going to limit it to not searching itself, but I'm going to limit it to understanding the market structure and also being capable when it comes to latency optimizations is somewhat in the middle here, but from an incentive perspective, there's literally no incentive because relays make zero revenue today. And then on the other part, you have builders and searchers. And I don't want to say that builders are more sophisticated than searchers.
00:10:36.348 - 00:11:46.662, Speaker E: I'm just trying to put them all together in one spot roughly here. But from an incentive perspective, there is significant incentive for builders to be sophisticated and capture mev. And from an MEV capabilities perspective, they're also the most sophisticated players in the supply chain. And the takeaway really is that along the supply chain, on all the different actors, currently, the incentives for release are zero. And this has some implications. And so again, looking at the supply chain and the compression towards the end of the supply chain, and taking into account the incentives, but also their capabilities, from an MEV perspective, you have these players, builders, relays and proposers, where proposers are not very capable. From an MEV standpoint, builders that are very capable, proposers that are very incentivized, builders that are also incentivized, but relays in the middle here that are not incentivized at all.
00:11:46.662 - 00:12:59.390, Speaker E: And so this all tends to trend towards the emergence of the builder relay. And that's also just because in the supply chain itself, there's this close proximity between builders and relays. And then secondly, from the capability perspective, they are just the best actor in the supply chain to also handle that infrastructure piece. So people will make an argument for this being a bad thing, and there's a good case to be made for this, and simply because it is bad for the competitiveness of the market structure. And there are several reasons. First reason being that also running a relay and being a builder massively increases the barrier to entry. Because running a relay not just only requires technical resources in terms of development, and it requires business development and relationship building capabilities, and it also requires being able to carry the ongoing costs of operating the infrastructure to run a relay.
00:12:59.390 - 00:14:04.966, Speaker E: And then so it massively increases the barrier to entry for new incumbents, but also for existing incumbents. Given how critical it is to minimize latency towards the end of the slot because it maximize value, nonintegrated builders will be at a significant disadvantage. And the other point I would like to make here is that it is also somewhat like pulling or pushing the nuclear button, because the first builder relay that emerges, specifically if it's one of the larger block builders, will naturally force the other block builders are also very capable to launch a relay. And that then will destroy the competitiveness of the market, so to speak. So it's sort of like the three larger block builders are all looking at it. No one wants to pull the trigger, because there are several implications. So what could be a possible solution? And there are several other solutions.
00:14:04.966 - 00:15:08.970, Speaker E: But I'm just going to talk about a solution that is most related to latency. It is essentially being able to build and operate a relay that is non integrated. And by that I mean it is just neutral and accepts blocks from every builder and without any preferential treatment. But also it is very important that this relay is actually really low latency and highly competitive. And what this does is essentially it commoditize the edge that a vertically integrated builder relay has, and very much disincentivizes existing builders to launch it relay. And so there's still a case to be made for some latency improvement by being vertically integrated. But if you push this to the boundary, if builders colocate to relays, which they already do, the additional latency is probably around 100 microseconds versus being in the same binary.
00:15:08.970 - 00:17:06.290, Speaker E: And so just given the overall tick to trade of the entire mev pipeline, 100 microseconds, given also the variance in network latency, and all of these things, is insignificant. And so should very much disincentivize the efforts required for existing builders to then vertically integrate. And from our perspective, this is one of the most realistic short term solutions. There are lots of other solutions that have been proposed and are being experimented with, but this is the most realistic one. So then some of the open questions around this are basically who is going to have the responsibility of developing such a relay, and also to operate this relay in the long term, specifically, given the incentive structures that exist today. So we have the existing actors like relays that are somewhat sophisticated from an mev capabilities perspective, but they make no revenue and there are no financial resources that actually allow to run such a business, or run it as a business in the first place, then secondly, you have builders, and builders are very capable, as I talked about before. But then if a builder was to actually launch a relay, why not make it a vertically integrated relay? Because if a builder is going to basically channel some of their resources into a public good, so to speak, why not run a vertically integrated relay? And there are some arguments to be made around social consensus and also thinking about long iterative games and what kind of impact, like significant market structure changes have for the outlook of a builder.
00:17:06.290 - 00:18:40.670, Speaker E: But these are open questions. And then what about the proposal? So the proposer in the supply chain is the actor that makes the most amount of revenue from all these shenanigans and how does the proposer fit into this situation? And then also there are searches. Searches now are more disconnected from the relay, but having seen the different use cases and why it impacts the bottom line of the searcher themselves, is there a case to be made that a searcher could somehow contribute to this as well? So maybe there's a way to form some sort of alignment between these different actors and develop such a relay, operate it and maintain it for the long term? Or is all of this okay, actually. So part of the PBS design is that we want to operate centralized infrastructure within the bound of a decentralized network. So as long as there's decentralized oversight, let's leverage the capabilities and the efficiencies that centralized infrastructure brings. So is this maybe all. Okay, all of these are open questions and we have no answers, all of this to say till there are some major market structure changes that are on the horizon and we don't know how exactly it's going to play out, but until then, relays and builders are going to continue their dance.
00:18:40.670 - 00:18:43.840, Speaker E: Thank you.
00:18:44.450 - 00:18:45.200, Speaker D: Thank.
00:18:55.850 - 00:18:56.902, Speaker B: Howdy. Hello.
00:18:56.956 - 00:18:57.560, Speaker E: Hello.
00:18:58.190 - 00:19:43.880, Speaker F: Okay, great job, Kubi. I guess my first question is, I've got a couple of questions, but the first one would be pretty, just like high level PBS is maybe like one way of avoiding sort of like conflicts of interest and maybe validators essentially stealing or taking all the med for themselves. Right. Number one is how do you think, when you think about PBS, is that the best design that you can think of? Are there other designs that you've thought about a little bit more? And I have a follow up question to that.
00:19:47.310 - 00:20:22.594, Speaker E: I don't have a better solution. It seems to be the most realistic solutions. I think the implementation detail is really what matters. And the market structure is still really early. And so I think this is not the final design. Still, I think conceptually it makes the most amount of sense based on what I've seen and based on the values that the Ethereum community has. But, yeah, I think the implementation details matter, and there are a lot of.
00:20:22.632 - 00:21:06.290, Speaker F: Question marks in the details based on your interactions with validators today. Like professional validators today, the big ones, not like maybe home stakers or curious whether you think that they are currently, if PBS didn't exist and validators were just doing vanilla blocks, do you think that these institutional validators and larger validators would actually have the capacity, have the capabilities, have the teams to extract the most value? Or do you think they would just kind of do vanilla blocks? And ultimately they led to using mev boost as a result of the fact that it exists.
00:21:08.390 - 00:21:38.540, Speaker E: So I think we've seen some behavior on other l ones that don't have a structured market like on Ethereum. And it tends to be that the node operators themselves don't extract the MEV directly, but they form partnerships with trading firms and so they just become private deals where you have an exclusive partnership with a trading firm and they extract MeV on their behalf in their blocks and then some sort of revenue share.
00:21:39.390 - 00:21:41.840, Speaker F: How is that any different than what exists today?
00:21:43.810 - 00:21:51.440, Speaker E: It makes it inaccessible to the everyday staker. That's the main difference.
00:21:54.550 - 00:22:50.420, Speaker G: Hey there, I have a question about for practical purposes, we have like a small training bot and it works on Polygon, which doesn't have builders, but we want to have it working on Ethereum. I'm wondering for when you interact with builders, is there some way to make a programmatic request that guarantees that you will land in the nth block or the n plus one block? Like if you identify the transaction, what I mean by this, if you identify the transaction when the block is currently in, you want to send it at that block or the subsequent one, but not the ones later. And if so, is there any documentation on the cost? First of all, is it possible to guarantee that? Second of all, is there any documentation on costs and how to do a financial model for that?
00:22:51.510 - 00:23:51.030, Speaker E: Yeah, so this is a hard problem, because what guarantees the inclusion of a block is currently maximum value, and that is always relative to what other builders are doing. So if builder a wants to do pre confirmations, so to speak, and they confirm or commit to a specific transaction based on the value at that point in time, but then let's say a few milliseconds later, there's a lot more value to be captured by not including your transaction by someone else, then what the builder will have to do is to subsidize the difference of that value in order to guarantee your inclusion. And then there's a question of how much value is there to be expected over a long period of time. By providing such a service and additional value unlock or revenue versus the net loss a builder would take on some of these blocks.
00:23:52.010 - 00:24:32.290, Speaker G: I'm just wondering if, based on your knowledge of how the current, just like trends in the industry, are builders on Ethereum already, how do I say it? In a relationship with searchers, to the point where they can say some searchers get a priority because we've known them for a while, and then if you just approach the builder from their contact email address on their website, my interpretation is that I need to know how many strong relationships they've had in order to realize whether or not it's possible to get higher up in that priority.
00:24:32.950 - 00:25:23.474, Speaker E: Yeah. So the priority that exists, at least to our knowledge, is usually just around priority queues when it comes to your bundle flow. And so that is more an anti spam protection than actual sort of deals that are based on. Okay, I like you, I know you, I trust you, and so I'll prioritize your bundles because overall, the incentive for the builder is still to build a more valuable block. And the builder doesn't care if the builder knows a specific search or not. All the builder cares about is the value in the bundle. And so the priority queues are generally just a reputation system more than a private handshake deal, because just based on the structure of the auction, it doesn't make sense to prioritize someone if there's not more value.
00:25:23.672 - 00:25:24.082, Speaker B: Okay.
00:25:24.136 - 00:25:39.990, Speaker G: And then as a final thing on polygon, even if you send a very high gas price, it's unlikely that you will get the n plus one block. I'm just wondering if can you confirm or deny that's the case on Ethereum or binance smart chain?
00:25:41.470 - 00:25:56.990, Speaker E: I don't know about BSE, but on ethereum it's relative to how much value you are paying to get included into the block, as well as how much value you are displacing by being included in the block.
00:25:57.410 - 00:25:58.800, Speaker G: Okay, thank you.
00:26:02.290 - 00:26:31.690, Speaker C: I guess my question is, you mentioned the emergence of the relay or builder. Do you think that PBS could centralize in the other way from the proposer relay? Just given how we've seen the LSD landscape collapse very quickly on just a couple top options, I guess. Do you think that's like a likely incentive alignment between the proposer and the relay to make builders compete for more valuable blocks rather than builders capture relays to ensure their blocks get relayed?
00:26:33.310 - 00:27:17.510, Speaker E: It is possible. I think it only works if the entity. So the proposer that builds such a relay has enough reputation that builders will trust that relay to not steal their MEV. Because that's the whole point of having the interface of the relay between proposers. And the other point would be, would the proposers or the node operator who's running that specific entity, do they have enough capabilities to build a relay that is performant enough or more performance such that it makes sense to source blocks directly versus sourcing it from like a third party relay?
00:27:20.590 - 00:27:20.954, Speaker B: Thanks.
00:27:20.992 - 00:27:39.550, Speaker C: One more round. Great. Yeah. Next we're joined by Max. He is the head of research at the special mechanisms group, and he'll be talking about structural advantages of integrated builders. So let's welcome Max.
00:27:47.910 - 00:28:53.190, Speaker D: So I guess it's just a coincidence that we both have talks on latency in PBS and the one who runs a builder put his transaction at the top of the block here. But I think it was actually a good introduction because I'm going to talk about some similar things, but dive into a little bit more of the nitty gritty details about why integrated builders exist. And here I'm talking about integrated builders, as in builders who are integrated with searchers, specifically sextex searchers, whereas I think Kubi was talking more about integrated builder relays. So this is slightly different notion of integrated, although I suspect eventually they will be the same thing. There will be integrated builder relay searchers. Yeah. So that was kind of the motivation we had when we started looking at this problem, which was why does it look like the integrated builders have a big advantage in sextex when the firms themselves are not necessarily ones that we would expect to be the most dominant in trading.
00:28:53.190 - 00:29:49.462, Speaker D: For example, we might expect a firm like jump, who dominates the centralized exchange trades, to do very well on chain, and they did, but they didn't have nearly the profit margins as the large shops that are associated with the large builders. So that was kind of the starting point here. So I'm going to give a quick introduction since Kubi already did most of it. For me, about web boost, which is that today about 95% of Ethereum blocks are built using web boost. Basically it's an open english auction, which is going to be important later in the talk. It happens every 12 seconds, except when the validator isn't subscribed to the relays. And the other part of it is the builders themselves are running their own auction before they submit the build to the PBS auction.
00:29:49.462 - 00:30:31.110, Speaker D: So they're building a block and they're combining some of their own transactions with public memphis transactions and also their private bundle flow. And I would call that process of aggregating the private bundle flow into a block, also an auction. It's a knapsack auction. And that auction right now is a first price sealed bid auction. So that's going to be important later. Here's a look at the biding process in action for a particular block. I chose a block that had a huge movement in the price of Ethereum on finance within the twelve second period where this auction took place.
00:30:31.110 - 00:31:17.558, Speaker D: And you can see that was associated with a very high bid in the auction here. The highest bid was almost 28 e. The reason, of course, is when you win the block and there's a huge arbitrage available, you get to put your own transactions first, or you get to sell that right to another searcher who submits to you in the bundle merge. So when PBS first started, it was mostly dominated by neutral builders who you can see in black up here. But quickly, on some timescales, I think a year in crypto is like an eternity anywhere else. But I think a year in academia is more like a month in crypto. Anyway.
00:31:17.558 - 00:32:24.170, Speaker D: So in a year, we moved from the picture on the left to the picture on the right, where we have basically domination by these integrated builder searchers. Why did that happen? That's the question in this talk. So let me give an explanation, which relies on some basic auction theory, which is that those two auctions, one of them, which is the bundle merge auction, and one of them, which is the PBS auction, are different, and we have parties competing in them, and parties want to compete in the english clock auction and not in the bundle merge, which is the first price. So in an english clock auction, this is kind of a stylized version of it. You have a bunch of bidders. They all put their hand on a button, and then the clock raises the price of the item, and then bidders take their hands off when they're no longer willing to pay for the item at that price. And when only one bidder has their hand left, that bidder wins at the price on the clock.
00:32:24.170 - 00:32:57.274, Speaker D: So that's the ascending english clock, the opposite clock, which is the dutch clock, where the price goes down. You have the bidders, they're waiting to press the button until they see a price on the clock that they want to buy it at. Now, let's compare that to those two auctions I just showed. You are dynamic, meaning they take place over time. Here's two static auctions. The first price, sealed bid auction. This is similar to what you see in the bundle merge, which is bidders submit sealed bids.
00:32:57.274 - 00:33:44.818, Speaker D: The highest bidder wins and they pay their bid. And in the second price, sealed bid, bidders submit sealed bids. The highest bid wins again, but instead of paying the highest, they pay the second highest. And most people have seen this in, like, econ intermediate micro or something like that. But this is important because the PBS auction is english clock. The bundle merge is this knapsack, first price. But we know that the second price, sealed bid auction and the english auction have some same equilibrium properties, meaning the time when you take your hand off the button in the english clock stylized auction that I showed is the same as what you would bid in the second price.
00:33:44.818 - 00:34:47.042, Speaker D: And similarly, the time when you press the button in the dutch clock, when that price at which you would press the button in the dutch clock is the same as you would in the first price under kind of idealized conditions. And so that means these two auctions belong to a different class. But in some ways, we have multiple agents, some competing in the first price auction, some competing in the PBS auction for the same thing, which is that top of block ability to capture the arbitrage. What do I mean by that? The integrated builders can bid their true value in their own bundle, merge, and then take profit later in the PBS auction. A non integrated searcher, for example, one that submits to Titan, has to choose how much profit to give to Kubi before the end of the PBS auction. So before they observe what other people are bidding in the english part. And that is a disadvantage.
00:34:47.042 - 00:35:21.086, Speaker D: And so that's what we model. Basically, we have Na integrated and NB independent searchers. And the independent searchers have to submit to an independent builder. So they're going to compete in a first price auction. The integrated builders can bid their true value in the bundle merge and then go onto this english clock, which we're going to model as a second price auction. So what we have is basically two types of builders. And they both get independent draws.
00:35:21.086 - 00:35:55.754, Speaker D: So we don't even have common values here, which is, I'm going to get to common values later. But in this model, basically everybody has private values. And there's still a problem. The key insight of this model is it's going to be like an ordinary sealed bid auction, except you have two types of bidders, and one of them pays their bid if they win. The independent winners pay their own bid if they win. Whereas the integrated winners will pay the next highest bid, whether it's from another integrated builder or from the independent winner. They will pay the second highest if they're integrated.
00:35:55.754 - 00:36:42.940, Speaker D: And the first price will be for the independent guys. So it turns out what's kind of quick to realize is that if you're competing in a second price structure, then you can bid your true value. So that's what this slide is saying. Basically, the integrated builders can bid their true value. And then because they bid their true value, the non integrated builders can look at the integrated builders, aggregate them all up. Look at the nth order statistic, the highest bid from the integrated guys as a kind of random reserve price. So they just take that as a given and then we're going to try to.
00:36:42.940 - 00:37:15.910, Speaker D: I'm going to skip this proof, I think. But basically, we're going to try to solve for how much shading should I do. When I submit my independent searcher bundle to Kubi? So that shading is going to be a strategy profile. Which is going to map how much I value the item to how much I bid. That's what this function sigma here is, is the strategy profile. It dictates how much I'm going to bid in the bundle. Merge as an independent builder.
00:37:15.910 - 00:37:42.394, Speaker D: So any auction theorists in the audience. Will recognize that this is very familiar, actually, the terms with a b in them. If you removed all the terms with an a. Which are for the integrated builders. This would look exactly like the equilibrium of the first price auction. Which is good, because if n sub a, the number of integrated builders is zero. Then you would expect those terms to be one, and they would just disappear.
00:37:42.394 - 00:38:08.098, Speaker D: So this is an extension of the kind of first price auction framework. With independent private values. And we solve. And we get this equilibrium. Here's a kind of example. We have three integrated and three non integrated builders. And we have various distributions of private values.
00:38:08.098 - 00:38:24.702, Speaker D: On the left side. On the right side. Those are just kind of putting into a numerical program. And solving for what those strategies look like. You can see on the right. And you can see the line, y equals x. That's the truthful line.
00:38:24.702 - 00:38:54.902, Speaker D: So these guys are below the truthful line everywhere. So that's the shading that we're talking about. So let's put some specific distributions here. And see what this disadvantage looks like in practice with these distributions. So we'll assume there's one independent searcher. We'll keep the number of integrated builders as a parameter for now. And we'll say that the integrated and the non integrated guy.
00:38:54.902 - 00:39:17.876, Speaker D: Have uniform distributions of their private values. And when we solve this, we get sigma v equals the number of integrated builders. Over the number of integrated builders. Plus one times v. That's how much we shade here. So, now that we know how much to shade. We can do the surplus analysis.
00:39:17.876 - 00:39:35.470, Speaker D: So we can look at how much these guys are actually getting in this game. The surplus as a non integrated searcher. In this game. With one non integrated searcher. Is up top. And if they were integrated, it's on the bottom. So, if you look down there in that takeaway box.
00:39:35.470 - 00:40:29.544, Speaker D: The important thing here is you're losing a fraction of your surplus. And that fraction is directly related to the number of integrated builders. So what does that mean? Currently, we have about three integrated builders, maybe two and a half, but let's go with three for now. So in this uniform example, if we just evaluate that coefficient, it's zero point 42. So they're losing almost 60% of their surplus. So even if they're way better at sextex arbitrage, they have way better price signals, they have better trading, they have better fees on finance, whatever, they still might not be competitive with the shops that run Beaver and R sync because of this first 2nd price thing. So here's another model that I wanted to get into quickly.
00:40:29.544 - 00:41:34.550, Speaker D: And actually this was first suggested by Julian at SBC this year, which is now we're going to look at common values. And before we had private values, now we're going to see some adverse selection from common values, basically similar to what Kubi had, which was, by the way, a terrific graphic with the binance price and the uniswap price, everybody is looking at the price, moving on binance over time. Some bidders are. One bidder is fast, one bidder is slow, the fast bidder is delta seconds after the slow bidder. So what happens basically at the red line, the slow bidder bids, at the green line, the fast bidder bids. So there's two cases, right? The price can either go up after the slow bidder bids, in which case the fast bidder will outbid them and win, or the price can fall after the slow bidder bids, in which case the fast bidder will be like, okay, you can have it. So this is winner's curse, basically, when you win, the price is moved against you.
00:41:34.550 - 00:42:13.440, Speaker D: And we actually show in a theorem in the paper that this model with deterministic latency leads to complete unraveling. So the slow bidder just doesn't bid at all. The fast bidder always wins, and they don't have to pay anything because there's no slow bidder at all. They're just the only bidder in the auction. So, one way to kind of address this is through a candlestick. So because the model completely unraveled, you might want to get a model that doesn't completely unravel. So you can make kind of latency random, you can make random response times.
00:42:13.440 - 00:43:11.830, Speaker D: But a natural way to go is this MeV geth candlestick, which is the end time of the auction, is slightly random. And so you don't know as the slow bidder that you're going to, 100% of the time, have a chance to be outbid. It's only part of the time. And if you look at kind of visualizations of when this is called, it's actually pretty much a normal distribution centered around whatever time the client wants to call. And the MeV client itself can also call the block at a different time. So if you don't know whether the client is playing timing games or not, they might also be calling at a random time for that reason. And the timing games are basically calling later in the slot so that you have more time to wait for Mev to come out.
00:43:11.830 - 00:44:10.308, Speaker D: So that's all I had. But the kind of takeaway is integrated builders and searchers together have a massive advantage, and it's through these latency games. But it's a little more complicated than just saying we have 100 extra milliseconds to wait for the price to move. We have 100 milliseconds to wait for the price to move so we can outbid other people when the price moves towards them and not outbid them when the price moves against them. And so if I have one takeaway from this talk for the audience, it's basically latency games are not about being fast, they're about being faster than other people. And if you think, well, we have twelve second block time, so latency games shouldn't matter. Well, no, because all of the activity actually ends up happening in the last 100 milliseconds, and then it will happen in the next 50 milliseconds in 2025, and it will happen in the last ten milliseconds in 2027.
00:44:10.308 - 00:44:15.720, Speaker D: So timing games and latency games are all about relative advantage.
00:44:46.890 - 00:44:59.260, Speaker C: Hey Max, thanks so much for the talk. I'm curious to hear what you find to be most appealing solutions to this relative latency advantage, or at least how you think of approaching it.
00:45:00.270 - 00:45:47.618, Speaker D: I think one thing that would be nice if you go back to all the way to this slide. Here we go. They're playing in a different game, right? One of them is playing first price, one of them playing second price. So what if the builders just made their bundle, the neutral builders just made their bundle merge second price instead of first price? That could work. That's not credible, though. One thing they could do is try to make their bundle merge more like an english auction, which could be credible. So I've advocated, I think, for builders to move towards giving more information about the status of the auction, the bundle merge auction, as it progresses.
00:45:47.618 - 00:46:14.290, Speaker D: And that would just look like right now, you submit your bundle, you get no feedback about what happens. You have no idea what's in the builder's bid when they bid, because it's just a hash. So if you just gave them like, hey, your bid got in versus your bid didn't get in to the bid that we just submitted to the relay, that could actually make a big difference for the neutral builders and the neutral searchers.
00:46:21.240 - 00:46:41.640, Speaker H: Yeah, it's an interesting approach. You have a bunch of assumptions. So I just ask you about robustness. So you're assuming that the fast guys know how slow, exactly when the slow guys would come in. Is there any information? There's information reported. I'm just asking. You can solve out different assumptions.
00:46:41.640 - 00:46:57.048, Speaker H: Some of them would have mixed strategy equilibrium too. Right. Because there's these auctions in the petroleum industry, Bob Wilson with asymmetric information that the outcome is extremely insensitive to the exact set of assumptions.
00:46:57.224 - 00:47:15.750, Speaker D: Right. I think if you start, so there's a number of models that you could do here. One of them is I bid, and then you have a chance to outbid me. And then I have a chance to get a chance to outbid you, basically. So you can make that chain. You're going to get a similar winner's curse. It's not going to unravel all the way.
00:47:15.750 - 00:47:49.324, Speaker D: So the slow bidders will still bid. They'll just shade their bid because of winner's curse and then have less surplus. Right. I think it's pretty robust to. I took a pretty simple model here because I think it's very stark, the results. But if you start to introduce the candlestick, as I mentioned, you'll get a similar thing. You won't get the same level of unraveling, which is total unraveling, but you'll get some winners curse, and that will affect shaking.
00:47:49.452 - 00:48:09.892, Speaker H: Be more concrete. Let's suppose the slow bidder. Maybe this is not feasible. I'm more an economist than a computer guy. Okay. But let's say the slow bidder can sort of wait to get their bid in right before the end, but they're not sure they could wait long enough to let the fast bidder not react. That would be a slightly different game.
00:48:09.892 - 00:48:16.584, Speaker H: Maybe it's not feasible, but if I'm sort of slower, I have a slower connection than you do. That's what I'm going to be thinking about.
00:48:16.702 - 00:48:48.272, Speaker D: Well, let's suppose you're in Tokyo and I'm in Ohio, and the server is in Ohio. So you're 200 milliseconds slower than me or 100 milliseconds slower than me, depending on your fiber connection. Right? Even if I don't observe your bid at all. Right, you try to submit 200 milliseconds before, because you have to get in before the deadline. Now, I observe what happens on finance for maybe I have ten milliseconds of latency. I have 190 milliseconds of latency on finance. Extra there.
00:48:48.272 - 00:49:08.996, Speaker D: Even though you've timed it just so you're right at the end, I'm also going to time it just so I'm right at the end. So I'm ten milliseconds before. And then if the price moves favorably, I'm going to submit a higher bid than you and I'm going to outbid you. So you're still suffering from winners curse there. Even if you try to time it right at the end, I don't need to observe your bid to make you suffer from winners curse.
00:49:09.028 - 00:49:09.464, Speaker B: Right.
00:49:09.582 - 00:49:11.610, Speaker H: Maybe we should discuss later.
00:49:16.160 - 00:49:52.280, Speaker F: Thank you for the talk. I'm wondering, one of the main takeaway from this talk is so dominant builder wings because they have better latency. But also I'm thinking what percentage time builder wing, because they have better private order flows, they have more data points, they can build more valuable blocks, and therefore their value could be much higher than the rest of non dominant vanilla builders.
00:49:52.780 - 00:50:22.400, Speaker D: Yeah. So this is an interesting question. I think we've seen a rise in private order flow that is unlikely to stop. The number in Matt's talk yesterday was something like 20% or 25% of transactions are now private. They don't ever touch the mempool. And that's from a number of sources. We have another paper, actually, which covers this question of what the relationship between private order flow and being a dominant builder is.
00:50:22.400 - 00:50:50.116, Speaker D: Basically because a block is sold wholesale. If you're good at private order flow, which often comes kind of in the middle of the block, and you're good at this trading stuff, which often happens right at the top, that's a compounding advantage. And so that can be even more of an issue. And if you look on chain at the data, the two builders that have kind of the highest percentage of private order flow also happen to be the two builders that are the most dominant in trading and are the integrated builders.
00:50:50.308 - 00:50:51.290, Speaker F: Thank you.
00:50:54.480 - 00:51:26.324, Speaker I: In the question before last, I noticed that you used Tokyo as one of the example locations. And I thought that was interesting because that's where the binance exchange is. And it made me think about what it would look like when we're looking at a latency race where you do have one person in Tokyo and you do have the proposer in Ohio, but the one in Tokyo, even though they're going to be slower to bid with more latency there, they're going to have faster access to what the actual true price is. So I was wondering if that would reflect in the strategies at all.
00:51:26.362 - 00:51:56.320, Speaker D: Yeah, maybe Tokyo is a bad example, because it should be the case that what matters is the sum of our distance from binance and our distance from whatever relay or, sorry, validator, who's taking the block. Right. What matters is probably the sum of those two distances. So if you're in Tokyo and the relays in Ohio and I'm in Ohio, then we probably have about the same advantage.
00:51:56.980 - 00:52:03.760, Speaker I: Would it split a little bit, though? Because I would have better pricing data from my bid, but you would be able to respond to my bid faster.
00:52:05.460 - 00:52:11.188, Speaker D: Well, I think we both have to submit based on the same price, basically.
00:52:11.354 - 00:52:12.976, Speaker I: Oh, right. Because it's sealed.
00:52:13.168 - 00:52:30.420, Speaker D: Well, we both are. Like, I'm getting ten milliseconds plus 200 milliseconds, so I have to submit based on the finance price from 210 milliseconds before the end of the slot. And you're getting ten milliseconds plus 200 milliseconds. So you have to submit based on the finance data from 210 milliseconds before the end of the slot.
00:52:30.960 - 00:52:38.220, Speaker I: Got it. So there wouldn't necessarily be any advantage just to being able to submit the bids faster based on, like, a response to the other party.
00:52:39.920 - 00:52:48.640, Speaker D: You could see what the other person is bidding, which might. If they have some private signal, then you can learn from their bid what their private signal is. So that might help.
00:52:48.790 - 00:52:50.130, Speaker B: Gotcha. Thank you.
00:52:50.740 - 00:53:04.980, Speaker C: One more hand for Mac. Great. Yeah. Our third and final session will be joined by Connor from Nethermind. So let's give it up for Connor.
00:53:10.680 - 00:53:31.630, Speaker B: Hey, everyone. So, yeah, I'm Connor from. So this talk is about value capturing based rollups with pre confirmations. So it's part of a PBS expansion pack, which we've just come up with that name recently because I guess. So this is a flashbots project that Nethermind are helping out. And in the last two months, we've been coming up with various different. Sorry.
00:53:31.630 - 00:53:53.572, Speaker B: We've come up with various different PBS designs for l two s. And basically we've l two s or roll ups, whatever you want to call them. And basically, we found that most l two s, depending on what their design requirements are, will have very different PBS designs. So one of the most interesting that we found with base roll ups. So maybe two weeks ago. So. Sorry.
00:53:53.572 - 00:53:54.550, Speaker B: Maybe I can.
00:53:56.840 - 00:53:57.444, Speaker E: The green button.
00:53:57.482 - 00:53:58.070, Speaker D: Right.
00:54:03.080 - 00:54:03.812, Speaker B: This one here.
00:54:03.866 - 00:54:04.436, Speaker D: No, this one.
00:54:04.458 - 00:54:17.176, Speaker B: Oh, sorry. Got it. Perfect. So again, we're not the first person to add to this expansion pack. Right. So I guess one of the main. The main contributors to this would be MVB boost.
00:54:17.176 - 00:54:47.190, Speaker B: But since then, we've seen things like PEPC enshrined PBS, alternate PBS, which was sort of the first iteration of this base roll up PBS. And there's much, much more. And typically, a lot of these are theoretical, experimental. But again, with all of these different designs, all these different requirements for different blockchains, we're definitely going to see a lot of PBS designs. So maybe a base roll up primer for people who don't know. So, base roll ups. The magic, the secret sauce, is that they inherit liveness from the l one.
00:54:47.190 - 00:55:17.112, Speaker B: So if you're an l two user, you submit your l two transactions to roll up builders. And those roll up blocks are sent to l one builders. So, as Max mentioned in the previous talk, these l one builders are running an auction. So the l one builders will choose the most valuable l two block for themselves. And then the l one blocks just typically will expect to see the l one blocks containing the most valuable roll up blocks. So these base roll ups are from several issues sort of hinted at in the previous slide. Two of the main ones are latency.
00:55:17.112 - 00:55:58.670, Speaker B: So the roll up confirmation speed, we should expect it to be approximately the l one block speed. Because of a problem mentioned in the first talk, which is that builders can only provide probabilistic guarantees that they will be the winning builder. So you probably just can't really guarantee much preconf. You can't really provide pre confirmations before you sort of build your block and value capture. So, because the l two blocks are competing for position in the l one block, the l two builders have to basically bribe the l one builder for position, which basically results in all of the l one revenue, l two revenue going to the l one proposer. So this is bad, right? So the profit margins for all of the l two players are extremely low. So we need to basically try and maybe bring some of that value back.
00:55:58.670 - 00:56:15.964, Speaker B: Okay, so, first problem that I mentioned was base roll up. Base pre confirmations. Sorry. The fact that we have latency issues on base roll ups. So, one way that we can get around this is based pre confirmations. A proposal from Justin a while back on e three search. So, base pre confirmations.
00:56:15.964 - 00:57:05.888, Speaker B: Effectively, the original proposal was that l one proposers sign pre confirmations that l two transaction will appear in the roll up block. So what we need to do, what we need for this is basically cr lists, or the proposers to actually be the builders and how we can actually enforce these pre confirmations? Well, signing, sorry. Basically the pre confirmations are signatures from the l one proposer. And with these signatures and restaking, again, restaking and slashing work hand in hand, we can basically prevent safety faults and liveness faults. So safety fault, if the sequence does not correspond to pre confirmations, then that's a slashable offense. Or if the l one proposer doesn't actually include anything in the l one block, then that's also a liveness fault because the l one proposer has full control over what they include. Right.
00:57:05.888 - 00:57:27.972, Speaker B: Or at least they should. With me boost, maybe they don't, but with crlist they should. So a liveness fault or a safety fault, both are sort of things that the l one proposer chooses to do. So both of these things should be slashable. And with restaking they are. So pre confirmations they work, or at least they should work. But that still doesn't address the other issue, which was value capture.
00:57:27.972 - 00:58:19.816, Speaker B: So PBS, there's lots of different reasons why we want PBS. One of them is as a value capture mechanism, and specifically they help the l one validators to sort of, I guess, smooth their returns and they lower the barrier to entry for l one validators. But to do this, so what happens, and basically the long and short of this is that the value that's generated from block building goes to the proposer. So the builders, through these auctions are paying the true value of the block to this intermediate, they're bidding through the auctioneer and they're paying that value to the elm proposer. So the expansion pack idea of this basic PBS design is that we take the value, we give it to the proposer, but then the proposer has to give it back to the roll up. This is the sort of the precursor to our idea. If the builders are going to pay the true value or they're going to pay something that looks like the true value via harbitra tax.
00:58:19.816 - 00:59:02.250, Speaker B: It's not a pure harbitor tax, but I will explain what I mean by Harbinger tax in a second. So what value are we trying to capture? So I've already sort of hinted at it, we're trying to capture the value generated from l two block building. What value is that? Well, it's basically the mev that we expect to happen on that, on that roll up, plus the pre confirmation tips. So if you're getting pre confirmations, you're going to have to pay for that service, because I guess if you're the l two builder. By providing a pre confirmation, you're giving up some optionality to include things later on. So in the original pre confirmation proposal, the pre confirmmer, which is the l one proposer, is inheriting this right for free. So our proposal is going to basically start charging them for this value, and we're hoping that the value that we're charging approximates the true value for the opportunity.
00:59:02.250 - 00:59:51.104, Speaker B: So how do we capture value? Well, typically the easiest solution is use an auction, but mev boost and exposed auctions in general, these are auctions that happen just before the block is created. They don't help. For the same reason I mentioned earlier, a builder can only provide probabilistic guarantees unless they know they're going to be the winning block. So how do we do that? How do we get around this? Well, Harbinger tax effectively should allow us to get around this. So along with people who don't know what Harbinger tax is, I'm going to try and maybe explain it now. So our protocol, every l one proposer inherits the right to pre confirm. So that's just basically everybody starts as a pre confirmer, then to sort of keep your pre confirmation rights, or to sort of like you can set this so you can set this value at zero, but to keep your confirmation rights, you set a Harbinger value for that block.
00:59:51.104 - 01:00:18.828, Speaker B: Right. So you're the l one proposer. You set a value that says, I'm willing to burn this much value to be the pre confirmer for this block, then the final pre confirm of that slot. So again, we have the initial pre confirm, and then we're going to have some notion of the final preconfirmer. The final pre confirmer will pay the final value of that slot. And then how we're going to let these pre confirmrs interact. So we know that the initial proposer of slot I owns the pre confirmation rights for slot I.
01:00:18.828 - 01:01:12.748, Speaker B: And so let's assume that some preconfirmer I owns the rights to slot I minus k, I minus k minus one all the way up to I. So the pre confirmmer of slot I plus one is then able to buy the pre confirmation rights of that pre confirm of slot I by paying any value greater than the values of the slots that have been sort of committed to by the pre confirm I. So pre confirm I plus one must buy all of the slots. So maybe just sort of maybe to why this stuff works for the l two s and not maybe for the l ones, right. So l two transactions sort of have relatively smaller space constraints than l one transactions. So the l two blocks can basically be added in a big clump, like maybe three or four blocks in one l one block. So there's not necessarily a constraint to have l two block every l one block, you can buy up the pre confirmation rights.
01:01:12.748 - 01:01:59.744, Speaker B: In this case for I minus k up to I, and then just put all of those l two blocks in one block in either slot I or slot I plus one pre confirm or I plus one buys those rights. And because of this interaction, because anybody coming after you can buy your pre confirmation rights for any value greater than your arbitrary value, we expect these values to approximate the true value of pre confirming for that block. Okay, so basic visualization of this situation so that at the top, all these colors should be different. But when I went for the negative color, the yellows and the oranges look the same. But these are all distinct proposers with distinct pre confirmation slots. And each of those proposers has stated a value for their pre confirmation slot. So v zero, v one up to v five.
01:01:59.744 - 01:03:06.512, Speaker B: Then in the second sort of row here, we have proposer five, who's also pre confirmed five, wants to buy proposer four's pre confirmation rights, so they have to pay any value greater than v four for those rights. And if they do, they will basically get those pre confirmation rights so they can offer pre confirmations for slot four and slot five, and then just submit all of those transactions, the l two transactions in their l one block. Okay, so at this point you might be thinking, there is some issues here, some glaring issues here, and there definitely is. I haven't gone through all the details yet, but things that we still need to tackle, how we're actually going to trade these pre confirmation rights, how can we prevent pre confirmed or centralization? So pre confirming has additional capital risk and hardware requirements for l one proposers. Now, if you're reading Vitalik stuff, you've probably read that in the end game, l one validators should be doing absolutely, almost nothing right. With pre confirming, we're putting a lot more sort of of these requirements that all lead to centralization on the l one validators. And that might basically end up with just one l one validator doing all the pre confirmations.
01:03:06.512 - 01:03:41.372, Speaker B: And that's not necessarily a good thing. We also may want to allow proposals to delegate pre confirmments. So in the previous sort of issue I mentioned, l one validators camp shouldn't be doing anything or shouldn't be doing much. We may want to allow for delegation, but doing delegation through the protocol, as opposed to sort of letting it happen in off chain markets that are unregulated or uncontrolled by the protocol. We can try and maybe you come up with a delegation protocol. Okay, so first of all, buying pre confirmation rights. So an l one proposer finds out they're going to be a proposer with between one and 33 slots, notice.
01:03:41.372 - 01:04:30.720, Speaker B: So the first proposer of an epoch basically finds out just before their slot begins that they're going to be the pre confirmer, the proposer, and in our case, the pre confirmer. That's not enough time to trade pre confirmation rights on the l one because of various issues related to censorship, resistance, and I guess just the fact that you can't buy. We need to know who the pre confirmers are before the slot begins. So one solution we have is that l one validators opt into the pre confirmation protocol in some restaking network. When you opt in, you state your Harbinger valuation curve, right? So you state the values that you have for your own slot, for the slot in front of you. If you have that opportunity and every possible slot in front of you, let's say. So then basically, once we know who the proposers are, we know what the valuation curves are, we sort of deterministically settle all these valuation curves and then lock in all the pre confirmed at once.
01:04:30.720 - 01:05:19.100, Speaker B: That's one possible solution. There's other solutions that could be possible once we bring in sort of an actively validated service into the mix, like Eigen layer, where we have this sort of very fast layer two or off chain system, where the l one validators are able to buy and sell rights. There's no selling necessarily in this protocol, just buying. You can buy somewhere else as a pre confirmation, right, in an abs. The only thing that we need to happen here is that the l two users have some way to verify that there is some mechanism that locks in the pre confirmator for that slot. Once you know who the pre confirmator is, you can send them the transactions, and you trust that if you get a signature back, your l two transaction will be included in the l one block, and therefore the l two sequence. Okay, so another issue that I mentioned was preventing pre confirmed centralization.
01:05:19.100 - 01:05:57.040, Speaker B: So there's a few ways we can do this. I guess these are sort of not necessarily robust to ocas, the first two at least, off chain agreements or off chain agreements, so we can introduce a tax. So in the initial example, you have to increase the arbitrary value of the person that you're buying off by anything we can actually make that arbitrarily expensive. If we don't want to allow one pre confirm it or one proposer to pre confirm everything, we can basically make it exponentially expensive to buy like n slots. If you buy one slot, it might cost one plus tax. If you buy two slots, it could be one plus tax squared. We can also implement a maximum number of slots per preconfirmer.
01:05:57.040 - 01:06:40.650, Speaker B: This is not robust to, again, off chain agreements because you can pretend you're the proposer of the L one, but you can actually be some guy, again, pulling the strings behind the scenes. But again, we can use anything that's enforceable on this restaking network. Okay, so we can actually maybe have some sort of identity based mechanism for pre confirmations. But again, this idea is very fresh, so there's lots of possibilities that we could use here. Okay, so just a bit of visualization of those examples that I mentioned. So if you want to, again, this is just, if you want to buy more than one slot, you have to sort of maybe exponentially increase your bids. Or in the bottom case here, where if we set a maximum number of slots per pre confirmed two, in the first case they're able to buy three, but obviously you can only buy two in the second case.
01:06:40.650 - 01:07:25.160, Speaker B: Okay, that's potential protections against centralization and then delegating pre confirmation rights. So this is probably the most likely way that we will see pre confirmations going, if pre confirmations happen, which we sort of expect, I think at this stage, or at least Justin's making strong arguments for procurement formations. So trust is delegation. So in a decentralized world, we don't trust anybody. At least that's sort of maybe the things that we agreed on maybe 40 years ago when we talked about BFT mechanisms. So how can we get around this? Well, we can introduce a mutual destruction contract. So if you're an L one proposer and you know that you can't actually do any of this pre confirmation, what you can do is find someone who will offer pre confirmations.
01:07:25.160 - 01:08:12.456, Speaker B: Again, as an L two user, you need to make sure that the l one proposer includes your transaction, but the person giving you the pre confirmation rights isn't the l one proposer. So you need to see another contract that says these two players are in some sort of an agreement that says if the pre confirmer gives me a signature, I know that if the l one proposer doesn't include that signature, the l one proposer and the l two, the l one proposer and the pre confirmer are going to basically burn stake. They're both going to lose stake with that agreement. You know, that the l one proposer will include the pre confirmer's sequence. And then if that sequence doesn't correspond to what the pre confirmations were, that's a safe default. And we have basically ways that we can, that's already incorporated into pre confirmations. If the sequence doesn't match, we can slash them.
01:08:12.456 - 01:09:10.052, Speaker B: If they don't include any sequence, they both lose stake. And that's a typical way to incentivize both parties to follow the rules or trusted delegation. So again, this is not necessarily the best, the most decentralized way to do this stuff, but we already have sort of, I guess, the concept of trusted relays, or at least relays that we have reputational trust. So we can actually maybe incorporate trust into the relays, or we can add trusted pre confirmbers into the mix. And what will a trusted pre confirm look like? Well, so I've been working with flashbots through that mind for the last two months, and now we're pivoting from l two pbs into sort of, I guess maybe looking, digging down into what swab could offer. And this sort of seemed like a potential use case for swab. So startup pack is like, okay, we could just basically, instead of having the l one proposers as the pre confirmmers, we can use roll up builders.
01:09:10.052 - 01:09:32.060, Speaker B: But the expansion pack of this would be actually, let's just use suave. All right, so roll up builders. Pre confirmation. Pre confirmation guarantees aren't actually sort of saying anything about the order in which your transaction will be executed. When you send it to the pre confirmmer, the pre confirmmer can do anything they want. It's only when you get the signature from them that you know what's going to happen. So basically that exposes your transaction to all sorts of Mev.
01:09:32.060 - 01:10:29.616, Speaker B: But if we have something like suave, where there is private compute going on private inputs, we might be able to get the perfect preconfirmer. And if we have a perfect pre confirmmer, the l two might say, okay, well, actually, let's just whitelist any outputs from suave, and then all you require from as an l two user is that the l one proposer will burn some stake if they don't include the suave output. With that guarantee, if you know suave will always provide that availability, you are able to basically get pre confirmations, you might say, then, okay, well, if suave is doing all the heavy work, and the only weak link in the system is the l one proposer actually using the suave output. Why do we even need an l one? And that's a good question. So in this high level idea, we probably don't need an l one. But sometimes people, I guess it's always nice to have that fallback of an l one. And I guess the whole point of base roll ups initially was that we inherit l one liveness.
01:10:29.616 - 01:10:46.650, Speaker B: Can swab provide l one liveness? I'm not sure, but we will see that over the next couple of months. So, yeah, that's the end of my talk. And any ideas or any questions or is a harbor tax will harbor tax work? I'm definitely open to discussions. Thank you.
01:11:04.210 - 01:11:18.114, Speaker C: Connor. Thanks so much for the talk. One thing I didn't quite understand is when you talked about how the valuation curves for the Harbinger parameter would be set deterministically, I couldn't really visualize what that would look like. Just wonder if you could clarify that.
01:11:18.152 - 01:12:07.886, Speaker B: Sure. There's a lot of moving pieces here. So the l one proposers are opting in through this, I guess, restaking network to being pre confirmers. All right, so once you allow for that, you can then basically say, if I'm elected as a proposer, I'll also set this as my Harbinger tax for that particular block. So again, you can extend that to saying, this is the value I'll set for my own block, and this is the value that I'm willing to pay if I'm allowed to buy a second block. So then once the election happens and you see the sequence of proposals, you can then say, okay, well, this guy has deterministically said he will pay, I don't know, one eat for pre confirmations, whereas the guy behind him says he's going to pay 1.5 e for that particular pre confirmation.
01:12:07.886 - 01:12:29.100, Speaker B: Right. And then we can basically deterministically say that's basically a purchase of pre confirmation rights. And now the second guy is pre confirming those two slots. So once we have some deterministic way of settling these curves, as a user, you can say, okay, well, I know who's pre confirming, and that's really hopefully what will happen. But, yeah, there's definitely a lot of design question marks there for sure. Cool.
01:12:29.550 - 01:12:37.180, Speaker G: When you speak about l two s, are you talking about zke evm l two s or just any type of l two?
01:12:38.590 - 01:12:49.540, Speaker B: So Tyco was sort of the inspiration for a lot of this work. And Tyco is a base dk rollup. So, yeah, it's really only focusing on the sequencing right. Then I guess the proving can happen later on. But maybe that's not the question.
01:12:50.230 - 01:13:08.200, Speaker G: So will there be a similar infrastructure when you talk about this, I guess system, will there be a similar system emulated on these l two s like Tyco? Or does all the action happen on Nethermind layer one?
01:13:09.290 - 01:13:40.766, Speaker B: No, well it's definitely eth layer one. Never mind. Also, all the sequencing is happening on the layer one. Even right now in cycle with this design is keeping the same tools. The sequencing is happening on the layer one, sort of the true sequencing, but we're allowing for maybe sort of intermediate finalization guarantees that are signed from the l one proposer. But the true sequence is, the enforceable sequence from the l two perspective, is the one that actually appears on the l one blocks.
01:13:40.878 - 01:13:47.540, Speaker G: Could you elaborate a little bit more on why that's the case or why sequencing happens only on the l one?
01:13:49.190 - 01:14:22.480, Speaker B: Why? Well, I guess so. In this sort of like the most adversarial case, I guess why base roll ups makes sense is the fact that we may not like the idea of trusting an l two consensus committee, or we might not like the idea of a centralized sequencer on an l two. So the reason I think base roll ups are one of the value, sort of the propositions of base roll ups is the fact that we inherit liveness from the l one. You're effectively submitting your transactions into the l one mem pool in terms of like that, answer your question?
01:14:23.250 - 01:14:24.622, Speaker G: I think so. Thank you.
01:14:24.676 - 01:14:35.860, Speaker B: Yeah, but definitely it's very early base roll ups. We're still in a design process. They've only really existed in public space, I think, for six months. So a lot of open questions for sure.
01:14:36.390 - 01:14:37.330, Speaker G: Understood.
01:14:38.070 - 01:15:30.210, Speaker C: Hey, quick question, Connor. So if I understand correctly, most of these auctions that you were playing out were different validators competing for the right to become the pre confirmer for a slot. There's kind of a second step here, which is when it's their turn to be the pre confirmmer, they have to decide whether or not to pre confirm a transaction or not. So they receive an l two transaction, they have to decide if they want to issue the pre confirmation, or wait and try and extract value from the transaction and still sequence it into the block, I guess. What do you see as the delta between how much a pre confirmation will cost for an l two transaction originator? In terms of the fact that if they get that pre confirmation, then the l one proposer loses some of the optionality of extracting more value from the transaction?
01:15:31.510 - 01:16:20.578, Speaker B: Yeah, I guess that's the issue with any unenforceable confirmation sort of policy. And I think that particular issue is one of the reasons why I think something like suave could be really, really cool. Now, obviously we're still a long way from suave being sort of able to do all this stuff trustlessly, but yeah, at some point if you're sending your transactions to random l one proposers, I think it's going to be really difficult to know how much you should pay and what sort of guarantees you're getting. Whereas if you're doing delegation and there's maybe even something like a reputationally whitelisted set of pre confirmers, then I guess you're still getting the same guarantees as you would with a centralized sequencer. Right. But yeah, I don't really know. The unforceability of these confirmation guarantees are definitely a concern, but I don't know.
01:16:20.578 - 01:16:22.290, Speaker B: I'm not sure how concerning.
01:16:23.130 - 01:16:26.280, Speaker C: All right, if there's no more questions, let's give it up for Connor once more.
01:16:35.610 - 01:16:36.022, Speaker B: Cool.
01:16:36.076 - 01:16:53.520, Speaker C: So that wraps up our session. I think we have a short break here and we reconvene at eleven. Is that correct, Tim? One sec before you go, let me confirm that with Tim. Okay? Yeah. Eleven. Back in here for session two on Mev. Thank you very much.

00:00:09.000 - 00:01:01.372, Speaker A: You. Hey, everyone. We're going to get started soon, so I guess this is going to be a bit of a different session. A panel, actually, it's going to be a rotating panel, so members of the audience, that means you guys will be invited at any point in time to just join the discussion on the panel and kick someone out. Can I have my phone? Yeah. Okay, so the overarching question for today's spicy panel is, will Mev go to zero? And I'll describe precisely what I mean by that later. But I want to try and keep the panel as fun as possible, as interactive as possible.
00:01:01.372 - 00:02:13.730, Speaker A: And so I've prepared a bunch of other questions that flow from this big overarching question that are also spicy. So here's a bit of a tasting menu for what's coming. One of the questions I want to ask is will Ethereum enjoy very soon Solana style latencies? And by that I mean 100 millisecond or 200 millisecond pre confirmations. I also want to ask, will Ethereum soon enjoy tradfi grade like New York Stock exchange grade execution quality? Should we increase the layer one block time? Maybe to 30 seconds, maybe to 60 seconds? That's a very, very spicy question with three spices. What about timing games? Should we worry about them? Should we not worry about them? What about separating, proposing and attesting? And basically my thesis is that to all questions, the previous question will Mev go to zero, but also these five questions, I believe the answer is yes. At least that's my thesis for this panel. And when Mev goes to zero, then Ethereum will look like this.
00:02:13.730 - 00:03:10.704, Speaker A: Now, I want to do a little bit of a detour. Before we start the panel, I want to share with you a very new idea that only came about eleven days ago. But I think it's a really fun and interesting idea and it has a lot of connections with the panel topic, and that's attester proposer separation. So the idea of attesta proposer separation is to take the validator, which currently bundles two different roles, attesting and proposing, and really remove the proposer role away from the validator. So the validators only do one thing, they just attest. And you can think of this as being a natural continuation of this incremental unbundling that we've seen in the MEV space. So with Mev Gef in 2021, basically we could have the miners that were effectively the block builders, have contributions from external searchers.
00:03:10.704 - 00:04:02.320, Speaker A: So the role of the searcher was kind of offloaded to the market. And then we had MeV boost in 2022, which separated the roles of builder and proposer with the merge and with PBS. And really here, what we're saying is that with attester proposer separation, we can unbundle the role of attesting and proposing. Now, the design is extremely simple. It fits on a single slide, and I want to try and describe it in this slide. So the way that we build and construct a tester proposer separation is to have this ticket pool. So you can think of them as being lottery tickets, right? If your ticket is selected, then you will be the next proposer.
00:04:02.320 - 00:05:15.980, Speaker A: Now, think of this pool as being fairly large, like there's a million tickets in the pool, and in order to buy a ticket, you need to pay a ticket fee or ticket base fee, which could be set with a mechanism like EIP 1559. So, for example, if there's more than a million tickets, so more than the target tickets in the pool, like the. The base fee just goes up and up every single slot and vice versa. If there's less than a million, which is the target, then the base fee goes down and down and down. So what I expect will happen is that proposers will be willing to pay for tickets at whatever they think the value of a proposal slot will be in the future when their ticket gets selected. And then there's another aspect to the ticket pool, which is that at every single slot, you randomly select a ticket winner, a lottery winner, and that lottery winner gets to propose a block. And so you can see here that what's happening is that Ethereum, the protocol, is kind of selling these proposal tickets to the broader market.
00:05:15.980 - 00:05:41.588, Speaker A: It's opening it up as opposed to giving free tickets right now to the validators. So we're really separating the role of proposing and attesting. Does that make sense so far? Happy to take questions in real time, if you want to interrupt me. I think that's part of the style of this conversation. Hopefully it makes sense.
00:05:41.674 - 00:05:43.620, Speaker B: You're viewing proposing as a purpose.
00:05:47.800 - 00:06:42.680, Speaker A: Yeah, exactly. So there's some value to be extracted from the privilege of having proposal rights, and so we're going to auction off these proposal rights to the broader market. And one of the important properties here is that the randomness makes it very, very difficult to have multiple slots in a row. So it's extremely difficult to buy, let's say, 100 slots in a row, which could be bad for censorship purposes. Another thing I should mention here is that this assumes inclusion lists, so we still have inclusion list proposers which are the validators. But those are not latency critical, those are not very sophisticated. So it's fine for the validators to do that, but the really sophisticated mev extractive proposals, which are latency sensitive, would be done by more specialized proposers.
00:06:42.680 - 00:07:35.908, Speaker A: Okay, so what are some of the advantages of aps? One of them is around the decentralization of the validators. So we're basically segregating and protecting the attesters in case proposing becomes a very sophisticated game. Imagine that proposing requires you to be in a very specific place in the world. It requires you to have very advanced networking infrastructure or very advanced computing, then that would kind of be a centralization force that would kind of pollute the attesters, so the attesters can stay totally segregated from that. Another really cool property is rewards moving. So right now, as a validator, my APR is pretty noisy because of the proposal lottery. Every once in a while, an expectation.
00:07:35.908 - 00:08:39.048, Speaker A: Once every 4.5 months, I win a lottery, and there's a very, very high variance. And so once we remove this lottery aspect for the attesters, then we have a perfectly smooth payout. And so that means that there's less of an incentive. There's no incentive, even for attesters to join a pool, a smoothing pool. And then another interesting aspect is that if you're trying to design a totally trustless and decentralized liquid staking token, maybe something inspired by the design of rocket pool, then you have this problem whereby operators can be malicious whenever they win the proposal lottery, and the MEV in their slot is greater than their collateral, for example, greater than eight e. In the case of rocket pool, then they can take the proceeds of that lottery and don't not give them to the pool, forego the collateral, but be in net profit.
00:08:39.048 - 00:09:34.460, Speaker A: So they're essentially stealing value from rocket pool. If they were to do that, and that becomes impossible to do if validators do only one thing, which is attesting. Another very interesting class of advantages is that now we have this more sophisticated entity, the proposer. Think of them as being sophisticated, like a builder, and we can start leaning a little bit more on this sophistication. So, for example, secret leader election was an idea that was specifically tailored towards unsophisticated proposers. The idea here is that we're going to shield the identity of the next proposer so that an attacker can't figure out their ip address and ddos them. But if the proposer is sophisticated, they can just have infrastructure like cloudflare or whatever it takes some sort of firewall to protect them against an out of service.
00:09:34.460 - 00:10:24.430, Speaker A: So secretly leader election becomes a future upgrade that can be postponed a little bit because it's not as important. Another interesting one is enshrine PBS. Maybe we don't need it so urgently. And the reason is that, in a way we're going back to the model of proof of work, where we had a few mining pools that were kind of semi trusted, and things worked fine there without needing this service to unsophisticated proposals, which is the guaranteed payment. Right. A big part of enshrine PBS is just guaranteeing to some sort of random untrusted proposer that they're going to get paid. But if you have a sophisticated proposer, they can make sure they can get paid through some other means.
00:10:24.430 - 00:11:21.920, Speaker A: And then the final thing that we can lean on in terms of proposal sophistication is pre confirmations. So in the previous talk there was this notion of based pre confirmations, where the layer one proposers not only can sequence the rollups, but they can also provide pre confirmations to roll up users. And so in order to be a pre confirmer, more likely than not, you're going to need to be somewhat sophisticated. You're at the minimum going to have to have the bandwidth to receive all the user transactions and provide pre confirmations in real time. And if there's hundreds of roll ups, then you need to have the bandwidth to support all of that. And so one of the nice things here is that we can have more proposal sophistication and we can lean on that to provide more services like pre confirmations at layer one. And that ultimately means that we're going to have more secure rollups.
00:11:21.920 - 00:12:32.596, Speaker A: Because my thesis is that the sequencing aspect of roll ups, which is basically critical for liveness, will incrementally become more and more decentralized over time. So we start with a centralized sequencer, and then we have maybe a trusted committee, which is the sequencer. And then we maybe have some sort of off chain consensus, which has a reasonably low amount of economic security, maybe a billion dollars or $10 billion. And then eventually the roll ups will move on to true World war three grade liveness and use the l one with hopefully trillions of dollars of economic security. Now, in terms of other advantages, we also get MeV burn for free, because the protocol is selling these lottery tickets, these proposal lottery tickets, and just like EIP 1559, the base fee for the tickets can just be just be burnt. And not only do we get an MEv burn, but we actually get an extremely efficient mev burn. In the previous proposals for MeV Burn, there was this synchrony assumption.
00:12:32.596 - 00:13:44.904, Speaker A: There was this period of 2 seconds, for example, which is required to make sure that the bids arrive on time and so that the testers can see the bids here. Really, we're in a position where the protocol is selling futures like block space, like slot futures, and so long as you can price these futures correctly, then you'll have a very efficient Mev burn. And then the final kind of fun, kind of second order effect here is that if you really like lotteries, and some validators really like the lottery aspect of being a validator, because every once in a while you get to win a block, and who knows how much maybe you're going to extract. It's going to be either like 0.1 or it could be 1000 e. And so if you really like lotteries, then you can just buy as many lotteries tickets as you want, which is kind of an interesting consequence. Okay, now, the reason why I went down this rabbit hole of a tester proposal separation is specifically because of timing games.
00:13:44.904 - 00:14:37.568, Speaker A: But it turns out that I think a tester proposal separation solves more than just timing games. But I kind of want to give you some insights on the proposal timing game specifically because I think it's interesting. So we have this slot duration, whereby the whole mev pipeline can play today on the order of 12 seconds, and then towards the very end of the slot, or just before some sort of arbitrary threshold, we have what I call advanced timing games, where only the truly sophisticated players can have an edge. Everything else in blue can be very easily commoditized. Nowadays, proposers are extremely unsophisticated. There's a whole four windows worth of mev to play with. But I think that's going to collapse very soon.
00:14:37.568 - 00:15:14.088, Speaker A: But it won't collapse down 100%. It will only collapse down. Only most of it will collapse down. So you still have this advanced timing game, which is maybe on the order of, let's say, 100 milliseconds. And I'm going to pick 120 milliseconds, just to make the math easy. So 120 milliseconds is 1% of 12 seconds. So, basically, what I'm trying to say here is that if you're really, really advanced as a proposer, you can make 1% more mev during your slot.
00:15:14.088 - 00:15:59.588, Speaker A: And one of the reasons why this is great news is because as a rational proposer, I also have a cost to playing these timing games. And the cost specifically is that sometimes I'm just so aggressive on my timing game that my block doesn't reach the attesses on time and then it leads to a missed lot. But when you have a missed lot, you lose 100% of the MEV. And so you see there's a huge asymmetry here, which is that when you win, you win a tiny amount. And when you lose, you lose everything. Really. It would be irrational for a proposer to miss more slots than they have as an edge.
00:15:59.588 - 00:16:45.828, Speaker A: So if they have a 1% mev edge, well, they shouldn't be losing more than 1% of blocks because otherwise they'll start losing money. And so one of the worries that we have with timing games is that it starts degrading the liveness of the chain. Specifically, it leads to more missed lots. But I actually think this is going to be like a tiny, tiny impact. Like surely less than 1%. But actually I think we can bring it way, way down less than 1%. We can bring it one in 1000 or one in 10,001 of the reasons is that we can redesign a little bit the incentives around proposals because right now if you miss your slot, then you don't really get penalized.
00:16:45.828 - 00:17:20.164, Speaker A: The main penalty is opportunity cost. Like you lose the opportunity of gaining some attestation rewards and also from getting meV. But what we could easily do is have a small penalty. Let's say you lose 0.1 e. And that's actually enough to basically completely eliminate these problems. And the reason is that the average amount of MEV per block is 0.1
00:17:20.164 - 00:18:12.944, Speaker A: e, one 10th of an e. And so if you take 1% of that, that's 1000th of an e. And so now if the penalty is on the order of one 10th of an EF, over 100 of an e, it's much greater than what you stand to gain. Another interesting thing that ties in with the topic of the discussion here is that if Mev goes to zero, and by that I mean Mev that leaks to the proposer goes to zero, then there just won't be much mev gains. And so the 1% of the Mev gain will be even smaller than what it is today. And then another thing that we can tweak here is the length of the slots. Because these really advanced timing games, they're mostly dictated by speed of light considerations.
00:18:12.944 - 00:19:17.990, Speaker A: And so you can think of them as being constant 120 milliseconds. But the size of the slot, the denominator can be increased and then the ratio improves. So this is one of the reasons why I'm actually not at all worried about proposal timing games specifically. Okay, so now we can get into the panel, but I guess I want to make sure that this previous section on a tester proposal separation games, attested proposal separation, are well understood and happy to take questions. Now, I guess, before moving on to the main event, which is the rotating panel, do you want to take the microphone? I guess just one observation is if you do make the slots longer, then certain types of MeV, particularly deck sex arbitrage, which I understand is the largest kind of MeV, will actually grow. And so that is an argument the other way. Okay, fantastic question.
00:19:17.990 - 00:19:52.130, Speaker A: So this is all about the next panel, where we're hoping to argue that sextex arbitrage MeV does not, in the future, will not grow with slot size. And the reason is because we have these new designs that solve LVR, things like Calswap and things like Sorella. And actually the panel will be seeded by Calswarp and Sorella that, I guess, are believers of this thesis that Mev will go to zero. So I guess that's something we'll discuss on the panel.
00:19:53.510 - 00:20:18.380, Speaker B: I had a question about the number of tickets you can sell, because it feels like if you sell a million tickets or a lot in advance, it's really hard for people to predict what's going to happen in the million slots. And if you make it too short, then you increase the chances of someone just buying all the tickets and having a monopoly over a certain period of time.
00:20:19.230 - 00:21:04.022, Speaker A: Yeah, that's a great question. Right now, we have roughly a million validators, so we have roughly a million tickets. And this uncertainty is being punted to the validators right now, and they seem to be perfectly happy with it. The other thing I want to highlight is this slide, which is, I'm shocked by this graph. So this graph basically shows the amount of MeV that went to the proposers, paid for by the builders. And what's shocking about it is so how straight it is. There's more than a year's worth of data, and it just goes straight up, and the slope is roughly 800 e per day.
00:21:04.022 - 00:21:56.360, Speaker A: So you take any given average day, you're going to have 800 e that leaks to the proposer. And one of the reasons why it's shocking is because if you zoom in to this chart, it's extremely bumpy, right? Because MeV is very spiky. But when you zoom out, it just looks like a straight line. And so, to answer your question, if this line is straight, then it's actually very easy to predict in the future. But I agree with you that if we set it to a million, then the proposers that will buy these tickets might be like macro hedge funds and kind of entities that can try and predict the future. Yeah. Ivy works.
00:21:56.360 - 00:21:57.720, Speaker A: Go first.
00:21:59.070 - 00:22:23.038, Speaker C: Hi, great presentation by the way. Thanks for doing this. So my question is with regards to the timing games. You mentioned that you throw in a fee like a 0.1 e, and definitely the penalty in that time for the time spent would be likely greater than the MeV. Yeah, that kind of thing. My question is, you still run the risk of losing quality of service, let's call it that.
00:22:23.038 - 00:23:05.870, Speaker C: They could still let the time run and they would take that fee and all of that. Wouldn't it be better to rather, instead of giving one slot to one validator, you could make it so that a single slot like 12 seconds gets more than one validator. You can spin like, maybe you can give it like every four validators, they can have 3 seconds in that slot. And pretty much the first person to propose a block is that one who essentially gets the slot. And assuming that there's more than one person, you can look at a hash and say whoever rose lower gets that. That way you can still get the quality of service without even throwing in that extra fee, that kind of thing. There's more to gain for that first person who proposed the block in that slot.
00:23:06.370 - 00:23:50.630, Speaker A: Right. So in terms of quality of service, I actually think this dramatically improves quality of service, because as I'm arguing, I don't think there's going to be many missed lots. But on the other hand, you can start relying on the sophistication of these proposals. So the proposers can start providing services like pre confirmations. And in my opinion, pre confirmations are like one of the things that will bridge the gap between Solana and Tratfi and will really give us an amazing user experience. So I would actually go the other way. Now, in terms of the multi proposer kind of suggestion, it makes things like much more complicated at the consensus layer.
00:23:50.630 - 00:24:27.980, Speaker A: But maybe more importantly is that it's not really compatible with pre confirmations. And the reason is, let's say there's n proposers that could propose and you don't know which one it is. Now, who are you going to get the pre confirmation promise from? Right. One of the reasons why pre confirmations work is because there's like this one entity that has monopoly over the next unit of time, and they can make promises over what action they're going to take within this unit of time. And so, yeah, multi proposers, I think, are a bad design, I guess. Thank you.
00:24:30.030 - 00:25:28.734, Speaker B: Yeah. So I was also curious in terms of timing games. It seems as if this advanced timing games that are currently played at the very end of the slot seems somewhat misguided from the proposer's perspective, in the sense of the assumption here is that the very last block to be sent by a builder to a relay will be most valuable. But given that relays are now offering cancellations, what would stop a proposer from instead getting the header throughout the slot near the end? Continuously querying get header to get all of the proposed blocks, all of the blocks that the builder sent, even the ones that are canceled, so they can capture the stat arb block that has been canceled because volatility moved against them so they can actually keep it even though it has been cancelled. Wouldn't that be a dominant strategy, rather than just waiting the very last second?
00:25:28.852 - 00:26:01.734, Speaker A: Yes. Ludwig the accelerationist, leaking all the alpha. Yes. So proposers today are extremely unsophisticated. They're leaving a ton of value on the table. There's basically 4 seconds worth of mev that's out there. And as you said, there's this very simple strategy, which is that instead of calling get header once, just continuously pull get header, just call it multiple times, maybe every ten milliseconds or whatever it is, and then pick the highest value there.
00:26:01.734 - 00:27:16.794, Speaker A: And you get several benefits. One benefit is that if you're pulling a relay which is very close to you geographically, then you're going to get lots of fresh values, as opposed to kind of waiting for a relay which is extremely far away and getting stale values. But the other thing that happens here is that you start breaking cancellations, right? Because the way that cancellations work today is that proposers only make one single get header query. But if they're constantly polling and just taking the highest, and then this one, the highest, turned out to be canceled, well, tough luck. And so, as a relay operator of the ultrasound relay, we've been talking to builders about that, and they're actually extremely worried that all their precious cancellations are going to break. And I think there's going to be this period of time of maybe a few weeks or a few months where cancellations will just be completely broken. Now, it turns out that even though you have this local maxima for the proposer to do the polling, this actually might be net negative for the whole proposer industry.
00:27:16.794 - 00:28:01.050, Speaker A: And the reason is that if you don't have cancellations then now bids overall will just be smaller to compensate for the risk of adverse selection from not having cancellations. And so, yeah, it will be an interesting transition period. What I think will happen in the end game is that proposers will, sorry, relays will offer two services. Well, two feeds. There's going to be the cancelable feed, which is going to be a real, sorry, uncanceable feed, which is going to be this real time thing that you can pull. Could be a websocket connection, for example. And then there's going to be a one shot cancelable feed, which will have potentially a larger amount of Mev.
00:28:01.050 - 00:28:26.470, Speaker A: But you can only call that feed once. And the only way you can call it per relay is by signing it with your proposal key. So we know cryptographically that the request came from you, and now you can't make two requests. And so this breaking of the cancellations will happen. But, yeah, I don't know how much time it will take, but as we know, crypto moves extremely fast. So I'm expecting this to happen in a period of few months.
00:28:26.620 - 00:28:30.040, Speaker B: It's going to change, like dominant strategy for builders, which is going to be.
00:28:31.210 - 00:28:43.866, Speaker A: Yes. Yeah, it's going to be fun. Thank you, Justin. Assuming proposer timing games are not a.
00:28:43.888 - 00:28:53.230, Speaker D: Threat, are there other disadvantages to a tester proposer separation that you perceive, aside from consensus logic increasing?
00:28:54.610 - 00:29:45.018, Speaker A: So there's kind of this theme out there, this recurring pattern where a lot of designs seem like fundamentally sound, but they have this mimetic disadvantage, which is that they introduce this centralization. So now there's this new role, this new specialized actor, the proposer, that's assumed to be sophisticated. And if you're just some random person observing this and you say, okay, this looks really bad, because now instead of having the proposal set be decentralized, it's much more centralized. And this pattern happens at the builder level. It also happens for things like Lido. And I think that the mimetic discount is really one that should be taken into account. It's basically a bad look to look centralized.
00:29:45.018 - 00:30:27.818, Speaker A: But what we're trying to achieve here from a fundamentals perspective is be in a position where decentralized actors can't do anything wrong or anything bad. And so if you take the context of builders, for example, we don't want them to censor, we don't want them to break liveness, we don't want them to break safety. And there's all sorts of things that we can do to really tie their hands to, to provide a good service. And it's the same thing with the proposer, really. Like the only thing you can do is play timing games. As a proposer, there's not much else, not much else you can do. And playing timing games, as is argued in this slide, is maybe not a big deal.
00:30:27.818 - 00:30:38.080, Speaker A: So I think the number one disadvantage is mimetic, meaning that it's perceived by some people to be bad. And I think the best way we can fight that is just with education.
00:30:42.210 - 00:30:44.390, Speaker E: When the slot auctions have been discussed.
00:30:44.410 - 00:30:45.678, Speaker A: In the past, one of the pushbacks.
00:30:45.694 - 00:30:56.178, Speaker E: Has always been that they seem to be a bit more centralizing in terms of the builder market because of this issue that you have to bid in advance, kind of your expected value. And so the dominant builder, it's easier.
00:30:56.194 - 00:30:58.086, Speaker A: For them to just get all of.
00:30:58.108 - 00:30:59.926, Speaker E: The slots instead of just sometimes when.
00:30:59.948 - 00:31:01.000, Speaker A: They happen to win.
00:31:01.770 - 00:31:04.360, Speaker E: Is this concern here mitigate? I guess.
00:31:04.730 - 00:31:06.390, Speaker A: Where do you see that the difference.
00:31:06.460 - 00:31:08.026, Speaker E: Is in this proposal versus what's been.
00:31:08.048 - 00:31:08.666, Speaker A: Discussed in the past?
00:31:08.688 - 00:31:13.114, Speaker E: Is it the fact that you are thinking of this actor, the proposal, as.
00:31:13.152 - 00:31:17.754, Speaker A: Really more of an intermediary that's then going to run the auction themselves, or.
00:31:17.792 - 00:31:18.650, Speaker E: Like, yeah, I guess.
00:31:18.720 - 00:32:11.790, Speaker A: What do you think about this? Yeah, so let's say I'm a hedge fund, I bought 10,000 tickets, and what I'm going to do is I want to maximize the value of these tickets. And so whenever I win the lottery, I want to extract as much value as possible. And so I'm going to delegate to the builder market. More likely than not, I'm not going to be the most efficient builder in that slot. And so what I expect will happen is that there will be the real time block auction, the PDS auction happening for the proposals, just like we have today. And so in terms of the builder market, I expect nothing will change just because for the purpose of maximizing value, you'll just delegate to the builder market. I think what we're doing here is that we're creating this new role, which is fairly centralized.
00:32:11.790 - 00:33:20.194, Speaker A: But the benefit here is that we're making their testers more decentralized and we can lean on the sophistication of this new role to have new services. Does that make sense? Yeah, except, I guess, what if the best way to maximize value is not to run the block auction like today, but to just bundle chunks of slots? Interesting. So here, I think the best response is what is currently called Mev Burn, where basically you have, which is your proposal, by the way. So Francesco came up with this amazing design where you have a set of attesters that are observing the bid pool. So basically, the off chain bids that come from the builders, and then the proposer is constrained in terms of which bid they can select. And specifically, the constraining rule is that they need to pick the highest value bid that they see. And so by doing so, you prevent things like censorship, but you also prevent things like.
00:33:20.194 - 00:33:37.050, Speaker A: Or you make it harder to do multi slot meV, or disbundling of services, where, for example, you make a promise to include certain types of transactions in the future. But if those are not maximizing, then your block won't even be valid.
00:33:41.070 - 00:33:41.386, Speaker B: Yeah.
00:33:41.408 - 00:34:08.110, Speaker E: So I wanted to ask you if you could elaborate more on the analogy with proof of work. Because if I understood correctly, it's a big if, but essentially proof of work. You have to spend resources. So it's like a flow. The one that gets to write to add the block has spent the most in this flow of resources, at least in expectation. The one that spends the most gets to add the next block. And of course, also the rewards are a flow.
00:34:08.110 - 00:34:40.590, Speaker E: Now, I have the impression that, okay, currently proof of stake is more of a stock. So I have a stock, and the one with the largest stock maybe gets more probability to add the next block. And you seems to be going back to this idea that I have to spend resources as a flow to be able to get resources. And then competition for spending these resources should get to some nice property in terms of naturally getting mev burn or things like this. So is this a correct analogy, or you meant something else when you said that we are going back to proof of work?
00:34:40.660 - 00:35:46.100, Speaker A: Yeah, I meant something else, which is that proof of work is just very naturally centralizing for various reasons. But one of them is that the variance of proof of work is extremely high. There's this cool statistic, which is that if you buy a $10,000 bitcoin mining rig and you run it for five years, so continuously twenty four, seven for five years, much more likely than not, this rig will never get any block. And so really, if you're a miner of reasonable size, like small or medium sized, then you have to join a pool to smooth out the rewards. And then what this gives us as a second order effect is that you have these few pools that basically act as the block proposer and the block builder and the searcher. Right. The pool is kind of this extremely bundled service today on bitcoin, at least because searching is so easy and building is so easy and proposing is so easy, that might as well just do everything.
00:35:46.100 - 00:36:42.260, Speaker A: And the reason why there's very few pools is that in order to do the smoothing, you need to reach a certain size, like escape velocity, you need, let's say, 1% of the hash rate at the minimum to be like a reasonably low variance pool. And so that actually puts an upper bound on the number of pools, right. You can only have at most 100 pools because each pool needs to be of size, at least 100. So it's kind of a similar dynamic here, where I don't expect many more than 100 reasonably sized proposers, because the proposers here, unless they're gamblers, which there could be plenty of gamblers, but those who are running proposers as a service, they will want to buy lots of tickets in order to smooth out their variance. Does that make sense? Yeah.
00:36:44.730 - 00:36:49.718, Speaker F: It seems like the whole development of the Ethereum transaction supply chain and.
00:36:49.724 - 00:36:52.742, Speaker B: How you're proposing blocks is a story.
00:36:52.796 - 00:36:54.546, Speaker A: Of separation of entities.
00:36:54.658 - 00:37:01.206, Speaker F: So I wonder whether this is the kind of finish line, or do you think that we have some other separations.
00:37:01.318 - 00:37:03.580, Speaker B: In the future that we should do?
00:37:04.910 - 00:37:54.700, Speaker A: Yeah, that's a great point. I mean, one of the things kind of structurally about here is that every entity is incentivized to be very low latency to the next entity. And so you have collocation, you have the searcher collocated with the builder, the builder collocated with the relay, and then the relay in the future collocated to the proposer. Once there's a proposer attested separation. But the nice thing about the attest is that they're at the end of the line, right? They perform their action, and then an eternity happens until the next thing happens. And so this is why I'm kind of optimistic about attester proposal games, is fundamentally because of this end of line effect. Hopefully, things don't get too crazy there.
00:37:54.700 - 00:38:37.350, Speaker A: Another reason why I'm optimistic about attester games is that when you're an attester and you make an attestation, it's extremely low entropy, meaning that specifically, there's one bit of entropy, which is that you either vote for whatever block was proposed or you vote for the fact that no block was proposed on time. So it's kind of a binary type of attestation. And so as we go down this stack, we're actually reducing entropy. Right? Like the searchers, they can search arbitrary long tail strategies. There's, like, lots and lots of entropy. The builders, they're much more constrained. It's more like of a combinatorial packing problem.
00:38:37.350 - 00:39:13.646, Speaker A: Given bundles and they try and pack as much as possible. Proposers is even less entropy. Like, the only thing they see is the block headers, they don't see the block bodies, and they just maximize over bids. So they receive, let's say 100 bids, and they just pick the highest one. And then a tester, even low entropy is just one bit of entropy, and you can't go less than one bit of entropy. So, yeah, these are some of the reasons why I'm optimistic. Another reason I'm optimistic is that Mev doesn't flow very well to attesters.
00:39:13.646 - 00:39:55.860, Speaker A: Right. There's this natural thing where it stops at the proposals. I mean, you could argue that the attesters will only attest to a proposal if they get paid, if they get bribed. And this is where things like Mev Burn really help, as opposed to Mev smoothing, where you kind of smooth out all the MeV to the attesters. And now you're kind of asking the, well, I don't know, it gets a little complicated. But the point is that if MeV indeed does not flow to the attesters, then you're in a position where as a mechanism designer, you have more control. You can set your rewards and penalties for doing certain actions, because you have more control.
00:39:55.860 - 00:39:58.930, Speaker A: The design space is larger.
00:40:04.050 - 00:40:32.490, Speaker B: Hi. So do you think it is better that besides the proposal timing game, we also need to make it more complicated for the proposer to find the MEb opportunities. For example, we can maybe design some penalties for the proposer if he organized the sequence of the transactions, which is different with the maybe descending order of the fees proposed by the users.
00:40:34.270 - 00:41:34.746, Speaker A: Okay, so the proposer is not the builder. So the builder is the one that kind of decides on the ordering of transactions within the body. The proposer only sees headers that are basically bids that come from the builders. And really what they want to do is pick the highest bid and potentially play timing games so that they have a bit more time to pick the highest bid. Now, in terms of the worst thing that they can do really, is cause a missed lot, because it's bad to have missed lots, because Ethereum skips a beat and the liveness degrades a little bit. And so the question is, okay, how can we incentivize not missing a slot? One way we can do that is by just having reasonably large penalties for missing a slot. And I think actually once we have a tester proposal separation, it's actually acceptable to have, let's say one e penalty for missing a slot because you're meant to be online, you're meant to be sophisticated.
00:41:34.746 - 00:42:32.110, Speaker A: There's no reason why you'd miss your proposal. You're not a Home validator on a flaky connection, so one efit should be perfectly fine. Another thing you can try and do to disincentivize timing games is to basically provide an incentive for the proposer to get attestations from as many attestors as possible. So if they get attestations, let's say from 60%, they'll get more revenue than if they only got attestations from 50%. So right now, if you're a proposer and you get 100% attestations or 50% attestations, you don't care. Like it doesn't impact your bottom line. But we could design the incentives in such a way that the more attestations you have, the more of a reward you have for proposing.
00:42:32.110 - 00:42:47.822, Speaker A: So this is where the design space is very, very clean, and I'm optimistic that we can solve a tester. Well, proposer games for sure, but hopefully also a tester games.
00:42:47.886 - 00:42:49.140, Speaker G: Okay, thank you.
00:42:50.470 - 00:43:02.300, Speaker B: So quick first question from Kaido. I'm acting as proxy. Where does the lottery actually happen? And then I have my second larger question relative to that.
00:43:02.750 - 00:43:36.264, Speaker A: Yeah. So the lottery here is. So you can think of this as a pay in, random out queue. So you know how we have first in, first out, blah, blah. So here is like pay in. In order to get in the queue, you need to pay and then random out. And the lottery aspect is in the random out, so you don't know when you'll get selected.
00:43:36.264 - 00:44:03.750, Speaker A: So a little bit. There's two aspects of lottery. One is actually at least two. One of them is when you do get selected, you don't know how much mev there will be in your slot. You could be unlucky and you get selected on a weekend like us, night hours, not good. But if you get selected on the exact tick where the fed announces their rate, then you're very happy. Yes.
00:44:03.750 - 00:44:32.072, Speaker A: So that's part of the randomness. Another aspect of randomness is that you just don't know how long you have to wait. And here there's a little bit of cost of money aspect. So in expectation, you'll have to wait 4.5 months because that's roughly, that's a million slots. But if you get unlucky, you might have to wait a whole year before getting a proposal. And so there's a little bit of cost of money, but it's actually very easy to smooth out once you buy many tickets.
00:44:32.216 - 00:44:46.236, Speaker B: And so I guess the follow up to that is. So, requirements, from my understanding here, requirements are the same as being a regular validator to enter this lottery pool, can you purchase multiple tickets as a single user?
00:44:46.428 - 00:45:05.428, Speaker A: Yeah, exactly. So you can have a 32 e validator, and instead of just having one ticket every 4.5 months, which is not super, doesn't provide much dopamine, just buy 100 tickets or 1000 tickets, and then every day you'll get a proposal. And every day is like Christmas.
00:45:05.604 - 00:45:41.940, Speaker B: So wouldn't this incentivize pooling? Let's say lido smooths out they're entering the proposer ticket pool, but now they can have a single validator and put all of that cash in, buying as many tickets as possible. So they have more fragile of a baseline infrastructure, but they have a far higher probability of being selected as a proposer. So you don't have the cost of capital of holding the stake, but you can game the ticket pool system to then smooth out and distribute those rewards.
00:45:42.360 - 00:46:07.768, Speaker A: Right? Okay. There's two types of cost of capital. Like one is you've bought your ticket and now the money is gone until you get selected by the lottery. But then what you're pointing at is something different, is you're saying, okay, in order to even participate in this game, I need to have 32 e and be a validator. That's not the case. What we can do is we can create a new role. Let's say propose a role.
00:46:07.768 - 00:46:20.320, Speaker A: And the only money that you need is the one if to cover the penalty, if you miss a slot. So you have different session conditions. It can be like a totally separate role. You don't need to be a validator.
00:46:20.740 - 00:46:44.840, Speaker B: But do you not see the game of pooling stake now shifting to this, where you have an entity that pools and smooths out the rewards of buying tickets and being a proposer. So you can then have a pooled ticket, which acts as a smoothened out reward for that time period.
00:46:45.420 - 00:47:12.960, Speaker A: Yeah. So Lido could start becoming a hedge fund and play this proposal game. That's totally possible. But the thing is that the economics are totally different. So today, Lido receive 99% of the mev, right? It's a great business, but if they stop playing the hedge fund game, then they only receive 1% of the mev. And the reason is the competitive market, where margins go to zero. They start competing cutthroat, similar to the searchers and the builders.
00:47:12.960 - 00:47:21.556, Speaker A: So Lido is in the business of big margins. I don't think they'd care about the 1%.
00:47:21.738 - 00:47:24.420, Speaker B: It's definitely a harder game to play. Far harder.
00:47:25.740 - 00:47:42.124, Speaker A: Yeah. And also it's very much permissionless, and there's an open, and there's less network effects. Like Lido has these network effects that give it certain advantages in certain circumstances, but those don't give them advantages in this specific game.
00:47:42.242 - 00:47:44.190, Speaker B: That makes sense. Thank you.
00:47:47.280 - 00:47:48.700, Speaker A: Talking about Lido.
00:47:50.400 - 00:48:11.460, Speaker B: From Lido, quick question on the. I still don't see clearly what stops at the limit. Proposers just running as many attesters as possible and sort of integration between proposers and attesters in order to actually maximize the probability of not missing a slot.
00:48:11.960 - 00:49:00.176, Speaker A: Right. So if we go back to this slide, basically the observation here is that any entity that's towards the top wants to be colocated with the entity next to the bottom. And so what I expect will happen is that the proposers want to be as close as possible to the attesters. But what does that mean? Basically what it means is that you want to be in the kind of the weighted center of gravity of the attesters. Right. So you want to be in the one place in the world where you're going to be able to gossip to all the attesters as quickly as possible. And so what? The logical conclusion here is that all the proposers will be in this one place of the world where they're simultaneously as close as possible to all the attesters.
00:49:00.176 - 00:49:10.660, Speaker A: But the hope, at least at this point, is that there aren't really incentives for the attesters to themselves be close to the proposers.
00:49:10.740 - 00:49:10.984, Speaker B: Right.
00:49:11.022 - 00:49:11.688, Speaker A: I get that.
00:49:11.774 - 00:49:23.150, Speaker B: It's more like the second order potential consequences of actually proposers themselves changing that center. Right. By running more attestors, let's say.
00:49:24.640 - 00:49:30.540, Speaker A: Oh, I see. So you're saying the proposers and the attestors start colluding.
00:49:32.260 - 00:49:33.360, Speaker B: Integrating.
00:49:33.940 - 00:50:38.308, Speaker A: Right. Definitely. More research needs to be done on timing games in general, like, just zooming out a little bit. There's something that I call the cycle of FUD, which is that there's this important topic that for years we just ignore, and then suddenly we discover that this topic is important, and then, like, fud goes to the moon, and then we start doing research and we start understanding things, and then we start doing technology, and then Fud starts going down. And I think for timing games, we've kind of ignored it for the last three years since, since the, or even more, you know, during the design phase of the beacon chain. And admittedly, we were extremely unsophisticated. And things like the honest proposer spec, where we kind of dictate that the proposers act in a certain way just because we wrote the spec and we feel entitled that they act a certain way is just very unsophisticated from our part.
00:50:38.308 - 00:51:23.090, Speaker A: And I think just a few weeks ago, one of the Lido operators, ptp.org, which also happens to be founded by one of the co founders of Lido, started wrote this post where they were saying, okay, we're playing timing games and it's great because we're getting more mev at the expense of everyone else. And so that's maybe a reason for you to use our service. And it's been a hot topic, at least within the Ethereum foundation. And so I think we're close to the peak Fud, and I'm hopeful that over the next few weeks and months, we'll be in a position where we understand the design space much better and can be more relaxed about it.
00:51:26.500 - 00:51:56.490, Speaker D: Hey, Justin, cool stuff. Just a question. Might the builder role and the proposer role have similar degrees of sophistication and capability? And obviously there's a relay in between there, too. And does this potentially break down the separation between the builder and the proposer? I. E. I'm a great builder, therefore I'm a great proposer. It's not totally clear to me, but might there be an advantage to a vertically integrated builder proposer in this model?
00:51:58.060 - 00:52:59.912, Speaker A: Yeah, it is possible that there will be this convergence of searcher builder proposer. I mean, Max just said that in his talk, that that was his prediction, or actually with the relay, I should say like searcher builder relay, but it might also extend to the proposal. And in a way, you can cut the mev pipeline down the middle, where you have the first phase of the pipeline, which is all about extraction, and then you have the other phase of the pipeline, which is all about distribution. Right. The proposer is kind of at the boundary where they start receiving all the mev, but everything before that is on the extraction side of things. And you're right that there's a lot of skills that are kind of common to all the entities. So, for example, being like low latency networking experts is important for all the roles.
00:52:59.912 - 00:53:34.810, Speaker A: And as a proposer, that's basically the only skill that you need, because it's very simple. You just receive these bids and you pick the highest bid. Like, computationally, there's almost nothing going on. Algorithmically, there's almost nothing going on. It's just purely a latency game. And then when you go up the stack and you increase the entropy, then you start adding more and more resources. So, for example, as a builder, if you're a pure builder, like Titan, you have a lot of computation, and you might have some algorithms, but you don't have capital, right.
00:53:34.810 - 00:53:39.316, Speaker A: Kyui, can you confirm that you guys are not running? Confirmed. Yay.
00:53:39.508 - 00:53:41.124, Speaker D: Not enough capital, clearly.
00:53:41.252 - 00:54:12.004, Speaker A: So QB is very poor, has no capital, but he can still operate a very good builder. And then you go up the stack, you want to be a sex arbitrage, and now suddenly you need tens of millions of capital, and you need exposure to dog tokens and stuff like that in order to be profitable. And then if you're in a tester, then you need almost no skills. You just need to observe whether or not a block came in, and you need to sign a transaction, and that's it.
00:54:12.202 - 00:54:24.570, Speaker D: I want to just challenge one thing. Doesn't the proposer have discretion over how many tickets they buy? So the proposer does need sophistication to determine the future value of the slots that they're bidding for, right?
00:54:25.420 - 00:54:50.320, Speaker A: Yes, but this is like a statistical thing that is fairly commoditized. This goes back to this slide here, which I'm kind of shocked by, which is this one. It seems that if you zoom out and you look at the big picture, it's like 800 e per day of Mev, and that's it.
00:54:50.390 - 00:54:53.650, Speaker D: So there's just not enough variability to really play the game.
00:54:54.660 - 00:55:18.090, Speaker A: Sure. And what I'm hoping will happen, or what I think will happen, is that this line will start going down, so the gradient will go down, and this is what I mean by Mev going to zero. Great. Okay, so now I guess we could do the panel. We have about half an hour, is that right? 20 minutes. Okay, perfect.
00:55:20.540 - 00:55:22.330, Speaker B: 30, counting Q and a.
00:55:23.680 - 00:56:20.856, Speaker A: Okay, perfect. So I guess I did have a little bit of a presentation to tee up the panel. I'll just go for it super quickly. So one of the things that I want to be very precise about is Mev going to zero, meaning MeV that leaks to the proposer, and that's like the total value of the bid. So what I'm hoping will happen is that this gradient, 800 e per day, will go down, let's say, to 80 e per day, will go down by an order of magnitude, or maybe two orders of magnitude. And one of the observations is that there's two aspects of MeV, right? There's the extraction phase, and then there's the redistribution phase. And as a consensus researcher, I guess at the firm foundation, we've put all our focus on the infrastructure.
00:56:20.856 - 00:56:58.852, Speaker A: That's where the spotlight has been. And really, you could summarize it as coping with MeV. We just receive all this mev that flows from l two to l one, and we need to cope with it. So we have strategies like inclusion lists, like Enshrine, PBS, like Mev Burn to deal with this mev that's kind of unwanted, but we just receive it. And then there's the other aspect, which is kind of the source, the creation of the MEV, which is the applications. And I'd say this has only received 10% of the attention it's compared to the infrastructure. And so I think there's a lot of low hanging fruits to just doing better applications that don't create more MEV.
00:56:58.852 - 00:58:09.980, Speaker A: And roughly speaking, most of the MEV falls in these three categories, sandwiches, arbitrages, and congestion. You know, the first two, let me just briefly explain the last one, which is that with EIP 1559 and the parameters that we set on Ethereum today, which is that the target is half the limit. About 10% of blocks reach the capacity. And so usually congestion is not an MEV problem because you burn the base fees, but in these 10% of blocks, you fall back to this first price auction, and then congestion does become an MEV problem. And one of the things that I'm hopeful will happen is that as we have data availability for hundreds of roll ups, if there is a congestion in one or a few of the roll ups, that's actually not going to lead to congestion on the data layer, because you're smoothing out across all the relays. And so I'm hopeful that with dank sharding, maybe only 1% of blocks will be full, as opposed to 10%. And so congestion mev goes to zero, and sandwich and arbitrages go to zero with designs like Sorella and Cal swap.
00:58:09.980 - 00:59:02.732, Speaker A: Okay, I'll just skip this and go straight to the panel. So I'd like to invite some initial panelists, Andrea from Calswarp and the fine folks at Sorella, Ludwig and Kartek. So I guess my first question, and I want to kind of gauge the temperature from the audience, is, who thinks here that MeV will go to zero? Okay. Who thinks here that Mev will not go to zero? Interesting. So this is what I expected. 80% of you guys think that Mev will not go to zero. And so this is one of the reasons why I think it should be a fun debate.
00:59:02.732 - 00:59:09.536, Speaker A: Let's start with the two folks from Sorella that raised their hand. Why do you think MeV will go to zero? Yeah.
00:59:09.558 - 01:00:40.876, Speaker D: My intuition is that MEV, in the current context of going to the proposer, is a result of this battle for block space, right? And it's a result of different payoffs for different orders. If you look at a specific block and you partition all the transactions in the block that interact with the same state. Now we can kind of have this notion of sections of a block that have irrespective ordering. They don't touch conflicting state, so they can be ordered in front of one another or behind one another, and there's no different payoff. Now, if you look in within those sections and see exactly where this value, this battle for getting to the top, to be the first to touch some specific contested area, perhaps a storage slot, if you look at the value that's extracted from that, presumably coming from the expense of a swapper, the underlying LP, perhaps. And instead of saying, let's bid this value back to the proposer, because it's obviously getting priced in whatever auction mechanism we assume in competitive equilibrium, let's say, now we just highlight who the actual adversely selected party is and have the auction done and return that value back to that adversely selected party. And the actual frontier for this is far better for everyone involved, right? Because now we have accurate pricing from these sophisticated players who are always going to be doing these arbitrage opportunities, but we actually have repayment to the underlying party that is adversely selected.
01:00:41.068 - 01:00:52.516, Speaker A: Right, so you're saying there's this rebate mechanism back to whoever the user is. The user could be some sort of swapper and then you don't have the sandwiching, or it could be the LP. Yeah.
01:00:52.538 - 01:00:57.300, Speaker D: Or more generally just whoever is kind of selling off this opportunity, right, because.
01:00:57.450 - 01:02:16.828, Speaker B: I guess what that comes to in the abstract is blockchains are slow, they don't have off chain information, and we're paying people to provide that information on chain, at least for the sex Dex form of MEB. If you're able to ensure that they are paying the people that they're extracting and controlling their ability to extract from that asymmetry of information at the application level directly that MeV to the proposer disappears, will that MeV disappear completely? No, in the sense that it is just moving up a layer. Right. There is still some rent to be paid to the stat arbor that is arbitraging against a pool, even if they're paying the LP directly, because they wouldn't be doing it if they weren't profitable. This isn't an easy thing to do, but will it happen at the underlying block level? I don't think so, because it is an additional rent that has to be paid and the proposer doesn't actually have the underlying control of this. We always operated under this assumption that the proposer is the be all end or, and in some sense that is correct. They get to decide which block gets proposed at a specific slot.
01:02:16.828 - 01:02:55.420, Speaker B: But if you gate the underlying execution of a pool behind some alternative proof, that has to be posted. Well, if the proposer is trying to include a transaction that paid them the most, but they don't have that key that unlocks that pool, it doesn't really matter. The execution will revert and then nothing's been extracted. And then that extraction is delayed to the next slot where another proposer that is acting rashly will want to include that transaction that does go through, and that went through the proper process to actually auction it off and redistribute that value back to the people that were being affected by that extraction.
01:02:56.080 - 01:03:10.348, Speaker A: I guess what you're saying is that the proposer doesn't have to be the sequencer. The application can choose whatever sequencer they want and then that sequencer can be tailored to capture the MUV and then give it back to the users.
01:03:10.444 - 01:03:41.620, Speaker B: Yeah, and it has to be done atomically. If you split it up into multiple transactions for a same auction, that breaks because then the builder has the ability to reorder at will. Or you can create a dependency between these transactions to force ordering so that if they modify that order in any way, then it invalidates their underlying execution. But that seems less efficient than just bundling up the transaction itself. Because you shave off on the overhead.
01:03:41.780 - 01:04:11.830, Speaker D: The goal should be like the maximum amount of mutually exclusive bundles, if that makes sense. So every bundle should be packaged in a way such that this is interacting with different state off chain ordering based on whatever we're trying to maximize the payoff to whoever party, to whichever party. And then however many of those exclusive bundles submitted to the proposer, to the builder. Now, the ordering of those exclusive bundles doesn't matter, right?
01:04:12.600 - 01:04:57.184, Speaker B: And this fixes sext, but for sandwiching Andrea, he gave the talk yesterday. That solves it, right? If you have an amm that operates within batches, blocks are naturally poised for that, then you don't have that problem anyway. So this idea that we should open up the pool and then everyone should be able to transact within a block. Okay, just do it within a single transaction, bundle it up, and then nobody's going to mess with your orders. Everyone gets the same price, and that completely removes that problem. Looking at liquidations, same thing today. Ave has this permissionless liquidation system, and everyone is bribing the builder, and the builders are bribing the proposer a significant amount.
01:04:57.184 - 01:05:23.048, Speaker B: And if you look at the profit margins of these liquidators, they're extremely small. But that value is being bribed back to the proposer, not to the liquidatee. If you had an auction mechanism that is application specific, and you gate the ability to liquidate behind some proof of consensus for your application specific logic, you have the same result. Now they're bidding back that value, but instead of biding it to the proposer, again, you bid it back to the.
01:05:23.054 - 01:05:28.588, Speaker A: Liquid at Andrea, you disagreed on Mev going to zero.
01:05:28.754 - 01:05:29.470, Speaker D: Yes.
01:05:29.840 - 01:05:59.424, Speaker E: I told you earlier that I believe MeV will go to zero just to be invited on the. I lied. So let me. Yeah. What we saw yesterday, how it is possible to build a different type of amm that eliminates arbitrage, profit, and sandwich attacks. Those are kind of, I guess, 80% to 90% of MeV. As Ludwig was saying, the same logic can be applied to liquidation in the context of lending protocol.
01:05:59.424 - 01:06:51.040, Speaker E: We've done some work on that. Also at Cowswap, that is the vast majority of the remaining MeV. Then you still have stuff linked to nfts or things like this, for which one can think of other methods, like ENS uses a very simple commit revealed schemes to prevent front running in their application. Those schemes, they are simple and could be potentially extended to other application. So, I mean, essentially, just with the technology that we have available, or soon we'll have, we can maybe get rid of, like 95% of MeV. So, not zero, but I hope that at one point, we'll get to a level where we don't care anymore, like whether it still exists, because, of course, new application will come online, and we'll have to figure out if they generate MeV. We'll have to figure out how to counter that at the application layer.
01:06:51.040 - 01:07:33.456, Speaker E: But at one point, the infrastructure layer will not have to worry about this. And I think to some extent, yeah, as you mentioned, we had two presentations about MeV at the application layer in these two days. So far, there were many more that mentioned MeV in the context of infrastructure. So there is this gigantic effort into trying to handle meV, MeV, decrease censorship. So we want to do something about censorship, so on and so forth. And to some extent, I was thinking like why is that? That we are spending so much time and effort to thinking about MBA and infrastructure layer? It might have to do that. We are a multidisciplinary crowd.
01:07:33.456 - 01:08:02.760, Speaker E: So there are the computer scientists, the economists, the people from finance, and I think if you have a computer science background, perhaps especially a cryptography background, the idea that your system sort of phase one, 2% of the time is unthinkable. There is one edge case which doesn't work. Then we all sit down and find a better system that takes care of it. I'm an economist, so we have a target. We are a little bit far from the target.
01:08:02.920 - 01:08:04.172, Speaker B: It's good enough.
01:08:04.306 - 01:08:16.288, Speaker E: We are not that picky. And I hope in some sense this logic will percolate through the community. And so, okay, if we have a system that takes care of almost all of MeV, then fine, right?
01:08:16.454 - 01:08:47.630, Speaker A: I guess one of the things you said is that when new applications come in, there's kind of this two phase process where first the application is kind of MeV naive, and then it's kind of tested out, and then it matures and it becomes MEV aware. And we're this transition point of awareness for some of the big ones, like dexes and maybe liquidations. And then what's possible is that ethereum grows so fast that we have so many new applications that the unsophisticated applications start dominating again.
01:08:49.280 - 01:10:09.472, Speaker D: I guess there's also this notion of what exactly MeV is right, like MeV as a concept has kind of gone through many rebrandings over the past few years when it's been studied. And I think that what we should hope to have as we progress as an industry, is this notion of like, let's be cognizant that extraction is always going to exist. They're going to be sophisticated players, they're going to compete against one another, and they want profit amortized at the end of the day. But now let's in the asymptote, make them compete in such a way such that any strategy extractive that they're running converges to whatever risk free rate is. And the actual adversely selected parties are somewhat cognizant, or they express willingness to, I guess, pay for whatever the arbitrage or the ren extractor is taking from them in the end result of the position they have. The canonical example is what Andrea mentioned yesterday, where if I have a liquidity position with ambient liquidity on an FMaM, essentially that is me paying for the right to have a 50 50 rebalancing portfolio and there's a price that a lot of people associate to that. That then that cost would be what the sophisticated arbitragers are extracting in rent from them to have that strategy.
01:10:09.616 - 01:10:28.590, Speaker A: Right. I guess that was very similar to one of your previous comments, which is that there's some cost of mev, which will bear on the user, which will be like paying all the salaries of the SAT arbors, paying for all their cloud bills, but also paying for their capital cost as well as their strategy cost.
01:10:29.360 - 01:10:33.212, Speaker F: But it's like paying for services, so I wouldn't even consider it.
01:10:33.266 - 01:10:33.944, Speaker E: Mev.
01:10:34.072 - 01:10:34.508, Speaker A: Yeah.
01:10:34.594 - 01:10:51.932, Speaker B: And I think it's important to remember that we pay their bills, and this is kind of a different view of it. They're extractors, right? They're there to make profit and they haven't been authorized. They just found the loophole.
01:10:51.996 - 01:10:52.272, Speaker A: Right?
01:10:52.326 - 01:11:21.144, Speaker B: They found the crack in the system. If we design systems with them in mind, we can repurpose them because they're very smart. Like, these people are extremely good at what they do. If we have them work for us, because they're going to be there anyway. They can provide that information at the lowest amount of latency. There's so many crazy examples of HFTs doing extremely crazy things. Jump had a group that was focused solely on finding the craziest ideas possible to shave latency.
01:11:21.144 - 01:11:42.704, Speaker B: They wanted to drill a hole through the earth to have a fiber optic cable to save on the amount of time it would actually take to provide the information. They didn't do it. But this kind of goes to show the extent at which they go to be the best. So if we have them work with us instead of against us, we can benefit greatly as an industry in terms of efficiency.
01:11:42.832 - 01:11:44.390, Speaker F: It's an alignment problem.
01:11:46.280 - 01:11:55.688, Speaker A: So I have many spicy questions prepared, but we don't have much time, so I'll just go for the spiciest of all, interject. Yeah, go ahead.
01:11:55.774 - 01:12:01.210, Speaker F: There was something that Andrea said that I wanted to kind of counter. So I agree with him that.
01:12:03.660 - 01:12:03.976, Speaker A: If.
01:12:03.998 - 01:12:39.840, Speaker F: We look beyond Defi, as the economy grows, new types of MeV will come in and we'll learn at the application layer to minimize them. But the part where I disagree is that I think at the infrastructure layer, we cannot stop worrying about it, because there will always be, like, in the success case of Ethereum being this dynamic economy that grows, there will always be leakage. And, yeah, even though it's not like a big threat, we need to be ready to actually handle whatever residual mev gets to the infrastructure.
01:12:39.920 - 01:12:40.116, Speaker A: Yeah.
01:12:40.138 - 01:13:14.304, Speaker E: So I guess what I meant is simply that right now it seems to drive and almost dominate a lot of the work that is done on the infrastructure layer. And my hope is that it will be one of the things that you guys worry about, but not the main driver of the thing. So my hope is that in 2025, there will not be a panel about MeV. Right. Because it will be considered as, okay, we know it's a problem, but we have other things that we want to discuss that we think they're more important.
01:13:14.422 - 01:14:07.570, Speaker B: It's fair. Also, what are we so worried about in terms of residual? I just might lack creativity, but the long tail MeV that we see is oftentimes laughable in terms of just how poor a specific application might have designed, some functionality that leaks an immense amount of value, or some really rare niche case that you see in it. You're at the point where you have to admire them for them coming up with the idea of extracting, but knowing that it's never going to happen again. So for those really poorly designed things, I think as we create these off the shelf solutions for applications, it's going to be far simpler for application designers to integrate them. Because today, Mev, now that we're cognizant of it, seems more of a problem of ignorance from application designers rather than a fundamental problem.
01:14:08.020 - 01:14:34.408, Speaker F: Yeah, but you do need some imagination. Like we are thinking about the longer term, right? Let's say that there is a complicated strategy game and now suddenly there is a lot of value being transacted there. There can be something that, it's beyond the token exchange that we see today, and maybe for one year or a few months, there is a ton of MeV. But then there's going to be this process that people like you are going to figure out how to solve it.
01:14:34.494 - 01:16:02.950, Speaker A: But anyway, okay, so I don't want to make time for this spicy question, which is basically Shermac's question, which is, can we really increase the slot time? Can we increase it to 60 seconds? And I think there's like big reasons for increasing slot times. And it has to do basically with the way that ethereum works, which is that we have lots and lots of validators and therefore attesters, and all the attestations need to be aggregated within the slot duration. And if we want things like single slot finality, we're actually adding a round of attestations. If we want to do things like enshrine PBS, we're also adding another round of attestations. And if we want to, for example, reduce the minimum amount of staked eth from 32 to something lower, then guess what? We're also increasing the number of attestations because we're increasing the number of validators. So increasing this lot time really gives us a lot of flexibility and opens up the design space for Ethereum and can make it much more better designed, better suited to be this settlement layer for the entertainment of value. But then there's this counterargument which is like, wait, if we increase the slot time to 60 seconds, doesn't that blow up the amount of sextex mev? And I guess the question to you guys is, is that true?
01:16:03.480 - 01:17:12.700, Speaker B: No. Worried about that at all. If that happens, you'll just have the alternative application layer, right? That has to have an auction and form this consensus. It'll just run these specific batches with a specific time frame within the block itself. So not only will the bulk of the sex decks actually be bribed back to the LP regardless, but you also have very much control of how long the batch times take to form completion, right? So I don't think that should be a concern of kind of lengthening the slot time. I think rather we should think of other applications that might kind of benefit from shorter or longer block times. But the financial one, given how valuable it is, and the natural value that can be extracted, the infrastructure to provide the required services to make this possible will exist and will be justified given that the value is there.
01:17:12.850 - 01:17:13.452, Speaker A: Right.
01:17:13.586 - 01:17:18.124, Speaker D: The intuition of like outsourced application. They're operating.
01:17:18.172 - 01:17:19.330, Speaker A: I knew you would come.
01:17:19.860 - 01:17:22.864, Speaker B: Incoming censorship resistance tool waiting for you.
01:17:22.982 - 01:17:23.312, Speaker A: Okay.
01:17:23.366 - 01:17:54.972, Speaker H: Yeah, I just wanted to jump in on slot times. I think it definitely does increase the overall MeV when you increase the slot time part of that, there's a super modularity of the more transactions you have, the more they interact with each other. And so the more contention you have, the more congestion you have. These are both drivers of MeV. And of course we know the more time there is for the price to move. And some folks in the audience have shown very rigorously that this increases the overall MeV when you increase the slot time.
01:17:55.026 - 01:17:58.556, Speaker B: I mean, with the current paradigms of amms, yeah, of course the idea would.
01:17:58.578 - 01:18:31.704, Speaker D: Just be like outsourced application have arbitrary application section times. Each application would have their own pre confirmation list, and then they have a block ordering from that pre confirmation list, which can be like 200 milliseconds, for example. I think this also addresses the problem of what you, Justin, call super linear Mev, where it's like if we look at the actual bids that are coming in towards the end it's linear throughout the block, and then towards the end it spikes up.
01:18:31.742 - 01:18:32.040, Speaker A: Right?
01:18:32.110 - 01:19:45.676, Speaker D: And this is purely a function of pricing and volatility. So if market makers in traditional finance are good at one thing, it is extracting out of the difference between what the implied volatility they price, what the futures that they market make on, and what the actual realized volatility is. Like 80 90% of the time they're actually pricing the implied volatility higher than what the realized volatility is. And if I, as someone who's placing the bid to build a block at 1 second into the block, not knowing what the exogenous price is going to be, I am going to do it in expectation to where I think the discrepancy between whatever the decentralized prices are and the volatility that I've seen in the past and where that's going to result in the final block time. Right? But as we get closer and closer to the end of the block, now that information gap is different, now it becomes very clear what the price is going to be and everyone has to convert to that price. So we spike up towards the end because there's no rent for me to extract from the discrepancy between implied and realized volatility. And as we move this kind of pre confirmation window down on the application layer, there's zero rep that can be extracted there, right? Because 200 milliseconds out, that's very easy for anyone to price.
01:19:45.858 - 01:19:56.530, Speaker B: And just to be clear to everyone, we are not saying that a 62nd block time would be good for current AMM designs. It would be absolute suicide. Like it would destroy them.
01:19:57.400 - 01:19:59.670, Speaker A: Who do you want to kick out? I don't know.
01:20:07.640 - 01:20:35.640, Speaker G: Hi, I just had a question about off chain batch auctions. It seems like on your quest to minimizing mev so much, you might actually do it at the expense of users prices. Because what happens in a block is you have a bunch of market makers and people that are arbitraging in between transactions. But if you're taking that whole block, that whole batch off chain, then you might on average actually have a worse price for users just to minimize the mev at the end of the block.
01:20:35.720 - 01:20:48.924, Speaker D: Well, given that a lot of users are transacting in this batch auction, market makers are incentivized to integrate in and see what the actual demand on the bid and ask side is in the batch auction from users and then market make accordingly.
01:20:48.972 - 01:20:52.776, Speaker G: Right, so then you're moving me into the batch instead of having it in the block.
01:20:52.828 - 01:21:24.268, Speaker D: Yeah, but their extraction isn't based on ordering, it's based on price that's exogenous. So now I see what the centralized price is. I see the implied price of whatever retail flows in my batch. I'm willing to quote this much based on what the centralized price is, but there's no ordering that can occur because everything's at a uniform price. What, sorry, it's cleared at a uniform price. So your order and then my order, we both get the same price of clearing, same with the underlying lps. So it's very difficult to arbitrage against anyone because you're executing at the price that everyone does.
01:21:24.434 - 01:22:09.356, Speaker H: I want to make a couple of points about off chain batch auctions. First of all, it's off chain. So that's not necessarily the goal for me, at least with blockchains, is to have things that actually operate on chain and don't have trusted third parties. And I include SGX based systems in that as well, because it's literally in the name trusted enclave, trusted third party, basically. So that's the first point. And the other point is, it does affect mev when you increase slot time, even if everything is batched. And the reason is when you have batch systems, you basically increase the amount of exposure that market makers have, and they will charge you for that.
01:22:09.356 - 01:22:47.640, Speaker H: And so the longer your batch system takes to clear, the more tension is right at the end of that batch. And there's a couple of papers on this. In the original Budhist crampton shim paper, they have a certain price process. If you use jumpy price processes, then that tension can become quite expensive. And so it's still important, even if you're doing off chain batching, to keep that slot time short and keep the exposure of the market makers limited. Otherwise they're going to have to charge you for it. And that's going to be MeV that's leaked.
01:22:47.980 - 01:23:00.236, Speaker B: This is true if you have a batch time that matches the block, which is not what's being proposed. Like you wouldn't have a 62nd batch because then you would have the problem that you mentioned. And also on the off chain part.
01:23:00.338 - 01:23:01.596, Speaker E: Yeah, maybe I can.
01:23:01.778 - 01:23:02.076, Speaker A: Yeah.
01:23:02.098 - 01:23:59.010, Speaker E: So, I mean, Koso, resize it as an off chain batching. So the whole process of collecting orders, putting it in a batch, and then auctioning off the right to execute those order is done off chain. And I would agree that it will be better to do it on chain or through something like some of the new things that are coming out like suave or like an enclave to give more guarantee. I would not take it as a point of there is an onchain element, provides guarantees, because the worst thing that can happen is that a solver that misbehaves makes everybody transact at their limit price. So the gain is not that large and is immediately visible, and we can slash those solvers. So, I mean, it will be better, but I don't think it's a deal breaker in my view. And as the ecosystem matures with new solutions that are coming online, this will for sure change in the future.
01:23:59.010 - 01:24:51.264, Speaker E: Like I said, I'm an economist. We are not at the best possible. We are a bit far from it, but it still, I think, provides good guarantees. And with respect to the block time, I mean, what you're referring to is a possible worse execution if you increase the block time. I think this is distinct from Mev, in a sense that market makers will face maybe more risk and more cost, and this will be passed on to users in the form of worst execution time. But the whole idea that market makers are making a profit at the expense of liquidity provider will still disappear. In a sense, both arguments that were made by Max and by Kartik are valid in a sense, because they're referring to two different things.
01:24:51.382 - 01:24:52.050, Speaker A: Right.
01:24:52.820 - 01:24:55.552, Speaker G: Mike, is this on?
01:24:55.606 - 01:24:56.256, Speaker A: Okay, cool.
01:24:56.358 - 01:25:57.264, Speaker G: Just to kind of continue following on Max's point for like, steel manning, the shorter slot time argument. Yeah, I guess I also see this trend of moving stuff off chain as kind of a concession insofar as the transactions that are happening off chain, and these actions are like, they have different settlement assurances and kind of different security properties. So I guess to ask the panel, do you see it as an okay situation where a bunch of the execution happens off chain, but the kind of settlement, and I guess, end state stuff happens on the Ethereum blockchain, or is it better to have more of these things happening on chain, have the same settlement assurances for all the transactions, and encourage that on chain activity rather than. I guess, to me, it feels like the panel theme is not about mev going to zero, it's just mev going off chain. And that doesn't actually necessarily feel like the best outcome, but would be curious to hear the panel's thoughts.
01:25:57.312 - 01:25:57.956, Speaker A: Thanks.
01:25:58.138 - 01:26:32.130, Speaker B: I think you have a great point. At the end of the day, it depends on the off chain piece, right? If we're talking about a single database that I run in my basement, that's very problematic. If we're talking about a system that naturally centralizes and very few actors can actually participate in it. Yes, that's a problem. The problem here is we're dealing with Ethereum. That is not that powerful of a computer. So if we could do these things on chain, it would be great, but we can't today.
01:26:32.130 - 01:26:45.750, Speaker B: So you have this problem that we're all facing. That is you're putting blockchains on blockchains. Is it ideal? I don't think so. But that is an Ethereum problem and not so much an application designer problem.
01:26:46.520 - 01:26:52.100, Speaker H: But the solution to Ethereum not being a very good computer is to make it a better computer, not to make it a worse.
01:26:53.480 - 01:27:13.736, Speaker B: I. Max, I don't disagree, but this is out of my hands. You know what I mean? Let's just go on, Solana. At that point we can call it a day. There are different trade offs that you're making, right. Ethereum has been very clear on their vision of their trade offs. If we're not happy with them, we can decided to move our applications on different venues.
01:27:13.736 - 01:27:16.444, Speaker B: But they're sacrifices, they're tensions that are play.
01:27:16.562 - 01:27:38.550, Speaker H: Yeah, I agree to some extent. But even if we work within, if I put myself with the same preferences as Justin, I think there's work that we can do that would still allow solo staking, still allow consumer hardware and make Ethereum a better computer with more throughput and shorter slot times.
01:27:39.960 - 01:28:06.272, Speaker E: I think I'll disagree with this idea that MeV is moving off chain. So obviously off chain has a trust assumption. So I'm cowswap. I announced that I'm going to just choose the winning bids among various solvers purely based on how good they are for our traders. Now you have to trust me to do that, of course. But of course, if I stick to my promise, there is no Mev. I'm not extracting anything.
01:28:06.272 - 01:28:53.180, Speaker E: I'm announcing the best for my users. Okay. The on chain part provides a floor to, if I do decide to misbehave, how bad is going to be, how much I can gain and how bad is it going to be for my user. And so the on chain component is very important because then we enter into a situation where even if I don't behave as I should, the benefit to me and the cost to my user is bound by what the smart contract says. On the other hand, it's observable by everybody that I misbehaved and I'm losing my entire business. From now onward, the interaction between the. So the on chain is still important, right? Although it's in this outside option worst case scenario element.
01:28:53.180 - 01:29:21.284, Speaker E: I think in both our design, the batch operator can still misbehave, in which case the amm behaves exactly like a constant product amm as it is now, but everybody sees it, that this operator that was supposed to be trusted is not trusted anymore, and you assume that everybody would just go elsewhere. So it's more complicated than just, say, because it's off chain. I don't trust it because the on chain still stays as a floor to what can happen.
01:29:21.482 - 01:29:40.008, Speaker B: Yeah. We have decentralized peers that operate on the basis of execution clients. Ethereum execution clients. Right. So you can have a model like that. You can have a decentralized model. You can have robust off chain components, especially if you're focused on a specific goal.
01:29:40.008 - 01:29:49.816, Speaker B: And we're not moving it off chain so much as we're dealing with the MEV off chain, but distributing it to the parties. That would be losing money otherwise.
01:29:49.928 - 01:29:57.928, Speaker D: That's the important clarification. MeV is not moving off chain. MeV is getting solved with off chain compute, which is just more efficient.
01:29:58.104 - 01:30:08.516, Speaker A: Right. We need to wrap up. Thank you guys so much. This was a great panel. Those, I think, four questions that are still to be answered. So let's continue discussion afterwards. Thank you so much, guys.
01:30:08.618 - 01:30:09.510, Speaker B: Thank you.
01:30:15.480 - 01:30:18.130, Speaker A: Yeah, close.

00:00:04.760 - 00:00:21.980, Speaker A: Okay, welcome back everyone. We're going to get started for the next session. Session three with Ari, Jules and Threeram. The first talk from Ari will be on rethinking.
00:01:16.370 - 00:02:00.482, Speaker B: The d in Dao. The decentralization part in particular my talk is based on. This doesn't seem to be. Yeah, I'm not seeing. Okay, let's try this again. Talk is based on this paper, which we released just over a month ago on archive. You can find it at the URL shown at the bottom of the screen or in the QR code.
00:02:00.482 - 00:02:42.100, Speaker B: We've also begun to release some blog posts describing in informal terms the concepts in the paper. Dows, as you probably know, have been increasing in popularity, especially recently. There's been quite a spike in interest, and currently Dow treasuries hold something on the order of $25 billion. Dows are used for a wide range of purposes. One of the best known dows Makerdao, for instance, is a DFI protocol that allows for lending and has an associated stablecoin. Bitdao is essentially a community run investment fund. General purpose investment fund.
00:02:42.100 - 00:03:40.450, Speaker B: Avocado Dao is a particularly interesting Dao. It's a gaming guild. It draws together a community of play to earn gamers and will acquire nfts to loan to them for gameplay. PleaserDao is an investment fund that focuses on nfts and famously acquired the well known doge NFT, which they subsequently fractionalized. Constitution Dao, which is one I'm going to talk about in a little bit more detail later in the talk was a Dao that brought together a community who wanted to purchase a physical copy of the US constitution at auction. I'll talk about how that turned out. And finally, just to give you some sense of the breadth of application of Daos, there's Dave Dao, whose purpose is to draw together a community of people named David just to give you some sense of what you can do with Daos.
00:03:40.450 - 00:04:26.142, Speaker B: As I'm sure all of you know, Dao stands for decentralized autonomous organization. The autonomous part refers to the fact that a DAO typically runs as a smart contract on a the term organization is more or less self evident. The tricky term to interpret, I would contend, is the decentralization. Decentralized part of a dow. Decentralization, of course, has multiple layers in a blockchain system. There's the consensus layer, which ideally involves the contribution of a disparate and independent set of entities. There are questions to be raised around centralization or decentralization.
00:04:26.142 - 00:04:58.718, Speaker B: When you look at code creation and maintenance is, for instance, code maintained by a small set of core debts. That would be a form of centralization. One that people particularly focus on is asset ownership, and asset ownership is related to the concept I'm going to talk about today, namely governance. This will be the focus of my talk. Now, I'm going to assume that when we talk about a Dow smart contract, it's bug free. There are no backdoors. Basically that it does exactly what it's advertised to do.
00:04:58.718 - 00:05:30.470, Speaker B: And so the focus will be, in particular on the implementation of decisions through voting and elections. Now, when you ask yourself or you ask others, what decentralization means, sometimes terms will come up like credible neutrality and so on and so forth. To motivate my talk, let me give you an example. Whoops.
00:05:33.970 - 00:05:34.862, Speaker C: Motivate the talk.
00:05:34.916 - 00:06:31.330, Speaker B: Let me give you an example. Let's consider two dows, minodao and whale dao, shown here. These pie charts show you token ownership by address. Each wedge in each pie chart corresponds to the token holdings of a particular address. And let me ask you, which of these two is more decentralized? Your instinct or knee jerk reaction would probably be to say that minodao is, of course, more decentralized. After all, the tokens are distributed in a more egalitarian way among a larger set of addresses than in whale Dao. But is it really? One thing that we know about ownership of tokens or crypto assets in general is that it's possible for one person or one entity to control multiple addresses.
00:06:31.330 - 00:07:06.682, Speaker B: So it could well be that the real situation is as follows. Whale Dao has five whales, who among them own all assets. Minodao has lots of different addresses, but it actually turns out that the lion's share of those addresses are owned by one individual. There's a puppet master, puppet master Alice here who actually controls a majority of the assets. In this case, of course, Minodo is actually more centralized, less decentralized than whale Dow. Okay, well, you could say this is sort of a corner case. Unlikely scenario.
00:07:06.682 - 00:07:38.710, Speaker B: Let's suppose that, in fact, it's one address per person. So now, which is the more decentralized? Well, now, of course, you can say Minodao is the more decentralized. But is it really? Consider the following scenario. Suppose that a yes no vote is taking place, and the outcome is determined by a majority vote. And additionally, there's no threshold here. We don't care how many people vote. However many people vote, the outcome is binding.
00:07:38.710 - 00:08:21.186, Speaker B: But there are 100 voters in Minodao, and 97 of them just don't vote. In this case, effectively, there are three voters controlling the outcome of a vote in Minodao, but there are five in whale Dow. So in fact, Minodao is the more centralized, the less decentralized. Those are two examples, but there are a lot of other examples of hidden centralization, if you will. For example, suppose that a majority of Minodao voters are bribed to vote. Yes, bribery is clearly a centralizing force. This is something happening behind the scenes.
00:08:21.186 - 00:09:24.314, Speaker B: You wouldn't see this in token allocations. Or suppose that Minodao voters just happen informally to vote the same way because they all belong to the same investment club. This would also be a form of centralization. Now, when people think about what decentralization means in informal terms, they'll use phrases like diversity of viewpoints. It's clearly important to enforce decentralization in government to have a governance to have a diversity of viewpoints. Another term that often crops up, as I mentioned before, is credible neutrality. Perhaps the most rigorous metric that people use for decentralization today, and it's a commonly used one, is entropy, or related concepts like the Nakamoto index, which is the minimum number of participants in a system, decentralized system required to control the system, or one.
00:09:24.314 - 00:10:23.740, Speaker B: You've probably come across the genie coefficient, which is a measure of wealth inequality that's typically used at the national level. Here, for instance, you see countries shaded according to their genie coefficients, and so you see a very low genie coefficient. It's actually a measure of income inequality. You see a low genie coefficient for instance in Scandinavia, and a high genie coefficient in certain places like southern part of the african continent. So, as I said, entropy is a popular metric today for measuring decentralization. What do I mean by entropy? To compute entropy, you pick a token uniformly at random from the entire set of tokens in a dow or whatever you happen to be studying, and this induces a probability distribution. Let p sub I be the probability that when you pick that token, it comes from address I.
00:10:23.740 - 00:11:37.010, Speaker B: Given this probability distribution, you can compute the entropy using this formula here that you've probably seen before. This is the formula for Shannon entropy and minodao by this metric has high entropy because tokens are distributed evenly across a large set of addresses and whale dow has low entropy. But the problem with entropy is that it's insensitive to key forces that result in centralization. Like the examples I gave you earlier, entropy won't pick up on the fact if you're computing entropy over addresses, at least entropy won't pick up on the fact that a majority of addresses may belong to one person, it has no way of gleaning that the vast majority of voters in a given Dow are not voting. We refer to, and I'll refer to this again later, refer to a large pool of non voting voters as an inactivity whale. Entropy is not going to pick up on the fact that you've got a huge inactivity whale in your dao, and similarly, it's insensitive to bribery, rampant vote buying. There's no way to capture that with entropy alone.
00:11:37.010 - 00:12:29.438, Speaker B: Basically, any form of strong alignment has a centralizing influence and is unlikely to be captured by entropy alone. So we need some different metric to really capture decentralization in a meaningful way. The metric that we propose in our paper, the new metric we propose is something called voting block entropy, or vibe for short. I refer to it as vibe. To understand vibe, we have to talk about utility functions. Let's suppose, for the sake of simplicity, that elections are binary, just to say their outcomes are either yes or no. And let's define a utility function as shown here, on a per player and election basis, depending on the outcome of the election.
00:12:29.438 - 00:13:20.550, Speaker B: So in particular, this notion of utility is the benefit to a particular player of a particular outcome in a given election. You can think of it as the dollar value benefit to a particular player. We also assume, for simplicity in our paper, though, you can relax this assumption, that utilities are symmetric, by which I mean that the utility associated with the s outcome is just the additive inverse of the utility for a no outcome. The intuition behind vibe, then, is that we're going to cluster voters by their utility functions across elections. So vibe ends up, or computing vibe ends up being a two step process. Computing entropy is a one step process. Computing vibe is a two step process as follows.
00:13:20.550 - 00:14:06.606, Speaker B: First, as I said, we cluster voters, or their tokens or addresses by utility functions across some set of elections, and you can choose your favorite clustering function. I'll describe a simple one in a moment. After we've done this clustering, we compute entropy over clusters, and again you can choose your favorite notion of entropy. It could be minentropy shan entropy whatever. To be concrete here, let me give you an example of a clustering function, the one that we lean on in our paper, something called epsilon Toc. This stands for threshold ordinal clustering, and the concept is actually quite simple. So for a given election, we place players in one of three buckets.
00:14:06.606 - 00:14:59.570, Speaker B: A player has either a reasonably strong preference for a yes outcome, or a reasonably strong preference for a no outcome or falls into a third bucket that corresponds to apathy. The third bucket corresponds in particular to a low utility value, absolute value for utility. The player may have a leaning toward yes or no, but it's a tepid one, it's not a strong one. And we can define a vector of preferences for a given player across a set of elections. Once we do that, we define epsilon toc as follows. Basically, what this says is that if two users have the same vector preferences according to this bucketing I just described, we'll place them in the same cluster. That's the concept.
00:14:59.570 - 00:15:35.466, Speaker B: Let me give you an example to illustrate how this works. So let's suppose that Alice, Bob, and Carol belong to a dow that's about to have a retreat, and they're going to vote in advance on food choices. They're going to vote on four different foods on the question of whether four different foods should be served, and they'll cast votes individually for each of these foods. Which of them is going to have some utility or preference associated with these four foods? Alice, for instance, loves oranges. Bob loves oranges. Carol hates oranges. Everyone loves bananas.
00:15:35.466 - 00:16:11.494, Speaker B: Carol hates chocolate. Alice and Bob have opposite preferences with regard to chocolate, but they've got kind of weak preferences. They've also got weak preferences with respect to granola bar. In this case, we would end up clustering Alice and Bob together. Their strong preferences match exactly, and otherwise, they just have weak preferences. Weak preferences fall into that third bucket of apathy that I described earlier. So they're regarded as equivalent, and Carol gets placed in a separate cluster because her preferences differ from those of Alice and Bob.
00:16:11.494 - 00:16:41.720, Speaker B: Her preference vector differs. Now, you may have observed that vibe is a latent variable. What I mean by that is that we can't observe it directly. We don't know voters utilities. In fact, voters usually don't know their own utilities. This would seem to be problematic. And you may be asking, okay, what good is this new metric you've introduced, vibe? If we can't measure the thing? There are two answers to that question.
00:16:41.720 - 00:17:20.754, Speaker B: First answer is that we can come very close. In particular, we introduce a notion we call observable vibe in our paper that gives us a very good estimate of vibe for epsilon Toc. Let me show you how this works. These are the preferences I showed you earlier for the four foods among our three players. Given those preferences, how are these players going to vote? Well, where they have strong preferences, they'll cast votes in the direction of their preferences. Alice will vote yes for oranges. Carol vote no.
00:17:20.754 - 00:18:10.158, Speaker B: And so on and so forth. Where their feelings are tepid, where they're more or less apathetic, they're unlikely to vote, as shown by the bot symbol there. So here are the votes we would obtain as a function of the player's preferences, and you'll notice that the players get clustered in exactly the same way. In particular, if apathy results always in nonvoting, and vice versa, then observable Vbe will give us an exact measure of epsilon Toc, observable vibe, I should say. Okay, so we can compute observable vibe, which gives us a handle. Very good and accurate measure of vibe. At least with epsilon Toc.
00:18:10.158 - 00:18:57.150, Speaker B: That's the first reason that it's fine that vibe is a latent variable. The second reason that vibe is useful despite being a latent variable, is that even just as a concept, it offers us important practical guidance for the management of dows. Let me talk about that now. We have a summary table in our paper of eight different lessons we draw from our study of dows through the lens of vibe. Obviously, I'm not going to have time to talk about all eight, so let me just talk about a few. The first is vote delegation. Now, your intuition may tell you, and my intuition told me, that delegation is bad for decentralization decreases decentralization.
00:18:57.150 - 00:20:06.542, Speaker B: After all, what is delegation? In a DAo? Delegation involves some players handing over their voting rights to other players to vote on their behalf, and generally they're going to hand over their voting rights to whales. So the result of delegation is just going to be bigger whales, and that's obviously bad for decentralization. But is it? What may actually be happening is that, and this is the case in most dows, most players are not voting. Most players belong to the inactivity whale. So those tokens are not really coming from individual players, if you think about this from the perspective of vibe, but from the inactivity whale. So even though some whales are growing this huge hulking blue whale, the inactivity whale may be shrinking, and as a result, delegation can produce a more even voting distribution, and therefore higher vibe. This is counterintuitive until at least I hope you see my argument.
00:20:06.542 - 00:20:55.554, Speaker B: So the lesson here is that at least where there's a big inactivity whale, delegation may actually be a good thing. Second lesson regards voting privacy. There's a well known phenomenon in voting that social scientists refer to as herding. People tend to vote the way their neighbors vote or other prominent individuals vote. For example, in a nice survey paper where dow voters were interviewed recently, voters indicated that they worried about reputational damage. You can see a quotation here from one of the interviewees. They were worried about people observing the way that they voted, and if they voted opposite the way that a prominent individual did, or against the common wisdom.
00:20:55.554 - 00:21:46.040, Speaker B: They were concerned that the result would be reputational damage. So players you can see as a result of reputational concerns and so on and so forth, tend to herd and cause whales to grow bigger. And this obviously is bad for decentralization. There's an obvious solution to this problem discussed in a moment, but it's clear that lack of privacy causes alignment and lowers vibe. If we want to solve this problem, we just need to make ballots secret, right? There's no mystery here. If people can't see how you voted, there's no risk of reputational damage. And in fact, Snapshot, which is the most popular platform for DaO voting these days, recently introduced a form of secret ballot called shielded voting into its platform.
00:21:46.040 - 00:22:34.740, Speaker B: The problem is that the privacy afforded by shielded voting is temporary. It's ephemeral. Once ballots are tallied, they get revealed, and so reputational damage remains a concern. And the reason they do this is probably it's just technically much easier to provide temporary privacy than to provide persistent, end to end privacy. But the upshot here, the lesson we learn, is that we really should be adopting persistent ballot privacy if we're going to improve decentralization. A third lesson regards the problem of bribery. Remember, I mentioned this as another centralizing force.
00:22:34.740 - 00:23:14.480, Speaker B: To be fair, today most dows are not very decentralized, and so bribery is probably not a concern. I mean, use whatever measure you like. Entropy, vibe, whatever. Most dows are controlled by a few whales, and consequently they probably don't have to bribe anyone. They can just cut backroom deals. But as decentralization increases in dows, which we hope it will, voting outcomes will rely increasingly on large numbers of ballots. And it's under these circumstances that systemic vote buying becomes a risk.
00:23:14.480 - 00:24:17.376, Speaker B: There are a few reasons in particular why such vote buying is a real threat. The first, and this shocked me when I learned about it only about a month ago, is that although vote buying is illegal in political elections, it's actually legal in shareholder elections. You can sell your proxy vote, and in fact, there's a company that set up a marketplace to do exactly this. So while I'm not an attorney, I would guess that you can probably also do this legally in dows. Second, as I'm sure all of you know, web three has a history of monetizing anything that runs, walks, or crawls. One example, which you're going to hear about repeatedly, is Mev minor or maximal extractable value transaction ordering that's been monetized. Your friends have been monetized, right? You know about that? Digital cats have been monetized.
00:24:17.376 - 00:25:26.408, Speaker B: Point is, anything that can be monetized will be, and we can expect that votes will be monetized by similar reasoning. The third reason is that smart contracts are great for setting up daos and running dows. Turns out they're also very good at facilitating vote buying attacks against daos. They're perfect for that purpose as well, particularly because digital votes in dows are digitally signed and therefore can be verified directly, publicly verified, by smart contracts. The question, though, is vote buying may be a threat, but how practical is it, really? And this question leads us to the topic of dark dows. Dark dows are a concept that my group introduced back in 2018, particularly my former PhD student Phil Diane in a blog post which quickly got picked up by coindesk. At that time, it was merely hypothetical.
00:25:26.408 - 00:26:20.460, Speaker B: We hacked together a prototype, but it wasn't a fully functional dark dao. We defined a dark dao at that time as a decentralized cartel that buys on chain votes opaquely, meaning confidentially. For decentralized cartel, you can substitute dao. It's a DaO that buys votes confidentially. The thing that enables darkdows to come about is an assumption that's made pervasively in blockchain systems, namely that a key is equivalent to an identity. What do I mean by this? Suppose our canonical user Alice has a private key, SK Subet. We tend to assume that if a transaction is signed with this private key, it's been authorized by know barring theft of her key and whatnot.
00:26:20.460 - 00:27:24.020, Speaker B: The problem is, this assumption can actually be broken. It can be broken in a particular way that we refer to as key encumbrance. Key encumbrance is where a private key is controlled not directly by a user, but by a program where the program is sitting in what's called a trusted execution environment. Or it could be sitting with a secure multiparty computation committee, but easier to think about in terms of trust execution environments. Let me briefly explain what a trust execution environment does so you can understand key encumbrance. Trust execution environment is an environment in which an application can run runs, in particular in what's known as an enclave that confers a couple of essential security properties on the application. First, property is integrity, the operating system and other processes, and even the owner of the host in which the program is running, can't tamper with the control flow of the program, and can't tamper with its code.
00:27:24.020 - 00:27:52.554, Speaker B: This property should look familiar. This is basically the same property we see in smart contracts. You can't tamper with smart contract code assuming that a blockchain is robust. The second property that you don't get in a smart contract system is confidentiality. The operating system and the owner of the host and so on and so forth. In principle, can't learn private state held by this program X. Now there are a lot of provisos here.
00:27:52.554 - 00:29:20.920, Speaker B: That's what those stars indicate, side channel attacks and so on and so forth. I'm not going to get into we'll just assume that a TE does what it's advertised to do. Additionally, tes can produce what are known as attestations. A TE can generate a kind of proof that a particular program is running in an enclave and can bind to that proof a key pair associated with a particular instance of that program. So a third party seeing this attestation knows that program X in particular is running in an enclave and the private key corresponding to PK sub a is held by that program. So you've got a unique identifier for an instance of a particular piece of code. You can see now how tes facilitate key encumbrance, and why key encumbrance can be useful, particularly for vote by if Alice's key is encumbered in some program X, that program can tell a third party what policy it's using for management of that key, and that policy could itself facilitate vote by and so the program X may generate an attestation saying if you give me a bribe to vote for a particular choice of candidate c, I will sign a ballot in favor of candidate c.
00:29:20.920 - 00:30:21.526, Speaker B: One important thing to know is that key encumbrance is invisible on chain. You may see a bunch of DAO tokens flow from an exchange to an address a and assuming this is an EOA a user address, you know there's a private key associated with the address. But what you can't tell by observing on chain activity is whether that key is encumbered. There's no indication on chain that that key is sitting in a te because a te is an off chain mechanism. With this tool in hand, with key encumbrance in hand, we can easily construct a darkdow protocol, and my group has built a complete end to end prototype. I'll give you some details in a moment, but generally how the prototype works is this briber advertises that she's willing to pay money for a vote. So Barbara, for instance, may be running for the security council on a Dow.
00:30:21.526 - 00:30:42.254, Speaker B: She wants to gather votes for herself, so she offers to pay bribes. 2 minutes. Okay. I think we started late, though. No, we start 10 minutes late, actually. Okay, how much time? I'm supposed to have? Only 30 minutes. Oh, 15 minutes for Q and A.
00:30:42.254 - 00:30:50.100, Speaker B: Okay, sorry. I thought. All right, so I'll wrap up quickly. All right. I can take five. Okay, that's very generous. Thank you.
00:30:50.100 - 00:31:32.850, Speaker B: Okay, so how's the dark dow protocol work? The program that's encumbered, the key offers to pay a dollar or indicates that if it's given a dollar, it will sign a ballot specified by the briber. Briber pays the money, and the program generates the ballot. What's happening here? Key encumbrance gives you a form of fair exchange. The briber knows that if she pays a dollar, she will get her vote. She gets her vote if and only if she pays her dollar. And the program X can ensure that there's no funny business from Alice. Alice, for instance, can't generate a second ballot and resubmit her vote.
00:31:32.850 - 00:32:08.714, Speaker B: Program X will prohibit her from doing that. But the system can be very flexible in the sense that Alice can otherwise use her private key however she likes. She can pay Bob, for instance, using her private key. And because of the fact that encumbrance is not visible on chain, the only thing you will see on chain is a transfer of money. The bribery itself is private and off chain. So I said we built an end to end, fully functioning dark dao. This works for attacks on Ethereum Daos in its back end, it's using a different blockchain.
00:32:08.714 - 00:32:47.674, Speaker B: It's using Oasis sapphire paratime, which is a te backed blockchain and has some nice properties. It ensures the liveness of tes. It's easy to use, makes tes easy to use, and it's inexpensive as well. It also works with Snapshot, the popular platform I mentioned, that is used for Dao voting today. Most popular platform for that purpose. And Snapshot also accepts off chain signed ballots, which makes composing this system easier. All right, I'll gloss over our darkdow light.
00:32:47.674 - 00:33:28.754, Speaker B: We've created a second darkdow that's very easy for users to engage with, very user friendly. Here's a tweet about our dark daos saying that oasis is the greatest thing since sliced bread because we use it in our dark dow. Well, that's not quite the lesson to glean here, but there is a positive message. One of the interesting things we end up doing in composing our dark dao is constructing new types of financial instruments, so dark Daos are of general interest. One of the things they can be used for is privacy preserving Daos. The constitution Dao I mentioned before raised money to buy copy the US constitution. The effort failed.
00:33:28.754 - 00:34:01.040, Speaker B: They were outbid because most likely their fundraising was visible on chain. You could hide that using a dark dao. We've released our code. We're not worried about it because Daos don't pose a threat in the immediate term, but they do in the long term. And we wanted to illustrate their contours and also mention that there's a technical tool known as complete knowledge, work my group did with Vitalik Bhutarin that can act as a countermeasure to dark daos. I can wind up there. Thanks very much.
00:34:26.750 - 00:34:27.660, Speaker D: Thank you.
00:34:31.470 - 00:34:34.986, Speaker B: Hi, thanks so much for the talk. Given that we didn't have the time.
00:34:35.008 - 00:34:36.458, Speaker E: To go over that last slide at.
00:34:36.464 - 00:34:37.946, Speaker C: The end of the presentation, I'd love.
00:34:37.968 - 00:35:04.370, Speaker B: To know a little bit more about what you found as the solutions regarding complete knowledge and what exactly that entails. It's great you bought me an extra 30 seconds of presentation here. Okay. All right. Let me not go through the slide. Actually, the idea behind complete knowledge is to require users participating in a system to prove that their keys are not encumbered. And one way you can do that is fighting fire with fire.
00:35:04.370 - 00:35:35.920, Speaker B: In particular, you require users to place their keys in the custody of an enclave program that reveals the key directly of the user and attests that it's done that. So you get a proof of transparency, if you will, that some user has seen the private key, some user has seen the private key. Encumbrance won't work. That's the idea in a nutshell. Thank you. You're welcome. Hello.
00:35:39.730 - 00:36:49.318, Speaker F: Yeah, firstly, thanks for the presentation. Love the awesome stuff. My question goes to the earlier part of your presentation, which focused on the inactive whales and just how you even introduce randomization, that whole voting process. My question is, what are your thoughts on using on chain data to determine who gets to participate in a given voting scenario? So, for example, instead of having to worry about these singular whales that you delegate to, what if you had these kind of evolving selection of delegates to delegate to based on certain on chain bits, such as maybe Alice is very popular in Ens and they do a lot of identity stuff and Bob is very popular in I don't announce down, you're very busy with NFT stuff, and maybe the stuff they have to vote on is focus on identity stuff. So instead of everyone just delegates into bar because he's popular or something, for NFTs, you have the system essentially help them randomly allocate to whoever's best set to tackle that particular topic. So in the case of inactive whales, you don't have to deal with that. You kind of have an evolving set of delegates to randomly pick from.
00:36:49.318 - 00:36:50.920, Speaker F: What are your thoughts on that?
00:36:52.650 - 00:37:49.802, Speaker B: So I'm not sure I entirely understand your proposal. Vibe doesn't give you a prescription for delegation. What it does enable you to do is determine whether a particular delegation scheme within a particular setting, for instance, when there's a large inactivity whale, whether this will result in more decentralization or less so proposals like the one that you're suggesting, random allocation of votes to different whales, for instance, or different delegates at least, can be analyzed through the lens of Vbe a priori. If you're dispersing votes to different entities, you'll get higher vibe and you'll get better decentralization. But the nice thing about vibe is that it gives you a handle on whether or not a particular prescription for delegation is going to be good or bad in the sense of being in the service of higher delegation or not.
00:37:49.936 - 00:37:53.660, Speaker F: Love it. Thank you. That clarifies a bit for me. Thank you.
00:37:54.030 - 00:37:54.940, Speaker B: You're welcome.
00:37:59.250 - 00:39:16.390, Speaker G: Yeah, thanks for the talk. Again, just a quick question that I think has played out broadly in if you refer to Ethereum as a Dow, that there's kind of like an opportunity cost of preferences, especially when we look at upgrades that might be included in a hard fork and people maybe might have strong preferences about multiple proposals, but feel that there's like a fixed amount of kind of throughput of things that they can vote for and have the Dow continue to be effective. And so do you think that there is an additional dimension, like in the kind of chart you were describing of Alice, Bob and Charlie voting on fruits? Maybe if the fruits have some relative costs associated with voting for them, there's maybe a different degree of decentralization that people have to account for, which is that there's some sort of relativistic costs. I don't know if that question is well formed.
00:39:17.530 - 00:40:03.272, Speaker B: Well, the question of cost or benefit to a user of particular choice should be baked into the utility function. But I think your question suggests a broader point I should make, which is that vibe is not the be all and end all when it comes to measuring or defining decentralization we see it as a step along the path, I hope, to better definitions of decentralization. And as I said, it's particularly useful because it is sensitive to things that entropy isn't. There may well be other notions of decentralization that are sensitive to other conditions or ideas like the one that you're expressing mean.
00:40:03.326 - 00:40:27.600, Speaker A: We are waiting for Sriram because he left the room. I guess I'll fill in with one question. I guess Ethereum doesn't have on chain governance, right? It has this off chain governance, as was mentioned. Do you think we have tools to observe the decentralization of and measure the decentralization of Ethereum?
00:40:28.180 - 00:40:54.360, Speaker B: As long as you know the outcome of a vote, you know who voted for what, and you know token allocations, you can compute observable vibe. So the tool doesn't require that the voting happen on chain. And in fact, snapshot typically conducts votes off chain, although there are mechanisms for on chain voting as well. So the concept is perhaps more general than I suggested.
00:40:54.860 - 00:41:08.270, Speaker A: But I guess in the case of Ethereum, the voting happens by running these nodes, and there's these huge incentives to be voting the exact same thing that other people are voting. And so you don't have much diversity of outcome when you just.
00:41:09.780 - 00:41:13.788, Speaker B: So you mean implicit voting in the sense of endorsement of blocks?
00:41:13.964 - 00:41:17.600, Speaker A: Yeah, like choosing a specific consensus rules.
00:41:18.580 - 00:41:42.810, Speaker B: I see. Okay. Yeah. I haven't given thought to the implicit voting in Ethereum. That may be harder to measure because not all participants in the system are voting at a given time. So there may or may not be a notion of vibe that corresponds to that particular form of voting. That's something worth thinking about.
00:41:46.060 - 00:42:20.980, Speaker D: Thanks for the great talk. I'd also like to ask a question. So my question is more of a meta question on decentralization. It's basically vibe with epsilon Toc, as you said. So I guess if we imagine that we live in the world where every different individual likes healthy eating, for example, they like fruit and they want to downvote chocolate, and they're all different individuals and they vote for that except for a tiny mass of 1% that really likes chocolate, then why would we consider that this is effectively a centralized system or that it has a centralization risk?
00:42:21.640 - 00:42:23.604, Speaker B: Yeah, that's a great question.
00:42:23.642 - 00:42:29.972, Speaker D: In other words, why would diverse viewpoints require that you have vote counts that are also very dispersed?
00:42:30.116 - 00:43:10.560, Speaker B: Yeah, that's a great question. We are trying to capture in vibe some informal notions that are pervasive, in our view, in the blockchain community, notions like diversity of viewpoints incredible neutrality, those notions. And I think the idea that most people have about what decentralization is suggests that herding or persistent herding is a bad thing for governance. That may or may not be true. If everyone in the world agreed on everything, it would certainly make for a more harmonious planet. But as I said, the prevailing sentiment is that that would not be good for governance. And that's captured in vibe.
00:43:10.560 - 00:43:13.860, Speaker B: So implicit in vibe is that particular viewpoint.
00:43:15.320 - 00:43:16.836, Speaker A: Amazing. Thank you so much, Ari.
00:43:16.868 - 00:43:17.930, Speaker C: Okay, thank you.
00:43:26.540 - 00:43:31.720, Speaker A: Next we have Sriram from Eigenve, who will be talking about stakehore.
00:44:05.600 - 00:44:38.730, Speaker C: Good afternoon, everybody. Thanks to Tim and Justin for the invitation to come speak here today. I'm Sriram, founder of a project called Eigen Layer, also was a faculty member at the University of Washington, Seattle. This is joint work with two of my former students who are also now working at Eigen Layer. The title of the talk is something quite ambitious. We're talking about mechanisms with unconditional economic safety. I'm going to define what it is and see if we can achieve this bar.
00:44:38.730 - 00:45:18.784, Speaker C: Okay, so I'm going to start with some motivating questions. The first question is, in blockchains, we talk about economic security or economic safety. You have so much of money at stake means you have some amount of security. It's an intuitive notion that we have. What does it really mean? How do you measure this concretely? You can take a blockchain like ethereum, and then you can see how much is staked in this blockchain and ethereum. Maybe that's like 40, 45, whatever, billion. But the blockchain is protecting 400, 500, maybe even more billions of dollars worth of assets.
00:45:18.784 - 00:46:32.968, Speaker C: So is this blockchain over leveraged? Is it unsafe? There are other questions that are important when we think about how existing blockchains work. For example, most of the blockchains, I think pretty much all blockchains I know are priced based on computation demand, like you're priced for units of computation. And maybe if the blockchain has infinite computation ability, the price will crash to zero, the fee will crash to zero. And if the fee crashes to zero, how are we providing any kind of security? Why are we not charging for security? Instead of charging for computation, are we charging the wrong access? And finally, I define this notion of unconditional cryptoeconomic safety, which is something like, I'm a user and I want to use the system, and it doesn't matter what anybody does, like a bad validator or a collusion of validators or anything. I should have a measurable amount of safety. Okay, so before I introduce this model, maybe it makes sense for me to take a second, see what other models exist to study. Blockchains.
00:46:32.968 - 00:47:01.830, Speaker C: The most popular model in distributed systems is the model of byzantine fault tolerance. What is this? In a byzantine fault tolerance system, you're saying that some fraction of nodes are honest. Actually, you should interpret this word honest to mean obedient. They just follow the protocol. Whatever has been given to you, just run the node as given as prescribed. The rest of the nodes can do whatever they're called, adversarial or byzantine. This is one model.
00:47:01.830 - 00:47:38.176, Speaker C: In this model, the type of results you get are 33% of the nodes. If less than 33% of the nodes are byzantine, then your system works. Or if less than 50% of the mining power is controlled by bad players, then your system works. There are other models where people study whether it's rational for a given player to follow the protocol, if everybody else is following the protocol. This is called a Nash equilibrium analysis. These are the two models which are widely studied. I think instead, here we study a third model we call the economic safety model.
00:47:38.176 - 00:48:29.852, Speaker C: Both of the other models require a certain notion of decentralization and independent operators. We saw in Re's talk that decentralization itself is a contentious term. And how can we measurably get known amount of decentralization? Can we instead just rely on economics? So that's the goal of this talk. And the title of the model says economic safety, not economic security. And this is carefully crafted because security relies on safety, which is that your executions are correct, and liveness, which is that new executions happen. And we're only going to talk about safety today because it is the harder or the more rigid property that you want. Liveness is also hard, but I'm not going to focus on liveness.
00:48:29.852 - 00:49:19.010, Speaker C: Okay, so what are these two quantities that you can use to define economic safety? A lot of this thinking comes from, like, a lot of many years of work in the Ethereum research community, particularly, we are going to define two terms called the cost of corruption. The cost of corruption is the minimal cost incurred. Even if all the validators, we assume that there's a group of validators running the system, they all collude together. We take the extreme case of one big whale running the system and they all collude together. And then still if they try to attack the system, they incur a certain cost. If they incur a certain cost, a minimal cost, that is called a cost of corruption. To make the system lose the safety property, you have to incur this cost.
00:49:19.010 - 00:49:50.732, Speaker C: There is the other side. Why are you doing this? Why are you attacking? Why is somebody attacking this blockchain is because they can extract something from attacking the blockchain. There is a profit from corruption. You can extract some profit from attacking the system. So now a system is said to be crypto economically safe. If the cost of corruption, the cost incurred by the adversary to attack the system is more than the profit that you can extract. Okay, so I attack the system.
00:49:50.732 - 00:50:27.370, Speaker C: I gain x dollars. That's the profit from corruption. But I lose because of some inherent mechanism which detects that I attack the system and extracts some value out of me. So if the cost of corruption is greater than the profit from corruption, you can think of this system as being safe. So that's one definition of crypto economic safety. So let's first understand. So what I'm going to do in the next 10 minutes is try to explain whether how ethereum works, or any blockchain for that matter, in the crypto economic safety model.
00:50:27.370 - 00:51:05.136, Speaker C: So the first one is cost of corruption. What is the cost of corruption of a blockchain? If a blockchain has a slashing mechanism, what is a slashing mechanism? A slashing mechanism is if two conflicting blocks are being finalized by that mechanism, then the blockchain detects it and finds the quorum intersection. Who are the nodes which signed on both these blocks? You should at least have some number of these. Otherwise you will not be able to get two finalized blocks. You detect them and then you go and slash them. Slash them means you take away their funds. In the ethereum version, these funds are burnt.
00:51:05.136 - 00:51:37.016, Speaker C: So that's the cost of corruption. And usually there are some quorum intersection arguments in these systems. And the quorum size is usually set in such a way that the cost of corruption is the total amount staked by three. So you can actually attribute that at least one third of the stakers were in both these conflicting quorums. Okay, so that's the cost of corruption. Some numbers in Ethereum, if you think of the stake as being like $45 billion, this cost of corruption is $15 billion. That's the cost of corruption.
00:51:37.016 - 00:52:07.448, Speaker C: Ethereum today. Okay, so what's the other side? What is there for people to gain? This turns out to be much more subtle and interesting. So attempt one. What's the simplest thing that you could say? Oh, this Blockchain stores so much of value. Like maybe it's eat, maybe it's all the ERC 20 tokens, maybe it's all the other things, layer twos running on top. All of these things, you can go attack all of them. The total value locked TVL is what we call it in the field.
00:52:07.448 - 00:52:42.020, Speaker C: So if you can go and attack the blockchain, you can basically lose the entire value that is stored in the blockchain. It's the first bound that one can deduce. How do you actually do the attack? You create a block in which all this value is transacted. You create a conflicting block in which all this value is transacted. And now you have double spent this amount of value. Okay, so that's the first attempt. And you say the profit from corruption is equal to the TVL.
00:52:42.020 - 00:53:27.216, Speaker C: But maybe not. Maybe TVL is a loose bound. Maybe we can make this sharper. So let's go ahead and see what else we can do. In a blockchain you have, in a blockchain like Ethereum, you have this idea of finalization, which is a block is considered final if certain number of our testers sign off on it. And if you have conflicting blocks which are finalized, then there is this thing where the blockchain still continues to proceed on one of the chains. There are two chains now which are conflicting because there was an attack.
00:53:27.216 - 00:54:17.708, Speaker C: And if there are two chains that are conflicting, then one of the chains continues to become the canonical fork. And here is an observation. The observation is what we call the reversion period. What is the reversion period? Imagine if there is a block that was finalized in Ethereum one month ago, okay? And now somebody comes up with a block and says that hey, this is the new chain starting from one month ago. Not only this guy will get slashed, but also the older chain which has been running for a month, will continue to be the chain on which all things get built. So if a block is entrenched in the chain beyond a certain period, then that block is incontrovertibly irrevertible. Because all of us have seen that block.
00:54:17.708 - 00:55:03.600, Speaker C: It is not protected by economic stake, it is protected by social consensus. So we take this vague concept of social consensus and convert it into a single solid concept called reversion period. Reversion period is the period beyond which, if you try to reorg the chain beyond this period, you'll simply not succeed in executing this attack. Okay, so now you can give a sharper bound of the profit from corruption. An attacker, a group of blockchain validators, perfectly colloding, trying to attack the system, can only extract the amount of value that was transacted within the reversion period. Because you can't go back and revert anything before that. It's not protected by the financial things.
00:55:03.600 - 00:55:40.888, Speaker C: It's actually protected by social consensus. Okay, now we've gotten a little bit sharper, bond, but this is not all. We have to go dig in further. Then you start observing that not all transactions are subject to the reversion problem. Why is this? It's because if a transaction is atomic on chain, imagine I go on uniswap and pay ETH and get USDC. This is the transaction. Now, if this transaction gets reverted, I either have ETH or have USDC.
00:55:40.888 - 00:56:08.416, Speaker C: There's no world reversion world in which I neither have ETh nor have USDC. Okay, this is interesting. Transactions which are on chain atomic actually don't add to crypto economic load, because if I get reverted, I still have not lost much. There's some slippage. Let's ignore that for now. You can add it on later. But there are on chain atomic transactions where you have both ends of the trade happening on chain.
00:56:08.416 - 00:56:49.004, Speaker C: In an atomic transaction, they revert together. They do not add to crypto economic load, because even if an attacker tries to revert it, they cannot steal my money. I either have my ETh or have my USDC. Okay, so now you can create another kind of a transaction, which is hybrid transactions. One end of the value flow is on chain, and the other end is in the real world or somewhere else. Those transactions are the ones that are subject to the reversion load, because if the blockchain reverts, suppose I sold my house for a million dollars by taking one side in ETH, and then that transaction reverted. Now I lost my house, but I don't have ETh.
00:56:49.004 - 00:57:14.724, Speaker C: So these are hybrid transactions. One and on chain, one and off chain. These are the transactions that actually add crypto economic load. So now you can go and revise the profit from corruption for an adversary. An adversary cannot really extract value from your onchain atomic transactions. It has to extract the value from hybrid transactions, because only there, you have something to lose if the blockchain rewards. Okay, so that's a sharper bond.
00:57:14.724 - 00:57:53.704, Speaker C: The total volume of hybrid transactions inside the reversion period. Can you reduce this further? Okay, so that's where we are going, is essentially trying to find ways in which we sharpen what is actually the profit that an adversary can extract. Okay, so here is a new rule. In the olden days, not olden days, I guess bitcoin still exists. If you use bitcoin, you would use a rule where you wait longer, then you get more protection. A block is more deeply embedded in the chain, then you get more safety. So exchanges still use a policy like this.
00:57:53.704 - 00:58:48.840, Speaker C: They say, oh, I'm going to wait a little bit longer for higher value transactions. Even in staked chains, could this have any merit? So here is a rule, a new confirmation rule. Normally, let's say the confirmation rule is if I get a transaction and it's finalized, I'm going to accept it and send you the house. Instead, I change the rule like this. If there is a transaction and this transaction has entered into the ledger and the reversion period has passed, only then I give you my house. Now I can be unconditionally sure that my house, that transaction is in and I don't need to worry about the reversion of that transaction. So we call this the secure confirmation rule.
00:58:48.840 - 00:59:31.088, Speaker C: Just because a block is confirmed doesn't finalize, doesn't mean you accept it. It's finalized and then the reversion period passes, then you accept it. So, observation, the secure confirmation rule. If to the extent that clients are using the secure confirmation rule, that does not add any crypto economic load because an attacker can't do anything with it. Okay, now we are left with this final bound, which is that the secure confirmation rule. If you use the secure confirmation rule, then what happens is the total value that can be extracted by the adversary is the total amount of hybrid transactions inside the reversion period. Using a non secure confirmation rule, like that's all that the adversary can extract.
00:59:31.088 - 01:00:00.640, Speaker C: So now this number can be much, much smaller than the other number, which is the TVL. Okay? That's the main observation of how the profit from corruption looks like in the existing systems. Okay? Now of course, one project could be just go and calculate this kind of a number retroactively. I just want to point out a couple of things. Hybrid transactions. There are two major sources of hybrid transactions. Number one, exchanges.
01:00:00.640 - 01:00:30.916, Speaker C: In an exchange, you give them your digital assets and they give you real world assets like USD in your bank account. So those are hybrid. The second source of hybrid transactions are bridges. Bridges are you're locking the state in one chain and releasing the state in the other chain. So bridges are hybrid. These are the two major sources you can imagine in a future world like Starbucks and other places accepting digital tokens. They will all also be hybrid transactions.
01:00:30.916 - 01:00:53.568, Speaker C: Okay? The big problem with this method is we can go do these calculations retroactively. But I cannot do this in a forward looking manner because I don't know how many hybrid transactions going to happen inside the reversion period. Who is using insecure confirmation rule. All these non observable and subject to coordination problems, like I don't know who.
01:00:53.574 - 01:00:54.384, Speaker B: Else is using what.
01:00:54.422 - 01:01:38.540, Speaker C: So there's no information which is recorded. Okay, so that's the problem. This is what prevents us from getting strong crypto economic safety. How do we coordinate across all these nodes and do it in a way that they are incentivized to make this information sharing? So I'm going to present a new mechanism called stake share. You can think of it as some kind of a staking insurance. This mechanism satisfies a new property that we define, which is a highly aspirational property called strong crypto economic safety. So we defined crypto economic safety earlier, which is, the cost of corruption for an adversary is greater than the profit from corruption.
01:01:38.540 - 01:02:11.284, Speaker C: The problem with this, I said, like, there's some bounds on profit from corruption, but they're unobservable. But also, suppose the adversary, for whatever reason, is willing to be irrational. Maybe it has a short position. Maybe it has something else that you don't know anything about. Then an honest user who's transacting on the system gets screwed and gets nothing. This is a major problem. So I'm going to define something really strong, strong cryptoeconomic safety.
01:02:11.284 - 01:02:52.400, Speaker C: You can call it unconditional economic safety. So here is the bar. It says, no honest user of the system ever suffers any loss of funds. That's a high bar. If I'm transacting, then I don't lose money. Okay, how do we get this? So, here's the intuition. If we want strong cryptoeconomic safety in a world which is imperfect, one of the things I want to repeat is I'm defining strong crypto economic safety in a sense where all validators are colluding, no decentralization required.
01:02:52.400 - 01:03:25.650, Speaker C: See the claim? That's why I'm calling it unconditional. The claim says nothing, that a majority of the honest validators are honest or anything like that. Okay. Very high bar. Okay, so what we need is. But the system is still run with temporal power being allocated to the validators, so the validators can mess up and something bad can happen. So if there is harm done in the system, then the users have to be compensated for the harm proportional to the amount of harm that has been done.
01:03:25.650 - 01:04:14.400, Speaker C: Okay, so if the users have to be compensated amount according to the amount of harm that has been done, we need the users to express the amount of harm that they may be suffering. So we need the users to commit to the amount of compensation that they may need. And this solves the information problem of soliciting how much, who is transacting, who's at risk, all of these things. Okay, let's go to the key ideas of how stakehore works. You can think of stake, we call it stakeholder, as like, staking insurance. So I'll also point out what the differences from standard insurance are. Okay, number one, in all existing systems which have slashing, the slash funds are burnt.
01:04:14.400 - 01:04:48.668, Speaker C: Why are they burnt? They're burnt because the system cannot. There's no neutral way for the blockchain to know who got harmed and then go and find it. Call Coinbase and talk to Brian Armstrong and distribute it. Not possible, right? You want to have a credibly neutral system, so you need it to be burned. But instead, if you want a closed loop of karma, the slashing is extracting the money out of the harming party. Needs to redistribute it to the harmed parties. So we need to do that.
01:04:48.668 - 01:05:37.304, Speaker C: Okay, so we need to allocate a portion of this funds to insurance. So instead of slashing and burning all the money, you detect an attack. You have to at least reserve some portion of this money to be redistributed rather than to be burnt. Idea number one. Okay, so who should we allocate this money to? Anything else other than what I state here? Seems like it's not a protocol. So what we can do is let users self buy insurance before you. So, you know, if the user can self declare the amount of value that they are transacting with, then you can insure them for that amount, and they have to pay a fee proportional to the amount for which they're buying an insurance.
01:05:37.304 - 01:06:17.464, Speaker C: The analogy here is something like FedEx. You go to FedEx and you ship your grandmother's ring, maybe like you have a special place in your heart for it. But when you go to FedEx, the guy asks, like, how much insurance do you want to buy? You say, I want to buy $10,000 worth of insurance, and you have to pay pro rata to the $10,000. That's the amount of insurance you'll get. So that's exactly the same principle here. You want to allocate the funds to users who self buy insurance. But if users are self buying insurance in the same transaction, the problem is that transaction can get reverted, like.
01:06:17.464 - 01:07:01.876, Speaker C: So it's a chicken and egg problem. Now, the reversion period, which we analyzed earlier, comes to our help. You cannot buy insurance at the same time you have to pre buy insurance. Okay, for the next reversion period. I have to buy the insurance in the previous reversion period so that I know that the insurance for the next period is solid, and then I can transact. Now this is very important that the analysis we did earlier about hybrid transactions, the major source of these kinds of transactions, hybrid transactions, only hybrid transactions need insurance. The major source is exchanges and bridges, and they can very easily pre buy insurance by saying that, hey, I'm Coinbase, I'm doing a daily volume of $100 million.
01:07:01.876 - 01:07:39.760, Speaker C: I need the reversion period as one week. So that's $700 million. I pre buy insurance with 700 million, set the volume limit on my exchange to be 700 million. You can operate a very tight, unconditionally safe economic system. Okay, so what is the, I call it rational transactor policy? Maybe more accurately, this should be called the safe transactor policy. A safe transactor should obtain enough insurance so that the entire value, the value of insurance that they hold is greater than their own funds at risk. So the self insurance problem solves one of the hard problems of a general purpose smart contract system, which is your transporting arbitrary state.
01:07:39.760 - 01:08:28.460, Speaker C: And there's no way to meter if you're just in bitcoin, just sending btcs. The system has an inherent unit on which it's transacting. I may be selling you a board ape, and God knows how much that is worth, but I can self declare what the value is. Okay, so this system starts to have lots of interesting properties. One of the property is self scaling security. Like if you ask why is the amount of security for Ethereum today at whatever, $45 billion? The answer is there is a staking APR curve, and that APR curve intersects four to 5% at perceived risk adjusted return. And that's the answer for how much is staked.
01:08:28.460 - 01:09:14.880, Speaker C: It is not the amount of security that's demanded by the market, because there is no security solid station mechanism. There is some amount of grieving attack here where if you buy all the insurance and you're also all the validators, then you can kind of cycle through it. And the way to solve it is a portion of the insurance fee is burnt and a portion of the slash funds is burnt, rather than all of them being redistributed. Okay, so that's the core idea of stake share. I just presented it as a high level system. One can sit down and write a lot of details about it, but because it's like insurance, I just want to make a quick contrast to an insurance system. Insurance systems are statistical.
01:09:14.880 - 01:10:11.650, Speaker C: The total amount of car insurance out available is far greater than the amount of money that is solvent in the company because they estimate that the probability of a car crash is small and overinsured, whereas stake share is fully collateralized insurance. The stakers have to put up enough money and the total amount of insurance sold by the protocol will be less than the amount staked. And if there is more demand for insurance, the APR on staking goes up and more stake enters to fill in the security demand. Because it's an open permissionless system, the system is closed. It's extracting value from the bad guy and distributing it back to the harmed guys. Unlike in a fire insurance, where you cannot extract the money from the fire and redistribute to the homeowner, there is no moral hazard. Like one of the things you have to worry about in insurance is what if I set my house on fire to claim the insurance.
01:10:11.650 - 01:10:32.552, Speaker C: You cannot say that somebody else double signed without them actually having double signed because it's cryptographically attributable. So there is no moral hazard. And I talked about grieving. I'm going to skip this. Okay, so there's a bunch of really interesting properties. You get self scaling security. You're now starting to price separately the axis of security.
01:10:32.552 - 01:10:52.280, Speaker C: From the axis of computation. You can have a computation price, but you can also have a security price. Imagine I'm doing a billion dollar transaction on a chain. This is loading the security of the chain heavily, but it's a simple transaction. It doesn't cost much gas. Somebody else is running a huge game. It costs a lot of computation, but is moving $1 of value.
01:10:52.280 - 01:11:22.920, Speaker C: So pricing separately on the axis of security and computation is the light thing. You can start building some of the other things I'm not going to talk about today. Okay, so I mentioned this briefly. Like the mental model that we have is a blockchain, is like a safe, and the assets and the validators hold the key to the safe instead. This was my previous mental model. Instead, my new mental model is the blockchain is like FedEx. It is transporting the value at flight, the value within the reversion period, and it's only protecting that.
01:11:22.920 - 01:12:02.224, Speaker C: So that's the new mental model. And so you can start mapping a lot of things into this model. Okay, now I'm going to spend the next, like four to 5 minutes explaining how we can use these concepts, these concepts to be applied to Ethereum. Ethereum needs to undergo like a protocol upgrade. So it's not under our control. So suggestion, but we are building a system called Eigen layer. I'll explain briefly what it is, unlike in a general blockchain where people stake, and when you stake, everybody is staked into the entire blockchain, so to say, in the sense all the validators are protecting all the applications on the blockchain.
01:12:02.224 - 01:13:11.740, Speaker C: Eigen layer is a mechanism for what is popularly called restaking, but more formally, I think it should be called permissionless programmable staking. It's a mechanism to. It's a mechanism where ethereum stakers can not only make credible commitments that they're going to run the Ethereum protocol correctly, but they're promising that they run all kinds of other protocols correctly. Of course, we do not or anybody does not have the ability to enforce this view on all the Ethereum validators. But some subset of the Ethereum validators can opt in to different subset of services so that they can validate these new services. Okay, so what's happening is validators opt in and promise to run these new protocols. These protocols come as arbitrary off chain systems called containers that you can download and run, and there's an onchain contract which can be used to slash people for misbehavior as well as payments.
01:13:11.740 - 01:14:05.932, Speaker C: Okay, so one of the emergent things here with Eigen layer is the concept of pool security. We call these services as ABS, actively validated services. So imagine there's $100 billion of stake on Eigen layer, and all of these stakers, just for simplicity, have opted in to serve all these applications. Now, the power of pool security is that if there is an attack, to attack any one application. So there are 100 protocols and $100 billion staked. In another world, there could be like $1 billion staked separately for each protocol. But the world in which $100 billion staked across all the 100 protocols is more powerful because to attack any one protocol you have to attack, you have to acquire the capital of $100 billion.
01:14:05.932 - 01:15:04.690, Speaker C: And also, you know that a big chunk of this $100 billion is going to be slashed. So that's the benefit of pool security. But there is a drawback of pool security, which is there is no special attribution. You're taking all these funds and then just indiscriminately, let's say, burning it. Now that we presented this idea of stakehore, where the idea was any single transactor can get attributable security out of a common pool, you can now apply the same idea also here, which is you have this $100 billion of stake and Eigen layer can allocate portions of this 100 billion dollar to each of these avss based on an insurance market. Or maybe avs one wants to buy 10 billion of security because it needs that, and so you can do it. So Eigen layer supplies both pool security and attributable security.
01:15:04.690 - 01:15:40.908, Speaker C: Okay, so I think I mentioned both pool security and attributable security already. I'll just mention two more concepts and then we are done. The other benefit of Eigen layer is economy of scale in insurance. Imagine you're an application and you're using two services, or maybe five services. Okay? Now, if you want to make sure your end application is solid, you need to buy insurance from each of these five services. Because any one service going wrong means your application goes wrong. You have to pay five x the insurance cost.
01:15:40.908 - 01:16:39.596, Speaker C: Whereas if somebody bundled all these services together and offered you a single protocol, then they only need to charge you one x. The insurance Eigen layer has this mechanism for economy of scale, where because it's a common pool that is underwriting security across all these applications, you only need to pay one x insurance even if you're using five services. And finally, it has the ability to elastically scale security. Amazon's cloud service is called EC two, elastic computation, and this is elastic scaling of security. What is elastic scaling of security if there are many applications, each of which have randomly varying amounts of security? Need I have a bridge? I don't know. I may be doing a volume between 10 million to 200 million. So if I had to have my own security pool, I have to provision it for, worst case, I have to have 200 million staked just for myself, even though I'm only consuming 20 million.
01:16:39.596 - 01:16:55.030, Speaker C: But when there are many, many applications like this and there is a common pool, you get statistical multiplexing, you get averaging, and you need much smaller amount of common pool. So those are the benefits of Eigen layer, and that's how we use stakehore in our design.
01:17:05.720 - 01:17:06.790, Speaker B: Thank you.
01:17:09.560 - 01:17:48.290, Speaker C: Just two questions. I'll be fast. Maybe I misunderstood something you said that it's not a statistical thing. But when you say there is like one pool which will be used to insure, how do you actually find the right radio? How do you ensure that at any given moment of time you will have funds to give back? It's an open marketplace. So what happens is if there is more demand for insurance than there is supply, more people will come and stake. So it just temporarily digests itself. But at any one time you have a fixed pool but because there is more demand, more people will show up.
01:17:52.250 - 01:18:21.206, Speaker G: Hey, thanks for the talk. I really like this idea of insurance for proof of stake systems, and I think the critique some people might lob is that starts to look more like a lending protocol where when the slash gets allocated to some other thing, you can maybe have a cascading liquidation type scenario where there's downward sell pressure, and maybe it's elastic in the other direction as well. So I'm curious.
01:18:21.338 - 01:19:16.194, Speaker C: Yeah, great point. So Eigen layer is built as a general purpose system for validation functions. Validation risk is different from price risk, which you are underwriting in DeFi protocols, because validation risk is what I call endogenous risk. If you're an operator and you're opting into only secured protocols, you only get slashed if you misbehave. And there is this information asymmetry between the service provider and the service buyer, and that's what the capital is tidying over. So I can securely opt in. If I validate protocols, I can opt into hundreds of protocols and be sure that I cannot get slashed in a way that you simply cannot, because in a margin lending protocol, if the market price moves 100 x, if the market price moves 1% and you're 100 x leveraged, then you get liquidated and you get cascading failures, whereas because the risk is endogenous, you control it as an operator, it's fundamentally a different system.
01:19:16.194 - 01:20:03.134, Speaker C: That's why we don't allow commingling of Defi in eigen layer. It's purely a validation risk for open oh, you mentioned that atomic reversions do not contribute to crypto economic load, but in the case where you have a swap which reverted, but that caused further liquidations on the line, that is the slippage thing. So what you would do is if you have an atomic transaction like that, you'd basically buy the. So you have to calculate how much will that reversion cost you, and then you have to buy insurance relative to that. So transactions are not fully atomic or fully hybrid. It's up to you to self estimate your risk and then buy insurance proportional to that. Yeah.
01:20:03.134 - 01:20:37.530, Speaker C: So you can't look at like a transaction myopically and see, say that this is atomic. That's right. It's just a simple classification, but once you go to insurance, it's up to you as the user to figure out, yes, if this gets reverted, I'm swapping $1,000 for ETh. But actually the slippage may be like 3% in the next week. So I actually go and now cover my risk of 3%. So it's up to you to self declare the value so you don't have to binaryize transactions into atomic or hybrid. You just self declare how much value you need if the transaction rewards.
01:20:38.910 - 01:20:59.522, Speaker E: All right, so you suggested that the amount of insurance someone would buy is equal to the value they have at stake. Can you explain why that would be the case? It seems to me that if I can pay one dollars, and then I'll get $100 if some event happens, that I should do that if I think the probability of that event is more than 1%.
01:20:59.656 - 01:20:59.954, Speaker C: Right?
01:20:59.992 - 01:21:07.570, Speaker E: And that's true independent of how much value I have at stake. So why would I be expected to pay the value at stake?
01:21:07.730 - 01:21:19.134, Speaker C: Because it's not a probability. You are not protecting against probabilistic events. The model here is you get slashed only if the operator is malicious. So the operator is underwriting their own malicious behavior by putting in a capital.
01:21:19.202 - 01:21:29.440, Speaker E: Question is, why should I pay one dollars for $100 of insurance if I think the probability of misbehavior by the validator is less than 1%?
01:21:31.010 - 01:22:08.706, Speaker C: Okay, so the question is basically, is it rational for me to buy, or is it just safe? In the extreme case, the answer is, if you want unconditional security, you have to pay that much, and there will be people who will ride without unconditional security. And our thesis is, once you have a system like this where you can actually get insurance, major agencies like Coinbase and others will be required to buy insurance from protocol, because otherwise you're taking other users funds and operating on arbitrary risk.
01:22:08.898 - 01:22:15.402, Speaker E: On the other side of this, though, if I think the probability is greater than 1%, then I should buy the insurance even if I have nothing.
01:22:15.456 - 01:22:24.590, Speaker C: This is not a probabilistic event. I think that is the problem is you are protecting against an adversarial event. There is no probability that you can ascribe to it. That's the problem.
01:22:24.660 - 01:22:30.814, Speaker E: Nonetheless, if I'm deciding whether to buy, I assign some probability to that event happening in the future.
01:22:30.932 - 01:22:45.170, Speaker C: I think that's not compatible with the worst case model of the world. So it's like you're launching a rocket and the rocket bursts or doesn't burst. So this is a non ergotic one time event. So just ascribing a probability may not be the right approach.
01:22:46.710 - 01:22:58.440, Speaker A: We're out of time. Thank you so much, rerun. We now have 20 minutes break, and then lightning talks after that.

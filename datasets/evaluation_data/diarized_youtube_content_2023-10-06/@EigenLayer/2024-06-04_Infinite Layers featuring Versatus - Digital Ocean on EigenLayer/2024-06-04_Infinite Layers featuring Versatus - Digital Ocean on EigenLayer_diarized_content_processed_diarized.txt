00:00:10.280 - 00:00:26.274, Speaker A: Hello everybody, welcome. Today we are here with another infinite layers and we are joined by Andrew, who is the founder of Versatus. So before I mess up explaining what Versatus is, do you mind giving a quick intro about yourself and also about the company?
00:00:26.714 - 00:01:20.554, Speaker B: Yeah, absolutely. So as Nader told you, I'm the founder of Versatus. Versatus is an integrated cloud platform built on eigen layer. A good analogy would be like digital ocean or decentralized digitalocean, which enables developers to provision and manage Linux vms virtual private servers. And through that, as a result of that, host front ends, databases, APIs, backends. Basically everything that's off chain in your application can be hosted on our platform and inherit the crypto economic security of ethereum via eigen layer, as well as the decentralization and censorship resistance of a blockchain without the rigidity and redundancy of a blockchain, therefore making it performant and cost effective, and as a result of that, decentralizing the rest of the web.
00:01:23.444 - 00:01:38.704, Speaker A: Nice intro. So we've been chatting for a while, but real. So this is a nice opportunity to kind of talk about all this stuff in public, but to go back a minute, you all have built an AV's on Eigen layer that is for save this, is that correct?
00:01:39.004 - 00:02:00.720, Speaker B: So our AV's is called Allegra. It's going to be deployed in the next week and a half to two weeks here. So it's not quite live yet. We just delivered our first demo of it for the Encode Club hackathon. That's ongoing. We were the fifth or 6th workshop last week. We did our workshop on Friday.
00:02:00.720 - 00:02:49.444, Speaker B: And so that demo video is live and Code club has it our full workshop recorded and on YouTube. We also have a video that we'll be posting of just the demo that we'll be posting and pinning on our Twitter, which is labs or I guess xercedaslabs. And we'll be rolling out a lot more. So docs, we're aiming to release the docs for Allegra this Friday and then we're aiming to actually launch a Devnet next week for Allegra on Eigen layers testnet and then we'll move that to mainnet when it starts. We also have a roll up called laser, which is a language agnostic, stateless roll up that's built on top of eigenda.
00:02:50.984 - 00:02:59.256, Speaker A: Nice. So the first product that you all rolled out was laser. And then now the next thing that you all are rolling out is like this digital ocean product, correct?
00:02:59.360 - 00:03:00.524, Speaker B: Precisely. Yeah.
00:03:01.104 - 00:03:21.384, Speaker A: Okay, exciting. And then I think I've read a lot of your writing and there's even more stuff that you all plan in the future. So we'll try to touch on all of this and to go in the right order. I want to talk a lot about the ABS stuff, but first let's talk about laser for a moment. I've kind of talked about this a little bit. We did a Twitter spaces together. I wrote a blog post.
00:03:21.384 - 00:03:51.894, Speaker A: Even the cool thing, the thing that really interested me the most, to be honest, was the fact that you're able to write applications using different languages that are not solidity, and they're not the traditional blockchain development languages, they're not the smart contract languages. They are more like languages that most developers already know. Python, typescript, rust. So do you want to talk a little bit about that product and how you all have been thinking about building that, how far that's come, and then maybe what you might be doing in the future there?
00:03:52.194 - 00:04:32.018, Speaker B: Yeah, absolutely. So laser, which is currently in a beta testnet, we're going to be moving that to a public testnet very shortly here. We haven't quite announced the date for that yet, but it's going to be coming up in the next 30 days. That's exactly it. It's a language agnostic roll up. I will try to stay pretty high level without digging too much into the technical weeds, but effectively a good way to think of it is you have a common protocol and then you have a bunch of account based micro roll ups. You can think of it where every single account in our network is a micro rollup.
00:04:32.018 - 00:05:08.922, Speaker B: The result of that is you still get composability between those different accounts, but you're able to shift execution off chain. And so the way that we enable language agnosticism, it's not through WASM, which a lot of other people have tried and in my opinion, have failed. I think WaSm, the developer experience, is just not quite there yet. We're probably five to 70 years away from that developer experience. Catching up to web two. The way that we accomplish this is with what are called app kernels, basically what an app kernel is. It's a sandboxed container.
00:05:08.922 - 00:05:58.182, Speaker B: It's a container that's not just isolated in its own user space, it's actually fully isolated from the host completely. It has its own kernel, its own file system, and it's designed to execute effectively single threaded, single applications. Um, and so the way that this, you know, enables language agnosticism is you can have run times for different languages that all communicate back with the protocol. And that protocol then enables the composability between the different accounts. So each account you can kind of think of as its own micro roll up. I know natter you and I were talking about how you could kind of think of it as like a row in a database, right? That each account is effectively a row in a database. And then these programs, the smart contracts, can actually alter those columns in that database.
00:05:58.182 - 00:06:52.748, Speaker B: It's an imperfect analogy, but for the web two developers saying that probably will help them grok it a little bit better. The goal of the programs is to return what we call instructions and basically what instructions are. If you want to think of it as a vm, as a single vm model, instructions would be opcodes. But in our model, there's only four instructions. There's create, update, transfer and burn. And as you can see, very much inspired by the crud model for database transactions in web two, we wanted to make this as close to a web two developer experience as possible, because frankly, we think that one of the major issues we have in web3 is just this massive shortage of developers. There's only about 25,000 or so active developers in web3.
00:06:52.748 - 00:07:11.104, Speaker B: There's 25 million plus in the world. And so there's this massive gap. It's not like this is brand new. I mean, like people keep saying, oh, it's early, it's early, it's early. And in some ways it is still early. But Ethereum has been around since 2015. Like, solidity has been around for nine years now.
00:07:11.104 - 00:07:43.174, Speaker B: Rust has been around since 2015 and has over half a million people that write rust code daily. Yet there's only like 15,000 people that write solidity code daily. So there's this massive gap. We did a lot of research. We even commissioned a survey to try to figure out why this gap exists. And one of the number one reasons that the gap exists from the research that we did was the language barrier. And developers don't want to have to learn a new language unless they absolutely have to.
00:07:43.174 - 00:08:29.870, Speaker B: Some are curious, some want to, but a lot of them, you know, you came out of college writing Java, you got a job writing java. You stuck with that job for ten years, you got a different job writing. Like, why are you going to change now? Like, it served you well. And there's an opportunity cost to learning a new language. You got to spend a lot of time doing it, and your time might be better suited just finding another job that where you can use the skill set you already have. So we wanted to build a roll up that enabled developers to use the skills that they already had to build smart contracts and as a result participate in web3. And if we want to segue there into Allegra, the goal of Versatus is to build this integrated platform where the fragmentation is eliminated.
00:08:29.870 - 00:08:50.374, Speaker B: You can build your front end, your back end, your smart contracts, you can have databases, function instances, all of that in one place. And that dramatically reduces the barriers to entry as well because you don't have to learn a bunch of different platforms or hire specialists in those particular platforms to build a web3 business.
00:08:52.154 - 00:09:58.466, Speaker A: Yeah, you touched on a lot that I wanted to come back and go over here. So the first one is, I'm very curious, like why in the world are there not as many blockchain developers as there are other areas? And I think you kind of tried to give your explanation and now you all spent time and money on an actual, you know, some research into this. But it just seems so interesting that, you know, you typically like have this, this demand when you have like high paying jobs, that there's like a lot of people that want to fill those jobs. And if you look at other parts of the software industry, you saw like a lot of people come into the space, a lot of new developers, and almost like there's too many developers even in the traditional web two world due to a combination of like a few layoffs and then a lot of new people coming into the industry. But in the blockchain world, there's just so many jobs that are still not filled and there's so much demand. And I think there's two parts to that. Like, first of all, the growth has just been pretty stagnant.
00:09:58.466 - 00:10:39.740, Speaker A: If you kind of look at the numbers, like they obviously have a little bit of up and down, but they are not going up that much. And then I think the second part is that it really is hard to be a good smart contract engineer. Like doing hello world is pretty simple, but you want to build anything sophisticated enough to be hired by a notable company, like a deep protocol that has been around or maybe some other new innovative, like smart contract platform. You know, you do need to be of a certain level of seniority because of the implications of bugs. You know, like you can't just write a bug in a smart contract.
00:10:39.852 - 00:10:41.916, Speaker B: That's just people's money risk.
00:10:42.020 - 00:11:13.284, Speaker A: Yeah, it's like unacceptable because you can do that for the most part. You know, you might put funds at risk. So therefore it's just a little bit different of a world where there's less room, almost for juniors when you kind of think about it in that perspective in terms of being smart contract engineers. So lowering the barrier to entry for existing seniors to be able to, like, use their existing skills makes a lot of sense because they're just a sheer larger number of seniors that will probably be able to come in and kind of like, hopefully use that existing knowledge here.
00:11:14.104 - 00:12:17.244, Speaker B: I think that that's absolutely correct. The other, so, like, to take a step back, why have we kind of plateaued? The easy and sort of, like, lazy answer to that is everybody thinks it's a scam, which if you go to Reddit or if you go, like, on, like, non crypto Twitter, or even if you go on crypto Twitter, right? Like, this is the way that it's portrayed to the public. But I think what we forget, and this is just human nature, right? Like, we see the same thing over and over again, and so we believe it. But what we forget is that there's a very, very loud minority on these different social platforms. Great book about network effects is the cold start problem by Andrew Chin at a 16 z. I think a lot of people in this industry have read it, especially if you're an entrepreneur, you've probably read it by now. But one of the interesting things I found in that particular book was the way that he described the hard side versus the easy side of a network.
00:12:17.244 - 00:12:54.612, Speaker B: And so I'm going somewhere with this, I promise. But, like, basically what I'm getting at is, like, the hard side of a social network is the loud minority. You need content creators in order to attract content consumers. And so most people on social media lurk. Now, in crypto Twitter, there's a little bit more engagement, but for the most part, people are just lurking. And so the impression that you get from Reddit or Twitter or anywhere else would be, oh, everybody just thinks crypto is a scam, and we've got to do a much better job. Explain the narrative.
00:12:54.612 - 00:13:33.128, Speaker B: What's funny is, like, the, in the survey we commissioned, that wasn't the number one issue. I mean, it was an issue that popped up, but it was nowhere close to number one. It was number six or number seven. The number one issue was the language and tooling barrier. And 40% of developers we surveyed, now, these were us based, where that the likelihood to think it's a scam is probably even higher because of media propaganda and things like that. Us based, full stack developers, 40% of them, said that they would be building a web3 today if they could use their existing skills. If they didn't have to learn anything new to build in Web three, they would be doing it today.
00:13:33.128 - 00:14:24.862, Speaker B: So, and like, that's very, I mean, 40% of twelve and a half million developers, like 5 million people, it's like orders of magnitude more than what we have building in Web three right now. Not to say that all of them would immediately move over, but there's a huge chunk that we could capture and bring in and with them bring new ideas, new techniques, new architectures, all sorts of new stuff come from that competition. And so I think that that is the number one problem, the number two problem, which we saw. I found this really, really interesting. We actually ended up adding a fault because we got this answer over and over again in the initial survey, like the test survey, so we ended up adding a follow up to it. And so the answer that they gave was that there's not enough support and resources. And I sat there, I was like, yeah, but that's just not true.
00:14:24.862 - 00:15:05.126, Speaker B: Like, there's, you go to YouTube and type in like, getting started with solidity and you'll find everything. And so it's funny, we, when we added the follow up, what they actually meant is like 102, 103 specialist tracks. So, yes, if you go to YouTube and you type in getting started with solidity, you'll find a lot of, like hello world, you know, build your cryptokitties. Right? Like a bunch of those, like very high level getting started tutorials. But when you get into the more, okay, well, I want to build like a complex, you know, amm or like a, you know, a liquidity aggregator or something like that. Like, there's no tutorials for that. There's, you just wouldn't.
00:15:05.126 - 00:15:32.136, Speaker B: You have to just kind of figure it out and chew glass on your own and hope you don't get something wrong. And one of the other big issues that we saw was the security burden. So that security, which there's, you know, there are smart contract languages that like move. Right. And I'm personally a big fan of move, although I think the barrier to entry is pretty high. What, what's great about move is that there's a lot of security built in. So a lot of the things that wouldn't have, that could happen in solidity just frankly won't be.
00:15:32.136 - 00:16:12.664, Speaker B: They're not possible in move in terms of security risks. So we've been trying to solve that problem, obviously, auditors and everything else, and you want to go through that proper process when you deploy a smart contract. But that security burden is a big one. And so a lot of people just, you know, if somebody breaches your database for like some, I don't know, like a golf app or something, like who cares, right? Like maybe they get your credit card, you cancel your credit card, like who cares really? Like in the end of the day and you'll be insured, you know, if they ever use your credit card. It's not that big of a deal. If someone breaches your smart contract, it's a big deal, your business is dead. Like it's game over for you.
00:16:12.664 - 00:16:46.884, Speaker B: Basically if someone hacks your smart contract. So that is a big one. It's saying that, look, frankly, like what we've built, we've tried to build a lot of security into it, but I think the biggest advantage is that you're going to be using languages you're familiar with, you're going to be using techniques and architectures you're familiar with, and as a result of that, you're going to be able to construct the logic in a way to where there's going to be less bugs and less likelihood for hacks. So I do think reducing the security burden is another big one that we need to solve if we want to attract that next generation of developers into web3.
00:16:49.984 - 00:17:16.476, Speaker A: Yeah, a lot of great points and I want to talk a little bit more about this, but I think we need to, to jump into the next thing, which is what I've been really excited about. And I had one more point to make, but I think I basically forgot it. But if I do remember, I'll come back to it. But, so, so that's laser. So laser is already out there. You can try it out. It already supports a few languages, so you can basically write your, your smart.
00:17:16.500 - 00:17:19.724, Speaker B: Contracts and JavaScript, Python and rust.
00:17:19.844 - 00:17:21.484, Speaker A: Yeah, got it.
00:17:21.604 - 00:17:24.744, Speaker B: Yeah, more, more coming. But those are the first three we're supporting.
00:17:25.133 - 00:17:57.328, Speaker A: Okay, nice. So next we're going to jump into Allegra, which is the main focus, I think, of this discussion. It's basically what we were talking about earlier. It's the digital ocean droplet or EC two instance on Eigen layer you can run arbitrary applications there you can deploy servers, do whatever you want, anything you could do on a server. So yeah, let's talk about that a little bit. And I think we might even have a quick demo that we can look at in just a second as well. So can you talk about why you built this, what the developer experience looks like, and then we'll take a look at the demo.
00:17:57.496 - 00:18:30.492, Speaker B: Yeah, there's a number of reasons. Number one, is I think that, like, smart contracts are just a small part of the application stack. The application stack goes so far beyond smart contracts. And I think smart contracts solve a very, very important, albeit very niche problem, which is what I like to call asset attribution. It's a ledger, right? Blockchains are a ledger. And so basically what they do is they inform the world that you own some asset that's good. Like, we need that.
00:18:30.492 - 00:19:16.376, Speaker B: It solves so many problems in the financial world. But that doesn't solve the problem of censorship of general applications. It doesn't solve the problem of resiliency of cloud. It doesn't solve the problem of data breaches and having single points of attack. We wanted to build something that brought the core benefits of web3, of crypto, of blockchains to the cloud. Originally, when I first met Sriram, we were building this as almost like a cosmos style layer zero, with different specific chains that were going to be built on top of it for specific services. After many, many conversations, probably about three and a half months of tree room trying to convince me, you should just build this on Eigen layer, it's going to be.
00:19:16.376 - 00:19:39.352, Speaker B: But at the time, like, Eigen layer was still, you know, it was, it wasn't nearly what it is today, let's put it that way. It was being built. Nobody really knew what it was going to look like, what the developer experience was going to be. And so I was like, okay, okay, yeah, like, you're biased, of course. You want me to build this on Eigen lair. I'll think about it. And as I thought about it and had conversations with them, it became more and more obvious.
00:19:39.352 - 00:20:10.454, Speaker B: Like the, the cost of bootstrapping that network, the resources that you need, the number of node operators that you need, the economic security that you're going to need. That became like a big point of emphasis for me, that this is going to be really expensive. It's going to cost us a ton of token inflation to actually bootstrap. It became obvious the best way to build this is actually on Eigen layer. And it wasn't Shriram just being biased. He had a point. And so we pivoted to building it on Eigen layer.
00:20:10.454 - 00:20:54.374, Speaker B: For me, I think, like, I'm a true believer in crypto. I'm old school anarchist. This is the crypto anarchist movement. And cypherpunk movement was something that really inspired me not only to build in crypto, but to get into coding in general when I was younger. And so I've always kind of been aligned with that ethos. And you look around the world, and in the US where I live, we're privileged in a lot of ways that we kind of have, even if it's not what it once was, we still kind of have this culture of free speech. We have a culture where code is treated mostly as free speech.
00:20:54.374 - 00:21:44.502, Speaker B: We're a little bit lucky in that, that there's not as much web censorship as other places. If you go around the world, just like wholesale applications don't work there, whether it's a licensing thing or just that they don't like the fact that it's an american application or european applicator or whatever it is, there's tons of web censorship throughout the world. And that can be really, really dangerous. And I think that the web, not just the Internet, which I think the Internet in most places is now considered a utility, but the web, which is the things we access over the Internet, is itself a public good and utility. And I think everybody should have equal access to the information that's on the web. Whether you like that information or not. If you want to seek it, you should be able to seek it.
00:21:44.502 - 00:22:33.424, Speaker B: And there shouldn't be any mechanism by which that could be censored. And so we wanted to rebuild the backbone of the modern web, which is the cloud, in order to have applications to scale the way that they do today, you need cloud, you need auto scaling mechanisms. You need the ability to spread out the load across multiple nodes, to scale up the number of nodes that a given instance, vps, instance or container instance, or whatever is running on, and therefore be able to create multiple points of access for us. So you don't get ddos and all the other things that go along with that. You can't do that on blockchain. Blockchains are just too rigid and they're too redundant. But you can do that with an AV's because the point of an AV's, and this was the thing that Sriram kept hammering home to me.
00:22:33.424 - 00:23:18.594, Speaker B: It's called AV's and not AVC for a reason, right? It's not actively validated chains, they're actively validated services. And a service can be anything from sort of a one off application to a middleware layer, which is kind of what we're building to a chain or a roll up to an oracle. It could be anything. I think the power of what you guys built there at Eigen layer. But for us, what made a ton of sense is we need to build an abstraction layer so that people can inherit the benefits of eigen layer without having to build their own AV's contract, their own slashing conditions. We don't want to live in a world where we have a million different slashing conditions. It's going to become really confusing for node operators really quickly.
00:23:18.594 - 00:23:33.054, Speaker B: So if you can abstract your slashing conditions away to us, we have sort of a small set of slashing conditions. Node operators know what they're getting into. We can scale out our network and you can run your app on top of us without having to worry about everything below it.
00:23:35.314 - 00:23:55.052, Speaker A: So how does the verifiability come into play? I want to talk about also building an AV's for people that are watching, that want to learn how to build an AV's. So like, is the verifiability essentially like a snapshot of the environment or something like that? Or just curious, curious how that actually works?
00:23:55.148 - 00:24:21.916, Speaker B: There's actually multiple pieces of verifiability. So there's verifiably censorship resistant, so which we use a network of hunters to hunt for. Our whole model is quorum based. So we hunt for nodes within a quorum that are responsible for a given resource. And they're, I'm trying to keep this as high level as possible, but basically they're pinging those nodes. The hunters know what they're looking for, they know what it's supposed to look like. And then those nodes respond.
00:24:21.916 - 00:25:03.392, Speaker B: And if they respond with either the incorrect data or they don't respond with the data that they're supposed to be responding with, then that's a potential slashing condition. So there's verifiable censorship resistance. There's also then the verifiability of the state of the instance. And that's a process that takes a little bit more time that's more akin to a traditional consensus mechanism. But as you can imagine, these instances could be like a gigabyte large. So you know, reaching consensus on a gigabyte takes a lot longer than on, you know, 512 kb or whatever. So that's about a 15 minutes process that nodes that are responsible for a resource have to be up to speed on it in a 15 minutes period.
00:25:03.392 - 00:25:33.244, Speaker B: Otherwise they have to drop out. They can't service, they become faulty, they become at risk of being slashed. So that's the way that our model works. So there's the verifiability of the state of the instance. There's also the verifiability that it's censorship resistant. And then there's also the potential for verifiable code that would occur in virtual tees. That's the way that we enable that is through virtual tees, which allow you to have sort of like verifiable execution environments inside of your instance.
00:25:33.244 - 00:25:38.074, Speaker B: And so that's a really important component of it as well. That opens up a lot of use cases.
00:25:39.574 - 00:25:42.754, Speaker A: You mentioned that you might have a demo that you wanted to share.
00:25:43.294 - 00:25:48.474, Speaker C: Yeah, I think I have the one which. Let me just share it.
00:25:50.574 - 00:25:52.630, Speaker A: Is this the same one from Encode club?
00:25:52.822 - 00:26:01.106, Speaker B: I think it is, but if it's the one from enclosed club, it's like the last seven minutes. I actually have a. Oh, this is.
00:26:01.130 - 00:26:03.294, Speaker C: The one which I found in the deck.
00:26:03.594 - 00:26:07.074, Speaker B: Oh, yes, you can play that one. Yeah, you can play that one.
00:26:07.114 - 00:26:09.534, Speaker A: Okay, cool. Let me know when it's okay to add it.
00:26:09.994 - 00:26:11.534, Speaker C: Oh, yeah, I think it's ready.
00:26:13.114 - 00:26:14.174, Speaker A: Okay, cool.
00:26:15.594 - 00:26:17.362, Speaker C: Should I zoom in or something?
00:26:17.458 - 00:26:19.322, Speaker B: You probably should, yeah.
00:26:19.498 - 00:26:20.494, Speaker C: How's this?
00:26:22.434 - 00:26:25.854, Speaker A: Still can't read it all that well. Is that this the font size?
00:26:26.034 - 00:26:30.674, Speaker B: Yeah, it's a video a little more. It's actually pretty good.
00:26:31.214 - 00:26:32.518, Speaker A: Yeah, I mean, I think that's fun.
00:26:32.606 - 00:27:02.498, Speaker B: Yeah. So this is sped up so you don't have to like read all the command lines. But basically this happened over about a seven and a half to nine minute period. And what you're watching is the process of provisioning. Now, hats, who's one of our developers, is actually ssh into a box on a random node. So he's ssh into an allegra, the equivalent of a droplet on Digitalocean, an Allegra box on a random node. You can see like the content address of the box.
00:27:02.498 - 00:27:35.910, Speaker B: So it's root at the content address instead of just the ip address. We route everything by that content address. And what he's doing here is he's going through the process of building the laser chess game. So the end result, what you're going to see is a decentralized front end and back end for laser chess, which is communicating with laser. And so here it comes. Which is communicating with laser. And you're playing an actual chess game against somebody else for money on laser.
00:27:35.910 - 00:27:39.874, Speaker B: And the front end is deployed to a completely decentralized network.
00:27:40.894 - 00:27:50.572, Speaker A: Wow, that's sick. So the front end is deployed on, on Allegra and then the network talking to is laser.
00:27:50.708 - 00:28:04.304, Speaker B: Correct. So, and this is, this is the chess game that hath built that laser chess that, um, you know, we're going to start hosting like some tournaments around this and stuff. And see, uh, you know, you play any chess? Chess?
00:28:05.044 - 00:28:07.148, Speaker C: Uh, so I'm dead, but I did.
00:28:07.236 - 00:28:37.344, Speaker B: Okay. Um, so you'll see here the game goes on. And this was just for a demo purposes, so hat was just playing himself and he loses to himself pretty quickly. But what's cool about this is you can gamble, onlookers can also place bets on who they think is going to win. And then when the game is over, it returns you back to the lobby. And just like that you have a fully decentralized application, front end, back end, smart contract, all in one place.
00:28:39.084 - 00:28:51.362, Speaker A: Very, very awesome. Like I have a bunch of questions now. So how do you actually make this happen behind the scenes? Are you spinning up this stuff locally or is this like running an AWS or something?
00:28:51.418 - 00:29:32.630, Speaker B: Or like it's not running on AWS at all. So we use system containers right now, primarily LXC and LXD and libvirt for the VMM for the virtual machine manager. And then we also have the ability to use CAtA containers, which are also a form of system container container, which basically behind the scenes is what AWS uses. I think they use VMware as well. But effectively you have your own hardware. Yeah, so this runs on bare metal. Now technically speaking you could run this, you could do nested virtualization and run it in a VPS as well.
00:29:32.630 - 00:30:06.216, Speaker B: So you'd have like a VPS running VPS's underneath. It kind of defeats the purpose at that point. Ideally you'd be running this on bare metal and then basically you can over commit. Two to one is probably the best ratio to overcommit. You could probably go as high as four to one. Get away with it, particularly in crypto, because most applications aren't going to be seeing a million plus simultaneous users. You could get away with some pretty high levels of over commit, but basically nodes in the network form into quorums.
00:30:06.216 - 00:30:39.544, Speaker B: They redundantly have a copy. Each quorum is responsible for different resources in the network, and every node in that quorum has a copy of it. And then each of those resources is actually erasure, coded and spread throughout the rest of the network. So in the event there's a quorum fault, we can still recover it. So there's a really, really high bar for resiliency in our network because that's a major benefit of our network. That's one of our value propositions. But these instances, these vps instances are running inside of system containers on bare metal.
00:30:39.544 - 00:31:11.688, Speaker B: So right now it's only Linux X 86 compatible because that's what's needed to run these systems containers. And then basically you use a CLI to provision an instance. You sign a transaction the same way you would sign a blockchain transaction. We recover your address from that signature. You now own that instance. You can grant you can transfer that ownership to someone else. You can authorize people by adding their SSH pub keys into it.
00:31:11.688 - 00:32:10.944, Speaker B: You can expose services on certain ports for what you just saw. We exposed port 3000, and if you watch closely, I know it's like very much sped up in that demo, but if you watch closely, one of the commands that hath Ran was exposed service, his instant port 3000. And then everything is mapped to a content address on the back end. These are static content addresses, unlike ipfs where they're dynamic, where every time it changes, these content addresses are based on your chosen namespace and the original owner's address. And so we create a unique namespace for every instance in our network. Then basically from our command line directly, you can ssh into it using the owner's address and the name that you chose. So you don't even need to remember what the content address is or the namespace was.
00:32:10.944 - 00:32:46.006, Speaker B: You just use human readable information to get into your instance. All the authorization happens on the backend. You can inject your ssh keys into it, other developers can access it. And then in my opinion, the coolest part, this is the cypherpunk in me talking. You can revoke, you can give up that ownership to a smart contract, which means now only that smart contract can ever alter it. And so basically it means that you can never alter it, right? It's, it becomes immutable, it becomes unstoppable. And the way that you pay for it going, the only way that it would ever be taken down is if you stopped paying for it.
00:32:46.130 - 00:32:48.954, Speaker A: Yeah, I was going to ask, how does it actually get paid for?
00:32:49.374 - 00:33:02.554, Speaker B: Yeah, so either the owner pays for it by loading up, you know, inverse tokens in our native token, or they can actually grant that functionality to a smart contract and a smart contract can handle that for them. Yeah.
00:33:03.254 - 00:33:37.206, Speaker A: Okay. So I think like a lot of, not a lot, but this has been trod once or twice that I know of at least. And the developer experience that I've encountered for trying to do this sort of thing and in the blockchain world has been just so bad, I never want to try it again with that particular product. And I think like what you all have also talked to me about is that you have a large focus on just making this a good developer experience. So can you kind of talk about, you know, your own experience up until this point and how you're kind of applying that to the developer experience.
00:33:37.390 - 00:34:02.300, Speaker B: Yeah, I mean, look, I'm a, I've been programming since I was 14, which is hard to believe. It's 20 years now. So I've been doing this for a really long time. I've seen all sorts of different glass that needed to be chewed, and I don't like it. I know, like, the Solana community loves to, like, take pride in, like, chew glass and all that. Look, don't chew glass. It makes your mouth bloody.
00:34:02.300 - 00:34:35.583, Speaker B: It's not fun. It hurts, it's painful, it's depressing. And, like, I so, like, the big inspiration for just, like, really focusing on developer experience actually comes from my experience as a data scientist. When I started my career as a data scientist, we were building multi factor regression and random tree models and random forest models in c, which was not fun. I mean, like, from the ground up, you know, and. Go ahead.
00:34:36.203 - 00:34:42.387, Speaker A: No, I was just going to say that sounds extremely complicated. I don't even know if I would even know how to do that.
00:34:42.515 - 00:35:18.822, Speaker B: Yeah, I mean, you needed to know the math, you needed to know how to write the code, you needed to understand all the algorithms, and you had to build a lot of this stuff from the ground up. It was not fun. And so, you know, fast forward, that was in zero, seven to zero, nine. Fast forward to zero, 920, ten. You started to have like some pretty stable versions of, like, scikit learn. I think Kerris came out shortly after that. Shortly after that, Tensorflow and Pytorch and all of these Python libraries for building machine learning, deep learning, and AI algorithms.
00:35:18.822 - 00:35:53.204, Speaker B: And you went, it went from there being, there may have been two or 3000 people in the world that could like, really call themselves a data scientist back then to where there were like 100,000. And it felt like it was overnight. It was over the course of maybe like five or six years. And then you fast forward to today, and the result of all of that is large language models and the AI revolution that we're seeing. And now, you know, pip, install OpenAI, import OpenAI. You're an AI developer. Basically, anybody can be an AI developer today.
00:35:53.204 - 00:36:34.416, Speaker B: You watch a few tutorials, you read the documentation of a few libraries, and you're an AI developer. All of a sudden, it lowered the barrier to entry dramatically. And what happened was the number of things that used data science techniques, machine learning, deep learning, and now AI skyrocketed. When I first started, the only people that hired data scientists were hedge funds is basically it. I mean, there are probably a few corporations that were doing it like some of the social media companies for like their advertising algorithms and things like that. But really it was hedge funds that hired true data scientists and machine learning engineers. And so that was where I got my start in my career.
00:36:34.416 - 00:37:08.506, Speaker B: And then you fast forward to today. Every business has a data scientist on staff, and many of them have multiple data scientists on staff staff. So, you know, it just, it lowered the barrier to entry. It increased the number of people in the space. And as a result of that, the use cases for it exploded. It went through the roof. And now everything that we touch and do right now, whatever we're streaming over, has some form of machine learning on the back end doing something, whether it's optimizing, like the way that I look, you know, my face isn't this smooth in real life, it's making me look better.
00:37:08.506 - 00:38:13.934, Speaker B: You know, like everything that we use and everything that we touch uses machine learning in some way that wouldn't have been possible if you had to chew glass the way that I did when I started my career. And so for me, making that developer experience have as low of a barrier to entry as possible, making the process of migrating your stack from Vercel or do or AWS or GCP or wherever you're at now, to Allegra, making that process, 1520 minutes max, hooked up, ready to go, and making it familiar where you're using the same commands you would be using in their CLI tools, on our CLI tool, where you can ssh in from versus code so that you have your terminal right there or your editor right there when you ssh in, making the deployment process as quality as possible. You know, all of those things are really, really important to me. Like the most important things to me, because without developers wanting to use our platform, we don't have, we don't have a platform like our customers.
00:38:14.594 - 00:38:50.350, Speaker A: Our customers should be of the highest priority. And a lot of teams are really, really smart and they build really interesting things, but they never become successful because of that. And then there's people that build products that are subpar, but the developer experience, the ease of use is so good that they get adoption and there's everything in between. So I think the sweet spot is obviously having like a really good product and a really good developer experience. But I have a few questions about AV's development specifically. But before I do, I was just asked if he had anything that he wanted to chime in on or any questions or anything.
00:38:50.542 - 00:39:08.784, Speaker C: Oh, yeah, I think I have a few questions. So right now, when so do you see like our, like currently, like, like all the operators using versatus as like one of the infrastructure to run their, like other avss?
00:39:09.684 - 00:39:43.172, Speaker B: Yeah, that's a really like, so like the nested node operator model. It's actually really interesting. So we've, we've been gaming this out behind the scenes, both for that and then like running Ethereum nodes. I don't know if you guys know this, but like a huge chunk of eth nodes run on AWS, like a huge chunk of them. It's like a huge risk to the network. There was an outage a few months ago and like Ethereum survived it, but it was close, like it was close to the default tolerance threshold when that outage occurred. So we do think that that will be a use case.
00:39:43.172 - 00:40:46.434, Speaker B: We think it'll actually become like a relatively prominent use case for Allegra is running validator nodes and operator nodes inside VPS instances on Allegra, and as a result of that, generating fees for the network and for the operators. And so we do think that that is a opportunity because we can keep the cost pretty low. I'm going to avoid talking about that to a certain degree because it involves our token. And just from a legal and regulatory standpoint, I don't want to talk about token price and stuff, but suffice to say, the way that the tokenomics are designed, they're designed to actually permanently undercut the centralized cloud providers and make sure developers are saving money. So it's a big part of our value proposition is to make sure that they're saving money. And we can do that because thanks to Eigen layer, we're using effectively latent resources that are being shared by multiple other AVss. I do think that that will be a primary early use case.
00:40:46.434 - 00:41:07.154, Speaker B: I think the other primary early use case will be for like matching engines for dexs, order books for dexs, and then like the front ends for DeFi protocols will probably want to use us because there's obviously like, if they can get that out of their hands, it reduces a legal and regulatory risk that they're currently facing.
00:41:08.254 - 00:41:40.434, Speaker C: Gotcha. And how right now I have used other decentralized clouds which have tried this, but the UX has been that great. Looking at the demos, it looks awesome. But what are your thoughts on the other decentralized clouds and how do you see the experience being more near to, more near to like digital oceans than like getting like getting a, like a cheap german vps?
00:41:40.934 - 00:42:23.818, Speaker B: Yeah. So like do is sort of our guiding, you know, like our guide in terms of like what we want the developer user experience to look like because it's like the droplet model is very powerful, you can do a lot with it. I don't want to say anything bad about other decentralized cloud providers. I will say this personally. I think a lot of them have chosen wasm as their primary runtime, which places just this massive barrier to overcome for developers. It makes it really, really difficult to build applications with the skills you already have. It's almost akin to just inventing a new language.
00:42:23.818 - 00:43:23.270, Speaker B: It's a little bit better than that. The other thing that I would say is that there's a lot of marketplaces that can, if you spend a lot of time setting it up, can operate this way, but you have to spend a lot of time setting it up. Some of the bigger compute marketplaces, technically speaking, you could automate the scaling process and purchase more resources and all these other things, but it's not really like built into it like a platform, the way that we're building this. So I think that that's really important having it be. The analogy I always give is like ebay versus Amazon on the retail side. On eBay, you know you're buying from a third party, right? Like it's very clear and explicit that you're buying from a third party. On Amazon you may be buying from a third party, in fact, oftentimes you are, but just it looks like you're buying it from Amazon, you probably tell people you bought it, right? So that's kind of what we're going for.
00:43:23.270 - 00:43:58.986, Speaker B: We want to be more Amazon than eBay. And I think that that's a good analogy. I do think that I'm glad that others have tried this before us. And by the way, some of them haven't. Like I hear people say, we get in this conversation, particularly with VC's, which we'll save that conversation for another day, you know, oh, such and such failed. And I go and look and I'm like, in what world is like a $6 billion market cap a failure? Like it's like what, it's not a hundred billion? That's so it's a failure because it's a 6 billion. Like that's crazy to me.
00:43:58.986 - 00:44:25.110, Speaker B: Like a $6 billion protocol is by all accounts successful. Now maybe it doesn't have the user numbers that you want, but like the market has spoken and the market is king and the market says that that's a successful protocol. There's also other $2.5 billion compute marketplace that's out there that a lot of you would know the name of. And I've heard people say that it's a failure. And it's been around for a year and a half. It's worth $2 billion.
00:44:25.110 - 00:45:00.764, Speaker B: In what world is that a failure? So I think there's a major disconnect between the investor world and the builder world. The builder world's looking to build cool stuff that, yeah, over time it's sustainable and it'll grow in value. The investor world is looking for 100 x day one. They're very impatient. They want it right away. It's like, you got to have a little bit more patience. One of the nasty parts about crypto, I think, that keeps a lot of people out is if you don't succeed immediately, people view it as a failure.
00:45:00.764 - 00:45:17.034, Speaker B: Fintech was a great example of this. It was three months in, it started going down and losing users, and everybody just like, forget about it. Like, it's over. It's been around for three months. What are you talking, like, give it a couple of years. At least let them.
00:45:18.374 - 00:45:30.278, Speaker A: Yeah, there is always that short sightedness here in this industry that, you know, you don't really see another. It's just too hype driven and less product and, yeah, yeah, and I think.
00:45:30.366 - 00:45:53.604, Speaker B: To the builders, like, just keep your head down and ignore that shit. I apologize if I can't curse, but I just ignore it. Like, ignore that. Like, keep building. If you have a vision, keep going forward. I think part of it is because tokens are public, right? And so everybody views the token and all this is. But it's like, ultimately, to build a quality product takes multiple iterations.
00:45:53.604 - 00:46:14.610, Speaker B: Ethereum is still iterating today. They have a roadmap for how they're going to improve Ethereum over the next, like decades. Like, Ethereum is not a final product and it's been around for nine years. So don't listen to the noise out there. Like, just build your product, build your vision out, iterate on it, make it better, improve it. That's the only way. And you need time.
00:46:14.610 - 00:46:32.744, Speaker B: And so just, if you're a founder out there, that's like, just don't run out of money. Be resourceful, minimize your burn, keep your costs low, and don't run out of money because you will reach the point where you get adoption, you know, and you just got to have that kind of grind set mentality.
00:46:33.964 - 00:46:50.436, Speaker C: Gotcha. And how is the, so how are the vp? Like, how is it priced? Like, how does. So, like, I want to run a node with like hundred gb storage and like 60 gb ram. Like, how would it be priced?
00:46:50.580 - 00:47:29.014, Speaker B: Yeah, so it's tiered pricing, but it's all based on our token and time. So one token gets you 100 hours of compute on the base machine in the network. So right now, what we're proposing, and this will eventually be governed by the restakers that are restaking in our abs. To start with, obviously we have to set some arbitrary base machine. The base machine right now would be the equivalent of a t two nano. So it'd be one VCPU, I think it's 256. 256 gigs of memory or of storage and eight gigs of ram.
00:47:29.014 - 00:48:14.070, Speaker B: I think something like that. Don't quote me on that, but effectively a one VCPU machine, basically like the smallest instance that you could get under the t two brand. And then so above that, if you go one level up, you know, then the cost goes up. If you go one level down, the cost goes down, but you're always paying in our token. And then the way that the network is governed over time, as compute becomes more and more available and there's more resources in the network, that base machine will go up and so, but you'll always still get 100 hours for whatever the base machine is with one token. And you'll always have that tiered pricing above and below that. So when the base machine goes up, everything goes up with it and the lower level machines become cheaper.
00:48:14.070 - 00:48:47.206, Speaker B: And the reason for that is that compute is actually a very inflationary resource. You've heard a lot recently about compute being the new oil or compute being the new gold, compute being the new currency. I agree with that. But I think there's nuance missing there, because compute itself is hyperinflationary. We're going to continue to get better and better. I bought my desktop, which was at the time top notch, deep learning desktop. Four gpu's, four Titan RTX gpu's like just kick ass machine, you know? Yeah, just killer.
00:48:47.206 - 00:49:10.794, Speaker B: I think I spent like 5500 for the base machine and then 2500 per gpu. It was expensive, but it was, it's, it's a killer machine. And this was in 2018. You can get like three times that for the same price. Now, like, I think I have 16 or. No, I have 32 cpu's or 24 cpu's, 48 logical core. 24 cpu cores.
00:49:10.794 - 00:49:44.114, Speaker B: You can get a 64 cpu core machine based machine for $5,500 off the shelf. Now it's almost triple the amount of cpu cores. So that's going to continue to happen. But what we can say is and also compute very heterogeneous. And so that makes it difficult. It's not a fungible resource. But what we could say is we can find something that sort of approximates homogeneity and something that, and time is something that's stable.
00:49:44.114 - 00:50:36.236, Speaker B: So 100 hours today is 100 hours tomorrow is 100 hours a decade from now. And what we know is that 100 hours worth of compute today will be twice as productive in four years, roughly, it'll be twice as productive. Your 100 hours of compute, what that token represents, becomes more and more productive over time. As a result of that, there's an incentive to save, to accumulate and save and spend it in the future, which is something that you want out of a currency, unlike the us dollar, which your incentive is to go and spend all your money right now, or take really risky bets because you're going to lose value by just storing it in cash. You want cash that's going to grow in value. You don't necessarily want it to go crazy up or crazy down. You want it to be relatively stable, but grow a little bit of value.
00:50:36.236 - 00:50:50.424, Speaker B: So there's a natural incentive to under consume. So that's the way that we've designed our token. We're going to publish a paper around this and everything, but just at a very sort of like high level spoken. That's the base concept of it.
00:50:51.764 - 00:51:02.494, Speaker C: Gotcha. That makes sense. And one last question. Right now, like all the vps servers are run by Versatus.
00:51:03.034 - 00:51:17.426, Speaker B: Yeah. So we're like in a, in a demo phase right now. Once we release our AV's contract, AV's operators will be able to opt into it. So, and that'll be coming in the next 14 days or so here.
00:51:17.610 - 00:51:29.094, Speaker C: Gotcha. And like how would this work? Select will. So these operators would need to like rent a cpu and like, like how would that actually work? Well, a lot.
00:51:29.134 - 00:51:46.394, Speaker B: So a lot. Like for example, I know the guys at a 41 really, really well. They run bare metal. They have, they have server racks in their office. Yeah. So a lot of node operators run bare metal. More individuals run like when they're starting up, they'll run on a vps.
00:51:46.394 - 00:52:19.894, Speaker B: But the best way to capture, you know, extractable value is to run bare metal and to keep your costs down and be energy efficient and all the other things that go into that. You're running a data center effectively, it's just a specialized data center. And so a lot of the node operators do run bare metal. So what they would effectively do is they would download our client. They would run our client our client would register them once it's up and running and bootstrapped into the network. They would have instance, they would get allocated to a quorum. They'd have instances that quorum is responsible for shared with them.
00:52:19.894 - 00:52:54.594, Speaker B: They keep redundant copies of that. And operators can run more than one node in our network. They can run 20 nodes, 50 nodes, 100 nodes in our network. We don't really care because it's not, it's not a blockchain. So they're not going to alter somebody's monetary value in their account by running more nodes. There is technically like a 51% attack type model where they could potentially delete a lot of the instances and make them not recoverable. So we still have to worry about byzantine fault tolerance.
00:52:54.594 - 00:53:15.464, Speaker B: But by running lots and lots of nodes that doesn't actually affect that particular piece of it. All that would do is add resources to the network so that we can service more. So node operators can actually run multiple nodes in our network. And so if they have a lot of excess compute that they're not using, there's no reason not to, to run it in our network.
00:53:16.364 - 00:53:44.954, Speaker C: Correct. So let me think. Gotcha. So like do you think you would like to have like some of these right now there are like multiple vps providers? Like there are so many like that providing like super cheap rates, but they don't really have a market like showcase it. So like do you want like get them into like running operator Eigen layer, get like some amount restrict to them?
00:53:45.334 - 00:54:46.380, Speaker B: Yeah, probably. I mean why not, right? There's a lot of latent compute resources out there. And so part of what we want to do is we want to bring more operators into the Eigen ecosystem. We scale with you guys, right? So like the more node operators that are running our AV's, the more applications that can be deployed to our network, the more developers that can use our network, the more services they can deploy to our network, the more use cases there is for our network, the more resources we can aggregate and allocate to different applications. Absolutely. The way I see the world going is actually I typically refer to as mom and pop data centers, you think of organic farms. So like there's been, I know a little bit about this because I own a farm in Iowa, but basically there's been like this move away from like these large scale industrial corporate farms to more like small scale organic farms because it's just much more profitable because you can sell your organic goods for such a high markup.
00:54:46.380 - 00:55:23.044, Speaker B: And so I see server farms going in a similar direction where you're going to have small, specialized mom and pop style server farms, like sitting in a strip mall somewhere. And you're going to have them all around the globe. All around the globe. So you're going to get crazy geographical and jurisdictional decentralization, but you're also going to have access to all of these resources. And as a result of that, we're going to be able to build fully competitive, at scale cloud on a purely decentralized network. That's what I'm really excited for. I think we're probably still like five to seven years away from that.
00:55:23.044 - 00:55:49.804, Speaker B: But I think Eigen layer kickstarts that process because now they can, like, why wouldn't you, like, why not go and like, lease an office, fill it with racks, put some solar panels, get like a really good air conditioning, and just, you know, run a bunch of, you know, Eigen Avss. And as Eigen scales, there's gonna be hundreds of things that you can run and earn money off of. So why wouldn't you do that?
00:55:51.264 - 00:56:20.774, Speaker C: This is amazing. Wow. Now that I'm thinking about this, this is really great because last week I was trying to run a run of Ethereum validator and looking around like this thing is if I run on a cheap german vps, I save 90% of my cost. But if I run it on AWS or digital oceans, I spend a crazy amount in, I save time, but I do spend a lot of money.
00:56:21.274 - 00:57:02.862, Speaker B: Yeah, either way, you're going to spend some money, you're going to eat into your profits. The best way to go is still bare metal. And I think that's where it's going to go. It's going to move away from these centralized cloud providers. We've got a collection. Part of what we're going to do as we roll out, we've got a collection of all the screw ups that cloud providers have had over the years. And like all the things that have gone wrong and can go wrong because of this extreme centralization and corporate control, whether it's censoring things that they don't like, whether it's, you know, faults in their, in their hardware that have led to like the loss of very valuable data, data breaches, billing nightmares.
00:57:02.862 - 00:57:34.514, Speaker B: Like there's an entire subreddit just dedicated to like, AWS billing nightmares where people like, wake up one day and have like a half a million dollar bill and they're like, what the hell happened? And so like, all of those problems are things that we are taking direct aim at to solve. And we think that they need to be solved. This is, this is, it's too important. Like, the cloud infrastructure is too important to humanity's future to just leave it in the hands of a few major corporations.
00:57:35.514 - 00:57:51.210, Speaker C: Got it? And how do you plan to, like, like, in case there is a downtown. By downtime. Downtime by any node. Like how, how do you plan to, like, if they go out for like, like half a day, then, like, it's, it's problematic. So like how do you think.
00:57:51.402 - 00:58:28.044, Speaker B: So it's problematic for them. It's not as problematic for a network because there's a quorum that has a redundant copy of. So there's, there's redundancy and resiliency built into the network. However, if you. So where, like, for the conversation where our thresholds are is 40% plus one of a quorum. If 40% plus one of a quorum becomes faulty, then that quorum has, the entire quorum has to go and they have to be, the rest have to be reallocated. And if 40% plus one of the quorums in the network become faulty, then we start to run into issues there.
00:58:29.324 - 00:58:30.356, Speaker C: Sounds good.
00:58:30.540 - 00:58:31.276, Speaker A: I know, I know.
00:58:31.300 - 00:58:33.844, Speaker B: We probably are bumping up against time here, huh guys?
00:58:33.964 - 00:58:50.388, Speaker A: No, we are, we are, we have to wrap up. But one last thing I want to touch on is can you give any people watching that are building abs, is any advice for, you know, anything that you've learned, but also just in general, I guess, like about building on Eigen layer.
00:58:50.556 - 00:59:22.868, Speaker B: Yeah, start small and go incremental. I think that like, when you first hear about an AV's and like what you need to do to build an AV's, it can potentially be overwhelming, but it actually isn't all that much if you just start with this. So start with registration, deregistration, then you can worry about payments. And I think the way you guys are rolling out actually helps with that because like, slashing isn't a thing yet. It's coming, but it's not here yet. And so, you know, you don't need to worry about slashing right away from day one. Think about it.
00:59:22.868 - 00:59:43.144, Speaker B: But you don't need to implement that logic right away from day one. So start, get started and then move incrementally to improve it. But I think that the concept is more difficult to wrap your head around than the actual process of building it. You guys have done a good job of that. And like, the amount of tutorials and resources available are pretty robust.
00:59:44.644 - 01:00:00.996, Speaker A: Okay, awesome. Well, this has been really great. Really excited to see when all this starts being made available publicly. I know. So laser is already available. You can start using it now. And Allegra is going to be coming in the next couple of weeks.
01:00:00.996 - 01:00:15.208, Speaker A: So if you're watching this in a couple of weeks, it might already be out. But if you're watching this live, it should be coming up soon. So if you want to learn more, follow versatus on social media. I'll go ahead and drop. They are versatus labs.
01:00:15.316 - 01:00:15.656, Speaker B: Yep.
01:00:15.720 - 01:00:19.928, Speaker A: And your name, that is like this. That's your. Same as your Twitter handle, right?
01:00:19.976 - 01:00:39.040, Speaker B: Same as my Twitter. That's why I put it here. Crypto nomicon. Crypto nomicon. And if you, if you get the reference and you dm me, we will send you some swag, but only, only if you haven't already told me that you know the reference. Like, you know, there's a few people who have told me or that I've told, so don't. Don't give it away.
01:00:39.040 - 01:00:47.354, Speaker B: But, yeah, if you dm me with explaining the reference to my name, then I will send you some swag. Some for Seida swag.
01:00:48.734 - 01:01:00.350, Speaker A: Nice. All right, well, thanks for your time. Thanks for coming on, and thanks for everyone that watched. We will be coming back next week with another episode, and until then, I will see you around.
01:01:00.502 - 01:01:02.054, Speaker B: Thanks, guys. Thanks so much for having me.

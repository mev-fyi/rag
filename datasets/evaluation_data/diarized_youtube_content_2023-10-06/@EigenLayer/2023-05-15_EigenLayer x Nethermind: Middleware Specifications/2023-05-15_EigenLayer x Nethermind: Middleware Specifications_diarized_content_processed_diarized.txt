00:00:00.090 - 00:01:13.570, Speaker A: Hi everybody, welcome to the Eigen layer node operator Specs presentation call. It has been a great pleasure to partner with Nethermind on actually developing the node operator specs. We have had the privilege of working with Swapnil and Miguel and the rest of the folks at Nethermind on building the node operator specs. It's mainly been their lead, so very happy to have them present the node operator specs which we put up on the restaking Nethermind IO website. So what we will do in this call is have the Nethermind folks lead us through some of the details of the specs and we can also solicit feedback from many of you here so that we can kind of think through any issues or things that we may have left out in the original specification. I also want to thank all of you for taking the time to come and attend this meeting and give us feedback. I think Swapnil was joking just a minute back that you should call this the eigenvector coding.
00:01:13.570 - 00:01:25.110, Speaker A: I think there is just an insane amount of talent and horsepower here that very thankful for. With that I'll hand over to Swapna.
00:01:26.410 - 00:01:29.580, Speaker B: Cool. Asmath, could you share your screen?
00:01:36.630 - 00:01:37.940, Speaker C: Can you guys see?
00:01:39.190 - 00:02:27.118, Speaker B: Yeah, right, so just some preface on what we're trying to attempt here. This spec is a spec for the AVS node software, so that if all the node providers follow the same spec, the operators will have a smooth experience of running, managing their nodes, monitoring and all that. And with the foresight that if all the operations are similar, then we can make a CLI tool which optimizes and automates a lot of these operations for the node operator. In this version of the spec we are focusing on the solo staker. So this is only for on premise setups. This could be extended for off premise setups or like multi node setups. But right now we're just focusing on of assumptions, some of the networking features that we use from Docker spoilers.
00:02:27.118 - 00:02:50.746, Speaker B: We use Docker kind of forces to be linux only, and that's a docker limitation. But it's not a massive limitation. And large parts of the spec work for macOS and windows. Some small features make it Linux only. Cool. Next slide. Yeah, so I've basically been through that.
00:02:50.746 - 00:03:22.210, Speaker B: Some of our ideas come from EIP 2195, which is proposing basically a standard way for node software to export metrics and stuff. And this is kind of what we're attempting again for the eigenve ecosystem because we see the problems or the troubles of maintaining nodes in the Ethereum ecosystem next slide. Cool. So here I want to hand it off to Akhmath who will talk us through about how we propose we should package our node software.
00:03:24.870 - 00:04:33.100, Speaker D: I will take on this. Yeah, Sony said we are trying to solve here some problems and one of them is the standard packaging for installation of EBS nodes. And we have in mind big problem that we have in Ethereum right now, for example, because there are several clients that do the same thing and behave the same way for the consensus layer and for the security layer, but each one is set up monitor differently. This makes very difficult to create and maintain like a single tool or set up wizard like rocket pool smart node or netherminds edge for smart stakers and also makes pretty difficult to implement a monitoring system while diversifying clients for institutional stakers. So in this case, this is our packaging proposal. We are trying to use Docker and Docker compose as a main technology to manage the nodes. In this case, Docker solves the dependencies or environment problem.
00:04:33.100 - 00:05:36.480, Speaker D: Docker images will be published to a docker registry. A docker compose script inside the package will define how to run the EBS node. EBS developers can make use of several Docker compose services to add like a utility container or a database, basically any external service or utility service that you might want to use. And also you can run everything on an insulated docker network. So this will work kind of firewall and the main files the main configuration files of our package proposal is the manager file and the profiles file. In this case the manifest file is the main of everything. It defines the version of your node, any hardware requirements that you might want to enforce or not.
00:05:36.480 - 00:06:45.570, Speaker D: Define the plugins we are going to describe the plugins in a while and the profiles. In this case the profiles. What we have in mind there is, for example, you might have a preset configuration for several networks, for example let's say Gurley or mainet. And you don't want the users to change some arguments or options to run your node that won't change for any girly instance, for example. So you want the user to focus on changing options like ports, stuff like that, generic stuff, but not on preset configurations. And the profile file will define all of these options that you want to get input from users. The EVs setup wizard will take care of this via prompts or flags to ask the user for all of the information required to run the node, for example like ports.
00:06:45.570 - 00:07:42.070, Speaker D: In this case, the format that we choose for these files is Yaml because it's human readable. Next slide please. The package must be located in a git repository called top. This is inspired on the homebrew approach and in this case all of these tabs will have to follow the pattern name for agent dash and then the project name. Evs developers will have to maintain this repo and make sure that they put the good required structure for your package. And let's say you have a new release because you want to update your node. Then you have to change the required files here and create a commit with a git tag that represents the new release.
00:07:42.070 - 00:08:57.760, Speaker D: This way people and tools can subscribe to the tag and automatically do something when a new update comes from. And also it might be an agent layers central repository git repository that will work as a public index for all of the tabs you as an ABS developer will have to worry about. Just only create a pull request to this public index to register your tab, but it won't be mandatory. On the right side of the slide we will have reference for the file structure, the literary structure, sorry, of the tab. In this case the package will be on the PKG folder. In this case mainnet and girly represents two profiles. Two example of profiles whose main files are the docker compose, JaML and NF and the profile in this case the docker compose will define how to run your node with mainnet or gurley based on your hard coded or defined options.
00:08:57.760 - 00:09:21.430, Speaker D: If you notice there is a dashboard in a panel folder, these are for Grafana, but we are going to talk about this later. Next slide please. Now my good friend Ahmad will guide you through some very good guidelines on how to make your node easily updatable.
00:09:22.890 - 00:10:45.680, Speaker C: Thank you Miguel. So basically the idea that we had is that to have some pointers for node operators on how to keep their node software, sorry for node developers to how to keep their node software easily updatable. So as explained, we chose docker and docker compose for containerization orchestration. This allows the ability for the user to easily update the software using a new version of the Docker compose file if he needs to. Another pointer that is quite important here is for node developers to keep in mind about migrating from one database version to another, especially when we're talking about relational databases with different schemas from one version to another. It's great to utilize some migration management systems for this that will basically migrate the schema from the old version to the new version for the software, as well as to keep in mind if they're using a key value database like BrooksDB for example. That when updating from one version to another, there is backwards compatibility there and the old databases that the users are already running will not break.
00:10:45.680 - 00:12:00.760, Speaker C: One thing also about state and shared state between multiple services in the same ABS is that they have to be able to deal with different versions of messages and stored state in the same volume, for example. And a small tip here for making things easy to managing shared state is to use event driven architecture between the services. That way it's a little bit easier to accomplish this task. Lastly, but not least, hopefully we are working on the ABS setup wizard tool. It's in development and basically it will make things easy for the user to upgrade from one software version to another with a single command. It will also make it easy for the user to roll back because it will do a backup before updating, for example if the user wished that. So it's good to follow the spec so you can be compatible with this ABS setup wizard too.
00:12:00.760 - 00:13:08.122, Speaker C: One of the other things that I would like to talk to you about is why did we choose Docker and Docker compose instead of systemd? Even though this would introduce software dependency on Docker for middlewares to run, we saw that the benefits outweigh the problems outweigh I lost the word. So basically, in Docker compose you can easily manage the lifecycle of multiple services with one command as well as. But you can do that with systemd you have to command each service to go down one by one. With Docker compose you can have private networks. So like the services that are running on the user's machine will not share the same network as the host. Whereas for system D that is not possible or not available out of the box. That is, you can also have isolated access to the file system for each AVF.
00:13:08.122 - 00:13:57.950, Speaker C: So through volumes for Docker compose, whereas with systemd that is also not available out of the box, you can easily backup using Docker comet and copying the volumes, taking backups of the volumes that's also not available out of the box from system D. And as well you can execute plugins which we will talk about at a later stage easily in the same environment that all the other containers and services are running, but out of the box. System D does not usually support that, so possibly it would be harder to run a plugin because it will have more custom logic in it. And now I will give it to Adrian to talk to us about backup and restore.
00:13:58.530 - 00:14:52.170, Speaker E: Thank you Matt. Well, as Ahmad mentioned, one of the feature we anticipate for the CLI tool is the ability to update. However there may be instances where the process does not go smoothly, leading to data loss from the previous version. To address this issue, we will develop a backup and restore system. With this system, users can create a backup of a node before updating it, and in the event of any issues during the update, the user can restore the previous version without losing the data. So next slide please. Well, this is the basis of the backup and restore, and one of the key considerations there is that it needs to be agnostic to the process.
00:14:52.170 - 00:16:19.900, Speaker E: Inside containers and node setups in general, this is one of the advantage of use Docker as the base of the setups. Docker containers and their volumes are self contained units that can be easily saved regardless of the process inside. Right? So this means that we can save a noise to top by saving all the containers and volumes in the Docker compose file. From the perspective of host resources, the excessive use of the backup and restore feature by node operators call a significantly increased disk usage. However, this cost is necessary to avoid data loss. Next slide please. Now I will talk about plugins because in some cases certain node setups may require actions specific to their structure or services that are not common to all setups and it is not feasible to implement specific functionalities for each one, right? On the other hand, specific functionalities are necessary for the tile control of each node setup, and that's why we raised the idea to provide this plugin system.
00:16:19.900 - 00:17:36.120, Speaker E: Next slide please. Well, what are the two principles here about plugins? Plugins are stored as Docker image, which contain the environment dependencies and the code for the plugin. And when the plugin is executed, a new instance of the image is created as a docker container and run in the same isolated environment of the Docker network as the node setup. This allows access to node services while keeping other setups on the same host secure, taking advantage of the docker networking system. Also, the CLI provide to deploying access to no setup services, so developers should keep this in mind when they are building the deploying and declaring configuration for the services during setup. They are responsible for ensuring that deploying interacts correctly with the noise setup, such as exposing an API in the setup for future use of the plugin. Next slide please.
00:17:36.120 - 00:18:57.470, Speaker E: Well, how plugins are installed? Well, developers should include installation instruction for deploying in the manifest file of the node package, and this can involve specifying the target image or relative path to a docker file inside the package to build the image. And when the user installs a new node, the CLI tool reads this information, automatically, downloads the image or builds or bricked it, making the plugins ready to use. To keep track of the relationship between plugins and node setups, the CLI stores all the necessary information in a data directory that we call state. This is necessary because there is a one to one relationship between plugins and node setups, meaning that a plugin can only access the noise setup from which it was installed. Next slide please. Well, this is a basic image or representation of what a plugin is. In this case, we have the host machine with the CLI process communicating with the plugin container, right? And the plugin container is an instance of the plugin image.
00:18:57.470 - 00:20:10.614, Speaker E: Notice that the plugin container are running in the same docker network of the noise setup and service 1213 are, in this case of the services in the docker compose of the noise setup. The relation between plugin container and services, as I mentioned, is responsible for its responsibility of the developers because they need to expose some API on the services to be used by the fluid container. Next slide please. Well, finally, these are some examples where plugins could be useful. The first example is register using information like public keys or mnemonic for on chain interactions. For example, in Ethereum you can start seeing the node without having the key store in the validator, right? And then you can add that after the sync. We can do the same here using the plugin system or something similar.
00:20:10.614 - 00:21:03.430, Speaker E: Other example is run some maintenance tools like database pruning. In the case your setup can have these maintenance tools, you can run it using the deployment. And the last example is more general and is enable or disable node functionalities. For example, if you have a new feature in your node, a better feature, let's say, and this feature is disabled by the file, right? Then the user can enable or disable the feature using the plugin. Next slide. Well, that's all, Miguel, let's talk now about the metric specification.
00:21:05.690 - 00:22:25.026, Speaker D: Hello again. Yeah, this is the second main component of the specs. It's the metrics one. This is very useful for all kind of operators or users because some of you might notice that the on premise setup with a tool very similar to rocket pool and using docker compose is not like very compatible with institutionalized, what institutionalized takers do because they usually run current clusters, right? But we have this in mind for the metric specification because it will be very useful for everyone. We, as very experienced people running nodes at a huge scale, we know this and have this in mind. For example, let's say monitoring and metrics, as you may know, is an essential part of a node operator processing is the most difficult part because you all the time have the docker images and the containers, but you don't have a tooling for monitoring. For example in Ethereum, nodes don't have a standard monitoring interface or infra for this.
00:22:25.026 - 00:23:55.470, Speaker D: Even when these nodes or clients implement Prometheus metrics, because each client has a different implementation of these metrics, which makes very difficult to set up a solid and genetic monitoring infrastructure, we want to avoid this problem in agent layer from the very beginning. Defining a metric specification. Each agent layer or EBS node have to implement and follow in solve the problem. It is simple and consists of three things in HTP API, some Prometheus metrics standard Prometheus metrics are going to define and recommendation for setting up Grafana dashboards yeah, as you see on the points there and some key point to mention, sorry, is that if you use the ABS setup, the tool, we will aggregate these metrics, the standard metrics that we're going to define right now, and also host metric machines like resource usage and put them on a single graphana dashboard that is not included in the package. Next slide please. Let's discuss some of the benefits for users and also for evs developers. Some of them is that it's the unified monitoring interface for multiple evs node providers.
00:23:55.470 - 00:25:00.722, Speaker D: This means you can plug in different new evs node to your infrared setup and your monitoring setup will work on the new node with minimal changes. Some of these minimal changes is that you need to change the target, the configuration of your Prometheus instance to use the new target, but that's all. This also talks about the easier configuration and installation and monitoring of these instances. You need only a Prometheus container and you're good to go. In the case of the if you are using the EBS setup wizard that we have mentioned, this tool will handle this automatically and maintain the required monitoring setup, including Grafana instance for your dashboards. We are mentioning Grafana and Prometheus a lot, but these are very mainstream and powerful tools that are widely used in the community. Users can use the dashboard published by EBS developers and customize them.
00:25:00.722 - 00:25:51.918, Speaker D: They can also set up alerts on top of the queries used to describe the different graphs and panels within these dashboards. Next slide please. For EBS developers, this offer better insights into software performance and health. This is because users will be using the same monitoring interface across several instances of your node, which allow a better feedback process. Also provides an effortless integration with existing monitoring tools and it's easy to implement if you know Grafana and Prometheus. These tools are integrate easily with a lot of services and tools out there. And Prometheus supports a big set of programming languages and implementer.
00:25:51.918 - 00:26:34.420, Speaker D: Implementing a Prometheus supporter, sorry, is often simple and kind of mandatory because of its overall usage. It's well used. Next slide please. The first component of the medical specification is the HTTP API. It's very simple. It has only five endpoints to implement and the main endpoint here is a health endpoint. It's simple and very handy for load balancers, both sidecars for kubernetes, clusters, docker compose, health checks, and basically any component or service that is interested in this node health next slide please.
00:26:34.420 - 00:27:26.030, Speaker D: Okay, let's go about the Prometheus metrics. The two main rules here is that there are going to be some standard metrics that each evs node will have to implement. And this metric has the agent underscore prefix and this is like reserve. You will be able to implement custom metrics, but you can use that prefix. These standard metrics covers economics metrics, performance metric and RPC request related metrics we are going to see right now. Next slide please. So these are the economics metrics he was talking about and briefly describing them.
00:27:26.030 - 00:28:27.842, Speaker D: The fish metrics capture the total amount of fish earned by a specific token by the node, whatever token use, you can use token for this. The second one measures the total amount of such incurred in a specific token by the node, and the third one displays the node's total balance in a specific token. Next slide please. The agent performance score is the only one related to the performance of the node. Score is a number between zero and 100 and ABS developer is free to choose or decide how to calculate this score. The other two are about related to the RPC request because it's very difficult to find an EBS node that won't be connected or interacting with an execution ethereum execution client or with an exposed JSON RPC API. So these metrics are about these requests.
00:28:27.842 - 00:29:03.620, Speaker D: Next slide please. And the final one just provide version metadata information for the very straightforward next slide please. Let's go to discuss some of the strengths of this specification. This provides a unified monitoring experience for multiple node instances. This is very similar to what we have mentioned before. About all of the users will be using Prometheus and Grafana for the software. They know how to use it.
00:29:03.620 - 00:29:53.780, Speaker D: Integrating new node is very easy to your setup. Even if you're an institutional staker, you're probably using Prometheus for your Kubernetes cluster and even grafana. So you need only to update the configuration of steel monitoring setup to integrate an ABS node that follows this specification. Of course it's integration with these popular tools. They are open source, they are free, they are very tested and very mainstream solutions on this community. In particular, it allows better software development practices among ABS developers because we are going to follow the same spec and this will improve communication between all of us. Next slide please.
00:29:53.780 - 00:30:56.180, Speaker D: Yeah, we think it's a good idea to try to show you some best practices and recommendations for keys management because most likely EBS nodes will often interact with some sort of keys or secrets. And this kind of raise a need for sharing suggestions and best practices for key management not only for developers, but also for users that are going to use these nodes. The goal here is always reach top notch security, but without compromising accessibility too much. Some of the key points here are importance of the keys management for developers and users. Developers need to understand proper key loading practices and we are going to explore that. Next and user need to manage keys effectively. Next slide please.
00:30:56.180 - 00:32:07.580, Speaker D: Okay, so we're going now to present and show you some of the approaches you can use for managing your keys. In case your keys are in the host machine or remotely. The first one is prompt for the passphrase or for the secret in case if you choose this method then you need to make sure the input needs remain hidden because most likely you're going to ask for this information in a terminal buffer and this can be persisted and attackers could search for it later. And in case we don't recommend you to proceed or save this secret unless it's encrypt, but try to avoid it. The second method is requesting a path to the key store folder or the secret file, the password file. In this case this secret is not saved in the buffer unless you print it or log it that you shouldn't do it, but also attackers could access this file. This is not like perfect.
00:32:07.580 - 00:33:19.380, Speaker D: Next slide please. One stronger method here is to retrieve the decryption key remotely and have the key encrypt in your machine that the attack surface case is slower and attackers will have to rely on advanced attacks like extracting the decrypted key from memory or impersonating the node process to receive the decryption key. And one of our favorite method is utilizing remote signers. In this case, one of the remote signers widely used on Ethereum right now is web three signer from consensus. And basically if you support a remote signer, you will be delegating the signing process to an external service or device. And the vulnerability here is about the availability of this remote signer or the communication that you implement between your node and this HMO signer. Next slide please.
00:33:19.380 - 00:34:52.190, Speaker D: Okay, so our really main recommendation for evs developers is to implement a seamless method of writing keys or secrets, such as asking for a path to the keystore folder via environment variables or CDI arguments. You can use plugins to process the given keystore and transform it to something the software knows how to read. These are the plugins that Ariane discussed before, or even let the user to generate the keystore according to the input provider. So this requires that you have to maintain or define a specification for the keystore structure that you want to follow. This is something that, for example, consensus clients in Ethereum do not all of them use the raw key store specification defined by the AIP. Implement all of them, get the keys and the passwords and put them in a no structure that they know how to read and maintain. Apart from this, it will be ideal if you listen to any changes in this keystore folder so dynamically you can handle any key change without requiring to restart your node.
00:34:52.190 - 00:35:50.370, Speaker D: Next slide please. In the case for users or solid stakers, there are a few recommendations from them, but let's be honest, not all of users implement good security measures with it, even when almost of the point. Focus here. Focus on creating backups and safely keeping the key. We won't spread them too much, explore them too much right now, but we will highlight a significant fact. This is that most of the secrets and keys or losses occur due to loss of the hardware on which the key resides, or losing your backup instead of losses from an attack. This doesn't mean that you shouldn't take measures to protect your keys from attackers, but keys and backups should be inaccessible as possible, ideally being entirely offline and physically secure.
00:35:50.370 - 00:37:24.830, Speaker D: Just to show this point in the next slide, we are going to see a small subset of these best practices that are the most often used by users or operators. Next slide please. And even when they most likely only implement these measures, or maybe one of them for not operators or huge stakers, institutional stakers, we have some recommendation for them as well. And this is use services like AWS secrets manager or hashicle vault to store the keys or secrets. We prefer hashicor vault because you can set up and maintain your own instance of hashicor vault. Use remote signers. This comes with a performance heat, but it's very secure and also in case of outage is safe and reliable in case that you're using seeds or mnemonics to generate your keys or your secrets.
00:37:24.830 - 00:38:17.220, Speaker D: If you have many like more than 500 secrets or keys that are generated, we recommend to use several mnemonics for this and split them for a new mnemonic or seed for every 200, 500 or 1000 validator keys. And something that we also do is we develop custom solutions. For example, you have our graphical bolt and you can implement or develop a tool that handles the keys, how the keys are saved, if you're checking for duplicates there and stuff like that. Okay, next slide. Sanel, you have some closing comments. Thank you guys.
00:38:19.030 - 00:38:45.660, Speaker B: In the end, basically we realize that we're trying to make a specification for a very wide amount of use cases and we might have missed some use cases or use cases that we just can't imagine you will probably come up with. So if you have any suggestions please, we're always looking forward to some of your feedback. We're happy to chat and set one to one calls with you. Yeah, thank you. Are there any questions?
00:38:54.050 - 00:38:57.070, Speaker D: Maybe we can begin with some of the questions in the chat.
00:39:01.890 - 00:39:03.140, Speaker B: Do you want take to the question?
00:39:04.550 - 00:40:23.500, Speaker D: Okay, I think the first one is from Gustavo. Any plans to create tooling to support Kubernetes environments in the future? Yes, in this case our main plan is to like right now we are thinking about two solutions here. One of them is using the docker compose from the package specification and generate helm charts from it. We know that you're going to miss some key features for kubernetes here, but we're thinking about letting the user provide what is left there. And the second solution will be something along the lines of you as a ABF developer, you define the packers like this, but you might also want to define a hem chart. That would be ideal, but it can be like quite expensive thing to do for developers that are not familiar with hem charts or kubernetes. But yes, off premise wrap is on our mind all the time.
00:40:23.500 - 00:41:22.880, Speaker D: And even though if we don't came up with a good solution for it, we think the metric specification will be very useful. Because for example, you can create smart tooling for, let's say your pod cycle for readiness or of liveness that use the health shake endpoint from the API. And you can use the Prometheus metrics, the standard ones at least in case you want to run several different evs nodes. Anything about that? If I jump into the next question, I see a question about how our test plan to be integrated. I don't think we understand that quite well. Could you please elaborate more on that?
00:41:24.930 - 00:41:39.860, Speaker A: Yeah, so this is Sentel. This question was specifically related to database migrations or schema migration. Post the migration, if you want to run some tests to check on the sanity of the data.
00:41:40.630 - 00:41:42.500, Speaker D: How do you focus doing that?
00:41:46.550 - 00:42:09.290, Speaker B: Right, effectively, you want to use the spec or the CLI tool as a development tool as well. It's something that I don't think I had considered, but that's kind of interesting actually. I think we, I don't have an immediately good answer for you, Miguel Asma.
00:42:14.210 - 00:43:21.102, Speaker C: Not really. We haven't really thought about that much. But yeah, I mean, if managing the schematics of the database happens on the node side, and the node side then continues to work effectively after the schematics of the database has been updated, that means the schematic has been updated successfully. In case of failure, the health check from the node will be false. And if you examine the logs, you would probably see that there's some kind of failure while upgrading the schematics of the database. Basically what we did is that we threw this kind of upgrading schematics part into the developers side, because not all developers are using relational databases that has schematics and could be updated. So it's the developer's responsibility to kind of make sure that on the upgrade, the schematics upgrade has been done correctly.
00:43:21.102 - 00:43:28.040, Speaker C: And the note software is the one that should make this confirmation. Okay.
00:43:29.290 - 00:43:30.680, Speaker D: Yeah, thank you.
00:43:32.890 - 00:45:24.250, Speaker C: I also see a question about El, how are you guys approaching making this compatible with running an e two proof of stake validator? For example, many validators already run eth Docker. Net, which already using modular docker compose files, right? So basically what we had in mind is that we will leave the running validators or proof of stake validator to the user. So the user can choose to run it in a docker, he can choose to run it through a tool like Rocketpool or Nevermind sedge. But if the middleware that you're running or the node software that you're running requires a connection to adjacent RPC, then you can provide the port where that software is running to it and it will connect and utilize it. So imagine that you are a user. You have an ethereum proof of stake validator running on the machine, and as well you have two node softwares for two different avs running, and both of them require JSON rpcs. Then you can point both of them to the same JSON RPC endpoint that you're maintaining, but it is not part of the spec or part of the CLI tool that we are building, which is the ABS setup weather tool to manage the eth proof of stake validator software.
00:45:24.250 - 00:45:40.890, Speaker C: Okay, another one is do you plan to provide support for distroless docker images? I guess Miguel or Adrian can answer that.
00:45:45.440 - 00:46:43.980, Speaker D: Well, it depends on the architecture of the stocker image. Well actually we didn't mention this, but the specification right now focus on running for example the package and the ABS nodes on Linux machines regardless of the cpu architecture. But if your image can be run well, virtualized well by a Linux machine then you'll be okay. Maybe this is something good to specify on the specification because of course on your docker registry you can publish the docker image that is not support or can be run in Linux.
00:46:49.620 - 00:48:03.268, Speaker C: Right. Another question is, is it possible to access the remote database like AWS services with? I mean yeah sure. If you're running the AVS software on a docker compose that has access to the Internet and the network or docker has access to the Internet then yeah, it will be able to access remote databases. But obviously you have to also set up the AWS service to accept remote connections. Right. One more is curious, how if you can make not upgrading a slashable offense or how you can sync node upgrades with updates to slashing conditions. Right, so we had a discussion with the Eigen layer team about this one and we thought that following the Ethereum approach is the best option where you basically upgrade before you start a fork.
00:48:03.268 - 00:48:46.484, Speaker C: So basically your software when you upgrade needs to continue working in the old manner till a certain point in time or block number or whatever, it forks and it starts working in the new manner. But the software needs to be upgraded beforehand for this operation to continue. But yeah, that's the idea that we have. The nice thing about this approach is that this is not a blockchain. Avs note, software most likely will not be blockchain like most of them.
00:48:46.522 - 00:48:47.108, Speaker E: That is.
00:48:47.194 - 00:49:19.520, Speaker C: So there is a possibility that you might not need to maintain old code. So each version will need to maintain old code only for one previous version and up and one previous version and then you can delete the previous previous version code that is not needed anymore, for example. So like maintaining the code you will not have that technical burden you're carrying with very old code. Like for example what you have in east node software.
00:49:27.300 - 00:49:28.450, Speaker B: Any more questions?
00:49:42.840 - 00:49:43.590, Speaker E: It.
00:49:45.320 - 00:50:16.300, Speaker D: Yeah, okay. When migrate new version of application, for example, it may require some migration of old database schema, something like that. In that case we should provide the migration tool also to container.
00:50:21.040 - 00:50:32.590, Speaker B: Yeah, I think you could provide a migrating tool as a plugin which is also invoked by your update process. I think that's what we had in mind.
00:50:35.240 - 00:50:36.550, Speaker D: Plugin. Okay.
00:50:52.090 - 00:50:55.670, Speaker F: Any more questions, comments, feedback?
00:51:02.730 - 00:51:11.690, Speaker B: I'll also share a replay. It's open source, so if you have any questions or any, you can also contact us through there or through our emails.
00:51:18.850 - 00:51:55.900, Speaker F: Awesome. Thanks Sop Neil, Ahmed, Miguel, Adrian for the presentation. Thanks everyone for attending coming to this call. We are recording this presentation, so we'll share the recording with everyone. You can check it out async later on. And many of you are already in touch with Nethermind team so you can ask questions soon enough. We'll have other teams also connect with Nethermind in Telegram and yeah, you can.
00:51:56.750 - 00:51:59.420, Speaker C: Feel free to ask questions more on this.
00:52:02.510 - 00:52:03.000, Speaker D: Thank you.

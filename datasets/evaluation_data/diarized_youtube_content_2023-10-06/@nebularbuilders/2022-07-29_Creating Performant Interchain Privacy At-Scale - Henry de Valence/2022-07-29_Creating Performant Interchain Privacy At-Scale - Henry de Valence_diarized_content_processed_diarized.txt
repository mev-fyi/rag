00:00:10.360 - 00:01:01.206, Speaker A: So yeah, I'm going to be talking about scalable private clients. And this is mostly the talk is based on the work that we've been doing for Penumbra specifically, but a lot of the kind of design ideas I think are more generally applicable. So, although I'll be talking about penumbra, you know, feel free to take any of these ideas and run with them to start, it's maybe helpful to give some context for everyone on what penumbra is, if you don't already know. So Penumbra is sort of a triple of three things. First of all, it's a private proof of stake l one built directly on top of tendermint consensus. We have our own app on top of that, and what it provides is a cross chain shielded pool so you can take any IBC asset, record it privately on this chain. Okay.
00:01:01.206 - 00:02:16.532, Speaker A: Why would you want to do that? Because it also has a private Dex that's integrated into the consensus so that you can do things like sealed input, batch swaps, or do private market making. And like I was mentioning on the panel, our thought is that that's kind of an interesting application for privacy, because you can build a product that's actually better because it's private and not just, you know, oh, it's nice to have privacy. So this is sort of this like grand vision. You have this sort of bigger cosmos ecosystem, all these transparent chains, and then people can do IBC transfers into penumbra, and once they're inside of penumbra, everything that they do on the chain is private by default. Okay, so that's kind of enough of the context. But the big question that we have is, like, how do you build some kind of like modular, scalable clients for this private blockchain? And the big challenge that we have to deal with there is about state and data models. I think that there's a little bit of a misconception, or maybe it's that people are kind of overindexed on it.
00:02:16.532 - 00:03:17.938, Speaker A: Um, there's a lot of excitement about proving technology, and I think part of that is because there have been a lot of really interesting and exciting advances in proving technology, and that's great, but it's actually still sort of like only one part of this combined system. If you actually want to build a private system, you have to think about, like, what is the state? What is the data? So to get into that, let's talk a little bit about the difference in state model between a transparent chain and a shielded chain. So on a transparent blockchain, you basically have a global, mutable state. Every transaction says, here's some actions that I'm going to do. I'm going to interact with this contract. I'm going to send this message to some part of the system that's all transparent and public, and all of the nodes are coming to consensus on those transactions, and then they're applying them to their global, mutable state. And on a system like Ethereum, basically the whole world sort of stops for every transaction.
00:03:17.938 - 00:04:00.602, Speaker A: That transaction can edit any part of the state, and then you go on to the next one. In contrast, in order to have a shielded blockchain, you have to have composable state. So a lot of the time people refer to this as the Utxo model. I think that's generally a terrible name because it's inheriting a lot of assumptions about the way that bitcoin works. But you can think of Utxos as like one instance of this state model. The idea is instead of having this big global state, we're going to have what the chain consists of is this tree of little state fragments. And then every transaction is going to consume some state fragments and produce some new ones.
00:04:00.602 - 00:05:48.112, Speaker A: And the state fragments themselves are generally immutable. Okay, why would we want to have this kind of fragmented system in order to have a shielded chain? It's because first of all, we can replace all of the individual state fragments with just like a commitment to what that data is. And then instead of having to sort of directly specify what the transaction does, we can have the transaction consume its input states and produce some new ones, and then also sort of seal all of that up inside of a ZK, proof that this whole state transition was done, honestly. But you'll notice here that these sort of solid squares that's supposed to represent some data that a user actually has, and the middle one or the hollow ones are just some commitment to the data, like a hash of it. And the big problem here is that now you've actually sort of, although the focus is on, oh well, we've made it private, what's actually happened is that you've moved the execution from the full node that's running the chain state machine onto the client, and all of the data has been moved off chain like great, yay, we win privacy. But now you have this question of like, okay, how does the client actually get that data? How does the client maintain the state that it needs? In this case, you're going to need the client to prove that all these state fragments that it's using were part of the chain state, what data does it need to make that proof? And that's kind of the problem that we get into with trying to design some kind of scalable client. So there's this question of what do we actually have to do, first of all.
00:05:48.112 - 00:07:16.624, Speaker A: So I've made this sort of diagram of this tree of little state commitments. There's two basic problems that a client has to do. First of all, it has to do detection. So if you have this private system where you're not just identifying the sender and receiver of every transaction, a client has to figure out through some other means, what of these new states do I actually have visibility into or control over? If someone sends me funds in a transaction, how do I learn that that happened? So this is the problem of detection. There's also this sort of, as part of that, the client needs to maintain some kind of state that's illustrated here in these gray lines, has to maintain some kind of authentication paths for how do I convince somebody else that this pieces of state that I know about are actually part of the sort of global accepted chain state? In order to do that on an ongoing basis, the client also has to keep this big tree in sync with the rest of the network. So as people have made other transactions, the state of the chain continues to evolve. There's new pieces of state that are added in that's going to cause this tree of state commitments to be evolving over time.
00:07:16.624 - 00:08:25.926, Speaker A: And in order to prove statements relative to the root of that tree, a client has to keep that in sync. And if we just sort of pause for a moment and think through what that means, actually this kind of sucks because you don't want to have a situation where every client has to process every transaction you could imagine. For us, this is particularly relevant because you imagine a Dex, let's say people start using it. You don't want the fact that your product is successful to cause the user experience to suck for all of the people who are already using it. So how do we figure out how we can still keep our privacy maximalism, but also make this a little bit more practical to give a sense of scale. And I could be wrong on these numbers, but it's just in my mind, it could have been misinserted. But I believe that the number of IBC transactions into osmosis is about 100.
00:08:25.926 - 00:09:32.860, Speaker A: Just transfers into osmosis, it's about 100 times more than the total volume of the zcash shielded pool over the entire existence of zcash. If you built a product that could actually get product market fit. You don't want to end up immediately, like suffocating yourself on your own lack of scalability. So the first piece of this, so I mentioned there were the two pieces, which is detection and then tree sync on the first part. We're trying to build a system that allows us to do fast scanning with delegated detection. So the first part of that is we have the chain build these compact blocks, which is like a stripped down representation of the block that just has the minimal data required to do syncing and scanning. And we actually put those compact blocks into the public chain state so that you can, as a client, authenticate what the contents of that compact block are relative to the block headers.
00:09:32.860 - 00:10:58.860, Speaker A: So this is really cool because it actually lets you have, I think maybe for the first time, I don't know, a trustless private light wallet where you can still be, you can keep the kind of like not having to run a full node, maintaining only minimal data, everything that you like about having a light wallet, but also you're not dependent on whatever particular server you're talking to, to be honest. And the second piece that we've built into the system is a fuzzy detection capability. So every penumbra address contains an additional, what we call clue key, which allows whoever is sending funds to that address to create some kind of probabilistic detection clue. That address has a detection key. This is like a sort of special purpose secret key, but they can send that secret key to some third party detector, and that detector can examine all of the clues that are in all of the transactions on the chain. And they'll be guaranteed to get all of the true positives as well as some adjustable false positive rate. And the false positive rate is set as a chain parameter that we can adapt based on the sort of observed message rates.
00:10:58.860 - 00:12:11.134, Speaker A: And that way we can trim the scanning work from being, while you have to scan through this giant fire hose of updates to, we can have somebody else filter the fire hose down to a garden hose. They still don't get sort of exact insight into what your transactions are, but you have a much smaller subset that you're going to be processing locally. And that way you can sort of safely delegate some kind of work to a cloud service without having to sort of lose any particular privacy about your transactions. Once you've got the sort of scanning part faster, though, you're still left with this problem of, well, I have to keep this tree in sync. Even if you could have like perfect pinpointing of what your transactions are, how do you avoid having to be processing everybody else's transactions into this state tree. And to address that problem, we've built the ability to do sort of fast forwardable tree updates. So our commitment tree that we use for these private states has a tiered structure that has these intermediate routes for each block.
00:12:11.134 - 00:13:20.108, Speaker A: In epochs, we start at the bottom with this block tree. This is sort of all of the new data that was created in a particular block. That tree is going to be sort of rooted as the leaf of this epoch level tree that groups together related blocks and then that gets put into this sort of global, what we call eternity tree for like the entire sort of history of the chain state. And the thing that's really cool about this is that let's say you've already solved the scanning problem by doing fast scanning, delegated detection, whatever. Now your client knows here are time periods where I didn't receive any transactions. And instead of trying to process everybody else's data, since I know that I didn't receive anything in this time, I can just immediately skip over this entire block, or even an entire epoch of blocks and just completely fast forward having to do the tree updates. And this is really cool because it means that the cost of doing a tree sync is based only on your specific account activity.
00:13:20.108 - 00:14:16.720, Speaker A: If you do more, okay, you'll have more stuff to process, but if you're not doing anything, you'll only be processing a constant amount of data per time. And so that way as a user you get this very nice kind of like privacy without compromise, where if you have some delegated detection, you can outsource the scanning work and you can skip over processing the data that you don't care about. And that's how you get to having some kind of scalable private client. So we're working on this. We have an implementation of the kind of core algorithms. There's still some optimizations that we could be doing with like even more, you know, skipping over stuff. But so far on our testnets we're able to synchronize and scan through about 13,000 blocks a second, which is like a pretty good number.
00:14:16.720 - 00:15:50.340, Speaker A: And to be sort of in a position where that's actually useful for wallet developers, we've structured that into a kind of like modular client implementation. So if you think about the traditional architecture of a client for a transparent chain, we've got, ok, here's the network, there's some full node, there's my wallet, and the full node is syncing some public state from the network. And my wallet is querying this full node or some RPC provider that's running full nodes, I learn about what my account state is by asking this full node, and then I can make a description of some action that I want to do, encode that into a transaction and broadcast that off to the network. And if you think about, so this is like kind of convenient as a wallet developer, because there's some separation of concerns between the responsibility of doing all this like synchronization and indexing, et cetera. And what I care about as a user of the chain is like, what's my state? What am I doing? Et cetera. So in order to try to preserve the good parts of this architecture in a private context, we've actually taken the wallet code and kind of split it up into three pieces. So we still have this idea of there's this network, a full node, but now we can differentiate and say what that's sinking is the public part of the chain state.
00:15:50.340 - 00:16:36.630, Speaker A: And then we introduce this view service, the wallet and the custody service. So the software is kind of split out by cryptographic capability. The view service only has the ability to view, and the custody service is what actually holds the sort of spending keys. The wallet software ends up being kind of a coordinator. So you have the view service synchronizing all of the public, or, sorry, the private state scanning it. But now the wallet can still be written, you know, as if it was a more traditional transparent wallet design. It's just that instead of querying like infuria or some other RPC, it's querying some local per user service that's doing this synchronization and indexing.
00:16:36.630 - 00:17:35.528, Speaker A: That indexing also gets a lot simpler because you're not having to, you know, by design, you're not indexing the entire world because you can't see the entire world. You're only having to index your own data once someone has this wallet software. And again, I'm using the word wallet, but this could be any kind of trading bot or ARB system. We've been testing this with a discord bot that we use for a testnet faucet as a proof of concept. That wallet can send a plaintext transaction plan to this custody service. The custody service is modeled as some kind of async RPC. So it could be in process, it could be a hardware wallet, it could be like a cluster that does threshold signing whatever, and it sends back a set of authorization data which is sort of like signatures that are going to be slotted into the transaction in the right place.
00:17:35.528 - 00:18:31.190, Speaker A: But the auth data actually comes before the sort of final transaction is built, so that the wallet can be doing all the expensive proving work on its own without having to involve this custody service. And at that point it can then broadcast this shielded transaction. But at the point that the transaction is actually being authorized, the custodian has complete visibility into what it's about to sign. And the wallet also doesn't have to worry about any of these details of how do I do this hyper fast optimized chain scanning thing. We can keep all of that code common and reusable across all of the different client implementations, and be able to just have the wallet focus on what is the behavior that I'm trying to achieve. So that's the end of the talk. Here's the last slide with all the links, if you're interested.
00:18:31.190 - 00:18:48.760, Speaker A: Happy to chat about it. Or you can join our discord where we do basically all of our development work, and we run some extremely unstable testnets if you enjoy playing with exciting and broken software.
00:19:05.390 - 00:19:17.290, Speaker B: Hi, I'm curious about the eternity tree and the epoch tree. Is the epoch tree just like lower subtrees of the eternity tree, or is there a meaningful distinction between those levels?
00:19:18.030 - 00:20:27.070, Speaker A: So we're aligning the I guess there's two ways to answer the question. The first is in terms of the actual commitment tree construction, it's just a subtree. It ended up working out for us that it seemed reasonably convenient to have all of the trees have the same size. Also, in our implementation, we're aligning the we're using the concept of the epoch is also the point at which we're going to be doing validator set changes. We want to be able to not be doing those all the time, so that we can like batch up changes to the voting power of different validators and have more privacy for delegations. But that's kind of a sort of app specific detail from the perspective of the tree and the scanning. The only detail that's important is that it's a way to create like a group of blocks.
00:20:30.970 - 00:20:53.450, Speaker B: I guess. I do have a second question, which is concerning the same tree to allow clients who may have gone offline at arbitrary points in history to catch up to the most recent state. Does somebody, presumably full nodes actually have to store all of the information that was ever in an epoch and or eternity tree? Or can we start cleaning up some of it?
00:20:55.030 - 00:21:43.580, Speaker A: If you're willing to. If you're willing to kind of like give up on accessing the data, then yes, you can only retain the roots or the intermediate routes. And those are just 32 bytes, so that's pretty small. You could also have the. In our case, we just bundle these compact blocks right into the state because it seems convenient. Another design could decide that that was going to be saved in some separate data availability layer or something and only commit the hashes.
00:21:45.340 - 00:21:46.280, Speaker B: Thank you.
00:21:49.140 - 00:21:50.980, Speaker A: Cool. Okay. Thanks a lot, Henry. Cheers.

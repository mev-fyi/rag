00:00:09.680 - 00:00:25.730, Speaker A: Okay, let's start. Okay, well, thank you. Thank you, everyone for joining this talk. Just so I know who I'm talking to. Who's coding here? Who's writing code here? Yeah. Okay, so most people. Nice.
00:00:25.730 - 00:00:58.340, Speaker A: And who's coding in crypto? Okay, awesome. So I'm going to talk about constellations, which is a real time investor for Stargaze that I built just a little bit more about myself. If you're french and you're over 40 years old, you probably know the website I created in 98, which is linuxfr.org dot. Yeah, thank you for that. I started crypto in 2011. I bought some bitcoin as many people, so it was quite early, but just as playing with it, not as coding.
00:00:58.340 - 00:01:33.996, Speaker A: I'm a senior investor in Stargaze in 2021, Shane here, the founder of Stargaze. And then in 2022, I started to do blockchain related coding, writing this indexer. So I've basically worked in tech for 30 years. I also co founded a bank, online bank for teenagers in France in 2020, 2018. Most of my life, I did Ruby on rails and Ruby for about 20 years. And objective C and Swift. So what is Stargaze? Some people may not know in the room.
00:01:33.996 - 00:02:18.184, Speaker A: So Stargaze is a layer one NFT focused app chain on the cosmos ecosystem. It actually won a prize in 2021 with the most decentralized chain at cosmovers in Medellin. They gave a few price, and one of them was most decentralized, which I think was the only price that was actually related to real numbers, not just like who loves it the most and so on. So I think it was very valuable. This is what Stygazz looks like for people who haven't been on the website. So you go on Stygazz zone and you're able to buy NFT through the marketplace. A lot of people don't know how much numbers we have on stargaze and how much traffic we have.
00:02:18.184 - 00:02:58.070, Speaker A: Because when you see this, you may think it's a very easy way, it's a very easy product, and it actually isn't. Over the past 30 days, this is the kind of traffic that we have on the cloudflare load balancer. So it's 3.9 billion requests. So it's actually used way more than most people would think. I don't think anyone in the conference today has any idea that we do almost 4 billion a month. When you build products in the ecosystem, indexers are actually monetary.
00:02:58.070 - 00:03:43.084, Speaker A: Many people don't think about it, and they usually focus on the smart contract part because they get excited more. But actually indexer will allow you to give a much better performance and user experience. And the users that we have today are users that have been using Internet for 20 years. So they actually expect web, two performances for your product and you won't achieve that without an indexer. The reason is, for example, the IPFS network that a lot of people use, it is very, very slow. RPC calls on the blockchain nodes are also very slow. You also have data that are not stored on the chain, but off chain.
00:03:43.084 - 00:04:08.460, Speaker A: Maybe not ipfs, maybe arweave and stuff. And you need to index those to get faster performances. This is basically what it looks like when you do a blockchain launch. A lot of people focus on the smart contract, so they're very happy. They take Cosmos SDK, they release the validator set and they think everything is done. But this is only 510 percent. There's a lot of remaining work to make a good product.
00:04:08.460 - 00:04:47.576, Speaker A: And what we think is that it probably requires about two years of full time work with the team to achieve the kind of performances and feature set that we have on slide. This is a few examples. If you look at ipfs. I just searched Google about people complaining about slowness, kind of issues that we had when we built it, and there's a huge amount of people complaining. And on a personal matter, I sometimes had 30 minutes time lapse. Calling RPC, calling ipfs, directorial listing. So 30 minutes is just unbearable.
00:04:47.576 - 00:05:29.574, Speaker A: So the IPFs server won't return in response, waits 30 minutes and then return to timeouthe. So you can't do it if you don't index ipfs as well when you have a product using it. So what is constellation? Constellation is basically a product that will fetch and cache all the blockchain blocks. Then we'll pass those into a database. Index all on chain customers and events without looking at any specific contracts, just indexes everything. It's going to index all off chain information as well. So all NFT related off chain on ipfs will be indexed as well.
00:05:29.574 - 00:06:25.370, Speaker A: Indexing width height, content type, content length gives you a public API through GraphQL that you can call. It's about 30,000 lines of code in rust, so it's not too big, but it's not small either. And it started as a side project. I basically started that last year when I was meeting with the Shane about potentially helping Stargaze. And two months later the site project was good enough that Stygaze asked me to co acquire it to use it as the main indexer for Stygase. So people who are not doing any crypto work just know that you can start project on the side and those projects are actually useful for the projects. They will usually accrue it or give you some kind of deal because everything has to be built on the blockchain and they're missing a lot of pieces that people are looking for.
00:06:25.370 - 00:07:07.008, Speaker A: So don't lose hope if you want to join this. This is the kind of feedback that I had on constellations over the few months. And Joseph said the constellation indexer sped up his development threefold. Because since the the indexer index all Cosmos and events, anyone deploying contract on the chain will get indexed automatically. And that helps a lot for a lot of features. You don't need to do that yourself. What's the benefit from new indexer Stygxer for a very long time before constellations happen.
00:07:07.008 - 00:07:52.290, Speaker A: So you can make products with that indexer, but this is the kind of performance that you get. Some pages that we have on the website took over 30 seconds because they had to call RPC nodes and fetch a lot of information from the blockchain and users complained on telegram channels that it just took 25 seconds to refresh Instagram page. All those pages, once moved to constellation, took less than half a second. So the performance boost is quite insane. And Osaka for second is actually way slower than the performance that I get that I'll show you later because the frontend does other stuff than calling constellations. So it adds a little latency. I'm going to explain quickly how to build an indexer.
00:07:52.290 - 00:08:23.474, Speaker A: So there's three phases. When you build indexer, Kent Beck said, make it work, make it right and make it fast. I think that very much applies to indexer. So I will say make it work. Then you make it robust to make sure that it works well, and then you make it fast. That applies a lot to rust coating in general. The reason that we did our own, by the way, is that we actually looked at options and none of the options were actually fast enough.
00:08:23.474 - 00:08:57.348, Speaker A: All the options were actually quite slower and we thought we could do better. Constellations done in Rust. Who in the audience is doing any rust right now? Awesome. Yeah. So you guys know. So we decided we went for Ros because of the memory safety and everything that you guys know already and the performance, but just know that it's not good enough to make a good and fast indexer. There's a lot of things like choking performances and knowledge that you've had over the years to make it faster.
00:08:57.348 - 00:09:36.678, Speaker A: And I'll show you a few of them that I hope you guys can live with this room with and be happy. Just as a side note, I started rust two years ago. I've been doing Ruby for 20 years, and the reason I started rust is because Ruby was too slow in the server side. So I started to rust and I was very happy about it, and I was looking at the faster option, and I liked the safety that rust was supposed to give me, which actually gave in the end. It's also the most difficult language I've had to learn, to be honest. I think a lot of people here are doing rust for smart contracts, not necessarily for like, lower system level. Smart contracts is much easier because it's a small subset of rust.
00:09:36.678 - 00:10:02.142, Speaker A: But when you want to do a system level rust, it's getting more tricky, to be honest. So, yeah, welcome to the nerd zone. So, first of all, I'll make it work. So how I made the indexer work. So the first part is fetching box. A lot of indexers are deploying their own node and running their own patched node to get information. Constellation does not.
00:10:02.142 - 00:10:40.870, Speaker A: It connects to public nodes, so it's going to connect to public nodes and fetch all the block information, stores it locally on disk so I can rerun the indexer without having to fetch those. As an example, site gauge is about 250 gig of compressed block information, which is probably about two terabyte of encompressed. So it gives you an idea of how much data it is, and then it does passing. So this is a little bit more complex. I've tried to explain what's running in multithread, to say how multithreading being much faster. I'll show you later the kind of performance that we get. And then what's monothreading.
00:10:40.870 - 00:11:22.426, Speaker A: Once I fix the block, the passing goes through all the block and saves all the contract instensation and migrations. So I know later on what events belongs to what contract, and I can run specific codes based on contract types. Then it's going to go through all the blocks and save all those events into an events table of a postgrade. All of that is done multi threaded, so it's going to max out your computer. I run those on Mac studio, and all the 20 calls are being fully used, 100%. Then I'm going to set invalid events. So invalid events is events that are being overrided by future events.
00:11:22.426 - 00:12:09.604, Speaker A: For example, when you do NFT and you sell the NFT to someone there is a transfer NFT event happening. When that transfer NFT event is happening it's going to invalidate all the previous events that you've applied. Like let's say I'm willing to sell my NFT for that amount that would be invalidated. The reason is then through the API you may request all the invalid events for a given NFT. So basically the current events on chain, not the one that has been expired, not invalidated by future events, that has to go monothreaded because it's time based. So this is the slow part in the indexing part. Then I'm going to prepose token events that I need for later use to fetch, for example IPFs URL for minting.
00:12:09.604 - 00:12:55.200, Speaker A: When you mint an NFT on chain you have the ability to set the IPFs URL of that given token and I will need that information to fetch the IPFs information at a later date. So I have to prefetch those and I am calling that prepost token events. Then its going to fetch all the collections details from ipfs because collections have details off chain on ipfs. So I'm going to fetch those in a multi threaded way as well. I'll show you later on some code how I'm doing this in a faster way. Then I'm going to update token states and name states based on the valid events. So I'm going to set the NFT owner the current fall price, the current price if the user wants to sell one.
00:12:55.200 - 00:13:38.616, Speaker A: And then on top of that in the end I'm going to fetch all of all the NFT metadata information over a PF's fetching the width, the height, the content type and the content length. And that would be applied to videos as well. Anything which is an NFT, those are done in a very smart way. When you have images that, let's say images is like 50 meg, I'm only fetching the first header, the first one k because that contains the metadata and then drop the connection. So I'm using a web that uses as little as bandwidth as possible and highly parallelized as well. And then on the third step I'm also adding a graphql API that stargaze is using and anyone is using. It's a public API.
00:13:38.616 - 00:14:02.806, Speaker A: I'll show you documentation later on. And also a Bi tool which is metabase. It's an open source bi tool, very useful for such we could use a product called Hasura which is basically a graphql API of a postgresql. But it was way too slow because it's good for generic. But, you know, we have millions and millions of events. We have a huge amount of calls. As you saw, we have 3.9
00:14:02.806 - 00:14:36.030, Speaker A: billion requests in the past months. We can't use Asra. We tried a little bit, but it was just too slow. And just as a side note, constellations gets about 15 million requests every day. So that's highly used. You have companies who built, companies who've been built and raised a huge amount of money to do eth queries over SQL. So being able to use an open source software like metabase just to create those kind of things gives a huge performance boost and also a big advantage for projects because you don't have to pay for those.
00:14:36.030 - 00:15:17.558, Speaker A: And we also use a metabase for public analytics dashboards that I'll show you later. So I've shown you how I made it work, the kind of steps I do for the indexing, and now I'm going to show you how to make it robust. The issue with crypto is that you're dealing with off chain and on chain data, but it's very rarely completely safe. Everything is like buggy. I had bugger CTF eight. I had the indexer working for 6 million blocks, which means like a huge amount of transactions, and then suddenly failing because there is a malformated ETF eight character. So you have to build for resilience and errors.
00:15:17.558 - 00:15:55.290, Speaker A: So what we did is I built the test framework, the helpers that helped me to do that, to cover as many test scenarios as possible. I'll show you after. We also used GitHub CI to do the automatic testing running, but I was too slow, so we had to run to our own CI runners using a product called Drone CI. The indexer broke also with malformated JSON at some point. And I'll show you how I fixed that. There's a lot of people doing rust, which is nice. Let me give you an example.
00:15:55.290 - 00:16:16.408, Speaker A: This line of code doesn't. There's nothing wrong in this line of code. Any rust engineer will say, yeah, it's perfect. It's very, well, it's rust. Rust. It's very rust, as we say. Does anyone see anything wrong in that line? There's nothing right, and there's actually something wrong when you run the indexer.
00:16:16.408 - 00:16:48.644, Speaker A: The thing is, you're looping because you're going through a lot of block and doing the question mark will fail instantly. So you're going to exit the loop and break your software. You're expecting to pass 10 billion blocks and on the 7 billion there's an issue and boom, you're exiting the, the loop. And this is the kind of errors that I made in my own code that I had to fix at some point. And this is the way you want to do it. You actually want to manage the error. So the question mark is a very nice shortcut in rust, but you have to be very careful when you use it because it may actually break your code.
00:16:48.644 - 00:17:29.496, Speaker A: And you have to manage errors in a way that makes sense to you. This is an example you want to adjust. So maybe it's not print the error, maybe it's sending it to sentry, maybe it's doing something else. But you have to take care of those errors and make sure that it runs then. This is a sample of a test that I wrote. This is taken from the code. So on the first line you can see that using a macro, this target test macro is injecting a test context in the code that allows you to have a DB connection and a specific set of commands that you can use to run the indexer on a specific set of blocks.
00:17:29.496 - 00:17:57.670, Speaker A: On the second error, index blocks is basically I'm asking in the test to index this specific block. And on the third error I just make sure that the events have been stored. So this is a very short example of a test, as simple as it can be. And then here's a more difficult one, more complex. So it's still using the same macro. Then I create a collection. Creating collection will actually call IPFs to create that collection that was done in production.
00:17:57.670 - 00:18:28.660, Speaker A: This is locally cached. All the network calls on the test with the macro are cached locally in the fixture, meaning when you run it on the computer it's going to cache it. And the second time it's going to run with the cached data. So on the CI it will go faster. And also if the remote server IPFs is failing, you're not related to that anymore, it doesn't matter to you. And on the third, I'm going to update the token. So update tokens will update the token state based on the events.
00:18:28.660 - 00:19:19.370, Speaker A: And then on the last one I'm going to make sure that that token has a given price based on the set of events that I had passed. So I'm writing a lot of testing like that to ensure that the indexer is actually properly passing. And this is just a quick example of how the macro, it's part of the macro that has been written for the test. So the macro just add a test context with the network so network is something you can pass as a parameter. So when you write the test, you can say stargist test, Mainnet, Starguest, Testnet or Devnet or, you know, whatever, and a few other options like archive mode, which is a specific mode the indexer is running. When I run the full indexing from Genesis, there's a few things that can be improved, because I know that I'm running from Genesis. And in the code, there's some different path of code depending on your archive mode.
00:19:19.370 - 00:19:57.990, Speaker A: So you can set the archive mode in the macro and then can run two same tests in archive mode and non archive mode. So constellation is mostly a one man job. There's other people in the team helping, but like a few pull requests. And as of today, it's about 42% of test coverage line based, which is not good enough. But, you know, it gives you an idea of a one man job in testing. I'm very much pro test mostly when you do indexing where you know, what's input and what's the output you expect. I think TDD should be the way to go, which is what I'm doing.
00:19:57.990 - 00:21:00.382, Speaker A: So how robust is the indexer with all this testing and stuff? To give you an example, this is century that. I connected a plot a few months ago, and you can see there's 14 errors over hundreds of millions of network calls, and many, many times of running the indexing full time, so only 14 errors. And when you see the last 24 hours on the time graph, there is not many. Sometimes there's a spike because you have an error happening a lot suddenly because something was forgot. But 14 errors over hundreds of millions of network calls is something I haven't seen anywhere so far in my experience. And to give an example, I looked at the NgInX logs and over a set of 7 million calls on the day I looked on that given file, there is only 200, 500 errors, which is less than 0.00%. So it's a very, very low number of errors, and I've never seen that ever.
00:21:00.382 - 00:21:33.100, Speaker A: And I think rust helps a lot for them. And as Shane said, decades of software engineering as well. But, you know, I've had three decades five years ago, and I didn't have those kind of results when I was using other technologies. ROS really helps with them. This is only for graph Qls, not for the indexing third. So third is making it fast. So how did I make it fast? First of all, I use Tokyo a lot, which, if you want, using for system, raspberry system.
00:21:33.100 - 00:22:18.352, Speaker A: You probably know and I'm going to show you how I do semaphore to limit the amount of Tokyo tasks that I'm running to ensure that I'm not overflowing the remote servers and also my local machine. There's a lot of caching. There's IPFS caching. We run our own ipfs cluster at Stargaze because if you're not running your own ipfs cluster, you're screwed basically. But they also have ipfs caching within my indexer because I want to avoid network calls when I re index the features for tests that I've mentioned earlier. And you have to keep in mind that when you do indexing the database, the blockchain space is growing over time. So you actually have to keep improving.
00:22:18.352 - 00:22:53.320, Speaker A: You can't just rely on what you did, you actually have to look at performance improvement all the time. Recently I've improved some code that took 90 minutes to run to three minutes with the following things and change that I've applied, which obviously makes me very happy. This is just as an example. Imagine if you have a loop that runs and takes a bit of time. Obviously this is the kind of result you get. You get 1.2 seconds to run this loop.
00:22:53.320 - 00:23:36.302, Speaker A: And this is the trick I'm using everywhere in my indexer. So I use a semaphore. The semaphore allows me to define how many tasks runs at the same time. So I don't let Tokyo decide that because Tokyo might decide a number that I don't agree with. So I'm using a semaphore and right here I'm saying I want to have 30 tasks at once and then I use a permit. So I query the single and I run the task. This obviously when you run it for the same task, sleep, which is pretending to be a long live task, takes 63 milliseconds.
00:23:36.302 - 00:24:19.740, Speaker A: This is what I use to go from 90 minutes to three for some specific code. This is very useful for network calls, so it avoids me filling up the other sites RPC nodes for example when I fetch too many at the time. But it also helps for local because in the local code I have database pool and that if you have a local postgrant you can go over 200 connection at once. Over 200 even on the local computer. Even with a very fast computer, start having issues. And if you have a limited amount of Tokyo tasks, the Tokyo task will run. But if you do anything on the database, the database may actually time that task because the database will be too slow and you're going to have issues.
00:24:19.740 - 00:25:02.420, Speaker A: So even when I pass locally multi threaded, I use this. But instead of using 30, I use the number of database connections I have in the pool to ensure that I don't have time at coming later. I also added a lot of tracing in the code. So Rust has something called instrument tracing, instrument that allows you to put this macro everywhere. And so I'm using this macro everywhere, the name, and it gives you information either on the output, console output or as a jagger tracing. This is the jagger tracing you get when you connect to Jagger. And you can connect to a lot of different tools.
00:25:02.420 - 00:25:31.730, Speaker A: How fast, how fast it is. So there's no magic trick in the indexer. Some people are asking me, why is your so fast? What's magic? There's nothing magic. There's no new algorithm. It's just careful software engineering practices that I had over my career, and that's it. And this is the kind of speed that I get when I run this indexer on my m one ultra 20 coils. It fills up all the cPU's and the indexer runs in about 3 hours.
00:25:31.730 - 00:26:03.400, Speaker A: So in about 3 hours time I fully indexed 250 gig of compressed information. Fetch all the ipfs. This is when I have IPfs caching. When I don't have IPFS caching, it may take a day because of the ipfs slowness, but if I have those caching, that's the kind of speed that I get. AptX is an open standard developed by an audience of companies that gives the kind of performance from a user point of view, how good your software is running. And 0.94 to one is good.
00:26:03.400 - 00:26:27.930, Speaker A: And this is when I enabled it, I got 0.99, so it's like fairly good. And the P 75 90 days is eight milliseconds, which means it's really really really fast. And even the P 95 is 153 milliseconds. So it's kind of amazing. We have a public set of Graphql API. This is just to give you an example.
00:26:27.930 - 00:26:57.250, Speaker A: So you can call the public API. This is a public, there's documentation. If you want to play the stargaze, this is kind of calls you can make. So you can call all events with the contract filter saying I want to have all the sgmarketplace setbuild events with the data filter of all the bidder, that address and all the collection of that value. And so you're going to get all the events related to that for free. And you can apply that to any customers and events on sluggaze. Because everything is indexed.
00:26:57.250 - 00:27:21.332, Speaker A: I need to go a little fast because I'm running a little late. Metabase I spoke about earlier, there's a team member called Kevin that managed those. We use metabase a lot to do JSON exports. It allows you to just pick up in the database. And I was saying earlier, some companies have raised a lot of money to do that. We get that for free. And this is the kind of dashboard that we get through metabase.
00:27:21.332 - 00:27:51.680, Speaker A: This is public. If you go on stygaze on the collection. This is a kind of very deep analytics dashboard you can get from Metabase using my database and extracting information. Deployment is done internally with Ansible. I'm going to skip it because I'm running very late right now. And this is the documentation you can see. It's on book cancellation zone and you have all the code samples if you want to play with Stargaze.
00:27:51.680 - 00:28:26.000, Speaker A: What's next? So I'm going to add verification based on previous run. So previous run will dump a bunch of information and I'm going to ensure that the next run runs the same. The reason is that you have network calls when you're in production. So you may have network issue that you haven't seen. It's millions of events. It's really hard to track and support IPC transferred and maybe store more things and maybe index more chains. Don, I tried to go very fast and make it interesting for you guys.
00:28:26.000 - 00:28:50.038, Speaker A: Thank you. Maybe we can take just one or two questions if any. Yeah. I don't know about Ross, but is there some way for you to add some fast testing or some easier way to build the test, the test cases for you not to have to go to? Yeah. Yeah. So fuzzy testing is something I'm looking for, but you know, it's very hard to find the ones you need. Fuzzy testing is usually done on the metal level.
00:28:50.038 - 00:29:10.360, Speaker A: What I'm testing right now is more like a scenario testing where I'm sure that the whole thing runs and in the end I have the events. I think fuzzy testing makes a lot of sense, mostly in rust because it's super fast. It's not something I'm doing right now, but it's definitely something I'm looking for. Yeah. Yeah. Anyone else? Good. Thank you.
00:29:10.360 - 00:29:18.100, Speaker A: Thank you for coming. Enjoy the conference. Enjoy Paris. Yeah, thanks. Thank you so much. Yeah, thank you. Thank you very much.

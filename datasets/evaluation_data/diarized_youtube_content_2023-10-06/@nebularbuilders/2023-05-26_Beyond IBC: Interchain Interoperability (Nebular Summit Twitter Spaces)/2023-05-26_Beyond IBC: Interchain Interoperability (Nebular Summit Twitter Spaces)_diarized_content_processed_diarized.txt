00:01:08.530 - 00:01:35.460, Speaker A: Yeah, welcome. So we're just going to wait a couple minutes here for speakers and everybody to come in. We got Ishmael. We'll bring you up on stage. Ishmael. And Mia is hosting on the nebula account. Hey, Mia.
00:01:35.460 - 00:01:37.312, Speaker A: Hello.
00:01:37.376 - 00:01:38.180, Speaker B: Hey, guys.
00:01:43.570 - 00:01:50.990, Speaker A: Can you make Ismail a speaker or. I think Ismail, you have to request it in order for us to bring you up.
00:01:52.010 - 00:02:01.430, Speaker B: And Bo is in here as well. I sent both of you speaker invites, so you should be able to accept those. And then we can hear your voices.
00:02:05.170 - 00:02:05.938, Speaker C: Hey, folks.
00:02:06.034 - 00:02:06.242, Speaker B: Nice.
00:02:06.266 - 00:02:07.430, Speaker C: Sebastian and Mia.
00:02:09.690 - 00:02:10.470, Speaker B: Hey.
00:02:12.050 - 00:02:12.834, Speaker D: Hey, guys.
00:02:12.962 - 00:02:14.162, Speaker C: Good to see you, Bo.
00:02:14.346 - 00:02:15.230, Speaker A: Hey, Bo.
00:02:16.930 - 00:02:17.874, Speaker D: How's it going?
00:02:18.002 - 00:02:21.830, Speaker A: Good, good. Really excited about this.
00:02:23.050 - 00:02:24.270, Speaker C: It's a good crew.
00:02:24.770 - 00:03:05.130, Speaker A: Yeah, I think we're waiting for Jim still. I wish I had some interoperability background music to play. But what would be a fitting, a fitting song for an interoperability panel?
00:03:21.990 - 00:03:32.676, Speaker B: It's actually a great question, sub. I'm trying to think of a good answer. I'm like, what are bands that are like, you know, like something with modularity, perhaps? I don't know.
00:03:32.828 - 00:03:33.932, Speaker A: Oh, I think I found one.
00:03:33.956 - 00:03:35.000, Speaker D: Hold on, hold on.
00:03:35.300 - 00:03:37.760, Speaker A: I got one. I got one. Here it is. Here it is.
00:03:48.260 - 00:03:49.200, Speaker B: Hey, Jim.
00:04:10.110 - 00:04:13.970, Speaker A: So, Jim, can you request to be a speaker and we'll bring you up.
00:04:17.400 - 00:04:18.140, Speaker D: It?
00:04:45.930 - 00:04:47.990, Speaker B: Cool. I think we are good to go.
00:04:49.490 - 00:05:05.350, Speaker A: Yeah, we'll just wait a couple minutes for more people to come in. But I'd appreciate if all of you could tweet the spaces or retweet. Yeah, retweet the spaces.
00:05:08.460 - 00:05:09.200, Speaker D: It.
00:05:47.430 - 00:06:32.532, Speaker A: Alright, so it looks like we got imperators in here, you guys. And also Varus ventures. And my favorite defi degenous, we're jizz farmer. So. Yeah, why don't we get started and so we can start with some introductions first. I can start. My name is Sebastian.
00:06:32.532 - 00:07:28.130, Speaker A: I am the GP at Interop Ventures and also organizer of Nebula summit here with Mia, who is leading partnerships and media and comms at Nebula. And we also host a couple of podcasts. I host the interop, and I'm also historically one of the hosts of Epicenter, which is soon celebrating its 500 episode ten year anniversary. But today we're going to be doing a panel on interoperability. And specifically, I'm interested in going beyond the entertainment, beyond IBC. I think it's a topic that a lot of folks here on this panel, but certainly in the circles that I follow on Twitter, are very interested in. And it's how do we bridge or bring more trustful and trustworthy bridging across different domains and blockchains.
00:07:28.130 - 00:07:47.730, Speaker A: So, to get started, I'd like to get our panelists to briefly introduce themselves, describe the project on which they're working, and also for context, which layer of the stack you're building in. So I'd like to start with. Yeah, let's start with Ismail.
00:07:48.920 - 00:08:34.190, Speaker C: Thanks, Sebastian. So, my name is Ismail. I'm the founder of Lagrange Labs. We build infrastructure for securely scaling cross chain state and storage interoperability, I would say, in terms of where we sort of sit in a modular interoperability stack, we focus very heavily on expressivity of computation that can be run on top of state data in a zero knowledge context. So one of our first products is ZK Mapreduce, part of our ZK big data stack that lets you run verifiable distributed computation across on chain states. Another of our products is what we call state committees, which are mechanisms to generate zero knowledge state proofs for optimistic execution environments. Excited to be on here.
00:08:37.010 - 00:08:54.509, Speaker A: Thanks. And we'll dive into what all that means, hopefully here on this panel. And for those interested, I interviewed ismail on the interop podcast a couple of weeks ago, so you can check the link in my description for that YouTube video. Let's go to Bo next.
00:09:00.369 - 00:09:29.488, Speaker D: Hey, my name is Bo. I'm a co founder at Polymer Labs. My primary focus, or our primary focus, is on building polymer. It's an IBC hub. The goal is to bring the IBC transport layer to other chains, and that's primarily where our focus is. It's to standardize interop across different chains using a single commitment standard, which is IBC. Bringing state from chain to chain is a different question.
00:09:29.488 - 00:09:39.860, Speaker D: And also there's a number of application standards on top. So we kind of like, in my mental model for interop between application transport and state, we focus on the transport layer.
00:09:43.500 - 00:09:45.720, Speaker A: Cool. And finally, Jim.
00:09:51.020 - 00:10:38.100, Speaker E: Hey, I'm Jim. I'm co founder of catalysts. Catalyst is a cross chain liquidity layer built for the scale of millions of chains. So essentially we see a world of proliferation of chains enabled by the modular stack roll ups or application specific roll ups or application specific chains, using these modular frameworks and having some sort of shared sequencing or shared data availability or shared enshrined settlement. And we're essentially building an extensible Amm mechanism that allows for the automatic inclusion of any new chain, which allows any new chain to instantly swap with any other chain that is in the catalyst network.
00:10:40.890 - 00:11:33.240, Speaker A: Excellent. So I'd like to start by maybe drawing a bit of a high level overview of where we're at right now in terms of bridges becoming more mainstream and certainly becoming more secure. And one data point that I thought was interesting that we've all seen floating around was that last year there was over $2.5 billion in bridge hacks. I don't have the numbers for this year, but correct me if I'm wrong, but it feels like so far this year there have been at least it looks like we're on track to have less bridge hacks. If that's true, is that because all of the low security bridges are now gone and what's left are better secured, less vulnerable bridges, or bridges with lower trust assumptions, or is there something else at play here?
00:11:35.570 - 00:11:59.510, Speaker C: I think one of the really interesting things about the majority of the bridge hacks last year is that they were not outright economic attacks on most of these protocols. They were more so social engineering or compromising very small validator set based systems. I think what we've seen is that people are far more perceptive to the security of their overall company and of their overall back end stack.
00:12:06.070 - 00:13:05.660, Speaker E: Yeah, maybe, maybe. To add to that, I do agree that it's not so much a failure of mech design, but maybe as a pushback. There are central points of failure that we've seen kind of be exploited in a lot of these bridge hacks, whether it be, again, some sort of social engineering to take over a validator set or some sort of, you know, unforced error and some sort of upgrade path. And so I do think, broadly, those are learnings that a lot of interoperability teams have taken in their design or in their kind of infosec or their kind of, or their kind of like, testing framework for upgrades to be more mindful of that. And so I think every unfortunate event that does happen in this space becomes learnings for the next generation of teams.
00:13:18.170 - 00:14:16.632, Speaker A: Jim, did you want to say something? Okay, well, I'll move on to the next question. Feel free to jump at any time, Jim. So, I mean, you're all working on interoperability solutions that are highly trust minimized, or at least leveraging them. And in the case of catalyst, meanwhile, there are other bridge technologies with significant traction that are operating validator secured models. So I'm thinking of Axelr, for instance. Looking at the future, it feels obvious that trust minimized is better design. And we're talking about mechanism design earlier, Bo and I, and how optimizing for better mechanism design can certainly improve security.
00:14:16.632 - 00:14:29.620, Speaker A: But do you think that there is a place for these two models to exist? And what place does higher sort of trust assumption bridges have in the broader landscape.
00:14:33.440 - 00:14:35.260, Speaker E: I think you guys hear me by the way.
00:14:37.770 - 00:14:39.474, Speaker D: Yeah, we can hear you.
00:14:39.602 - 00:14:41.794, Speaker E: So you didn't hear my last answer.
00:14:41.922 - 00:14:46.670, Speaker C: No, no, we heard that. I think it was Bo, or if it was you.
00:14:47.010 - 00:14:48.910, Speaker E: Gotcha. Sorry, just double checking.
00:14:53.690 - 00:14:56.590, Speaker D: Yeah, yeah, I guess. Yeah, sorry, go ahead.
00:14:56.970 - 00:14:58.110, Speaker C: No, ignore me.
00:15:00.290 - 00:15:31.100, Speaker D: Yeah, I think that, you know, we're starting to see a convergence to more trust minimized solutions, or modular solutions for how to bring state from one chain to the next to be the case. I mean, if you think about at least my mental model for bringing state from chain to chain is that there's like a cost and then like a trust spectrum. And I think that there's always be, you know, developers that want paid offs between like cost and trust.
00:15:37.000 - 00:16:40.440, Speaker C: Yeah, I think to expand on that, I think a lot of the existing cross chain protocols are beginning to realize that modularizing how their ingesting state allows them to improve their security and not anchor to a specific mechanism for deriving validity of state that potentially can become obsolete. I would add though, that with respect to the initial question of does it make sense to have these enshrined validator models where they're run by more or less a single centralized actor? And I think it does still in some contexts. In particular, if you have roll ups that don't have a clear settlement layer that make it very difficult to prove what finality of that roll up is, it makes sense in some cases if that roll up doesn't have enough liquidity to bootstrap its own network of people independently running those watchers or those validators, to instead have a single actor do that and underwrite any of the costs for moving assets on and off that chain or off that world.
00:16:48.230 - 00:16:49.610, Speaker E: I got nothing to add.
00:16:51.990 - 00:17:45.480, Speaker A: Okay, so it sounds like there is like this spectrum, right? And Li fi put out this post last year where it talks about this spectrum in blockchain bridges. And Jim, you've written about this as well and referenced those pieces. And on the one end of the spectrum we have the fully trusted multi sig bridge, and on the other end of that spectrum we have fully trust minimized bridges like IBC and ZK bridges. I mean, when moving towards the trust minimized end of that spectrum, are we just offsetting the risk to other layers of the consensus stack or. Yeah, how should people reason about where they're placing, where risk is being externalized to when leveraging trust minimized bridges?
00:17:51.260 - 00:18:13.542, Speaker C: I think polymer and Bo in particular have done a very good job kind of talking about the modularization of the cross chain stack. And I think if we start thinking about it broadly as being fragmented into three components, validity of state transport, and then computation on top of that state, I think broadly the question is, what are the security assumptions associated with each of those layers?
00:18:13.646 - 00:18:13.862, Speaker D: Right?
00:18:13.886 - 00:19:10.850, Speaker C: And so if you can prove the consensus of one chain on another, there's no real additional assertion over the trust of that state, since you can verify the correct execution of the consensus logic. If you then are talking with a transport layer, you have a censorship assumption, or a one event assumption where you need at least one party to transmit some message in a timely fashion. And then computation, it depends on sort of what you're looking for with that computation. If you're capable of doing something that's zero and all context and therein are not required to trust the party executing that computation to prove the result of it, then you also have a one event assumption there where it's only censorship. So in this situation, you're moving the cross chain security model from being something where you're trusting the cross chain protocol to correctly derive the state, correctly derive computation on top of that state and give it to your cross chain application to a protocol whose only job is to prevent you from not getting that data as a result of censorship.
00:19:21.710 - 00:19:24.366, Speaker A: Bo, did you want to add on that?
00:19:24.518 - 00:20:04.710, Speaker D: Yeah, Ishmael makes a great point about there being the different layers and also the different types of essentially attack vectors at each layer of the stack. I think within our protocols we should be more transparent regarding the trust assumptions and the types of attack vectors that will affect it. Like with some multi sick solution for proving validity or approving the state, then you're going to be able to be subjective to social engineering. Some of the attacks that we've seen before, and with consensus, you're subjective to economic attacks, and we should be clear about these and what the risks are to the end user.
00:20:12.210 - 00:20:50.520, Speaker A: Yeah, what kind of risks should end users be concerned about? I mean, beyond the risks that were already mentioned, mechanism design, we have also, we have the social engineering attacks and things like that. I mean, one thing that comes to mind is Mev as say, a lesser risk, but a new form of concerns that cross chain bridging brings into this conversation. What kinds of new Mev does this interoperability create? Maybe, Jim, you have some insights on that?
00:20:52.120 - 00:22:18.994, Speaker E: Yeah, it's a bit of a different risk, so to speak. But I do think inherent in any interoperability solution is the, like what Ispino said, like that, the censorship kind of component to it that is kind of coupled with like, liveness of kind of the delivery of these messages. And I think kind of on the third side of that proverbial three sided coin is latency. And so we introduce kind of latency as it pertains to kind of liveness or some form of, you know, of censorship ability. There is MeV that can be extracted from that scenario. And so latency as it pertains to slippage for, you know, some sort of order or latency, you know, as it pertains to someone kind of holding your packet that's being relayed as ransom for you to actually pay in order to deliver it in a timely manner, is definitely a risk that I don't think users are too aware of. And so that was kind of like the first thing that came to mind for me is even if you get the mech design completely right, you're passing a valid state.
00:22:18.994 - 00:23:04.040, Speaker E: There's still other kind of vectors that you need in order to be mindful of in order to actually have a good user experience. Because at the end of the day, we're dealing with different domains, and that introduces asynchrony into, into the, and even potentially like, lack of animicity into the system. Right. You can like have a multi step order that does not have guaranteed atomicity, so you might be stuck kind of in an intermediary lag. So from that perspective, definitely, you know, users need to be mindful of kind of what are the promises and what are the assumptions that beaming some of these primitives that they're leveraging.
00:23:06.790 - 00:24:19.780, Speaker C: To add to Jim's point, I think as we start talking about increasing the expressivity of what can be proved cross chain, where it's no longer relaying a single block header to make an assertion over a single transaction. And now we're talking about moving block headers that are, that are being used to derive complicated pricing data on top of them, you get a lot of the same MEV issues that you'd have for Oracle or from any sort of passer of complex data, wherein, for example, if you have a lending app on a Dex, on a modular roll up, that's relying on catalysts for its liquidity, for its liquidations, and it needs a twap across a bunch of catalyst instances. And the party who's responsible for relaying that proof of the TWAP also wants to be the party who liquidates to collect a fee, there is now an extractable value by being the person who has the ability to relay the message. I think broadly we're going to see a lot of these sort of, these use cases start to come to fruition more. We start talking about cross cross roll up transactions or roll up transactions that are predicated on cross roll up state becoming an increasingly large portion of how on chain activity is conducted.
00:24:21.240 - 00:24:54.940, Speaker D: Yeah, this kind of feeds into a lot of the discussions on crypto, Twitter and external as well on shared sequencing. I think like cross domain MEV across rollups, across like roll ups and app chains, they're all going to contribute heavily to MEV for users. And the mechanism design there with systems like Espresso or like Astria are going to play into how MEV works there. I think there's a lot of value to be extracted, especially during times of great volatility across domains.
00:24:58.480 - 00:26:04.230, Speaker A: Yeah. One topic that I'd like to address here and maybe get your thinking about how applications are going to be reasoning about this is latency. Up until now there's been applications. People's experience when using application has been fairly high atomicity in terms of different actions happening. If you're interacting with DApps on Ethereum, everything happens or is meant to happen in one block, otherwise the transactions revert. With cross chain applications now coming online and transactions potentially happening async, that's going to introduce opportunities for searchers to extract MEV, but also opportunity user experience issues that the industry will need to resolve. What do you think is the biggest challenge when it comes to addressing this latency and how it's going to be perceived by users?
00:26:06.810 - 00:26:11.390, Speaker E: I think. Do you want to take this one?
00:26:11.730 - 00:26:35.560, Speaker D: No, I was going to say like Ishmael's team is working on like improving UX latency wise across optimistic roll ups, for example. But yeah, that's a huge issue, especially if you're going across optimistic roll ups. Like imagine trying to do a sweat, like the full challenge period. That would be a terrible UX and you would encounter a massive slippage.
00:26:40.140 - 00:27:17.500, Speaker C: I think that's a very good point. And broadly speaking, I think when we think about this, this multi chain ux, I think we have to start thinking about asynchronous programming the same way we think about asynchronous programming in web two, wherein it's, there's no assumption of synchronicity. If you are developing something client side, you need to communicate with remote server. I think we're going to start seeing a lot of these same paradigms in module application development, callbacks, locks, everything that you would traditionally do in web two engineering or in traditional engineering.
00:27:22.880 - 00:28:44.120, Speaker E: Maybe you have a bit of a more Sci-Fi take. But I do think this is where kind of the conversation around intense becomes very pertinent. And I. I know Ismail talked about how do you increase the expressivity of a user desire. So basically, for people that aren't familiar with intents, it's basically a formal kind of abstraction of users expressing their preferences or their desired end state, and essentially having an abstraction of an ecosystem of so called solvers or executors are able to actually deliver against then. So this is something that, you know, is kind of being talked about a lot because of suave as well as, you know, has been pioneered for a few years now with Chris over at Enoma. But I do think that's where kind of the broad theme or the broad through line of that is essentially, you know, in a cross domain environment with asynchrony, with, you know, lack of atomicity, with kind of latency baked into some of these kind of cross domain communication lines.
00:28:44.120 - 00:29:09.900, Speaker E: How do you abstract away what is the desire of a user in this multi domain context? And how do you slot in kind of a sophisticated actor that's able to execute against it and take on a bit of, you know, finality risk or capital risk in order to do so? That's obviously the only solution that I think is potentially possible to kind of overcome this issue that we've been discussing for the past few minutes.
00:29:14.520 - 00:30:00.840, Speaker C: Yeah, I think to add to Jim's point, I think the great thing about intents is, broadly speaking, you allow a user to recuperate a large portion of the extractable value from the execution of their transaction across a multi domain execution or settlement space. And I think that that doesn't inherently remove cross train MeV, but it allows the person who is specifying that intent to recapture a portion of the value accrued from execution. I think that is an improvement. And as you start talking about additional mechanisms to program what happens to that value that's captured, you can create some very sophisticated systems that are potentially far less adversarial to the person who is submitting that transaction or intent to begin with than we would traditionally see with a multi chain execution.
00:30:05.140 - 00:31:31.580, Speaker A: Yeah, I think we're all pretty excited about the conversation about intents to continue to flourish. And certainly in this context, I think it makes a lot of sense. I want to maybe talk a little bit about the cosmos ecosystem. And I was listening to an episode of the Bell Curve this morning, and Hasu was saying that the cosmos basically was saying cosmos and Ethereum will soon be difficult to distinguish. And presumably, I think what he was talking about there was because there'll be better interoperability between those two ecosystems. And also, I think the infrastructure that is currently built in Cosmos or using the Cosmos stack will also serve the Ethereum ecosystem, and different layers of applications will be leveraging some of the infrastructure that's being built using Cosmos stack. Do you agree? And furthermore, do you think that interoperability will go just beyond message passing? Do you think that at some point, Ethereum and Cosmos just become, or Ethereum and the Cosmos stack just become more compatible and it's less about interoperability, but more just about sort of like merging different parts of those technology stacks?
00:31:35.000 - 00:31:53.820, Speaker D: I think that even if the technologies are merging, which I kind of see that happening already, the ecosystem is kind of somewhat coming together, there's still going to be interoperability needed between, whether it's like a roll up l two and l three, or an app chain or an app roll up.
00:32:00.280 - 00:32:24.950, Speaker C: And I also think when we look at the Cosmos, a lot of the development work there has sort of been at the forefront of. Of building in a multi chain environment and building standardizations around how multi chain transactions and data flows should be coordinated. I think we're now seeing some of those standards, similar to the work that Bo and his team are doing at Bollimer, becoming popular in context outside of the cosmos.
00:32:31.170 - 00:33:24.510, Speaker A: Yeah, absolutely. When it comes to the Cosmos stack and the Ethereum stack, I think one of the issues when it comes to using IBC beyond Cosmos is finality. I've heard someone talk about this on my podcast where they said that if we had single slot finality in Ethereum, we would be able to implement IBC without an intermediary protocol like polymer. Is that the case? And if so, do you think that protocols will, over time, evolve in order to have better interoperability with protocols like IBC that do like client verification?
00:33:26.090 - 00:34:23.506, Speaker D: Yeah, I'm not sure I agree with the statement that you need to have single slot finality to implement IBC natively. I don't think those two things are mutually exclusive. On the other hand, the protocol that we're building is actually a drop in replacement for native IBC. It's compatible with or without native IBC, and there's also like a migration path between the two. If the user or protocol so chooses to switch between them, finality is relegated to the client or, sorry, the state layer of interop. In my minfowl model, and depending on how you define the client or like the IBC client, quote, unquote. At that layer, you can specify, let's say, you know, two justifications of an ethereum block is kind of like your four choice rule in your client.
00:34:23.506 - 00:34:37.470, Speaker D: You can specify rules or client rules that will map to a finality for that particular chain or a high level finality for that particular chain. So I don't think you need to have single slot finality to have IBC.
00:34:40.930 - 00:34:52.524, Speaker A: Okay, thanks for clearing that up. I still have a little bit to learn, I guess, in terms of how IBC works across domains. Ismael, did you want to say something?
00:34:52.652 - 00:35:44.400, Speaker C: Yeah, I do. And so I think there's a love of single slot finality in the context of how that enables interoperability to function very fluidly in the cosmos. But I think it's important to realize that the reason Ethereum doesn't have single slot finality is because it supports an incredibly large and unbounded set of underlying validators. Right. And so trying to sacrifice the underlying security of a base layer or an l one in order to try to improve the interoperability external to it is very much at a counterpoint with the purpose of that l one. So I would argue that what makes sense is to continue to build tools that allow these ecosystems of very high security to be able to interact externally in a fluid fashion. And that comes down to the developer rather than the protocol itself, trying, trying to adopt a new mechanism to shrink, validate, or set size to get single slot finality.
00:35:50.020 - 00:36:52.376, Speaker A: Yeah, that's a great point. I think it bears reminding that as you increase the number of participants in consensus, you also sacrifice finality in some way. Those two things are sort of, you know, counter to each other. And so, you know, in Cosmos, or at least in tendermint or comet, BFT, we have a limited number of validators, which, which allows us to achieve this single slot finality. You know, as we talk about IBC and bridging IBC across, leveraging IPC across different domains, what are your thoughts on projects like composable and lineslide? And I think there's another one, Nicero. I think that's building IBC over into Solana. It feels like IBC is really gaining traction across multiple, many domains.
00:36:52.376 - 00:37:21.560, Speaker A: And in some ways, I think a lot of the folks in the cosmos ecosystem are hopeful that it will become an industry standard. How confident are you that IBC will be the most used interoperability protocol in the next five to ten years? Or are there other standards that could compete with it, causing sort of a standards war as we've seen in many other industries.
00:37:24.340 - 00:38:05.260, Speaker D: I think most of the other ability solutions are not standards. Like if you look at the layer zero, if you look at Axel or you look at some of these other protocols, I see them more as products. IBC is a standard. It was incepted as a standard from the, like the early days. That's why you're seeing the level of adoption when there's like a fixed set or like a very clear set of specifications for how something should be built, how something should be standardized. That's the only way to collaborate on it. And we're just not seeing that level of like detail and specificity in like different specs for other, I guess, competing products that may turn into a standard one day, but that's probably going to be further down the line even if it does happen.
00:38:05.260 - 00:38:23.450, Speaker D: So I would say the IBC is definitely the front runner in this regard, given all the data points that we have. And just by taking a look at the IBC specifications and comparing those to other ones that either don't exist or exist in a very like raw or minimal form. Yeah, IBC is definitely the front runner.
00:38:26.150 - 00:39:10.980, Speaker C: I would agree that IBC is the front runner as well. But I'd also add that despite how bullish I am on IBC, I don't think it matters whether or not IBC is the dominant standard or the only standard. Because I think if we were to look at, for example, API schemas in web two, and we're to say okay, rest, graphQL, soap, RPC, does it matter which one of those is the most dominant? Or does it matter that we have the agency as developers to be able to securely integrate whichever one we want into the application we're building, I'd say that's the heuristic we should optimize for where if someone comes out with a great standard later on, great, we should have support for that. If someone doesn't, then we should keep using IBC. We should keep using whatever the most expressive and functional standard is and secure standard is at that time.
00:39:13.650 - 00:40:00.876, Speaker D: I think some of these application standards like HTTP, GrPC and so on will be innovated on as application standard on top of IBC at least IBC transport standard. I also, but I do agree with Ishmael that it's not necessarily that like IBC has to be the like the only transport standard for interop. But I think there needs to be a transport standard for interop. It makes it easier for folks to innovate across different ecosystems and collaborate. It definitely scales the pace of innovation and also the pace of application protocol innovation on top, be it. That's what most developers will be using. Most developers these days don't interface with a raw TCP IP socket.
00:40:00.876 - 00:40:03.360, Speaker D: They use some application protocol on top.
00:40:07.990 - 00:40:09.770, Speaker C: Unless you're building fire dancer.
00:40:10.590 - 00:40:11.370, Speaker D: Yeah.
00:40:13.910 - 00:42:04.900, Speaker A: Yeah, I mean I agree with you mister Mel, that, you know, there can be, there can and should be many standards, but I think that as you go sort of lower in the stack, it's helpful to have, you know, dominant or at least, you know, very well adopted standards if you want to be able to have innovations at the higher layers of stack. Like imagine if we had three different transport protocols for packets across networking. It would be just very complicated to build applications on top of that. If we have one dominant standard, I think it benefits the industry greatly. I think Jim had to hop off, but we'll, we'll finish up here with maybe a final question. So my thesis, and I didn't come up with this, is that infrastructure inspires applications. So for example, if you look at Ethereum, Ethereum as an infrastructure inspired icos and defi alt l one s inspired NFT summer, and we see this sort of trend all through information technology, but also going back as early as the light bulb, in what ways do you think that all of the interoperability, innovation and infrastructure that is coming online now will play a role in the next cycle? Like what, what applications do you think this will inspire? Like is it gaming, is it social fi? Is it something else that I'm missing here? And what are the applications that the next cycle of mainstream retail users coming in will be able to use as a result of all of this work on interoperability.
00:42:06.720 - 00:42:53.180, Speaker D: I'm going to speak a little bit lower in the stack than the end user since I think there's a difference in what you can build with different transport standards. For example, with IBC as a transport standard, if we expose certain information about like relayers and such, you're able to do like relay incentivization at the IBC layers. There's actually a lot of infrastructure protocols that you can build at like the quote unquote application layer of IBC Interop that you can't build at least currently with or easily with a lot of these other like competing standards or products. So I think we'll see a lot of very infrastructure interesting, like infrastructure level, like applications being innovated on top first, in addition to some of these user facing ones.
00:42:54.840 - 00:44:00.820, Speaker C: I think that's a very good point. I think the things you can build with IBC modules give you the ability to implement other protocols for cross chain interoperability as module as almost libraries within IBC. I think that's a very powerful primitive. I would also say, I think one of the most enjoyable things about looking at every crypto cycle is trying to identify the consumer facing applications that will continue to drive revenue and fees to infrastructure providers, and therein continue the cycle of capital deployment into infrastructure. And when I sort of look at the early industries that were the early markets that I think we're seeing grow and that we're seeing a lot of interest in, I would look at principally intense and autonomous worlds as two things that I think interoperability is going to drive a significant amount of value to over the next two to three years. And then I think we'll in turn drive a lot of value back to interoperability providers who can implement solutions that are supportive to how those protocols function. And I also think we're going to see continually a lot of innovation in defi building more fault tolerant and more anti fragile products overall.
00:44:02.160 - 00:44:32.910, Speaker D: Yeah, I'm hoping to see some more innovation now that there's interoperability lends to scalability, the more interoperable things are you're able to build an app chain that can settle on Ethereum, and if you want to build a game, you may not need to co locate your game, which may not do a ton of volume with a bunch of other applications that are going to price out what you're building. Hopefully we'll see a lot of innovation on things beyond DeFi, especially in the gaming side, which personally I'm quite interested in.
00:44:37.300 - 00:44:52.480, Speaker A: Yeah, absolutely. Also very interested in applications that go beyond Defi. So what are next steps for each of you? Maybe just taking opportunity to shill each of your projects and upcoming milestones on the roadmap?
00:44:55.900 - 00:45:48.410, Speaker C: Yeah, we're getting ready for a testnet launch on a portion of our infrastructure in roughly four to six weeks. That will make it far easier to interact with optimistic roll ups that settle on Ethereum with near single slot finality, which we think is going to unlock a lot of utility for cross chain protocols and applications that want to build on a DLP stack or an arbitrary stack and want fast provable cross chain finality. We also are going to be having a test this summer on the first version of our zero knowledge Mapreduce framework that allows you to really write truly expressive distributed computations that can be proven on top of a single block header. So if you want to prove historical asset ownership, historical pricing, all of that at a big data scale, you'll be able to very soon do that with any existing messaging protocol or even with a watch or relay or any type of transport protocol you want to use.
00:45:52.030 - 00:46:18.312, Speaker D: We're also looking to launch our private testnet and soon thereafter, public testnet. In the coming months. We're also going to be collaborating with Ishmael's team. Definitely going to be downstream consumers of their work on supplying a committee for optimistic roll up state. That's going to be very interesting to us. As I mentioned before, our primary focus is on the transport layer of IVC. So we want to bring the transfer protocol to different chains.
00:46:18.312 - 00:46:26.080, Speaker D: But in terms of proving validity or proving the state of a chain, you know, we're happy to work with teams like Lagrange and Ishmael.
00:46:28.100 - 00:46:29.800, Speaker C: Excited to work with you guys, too.
00:46:32.740 - 00:46:45.668, Speaker A: And, yeah, Ismail, congratulations on recently announcing your funding round. I saw that you guys announced that. I think it was last week. Very much appreciated. We're very, very excited about everything to come.
00:46:45.804 - 00:46:46.680, Speaker C: Thank you.
00:46:48.670 - 00:47:20.110, Speaker A: Great. Well, I think this brings us to the end of the panel portion of the spaces. We just want to give a couple of updates on Nebula summit before we wrap up here. And just wanted to also point out that Ismail, Bo and Jim will be speaking at Nebular summit. Mia, I don't know if you're around, but do you want to go over some of the. Some of the things that we're announcing this week?
00:47:20.650 - 00:47:25.430, Speaker B: Yeah, sure. Should we quickly, I just. I see JP has his hand raised.
00:47:26.330 - 00:47:27.242, Speaker A: If you have question.
00:47:27.266 - 00:47:28.026, Speaker E: Oh, yeah, sure.
00:47:28.218 - 00:47:31.510, Speaker B: We can answer that and then we can do some updates.
00:47:35.450 - 00:48:04.284, Speaker A: I just invited you to speak, JP. JP, do you want to come up and speak? I mean, yeah, let's start with the updates, and if he requests to speak, we can bring him on stage.
00:48:04.452 - 00:48:27.102, Speaker B: Cool. Sounds good. So last week, we were really excited to announce a couple of new sponsors that joined Nebula as our partners. We welcomed DyDx as well as Nim and Juno as new sponsors. Juno is going to be hosting a workshop, so will Dydx. We're really excited for that content. We also welcomed Hyperlane, who's going to be sponsoring our ice cream booth.
00:48:27.102 - 00:48:35.914, Speaker B: It's going to be very hot in Paris. And we also have squid, who joined as a sponsor. They'll be our coffee booth sponsor. So we do still have.
00:48:35.962 - 00:49:16.334, Speaker A: I just want to. I just want to show our ice cream. Our ice cream game. So, like, I live in a town in the suburbs of Paris, and there's an ice cream, like, an ice cream shop there that they're, like, third generation ice cream makers, and these guys make, honestly, the best, the most unique flavors of ice cream. So they make, like, saffron and cardamom and, like, all of these really unique ice cream flavors that you've never had anywhere, because the guy, like, lived in meritos for a couple of years and was inspired by the kind of indian influence over there. And so, like, the ice cream this year is going to be amazing. I just.
00:49:16.334 - 00:49:18.478, Speaker A: Yeah. Like, really excited about the ice cream.
00:49:18.614 - 00:49:22.730, Speaker B: I think we should have an interoperability flavor ice cream this year.
00:49:24.270 - 00:49:25.614, Speaker A: Totally. Yeah.
00:49:25.782 - 00:49:48.940, Speaker B: And just combine, combine a bunch of flavors. But yeah, ice cream booth is going to be great. Just a couple other quick updates. So we have our second wave of early bird tickets up for sale. They're $59 each. You can use Adam to check out. And we also have so far given away 15 student tickets, and students can still apply for tickets.
00:49:48.940 - 00:50:27.830, Speaker B: So if you have any friends, engineering students, etcetera, you can urge them to apply. We are going through speaker apps as they come in. We're hoping to get an answer to everyone's applications by the end of this month, but the applications are still open to apply, so if anyone has team members, they'd like to apply. If you haven't gotten yours in yet, just urge you to get that in ASAP so we can get back to you. And the last updates are exciting. So we're working on a new version of our website that will be coming soon. It's going to have a lot more information on the actual content you can expect to see at Nebula this year.
00:50:27.830 - 00:50:47.210, Speaker B: And we also have an edition of a workshop day that we're going to be hosting. There was a huge demand from sponsors and partners to host workshops. We really wanted to make it accessible and free to attend for folks. And so we're going to be announcing that soon that we'll be doing a workshop day right before nebular to kick off the event.
00:50:49.510 - 00:50:51.290, Speaker A: Yeah, and I really want to stress.
00:50:55.800 - 00:50:57.680, Speaker B: I think you got cut off, sub.
00:50:57.840 - 00:51:16.392, Speaker A: The workshop day is going to be open for anyone, and it's free for anyone when to attend, so. Oh, sorry.
00:51:16.536 - 00:51:18.540, Speaker B: Yeah, the workshop day will be open.
00:51:18.910 - 00:51:24.410, Speaker A: Yeah, I was going to say, like, I want to stress that the. What?
00:51:33.830 - 00:52:07.200, Speaker B: Yeah, sorry, seb. I think your Internet maybe cut you off a bit there. But yes, the workshop day will be free to attend for anyone who applies. We're going to be working with crypto, job listings, and some other partners as well to really promote workshop day and just get a ton of more early stage developers who want to build on IBC attending. But yeah, we're really excited. And thanks so much to Ishmael, Bo, and Jim for joining us today. Can't wait to hear your talks during the nebular summit this summer.
00:52:08.580 - 00:52:10.280, Speaker C: Thank you guys as well. I'm looking forward.
00:52:10.940 - 00:52:12.454, Speaker D: Yeah, thanks for having me.
00:52:12.652 - 00:52:18.430, Speaker B: Awesome. Yeah, thanks, everyone. Thanks for coming, and we will see you this July. Thanks for your time.
00:52:19.930 - 00:52:21.082, Speaker C: Take care, folks.
00:52:21.266 - 00:52:22.570, Speaker B: Bye bye, everyone.

00:00:00.250 - 00:00:17.920, Speaker A: They should not and should never trust us for having integrity in any matters that happened on chain. The whole purpose of blockchain is to eliminate trust assumptions. And this is what Zksync is all about.
00:00:20.450 - 00:01:05.750, Speaker B: All right, everyone, welcome back to another episode of Zero X Research. The show is made possible thanks to our incredible sponsors, chain analysis and flipside. We're recording this episode on December twelveth, and we have a great interview coming with two members of the matter labs team, Alex and Anthony. And this is the team behind ZK sync. We kind of dive into all things ZK sync and kind of explaining that ZK rolt that they're building and getting into more of the technical details of what an l two and l three environment looks like in their vision. But before we dive into that interview, we are joined by Matt and Westy from the Blockworks research team. We're going to kind of hit on all the latest market happenings and a little bit of the world that we are all living in in crypto, Twitter.
00:01:05.750 - 00:01:09.826, Speaker B: Westy, can you kind of kick us off here? And I know you got someone on the hot seat for.
00:01:09.928 - 00:02:26.314, Speaker C: Yeah, definitely. For my hot seat, I have Sushi, who's a little shroud for cash at the moment. Sometime last week, Jared Gray, who's essentially the CEO of Sushi, the head chef, he had a forum post that essentially outlined their finances, basically saying since he joined, their Runway was cut from 9 million to 5 million. But that's not enough because they still only have one and a half years of Runway. So that's what seven and a half million dollars left in their treasury to pay employees. So the idea they had, and that was outlined in the forum post was to direct all revenue, which was originally going to ex sushi holders, and actually direct that to the treasury to be able to pay out their developers, which is pretty interesting because it's really the first sign of a dow that's basically said, yeah, we're in trouble and we sort of need to cut back, cut costs and figure out more sustainable model to go from here. And so I wonder, where do we go from here with other dows that are struggling? Do they also come out and start to direct revenue instead to their token holders, but to their treasury? So, yeah, it's an interesting case.
00:02:26.314 - 00:02:35.598, Speaker C: I hope sushi comes out of this fine. They do have one and a half more years of Runway, and I hope revenue helps there. But, yeah, struggling at the moment.
00:02:35.684 - 00:03:04.038, Speaker D: I think it's interesting. I mean, it's definitely sad to see that they're running out of treasury funds. Sushi has a great team of developers supporting a whole bunch of different products. Shoyu, which is their NFT marketplace, I've heard rumors is going to launch in the next couple of weeks or months, so that's something to keep an eye. Furo, I believe it's called, which is their Dao payment streaming platform just reached like an all time high in TVL. So sushi does seem to still be building and working hard. I definitely support their team and I kind of hope this proposal does pass.
00:03:04.038 - 00:03:26.318, Speaker D: I think it's far more important to have long term sustainability and have these developers on board than it is to have. I think it's something like maybe 50 or $100,000 a month going back to the treasury, last time I checked, not sure what it is now. It could be even less. So I think it's good. Build up the treasury, definitely a roadblock, but I don't think it's the end of the world for the sushi protocol. And I definitely hope to see this governance proposal pass.
00:03:26.404 - 00:03:55.990, Speaker E: Yep. Strong agree here with Matt. I mean, they're kind of like an OG in the defi space, and a lot of people use sushi on a lot of different chains, so rooting for them. And I also think it sucks to put them in the hot seat here because I think a lot of other protocols in the space today will probably ultimately face the same problem if they're not accruing value back to their treasury, where they can then pay out developers to keep the thing running for the longer term. So I don't think this is the last that we'll see. It's just kind of the first big one that we're having our eyes on with this problem.
00:03:56.060 - 00:04:19.338, Speaker B: Do we know if they're doing anything to kind of compete a little more so on the trading volume side of things. Right. So obviously Uniswap's v three is really kicking everyone's ass in terms of volume, but Curve has their v two protocol as well for concentrated liquidity. Matt, I know you're kind of more of the guy in the weeds of the sushi protocol. Do you know if they have any plans for like a concentrated liquidity approach or anything of that nature?
00:04:19.434 - 00:04:54.650, Speaker D: Yeah. So sushi has already built a concentrated liquidity amm and the technology that goes with it, it's called Trident. Trident is deployed on, I believe, I think, two or three chains. It just deployed on arbitrum. And the reason it's not deployed on Ethereum mainnet yet is they are waiting to have a longer trial on these smaller TVL chains, see how it goes. Make any tweaks necessary before it eventually does go on main net. I was actually having a conversation in their discord this morning about that and asking about when that might happen, and it definitely is still expected in 2023, but it could be a little while before we actually see it occur on main net.
00:04:54.720 - 00:05:02.982, Speaker B: I don't want to put you on the spot here with like a very specific question, but do you know how sushi competes in terms of deck swap volume on arbitrum?
00:05:03.046 - 00:05:30.946, Speaker D: Last I checked, they had a large portion of Dex swap volume on arbitrum as compared to on Ethereum mainnet or, sorry, a larger portion on arbitrum. But I think a lot of that probably has to do with airdrop farmers, which we've kind of talked about on other episodes, and people just playing around with lots of different protocols and trying to kind of. Maybe it's not volume, that's just native people actually looking to swap assets. It might be more like manipulation and things that aren't really long term sustainable.
00:05:31.058 - 00:05:43.290, Speaker B: Yeah, that'd be really interesting to watch that kind of like dive into when that gets launched on main net and kind of see if it can compete with even curvy too. Kind of generally comes around in that second place spot.
00:05:43.630 - 00:06:05.726, Speaker E: I think generally speaking too, the reason for that sushi dominating volume on arbitrum is it's a little bit harder to launch like a v three pool on uniswap than it is like a typical XyK pool on sushi. So that's why Sushi is seeing quite a bit more volume. Just tokens typically launch on sushi before univ three there. But Matt, I'm curious who you got in your hot seat today?
00:06:05.828 - 00:06:38.726, Speaker D: My hot seat today is finance. You might want to call it FuD. I don't know what you'd call it, but there's a whole lot of Reddick going around post their proof of reserves audit. So basically, finance did a proof of reserves audit, though it's supposed to prove if you have assets on finance, they are backed. So finance actually has the ability to go and fund 100% of withdrawals. If every deposit went withdrawal, they actually have the liquidity so that everyone gets their money back out of the exchange first. I believe Jesse Powell, who's the founder and CEO of Kraken, pointed out that there were some things that he didn't love about the proof of reserve audit.
00:06:38.726 - 00:07:25.750, Speaker D: So he said that they group together, BBTC and BTC, as one asset. So both of those other ones, BTCB and BBTC, are binance wrapped bitcoins. So when you say, okay, we have, let's say a thousand bitcoin, that's some of any of these three types of bitcoin, whether it's native bitcoin or the other two, you would hope that you could actually see the bitcoin backing those wrapped assets. That was not the case. So maybe it's hard to 100% trust that those wrapped bitcoins are actually backed by bitcoin. We would prefer to have seen the actual bitcoin that was backing all customer deposits. Another thing that he pointed out, and this is Jesse Powell again, that the total, they had 97% of their bitcoin deposits collateralized.
00:07:25.750 - 00:08:16.710, Speaker D: And they said that there were 101% collateralized over collateralized, if you include other assets, there was no transparency on what those assets were. A lot of people on Twitter seem to be speculating that it might be BNB. Okay, first of all, 97% backing is pretty solid. If you compare that to the fractional reserve banking system, banks are not required to have nearly 97% of your deposits backed by actual liquid dollars. But at the same time, I think that most people in crypto do hope that these exchanges have 100% of the actual assets to back, that there is no fractional reserve, that it's 100% reserved. So seeing that this was 97% collateralized by these BTC, BTC and the two wrap bitcoins, I think might have worried some people a little bit. So, according to Nanson, there was $300 million in outflows just in the last 24 hours from finance.
00:08:16.710 - 00:08:59.346, Speaker D: So this is really why, in my opinion, they deserve to be in the hot seat, whether or not the assets backing it, I think less. But definitely people are worried and withdrawing. So 100% in my head, that's why they are in the hot seat, I think. Lastly, Travis Kling, who is the managing director of a now defunct crypto hedge fund who lost most of their money on FTX, tweeted today that binance stopped allowing withdrawals, I believe, on Ethan BNB chains, not, I forget, on two EVM compatible chains. And he know is pointing out that this isn't a good look and that this could be a scary sign, in my opinion. And this is such a. I hate saying this now, especially after the last six months or year with, oh, there's a slight chance that FTX is insolvent.
00:08:59.346 - 00:09:18.766, Speaker D: Well, as we saw, they were insolvent, saw the same thing with Celsius. We saw the same thing with Blockfi. So now I have a trouble know, but in my think, you know, at the end of the day, get your money off of centralized exchanges, learn to do self custody. It's worthwhile if you're doing it safely, you're lowering your risk, so there's no reason not to. And that's all I'll say, I guess.
00:09:18.868 - 00:09:51.046, Speaker E: Yeah, I would agree with everything you said, Matt. Everywhere there's been smoke this year, there's been fire. I think that's what Ryan from Bitwise said last week on our episode, Dan. So I agree they deserve to be in the hot seat. And yeah, I think it was just binance, smart chain, and ethereum for USDC withdrawals. So you could still technically get native bitcoin out of the exchange or native eth out of the exchange. But who knows how this actually changes considering we're recording on Monday, December the twelveth, and it'll be the 15th by the time this actually airs.
00:09:51.046 - 00:10:28.594, Speaker E: So good chance something changes between now and then. But I can move on over to my cool throne. I've got Vance from framework Ventures. His take on Twitter last week, I thought it was really good. It's related to the FTX drama. So they basically had zero bitcoin and very little eth, if any, by the time the last snapshot was taken in terms of their holdings on the chain. And he kind of made the case that the Alt L one rotation was inflated as a result, because it's highly probable that FTX Alameda were taking customer deposits or even dollar deposits from bank accounts that were supposed to be buying certain assets.
00:10:28.594 - 00:11:04.162, Speaker E: And instead of buying those assets for their customers and custodying them, they were actually buying solemn. Their vc allocated bags, so that kind of, like, pumped those prices, pumped other layer one prices, and then on top of that, you've got all these different l ones that are launching here in the future. Like Aptos. Aptos already launched, I think. But regardless, I think that all of those l ones that were seeded in the aftermath of the layer one season, I think they're kind of grossly overvalued. And that's what Vance said on Twitter. So he definitely got my cool throne for the week.
00:11:04.216 - 00:12:30.874, Speaker C: Yeah, I mean, it's pretty wild that at that last snapshot for bankruptcy, there was zero bitcoin that they held. That either means that they sold all the bitcoin that people had in their exchange, or at least enough so that when there were mass withdrawals, it drew essentially their reserves to zero, which means, like you said, that they must have been selling bitcoin and buying other assets. And I think we can pretty fairly speculate that that was sol serum, all the tokens that they had as collateral, which is pretty wild when you think about it. And yeah, I agree, this definitely does mess with valuations for these l ones and maybe even l two s as well, compared to the base layers that we know have value, and that's bitcoin and eth. So I wonder, in the next cycle, does that continue? How much adoption does an l two or l one need to have when compared to Eth for it to actually have a similar valuation? It's pretty tough now given eth supply dynamics after the merge in EIP 1559, it's really tough for another alt one to sort of compare to that, especially with the amount of activity and the amount of l two s that are building on Ethereum. And so, yeah, I can't agree more. It definitely messes with those valuations going forward.
00:12:30.992 - 00:13:07.478, Speaker B: Yeah, just on that first point you make that there is zero bitcoin left, right? With all the billions of dollars of customer deposits that are still stranded on FTX, surely some of those were held in bitcoin, right? So it's hard to paint a picture that there wasn't this commingling or funny business, whatever you want to call it, with customer deposits. That seems like a smoking gun to me. If you go back to some of these funds that had their deposits held on FTX for security and, like, you're telling me all those funds had zero bitcoin exposure, I just find that super hard to believe.
00:13:07.564 - 00:13:35.134, Speaker D: I'm consistently impressed with Vance and Framework's takes, framework being the VC fund that he's, I believe, co founder, managing director of framework has invested in layer one. So to hear him say this, I think it hits even a little bit harder than maybe just anybody else. But yeah, I would just echo that. He definitely deserves to be in the cool throne, and I'm always impressed with him and Haseeb and their VC funds and just kind of how finger on the pulse they always are and have great takes.
00:13:35.252 - 00:13:35.486, Speaker F: Yeah.
00:13:35.508 - 00:14:05.494, Speaker B: And on that last cool throne, I think I got a good one for us. And it's really those Starbucks NFTs, right? So those launched on the eigth and they're doing a pretty cool little program with those, right? So it's essentially like an odyssey where participants kind of go through what they call journeys, and going through these journeys, you essentially collect these points and those points are then redeemable or as well, you can earn or purchase. Even so, NFT is called journey stamps that are effectively redeemable for these different experiences.
00:14:05.542 - 00:14:05.706, Speaker A: Right.
00:14:05.728 - 00:15:07.854, Speaker B: So I think some of the ones that they have highlighted are like at certain Starbucks reserves, which are like the high end Starbucks, if you will, there's like different experiences you can get in store. You can go visit some of their coffee farms in Costa Rica if you, I assume, are a die hard NFT collector for these Starbucks NFTs, I'm sure they'd be quite hard to get. But it's pretty interesting to see these on chain loyalty programs, especially from such a big name. I know the Starbucks loyalty program is a massive one and they have a great app that makes it super easy to use and interact with their loyalty program. So kind of testing out this beta of a real world use case for NFTs is really interesting. It's cool to actually see this come to fruition after being talked about for a few months. I think it's really important to note that this is all kind of going down on Polygon, which essentially seems to be, we've seen like it was biz Dev announcement after Biz Dev announcement, and now I think we're in the couple months.
00:15:07.854 - 00:15:17.642, Speaker B: Out of all those announcements, are you going to be actually seeing the products that were announced all these months ago? Which is actually really exciting to see these things kind of come full circle.
00:15:17.706 - 00:15:53.490, Speaker D: One thing I think is really interesting about the Starbucks NFTs is as someone that's super crypto native, like all of us, we all spend a lot of time, we know about a lot of different NFT projects, like, oh, the pictures are stored on centralized servers. There's so many things that we could point out as this is negative. This isn't really what we look for in NFTs. But I think if you ignore all of that for a minute and just look at this is a loyalty program. And just like a very cool new thing that people that are already using the biggest loyalty program in the world are going to have access to. I think it's a really cool innovation and one that should not be faded or ignored.
00:15:53.590 - 00:16:34.106, Speaker C: Yeah, I think it's a really cool experiment and it has me think, can you apply something similar to other rewards programs? There's a lot of bigger ones. I think Amazon prime is a great example. But yeah, there's plenty of rewards programs from the biggest brands in the world. How do you apply crypto to that? And so if Starbucks is successful here, I can imagine we see a lot of bigger brands start to tack on and either create NFT rewards or maybe something like Cole's cash becomes an ERC 20. Maybe that's jumping the gun a bit, but yeah, I think it's a cool experiment. I'm excited to see where things go.
00:16:34.208 - 00:16:58.018, Speaker E: Yeah, me too. I'm super excited about this one. I personally go to Starbucks a good bit, like once a week, and the rewards program is awesome. I get a free coffee every month, so I'm definitely going to take part in this odyssey thing. And I already signed up for the waitlist. I also think it's cool that they're using nifty gateway and letting people use credit cards to buy the NFT. So there's an actual marketplace and it's not as crypto native, so you don't actually need a wallet or anything like that.
00:16:58.018 - 00:17:15.110, Speaker E: So definitely excited to see how it plays out. And I also just think every other company is probably watching this super closely and if it is super successful, like you said, westy, I think it was. Everyone's going to have to develop a strategy around NFT loyalty. Dan, you want to get our flip side chart of the day pulled up?
00:17:15.180 - 00:17:29.162, Speaker B: Yeah, let's do it. Westy, while I get this pulled up, do you want to give us a little bit of background on what the ape staking is for the board Ape yacht club in Co. Yeah, I can do my best.
00:17:29.296 - 00:18:32.686, Speaker C: None of us are board ape holders, so we're not exactly experts on the mechanism here. But yeah, essentially ape is sort of the governance token of the board API club universe, you could say. And they're trying to implement staking to essentially distribute the token to more of their active users and essentially give them a reason to lock up the token to give it more value. And essentially, if you have one of their nfTs, whether that's the board ape yacht club themselves, or they have mutant apes, as well as kennel Club, which is their dog NFT. If you hold one of those or maybe a combination of something like the mutant apes and the dogs, you can get a higher APR on your staking. And so those APRs are upwards of 200% to 300%, which is pretty attractive. And there's actually a trade going on where a lot of the board ape holders aren't exactly DFI native like we are.
00:18:32.686 - 00:18:53.510, Speaker C: And so they see 300% APR and they think it's really attractive, not realizing it's inflation. But they also don't hold any ape, they just hold the NFT. And so they need to buy into ape to then stake it and earn that yield. And so, yeah, staking, I think, went live or is going live. But yeah, we can look into the data here.
00:18:53.580 - 00:19:25.154, Speaker B: Awesome. And yeah, there's a lot of great data on this dashboard. It's created with flipside data, which is the most comprehensive on chain data in crypto and it really gives you the insights that you need to work smarter. And so this dashboard was created with some custom queries built on mostly the ERC 20 transfers data. And so we can see where these ape tokens have been allocated, in this case staked to. There's a great dashboard, we'll link to it in the show notes. But one thing I want to highlight here is this chart on the far right.
00:19:25.154 - 00:20:23.982, Speaker B: And for those listening, rather than watching along on YouTube, this is the distribution of ape stakers by their total staked volume. So basically how many tokens does basically bucketing the ape stakers into the number of tokens that they have staked in a particular pool? So you can either just stake the ape token to a specific pool by itself or you can pull it alongside your NFT. And so you can see the board ape yacht club pool here, the mutant apes here, and the kennel club here. And one thing to note between the two is the more expensive nfts, right. The board eight yacht clubs themselves. Those gen one nfts have this red color here is 10,000 to 10,0000 tokens staked and they have by far the largest ape stakers. Right? So there's way more in this bucket.
00:20:23.982 - 00:21:07.918, Speaker B: Roughly 60% of all board ape yacht club pool stakers are between 10,100 thousand ape staked. So it looks like the whales are really hanging out in that pool, which makes sense again, because those nfts tend to be costlier than the others. But one more time, I just want to give a shout out to flipside for being able to make this data free to everyone to query. And we can end up getting great dashboards like this one. Again, we're going to link to it in the show notes, but alongside that you also see a custom flipside challenge or bounty posted to earn yourself some USDC. And so if you're someone who likes building queries and building dashboards, definitely be sure to check that out and you can earn up to $75 in USDC as well as improving your querying skills.
00:21:08.014 - 00:21:41.894, Speaker E: Yeah, I just want to take a second too and thank our other wonderful sponsor, chainalysis. They're one of the leading crypto analytics providers that are helping provide the tools to industry professionals to help legitimize our industry. They enable investors to track funds on chain with ease. And they also have some great research on their site which can be found there for free, so we'll be sure to link to that in the show notes as well. They offer some really cool courses on some really niche topics in crypto that really can't be found anywhere else. And that's pretty important, in my opinion, so that they actually educate people on all things crypto. So, yeah, again, just go ahead and check out chain analysis.
00:21:41.894 - 00:21:46.826, Speaker E: We'll put their link to their website and their research in our show notes, and we'll catch you guys in the interview.
00:21:46.938 - 00:22:17.234, Speaker B: All right, everyone, welcome back. We have joined here by Anthony and Alex from ZK Sync, a team working on scaling ethereum through their own ZKe evM. Really excited to have you guys on today. I'd love to kind of dive into what all it is you're building and the details, especially on more of the technological side as well. But first, if we could kind of hit some of these and highlights. You had a pretty big announcement coming out, around a 200 million dollar raise as well as some other things. But if we can kind of dive into what was the meat of the 200 million dollar raise as well as the partnership with open Zeppelin, what all does that entail?
00:22:17.362 - 00:22:44.894, Speaker A: Absolutely. Thank you guys for inviting us. Really happy to be here and happy to talk about these topics. I find them extremely important. At matter labs, we've been building ZK sync now for four years. We started as a very small research group, and we've been gradually focusing on the technological side of the product. Just doing research in zero knowledge proofs and their application to scaling blockchains, to solving different technological challenges of the scalability, breaking out of the scalability trilemma.
00:22:44.894 - 00:23:27.242, Speaker A: And we were always very conservative and very heads down doing the research work because there were a lot of unsolved questions in the zero knowledge proof space. The protocols were not mature enough. We didn't have plonk, we didn't have starks. Like everything was kind of weak. But recently, with all the recent research and development and our work on ZKVM specifically, we're the pioneers of this technology. Things are now very clear. We have a very strong vision on how to scale Ethereum in a way that will allow Ethereum to reach basically everyone in the world at very affordable costs.
00:23:27.242 - 00:24:24.538, Speaker A: And what we need now was just get enough resources on the engineering side and on the product side to fully implement this vision. So the phase of research is over, and now it's phase of pure implementation. And once we realized that we figured, okay, now it's time to scale. And now we need much more resources than what we used to have in the past. And we reached out to the investor community, to the backers, and we closed the 200 million dollar round led by blockchain capital and Dragonfly, with participation of our previous investors from Andreezen Horowitz and a lot of other folks who are important in the space. But we made sure that we don't sacrifice the values that were the fundamental at the core of our project from the inception. And we always wanted Zksync to be just an extension of Ethereum.
00:24:24.538 - 00:25:02.490, Speaker A: And we realized it's going to be a separate network, a separate layer on top of Ethereum. But we wanted to make sure that the community preserved the ownership of this. There are a lot of projects who people degradingly call VC coins and things like, oh, those guys sold their soul for a lot of money and they are now just like going to pump and dump the token, whatever. We never wanted to go in this direction whatsoever. We were never eager to introduce the token. We were just building technology that we will then use to scale it. And like, if token is a necessary part of it, we're going to use the token.
00:25:02.490 - 00:25:36.258, Speaker A: If we don't need it for some functions, we're not going to use it. We came to conclusion that we will eventually need the token to decentralize the sequencer. And we will talk more about this in this conversation. But the best way, we don't have to reinvent the wheel, we don't have to reinvent every single technology, every single approach. We can take whatever works and focus on the core innovation, which is zero knowledge, proofs and scalability. We're using sarcs. So we realized that the best way to decentralize things today is using tokens for creating community of validators.
00:25:36.258 - 00:26:55.246, Speaker A: But we made sure that in all the commitments we have, all the promises we make to anyone, we made very clear that two thirds of whatever initial token supply is going to be created will be reserved for the community. And we made sure that the community has. That's necessary, but not a sufficient condition, because if you have something that can eventually be accumulated in the hands of a few people, if those few people will have tremendous power, then it doesn't matter that you give the rest to the community or whatever. So we wanted to make sure that the community remains the guardian of the project and of the project values and ethos, and that it always remains in sync with the values and ethos of Ethereum, and essentially remains the same thing. That is why we're doing full open source with MIT Apache license, which is a full permissive open source, not some fake invention that will say, oh yeah, cord is visible, use it. Or like, oh yeah, sure, it's open source, but you can only use it for our project. That would prevent people from being able to fork the project in case the original inventors or the operators of the validators of this network at some point would become malicious.
00:26:55.246 - 00:27:29.158, Speaker A: And that is extremely important. That gives the ultimate control to the community. No matter what token distribution, no matter if we became people can change over time. People can just go crazy and do completely unexpected things and just say like, oh, now I changed my mind, I just want to get rich. And I don't care about community. We want to create mechanisms that do not require people to trust us. We want to be trustworthy.
00:27:29.158 - 00:28:17.130, Speaker A: We want to create trust for our users, for developers who are building on the private platform. And the first line is the trust in our vision, in our ability to execute, because people have make commitments. You decide which platform you want to build on. Obviously you have to trust that team to perform to the standard to which you expect, but they should not and should never trust us for having integrity in any matters that haven't on chain. The whole purpose of blockchain is to eliminate trust assumptions. And this is what Ziki sync is all about. This is why we're using snarks and provide actually, snarks or zero knowledge proofs are a bit of a misnomer.
00:28:17.130 - 00:28:47.882, Speaker A: The scientific community prefers to call it something like proofs of computational integrity, like showing doing the computation in the correct way while no one is watching, and enforcing all the rules of contracts, of whatever people agreed on, whatever was committed to, without anyone being responsible and carrying actually the execution of this trust on his back. So this is why full open source with MIT Apache?
00:28:47.966 - 00:29:04.060, Speaker E: Yeah, that makes a lot of sense and actually segues me in pretty well into kind of like an overarching question between EVM compatibility and EVM equivalents. Obviously, that's kind of like the talk of the town right now between all the different ZkeVM teams in the race. Can you kind of explain the benefits and the trade offs of the two?
00:29:05.070 - 00:30:05.138, Speaker A: I'm happy to start. And then Anthony can add more flavor to see this. We don't see it as a binary choice. We see the solutions, potential solutions in the design space as a spectrum between full EVM equivalents, where everything just is exactly like Ethereum, with all the good things, but also with all the bad things with all the problems and bottlenecks of Ethereum on the one hand. On the other hand, it's a complete diversing from Ethereum and going in a completely different direction, using different programming language, different virtual machine, not following the standards and conventions, right? And all the projects are somewhere in between. None of the projects in the Zk roll up space, in the roll up space that I'm aware of, are on the extremes. There are no projects that are 100% equivalent, and there are no projects that are 100% not compatible with Ethereum, because even if you take Starknet, they follow some conventions.
00:30:05.138 - 00:30:48.662, Speaker A: Calling conventions is similar. The idea of contracts and calls, et cetera, some things are similar. It's pretty far from EVM, but it's still somewhere on this far part of the spectrum. So where we are on this spectrum is we are compatible on the source code level. Today you can take any contract written for Ethereum in solidity or in Python, sorry, in viper you can compile it without modifying the contract. In 99% of the cases we don't support a few functions. We can talk about that, but if the code compiles, it will execute and it will perform its functions exactly as it was meant by the creators of the contract.
00:30:48.662 - 00:31:49.680, Speaker A: And we paid a lot of attention. We actually had to make some architectural changes to enable this. What will not work, apart from the things we don't support, are for example self destruct, which is a function that is not recommended, and Ethereum is getting rid of it, I think already scheduled for inclusion in some of the upgrades if you are minor functions that are not frequently used. But that means that most of the tooling will work out of the box. You do not need to make any changes, or need to only make small changes in the scripts, replace the compiler, or change the API to something else, et cetera. There are some things that will not work, like the binary code level tools like bytecode debugger will not work, so we will need to re implement them, or we are working with partners to integrate the support of Ziki sync in those tools. Fortunately for us, those are very few and they are rarely used.
00:31:49.680 - 00:32:56.786, Speaker A: However, we recognize that there is a need sometimes, in some rare cases for full bytecode compatibility. One good example of this is where you want to take an existing contract and preserve the address compatibility across multiple chains. You want your non safe to be safe multisig to be deployable in any chain, regardless of where you deploy it, at exactly the same address. This would require bytecode compatibility with Ethereum, and this is something we are considering. This creates an overhead, like all the projects that are following more closer who are trying to go in the direction of more equivalents, pipe code compatibility, full follow up on the pre compiled, et cetera. They necessarily pay for this with performance. And this was not a trade off we were willing to make, because we are aiming, our mission is to scale, to accelerate the mass adoption of blockchains of Ethereum, specifically for personal sovereignty.
00:32:56.786 - 00:33:22.890, Speaker A: And that means onboarding millions and potentially billions of people. That requires the absolute optimization to the maximum of the performance characteristics of our approvers. So we had to follow to be on the more performance side. But it's possible to also support full bytecode equivalents for some specific cases. And this is something we're working on. And Anthony, do you have anything to add to this?
00:33:23.040 - 00:34:04.458, Speaker F: Honestly, not a huge amount. I think that covered it very nicely. I will say, just to highlight, this was a very deliberate choice when it came to the design of ZK sync V two. And it took all of the learnings that the team, I mean, ZK sync version one has been running in production for, I guess of the order of two and a half years at this point. The cryptography team is a lot of experience in what will work, what's easy to do in ZK, and what's obviously very challenging. And when we were designing the system for version two, it really was this key question around everything is a trade off to a degree, when you're building these complex systems. We did not want to compromise on performance, and the design of the system is such that this really is one of the things that we're really optimizing for.
00:34:04.458 - 00:34:18.142, Speaker F: So between performance and reliability, these are the two sort of combined north stars for the engineering team at the moment. And these have been guiding principles right from when we were iterating on the design, thinking through how do you go from version one to something general like version two?
00:34:18.196 - 00:34:34.862, Speaker E: Yeah, that makes a lot of sense. Do you guys mind getting a little bit deeper into the proving process and kind of the sequencing process in terms of building blocks and how that works and what are the main challenges with decentralizing that process in the longer term?
00:34:34.926 - 00:35:27.406, Speaker F: Yeah, sure. So I'll talk a little bit about maybe where we are at the moment, talk a bit about how we're thinking about decentralization, both of the sequencer and the prover. So the first thing I'll say is kind of rewinding ten or so months back to roughly when we deployed the first version of the system, the version two system testnet. The question we really took a step back to try and answer was what's the shortest path between having the version of the system that we had at that point running on Testnet and really giving something to the community, like really building a production system that was the skeleton of the system that we really think this thing will be in the fullness of time. And broadly, actually, I would say that the roadmap that we made public this summer is a sort of external representation of that internal roadmap. And obviously, when you're looking at this system, it's no secret that this is complex. There is a lot of work to do to make these systems functional.
00:35:27.406 - 00:36:19.106, Speaker F: There is a lot of risk that you have to think carefully about how you manage as you're building this system. And to build the decentralized version of the system to begin with is just like obviously strictly harder, probably orders of magnitude harder. That being said, it's very important to us to make sure that we design the system in a way where we are not locked into having a centralized version of the system that runs forever and are being thoughtful about the roadmap and thoughtful about our investments on the long lead time research items such that actually we are making progress on them today, even if we don't expect to see them in production for say six months or twelve months. So internally, at the moment, the sequencer is fully centralized. The proving is centralized too. So for the first version of the system, we will be operating the stack. Both of these things are planned for decentralization.
00:36:19.106 - 00:37:13.458, Speaker F: They are. Well, I mean, it's a question of priorities for us at the moment. The decentralization of the sequencer, I think, is going to come first. I don't know necessarily that this is the most important thing to do, but we are already actively working on it and we are building an internal testnet with a decentralized version of the sequencer, partly as a mitigation strategy against overfitting the centralized version of the system that we have today. But one of the major things that we're planning on the proof side is for us today, the hardware required to run these provers is they're bpgpus, right? You're not going to have many people operating these things at home like sat on their desktop pc. So we are planning and have actually already started on the cryptography side of a major upgrade to our proof system. And a big motivation for the upgrade to the proof system is actually to lower the hardware requirements for operating approver.
00:37:13.458 - 00:38:02.694, Speaker F: So as part of this, obviously relatively recently, a large number of gpus became freed up with Ethereum going through the merge. We really want to get to a point where we can distribute and decentralize the proof network, as well as obviously decentralizing the sequencer. So both important for us. We really wanted to make sure that there's a lot of value in when you're building these systems, to make sure you're building them in a way where you're getting feedback from the real world. It was really important to me personally to the engineering team that we didn't attempt to just kind of go heads down, build the perfect version of the system over the course of however long that would have taken us, and do this fully in isolation, do this without the community. So getting the system live in its first version where the architecture was correct, but we knew we could iterate, where the performance was correct for where we need it to be today, but we know we can iterate. All of these were things we were optimizing for.
00:38:02.694 - 00:38:39.570, Speaker F: But we do have a team kind of actively working today on the internal testnet where we can take the centralizer and we can take the sequencer and decentralize it. We are not actively working on decentralizing the proof network until we have gone through this upgrade of the proof system, but this will obviously be a huge priority for us. The decentralization of this system is incredibly important to the engineering team, so we're guarding against technical decisions that lock us into a centralized version of the system today because we know this is where we want to be. And obviously this is important for many properties of the system we want to achieve.
00:38:41.350 - 00:39:08.662, Speaker A: I would just add one sentence. It's not just important, it's non negotiable for us. We are building a protocol that will be owned by community. The community cannot depend on one company to operate is concerned. It's a completely obvious thing. It's just a matter of priorities of like do we build something that is perfect but is not available, or do we give the community something that they can immediately use and then we upgrade it to the full version, but it will be done in a very short term.
00:39:08.726 - 00:39:28.462, Speaker B: Now, when you think about the actual process of decentralization, are you thinking about how a token fits into this role outside of just distribution? Like is it actually involved in the process itself? Or do you just view the token as like this distribution method to give the community ownership of the protocol?
00:39:28.526 - 00:40:17.666, Speaker A: No, as I said in the beginning, we only introduced a token in the system because there was a need for a token. It's not that we took the system or some technology, it's separate. And then the token thing is separate. The community is separate. No, the token is actually required to operate the system properly, in a fault tolerant way, and in a byzantine fault tolerant way, in order to make sure that anyone can become a validator, or anyone can participate in the consensus of these validators, so that the community does not rely on anyone particular. And if someone is faulty or malicious, even worse, then they can easily be replaced by the community. And then we have the ultimate nuclear option of the community to fork away if all of that didn't work.
00:40:17.666 - 00:40:59.594, Speaker A: But that is expensive. Imagine. So we're building a mechanism to enable people to submit transactions from layer one, if they feel censored, if their transactions are not being included by the validators. And we are making this mechanism, we're designing it in situated as to support mass migrations. So if an entire fraction of the user base is being censored, for whatever reason, they can just coordinate and submit a big batch of transactions and just migrate to a different network. But you can imagine that's costly. Like anytime you need to rely, fall back on social coordination.
00:40:59.594 - 00:41:33.610, Speaker A: It must be an extraordinary event. You cannot do it every time a server goes down or like an organization, for whatever reason, becomes bankrupt or manager, stakeholder or whatever. So you need to build technical systems that provide a pretty good reliability and security and redundancy in the very adversarial environment in which we find ourselves in the blockchain world, and then have these fallback mechanisms where you rely on layer zero, essentially on the community to keep it in check.
00:41:33.680 - 00:42:05.010, Speaker E: Makes a lot of sense. I want to get into l three s a little bit, because, Alex, I believe you were potentially the one who came up with the idea of Zk Porter. I might be wrong on that, but you guys have since pivoted over to opportunity to launch that on testnet, hopefully in q one or q two of next year. How is that going? How do you see this vision playing out? Steve, one of your colleagues has talked many times about the grand vision of l three s on like a unilateral proving system. So just to hear about that and some of the advantages and a status update would be fantastic.
00:42:05.690 - 00:42:32.326, Speaker A: I'm happy to start. And again, let Anthony add more. And I want to begin by giving credit to. I was not the one who invented VK Porter from scratch. In every invention, you are standing on the shoulders of giants. Every invention is just one small step, one simple idea that makes the previous technologies like a little better. So this applies to ZK Porter.
00:42:32.326 - 00:43:12.358, Speaker A: And by the way, Zikk Porter has not much to do with layer three. It's a separate technology. It's about data availability and making sure that we can build something that will scale. It has application in l three world because it allows l three to become way more scalable, like unbounded scalable. But it's in addition to l three. But regardless, both Zk Porter and l three s are ideas that are built on many iterations of other great people. So like for ZK Porter, Starquare team came up with the idea of volition, where you have ZK Porter, sorry, ZK roll up and validium and you can interoperate.
00:43:12.358 - 00:43:35.540, Speaker A: We added the idea of using tokens to make it permissionless and have data availability adding guardians. Anyone can run the software and make the system a lot more reliable. With layer three, our biggest innovation is not the idea of layer three itself. It was kind of obvious. It was on the surface. Stackwork came again. They were the first to announce this idea.
00:43:35.540 - 00:45:24.606, Speaker A: The biggest breakthrough or the biggest design choice that we are extremely excited about in ZK sync for our version of l three is what we call hyper chains connected by hyper bridges. That's an extremely interesting idea. We will take an entire episode just talking about that. But in short, if you make every layer three separate from each other, and anyone can deploy their own version, that's going to be one world with a lot of diversity. But if you say, let's standardize some aspects of this protocol, like everyone can do whatever they want, they have full freedom and full sovereignty and full customizability over how the chain is going to work, how are they going to sequence transactions, provide data availability, build privacy, or not build privacy, or use roll up or Ziki Porter or pure validum or whatever, you can do all of that and introduce your custom rules. But if we all agree on the same standard for bridging and for proving the circuits, we get some extremely interesting properties. All of a sudden we can build a network, essentially the Internet of value, where any user on any of the hyperchains can send transactions to any other user on any other hyperchain, with zero trust assumptions, zero capital requirements, and essentially at the cost of a simple transaction within each chain.
00:45:24.606 - 00:45:29.042, Speaker A: So that is the most exciting thing about our vision of l three.
00:45:29.096 - 00:46:17.698, Speaker F: Yeah, I can add a couple of pieces specific to opportunity if it's useful, because I think Alex covered a lot of the things that we find really interesting. I would say there's also a lot of value in us working on this sooner than maybe was obvious even a few months ago. There's value in terms of figuring out what and how these things are. Speaking with partners who have ideas for use cases that maybe we wouldn't have come up with ourselves has been really interesting. And hearing about the types of layer three that people may want to configure, it gives us a lot of ideas for actually how to prioritize problem solving from an engineering perspective. I think there's a lot of value in us also going through this exercise now in terms of even making the layer two better. So, for example, there were certain pre compilers we hadn't prioritized for baby alpha because we knew the system was going to be in this closed state.
00:46:17.698 - 00:47:02.866, Speaker F: We haven't needed them initially. We have like things that we would want to add, but to be able to do verification of a layer three at layer two, you need these pre compiled. So it forces us to do some of these things and these things are not, they're generally useful, right. These are useful for any other protocol or any other project that wanted to take advantage of verification of layer two. More than that, I think there's some other things that, if you think about it from a purely engineering point of view, are really interesting. How do we design the system in a way where it's sort of agnostic to how it's being deployed in terms of the environment? Right? Like layer two, assumed ethereum is the layer one. But in a world where you're deploying a layer three or maybe a layer four, or who knows what, can you build the system in a way where it's easy to deploy these systems? You haven't got to build these.
00:47:02.866 - 00:48:18.570, Speaker F: It's not overfit to the original idea for the layer two s. As we take on projects that we mentioned earlier around decentralization of the sequencer, how do we preserve the ability to deploy and configure these systems in different ways? Where some use case may be that, I don't know, party X wants to deploy a very centralized version of the layer three. Well, if we've fully decentralized the layer two, have we lost something that actually would have been useful for one of these people at some point in the future? So, yeah, from our perspective, I think there's really interesting engineering challenges. How do we make it easy to deploy these things, tear them down, redeploy them, and really iterate on building and testing ideas in the space? I think partnering with people in the ecosystem, both builders and users, will help us actually get to a point where opportunity delivers something that we can start to see much further into the future for as we really understand layer threes. And then part of this stuff, you have a lot of great ideas on the whiteboard, but building things, testing things, and really thinking through the problems and actually having a real prototype, I think really give us a lot more clarity over the future of how these systems evolve and how they fail. This is another thing that we're really interested in. Where are the new problems that we'll find at layer three that maybe are less obvious when you're thinking about these systems in a more abstract way?
00:48:18.640 - 00:48:43.250, Speaker B: So when I'm thinking about the l three s, right, so I think about Ethereum sitting at the base layer, providing the security to the l two s, which the l two s then take that security and provide scalability to the l three s. And then, so if I'm thinking about l three s, what are the main appeals of this ecosystem? Right. Would that be like the customization that you'd get at this point, and the fact that you'd have a web in some sorts of interconnected chains at that point?
00:48:43.320 - 00:49:52.874, Speaker A: Yeah, I think, again, this is something where value comes gradually in waves. So this can be something that you can use immediately. And then there are longer term implications of this technology. The first and immediate value that we will create is, yes, you can build your own depth chains that fully inherit security from Ethereum, but you have control over how you want to structure them with regard to data availability, which determines the costs of transactions and whether or not they depend on the data availability. From Ethereum, it's about the sequencer, it's about the approach to meV, and very importantly, it's about privacy, because currently we're not using the zero knowledge aspect of zero knowledge proofs, but it can be used, should be used. And it's very important for normal consumers making payments, but also for enterprises, for banking, for doing. You cannot make all of the financial activity of the world completely public to everyone.
00:49:52.874 - 00:50:54.842, Speaker A: At some point you need to introduce privacy, and this is something that is very easy to do with layer three. You essentially get it out of the box for free. All you need to do is to make sure that the sequencer does not publish data on chain, but instead they keep it private and they only publish the root hashes or maybe encrypted data or something like this. But the technology to create something private is the same exact technology as just to build generic layer three. Over time, more of the other values materialize, such as, yes, we are building a web of value that will allow to scale ethereum indefinitely to arbitrary number. It's going to be limited, just like Internet is limited only by the amount of hardware resources by number of gpus or asics or whatever you need in the world to make the computations. But you can add as many of them as you want and the system will still be growing.
00:50:54.906 - 00:51:17.022, Speaker B: If you can't tell we love data here at Blockroots Research and chainalysis, the leading blockchain analytics company, shares this passion with us. We use data to extract alpha and find the next thing coming in DeFi. But chainalysis is doing the gritty work in building trust in blockchains to onboard the next trillion dollars of capital into the industry. We need to grow safe consumer access to cryptocurrency and promote more financial freedom with less risk.
00:51:17.086 - 00:51:55.140, Speaker E: Chainalysis has some of the most comprehensive and reliable data in the space, and they use this data to power a full suite of their solutions that can be utilized by industry professionals. Best in class training and certifications are also led by chainalysis and some of the brightest minds in the space. If you haven't heard of chainalysis, you gotta check them out and we'll link to them in the show notes. I don't want to pry at this too hard because I'm sure it's still getting figured out. I mean, we're all kind of figuring it out as we go here, but I'm just curious because I hate bridges. So how does that work? How do you have a completely trustless way to go from chain a to chain b in a layer three world.
00:51:57.270 - 00:53:17.350, Speaker A: I can recommend so I can give you a high level technical overview, and I will refer to the paper called flush from geometry guys who explored this topic in depth, and we had the exact same idea. We read the paper and we were like, wow, this is a really good write up of the idea. But essentially the idea is not new. If you look at the privacy chains, such as zcash, the pioneer of privacy, the way they work is you make a commitment to your transaction first and then you kind of redeem this transaction. So first you create a node in some ledger in your Merkel tree saying like, I have spent some amount of my zcash here, and you provide a zero knowledge proof that this is valid and that it's added to the ledger. And then on the other side, once the recipient wants to redeem these tokens again, they provide a proof that there is an entry on the ledger somewhere, such as, someone has sent me this amount of tokens so I can claim them and add to my balance. So now you can do it within one chain to achieve privacy, or you can do it between multiple chains to achieve scalability, because it's very easy to concatenate Merkel trees.
00:53:17.350 - 00:54:12.960, Speaker A: Concatenating Merkel trees is just taking the root hash of one and putting it as a leaf of the other. It's very technical, and for maybe less technical audience, what it means is any layer three can freely read the state of any other layer free. I mean, the last finalized state, not, maybe not the most recent state of validators, but the last state that was finalized and was propagated down to Ethereum. But they can read arbitrary count, arbitrary point on any data, and they don't have to have full state of all the other hyperchains. All they need is a short merkel proof of a particular point on a particular chain. And once you have this point, you can say like, oh, I trust that other hyperchain because it has exactly the same circuit as me or the chain I'm building on. So for me, it's the same as trusting myself.
00:54:12.960 - 00:54:43.398, Speaker A: I know it was produced running exactly the same code as I'm using. So I'm just going to add this balance to my account. And this is an operation which takes place just in two chains and doesn't affect really, you don't have to propagate all the data down to layer two or layer one. All you need to propagate is one hash per chain, and it just like logarithmically compressing. For more details again, please refer to the slash paper.
00:54:43.484 - 00:55:15.330, Speaker B: Yeah, that bit makes, it makes a ton of sense, and it's exciting to think about that type of world. And when you say they're running on the same circuit, is that there's going to be, I think earlier you mentioned that there will need to be some portion of the l two stack that becomes widely adopted. What exactly is that? And there's multiple people or multiple teams that are actively working on building out their version of the ZKe EVM. And so all these l three s would need to live within the same circuit, then. So what exactly piece is it that needs to be standardized?
00:55:16.390 - 00:56:14.874, Speaker A: It actually has to be the virtual machine itself, like the most basic circuit, or essentially the thing that executes transactions. So this is a really interesting question on how we can reach interoperability with other chains. I think I look at different competing approaches, more like experimentation. We're in a very early phase of creating zkvms. We built the first ZkvM I think we introduced the idea two years ago and we built the testnet, launched it internally a year ago, and we opened it to the public in February last year. So it's running now for ten months. So all the other approaches were much later they came up with something like some testnets were announced around public, testnets of polygon and scroll were announced around Devcon.
00:56:14.874 - 00:56:58.690, Speaker A: So we will see how these approaches work and which one is most efficient. And eventually I think we will all converge on one single bottle tested and most efficient approach to the click. I can compare it to the IP protocol that powers the Internet. In the beginning of Internet there were multiple competing protocols. IP was not the only one. There were streaming protocols, there were packet protocols, there was AP, there was UDP, TCP IP, they're still being used. But there were also competing protocols to the Internet protocol itself.
00:56:58.690 - 00:57:41.258, Speaker A: But eventually everyone realized that if you use one standard, you can create one giant network where everyone can talk to everyone else. And this is not a disadvantage, doesn't mean that you need to close down. Your data is going to be transparent to everyone else. And the only way to guard your data is to build intranets. No, just build firewalls. You encrypt your data, you use SSL, you use HTTPs, et cetera. But you need to agree with this one single piece, which is common across different hardware, different channels, fiber optics, wireless networks, like modem connections, all of them agree on this one single piece of IP.
00:57:41.258 - 00:58:06.390, Speaker A: And this is how we see the circuits that will eventually crystallize. Like this is the way and this version, and you're absolutely right, it's important to define what this part is. And the smaller it is, the better. We want it to be as small as possible and have as many eyes as possible looking into it and into its security and making audits so that it's easier for everyone to agree on this one.
00:58:06.540 - 00:58:33.566, Speaker F: Know, coming back to what Alex was saying earlier about our open source strategy, all of this is consistent. We want to get to the point where we've opened the protocol. You know, our aspirations are to be one contributor of many to a protocol that does converge on a standard. And we can actually start to talk about how these systems scale and scale in a way where it's the community scaling it. So no, again, it's informed open source strategy and it's really how we think about things at the moment.
00:58:33.668 - 00:58:44.530, Speaker E: Winding back a little bit, I know you guys just launched your alpha main net open to developers. How is that going? Are you seeing good traction? What applications are you most excited about? Would love to get your thoughts there.
00:58:44.600 - 00:59:42.262, Speaker F: Yeah, I can say a couple of bits and then Alex, if you want to jump in. So at the moment, the state of the system, we're really excited. We hit a huge milestone that for us had been something we were pushing hard to achieve, which was to have a version of the system that was our real mvp, the version of the system that we were comfortable deploying to mainnet after having run to Alex's point around ten months or so on testnet, major improvements over that time, major challenges solved. But we had the first production version of the system. We wanted to deploy it onto Mainnet for a number of different reasons, and I would say they're broadly bucketed under security and performance. So the moment the system is still closed, in the sense that we are the only ones who are able to access the system, it's running on Mainnet, it's live, but it's live in a very, very restricted way. It's not like a full live production system today, and external developers can't deploy on it yet.
00:59:42.262 - 01:00:19.406, Speaker F: What we're doing right now is we're going through a series of activities on the security side, including audits, as we mentioned open zeppelin earlier, layer one. I think we published the findings from our layer one audit relatively recently. Layer two and multiple other pieces of the system are under audit at the moment. And then we're also working on the prover performance. So this is a pretty tricky technical problem, and using our GPU resources efficiently is important to make sure that the system runs in an economically efficient manner. So we have a bunch of activity going on the security side. We ran a code arena contest.
01:00:19.406 - 01:01:20.258, Speaker F: We have a lot more to say about things that we'll be doing on the security side. Incentivize hacknets and various different bits and pieces, like having the system live on Mainnet, learning to operate the system and really iterating on the performance of the system are where we are today. We are very close to the next major milestone, which is what we've called fair onboarding alpha. So at this point, projects, and I think there's more than 200 projects who have registered to use the system today, including many exciting big names across DFI, gaming, NFTs, kind of a big cross section of the community. They will be able to bridge value into the system, deploy their applications, kind of have a period where there's no sort of first come, first served effect. It will be everyone is able to deploy at the same time. They have some period which we will define and talk more about and add more detail on soon where they can test, knowing that at the same time everyone sort of goes live instantaneously.
01:01:20.258 - 01:02:10.130, Speaker F: So the first milestone will be development teams only, there'll be some period, and then after some relatively short window, we'll release the constraints on the bridge and actually users will be able to bridge value into the system and simultaneously, essentially the entire ecosystem goes over at once, which is, I think, a pretty exciting prospect. So we are not far away from any of these things. We are in the closing weeks of one of the major security audits that we are working on at the moment. Obviously, we can't commit to being like, we'll get this thing on January X, we'll be live on January X plus one. We want to make sure that we've got a window to evaluate any findings, implement any changes. The GPU performance work is ongoing and we'll likely be publishing a blog post soon. We want to make the system and the engineering that we're doing a lot more transparent.
01:02:10.130 - 01:02:26.854, Speaker F: So we are aggregating all of the work that we're doing. We'll be speaking very publicly about some of the changes we made, the effect on the system, and we'll be slowly opening up a lot more of what we're doing on the engineering side. But yeah, coming months we'll see these two exciting milestones. First developers and then users.
01:02:26.982 - 01:03:38.322, Speaker A: I will just add that we see a lot of developer activity on our testnet, which is running since February and is very stable, and we have hundreds of projects building there. We have over, I think, 200 partners committed to launch on the launch day of ZK sync, which will make ZK sync the largest launch of a mainet in blockchain history so far, to the best of my knowledge. So I'm personally excited about all of them. We have some really big names starting with Uniswap and Aave balancer curve, all the top Defi protocols, a lot of really interesting community protocols that are less known of. A lot of new things that people experiment with on Ziki sync, because it's going to offer very interesting properties using snarks and it can create communities based on that. Like we had zigzag exchange launching on Zksync version one, and the whole community was people who are excited about zero knowledge proof scaling. So I don't want to give preferences, I'm genuinely excited about all of them.
01:03:38.376 - 01:04:02.314, Speaker E: You mentioned snarks like multiple times throughout the conversation, and I think a lot of people contrast things that Zke, EVM teams are building with things that Starkware is building, not to say one approach is better than the other. We're still figuring it out. But I guess, what are the main tradeoffs, and why did you make the design choices to not try and use a more performant language like Cairo or using snarks over starks like Starkware has?
01:04:02.432 - 01:04:56.710, Speaker A: That's an amazing question. So, first of all, it's a matter of terminology. Technically, starks are a subset of snarks. Starks are also like we are not bound by a particular technology or a particular zero knowledge proof protocol. Right now, we're using plonk, but we have came up with a proof system called redshift a couple of years ago, then the guys from mirror protocol, now part of polygon, took this idea and made some changes in the parameters, came up with something like plonky two, which is essentially redshift with a smaller field and a few interesting properties. So the protocols are evolving, and I believe that all of the teams will eventually converge on something that is more most efficient. Right now, we're in a phase of a cambrian explosion of zero knowledge protocols.
01:04:56.710 - 01:05:57.966, Speaker A: But at some point, there will be consolidation, and we will be coming slower to asymptotic improvement, where the pace of innovation is not as wild and it's more stable. And then everyone can see, okay, this is the way to do it, because starks depend on the efficient hash functions that are both efficient in circuits and on the processor. There are some candidates for such hash functions that are currently being tested. Like, once they are available, it's going to be a lot cheaper to use them. But for now, recursion is probably cheaper on this other system. So we are not dogmatic, we are completely agnostic and open to whatever the latest research will be, and we will just switch to these proof systems. But the great thing about all of them, plonk, starks, plunk two, like hyperplunk, all of the things, is that they basically all use the same format to represent the programs we call it.
01:05:57.966 - 01:07:13.638, Speaker A: In the world of snarks, we call it arithmetization, how you transform your bytecode or the logic of your program into a polynomial in one huge polynomial, or like a matrix of numbers in finite fields. And this format is strikingly similar. It's essentially the same thing between starks, or very similar. So it's very easy for us to transition from what we have today to a new proof system without changing the circuits, essentially. Right now, what matters for Ethereum is scalability and low cost of transactions and relatively high frequency of checkpoints, of the speed of finalization of your blocks on Ethereum. So if you look at specialized ZK roll ups such as ZK sync version one, roll up for payments and swaps, and NFTs and Starkx, they specialized ZK roll up for an exchange. Both of them are producing, making very similar things.
01:07:13.638 - 01:08:05.618, Speaker A: But in ZK sync version one, you have blocks like about ten times more frequently finalized in Ethereum than in Starknet. And the reason for this is that we're using plonk, which costs half a million guests to verify, whereas starks require 5 million guests to verify. So you have to wait for a lot more transactions to accumulate in the block to justify the cost to verify this block on Ethereum, because the verification costs are the same no matter how many transactions you have there. Right? So this is one important trade off. In the future, again, we will be using just the most efficient thing. And in the longer term future, it must be something fully transparent. I cannot imagine all of the world's financial systems relying on some trusted setup, no matter how many trusted participants and reputable participants were in that setup.
01:08:05.618 - 01:08:16.282, Speaker A: Has to be like a completely transparent system with something like Frybase, Starks or Halo or similar things.
01:08:16.416 - 01:09:05.066, Speaker F: Yeah, not much more to add, except to say, as I mentioned earlier, the cryptography team are already looking into the next version of the proof system, and as part of that are looking into things like priybase proofs, hyperplant, moving away from a trusted setup. A lot of the things that Alex talked about are things we're actively thinking about. And really the question also comes down to how do we optimize for not so much the specifics of the proof system itself, but the things that really, really matter at the system level, like how do we optimize for security, how do we optimize for simplicity and ease of modifications, ease of extensions, those things really matter. And yeah, so we're balancing trade offs between what we want to see in the proof system and also how easy it is to kind of keep iterating on the system, keep delivering for users with Zkatin B two.
01:09:05.168 - 01:09:29.602, Speaker B: Yeah, account abstraction has been a hot topic recently, and I'm curious when that gets implemented, then it gives the ability for transactions to be paid the gas, for transactions to be paid in any token. And I'm curious if that's something that you think about when you're designing systems like an l two that ultimately are paying back, paying, settling transactions on the l one. And of course paying gas. Is that something that you've considered yes.
01:09:29.656 - 01:10:49.146, Speaker F: So this is implemented and live today. So we support account abstraction natively on Zksync version two. This has been, I think, one of the most exciting and interesting features that really highlights how we're thinking about crypto becoming something that can really scale to millions of people when we're talking about usability and not just scalability. What you can do with account abstraction, what the tools to your point about giving flexibility to development teams to think about do we want to pay for transactions on behalf of our users? Do I want to sort of configure my payment interface to accept some subset of tokens that I care about? The level of flexibility that I think we'll see developer teams have at layer two is just much richer and really it lets you start to design wallets. I think there's many good examples of people who are innovating on wallet design. I think Argent is one of the ones that obviously is very close to us. We've seen some really creative and compelling features that just, you can't imagine that many of us today, as cliche as it is, it's still early and the user experience at layer one can still be pretty rough, right? You still may want to send those test transactions or double check that copy paste errors are not there.
01:10:49.146 - 01:11:38.282, Speaker F: And really, when you see the innovation from wallets leveraging these account abstraction features at layer two, you can start to actually see a world in which millions of people are going to be using this thing. Because to a large degree, I think for most people, the blockchain should be abstracted away. I mean, really in the same way as people using Facebook today don't care necessarily about the Internet protocols on which it's built. Many applications are going to want to be built in a way that people don't care that there's a blockchain involved. And I think account abstraction is really a bet on bringing crypto to a community that doesn't or can't engage with it today. And it's not just scalability at the level of providing an execution environment that can handle those number of transactions, but also providing a user experience that can support people who don't or aren't interested in learning about the technology or protecting themselves in the way that they might need to.
01:11:38.336 - 01:12:11.762, Speaker A: So I want to share a story about this. A few weeks ago, a friend of mine calls me and says, alex, I received the crypto payment from my employer. They agreed he will be paid in crypto and he received USDC. And he was like, I was trying to send it to an exchange, but I couldn't because it said I need to pay some gas with whatever, and I don't understand it. What does it mean? It says I need some ether. I don't have ether. So I tried to change this USDC into ether to pay for gas, but I can't because I don't have ether to pay gas.
01:12:11.762 - 01:12:49.538, Speaker A: And the problem is, in the ERC 20 standard, there is no way for him to make this transaction without having ether. He cannot just let a wallet to pay for it. He actually must have ether in the first place. So he must ask someone to send him ether, and only then can he authorize the transaction, or they need to do some chain or whatever. So it illustrates perfectly how you get something. If you don't think about the user experience, in the end you're going to get some mess. And for us, I'm just going to repeat it because it's very important.
01:12:49.538 - 01:13:34.618, Speaker A: And everything we do is centered around the mission. And the mission is to accelerate the mass adoption of crypto. And mass adoption means usability. As Anthony just said, the UX is at the core of it. The mass adoption of PGP never happened. What happened is like mass adoption of signal and telegram with I'm not sure how encrypted telegram is like, let's say signal or even WhatsApp, why PGP was there for 20 years, but it was so complicated that even the most advanced cryptographers in the world are not really using it between themselves because it's just too cumbersome to deal with. That is a part of mass adoption.
01:13:34.618 - 01:14:14.910, Speaker A: And everything we're building at ZK sync, we are having the end user in mind. This is how we build version one. This is how we're building version two. Like we're imagining if this thing is to be used as the standard of the Internet of value, is it going to be usable? We have all the functions sufficient for it. Is it going to be affordable? Can we scale it? All the aspects are done with this final vision in mind, and this obviously includes account abstraction. This is why we did it as the very first thing diversion from Ethereum, because Ethereum's eap for account obstruction was heavily discussed in the community. It was not final.
01:14:14.910 - 01:14:21.662, Speaker A: And we realized we cannot launch without it because it's not going to be something really usable for masses for millions of people.
01:14:21.716 - 01:14:43.782, Speaker E: Yeah, I would venture to bet that all four of us on this call have bridged somewhere at some point and then not have the gas token when we got there. And it's very frustrating but you guys have been super generous with your time. So I just want to round it out with one more question. What are you guys most excited about in crypto? Broadly, it can be anything you want, ZK sync related or anything else over the next twelve to 24 months, let's call it.
01:14:43.836 - 01:15:39.930, Speaker F: I mean, for me, it's hard to look beyond our roadmap. I mean, as cliche as it sounds, it feels like we are right on the precipice of really being able to open the gates to something that we've been thinking about for a long time. To Alex's point, years of work have kind of led up to the point where we have this version of the system. We are really kind of in these last moments of thinking through, like, have we crossed all the t's, dotted all the I's? Really, have we shouldered the early risk from a security perspective, have we really pushed the system performance to where we feel comfortable to launch it? We have a large number of partners ready to use the system. And for me, I can't look much beyond the next couple of milestones. I think it's going to be challenging, exciting, but ultimately we're right there with a system which I thought many people would have expected to take much, much longer. An enormous amount to do, but looking forward to doing it in production and.
01:15:40.080 - 01:16:30.946, Speaker A: With the community, it's kind of similar for me. I'm super focused on what we're doing. We're scaling the company, we're scaling teams, we're doing a lot of research, development, brainstormings. But in general, how I feel about crypto is what I'm really excited about in crypto are the brave things that change the status quo. Some innovations that kind of do this creative disruption of the way old systems used to work. And some examples of this are obviously defi, which is like a radical innovation in finance, things around identity. I'm really looking forward to the identity solutions that can replace just like passwords and the way you authorize in credit cards.
01:16:30.946 - 01:17:53.150, Speaker A: Like every time I go to a new city and have to ride a bike like the scooters, I have to fill like 1000 forms and add my credit card and sms confirmation, all that stuff. Or you're trying to buy a plane ticket on the new airline, you have to do the same process over and over and over again. She can be just replaced with one single click. Connect your wallet and authorize some data and you just confirm that you're willing to provide this data in a privacy preserving manner, but also authorizing you and saying like, yeah, you're a real legit person and you are not a fraudster and you are willing to pay and provide your identity all at once without passwords, which are notoriously insecure. So identities, things like industry disrupting ideas like DSi, centralized science, where all of a sudden you can compete with huge pharma concerns on big organizations because you can directly be appealing to your future users, to consumers. Something like what crowdfunding did in the past, but specifically applied to patents and scientific ideas and scientific innovation. Because I think there are a lot of problems in academia.
01:17:53.150 - 01:18:25.570, Speaker A: People from academia I speak to are all very worried about them. And the sooner we can transition to something decentralized where people with genuine interest and passion for science can just go and get funded directly, like bypassing all of these bureaucracies and inefficient processes, that's going to be really cool. And I know a couple of projects that are working this direction that are really interesting, so thinks in this direction. There are many more which I'm not aware of because I'm super focused on CK secret.
01:18:25.670 - 01:18:39.266, Speaker E: Awesome. Yeah, crypto is definitely exciting. It's moving quick. I'm excited to see how it pans out over the next twelve to 24 months. But thank you guys so much for joining on. We'll have to do this again sometime, but if you want to tell people where they can find you, that'd be great.
01:18:39.368 - 01:19:13.086, Speaker A: Sure. The best way to follow us is to go to Twitter and search for zksync. One word and all official updates. Everything we share is posted there first in real time. We are building the teams after raising a really big round now and especially in the bear market. It's a good place if you are passionate about freedom and trustless technologies. And I think the recent events highlighted again.
01:19:13.086 - 01:19:46.546, Speaker A: How important is it to build systems that rely on math and publicly auditable code and not on individual people who can be corrupt or can become corrupt or misbehave at some point. So if you are passionate about those things and you are a blockchain engineer or you want to explore, we have a number of positions open. So if you go to Zikisync IO, you will find a link to our jobs page and you can see things there or you can just apply if you feel that you can be useful in a different role.
01:19:46.578 - 01:20:04.302, Speaker F: Maybe just one thing to add as well. We have a very active community, discord, developers, users, lots of people that are building on Zksync B two today on Testnet. If you want to come get involved, there's also lots of tutorials. Yeah. More feedback from the community is always welcome. And there's a team. They're always happy to chat about what we're doing.
01:20:04.356 - 01:20:09.100, Speaker E: Awesome. Thanks so much. Close.

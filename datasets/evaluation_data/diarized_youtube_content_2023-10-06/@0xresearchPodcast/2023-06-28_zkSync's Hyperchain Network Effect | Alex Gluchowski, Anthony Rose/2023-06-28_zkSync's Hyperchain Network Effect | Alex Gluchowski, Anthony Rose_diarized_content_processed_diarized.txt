00:00:00.170 - 00:00:19.470, Speaker A: We want to give people an alternative that will actually work. If you compare the ZK stack to the cosmos ecosystem, the difference, basically the difference between all the similar stacks is going to be, in a way, how the bridges work. The bridges determine the properties of the ecosystem.
00:00:22.290 - 00:01:21.462, Speaker B: What's up everyone? Welcome back for a bonus episode code. This week we got a really special announcement for you, which is the ZK stack. The matter Labs team who built ZK sync era has now published their Zk stack, which is more of an interoperable modular type solution for building l two s and l three s based on Ethereum. So the whole idea kind of centers around hyperchains, and hyperchains are just roll up blockchains that have a broad design space so you can have a hyperchain that's a validium, meaning it uses a centralized DA provider, so it has a different set of security guarantees. And that lives on a spectrum all the way over to the complete other side, which would be like a pure Zk roll up that inherits the security of Ethereum. Now, those hyperchains can be l two s and settle down to Ethereum, or they can be l three s, where a hyperchain would be like settling down to the l two. So for example, maybe you're a game developer and you don't want any of the crowded user traffic of DFI applications taking up some of that block space.
00:01:21.462 - 00:01:51.806, Speaker B: So you build your own l three. That maybe settles down to Zksync era, which is another hyperchain. So it kind of gives you this modular stack to build Ethereum based roll ups in. And further to that, it comes with an out of the box interoperability solution, which is being dubbed hyper bridges. And so having the same prover. So using like a shared proverbs technology in this stack allows this seamless and trustless bridging between different hyperchains. So super exciting announcement that comes through.
00:01:51.806 - 00:02:04.554, Speaker B: And we have Alex and Anthony from the Matterlabs teams coming on to really give the lowdown of what all of that actually means and why it's important. So super fun episode, but we got another couple of announcements for you guys, so I'll toss things over to you, Sam.
00:02:04.602 - 00:02:36.682, Speaker C: Yeah, guys are going to be super thankful for that intro Dan just gave you too, because not going to lie, we kind of jumped right into the nitty gritty of it all. And it's a bit hard to keep it all straight. So hopefully that helps you out. But I did want to take a moment to shout out permissionless. It's by far the most fun crypto event of the year went last year. We had an absolute blast. We definitely want all of you guys to come down, and if you want to buy a ticket today and get 20% off, you can use the code pods, pods in all caps, 20 to receive, 20% off to permissionless tickets.
00:02:36.682 - 00:02:43.902, Speaker C: So be sure to do that. We will link to it in the show notes. And then we also, as always, have a quick little atom accelerator shill for you all.
00:02:43.956 - 00:03:02.354, Speaker B: Yeah, I got to mention it. Love our great sponsor, atom accelerator. And if you're a builder looking for a home in this space, then you know where to go. And the answer is the atom economic zone. Continued development over there. The podcast that released yesterday. So this will be a Wednesday, June 20 eigth.
00:03:02.354 - 00:03:36.926, Speaker B: We talked a ton about duality, which is a very exciting development coming to the atom economic zone. And it's really bringing this new era Dex to the ecosystem. On top of that, you have IBC, you have interchange security. The list goes on and on. And with USDC coming through Noble in the next couple of weeks, that's just a continued development that the ecosystem gets to be excited about. So if you're looking for a grant, or you're a builder, or you're passionate about some piece of the ecosystem and you think you can add value, then be sure to reach out to the atom accelerator. I'll put a link to their website in the show notes, so be sure to check that out.
00:03:36.926 - 00:04:00.278, Speaker B: And they're giving grants on a rolling monthly basis of $10,000 to $1 million. So again, be sure to check them out with the link in the show notes. But without further ado, we can jump straight into things with Alex and Anthony from matter Labs. All righty, everyone. Welcome back. We are joined today by Alex and Anthony from the matter labs team to discuss an exciting announcement. Appreciate you guys coming.
00:04:00.278 - 00:04:14.366, Speaker B: Know this has been a long time coming, getting this out the door. So I'm sure that there's a huge weight off your shoulders just to kind of get everything out there. But real quickly, I'd love to get the announcement from you. So what is the big news and what was released today? Maybe I'll toss it over to you.
00:04:14.388 - 00:04:46.146, Speaker A: Alex, absolutely happy to. Thank you for having us. So we announced the release of the ZK stack. What's ZK stack? It's the next step of the evolution of Zksync project. We started out as a mission focused project, deeply mission driven. We wanted to scale Ethereum, we want to scale public blockchains to get to mass adoption, to accelerate the mass adoption. And we started by focusing on the core technology first, we built the first version of Zksync, which is now known as Zksynclite.
00:04:46.146 - 00:05:52.026, Speaker A: It's a specialized roll up for payments. Then we made the next huge step in bringing the first ZKe EVM into production, which is known as Ziki sync era, which is the first network, which is the first blockchain in our network. And now we're taking the code of Ziki sync era, and we're giving it over to the community. This is something that we planned, actually, from the beginning, but now it's actually official. We unveiled the plans for Zksync to be bigger than just one blockchain. We're giving you a framework which you can use to build your own chains, which all can be part of this big interconnected ecosystem with shared liquidity, seamless interoperability between the chains, fully, trustlessly, with minimal costs. And this is something that has this hyperscaling property it can scale to accommodate any need that will arise for this emerging Internet of value.
00:05:52.026 - 00:05:54.502, Speaker A: That's roughly the idea of the SDK step.
00:05:54.576 - 00:06:12.066, Speaker C: Great, I appreciate that intro. And just to zoom out a little bit, you guys also published your manifesto of sorts on GitHub just a little bit ago. It's called ZK Credo. So I was hoping you guys could kind of dive into that. Why you felt the need to kind of release a vision of sorts, to kind of align the community and what the core values are?
00:06:12.168 - 00:06:48.990, Speaker A: ZK Credo is something we actually used internally for years. Not a release of this manifesto, of this ideas. It was more a codification of them, just putting them in a shape in some solid form that can be discussed by the community, that we can use strict definitions for. We can formalize the North Star, the criteria of how we achieve the mission. But we certainly understood them all these years as we were building things, we were building the first version, the second version of Zksync protocol. We were guided by those principles implicitly. Now we just wanted to make them explicit.
00:06:48.990 - 00:07:25.786, Speaker A: It's a first draft. It's open for the community to comment, to make prs on GitHub. We want to formalize it, collect enough feedback, and kind of come to a consensus of what this ethical framework is basically for all ZK powered network. Because it's very generic, it's not specific to EZk sync. It outlines what we believe are the properties of this hyperscalable networks that must be implemented in order for us to fulfill the mission of getting to the.
00:07:25.808 - 00:08:24.522, Speaker D: Massive ocean, maybe just to add one thing there as well. I think, at least internally, this has been, to Alex's point, like a framework or a set of lenses by which we think through every decision we're making on the technical side, because all of the technical work is sort of in support of a mission and in support of a vision for how the future could look. And as we're at this point now with ZK sync, where we're this inflection point where we want the community to be involved, we want the community to start driving things in a way that it's not just matterlabs and it really opens up. And I think this is where we are. Obviously, with the ZK stack, it's really important that these principles are, like, foundational to the way that this work happens. The technical work is in support of something, and this vision is something that we wanted to socialize our perspective and start to work with the community to refine, to hone, to discuss. And, yeah, this inflection point, I think a lot of these things kind of coming together is because of this is where we are on the technical side, and we need to do it in service of the broader mission.
00:08:24.586 - 00:08:50.498, Speaker B: That's awesome. I love how you guys have kind of laid down these base principles and ideals that you are kind of using to build out your vision. But I want to kind of dive right into the ZK stack now and really start unpacking what this is and who it's for. So if we look at the l two landscape today, now arbitram has orbital optimism, has the op stack. How is the ZK stack different, and what are the primary benefits of using ZK over the optimistic designs?
00:08:50.594 - 00:09:41.030, Speaker D: Sure, I can maybe start with a quick outline of what it is, and then we can talk about why you might consider it and some of the advantages. So to start with what it is. So the ZK stack, kind of at a glance, is, you could argue, like, the generalization of the code base that we've built and have been developing for era, but starting to also give the toolkit the template for what we're calling, like, hyperchains. And this sort of vision for hyperscale, this could be built on this technology. So in scope, sort of from the technical perspective, for the ZK stack are the core components that we have developed for era. There will be more coming as we kind of make the system more configurable, more modular, and so on. But it would include things like the sequencer, the circuits, the prover.
00:09:41.030 - 00:10:26.660, Speaker D: The system contracts bridging interfaces. So it's definitely sort of the core components that you would need to deploy if you wanted to deploy a hyperchain, a version of a system that looks a lot like era. It will also include things like the tooling around that. So the compiler sdks for configuring things, Clis. So essentially it's the set of things that you would need if you were a development team to be able to deploy a version of this system that looks like era today, but over time could be more flexible and designed in different ways to support different use cases. So yeah, it's this free, fully open source piece of code, composable design, configurable design. And essentially this is what the ZK stack is.
00:10:26.660 - 00:10:35.800, Speaker D: Alex? Yeah, not sure if you have anything to add to that, but this is at least what exists today. And then we can talk more about obviously where we're going with the system.
00:10:36.490 - 00:11:33.820, Speaker A: Yes, and I want to answer the second part of this question. Why ZK stack? So yes, you're right, there are a couple of things you can use today to build your own chains. There are optimistic roll ups, there are things that even are non roll ups that you could build to just deploy chain, which is like separate to Ethereum or inherit some security. The problem with those approaches is that they use these older technologies. If you build your own stack, if you build a chain that is based on Ethereum, like let's say you built an optimistic roll up, it's going to be very hard for you to transition to these newer technologies. You can do this potentially, but then you will not be able to leverage this kind of what we call superpowers of the ZK because you need, certain design decisions must be taken from the start. If you don't put them in from the start, it's really, really hard to change.
00:11:33.820 - 00:12:39.290, Speaker A: This is happening with every technological shift in the past. You go from zeppelins to airplanes, you cannot just replace the engine you need to build, like to change the entire infrastructure, you need to change the hull of the aircraft, you need to do different aerodynamics and so on. Specifically with ZK, there are properties of zero knowledge proofs, succinct zero knowledge proofs, such as succinctness, that allows you to compress data availability, that allows you to use different approaches. Like when you optimize, for example, your account abstraction design for optimistic roll ups or for ZK roll ups, you will end up with two very different designs. And if you stick, like imagine you start building, you open your chain, you invite applications to start building on it. You have a set of standards that they have to start adhering to, and then the ecosystem forms around that. You cannot really change this anymore.
00:12:39.290 - 00:13:22.858, Speaker A: Look at Ethereum, look at self destruct, look at the AP for eight four. Why do we have AP for eight four? Because we cannot change Ethereum at this core protocol level easily. There were attempts to build AP 84844 in a way that would natively support account abstraction for all accounts, but they were rejected because this would break one or the other invariant one or the other convention that people are depending on. And this would kind of remove this backwards compatibility. The backwards compatibility is a cost. You have to carry it over very long time. So if you don't build certain, you don't have to do everything.
00:13:22.858 - 00:13:53.478, Speaker A: There are certain things that you can change. You can always extend the chain if you go for a specific design, like you can go for EVM compatible design. And later you can add other languages which arbitrum is doing, which we are doing with our LVM compiler. So you will be able to write smart contracts in rust, for example. So this is a strict extension. It does not affect anything that was previously deployed that is unproblematic. You can always do it on all chains, but changing the fundamentals are hard.
00:13:53.478 - 00:14:04.906, Speaker A: And there are really a few things that specifically around call data and data availability that you can't really change after you deploy the search.
00:14:05.008 - 00:14:30.014, Speaker C: Interesting. Okay, so if I am a developer looking to build with the ZK stack, what are really my options and what are the security trade offs of the different options? It's kind of hard to keep it all straight. You got ZK Porter accounts, you have hyperchains, and then you have the marketing lingo l three that everyone tosses around pretty casually. Can you kind of clear the air around the different architectures that are actually available through the ZK stack?
00:14:30.062 - 00:15:12.358, Speaker A: So zkstack is a modular framework. You can customize different aspects of your chain. You can start with all the defaults, just copying the configuration of Zksync era, or you can say, I want this component to look differently. So let's walk through the components that you can customize. The first is your sequencer. You can opt into a centralized sequencer, which is easier to maintain initially, but you probably don't want to stick to this option unless you need a centralized sequencer. You're an enterprise, a bank, maybe a gaming company that really does not need to decentralize the sequencer.
00:15:12.358 - 00:15:43.962, Speaker A: But we expect most chains to decentralize the sequencer. In a way that, for example, you run a consensus in L2 that will sequence transactions. So then you'll need the validators. You will need to stake some token, maybe to decentralize it permissionlessly and so on. So you will be able to choose all of that parameters, which consensus algorithm you want to use, how do you secure, what token do you want to use there, and so on. The second option is or configuration is data availability. This is really, really important.
00:15:43.962 - 00:16:48.238, Speaker A: This is a huge topic. By default, Zksync era is a ZK rollup, and we encourage everyone to build ZK rollups and promote ZK rollups first and foremost, because ZK Rollup is an architecture in which you publish data availability through the Ethereum network. So you rely on Ethereum's layer one as your data availability layer, and you do it in a way that is basically giving you 100% of the Ethereum security. You do not rely on Ethereum validators, you rely on the entire network. The validators do not have any power to withhold data from you because you depend on all the full nodes of Ethereum. So this is by far the best and most secure option and the most decentralized one. But it comes at the price, because all the roll ups on Ethereum, optimistic and ZK roll ups alike share the same data bandwidth, the same limited block space which you can utilize for your data.
00:16:48.238 - 00:17:49.390, Speaker A: So it's currently pretty limited. It will be extended after protodunk sharding, and then with dunk sharding it will go much bigger and we will be able to accommodate potentially thousands of transactions per second across all the roll ups. But we still need some path to go there and meanwhile, but might be quite expensive, once all the roll ups get a lot of traction and you really bring millions of users onto them, the data availability will become a bottleneck. So on this path forward towards Ethereum getting full sharding on DA, you need to consider other options. And the alternatives could be avalidium, where one or multiple parties hold the data availability for a given chain. The state transitions are still secured by Ethereum, but the data availability is then managed by these parties. It gives you an upside of privacy.
00:17:49.390 - 00:18:58.650, Speaker A: So this party could be a bank, and they might not want to disclose all of the transactions that happen on this specific chain, while still guaranteeing to the users that all the rules are preserved. You don't trust the bank to not spend your money. It's still enforced by Ethereum, and all the smart contract rules are enforced, but it's obviously like they control the data, and they can just shut down the data for everyone burning the entire chain, which is a bit suboptimal. The other option is ZK Porter, where it's essentially the same architecture. It's still a validium, but the data availability is secured by the users, by token holders putting something at stake. They stake some token and they guarantee data availability from there. Now, depending on what token you use, you get different properties, but roughly like if you use some stable token, it will be suicidal for them to burn all of the stake.
00:18:58.650 - 00:20:04.398, Speaker A: The risks are significantly lower than the pure validium. So you as a user can choose, like, do you want to settle for that? Do you want to go for full ZK roll up? And in the Zksync architecture, because it's designed like this from the beginning, you can have what is called officially volition. You can have a choice which account you want to use within the same chart of the system. It's done in a way where roll up accounts and ZK Porter accounts can seamlessly interact with each other synchronously within a single transaction. What this practically means is ZK porter users will be able to interact, let's say with Uniswap or with balancer, with curve, with all the DeFi protocols on the ZK rollup side, where the whales hold all of their liquidity very cheaply because they don't have to pay. Like the data availability is going to be amortized. So this is one very interesting flexible hybrid option.
00:20:04.484 - 00:20:29.826, Speaker D: I think to a first approximation, these are going to be some of the most interesting areas. I think there will be, in the fullness of time, other pieces that can be configured, we can talk about decentralization of the prover or centralizing of the prover. But yeah, to first approximation, I think data availability and the options around the sequencer are going to be the most interesting, because it is where you probably are able to customize the stack the deepest, at least initially.
00:20:29.938 - 00:21:22.998, Speaker A: Yeah, and I think on top of that you can just customize the various, you could put different restrictions on the stack. For example, you can say, I want to launch this chain which will only host this one application, I don't want any DeFi apps there that will clutter the sequencer space with something irrelevant. It's just a chain for this specific game. So we only deploy this one contract on this chain, and then you interact within the bounds of this contract, or you can only deploy contracts of this type. You have full freedom to shape all aspects of the experience on the chain, depending on what you need. On top of that, you can also choose different privacy options. As I said, if you have a validium, you get privacy out of the box at the expense of decentralization and full ethereum security.
00:21:22.998 - 00:22:11.794, Speaker A: But you could also build a chain that is private by default, that only allows private transactions. You deploy a privacy protocol, something like adstack, or there are multiple other different options. Espresso labs is working. One other guys, I forgot the name of the protocol, but there are multiple different protocols now in development that you can deploy, and you can say on this chain, all the transactions must be transactions from this protocol, and then you still remain in the ecosystem that shares the liquidity. So when we say hyperchains, it's not really an option. Everything you launch is by definition called hyperchain. If you build something with the ZK stack, it's basically a hyperchain.
00:22:11.794 - 00:22:43.026, Speaker A: It can be an isolated hyperchain, or it can be a hyperchain plugged into this network. And this is really interesting. This is the key, most important feature of the ZK stack. So you have to imagine it like this. You have different chains, you have Zksync era. Someone launches their own, like let's imagine Uniswap would launch their own uni chain as a separate hyperchain in the Zksync network. So it's fully separate, it has its own sequencer, it's a ZK roll up.
00:22:43.026 - 00:23:47.250, Speaker A: So it inherits security from Ethereum. Now, you have some funds in a wallet on Zksync era, and you want to interact with uniswap on its own chain. The way it will work for you from the user perspective is essentially the same as if the Uniswap protocol was deployed on Zksync era. You will go to the website, to the depth application, whatever you use, you connect your wallet, you choose transaction parameters, you click initiate, you do one click and say, like, I authorize this transaction. What will happen is the transaction will then go, will bridge from Zksync era over a hyperbridge to the uni chain, will execute, will reach the smart contract there, will execute, swap some tokens, and then it will send you the results back over a hyperbridge to Zksync era. All of that will happen asynchronously, but atomically. So all of these transactions will be scheduled and they cannot be stopped.
00:23:47.250 - 00:24:29.966, Speaker A: They will have to be like you will be able to enforce them. As long as the chains remain live, the transaction will fully come through. And if they stop, then subject to the security liveness assumptions, you will be able to process it there. But essentially for you as a user, you just wait a couple of minutes and the funds come back. And this is the experience you get today with centralized exchanges. I mean, the experience is even worse. If you want to trade on Coinbase or Kraken or binance, you first have to bridge funds there, wait ten minutes until they arrive, then you make the swap, and then you send funds back, and then you wait a couple of minutes till they arrive.
00:24:29.966 - 00:25:28.054, Speaker A: But now you have to do like three different transactions, whereas with hyperchains, it's one transaction. You don't have any trust assumptions, you don't have any additional capital requirements, and the UX is completely seamless. And the reason it works is that all the hyperchains that want to be part of this network will have to use a single breach hat on layer one. So you don't deploy a separate instance, completely separate from all the other chains. You will deploy it on a special smart contract that will keep the states and the balances for all of these chains and will offer an option for shared prover. It's going to be fully optional. So all the hyperchains at all times, whether they are l two s or l three s, you have a choice how far up the spec you want to go.
00:25:28.054 - 00:25:48.922, Speaker A: Have full sovereignty. They do not depend on each other. They do not depend on Ziki sync era. They only depend on Ethereum. So this contract, even though it's shared, it's fully independent. So if you don't want to use your shared proof with someone else, you can always generate your own proofs and you can settle them on Ethereum. This will work.
00:25:48.922 - 00:26:24.546, Speaker A: It's just going to be less efficient than if multiple chains get together and compress the proofs. And there's going to be protocol for this, how to do it easily and with high liveness. You basically just accumulate proofs, and then anytime anyone can compress them. And it's going to be very cheap, computationally, to produce this final proof that you settle on Ethereum. But if you don't like the system, you can always kind of exit. The right to exit is one of the core fundamental properties declared by the Zk credo. And we're going to honor it at all times in any conditions.
00:26:24.546 - 00:26:36.970, Speaker A: Like we will build protocols that allow you to go away with your own chain or go away from any chain if you don't like whatever happens on the chain, even if it's like mass movement and mass exit of many users.
00:26:39.550 - 00:27:30.954, Speaker B: Okay, I want to dive a little deeper on that one bit there. I think that's really exciting, that you can have two separate hyperchains that have composability between the two chains. And so I want to dive into exactly how that gets enabled. So it sounds like you have to opt into the shared prover, which is a contract that lives on ethereum l one, and then that would allow two l two hyperchains to interact. So if we think about the architecture, right, so there'll be l two s that can speak to this contract, and then each of those l two s could theoretically have l three s built on top of them. So if I was trying to transfer funds, let's just say make a transaction between two l three s that are both opted into the shared prover. Is that possible as well? Or is it only the transactions between the l two s themselves?
00:27:31.072 - 00:28:15.898, Speaker A: You can make a transaction, you can transact from any address on any hyperchain in the network, whether it's an l two l three l five, it doesn't matter to any other. And it's going to be very fast. The latency of this transaction is going to be like a few minutes. It starts with probably 15 minutes, and then it's going to go down to 1 minute and maybe even under 1 minute, because the proofs will be generated very fast, recursively. We're building a tree of recursive proofs, no matter how large your block. It's all going to be proven in parallel and will take just a few minutes with the modern GPU provost that we have.
00:28:15.984 - 00:28:40.686, Speaker D: Maybe just to kind of give some intuition about how we're thinking about this design and why we're thinking about. To your question about can two l three s interact? I would argue that for us to get to the point where we're talking about billions of users being able to interact with applications that are built on top of a system like this, built on top of a system like ethereum, we need to be able to abstract away that sort of question to a degree.
00:28:40.718 - 00:28:40.914, Speaker A: Right?
00:28:40.952 - 00:29:51.622, Speaker D: In the same sense, the obvious analogy for me is email. I don't have to worry about where, if I want to send you an email, where your email hosting situation, like how the infrastructure is configured, none of that matters, because to the user, the thing that we want to do is to be able to send information from me to you. In this example, what we're thinking about is actually how do you get to something that feels like email, but for sending value? And you can think about some future iteration of something like Ens unstoppable domains where you could imagine having an Ens like address that could speak to Dan Smith at X. And this protocol can start to provide a user experience where it doesn't matter where the thing is deployed, you can build a composable experience in between a wallet hosted on some layer five, some L2 really is kind of agnostic to the situation, because the hyper bridging infrastructure provides connectivity in a way that the user doesn't need to think about it. And to first approximation, application developers shouldn't really need to think about it, right? You're building to an interface, and the interface can look constant independent of whether it's now two or whatever configuration of the Zk stack.
00:29:51.686 - 00:30:26.760, Speaker C: Interesting. Okay, so something that you guys talked about, that's from the credo, as well as just a core value of what you guys hold is like sovereignty and the ability to exit. I get that from the perspective of the individual chain. But if I'm a user on an l three, and I want to return to the l one, and something's going on with era, how exactly can you force include a transaction to the l one? What really is the security assumption from the user of the user, or the perspective of the user? How hard would it be to actually get your assets back to layer one?
00:30:27.530 - 00:31:15.610, Speaker A: So we have to consider every chain separately, because every hyperchain will have its own set of trade offs. Like if it's a validium, for example, they could freeze the data and there is nothing you can do, but you can try to do something. You can request an exit, and then if your request is not respected, then the entire chain has to hold. For Ezksync arrow specifically, it's a first and foremost EZK roll up most accounts, and we encourage all the users who can afford it to have an account on EZK rollup. And for ZK Rollup we will have something called a mechanism called the priority queue. So you can always go on layer one and submit your transaction there. You don't have to provide or generate any zero knowledge proofs, you just submit a basically self sequence.
00:31:15.610 - 00:32:09.014, Speaker A: You sequence your own transaction there, and it is supposed to be included in the next block within some time frame, some deadline by the validators of Zksync error. If it's not included, the protocol will hold and enter the priority mode where anyone can sequence transactions like whatever is in the priority queue has to be processed, the protocol will just not work until the priority queue is emptied. And since the priority queue will have a kind of predefined sequence of transactions. It's going to be easy for anyone to generate these blocks and produce the proofs without any race conditions. Because the transaction sequence is predefined, there is no race. You know exactly what's going to go in which block. So you can build that.
00:32:09.014 - 00:33:00.114, Speaker A: And when you generate the proofs, you can do it in small chunks. And then if no one else generated the block, you just submit this block and you collect the fees that the users who are requesting transactions to exit will have to put in there. So it's kind of a game, theoretically stable system. It's not that someone needs to do selfless work to make it work, it's just like it will stop. And anyone can do the work for being compensated for this work. So the tricky part is, if you as a user, have to submit a single transaction on layer one to exit, it might be too expensive for you, because we expect layer one at some point, it might become very expensive, just like it was in the past. It might cost you like $100, $1,000 to submit a single transaction.
00:33:00.114 - 00:33:34.298, Speaker A: So we realized that this is a problem. And the solution to this is that the design of the priority queue is going to be extended so that the users can get together and submit a collective claim. So basically doing, starting sequencing transactions together. So imagine a group of users is being censored. They get together like there is a leader. Someone organizes that and says, censorship is happening. So we cannot trust this chain anymore.
00:33:34.298 - 00:34:15.466, Speaker A: And we all have a moral obligation to exit, like we, the minority, and everyone who supports us. And we believe there should be a broader movement, like more people who support the, who embrace the values of the ZK credit have to say, this is not a normal situation. No one should be centered on the chain. Even if one person is centered, we have to all exit. So they get together and someone deploys another instance, another hyperchain, which will not censor the seizures or will not behave. Actually, the censorship should be resolved at the protocol level. But let's imagine that the chain tries to change this and introduce some form of censorship.
00:34:15.466 - 00:34:57.686, Speaker A: So before this time, the users get together and say, we launch this new instance, and then we all want together to exit. So you basically start collecting many transactions together, using the front end of the other chain, saying like you as a user, you just have to sign this transaction. Then all the signatures are getting together, and you submit a big batch by you, I mean whoever is organizing this movement. And then you get a lot of users going from hyperchain a to hyperchain b, not through layer one, but through the mechanism of hyperchains, sorry, hyperbridges, which is going to be very cheap.
00:34:57.798 - 00:34:58.122, Speaker D: Great.
00:34:58.176 - 00:35:17.010, Speaker C: Okay, that's super helpful. And then Anthony, you alluded to the use of account abstraction, and that's obviously been a core focal point of Zksync era. And you also referenced in the Zkstack blog post that you released this morning, gasless call data. Could you kind of elaborate on that and what it enables in the future?
00:35:17.080 - 00:35:45.162, Speaker D: Yeah, so in terms of account abstraction, this is definitely one of the sort of key features that we would highlight when we're thinking about scale. Scale isn't just infrastructure. Scale is user experience. So yeah, for us, this is a big part of what it looks like for us to actually be successful as we imagine the future here with respect to gas's transactions. Maybe Alex is a good one for you to pick up.
00:35:45.216 - 00:36:44.138, Speaker A: The idea is with account abstraction design that we use for Zksync era, we rely on the fact that call data comes essentially for free, because in our design, we only publish the state disks define the outcomes of the transaction, the effects of this transaction on the state. So you can include any number of inputs, you can do a lot of parameters, and for these parameters, you will not have to tap into Ethereum's data availability, which is expensive. You only need to process them computationally, which is cheap because we're using very, very efficient zero knowledge proofs and very efficient GPU provers for them. From the practical perspective, they are free. So our design leverages this fact. You could put signatures that are coming from the biometric devices on your phone, for example, which are going to be much larger. You can put a lot of parameters, you can put a lot of invariants into this transaction.
00:36:44.138 - 00:37:12.594, Speaker A: You can put a lot more safety for the users because you can say, as a result of this transaction, my account has to remain like this. I only want to allow modification of this and these tokens, and I am only authorizing to spend this token up to this limit and so on. You can put all these parameters in there and the resulting transaction is going to be as cheap as a simple transfer on Ethereum.
00:37:12.642 - 00:37:26.726, Speaker D: Yeah. The way I would think about account abstraction generally is that I think of it like we've designed this or thought about this in a way where developers should have some freedom to customize their payment interface to a way that makes sense for them at scale.
00:37:26.758 - 00:37:26.906, Speaker A: Right?
00:37:26.928 - 00:38:20.410, Speaker D: So account abstraction isn't necessarily one thing, but you can think about, okay, I have a design in mind for my application, wherever happens to be. I want to subsidize, I don't know, the first ten transactions of a specific user. I want to pay their gas, or maybe I have some relationship with a dow. And for anyone who holds this specific sole world NFT, I want to make sure that transactions to this application are gasless forever. So I think of the set of tools around account abstraction, are set of tools to enable really good user experience, a set of tools for development teams to be able to customize their payment interface. And then related to what Alex was saying is the cost of these transactions, you can benefit from the implementation of state diffs such that you don't necessarily have transactions that look incredibly expensive as a function of the complexity of what developers are choosing to do with them.
00:38:20.480 - 00:38:48.078, Speaker C: So is it fair to think of this architecture as a bit like when I open my chase mobile banking app, for example, I've got a checking account, a savings account, a brokerage account, et cetera. So maybe I'd want my funds to rest on Zksync era where it has strong security guarantees, my savings account. And then if I want to use Uniswap, maybe I have an exterior account that has 5% of my value. There is that kind of the right framework, and then you're able to easily interchange between different accounts on different chains with different security assumptions.
00:38:48.174 - 00:39:30.420, Speaker D: This is typically how I would think about the split between, say the roll up account, which I would argue is basically your equivalent of your savings account, right? So the roll up account with all of the guarantees that we've spoken to, with the ability to maintain control of your assets from L1, this is essentially the highest security. So this is the account that would be more expensive to a degree to maintain this account. But it comes with security assumptions that are as strong as they could be. This is where I would argue for most users, most of your funds should be maintained. And then the way I think about the porter account is more like your checking account, right? I want to do some cheap transactions. I want to interact with the game. I want whatever it happens to be.
00:39:30.420 - 00:40:08.350, Speaker D: You don't have the full security. In the same way, there is this different approach to data availability that introduces slightly less secure situation with respect to the funds, but you benefit from that with orders of magnitude cheaper transaction fees. So you can think about your individual risk tolerance. Some people might choose not to have a wardrobe account, some people might choose not to have a roll up account. I would imagine that actually most people would have, to your point, some large majority of their activity, like day to day activity from a cheaper account, like a Porter style account, but then the savings account is the roll up account.
00:40:08.420 - 00:40:43.660, Speaker A: But to also clarify something you touched on in the question, both roll up and porter accounts can be part of the same hyperchain. So this can be the part of ZK sync error. On one single chain, you have instant seamless synchronous connectivity between them. It's not that you need to build a separate hyperchain to implement ZK. Porter. The way we think about the needs, like cool will need their own hyperchain is slightly different. You build your own hyperchain if you need to control you customize certain aspects of it.
00:40:43.660 - 00:41:48.190, Speaker A: I don't see the much need, maybe the market, the builders will decide. But the generic chains are probably less of a candidate for being a hyperchain. It's more for application specific chains where you don't want to share the sequencer with everyone else. Because if you're sharing the sequencer, you're probably just better off on a single chain, which is going to be high capacity, high throughput with roll up and porter accounts giving users different levels of security and throughput trade offs now. But like enterprise chains, gaming chains, app chains for maybe you don't want a decentralized sequencer because latency of transactions is too low, but instead you want high frequency trading, like ultra low confirmations for your transactions. Think something like DyDX. They can have their own separate chain just for this exchange.
00:41:48.190 - 00:42:24.122, Speaker A: Maybe social networks, some specific social networks that, or like, maybe even if you think of Reddit, with 500 million active daily users, they will likely need multiple hyperchains for separate subreddits, not just for the Reddit entirely. They might want to use the Reddit hyperchain and then l three s for, for all the different subreddits. So this is how we think about it. It's more for customization and application specificity and full control of what you're doing there, and potentially also for privacy for banks, enterprises and so on.
00:42:24.176 - 00:42:48.690, Speaker B: Okay, so that landscape makes a lot of sense to me. And one of the things I want to dive a little deeper on is the state of the sequencer today. So all these l two s have centralized sequencers, but there's been serious talks towards shared sequencing or the idea of decentralizing the sequencer. How do you guys think about what the next step is for decentralizing the sequencer of Zksync era and offering that to other chains to opt into?
00:42:48.760 - 00:43:41.198, Speaker D: Yeah, I mean, I can jump in with respect to what we're doing already for era and can generally speak to the plans for the, you know, you can think of as we have spoken to era is the first hyperchain in our opinion. But it's also true by definition that even in a world without hyperchains, the philosophy behind what we're doing is such that the secrets has to be decentralized. This is sort of a non negotiable piece for how we're thinking about the design for era. So this is something that we've been working on. We had an engineering team actually working on for months at this stage, and we're very close to actually having the decentralized version of the sequencer ready for public testnet. So this is something that from just talking about era and then not even talking about the generalization through the ZK stack, this is very very close to completion. This is something we'll be doing in public very soon and again critically important for us for a number of different reasons.
00:43:41.198 - 00:44:28.866, Speaker D: But thinking about liveness of the chain, you need to get to a point where the system is decentralized to hit the reliability metrics that we're looking for with respect to liveness. It's been part of the era. Roadmap wasn't obviously part of the alpha release for, I think, sensible reasons of a lot of hard problems to solve when you're building a system like this. Like we can sequence them in a sensible way, but this is very close to completion and it will be part of the ZK stack. So for people that are choosing to work with the ZK stack, they will have the option to implement a decentralized version of their system just along the lines of the way that era will work. So yeah, the engineering work is very mature at this stage. We haven't fully open sourced everything we're doing on this, but we will do very soon and people will see a decentralized version of era on testnet very very soon.
00:44:28.866 - 00:45:14.974, Speaker D: And this is one area where I think personally just sort of interested for people to think about modularization. Are people interested in building different consensus algorithms? When we think about ZK stack, I think in the fullness of time, or at least the way I think about it, it'd be nice for the community to be able to contribute modules which aren't necessarily implementing things exactly in the way that we have implemented them era, but providing some flexibility for different use cases. So we will have, I would argue, like the first version of the decentralized sequencer available for people to run on their version of the ZK stack, or obviously we'll be deploying as we decentralize era. But this is also an opportunity for innovation, creativity, more modular options to be built into the stack itself.
00:45:15.092 - 00:45:35.906, Speaker B: And so when you think about decentralizing the sequencer, what does that actually look like? Is that like creating an alternative validator set that is kind of acting similarly to something you'd see on the l one, where these validators are working together? Maybe they have something at risk or some token that's staked to kind of prove their honesty. Or how do you think about actually decentralizing the sequencer?
00:45:36.018 - 00:46:32.426, Speaker D: Yes, so the idea would be that you have a validator set at l two that are performing the role that we perform with the centralized sequencer today of ordering and processing the transactions. We have a design, like I mentioned, for what this looks like for era, and we will be talking about that a lot more in the coming months. We'll be rolling this out, and you can imagine what this looks like. The first simple version, from an engineering perspective that we might even have on Testnet, is something like a proof of authority network, where you basically say, look, we want to test the decentralized sequencer on a testnet. We're going to run n nodes, and this just doesn't require proof of stake, right? It's a testnet. We're actually more interested in testing the consensus, testing the edge cases that come with decentralizing the sequencer. Over time, as we take this to our main net, the design will mature and we'll roll more pieces in.
00:46:32.426 - 00:46:44.954, Speaker D: But yeah, we have a roadmap internally for how we're thinking about bringing this to production, and it will look like an increasingly mature and increasingly sophisticated consensus algorithm.
00:46:45.002 - 00:47:13.446, Speaker A: It's not enough for us to decentralize the sequencer. We also have to decentralize the prover, which is a bit more challenging because you need to orchestrate a lot of work and then merge the results of this work recursively in a relatively timely manner. But this is doable, and the key part of this is building the proverb in a way that can run on the consumer hardware. We actually made huge progress in this direction. We'll publish some really interesting news about this soon.
00:47:13.548 - 00:47:29.500, Speaker C: Okay, I see. And I imagine it's harder for you guys to say, but the Zksync token, if there ever is one, would be pretty integral in decentralizing the prover, the sequencer, and then also securing the data of ZK porter chains. Do I have that correct?
00:47:30.930 - 00:47:48.018, Speaker A: We will publish separate designs on this layer. There are important aspects to take into account. But in general, I can say that we don't have better mechanisms to decentralize permissionlessly other than the token at stake. So you can infer things from here.
00:47:48.184 - 00:48:27.454, Speaker B: That part is interesting to me though is last time we spoke, we had a long, long conversation on the idea of the industry arriving at a standardized proving format so that you could have composability across a larger ecosystem. So that was a couple of months ago. Now I'm curious to get your ideas around. Are we closer to arriving at a common standard or will this be kind of like we'll likely have separate ecosystems that are utilizing different proving mechanisms and therefore can't totally interact with each other. What are your thoughts around all that we will have?
00:48:27.492 - 00:49:31.230, Speaker A: So the hyperchains are built around the idea of a common standard. It's just a question of what this common standard has to be. So you have several components here. You have this shared bridge hat, this shared smart contract where hyperchains can be deployed on, and then you need for them to have certain common circuits that they trust from each other that certain actions work from correctly. So it would be a challenge to find the minimum viable protocol like minimum set of circuits that are required there. But the necessity to have this shared smart contract means that it requires you to pick an ecosystem in which you will be building your hyperscalability. You cannot do hyperscalability across multiple ecosystems.
00:49:31.230 - 00:50:18.770, Speaker A: You can trustlessly bridge between different roll ups. You can trustlessly bridge, for example, even between optimistic and ZK roll ups. That is possible, but it's not going to be seamless. If you bridge from an optimistic roll up to ZK roll up, you have to wait seven days for the native security from Ethereum. If you bridge something from one ZK roll up to another ZK roll up, not using synthetic assets, but actually like true bridging of real assets. You will have to pay to Ethereum for this transaction. You will have to pass this transaction for Ethereum actually transferring assets from one layer, one contract to another layer one contract, in which case you don't have any benefit of the scale.
00:50:18.770 - 00:50:58.670, Speaker A: You still have to pay for a single ether or ERC 20 or NFT transfer on layer one. It defeats all the purpose of scale. It's not hyperscalability. It will not give you the seamless experience with user on any chain, interacting with any protocol on any other chain. So I think we'll end up a situation where the users have to pick this ecosystems and then this is why you have to pick the ecosystem wisely. From the beginning, because it's going to be very challenging for you to change. If you build today on a stack that is incompatible with the, let's say, ZK sync ecosystem, then you cannot migrate.
00:50:58.670 - 00:51:10.500, Speaker A: You will need to abandon the old system and then build something from scratch in the hyperchain world. I hope this answers the question.
00:51:11.990 - 00:52:14.566, Speaker D: Maybe just add one other quick thought as well. I think there's some tension between the idea of reaching sort of more standardization, more commonality today, with also how quickly we're seeing innovation. So when things are moving as quickly as they are, my expectation, I think our expectation internally is that at least for the foreseeable future, there is a lot more ten x 100 x improvements to happen when it comes to the design and implementation of the proof systems. Lots of optimization that we're not ready for yet, or at least hasn't been implemented yet. So lots of optimization that's still a low hanging fruit. And also, as research continues, lots of new ideas that will, I'm sure, proliferate. So, yeah, for us, when we're thinking about standardized proving, shared proving, doing it inside the framework of the ZK stack is really compelling because you get to move these things in a way that's consistent, related, and everybody can kind of benefit from the advantages and the implementations that are done in a shared way with the open source technology.
00:52:14.668 - 00:52:50.290, Speaker C: So I want to zoom out a little bit just to get your guys'take on one question. So I feel like it's undeniable that l two s have kind of taken a page from the Cosmos playbook with the app specific stuff and interoperability between an ecosystem of chains. It's just roll apps versus app specific. But then we saw Dydx announce their commitment to the cosmos, and that should be launching in the next couple of months. So I just wanted to ask you guys, is there anything you're watching closely on that move that would potentially change your Ethereum centric thesis if you set aside your values, I guess, for decentralization and security for a moment.
00:52:50.360 - 00:53:38.500, Speaker A: So I want to start with saying that this is not a coincidence, that we're having a very similar paradigm, because the original idea of cosmos was to build the Internet of blockchains. And if you think about it, basically, blockchains themselves are just a continuation of the Internet. With blockchains, what we're trying to build is the Internet of value, extending the Internet with the ability to transfer and program value. The analogies are inevitable and they are going to be present in all ecosystems like Ethereum is the Internet of roll ups. ZK sync is going to be the network of hyperchains. From this perspective, it's understandable. It's also understandable why DyDx had to move.
00:53:38.500 - 00:54:12.566, Speaker A: The keyword here is sovereignty. They did not have sovereign, like they were not sovereign enough. In the previous ecosystem in which they were incubated, it was not fully open source. It is, to my best knowledge, still not fully open source. They did not have something like the priority queue, so you could not enforce transactions to be exited unless the validators of your network agreed to this, and so on. And they clearly needed more control and more decentralization. And they did not have anything available back then other than the cosmos chains.
00:54:12.566 - 00:55:07.526, Speaker A: Then Cosmos SDK tendermint, where you can just plug in your consensus, and it's a modular framework where you can build stuff. And for whatever reason, they were not happy with the optimistic stack alternatives that were available back then, because having been ZK killed in the first place puts you in a position where you don't like seven day delays and stuff like this. So this is why we're building the ZK stack. We want to give people an alternative that will actually work. If you compare the ZK stack to the cosmos ecosystem, basically the difference between all the similar stacks is going to be, in a way, how the bridges work. The bridges determine the properties of the ecosystem. If the bridges are trusted, they are not different from extended multi six.
00:55:07.526 - 00:55:48.570, Speaker A: So you introduce trust assumptions. You cannot bridge from one chain to the next, and then from there to the next and to the next. You can do this multiple hopes of trust, because you're going to be accumulating trust assumptions severely. It's not scalable, it's not trustless, it's not the spirit of blockchains as we know them. The decentralized toshi vision with hyperchains. The thing that makes hyperchains hyperchains is hyper bridges. This name is derived from the Internet idea of hyperlinks, which take you from any page on the Internet to any other page in exactly one click.
00:55:48.570 - 00:56:21.618, Speaker A: And zero trust assumptions. Because if the link is HTTPs, then you know for sure that you're landing on the right page. Right? Like, you don't have to think about the architecture underneath. All you need to know is it's seamless, cheap, one click and trustless. And this is what hyperbridges enable. And we've touched a little bit on the architecture, on the aspects, like how exactly this works. We encourage the listeners to actually go into the docs and read the posts.
00:56:21.618 - 00:57:00.018, Speaker A: And we did our best to expand it, and we will have. We encourage people to ask questions, and we're happy to engage and try to provide more clarity there. But with hyper bridges, you rely on math, cryptography and ethereum, and nothing else. On Ethereum is the whole set of the entire set of Ethereum validators. With cosmos chains, you rely on Cosmos validators. You have to trust some group of people. This is the key difference that determines everything else.
00:57:00.104 - 00:57:46.418, Speaker B: That's fantastic. I want to try to sum this up and tell me if this is the inaccurate way to kind of explain what the ZK stack really is. So the ZK stack gives you the ability to create a network of blockchains that are called hyperchains, and they can take the form of either an l two or an l three, depending on what the use case particularly is. And the actual design of the hyperchain can vary. You can use a validium that maybe has different security guarantees because it uses some centralized Da layer. Or you could build the opposite end of this spectrum, which would be like a pure Zk roll up that posts all of its data down to the l one. So there's like a design space within the hyperchain itself, as well as kind of where it's situated in the stack, again, being an l two or an l three.
00:57:46.418 - 00:58:01.446, Speaker B: And then all of these hyperjanes have native communication between them because of the shared prover system that enables the hyper bridges that you just spoke to. Is that like a good way to kind of sum up what the design space of the ZK stack really is?
00:58:01.548 - 00:58:04.630, Speaker A: That was an amazing summary. It's extremely accurate.
00:58:06.490 - 00:58:30.510, Speaker B: Okay, perfect. I love that. All right, so this kind of just gives you this full interoperability space to really kind of create into. And I just want to have one more question for you of what do you think is the. Have you talked to any teams that are excited to come build out their own hyperchain? And what's the leading kind of design choice? They don't have to speak to exactly who it is, but rather what they're building and why they think a hyperchain is the right solution for them.
00:58:30.580 - 00:59:11.898, Speaker D: Yeah, I can jump in. So we've got some really exciting early partners, I think, with respect to announcing specific names. I think I will leave it for them to make their own announcements, and I'm sure many will be coming soon. The choice of partners early on was not accidental. So one of the things that we wanted to do was start to sort of sample the possible landscape for different use cases. For example, in a world where you picked three different banks, probably the solutions that they would have chosen would look somewhat consistent. So we've definitely got a cross section of partners who are doing different things, maybe surprisingly, maybe not, that one of the big early use cases that people have wanted to explore was what a validium would look like.
00:59:11.898 - 01:00:02.806, Speaker D: So we want to be able to deploy an instance of the ZK stack, but for whatever reason, we want to keep some of the state private. And there are different reasons that different partners have got for wanting to make that design choice. But yeah, what we'll see in the coming months is we will see progress in public from, I think, of the order of four or five key partners that are building towards their own particular solution with the ZK stack. But definitely in terms of some of the early use cases, they want to be able to have interoperability with the broader ecosystem. They want to be able to interact with the credibly neutral platform that I think is ethereum. But for whatever reason, and there are different reasons behind this, they want to keep some of their state or have different choices with respect to data availability such that not everything is fully public. So this doesn't look consistent.
01:00:02.806 - 01:00:16.462, Speaker D: Partner by partner, they have different reasons for doing so, made different design choices. But this is one of the interesting areas that we've seen explored with the first few people that we've been sort of privately thinking through some of this before being ready to do it as publicly as we are now.
01:00:16.516 - 01:00:36.130, Speaker C: And then last question for you guys. You've already been so generous with your time, but just a real quick one. So in your blog post, you mentioned being able to use external DA layers for data availability services. Obviously. So would you lose some of the interoperability benefits if you would choose maybe like a Celestia or eigenda to post your data to as a hyperchain?
01:00:36.290 - 01:01:11.806, Speaker A: Not at just they will determine the security properties of your hyperchain. But the beauty of it is as soon as you move funds from one hyperchain to the next, the original hyperchain doesn't matter for you. This is not the case for Cosmos, but this is the case for us. Even if the original chain crashes, collapses, the data availability is not working there, you're safe because you just moved it to some ZK roll up. So, yeah, it's the choice. It's sovereign choice of each participant, does not affect anyone else.
01:01:11.908 - 01:01:28.530, Speaker C: Interesting. All right, well, thank you guys again so much for coming on and being so generous with your time. We love getting to talk to you too. Every three to six months so we'll have to do it again, but I'll toss it over to Alex. Maybe first, then Anthony we can go to you if you guys just want to share where you can learn more about ZK sync, what you're building, and maybe where to find you on Twitter.
01:01:28.610 - 01:01:46.014, Speaker A: Well, we are on Twitter under ZK sync and we publish all updates there. We encourage you guys to take a look at our code base and consider contributing or applying to join our team to help us build scalable blockchains. And thank you for having us. It was a fun conversation. Loved it.
01:01:46.052 - 01:02:05.522, Speaker D: Yeah, maybe just to add, we would love really feedback on the ZK credo comment. We've got everything open in public on GitHub now. We would love for some discussion with the community. For anybody who's interested in building or thinking through solutions for the ZK stack, don't hesitate to reach out. We'd love to chat and love to discuss more as the system volts.
01:02:05.586 - 01:02:07.880, Speaker C: Awesome. Take it easy guys. Talk to you next time.

00:01:40.255 - 00:02:25.755, Speaker A: Okay, so I guess it's 10:30. Let's start. There was one more result that I wanted to prove last class that we didn't get to, that the fact that every manifold has every point in a remaining manifold has a neighborhood which is geodesically convex. I gave the definition, I'll review it right now. And we proved the lemma, which I'll just state again without proving it again. And then as a corollary to that lemma, we'll get this result and I'll say a little bit about what it's good for, and then we're going to move on to curvature. So recall, a subset of our Riemannian manifold is called geodesically convex if and only if, whenever you have any two points in the closure of that subset, there exists a unique minimizing geodesic joining those two points and the interior of that geodesic.
00:02:25.755 - 00:02:57.709, Speaker A: That means all the points on it, except possibly for the two endpoints, is contained in S. Right? So here's a picture of S bar closure of S. Here, both points are on the boundary. Here one is, you might have no points on the boundary. The point is the only points on this geodesic that are allowed to not be in the interior of S are the endpoints. And those, of course, are at least in the closure of S. And last time we proved the following lemma, which, on the face of it, doesn't have anything to do with geodesically convex subsets.
00:02:57.709 - 00:04:29.825, Speaker A: It says, for all P and M, there exists an epsilon such that any geodesic in M that is tangent at Q to the geodesic sphere BR of P with R less than epsilon stays out of the geodesic ball BRP for some neighborhood of Q. And the picture for this was, here's the point P. This is the ball of radius, the geodesic ball of radius R centered at P and R is less than this magic number epsilon that we say exists, that we proved exists. So if you had a geodesic tangent to the geodesic sphere, then what it says is that near Q, the geodesic has to lie outside of this geodesic ball. It could come in again later, we don't know about that. But near there, it has to lie outside of it for at least some neighborhood of Q. So we proved that last time.
00:04:29.825 - 00:05:20.685, Speaker A: Now we're going to use this lemma to show that every ball has a geodesically convex neighborhood. Okay? And this is another one of those proofs in docarmo where he leaves out some details which he says are clear and they're not actually that hard. But it would have. With two more sentences you would have made it crystal clear. And without those two sentences it looks confusing. So I'm going to try to put in all the details. Corollary, for all P and M, there exists some beta positive such that the geodesic ball B beta of P is geodesically convex.
00:05:20.685 - 00:06:08.383, Speaker A: So every point lies in a neighborhood which is a geodesically convex sub open set. So I E before we prove it, I, e for all Q1. Well, I don't need to repeat it. It's exactly what I said over there. Let's see how this goes. So, first let epsilon be positive, as in the previous lemma. The previous lemma says for every point there exists some epsilon.
00:06:08.383 - 00:07:08.529, Speaker A: It depends on the point. Okay, now choose a totally normal neighborhood W of P such that the delta in the totally normal neighborhood is less than Epsilon over 2. Remember, when we prove that every point lies in a totally normal neighborhood, there was a delta associated to that totally normal neighborhood. And I showed in the course of the proof that we could make that delta smaller if we want. So if it's not already smaller than the epsilon over two, we just choose it to be smaller. And let's let beta be strictly less than delta, okay? Such that. Such that S bar, which is x p of B beta 0 closure is contained in W.
00:07:08.529 - 00:07:40.405, Speaker A: So we can do this by continuity. Right? The exponential map is continuous. W is some neighborhood of P. By choosing beta, I want beta to be less than delta, which is less than Epsilon over 2. I can choose a smaller so that the image of the closure of this is still contained inside this totally normal neighborhood. And we claim that S is geodesically convex. Convex.
00:07:40.405 - 00:08:16.231, Speaker A: Okay, so what do we need to show? We need to show that given two points in the closure of S, we need to show there gives a unique minimizing geodesic joining them and that and that that geodesic, the interior of it stays inside S. It doesn't leave S. Okay, so let's let Q1 and Q2 be an S bar which is contained in W. Since this is a totally normal neighborhood, we know that any for any two points in the totally normal neighborhood, there will exist a unique minimizing geodesic joining them. We just don't know that it lies in W. Right. Now we want to show not only does it lie in W, it actually lies.
00:08:16.231 - 00:09:03.435, Speaker A: The interior of it even lies in S. So? So we know there exists a unique minimizing, minimizing geodesic gamma from Q1 to Q2 lying in the geodesic ball of radius Delta centered at Q1. Okay, so hence with length less than delta, which is less than epsilon over two. And this is because W is a totally normal neighborhood. So let me draw a picture. This is going to be a picture inside tpm. So this is the origin.
00:09:03.435 - 00:09:39.445, Speaker A: This is the ball of radius delta. And here's the ball. This is not to scale. This is the ball of radius epsilon. Remember, delta is less than Epsilon over 2. It kind of looks right, maybe in the picture. So I have my points Q1 and Q2, Q1 and Q2 are in the closure of the ball of radius beta.
00:09:39.445 - 00:10:28.195, Speaker A: And beta is less than delta. So maybe this is this blue one is beta. And I have Q1 and Q2 are in the closure of the ball of radius beta. And I know that there exists some, there exists some geodesic joining these two. I claim this geodesic gamma lies in B epsilon of P. Okay, inside this green ball. Well, let's see.
00:10:28.195 - 00:10:46.787, Speaker A: This is what document says. This is clear. Okay, let's see why this is clear. So suppose not. Suppose it comes outside of the ball of radius epsilon. But what we can do, we can look at this is a geodesic. I mean, I'm talking about the image under the exponential map.
00:10:46.787 - 00:11:12.781, Speaker A: I'm drawing all the picture in tpm. But you should be thinking of the image under the exponential map. That's a geodesic here. And this pink thing is a geodesic. Right? And we are inside a geodesic ball here. Remember, it's a geodesic ball. Means that the image that even when we took the closure of the ball of radius epsilon, the green, the closed green ball is still in the domain where the exponential maps of diffeomorphism.
00:11:12.781 - 00:11:57.859, Speaker A: So by the local minimize the unique by the local minimizing property of geodesics. If I look at the the geodesic from here to here, the straight line from here to here is a unique minimizing geodesic between these two points. And therefore any other piecewise smooth curve joining these two points will have length at least that. So if I look at this curve here, this distance is epsilon. This distance is call this thing L. Let's call it S for my to agree with my notes. And this, this one here is L.
00:11:57.859 - 00:12:42.935, Speaker A: Okay, so what do we know? We know that epsilon is less than or equal to S plus L, right? Because that is a curve, a piecewise smooth curve joining this point and this point and they lie inside a normal neighborhood. So therefore L is at least S minus epsilon, minus S. And what do we know about S? S is less than or equal to beta, which is less than delta, which is less than epsilon over 2. So that means that minus S is bigger than minus epsilon over 2. So L is at least epsilon over 2. OK, so this purple line here is at least Epsilon over 2. I can do the same thing for this guy.
00:12:42.935 - 00:13:26.475, Speaker A: So the sum of these two pieces is at least epsilon over two. And then there could be more. So the curve has length at least epsilon, but I know it has length less than epsilon over two. So this contradicts star. Okay, so the claim is true that this geodesic, this picture can't happen, right? It has to stay inside the green ball. So let me erase the bad picture pink. So it has to look kind of like this.
00:13:26.475 - 00:15:49.345, Speaker A: Now we're almost done. So why are we done? Now we're going to use the lemma, which thankfully, miraculously, is still on the board. Okay, so gamma is contained in B epsilon P. So again, looking at this picture, there's going to be a point on this pink geodesic in TPM here, right? This is the, this is the, this is the inverse image of the geodesic under the exponential map. Okay? This is the, this is the thing, the curve in the X in the, in the, in the geodesic ball in tpm, in the ball in tbm, which gets mapped onto the geodesic by the exponential map, there's going to be a point on this pink curve of maximal distance from the origin. So there exists by the fact that the domain, there is a closed bounded interval and continuity, right by the extreme value theorem, there exists a point on the image of Gamma whose distance with respect to this inner product gp to 0p, the image of X p inverse composed Gamma, whose distance with respect to gp, whose distance to the origin is maximal, equals R is maximal and R is less than epsilon, because we know that the whole pain curve lies inside the ball, the open ball of radius epsilon. So this point may be here is on the ball of radius R, which is less than epsilon.
00:15:49.345 - 00:16:58.805, Speaker A: Okay? And the time at which this maximum occurs is somewhere inside the. Oh, there it goes, inside the domain of this closed bounded interval. So we note this maximum must occur in the interior of the domain. 0L of the geodesic occur at a time in the interior. Because why can't it occur at the endpoints? Because we know that the endpoints are in, inside the closure of the ball of radius beta. No Sorry. That's true.
00:16:58.805 - 00:18:51.917, Speaker A: So, okay, this is true. Before writing this sentence, let me say now suppose that the geodesic leaves B beta of P, okay? Then this maximum must occur at an interior point, must occur at here, because gamma of zero and gamma of L are in the closure, right? Because their distance from in here, their distance from the origin is at most is less than or equal to beta. And so their distance from the point, the length of that geodesic is. They're in the geodesic sphere, the closed geodesic sphere of radius beta. Okay? So if we come out of this geodesic sphere, it can't be at one of the end points, it has to be at an interior point. And now, but by the lemma, since R is less than epsilon, the points in a neighborhood, let's see, exists a point, let's say M, which is gamma of some T naught. Okay? So at a time, T naught.
00:18:51.917 - 00:19:59.087, Speaker A: So in the picture, this is the point M, which is gamma of T. Well, this, this is X inverse of M. I'm kind of abusing notation, writing the points and their images. The points in a neighborhood of M lie outside of B R P. And that's a contradiction, right? Because how is this point found? We were saying there's going to be some point on this pink curve which is farthest from P, okay? And then that means it's tangent, this geodesic, this pink geodesic is tangent at M to this geodesic sphere of radius R. But the lemma exactly says that when you have a geodesic which is tangent at a point to the geodesic sphere, then it has to near that point lie outside the sphere. But this was the maximal point.
00:19:59.087 - 00:20:40.265, Speaker A: So all the other points are inside the sphere. That's our contradiction. So that means that this hypothesis is false, right? Because if that was true, we would get our contradiction. And therefore the geodesic stays inside the ball. So hence gamma stays inside B beta of P, the interior of gamma. Okay, so that's the, that's the proof of the corollary. Yep.
00:20:40.265 - 00:21:28.369, Speaker A: Because I'm, I'm working inside, I'm identifying the, you know, this and its image on the exponential map. If I'm working in here, this is a vector space with our norm coming from gp. So I know what spheres are in here and what the distance is and all that. So that's a continuous, the image of the geodesic under the inverse of the exponential map. This pink curve is really XP inverse of gamma. Right? And this is a curve Joining two points lying inside this green ball, it's going to have some point on it which is maximum distance from the origin, okay? And that point is going to be tangent to the, to the sphere. Okay, so that's the end of that theorem of that corollary.
00:21:28.369 - 00:22:43.655, Speaker A: Here's an application which I'm not going to do the details of, but just so you know why this is important. So this is an application to the existence of good covers on a manifold for the computation of the check cohomology of a sheaf, right? I'm not assuming you know any of this stuff. This is just an aside. So if you have a sheaf on a manifold you want to compute its Czech cohomology, then that's defined as some kind of categorical direct limit of some computations that you can do given, given an open cover of your, of your manifold. And there's a theorem you learn when you study check homology that says if your manifold had a good cover, then if you compute the check homology for that good cover, you get the actual answer. You don't have to take any direct limit. Okay, so what's a good cover? A good cover of a manifold M is an open cover.
00:22:43.655 - 00:23:43.771, Speaker A: Let's say U alpha of M such that each U alpha is contractable. And that's a topological notion. And all finite intersections, if they're non empty, all finite intersections, u alpha 1 up to u alpha N are contracted. So the theorem from Czech homology says that if you had such a cover for your manifold and you computed the Czech cohomology, you get the actual exact answer. And so here I'll leave it as an exercise for you. Any manifold has a good cover. And you know, for us, our manifolds are always those that admit partitions of unity.
00:23:43.771 - 00:24:49.255, Speaker A: It's not true if your manifold doesn't admit partitions of unity. So we definitely need the countable basis property and the house door property, which is what gives us partitions of unity. So the proof choose any Riemannian metric G on M and you know that those exist if you, if your manifold admits partitions of unity and let U alpha be a cover, be an open cover of M by geodesically convex neighborhoods. We just proved that every point lies in geodesically convex neighborhood. So we can cover it like this. And what you need to show is first, any geodesically convex set is contractable. Let me say open set and 2.
00:24:49.255 - 00:25:53.881, Speaker A: The intersection of two or any finite number, finitely many geodesically convex open sets is geodesically convex. Hence contractable by one, intractable by one. So this part is obvious by the definition of geodesically convex, right? It says that you have two points in there. There exists a unique minimizing geodesic whose interior is contained in there. So if S1 and S2 are both geodesically convex and you take two points in the intersection, there's a geodesic joining them, a unique minimizing geodesic, and it lies in the interior of S1, and it lies in the interior of S2. So it lies in the interior of S1, intersect S2. So this is obvious, and this one's not hard, but I'm not going to do it because you really need to know what contractible means.
00:25:53.881 - 00:26:32.775, Speaker A: And I'm not assuming people know what contractible is. Plus, this is not the point of the course, right? But that's an application of this. Geodetically convex neighborhoods, as I said, I don't think we're going to actually use them in the rest of the course. The totally normal neighborhoods will be enough for our purpose. But maybe I'm wrong. I can't remember exactly everything that we need anyway, so that finishes chapter three of Dokarmo, which in some sense is the most painful in the book, because even though we're going to get to more and more deeper theorems, it's going to be somehow less. Less technical for the most part.
00:26:32.775 - 00:26:59.767, Speaker A: Now we're going to move on to chapter four, which is about curvature and is I'm going to treat this the way I treated chapters one and two, that it's a review. I know that it's not a review for everyone. Some of you have not seen it. But because it's supposed to be a second course in Riemannian geometry, I'm supposed to assume something. So I'm going to just go through all of chapter four. I hope today, in the next, you know, 55 minutes, I'm not going to prove. I'm going to prove a very few things.
00:26:59.767 - 00:27:52.455, Speaker A: Most things I'm not going to prove. So you should read chapter four on your own. It's not hard stuff. But we're going to define what is Riemann curvature, What is sectional curvature, what is Ricci curvature? What is scalar curvature? And I'll. And I'll say some interesting things about them along the way. And then the point of the rest of the course starting next week will be to relate geodesics and curvature, right? That knowing something about curvature or geodesics tells you something about the other. So curvature, okay? So remember, as always, we have a manifold with a fixed Riemannian metric on there definition given two vector fields on M.
00:27:52.455 - 00:28:45.761, Speaker A: Let's define a map R of XY which is going to go from vector fields to vector fields by. Well, I have to tell it, tell you what it does to a vector field R of XY applied to some vector field Z is going to be Nabla X of Nabla yz minus Nabla Y Nabla X Z minus Nabla of the lie bracket XY applied to Z. Okay, this looks like a very strange thing if you've never seen it before. The first thing to see. So here, this is for all Z vector fields on it. The first thing to see is because covariant differentiation is linear. This is a linear map.
00:28:45.761 - 00:29:57.555, Speaker A: That's an infinite dimensional vector space. And this is a, this is a linear operator on this infinite dimensional vector space for every fixed X and Y. Okay, so why do we define it this way? If you know what connections on bundles are, then this, you know where this comes from. But actually when it was first discovered, people didn't know about general connections and you know, they found it sort of the hard way and had to wrestle with understanding what it means. But here's a, here's a claim which is an easy exercise that you should do. For all smooth functions M and for all vector fields X, Y, Z, you can multiply X by F, that's another vector field. So you can calculate this, or you can multiply Y by F, or you can multiply Z by F and all of those things result in the F just pulling right out.
00:29:57.555 - 00:30:45.853, Speaker A: Okay, so if we multiply X, Y or Z by a smooth function, it comes right out. And, and this crucially uses, needs the third term, the one with the lie bracket. And you may not like that. The first time I saw that definition, I didn't want that lie bracket term to be there, right? Because this looks like a commutator of co brand derivatives. But the problem is that if it's just this, it's not tensorial, right? If I multiply by functions, they don't pull out. And you can see why, because if I had a function here, it does pull out of here, but then X is going to differentiate that function right here. It won't get differentiated.
00:30:45.853 - 00:31:40.013, Speaker A: So there has to be some other term involving X differentiating a function and Y being not differentiated. So this is why this is here. So that's an easy exercise. But the consequences, hence the map X Y Z goes to R of XYZ is a smooth tensor on M. Called the Riemann curvature tensor, the Riemann curvature tensor of the metric. And of course it depends on the metric because we defined it using the levitic connection and that depends on the metric. So it's a tensor.
00:31:40.013 - 00:32:31.735, Speaker A: And being a tensor just means that you can, you can pull, you can pull smooth functions out, right? It's linear over smooth functions. Why is it a 1, 3 tensor? A 1, 3 tensor is something that eats three vector fields and a covector field to give you a function. Right? Well, this eats three vector fields and what's left is a vector field. That's exactly the kind of object that wants to be fed a covector field, the one form to give you a function. So in local coordinates we can write R as R I j K l d by dxl tensor dxi tensor dxj tensor dx k. Right. It's got three subscripts and one superscript that's a 1, 3 tensor.
00:32:31.735 - 00:33:32.241, Speaker A: So what is this? This says that R L I j K D by dxl this vector field is exactly what you get by applying D by dxi, D by dxj, feeding those into R and then acting on D by dxk. So I want to make a remark here. Docarmo defines the Riemann curvature tensor to be the negative of what I did. And I think he's the only one who does that. So note, Documo defines R of XYZ with the opposite sign. And as I said, I don't. I haven't seen anyone else do that.
00:33:32.241 - 00:34:46.455, Speaker A: Okay, I'm sure other people do it, but it's not a good idea. Another comment later where I make that comment. Well, maybe I should say it here. Some authors will define this. So some authors, including me, when I teach pure math, 868 next term and last term, this would write this as R K L I J D by dxl okay, so the point is that two of the indices are playing a separate role from the other one, right? These are the two that are being fed into here. And you can see from the definition that if I interchange X and Y I get the negative, right? So R of XYZ is minus R of Y X Z. And this says that Rijkl is minus rjikl.
00:34:46.455 - 00:35:26.985, Speaker A: Ok, and so the convention of whether to put the IJ first or after. And what do we have? We really have a, a two form something that eats two tangent vectors in a skew symmetric way. And once you fed it those two tangent vectors, it wants to act on a tangent vector linearly to give you another tangent vector. So it's an endomorphism valued to two form. And so if you want to put the two form indices first, which is what we're doing in this course, it's hue in these two. If you want to define this guy to be that, that means I'm putting the two form indices at the end. And the K and the L are the indices for the operator one up and one down.
00:35:26.985 - 00:36:54.225, Speaker A: Okay, so let's work out just once and for all what the components of the Riemann curvature tensor are in terms of the metric. It's a brutal formula and very rarely are we going to need to use it, but we are occasionally going to need to use it, but it's more important for giving you a feel for how ugly this beast is. Okay, so let's compute R in local coordinates in terms of the metric. So first of all, the definition is R D by dxi, D by dxj D by dxk I'm going to simplify my life. I'm going to write D partial I to mean D by dxi, so I don't keep writing this, ok? And I'm going to write NABLA I to mean NABLA in the direction of D by dxi. These are standard abbreviations. So this is NABLA I applied to nabla J DK minus NABLA J, NABLA I DK minus nabla partial I, bracket partial j, dk.
00:36:54.225 - 00:37:41.657, Speaker A: This is just this definition where X is D by dxi, Y is D by dxj and Z is D by dxk. So now the bracket of any two coordinate vector field is zero. So this goes away. And then by the definition of the Christoffel symbols, this is NABLA I of gamma jkm vm - nabla j of gamma I km partial m. And now remember that the covariant differentiation has a Leibniz rule. So those capital gammas, there are functions for every fixed I, j and K or m j and k. This is a function times the vector field.
00:37:41.657 - 00:38:41.285, Speaker A: So when I take the covariant differentiation in the D by dxi direction, I'm going to first differentiate this function with respect to xi and do nothing to that guy. And then this guy pulls out and I differentiate, covariantly differentiate this. So that's going to be a partial I on gamma MJK times dm plus this. This guy now comes out and I have a gamma IMK decay and the same thing with I and J interchanged. And now just to simplify this, I'm going to change the M here to. What have I done? I didn't want to call these. Ok, sorry, I shouldn't have called this K, right, because I already have a K here.
00:38:41.285 - 00:39:15.475, Speaker A: These should be Ls. Anything that's not already used. And now I'm going to change these M's to L's so I can group everything together. I get partial I, gamma, L, J, K minus, partial j, gamma L I, K plus. And these are just functions. I'm going to write them in the opposite order. Im L, M, J, K minus J, M, L, M I, K.
00:39:15.475 - 00:39:48.989, Speaker A: All of this times DL. And remember, this had to be R I, J, K, L, D, L. So that says that this tensor equals this. And I mentioned to you earlier in the course that the Christoffel symbols are not components of a tensor. You can work it out explicitly and see that they're not. They don't transform the way a tensor should under change of coordinates. But also you can, you know it because you know the.
00:39:48.989 - 00:40:15.607, Speaker A: Because of the Leibniz rule, right? You can't just pull functions out of. Out of both arguments. In the covariant derivative, one of them has a differentiation in it. But nevertheless, even though Gamma is not a tensor, this combination you get from Gamma by taking some partial derivatives and some products of gammas and taking. There's a sum here over M, right? Sum over M. This is a tensor. And recall that.
00:40:15.607 - 00:41:00.855, Speaker A: How do we get the Christoffel symbols from the metric? It's 1/2 GK L D, L G. Sorry, D I G J, L plus DJ Gil minus DLGIJ. So I mentioned when we talked about this that, you know, not only do we have to differentiate the metric, we have to multiply by the inverse of the metric. So this might be linear in the first derivatives of the metric, but it's definitely non linear in the, in the zeroth derivatives of the metric. And now it's even more nonlinear because we're going to have a square of these gammas. So it's going to be quadratic in the first derivatives. It's going to be very nonlinear in the zero derivatives.
00:41:00.855 - 00:41:52.345, Speaker A: And here too you're going to have terms where you differentiate these guys. So it'll be linear in the second derivatives, but when you differentiate this, you're going to get more first derivatives. So this whole thing is something which has its linear and second derivatives. It's quadratic in first derivatives and it's extremely nonlinear in the zeroth derivatives. Okay, let me just state that for emphasis. And this is the Reason why Riemannian geometry is non trivial, right? Because the curvatures are a very nonlinear expression in the metric. So Riemann curvature is very nonlinear in the metric.
00:41:52.345 - 00:42:51.565, Speaker A: In the metric and its first two derivatives. Okay, but let's give a simple example. Let's take Rn with a Euclidean metric. Then we know that in the standard global coordinates on Rn, gij is just delta ij, and that means that the gammas are zero. And that means that the Riemann curvature is zero. Ok? And the Riemann curvature is a tensor. So I computed it in this coordinate chart and I found that it's zero at every point.
00:42:51.565 - 00:43:32.289, Speaker A: Well, that means it's zero independent of any coordinate chart. So R is a tensor. Hence R equals zero everywhere independent of coordinates. So note, even if you take this same Euclidean metric and you look at in some other coordinate chart, these will change. These will change, but this will still be zero. Right? If it turned out that I got something that was non zero, then the actual values of these functions in a different coordinate chart would be different functions. Right? But the tensor is a well defined global object.
00:43:32.289 - 00:44:50.725, Speaker A: So if we, for example, if we, if we take, if we consider the euclidean metric on R2, but in polar coordinates. So really we have to remove the origin there and remove a half array. Then gij is not equal to delta IJ and gamma kij is not zero in general, but it's still the curvature. At the end of the day, when you have the patients to calculate out, it will be zero. And it has to be, because that's a tensor. Okay, so let me make, let me give you an aside. Aside, we say that a Riemannian manifold mg is flat if it's Riemann curvature tensor vanishes.
00:44:50.725 - 00:46:01.661, Speaker A: Okay, and here's a fact which we're not going to prove because it's not the. Of this course, mg is flat if and only if it is locally isometric to Euclidean space. So this means that is, for all P and M, there exists some U containing P open and an isometry F from U together with G restricted to U to F of U, which is open open in Rn and the Euclidean metric restricted to F mu. Okay, so we know that if we have a manifold, any open subset is a manifold. We know that we can restrict a metric to that open subset. We get a Riemannian manifold. So, and you saw in the homework, hopefully you're already working on the homework.
00:46:01.661 - 00:46:37.475, Speaker A: And isometry means diffeomorphism that pulls back the metric here to the metric here. It's an equivalence in the category of riemannian manifolds and isomorphism in the category of Riemannian manifold. So it says that a manifold is flat. It's not true. You might want it to be the case that a manifold is flat if and only if it is isomorphic to Euclidean space. But that doesn't have to be true, because the curvature you can see involves derivatives of things and that only tells you local information, it doesn't tell you global information. So you could have a non trivial topology and still be locally isometric to Euclidean space.
00:46:37.475 - 00:47:55.995, Speaker A: And the standard example, if you take the Euclidean space and you quotient by a lattice by a, we take Rn and you quotient by a zn which is acting by isometries, then the quotient will be a torus will be compact and they'll still be flat. The curvature will be zero. Okay, and this is equivalent. This is equivalent to the existence in a neighborhood of any point of local coordinates x1 up to xn such that gij which is g of d by dxi, d by dxj is delta ij. Okay? It's not hard to show one direction of this the other direction. Well, you see, if I can find such coordinates, it's very easy from these formulas here. They're here, right? If I can find coordinates where G is delta ij, then this becomes zero and this becomes zero.
00:47:55.995 - 00:48:32.505, Speaker A: So that's a necessary condition, flatness. There's a necessary condition for the existence of this. The non trivial statement is if the Riemann curvature is zero, then you can find such local coordinates. Right? And that is something that we proven in pure math868 next January. Well, near the end of the term. Let me make a remark. We can always find a local orthonormal frame E1 up to EN.
00:48:32.505 - 00:50:06.335, Speaker A: So GIJ is G of EI, EJ is Delta IJ. Right? Because you just take any frame and run the gram Schmidt process on it and make a normal frame and then that's still going to be a smoothly varying family of linearly independent vector fields and the metric will be delta GI j will be delta ij. The non triviality is can you get your local orthonormal frame to be a coordinate frame? Okay, so r equals 0 if and only if there exists local orthonormal coordinate frames. That's not always possible. Okay, so let me make one more remark. Note From Rijkl is minus Rjikl we see that if n equals 1, then r equals 0 for any metric. So any Riemannian one manifold is flat and that's because you can't have a two form on a one dimensional manifold, non zero, two form.
00:50:06.335 - 00:51:05.435, Speaker A: So for those who are thinking, well, I talked about, I learned about curvature of a curve in undergraduate curves and surfaces, right? That's a different kind of curvature. That's an extrinsic curvature. Based on how you're putting that curve inside rn, it really matters how you've embedded inside rn. If you took the Euclidean metric on RN and you look at any curve in RN and you restrict the Euclidean metric to that curve, you can find local coordinates in which local coordinate, a single local coordinate for that curve, which is orthonormal. And we know that because you can get, you can reparameterize your curve by arc length. And if you've reparameterized your curve by arc length, that means you've written the metric G11 as one. Okay, so we only care about n at least two in this course, right? Because there's nothing interesting in Riemannian geometry in one dimension.
00:51:05.435 - 00:51:54.477, Speaker A: Okay, how are we doing there? We're coming along. So some more facts which I leave for you to prove. Proposition. This is called the first Bianchi identity. It says that R of x y z plus R of yz x plus R of zxy equals zero. If I cyclically permute xyz, keep them in the same order and add, I get zero. And this is an exercise, just write down the definition.
00:51:54.477 - 00:52:44.245, Speaker A: And it uses the fact that the Levy Civita connection Nabla is torsion free. So remember what that means is that Nabla x y minus Nabla Y X is X bracket Y. Okay? So in fact, if you know about more general connections, for any connection on the tangent bundle, you can define the torsion. If you have a torsion free connection, it's it. Its curvature is going to satisfy this. Bianca Dendri, there's a more general formula on the right hand side is not zero involves torsion and derivatives of torsion. So in local coordinates this says that R I j K l plus R j kil plus rki JL is zero.
00:52:44.245 - 00:53:46.067, Speaker A: Ok? Now what we can do is we can use the metric to change our 1, 3 tensor into a 0, 4 tensor. So here's the definition. R of xyz w is defined to be you calculate r of xy applied to z and then you take the inner product with W, right? This. Remember I'm using the angle brackets to mean the inner product Z. Okay? This is a smooth 04 tensor on M. Because we know already that if I put a Function in front of X, Y or Z, it comes right out, and then it'll come out of the inner product. And if I put a function in front of W, it comes out of the inner product.
00:53:46.067 - 00:55:08.835, Speaker A: So that's a smooth 04 tensor. It's something with four subscripts in local coordinates. And this is also called the Riemann curvature tensor of M. And it's not problematic because each one determines the other, right? If you know what the metric is, and you know the 1, 3 tensor or the 04 tensor, you can find the other. And that's because of course, if you know the 1, 3 tensor, you can find the 04 tensor, but also because the metric is positive definite, if you know the inner product of this guy with any W, then you know what this is. So in coordinates R I, j, k, l, downstairs is R of partial I, partial j, partial k, partial L, that's equal to G of R of di DJ and then DL and this is R I, j, k m partial M, that's a function, it can come out. So I get R I, j, k m times the inner product of partial m with partial l, which is GML.
00:55:08.835 - 00:56:25.695, Speaker A: So the, the Riemann curvature tensor with four indices downstairs is obtained by taking the 1, 3 tensor. And what we say we lower an index with the metric, we have an M upstairs, we multiply by gml. There's a sum over m here, so there's an l downstairs at the end of it. So let me make another remark here about conventions. So note, some authors define r I, j k m G m l to be R I, j, l, k, right? They'll lower the index and the lower to the front. And there's a reason for that, because when it depends on how you you write, your isomorphism and non degenerate bilinear form will give you an isomorphism between a vector space and it's dual. And the way you do that will depend on whether you lower to the left or to the right.
00:56:25.695 - 00:57:57.245, Speaker A: So this might make a lot of sense to you. If it doesn't, don't worry about it. Right? Or they might write this. Remember, if they write rkijm, if they're writing the skew part at the end and then they lower it, they might, they might lower it to the front or they might lower it afterwards. What always is true is that the skew part, the skew indices stay together and the endomorphism indices stay together. But the order in which those are written depends on conventions and which ones you write first also depends on conventions so just the moral of the story is, be careful. Anytime you read any paper or book on Riemannian geometry, the first thing you need to do is say what conventions are they using for the Riemann curvature tensor? Okay? Another fact about the curvature tensor, which I will leave for you to prove or read in the book Proposition R X Y Z inner product W is equal to minus Z R X Y W.
00:57:57.245 - 00:59:39.155, Speaker A: Okay, so this says that if I think of this for fixed X and Y, if I think of this as an operator on vector fields or tangent vectors on a, because it's a tensor, it's skew a joint. Okay? So for all P and M R P X, P Y, P, which goes from TPM with an inner product to itself is skew a joint, right? We can move it over at the cost of a minus sign. And this uses the fact that the Leviticus connection is metric compatible. Remember what that meant was that if I took G of YZ and differentiated it in the direction of a vector field, there's terms where I differentiate the Y and the z, but there's no term where I differentiate the metric. So this, this fact is true for any metric compatible connection. And in local coordinates, this says that Rijkl is minus Rijlk, right? Because the, the metric is symmetrical, right? It's an inner product. So I can write this as minus R of XY wz and you can see that that means that R I, j, K L is minus Rijlk.
00:59:39.155 - 01:01:09.585, Speaker A: So what have we seen so far? This guy, this guy is skewing the first two, it's skewing the last two. And if we cyclically permute the first three and add, we get zero. That's the Bianchi did it. There's one more which follows from all three of those. So the last proposition about the Riemann curvature tensor says that R of xyz W is equal to R of Z W xy if I move X and Y to the, if I swap the X with the Z and the Y with the W, it doesn't change. So in local coordinates, this says that R I, J K L is R K, L I J. And this uses both torsion free because it uses the Bianchi identity and metric compatible because it uses the previous proposition.
01:01:09.585 - 01:01:54.301, Speaker A: Okay, so, so really this, this symmetry is something particular to the Levita connection. And remember, the Leviticus connection is the only one we talk about in this course. Okay, so that's a crash course or a crash me telling you facts about Riemann curvature which you've either seen or haven't. Now let's move on to sectional curvature and scalar arici curvature. And scalar curvature. Yep, Yep. Yes.
01:01:54.301 - 01:02:31.537, Speaker A: So the question is about these different conventions. So because of the symmetries of the Riemann curvature Tensor, right, with the 04 tensor, the one with four indices downstairs, will differ from anyone else's by a sign. Yeah, because everyone agrees that the 2, 2. The two skew indices, there's two pairs of skew indices, those have to be written together. No one will write ILJK for this. Right, but then you're right, because of the fact that it's skewing the last two and skewing the first two, and we can swap the first two with the last two. That means if you're computing this and you don't know what convention you've got, you're going to be at least correct up to a sign.
01:02:31.537 - 01:03:17.185, Speaker A: That's true. So if all you care about is flatness, it doesn't matter. Okay, so let's let M be Riemannian and N at least two, because remember, one dimensional is uninteresting. Let P be a point and let LP be a two dimensional subspace. So you can see we need N to be at least two, otherwise there are no two dimensional subspaces if this is one dimensional. And of course, if M is two dimensional, LP has to be all of tpm. There's only one two dimensional subspace of a two dimensional vector space.
01:03:17.185 - 01:04:04.509, Speaker A: And let's let XP and YP be a basis of TPM of lp. This is a two dimensional space, so that just means these are two linearly independent vectors in lp. The section. This is a definition, the sectional curvature of this Riemannian manifold at the point P. I mean, let's let me say it this way. The sectional curvature of lp. So there's two pieces of data you need to define sectional curvature.
01:04:04.509 - 01:05:15.071, Speaker A: Once you have a Riemannian metric, you need a point and you need a two dimensional subspace of the tangent space at that point. So the sectional curvature of LP is denoted K capital K of LP and is defined to be. It's a real number and it's this real number K of LP is R of XY YX divided by XP squared YP squared minus XP inner product YP squared. Okay, so there's various remarks we have to make here. So first of all, why is this well defined? Why is the denominator not zero? So this denominator is not equal to zero because x, p, Y, P are linearly independent. So this is cauchy Schwartz. Right.
01:05:15.071 - 01:05:42.205, Speaker A: The only we know by Cauchy Schwartz this is greater than or equal to zero. And the only way it equals zero is if X is a multiple of Y or Y is a multiple of X. Right, but they're independent. So in fact this is positive. This is positive. And the next thing to ask is, well, we made a choice basis. We have to make sure this is independent of choice of basis.
01:05:42.205 - 01:06:40.137, Speaker A: So fact, this is well defined independent of the choice of basis of basis X, P, Y P of tpm. Okay. And the proof of this uses the symmetries of the Riemann curvature tensor. So yep, here I have X, Y, Y, X. This is my, this is because of the convention I'm using. I'll make a comment about that in a minute. Okay, I don't know what Doc wrote here for he write XY XY because he has the negative.
01:06:40.137 - 01:07:28.775, Speaker A: His definition of R is the negative of mine. Okay, so this is what I was going to say and I might as well say it now. So there are many disagreements about how to define the Riemann curvature tensor and how to define where to put the indices, where the lower indices or whatever. No one disagrees on what the sectional curvature should be in the sense that if you take a sphere, let's say the unit sphere in RN plus 1N sphere, that should have positive sexual curvature at every point, the same constant positive section curvature at every point. So with the convention that I gave for the Riemann curvature tensor, this has to be the sectional curvature for the sphere to come out to be positively sectionally curved. With docarma's definition, which is the negative of mine, he needs the negative of this. And you just fix that by swapping those X, Y, X, Y.
01:07:28.775 - 01:08:05.165, Speaker A: Okay, so, so how would you check that this independent of the basis? I'll let you read it in documo. But you know, what can you do? For example, you can, you can take a basis vector and scale it, right? Well, if I scale, let's say X by lambda, I'll get a lambda squared here and a lambda squared here. And I'll get two more lambdas here. So you can see it's independent of scaling for X or Y. And then you can say, well, let's say I replace Y by adding a multiple of X to it. If I replace Y by adding a multiple of X, you'll show what happens to the denominator, what happens to the numerator and they cancel out. It's independent of choice basis.
01:08:05.165 - 01:09:01.105, Speaker A: So in particular, if e1 and e2 is an orthonormal basis of lp, then k of lp is just r e1, e2, e2 e1. Right? Because for an orthonormal basis, this is 1, this is 1, this is 0. So the denominator is 1. And then I just have this and you can see if I swap the order of 1 and 2, I swap these and swap these, I get 2 minus signs, they cancel. So it doesn't depend on orientation in any way. Right? This is, does not depend. This is equal to R of E2 E1, E1, E2.
01:09:01.105 - 01:10:09.521, Speaker A: So K of LP, it doesn't depend on orientation. Okay, what else can I tell you about sectional curvature? One more thing. Two more things. So here's a fact. The sectional curvature is both determined by and determines the Riemann curvature. So they're equivalent pieces of data. So there are equivalent.
01:10:09.521 - 01:11:12.725, Speaker A: In other words, we already see from this, this formula that if you know the Riemann curvature and the metric you get, you can get all the sectional curvatures, right? But what this is saying, this fact says that if you know for every point and every two dimensional subspace of that point, what the sectional curvature is, if you know all that information, then you can get the Riemann curvature at any point for any four vectors. So that is, there exists a formula for R X, Y, Z W in terms only of sectional curvatures and the metric. Okay? And it's a horrible formula. And he doesn't even write it down. He proves sort of abstractly that this must be true. He doesn't write it down. You can write it down.
01:11:12.725 - 01:12:25.765, Speaker A: It's not really worth it. What we're going to use this for is the following. How am I doing on time? Okay, so that's a fact. So one, so let's make a definition. Mg is said to have constant sectional curvature, little K, which is a real number if and only if the sectional curvature is equal to little K. For all points in M and for all two dimensional subspaces of tpm, what we're getting here is for every point and for every choice of two dimensional subspace, we get a real number. Certainly for a fixed point, there's no reason for this real number to be independent of lp.
01:12:25.765 - 01:13:03.957, Speaker A: So you'll get a function on the space of all two dimensional subspaces of tpm. But also this can vary as you vary the point P. But if it doesn't vary for either of these choices, that's called constant sectional curvature. And one can show using the fact, the previous fact, that the sectional curvature determines the Riemannian metric. This says we know all the sectional curvatures. In this case they're a constant no matter what point, whatever two dimensional subspace we get. So there's some formula for the Riemann curvature tensor.
01:13:03.957 - 01:14:09.405, Speaker A: You can work out that if MG has constant sectional equal to K, then R of XYZ W is equal to little K times X inner product w, Y inner product z minus X inner product Z, Y inner product W. Okay, so again, in docarmo he uses the opposite sign convention for the Riemann curvature tensor. So you would have the negative of this. And let's just check what happens if I put R of X, Y, Y x in here. So I'm going to let Z equal Y and W equal X. That means I get K times X squared Y squared minus XY squared. Right.
01:14:09.405 - 01:15:08.929, Speaker A: And then to compute the sectional curvature, I have to do X, Y, Y x over that. So that tells me that K of LP is little K for all P and for all lp. Okay, so this tells me that this metric, that if I had a metric whose curvature was this, the sectional curvature would be constant equal to little K. But this fact, which I didn't prove, says that this is the only curvature tensor of a constant sectional curvature metric. And in local coordinates, what does this say in local coordinates? R I, J, K, L is little K times GIL GJK minus gik gjl. So that's nice. I defined what it means to have constant sectional curvature.
01:15:08.929 - 01:16:03.765, Speaker A: Yeah, question. Sorry, that doesn't really remind me of one of the curve listers from like Hasco. Well, you're thinking of the denominator, so the question is it reminds him of a formula from curves and surfaces, and it's because the length of the wedge product is defined to be this and this, this is also in R3, the same as the cross product. That's what's reminding you of it? Well, there is in a sense, no, not between sectional curvature, but the cross product in R3 is essentially the wedge product. Up to some identification, some isometries. And this denominator I could have written, that's the norm squared of the wedge product. But then I would have to tell you what do I mean by the norm of the wedge product? So I didn't want to do that.
01:16:03.765 - 01:16:56.413, Speaker A: Well, yeah, we're gonna, we are gonna see that. Right. One of the things we're gonna do in chapter six, which will probably come in two weeks, is to get a geometric interpretation of what sectional curvature means. So we'll eventually show a geometric interpretation of sectional curvature, but we're still a bit aways from that because it uses the exponential map which we've already talked about, but it also uses the notion of the second fundamental form of a sub manifold in a remaining manifold. So we're gonna have to wait. But it's coming. But what I was gonna say here is.
01:16:56.413 - 01:18:09.845, Speaker A: So now I, I've told you, suppose you had a Riemannian metric whose sectional curvatures were all constant, then the curvature would have to take this form. I haven't proved to you that there are any such things, but obviously there are, because if I take Euclidean space, the whole curvature is zero and so all the sectional curvatures are zero. And there is an example. So here's some examples of constant sectional curvature metrics. So first, if I take RN with the Euclidean metric, this has constant sectional curvature equal to zero. If I take the unit sphere with the round metric, this is the unit sphere in RN plus one with the metric it gets from the euclidean metric in RN +1. Restricted, this has constant sectional curvature equal to +1.
01:18:09.845 - 01:18:47.955, Speaker A: And there's something else called hyperbolic space. This is hyperbolic space has constant sectional curvature equal to minus one. Okay, I haven't told you what a hyperbolic space is. You can look it up in Dokarmore, in any Riemannian geometry text. You can do this for any dimension. Of course, when n equals 1, these are all, these are all flat. Everything is the same.
01:18:47.955 - 01:19:28.141, Speaker A: But Hn as a manifold is the interior of the ball in rn. So if you look at the points in RN whose distance from the origin is strictly less than 1, that's some open subset of RN. And there's a special metric on there which is not the Euclidean metric, and that one has constant curvature minus one. And there are other models for hyperbolic space too. You can also look at it at the upper half space with a different metric and you can show those are isometric. And there's another model which you can get by seeing it as a, what's called a space like sub manifold of Minkowski space. But you need to know some other things to understand that.
01:19:28.141 - 01:20:03.929, Speaker A: But there's a metric on a manifold which has constant section curvature minus one. Now I've shown you you can get zero one and minus one. This one's compact, those two are non compact. Let me, let me say that because it's worth, it's worth emphasizing two minutes. These are non compact, this is non compact, and this one is compact. Okay? Because one of the things we're going to prove in a few weeks is that if you had a metric with whose curvature was, was positive sectional curvature. It has to be compact.
01:20:03.929 - 01:20:43.421, Speaker A: So you're not going to be able to find a positive sectional curvature metric on a non compact manifold. That's one of the nice results we'll get to later. So I got, I showed you how to get 0, 1 or minus 1. It's very easy now to get any negative or positive constant because if you take this metric and multiply it by a positive constant, it's easy an exercise to show that the sectional curvature will scale by a positive constant. And I guess it's if you change this by lambda squared, the sectional curvature I think changes by one over lambda squared, something like that. So you can get any positive constant or negative constant sectional curvature. And in some sense this is almost all the examples.
01:20:43.421 - 01:21:11.875, Speaker A: So these are all simply connected when n is at least two. Right? These are all simply connected. And this one is when n is at least two. And we don't care about this when n is one. So you can prove that if you had constant sectional curvature and you are simply connected then up to an overall scale, you have to be one of these. That's, I think we're going to prove that in the, in the around week, week eight or nine, we'll probably try to prove that. Or 10.
01:21:11.875 - 01:21:55.303, Speaker A: And then you can say what if you're not simply connected? If you're not simply connected, if you know some topology, algebraic topology, there's a universal cover. The universal cover will have a metric on it which has also you'll be able to lift, lift the metric to the universal cover. It'll have a constant sectional curvature and therefore the universal cover will have to be one of these. And that means that up to a scale and you can always rescale so your constant sectional curvature is 0, 1 or minus 1. So that means that any constant sectional curvature metric is a quotient of one of these by a discrete group acting by isometries. And that we're probably not going to do just because it needs more topology. But I think the simply connected case classifying this we will do.
01:21:55.303 - 01:22:29.827, Speaker A: So I'm out of time. There's three more pages of notes in here on chapter four. So 10 minutes to talk about Ricci curvature and scalar curvature, which shouldn't take us more than 10 minutes. And then we're going to start chapter five about Jacobi Fields. And the point of chapter five is you say suppose you have a geodesic and suppose I move it through a one parameter family of curves that are all Geodesics. Right. What can I say about that variation? And you'll see that studying that problem will tell us something about the curvature of the manifold and vice versa.
01:22:29.827 - 01:22:44.747, Speaker A: Okay. Yep. Questions? Yep. Yes. Well, what does constant Riemann curvature mean? Right. Because it's not a function. It's not.
01:22:44.747 - 01:23:01.175, Speaker A: It doesn't give you any real numbers. Right. So in the sense that the sectional curvature determines the Riemann curvature. Right. So in these examples, the Riemann curvature is this, where k is 0 or 1 or minus 1. Right. So that's as constant as it can be.
01:23:01.175 - 01:23:32.015, Speaker A: Yes. So the comment is that the gap in two dimensions. Well, Gauss curvature only makes sense when you have a surface in a Euclidean space. Right. And that turns out to be by Gauss remarkable theorem. Equal up to a factor of two to the sectional curvature. Yeah, you can talk about constant Gauss curvature.
01:23:32.015 - 01:24:00.239, Speaker A: Well, the point is that. Okay, so when you see, on Monday, when I talk about the scalar curvature in dimension two, in dimension two, the ga. The whole point is there's only one two dimensional subspace of tpm. So the Gauss. The sectional curvature for a two dimensional manifold is an honest function. Right. You just given a point P, you get a real number because you have no choice for lp, it has to be tpm.
01:24:00.239 - 01:24:15.495, Speaker A: So the sectional curvature in two dimensions is an ordinary function and up to a factor of two, it's the section is the scalar curvature and it's equal to the Gauss curvature. Right. Higher dimensions, sectional curvature is a more complicated beast. Okay, so that's it.

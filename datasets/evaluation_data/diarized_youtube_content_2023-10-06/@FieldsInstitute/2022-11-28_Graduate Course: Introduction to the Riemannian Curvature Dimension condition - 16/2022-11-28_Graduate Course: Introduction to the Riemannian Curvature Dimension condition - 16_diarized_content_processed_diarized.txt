00:00:00.280 - 00:00:23.014, Speaker A: Discussing the proof of the splitting theorem in the context of RCD spaces. I guess before entering today, there is one last thing I want to say about RCDK Infinity and RCDK spacing about the structure of juridistics. Basically, I want to prove the brunier mechanism theorem in this setting. This will turn to be useful in a couple of situations and for what.
00:00:23.054 - 00:00:26.362, Speaker B: Concerns the splitting theorem, I recommend.
00:00:26.458 - 00:01:03.420, Speaker A: So I brought a sub. So the actual original paper is long, it's like 100 pages, and it is based on another previous paper, another 100 pages. But I wrote an overview on the proof of the splitting theorem, which is 50 pages in total. And that's. I recommend that as a first reading, there are a couple of details missing. But instead, details missing are hopefully, I mean, it should be clear that there are just technical, I mean, they are not crucial ideas that are, that are sort of omitted in this overview. All right, so, first theorem that I want to prove today.
00:01:03.420 - 00:01:17.984, Speaker A: Now, before going to the splitting, a word about autumn maps. And here is the first result. And this is a theorem that comes by a combination of efforts of myself, Rajael and Sturm.
00:01:20.104 - 00:01:23.044, Speaker B: In two and a half papers.
00:01:23.384 - 00:01:26.924, Speaker A: And the theorem is the following. So say that x is RCD.
00:01:30.224 - 00:01:30.608, Speaker B: And.
00:01:30.656 - 00:01:32.204, Speaker A: Say that you have.
00:01:34.984 - 00:01:35.776, Speaker B: Let me put.
00:01:35.800 - 00:01:46.624, Speaker A: This way, you have two measures. Let me be a bit, a bit lazy. A bit lazy in the domain of the entropy. Well, then.
00:01:48.404 - 00:01:51.784, Speaker B: Then I could actually.
00:01:52.884 - 00:01:54.744, Speaker A: Let me say absolutely continuous.
00:01:56.524 - 00:01:57.356, Speaker B: Hi.
00:01:57.540 - 00:02:10.024, Speaker A: Then there exists a unique optimal plan. Actually, I could say. I could say. Let me put this one. There exists a unique w, two geodesic.
00:02:14.754 - 00:02:18.734, Speaker B: From, you know, new to new, and.
00:02:19.354 - 00:02:21.094, Speaker A: A unique lifting of it.
00:02:28.474 - 00:02:29.098, Speaker B: Okay.
00:02:29.186 - 00:02:31.094, Speaker A: So in particular, in particular.
00:02:35.354 - 00:02:41.852, Speaker B: In particular, there exists a unique optimal plan and.
00:02:41.868 - 00:02:57.584, Speaker A: Is used by ma. Let me see if what I wrote makes sense.
00:02:57.884 - 00:02:58.944, Speaker B: That exists.
00:03:00.844 - 00:03:03.184, Speaker A: And sortie. And this is induced by a map.
00:03:12.144 - 00:03:12.912, Speaker B: Okay, what is it?
00:03:12.928 - 00:03:18.024, Speaker A: I'm saying. Let me repeat what I'm saying. So, pick an RCD space. Pick two measures, both. Absolutely. Continue.
00:03:18.184 - 00:03:19.592, Speaker B: Okay. Both.
00:03:19.648 - 00:03:31.756, Speaker A: So that marks a clear difference with respect to this statement of Brunier or McCann's theorem. We are, we are imposing something, also measure. Okay, then what happens? There exists a unique vertex, tangential. Is it connecting these two?
00:03:31.880 - 00:03:35.264, Speaker B: First of all, this vast angel d.
00:03:35.844 - 00:03:41.184, Speaker A: As any absolutely continuous curve means a lifting. But this lifting is in fact unique.
00:03:41.804 - 00:03:42.540, Speaker B: Okay?
00:03:42.652 - 00:03:44.980, Speaker A: And moreover, it is also induced by a map.
00:03:45.132 - 00:03:45.780, Speaker B: This means.
00:03:45.852 - 00:03:53.628, Speaker A: So this means. This means that there exists a map t that goes from x to geodesics.
00:03:53.676 - 00:03:56.700, Speaker B: On x such that.
00:03:56.812 - 00:04:03.298, Speaker A: Such that our lifting PI is t push forward mu is our starting measure.
00:04:03.466 - 00:04:03.874, Speaker B: Okay.
00:04:03.914 - 00:04:06.274, Speaker A: For almost every point, there exists a unique heart.
00:04:06.354 - 00:04:07.094, Speaker B: Okay.
00:04:07.754 - 00:04:23.626, Speaker A: Now, in particular, in particular, there is only one optimal plan between mu and nu, and it comes from a map. But by the way, actually, let me just take, let me just stick to the uniqueness of the listing. So what is saying? What is, what it is saying is.
00:04:23.770 - 00:04:26.366, Speaker B: Look, I want to go from my.
00:04:26.390 - 00:04:35.114, Speaker A: Absolute continuous measure mu, to my absolute continuous measure nu. And how do I do that? Well, there is only one to this.
00:04:35.734 - 00:04:40.074, Speaker B: And only what is. Okay. Makes sense.
00:04:41.934 - 00:04:51.640, Speaker A: So this is. So if you are on a romanian manifold and you forget about the absolute continuity of the target measure, this is, you know, basically Meccan's theorem.
00:04:51.742 - 00:04:52.504, Speaker B: Okay?
00:04:55.724 - 00:05:33.044, Speaker A: Now, interestingly, the proof of this result has nothing to do with the ideas of the proof of Meccan's theorem, of Brunier's theorem. It is actually more related to the two ideas by champion and de Pascale. They use the idea that I'm going to discuss in a second in the setting of RD and for cost equal distance, for a distance coming from a generic norm and to prove existence of, you know, optimum maps. And, and in fact, it has nothing to do with controversial potentials, you know, nothing to do with dual problem and whatever. So it's much, it's much more geometric proof. And the idea is the following.
00:05:33.584 - 00:05:34.324, Speaker B: Take.
00:05:47.724 - 00:06:10.544, Speaker A: So these are, these are, okay, of course. Of course. These are probability measures. We find at second moment, I forgot to mention, otherwise, there is no judiciary. So there is a judiciary connecting them, let's say, and pick a lifting. Now suppose this lifting does not come from a map. Then that exists.
00:06:10.544 - 00:06:21.244, Speaker A: Then there exists. Okay, so suppose, suppose the lifting.
00:06:26.224 - 00:06:26.584, Speaker B: Of.
00:06:26.624 - 00:06:27.644, Speaker A: The Judisic.
00:06:30.664 - 00:06:31.136, Speaker B: Does not.
00:06:31.160 - 00:06:32.084, Speaker A: Is not indeed.
00:06:44.564 - 00:06:49.452, Speaker B: Well, then by definition, there exists, you know, the set.
00:06:49.588 - 00:06:59.228, Speaker A: You know, what can I say? Let me put this way. So there exists a set e inside.
00:06:59.316 - 00:07:03.544, Speaker B: X, Borrell, with positive measure.
00:07:06.134 - 00:07:44.086, Speaker A: Such that for almost every x in e, there are, you know, the, you know, if I look, if I look, so I disintegrate PI with respect to the projection onto the first margin. And so, and I look at this set and I look at the, you know what it is, the card, I should say the diameter. I want to understand when it is that PI x. So basically, in order for PI to be induced by a map PI x, the disintegration should be a delta for almost every x.
00:07:44.270 - 00:07:45.326, Speaker B: So if it is not induced by.
00:07:45.350 - 00:07:52.190, Speaker A: Map PI, x is not a delta for most of the x. And therefore the diameter of this guy is bigger than zero.
00:07:52.262 - 00:07:56.582, Speaker B: You know, that's basically by definition of.
00:07:56.638 - 00:07:58.074, Speaker A: Not being used by a map.
00:07:59.854 - 00:08:02.582, Speaker B: All right, okay.
00:08:02.678 - 00:08:03.314, Speaker A: But.
00:08:03.694 - 00:08:12.470, Speaker B: Okay, but then, then there exists e and there exists r such that also.
00:08:12.542 - 00:08:21.074, Speaker A: This set has positive measure. There is a positive mass above a certain threshold of.
00:08:25.244 - 00:08:30.460, Speaker B: All right, now with that.
00:08:30.492 - 00:08:47.664, Speaker A: So let me, so now there is a technical point, but let me, let me say. So in particular, in particular. Now let me say up to a measurable selection argument, that is a Borel selection, I could find.
00:08:50.904 - 00:08:57.912, Speaker B: Two maps, say t one and t two.
00:08:58.048 - 00:09:08.484, Speaker A: These are both maps defined. They just only set e with values on the space of geodesics with the following properties.
00:09:09.024 - 00:09:17.366, Speaker B: So ti of x always lives in the support PI of x, you know.
00:09:17.390 - 00:09:22.114, Speaker A: For almost every x, not m, almost every x.
00:09:23.734 - 00:09:28.494, Speaker B: And second, the distance in this space.
00:09:28.534 - 00:09:33.390, Speaker A: Of jurisdictions between t one x and.
00:09:33.422 - 00:09:38.870, Speaker B: T two x is bigger than other nodes, say r over two for m.
00:09:38.902 - 00:09:40.286, Speaker A: Almost every x and of course m.
00:09:40.310 - 00:09:46.584, Speaker B: Almost f. No, you need make sense.
00:09:48.084 - 00:10:01.004, Speaker A: Just instance, pick the one, pick t one, just satisfying this. And then, you know, given that this condition is satisfied, you have room to find also t two. I'm not saying anything.
00:10:01.044 - 00:10:09.374, Speaker B: Okay. The PI X here, when you write there you go like the support of your integration.
00:10:10.474 - 00:10:18.298, Speaker A: Of course, of course. Sorry. Thanks. Absolutely. Yes, of course I have this in mind. And maybe also I said, but sure, the diameter of the support.
00:10:18.386 - 00:10:19.054, Speaker B: Thanks.
00:10:20.674 - 00:10:31.754, Speaker A: Yeah, I have the disadvantages. So for almost every x I have a measure uniquely defined the support. So this bigger than r for almost every x is a. You know the statement that makes sense?
00:10:31.834 - 00:10:33.686, Speaker B: Okay, okay.
00:10:33.710 - 00:10:39.674, Speaker A: I should verify that the amount that takes x and return diameter, the support is boring. So that, you know.
00:10:40.534 - 00:10:49.394, Speaker B: Okay. All right. Now.
00:10:54.254 - 00:10:56.234, Speaker A: Let me see, let me see if.
00:11:06.874 - 00:11:09.706, Speaker B: Let me actually look, let me.
00:11:09.730 - 00:11:41.136, Speaker A: Be a bit lazy, because I have to fix a mistake in here. So I mentioned that there exists adjudicity between mu and you, right? And actually, to be honest, this is cheating because I know on RCD or CD space, I only know the, if I start from measures in the domain of the entropy a priori. Okay, let me, so let me, so let me actually rephrase these with a much stronger. So let me say that these two measures have bounded density. Anyway. Then in the, in the final dimensional case, we can simplify that. And here is for the following.
00:11:41.136 - 00:12:02.188, Speaker A: I do this for the following reason. So let me think 1 second. Well, perhaps, perhaps. Look, let me do this for you. So let me describe what the idea. And then, and then, and then it gets. So the idea is this.
00:12:02.188 - 00:12:35.092, Speaker A: Suppose, suppose you are in a situation like this where you have a compact space, a compact set. And on this compact set you have defining two maps, and these two maps, actually, I'm already at that, so. And I have, you know, t one, t two. T one, t two. And what, and what you know, and what you know is that if you take this compact space and you follow just the path of the first map, then the entropy is, you know, sorry, not the compass space. You pick the measure restricted is composite and normalized. And then you move it according to.
00:12:35.108 - 00:12:37.716, Speaker B: The first map, say t one, what.
00:12:37.740 - 00:13:03.354, Speaker A: You obtain is something with, you know, entropy, which is convex, and the same with t two. Then, well, this is not possible, basically, unless the measure of this compact set is zero. Okay, and why is that the case? Well, because if, you know, if say that so, say so, let sigma be the measure restricted to this compact set, normalized.
00:13:06.574 - 00:13:07.470, Speaker B: Okay?
00:13:07.662 - 00:13:18.544, Speaker A: And say that. And I'll say sigma, I don't know, one t is just is, you know, et. Push forward t one. Push forward sigma.
00:13:18.704 - 00:13:19.408, Speaker B: Right?
00:13:19.576 - 00:13:21.280, Speaker A: And suppose that the amount that takes.
00:13:21.312 - 00:13:24.744, Speaker B: T and returns the entropy of sigma.
00:13:24.784 - 00:13:54.044, Speaker A: T is k convex. All right, well then, if this is the case, now let's wonder, how big is the support of sigma t? Or actually, how small can it be, the support really mean in the measure of theoretic sense. So write sigma t. Well, if it is convex, then sigma t certainly must be absolutely sigma one t must be absolutely continuous. Let's call the density rho one t.
00:13:54.904 - 00:13:59.128, Speaker B: M. So, and now I question, how.
00:13:59.176 - 00:14:07.826, Speaker A: Big is that the set, you know, where rho one t is strictly positive.
00:14:07.970 - 00:14:11.794, Speaker B: And the question, you know, of course.
00:14:11.834 - 00:14:18.514, Speaker A: Rho is an m almost everywhere defined function. So this set is defined up to negative sets, but its measures is well defined.
00:14:18.634 - 00:14:19.414, Speaker B: Okay?
00:14:20.354 - 00:14:23.574, Speaker A: And my claim is that the linen.
00:14:24.354 - 00:14:26.930, Speaker B: That this cannot be too small, because.
00:14:26.962 - 00:14:35.114, Speaker A: This line must be at least, at least the measure of where, you know, you know, actually the measure of k.
00:14:38.534 - 00:14:39.394, Speaker B: Okay?
00:14:39.814 - 00:14:50.262, Speaker A: And why is that the case? It's basically by Jensen's inequality and convexity, because if the entropy is convex, if the entropy is convex, what we know, in particular, what we know is that.
00:14:50.278 - 00:14:53.750, Speaker B: The limb soup of the entropy of.
00:14:53.822 - 00:15:24.674, Speaker A: Sigma one t is less or equal than the entropy of sigma. Because my convexity stays below, okay. And if it stays below okay, I should, I should pay a little bit of attention here, because it could be convex, but it could be that, you know, at time one, it is plus infinity. So I could be, in principle, interval, let me exclude this. So, so this limb slope of the entropy should be, you know, less regular than the entropy of sigma. But the entropy of sigma. We know how much it is, right.
00:15:24.674 - 00:15:29.618, Speaker A: We've computed already several times the entropy of the reference measure restricted to a certain set.
00:15:29.666 - 00:15:32.522, Speaker B: And that is minus log of the.
00:15:32.578 - 00:15:33.574, Speaker A: Measure of k.
00:15:36.074 - 00:15:36.978, Speaker B: Okay?
00:15:37.146 - 00:15:52.506, Speaker A: But on the other hand, by Jensen's inequality, on the other end, by Jensen's inequality, what it is that we know. So the entropy. Who is the entropy? So who is the entropy of the measure sigma one t. Well, that is.
00:15:52.530 - 00:15:59.648, Speaker B: The integral of rho, one t. Log of rho, one t. Right.
00:15:59.736 - 00:16:06.000, Speaker A: Dm. Of course, this integral, I can certainly restrict to the set where rho is positive, right.
00:16:06.152 - 00:16:10.960, Speaker B: This row. Well, then let me.
00:16:10.992 - 00:16:26.264, Speaker A: Let me normalize the integral. So, let me, you know, let me put this way, and let me multiply a measure of this set where rho is positive, what it is to the minus one. No, without minus one, multiply and divide by the mass of this set.
00:16:27.124 - 00:16:29.300, Speaker B: Okay, now.
00:16:29.452 - 00:16:40.948, Speaker A: And now I'm in position of applying Jensen's inequality. Let me rewrite this. This is measure of this set where rho is positive times the average integral of u of rho.
00:16:40.996 - 00:16:50.050, Speaker B: Rho is Rho one TDM right over this set where Rho is positive. Makes sense, right?
00:16:50.162 - 00:16:56.854, Speaker A: But. But this is greater or equal, right. By Jen says U is convex. So this is greater, equal than if I have this mass.
00:16:58.754 - 00:17:10.574, Speaker B: And then I have u of the average integral over the set of rho, of rho Dm. Right?
00:17:11.874 - 00:17:21.760, Speaker A: But this, we know how much it is, right? Uh, that's because rho integrates to one and we are averaging. So, so this is, this is, you know, uh. Uh, all.
00:17:21.792 - 00:17:23.336, Speaker B: This is what?
00:17:23.360 - 00:17:26.576, Speaker A: This is one over the mass of this set.
00:17:26.640 - 00:17:27.244, Speaker B: Right.
00:17:30.144 - 00:17:39.864, Speaker A: So this is. So this is. So this is. Again, so it's one over the mass. Log of one over the mass. And so this is minus the mass of this set.
00:17:41.324 - 00:17:41.732, Speaker B: Right.
00:17:41.788 - 00:17:43.504, Speaker A: You plug this here, and you get this.
00:17:47.924 - 00:17:55.460, Speaker B: Right. I said.
00:17:55.492 - 00:17:56.504, Speaker A: But I didn't write.
00:17:57.444 - 00:17:58.108, Speaker B: Sorry.
00:17:58.236 - 00:18:00.380, Speaker A: Mine minus because it's one from the lock.
00:18:00.412 - 00:18:02.264, Speaker B: Right. Make sense?
00:18:03.684 - 00:18:10.414, Speaker A: Okay. Okay. What's wrong? Sorry, sorry, sorry. Because it canceled.
00:18:10.454 - 00:18:11.654, Speaker B: Yes. So. Thank you.
00:18:11.694 - 00:18:17.206, Speaker A: Log of them. Only log of the mask. Only log of the mask. You plug it there, minus simplifies and log. Thanks.
00:18:17.270 - 00:18:28.558, Speaker B: Yes. Thanks. I was lucky. All right. Well, what's wrong with that? Well, with that. What is wrong is that now we.
00:18:28.566 - 00:18:29.994, Speaker A: Have a situation where.
00:18:32.114 - 00:18:37.378, Speaker B: Following the red path spreads out.
00:18:37.466 - 00:18:40.894, Speaker A: I mean, this model tells that the mass is a little bit spread out.
00:18:41.794 - 00:18:45.494, Speaker B: Following the blue path. No, what is this?
00:18:46.314 - 00:18:49.482, Speaker A: How can this be blue outside and green inside? Following the green path.
00:18:49.578 - 00:18:50.614, Speaker B: Okay, it's blue.
00:18:53.434 - 00:19:06.190, Speaker A: And, yeah, following also this other path is also, you know, spreads out the mass, but also, in some sense, as a part of the assumption, also following both together is still optimal.
00:19:06.342 - 00:19:10.314, Speaker B: Okay, so here we have a situation.
00:19:10.614 - 00:19:30.710, Speaker A: Now let's follow both paths together. And, okay, again, here is the contradiction case compact. Right? So you can find a little open set containing it. So, such that the mass of this open set is smaller than, say, three.
00:19:30.782 - 00:19:33.718, Speaker B: Halves of the mass of k if.
00:19:33.766 - 00:19:40.074, Speaker A: K has positive measure. If k is positive measure, you can find an open set u containing k.
00:19:40.974 - 00:19:46.594, Speaker B: Such that this is true. Right. Now for t, very small.
00:19:47.174 - 00:19:53.630, Speaker A: All these, all this sigma one t and sigma two t will have support. Will have support in the. In, you know, in this open set.
00:19:53.662 - 00:19:58.388, Speaker B: Uh, and for possibly taking t smaller.
00:19:58.516 - 00:20:13.012, Speaker A: They have, you know, they should be considered on a set which are, you know, of comparable size as k in particular, you know, for t very small, we should have that. The set where, you know, where rho.
00:20:13.148 - 00:20:16.684, Speaker B: One t is positive and the set.
00:20:16.764 - 00:20:19.560, Speaker A: Where rho two t is positive.
00:20:19.732 - 00:20:23.640, Speaker B: This should have intersection the mass of.
00:20:23.672 - 00:20:46.944, Speaker A: This with the positive. But this contradicts the essential non branching. You know, what is happening in here? What is this telling? This is telling that, you know, there is some point here that comes both from a red path from some guy and from a green path from some other guy. And this happens on a set of positive measures because of mass constraints.
00:20:47.354 - 00:20:48.074, Speaker B: Right?
00:20:48.234 - 00:20:49.534, Speaker A: But this is not possible.
00:20:50.194 - 00:20:51.866, Speaker B: Okay? By essential non branching.
00:20:52.010 - 00:20:54.854, Speaker A: And RCD are essential non branching because. Because we.
00:20:55.674 - 00:20:59.094, Speaker B: Okay, right.
00:20:59.434 - 00:21:19.064, Speaker A: So, in fact, in fact. Okay, now from here. Now from here is a technical, you know, it's. It's verifying that, that. That, you know, I can actually make Borel. Borel selections that when I go. When I go along these measures, the entropy remains, you know, finite.
00:21:19.064 - 00:21:21.832, Speaker A: It does not blow up. So everything makes sense, etc. Etc.
00:21:21.888 - 00:21:22.712, Speaker B: Etcetera.
00:21:22.888 - 00:21:28.364, Speaker A: And this is a matter of playing a little bit with this assumption, but nothing. Nothing conceptually, you know, too hard.
00:21:28.744 - 00:21:33.040, Speaker B: Right. All right, so this actually, this argument.
00:21:33.072 - 00:21:54.062, Speaker A: Is the argument of my paper on optimum maps. Then real soon came, well, I assume non branching, actual number ranging. And then Ayala Sturm, you know, observed, proved that, you know, RCD spaces are actually, you know, essentially non branching. And this was enough to. To make the argument conclude, okay, all.
00:21:54.078 - 00:21:58.318, Speaker B: Right, now, so you see no control.
00:21:58.366 - 00:22:04.658, Speaker A: Over its potential or nothing. It's just a non branching business. Together. Together with this. Together with this observation.
00:22:04.846 - 00:22:08.522, Speaker B: Okay, there are also, by the way.
00:22:08.538 - 00:22:28.306, Speaker A: There are workshops, let me mention. So that this sort of argument extends to the setting of MCP, MCP spaces by, as it has been observed by Cavalier Mondi. Now, what is I want to say, let me, let me, you know, I.
00:22:28.330 - 00:22:31.926, Speaker B: Want to now to improve from RCDK.
00:22:31.950 - 00:22:40.566, Speaker A: Infinity to RCDKN, we finite n. And what I gained by putting n is that I will have to impose nothing on the target measure.
00:22:40.670 - 00:22:41.182, Speaker B: Okay.
00:22:41.278 - 00:23:12.524, Speaker A: In some sense, as far as you continue to live and work in RCDK infinity, you have to put something else on the target because, you know, otherwise, you know, you have tightness problems, you have no, basically you have nothing, because RCD or CDK infinity really speaks about, you know, measures with finite entropy. But as soon as you put a finite. Nice. At the technical, you know, there are technical simplifications. And perhaps, in fact, let me, let me, let me state in the form of a proposition, something that we have.
00:23:12.564 - 00:23:15.904, Speaker B: Learned from the last lecture.
00:23:16.324 - 00:23:31.316, Speaker A: So let, sorry, perhaps, maybe I should have clarified so what it is. So this argument that I was proving, I mean, just to show that with you. So the general thing, what does it say? States that I cannot.
00:23:31.420 - 00:23:34.836, Speaker B: So who is k?
00:23:34.900 - 00:23:36.780, Speaker A: Now, k would be a compact subset.
00:23:36.812 - 00:23:38.836, Speaker B: Of e here, right?
00:23:38.980 - 00:23:49.744, Speaker A: And then, and then once I have this compass that I can forget about my initial and target measure, I just replace my initial measure with the uniform distribution on K. Right? So, and this argument proves that.
00:23:51.904 - 00:23:52.240, Speaker B: Any.
00:23:52.272 - 00:24:10.792, Speaker A: Lifting of any Jody Sic must be in fact induced by a map. And this proves the uniqueness of the lifting. And also, then the uniqueness of the. Because otherwise, if you have two different liftings, you take PI one plus PI two over two. That's a new lifting which is not induced by a map. If the two were different.
00:24:10.848 - 00:24:20.234, Speaker B: Okay. All right, so now let x be rcdkn.
00:24:20.654 - 00:24:24.830, Speaker A: And, you know, when I write n, I implicitly want to mean that n is finite.
00:24:24.902 - 00:24:25.634, Speaker B: Okay.
00:24:26.614 - 00:24:36.434, Speaker A: And, and let's, and let, you know, mu t equal rho t m. Let's say t to mu t be w to g.
00:24:48.394 - 00:24:54.762, Speaker B: Well, then n PI b.
00:24:54.858 - 00:24:56.018, Speaker A: Let me say lifting.
00:24:56.146 - 00:24:56.746, Speaker B: For the moment.
00:24:56.770 - 00:24:58.054, Speaker A: Let me say lifting.
00:25:00.434 - 00:25:03.746, Speaker B: Well, then, what we know, what we.
00:25:03.770 - 00:25:12.778, Speaker A: Know is that, is that rho t gamma t to the power one minus one over n, this is greater or equal.
00:25:12.906 - 00:25:17.842, Speaker B: Then sigma one minus t a n.
00:25:18.018 - 00:25:36.814, Speaker A: Distance gamma zero, gamma one, rho zero, gamma zero to be minus one over n plus the symmetric, you know, sigma t, etcetera. And this holds, you know, then for every t, these holds for PI almost every gamma.
00:25:40.094 - 00:25:43.822, Speaker B: Okay, where does this come from?
00:25:43.998 - 00:25:55.950, Speaker A: This comes from the local, you know, from the, we had the integrated. So the CD kn, or actually, CD star. Kn means writing this in the integrated form.
00:25:56.142 - 00:25:56.878, Speaker B: Okay.
00:25:57.006 - 00:26:17.460, Speaker A: But then after the essential non branching, you know, we can start from a lifting and restrict to a set of, you know, if this fails for a set of. Of positive measure, I restrict my, you know, lifting to that set. That would be, you know, another plan where. Where, you know, I should have the inequality, but I don't. And that's contradiction.
00:26:17.532 - 00:26:18.264, Speaker B: Okay.
00:26:20.524 - 00:26:42.214, Speaker A: If you want. If you want, I could perhaps, you know, notice that given that I assumed this measure to be absolutely continuous, if this fails, I can assume that it fails on etcetera judiciary, where both row zero and row one are bounded. So I can apply, you know, I can apply the statement above. Once these are bounded, there is only one, you know, Judisc, you know, connected.
00:26:43.434 - 00:26:47.906, Speaker B: All right. Okay.
00:26:47.970 - 00:27:11.054, Speaker A: So in particular, now let me, let me just work with the case k equals zero, which is the relevant one for the splitting, just for simplification. Anyway, I mean, all the formulas, you know, are more complicated, but they are valid even in more general case. If k equals zero, this reads as rho t gamma t is, I think.
00:27:12.274 - 00:27:13.130, Speaker B: Well, let me guess it.
00:27:13.162 - 00:27:33.334, Speaker A: So this should be rho t gamma t. This should be less or equal than one over one minus t to the power n rho zero, gamma zero. If I correctly, remember in particular, plus. Okay, could write plus one over t to the n rho one gamma one.
00:27:34.114 - 00:28:12.494, Speaker B: Do I really want this? No, I don't. No, I don't. Let me see. Make sense, what I'm seeing. Oh, where is it? Oh, yes.
00:28:12.574 - 00:28:20.908, Speaker A: Actually, actually, actually, yes. So what I get. So let me, let me actually, let me put, let me write all the steps. So, if k is equal to zero, if k is equal to zero, then.
00:28:20.956 - 00:28:24.388, Speaker B: Sigma one minus t zero.
00:28:24.476 - 00:28:31.628, Speaker A: N d is really one minus t. The k, d, n and d disappear.
00:28:31.756 - 00:28:32.544, Speaker B: Okay?
00:28:33.604 - 00:28:39.460, Speaker A: So then, you see, I get rho t to some power greater equal than one minus t, rho zero to some.
00:28:39.492 - 00:28:42.908, Speaker B: Power plus some other, some other term.
00:28:42.996 - 00:28:52.746, Speaker A: That if I want, I can draw out because it's non negative. Okay, and then, and then, and then you, you know, you raise the power minus n, and you get, then you get.
00:28:52.770 - 00:29:09.666, Speaker B: Exactly. All right. Um. Um, what else? Okay.
00:29:09.690 - 00:29:14.324, Speaker A: Yes. And now, and now comes the theorem. Yeah, I know. Corollary.
00:29:19.224 - 00:29:20.804, Speaker B: Corollary of this statement.
00:29:29.224 - 00:29:31.032, Speaker A: And notice that. So here.
00:29:31.088 - 00:29:34.160, Speaker B: So perhaps, let me emphasize this, the.
00:29:34.192 - 00:29:44.322, Speaker A: Possibility of writing this. So a bound on rho t, just in terms of row zero is really something which is finite dimensional on RCDK infinity.
00:29:44.378 - 00:29:46.290, Speaker B: You cannot have this, okay?
00:29:46.402 - 00:29:54.130, Speaker A: And this is related to the fact that basically, you know, there is, you know, the entropy blows up if the target measure becomes, becomes more singular.
00:29:54.242 - 00:29:56.930, Speaker B: Okay, so you're gonna get this, okay.
00:29:57.122 - 00:29:58.654, Speaker A: And the corollary of this.
00:30:00.594 - 00:30:01.114, Speaker B: Is that.
00:30:01.154 - 00:30:10.944, Speaker A: Look, say that you have, you know, xrcdkn. Actually, let me say RCD, zero n. But, you know, there's an analog statement with k and.
00:30:13.484 - 00:30:20.116, Speaker B: Mu, new probability measures with, say, mu less or equal than.
00:30:20.140 - 00:30:23.108, Speaker A: Some constant times n. But I assume nothing on you.
00:30:23.236 - 00:30:25.144, Speaker B: Okay, then.
00:30:27.844 - 00:30:30.172, Speaker A: There exists a Judisic, you.
00:30:30.188 - 00:30:33.864, Speaker B: Know, Judici connecting them.
00:30:40.004 - 00:30:45.660, Speaker A: With, with mu, t less or equal than one over.
00:30:45.732 - 00:30:49.064, Speaker B: One minus t to the power n actually cost.
00:30:51.044 - 00:30:59.304, Speaker A: For every t, you know, in, say, zero, one excluded. I mean, in one, this is nothing.
00:31:00.744 - 00:31:11.232, Speaker B: Okay, proof. If new also was absolutely continuous, then.
00:31:11.328 - 00:31:56.172, Speaker A: Pick the geodesic connecting them. And notice that for this judicious boundholds, and therefore, for this judiciary is bound also the root. Even then, you know, you now approximate your target measure, new with absolutely continuous ones, even with boundedness, if you want, when you let go to zero or Epsilon go to zero, this estimate, you know, remains there, that it does not depend on Epsilon. This kind of estimate is stable by weak convergence. If you have a sequence of measures new epsilon t satisfying this bound, and this converge weakly somewhere. Okay, and what about, how can you be sure that there is enough compactness? Well, recall that CDK and spaces are.
00:31:56.188 - 00:31:59.264, Speaker B: Doubling, so they are locally compact.
00:32:00.004 - 00:32:18.724, Speaker A: And so, once you're done, once you're in locally compact space, if you have, you know, if you have a sequence new epsilon that is converging w two to some limit new, you start building geodesic. These must converge, you have enough compactness to conclude.
00:32:18.884 - 00:32:28.162, Speaker B: Makes sense. All right, and now here is the theorem, which again, is by the same motors.
00:32:28.338 - 00:32:32.214, Speaker A: And it is the, if you want the finite dimensional improvement of.
00:32:34.194 - 00:32:35.986, Speaker B: This, and.
00:32:36.010 - 00:33:08.064, Speaker A: You can think both as a theorem about optimal maps, or as a theorem about the possibility of making exponentiation in metric measure space in our city spaces. So, let's say that x is RcD, okay? Let me write zero, but you can read, I mean, read k if you want. I mean, this works even for k. And let's say, let's say that you have two measures, probability measures. Actually, let me put it different. Say that you have phi.
00:33:10.004 - 00:33:10.580, Speaker B: From x.
00:33:10.612 - 00:33:22.834, Speaker A: To r, which is a contrabid potential, you know, c concave, c is, you know, c is distance squared over two, as usual, and locally lipids.
00:33:29.934 - 00:33:43.022, Speaker B: Okay, then for almost every x, there exists a unique guy p of x.
00:33:43.118 - 00:33:45.714, Speaker A: In the c sub differential of phi of x.
00:33:49.254 - 00:33:50.114, Speaker B: Okay?
00:33:54.974 - 00:34:14.014, Speaker A: And in particular, if, you know, I have two given measures. Actually, if I have, let me put this way. If you have two measures, let me say.
00:34:21.514 - 00:34:22.426, Speaker B: Well, let me put this way.
00:34:22.450 - 00:34:25.814, Speaker A: So if you have one measure which is absolutely continuous with respect to n.
00:34:26.234 - 00:34:29.730, Speaker B: Mu is in p two, then there.
00:34:29.762 - 00:34:37.994, Speaker A: Exists, let me say at most.
00:34:41.974 - 00:34:42.670, Speaker B: One.
00:34:42.822 - 00:34:44.434, Speaker A: You know, w two geodesic.
00:34:47.894 - 00:34:48.834, Speaker B: Mu, t.
00:34:49.334 - 00:35:12.373, Speaker A: With, starting from, you know, with mu zero equal mu, and for which, for which phi is a control of each potential. Also, this judisc has a union lifting.
00:35:13.633 - 00:35:16.737, Speaker B: And this Judisc, and this Judisc, you.
00:35:16.745 - 00:35:18.457, Speaker A: Know, and let me put this way.
00:35:18.505 - 00:35:36.844, Speaker B: And t four mu is the only lifting. Okay.
00:35:39.304 - 00:35:50.276, Speaker A: Let me, let me read this statement. Once we prove that for a certain class of for one potential, you have.
00:35:50.300 - 00:35:54.116, Speaker B: This statement, then it is clear, it.
00:35:54.140 - 00:36:21.284, Speaker A: Is clear that, you know, then Bruni mechanical theorem applies. You know, how do we prove Branima? Can we prove that? You know, we have a convex function. Convex functions are, you know, differentiable almost everywhere. Therefore, by the link between differential subdivision and c sub differential, you know, for almost every point, there exists a unique guy over here. And then we are done because by generic alternate of business. So once we have this, the rest follows the same sort of line of thought of the proof of green maker.
00:36:21.744 - 00:36:23.560, Speaker B: Okay. All right.
00:36:23.592 - 00:36:54.922, Speaker A: Let's do this. By the way, so, one comment. Why here I'm speaking about existence and uniqueness, while at the level of measures, I only pointed out the uniqueness and not the existence. Well, just because if it exists, so it's a ten, there's a problem. The total cost should be finite. So I did not quantify the local ipsis regularity here. So in principle, if there is a jurisdiction.
00:36:54.922 - 00:37:17.998, Speaker A: So basically, the distance between mu and the target measure would be integral of distance squared x t one x d mu x. But this in principle could be plus infinity. So in some sense, it could be the following brings us out of p two, and therefore, you know, we don't have finite distance. But as soon as this is finite, you know that the Judiasic also exists.
00:37:18.086 - 00:37:18.834, Speaker B: Okay.
00:37:21.894 - 00:37:55.290, Speaker A: So how do we prove this? Well, so first of all, so existence, existence is a consequence of the local ips regularity and local compactness of the space. So, proof, why do we have existence? So say, so what does it mean? So, I'm looking. So fix. So actually, existence there is for every x.
00:37:55.442 - 00:38:00.638, Speaker B: So say pickaxe, pick a point and pick.
00:38:00.726 - 00:38:19.686, Speaker A: So I'm looking. So I'm looking for an element in the c sub differential. So I'm looking, I'm looking for minimum of what of the mag that takes y and returns distance squared x y.
00:38:19.790 - 00:38:25.134, Speaker B: Over two minus phi of y, right?
00:38:26.714 - 00:38:36.334, Speaker A: So pick a minimizing sequence that for sure exists. So pick yn minimizing sequence.
00:38:37.754 - 00:38:48.314, Speaker B: And notice that if this yn remains on a bounded set, then bounded sets are relatively compact.
00:38:48.354 - 00:39:16.714, Speaker A: So I can pick subsequence converging somewhere. And then, and then, you know, it's clear that any limit is actually desired minimum. Okay, so I only, you know, I only have to exclude that d x, y n goes to plus infinity, right? So let me say that this is the case. And let me pick gamma n. You know, let me say constant speed judistics parameterized, you know.
00:39:19.254 - 00:39:31.950, Speaker B: From, from x to y n. Let me call zn the.
00:39:31.982 - 00:39:46.802, Speaker A: Point along digior dc, you know, at value one. Now, zn is for sure bounded sequence, right? Because actually the distance between zn and x is identically one.
00:39:46.938 - 00:39:47.694, Speaker B: Okay.
00:39:50.114 - 00:40:01.654, Speaker A: And now let me, let me notice the following. What should I notice? Yes, I should notice that. So how much it is phi of zn minus phi of x.
00:40:03.114 - 00:40:04.054, Speaker B: Let's see.
00:40:07.694 - 00:40:08.434, Speaker A: So.
00:40:10.774 - 00:40:13.914, Speaker B: I want to say that this.
00:40:15.294 - 00:40:16.542, Speaker A: Actually I want to say that the.
00:40:16.558 - 00:40:25.638, Speaker B: Limb soup of this is. Let me think.
00:40:25.686 - 00:40:27.142, Speaker A: 1 second. I want to say this is less.
00:40:27.198 - 00:40:30.598, Speaker B: Equal than the lean soup in n.
00:40:30.646 - 00:40:45.674, Speaker A: Of minus distance squared zn. So why is this true? Let me think.
00:40:56.494 - 00:41:02.654, Speaker B: So is this correct?
00:41:03.274 - 00:41:06.694, Speaker A: What is happening with yn? So yn is standing.
00:41:16.834 - 00:41:17.842, Speaker B: So let me think.
00:41:17.898 - 00:41:24.706, Speaker A: So I have this written in my notes, but it's not justified. So I have to think. So what is that is true.
00:41:24.730 - 00:41:29.010, Speaker B: So, phi c at x.
00:41:29.202 - 00:41:38.434, Speaker A: So this is equal to the limb in n of distance squared x y n divided by two minus five of.
00:41:38.474 - 00:41:45.374, Speaker B: Y n. But of course, phi. No, I don't like this.
00:41:48.834 - 00:42:04.764, Speaker A: Another phi sigon k. Sorry. Phi si concave. So given that phi c concave, I know that phi c of. So with a m of phi.
00:42:07.224 - 00:42:07.512, Speaker B: I.
00:42:07.528 - 00:42:08.880, Speaker A: Would like to put there phi of.
00:42:08.912 - 00:42:09.484, Speaker B: X.
00:42:27.924 - 00:42:29.596, Speaker A: Minus five c awareness.
00:42:29.700 - 00:42:35.504, Speaker B: This is. So this should be true. Is it true?
00:42:38.204 - 00:43:01.226, Speaker A: Look, I have to draw the picture. If I draw the picture, I understand this. So what does it mean that phi is secant cave, PI c concave means that, you know, phi is the infinity. The graph of phi is the inf of parabolas. Okay, so the fact that yn is a minimizing sequence for this guy means for phi of x means that means that, you know, phi of x is.
00:43:01.250 - 00:43:08.650, Speaker B: The info distance squared x y n.
00:43:08.722 - 00:43:10.794, Speaker A: Divided by two minus five c over.
00:43:10.834 - 00:43:11.914, Speaker B: Nice.
00:43:11.984 - 00:43:20.534, Speaker A: So the so what, the yns are vertex of parabolas, basically. So, okay, but on the other end, on the other end, PI of zn.
00:43:20.694 - 00:43:23.982, Speaker B: Is also for every n, this is.
00:43:23.998 - 00:43:29.454, Speaker A: Also less or equal than the distance squared zn, yn over two minus five.
00:43:29.494 - 00:43:33.326, Speaker B: C of y n. Right?
00:43:33.510 - 00:44:06.566, Speaker A: And now, so this is true for every n, if you want, if you want, this is so we can put it this way, plus epsilon n, if you want. The epsilon n goes to zero. Okay, and now we have done because now what I can say, look, let me take out the in soup. So what I know now is that this minus, this is less or equal than this, say minus epsilon n, actually epsilon here, model. Okay, if I want epsilon positive, I should put the minus here. So this makes a little bit more sense.
00:44:06.630 - 00:44:10.614, Speaker B: Okay, now here, zn.
00:44:10.694 - 00:44:54.274, Speaker A: Now here, the point is that zn, actually, let me, let me draw the picture. Let me, let me show you with the picture what is happening. If the vertex of the parabola goes very far from x, the steepness of the parabola at x increases. Makes sense. But if the steepness increases and goes to plus infinity, how can phi b locally reach? Okay, in practice, what is happening over here is that we actually know how much it is this distance, because the distance between, you know, the distance between zn and yn is one, is the distance between x and y n minus one.
00:44:56.854 - 00:44:57.594, Speaker B: Right?
00:44:58.094 - 00:45:07.134, Speaker A: So if I, if I, you know, I can plug this. Take the squares, the distance square simplifies. I get here something like a minus.
00:45:07.254 - 00:45:15.902, Speaker B: Distance between x and y n. Okay, plus constant, right?
00:45:15.998 - 00:45:33.160, Speaker A: For every n. But now, you see, you see that if you let n go to plus infinity, this goes, goes down to minus infinity. But phi was rearranged with local riches. How can this be literally function if you know a distance one from x? I found a point whose value is.
00:45:33.232 - 00:45:40.204, Speaker B: As little as I want. Okay, so this proof exists, right?
00:45:40.624 - 00:45:53.360, Speaker A: And what about uniqueness? Now the almost sure uniqueness comes out of this and more or less the same argument that I was giving before. So suppose, actually, let me, let me just draw the picture.
00:45:53.392 - 00:45:57.454, Speaker B: So suppose, suppose that uniqueness fails.
00:45:58.754 - 00:46:00.346, Speaker A: So uniqueness fails means that there is.
00:46:00.370 - 00:46:04.362, Speaker B: Some compact set and two maps up.
00:46:04.378 - 00:46:55.644, Speaker A: To borrell selection, whatever, such that both these maps, you know, I have the t one, okay? So I have the maps are t and s. No. And I have that t of x evaluated at time one belongs to the c sub differential of phi and the same sx equality time one belongs to the sy sub differential of higher s. Suppose we got this case now. Now what do I, do I want to exclude that this happens for a set of positive measure? So let's pick a compact set, k, where, you know, these two guys are different. And now what do I do? I start with this measure, you know, as before, and then, and then put, you know, pic t one, push forward sigma. This is a measure that can be singular.
00:46:55.644 - 00:46:58.508, Speaker A: I don't know, it's, I have no idea. It doesn't really matter.
00:46:58.636 - 00:46:59.868, Speaker B: I have some measure.
00:47:00.036 - 00:47:03.984, Speaker A: And what I know is that PI acts as a controlled potential for this mass.
00:47:04.564 - 00:47:06.260, Speaker B: And I can certainly also, you know.
00:47:06.292 - 00:47:18.464, Speaker A: Up to the state k. I can also be sure that both t and s are bounded mass. So you know, that this integral is finite. I don't go to plus infinity. It's just, you know, for uniqueness, I can pick, you know, this set as more as I want.
00:47:19.784 - 00:47:21.928, Speaker B: What I know is that there exists.
00:47:21.976 - 00:47:24.444, Speaker A: A two DC connecting them for which that bound holds.
00:47:25.744 - 00:47:26.484, Speaker B: Right?
00:47:27.264 - 00:47:37.804, Speaker A: So in particular, I have, you know, absolutely continuous, you know, evolution. And for this absolutely continuous evolution, now, now, you know, now I can apply this game.
00:47:39.784 - 00:47:40.312, Speaker B: Okay.
00:47:40.368 - 00:47:41.752, Speaker A: And I do the same for the.
00:47:41.768 - 00:47:47.644, Speaker B: Other, and then I'm done. Okay, so that lemurs and that crawler.
00:47:47.684 - 00:47:49.132, Speaker A: If you want, is what allows me.
00:47:49.148 - 00:47:53.220, Speaker B: To, you know, to not care about.
00:47:53.332 - 00:47:57.708, Speaker A: How singular is the target measure in here, okay? Because in any case, it's going to.
00:47:57.716 - 00:47:59.904, Speaker B: Be absolutely continuous, right?
00:48:00.284 - 00:48:01.500, Speaker A: Or if you wish, actually.
00:48:01.572 - 00:48:02.444, Speaker B: Yeah, yeah.
00:48:02.484 - 00:48:24.046, Speaker A: Actually, you know, I don't even, I don't even need this limb of the entropy. This argument is already telling me that if the starting measure is, you know, the reference measure, concentrate to a set, then the constant c over there is really one over the measure of that set. And this already tells me, this already tells me, you know, if the, if.
00:48:24.070 - 00:48:27.646, Speaker B: You have a measure whose density is.
00:48:27.670 - 00:48:31.314, Speaker A: Less or equal, then, you know, when t is zero, this is almost one.
00:48:31.814 - 00:48:33.006, Speaker B: So if you measure this is less.
00:48:33.030 - 00:48:43.410, Speaker A: Or equal, then one over the master of a set, in some sense, well then the set where the density is positive should be at least the mass of the set. You see what I mean?
00:48:43.562 - 00:48:50.506, Speaker B: And so, end of the proof this time we can repeat the same argument.
00:48:50.570 - 00:48:54.574, Speaker A: Thanks to the fact that this estimate above does not depend on the regularity of the target.
00:48:56.754 - 00:48:58.386, Speaker B: And now that as follows, right?
00:48:58.490 - 00:49:06.034, Speaker A: Because once, so basically, once I prove this, well, the rest, the rest is business as usual, right?
00:49:08.014 - 00:49:10.622, Speaker B: Okay, okay, that's a good point.
00:49:10.718 - 00:49:25.674, Speaker A: Where to take a break a couple of minutes and then with the, you know, with this happy, you know, opera. Let me just mention, let me just mention, well, I don't mention, I mean, let us take a break. And then, and then, and then I start showing the performance.
00:49:27.614 - 00:52:28.950, Speaker B: All right. It ha, all right, let me sip.
00:52:28.982 - 00:52:30.074, Speaker A: The coffee and then.
00:52:30.974 - 00:52:37.234, Speaker B: Can you close, please? Thank you.
00:52:41.294 - 00:52:49.714, Speaker A: Okay, what is this splitting theory? Let me state first in the, in the smooth category this theorem by Chigger and Gomorrah.
00:52:56.274 - 00:53:13.154, Speaker B: So let m be remaining manifold, smooth, complete, connected, no boundary, okay, with non.
00:53:13.194 - 00:53:59.882, Speaker A: Negative ridge and containing a line. What is a line? A line is an isometry of r into the manifold. So a map gamma from r into the manifold with the distance between gamma t and gamma s being equal to s minus t for every tns reals. So it's a curve that not only is a Judicial Incident in the romanian setting of Being Locally Minimizing, but it's really, you know, globally minimizing. So something that, you know, you know, circles around, say a cylinder will not be aligned.
00:53:59.978 - 00:54:02.666, Speaker B: Okay, okay.
00:54:02.690 - 00:54:11.530, Speaker A: Then the Manifold splits. That's what the splitting theorem, so that m is isomorphic to the product of.
00:54:11.562 - 00:54:15.370, Speaker B: Some other MAniFoLd Times R. In fact.
00:54:15.402 - 00:54:35.826, Speaker A: I can tell you more. I can tell you, I mean, they can tell you that n is of course, the remaining manifold with the rich curvature of n non negative. And the isomorphism here takes the form that x is being sent to, you know, some point p of x that, I don't know what it is, but.
00:54:35.890 - 00:54:40.222, Speaker B: Here, well, I should say, well, in.
00:54:40.238 - 00:54:42.318, Speaker A: Fact, in fact, actually, let me, in.
00:54:42.326 - 00:54:47.766, Speaker B: Fact, there exists, actually end, you know.
00:54:47.790 - 00:54:51.198, Speaker A: There exists a map b, which is called the Bozeman Function, that goes from.
00:54:51.246 - 00:54:57.302, Speaker B: M into r with such that the.
00:54:57.318 - 00:55:01.574, Speaker A: Following two things are true. So if you compute b at gamma.
00:55:01.614 - 00:55:04.404, Speaker B: T, you exactly get tired.
00:55:05.574 - 00:55:10.302, Speaker A: And the manifold n is actually, you.
00:55:10.318 - 00:55:15.798, Speaker B: Know, the primary of zero b has.
00:55:15.886 - 00:55:39.882, Speaker A: You know, b is most with zero Hessian. The hessian of b is identical, is zero. The global lips is constant. Also, the local lips is constant, is one. And, and now I know who is this. The isomorphism is basically, well, here, the.
00:55:39.898 - 00:55:46.530, Speaker B: Isomorphism sense x. I want to go from here to here, and I'm taking.
00:55:46.602 - 00:55:59.240, Speaker A: X and I'm sending it. Well, the second point is b of x. And the second point is, let me say, I don't know, it's called projection of x, where this is obtained through.
00:55:59.352 - 00:56:03.684, Speaker B: A gradient flow x.
00:56:05.504 - 00:56:28.454, Speaker A: Well, I comment this in a second. Let me write, let me describe the proof of this, and then you see why this comes wrong. I want to make a few comments on this statement. So, first of all, from the purely geometric perspective, from the purely geometric perspective, what here matters is this.
00:56:31.514 - 00:56:32.218, Speaker B: If you.
00:56:32.306 - 00:56:45.654, Speaker A: If you have a main, so having on a remaining manifold, having a function with zero, essential is, you know, already remarkable per se. Typically, you don't have this. And if you have, then locally the manifold splits.
00:56:46.274 - 00:56:49.354, Speaker B: Okay, I will comment.
00:56:49.434 - 00:57:02.936, Speaker A: I mean, I'll be a bit more precise in a second. But here, the point is that now you have a function which is zero error everywhere. So this local splitting becomes a global splitting. That's, you know, from the. So here is where the splitting happens in some sense.
00:57:03.120 - 00:57:07.404, Speaker B: Now, other comments? This is a rigidity statement.
00:57:08.264 - 00:57:27.802, Speaker A: You should think of the splitting theorem as a rigidity. It's telling that morally, if you have equality in some inequality, then something special occurs. Let me, let me explain why I'm saying this. There's an analog for the splitting, or the splitting for a positive lower reach.
00:57:27.858 - 00:57:33.734, Speaker B: Bound, which is a theorem that I guess was biomata.
00:57:35.234 - 00:58:10.454, Speaker A: Well, perhaps there are two theorems that are there. So, theorem Bonnemier's in a cool. So if, you know, if the rich curvature of some manifold is greater or more than k and k is positive, then the diameter of the manifold is bounded from above by what? By the square root by PI. Square root of k divided by no, k times n minus one.
00:58:12.194 - 00:58:16.374, Speaker B: Something like this. Thank you.
00:58:17.034 - 00:58:18.098, Speaker A: Otherwise, doesn't work.
00:58:18.146 - 00:58:19.674, Speaker B: Yes, thanks.
00:58:20.414 - 00:58:21.494, Speaker A: Yes, thank you. Of course.
00:58:21.534 - 00:58:22.038, Speaker B: Thanks.
00:58:22.166 - 00:58:34.358, Speaker A: Okay, so this is telling, so this is telling. A way of reading it is that if your manifold is more carved than the sphere, then the diameter is smaller than the one of the sphere.
00:58:34.526 - 00:58:35.382, Speaker B: Okay.
00:58:35.558 - 00:58:44.114, Speaker A: S here, sn would have reached curvature exactly equal to n minus one. So this is one. And the diameter of sn is exactly PI.
00:58:44.514 - 00:58:49.922, Speaker B: Okay, now, what happens if I have actual equality? Only as usual, when you have an.
00:58:49.938 - 00:58:51.402, Speaker A: Inequality, you can wonder, well, is this.
00:58:51.418 - 00:58:54.094, Speaker B: Inequality sharp, first of all?
00:58:54.434 - 00:58:59.602, Speaker A: And if it is, okay, maybe if it is, I could find, actually find the many polyquality.
00:58:59.618 - 00:59:03.746, Speaker B: Of course, yes, the sphere, okay, but.
00:59:03.770 - 00:59:12.234, Speaker A: Is the sphere the only case of equality? Would be interesting if this is the case, right? Because it force you, some structure out of an inequality. And this is the Obata theorem.
00:59:17.254 - 00:59:24.554, Speaker B: Equality if m is the sphere, if m is sn, right.
00:59:26.894 - 00:59:38.242, Speaker A: Okay, now let's think of this case. So let's think. Let's look at what happens when k, when you let k go to zero in this inequality. Well, first of all, for positive k, you cannot have a line because the.
00:59:38.258 - 00:59:40.894, Speaker B: Manifold is bound as simple as it is.
00:59:41.394 - 00:59:42.890, Speaker A: Of course, if you let k go.
00:59:42.922 - 00:59:44.970, Speaker B: To zero, the diameter blows up, so.
00:59:45.002 - 00:59:46.506, Speaker A: You are closer and closer to the.
00:59:46.530 - 00:59:51.818, Speaker B: Possibility of having a line now suppose that k is exactly zero and you.
00:59:51.866 - 01:00:04.668, Speaker A: Actually are in a case where you have a line. How does you know? Of course you would like to be in some sort in this situation, right? And the analog of the situation is pretty. So you are not a sphere, you're.
01:00:04.676 - 01:00:09.700, Speaker B: Not euclidean space, you are just a product, okay?
01:00:09.812 - 01:00:25.060, Speaker A: And it is clear that you cannot get more than this, because it is clear that if you, if I start, you know, from a manifold with a negative ridge, I multiply it by r, I obtain a cylinder which certainly contains a line. So it is clear that I can get more, more than this.
01:00:25.092 - 01:00:31.084, Speaker B: No? All right.
01:00:31.384 - 01:00:54.072, Speaker A: It has a long story, this theorem. So, the first version has been proved by convocon. It was in dimension two, there was just one curvature and basically said, look, if I have a surface with a negative curvature, contain a line, then it is either the plane or the cylinder. And then the danger lies first to lower sectional bound. And this is, you know, the version of the most famous one, by the way.
01:00:54.128 - 01:00:57.098, Speaker B: So why is this relevant?
01:00:57.226 - 01:01:28.594, Speaker A: Well, conceptually is relevant because it gives you some structural versatile, and it tells you that the structure of a certain n dimensional manifold is in fact totally dependent on the structure of n minus one dimensional manifold. And this is particularly, even more. I mean, this sort of statement is particularly relevant if you study rich limit or RCD spaces, because of the following idea that goes by, you know, the works of shiver and Kolding, that study rich in spaces.
01:01:29.214 - 01:01:32.118, Speaker B: So suppose you have a version of.
01:01:32.126 - 01:01:33.194, Speaker A: This for RCD.
01:01:34.894 - 01:01:35.326, Speaker B: Okay?
01:01:35.350 - 01:01:37.110, Speaker A: You can wonder, even for many people.
01:01:37.142 - 01:01:39.470, Speaker B: You can wonder, well, and the spine.
01:01:39.502 - 01:01:53.792, Speaker A: Is dandy certainly, you know, but how can you apply this? I mean, how often does it happen that you actually have space or manifold with and if I chill and cold, you notice that this happens often if.
01:01:53.808 - 01:01:55.936, Speaker B: You look at tangent spaces, right?
01:01:56.040 - 01:02:25.570, Speaker A: So pick your arbitrary rcdk kn space, k might be negative. Pick a Jody Sq on it. Pick a point along this Jodisic, not an extreme point, and blow up this space. So rescale this space by multiplying by, you know, some factor lambda the distance very big, so that you converge maybe up to subsequences. Use glom of pre compact as you converge to limit space. Well, when you dilate the space, the lower bound in some sense tends to become a lower bound by zero. So your tangent space would be RCD zero n.
01:02:25.570 - 01:02:57.340, Speaker A: Okay? And given that this point was, you know, a long a this, and the limit became a line. Okay, so for free, if you know, the splitting for either rich limit or for RCD you know, for free that tangent spaces at points, you know, along geodesics must split. Must, sorry, must split a euclidean factor. Okay, so that's already, you know, already you get an arm out of this RCD sort of business. And now what is the chiral? And Kolden said, well, now start drawing.
01:02:57.372 - 01:03:00.108, Speaker B: All possible jurisdictions and start looking.
01:03:00.156 - 01:03:20.582, Speaker A: You know, most of the points will be intermediate points of many jurisdictions. But if that is the case, those tangent spaces should split up a lot of us. But it cannot be too many for doubling sort of condition. Right? You have the measure. So basically out of these you can deduce for procure that for almost every.
01:03:20.638 - 01:03:24.686, Speaker B: X, the tangent space is euclidean and.
01:03:24.710 - 01:03:38.332, Speaker A: This is the starting point of any regularity theory. So you start then saying maybe you have charts, maybe of some regularity, et cetera, et cetera, et cetera. But in some sense, the starting of geometric measure theory is this sort of statement.
01:03:38.478 - 01:03:38.952, Speaker B: No.
01:03:39.048 - 01:03:42.160, Speaker A: For reach limits or for parse disputes.
01:03:42.272 - 01:03:44.804, Speaker B: Right. Okay.
01:03:47.504 - 01:03:53.112, Speaker A: How do one proof this splitting theorem? Well, let me, you know, outline, let me give you an outline of the.
01:03:53.128 - 01:03:53.764, Speaker B: Proof.
01:03:56.704 - 01:04:05.994, Speaker A: Without giving details. I will give more details in this instead of RC spaces. But the starting point is the, is the laplacian comparison estimate.
01:04:06.104 - 01:04:19.394, Speaker B: So it is a fact. Pick a point p in your manifold and pick as the function f f of x, one half distance squared, xp.
01:04:20.094 - 01:04:22.262, Speaker A: Distance, of course, is the riemannian distance.
01:04:22.398 - 01:04:26.214, Speaker B: This, then the Laplacian of f is.
01:04:26.254 - 01:04:27.526, Speaker A: Less or equal than the dimension of.
01:04:27.550 - 01:04:33.834, Speaker B: F. Okay, what does it mean?
01:04:33.994 - 01:04:45.442, Speaker A: Fact, I mean, this is Karabi, what does it mean? This of course. Well, I can mean many things. So as a first approximation, this function.
01:04:45.498 - 01:04:49.826, Speaker B: Out of the catalogus is moose the catalogues.
01:04:49.850 - 01:05:15.878, Speaker A: This inequality holds in the sense of, you know, I compute the Laplacian and negative. But Kaladi observed that in fact, morally, this also not modeling technically, it also works even at singularity points. Okay, Karabi may work in the sense of barriers. So basically what he said was, look for any x. For any x I can find a c two function touching the graph touching.
01:05:15.926 - 01:05:19.374, Speaker B: F from above such that, and touching.
01:05:19.414 - 01:05:24.678, Speaker A: At x so that at that point, the Laplacian of the touching function is bounded from above.
01:05:24.726 - 01:05:27.700, Speaker B: This by the maximum principle.
01:05:27.732 - 01:05:50.990, Speaker A: I can interpret this as a way of defining, you know, Laplacian upper bounds. We in RCD, we work with a different construct. We work with distributional Laplacian. But still, you know, a good point of taking out is that, you know, even in smooth setting, this inequality holds, you know, even across singularities. And you should, it is important that it works even across singularity. So that is a global sort of issue.
01:05:51.092 - 01:05:51.642, Speaker B: Okay.
01:05:51.738 - 01:05:52.866, Speaker A: By the way, another way of reading.
01:05:52.890 - 01:05:55.818, Speaker B: It is this really rich curvature business.
01:05:55.866 - 01:05:57.946, Speaker A: Of course, this comes from non negative richie.
01:05:58.050 - 01:05:58.658, Speaker B: Okay.
01:05:58.786 - 01:06:06.454, Speaker A: And you can read this as follows. On RD, the Laplacian of x squared over two is exactly equal to d, the dimension of the state.
01:06:07.794 - 01:06:08.330, Speaker B: Okay.
01:06:08.402 - 01:06:15.054, Speaker A: If the manifold is reaching greater than the one over d, then the Laplacian of the distance is less than, you know, the correspondence.
01:06:15.714 - 01:06:16.574, Speaker B: Okay?
01:06:18.014 - 01:06:26.310, Speaker A: So in particular, if we believe in chain rules, if we believe in chain rules, and we should, the Laplacian of.
01:06:26.342 - 01:06:30.814, Speaker B: The distance function from p, this is.
01:06:30.854 - 01:06:48.074, Speaker A: Bounded from above, you know, this, this should be equal to, you know, distance function Laplacian of the distance function, or. Sorry. So this should be the Laplacian of distance squared over two divided by d. And then I should have, all of this.
01:06:50.574 - 01:07:06.798, Speaker B: Is ddd minus grad d squared, I guess. Yes, right. I mean, I'm just saying that the.
01:07:06.806 - 01:07:19.414, Speaker A: Laplacian of square over two is f laplace and f minus squared. Okay, now, so this is less or equal. I have an upper bound on this, which is the dimension of the manifold.
01:07:22.874 - 01:07:23.810, Speaker B: Okay, this is positive.
01:07:23.842 - 01:07:30.294, Speaker A: Let me draw about, I mean, this is constantly equal to one. But, you know, I can neglect is a negative term divided by the distance.
01:07:33.074 - 01:07:35.938, Speaker B: Okay, so if I start, you know, the Laplace.
01:07:36.026 - 01:07:37.448, Speaker A: So if I, if I pick a.
01:07:37.456 - 01:07:40.040, Speaker B: Very far point and I look here.
01:07:40.192 - 01:07:43.992, Speaker A: At what is the Laplacian of the distance, well, it is almost less or equal than zero.
01:07:44.048 - 01:07:45.524, Speaker B: That's our take.
01:07:46.784 - 01:07:52.244, Speaker A: Now, here comes a very important geometric construction, the construction of this so called Bouseland function.
01:07:53.704 - 01:08:00.964, Speaker B: This is a purely metric bouzon function.
01:08:02.844 - 01:08:32.066, Speaker A: And this is the function b that I was speaking before. This is something that you can define as soon as you have a half line. So say that eta from zero plus infinity to m is an half line, so, satisfies the same, you know, identity that I wrote before, you know, for every smt. But this dimension negative.
01:08:32.140 - 01:08:32.754, Speaker B: Right.
01:08:33.494 - 01:08:36.390, Speaker A: Well then, the Boseman function basically gives.
01:08:36.422 - 01:08:40.102, Speaker B: A way, morally, of thinking about the.
01:08:40.158 - 01:08:45.606, Speaker A: Distance from the point at infinity of it. So I could define the function ft.
01:08:45.710 - 01:08:50.510, Speaker B: Actually, bt, let me put this way, btx. This is.
01:08:50.542 - 01:09:04.392, Speaker A: So what I would like to work with is the distance between x and dirt. And I would like to send these two plus infinity. Of course, if I do, this blows up. So I have to renormalize.
01:09:04.488 - 01:09:06.608, Speaker B: Let me subtract t, which, by the way.
01:09:06.616 - 01:09:09.856, Speaker A: So if you want, this is, or if you want the distance between eta.
01:09:09.880 - 01:09:15.176, Speaker B: Zero and eta t. Okay, let's observe.
01:09:15.200 - 01:09:32.708, Speaker A: This in this function. So for any t. So this is defined for t greater than zero. These functions are uniformly one leave sheets. And clearly they are uniformly bounded, right? Because if I, so b of x.
01:09:32.836 - 01:09:35.452, Speaker B: You know, b of x, b t.
01:09:35.468 - 01:10:03.348, Speaker A: Of x is bounded by what is bounded from above and from below. Actually, the absolute value of v of x is bounded by the distance between x and d zero. In fact, these are also. So I could already say that up to some sequences by askoriarzelada should locally, uh, uniformly converge to some limit. But in fact, I don't need any subsequence because there is monotone convergence. So bt. So there is an inequality.
01:10:03.348 - 01:10:20.924, Speaker A: Now, I mean, is either bt less or equal than B's or bt bigger or equal than B's. Let's check which one of the two is true. Um, what? So let's look at the picture. So this is Eta, this is x, and bt is like this. So this is eta t. And b t is like this. I take this and I subtract this.
01:10:20.924 - 01:10:24.324, Speaker A: This is actually, this is beta t, sorry, beta bt.
01:10:24.364 - 01:10:25.384, Speaker B: This is bt.
01:10:26.004 - 01:10:28.748, Speaker A: And what is B's? Let's say that I pick, you know.
01:10:28.796 - 01:10:32.704, Speaker B: This is Eta S b s. Is this minus this?
01:10:33.964 - 01:10:36.780, Speaker A: Okay, now you see that there is a triangle inequality going on, right?
01:10:36.812 - 01:10:41.292, Speaker B: So s b s is smaller than beta, right?
01:10:41.348 - 01:10:50.488, Speaker A: Because this yellow line by triangle inequality is less or equal than the green line plus this. But here you have equality because you.
01:10:50.496 - 01:10:54.088, Speaker B: Are a longer geodesic, so you get an m, right?
01:10:54.256 - 01:10:56.004, Speaker A: Okay, so there exists a limit.
01:10:56.904 - 01:11:01.124, Speaker B: So there exists b of x. Lim.
01:11:01.664 - 01:11:04.964, Speaker A: St goes to plus infinity of BTX.
01:11:08.624 - 01:11:09.200, Speaker B: All right?
01:11:09.272 - 01:11:30.170, Speaker A: And by that inequality, by that inequality. So this is purely metric. So I could stay this in a metric space. And in fact, I do. I mean, not, I boost my. Okay, this is purely metric. Now, if I couple this business with the laplacian bounds that I have under non negative Ricci, what I get is.
01:11:30.202 - 01:11:32.514, Speaker B: That, you know, I, I mean, by.
01:11:32.554 - 01:11:43.236, Speaker A: Passing to the limit in here, I get that the laplacian of the bosom function is less or equal than zero. I mean, I should work out how to pass limit on this sort of Laplacian, et cetera, et cetera, et cetera.
01:11:43.370 - 01:11:44.164, Speaker B: Okay?
01:11:45.224 - 01:12:01.480, Speaker A: And you see that in doing this, it is, whatever it is, it is important to be able to formulate this even on cut locus, and there's a global inequality. Because when, when the point p goes to plus infinity, I have no idea whether, you know, I'm, you know, the cut locus. If I have to exclude something or whatever.
01:12:01.592 - 01:12:04.904, Speaker B: Okay, I drink this. All right.
01:12:05.024 - 01:12:31.424, Speaker A: But now we don't have enough line. We have a line. So we have a line. So we could define, you know, we can define two boosebound functions, b plus and b minus, according to whether we are taking the limb as t goes to plus infinity of, you know, the expression of bt. Let me write. Or as the limit st goes to minus infinity of bt, in either case.
01:12:32.164 - 01:12:38.116, Speaker B: Okay, now, both these functions. Both these functions will.
01:12:38.180 - 01:12:43.796, Speaker A: Will be, you know what it is? Subharmonic Laplacian is super harmonic.
01:12:43.900 - 01:12:46.956, Speaker B: Okay, now let's have a look.
01:12:47.020 - 01:12:48.864, Speaker A: Let's have a look to what happens. So.
01:12:50.964 - 01:12:55.132, Speaker B: I claim that b plus plus.
01:12:55.228 - 01:13:01.024, Speaker A: B minus, at any point, gamma t, it is zero.
01:13:02.864 - 01:13:04.244, Speaker B: And I guess.
01:13:04.984 - 01:13:11.288, Speaker A: I guess this should be clear, right? Pick. Or if you want, just if you want, just if you want just a gamma z.
01:13:11.456 - 01:13:12.192, Speaker B: Okay.
01:13:12.328 - 01:13:15.444, Speaker A: Who is b plus a gamma zero? Well, b plus a gamma zero is.
01:13:15.824 - 01:13:18.080, Speaker B: The limit of bt.
01:13:18.152 - 01:13:25.364, Speaker A: In gamma zero, bt, gamma zero is. I take the distance from Gamma T, and I subtract the distance from gamma zero. So this is zero. And the same for the vice versa.
01:13:25.904 - 01:13:26.644, Speaker B: Right?
01:13:29.084 - 01:13:50.804, Speaker A: And I also claim that there is a sign over, you know, what it is, b plus plus b minus over the whole manifold. And let's see what this sign is. So, I claim that this is, you know, always, you know, on the manifold. And why is that the case? Well, let's look again at the picture. So I have. So image, actually, let me draw the picture here. So I have gamma.
01:13:50.804 - 01:14:12.930, Speaker A: This is gamma zero. Well, sorry, gamma zero. How do I compute BT at some point? BT at some point, you know, I have gamma t here. And I do this minus this. How do I compute B minus t? Let's say that this is gamma minus t. I do this minus this. But this guy is a juridic.
01:14:12.930 - 01:14:17.050, Speaker A: Now, here I use the fact that gamma is really a line. So the distance between these two guys.
01:14:17.082 - 01:14:19.234, Speaker B: Is really too tight.
01:14:19.304 - 01:14:27.234, Speaker A: So if I add this up, I'm really adding, you know, this distance plus this distance minus this distance. So by triangular, this is greater equivalent.
01:14:28.854 - 01:14:29.714, Speaker B: Okay?
01:14:31.854 - 01:14:37.926, Speaker A: But now, here the strong maximum principle comes into play. Now, here is an essential part for the rigidity.
01:14:38.070 - 01:14:41.582, Speaker B: And the rigidity is, you know, the.
01:14:41.598 - 01:14:46.634, Speaker A: Laplacian of the bosom on both above and below is greater equal than zero. So the Laplacian of the sun.
01:14:50.074 - 01:14:50.410, Speaker B: Is.
01:14:50.442 - 01:14:51.614, Speaker A: Less or even zero.
01:14:52.834 - 01:14:56.322, Speaker B: Okay, now we have a function.
01:14:56.498 - 01:15:08.874, Speaker A: Define. Okay, I don't know how small it is. It's at least one lipschitz, okay? Such that. But it's continuous. In particular, the Laplacian is less or equal than zero. The Laplacian less equal than zero means morally like this.
01:15:08.954 - 01:15:14.642, Speaker B: Okay? It is always non negative, but it.
01:15:14.658 - 01:15:15.450, Speaker A: Is zero in some point.
01:15:15.482 - 01:15:19.214, Speaker B: So this guy has a minimum on the manifold.
01:15:20.274 - 01:15:25.014, Speaker A: By the strong maximum principle, this can only occur if this guy is constant.
01:15:26.634 - 01:15:28.054, Speaker B: Does it make any sense?
01:15:29.074 - 01:15:40.682, Speaker A: Okay, but if this guy is constant, this is the sum of two functions that were both of which were subharmonic. So this means that b, well, b plus must be equal to minus b minus.
01:15:40.738 - 01:15:40.912, Speaker B: So.
01:15:40.938 - 01:15:43.544, Speaker A: So b class is harmonic.
01:15:45.884 - 01:16:01.584, Speaker B: You know? Right.
01:16:01.884 - 01:16:04.464, Speaker A: And now it's harmonic, so it moves.
01:16:05.244 - 01:16:06.104, Speaker B: Okay.
01:16:06.704 - 01:16:15.564, Speaker A: Okay, now we have a Laplacian which is equal to zero. But I claim that you can, you can arrive to Hessian equal to zero, which of course, is a way stronger information.
01:16:15.944 - 01:16:18.536, Speaker B: Okay, how do we pass from an.
01:16:18.560 - 01:16:28.072, Speaker A: Information from about the Laplacian to an information about the Hessian? Well, in lower reach bound, there's only one way of doing this. It's always the same. It's boca equation.
01:16:28.208 - 01:16:29.592, Speaker B: Okay, let's have a look.
01:16:29.608 - 01:16:52.474, Speaker A: To bokeh in equation, the bokeh inequality. Actually, let me write down the boca identity. And the bokeh identity does the following tells that for any f smooth the Laplacian wide, this is equal to the.
01:16:52.514 - 01:16:55.626, Speaker B: Hessian of f squared, the Hilbert Schmidt.
01:16:55.650 - 01:17:01.854, Speaker A: Norm plus grad f grad laplace, and f plus the rich curvature in direction grad f.
01:17:05.084 - 01:17:07.708, Speaker B: Okay, now let's have a.
01:17:07.716 - 01:17:11.180, Speaker A: Look at what happens with our, with our Bozeman function. So our booze function.
01:17:11.212 - 01:17:17.028, Speaker B: So let's pick fb if you want f equal b. Well, then we just proved that the.
01:17:17.036 - 01:17:48.440, Speaker A: Laplacian of b is zero. And okay, I did not prove, but I guess maybe you can believe me if I say that the gradient of b is identically one. You think about the picture. This is really increases as I move toward the direction of the point that infinite. Well, but then grabby square is identically zero. So the right hand side f zero. And this should be equal to the.
01:17:48.472 - 01:17:52.600, Speaker B: Hessian of b squared plus.
01:17:52.672 - 01:17:57.754, Speaker A: What about this term? Well, this term, there is a Laplacian of b. You do then whatever you want, but it is zero.
01:17:58.094 - 01:18:08.678, Speaker B: Okay, so that disappears. Then plus Richie, the direction is going to be grabbing. Okay, but of course, by assumption, the.
01:18:08.686 - 01:18:13.954, Speaker A: Rich is non negative. So this forces the Hessian to be zero.
01:18:17.014 - 01:18:17.954, Speaker B: Makes sense.
01:18:19.334 - 01:18:25.304, Speaker A: This is greater equal than the Hessian of b squared. Therefore, the Hessian is zero.
01:18:30.044 - 01:18:33.140, Speaker B: Okay, what do I do?
01:18:33.172 - 01:18:43.940, Speaker A: So how I conclude from Hessian equals zero? To my splitting guy, my splitting principle well, now the point is this. So whenever, so whenever you have, I state the thing globally.
01:18:44.052 - 01:18:46.724, Speaker B: But you can see that if you want.
01:18:46.764 - 01:18:51.462, Speaker A: I mean, it's easy to reformulate this in a local business.
01:18:51.638 - 01:19:05.874, Speaker B: But now let me define n to be the preimage, you know, of Zena.
01:19:08.254 - 01:19:22.220, Speaker A: I claim that this is bootstrap manifold. And what is the case? Well, you know, if the Hessian is zero, the gradient cannot vanish basically, right? So this is an affine function. So the grid. So the action is zero degree constant. We want the grad. There is a formula, grad, the grad.
01:19:22.252 - 01:19:24.372, Speaker B: B squared, if you want.
01:19:24.508 - 01:19:39.692, Speaker A: This is the Hessian of the grad b y. So this, for in our case, this is zero. So this is a constant function. So this is identically one. So all points are regular point or values are regular values. And the primary is a smooth one. It's movement.
01:19:39.788 - 01:19:44.828, Speaker B: Okay, now this function b has zero ers.
01:19:44.916 - 01:20:34.344, Speaker A: Therefore, this manifold is totally juicy, is a convex subset. If you pick two points, two points, you know, in n, and you connect them by a Judisc, then the judisc must lie entirely on n. And why is that the case? Well, p gamma, you know, you know, with b of gamma zero equal b of gamma one. I mean, that really works for any sublevel. Okay, and let's compute the second derivative of b along gamma t. So the first derivative is, you know, grad b in gamma t dot gamma t prime. The second derivative, given that this is a Judisc, if I throw the derivative on gamma, I get zero.
01:20:34.344 - 01:20:44.578, Speaker A: I mean, we get the covariant derivative of gamma that is zero. And then you have the hessian of b and the point gamma t in gamma t prime, gamma t prime. But the Hessian is zero. So this is zero.
01:20:44.746 - 01:20:50.850, Speaker B: Okay, but if this is zero, now, I have a function which is an.
01:20:50.882 - 01:20:55.698, Speaker A: Affine function, because second derivative is zero and the value of the initial. Define a point at the same.
01:20:55.866 - 01:21:03.094, Speaker B: So this function is constant. Okay, so b is constant along Judis six. And therefore. And therefore, that's it.
01:21:05.534 - 01:21:33.686, Speaker A: Well, but now, now this, you know, the Ricci curvature of n, of n greater than zero is a, you know, is a consequence of, you know, standard formulas about, you know, manifolds and immersions and so on and so forth. So basically, there is no, there's no curve virtual generated by, by how n is sitting inside m in sentence. No, any, so if you have a total manifold of a given manifold, whatever is the curvature bound on the manifold, this, you know, gets in edited by.
01:21:33.710 - 01:21:43.314, Speaker B: By, by the subnet okay, all right. And now, and now what do I do?
01:21:43.654 - 01:22:20.754, Speaker A: How do I define? So how do I move in some sense? So what? My splitting map and my splitting map is the following. My splitting up is the following. Now, I can define the gradient flow of this I can define, you know, for every x. Well, let me define the map f, you know, from m cross. If you want r into m, define the following way. So the curve that takes t and.
01:22:20.794 - 01:22:31.598, Speaker B: Returns ftx is the only solution of.
01:22:31.766 - 01:22:44.154, Speaker A: You know, eta t prime equal grad b at the point eta t, eta zero, equal x. So I follow the gradient for b.
01:22:48.174 - 01:22:52.660, Speaker B: Now notice, notice that if I do.
01:22:52.852 - 01:22:55.740, Speaker A: If I pick f, apply to x.
01:22:55.812 - 01:22:59.588, Speaker B: With time, which is minus bx, this.
01:22:59.716 - 01:23:06.924, Speaker A: Will always leave in my summarize. So by definition, if I move, if I move along a gradient flow, actually, perhaps, okay, the basic formula is that.
01:23:06.964 - 01:23:14.732, Speaker B: B at f dx is b of x plus d. I guess b is one.
01:23:14.748 - 01:23:34.310, Speaker A: Leipzig, I'm moving along the gradient flow. So b varies with speed one in some sense along this flow. So if I pick a suitable t, I end up in the level zero. Okay, so let me call this map the projection map. So this really acts as a projection.
01:23:34.342 - 01:23:36.694, Speaker B: On n. And now my splitting map.
01:23:36.734 - 01:23:39.790, Speaker A: Is, the map depicts x and returns.
01:23:39.822 - 01:23:49.614, Speaker B: The projection with x comma b of x. Okay.
01:23:51.554 - 01:24:20.104, Speaker A: I've done everything. Let me just check now. I should, I only have to check now. This is pretty much the m is a problem, but you know, this is b. So yes, this is b has zero Hessian, the literacy constant is one, and n is a level set. And there's no negative rich. Okay, what else? Perhaps what else is worth to point out? I wanted to see one thing.
01:24:25.244 - 01:24:26.140, Speaker B: Okay, don't remember.
01:24:26.212 - 01:24:34.580, Speaker A: Okay, let me, let me go on. So clearly, this is a map from m to the product of n cross.
01:24:34.612 - 01:24:35.184, Speaker B: R.
01:24:38.594 - 01:24:51.378, Speaker A: Is it a bijection? Perhaps. And yes, it is. And why it is? So? Because what happens? So what happens?
01:24:51.426 - 01:24:54.890, Speaker B: So if x and x prime have.
01:24:54.922 - 01:25:13.732, Speaker A: The same projection, it means that they are leaving. So I have this manifold, nice manifold, and then I'm moving along the gradient flow of b, the vertical direction. Now, if you know where a point is sitting in the projection and b of x is, you know how far is the boom function, then you know.
01:25:13.748 - 01:25:18.228, Speaker B: The point makes sense and vice versa.
01:25:18.276 - 01:25:30.462, Speaker A: So this map is injected and it is subjective because, you know, for any point in the sub manifold and for any real time, if I flow along the gradient flow for the current amount of time I reach, you know.
01:25:30.638 - 01:25:34.950, Speaker B: Okay, and now let's check so I.
01:25:34.982 - 01:25:51.634, Speaker A: Want to check that m is a product. What does it mean that I have to check that m is a product? I have a map which is clearly smooth between riemannian manifolds. So it is a bijection. So I really want to prove that the differential of this map is, you know, is an isometry of tangent spaces.
01:25:53.834 - 01:25:56.386, Speaker B: Okay, that's what I want to prove.
01:25:56.530 - 01:26:03.562, Speaker A: I have a metric tensor on m. I have a product metric tensor in here, and I want to check, and by the way, what is the problem?
01:26:03.618 - 01:26:07.562, Speaker B: What is, okay, what is the matrix here?
01:26:07.618 - 01:26:13.894, Speaker A: Well, is the product matrix in which the two factors are orthogonal at every point the only one.
01:26:16.794 - 01:26:17.770, Speaker B: Okay, here is the thing.
01:26:17.802 - 01:26:21.564, Speaker A: Now, if I, so let me, let me conclude the following way.
01:26:21.604 - 01:26:28.236, Speaker B: So if, so, if, let me, let me look, let me look, let me.
01:26:28.260 - 01:26:53.956, Speaker A: Look at the level. Let me check that the differential of this map is an isometry on the level set on the points that are already on n. And then I comment how to, you know, deduce the same thing, the same thing for other level sets. Now, if I have a point that is sitting over here, this tangent space clearly splits into parts. One tangent space with the tangent space in n and one and one vertical one. Now, on the direction of the tangent.
01:26:53.980 - 01:26:57.224, Speaker B: Space in n, this map is an isometry.
01:26:59.924 - 01:27:09.580, Speaker A: I move nothing, okay? And b of x is zero. So if I perturb x in the direction of the tangent space, the differential is an isometry.
01:27:09.772 - 01:27:11.064, Speaker B: Make sense what I'm saying?
01:27:11.884 - 01:27:28.944, Speaker A: Okay, and what if I perturb x in the vertical direction? So orthogonal direction of this. Well, if I perturb in the vertical direction, it means that I'm perturbing exactly direction of the gradient of b, because this is a layer set of b. So the vertical direction is really degraded of b. But if I perturb in the gradient of b, I'm following the flow.
01:27:29.024 - 01:27:33.004, Speaker B: I mean, you see the gradient of this guy, right?
01:27:33.304 - 01:27:41.524, Speaker A: These two components, the horizontal direction, the vertical direction, are orthogonal in m, and they are also toggle in the, in the product. So that's enough to conclude.
01:27:43.604 - 01:27:46.316, Speaker B: Okay, why.
01:27:46.460 - 01:28:11.754, Speaker A: Why, what happens at different level sets? Well, at different level sets, what you can, you can argue in various ways. One way is to notice, is to notice that the map that takes, you know, fixed t and let and pick the map that takes x and f dx. So I move along this gradient flow. This map is an isometry of m into itself, if you want, as a consequence of the fact that, again, the action of b is zero.
01:28:12.174 - 01:28:12.566, Speaker B: Okay?
01:28:12.590 - 01:28:17.910, Speaker A: So taking the level set zero or any other set is really the same. There is nothing special about zero.
01:28:17.982 - 01:28:20.914, Speaker B: Okay, makes sense.
01:28:21.814 - 01:28:47.702, Speaker A: I've been a little bit in a sloppy this last part, but, you know, I will give more details in the metric setting, where in the metric setting, being a product, should really be checked, not at the level of tangent spaces, because that would be less clear what they are, but really they develop Pythagoras theorem. Okay, you know, we have triangulus and they have, you know, the correct, the correlations. Let me make one final comment.
01:28:47.758 - 01:28:48.434, Speaker B: Perhaps.
01:28:54.934 - 01:28:57.834, Speaker A: Is the product, what is it? I want to say.
01:29:01.074 - 01:29:04.106, Speaker B: Perhaps, of course.
01:29:04.290 - 01:29:09.314, Speaker A: In our more metric setting. In our more metric setting, we won't.
01:29:09.354 - 01:29:13.374, Speaker B: Really have, we won't really have this.
01:29:13.954 - 01:29:40.792, Speaker A: At least as of now, we won't have this book. In this way, we only have the one without the action. And still we need to extract information about the Hessian. So that will require a little bit of work. But a basic idea, a basic idea is this. And then we will, and then I will stop. But the basic idea is that even if.
01:29:40.792 - 01:29:44.352, Speaker A: So, let me, let me just try to convince you about this.
01:29:44.408 - 01:29:47.840, Speaker B: So suppose you only know that on.
01:29:47.872 - 01:30:20.134, Speaker A: Your manifold, these manifold. So we are in a good setting, but we don't have book, and Weisenberg never brought that identity. The only thing that they proved was that grad Laplacian of grad f squared over two is greater or equal than grade f. Grad Laplacian f for n is multiple function. Suppose you already, you only know this. Okay, how can this be sufficient to extract information about the Hessian of b, you know, for a Boseman function? Well, and the point is that, is that the, our bosom function will satisfy the equality here.
01:30:20.954 - 01:30:21.746, Speaker B: Okay?
01:30:21.890 - 01:30:32.374, Speaker A: While any other function satisfies an inequality. And this allows us to write an Euler equation for the Bozeman function that basically enclose the same information that I've encoded by this.
01:30:33.114 - 01:30:36.138, Speaker B: Okay, so I guess this sentence is.
01:30:36.146 - 01:30:51.762, Speaker A: Just a preparation to what? To what will come next. So on Friday, there will be no lecture, sorry, the lecture on Friday is cancelled. So the next lecture is next Monday. And what I start, I will start doing next Monday is, okay, I erase this Laplacian comparison on RC setting.
01:30:51.858 - 01:30:52.410, Speaker B: Okay?
01:30:52.522 - 01:30:57.658, Speaker A: And then we start instant, try to run this program in Rc setting and see. And see if we reach an app.
01:30:57.786 - 01:31:00.434, Speaker B: Right. All right.

00:00:00.480 - 00:00:45.894, Speaker A: So today I'll be talking about convex Klee configuration spaces. So I'll start where Sean left off last week. So he talked about the single interval property and defined what Klee configuration space was. So this idea of convex Kaylee configuration spaces is sort of a generalization of the single interval property to multiple non edges. And I'll talk about some interesting results with regards to the convex scaly configuration spaces. And I'll talk about some applications to doctor plans. Doctor plans is something we've been studying in this course for the last few weeks.
00:00:45.894 - 00:01:49.624, Speaker A: And Doctor Sitaram gave a talk on FlexVr plans in, in one of the rigidity workshops. So you'll see how this idea of convex scale configuration spaces is applied there. And the other application with regards to doctor plan is this idea of Kleed combination, where before two weeks ago we were talking about how we are optimizing for algebraic complexity when we are recombining solutions given a doctor plan. So this is a different take on that, different way of doing it. And that will probably cover all of today. And then on Thursday, I'll talk about application of convex scale configuration spaces in three d to molecular assembly. Okay, so I'll get some definitions out of the way first.
00:01:49.624 - 00:03:07.244, Speaker A: So we define a k sum of two graphs, g one and g two, containing a k clique as a proper subgraph by gluing g one and g two, by identifying matched pair of vertices that belong to the cake leak. And when you do this operation, g one and g two are called the kissimmee components. And given a graph, you can run the inverse operation where you inverse operation of this, where you kind of separate them, and then you have the two k some components. So when we're doing the inverse operation, if you're unable to do this separation by identifying a clique, common clique, then we call it a minimal k some component. And given a non edge in the graph, um, the minimal k some component containing the non edge f is a minimal subgraph that is both a ksm component and the, and contains the vertices of the non edge f. So it's not really a k some component that is minimal and happens to contain f, but rather it's a minimal subgraph that is, that has both k some component and contains the vertices of f. So this is going to be a little bit of recap.
00:03:07.244 - 00:04:03.094, Speaker A: Sean talked about this last week. Given a linkage that is a graph with edge length as positive edge length assignments to e and a set of non edges f, its d dimensional Klee configuration space denoted as phi dfg delta. That here the d is the dimension in which you're realizing f is the set of non edges. So the Kaylee configuration space is the set of realizable distance, distance values for the non edges in f in dimension d. So if you take this example over here. So this is a linkage abcd. I've given edge lens one to all of the edges, and I'm choosing this dashed line here, cb, to be my non edge f.
00:04:03.094 - 00:05:36.822, Speaker A: So the Klee configuration space of this linkage with on this non edge is all of the realizable values that all of the lengths that cb can take in any realization of this linkage. So as you can see, this can take a value anywhere between zero and two. So, and given a linkage and a non edge of the graph f, the pair gf, as what we call the d dimensional single interval property, if the Klee configuration space of the graph on f is connected for on all edge length assignments delta. So again, this is an example where for your non edge f, your, you know, this has the single interval. So it just takes single interval from zero to two, whereas this example over here, I've taken the non edge to be v one, v two, this red dashed edge, and this is again in two reals. And because this is, you know, this can only be drawn in two different ways, where v two is on this side or the other side, it has only, this v one, v two has only two realizable edge lengths. And it's a, it's not a single interval.
00:05:36.822 - 00:06:36.254, Speaker A: There are two disconnected points. Okay, so with this definition of Klee configuration space, these are some of the interesting questions we ask about them. So, first question we ask is characterize graphs with connected convex linear polytope 2d Klee configuration space. So this again is a generalization. It's not just talking about on a single knowledge, but rather on a set of non edges. Then, the second interesting question is this idea of inherent connected Klee configuration spaces. And so these two points will be where I'll be spending bulk of the first hour of the lecture.
00:06:36.254 - 00:07:32.264, Speaker A: And then other interesting questions here include, if you're given a graph, can you efficiently recognize if the graph has convex Klee configuration space? And the last one is about sampling and realization. So again, going back to the single interval property, this was a theorem. Sean talked about this a little bit last week. I'm not going to go into the proof of this theorem here. So given a graph g and a non edge f, the Klee configuration space on f for the graph g. And, you know, assign edge length assignments. Delta is a single interval for all delta if and only if the minimal two sum components of g union f that contain f are partial two trees.
00:07:32.264 - 00:08:21.458, Speaker A: So this result is true in all two reals, but it does not extend to three reals. So for example, you know, you can have partial three trees like the two shown here, and a non edge such that, sorry, these are not partial three trees. You can have graphs that are not partial three trees, but they still have the single interval property. So you can take these four vertices, these are k four. And then you can imagine these two as the wings. And, you know, they kind of hinge around these edges. And, you know, the length of this non edge f is just a single interval.
00:08:21.458 - 00:09:45.744, Speaker A: The same here. So this is one of the problems that meera, Sean, William Lufteris and I are currently working on to find a characterization for this. Okay, so we next talk about characterizing graphs with convex scaly configuration spaces. This is again a theorem in this paper by Sitaram and Gau. So this theorem has two components. The first says that if you have a graph and the graph has a two sum component g that is an under constraint partial two tree, then there exists a non empty non edge set f that is entirely in this two some component such that for any edge length assignments to the graph, the Klee configuration space on these non edges is a linear polytope. Moreover, there is such an f such that this configuration space is genetically complete for the graph.
00:09:45.744 - 00:10:18.404, Speaker A: And the second part of the theorem is that, you know, if a graph is an under constraint partial two tree, then for any non empty non edge set f dash that preserves the partial two tree, um, when you add it to the edge set, then this clearly configuration space is still a linear polytope. So we'll go into the proof of this theorem a little bit.
00:10:18.984 - 00:10:24.004, Speaker B: So Rahul, could you say again, what does generically complete mean?
00:10:25.024 - 00:11:18.394, Speaker A: So here, generically complete is talking about g being, you know, minimally rigid. So I can pick non edges f. So that, you know, when I add it to, when I add it to the graph, that the graph becomes minimally rigid and your configuration space, that's what it's talking about. Okay, thanks. Okay, so, um, right, so we are trying, yeah, first we'll try and prove a. And for to prove a, you need this lemma here. That kind of depends on the lemma 5.7.
00:11:18.394 - 00:12:02.498, Speaker A: So let's go them one by one. So if you take a graph g g, and if g is the two sum of a whole bunch of Gis. Then for any edge length assignment, delta g delta has a realization only if each of the two sums has a realization. I don't think this should be very hard to see. I mean, it should. It kind of intuitively makes sense that, you know, each of the two sums should have a realization. So take a graph we're talking about lemmev 5.7.
00:12:02.498 - 00:13:07.704, Speaker A: Now take a graph with two sum components gi and a non edge set f that is entirely contained within one of these two sum components. Let's say that two sum component is g one. Then for any delta, that is the edge lengths assignments, the Klee configuration space of the original graph g on the non edge set f in 2d is the same as the Klee configuration space of this g one in which we have added the non edges if all the Gis hang on. Oh yeah. You know, so these two are the same if all g's are non empty. That is going back to this lemma here. Otherwise this is empty.
00:13:07.704 - 00:14:18.494, Speaker A: So all it's saying here is that if you can find a two sum component and stick in non edges into the two sum component, then the configuration space of the two sum component is the same as the configuration space of the entire graph. So we are proving a here. So, which is again saying that if you have an under constraint partial two tree as one of the two sum components, then your configuration space is a linear polytope. Okay, so starting with the, with the setup that g is an under constraint partial two tree. So because it's an under constraint partial two tree, we can find a non empty set of non edges g by adding, which you can make it a complete two, three. And we call this, these edges that we add to make it a complete two tree as f. Note that such an f is a completion of g.
00:14:18.494 - 00:15:04.950, Speaker A: That makes g minimally rigid. So because two trees are minimally rigid, adding in f makes it minimally rigid. So the Klee configuration space is full, full measure and genetically complete. So, so that proves the, you know, the second part, the generically complete part. Now we get to the polytope part of it. So a two tree can be written as two sum of triangles. And because it can be written as a whole bunch of to sum of triangles, the all the edge lengths and the non edge lengths are governed by triangle inequalities.
00:15:04.950 - 00:16:01.424, Speaker A: So you have a whole bunch of triangle inequalities governing the lengths of these non edges. And, you know, because of that, this thing is a linear polytope. So now, since f is entirely in, we assume that f is entirely in g. So we can kind of use lemma 5.7 here, that which said that if it's entirely in the two some component, in one of the two some components, the configuration space is configuration space of the original graph is also the same same thing. So that's for all edge length assignments. The configuration space of the original graph is also a linear polytope.
00:16:01.424 - 00:17:11.670, Speaker A: Let's go back to b here. So we prove b now. So here it's saying that if the graph is an under constraint partial two tree, then for any non empty non edge set f that preserves the partial two tree in s, the configuration space is a linear polytope. So for any under constraint partial two tree, we can again find a set of non edges that make it a two tree. And we've showed that when we make this a two tree, this whole thing about it becomes generically complete. And the linear polytope is a, I mean, the Klee configuration space is a linear polytope. So you can take any non empty subset f dash of such an f.
00:17:11.670 - 00:17:48.166, Speaker A: So note that, you know, when you have a partial two tree, there is no unique completion. There's no unique set that make it a two tree. I can, you know, give you several different types, usually several different sets of edge that compare to several different two trees. So I'm picking one of those completions. So we take any non empty subset f dash of such a completion. These are exactly, you know, the subsets that would preserve the partial two tree ness. Because starting with the partial two tree, you're going towards a two tree.
00:17:48.166 - 00:19:40.774, Speaker A: So any edge you you add will be subset will be contained in the two tree. So this preserves the partial two tree ness. Therefore, the Klee configuration space on any of these subsets is kind of a projection on a projection of the entire configuration space with all the non edges on these f dash that you have chosen. And because we proved in the first part that this portion, that is the Klee configuration space on the non edges that completed to a two tree was a polytope, its projection is also a linear polytope. Okay, so this theorem here is kind of extending that previous result a little bit. So it says that given a graph and a non empty set of non edges, the 2d Klee configuration space is a linear polytope, connected or convex for all edge length assignments, delta if and only if all minimal to some components of g union f containing any subset of f are partial two trees. Furthermore, the Klee configuration space is generically complete if and only if the under constrained minimal two sum components of g are partial two trees and the minimal two some components of g union f containing f are two trees.
00:19:40.774 - 00:21:13.844, Speaker A: So it's basically saying everything in the previous theorem and extending it a little bit so we'll not spend too much time on it. So we move on to this idea of inherent Klee configuration spaces. So, in the previous section, when we talked about convex Klee configuration spaces, I always gave you a graph and a non edge set. And I said that for this graph on this non edge set, you had a convex Kaylee configuration space. But in this idea of inherent Klee configuration space, all I'm saying is that if I give you a graph edge, you can partition the edges of h any which way into two sets e and f. Then the graph g got by the edge set will always admit convex scaly configuration space on the set of non edges f. Was that clear? Okay, and again, this be something we recall from last week's lecture, this idea of deflattenability.
00:21:13.844 - 00:22:26.044, Speaker A: So, a graph is said to be deflattenable if for every edge length assignments delta, a euclidean realization in any dimension also has a realization in RD. I don't think this has to just be euclidean, but that's just the way I've written it. Okay, so this is an interesting result that kind of connects flatten ability with this idea of convex scaly configuration spaces. So the theorem here states that if a graph is deflattenable, it admits inherent connected d dimensional Klee configuration space. So this is going in one direction. It's saying that if a graph is deep flattenable, it admits inherent d dimensional Klee configuration space. So this was proved in the Ctaram Gao paper for l two only.
00:22:26.044 - 00:23:45.360, Speaker A: But a later paper kind of proved this for general Lp norms and also improved the reverse direction. So, first I'll talk about the proof of this in just l two and just the one direction. And then we look at the generalization a little later. Okay, so, does everyone know what a euclidean distance matrix is? So it's just n by n square matrix, which happens to have the property that there exists some assignment of points p one, p two belonging in rd for some dimension d, such that the distance between PI and pj corresponds to the ijth entry of the matrix. So this is again symmetric and zero diagonal matrix. All the good stuff. So, start with this idea of an implied and distance matrix.
00:23:45.360 - 00:24:55.224, Speaker A: So a classical result that, you know, that was in one of Schoenberg's papers that follows from the positive semi definite of gram matrices says that the set of all Euclideans, euclidean distance matrices is a convex cone. So because the, you know, this n by n matrix is the set of, if you think of this as the vertices of a graph, you're thinking of all v square distances. That's the convex cone. The projection of this cone on any set e union f is also convex. So taking a convex thing and taking a projection of it on some edges, so that's going to be convex. So by the definition of g flattenability of a graph. So we're taking a different graph h here with the vertex at v, and the size of the vertex at is n.
00:24:55.224 - 00:26:31.354, Speaker A: This kind of projection on the edge set is exactly all of the square distance assignments to the pairs in union f for which the graph h as a realization in RD. So we denote this projection onto the set of union f as the scaly configuration space in d dimensions, union f. So I put squared here because I'm talking about the squared Klee configuration space here. It's just that the, instead of realizable lengths, I'm taking the squares of the realizable lengths. So now we take a section of this projection that is obtained by restricting this delta star that I defined here for h to be delta over the set of edges. And this is exactly the Klee configuration space of the graph g delta for its non edges f. So since, you know, the scaly configuration space was section, I mean, we only took sections and projections here, and sections and projections preserve convexity.
00:26:31.354 - 00:28:01.314, Speaker A: So this sections and projections of this original cone that, you know, the preserved convexity. So the Klee configuration space that we get here is convex. Um, so notice that I did not make any assumptions about uh, e and f here. Um, you can partition the graph into any set of edges and non edges. So this kind of shows that if a graph is deflattenable, then, um, what direction are we going? Yeah, if a graph is deflattenable, um, it admits inherent Kaylee configuration space. So you can partition the graph into any set of edges and non edges. Were there any questions so far? Okay, so like I was saying earlier, this theorem by Sitaram and Willoughby kind of extended the previous result for any Lp norm.
00:28:01.314 - 00:28:59.152, Speaker A: So this theorem says that for any Lp norm, a graph g is deflattenable if and only if g admits inherent d dimensional Klee configuration space for each of its sub graphs. So if you notice, the previous proof that went from graph is deflattenable to, you know, it admits inherent connected Kaylee configuration space only relied on the fact that the cone was convex. So, to prove. To prove this, for any LP, all we'd have to show is the cone of square distance. Vector NLP is convex. So this notation is slightly different. N is the points and LP is the.
00:28:59.152 - 00:29:32.744, Speaker A: Is a new norm. So if you can show that this is convex, then our previous proof would just go through. But for. Yeah, this is the only if direction. But for the if direction, we would need to show that the cone is a convex hull of the LPP distance vectors in any dimension. So, yeah, like I said, for the only direction.
00:29:34.784 - 00:29:36.832, Speaker B: Rahul, there's a question in the chat.
00:29:36.928 - 00:30:02.864, Speaker A: Oh, sorry. I cannot see the chat. Sorry. Is the result for on P in the closed interval? I don't think it applies to l infinity. I'm not sure. Maybe Doctor Setharam can pitch in. I think it's the open interval.
00:30:02.864 - 00:30:10.612, Speaker A: So he's asking if this LP norm is.
00:30:10.708 - 00:30:13.660, Speaker C: Yeah, I think. I don't think we showed it for infinity norm.
00:30:13.772 - 00:30:14.788, Speaker A: Yeah, yeah. So.
00:30:14.876 - 00:30:15.468, Speaker C: But in.
00:30:15.556 - 00:30:18.140, Speaker A: Yeah, it was just the open interval of.
00:30:18.332 - 00:30:20.556, Speaker C: The paper has some results for the.
00:30:20.580 - 00:30:23.220, Speaker A: Infinity norm, just for this particular theorem.
00:30:23.292 - 00:30:37.724, Speaker C: I don't think was for the case of dimension two, because then l one and l infinity pretty much behave the same way. But that was in about forbidden minors later in the paper. Yeah.
00:30:38.384 - 00:30:43.444, Speaker D: So is it true for l one? Was it a little bit lost on that?
00:30:43.984 - 00:30:46.024, Speaker C: Yes, this is true for l one.
00:30:46.144 - 00:30:48.488, Speaker D: Okay, so it's just l infinity. That's the.
00:30:48.576 - 00:31:12.224, Speaker C: Yeah, okay. Yeah. L infinity is a problem. I mean, we use that, this convexity, if you took the d strata and take the convex hull for any d, you basically get the cone. And that uses. I think you gave that proof in your. Sean, in your lecture.
00:31:12.384 - 00:31:17.208, Speaker D: Yeah. And the proof, as far as I could tell, didn't work for l infinity.
00:31:17.336 - 00:31:17.998, Speaker C: Correct.
00:31:18.136 - 00:31:18.890, Speaker D: Because you need to.
00:31:18.922 - 00:31:22.746, Speaker C: Correct, yes, because you're adding up those. Exactly.
00:31:22.850 - 00:31:23.138, Speaker A: Yeah.
00:31:23.186 - 00:31:24.454, Speaker C: Adding up those distances.
00:31:24.834 - 00:31:30.562, Speaker D: And if you p is equal to infinity, then things don't make much sense. That's why I was wondering about the question.
00:31:30.618 - 00:31:32.810, Speaker C: Yeah, yeah, yeah, that's right. Yeah.
00:31:32.962 - 00:31:33.658, Speaker A: Okay.
00:31:33.786 - 00:31:34.794, Speaker D: All right, thank you.
00:31:34.914 - 00:31:53.934, Speaker A: Yeah. Okay, so we'll talk about the if direction of the proof. So. So this is going from if your graph admits.
00:31:56.634 - 00:31:59.654, Speaker C: I think Sean gave this proof, right, Sean?
00:32:01.794 - 00:32:05.810, Speaker D: I think so. Could I just see the statement to remind myself?
00:32:05.962 - 00:32:06.694, Speaker A: Yeah.
00:32:09.114 - 00:32:13.200, Speaker D: Yeah. So I did. I didn't do it for lp, but I don't think there's much difference.
00:32:13.352 - 00:32:20.528, Speaker C: Yeah, I think you did do the sum the. Yeah, yeah.
00:32:20.656 - 00:32:21.792, Speaker D: So you just need to so you.
00:32:21.808 - 00:32:24.392, Speaker C: Can go over it one more time if you want. Yeah, yeah.
00:32:24.408 - 00:32:27.984, Speaker D: I think the only change is the squared stuff turns into p and then.
00:32:28.064 - 00:32:38.912, Speaker C: Exactly. So this last. Yeah, the second bullet, you know, that's what the entire proof basically just uses. The second bullet.
00:32:39.008 - 00:32:48.164, Speaker A: Yeah, yeah, yeah, yeah, yeah.
00:32:49.664 - 00:32:52.616, Speaker C: Okay. Go ahead, Rahul. That's okay. We can repeat it.
00:32:52.680 - 00:33:25.224, Speaker A: Yeah. So, yeah. Okay. The direction we're going from the graph has. The graph admits inherently convex klee configuration space to the graph is deflattenable. So suppose, what am I seeing here? All D dimensional. Klickon.
00:33:25.224 - 00:34:10.156, Speaker A: Okay. Oh, this should be g, I think. Yeah. So we're taking the D dimensional klee configuration space. We're talking about the d dimensional Klee configuration spaces corresponding to sub graphs of gift, you know, minus the non edges. And we're saying that we are certain that they're convex. And, you know, we note that because here we said that for all sub graphs, this is convex.
00:34:10.156 - 00:34:55.350, Speaker A: This should certainly be true for the empty subset f. And we denote that empty subset here, the configuration space of the empty subset here. And, you know, this is just the configuration space g of the entire graph. Because this is convex. It is its own convex hull. So if you take a d dimensional stat of that, it, you know, it turns out to be the same as. Sorry.
00:34:55.350 - 00:35:35.394, Speaker A: The d dimensional strata of the graph turns out to be the projection of the convex hull on the set of vertices. This turns out to be the entire cone. So, you know, kind of shown that the Klee configuration, the configuration space, d dimensional. The d dimensional start of the configuration space is the entire configuration space. So it's deflat number. I think that was it. These are some of the references for the things I have talked about so far.
00:35:35.394 - 00:36:40.484, Speaker A: And now I'll talk about some of the applications of this idea of convex scaly configuration spaces. So, I'd like us to recall that doctor plan of a constrained graph is a forest, where each node in the forest is a rigid subgraph of g. The root node is a maximal rigid subgraph. The internal nodes is a union of its children, and then the leaf nodes are single constraints. So we also talked about, in previous lectures about this idea of, you know, the size of the doctor plan. That is the, you know, what's the size of the largest in decomposable system that we have to contend with. So, sometimes it turns out that even with an, you know, optimal doctor plan, that kind of reduces the size of the largest indicomposable system, the size of the largest in decomposable system.
00:36:40.484 - 00:37:19.960, Speaker A: You get is very large to be tractable. So. So these are pictures from Mira stock on flex VR plants. Here, both these graphs, this is in 2d, by the way. Both these graphs do not have any non trivial subgraph that is rigid. So there's no rigid subgraph bigger than a triangle. So if you try and decompose this, you know, the size, the size of the largest indicomposable system kind of depends on the size of the graph.
00:37:19.960 - 00:38:12.474, Speaker A: So it can, it can get very ugly. So to deal with these kinds of issues, they have this idea of what they call the flex k doctor plan. So it differs from doctor plan in just one crucial way, in that for a doctor plan, you needed each node is a subgraph of g that was rigid. But here you allow, you know, each node of each node of the doctor plan to have k degrees of freedom. So you have allow it some flex so that you can have much nicer doctor plan. And the size of the doctor plan is maybe constant.
00:38:15.254 - 00:38:20.744, Speaker D: Sorry, what's meant by a maximal subgraph here? Maximum what sense?
00:38:23.724 - 00:38:26.464, Speaker A: Where maximal subgraph?
00:38:27.884 - 00:38:29.372, Speaker D: Maximal rigid subgraph?
00:38:29.428 - 00:38:34.116, Speaker A: Or maximum rigid sub. Oh, yeah, maximal rigid subgraph. Sorry.
00:38:34.220 - 00:38:34.892, Speaker D: Ah, okay.
00:38:34.948 - 00:38:35.212, Speaker E: Okay.
00:38:35.228 - 00:38:37.824, Speaker A: Yeah. So I miss rigid. Here.
00:38:38.284 - 00:38:39.068, Speaker D: Cheers. Thanks.
00:38:39.156 - 00:39:47.838, Speaker A: Yeah. Okay. So, um, we use this idea of a flex doctor plan in illustrating the configuration space of these cycloalkanes. So, cycloalkanes are these hydrocarbons where the carbons form a ring, like a single ring, and then they're attached to hydrogen atoms. And when the number of carbon atoms in this ring is six or less, this hydrocarbon is rigid, and it has only finitely many configurations. For example, this cyclohexane has only two configurations, the chair and the board configuration, as they call it. But if the number of carbon atoms in this chain is greater than six, you have some flexes.
00:39:47.838 - 00:40:50.232, Speaker A: And there's a lot of interest in studying the configuration space of these flexible cycloalkanes and flexible cyclones. So far in literature, only cycloheptain and cyclohocktane have been studied in any detail. And even these studies do not give any formal mathematical model to generate the configuration space. They are kind of ad hoc and focused on that particular cycloalkane that they're looking at. So we use this idea of convex Kaylee configuration spaces here. So first thing we do is convert this to a distance constraint graph. We treat all the carbon atoms as points in a graph, and then we add a distance constraint between carbon atoms that share a bond.
00:40:50.232 - 00:42:09.028, Speaker A: And then, because the bond angle between the three carbon atoms is fixed, we can add a distance constraint between, you know, carbon atoms that are separated by, you know, that are separated by this one, and we end up with a constrained graph. So like I talked about earlier, there are certain classes of graphs where, that have Kaylee configuration that admit Klee configuration spaces. So it turns out that these KLE configurations, I mean, these cycloalkane graphs, they do not have this property. So what we do is we drop certain edges. So this is the cycloalkane constraint graph that I have. This is cycloheptain seven molecules and edges for bonds and edges for angle constraints and so on. So what I do here is I drop these three edges that I've shown in red here.
00:42:09.028 - 00:43:15.124, Speaker A: And so soon as I drop these three edges, it becomes a partial three tree. And because it's, you know, it's a, it's a partial three tree, it admits, you know, Kaylee configurations, convex klee configuration spaces. All I would have to do is add in non edges that complete this to a three tree. And, you know, if I parameterize the configuration space on these non edges, I'll get a convex, convex space. So what do we do with this convex space? So let's, let's say that this was the original graph g. By modifying this graph, I got a graph g, and let's call this graph edge, where I've added the non edges. So we sample the Klee configuration space of edge on the set of newly added edges that I call these green edges that I call f.
00:43:15.124 - 00:44:32.514, Speaker A: And for each configuration in this configuration space, what we do is we compute the realization of this edge. And once we computed the realization, um, we, you know, in the realization, we can measure the lengths of these dropped edges. So, notice that in this edge, four, three and five, three and two four are not really edges. They're non edges. So when I realize this graph, for some length values of these green edges, I can measure the length of what this fourth four, three non edges taking. And I only keep the configurations where this non edges, where these non edges kind of take the value that they had in the original graph. And why is this an easy way of doing it is because realizing this graph is, I mean, first of all, sampling this space is very easy because this area is convex.
00:44:32.514 - 00:45:25.624, Speaker A: I can use any convex sampling method to directly sample the space. And then once I've done that, the realization step is also very easy. So this is, again, cycloheptain. I kind of split this up into its four constituent tetrahedra, you know, and each tetrahedron can be realized very quickly. So I have, you know, a triangle here, and I can intersect two spheres to get the two realizations and so on. So, yeah, that's, that's how we plan to generate the Klee configuration space of recycloheptains. And notice that, you know, I showed the example of cycloheptain, but it's also the same for cyclooctane.
00:45:25.624 - 00:46:16.600, Speaker A: I can always just drop three edges and get a partial three tree. And I'll have to add, you know, how many ever more edges to kind of make it a three tree. And once I, you know, have a, have a three tree, I can, you know, the, the non edges that I added to make it a three tree are convex. Okay, we have any questions so far? Okay, yes.
00:46:16.632 - 00:46:38.494, Speaker B: Wait. Yeah, so I'm a little confused. You're doing the sampling, but it seems like you should never get edges that are equal to the edges in g, the length edges. Like, what if you're doing random sampling, how come you ever get any of them to be like that?
00:46:39.154 - 00:47:38.878, Speaker A: Random? So we're not really doing random sampling. So what we are doing is, like I said, these, because this is a three tree, and I've added these non edges and make it a three tree. This kind of gives the entire configuration space of all the realizable edge lengths that this linkage can take. And like I talked about earlier, this is a linear polytope. And in that linear polytope, we kind of do a uniform sort of grid sampling. And, you know, at each of those configurations, we try and measure the lengths of the non edges. Does that answer your question or.
00:47:39.046 - 00:47:43.594, Speaker B: Yeah, I guess that maybe makes more sense. Yeah. Okay, thanks.
00:47:52.734 - 00:49:18.266, Speaker A: Okay, next we'll talk about this idea of optimal recombination. We talked about a little bit, a little bit about this two weeks ago or so, where you start with a given doctor plan and you have the solutions to each of the subsystems and you're trying to recombine the subsystems to get the original system. Like kind of doing a bottom up building to go from your solutions to of your subsystems to the original graph. So we kind of saw that this optimization. Sorry, this recombination, if you do it in a naive way, your algebraic complexity can, can really grow. And because of that, you know, we, we had this whole idea of, you know, how do we, how do we optimize this recombination step? And, you know, when we talked about it last, we were optimizing for algebraic complexity using rational quaternion parameters. And you know, we studied greedy algorithm that was developed using the underlying metroid called the C matriid and so on.
00:49:18.266 - 00:50:54.010, Speaker A: So now I'll be talking about how we use kv parameters to optimize for algebraic complexity when recombining solutions. So this, so we are not using quaternion parameters anymore and we are using Klee parameters instead. So this brings us to the idea of optimal modification for decomposition. So even though the slides I present here talk about how we modify an indie composable system so that we get a small doctor plan, even when you have a decomposable system sometimes, you know, this idea of optimal modification is useful. So you're at a particular node in the doctor plan and you cannot decompose it any further. So you have let's say n subsystems that you want to combine. So this idea of optimal modification talks about how can we modify that node so that modify the node slightly so that instead of getting this indie composable system, we get a small doctor plan that preserves the solutions of the original system before modification.
00:50:54.010 - 00:52:20.704, Speaker A: And then it should also be very easy to search for this original solutions in the modified system. So yeah, so this gives us the idea of the OM DK problem. So you're given an independent graph g with no non trivial proper isostatic subgraph. That is, you know, you original graph g is indecomposable and you're given two constants, k and s. So the question of the Omdk problem is, does there exist a set of edges that I can remove from the original graph g? And you know, I don't want to remove more than k edges and a set of non edges f. So that the modified graph where I remove the edges in e one and add the edges in the set of non edges f, has a doctor plan of size at most s. So I'm taking the original graph, removing certain edges at most k edges, matting some non edges.
00:52:20.704 - 00:53:44.980, Speaker A: You know, I'm some non as I'm making them edges and I'm seeing, I'm asking whether this new graph has a size at most s. That is, can I decompose it into at most s sub graphs, sub rigid subgraphs. So notice that the Omdk problem, the k is a fixed boundary. It's not part of the input, it's part of the problem itself. And if we can find such a tuple g comma s, then we call it a member of the set Omdk. So in this paper by Troy Baker et al, they kind of showed that if you are given an indie composable graph g, then if you take the spanning partial two tree, so you want all the vertices to be covered in the subgraph that you're taking. And if that subgraph is a partial two tree, and if you can get to it by removing at most k edges, then g two belongs to the Omdk set.
00:53:44.980 - 00:54:14.336, Speaker A: That is, you'll have a, you know, start with the original graph that's indicaposable. Then you modify it. And now your doctor plan has size two. You can decompose it into two rigid subgraphs. So they proved this for two d, I think. Yeah. So you start with the graph g.
00:54:14.336 - 00:55:16.354, Speaker A: And, you know, the problem statement says that I can remove k edges to get a two tree, a partial two tree. And once I get a partial two tree, I can complete it to a two tree by adding certain non edges. And, you know, because a two tree has Dr. Plan of size two, that is, two tree is just a bunch of triangles glued together, I can always pull out a triangle and recursively decompose it this way. The modified graph h has a doctor plan of size two. So, you know, if a graph has this property that by removing k edges it becomes a partial three tree, then we call this, in short as k approximately convexifiable. So you may notice that I listed three properties earlier.
00:55:16.354 - 00:55:54.844, Speaker A: One of them was small doctor plan. Then the solution preservation and efficient search. Um, this kind of, um, addresses two of the problems. So, but it does not talk about, talk anything about, um, you know, being able to efficiently find solution for the original graph g. So that's where the idea of convex klee configuration spaces comes in. Basically. Um, you know, you, you had, you had a partial two tree that you competed to a two tree by adding the set of non edges f.
00:55:54.844 - 00:57:10.082, Speaker A: Therefore the configuration space you get by doing this is convex, and you can efficiently search that configuration space to find the solution of the original graph. So this theorem is kind of saying that. So if you are given an indicaposible k approximate convexify convexifiable graph, that is from the graph g, I can remove at most k edges and make it a partial two, three partial two tree then, and let f be the set of non edges of g that I add to make it a two tree. So h is the two tree. Now. So each solution of the original graph for an orientation type can be found in order log w, where, you know, w is like the discrete volume of this configuration space. So divided, I've done a uniform grid sampling on the configuration space and w is the volume.
00:57:10.082 - 00:58:06.578, Speaker A: And it says that I can do, I can find this given an orientation type for the original solution of the original graph. I can find this in order log w. This is just by doing binary search on all the different parameters. But you have to notice that w is exponential in the size of f or its polynomial in the range of f. So let's do an example to kind of see how this works. So you have your original graph, this is a k 33. And as you can see, you know, this does not have any decomposable portion.
00:58:06.578 - 00:58:58.862, Speaker A: So if I were to split this up, I think I'll only get edges. I don't think we even have triangles here. So if I want to find the realization of this k 33, if I rule out, even if I rule out isometry, I mean I'm going to rule out isometry. So I place the, one of the vertices at the origin and then I'll place, you know, another vertex on the x axis. Even then I'll have to find, I'll have to deal with eight quadratics and eight variables. So there are eight more edges, so that eight more edges. And for each vertex I have the x and the y variable.
00:58:58.862 - 01:00:12.028, Speaker A: So I'll have to solve, I mean, to realize this system and have to solve a quadratic system, a system of eight quadratic equations in eight variables. So let's see how we can do better by using this idea of, you know, optimal modification. So I'll identify two edges, e one and e two, and I'll remove them from the original graph. Once I remove them from the original graph, this is, this is g. This turns out to be a partial two tree. And on this partial two tree graph I can, you know, I can add two edges here, two non edges here, f one and f two to make it a two tree, a complete two tree. So if you can see, uh, and if you can see the way I've drawn the k 33, um, there's one triangle and then you paste another triangle on the edge, another triangle on the edge and so on.
01:00:12.028 - 01:01:38.124, Speaker A: So you get a complete two three. So what we do is generate the Klee configuration space of this linkage on f one and f two. And you sample the entire configuration space basically. And once you sample the entire configuration space, you have a convex region through which you have to search for configurations whose realization gives you the length of the original drop edges, e one and e two. So it also turns out that the theorem here said that, you know, there is a way of doing this optimal modification such that you have to remove at most k edges to get this optimally modified graph. But for k 33, it turns out that there is another way of doing it. So all you have to do in this case is drop just one edge.
01:01:38.124 - 01:02:47.376, Speaker A: And when you remove that one edge and draw and add this new non edge f three, you have what are called three decomposable graphs. And it's shown that even for three decomposable graphs, the set of the Klee configuration space is convex. And you can do the same thing again. You sample, you sample the, you know, the realizable lengths of f three for. And, you know, at every realization, you compute the length of the non edge e here and then see if you find the original length and that those will be your configurations. And previously we had to solve a system of eight quadratics with eight variables. But now, because you've modified it, you know, at each stage, this realization step, you have to just solve two quadratics.
01:02:47.376 - 01:03:38.514, Speaker A: No, you, I think you can even, you know, make it even better. You can do one quadratic and one linear because it's, you know, just a circle intersection. Okay. Um, so the idea of optimal modification OMD was in this paper. It's an optimal decomposition and decomposition of isostatic geometric systems. And here are some other references for this. So do we have any questions so far?
01:03:54.214 - 01:03:57.678, Speaker F: So I have a question. Yeah, Rahul.
01:03:57.806 - 01:03:58.590, Speaker A: Yeah.
01:03:58.782 - 01:04:06.074, Speaker F: So, so, yeah, so my question is, does this procedure improve the numerical stability?
01:04:08.974 - 01:04:10.034, Speaker A: Say that again.
01:04:10.614 - 01:04:15.074, Speaker F: Does this procedure improve, improve, improve the numerical. Numerical stability?
01:04:16.254 - 01:04:22.360, Speaker A: Improve numerical stability. So what do you mean by numerical stability?
01:04:22.502 - 01:04:33.492, Speaker F: Um, like solving the original one. Solving, yeah, like the error, if you solve the original one. Like eight, eight quadratic equations. Right. So.
01:04:33.548 - 01:04:44.004, Speaker A: Oh, no, no, the original system, if we hadn't modified it, that would have had eight quadratics and eight, uh, variables. But, yeah, then the.
01:04:44.164 - 01:04:59.384, Speaker F: Yeah, then the error bound. Right? If you perturb the input, then the other put, the error of the other put will be, will be quite large, right? Because you have a, you have a many equation and many, many variables, right?
01:04:59.424 - 01:05:04.524, Speaker A: Yes, yes, yes. So. But now, yeah, so go ahead.
01:05:04.984 - 01:05:11.204, Speaker F: Yeah, but now you're doing this way. So, yeah, so that means the error is smaller.
01:05:11.504 - 01:05:39.114, Speaker A: Yes. So it's not just about the error being small. It's also about, you know, interactability. So as. And when the system kind of goes higher, the size of the system kind of becomes larger. Most softwares won't even be able to handle those large systems. But here you have a nice way of solving these, you know, just circle intersections.
01:05:39.114 - 01:05:45.078, Speaker A: So, yeah. Does that answer your question or was it something?
01:05:45.126 - 01:05:45.502, Speaker F: Yeah.
01:05:45.598 - 01:06:11.634, Speaker A: Okay. Okay. Um. So, yeah, I think. Doctor Sitaram. So this is what I planned for today. I think I've finished a lot earlier than I thought I would.
01:06:11.634 - 01:06:21.092, Speaker A: Should I, should I continue or should I just stop here and talk about.
01:06:21.148 - 01:06:22.532, Speaker C: I think you should continue.
01:06:22.708 - 01:06:23.544, Speaker A: Okay.
01:06:24.644 - 01:06:28.384, Speaker C: I mean, I think you went very fast through the very first section.
01:06:28.844 - 01:06:29.624, Speaker A: Yeah.
01:06:30.284 - 01:06:43.234, Speaker C: I mean, the notation is bad and hard for people to follow, but in any case, um, some of it was already done by, um.
01:06:44.134 - 01:06:46.422, Speaker A: Sean. Yeah, Sean.
01:06:46.478 - 01:07:13.814, Speaker C: And I think the main theorem is somehow missing in here, by the way, the. I think it was theorem 5.10 in the paper. These are always to, I mean, along the way, proving, proving that theorem. Oh, yeah, item b. Yeah, item b. Every under constraint to some component is a partial three.
01:07:13.814 - 01:07:17.474, Speaker C: Three. That's sort of like the key theorem. Um.
01:07:19.934 - 01:07:20.674, Speaker A: So.
01:07:22.534 - 01:08:00.774, Speaker C: Item b and theorem five point ten. The things that you had there are sort of along the proving it, you know, see all these little other theorems that I needed to prove it. But, you know, that's where I would have expected to have spent quite a bit more time. So people followed it. But I would suggest you just proceed with whatever you had planned. And there's plenty of material there that maybe even Thursday would not have been sufficient to cover. So simply add to it if necessary.
01:08:01.074 - 01:08:01.666, Speaker A: Okay.
01:08:01.730 - 01:08:02.614, Speaker C: For Thursday.
01:08:02.954 - 01:08:03.814, Speaker A: Okay.
01:08:04.874 - 01:08:05.774, Speaker C: Okay.
01:08:32.534 - 01:09:47.414, Speaker A: Okay. So I'll talk about now this idea of using Klee configuration spaces in molecular assembly. So I'll spend some time setting up the problem, and then we'll talk about how Klee configuration spaces are kind of used here. So, molecular assembly is a process in which these huge protein molecules that have potentials on their, on their atoms, they are guided by local interactions and they, you know, they arrange themselves into some predefined shape. What you see here on this on the right side is actin filaments, kind of self assembling here. And then what you see here on the bottom is what we call micellar fusion into clusters. So some examples of molecular assembly include protein docking, formation of actin filaments, like I showed here.
01:09:47.414 - 01:10:33.738, Speaker A: And another big thing is the self assembly of virus, capsids. And usually in all of these processes, we have what are called, I mean, these are all guided by these Leonard Jones potentials. So if an atom pair, one on each, you know, different molecule is at a certain distance from each other, the potential kind of drops. And those atoms kind of want to stay in that region. They get too close, they get repelled, and if they're too far apart. You know, they don't interact at all. So, yeah, they kind of stay in this.
01:10:33.738 - 01:11:50.760, Speaker A: In. They want to stay in this. LeOnard jones well, so here, even though I've shown, you know, multiple, you know, kind of particles assembling in both of these, we, in this, you know, in this study, I'm just going to talk about two protein molecules assembling together. So you have protein molecule a, protein molecule b, you have atoms on the surfaces of these proteins that have potential, you know, that have pairwise potential, you know, with atoms on the opposite molecule. And if I want to generate the configuration space of all the orientations one protein molecule will take with respect to the other, you know, this configuration space is topologically very complex. And I'll get a little bit into why it is topologically complex. So, what we do here is, you know, kind of geometrize this.
01:11:50.760 - 01:12:42.332, Speaker A: Um, we geometrize this. Leonard Jones, well, into three discrete intervals. We say, if the pairwise distance between two atoms is less than, you know, it's less than a certain value, we say that, you know, it's geometrically infeasible, and they're colliding. If the distance is too far apart, then we say that it's it's a non interacting, inactive constraint. And then if it's in this. LeOnaRD jones well, that is, if it's within this interval, then we say that, you know, those atoms are, they are in an active constraint. So what I've shown here on the top right should give you some idea.
01:12:42.332 - 01:13:12.634, Speaker A: So, you have these protein molecules, you have, these are numbered. An edge between, you know, when I draw an edge between two atoms here means that they are in, you know, their pairwise distances within this. LeOnard jones well, and then they're interacting. So I can formally reduce this, too.
01:13:13.214 - 01:13:28.474, Speaker B: Rahul yeah. Can you just go back to that picture? Yeah. This one. Are we assuming that the blue atoms are part of a molecule that's rigid?
01:13:29.094 - 01:13:30.714, Speaker A: Yes. Okay.
01:13:31.934 - 01:13:40.682, Speaker B: Rigid objects, and somehow we're trying to match figure out how they configure with respect to each other. Okay, good.
01:13:40.778 - 01:14:00.814, Speaker A: So even if they have internal degrees of freedom, we can deal with it. There's a generalized version of this. But then that, again, kind of uses this idea of decomposing this internally and finding out all the configurations. So here, I'm assuming that both of these molecules are rigid.
01:14:02.094 - 01:14:19.634, Speaker C: Yeah, basically, as he says, if it's not rigid, you know, just decompose it into rigid pieces, and then there'll be some extra constraints in between the rigid pieces. And those will be treated similarly. We continue in this fashion.
01:14:23.414 - 01:15:28.858, Speaker A: So what we do is we treat these, the atoms in each molecule, as points. And then we say that we want all pairs of atoms, one from each point set, to be a distance at least delta ab, from each other. This is to prevent them from colliding with each other. So no molecules should get too close. And the second constraint says that. So if I have to generate the configuration space of one molecule with respect to the other, I don't want any configuration space where the second atom is kind of floating. So I hold the first molecule rigid, the second molecule, I want at least one constraint to be active.
01:15:28.858 - 01:16:24.904, Speaker A: So at least one pair of atoms, one from each molecule, is within this. Leonard Jones well, so that's what the second constraint is saying. So, you know, all these are basically distance constraints. So when I have a whole bunch of these, I get a semi algebraic set, because it's a union of sets defined by polynomial inequalities. So you kind of get the idea why this is not, the space is not very nice. So we have this methodology called easel. Um, so it basically does, it generates the configuration space of these two interacting molecules.
01:16:24.904 - 01:18:07.466, Speaker A: So we employ some key strategies here. So the most, I mean, the first strategy we employ is because this configuration space is very not nice, we kind of first partition the configuration space into what we call active constraint regions. So, an active constraint region is a set of configurations that all have one key property in that the set of active constraints within all those configurations are the same. For example, if I have an active constraint region that, you know, that has the set of active constraints, a one, a two, that means all configurations in the a one b one. All configurations of these two molecules within that region have the constraint a one b b one. So we partition the configuration space this way, and you can kind of see that, you know, if I have a constraint, a one b one, if I have a one b one, and if I add an additional constraint, a two, b two, that region sort of forms the boundary of, you know, my original a one b one region. So this kind of gives us like a stratification of these partitioned regions.
01:18:07.466 - 01:18:40.534, Speaker A: We organize it like a directed Ac click graph. So we, like, I'm showing it here. So this is one active constraint region here. This is characterized by all config. This, um, region has configurations that have these two particular constraints, active. So this is, you know, this is what we call an active constraint graph. And there's a, you know, there's a molecule here, and I'm only showing three of them.
01:18:40.534 - 01:19:57.900, Speaker A: And this is just showing that some molecule, some atom here, is connected to some atom here. So the children of this, what we call active constraint region, are exactly those that have these constraints plus one additional extra constraint. So, as you can see, if you see the graph here, they have the same constraint as in the parent, but they have one additional extra constraint. So the same here, the same here, and you kind of stratify it this way. So you have five dimensional regions where there's just one constraint active, and there is four, and all the way, you go all the way to the bottom, where all the configurations are kind of rigid. The second strategy we apply is, you know, I said the active constraint region at the top is five dimensional. And if my goal is to find all the zero dimensional configurations, there are two ways I can go about it.
01:19:57.900 - 01:21:02.598, Speaker A: First one is start in the middle of the 5D region and shoot race everywhere and hope that it hits zero d configuration, which is not a very good strategy. So what I do is this is a kind of analogy for what we're doing. So we start at the center of this cube and we shoot race to find a lower dimension, you know, a lower dimensional boundary that is just one dimension lower. For example, if I started with four dimensional active constraint region here and a shoe trace, I'm only looking for three dimensional active constraint regions. So in this cube example, shoot rays everywhere. And, you know, it's much more likely that I'll hit a face than directly hit a corner. So once I hit a face again, I'll do the same act there, again, I'll shoot race all along the surface, and it's much more likely to hit an edge than it is to hit corners again.
01:21:02.598 - 01:21:54.344, Speaker A: This way I recursively decompose from, you know, from the center of a 5D region to I go to a so on, and all the way I go to zero dimensional regions. So once I have the stratification and I have a strategy for how. I mean, and I have this second strategy, which is saying I want to do recursive search. The third key strategy is this idea of Klee convexification. So what we do here is. So maybe I should pull up this graph. Hold on.
01:21:54.344 - 01:22:39.544, Speaker A: Should I. I just saw your chat, Doctor Sithan. So were you referring to the initial portion of the.
01:22:49.264 - 01:22:51.896, Speaker C: That was 20 minutes ago. Just ignore it.
01:22:51.960 - 01:23:12.744, Speaker A: Okay? Yeah. Okay. So when we are doing molecular assembly, these are. This picture shows all the possible graphs you can get.
01:23:12.864 - 01:23:14.160, Speaker C: We can't see anything.
01:23:14.272 - 01:23:54.190, Speaker A: Oh, okay. Um. Yeah, so when we're doing assembly of two molecules. These are all the possible contact graphs you can get. So when I mean contact here, it means that, you know, a pair, one, a pair of atoms, one from each molecule, is in the. Leonard Jones well, so let me explain what the blue and the green are. So the green are all the atoms on one molecule.
01:23:54.190 - 01:24:37.676, Speaker A: The blue are all the atoms on the other molecule. Not all of them. Some of them. So this green set also has other atoms attached to it, and this blue set has other atoms attached to it. So I'm just showing the ones that are, you know, in an active constraint. So this, this picture lists all the possible ways in which you can, you can kind of have contacts in molecular assembly. And it turns out that most of these graphs are partial three trees.
01:24:37.676 - 01:25:27.924, Speaker A: And because they're partial three trees, I can add non edges to make it a complete three tree. And my configuration space now becomes convex. And because it becomes convex, sampling in it becomes very easy. So, for example, here I'm showing the configuration space of these two molecules. So there's a blue molecule here, tiny blue molecule here with six atoms, and then there's another blue green molecule here with six atoms. And what I'm showing on the top here is the configuration space. And of course, yeah, I have to mention that this, all configurations in this region have four active constraints.
01:25:27.924 - 01:25:44.114, Speaker A: So it's a two dimensional active constraint region. So if I look at the configuration space in the regular cartesian or quaternion parameterization, this is what it looks like.
01:25:45.094 - 01:25:47.726, Speaker C: And what is each point on top?
01:25:47.910 - 01:26:36.314, Speaker A: Yeah. So each point here is an individual configuration in this active constraint region. And all configurations in this configuration space have exactly four active constraints, and they're all the same four active constraints. And I've grouped them into these different colors to indicate that they form a continuous region in the Cartesian space. So, as you can see, if I use Cartesian or quaternion parameterized parameterization, this is what I have to deal with the configuration.
01:26:36.354 - 01:26:37.894, Speaker C: Why are there gaps there?
01:26:39.434 - 01:26:42.494, Speaker A: Why are there gaps here? The Cartesian.
01:26:43.594 - 01:26:44.374, Speaker C: Yeah.
01:26:49.394 - 01:27:52.460, Speaker A: So there are two reasons there are gaps here. One is that some of these regions are configurations in some of these regions violate tetrahedral inequalities. And the other reason is I mentioned this, this other constraint here, where I said that molecules cannot get too close to each other. So I've ignored all those configurations. And also, I have to say that if you represent this active constraint region in Cartesian parameterization, this is, you know, that has six parameters. So it's a 6d space that I've kind of projected onto 3D. I've just projected it onto the three XYZ parameters.
01:27:52.460 - 01:28:14.484, Speaker A: And, you know, the angle parameters, they've just been smushed down. So even though this looks disconnected here, it may not really be disconnected because it's just. No, it should be disconnected in the 60 as well.
01:28:15.224 - 01:28:23.464, Speaker C: Also. I mean, it's six dimensions, but you expect this to have a two dimensional structure because there are four active constraints, right?
01:28:23.584 - 01:28:31.194, Speaker A: Yeah. Yeah. So it's a 2d space within 60 regions.
01:28:31.724 - 01:28:34.264, Speaker E: What's a circular pattern represent?
01:28:36.564 - 01:28:38.180, Speaker A: The circular pattern here?
01:28:38.332 - 01:28:40.104, Speaker E: Yeah. What does it represent?
01:28:49.124 - 01:29:27.624, Speaker A: So you may be asking about two different things. So the first thing is each of these configurations, you know what each of these configurations are? Each of these little dots are right. There are all these configurations that you can take while maintaining those four contacts. Are you. If you're asking why this is kind of like a circle, it's probably because you have one atom, you know, in the middle. Sorry. One molecule in the middle, and then you have a set, certain set of contacts, and then the other molecule is kind of moving around it.
01:29:27.624 - 01:29:29.228, Speaker A: Right.
01:29:29.356 - 01:29:31.508, Speaker E: So it represents some motion.
01:29:31.676 - 01:29:32.424, Speaker A: Huh?
01:29:32.844 - 01:29:35.064, Speaker E: Does it represent motion?
01:29:35.364 - 01:29:52.464, Speaker A: No, no, this. This is not representing any. So if you see in this graph up here, there are. It consists of a whole bunch of little dots. Is that visible? So each of those dots is a different configuration.
01:29:53.754 - 01:29:58.018, Speaker C: So in a way, it represents a motion. If you looked, I mean, if you.
01:29:58.066 - 01:30:01.874, Speaker A: Traversed on this surface, it would.
01:30:01.914 - 01:30:03.874, Speaker C: It's got two degrees of freedom, right?
01:30:03.914 - 01:30:19.798, Speaker A: Yeah. So if you traversed on this, on this surface here, from one configuration to another configuration here, it would represent motion of this going around. Does that.
01:30:19.926 - 01:30:22.554, Speaker E: That motion is periodical. Right.
01:30:24.174 - 01:30:25.754, Speaker A: Periodic in what way?
01:30:27.094 - 01:30:47.974, Speaker E: Well, we are talking molecules here. Right. And the atoms and. Yeah, of course, electrons. And so it's natural to expect this kind of periodicity or circularity or whatever. But the question is. And.
01:30:47.974 - 01:30:52.326, Speaker E: Sorry, I just didn't. I just showed up in your talk only now.
01:30:52.430 - 01:30:53.114, Speaker A: Yeah.
01:30:53.454 - 01:31:16.578, Speaker E: So, but the natural question is, all this optimization and your strategies ended up with a beautiful picture. And the details are very, very basic. Very interesting to know the exact details.
01:31:16.746 - 01:31:47.434, Speaker A: Yeah. So I don't know if I mentioned this before. So we are, when we are doing this, generating this configuration space, we are not doing any dynamics or anything, we are just laying out the potential energy landscape. So I don't know if you. By periodicity, you meant something about motions and things like that?
01:31:49.774 - 01:31:55.474, Speaker E: Well, it will be interesting to look at the connection, but I don't want to stop your flow here.
01:31:56.534 - 01:31:58.470, Speaker A: Yeah, it's okay. I mean, thank you.
01:31:58.582 - 01:32:02.570, Speaker C: Yeah, you might want to use the word sampling.
01:32:02.742 - 01:32:07.506, Speaker A: Yeah. Yeah. So we're sampling the configuration space. Yes.
01:32:07.610 - 01:32:08.454, Speaker E: Okay.
01:32:11.834 - 01:32:39.180, Speaker A: Yeah. So these are all samples in the configuration space. Yeah. Okay. So, yeah, this, this thing on top that looks quite ugly is, you know, the active constraint region with cartesian parameters. But as soon as you switch to Klee parameters, this becomes convex. It's just a 2d region.
01:32:39.180 - 01:34:10.224, Speaker A: And sampling here is so much easier. I can just do a regular grid sampling here, whereas here I would have struggled quite a bit to do that. Okay, so after we do all of these, we generate a lot of properties of the configuration space, which include potential energy basins and so on. But the next thing I'm going to talk about is this idea of finding paths in the assembly configuration space. So the idea is we start with a rigid configuration, and I'm given a source and a destination rigid configuration, and I want to drop one constraint at a time to reach from source source to a destination. That gives me kind of like a smooth one dof path. So all these configurations in the middle here, I get to each one by dropping a constraint, moving a little bit, adding a different constraint, then dropping another constraint, moving a little, and so on till I reach my destination here.
01:34:10.224 - 01:35:06.602, Speaker A: So we want to find a continuous motion path, and this path is made up of segments. So think of this as the path, and it has these little segments. So these little squares along the path, these are all rigid configurations. So I start from a rigid configuration, I drop a constraint, so I have one degree of freedom. So I kind of flex the molecule and end up in a different rigid configuration. Now I drop a different constraint, I get a flex, and I do this over and over again till I reach my destination. So if you look at the entire configuration space as a polytope, it's not going to be as nice as this cube.
01:35:06.602 - 01:36:24.438, Speaker A: But essentially what you're doing is starting from a vertex, walking along an edge to a different vertex, and then walking along a different edge to a different vertex, since, you know, you keep doing this over and over again till I reach my destination. Rigid configuration. So, as you can imagine, if I were to give you the original configuration space, this would be quite hard to do because, you know, it's highly non convex and disconnected and you wouldn't know where, you know, a 1d configuration would be. So it would be quite hard, but in easel, because we have kind of partitioned the configuration space and kind of arranged it neatly. When I start at a rigid configuration, if I drop an active constraint, I know exactly the configuration space, the 1d configuration space I'll be in. So I can traverse along that 1d configuration space and then add a different constraint and go to a different zero d configuration. And I keep doing this over and over again.
01:36:24.438 - 01:37:05.398, Speaker A: So this is what we call the atlas, by the way, that I showed you earlier, and the config. And you know what we show on the right? These are all rigid configurations, and these are all active constraint regions that have one degree of freedom. So. Yeah, so I don't think I've mentioned this before. Maybe I should. The easel sampling is not a one to one map to the cartesian sampling. It's a many to one map.
01:37:05.398 - 01:38:36.638, Speaker A: So each little configuration here, each Little Sample here, if you will, corresponds to finitely many different configurations in the cartesian parameterization. So whatever I've shown in pink here, all these correspond to the configurations that are pink in the upstairs as well. In the cartesian configuration space, there's some little gold colored ones here that correspond to these. But all these black configurations that I've shown, these correspond to, um, you know, configurations that have, you know, that belong in multiple of these different groups. So easels parameterization is, is a, is a many to one map. So, you know, if I have to do pathfinding in and, you know, and I have to traverse easels 1d region, it's, it's not as straightforward as, you know, just walking along a 1d region. So it's basically like sheet of pancakes of 1d regions that are stuck on top of each OTher, and, you know, they kind of attach only at certain places, and only there I'm allowed to switch between the different pancakes.
01:38:36.638 - 01:39:31.840, Speaker A: So here, for example, I've shown a 1D Kley configuration space. This entire set is one kili point. So is this and so on. So the split kind of shows that corresponds to many CaRTEsian configurations. So when I'm in a zero d node and I drop a constraint, I could end up in any of these different CaRTEsiAn configurations, and I can only traverse along ones that are connected by an edge. So if I traverse along these sequence of blue boxes, that represents a smooth one degree of freedom motion. So I cannot switch, for example, from this blue to this red unless a special thing happens.
01:39:31.840 - 01:40:33.342, Speaker A: So there are what are called tetrahedral bounds, where, you know, these flips, as we call them, meet. And, you know, if you have two such things meeting, then I can, for example, start from this pink little square here, move along here, and at this point, I can switch to the orange, and I can go. And this would still represent a smooth one day of motion. So that's not interesting. Okay, so I've given a source and a destination configuration. What I can do is I can first find out a sequence of these ads and drops. So start with a zero drop, an edge, add a different edge, and so on.
01:40:33.342 - 01:41:53.542, Speaker A: So I can figure out a sequence of ads and edge add and drops that will give me, that will get me from the source to the destination. So that is, I mean, that, that kind of tells me if there, if a potential path even exists. And once I do that, I'll have to go ahead and evaluate if after I drop a constraint from a zero d node and end up in a 1d node. If I can even traverse to a different configuration in the 1d node where I, you know, where I can add a different constraint. So all we'd have to do is at the outermost level, we call this the region flip graph. In the atlas, we just figure out a sequence of potential ads and drops that will give me, get me from the source to the destination, and in, and then within 1d active constraint region, I do the same thing. Sorry, I again define a different graph and traverse it.
01:41:53.542 - 01:43:03.642, Speaker A: So, putting it all together, let's say I'm in this source configuration. Let's say this is my source configuration. I mean, this source configuration, I can drop a constraint, I'll end up in the parent, and I can traverse this parent like, kind of flex the parent configuration to end up in a different configuration where I am allowed to add a different edge to end up in a different rigid configuration. And from here, I can drop a different constraint and end up in a different 1d active constraint region. And I can keep doing this over and over again till I reach my destination configuration. So I think I'll stop here. So we're working on a software that kind of finds these paths in the configuration space, and hopefully it will be completed soon.
01:43:03.642 - 01:43:43.334, Speaker A: Maybe on Thursday I can give a little demo. Oh, okay, I have this here. This is from an early version. So that was the source configuration at the beginning, and then these are all the different intermediate configurations it takes to reach the destination. There was some issue with this. We're showing more configurations than required, but hopefully on Thursday I'll be able to kind of show this working for all set of molecules.

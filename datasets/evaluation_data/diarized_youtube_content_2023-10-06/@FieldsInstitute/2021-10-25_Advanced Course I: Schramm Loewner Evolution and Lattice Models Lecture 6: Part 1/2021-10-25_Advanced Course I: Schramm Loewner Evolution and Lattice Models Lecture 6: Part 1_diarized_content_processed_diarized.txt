00:00:02.920 - 00:00:38.050, Speaker A: Good morning, evening, afternoon, wherever you are. Welcome everybody. And let's continue with today we'll start with discussing very elementary things like conditional expectations, martingales. But then it hopefully will quickly become more interesting. But first, I wanted to remind you some standard definitions. So, let's start with conditional expectations. Let us look at two sigma algebras in omega.
00:00:38.050 - 00:01:21.980, Speaker A: So omega for us would be this probability space. So there is also some way a probability measure there. And suppose that f is b measurable function. And suppose also that it has finite expectations, that essentially it's a number absolute value of f is integrable. So f is null one. Then I want to define conditional expectation of f with respect to subsigma algebra. So, this is unique, a measurable function, such that when you integrate it over any set from a, you get the same answer as you would get when you integrate f.
00:01:21.980 - 00:02:22.724, Speaker A: So you start this function, which may not be a measurable, which is just some coarse function, and then you try to make it a measurable. Such a function exists simply because if you look at this exciting functional from a to integral of f with respect to a, this is absolutely continuous measure, not necessary positive, but a measure on sigma algebraic. And so by radon nicotine theorem, it has density. So this is conditional expectation. And let me list some properties of it. So, first, an easy example, just to make you feel what it is. So, if you look at the dyadic filtration, that what conditional expectation do on each interval, adjust average of this function over this integral.
00:02:22.724 - 00:03:18.384, Speaker A: So you take average of the interval, and it's on this interval. So that's what conditional expectation with respect to dydic partition is for any measurable function. Okay? So sum is the properties. Well, obviously it's linear, because integral is linear. So conditional expectation of linear combination is linear combination of conditional expectations. Now, if sigma algebra a is subset of sigma algebra b, then if you first take conditional expectation with respect to b, and then take conditional expectation of this new function with respect to a, it's the same as if you started this conditional expectation of original function f with respect to a. So you kind of can remove the middle.
00:03:18.384 - 00:04:10.404, Speaker A: And the reason for this is that you can compare, just compare integrals with respect to any subset of sigma algebra a, of small sigma algebra, or of two sides, and they should be the same. They both should be integral of f. Because again, any guy here also belongs here. Okay, so another very important property, if h is immeasurable, you can take it out of the bracket. So in particular, expectation of function, which is already immeasurable is the function itself. And the proof is easy. First you check it for characteristic function for any set in a, because you know, for every set as a set, the intersection also belongs to a.
00:04:10.404 - 00:05:09.794, Speaker A: So it's easy to see that expectation of characteristic function of a zero multiplied by f is the same as you just restrict expectation by naught. And you just check that the integrals are the same. And then bilinearity is true for step functions. And then you can just pass to the limits, because again, you can the usual thing you do, dominated convergence, for example, and see that both integrals are the same. Okay, another very important property which we will use a lot. If f is independent on a, then the expectation is just constant. So what it means, it means that if you look at carefully at definition, it means that expectation or integral of f with respect of a is the same as expectation of f multiplied by probability of a.
00:05:09.794 - 00:06:12.198, Speaker A: But this is standard definition of independence. So, so again, when you take independent part, it just constantly. Okay, so with this preparation, again, I hope that most of the people who listen to this saw this definition before, and now why we needed this definition, we want to define Martin Gates. So if you look at the real valid ft adapted process. So remember, it means that xt is ft measurable and ft are getting bigger and bigger. So again, the way you should think about it, as time goes, you get more and more information. And let's assume that for every time you belong to l one, I'm not saying that supreme over all t is finite.
00:06:12.198 - 00:07:06.154, Speaker A: That's another condition. Okay, now, XT is called martingale if the following is true. If when you take s less than t. So, okay, I already wrote it here. So, expectation of XT with respect to fs gives you back access. So you should think of it as you get more and more information about your process as time goes on. But the information that you get by time s already gave you an average of what would happen at time tier.
00:07:06.154 - 00:07:52.964, Speaker A: Now, a submartingale is when this expectation is increasing, well, at least not decreasing. So conditional expectation with respect to fs should be at least excess. And finally, super martingale is opposite. Conditional expectation for activity with respect to fs is less or equal than excess. Okay, so this terminology should definitely remind you of our favorite harmonic, subharmonic and super harmonic functions. And again, we'll see when we talk about eta calculus. Then you apply harmonic function to a martingale.
00:07:52.964 - 00:08:31.984, Speaker A: Martingale, you get back a martingale, or at least local martingale. When you apply sub harmonic function gets sub martingale. When you apply super harmonic function, you get super martingale. So this is all great. But now just one comment, which is standard in financial mathematics, that although it's called super martingale, there is nothing super about it. So you see what happens here. If x represent the price of something, your average price actually decreases.
00:08:31.984 - 00:09:15.224, Speaker A: So if you are in financial market, you want to be in sub Martingale realm, not in super martingale realm. So just remark that martingale by definition is a process which is both submartingale and supermarting. Okay, so this is the definition. And again, I assume that many of you have seen it before, and this would be crucial to study notion. And let me do some examples here. The first is meta example. So we would actually love all martingales to be like this.
00:09:15.224 - 00:09:47.042, Speaker A: Unfortunately, they are not. Suppose that f is f infinity measurable. So remember, f infinity is a minimal sigma algebra which contains all fts. And suppose that it belongs to l one. And let's define fs to be expectation of f with respect to fs. Then I claim that it's martingale. Indeed, if you look of expectation of ft with respect to fs is the same.
00:09:47.042 - 00:10:29.318, Speaker A: Remember, definition of ft here, it's expectation of f with respect to ft. And then you take expectation of this with respect to fs. But remember, one of our properties of conditional expectations, this is expectation of f with respect to fs, because we can simply disregard this part. And so this becomes fs. So this is indeed a martingale. And again, this is the best martingale, because instead of studying the process, you can just study functions f, you can just study l one. Isn't that great? Okay, so just sub example to this example.
00:10:29.318 - 00:11:06.494, Speaker A: For diadic martingale, you can start with any function l one with respect to Lebeck measure. And then fn would simply be the average of this function on the diadic interval. So you take better and better averages. That's all. And this is, this is the same thing that happens in general. You take better and better averages. Okay, now let's look at Brownian Marshall.
00:11:06.494 - 00:11:47.954, Speaker A: It's also emergency, but not a great one. For example, it's not of this form, as we will see, but expectation of brownian motion with respect to fs. Bt with respect to fs, s less or equal than t. Let's write it down. It's bt minus B's plus B's, right? And bt minus B's, by definition of brownian motion is independent of fs. So that's just the definition. So what we left with this thing dice.
00:11:47.954 - 00:12:24.254, Speaker A: So expect, this is expectation of B's with respect to fs. And surprise, surprise, since B's itself is fs matchable, is B's. So, brownian motion is an example of Martin. And as we will see, on one hand, it's a bad example of martingale. It's not a martingale generated by single function. On the other hand, it's prototypical example of martingale. Any martingale with continuous trajectories is time change brownian motion.
00:12:24.254 - 00:12:54.358, Speaker A: Well, with some kind of edge. Another very important martingale is also derives from brownian motion. It's bt squared minus t. Indeed. Let's do the expectation of this. So conditional expectation of bt squared minus t with respect to fs. First, let's select an independent part, bt minus B's squared, that's independent of fs.
00:12:54.358 - 00:13:42.106, Speaker A: So we'll be able to throw it out. So, plus two btbs minus t minus B's squared with respect to fs. Let's see what it is. So this thing is dead now. Well, it's that, but it's, it means that we get expectation of this without fs. So we get t minus s here, so minus t here. And let's take B's out expectation of two bt minus B's with respect to fs.
00:13:42.106 - 00:14:25.654, Speaker A: And then we already use the fact that bt itself is a martingale. So this becomes b squared minus s. So this is yet another martingale, very important one. Finally, let's look at yet another brownian martingale, which is called exponential transform. And so this is more interesting. It's exponent of alpha bt minus alpha squared t over two. Well, first of all, it takes some time to check that it belongs to l one, but it does.
00:14:25.654 - 00:15:05.354, Speaker A: You just integrate it using just properties of normal distribution. And again, let's do conditional expectation. So we select the part which is t minus s related, the part which is s related. So use linearity. Then let's use Markov property. So we take this out. But what happens here, bt minus B's has the same distribution as Bt s.
00:15:05.354 - 00:15:52.674, Speaker A: So this whole thing becomes this multiplied by expectation of alpha bt minus s, which has normal distribution, v minus s variance. And then it's an easy computation that expectation of this guy is actually one that's actually characteristic property of brownian motion of normal distribution, which we already used when we derived fixed formals. So. Well, actually, sorry, we will derive fixed formals later today. So. Okay, so this is the first time we see it. And so what is left? So this is equal to one.
00:15:52.674 - 00:16:48.714, Speaker A: And we left with this, which is ys alpha. Okay, so here, the key word was that when you take a normal distribution, think about it as a normal distribution with this variance, alpha squared t minus s, and then you take normal distribution and subtract one half of its variance. The integral would be one again by change of variables. You just need to prove it for standard normal distribution in trivial computation. Okay, now I want to switch gears. So examples two, three and four were for continuous time. Now I want to do discrete time.
00:16:48.714 - 00:17:36.753, Speaker A: And this would be first instance of integrals that we see. Well, it would first be unclear why it is integral at all, but, well, hopefully it will be clear later. Okay, so what I want to do here is the following. I want to start with bounded predictable process. So the time is discrete now, and predictable process is a process which is measurable with respect to the previous sigma algebra with respect to n minus one. So the meaning of this, that at time n minus one, you can already predict what would happen with this process at time n. So this is called predictable.
00:17:36.753 - 00:18:07.754, Speaker A: And suppose that x n is a martingale. And let us do the following new martingale. Y zero would be just x zero. You start with the same, but y n would be the following. If you would want to get xn, you would just add xn minus xn minus one. But here you multiply it by this adaptive process. So why is it an integral? This is like Riemann sum.
00:18:07.754 - 00:18:54.158, Speaker A: So you integrate H dx discretely and you write a Riemann sum. Okay, so I claim that this van is also a martingale. So if you add predictable process to you multiple, rather you multiply increments of the martingale by predictable process. You get back a martingale. And this is great. So this is important statement. But as we all know, proofs of important statements are usually trivial.
00:18:54.158 - 00:19:41.022, Speaker A: So no difficulties here. Expectation of y n with respect to n minus one. It's, you write yn minus one plus h and x n x n minus one, y n minus one is fn minus one, measurable out. Hn, this is important, fn minus one, measurable out. And you are left with expectation of xn minus xn minus one with respect to fn minus one, which is surprisingly zero, because expectation of xn with respect to fn minus one is xn minus one, and x n minus one itself is already fn minus one, measurable. So the key thing was that we could take Hn out of the bracket. That's why we needed fn minus one measurability.
00:19:41.022 - 00:20:48.654, Speaker A: That's why we needed predictability. So, expectation of fin is y and minus one. By the way, one important remark which I always forget to make, but let me not forget it now, is that for discrete martingale, you actually don't need to check all the times, you don't need to check all the s and t. It's enough to check that at the previous time, the conditional expectation is the same as the value there. Because then if you have two different ones, you can go step by step down and use the fact that taking expectation with respect to big sigma algebra and then taking expectations with respect to small sigma algebra is the same as immediately taking it with respect to small sigma algebra. An easy remark, but it will save us some time. So again, it was enough to establish that when martingale in discrete time to check, that expectation there is back to f n minus one minus one.
00:20:48.654 - 00:21:48.820, Speaker A: So this is our new martingale. This is a way to construct martingales and notation for this would be the notation that traditionally is used for integrals. This is h multiplied by x, but with a dot here. So it's not h time x, it's this h x. And again, the way we obtained is inducted by making increments smaller or bigger by multiplying them by h n. Let's apply it to very important result. And this is, this would make a stopped martingale.
00:21:48.820 - 00:22:17.284, Speaker A: So suppose that t is a stopping time. And let's define x and t to be x at the time minimum n and t. So what it means is the following. You run your martingale till you hit time t, then you stop. T is a random time. So for some omegas you might be running up to infinity. For others, you stop.
00:22:17.284 - 00:23:06.230, Speaker A: And yet what you get is still a martingale, which is called stopped martingale. So far, again, we can prove that only discrete stop time martingale is a martingale. So again, the idea is that you just run your time till you hit the stop. And amazingly, what you get by taking x at this time is still multiple. Okay, so now let's take hn. This characteristic function of t big o equals n, which is one minus characteristic function of t elisa equals nine minus one. So it's predictable because this is by definition I find minus one measurable.
00:23:06.230 - 00:23:53.494, Speaker A: Because of this, I claim that x and t is actually h xn. Why? Because what is x and t minus x and minus one t? If we didn't yet hit time t. Then this is x n minus xn minus one. If we did, it would be zero. So they don't change. So the Merzingale stopped changing when we hit this time. So indeed this x and t is hxn when with this exciting function h.
00:23:53.494 - 00:24:35.090, Speaker A: So we get our theorem and we'll use it a lot, actually. Now let me prove another theorem. Again, we'll have much more general form, hopefully even later today. And this is called discrete optional stopping time theorem. So, suppose that XNb discrete time martingale and s and t b two bounded stopping time. This is very important here they are bounded. Let us define stopped sigma algebra.
00:24:35.090 - 00:25:11.984, Speaker A: So, sigma algebra generated by stopping timelines. So these are all set. Well, remember, what is fn? Fn is kind of what, you know, by timer. What is stopping time s. Well, you know that this is, this itself is fn measurable. Let's define a to be all set such that intersection of a with any such set s less or equal than n. There are just countably many of them, belongs to fn.
00:25:11.984 - 00:25:53.468, Speaker A: So again, the meaning of this is that this set kind of respect the stopping time. And since the claim is that excess, so this is value of Martin. So let me just show you how that it's not just logical statement. This is the value of your martingale at a random time. And I claim that this is just expectation of xt with respect to fs. Notice two problems here. First, that we only talk about discrete time martingales.
00:25:53.468 - 00:26:23.276, Speaker A: And second, that stopping times are bounded. Not just, they are not infinite. That would be a normal condition. They are bound. We would be able to significantly weaken both of these conditions, but we would not be able to completely remove them. And again, I hope to discuss later today why. Okay, so let's prove it.
00:26:23.276 - 00:27:33.324, Speaker A: That's not too complicated. Let's take our two stopping times, tns and m be our bounds. So m in natural numbers, which is bigger than any of them. And without loss of generality, we can assume that x zero is zero, because otherwise we just subtract x zero from xn. Doesn't affect any of the calculations here. And let Hn will be a characteristic function of this set, as before, t big or equal, z minus characteristic function of s. Again, predictable process, because a difference of two, predictable process.
00:27:33.324 - 00:28:39.368, Speaker A: Okay, notice that if n is bigger than n, then both of them already stopped. So hxn is just xt minus xs. Okay, so expectation of the difference of xt and excess is expectation of Hxn, which is expectation of h of zero, which is expectation of x zero. And we took x zero to be zero. So this is zero. So expectation of xt is equal to expectation of xs. Again, what we used, we used our integration sync with, now this function, okay, but that's not yet this all we are saying that the expectation is the same.
00:28:39.368 - 00:29:30.744, Speaker A: But now let us fix b in fs and let us consider new stopping times. On b, it would be s on m, it would be on complement of b. It would be m. So by, and the same with t Tilde, t on b m on bc. Then by definition of fs, by the very definition of fs, this is a stopping time because b belongs to this fs. So that's actually the condition that for any, so b belongs to fs. If this function is stopping time.
00:29:30.744 - 00:30:09.410, Speaker A: Uh, so if y and n, this is true. So now still then t tilde lesser equals nm. No problem here. Now, expectation of xt on B. So that's, remember, that's what we want to compute. So want to say that this part is equal to this part. So then that would mean that access to the conditional expectation of xt.
00:30:09.410 - 00:31:20.504, Speaker A: So again, we took any bmfs and want to check that this is equal to this. Okay, so now this is print. This is expectation of x t tilde. So let's see, why is it true that this is expectation of x, t tilde minus m, p of Bc? Because what is expectation of x t tilde? It's expectation of xt on B plus m, expectation of one on complement of B. So minus m, probability of Bc. But what we already know that we can apply this thing to t tilde and s tilde. So we have that this thing is the expectation of x on t tilde is the same as expectation of x s tilde.
00:31:20.504 - 00:32:22.984, Speaker A: Again, minus m, probability of complement of b. And surprise, surprise, this is exactly what we need, this expectation of excess on b. So we just proved this. And again, where we used definition of fs here, wanted both of these guys to be stopping times. So actually here it was enough to assume that b belongs to ft, which is a finer than fs. Okay, so just a remark here to the theorem. If you have a super martingale, then exactly the same proof would give you that either XT increases the conditional expectation or decreases.
00:32:22.984 - 00:33:16.944, Speaker A: So one fine thing there is to check that here. If you start with SAP a super martingale, get SAP a super martingale. But again, this is the proof is exactly the same. Just instead of equality, you would have an inequality here, because this would be positive or negative, and then everything goes through this. So we mostly, we will mostly use it for martingales. So I wanted to present it in this generality, but for, just wanted to let you know that for Saban super martingales, it will be exactly the same. Okay, so let's move to more interesting stuff now.
00:33:16.944 - 00:34:00.480, Speaker A: Let's move to maximal inequalities and real optional stopping types here. So what would happen here, actually, really, really reminiscent of theory of hard spaces in the disk or in the half plane, there will be maximum function. There will be convergence to the limit in HP when p is bigger than one and there are some conditions in h one. And everything is very, very similar. And again, it's not surprising there are some precise connections. More than that, there will also be a hard displacement. We will discuss stochastic integration.
00:34:00.480 - 00:34:46.293, Speaker A: So this theory should be really familiar. Well, what happens here should be very reminiscent to the people in this program of what happens in their well known hard spaces. Okay, so let's start with the definition, which is again just from hard space or single integrals realm. Let XTBA process. The maximum function is simply the maximum value of this. So this is supremum of x tier. It's a random number.
00:34:46.293 - 00:35:43.384, Speaker A: It's a random because random variable, because again, for each omega just supreme of all vectors. And as you know, by the way, if you plug in here, brownian motion, since brownian motion tends to infinity, almost surely the supreme would be infinite. So for brownian motion, this doesn't quite work. Okay, but again, we define it for any process here. We don't assume that it's martingale, sub martingale, super martingale, semi martingale, or just any process definition is independent of Einstein. Our first theorem deals with very easy case of not just discrete but finite time. So this is a submarting view.
00:35:43.384 - 00:36:51.836, Speaker A: And the claim is that for every positive number, lambda probabilities that you are bigger than lambda is kind of bounded by normal Markov bound one over lambda integral, but integral of what? So Markov bound would be integral of x star. But here I claim that you take the integral of x n the last time. So lamb, the probability that you are bigger than lambda is actually bounded above by the integral over the set where this probability is bigger than lambda of xn. So x n, remember, is the last time. That's why we take finitely minor. Eventually we'll of course generalize ethereum to the situation where the indices are infinite. And you would just know that this integral stays and stay globally bound.
00:36:51.836 - 00:37:35.904, Speaker A: But let's see. Okay, so now let us prove it. First, let us observe that absolute value of xn is by itself a sub martingale. That's just convex, the inequality. And let's define a stopping time t. So this is either the first time you are above lambda, and this happens if and only if maximum function is at least lambda and there is no n here. Sorry.
00:37:35.904 - 00:38:17.234, Speaker A: If x star lambda is bigger, x is bigger than lambda, and let it be n capital. Otherwise, so if we didn't reach lambda, that's it. So this is stopping time. T is a bounded stopping time. So by our discrete optional stopping time theorem, expectation of xn is bigger equals an expectation of x t. Oops. I promised you that I will mostly use optional stopping time theorem for martingales, and here I immediately use it for sub martingale xn.
00:38:17.234 - 00:39:41.134, Speaker A: Sorry. Okay, so what is expectation of xt? That's the expectation that the integral over the set the x star big o equal to lambda of x star. So this is the maximum plus this plus integral of x n on the remaining on the set where x star is less than lambda. Of course, this integral is at least lambda, p of x star bigger equals than lambda. Now let me make a correction. So here, of course, if you look carefully at this, this is not, this is x t just when x star is bigger than lambda, this is bigger equals than lambda. So we can just write lambda probability of x star bigger equals than lambda and plus this integral.
00:39:41.134 - 00:41:09.434, Speaker A: And now you just subtract this from both sides to get exactly the same, because after you subtract this, what is left is the integral of xn on the side where x star is bigger equals on lambda. Okay, so that was relatively cheap estimate. Let's see what we can do using this in more general consideration. So, first comes the maximum equality for p bigger than one. So let x t be a sub martingale and assume that it has the continuous trajectories. Yes, if index is either real line or non negative real line, then the claim is that if this is bounded, if the supreme number all t of lp, norms of xt is bounded, then expectation of x star to the p is also bounded. So x star also belongs to Lp.
00:41:09.434 - 00:41:56.934, Speaker A: And there is this precise bound p over p minus one to the power p. Okay, so this again very much reminiscent to theory of hp spaces for p bigger than one. Maximum function belongs to lp. Always if you uniformly over the disks belong to Lp. So if you belong to hard space. Okay, so how to do it. Let us first prove it for finite time.
00:41:56.934 - 00:42:49.254, Speaker A: So we use what is called layer k principle. Let me be the law of this x star. We know that x star is now finite and well defined. So let's estimate lp norm of it. So by standard layer kx, this is lambda to the pd milder. And we can also rewrite it by Libyako again, Lake principle as p lambda to the p minus one probability of x star big equal to lambda d lambda. And here we use our estimate that this is bounded by this divided by lambda.
00:42:49.254 - 00:44:28.344, Speaker A: So this is p lambda p minus one one over lambda integral of on the set x star big lambda x n dp. So then we just use Fubini to see that this integral is actually this p expectation of absolute value of x n multiplied by integral of lambda p minus 2d lambda from zero to x star, because lambda is less or equal to x star. So this is p over p minus one expectation of x n times x star to the power p over p minus one. We simply compute this integral and then we just use young inequality that this is p over p minus one lp norm of this of x star, lp norm of xm. And then we just, you know, divide both sides by this and get this inequality, but only for not just discrete, but for finite time. Okay, so for finite time, again, so of course I did all the details here, but this calculation should be very familiar to anybody who did any sort of single integrals. This is vehicle one estimate.
00:44:28.344 - 00:45:15.754, Speaker A: Of course it implies something like this for lp estimate. But again, this is a standard proof which works not only in probability, but everywhere. Now let us do it for discrete time. So let n go to infinity. So let's define extend star. So it's a maximum function up to time n it increases and conversion to x star, of course. And for each n expectation of p's power is bounded by this.
00:45:15.754 - 00:45:57.686, Speaker A: Of course it's bounded. This integral is bounded by supreme of all the integrals. Of course they're increasing, because again x n to the p is also submerting. So of course expectations are increasing, but so this is all uniformly bounded. So monotone convergence would give us that expectation is the limit of the expectations of these guys is uniformly bound, end of story. For discrete time. Now, continuous time, so continuous time is slightly more interesting.
00:45:57.686 - 00:47:23.174, Speaker A: And this is a standard argument, which I will do for everywhere. But let me do it carefully here. First, let us know that by continuity, to define x star, you just need to take supremum of xt, well, absolute value of xt, of course, over only over rational numbers. And then let us represent rational numbers as union of finite sets, increasing union of finite sets. And then this x n star, which is maximum over these guys over values of x t on t, in the end, would increasingly converge to x star, and the same estimate would hold expectation of x star to the p would be the limit when n goes to infinity of expectations of x n to the p, which are bounded by the same supreme. So again, the same trick, but with continuous time. Since you have uncountably many things, you need, well, two steps here.
00:47:23.174 - 00:48:24.284, Speaker A: First, you go to rational numbers, which you can do by continuity, and then you exhaust everything by finite sets. And for finite times, everything is great. Okay, so now, as a corollary. Well, it's not a corollary, it's kind of extra statement. If you have a sub martingale, which has continuous time, which is continuous. If your time is continuous, then you have vehicle one inequality. So probability that maximum functions and lambda is actually bounded by supreme of the expectations, if they have bounded expectation of absolute value divided by lambda.
00:48:24.284 - 00:49:20.004, Speaker A: Okay, so the proof is actually absolutely the same. You do exactly the same discrete approximation as we did here. Well, not just discrete finite approximation. So this corollary is companion statement. Okay, now this is the first limiting theorem, which we will significantly improve. Let x t be a submartingale which is continuous. If your time is continuous as usual, and suppose that supreme is bounded, then the claim is that when you go to infinity, lim soup of absolute value of Xt is actually finite almost everywhere.
00:49:20.004 - 00:50:09.054, Speaker A: Okay, so this is actually very huge statement if you think about it, because what we are saying here is that we just have a process. All we know that it's a martingale. You know that expectation of absolute value of Xt is bounded uniformly. And then it turns out that the process doesn't tend to infinity. So brownian motion is definitely a lot like that, right? Well, proof is trivial. Probability that this limp is bigger than one over epsilon is bounded the probability that it averaged value bigger than one over epsilon. So it's less or equal than probability that maximum function is bigger equals than one over epsilon.
00:50:09.054 - 00:50:48.654, Speaker A: And as we know from the previous corollary, this is bounded by epsilon suprema of expectation of x t. So if it's infinite, it's true. For every epsilon, probability of such an event is less than epsilon multiplied by something for any epsilon. So it's zero, end of story. But this is actually very weak theory. We'll see a bit later that more is true that actually there is a limit, but that we'll discuss after a ten minute break. So let me start.

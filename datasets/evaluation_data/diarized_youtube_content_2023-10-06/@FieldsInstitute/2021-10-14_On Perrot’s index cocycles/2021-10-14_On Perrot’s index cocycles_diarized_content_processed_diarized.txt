00:00:04.080 - 00:00:15.994, Speaker A: Okay, so it's my great pleasure to introduce our next speaker this morning, Nigel Hixson from Penn State. His title is on Pero's index co cycles. Nigel, please.
00:00:16.774 - 00:00:21.834, Speaker B: Thank you very much, mister chairman. What time should I stop?
00:00:22.934 - 00:00:32.124, Speaker A: Well, the standard time limit is 50 minutes plus ten minutes for. I mean, that's the standard for everyone, right? So, I mean.
00:00:32.784 - 00:00:41.160, Speaker B: All right, I'm putting a little note that I'm going to aim to stop at 1105 Eastern standard time, 11:05.
00:00:41.232 - 00:00:44.080, Speaker A: That's fine. I mean, good.
00:00:44.272 - 00:01:07.244, Speaker B: Thank you very much. So thank you to all of the organizers for the invitation to speak here. Thank you to all of the participants for tuning in. It's a great pleasure to be with you, wherever you are. I'm going to talk about. It's a sort of public service talk. I'm going to talk about a paper that I've spent years trying to understand.
00:01:07.244 - 00:01:41.520, Speaker B: I think it's a very frustrating paper because it's been extremely difficult to read. But at the same time, I think it's really a remarkable piece of work. And the more I read it, the happier it makes me. So I'd like to try and share some of the joy with you. Co workers are on this, who are written on the slide. Jonathan block down the road at UPenn, and Jesse Sanchez, who's here at Penn State, is a student of mine. And over the years, I spent a lot of time chatting with Rudy Rodson, who was Denis Perot's student about this.
00:01:41.520 - 00:02:27.218, Speaker B: And so I certainly benefited a lot from those discussions. Okay, here's the paper that I want to discuss with you from a little while ago. Now, if you like. It's a proof of the index theorem, but I think it's really much more than that. It's an extremely interesting new calculus related to index problems, and it's more the calculus that I want to describe than the final result, the index theorem. After all, we already know the index theorem is true. And when you read this paper, you can't avoid thinking that you've seen parts of the paper, various parts before in various places.
00:02:27.218 - 00:03:19.644, Speaker B: For example, in the work of Kasparov on his index theorem, the work of Goetzler, of course, on the local proof of the index theorem for the Dirac operator, the Matai Kulin work on calculating Tom classes, the local index formula that we heard yesterday of Khan Moskovic. That's certainly very suggested, very much suggested by this work. However, the more you think about it, the more it seems that this, this paper of Denis is different. It's it's really a remarkable piece of, excuse me, a remarkable piece of work, and it doesn't seem to quite be the same as any of the things I just mentioned. Okay, so I'd like to try and introduce you to it. First of all, the overview, after which you can fall asleep if you're not terribly interested in what's going on. Here's what Perot did.
00:03:19.644 - 00:04:04.718, Speaker B: He built two periodic cyclic co cycles, actually four, because there are two different versions of his theorem, but let's call it two. And they look like JLO co cycles, which to this audience doesn't need too much introduction. But as opposed to GL Oco cycles, there's no Hilbert space in sight. There are no trace classes operators in sight. There is a Dirac operator, which you use to build the JLO co cycles, two Dirac operators, in fact, but they're not elliptic, they're not Dirac operators in the ordinary sense of the term. So it's all very different and intriguing. Anyway, the two co cycles are basically the same.
00:04:04.718 - 00:04:40.582, Speaker B: They're both JLO co cycles, both involving a Dirac operator. And the squares of these two Dirac operators are basically the same as I'll show you as we go along. But then something rather interesting happens. First of all, by virtue of the fact that the two co cycles are basically the same, it turns out that they are, in fact, cohomologous. But one of them directly relates to analytic index. One of them is exactly the so called radulco cycle from the theory of central extensions of the algebra pseudo differential operators. And so it's known to be directly related to the analytic index of the tyrian singer.
00:04:40.582 - 00:05:17.772, Speaker B: On the other hand, if you calculate the other one, which is what I'm mostly going to be concerned about today, what you find is exactly a current Durham current. So this co cycle is actually just a Durham current, and it's the tart class, or the dual of the Todd class at point ray dual. And so the fact that these two co cycles are the same is the index formula. But as I say, I don't think the index theorem is the main point here. There's just a remarkable new calculus in this paper that deserves to be studied. Okay, so here's what I should like to do. I'm not exactly going to go through Perot's paper.
00:05:17.772 - 00:06:16.004, Speaker B: I'm going to take a sort of semi classical limit of Perot's paper and describe a simplified version, which is a little more geometric in nature. So I shall be barely talking apart from these introductory slides. About pseudo differential operators at all. Instead, I'll be talking about functions on the cotangent bundle, which are more or less some semi classical version of pseudo differential symbols, and differential operators on the cotangent bundle as well. And the interesting thing is that these differential operators will be of infinite order. There will be some indeterminate in the algebra which will allow me to form infinite formal series, and so these will be infinite order differential operators. So the two things I would most like to do, I describe this algebra to you on the one hand, and on the other hand, describe the trace or super trace that Perot builds on this algebra.
00:06:16.004 - 00:06:45.070, Speaker B: These define the stage, if you like, on which Perot's work is set. So these are the main two things I want to do. There's a small parenthetical remark. This super trace is actually defined on a bimodule, not on the algebra itself. But we'll get to that in due course. So, everything that I'm going to tell you is due to Perot, except I took, as I say, some kind of semi classical limit. I formed some, I don't know, associated graded version of Perot's work.
00:06:45.070 - 00:07:31.114, Speaker B: And then it looks simpler, and it's more suitable to introduce to you, I hope. Well, let's talk about index theory. So there also have to be spinners of some sort in Clifford algebras and so on. So I'm not actually going to be talking about scalar differential operators, but operators acting on the sections of a certain Clifford algebra bundle built out of both the cotangent bundle and the tangent bundle. So I'll form what the geometers call the generalized tangent bundle bundle, which is just the direct sum of the cotangent bundle and the tangent bundle. This is originally over M, and I'm going to pull everything back to t. Then I'll be looking at differential operators there, and among them is a Dirac operator D.
00:07:31.114 - 00:08:20.370, Speaker B: This is one of the two Dirac operators that Denise studies. And I want to say right away, I already did, but I'm writing down a formula to show it to you right away. It's not an elliptic operator. When you square this operator in the standard canonical coordinates on the cotangent bundle, what it looks like is what you see in the red box. Well, there's a formal parameter epsilon, but then you see DDX times DDP, and it's not therefore elliptic at all. And that's related to the fact on this generalized tangent bundle that the natural metric in quotation marks is an indefinite form, the natural way of pairing cotangent vectors against tangent vectors has signature nn, not signature two n comma zero. Okay? And so we have an interesting algebra with an interesting supertrace.
00:08:20.370 - 00:08:58.094, Speaker B: We have a Dirac operator. And finally, there's a simple way of including functions, the function algebra, for the codesphere bundle, into our interesting algebra curly c. And now we have three things. We have an algebra, it's just the commuted up algebra of functions. On the cosphere bundle, we don't have a Hilbert space, but we have a supertrace, which would be, which we would have if we did have a Hilbert space. And we have a Dirac operator, which is not elliptic, but oddly enough, that doesn't matter. And we have some sort of version of a spectral triple, except there's no spectrum and no Hilbert space.
00:08:58.094 - 00:09:21.026, Speaker B: So as soon as you have this data, it's sort of natural to try to write down some kind of JLo co cycle. And that's exactly what Perot did. And what I'll try to discuss very briefly. The cyclic part I'm actually not going to say too much about in this class. Of course. In JLo, there's an exponential. You take D and you square it and you exponentiate it.
00:09:21.026 - 00:10:03.634, Speaker B: And that's a crucial ingredient. And here we're going to do that just by taking the formal power series for the exponential function. No functional calculus whatsoever. Nevertheless, we'll get a well defined cyclic co cycle, and then I'll describe roughly how it's calculated and the fact that this co cycle is on the nose, even though it comes from a Dirac operator in this way, in this odd way, it's on the nose, a current. It's just the Todd class, as you see in this formula. And the calculation is rather interesting in many respects. I'll focus on just two things, which, the first of which is our own modest contribution to this, and the second of which is just lifted from parole.
00:10:03.634 - 00:11:05.264, Speaker B: The first thing is that this operator, and the cyclic co cycle that you build from it, has an interesting sort of rescaling property, which is expressed on the tangent groupoid. And what you find when you look at how this operator behaves on the tangent groupoid is that the operator behaves like an operator of order zero, despite it being that I'm talking about d squared, despite being a second order partial differential operator. So somehow, Perot is taking advantage of some strange feature of this operator, which gives it, formally or geometrically, order zero. That's maybe worth contrasting with what Ezra Getsler does in his calculus, where the operator has order two the operator and its order don't change. On the other hand, the manifold is given dimension zero by introducing some super variables. So it's different from what Perot does. Anyway, whenever you have an index theorem, you always ask, where does the Todd class come from? And here it comes from ancient history.
00:11:05.264 - 00:11:39.874, Speaker B: It comes from what Schur did to calculate the derivative of the exponential map. So the Todd class is explained in an extremely simple way, as we'll see in at the very end of the talk on very last slide. Okay, just a couple of quick remarks about pseudo differential operators. I don't want to say a lot. I don't have time to say a lot, and it's actually not necessary for me to say a lot here. Of course, there are pseudo differential operators. Each pseudo differential operator has a complete symbol, which is the class of the pseudo differential operator, modulo smoothing operators.
00:11:39.874 - 00:12:07.248, Speaker B: And it's this quotient algebra of complete symbols, which is what Perot focuses on. This is an extremely complicated algebra. Oopsie. What's going on here? There we go. Sorry about that. But it has a filtration by the usual notion of order. And if you study the constituents of the associated grade at algebra, what you find are very simple spaces.
00:12:07.248 - 00:13:11.428, Speaker B: They're just homogeneous or polyhomogeneous functions on the cotangent bundle, like you see in the definition and the way that the multiplication works in the associated graded algebra is just point wise multiplication. So although the algebra of pseudo differential symbols is very, very complicated, it has a degeneration which is just a commutative algebra, the commutative algebra of polyhomogeneous functions on the cotangent bundle, to put it maybe a different way, the algebra of symbols is a deformation of this commutative algebra of functions. So I shall work on the easy commutative algebra, where nevertheless, most of Perot's calculations live. And the full story requires lifting to pseudo differential symbols. But most of the work, and I think a reasonable introduction to the paper can be carried out just on this degeneration, this commutative algebra. All right, a couple of small, not small at all, important structures play a big role in Perot's work. One of them is the Vojitsky residue, or the residue trace.
00:13:11.428 - 00:13:54.078, Speaker B: And I won't say so much about it here except to remind you that if you have an operator of order minus n or a symbol of order minus n, this non commutative residue, which is in general extremely complicated, is easy to calculate. It's just given by an integral of the principal symbol. And the second thing that Denis uses is the so called radical cocycle, which I mentioned before. It's a cyclic one cocycle which is built out of the trace and the derivation which preserves the trace and the derivation. It's not so important what it is. It's an outer derivation. And the key fact which is important is that the Radl co cycle is intimately related to analytic index theory.
00:13:54.078 - 00:14:25.710, Speaker B: If you know the Radl co cycle, then you know the Fredholm index. Okay? This is work that Denny did prior to the work that I'm describing today. All right? So let's try and build some algebras of infinite order differential operators. First of all, let's. Well, let's just go to it. I was going to say something else, but I shot. I want to look at differential operators on the cotangent bundle.
00:14:25.710 - 00:15:08.142, Speaker B: I want them to have polyhomogeneous coefficient functions, basically polynomial coefficient functions in the cotangent directions, in the fiber directions. If you want to make that precise, you should use the Euler vector field. And what I'm doing is I'm looking at operators which are in the eigenspaces, the integer eigenspaces of the Euler vector field, okay? It's differential operators on t of m and in the fiber direction. They're just homogeneous in the way I've just described. Okay? Order zero operators are just polyhomogeneous functions. And that's this degeneration of the symbol algebra that I was mentioning. It's just the associated gradient of the symbol algebra.
00:15:08.142 - 00:15:48.256, Speaker B: So this algebra that I'm building is not some commutative counterpart of the algebra of symbols. It contains a commutative counterpart of the symbols in order zero. And then there's more stuff too. And I'm going to build a much bigger algebra by introducing a formal variable, epsilon. And this bigger algebra will lie somewhere between polynomials in epsilon with coefficients, which are differential operators and all formal power series. And it's important to note that you can make an obvious sheaf out of this. You can restrict to any open subset.
00:15:48.256 - 00:16:29.866, Speaker B: And the reason it's important is that the Laplacian that I wrote down before associated to a coordinate system will play a big role in this. And so we shall frequently want to restrict to open subset. I should like to build an algebra. This would be ideal for which the exponential of epsilon times delta is a member. That's not actually what happens, but it's close to what happens. The reason for introducing this formal variable is to be able to handle the exponential of epsilon times the Laplacian. It doesn't quite work out that way, however, and there's a small compromise that's going to be made in a little while.
00:16:29.866 - 00:17:10.134, Speaker B: By the way, this operator delta needs to be treated with a little bit of caution. It definitely depends on the coordinates, and so you need to be a little careful as you manipulate. As for what this algebra is, which is intermediate between polynomials and formal power series, it actually doesn't matter that much. There's a whole continuum of algebras defined by different conditions that you could use. And we want the algebra a to be not too small for a certain purpose. It should be invariant under conjugation by this exponential, which is certainly some formal power series. So it makes sense to conjugate.
00:17:10.134 - 00:17:49.818, Speaker B: That is, if you like a lower bound on the size of a of t star of m. It has to be big enough that it's invariant under conjugation, but it also needs to be small enough that we can build this interesting trace. But these are kind of relaxed conditions and there's a lot of room in between for different definitions of a. You shouldn't think of a as being a really important object just by itself. It's more the trace which is important, not the algebra a. It's a bit like when you do functional analysis in index theory. You have to, you know, you have to choose some kind of space of functions, and exactly which space of functions you choose, it doesn't matter that much.
00:17:49.818 - 00:18:30.754, Speaker B: Maybe you're a fan of Hilbert spaces, so you use l two. Or maybe you're a fan of some fresher space, so you use c infinity. It doesn't really matter. They all give rise to the same result in the end. Okay, so let's take our algebra of differential operators on t star of m, which have polyhomogeneous coefficients, and let's filter it. When you think about doing that, you see there are all sorts of different filtrations floating around, and that's part of the, that's rather important for what's going to come. First of all, there is the Euler vector field, which I mentioned before, and it acts by conjugation by the bracket on differential operators.
00:18:30.754 - 00:19:13.364, Speaker B: And by definition, our algebra differential operators is graded by this action because it's the direct sum of the integer eigenspaces. So there's a total vertical order given by the Euler vector field. Secondly, these are just partial differential operators, so they have a usual partial differential operator order like you always have on any manifold. And thirdly, you could just look at the number of derivatives in the horizontal direction. In other words, anything that happens in the vertical direction, you could assign order zero to all of the ddps, you could assign order zero to and just count the number of ddxs. And that'll give you what I'm calling here, a horizontal PDO order. And I wrote a little table to show you how they work.
00:19:13.364 - 00:19:59.660, Speaker B: All of the coefficient, all of the coordinates on the manifold always have order zero. But then the DDXs and the DDPs have different orders depending on how you choose your filtration. What we're really interested in is some interesting combination of them, which I've written at the top of the slide. I just called it the helpful order, because again, I emphasize there's nothing unique about this fellow and you shouldn't attach too much meaning to it. It's just a suitable order which builds an algebra which is neither too big nor too small. The reason for writing down the actual formula is that if you choose to read Denis paper, you'll be confronted with this on one of the early pages. Basically the beginning, right at the beginning, when he gets to work.
00:19:59.660 - 00:20:30.464, Speaker B: And so it's helpful, it's useful to know where everything comes from. So here's an order which is a little bit ad hoc. It defines a filtration on the algebra of partial differential operators on T. How does it work? Well, usefully, the Laplacian has order two. That's good to know. On the other hand, the derivatives in the vertical and horizontal directions have strange orders. Yeah, so that's just something you have to get a little bit used to.
00:20:30.464 - 00:21:15.044, Speaker B: Anyway, we now define some algebra of formal power series just by looking at formal power series whose coefficients have helpful orders bounded by the degree of the exponent, bounded by the exponent of epsilon, maybe plus some extra number. Pretty standard thing to do. After you've done all of this, you can immediately experiment by looking at whether or not the exponential of epsilon times delta is in the algebra. And, well, it isn't, because delta has ordered two and epsilon multiplying Delta just has order one. So you can see right away that this is not going to be an element in the algebra. Nevertheless, this algebra is going to be good for us. Okay, so this algebra is indeed large enough.
00:21:15.044 - 00:21:58.436, Speaker B: The helpful order is compatible with Lee. Bracket by Del. The bracket by delta only increases the helpful order by one, which is the sort of thing that you need to manipulate power series. It's very reminiscent of what you see in the Muskovic paper on the local index theorem that Henry was talking about yesterday. And so it follows that this algebra is invariant under conjugation by exponentials of delta, even though the exponential of delta is not in the algebra itself. You definitely don't want to do this in the world of analysis, because the operator you're conjugating by is far from invertible. But algebraically speaking, you can do this.
00:21:58.436 - 00:22:45.228, Speaker B: The second interesting thing is that if you choose two different systems of local coordinates in the same chart, then you'll get two different exponentials of Epsilon Delta. And they're not the same, but they're multiplicative different. Their difference, their quotients quotient is an element of our algebra, because the difference between delta and delta prime actually has rather small order. It has quite big order in the traditional sense of partial differential operators, but small, helpful order. That's part of why the helpful order is helpful. And thanks to that second fact, there's a well defined vector subspace of all formal power series, which is the algebra a times the exponential. That doesn't depend on the choice of coordinates.
00:22:45.228 - 00:23:22.834, Speaker B: I don't know how to define this thing in an invariant coordinate free way, but it is invariant and coordinate free, and it's a bi module. It's invariant under both left, that's obvious, but also right multiplication by elements of the algebra a. So it's an a bimodule, a free a bimodule. And this is the, sorry for the spelling mistake there. This is the bimodule that we shall be working with because it doesn't depend on coordinates. You can patch together and build a canonical bimodule in the global context of a manifold M. And that's exactly what we shall do, following Perot.
00:23:22.834 - 00:24:16.664, Speaker B: And yeah, now I wanted to find a trace on this bime module. Okay. Strictly speaking, if m is not compact, you need to look at compactly supported elements in the bio module, compactly supported in the m direction. But I'll ignore that detail. So now we are going to define the trace, the analog in this purely algebraic world, of the usual trace on Hilbert space, on operators, on Hilbert space. And there are several stages to the construction, some of which are kind of simple, but others of which are rather inspiring, I would say, or inspired by Peru. So we shall, roughly speaking, integrate, in order to get a number, the coefficients of differential operators separately from the operators themselves.
00:24:16.664 - 00:25:16.384, Speaker B: So we're going to handle, in local coordinates, translation invariant operators, constant coefficient differential operators one way, and then we're going to handle general variable coefficients another way, and then we'll combine everything to get a trace, and then we'll, of course, prove that it really is a trace as for the integral on functions, this is a sort of poor man's version of the Wijitsky residue. It's just, it retains just the tiniest little hint of non commutative residue, namely, if you have a polyhomogeneous function, you can just, it's graded by order, this algebra of polyhomogeneous function. So you can just select the order minus n component without issue and integrate it. And the way you integrate it is you identify order minus n functions on the cotangent bundle with top degree forms on the cosphere bundle. That's a standard trick in symplectic geometry. And then you just integrate the form. That's simple.
00:25:16.384 - 00:25:45.228, Speaker B: As for the coefficients, excuse me. As for the constant coefficient differential operators, here's what we're going to do. This will make Emil happy. This is what the physicists do. If you have a polynomial times an actual Gaussian, let's say, is a positive definite matrix in this top display. Then, of course, you can integrate the polynomial times the Gaussian. And there's a formula for what you get, which every physicist knows, it's taught to them in childhood.
00:25:45.228 - 00:26:36.528, Speaker B: And here it is, and it's, you have to do something with the polynomial to explain its contribution. And you just take various derivatives of the polynomial according to the value of the entries of a. Okay? And so we'll do exactly the same thing, if you like, under Fourier transform and then some kind of wick rotation. We'll do exactly the same thing for these gaussian expressions involving just differential operators. If I have a polynomial in ddxs and ddps times my exponential, I'll just plug them into the formula above. I'll just do what would apparently come natural to a physicist, and then I'll get, well, I won't necessarily get a number, because this formal variable, epsilon, appears. I'll get something which is a Laurent polynomial in epsilon.
00:26:36.528 - 00:27:16.294, Speaker B: And it's a little important to be worried about just how many negative powers of epsilon are going to be involved here. I won't go into that in detail, but there's a little, you might see a little asterisk a couple of lines down. So I'll do a little bit of worrying on the next page. All right, so here's how we're going to define a trace. Take a formal power series in epsilon, whose coefficients belong to the algebra of ordinary differential operators on t of U. So that thing is made up out of a whole bunch of terms which look like a power of epsilon times a function, times some derivatives in the x direction. Times some derivatives in the p direction, times r, exponential.
00:27:16.294 - 00:27:51.924, Speaker B: Okay. And what I'm going to do is I'm going to take the derivatives and the exponential and apply the procedure above to them. And out we'll pop just the function times epsilon to the k. And then I'll just collect together all of the contributions I obtain in this way. And I'll pick and what I'll get. I guess I wrote that. On the next slide, what I'll get is some kind of morphism from our bimodule into polynomial functions with epsilon adjoint Laurent polynomial series in Epsilon.
00:27:51.924 - 00:28:33.944, Speaker B: Pretty much, but not exactly. There is a little problem here, which is that when you do this gaussian integration, you'll collect lots of negative powers of epsilon. And so what you find is that contributing to the traces I tried to define it, although intermediate traces I tried to find it on the previous page, are infinitely many terms attached to any single power of epsilon. And now it looks like we're back in the world of analysis. You have to add together infinitely many things. So that's a bit of an issue. And it's here where you need to take some steps to make sure that the algebra a is small enough.
00:28:33.944 - 00:29:21.864, Speaker B: And according to the definition of a, this will only happen in a situation where the corresponding orders of the coefficient terms, the homogenized orders of the coefficient terms, converge to minus infinity. Since the integral that I, as I describe it, of these coefficient functions, vanishes on any function of order less than minus n, we don't have to worry about this infinitude. It's not really there. So, in summary, the trace is defined in the following way, as you see at the bottom. First of all, you integrate out the differential operators to just leave the coefficients, and then you apply this residue trace to integrate out the coefficients to just leave a Laurent series in Epsilon. And finally, we'll select the coefficient of epsilon to the zero. That's the definition of Perot's trace.
00:29:21.864 - 00:29:52.232, Speaker B: And overall, this is well defined, even though this first gaussian integral step doesn't quite make sense. But as long as you then apply the residue trace, everything is fine. And remarkably, this trace is independent of the choice of local coordinates, which were steeped in its construction. And secondly, the trace is a trace. I mean, that's good news. It's a trace on this biomodule that we've been discussing. It's not obvious at all that the trace is a trace.
00:29:52.232 - 00:30:29.862, Speaker B: And it's a little bit interesting to track down where the trace property comes from. And if you do the calculation, what you'll find is you need to know the following thing about the gaussian integral. Namely, if you have a term which you're Gaussian integrating a polynomial times an exponential, and if the overall expression is a partial derivative, then the gaussian integral is zero. That's in ordinary gaussian integrals. That's just the fundamental theorem of calculus. And it's true here by some weak rotation from positive definite matrices to non positive definite matrices. So it's a trace.
00:30:29.862 - 00:31:10.344, Speaker B: It doesn't depend on the coordinates. I don't know how to define it in a coordinate free way, but because it's invariant, I can patch together by partition of unity and build a trace. Now, on our bio margin, icann did. It's a beautiful construction. I can't say I ever saw anything like it before, certainly not in the canons of index theory. Maybe in physics it seems like a more ordinary construction. But then the connection with index theory won't be apparent.
00:31:10.344 - 00:31:37.704, Speaker B: All right, so let's go back to spinners and clip it algebras and so on. I mentioned we'll use the generalized tangent bundle with the obvious bilinear form in which cotangent vectors are paired against tangent vectors. Symmetric bilinear form. It's non degenerate, but it's indefinite. It's non definite signature. And whether or not it has definite signature, you can certainly form a Clifford algebra anyway. And that's what we'll do.
00:31:37.704 - 00:32:19.278, Speaker B: And then we'll pull it back to the cotangent bundle and to get a bundle of Clifford algebras. And what I want to consider are differential operators acting on sections of the bundle of Clifford algebras. This is not the minimal thing you could do. After all, you could look at differential operators acting on sections of a spinner bundle for this bundle of Clifford algebras. But we're not going to do that. We're going to study exactly what's written in front of you, differential operators on the bundle of qliphoths, which are polyhomogeneous in the fiber direction. So we just introduced some matrix coefficients, if you like, to the story, but it doesn't really change anything.
00:32:19.278 - 00:33:23.174, Speaker B: And you can repeat the entire construction of an algebra of infinite order differential operators that I went through just a moment ago to create a new algebra of formal power series in epsilon with coefficients which are differential operators. I'll call it C, Curly C. And you can build a new bi module. And on this new bi module, you can build a new trace, except now it's naturally a super trace, because we can use the super trace on the Clifford algebra to introduce a little bit of supersymmetry into the story. After you've done all of this, what do you have? Well, first of all, you have a bio module, which is supposed to call to mind something like a Hilbert space, excuse me, that you see in Kasparov's work. Kasparov, when he builds his Dirac operator, always uses the Clifford algebra, not the spinner bundle. And so this is a little like what Gennady would do were he to build the Dirac operator for you, except we're in this strange world of indefinite signature.
00:33:23.174 - 00:34:16.250, Speaker B: But this is a, there is a cognate for this construction in our world, but only in the elliptic world of operators. Okay, so there is a rather, I don't know, alluring bimodule with an alluring trace. And there's a way of handling the exponentials of Laplace type operators, at least in this indefinite signature context. All sorts of ingredients that seem rather oddly familiar to us are now algebraicized, and it's time for some geometry. Let's try to see what to do with this. Let's start with an affine connection on the tangent bundle over the original manifold M. Well, of course, then you get a connection on the cotangent bundle over m.
00:34:16.250 - 00:35:21.272, Speaker B: And so what? Well, with this data, you can talk about horizontal vector fields on tm, and therefore you can identify the tangent bundle of t star of n of the manifold t with the generalized tangent bundle GTM, well, pulled back to t. So the tangent bundle of t, once you've chosen a connection, falls apart into two bits, a horizontal bit and a vertical bit. And using the connection, we'll just build a Dirac operator in, so to speak, the usual way, just by clipping multiplications and connection operators. Except we're going to introduce the formal variable epsilon into 50% of the story exactly as you see here. Otherwise, it's just the usual thing, because the Clifford algebra is built from a form of indefinite sign. Once you build this d, it's certainly not a Dirac operator. The square of this Dirac operator is the laplacian delta that I've been describing all along, plus lower terms.
00:35:21.272 - 00:35:56.168, Speaker B: So it's certainly not elliptic. As for the Clifford multiplications, you have a choice here, because the Clifford operators are acting on sections not of a spinner bundle, but of a Clifford algebra bundle. The record we want the Clifford operators to act on the right as opposed to the left. And then there are some signs that you need to take care of anyway, just. You can ask Gennady. Because it's exactly what he does to build his Dirac operator. So we have a Dirac operator and we have a super trace.
00:35:56.168 - 00:36:21.030, Speaker B: And we have a representation of a commutative algebra a inside of our bimodule. Sorry, excuse me. Inside of us, algebra C of t. Because if you have a smooth function on S star of m. Of course, that's the same thing as order zero homogeneous function on t. That thing acts as a multiplication operator. That's almost what you want to do.
00:36:21.030 - 00:36:41.898, Speaker B: But for the record, you want to compress that multiplication operator. By a certain minimal projection in the Clifford algebra. The projection onto zero forms. Okay. This projection, PI, is the source of all sorts of interesting phenomena. It commutes with everything. It commutes with f.
00:36:41.898 - 00:37:12.504, Speaker B: It commutes with the Dirac operator. And it plays an interesting role in the whole story. The subsequent story that I'm going to try to fit into the remaining part of the lecture. At any rate, this is now sort of algebraic spectral triple. It's not too bad, really. There's one slightly mysterious selection of a notion of useful order. But then the rest of the construction, or helpful order, I guess, as I was calling it, the rest of the construction is it's not too bad.
00:37:12.504 - 00:37:34.794, Speaker B: And it's a mysterious thing that we built. That Peron built. Okay, on to cyclic co cycles. Happy birthday. Cyclic theory, by the way. So now we'll do the obvious thing, or what would seem to be the obvious thing, namely, build a JLo co cycle. It all makes sense.
00:37:34.794 - 00:38:06.734, Speaker B: If you take D and you square it, and you take the exponential, and you plug it into the JLo formula in the usual way. What you get inside of the supertrace that you see in the big display is an element of our bimodule. That's a simple calculation. So you can take the super trace, and now it's a scalar function on a simplex. So you just integrate it. The whole thing makes perfect sense. And you get a jl or co cycle out of our not exactly spectral triple, but out of our algebraic triple.
00:38:06.734 - 00:38:33.018, Speaker B: And ordinarily, if I was giving a talk like this, I'd have to, you know, tell you or lie about what cyclic theory is and what this JLo is. But. But here, I think we can just assume that everyone is happy with this thing. Another spelling mistake. You build a beautiful co cycle. And of course, you want to know, what is it? Well, the answer is that it's zero. So that may seem a little bit disappointing.
00:38:33.018 - 00:39:17.812, Speaker B: After all, of this work, you build this beautiful co cycle, you feel happy and optimistic that you're onto something, and then you calculate the thing and you get zero, identically zero in every degree. So it's just plain zero. That may seem a little bit of an anti climax, but in fact it's good news that it's zero. If you apply the Perot strategy, which involves lifting to pseudo differential operators, pseudo differential symbols, what you can do is use this calculation. It's a non trivial calculation to show you get zero. But the result of the calculation is that the non commutative residue, the trace, turns out to be zero. In cyclic homology, of course, as we all know.
00:39:17.812 - 00:40:07.230, Speaker B: So this is another proof of that fact. If you really want to get the Todd class and do index theory, you need to be in odd degree, not in even degree. After all, a cosphere bundle is an odd dimensional manifold, so it's, in retrospect, perfectly to be expected that an even degree cosine should not be very interesting. Anyway, here's how you do it. I'm not going to stress the details here, because, again, for cyclic people, this is all fairly straightforward. Apart from the supertrace, there is also outer derivation on our bimodule and on the algebra curly c, which is an analog of the derivation that you see in the definition of the Radil co cycle. I didn't think I wrote down what it is.
00:40:07.230 - 00:40:30.470, Speaker B: Oh, I did write down what it is. In the first point, you take the symbol of an actual Laplace operator on m, made using a romanian metric. So that's a function on t of m. And then you take the logarithm. I've missed a step in my description. In the first step there, you take the logarithm of the symbol of an actual Laplace operator. So that's another function on t.
00:40:30.470 - 00:41:11.214, Speaker B: And of course it generates a hamiltonian vector field and commutator bracket. With that hamiltonian vector field is the derivation delta. So now you have not just a trace, but a derivation, and the trace is closed with respect to the derivation. And it's not a surprise, therefore, that you can elevate the even Jloco cycle to an odd version of the Jloco cycle using this extra derivation. And that's exactly what can be done. This fits very nicely into the formalism of Quillin, as pointed out by Rudy in one of his papers. Rudy wrote song all right.
00:41:11.214 - 00:42:03.274, Speaker B: And concerning this second co cycle, here's what Perot proved. The first thing is that if you pull this back from functions to order zero symbols along the principal symbol map. Then you get, well, one of the two co cycles that I was mentioning at the very beginning. And so you get a co cycle which is chromologous to the Radl co cycle. So that connects this co cycle to analytic index theory, because the raddle co cycle gives you the analytic index. On the other hand, as for this co cycle itself, if you happen to use a connection with additional symmetry, a la vita connection, so a connection for a metric, then you can calculate what this connection is, and what you find is the tau class. This cyclic co cycle is not a general, arbitrary cyclical bb cocycle.
00:42:03.274 - 00:42:55.094, Speaker B: It's actually a family of Durham currents, exactly as you see in this formula. I want to explain very briefly, I don't have too much time, just a little bit of what happens when you go back into the world of pseudo differential symbols from this semi classical limit of functions on T M. So I've been describing not the true Perot story, but in an effort to make it a little more transparent, I took this semi classical limit I deformed to the commutative. So I just want to explain what happens or degenerated to the commutative. I just want to explain what happens if you try to deform back as quickly as possible. I think the good way of understanding this is to use just a little bit of Lie algebra theory. And I'll just talk about scalars, scalar operators here.
00:42:55.094 - 00:43:36.816, Speaker B: I won't mess around with spinners. Just for simplicity or clippered algebras, let's look at the following l algebra, it's first order scalar differential operators on M. So they have an order one part and maybe an order zero part in local coefficients. And so it's a lie algebra under commutator bracket, and it acts on symbols by commutator bracket. Because after all, every differential operator is a pseudo differential operator. So there's a natural action, actually an inner action of my lie algebra g on the algebra of pseudo differential symbols. Now as for the Lie algebra, it's filtered by the usual notion of order of differential operators.
00:43:36.816 - 00:44:31.082, Speaker B: So I have a filtered lie algebra acting on a filtered algebra, and the action is compatible with the filtrations. So everything descends to an action of the associated graded algebra on the associated grade of s of m. So in other words, we get some lie algebra action on s graded of M, which is just polyhomogeneous functions on T. What is this Li algebra action? Well, what you find is that g graded consists of vector fields on tm, which in this vertical filtration have either order zero or minus one. So the grading on g graded comes from, from the vertical order that we saw a little bit earlier. And, you know, if you're an operator, algebraic, and you have an action, you really can't resist forming a cross product. So let's do that here.
00:44:31.082 - 00:45:23.694, Speaker B: There are two alternatives. We can do it upstairs on symbols or downstairs on this semi classical limit, this degeneration, if you do it. So when we have two cross product algebras, they carry obvious representations as endomorphisms of s, of m, and s graded, of m respectively. And if you look at what happens in the graded situation, what you find is you recover the algebra of polyhomogeneous differential operators that I was describing, that we organized everything around. So maybe therefore, if you want to lift to pseudo differential symbols, you should study instead the cross product upstairs on s of M itself, and the image of the cross product inside of operators on s of M. And that's exactly what PeRot does. He calls this algebra l of M.
00:45:23.694 - 00:46:11.214, Speaker B: And then he defines another algebra, d of M of formal power series, just exactly the same way we defined a Star of M. And he lifted everything from the semiclassical limit back to actual pseudodifferential symbols. And when you do this, it's a little bit. So now you want to build the Dirac operating, okay, we just bring back the Clifford algebra and so on. Now you want to build the Dirac operators. And what you find is a little bit discouraging to begin with, because if you fix a connection on the manifold M and attempt to build a Dirac operator according to the usual formula, what you find is that it's no longer canonically defined. You can't just write down the usual formula and say it's coordinated independent, because it isn't coordinate independent, it's coordinate dependent.
00:46:11.214 - 00:47:00.530, Speaker B: That already happens in this cross product algebra, although not in the representation of the cross product algebra. So it gets a little messy. And what Perrault has to do is he has to work in local coordinates and patch together using a partition of unity. So that's, for the time being at least, an aesthetic blemish to the whole story. On the other hand, the cross product perspective tells you exactly why there are two Dirac operators. Because whenever you form a cross product by an inner action, which is what we're discussing here, whenever you form a cross product by an inner action, the cross product algebra is always isomorphic to just a tensor product, you can untwist the action and it becomes a usual tensor product, not a twisted tensor product. And so you see, inside of the cross product, there must be two copies of the Li algebra g.
00:47:00.530 - 00:47:36.216, Speaker B: There's a copy inside of the enveloping algebra as it acts in a non trivial way on s of m. And then there's another copy which doesn't interact with s of M at all. And if you have two copies of g, it stands to reason that you should be able to build two Dirac operators. And it stands to reason that the Dirac operator built using the non interacting, so to speak, copy of g. I apologize to Emil for using a word like that. That Dirac operator is going to be extremely simple because it's going to commute with elements in our algebra a. All of the commutators, D comma a, are just going to be zero.
00:47:36.216 - 00:48:23.744, Speaker B: So whatever Jlo formula you build is going to be concentrated in the lowest degree. And that's the explanation of why you get from that 1st 2nd Dirac operator. You get the Wojcicki residue, or you get the radical cosine. Just want to end. I've got a couple of minutes, a couple more slides by describing something that I'm kind of enthusiastic about right now, which is the behavior of the Dirac operator on the tangent groupoid. When you lift it to the tangent groupoid, if you want to do calculus with symbols, then as Alain pointed out, it's very natural to lift everything to the tangent groupoid. You can do this for the ordinary symbol calculus.
00:48:23.744 - 00:48:49.328, Speaker B: And you, you can also do it for Getzler's symbol calculus. And in the case of Getzler's symbol calculus, you have to monkey around a little bit with the spinner bundle as you lift it to the tangent groupoid. And you can do something similar here. Where did I do it? Yeah, it is here. Good. So first of all, here's what I want to do. I want to take the tangent groupoid, which I'm just going to call M here.
00:48:49.328 - 00:49:46.712, Speaker B: And then I want to take the cotangent bundles of the source fibers of the tangent groupoid. And I'm going to call that thing t star of m, because I thought t star of t of m was a bit of a mouthful. So this is a family of cotangent bundles thought of as manifolds, most of which are just t star of the original manifold M. Okay, so it's a family of cotangent bundles. And I want to build over this family of cotangent bundles, a family of Clifford algebras. And what I'm going to do is make a small rescaling of the generalized tangent bundle by defining, as people do, for example, in Alain Melrose, defining the bundle indirectly via sections. So a smooth section of the rescaled tangent bundle, let's say, over the unit space to begin with, is just a section of the generalized tangent bundle, which is entirely concentrated in t of m at t equals zero.
00:49:46.712 - 00:51:07.260, Speaker B: It's a small variation on the usual, on just GTM. To build RTM, it's isomorphic, actually, to the two bundles are isomorphic, but not in a. I mean, you have to, in a non trivial way. And here's the calculation, which I think, which is due to Perot, but we've recast it in this form. Suppose you take the Dirac operator and you square it in ordinary elliptic operator theory, and for that matter, in Goetzler's theory, after you've done this, you should multiply the Dirac operator by t squared, and then you'll get a family of Dirac operators on the fibers of the cotangent groupoid, and that family will extend smoothly to t equals zero, where you'll see the symbol of the Dirac operator, or the Goetzler symbol in the case of the more complicated Goetzler calculus here, you don't have to do that. If you put the Dirac operator of Perot, after you've squared it on every single cotangent space, t star of m, which sits inside of our family of cotangent bundles, without changing it at all, then nevertheless, despite the fact you didn't make any changes at all, there will be a smooth extension to t is equal to zero and what it means. So that's an interesting calculation, which uses some non trivial things.
00:51:07.260 - 00:52:04.124, Speaker B: For example, it's important that the connection torsion free for this to be a true fact. What this means is that if you want to calculate the JLo co cycle, you can, instead of doing the calculation at t equals one, you can do it at t equals zero. And now you're just calculating on a bunch of cotangent vector spaces. And on each cotangent vector space, the relevant operators are actually translation invariant in the t of m direction. So how hard can the calculation be? The answer is not very hard at all. When you square the Dirac operator, you get just the flat Laplacian, in our converted sense, d dx times ddp plus a term which only depends on the curvature of the connection at the point m. If we're on the tangent space over m, if you look at the commutators d commuted with f, you just get df with this epsilon strategically inserted, but nothing very complicated.
00:52:04.124 - 00:52:43.568, Speaker B: And finally, when you take the trace, this isn't quite true on the nose, but after under the trace, the exponential of d squared. In other words, the exponential of epsilon plus r of m. Think of this as epsilon delta plus a small perturbation. What Schur examined is how the exponential changes under small perturbations of the argument. And what he found is the usual formula for the derivative of the exponential maps, and which involves one minus e to the minus x over x. The usual thing. And that's where the todd class comes from, from this well known formula.
00:52:43.568 - 00:52:55.764, Speaker B: So it's all really rather remarkable and quite accessible, really, at least if you take the semi classical limit. All right, time's up. Thank you very much. And there are some references, if you like.
00:52:56.144 - 00:53:06.984, Speaker A: Thank you, Nigel. Let me stop the video first. There you go.

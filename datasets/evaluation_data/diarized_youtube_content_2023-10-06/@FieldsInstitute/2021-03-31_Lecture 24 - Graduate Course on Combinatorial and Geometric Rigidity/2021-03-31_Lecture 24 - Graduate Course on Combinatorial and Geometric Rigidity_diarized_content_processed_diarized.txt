00:00:00.120 - 00:00:58.024, Speaker A: I'd like to start this lecture with what I'd intended to be the second half of Monday's lecture. So on Monday we started talking about frameworks in two dimensions that were nearly but not quite generic. And if you remember, we talked a lot about frameworks with two coincident points and showed that already that special case was enough for there to be both quite interesting theory needed, and it was applicable to certain situations. Um, so similar setup happens if you talk about from some collinear points. Of course, any two points define a line, but if we have at least three points that are collinear, then you're definitely not a generic framework. And so that's what I want to talk about for the first half of this lecture. Okay, so what are we going to say? We're going to take a graph g and we're going to pick three special vertices x, y, z in the vertex set.
00:00:58.024 - 00:01:59.966, Speaker A: And I'm going to take a minimally rigid generic realization of the graph in two reals. So suppose I've picked a graph which has such a property. So I've picked a minimally rigid generic graph. And the question is, for these three special vertices I've picked when does there exist a framework of the graph such that everything is generic except px, p y and p z are collinear, and the resulting framework has to be minimally rigid still. So when can I realize three points in a collinear way without destroying the rigidity? Okay, so a very simple example would be to take the complete graph on three vertices. It should be clear that when we had this before when we talked about collinear triangle for the one extension technique, that this is not infinitesimally rigid. So I'm always gonna be talking about infinitesimal rigidity when I have my non generic realizations.
00:01:59.966 - 00:03:04.594, Speaker A: And we saw that the free rows in the rigidity matrix are dependent if the free vertices of a triangle are collinear. Okay, so this is obviously one very small example, but it really does model what happens in the general situation. So if we have a general minimally rigid graph and we have set three of the points to be collinear, what can go wrong? Well, it's really just generalizations of this picture. So for example, let's replace the edge between vertex x and vertex y with a bigger critical set. So remember, a critical set is a set of subset of the vertex set x, such the number of edges induced by x is two x minus three, and a single edge has two times two minus three is one is an example of such a critical set. But if we replace xy with a larger critical set z, which contains x and y. It contains the two ends of the edge xy, but it does not contain the third vertex.
00:03:04.594 - 00:04:05.584, Speaker A: Then it may be that we've just picked a critical set which contains the edge xy and then we haven't really change the example of the dependence, but it may be that it doesn't. And so it may be that we have a picture like this one where I've picked some minimally rigid generic framework which includes the vertices x and y, but does not include z. And because it's rigid, the length of x y is determined. So, in language of the rigidity matrix, the row that you would write for the edge between xy is some linear combination of the rows for these four, these 1235 edges. And so the edges in effect implied. And so the dependence that you get from the collinear triangle extends to this situation. And of course, when you see you can do that, you could also do the same thing to the other edges in your collinear triangle as well.
00:04:05.584 - 00:05:00.544, Speaker A: So what you can think of is the collinear triangle problem. The triangle being dependent with the free vertices collinear extends to a general picture like this. So you have three critical sets, an x, a y and a z, which each contain two of them. The intersections are exactly the three single vertices x, y and z. Whether any of the sets contain the particular edges x, y, yz or xz or not, this will still have the same dependence from these, this now completely implied triangle. Okay, so let's say a structure like this one is an obstacle for the special triple. Okay, so it's a set xyz of critical sets where each of the, each pair intersect in the relevant vertex.
00:05:00.544 - 00:06:07.664, Speaker A: And this is going to be the, the only reason why a framework of free collinear points that was minimally rigid suddenly becomes not rigid infinitesimally with the realization of those three points collinear. Okay, so we already talked about such critical sets before. And so we saw earlier in the course that if you have an obstacle x, y, z like this, then the union is critical and there are no edges between them. So in this picture there were no edges like this, this or this. Okay, so here's the theorem. And so these obstacles were introduced by Jackson and Jordan in 2005, and they studied this problem with the collinear triple x, y and z. So I take a minimally rigid graph in the plane, and then I want to know, does there exist some realization which has the property that px, p y and p z are collinear and is infinitesimally? Rigid.
00:06:07.664 - 00:07:14.294, Speaker A: And the answer is. So you take your, your two free tight graph, your minimally rigid graph in the plane, and as long as it contains no obstacle as I just described. So this is a very concrete description of exactly when this collinear realization fails to be infinitesimally rigid. Okay, so I decided not to go into the details of the proof. So I'll just make one small remark, is that it's kind of, it would have been a natural thing to include in the course, because it's the same proof technique that we've used a lot. So it's based on the fact that zero and one extensions preserve rigidity and the difficulty, and what takes quite a while in their paper is to deal with the one reductions and avoid creating these obstacles. So as you're doing your one reductions, as well as checking the two free sparsity condition, you also need to avoid creating new obstacles for, for your, your triple.
00:07:14.294 - 00:08:51.874, Speaker A: Okay, the next thing I want to do is extend this result from a collinear triple to an arbitrary subset of the vertex set that's collinear and allow so I can have an arbitrarily sized subset of the vertices that are collinear and that the cost will be that this condition, when this minimally rigid, will become much more complicated. Okay, so what's the idea? Well, I'm actually going to say almost nothing combinatorial. I say the combinatorial characterization would be much more difficult. But what I'm really going to do is avoid combinatorics by relying on a previously known combinatorial result, which I'll mention maybe in about ten minutes, and instead just use a geometric transfer, a projective geometric transfer rigidity, which goes back to what we talked about a number of lectures ago. So a while ago I introduced frameworks on a sphere, and I showed you so by hand, these row and column operations which transferred infinitesimal rigidity from the unit d sphere to the plane, say Z equals one, the last coordinate equals to one. And what we were really doing was we had a picture like this one where we had a point on the sphere and we used the unique line defined by that point and the center of the sphere. And we were able to slide that vertex by these row and column operations to the plane at z equals one.
00:08:51.874 - 00:10:07.204, Speaker A: Say we're on the two sphere, just for simplicity of the explanation. And the thing that we talked a little bit about there, I think it was pointed out as a comment and explained a little bit there was that this transfer becomes a little bit problematic if you have points on the equator of the sphere because instead of being moved up to the plane, they say here heads off to infinity. And so you have to move to sort of a projective view and include what happens when there are the points on the equator. So before I move on, in the words, let me just show, so here I've got three points on the equator and the same thing happens as a collinear triangle. If you're thinking about a framework on the sphere that if you have these two edges, then the other one will be dependent. If you think about that as euclidean distance edges, and this is completely clear because it's the same as in three dimensional space where completely flat collinear triangle would be dependent. And if you think about it on the sphere of geodesic edges, it's that when you go around the other way, any two of the three edges determines the third distance still.
00:10:07.204 - 00:11:05.758, Speaker A: So what I also wanted to show you with this picture just before I move on is that I have these three points on the equator. What I want to do is apply a, a rotation of the sphere. And that rotation would just be a very small rotation. So any other point doesn't end up accidentally going back to being collinear, but these three points will rotate off the equator to some other great circle, so there'll be some great circle somewhere. That picture was not very good, but now they're all not on the equator. I can invert any point that was on the lower hemisphere up to the, the upper hemisphere and then I can send them all off to the plane. The cost being that the points on the same great circle will be collinear up in the, it won't look like the line I've just drawn, but the points that are on the same great circle of the sphere will end up collinear in the plane.
00:11:05.758 - 00:11:56.684, Speaker A: And hence, if we can understand frameworks on the sphere with points on the equator, we can transfer it via the same row and column operations dealing with infinity, which is a little bit more complicated. But I'm going to omit that, that challenge up to the plane and say that the infinitesimal rigidity of the object up here with some subset of points collinear is equivalent to the infinitesimal rigidity down here with that same subset of points lying on a great circle. Okay, so let's, let's see some of the words to explain that. Okay? Yeah, so this is what I was just explaining. So, so very roughly, you, you have your points that lie on the, the unit. Let's always talk about two spheres in r three. So it lies on, on the unit two sphere and say some subset of points lies on the equator.
00:11:56.684 - 00:13:00.314, Speaker A: Then we assume everything else is sufficiently generic that a small enough rotation won't move any of the point onto the equator. And so a small rotation, which of course preserves rigidity of the whole framework, moves so that no point lies on the equator anymore. And now we can apply the same row and column operations as we, we used to apply to move the framework to the plane. Except the cost is that the plane framework won't be generic, it will have some subset of points that are, that are collinear. Okay, so this is a very rough explanation of the following theorem, which one sort of key part of this theorem I'm going to explain after the statement as well. And again, it will only be sort of hand wavy. So I need to introduce some notation to describe the combinatorial condition, which you'll see is significantly harder than the usual camp conditions that we've had.
00:13:00.314 - 00:13:56.314, Speaker A: So give a graph and a specified subset of vertices x and x is going to be the subset of vertices that are going to be on the equator of the sphere, or will be realized collinearly in the plane. So for a subset of the edge set of the graph, for a subset a, I'm going to use v sub x of a to denote the number of vertices in x which are incident to edges in a. Okay, so that's going to come up in our combinatorics. The theorem is just too big to fit on the page, so let me just shrink slightly. Okay, it shrink wants to shrink a lot. Okay, so this is a theorem due to Yasf Takhari and a group of us whose names are probably familiar to you. What we do is we have a graph and we take a subset of the the vertex set.
00:13:56.314 - 00:14:43.128, Speaker A: Then we say there exists an infinitesimally rigid framework gp and two reals such that the points assigned to x lie on a line. So you can imagine everything else is generic. The points are next are generic along some line and they're allowed to move off the line. They just happen to lie on that line in this realization. And it's infinitesimally rigid if and only if your graph contains a spanning subgraph, g dash. So it's a spanning subgraph, the same vertex set, possibly a subset of the edge set, possibly the whole thing with two v minus three edges, which is the natural Laman count. We still have to be just like in the Jackson Jordan case.
00:14:43.128 - 00:15:36.194, Speaker A: We still have to have a two three tight graph. But we have a more complicated subgraph condition that not all two free tiegraphs satisfy, we have to be a bit more careful. And to see examples that don't satisfy it, you can just do look at the free collinear point case where you saw, and you can imagine that for sure. You get similar obstacles for quadruples and five tuples, etcetera, by making very flat. So any collinear cycle will be dependent. So you can make yourself many, many examples using that. So what's the subgraph condition? So you take any subset of the edge set of this spanning subgraph and you take any partition, a one up to as of the set of edges you've picked in e prime.
00:15:36.194 - 00:16:23.578, Speaker A: And then what you need to be true is the size of the set of edges you picked. A is at most this sum. So you want to go through each element of your partition, you look at a one up to as and you take this v sub v, not X and v sub X of the two things. And you have the vx twice actually. So you have vx for the whole thing. And I guess I don't want to spend any time going into the details of why this is quite the, the right combinatorial count. The one thing I'll try and say to give you a sort of flavor of it is in some sense what we're doing is we're taking the cycle matrix.
00:16:23.578 - 00:17:06.574, Speaker A: So we're having the mod v minus one matriid, we're having the mod v minus two matriid, two mod v minus two matriidal, and we're taking a matriid union. But there's also an operation called a Dilworth truncation going on here. And so I haven't defined matroid union or Dilworth truncation in the course. So in some sense there are two nice and easy to understand count matroids. But then there are more complicated operations going on, which leads to this precise, but a bit complicated to understand and digest at least first viewing.
00:17:07.074 - 00:17:15.094, Speaker B: Tony, sorry, it's will. Could I just ask a quick question? What is the vx v sub x here?
00:17:15.514 - 00:17:19.854, Speaker A: Sorry, I missed that. So it's here. So let me say it again.
00:17:20.554 - 00:17:22.214, Speaker B: I see I missed it up here.
00:17:23.154 - 00:17:37.334, Speaker A: So you take a subset of the vertex set and a subset of the edge set, and then v sub x of a for the relevant subsets is the number of vertices in x which are incident to edges in a.
00:17:37.994 - 00:17:38.506, Speaker B: Thanks.
00:17:38.570 - 00:17:53.894, Speaker A: Okay. Okay. But I don't want to dwell too much on this. I don't think I understand this combinatorial condition in a great amount of detail. So I don't want to dwell too much on it.
00:17:54.674 - 00:18:33.374, Speaker B: Could I actually ask one other question? Uh, I understand, I guess, what the. The proof is or what the. What the theorem is saying. But I was expecting, um, things to go in a slightly different direction. So, uh, um, if you have three like this, this takes three collinear kind of points and. And extends to four or five or more collinear points. What about the situation where you have three collinear points and then a different set of three collinear points?
00:18:37.514 - 00:19:00.366, Speaker A: Yeah. This is a very interesting question, and I think people are looking at this. I thought about it a little bit myself, and I just don't have a. Don't know what that is. I don't know a really good way to go about it. So you're completely right. It would be interesting to take sets x, y, z.
00:19:00.366 - 00:19:53.454, Speaker A: I should use x one up to x, k or something where there is lots of different lines, and there happens to be, say, three points on this line, three points on this line, three points on this line, and do that. And if the number of lines up here is sufficiently small, then it may be possible to extend the Jackson Jordan theorem in this kind of direction, because you'd want no obstacle for the triples on each line, and then you'd have to worry about how the lines interact with each other. But that combinatorially was. Well, it was an entire journal article, the paper. It was maybe 15 pages of combinatorics, so it's not going to be a trivial extension. And three points on a line is maybe not quite what you want. You'd want each of these lines to have lots and lots of points.
00:19:53.454 - 00:20:32.346, Speaker A: And so what would be much. What would be nicer, I think, is if this kind of combinatorics could be extended. But I have no idea how to do that. So the proof here is really from the projective context that. And there's only one line at infinity that. So I really don't know how to get a second line in the techniques we were talking about. So, as I said, I think some people are working on this, so I hope there are some nice results in the near future, but it's an important point.
00:20:32.450 - 00:20:33.974, Speaker B: Okay. Interesting.
00:20:36.834 - 00:21:22.314, Speaker A: Yes. So let me go to. To hear. So I wanted to basically, in this theorem, in some sense, this theorem you can think of as a corollary to another result. So what I explained was why frameworks in the plane with collinear points was equivalent to frameworks on the sphere with collinear points. And that was by thinking of them as frameworks including points at infinity. You can also translate that to another problem which we could show was equivalent by the same kind of row and column operations which is to the study of point line frameworks.
00:21:22.314 - 00:22:08.624, Speaker A: And in fact we could do this in D dimensions. So it could have been, this could have been RD and this could have been the D sphere and then there would be point hyper plane frameworks. And the actual theorem I quoted is really saying, really what happens is that this rigidity condition is equivalent to the point line condition. And I'll tell you what point line means in a minute to a point line rigidity condition. And there was a pre existing theorem that point line rigidity was equivalent to this combinatorial situation. So in some sense our paper, we didn't do anything combinatorial for this, this result here, it was the project of geometric transfer and then applied a previous result. We did other combinatorial things in the paper but at this point we didn't.
00:22:08.624 - 00:22:57.954, Speaker A: So what are the point line frameworks we relied on? So again I'm going to be very brief and in fact what you can see is basically all I'm going to say. So I take a graph and I'm going to partition both my vertex set and my edge set. So the partition is going to be into VP and Vl where I think this is point vertices and this is line vertices in my point line. Well the graph at this stage, but it's going to be a point line framework in a moment and my edges are going to be partitioned into point point edges, point line edges and line line edges. Okay, and so then a point line framework is a pair which realizes the point vertices as points and the line vertices as lines. And each edge corresponds to the relevant thing. So an edge in EpP gives me a point distance constraint.
00:22:57.954 - 00:23:47.934, Speaker A: So that's our usual constraints between points. An edge in PL gives me a point line distance constraint and an edge in ell gives me a line line angle constraint. So you could imagine a graph like this one where the partition of the vertices is into filled and unfilled circles. So the filled circles are the points so they just get realized as points and the unfilled vertices are the lines so they get realized as lines. And then in this picture there's no edge between the two lines so there is no angle constraint between the lines, but there is an edge between the two points. So there's a distance constraint between points and the rest are sort of point line distance constraints. And so you can ask about the rigidity of such a system.
00:23:47.934 - 00:24:37.984, Speaker A: So your lines are allowed to translate and they're allowed to rotate and your points are allowed to move freely subject to the constraints. And so, one thing beyond the usual two v minus three condition, and I mentioned this before, the cycle condition is that if you have a cycle of angle constraints, then the last one is always determined. So you need to have be a forest on the line. So the ell should be at most vl for any subset of your graph on the lines. And so this gives you a second count to incorporate with the usual one. And this is where some of the complication comes from, at least. But there is a nice paper, and I should have referenced it here, so sorry about that.
00:24:37.984 - 00:25:35.464, Speaker A: The paper is by Bill Jackson and John Owen, where they prove, I've forgotten the year, I'm sorry that they prove that a point line framework is rigid if and only if the combinatorial condition up here, which I'm in danger of having far too much color all over this bit. But this combinatorial condition is equivalent to rigidity of a point line framework. And so the theorem stating here was really saying that this collinear condition is equivalent to point rigidity. Is equivalent to point line rigidity. Okay, so that's the, the end of what I wanted to explain last time. I've now caught up. Are there any questions on that before I move to a different onenote file? Yes, this is the right one.
00:25:35.464 - 00:26:29.420, Speaker A: So I'm going to change topic basically completely to something called a pseudocompositions. So actually this was something I was about including. But Sean, who I can see is here, said he wanted to, he did want to hear a bit about them. So, so let's see what I can say in the second half of the lecture. So what's the idea? So the idea is motivated by engineering. So in fact, there was an engineer maybe 100 years ago called Leonard Asu, who, and in the engineering community, sometimes what I'm going to call azure graphs are known as azure groups. They're not groups, they're graphs.
00:26:29.420 - 00:27:19.496, Speaker A: So we have to go to autographs. The idea is, if you want to control some mechanism, then a nice thing to do is to break it up into easier parts. So you take, let's say we're in the plane and we have something that's minimally rigid. If we delete any one edge, we'll create a mechanism, we'll create a motion that they might want in some mechanical engineering piece of machinery, say, and what the assure idea is to break your minimally rigid thing up into its, into the smallest parts. So when you remove an edge, you know exactly how it's going to move. So we will look at minimally rigid objects and look at what rigid subgraphs are inside a minimally rigid graph. Except we're not going to do it for arbitrary minimally rigid graphs.
00:27:19.496 - 00:28:06.720, Speaker A: We're going to do it for pinned graphs and pinned frameworks. So I could use the language we had of linearly constrained frameworks from earlier, but that's not consistent with the literature on a sewer graphs and assume decompositions in rigidity. So I'm going to move the notation a little bit. So I'm going to, again I'm going to partition my vertex set but this time I'm going to partition the vertex set into I and P. So I am not so keen on this notation but this is what was used in the literature. So I means inner and p means pinned and you still have your edge set. So our vertices will, some of them will be pinned which means that any infinitesimal motion of that vertex must be the zero motion.
00:28:06.720 - 00:29:19.954, Speaker A: It doesn't move in any continuous motion and inner vertices are ones that are allowed to move freely. So unlike linearly constrained frameworks we don't have the option in the middle where there are say sliding constraints to fix hyperplanes or just fix lines in the plane. Okay, so a pinned framework, well it's just a pair gp. So we just have a map which assigns positions in d space to the inner vertices and to the pinned vertices and we can do a pinned rigidity matrix. So again this is distinct from linearly constrained but equivalent because what we're going to do to pin the vertices we're going to insist that the infinitesimal motion of those vertices is zero, which we achieve by striking out the columns. So there are only columns of the rigidity matrix, the pinned rigidity matrix for the inner vertices any pinned vertex has its columns thrown away. Okay, so because we've thrown away the columns we can throw away isometries because these vertices become pins so we can't translate or rotate if we have enough of these pinned vertices.
00:29:19.954 - 00:30:30.552, Speaker A: So what we're going to say is that the framework is pinned de rigid. So in dimension d if the only infinitesimal motion is actually just zero, so sine velocity zero to every vertex. And so because I've thrown away the columns for the pinned vertices I only have columns for the inner vertices, I have d of those since we're in dimension d and I've got rid of all isometries so I've got rid of everything in the kernel. So the rigidity condition infinitesimally is equivalent to the rank of this pinned rigidity matrix being equal to the number of columns which is d d times the number of inner vertices. And so we have pin d rigid. We can have pin d independent if the rows are linearly independent and pinned minimally d rigid if it's, if it's pinned d independent and also pinned d rigid. So this is just exactly as, as usual and we can define, because I want to talk about generic frameworks I have to be a little bit careful because I'm going to allow the pinned vertices to not necessarily be generic, that's not required as long as they aren't all coincident.
00:30:30.552 - 00:31:25.280, Speaker A: But the inner vertices will have to be generic. But I can talk about these rigidity concepts for the graphs as well as for the frameworks because I'm only interested in the generic situation. Okay, so remember for the Linley constrained world we talked about and proved a theorem of Strano and Ferran which included the case linear constraints include the case where there are multiple linear constraints at a vertex. So you can have say two in the plane that the two lines are not parallel so they restrict a vertex to a set location, the intersection, and hence that's a pinned vertex. But the, the theorem for just for pinned frameworks was proved a little bit earlier by Brigitte Savatius Ofashai and Walter Whiteley. So what does it say? Here it is, I'm not going to prove it. We proved that the slightly more general one.
00:31:25.280 - 00:32:13.334, Speaker A: So I don't think we need to prove this one. It can be proved. In fact I think they did prove it via zero and one extensions. So I take my inner and pinned vertex set and I set the locations of the inner vertices to be generic and the location of the pinned vertices can't all be the same place, so it spans at least two distinct locations. Then the framework GP is pinned minimally too rigid. So this is a generalization of lemans theorem to include pinned vertices if and only if the number of edges is equal to twice the number of inner vertices. So it doesn't matter how many pinned vertices you have as long as you have at least two different locations that the count is just in terms of inner vertices.
00:32:13.334 - 00:33:20.204, Speaker A: But for subgraphs we have to care about the pins a little bit, but not too much. So for all subgraphs g I union, p e dash, we have the standard inequality that compares to this one everywhere. But in particular we care when that's at least two pinned vertices in the subgraph, when there's only one pin exactly one pinned vertex in the subgraph we have a slightly stronger inequality and when there's no pinned vertices in the subgraph and there's at least one edge, then we have the standard la man inequality. So we have an even stronger inequality we need to be, to be true. So I think this situation should be relatively clear. So if you had this one, so say I have two pinned vertices like this and two edges like that and then the four vertices up here and the k four are all inner vertices, then this graph has eight edges and four vertices, so e equals two. I happens this inequality is always satisfied.
00:33:20.204 - 00:33:58.784, Speaker A: But what goes wrong is that if we have no pinned vertices and you just look at, say this subgraph, we fail the Laman condition. So it should be relatively clear. You need this and if you think for a moment you also need this one as well and then they turn out to be these three. The natural answer to give exactly this pinned minimal to rigidity. So as I say, this is a special case of a linearly constrained result. We did go through the statement in proof of, but we used a different language there with looped simple graphs, whereas here we're using this inner and pin. So I wanted to dwell on this statement a little bit.
00:33:58.784 - 00:34:00.340, Speaker A: Any questions?
00:34:00.492 - 00:34:12.064, Speaker C: Yeah, so the generic condition is only required for the inner vertices in this there's no assumption on the pinned vertices.
00:34:12.644 - 00:34:22.896, Speaker A: As long, as long as it's not all the same. If all the pin vertices are in the same place you'd still be able to rotate everything around that center. But as long as there's two distinct locations it's okay.
00:34:23.080 - 00:34:36.496, Speaker C: What if I was to do a pinned vertex in the position of one of the inner vertices so I create like a zero length edge, is that also allowed or not allowed?
00:34:36.680 - 00:35:30.832, Speaker A: Okay, yeah, you're right. So we're not allowed to have zero length edges. So the, I mean you could have it that. So say this wasn't a complete graph here I could have this pinned vertex could overlap with, let's say I just had a zero extension on here so this pinned vertex could overlap with this one because its edge would still be fine. But as you say, if you put a pinned vertex on top of an inner vertex that's adjacent, the row in the rigidity matrix would be the zero row. So yes, you're right. Actually I thought I copied the theorem statement from their papers so I wonder if maybe they made an assumption that there was no coincidence points earlier on, but as you say, it will create a zero row, right? So it must be excluded.
00:35:31.008 - 00:35:47.474, Speaker C: I think there must be other generic conditions. Because you could have, you could have a pinned vertex, the rest of the framework somewhere, an inner vertex and you could have the inner vertex forming a line or something like this. And then you would have a problem.
00:35:48.294 - 00:35:50.274, Speaker A: Say again, I've got a pinned vertex.
00:35:50.654 - 00:36:04.794, Speaker C: Yeah, you've got pinned vertex. You've got an inner vertex connected to the pinned vertex and one other vertex which causes a collinear triple. So one of the inner vertex or something like this.
00:36:05.244 - 00:36:06.092, Speaker A: Yeah.
00:36:06.268 - 00:36:08.864, Speaker C: Then this is a problem.
00:36:10.364 - 00:36:11.104, Speaker A: Right.
00:36:11.724 - 00:36:14.224, Speaker C: Because you still got an infinitesimal flex.
00:36:17.124 - 00:36:37.524, Speaker A: So this, this. So say this was pinned. Yeah, this is still minimally rigid. This is still a. The rigidity matrix here would have rank two. Say we're in the plane. Okay.
00:36:39.824 - 00:36:41.204, Speaker C: But it should have.
00:36:41.824 - 00:36:47.384, Speaker A: And you're not allowed edges between pinned vertices. I don't think I said that. But that should be relatively clear that.
00:36:47.504 - 00:36:47.992, Speaker C: Yeah, okay.
00:36:48.008 - 00:36:51.576, Speaker A: Yeah, they're both pinned. So this is, this one would obviously be dependent.
00:36:51.720 - 00:37:04.980, Speaker C: Yeah, yeah, yeah. I don't think that's infinitesimally. I don't think that's minimally rigid though, because you can put a flex coming out of the middle vertex that's orthogonal to the two edges connected to it.
00:37:05.012 - 00:37:05.584, Speaker A: Right.
00:37:09.004 - 00:37:12.544, Speaker C: So there must be something in the kernel of the rigidity matrix.
00:37:16.484 - 00:37:17.624, Speaker A: That's true.
00:37:19.564 - 00:37:22.716, Speaker C: Yeah. I think there needs to be some sort of like the.
00:37:22.900 - 00:37:32.080, Speaker A: Oh yeah, you're right, you're right. Of course, aren't you? Because I mean, these ones are struck off. I think they need, I think the.
00:37:32.112 - 00:37:50.520, Speaker B: Generic, the genericity assumption here needs to be adjusted because the point is that this inner vertex is not generic with respect to the other pinned vertices.
00:37:50.592 - 00:37:50.800, Speaker C: Right.
00:37:50.832 - 00:37:55.814, Speaker B: It sits in the field extension, their coordinates.
00:37:56.314 - 00:38:01.614, Speaker C: Yeah, yeah, yeah. Something like that, will. Yeah, I think that's needed.
00:38:02.634 - 00:38:23.074, Speaker A: Yeah. So I mean, maybe I should have just expressed it that way, but I did look at that paper to the earlier today to check. And I thought I said it exactly the way they did, which was this strong condition that the pins can be almost anything. So I'm just bringing that paper to see if I've misquoted something.
00:38:24.854 - 00:38:43.918, Speaker C: They might define generic. Funny, because I would seem the most logical thing. What Will said to say that PI is generic with respect to the pinned vertices, the field generated by the rationals and the coordinate pin vertices.
00:38:44.086 - 00:38:55.314, Speaker A: Yeah. Yes. So they do say for all placements of the pinned vertices with at least two distinct locations and all generic positions, the inner vertices. So I think I have quoted it correctly.
00:38:56.894 - 00:38:59.034, Speaker C: Yeah. Maybe it's the definition of generic.
00:39:09.974 - 00:39:12.674, Speaker A: I wonder whether we should dwell on it or we should move on.
00:39:13.974 - 00:39:16.358, Speaker C: I mean, if we take Will's solution, we're fine.
00:39:16.526 - 00:39:18.142, Speaker B: I think we should just move on.
00:39:18.278 - 00:39:20.114, Speaker C: Yeah, so probably just move on.
00:39:21.454 - 00:39:34.514, Speaker A: Okay, so the vertices, either pinned framework are in generic position in their paper, if any sub matrix of the rigidity matrix is zero only if it's identically equal to zero of the coordinates of the inner vertices as variables.
00:39:35.174 - 00:39:42.598, Speaker C: Okay, so this is like the weaker generic of kind of like completely regular sort of thing.
00:39:42.766 - 00:39:43.470, Speaker A: Yeah.
00:39:43.622 - 00:39:54.694, Speaker C: Okay. Yeah, but that would, that would fix it. That would fix it. So this is weaker than what Will said, but sufficient, I think. I think that's sufficient.
00:39:57.154 - 00:40:32.104, Speaker A: Yeah, that's so. Needs a big star by to change from what I said. Yeah. Okay, so before I continue, any more questions about the theorem. Okay, yes, so I mean, I want to talk about arbitrary dimensions. So for the, for the rest of the. Well, there's not much time left actually, but for the rest of the lecture.
00:40:32.104 - 00:41:31.346, Speaker A: But in higher dimensions, we can't have a similar theorem because of the double banana kind of examples still prevent us from, from having a nice understanding of pinned de rigidity. But we do have the sort of obvious necessary counts that you want the number of edges to be the rank, which is the number of columns, and you want that inequality to be all the way through the inequalities we had here. If you think about it for long enough, you can write down similar things for say three d. I just haven't bothered to do it. I just want to. And I just need this condition to explain some of the next things. Okay, so a de assure graph is a pinned minimally de rigid graph, which is minimal in a second sense, so as well as minimal in the sense that when you remove an edge, you remove the rigidity.
00:41:31.346 - 00:42:16.234, Speaker A: It's also minimal in the sense that there are no proper pinned subgraphs which are themselves rigid. Okay, so I draw some examples in a moment. So maybe I will defer the examples. So to understand the parts of a pendman and rigid graph, which are a sewer graphs, I'm going to introduce orientations of the graph. So I say a dedirected orientation of a graph. Obviously we're going to assign directions to all the edges. And the condition is that every inner vertex has out degree exactly d and every pinned vertex has out degree exactly zero.
00:42:16.234 - 00:43:26.642, Speaker A: Okay, so there is, this condition allows me to guarantee that a minimally pin de rigid graph can be assigned one of these orientations. So there is graph orientation theory that I think several papers prove it. But the earliest one that I'm aware of is Hakimi in the sixties proves that every graph basically in it with this condition can be assigned an orientation with this bounded out degree d or exactly out degree d if you're tight rather than just sparse at every inner vertex and our degree zero elsewhere. Okay, so I mean, so, but it is worth saying, I think that this orientation condition is not sufficient to characterize d rigidity. It just follows from it. So here's an example of that and it's, I think we showed this example a little bit ago. We have two pinned vertices, a k four appear and what you can see is that say this vertex got out degree two and in degree one this, this one has out degree two.
00:43:26.642 - 00:44:10.364, Speaker A: Yeah, out degree two out degree two. And then these only have in degree that is not zero. The out degree is zero. So this is an example of my out degree two in degree zero, sorry, out degree two, inner out degree zero, pinned orientation of a graph. But it's not a nice rigid one. You can see for yourself that this thing will move, the whole k four can move as a, a rigid block but it will be a non trivial motion for a pinned framework. Okay, so given one of these dedirected orientations then you can think about, in any directed graph you can think about strongly connected components.
00:44:10.364 - 00:44:59.504, Speaker A: So here we're going to decompose our graph into strongly connected components except there's a little bit of the oddity of including the pinned vertices. So what we do for this is to identify the pinned vertices. So you, so for example, it's maybe not a good one to do here, but the k four is a strongly connected component and then you include the outgoing edges coming down from the component and you include those and sort of collapse everything down and then you would find a second component lower down perhaps. Again I think this is an example hopefully coming up quite soon. Was there a question?
00:45:00.444 - 00:45:03.700, Speaker B: Sorry Tony, what does strongly connected mean?
00:45:03.852 - 00:45:08.584, Speaker A: Oh, it means that between any two vertices there is a directed path.
00:45:09.644 - 00:45:11.424, Speaker B: Okay, directed path, great.
00:45:12.124 - 00:46:29.248, Speaker A: So between a and b there's a directed path from a to b and one from b to a as well. So you could imagine like maybe a directed cycle is a nice example where this is true. So obviously in a graph like this one there's only one strongly connected component. But you could imagine that maybe you had two of these cycles. I'm forgetting about pinned and inner just for this picture about the orientation condition. So here you've got a, a strongly connected component here and a strongly connected component here and then there's parts that are not not involved in them in general we're going to, what we're going to do is form a partial order from the strongly connected components when we're using the pinned vertices and we're using edges down from a component to the lower part and this partial order we're going to get in this way which maybe will become clearer when I do some examples is going to model the decomposition of your graph into its dsur subgraph so into the doubly minimally rigid parts of it. So we're going to decompose g into components each of which is a DSU graph.
00:46:29.248 - 00:47:26.130, Speaker A: And in that context what you do is that your first one is of course it's a pinned minimally rigid thing so it has to be attached to some pinned vertices but the second one might only be attached to inner vertices so the inner vertices in the first component are reinterpreted as pinned vertices. To think about the second component. So maybe I'm going to skip ahead and do it, do an example now and then go back up. So here's an example that hopefully makes some of this clearer. So we're in two dimensions I have made four pin vertices and six inner vertices and so what's a. And in fact I'm telling you that this thing is a pinned minimally too rigid graph or framework generically. So for my first rigid thing what is it? Well if I just take this vertex and its edges downwards to these two pin vertices it's a degree two.
00:47:26.130 - 00:48:12.026, Speaker A: So it's clearly a little rigid thing on its own. So in this case the, the assure graph is just, I call it c one is just the single vertex and its edges down to the two pins. And in terms of a strongly connected components I'm thinking of this vertex as sort of on its own. It's two out edges down. It has no outgoing edges anywhere else in the graph so it can't be involved in any bigger strongly connected component, it just itself as a single vertex. So it's a trivial component in that context. And then I can move on and I can look at the second component and again it is just a degree two, I'm going to call it the component c two and it's two out edges down.
00:48:12.026 - 00:49:22.834, Speaker A: This one was to an inner vertex but for c two c one is reinterpreted as a pinned vertex and it's over edged down to this guy and again the edges were all directed out from it. And then for my third component I can take, again it's a trivial component, I take c three and it's two out edges. And then for the last component where I actually have a non trivial thing going on, I can look here and say, well, here's a strongly connected component in the graph. This is a directed cycle, so it's clear I can move between any two vertices by a directed path and it's free out edges, the one to a pin and then two of them to vertices reinterpreted as pins to get my fourth component in the decomposition. So I end up with this. In this case it was the I had c one and then I had c two and then I had c three and then I had c four. So it was a very linear order, but in general it could have been a partial order just from degree two as you can, you can kind of see that it could have been that, say I had a, another degree two that looked like that one.
00:49:22.834 - 00:49:44.970, Speaker A: So then at the stage where I got to c two, I could have chosen to go to c three prime instead. And then it wouldn't have mattered whether I added c three or c three dash first. Either one of these could have, could have gone first. And so you can see there's a, there's some choice in what you're, you're doing. C one has two converts, right?
00:49:45.162 - 00:49:47.174, Speaker C: Or is it just the regular?
00:49:48.184 - 00:50:15.510, Speaker A: So it depends on how you think about it. I like to think of it as just the vertex here. And the pin vertices aren't part of the component, because in a moment we're going to talk about the rigidity matrix and that's the natural thing there. But it's really, a DSU graph is a minimally pinned rigid thing. So in that context, yes, it has to include the two pins. It has to be this whole blob. So we're sort of thinking of it in both different ways at the same kind of time.
00:50:15.510 - 00:51:01.820, Speaker A: And so if we think, if we think about it in that way, then for c two you think of this entire thing. So every vertex in c one is pinned and then your c two is like that, and then again you think of everything in there as pinned and then your c three is like that and so on through the whole thing. And so you do include all the pinned vertices, but if you like, and in terms of the strongly connected components and the rigidity matrix, you think of individual subparts of just parts of the inner vertices as being partitioned into the component. So you kind of have to keep both of them in your head at the same time. Okay, thank you. Hey, Tony. Hi.
00:51:01.820 - 00:51:20.334, Speaker A: So then the decomposition corresponds to one path in that partial order? Yes. Any path through the partial order from the. Whatever it is, source to the sink or whatever is a. Gives you a decomposition. Yes.
00:51:21.114 - 00:51:36.324, Speaker C: Okay, maybe I didn't understand the definition of a zoo graph, but is it not supposed to have no pinned minimally rigid subgraphs? But this thing seems to have pinned minimally rigid subgraphs.
00:51:36.404 - 00:51:41.908, Speaker A: I got that wrong. It shouldn't have any pinned minimally rigid subgraphs. So did I make a mistake?
00:51:42.076 - 00:51:51.364, Speaker C: I mean this yellow, I mean the green graph and the yellow graph seem to. So the bits that you've circled, they all seem to be minimally rigid.
00:51:51.404 - 00:52:13.198, Speaker A: Right, right. So this one was my first one. And that definitely has no minimally rigid subgraphs that are pinned. Then my second one was to do this. Okay, right. Okay, so in the second one I forget that this is a, an inner vertex. I forget the edges exist and this is just now a pinned vertex.
00:52:13.198 - 00:52:20.834, Speaker A: And so this thing is, is minimal. I mean I was including this before because it's really attached to the whole thing, but, and that's minimal.
00:52:22.534 - 00:52:35.294, Speaker C: So this is the azure decomposition. You're decomposing any minimally rigid graph into a zur components in this way. Okay, yeah, I misunderstood. Sorry. All right, thank you.
00:52:38.114 - 00:53:04.530, Speaker A: Okay, so I've been jumping around a bit, so I'm probably not being sufficiently clear. So. Yeah, so let's go back up here. So what we said, we talked about the part as Alex's question. The partial order will give us an is your decomposition, but it might not be a unique decomposition. There may be different orders you can take, take things in. Say one thing I want to be clear about.
00:53:04.530 - 00:53:39.434, Speaker A: So I didn't do an example, but in the example I had drawn arrows on the edges and used this to find the strongly connected component. That was a directed cycle. Here the choice of directions doesn't matter. So I said it has to satisfy whatever it is. There's dedirected orientation conditions. So it has to be that the out degrees are exactly d for inner vertices and it has to be the out degrees are exactly zero for pinned vertices. But that's the only condition.
00:53:39.434 - 00:54:22.600, Speaker A: In fact, what's true is that if you take any directed cycle in your graph, in your directed graph and you reverse the orientations on that cycle, you will not change the strongly connected components. And hence we're about to see is the strongly connected components. Tell us your co decomposition and hence the if you choose any do directed orientation you're fine. You pick one however you like and it will always work out that you don't end up having different decompositions into a SEO components based on different orientations. It's all the same. That shouldn't be a worry. Okay, so here's the theorem, which again today I decided not to prove.
00:54:22.600 - 00:55:35.572, Speaker A: So maybe I'm just being a bit lazy today, but the theorem due to offishai, Adnan Shloker and Walter Whiteley says if you have a pinned minimally de rigid graph with any orientation of the the edges, any dedirected orientation, then the following three things are equivalent. So this DSUO decomposition. So the minimally pinned, minimally de rigid subgraphs decomposition the decomposition strongly connected components. But we also have, which I've sort of omitted to say a block decomposition of the rigidity matrix. So we know we have, let's say we're in d dimensions, we've got di columns, we know we need to have square submatrix with di dash rows for it to be minimally rigid. So we end up decomposing block by block, like this should be some dots, and then these things are equivalent. And so the one nice thing about this is that about the theorem, is that when talking in D dimensions, yet there's this nice combinatorial understanding of the, the rigid parts of the, the graph.
00:55:35.572 - 00:56:26.524, Speaker A: And the trick I guess, for that is that we're assuming minimally de rigid. So we're assuming we don't have problems, we don't have double banana kind of things, because we're minimally de rigid. So the rows are all nicely independent. We know the rank, we know that as soon as we have something of the right rank, it will be a pinned minimally derigied thing, and hence it will be in a sewer component in this decomposition. So maybe that sort of gives you a hint as to how the, at least one of the parts of the proof goes. And again, the strongly connected components are related to this graph orientation thing, which is for the graphs with the sort of d comma zero sparse graphs, any of those can have it. But for d zero type graphs, again, you get to these relevant components from your conditions.
00:56:26.524 - 00:56:56.364, Speaker A: I appreciate I'm basically out of time, so I'm sort of starting to rush. And maybe I should actually stop because there is probably too much to fit into 1 minute. So maybe I will stop and I'm happy to answer any more questions and I can, if people want in the next lecture I give, I give, say a bit more about SEO decompositions. I did have a few more little remarks and a result or two to mention.
00:57:00.674 - 00:57:06.174, Speaker C: So will you be in the next lecture discussing applications of this.
00:57:09.914 - 00:57:44.174, Speaker A: I forgot to be honest. What was I going to say? Yeah, so I was really going to do very little, as you can see. More, the main thing is that strongly connected components can be tested very efficiently. So if you, if I give you a minimally de rigid pinned graph, then you can tell me very efficiently, the strongly connected components. And the nice thing about that is if we go to the example that's sort of been destroyed by now. So let's go to it. Let's write out a.
00:57:44.174 - 00:58:57.984, Speaker A: So we start with something trivial just to build up some space, and then we can maybe have some, some other more complicated parts. So if I give you something that's minimally pin de rigid, then what the. I think what the engineers like about a serographs is it says, well, if I delete one edge somewhere, which vertices move in there, so what parts of the mechanism they've created are actually moving nicely. And so it should be clear from the minimality of the things, if there's no rigid subgraph at all, and you remove something, that everything will move. So if you're in a sewer graph and you remove an edge, they call it a driver, which says that everything goes into motion, whereas if I remove one up here, then clearly the things down here are not going to move. And so they can control by looking at which part of the decomposition is what's in, what's in motion and what's not. So I think that's kind of the intuition for the kind of applications they're interested in.
00:58:59.764 - 00:59:10.624, Speaker C: Okay. And you can, I guess you can apply this to Laman graphs by just pinning two vertices or pinning an edge effectively, I guess.
00:59:17.344 - 00:59:19.432, Speaker A: What do you mean apply it to the mangroves?
00:59:19.608 - 00:59:49.354, Speaker C: So, I mean, if I wanted to see what happens to the mangraph, like how it moves when I remove an edge, like what parts of the graph move, all I need to do is take my Loman graph, pin both sides of an edge and delete that edge, and then just do the decomposition of the pinned framework. I guess then that would tell me what happens when I remove certain edges and stuff.
00:59:50.734 - 01:00:52.554, Speaker A: Yeah, I think so. But there is a, there's a related problem that's a bit subtle, though, that outlet mangroves. So somehow looking at these, a serographs for pinned is easier than the Lehman case. So if I give you a. I might get this wrong, because I haven't thought about this for quite a while now, but given a minimally too rigid, minimally rigid in the plane graph, whose only rigid subgraphs are let's say single edges. I want to give this a name. So, at minimally rigid graph, because only rigid subgraphs are single edges, is called a, I want to say mig.
01:00:52.554 - 01:01:16.974, Speaker A: So this is just consistent with a paper of Rudy Penner from the nineties, I think. So here's what I think is a hard problem. Give a Henneberg oops recursive construction of migs.
01:01:19.434 - 01:01:21.386, Speaker C: And you want every step to be a MiG.
01:01:21.530 - 01:01:49.656, Speaker A: Yes. Yes. Well, if you didn't want that, then just though the one that exists for the mangraphs would work. And so this, this to me is a sort of analogous kind of situation. So I'm minimally too rigid. But the only rigid sub graphs are single edges, is somehow a mysterious class of graphs that would have interesting applications. And if you like this, where I said single edges, you might replace that with r complete.
01:01:49.656 - 01:02:19.704, Speaker A: So you might allow a triangle. We might say triangle is fine, but nothing bigger. But in either case, I think there'd be, there'd be interesting applications if something, if this could be done. But I think it seems, well, at least to me, it's hard. And so I'm a bit, in general, a bit concerned about moving to a sewer, like things in the non pinned world because of this kind of problem. Doesn't say what you said was false. It might be what you said was true, but it's just.
01:02:19.704 - 01:02:26.024, Speaker A: I'm just saying there's some subtleties around the unpinned world for this kind of problem.
01:02:30.764 - 01:02:43.464, Speaker C: Maybe it's fine because the Azer decomposition is not going to give you a one extension, a Hennenberg recursive. It's different to that, I guess.
01:02:44.924 - 01:02:54.004, Speaker A: Yeah, I guess I just like the opportunity to advertise this problem that I'd like to solve but haven't managed to. It sounds interesting. Okay.
01:02:58.944 - 01:03:01.524, Speaker C: It might be more tractable in.
01:03:03.544 - 01:03:03.880, Speaker A: Two.
01:03:03.912 - 01:03:08.844, Speaker C: Two tight graphs, actually. I guess that's a completely different problem.
01:03:17.324 - 01:03:35.796, Speaker A: Why? I never thought of it. Maybe what's the analogous question for two two? Are you talking about the red question or the black question or the in between one where triangles are okay. And k four is not? Yeah.
01:03:35.820 - 01:03:58.844, Speaker C: So kind of my idea would be that you can't have, you probably don't have, like the vertex to k four extension move. Maybe I would need to think about it, but I think maybe you won't have something. Oh, no. You could still possibly have that. Okay, now, forget what I said. Actually, I'm not. I go back on what I said, it might still be very difficult.
01:04:01.584 - 01:04:49.384, Speaker A: I'm writing it down because it, I mean, I have no idea why it would be interesting, but just because I like two, two tight graphs, so it might be interesting to me. Okay, so the problem with items and where I'm keeping people longer than maybe I should, but. So the problem, I guess what you're saying, sean, is that if you had a two two type variant, you might get rid of the problem where you try and do a recursive construction of two two tight graphs where you have lots of k four s in your graph. And now the degree free here can't be reduced because in a k four, but maybe all of them are in k four. So maybe your graph looks something like this one, and now nothing's reducible because they're all in. There's no degree twos in all the freezer in k four s, which you don't want, and you want to be in the simple graph world. Yeah.
01:04:49.384 - 01:05:38.834, Speaker A: So if you said the only rigid subgraphs are single edges, then this graph would disappear. But even in the two free world, I have no idea how to do a reduction at a degree free vertex, because it might be that there is a large set here with two x minus four, which I'd be perfectly happy adding the edge in and still being too free tied. But now I'm not because it would create two free tight proper subgraph, and hence it wouldn't be in this no rigid subgraph case anymore. So the blocks to the degree free moves are much more global than k four s. So in either case, the two two tight world or the two free tight world, you'd still have this sort of worry.

00:00:00.160 - 00:01:03.824, Speaker A: To be at fields. It's a great pleasure to be lecturing again with chalkboard. So the work I'm talking about today is joint with Jim Preitag, Ramey Zhaoi and Ronnie Naglu. We'll always be working in k, some saturated differentially closed field, and c will be the constant field. So the starting point for this is an old result of Poisson from the mid seventies. I think it's in one of the Paris seminar volumes. I don't think it was ever published in a journal.
00:01:03.824 - 00:02:00.110, Speaker A: Look at the solutions to the equation. X prime equals xx double prime. So this is an order two differential equation. What he proved is that the only order one's differential sub variety is the constant field. It's just given by x prime equals zero. Of course, if x prime equals zero, that'll be a solution to this, but it's the only one. Now, this is at least the first example that model theorists had that differential algebra is weird, that it's very, very different from the differential.
00:02:00.110 - 00:03:03.114, Speaker A: Algebraic geometry is going to be very different from algebraic geometry. So this is a transcendence degree two set. I mean, x and x prime are going to be algebraically independent elements for, for a generic point. But in algebraic geometry, you think if you have something of transcendence degree two, it'll have a lot of transcendence degree one sub varieties. This says that in differential algebra, that may not happen. So this is an example of something which is, it's the first example of something that's. And I'm going to rewrite these equations most of the time, and to sort of throw out the x prime equals zero locus, I'm going to think of this as being x double prime over x prime is one over x.
00:03:03.114 - 00:03:55.558, Speaker A: And this is going to be the first example of an order one order greater than one strongly minimal set. It's also an example of something that's irreducible, but has morally degree two. There are two rank one types, the type of x prime equals zero, and the type of a generic. Pardon, this set strongly. Sorry. So this set is, so this is the first example in order greater than one strong normal set, the original variety sum, it's irreducible input. But morally degree two, again, very different.
00:03:55.558 - 00:05:09.952, Speaker A: What one might expect. And just using algebraic geometric intuition, there's a proof of this in my lecture notes on differential fields. Probably none of you read the proof because it's three pages of algebra, doing calculations in the differential polynomial ring, and eventually showing that if I take any order one polynomial, the differential polynomial that divides this one, then x prime has to divide that. I'm not sure anyone has read that, except Jim Freitag in his thesis, I think an unpublished part of his thesis. He gives a variant of this. You look and set it x double prime, x x triple prime, and now x double prime equals zero is the only, is the only infinite proper sub variety. I had suggested he look at this problem, because this is something, again, that's quite weird.
00:05:09.952 - 00:05:37.394, Speaker A: It's a, you know, it's a Colchian closed set, and all the Morley rank is constant. It's rank two, but all the Morley rank is concentrated in the sub variety. So the generic, the generic type, in the sense of the Colchian topology, isn't generic in the model theoretically. Again, this is an even worse computation. So let me just give you some examples of.
00:05:37.554 - 00:05:46.846, Speaker B: So, Dave. So, Dave. Sorry, Dave. This example is also strongly minimal outside the infinite. Outside that, yeah, yeah.
00:05:46.910 - 00:06:25.854, Speaker A: Again, this is the only way you can get a differential algebraic sub variety of this is to take x double prime equals zero. So by quantifier elimination, there's nothing else. So again, some other examples of higher order strongly minimal sets. And. Okay, so, okay, so there's this. As I said, you start with the example of Poza. It was generalized in work of Burstowski.
00:06:25.854 - 00:08:00.474, Speaker A: I'm not going to state exactly what his result is, but he sort of finds a class of, a class of different strong, eminent old sets. But where Pozza's computations and proofs more or less work, as is a more natural example, was done by Colchian, who's sort of the first panel of a equation, x double prime is six x squared plus t. And sort of, in a letter from Colchian to Carol Wood, he gives a proof that this has no, this is an example of a, an order two differential sub variety. There's no order one sub varieties. The next examples really come in Hershofsky Sokolovich, and this is when you get to monum kernels. So, just to remind you here, a is a simple abelian variety. So, no proper infinite subabelian varieties, not isomorphic to a variety defined over the constants.
00:08:00.474 - 00:09:51.064, Speaker A: And Osharp is the minimal infinite definable subgroup. We can give a more concrete characterization as the Colchian closure of the torsion points. Naglu and Pele looked at panel equations with generic parameters and showed that these were strongly minimal. These are strongly minimal and trivial. I'll say a bit about that in a minute. Freitag and Scanlan looked at the equation, satisfied by the j function and show these were strong, minimal, trivial. I guess these are order two equations.
00:09:51.064 - 00:10:28.504, Speaker A: These end up being. The order ends up being twice the dimension of the abelian variety in these cases. What's interesting about these things is all these results are kind of hard. I mean, the Poisson example and the Colchian example involve sort of horrible calculations. I mean, the first version of my differential fields, note had the Colchian example in it. It later appeared in his collected work. So I took it out because I didn't want to.
00:10:28.504 - 00:10:32.024, Speaker A: I didn't want to claim that the argument I gave was completely right.
00:10:32.884 - 00:10:35.904, Speaker B: Dave Colchen is pen levy one, right?
00:10:36.334 - 00:11:08.254, Speaker A: Yeah. Panlove a one. Yeah, yeah. Of course, this is a non trivial argument. This depends on some of the lot of the work done by the japanese school in differential algebra. This result uses Pilaw's stuff on excellent weierstrass theorem for j functions. So I find this an interesting point that it's very hard to show.
00:11:08.254 - 00:12:44.424, Speaker A: For the most part, it's been very hard to show anything is strongly minimal, but maybe almost everything is. So, some recent results. One of Rami, you take a, a generic planar vector field, a polynomial vector field over the constants. I think I want to say a degree greater than or equal to three, but maybe I want to say greater than three. This is going to be strongly minimal. And a more recent result of Matthew Devilbuss and Jim Freitag. I want to look at f of x equals zero, where the, let's say it has order n degree at least two times n plus two, and differential transcendental coefficients.
00:12:44.424 - 00:14:55.154, Speaker A: This is somehow saying that a reasonably complicated differential polynomial, if it's generic, it's going to be strongly minimal. So, even though it's very hard to show particular examples, this somehow says most of them are okay, let me just remind you of the trichotomy in this case, and this again goes back to Hiroshowski and skull of it. There was a model theory year here in, I think, 96, 97, and Anand gave a course where he did some of these things. So again, I have x strongly nmol. Then one of three things happens, and basically you get the Zilbert dichotomy, but in a quite strong way. The Zilbert trichotomy in a quite strong way, either your non orthogonal to constants, or you're non orthogonal to a monochirnal, or you're trivial. So the non locally modular cases, the only non locally modular cases are the constants.
00:14:55.154 - 00:16:27.504, Speaker A: The only non trivial locally modular cases are the modern kernels as a result, which I think is probably folklore. It's a corollary to this. Suppose I have an equation f that's over the constants, an order bigger than one. If it's strongly minimal, it has to be trivial. Part of this is easy, that if it has, if the order is greater than one, it can't be non orthogonal to constants because the transcendence degrees are wrong. It takes a slight bit of work to show that if it's that because it's defined over the constants, if it's locally modular, non trivial, it can't be non orthogonal to a mall and kernel. So this says that the Poiseau example, the Poisson example at least, is, is an example that's trivial.
00:16:27.504 - 00:17:16.804, Speaker A: Okay, so that's the introduction. And the jolly ones are. Yeah. The other ones, you have to give some kind of proof that they're trivial. And one of my favorites is, I find the Pillai Naglu proof of triviality is, I find particularly amusing because it uses an essential way that there are non generic things that are not strongly minimal in the proof that the generic things are trivial. Here's the theorem. I.
00:17:16.804 - 00:18:48.114, Speaker A: What I want to look at today is I want to consider the general family of equations which Pozza's equation fits in. Let f be some rational function of the constants. And I want to look at x double prime over x prime equals f of x. Okay, so the first observation, and this, I think, is actually in Pozov's original article, suppose you take g of x. So if g is in c of x and g prime, which I'll use to denote just the usual derivative of g with respect to x is f. So this says I have a rational function f, and I can integrate it as a rational function. Then, if I look at the differential equation g prime equals g of y plus c, and I differentiate this, I see that y double prime is f of y prime.
00:18:48.114 - 00:20:53.844, Speaker A: So if I have a function f that can be integrated, I'm always going to have an infinite family of, of one dimensional sub varieties, or a function from this variety to the constants. So this is this case, I get something of rank two, and I get something that's non orthogonal to the constants. If I have time, I'll say a bit more about what the possibility, what some things that could possibly happen in this case at the end, and our theorem is somehow that the converse holds that if, if f has no antiderivative in c of x, then the equation defined as strongly minimal, and by necessity trivial. The interesting thing is that. Pardon? Thank you. That, unlike the pozad example, this has a. Well, unlike Pozza's proof, this is a very short and memorable proof that I'll shortly give.
00:20:53.844 - 00:22:10.324, Speaker A: So, first, how do I use no antiderivative? Well, now, there's an advantage to having spent years teaching freshman calculus. So, I have a rational function. I can do the partial fraction decomposition. And since I'm doing it over an algebraically closed field, I can always write f as a derivative plus a second term, a derivative plus a linear combination of terms, one over x minus alpha I. And so f is. Now, of course, things like this don't have to integrate them. I would need to introduce logs.
00:22:10.324 - 00:23:19.394, Speaker A: So, being integrable is exactly saying. Being non integrable is exactly saying sum CI is not zero. Equivalently, I can take f of x and write it as a Laurent series, the sum from some r, possibly negative, to infinity. AI. Let's see. Sorry. Let me say, without loss of generality, I want.
00:23:19.394 - 00:24:02.994, Speaker A: I want to have a simple poll at zero. I could, because the alpha is a constant. If I do a change of variables, x minus alpha, I, that will just change the problem to one where I have a pole at zero. And now, if I write out the rational function, what this ends up telling me is that a minus one is not zero. So there's a residue. This is a residue. Okay.
00:24:02.994 - 00:24:43.930, Speaker A: Okay. So that's what I know about x. So, let's suppose not. What would that say? Is it will? I would say that over some field, k delta, not necessarily over the constants. Maybe I have to add some terms in. There's a solution. Yeah.
00:24:43.930 - 00:25:47.194, Speaker A: That's transcendental over k. But y prime is algebraic over ky. Okay, this is saying that y and y prime satisfy some equation, algebraic equation over k. So, this gives me a first order equation. So, I'm going to work in the Plisso series. So, I take the union of the Laurent series y to the one over n for all. And in the fundamental theorem, this is an algebraically closed field.
00:25:47.194 - 00:26:59.514, Speaker A: So, I can identify y prime with some u in the pliso series, and I want to find a derivation. Delta. Then, if I differentiate a series, I'm going to get what I usually get first. A series where I differentiate the coefficients. But then I get u times the sum of the IaI minus one. So, we've chosen this derivation, putting this u in.
00:26:59.674 - 00:27:02.050, Speaker B: Sorry, Dave, can I ask something?
00:27:02.242 - 00:27:03.186, Speaker A: Sure. Yeah.
00:27:03.210 - 00:27:14.466, Speaker B: So, on the first line, I mean, you. You identify y prime just as a. As a. As a field object. I mean, just because it's algebraic over algebra over y.
00:27:14.530 - 00:27:15.734, Speaker A: Right, right.
00:27:17.074 - 00:27:18.654, Speaker B: There's no derivation yet.
00:27:18.994 - 00:27:20.358, Speaker A: There's no derivation yet.
00:27:20.466 - 00:27:22.246, Speaker B: Okay, just to, now I built the.
00:27:22.270 - 00:28:47.344, Speaker A: Derivation and I've done this exactly so that delta y is u. So I've chosen u so it satisfies the right algebraic equations with right algebraic equation with accept to y. And now I've defined the derivation so that delta of y is u. So this extends the derivation on k of y, y prime. The derivation is now on the full puso series, but it extends the natural derivation we'd have on delta y prime. Okay, so let's, let's write u out as a series. Let's say it's the sum from zero to infinity and y to the r plus I.
00:28:47.344 - 00:29:25.312, Speaker A: What? I'm putting the r. I'm putting the, I'm putting the r here. So it looks something. One way to write it is something like this. So y double prime is u prime. Pardon? I equals zero to infinity, AI y to the r plus I over some n just as a sum crucial series. Sorry, I changed things a number of times as I was writing it down.
00:29:25.312 - 00:30:29.820, Speaker A: So I write out the derivation. First I differentiate the coefficients, then I get u times the usual derivation. And let's just notice, let's see this part. If I look at the valuation, which is the lowest term with a nonzero coefficient, this is at least r. So let's look at y double prime over y prime, which is u prime over u. And let me just write alpha here for this part, divided by u. And so I'm dividing by something that has value r.
00:30:29.820 - 00:31:30.394, Speaker A: So this has value greater than or equal to zero. End up ignoring that. Here I just cross out the, um. Okay, and this is supposed to be equal to f of y. Okay, all the terms here have powers that have powers of y that are non negative. Here you look at the y to the minus one coefficient that happens when r plus in is zero. And now I've multiplied that out.
00:31:30.394 - 00:32:25.424, Speaker A: I've multiplied by zero. So the y to the minus one coefficient is zero. So this can't be equal to f of y. So you see what I mean when I say this is sort of a memorable proof. It's not so special, this equation. Dave, can you say again why the coefficient is zero, the last coefficient? Ah, sorry. Yeah, if I look at the coefficient of y to the minus one, where does that come from? That comes from when r plus in is zero and I multiply, so I've multiplied by zero that term.
00:32:25.424 - 00:32:43.694, Speaker A: Oh, right, right. Okay. Yeah, it's just right, sort of. You take a rash, any power series, you differentiate it using the standard derivation. You don't get a minus one, you don't get a minus one term. I'm sorry, there was another question. Yeah, I was talking about extending the derivation.
00:32:43.694 - 00:33:08.844, Speaker A: So, I mean, you just, you have to check that this is, I mean, the usual derivation. I put on the power on the Piseau series. I would define the derivation so that y has derivative zero or derivative one. And I, so I would just not have the u term here. That's the standard derivation. But just. You can check this is a derivation and it does what I want it.
00:33:08.844 - 00:34:54.624, Speaker A: Let me give a strange corollary that we've just discovered in the last couple of weeks. Let's say again, assume f has no antiderivative. Now, I want to look at this equation, y double prime plus f of y, y prime plus. And now I'm just going to write down the generic rational function with the sum from one to n, or zero to n of cix to the I sum from zero to m di xdi, where the CI di are algebraically independent constants. Let's see, x's or y's. So, I've written down some kind of generic rational function here. What I can conclude is that this has to be orthogonal to the constants.
00:34:54.624 - 00:35:57.254, Speaker A: What I don't know is. Sorry, let's make an equation. What we don't know is whether it has to be strongly minimal, but it's going to be orthogonal to the constants. And this follows from a specialization theorem of Jolly that under Nice, you have a nice map between d varieties where everything's defined over the constants. If, when I look at the d points, if a generic fiber is non orthogonal to constants, then all the fibers are non orthogonal to constants. Since we know there's some fiber, if we chose all the CI's to be zero and all the di's to be one, I'd get a zero here, and I know that's orthogonal to the constants, then the generic fiber is going to be as well. These are examples of something called Lenard equations.
00:35:57.254 - 00:37:11.024, Speaker A: So these are equations of this form which arise in things like circuits, I believe, maybe some kind of planetary motion things. They're studied a bit by applied, by applied mathematicians, and they try to prove things like whether you can find solutions in Louisville extensions. Now, I don't think they've ever looked at. They tended only deal with special cases, mostly with f and g or polynomials. But what this kind of result says is that because things are following the constants, you're not going to get them two step analyzed little by constants, which they would be if they were if you could find solutions in a Louisville extension. This says something about solutions to this type of equations. We're still working on what this might mean.
00:37:11.024 - 00:38:28.744, Speaker A: Okay, I want to look a bit more at these equations and try and understand the algebraic relations between them to give a sort of more fine structure. So I want to look, let's say so by vf, I mean, prices were x double prime over x. Prime is f of x. And let's let x be in vf, yb and vg, where these are generic solutions. Now, I'd like to understand, when can we have algebraic differential algebraic relations between x and y, again by triviality. I know that if I have relations, they sort of only hold. I don't need to have a lot of things from vg to get out x algebraic with only algebraic over, it'll be algebraic.
00:38:28.744 - 00:40:01.076, Speaker A: Oliver, one, the first theorem, which I won't say anything about the proof of this. So, suppose again for some k, x and y transcendental over k. So, suppose I have two solutions like this. X is solution for f y, a solution for g, possibly f equals g. I'm allowing here, and over some field, they're inter algebraic in the differential sense. Then actually they're algebraic first over the constants. Again, that's mostly a consequence of triviality, but the derivatives don't matter.
00:40:01.076 - 00:40:49.834, Speaker A: If this happens, then it's actually because x and y are inter algebraic. And the proof of this, well, it certainly makes essential use of triviality, but also the connection between transcendence and Kaylor differentials. And it builds on work of Rastoffsky, but also Rosenlicht, his proof of non minimality, of differential closures and ultimate, originating really in acts in his work on Shanuel's conjecture for powers.
00:40:51.574 - 00:40:54.674, Speaker B: Sorry, Dave, the assumption, what's the assumption on x and y?
00:40:55.454 - 00:41:12.810, Speaker A: So it's. It's this one that these are. Let's say x is a solution of the equation with f. Y is a solution with the equation with g. Each of f and y are transcendental over.
00:41:12.842 - 00:41:17.494, Speaker B: K. And something about no antiderivatives.
00:41:18.754 - 00:41:42.954, Speaker A: Oh, yeah, sorry. I'm in the case where I'm assuming this is strongly minimal. No, no, I mean, that was only in this. Weird. These are just f and g. Sorry, I should write this out carefully. F and g, rational functions over the constants with no antiderivative.
00:41:54.514 - 00:41:56.014, Speaker B: Okay, thank you.
00:41:59.674 - 00:43:03.444, Speaker A: So we do a quick calculation. So there's going to be some algebraic function c, where y is phi of x. So y prime is phi, prime of x. X prime. For this, I just mean the formal derivative of c x prime. Take the second derivative, I get phi, prime of x. X prime squared plus.
00:43:03.444 - 00:43:36.404, Speaker A: No, I get phi double prime of x. X prime squared plus phi, prime of x. X double prime. But this is y prime, g of y. Pardon this line. Yeah. So I'm just.
00:43:36.404 - 00:44:58.750, Speaker A: So by psi prime, I mean just the formal derivative, but just the chain rule and the function applied to x to differentiate that I differentiate the function and differentiate what's inside. Now, I replace this by x prime, f of x. I recognize that y prime, g of y, is phi, prime of x. X prime, g of phi of x. Now, rearranging terms and canceling an x prime, I get this equation. Phi, double prime of x times x prime, is phi, prime of x. G of x.
00:44:58.750 - 00:46:24.764, Speaker A: G of phi of x minus f of x. So, starting from this assumption, I get to this equation over the constants. Yeah. Now, if this were non zero, I would have a first order equation satisfied by x and x prime. Remember, phi, prime of x and phi, double prime of x, are just your algebraic functions over the constants. So this would give me an algebraic relation between x and x prime. And that violates strong minimality.
00:46:24.764 - 00:47:09.614, Speaker A: So that tells me that this algebraic function is particularly simple, is just a linear function, ax plus b. Now, phi prime can't be zero. That would, if phi prime were zero, that would say phi is just a constant function. It's supposed to map. It's supposed to map into something transcendental. So this is non zero. So if the left hand side is zero, the right hand side has to be zero and it has to be zero, because this is true.
00:47:09.614 - 00:49:06.284, Speaker A: So this also applies that g of phi, of x, is f of x. Yeah, yeah, yeah, yeah. Okay. So if I think of the affine group and I think of the action, um, think of phi as acting by composition. What this says is that vf and vg are non orthogonal if and only if they're in the same orbit. So this, I mean, certainly if, if g was given by f, composed with c, that would give me a function from vf to vg. But this says, this is the only way it can happen.
00:49:06.284 - 00:50:09.684, Speaker A: But what about when f equals g? So the same situation. But now I've got x and y both in phi of f. This would say that phi stabilizes fucking. So this usually doesn't happen. This is impossible. If, say, f is reasonably generic. Or in something like the original Poisson case, f of x is one over x.
00:50:09.684 - 00:51:03.964, Speaker A: So in these cases, it tells you that the algebraic closure is disintegrated. The only element of vf that's algebraic over x will be x itself. For any other element, it won't be true. Finish up very close to the end. Pardon? Rational function. Yeah. Let me give you two examples where this does happen, and you do get algebraic closure.
00:51:03.964 - 00:53:16.724, Speaker A: If f is one over x minus a minus one over x minus b, you have this function phi, which has, it's an order two function that maps f to itself. So in this case, you get at least a least a point that has another point in the algebraic closure. Another example, let's let c we have primitive nth root of unity then, and look at the sum of the one over CI to the x minus one, and phi of x is just c times x. Okay, that will permute, that'll permute this function. Let a be the places where we have a non zero residue. There's at least one. If n equals one, it's a simple computation shows this is impossible.
00:53:16.724 - 00:54:22.614, Speaker A: So we're in the disintegrated case again, if n is greater than one, I'm going to use the fact that the affine group is at x on the, on the, on the line is sharply too transitive. It's going to have to. Any rational function that permutes the, any rational function that preserves f is going to have to mute the alpha is. So there are n choices to where to send alpha one, n minus one choices for where to send alpha two. And then once I've done that, I'll know the whole permutation. So they're going to be at most n times n minus one. Affine functions that permute these things.
00:54:22.614 - 00:55:11.954, Speaker A: So this tells me that I've got a bound on the size of the algebraic closures of a point, so that even though I don't know that it's disintegrated, I still know that I have Aleph zero categoricity. And in fact, a much more complicated argument shows that n is actually good enough that this example with the roots of unity is sort of the worst. The case where you get the most algebraic. Okay, so I'm out of time, so I'm stuck. I'll stop here. I'll say we do know a little bit about what happens in the, what can happen in the, in the case where f is integrable and sort of like everything that might happen does, but. So.
00:55:11.954 - 00:55:55.054, Speaker A: But I'll stop here. Thank you very much for the talk. Are there any questions in the chat? Maybe. Let's thank the speaker again. Thank you. Well, I mean, if I have something.

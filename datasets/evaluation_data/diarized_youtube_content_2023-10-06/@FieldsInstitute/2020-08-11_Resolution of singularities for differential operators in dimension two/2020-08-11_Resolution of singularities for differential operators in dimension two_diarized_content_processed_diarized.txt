00:00:02.720 - 00:00:02.944, Speaker A: Yeah.
00:00:02.944 - 00:00:24.674, Speaker B: So, welcome to the geometry and model theory seminar, summer edition. Today's speaker is from Strasburg, Daniel Panazzolo. And he will tell us about the resolution of singularities of differential operators in dimension two.
00:00:26.474 - 00:00:35.014, Speaker A: Okay, so, first of all, thank you very much for the invitation to the seminar. So for, for those.
00:00:37.274 - 00:00:43.934, Speaker B: Oh, sorry, Daniel, I need to unmute you for some reason.
00:00:48.314 - 00:00:49.794, Speaker A: Can you hear me? Yes.
00:00:49.834 - 00:00:50.818, Speaker B: Now it's good. Sorry.
00:00:50.866 - 00:01:24.872, Speaker A: Yeah, some people perhaps have heard this talk in the Zagreb's seminar. So, I'm sorry. It will be quite similar. So. And I hope it will be understandable, because I just try to be very basic. So, yeah, so the basic problem that we can put is to solve differential equations. So here I, I make a small introduction about, let's say, ordinary differential operators versus partial differential operators.
00:01:24.872 - 00:02:01.644, Speaker A: So, in the more general form, you can imagine this as a polynomial in a function and its derivatives. And this function can, of course, depend on several variables. And you want to solve such a kind of equation. And of course, things. The basic thing that you want to answer, first of all, is the existence. So we have same very general results for the existence in the case of ordinary differential operators, it's the Koshylips theorem. And then in the case of partial differential equations, have more or less general result, is the Koshikovalevsk.
00:02:01.644 - 00:02:03.784, Speaker A: I'll come back to this a moment.
00:02:04.084 - 00:02:08.224, Speaker C: Any means a polynomial or just any function?
00:02:08.644 - 00:02:54.824, Speaker A: Yeah, that's, it's any function for the moment, but particularized to the case of polynomials. And in my case, in fact, I try, I would treat linear differential operators. So here I have to suppose that t is linear in f and in these derivatives. But of course, for the moment, it's just a general discussion. And I would. Yeah, that's the meaning of solution. And of course, instead of solving the equation explicitly, you can also try to understand its qualitative behavior in the sense of poincare.
00:02:54.824 - 00:03:20.304, Speaker A: So it's. Okay. Let's see. It's. And okay, some basic, let's say, question is how to simplify. When you are in face of a very complicated differential equation, you want somehow to simplify it to fall in a simpler case. And the matter is that singular differential operators appear very naturally.
00:03:20.304 - 00:03:59.856, Speaker A: So, just a simple example related to the actuality. So here, the c model for epidemiology. You see that even if you write these simple differential equations, you, you find yourself with a singular point here. And interesting things happen near the singular point. So this is an ordinary differential operator, an example of a singular, singular, partial differential operator. It's a very classic example of the Laplace equation when you try to solve it on open manifolds. So more generally, I'm talking about laplace equation on manifolds.
00:03:59.856 - 00:04:50.586, Speaker A: This, so this is in fact the Laplace belt Romeo operator. And in this case, to write the Laplacian, you need to have a metric on your manifold. And if your manifold is open, usually you want to compactify to see what happens at the boundary, let's say. And sometimes when you compactify, you find yourself with a cusp or a single point like this, and your metric degenerates on this point, right? So if your metric degenerates, you find yourself with a singular differential, partial differential operator here. And this is also very, let's say, studied problem for people, which works in the elliptic differential equation. Partial differential equations. So now I'm, I'm going to define more or less precisely my object.
00:04:50.586 - 00:05:37.008, Speaker A: So what's the linear differential operator? So in general terms, you consider a manifold, let's say, the real analytical allomorphic setting. And you have two vector bundles, e and f over m. And now you can define a differential operator between these bundles as a linear map between the sheath of sections of this bundle. So you have this, it's amorphism of sheets. So you have the sections of the first bundle, the section of the second bundle, which I write by calligraphic e and calligraphic f. And you have this morphism here. So of course this to general object.
00:05:37.008 - 00:06:59.264, Speaker A: So in general, you can classify this morphism in terms of its order. So how do you find the order of a differential operator? You see how it commutes with the multiplication by functions on the structural sheath. So a differential operator has order zero if it commutes with the multiplication operator. More precisely, if you have this relation here, where mu of f is simply the map which multiplies section of the bundle by a function f, right? So if you have this commutative, you say that the operations of order are zero, and more generally, you say that the operator is of order d. If it's d, bracket with the multiplication operator vanishes after d after de iterations, right? So, basic example. So, allomorphic function, you consider anomorphic function on your, on your manifold, and it defines clearly a differential operator of order zero between the structural index in the structural sheath, right? Since of course, it commutes with all multiplications. In the same way, a vector field defines the differential operator for order one.
00:06:59.264 - 00:08:18.274, Speaker A: Again, considering here, then, let's say the trivial vector bound given by this descriptor sheath in this case, you see that after two commutations is the multiplication. This is just the Leibniz rule. You get zero. So it's vector fields, it's simple differential operator of order one, and more precisely, it's an homogeneous differential operator of order one, right? So of course in terms of local presentation, if you fix local coordinates on a point, you see that differential operators, simply written as in this form, where this feed k are just matrices with f rank of f columns and rank of equines. And of course, if it's of order d, then you have to make this, this here I'm using the multi index notation, of course. So this is, each term here is a differential operator of the derivation of order up to d. Okay, so in this talk I just consider the case where the ranks of these operators of this bundles of order one.
00:08:18.274 - 00:09:31.070, Speaker A: So you can imagine that locally, this phi k, this coefficient are simply functions, it's just section of the structural sheath. And well, even in this case you have very, let's say, difficult and interesting results. For instance, I have to ask yourself the question of local resolvability given a function f g. Sorry, you've tried to find an f such that if you have f equals g, and important index problems where you have to find more generally the rank of phi and the core rank of phi. And, okay, so a more general question is how you invert this operator. So of course you have this pseudo differential calculus where you try to place yourself in a convenient function class where you can explicitly write the inverse operator, right? So this very well developed, very well developed field. So the basic dichotomies here at that time you have the versus, versus the global versus the local behavior.
00:09:31.070 - 00:10:35.750, Speaker A: But what's going to interesting me more is the dichotomy between the generic versus the exceptional phenomena, right? So you can imagine that this operator has a different behavior in some exceptional set, let's say, which we're going to call the singular set, as opposed to its behavior in the generic, let's say the complement of this exceptional set. So this is the cotton with the singular behavior, and the generic behavior is what's going to interest us here. Let's say that's just basic example. So if we take a function, remember that I said that a function is a can be seen as a differential operator for their zero. And in this case, you can look at the level sets of the, of this function f, right? So in this case, let's say the singular set is the set where the levels, the set of the levels are not smooth. It's a singular set of coordination two. And explicitly it's given by the set.
00:10:35.750 - 00:11:50.134, Speaker A: If your function is reduced, it is given by the set where the differential vanishes. So of course our here we are interested in characterizing this singular set in more, in more gender for higher order differential operators, and then to understand what happens when you are near this singular set, right? So for a vector field it's, let's say more, perhaps not so classical definition, but what happens, another vector field is locally rectifiable outside the subset of coordination greater or equal to two. Right, two, one, sorry. So this is the simple, this is simply the flow box theorem, which says that locally, if you are outside the singular set, you can find local coordinates to error. Vector field is just a constant one, and the singular set is defined as follows. Just in local coordinates, you write your vector field, you expand this vector field in terms of the basis of the tangent bundle, and then the singular set is locked given by the vanish of these coefficients. Right, classical thing.
00:11:50.134 - 00:12:59.068, Speaker A: But of course our goal here is to understand what happens near the singular sets, right? So in some sense you can say that locally things are easy to understand on the generic points, but on the similar set there are much complexity which can appear. In fact, Tom called this points the organizing centers precisely because according to him, this is where the interesting things appear. So the goal is this like to have a good description and the vicinity of the singular points. And in fact there is a very powerful tool which has been developed during several decades to study the behavior near the similar points, which the so called normal form theory. But most of the time this theory is only, can only be applied when you, the similar points are not to degenerate. Not to degenerate, right. So it's usually works as follows.
00:12:59.068 - 00:14:12.944, Speaker A: If this singular point satisfies some non degeneracy condition in terms of its, let's say it's versal it is, and so on. You can say many things about its normal form, but we would also treat the degenerate case where the normal form theory is not directly applicable, right? So the approach that I'm going to propose here is the approach that in some sense has been used with quite successfully in the case of differential operators of order zero and one, which the so called resolution and reduction of singularities approach. Right? So let's say inverse schematically that there are some steps. The first steps define what we understand by the singularity of a differential operator. So for the moment I've not defined this. In the case where differential operator is order higher than two. But of course, we need some notion which will generalize the well established notions for the case of vector fields and for the case of functions.
00:14:12.944 - 00:15:18.554, Speaker A: So of course, the basic requirements that the local behavior should be simple to be defined outside the singular set. And well, preferably we want the singular set to be something which is of great co dimension, or let's say the simple behavior should be the generic one. Okay, now the second and the most difficult step of course, is to define is to prove that there exists a modification. So, supposing that you start with a pair given by a manifold and the differential operators, you want to modify your manifold and at the same point, at the same time modify your operator biomorphism, which I call phi, which such that, so what? Understand biomodification, it should be proper and a biolomorphism outside the singular set. Right? So by this I mean that you don't want to modify the points which are already good. They are the points which are. Your behavior is already simple.
00:15:18.554 - 00:16:07.784, Speaker A: And then the operator Phi prime, it's what you call the strict transform of the original operator. I'm going to define this more precisely in a moment. And finally, we want that all singularities of this. So we are not going to be able to eliminate completely the singularities here. Going to see that there are some phenomena which are persistent. But anyway, the goal is to simplify the singularity in the sense that all the singularities that you are going to find for this final differential operator should be amenable in some sense to the normal form theory. So we are going to call the final, this set of simpler singularity our final models.
00:16:07.784 - 00:17:20.484, Speaker A: Okay, so, do we have any questions? Okay, so just to give a small list of examples. So if you take the known case of functions, this is, as I said, it can be seen as zero order differential operators. And this is, of course, this program, of course, is completely, let's say, clear right now, because it's simply a consequence of Hirnacker's theorem on resolution of singularities. So in this case, of course, this modification exists. And what Hirnaka says is that the final model are simply monomials in the sense that each function can locally be written in appropriate coordinates as a product of powers of the SM anomaly. Right? So small drawing to illustrate this. So for vector fields, this is a more, let's say, new result and more recent result, and it's already completed in the case where the dimension of the ambient manifold is smaller or equal to, to three.
00:17:20.484 - 00:18:10.384, Speaker A: And now I have to define more precisely, what are the final models that say what we obtained by this resolution of singularities that I just explained it. So the final models are what we call the canonical singularities of a vector field. So what? How did I define this? So consider again a vector field given by, in local coordinates such as this. And the name canonical singularity comes from, let's say, a theory which is very fashionable right now in the algebraic geometry called the foliated minimum model program. And it goes as follows. So you consider the local ring at some point p on the singular set. So now here, phi, for me, it's a differential operator for the one.
00:18:10.384 - 00:19:29.642, Speaker A: And by definition, your differential operator maps the maximal ideal into itself, because f one and fn are supposed to vanish at p. So you have this relation, and by Leibniz rule, this also holds for all powers of the maximal ideal. So the kth power of the maximal idea is mapped to itself by the derivation and the linearization. Once you have this, the fact that the powers of the maximal ideal are preserved by the derivation, you can consider the linear map given by the linear endomorphism given by what you call the linearizations, the map of the quotients of m by m squared into itself. So if you are in a manifold of dimension, dimension, dimension n, sorry, this is isomorphic geo vector space of dimension n. So this is just, you can see this, just a linear map, just as a linear map of dimension n. Let's say a matrix n by n matrix in an appropriate, if you fix a basis.
00:19:29.642 - 00:20:02.434, Speaker A: And then we say that the, the derivation or the vector field is loganonical at the point p, if this linearization is not nipotent. So this is what we call log canonical. And then we have a more, let's say, precise notion of canonical, which I'm not going to give the precise definition here, but once you have a low canonical singularity, we say that it's canonical if, furthermore, it's not of radial type.
00:20:04.094 - 00:20:12.854, Speaker C: Daniel isn't the same as the traditional for this business name of the elementary singularity.
00:20:13.014 - 00:20:15.634, Speaker A: Yeah, that's the same thing. That's the same thing.
00:20:17.494 - 00:20:26.804, Speaker C: Of course, it's none of my business to dictate the terminology, terminology to other people, but.
00:20:29.024 - 00:20:29.924, Speaker A: Okay.
00:20:30.744 - 00:20:36.824, Speaker C: The idea is that local canonical is so fashionable right now that you can.
00:20:36.864 - 00:21:10.624, Speaker A: Be easily, well, there's my collaborator, McQuillan, which convinced me to change the name. I used it to use the name elementary also. But he says to me that the, the canonical means something more, let's say precise in terms of the functionality of the definition, because it's invented by birational maps. Sorry, but. And in some sense the name elementor is a little bit overcharged. In some sense. It's used for so many things that.
00:21:10.624 - 00:21:33.834, Speaker A: But it's the same. Let's say it's the same definition. It's not. Danielle, it's not the same, right? Almost the same, yeah. Log canonical. Yeah, log canonical is the same as elementary, but the canonical is elementary plus not of radial type. Sorry, I have to return.
00:21:33.834 - 00:21:43.382, Speaker A: I'm not going to define it. Okay, so in more concrete terms, if you want to.
00:21:43.478 - 00:22:08.554, Speaker C: I just wanted to defend the trademark that was defended by our society communities a long time ago. So not everything fashionable should be immediately put on the banner.
00:22:08.714 - 00:23:01.734, Speaker A: Yeah, but don't mind, because in a moment I'm going to change this name out again. So let's see if you prefer the last name, because it can also be put in a more general context where you can see this log canonical as a particular case of a notion which is very well established, let's say. Let's say in a more general context. So perhaps we can discuss this in the end. So let's say in the more general, concrete terms, if you consider the jacobian matrix, let's say d f I d xj is just asking for this matrix to have at least one on zero eigenvalue. So this is very, let's say, not perhaps a more classical definition. So in these two settings.
00:23:01.734 - 00:23:51.744, Speaker A: So again, I forgot to say this. So what? The results is that if the ambient space is of dimension smaller or equal to three, then you are able to achieve these final models by a finite number of blowing ups. So, modification of the ambient space is given by a sequence of sub elementary operators, which we call blowing ups. I'm going to explain this with just a drawing. A blowing up is just a way to separate lines through a point, roughly speaking. So imagine that you're in c two. So you have these lines through zero, and you can see these lines, more or less is the action of one dimensional torus on c two.
00:23:51.744 - 00:25:09.888, Speaker A: And then these lines are the orbits of this action and they're blowing up. It's simply. So you see that these orbits, they contain the origin and their closure. And the idea is that you're going to separate these orbits by this algebraic map. And now you see that, let's say these orbits, they arrive in different points on this projective space, in this projected line. And this map here gives this, let's say it's a birational map between some submanifold of p one times c, which is, let's say, in the real set inside, isomorphic to amoebus band two, c two. So the idea is that to separate lines, and of course, if this origin is some singular point where some complicated behavior appears, it's more or less natural to imagine that things are going to be simpler when you separate these lines, right? So this is local definition, just a basic example if you want to solve, let's say, this function again as a differential operator for order zero.
00:25:09.888 - 00:26:17.304, Speaker A: So you see that this is not of a monomial type, it's a cusp singularity. So if you do a first blow up, so schematically, I write, I draw this blow up as, um, let's say the projective line which parameterizes the lines through zero. I'm going to write this just as a small circle. So in the first blow up, you still see a singular behavior here which is not of monomial type. But after three blow ups, if you see what happens locally at each point, you are going to find that this function, or more precisely its strict transform, becomes locally monomial at each point of your new ambient space. So this is a say that we have achieved our goal here because we have achieved the local finals. Okay, so just very schematically, how, what do you obtain? Let's say just some drawings, if you solve the singularities of a vector field, dimension two.
00:26:17.304 - 00:27:12.654, Speaker A: So you cannot hope to have, let's say, this local monomial behavior. But you have a very well established list of topological final models. So these are what we call the phase portraits that you're going to obtain. So this is a very useful result in dimension two. For vector fields, for example, it can allows you to classify topologically the germs of real analytic vector fields in the plane, namely that if you have a real native vector field in a plane, if it has at least one orbit which goes to zero, then you can split a neighborhood of zero in a finite number of sectors which are either elliptic, parabolic or hyperbolic. Perhaps you know this result. And again, of course, this result also plays an important role in the solution of dulux problem.
00:27:12.654 - 00:27:48.978, Speaker A: It's an essential ingredient here. So for vector fields, dimension three, this is a more recent result. So I forgot to say that in dimension two, this is a result which was proven in the beginning of the 20th century. And for vector fields, dimension three, this is more recent. And in fact, what is interesting here is that you have to introduce a more general type of modification of a space which is called a weighted blowout or a quasi homogeneous blow up. So a quasi homogeneous blow up. I'm going to explain it also.
00:27:48.978 - 00:28:19.394, Speaker A: It's a drawing. It's more or less the same thing in the sense that you're going to. You're going to separate curves which are going through zero. But now these curves are not lines but they are monomial curves, right? So again you can imagine these as the orbits of some torus action. And these orbits all contain zero in their. In their closure. And then we are going to separate these orbits by some algebraic map.
00:28:19.394 - 00:29:05.914, Speaker A: So this, let's say this bold, bold line which appears here. In fact it's the. You can see this as the orbit space of your action. And in the case where the weights are not the usual ones, you have to. The orbit space is the weighted projective space, right? So in general this. This generalization of the notion of projective space is defined precisely as this by the orbit space of this kind of action, right? So what's the. Let's say, what's the advantage that you, you can take into account with this, the quasi homogeneity of your behavior of singularity? Let's say if you go back to the same example of your cusp singularity.
00:29:05.914 - 00:29:51.056, Speaker A: It can be dissingularized with a single weighted blow up. Which is given precisely by taking these monomials, the weights two and three. And you see that after one modification you achieve the local monomic behavior. One important ingredient here is that when you do these blow ups in higher dimensions in general your ambient space becomes singular. But let's say it's a singularity of a quite mild type. Because it's what you call an orbifold singularity. So it's essentially the quotient of a copy of CN by a finite group.
00:29:51.056 - 00:30:12.200, Speaker A: So we usually think that it's a quite controllable type of singular ambient space. So Matt, more question. Yes? So can you think instead of weighted projective space. Can you think of just the projective space and the weights go in the map? Like instead of having just a projection.
00:30:12.232 - 00:30:13.744, Speaker B: You can have a more complicated map.
00:30:13.784 - 00:30:32.144, Speaker A: That somehow give this weight or. Yeah, so what you can do is that you. I mentioned that you went. When you do this weighted blob. You find yourself within a similar ambient space. And then you can ask you can. What you can do is that you can de singularize this singular ambient space.
00:30:32.144 - 00:31:25.654, Speaker A: Using for instance. Hironaka's theorem, right? It would give you a modification mapping. Let's say a smooth ambient space shall new smooth ambient space. But the problem is that remember that you want to simplify let's say a vector field which lives in this initial manifold to a vector field which lives in your final manifold. And what happens in dimension three or higher is that in some sense you have a choice. Either you admit singularity on the ambient space, either you cannot achieve the final models. So in some sense, if you use your weighted blow ups, let's say you start a vector field here, you use your weighted blow ups and you end up with a norbifold with low canonical singularities.
00:31:25.654 - 00:32:53.104, Speaker A: Then if you try to dissingularize this ambient space by using hironographer, let's say, pass from an orbit to a smooth manifold, what you're going to see is that the singularities of the vector fields will become worse, right? So in some sense it's inevitable, at least in this setting, to allow singularity in the ambient space. This is by this, what I mean is that it's necessary to use weighted blow ups here because you have counter examples which say that either you admit singularity on the ambient space or you admit no log singularity for a vector field. Okay, thank you. Okay, so let me just make some comments about the basic techniques which are used here. So how do you control that a singularity improves under blow up? So the main combination object which is used, let's say, can be used both on the case of functions and in the case of vector fields, is the so called Newton polyhedron. I imagine that most of you have already heard about it. So let's say it has several applications, but for us it is used to control the resolution.
00:32:53.104 - 00:34:00.154, Speaker A: I'm going to define it here. So perhaps for the case of differential operators, not so standard definition. So again, we fix local coordinates and we write a differential operator for their d, like this expansion. But if you want to construct the Newton polyhedron, what you have to do is that you have to use the logarithmic basis. So in fact you're going to re expand this operator in the way that I've written here in the bottom, by meaning that you're going to expand with monomials x to the power squared multiplied by polynomials on these logarithmic differential operators. So of course, if you are in the presence of a differential operator of order d, these polynomials will be polynomials of degree at most d. Okay, but the subjectivity here is that these exponents can be also negative because we are forcing here the appearance of this logarithmic basis.
00:34:00.154 - 00:34:53.610, Speaker A: So some of these exponents can be negative. I'm going to show an example in a moment. So once you have this new logarithmic expansion, this is just more or less a classic construction. You define the support of your operator as the set of n sorry, integers. So you have this collection of polynomials p's. So the support is a set of n apples of integers such that the polynomial p s is not zero, right? Then the Newton polyhedron is just the convex envelope of the support Minkowski sum with the positive quadrant. So just a small example here.
00:34:53.610 - 00:35:43.926, Speaker A: If you take this function here, so differential period of order zero, you see that its support is given by the points 3002. And now I have written, I have drawn here that this Newton polyhedron is Newton polygon. So an example for a vector field of dimension two. So as I said, if you force the appearance of this logarithmic basis, you have to allow negative exponents. But I want to convince you that this is a quite natural behavior. So here you see that if you write the d over dx as x d over dx, you have an x minus one times y and this gives you the point minus 10. And in the same way you have the points two, the .2
00:35:43.926 - 00:36:29.554, Speaker A: minus one which should appear in your support. And the Newton polygon is now like this, right? Okay, so one last example takes, consider the heat equation. So differential operator further two. So now to make, to make the things simpler, it's easier to use this binomial notation. So we write the differential operator d over dx squared as x minus two. So this part here, sorry, I cannot. Yes, this part here is the same thing as d over dx two, right? But since you divided by two factor, I think yes, times two factor.
00:36:29.554 - 00:37:53.454, Speaker A: So if you want to, so this shows you that there, there is a monomial with coordinates minus 20, and on the same way there is a monomial with coordinates there, zero minus one. So this is the Newton polygon for the heat equation. Of course, one important thing is that this Newton polygon, it depends on the choice of the coordinates, right? So of course if you change the coordinates even by a linear linear map, this will have, of course, of course you'll modify this new polygon. And this is one of the main obstacles when you try to apply, to use this construction to the resolution of singularities, because you want to have, let's say concept, which are intrinsic, which cannot depend on the coordinates that you choose. So what you can read on the Newton polygon which is independent of the choice of the coordinates, this is one of the important points. So first of all, intuitively, how do we measure, how we measure how singular a germ is by its Newton polygon. So essentially all the approaches that exist somehow measures the distance between the Newton polygon and the origin.
00:37:53.454 - 00:38:35.414, Speaker A: The way that you measure this distance, of course depends on the approach that's been used. So the classical approach linkage to the semi variety called the multiplicity, in some sense it measures this distance by the, I call it the l one norm. So this, the shape of these balls infected, they are diamond shaped balls. And this is the multiplicity measure. But in fact there are other ways that you can measure this distance and this gives you different ways of measuring the how singular your germ is. Right. So very, very general.
00:38:35.414 - 00:39:37.026, Speaker A: So important thing is that you have to measure this distance in the logarithmic settings. So I'm going to use this discussion to show to you how we define in fact the strict transform. So what's the logarithmic setting? It's the funny thing, the signals of the blowing ups that you use. Each blow up creates an hyper surface in the ambient space which is in fact a copy of some project k dimensional projective space, right? Remember that I made a small drawing of a projective space of dimension one. Of course you can generalize this for k dimensional projective space. And the, then let's say in the sequence of modifications, the union of this projective space of copies of the project space is what we call the exceptional divisor. So here's, I make a small drawing with the two blow ups.
00:39:37.026 - 00:40:24.902, Speaker A: So you have created a first exceptional divisor and then like say the second exceptional divisor is just the union of two protective space which cross traversal at this point. So at each step you have, let's say you have this differential operator phi zero, and then you transform it to phi one and then to phi two in the following way. So there is a unique way of transferring phi zero to phi one and to phi two and so on in such a way that phi should leave the differential operator. Sorry. The exceptional divisor invariant in the following sense, if o equals to zero is the local equation of the exception divisor.
00:40:25.038 - 00:40:36.834, Speaker C: Daniel fee small and fair capital is the same as was used before or.
00:40:37.374 - 00:40:45.334, Speaker A: Yes, yes. Yeah. So fee small is the modification and fee capital is the operator, is the differential operator.
00:40:46.714 - 00:40:54.334, Speaker C: No. So it's, it's not clear how you define the conditions of invariance.
00:40:55.034 - 00:41:32.894, Speaker A: Ah, so here. So I just written here. So you have a differential operator. So it acts on the, it acts on the section of the on, let's say on functions. So suppose that the equation of your exceptional divisor is whole. It's a reducible equation of your local equation of exceptional divisor. Let's say each reducible component of e is given by function rho, right? So your operator acts on rho and gives you another function.
00:41:32.894 - 00:42:14.074, Speaker A: It acts on whole power k and gives you another function. So what you want is that it maps the ideal generated by the kth power of rho into itself for, ok, so this is what I mean by invariance. If you think of the case of a vector field, this simply means that the solution curves of star vector field should be tangent to the, to the, to the exceptional device. They should, if a solution curve starts in exceptional on one of these components, it should stay on this component all for the whole time.
00:42:14.534 - 00:42:23.594, Speaker C: So it does follow from the fact that the coefficients of your differential operator vanish at the singular point. We should read.
00:42:24.634 - 00:43:47.340, Speaker A: Yeah, but, yeah, but this is, this is that, yeah, but this is more general, because here, in fact, if you have higher order differential operators, you have to demand this condition for all powers of the defining equation, not only the first one, but for vector fields, it should be sufficient to ask this only for k equals to one. Okay. And so the second condition, which, what they call the strict transform is that, sorry, can I get. Yeah. Is that in fact phi should not be divisible by rho. What I mean by this is that there exists some power k such that phi applied to the Rho, to the power k, is not mapped on the k plus one power of the initial a. So this is quite technical way to see, to say the following thing is that once you make the first blow up, in some sense, you pull back your differential operator, and then what you do is that you factor out the highest power of the, the equation rule that you can factor out.
00:43:47.340 - 00:44:41.098, Speaker A: So this is precisely the second condition, but you don't factor out too much. And this is the first condition because it should be invariant, but not too much invariant. So these two conditions uniquely define the way that you transform phi zero into phi one into phi two, and so on. So just let's say a very basic example here. So consider the case of, again, the case of the cusp. So you just make a blow up, as I said, it can be seen locally as a change of coordinates like this one, and then replace Y by x times t. And the idea is that you factor out the highest power of x that you can.
00:44:41.098 - 00:45:17.194, Speaker A: So in this case it's x squared. And so the strict transform is given by the term which lies in the parenthesis. So it's t squared by minus one. So in terms of the Newton polygon, the movement is the following one. You see that you have the Newton polygon of the I squared minus x to the power three, and then you make this first transformation and it gives the polygon which is in the middle. And then this trick transform means that you are going to make a translation to the left, sorry, by two units. So this is the division by two.
00:45:17.194 - 00:46:43.714, Speaker A: And again, if you look at the right most and the left most polygons, and somehow you see that I think the polygon becomes nearer the origin. So this is more or less a general principle. Okay, so one important application of these final models is that they allow to, sorry, of the Newton polygon is that it allows to identify in terms of this combinatorial object, the final models, let's meet, let's see how. So, for the case of functions, this is very simple, because remember that I said to you that you have this case of function. Our faunal models are the monomials, right? But since we are in the logarithmic setting, you can think that the monomial, each power, each function which appears on the monomial is the equation of one component of the exceptional divisor. So in a certain sense, when you factor out all the possible components of the section divisor, what you find out is a unit, right? So in this logarithmic setting, the final model for a differential operator, zero for a function is just a polygon, which is a quadrant like this. Well, so the, where the point here is the origin.
00:46:43.714 - 00:47:31.474, Speaker A: So the important thing here is that zero lies in the Newton polygon of f in this case. So this is the final model of our functions. Let's see what happens for vector fields. So the case of vector fields. Remember that I said that you have this log canonical situation, and also you have the generic situation where the vector field is not singular, right? So I've drawn these two situations here side by side. So the first one is the situation where the vector field is not, is non singular at the point. And you see that you have here, if you write the, if you draw the Newton polygon, you see that there is a point here which is in the negative side.
00:47:31.474 - 00:47:35.994, Speaker A: And on the right side, I have drawn the case where you have.
00:47:37.814 - 00:47:38.166, Speaker D: Let'S.
00:47:38.190 - 00:49:31.254, Speaker A: Say a singular point, but it's log canonical. So in this case, you see that again, in both cases, zero belongs to the Newton polygon of your vector field, right? And these are the case which are final models. So the pattern that we let's say we observe in these two cases, is that the position of the, let's say it has something to do with the fact that zero lies on the, on the Newton polygon or not. Okay, so now, as I said to you that there is an important dichotomy which is, let's say, very, very similar to what happens in a field of algebraic geometry called geometric invariant theory, which is dichotomy between what we call the stable and semi stable situations. What is this? So, okay, sorry, I'm not going to explain this in the set of geometric differential, a geometric invariant theory, but I'm going to define in this way because this is precisely the notion which appears in geometric invariant theory. So in the, in the general case, now the case of an arbitrary order differential operator, we're going to see that phi is unstable at the point p if there exists a system of coordinates centered p such that zero does not belong to the Newton polygon of phi with respect to the system of coordinates. Okay, so in other words, you can find a system of coordinates such that the Newton polygon of phi on this system of coordinates does not contain zero.
00:49:31.254 - 00:50:45.724, Speaker A: So dually, we say that phi is semi stable at the point p. If for all coordinate systems x one, x t xn centered p, zero belongs to the Newton polygon. Okay, so if you heard about what we call the Hilbert Manfold criteria for the instability or semi stability of points in geometric. This is precisely the notion that they use there. So, okay, so if you see, now you compare with the notion that we have before, the cases of final models are precisely what we call semi stable. Okay, so for now, there is a, let's say there is an unifying concept which works for functions, for vector fields, which says that a final model is a model where the differential operator is semi stable, right? So this is the good guys. And what we want to eliminate are this one.
00:50:45.724 - 00:52:12.888, Speaker A: Okay, so again, you see that if you're not in a, the safety. Yeah, sorry, let me just come back. No, no. Okay, so if you, if you have some unstable point, this is our, these are the bad guys for us because the Newton polygon is far from the origin in some appropriate system occurrences. So these are the points which are we want to get rid of, right? So, okay, so now I have the notion of, let's say what we call simplest, semi stable and simplest, and these are the points, the set of unstable points, which I call unstable points of fee, is a set that we want to get rid of, right? By analogy to the case of vector fields, and to the case of functions, unfortunately, this notion, of course, you see that here there is a, it's based on the, let's say there is a quantifier here which says that there exists a system of coordinates, such data. So it's very hard to work with this definition. And for instance, I'm not able to prove up to now that this set is a closed analytics subset of m, except in the case where the order is more than or equal to one, because this is a case of vector field and the case of functions.
00:52:12.888 - 00:52:45.734, Speaker A: In both of these cases, these are precisely the notions of monomial. Sorry, this is precisely notion of monomial and log canonical. But for higher order terms. But I said for higher order differential operators, I'm only able to prove that this unstable set is closed if the dimension of enderment spaces is more equal to two. If I have. I don't know, Patrick, how much time do I, do I have.
00:52:49.594 - 00:52:57.730, Speaker B: Well, in principle, we are almost done. I don't know. How much time do you think you would like to end?
00:52:57.922 - 00:52:58.934, Speaker A: Three minutes.
00:52:59.234 - 00:53:01.546, Speaker B: Oh, yeah, okay. Yeah, sure, go ahead.
00:53:01.730 - 00:53:51.494, Speaker A: Just after the results. So. So, of course, then, just to give a higher order example here, you come back again to this heat equation that I mentioned it in a moment. So, remember that I've drawn to you the case of, let's say, the Newton polygon of the heat equation, which is this one. So, in fact, you see that in this case, the origin lies in the interior of the Newton polygon, and this of course is stable, but all changes of coordinates. So you cannot find a system of coordinates such that this polygon is pushed away from the origin. So in this case, we see that we are in the presence of a semi stable germ.
00:53:51.494 - 00:55:24.664, Speaker A: Yeah, just tell me. So, just to recall that the Kovalepska theorem, so, there's a theorem of existence, of local existence of solutions for differential operators. So just in a drawing, the Koshiko Walewski theorem says, can be applied in the case where you are in the differential operator of order D, and you have at least one monomial corresponding to the support which is on this line here. Right? So in some sense, this is a generic situation, but there is a gap between the points where you can apply Koshikovalevsk and the semi stable points, because in my case, I also allow the possibility of the presence of points between the zero. And here, in some sense, there are new cases which cannot appear for vector field, because in the vector field case either, let's say you are semi stable and you can apply Norfolk theory or robot theorem, or you are unstable. But here, for differential prices of higher order have much more possibilities, and there is much more open, let's say open problems to treat. So, just to announce the result, what I was able to prove that in dimension two, we consider what they call the theorem of elimination of unstable points.
00:55:24.664 - 00:57:18.834, Speaker A: So, first of all, if I have a differential operator of arbitrary order, no, zero, of course, and living in a compact manifold of dimension two, then there exists a finite sequence of weighted blow ups. So here it modifies the triple given by the manifold operator and, and divisor such that in the final object that you obtain here, all points of different, of your different differential operator are semi stable. So you completely eliminate the points which are unstable, namely the points where your polygon is too far away from zero. Well, this is just so for me, more than the result. What is interesting is the idea which is behind, because I think it's quite new with respect to the usual ideas, which has been used through the Newton polygon, because what I use is a sort of analog of a thing called Kemp instability theory. So the idea is that now, instead of trying to measure the distance between zero, so the idea is that you're going to make your polygon become nearer and nearer zero as first possible. So how do you measure this distance? The idea that you're going to measure this distance using a metric which is a sort of l two metric, because it's a metric given by a linear product and this color product, right? So once you find this, if you fix this metric, what Kampf do is that, let's say, is a sort of min max procedure, because you are going to find the coordinates such that the polygon is as far as possible from zero.
00:57:18.834 - 00:57:56.834, Speaker A: So you find coordinates such that this polygon becomes the fastest possible from zero. And these coordinates in some sense are very, very intrinsic. Why? Because once you find this coordinates, let, I suppose that you have this is that the coordinates which appear here. So you cannot put this point, this is the nearest point, this is point key, which is written here. So you cannot put this point farces the weight by a local automorphism, by a local chain point. So in this case, you measure this distance. And people from geometric environment theory call this the speed.
00:57:56.834 - 00:58:33.444, Speaker A: And once you have this vector here, the weight is simply given by this normalization of this vector. So this is the weight that we're going to use for the blow up, right? And, well, the difficult part is to show that once you blow up with the weight given in such an intrinsic way, this speed will strictly decrease. So let's say you measure it again after blow up, and it will become smaller. So eventually you are going to achieve your ball. So thank you for your attention.
00:58:36.944 - 00:58:44.924, Speaker B: Thank you very much. Yeah, it sounds like there is more to be said about the procedure.
00:58:46.624 - 00:58:50.154, Speaker A: I have some more. Okay.
00:58:51.174 - 00:59:02.674, Speaker B: Right. Well, you know, again, let's see. First, are there any questions for, you know, the setup that we saw today and the result. And you might have to unmute yourself before you talk.
00:59:04.334 - 00:59:21.924, Speaker C: Sorry, Patrick, if I may. Yes, yeah, go ahead, Daniel. You introduced the object to which. Which you describe as the Newton diagram for differential operation.
00:59:22.224 - 00:59:23.004, Speaker A: Yes.
00:59:23.304 - 01:00:02.374, Speaker C: This notion is clearly local, meaning that you need also to treat the monomial coefficients before the differential operators. Before. So, in fact, during Newton diagram lives not in the case of two variables in the two dimensional lattice, but rather in the four dimensional lattice of powers of x and the derivatives in each x.
01:00:04.474 - 01:00:05.254, Speaker A: Yes.
01:00:05.794 - 01:00:54.024, Speaker C: So I could not really figure out what is the final result. So you claim that by using monomial transformations or quasi homogeneous monomial transformations, you can simplify this even dimensional Newton diagram to some form, which is. Which does not contain the origin. So, for instance, let me ask the probably idiotic question. Suppose that your dimension is one.
01:00:54.844 - 01:00:55.580, Speaker A: Yes.
01:00:55.732 - 01:01:03.740, Speaker C: So you have only one variable, x, and only one derivation. D over dx.
01:01:03.932 - 01:01:04.684, Speaker A: Yes.
01:01:04.844 - 01:01:12.784, Speaker C: Your differential operator is characterized by the Newton diagram on the plane.
01:01:13.724 - 01:01:37.566, Speaker A: Sorry, Sergey. In fact, there's. Let's say there's another notion of Newton polygon, where this is. I think we call this Hamee's. I don't know the precise name. There's a Newton polygon where you take into account the order of the differential operator. And this is a perhaps is what you're mentioning.
01:01:37.566 - 01:01:52.126, Speaker A: But in my case, in fact, if you have an ordinary differential operator in one variable, my polygon will be one dimensional. Okay, so.
01:01:52.270 - 01:01:58.694, Speaker C: Okay, so it's probably a mistake. And comprehensive.
01:01:58.774 - 01:02:00.030, Speaker A: So, yeah.
01:02:00.062 - 01:02:06.994, Speaker C: Well, I'll write you privately of. On what I. What I have in mind.
01:02:07.574 - 01:02:44.284, Speaker A: Yeah. So I think it's perhaps one of the critic. One thing that you can find quite strange about this construction is that, let's say, when you work with differential operators, partial differential operators, one important object is what we call the current characteristic variety, which the variety living in, let's say, in the cotangent bundle given by the monomials in the operators and the functions. Right? So this is perhaps. This is the. Let's say I have two if you are.
01:02:44.624 - 01:02:53.672, Speaker C: Basically, this means that your theory is meaningful. Starting from dimension two of this space, variables.
01:02:53.808 - 01:03:16.844, Speaker A: Yes. So in some sense in my construction you cannot filtrate your operator by the order. So in some sense the characteristic variety is hidden here. You cannot see it directly because. Let me just give you the. Again then.
01:03:17.784 - 01:03:29.364, Speaker C: No, see Daniel, probably, I guess you have something written on this subject. So if you send me a reference, I would try to read it and.
01:03:30.264 - 01:03:41.684, Speaker A: Yeah, so. Yeah, so, but you see here in the construction, you see that this p of s, these polynomials can have arbitrary order, let's say up to d. Well.
01:03:42.504 - 01:04:09.554, Speaker C: That'S exactly what I said. So you have s as a multi index and X D over Dx which is also multi indexed. And so you have an even order lattice z to two n. And your diagram is living there and not in.
01:04:10.174 - 01:04:33.194, Speaker A: That's it. Yeah. Yeah. In some sense it's a sort of filtration of differential operator which you. Let's say you stress more the powers of x and not the powers of the operator. So this is the way that they work.
01:04:34.734 - 01:04:44.114, Speaker C: Okay. So I guess that we can settle our questions between ourselves.
01:04:47.114 - 01:05:08.458, Speaker A: I also have a question. So in the. In your statement for surface seems to be implicit that the set of unstable points is always co dimension two. Is that right? Yes. No. It can be condemnation one. I'm not sure it's.
01:05:08.458 - 01:05:52.838, Speaker A: No, because how do you get rid of them? By blowing up. Because once you. Let's say suppose that you. Your polygon can be a quadrant which is let's say at some height, some height. And then at each blow up it decreases like this. So in fact once you include, let's say suppose that you have a line of unstable points. When you blow up you are going to include this line on your exceptional divisor, right? And then when you include it in the exceptional divisor you can.
01:05:52.838 - 01:06:18.562, Speaker A: You can factor out the power of the power of the equation which, which defines this exceptional. This line. And this gives you the. Your Newton polygon becomes nearer and nearer zero effect. So it's more. Yeah. You are saying that unstable in codimension one implies divisibility in your definition.
01:06:18.562 - 01:06:41.750, Speaker A: Yeah. In fact, even for the case of. If you could think of the case of vector fields. Usually when it. When we work with vector fields we suppose that the singularities are of codimension, the set of similarities of condimential two. But even if you have similar condimential one singularity, you can get rid of them by. You don't blow up.
01:06:41.750 - 01:06:53.474, Speaker A: You just divide. That's my question. So. Unstable a differential operator with isolated signal. It is the set of unstable points. Yes, that. Yeah.
01:06:53.474 - 01:07:02.578, Speaker A: Thank you. Yeah.
01:07:02.626 - 01:07:04.014, Speaker B: Any other questions?
01:07:09.914 - 01:07:11.294, Speaker D: I have another question.
01:07:11.954 - 01:07:12.458, Speaker B: Okay.
01:07:12.506 - 01:07:25.454, Speaker D: Yeah, sorry, one question. So is this collection of coordinates where you have the first. This distance to the origin?
01:07:25.614 - 01:07:26.354, Speaker A: Yeah.
01:07:26.734 - 01:07:34.670, Speaker D: Is this playing an analog role of maximal contact hypersurface or is it.
01:07:34.822 - 01:08:13.854, Speaker A: No, it's very different, in fact. Okay, because how this. No, because, in fact, it's easy to see that. No, that's it. You can see that even in the case of vector fields, you cannot define a maximal contact surface. It's something which is, let's say, a new phenomenon which appears already in the case of vector fields, is that the theory of maximal contact does not behave as well, at least in the approach that I try to make. So you.
01:08:13.854 - 01:09:04.443, Speaker A: The fact that there is a hyper surface which is contained in a stable way, all the points which are of higher complexity, in some sense, it's something which does not hold in the case of vector fields. So it's a different approach, but it's very, very similar to this approach which has been proposed by Kempf. So this, in geometric invariant theory, you have this measure of the instability given by the distance between the polygon and zero. But of course, here he works in a finite dimensional setting. Now I have. And this gives you a sort of stratification. So this is the stratification by the speed.
01:09:04.443 - 01:09:22.444, Speaker A: And this is what we call the hessian link certification. So my goal is to prove that this certification also holds in the infinite dimensional setting that I'm trying to apply it. So it works in dimension two, but I'm not sure that it works in the higher dimension.
01:09:28.664 - 01:09:48.244, Speaker D: Okay. Because, I mean, from what I remember from Kemp's book, well, paper, like, you only need an action on a variety. Right. And then you can apply this.
01:09:49.984 - 01:09:58.404, Speaker A: Yeah, but the problem is that there's magic war here, because the camp theory is for.
01:09:59.224 - 01:10:00.604, Speaker D: Yes, you are correct.
01:10:01.054 - 01:10:31.644, Speaker A: And in our case, we're very far from this. Well, there are some people which have developed the. Sorry, I perhaps just give this reference, there's very recent results on the non reductive geometric environment theory, and perhaps I can adapt this for my setting. But there's a quite active domain of research about how to apply these tools in the case where your group is not. Is not reductive.
01:10:32.224 - 01:10:34.324, Speaker D: Okay. Yeah. Thank you.
01:10:38.664 - 01:11:09.268, Speaker B: Okay, well, any other questions? I'm guessing that's a no. Well, let's thank the speaker again. Thank you very much. A very nice talk. So, just before everybody goes, I'm thinking that we will be organizing seminars like this. Not weekly. That's too much.
01:11:09.268 - 01:11:32.760, Speaker B: But regularly. So if any of you would like to speak, please let me know. All right, that would be nice to know. And also, right now, it seems like there are still a lot of questions people would like to see a bit more of this talk. I don't know if. Danielle, you're ready to maybe follow up on this?
01:11:32.952 - 01:11:38.400, Speaker A: Yeah, about the proof. If you want a little bit about the proof.
01:11:38.472 - 01:12:17.806, Speaker B: Yeah, I think it was very instructive what you told us so far, and it would be nice to see a little bit how this, the algorithm works. So I think we'll probably plan another one, follow up with this one in a couple of weeks or so. So. Yeah, that's all I have to say. If you guys would like to talk to each other, we can stay on for a little longer, or eventually I will have to turn it off, I guess. I think we have the time slot for a little bit longer. But.
01:12:17.806 - 01:12:33.194, Speaker B: Yeah, I know it's a little strange. I don't know what to. I'm not a good master of ceremonies, but you might have to unmute yourself if you want to say something. I can only ask you to unmute. I cannot unmute you directly.
01:12:35.294 - 01:13:12.254, Speaker D: So then I have more questions, but this is a little bit unrelated. So, like, I was checking Daniel's paper, resolution of singularities of real analytic vector fields in dimension three. So, like, is this the strategy you follow? Or is this, like, what is the difference between this and the strategy? Because in the other one, it's different. Yeah, it's a little bit different, but yeah.
01:13:12.334 - 01:13:37.574, Speaker A: In fact, it took me a long time to. Tried a lot to adapt my. Even for the case of vector fields in dimension four or higher dimension, I tried very hard to adapt the techniques that I use it for this high dimension case that I. I realized that they are not. Yes, it's very. Yeah. I did not succeed to adapt them.
01:13:37.574 - 01:14:18.154, Speaker A: So my approach was, in fact motivated by. To prove the results for vector fields in higher dimension. Right. So I realized that the technique that I was trying to develop did not put any restriction on the order of differential operator. Right. So the idea that if my approach works for different vector fields, it should also work for any other differential operator. So, in some sense, I was able to prove that it works for differential operator for the two, for arbitrary dimension two.
01:14:18.154 - 01:15:18.644, Speaker A: But it's quite different, because in some sense, my usual approach is to measure this distance by the l one norm. As I said, what you do is that in some sense, instead of using the distance with respect to some inner product with the norm, you use the l one norm by say that you just look at the points which are near the origin as the multiplicity. Right? So it's very different. I make some transparency in comparing these two approaches. But by the way, it's also different from the approach that has been recently developed by McQuillen and Marcel in their paper. In some sense, they use an approach which is similar to my original approach, interdimensional vector fields. And it's.
01:15:18.644 - 01:15:25.124, Speaker A: Yeah, it's not the same. Sorry, I cannot give too much.
01:15:26.384 - 01:15:30.844, Speaker B: I would be happy to see a little bit more how this works.
01:15:33.864 - 01:15:35.204, Speaker A: Mister Tamar, perhaps?
01:15:36.504 - 01:15:43.804, Speaker B: No, but let's do that for another seminar, I think. I'm guessing you can easily talk another hour on this, right?
01:15:45.024 - 01:15:46.924, Speaker A: If you want to hear me, yes.
01:15:47.224 - 01:15:57.684, Speaker B: Yeah, that would be nice. So we'll figure out another time slot in a couple of weeks or so. Okay, I'll do that.
01:16:00.224 - 01:16:02.564, Speaker A: Okay, thank you very much.
01:16:03.264 - 01:16:08.432, Speaker B: Thank you for the great talk and bye bye. And bye bye.
01:16:08.608 - 01:16:09.024, Speaker A: Thank you.

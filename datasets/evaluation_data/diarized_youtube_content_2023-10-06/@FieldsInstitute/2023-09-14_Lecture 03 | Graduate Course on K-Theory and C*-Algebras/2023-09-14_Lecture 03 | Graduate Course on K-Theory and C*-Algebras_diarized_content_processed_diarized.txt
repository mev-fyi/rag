00:00:00.800 - 00:01:54.928, Speaker A: Good afternoon. I'd like to begin by quoting from a paper by the pioneering person in the field, pioneering in the field of operator altruism covered space. This is a paper which was published in the Mathematical Reports of the Academy of Science of Canada in 2009. A note on projection dedicated to the memory of Ezri Mahalfan, the guiding spirit of canadian functional analysis, and a fearless fighter for the freedom of scientists everywhere. So this is a footnote from the one where in the introduction where he says basic technique introduced by Merrigan van Diemen in the analysis of factors, those phenomena algebra, whose centers consist of scalar multiples of the identity operator I is that of comparison of projections in the phenomenalgebr. This is now referred to as Murray von Neumann equivalence. And it was on well concerns the origin of the notion of american, I mean, equivalence of production.
00:01:54.928 - 00:02:58.226, Speaker A: Comparison of production. From personal conversations with Murray von Neumann and Halperin, to whose memory this article is dedicated, this author has concluded that remark to von Neumann by Halpern was fundamental to the development of the comparison theory of production. Halperin, as a young mathematician sent to the Institute for Advanced Study in Princeton in 1935 for early guidance by van Lehmann, was invited to be a party to the very first discussion von Lehman had with Murray. Murray, too, had been sent to van Leevin as a young postdoc. In those early discussions, van Leemann was setting worry on the project. It was to become the subject they called rings of operators, and more specifically, the theory of factors. Today, following Halpern's remarks, when Lehman mentioned to Halperin excitedly, so it seemed to lead to significant consequences, he requested Halpern's wealth.
00:02:58.226 - 00:04:33.244, Speaker A: And it's in fact, in hindsight, 90 years ago, one might say it led to both what's called operator algebra theory, most of a large part of what's called modern algebra, modern algebraic operator algebraic theory, and also what's called what's now called k theory, he requested Halpern's permission to use that suggestion. Permission was granted. Of course, that situation is reminiscent of commends request to Bo Koopman a day after Koopman had made his observation, and this is irrelevant to our course Dufundhen, that a measure preserving transformation gives rise to a unitary operator on the L two Hilbert space of the measure, which became known for a period as the Koopman ergodic theory, which became known for a period as the Koopman method, that von Neumann be allowed to use it. Von Neumann had proved his meandergodic theorem with the aid of Koopman's construction a few hours after hearing of it from Putin, evidently, when punctilious. So it's been nice to work with purpose for them. Well, for that matter, it was nice to work with Israel. How could you repeat the article title.
00:04:34.424 - 00:04:35.568, Speaker B: What the reference is?
00:04:35.656 - 00:05:00.460, Speaker A: Yeah, it's. Okay. Well, this journal is online, and it's called math reports of the Academy of Science in Canada. And. And you just look up. I think Kadison just has the one paper, so it's searchable. Just type in Kadison under search and it comes up.
00:05:00.460 - 00:05:41.940, Speaker A: I mean, if you just type in Candace and Halpern into Google, that might make it come up, too. These things are pretty fascinating. It's almost a kind of a game to find the shortest keywords. Bring something. Bring something up. Okay. I assume.
00:05:41.940 - 00:06:48.166, Speaker A: I trusted everyone has the course intro, which mentions the. Gives the reference for the textbook and the administrative structures of the course, which has to be approved by. Tentatively, I suggest that homework consisting of exercises, say three to six per week, handed in on Mondays, and project essays, say two, to be handed in on two. Dates. And grades count 50%, one half towards the final grade, and classwork, well, explaining things and maybe asking about things and then. So I like to be able to ask people a question to make that easier. It might be nice if people move.
00:06:48.166 - 00:08:02.254, Speaker A: Maybe if there's just as many people, then occupying the front two thirds or half to two thirds of the seats might be communication, even easier. I don't mean moving that, but I think one might consider, because one thing in the back, it's also quite dark. And I'm supposed to be. I'm supposed to get to know people, right? All right. Okay. So I started out by talking about linear algebra and how that's important. Case theory and the main, main fact, and many are about meaning over an arbitrary field, not looking at inner product spaces, so not the spectrum theorem, theory of finding degenerate effects.
00:08:02.254 - 00:08:50.984, Speaker A: This is a. Well, the main is a single. This is a single fact. The main factor for linear algebra, a second order statement, which I like to call the fundamental theorem of linear algebra. I think someone else might see on that. One of the basic facts. We want first order theorems, the second order theorem, the meta theorem, if you like, is that all non trivial facts in linear algebra, finitely generated vector spaces over an arbitrary field, fixed field.
00:08:50.984 - 00:09:57.634, Speaker A: If they're non trivial, then each one of them implies anyone and the others. And then, in fact, in a trivial way, they're not trivial facts, but they are trivially equivalent. This is a very good exercise. I would suggest taking different formulations of the basic fact of what I'm calling different formulations, basic factors, and just take two of them and then show that one implies the other. If you do it for all possible ordered pairs, then that's the same as proving a draw in filling anyone wide as any of the others. Okay, but you might start off by giving a reasonable count of how many there are. I hope it's not as many as 14.
00:09:57.634 - 00:10:23.144, Speaker A: Anyway, one of them, well, there are two ways of, there are two ways of formulating which are not usually brought up in an elementary course, probably never brought up.
00:10:23.724 - 00:10:25.144, Speaker B: One of them is that.
00:10:27.444 - 00:11:15.384, Speaker A: There'S an ocean of index for linear operating, you have a vector space and a linear transformation, linear operator from the space into itself. And there's, sometimes it has what's called index. It has, you say the operator has index. This means that kernel and the co kernel, which is the whole space module. Kernel and co kernel both have finite dimension, finitely generated. Okay, so statement has two parts that the vectors will consume. This vector function generated to begin with.
00:11:15.384 - 00:13:01.068, Speaker A: And the trivial fact, it's an easy fact that every quotient space and every subspace, so having index, automatic, because index means for an arbitrary linear operator means the kernel and the core kernel are finitely generated. And this was true. But conversely, if every linear operator has indexed, has finite finite generated kernel and finite worker, and then it must be, then the whole space must be finitely generated. That's quite simple, because if you look at the zero operator, then kernel is everything, right? The kernel has to define it because I mean, you finish conversely. Okay, it's good to exercise. But the point is that if you say that this is straightforward and every operator has index refining generated records. But if you, the important fact now, how many people can know or can want to guess what the property is always? Oh, what property? If there's something that's always true for the index, then finally generated vector space.
00:13:01.068 - 00:14:23.478, Speaker A: If every operator has an index, and you can always say what it is, some number that always is, then what is it? By the way, I have, see, I haven't even defined the index yet, right? It shouldn't matter. The question is, we have two, we have two, we have two spaces, but we have the kernel and the co kernel, and each of these has what you might call the smallest number of generators, fake dimension. Okay, so you compare these two numbers, the quite fake dimension of the quotient of the co kernels and the fake dimension of the kernel. And, well, in finite dimensions in finitely generated space. There's always a simple relationship between these two numbers. Okay, so what is it? Yes, there's some to the connection. Okay, that's what I think.
00:14:23.478 - 00:15:20.390, Speaker A: What you meaning to say is, let's. Do you know anything that I'm going to talk about? I'm not going to talk about. And so let me give you a hint. The answer is as simple as it could possibly be. Yes. By the way, maybe I should hear somebody. Charlie.
00:15:20.390 - 00:16:39.390, Speaker A: Yeah, they may have to hear it. Yes. In fact, this is the grand finale. The kernel and the profile are isomorphic because they have the same faith dimension. We're not talking about dimension of water, other words like. And you have two numbers that are always the same but not always. In the picture, there are two numbers.
00:16:39.422 - 00:17:05.114, Speaker B: That are always the same, but they're not always. I mean, they're always the same with each other. They're always the same. They're always equal to each other, because every operator has this pair of numbers, and the numbers, these two numbers are always equal, but they're not always the same. The first number is not always the same, and the second number is not always the same. Okay. But the first number is always equal to the second number.
00:17:05.114 - 00:17:55.784, Speaker B: Well, I said we were going to try to get the simplest possible formulation of the situation. Right. Well, I suppose you have a whole lot of pairs of numbers and the whole lot of ordered pairs and numbers and the two coordinates are equal, then what's a single thing which is constant? If two numbers, a, a and b and a is equal to b, then what? But a is not always the same and b is not always the same, but they're always equal, then what is the fundamental actual. The two numbers themselves are not the fundamental number, then obviously. Well, I would say. Yes. Sorry.
00:17:55.784 - 00:18:15.894, Speaker B: Yes. Now, are you an expert? Have you studied this? Okay, but then that's great. Okay, because, I mean, what it. What it means is I'm. Well, I don't. I hate to. I shouldn't be putting the limelight on me, right? But what it means is I've got the right principle.
00:18:15.894 - 00:19:06.514, Speaker B: If you're lucky, someone will find the simple formulation, okay, so the index is always zero, but the index is the difference between the two numbers, okay? It's a convention which you subtract which one you subtract from which one. Let's not worry about that. But the point is that in finite dimensions, it doesn't matter. They get zero. Okay? Of course. If you knew the index was an integer and I told you it was always the same and didn't have to be always positive or always negative. Yes, well, it's fake.
00:19:06.514 - 00:19:32.714, Speaker B: Dimension is the same. They're isomorphic if you like. They're both vector spaces. One is a subspace and one is a quotient space. Right. But so you can't quite say they're equal even, because it's like apples and oranges, right? You can have the same number of apples and the same as orange, as oranges, but. Okay, but, all right, so that's, that's one form of the.
00:19:32.714 - 00:20:27.378, Speaker B: Yes, well, okay, this is an exercise. The definition still makes sense. An operator, always any vector space, any linear operator from the space into itself, okay, it always has a kernel, it's sometimes called a null space, and it always has a co kernel. And this is not inner product space. There is, you have to take the image and divide it by. Take the, I'm using class, I'm using the classical language where you don't quotient by something, you divide it by. Okay, so you get two vector spaces and you saying the operator has index.
00:20:27.378 - 00:21:02.358, Speaker B: By definition it means these two vector spaces, the kernel and the co kernel, are finitely generated. Okay, now remember what I was going on about. Sliding if you have. Well, dimension is a subtle comment. Sorry, sorry. Well, the story of dimension is a subtle commentary, but it's very important. But fake dimension, anyone can do fake dimension.
00:21:02.358 - 00:21:46.320, Speaker B: Okay? Fake dimension is any vector space has a set of generators. Okay? You could take all the vectors, right? And I tried to make a joke about you have to decide whether to include zero or not. But that's not, if it's an infinite number of vectors, then it's not going to include zero, is not going to make any difference of how many generators you have. And what you do then is look at all sets of generators and look at the cardinality of each one. And if the space is finitely generated, and that means you're in this starting and you're in the scheme of finite cardinal finite natural numbers. And any set of natural numbers, any bunch of natural numbers has the smallest element. It's true.
00:21:46.320 - 00:22:25.464, Speaker B: For any bunch of cardinal numbers, look at all cardinal numbers. There's the smallest one, right? What's the smallest cardinal number? Do you know what cardinal numbers are? What's the smallest natural number? Yeah. Okay. That's also a cardinal number, so it has to be the smallest cardinal number, I guess. Okay, cardinal numbers are how you count the elements in a set, the number of elements in a set. Okay, so you look at all sets of generators for your vector space. And you look at the cardinal numbers and one of them is finite.
00:22:25.464 - 00:23:47.554, Speaker B: And it's simpler to visualize. You just look at the smallest one, and that's, well, that's, that's going to, after the fact, when you, when you've proved a lot of things, that's going to be the dimension, okay? But in the meantime, we can call it the fake dimension, all right? And so the index of an arbitrary linear operator that has index is the difference of the, you look at the fake dimension of the kernel and the fake dimension of the co kernel and you subtract it. I'm sorry. Well, there isn't a fixed, there isn't a fixed dimension. Look, the word I'm using is fake dimension. Yeah, yeah, it's right, because real dimension, real, real dimension is a very special thing and it's a number of elements in a basis, but it's after you've proved that it's additive. Right? Anyway, one way of saying the, let's just outline the difference between dimension and fake dimension, okay? Dimension is a number.
00:23:47.554 - 00:24:59.634, Speaker B: Dimension is what the fake dimension is. After you have proved that, you take the direct sum of two vector spaces, then the fake dimension of the, of the direct sum is the sum of the fake dimensions. But try and prove that. That's a deep theorem. That's one of the basic statements, okay? That's one of the non trivial statements that are equivalent through all the other, okay? No, because this is an arbitrary field, fixed field. The field is fixed, okay? But the dimension of the vector space, the fake dimension of the vector space, it's, before you start worrying about deep theorems, and it's supposed to be a shallow definition, and it's just, you look at all sets of generators, which is kind of a joke, right? And then you take the smallest number of elements that you can do, you can get, like if it's just a singly generated vector space and it's non zero, then I guess you can, it's pretty simple to compute that the fake dimension is one. Okay, good.
00:24:59.634 - 00:26:16.230, Speaker B: And so the way you define the index is it's the difference of the fake dimensions of these two spaces, vector spaces, which are assumed to be finite, finite, finite, regenerative vector space, which an exercise that if the whole space, well, the whole space is not finitely generated, in that case, it's automatic that the quotient, a quotient is in a subspace. That's a good trivial, that's what I'm calling a trivial statement, which is good to work out. I would really like to see people making notes mentally or on various devices and including, well, including the cost of the mythical piece of paper and then in their weekly exercise deliveries, maybe include some of these facts that some. Some. Some statements are trivial. Some statements are trivial, like there exists a basis and for a finitely generated vector space. And.
00:26:16.230 - 00:26:31.570, Speaker B: And also that, um. That one of the. Suppose you, suppose you assume. Okay, so the. What. What's the. I was saying that the index gives you one.
00:26:31.570 - 00:27:12.206, Speaker B: The notion of index gives you one formulation of the. Of the really important fact about linear algebra. The single really important fact. Linear algebra. And that is that. Well, there's, there's. Well, okay, the formulation I'm getting at with talking about index is.
00:27:12.230 - 00:27:12.438, Speaker A: It.
00:27:12.486 - 00:27:52.218, Speaker B: Is what. What's the formulation of the. Of the basic non trivial fact of linear algebra? Which. What's the statement in terms of index? Yeah. Okay, so you're repeating the. You're, you're, you're doing things up around. You're repeating the definition of index.
00:27:52.218 - 00:28:03.666, Speaker B: Yeah. And there's a. You have to. There's a certain standard convention which. Which one. Which of the two numbers subtract from the other that maybe is different, different countries. Sure.
00:28:03.666 - 00:28:24.694, Speaker B: Wouldn't, wouldn't be. Okay. But, um. And that's, the notion of index is really fundamental to both the mathematics. There's the index. The theorem of the 20th century is sometimes considered to be the index theorem. Okay.
00:28:24.694 - 00:29:15.110, Speaker B: Or different or something which is related to it, like the fermat's last term. I would. My understanding is it's related to the index, and the Langland's program is related to the index. So it's too bad. I think it's too bad that index formulation of the basic fact of linear algebra, that basic non trivial effect. I think that this is not standard to say, just that the index is always zero generated vector space. I think that's a bit too bad.
00:29:15.110 - 00:30:24.748, Speaker B: But there's another, and there's another formulation, which is the notion of index is basic to this course, but it was already basic in my other cross listed course, which I gave a year ago in the fall, namely linear operators. Okay? But the basic theme of this course is case theory. And as I was describing, as I was getting, starting to talk about on Friday, there's a theory formulation of, of linear algebra. Do you remember what that was? Or did I get far enough into it? Okay, but I didn't finish defining k zero. Right. I. Fine to talk about that today, but it's a group, right? Yeah.
00:30:24.748 - 00:30:53.934, Speaker B: It's a group of integers. Okay. And if you know that and you know what k zero is, then you know linear algebra. Okay? And that's, um. But you don't learn that in first year or second year. But why not? Why not? You learn about the integers. Okay, so why not that the integers is the k zero group of a field? Well, all right.
00:30:53.934 - 00:32:09.914, Speaker B: This, by the way, it would make sense. Someone is looking for an essay topic then studying the structure of linear algebra that I'm suggesting in terms of the meta theorem. All non trivial theorems are trivially equivalent. That would be a good think about, I think, certain study. But then also to check out some of the, some of the trivial, what I'm calling trivial equivalences between different non trivial facts, one of them being that that fake dimension deserves to be called dimension because it is the dimension of a direct sum is the sum of the dimensions. Well, okay. And another thing that this study could involve is the fact this other new formulation of linear algebra, the k zero group.
00:32:09.914 - 00:33:14.960, Speaker B: K zero group of a field, any field is a group of integers. Well, okay, so what's k zero? Well, there are two ways to approach it. One is the way in the textbook, which is in the way that Maureen von Neumann did, namely to look at projections, projection operators, elements of the algebra. You have an algebra of a ring which are equal to their squares. Those are called isompodens. If it's a star ring, it's a ring of operators closed under the adjoint operation. If every operator in the algebra, if that joint is also there, star, well, then a projection is an idempotent element that is equal to its self adjoint at the same time, self adjoint iodine.
00:33:14.960 - 00:34:21.544, Speaker B: But in the definition of k theory, it works for an arbitrary ring, maybe to begin with. Well, to begin with, we look at the case of a unital ring, okay? So we have, we're talking about unit of rings. And, well, if you look at the book, then it's in the case of a sister algebra, it looks at the idempotent or the self joint idempotent. But the way that works for an arbitrary ring, which Groton Deacon used, is you look at modules, okay? Remember, a module over a ring, unit or ring, is much like a vector space over a field. Vector space over a field is a special case. That's what a module is over a field. In other words, you can take ring elements and multiply vectors, multiply vectors by them.
00:34:21.544 - 00:35:37.470, Speaker B: So, and so, just like direct sum of vector spaces, you can talk about direct sum of modules. And so suppose, suppose we have a bunch of modules over. Ring unit over. And suppose it has, suppose it, suppose the, suppose it's closed under direct sums. Closed undertaking direct sum, finite direct sum. These are left modules, okay? You could do it just one side of modules. Left module.
00:35:37.470 - 00:36:57.514, Speaker B: You could do it just as well with right modules. By the way, this is going to give you the same answer as for idempotent, but for idempotent, when you do it for idempotent, as in the book, there's no left and right. There's no left and right. There's not such thing as a left item potent. It's just square is equal to itself, okay? And where the module is either a left module or a right module, if you do this, the construction I'm talking about of a group, a billion group, well, at least if it's, if it's a special class of modules that one considers. In case here, this is just some arbitrary class of modules, okay? With certain properties, but the ones that are important. So in for k zero, we consider finitely generated, finite regenerated, what are called projective modules, okay? But don't worry about that right now.
00:36:57.514 - 00:38:30.074, Speaker B: So, projective means a direct summon of a free module. And the free module is a direct sum of copies of the r of the ring. So we're not going to consider case theory right away, just this general construction of an abelian group. But to check that it works in this setting, you want to check with finitely generated productive modules are closed under taking direct cells, okay? And also we want closed under taking isomorphism, closed under isomorphism. If we have a module within the class and another one is isomorphic too, it should also be in the class, all right? And the third property we want is that the isomorphism classes, the isomorphism classes form a set, okay? And the reason we want them to form a set is that we're going to make them into a group. We're going to define an operation on them. But that, and it's going to be a nice operation, a Boolean operation, associative and so on.
00:38:30.074 - 00:39:09.910, Speaker B: And they have inverses and a zero element. But if you have something which is not a set, it's just a class which is not a set, then you're not going to get a group, right? The group has to be a set. Okay, well, that's the, I'm sort of standing back and doing it from a distance. But you never think the conceptual nature of a subject, never. Some things, no matter how far you stand back, you can always see them. You have to take care of them. Okay? But the details like finitely generated projective module.
00:39:09.910 - 00:39:42.788, Speaker B: Projective module being a direct summon of a free module. Which is a direct sum of copies of the. Of the ring. For instance, here's an exercise. If you have a finite finite sum of. If you take a drag summon of a finitely generated free module. Is that the same as taking a finitely generated drag summon of a free module? Okay, it is an exercise.
00:39:42.788 - 00:40:21.874, Speaker B: Very easy to think of an exercise, right? Almost anything is an exercise if you look carefully at something. Okay, so we're saying what the finitely generated projective modules are. And what's the definition? Well, it's a direct summon of a free. It's a finitely generated module which is a direct summon of a free module. Okay? Well, turns out it's a direct sum and have a finite drag sum of copies of the ring. And also anytime you do that, you get the finitely generated module. Okay? So that's.
00:40:21.874 - 00:41:03.144, Speaker B: I'm just repeating that example of a sort of nitty gritty type exercise. But what I'm doing here is standing back and just saying, well, more or less, I'm standing farther back and not worrying about particular kinds of modules, just general properties. Okay? So the isomorphism classes form a set. So I clean the theorem. They form a group. Okay. Not only do the isomorphism classes of these modules form a set, but they form a group.
00:41:03.144 - 00:41:27.644, Speaker B: Of course, I have to say what the operation is, right? What's the operation? How many people. Who wants to. Who wants to speculate on what the operation is? Yes. Remind me of your name, please. Oh, Daniel. Yeah. Talking yesterday or Monday.
00:41:27.644 - 00:41:57.500, Speaker B: Yes. And except that's a slight, slightly overly concise. Someone might say it's overly concise, right? Because we're talking about isomorphism classes. The elements of the group are going to be isomorphism classes. And so how do you define the direct sum of two isomorphism classes? Well, yes. Yeah. Okay.
00:41:57.500 - 00:42:03.904, Speaker B: Yeah. But. Yeah. Okay. Well, I'm not suggesting Daniel is stuck. I just. Remind me of your name.
00:42:04.844 - 00:42:05.588, Speaker A: Ellen.
00:42:05.716 - 00:42:06.396, Speaker B: Ellie.
00:42:06.540 - 00:42:07.420, Speaker A: Ellen.
00:42:07.612 - 00:42:21.204, Speaker B: Ellen. Okay, thank you. Yeah, we. We were talking before, but I didn't ask her. I didn't get around to asking your name. Did I get your name? I think I did. I'm still having trouble with it.
00:42:21.204 - 00:42:40.804, Speaker B: Chrissy. Chrissy. No, I'm sorry. C r I s s. Okay, that's. That's more letters than I can take in. I'm sorry.
00:42:40.804 - 00:43:46.664, Speaker B: But send me an email sometimes with a question, and then we can have a con. By the way, one thing I like to do is hear people through email. Okay? And not just the, not only the assignments, of course. That's enough. That's already enough, maybe. Okay, so yeah, so Alan is saying that if we have two isomorphism classes of modules over this fixed ring r, fixed unit over r, and a module over unit over means the unit, when you multiply the unit of the ring by a vector, you get the vector back again, right? The same vector modifying by the unit of the ring is the identity operator on, on the group of vectors. And if you have the zero element of the ring and you multiply a vector by that, of course you get zero, right? Zero vector, the zero vector.
00:43:46.664 - 00:45:10.480, Speaker B: Okay, so we, Alan is saying look at two isomorphism classes and then choose representatives, all right? We know the representatives are in the class of modules, right? Close under, closed under isomorphism. So if you have, well, you take any representative, it doesn't have to be all representative, just in the class of all modules, we have two, two modules. It's understood in your answer. It's what Daniel said. You take the direct sum of the two representatives, okay? And you get a module and you look at its isomorphism class, then it makes sense to say we want to call this the sum of the two given isomorphism cost, okay? But if you have an operation, it can't depend on any arbitrary choices, right? You have to show it's independent of the choice of representatives. And that's a, that's, if you like, it's an exercise or a lemma or something. So, you know, I hope I can do all these exercises.
00:45:10.480 - 00:46:43.430, Speaker B: Okay? But what I hope is that I don't have to that, of course, once in a while I should do one. But I think people who are recording them ought to think, first of all about keeping track of them, which is half the battle, and then also doing at least some of the exercises actually carrying them out. So the isomorphism class of the sum of two representatives of two modules is independent of the, by the way, this is a, maybe I'm making too much of it, because it's a very easy exercise. That's one reason to look at modules when you're defining p theory, because if you talk about idempotence, the fact that equivalence classes are quite important, the fact adding equivalence classes is independent of choosing representatives. This is called Murray von Neumann additivity of equivalence. And this is what they and Halperin were talking about in 1935. Well, that's, that's, it's an, it's, it's a fairly demanding exercise, okay? You have to, it's computational, to keep track of what the algebraic, the symbolic description of equivalence of projections is equivalent of items.
00:46:43.430 - 00:48:10.160, Speaker B: Okay, that's, but with modules, it's just conceptual. It's, so what Alan and Daniel are proposing is, I don't want to, I don't want to look down on it too much, but it's easy. Okay? That's why I'm taking the module approach, that if you have two modules, you look at the isomorphism classes and you choose two other representatives of those isomorphism classes and take the sum, take their direct sum, then you get the same. What you get is isomorphic to if you took the two original modules. Okay, so you have an operation, and it's, by the way, why do you take the isomorphism classes? Well, one thing is you're never going to get upset if you don't look at the isomorphism classes. If you just look at even singly generated modules, if you don't look at the isomorphism classes, there are too many of them because they might have, one might be apples, one might be oranges, all kinds of things. You have the isomorphism classes and they form a set for that.
00:48:10.160 - 00:49:19.940, Speaker B: Except you have to assume that talking about arbitrary, possibly arbitrary modules, you can't just take arbitrary modules because the cardinal number would be, would be too large, would mean arbitrarily large, and there's no such thing as a set of all cardinal numbers, right? So that's why we take finitely, that's one reason you take finitely generated here, because that means that the isomorphism classes will form a set. That was an exercise to check that this bunch of modules satisfies these initials. All right. Well, that's, but that's, this construction of an abelian group, which works for really quite a general class of modules, is, of course, if it's over a field, then it would have to come down with, here's another exercise. If you're talking about over a field, if r is a field, then it would have to be the usual one, okay? More or less the usual. I mean, there's just vectors, finitely generated vector spaces. Well, no, they could be countably generated vector spaces with some fixed bound on the number of generators and the minimal number of generators.
00:49:19.940 - 00:50:14.804, Speaker B: Well, all right, I think that's a good place to stop. We've got k zero of r, okay? It's an abelian group and it's a functor. Okay? So on Friday we'll whiz through what it means for it to be a functor and prove it's a functor. Unless everyone has proved already by farting that it's a. Everyone know what a functor is? It's, it's a fun, it's a category. Everyone know what a category is? Okay, category is a is a class, like take all, take all modules. It's not a set, but it's a category because you have objects and modules and then you have maps, arrows between the modules in the objects.
00:50:14.804 - 00:51:27.534, Speaker B: And association of arrows is composition of arrows is associative, okay? And it's almost like having semi groups and a functor between two categories is just a homomorphism. It preserves that the map takes objects into objects and arrows into arrows, and it preserves concatenation of arrows. Of course, you can't always compose two arrows, but when you can, then you can compose what they are mapped into and what you get is the same as what you get when you compose them before you apply the. Okay, so that's k zero, r is a reading group and k zero is a functor. And this functor, this is oversimplification. Roughly speaking, this function classifies sea star algebra, okay, by sea star algebras, I mean most ones and k zero and related things, correlated related functions. But at least well behaved, suitably well behaved sister algorithms, also phenomenal algebra in a different sense.
00:51:27.534 - 00:52:21.154, Speaker B: And so that's a rough summary of the course, but any, naturally. Well, I will welcome questions or comments with any, any time. All right, well, I guess we're. I figured out why. The secretary told me why we're not getting kicked out on the hour. Okay, because these tutorials haven't started yet. For some reason these large rooms are booked already for tutorials, but they haven't, which will soon start.
00:52:21.154 - 00:52:54.684, Speaker B: Oh, but we have a tutorial booked in a small room, 61. Well, Mister Lowell will tell you. 6180 pa 6180, it has room for ten or 15 people if you bring in a few extra chairs, and easily 15 people. Mr. Lau, I highly recommend his tutorial.

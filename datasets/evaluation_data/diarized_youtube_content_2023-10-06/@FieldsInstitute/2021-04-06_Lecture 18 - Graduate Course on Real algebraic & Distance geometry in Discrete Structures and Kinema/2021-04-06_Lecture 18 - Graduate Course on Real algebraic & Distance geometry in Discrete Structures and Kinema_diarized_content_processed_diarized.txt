00:00:00.480 - 00:00:36.020, Speaker A: You can see the plan to the left. And this is just a rough plan. So in case you want to ask more questions about something, let me know and I'll jump to it. Secondly, I'm not really an expert on this area, so my goal today is more to, I think I know enough to get you interested in the subject and perhaps to get you interested enough to join this workshop that you can see in the middle. Oops. There shouldn't be an alien here. Okay.
00:00:36.020 - 00:01:16.786, Speaker A: And so this workshop would be a good way to learn the basics at, like, a much higher level than what we'll get today. And, you know, interstrued with exercise sessions and all sorts of practical implementation. Like you'll be using software to actually solve problems. So I think this would be, should you be intrigued today, this would be a nice next step. Okay, great. So we've already accomplished one item on the menu. So next we have a puzzle.
00:01:16.786 - 00:01:45.650, Speaker A: So let's look at that. So, puzzle. And this puzzle I learned from Tadashi Tokiedo's videos on geometry that you can find on YouTube. And I think it's a really nice puzzle to sort of begin today. Okay, so here's the puzzle. Hold on. My pen doesn't seem to be working very well.
00:01:45.650 - 00:02:32.934, Speaker A: Okay, there we go. So the goal is to connect point capital a with point little a by a continuous path. That path has to stay in the disk. It can't go out here, but it can do whatever it wants in the disk. Okay, now that seems like an easy task to connect a to little a, but then also going to have to connect big b to little b and big c to little c. So what we need is we need three paths. We need a path from a to little a, and then a path from b to little b and another path from c to little c, and they cannot cross.
00:02:32.934 - 00:03:22.314, Speaker A: So the idea is the three paths. Three paths can't cross. They can't intersect, and they have to stay within the disk. So at first, I mean, at least to me, it's not immediately obvious how to do this puzzle or if it can be done, if it even has a solution at all. So what we'll do instead is we'll use a homotopy. And so what we'll do is we'll keep the, the boundary of the disk fixed, and we'll twist the disk sort of in the interior until we have points looking more like this. We twist little c up and it comes up here.
00:03:22.314 - 00:03:48.994, Speaker A: And then big c stayed where it was. We twisted little b down and to the right. Over this way. And so now it's over here. And little a and big a both remained on the disk because we fixed that. And now, you know, the solution is quite obvious. Like, okay, there's a path connecting b to b, another path connecting c to c and another path connecting a to.
00:03:48.994 - 00:04:57.794, Speaker A: So what we did is we did a homotopy, a continuous deformation until the problem was simpler. And now, you know, the issue is this wasn't our original problem. So what we have to do is we'll do a homotopy back. And so if we take our solution back to the original coordinates, oops, now all those, those points have to go back to the original spaces and we just keep our solution paths along for the ride. And I think you can see what's going to happen is something like this. Oh wait, let's see, c, b and a. Okay, so that's sort of the toy example that demonstrates, you know, at the core, what is homotopy continuation.
00:04:57.794 - 00:06:01.634, Speaker A: So let me just state it. So homotopy continuation is what we're going to talk about. And we're going to, you know, this is, these are just two words, but we mean them in a very specific sense for solving systems of polynomial equations. Right? So to solve just an arbitrary system of polynomials is in general a very difficult problem. For example, all of representation theory in finite dimensions at least, it just involves solving a big system of polynomial equations. And you know, well, for representation theory there's a really nice solution to that problem, but you know, this is very rare. And so in general, solving a system of polynomials is very difficult.
00:06:01.634 - 00:06:44.502, Speaker A: Okay. Yeah. So what I mean by polynomial equations, I just mean a list of equations. And so I'll usually write it like f will be our polynomials and they'll be in maybe capital n variables and there will be little m equations, maybe. So this would be n variables, maybe x one, x two to x m goes to m polynomials. So there's our first polynomial, here's our second polynomial in n variables. And the map is to Cm.
00:06:44.502 - 00:07:28.174, Speaker A: So that means we have m equations or m polynomials to satisfy. The solution set is just the preimage of a point. Over here, the solution set is somewhere inside of c to the, nice. And you know, typically we set up our polynomials so that we want them to be equal to zero, every single one of them. And so then, you know, the, we'd say maybe the variety associated to f is just the, the preimage of a point. Typically the .0 in Cm.
00:07:28.174 - 00:08:03.354, Speaker A: Okay. And maybe, maybe it's better just to say the zero set. Or maybe to call this an algebraic set. Just to make it clear, we're just talking about the set. It's a set of points in c to the n. Okay, so, now, homotopy continuation is a way to use, essentially, this idea in order to solve polynomial systems. And so, you know, in this idea, it was very crucial to have a simpler.
00:08:03.354 - 00:08:13.318, Speaker A: A simpler problem that we could solve. Okay. And so maybe we're done with the puzzle.
00:08:13.446 - 00:08:17.734, Speaker B: Okay, Alex, before you're done with the puzzle.
00:08:17.854 - 00:08:18.874, Speaker A: Okay. Yes.
00:08:20.054 - 00:08:30.004, Speaker B: So how many elements of this puzzle are you going to analogize for the polynomial system? Is the fact that they don't intersect important?
00:08:30.864 - 00:08:45.712, Speaker A: Oh, no, not really. That's just. That was just part of the puzzle setup. I mean, I could try to make an analogy because you do want to avoid homotopies where paths intersect, but we won't really be talking about that.
00:08:45.848 - 00:08:56.314, Speaker B: I see. So, because in this particular case, I mean, you can look at the graph of edges that you want and ask whether it's planar, right?
00:08:57.174 - 00:08:57.954, Speaker A: Yeah.
00:08:58.574 - 00:09:04.834, Speaker B: And it doesn't have a k five or a k 33 in it, then you'd be done.
00:09:06.174 - 00:09:06.510, Speaker A: So.
00:09:06.542 - 00:09:15.194, Speaker B: But I guess underlying that proof is something that's homotopy invariant. The idea of connectedness.
00:09:15.294 - 00:10:07.278, Speaker A: Yeah, yeah, yeah. I think this. This is a nice puzzle, and it could be used in many ways in our situation, but I was just sort of using it in terms of. Well, maybe I'll make it more explicit. So, say we have some polynomial system, f, that we want to solve, and, you know, we want to solve it. And then say we know a simple system that we can solve, we'll call it g, whose solutions we know. So, in this situation, f is up here.
00:10:07.278 - 00:10:39.128, Speaker A: It's the unknown thing that we couldn't solve at first. G is down here. It's a thing that we can solve. And so the key will be, the basic idea is construct a homotopy between g and f. In other words, deform f into g. Solve g deform. Oh, that's not deformed.
00:10:39.128 - 00:10:57.444, Speaker A: Deform the solutions back to f so that now they become solutions of f.
00:10:58.434 - 00:11:06.546, Speaker B: And I guess here you do want the path, the solution paths to not intersect, right? That's what you mentioned.
00:11:06.730 - 00:11:14.650, Speaker A: Yeah, yeah. So there is. There's. You know, if I had been clever, there were more things I could have done with this analogy, but.
00:11:14.842 - 00:11:27.834, Speaker B: Yeah, yeah. That would be sort of like, you know, when you apply the homotopy, what happens to those paths? You know, that is another path. That's what you're talking about here.
00:11:28.254 - 00:11:37.150, Speaker A: Yeah, exactly. And actually, what I have planned is that we will literally see those paths, in fact, an animation of them.
00:11:37.342 - 00:11:40.150, Speaker C: Can you help me with notation here?
00:11:40.342 - 00:11:41.734, Speaker A: Sure, yeah.
00:11:41.774 - 00:11:46.274, Speaker C: This c that you have, C to the n. This is a complex.
00:11:47.014 - 00:11:48.550, Speaker A: Yes. Yeah.
00:11:48.622 - 00:12:02.476, Speaker C: So so far you didn't mention anything about taking advantage of conformal, you know, geometry and the complex you're going through, are you?
00:12:02.620 - 00:12:31.424, Speaker A: Well, yeah, I mean, so this is, in essence, what makes homotopy continuation work so well for polynomial systems is that algebraic geometry over c, you know, is very clear, closely tied to complex analytic geometry. And so all the nice things about complex analytic maps will sort of mirror the nice things about polynomial maps. And so they are available.
00:12:31.584 - 00:12:33.888, Speaker C: All these tools will be available here?
00:12:33.976 - 00:12:34.648, Speaker A: Yeah.
00:12:34.816 - 00:12:36.724, Speaker C: Okay, cool. Cool, thanks.
00:12:37.384 - 00:12:48.286, Speaker A: I mean, I won't be talking about them because I'm not, you know, I couldn't speak intelligently on those connections. But that is why this stuff works. So.
00:12:48.470 - 00:12:51.274, Speaker C: And we're not going to talk about it.
00:12:51.574 - 00:13:01.234, Speaker A: Well, I'll talk about it a little bit. I mean. Yeah. So we'll see if you want. If you want to bring it up later. We'll see. I don't think I have much to say on it, but we'll see.
00:13:01.234 - 00:13:40.260, Speaker A: Okay, so, good. So I'd say that's done with the puzzle. So let's move on to the basic setup. Okay, so. Okay, to be, to be very simple at first, let's say that we have f of x equals x to the fifth plus. Okay, well, two x three, x to the fourth plus five, x to the third plus seven, x squared plus nine, x plus eleven. That's it.
00:13:40.260 - 00:14:39.524, Speaker A: And so, you know, this is a degree five, polynomial in one variable, and I don't know its solutions off the top of my head. And, you know. Okay, so for polynomials in one variable, you know the best. Probably the best. Okay, well, first of all, symbolically, you might hope to write down some sort of exact solution. But because the polynomial is degree five, it could be that it has sort of an exact, you know, exact solution, but it also could not be the case. And so, first, I would just like to point out that there's always sort of a symbolic versus numerical, um, not an argument, but just a choice.
00:14:39.524 - 00:15:51.344, Speaker A: But for practical purposes, it's really not symbolic versus numeric. It's really how far do we go symbolically before we eventually go numerically? Because even if I write down, let's say, the solution involved the square root of two, like, that's just a symbol. And in order to actually compute with it, and use it in interaction with other quantities. Like, I'm going to need to get some sort of approximation for this. And so, you know, even in the cases where you can solve by radicals, if you're going to use those things, you might have to convert them into numerical quantities and use floating point arithmetic. So our approach is going to be that solving an equation is to give a list of floating point numbers that are extremely close to real solutions and whose accuracy we can increase to any amount that we want. And then we'll say that we've solved it.
00:15:51.344 - 00:16:27.784, Speaker A: So maybe that's sort of, this is sort of just an aside. Well, okay, so here's our, you know, unknown solutions. Now here's another polynomial. Its solutions we know in particular, they form a. What a pentagon. There they are. This is in the complex plane.
00:16:27.784 - 00:17:17.391, Speaker A: And so known solutions. Now here's the basic idea. We are going to deform f into g and vice versa, and backwards. And so this will be our homotopy. And so we'll write h for homotopy, and it'll just be, let's see, tg plus one, minus t, f. And so this is just now we're thinking of f and g now as points in some space of, let's say, the space of degree five polynomials. This is a six dimensional complex vector space.
00:17:17.391 - 00:18:00.450, Speaker A: Or maybe since our polynomials all have real coefficients, we could consider it a six dimensional real vector space. And we're just going to take the straight line between f and g. And that is our homotopy. Now, later, it'll turn out that we'll want to twist this by a complex number, um, to avoid bad things. But for, for now, this is good enough. And so what is, you know, what is h? H is really a map. Maybe we can think of it like this, where we take x and t and we send it to h of x t, where h of x.
00:18:00.450 - 00:19:17.764, Speaker A: T is defined as t of g of x plus one minus t of f of x, where f and g are literally these polynomials here. So our unknown, our polynomial with unknown solutions, and our polynomial with known solutions. Okay, so now we have this, you know, straight line between the two polynomials. But then what we're going to want to think is that as we deform from f to g, our known solutions, which I've drawn here, will also sort of move around in time. This one might go over here. And so all of these solutions will move around in the complex plane, and they'll be following paths that will say, you know, maybe it's a path from time goes to zero, or time goes to zero to one, and they're just moving around in the complex numbers. Right? So we have our initial solutions, and they're going to move around in time following these paths x of t.
00:19:17.764 - 00:20:20.574, Speaker A: Okay? And so, sort of, we know that these paths should exist. These are maybe our solution paths. And so the idea is now to look at this homotopy and derive a system of odes that these solution paths are following. You know, at every point, this solution path has a time derivative. And so we could think to follow these solution paths just like we would follow the motion of planets under Newton, newtonian gravity, or any sort of ordinary differential equation with solution paths that we can follow through its phase space. And so that is the idea. So here we have our homotopy, and if we think, okay, well, instead of just a point x, I plug in the path x of t.
00:20:20.574 - 00:21:06.784, Speaker A: Then, you know, if these are solution paths, at the beginning, they were solutions of g. And at time t, there'll be solutions to some other polynomial, namely the polynomial. That's sort of t of the way between the polynomial g and the polynomial f. And so what we notice is that at every point in time, that should solve the equation. And so this must be true. The time derivative should be zero, just identically zero at all times. Is there any questions on this so far?
00:21:10.764 - 00:21:22.624, Speaker D: So, Alex, the reason that the derivative here is zero is because h, when you make the substitution, h, vanishes identically.
00:21:23.644 - 00:21:57.004, Speaker A: Yeah, exactly. So this is. So here's our homotopy, and we suppose a solution path x of t exists. And so what that means is that just we assume that there's some path that if I plug it in for x, regardless of the time, it'll always give a solution. So, in other words, x of. Let's see, x of zero. If I plug in t equals zero.
00:21:57.004 - 00:22:09.244, Speaker A: X of zero solves f, x of one solves g. Okay.
00:22:11.424 - 00:22:12.320, Speaker D: Got it.
00:22:12.472 - 00:22:34.668, Speaker A: Got it. Okay. And so this. Sorry, I should have written this down, because we don't know this solution path. We would love to know the solution path, because if we knew the path, then we could just follow it and get the solutions of f. By the way, we're following. Follow from t equals one, which seems a little bit silly.
00:22:34.668 - 00:23:00.084, Speaker A: Two, t zero. But the reason is that there are many more floating point numbers near zero than there are near one. And it turns out that everything will be easy until we get right to the end at t equals zero, at which point we could find singular solutions, and things will get harder. And so we'll want more floating point numbers. Numbers, but.
00:23:01.864 - 00:23:14.564, Speaker D: Seems hard to me. What's, why do we start at t equals one solving g?
00:23:15.104 - 00:23:15.600, Speaker A: Yeah.
00:23:15.672 - 00:23:18.296, Speaker D: Okay, so we're just reversing time. Okay, that's fine.
00:23:18.400 - 00:23:57.084, Speaker A: Yeah, exactly. This really bothered me for a while when I was first learning this, because why not just go from time zero to time one? Well, the reason is because when you actually implement this, you need more floating point numbers at zero. So in other words, the end points of your pass are going to be tricky. So that's why. Okay, so, and please continue to interrupt me with questions, because it would, it makes it way more fun for me. So sort of selfishly for me, please interrupt. But also, you'll get more out of it if you interrupt.
00:23:57.084 - 00:24:38.842, Speaker A: Okay, so this is the basic setup. And now when we make this observation that, you know, the time derivative is zero, then let's just expand this left hand side and see what it says. Well, dh dx at x of t, t times x dot of t. That's the time deriVative. And then plus, this is just the chain rule. Now, we DifferentiAte in the first slot, and then we differentiate in the second slot. Dh dt, and then dt dt is one.
00:24:38.842 - 00:25:28.574, Speaker A: So in other words, right here we have a, you know, system of ods. And so in this case, where we have just polynomials of one variable, right? G of x was x to the fifth minus one. F of x was some degree five polynomial. And so we really only have ONE variable. And so it's not, you could say it's not a system, it's just one ode. But even in this case, these numbers, the solutions here are in C. And so really C is R two.
00:25:28.574 - 00:26:07.974, Speaker A: And so we sort of do have a system. In other words, we could think about this as, you know, the real and imaginary components. And then this is a two by two matrix, and this is a two by one column vector, and this is a two by one unknown column vector. And so we have a system of two of these. But in actuality, like, we can each of these two dimensional things, we, it has, you know, its real AnD IMAginarY part. And so we can just do all the arithmetic with complex numbers. And doing arithmetic with complex numbers is, you know, is going to exactly encode the same information.
00:26:07.974 - 00:26:56.492, Speaker A: So, okay, so now this is a system of oriz. And so at this point. And also it's an initial value problem. Initial value problem. Why? Because we know that at x of one, x of one is in, you know, this set. And so we just propagate from x of one back through time. And then we discover x of zero, which will be sort of, we just propagate these solution paths forward using this ode system, and we get it.
00:26:56.492 - 00:28:27.474, Speaker A: And so, in particular, use any of the many methods, for example, like ode, four, five, or something in Matlab or something like that. Rungakuta method, any methods, any of the many methods to numerically solve OD's. And you will pick up the unknown solutions as the endpoints of the time evolution of each of these initial solutions. And so that's sort of the idea. Okay, so, as a recap, we took our hard problem, which is we didn't know the solutions to g, and we constructed a homotopy, in this case, a straight line in the space of degree five polynomials, to some easier situation, whose solutions, we knew all of them. Then we track these solutions back through time until they become solutions of g by just solving this ode, which we obtain by just time. Just take the time derivative of our homotopy, and now we can solve.
00:28:27.474 - 00:28:30.154, Speaker A: Okay.
00:28:31.894 - 00:28:49.384, Speaker D: Alex, have we made some kind of interchange of g and f at some point here? Maybe I'm getting this wrong, but I thought we started with f, which was at time one that we didn't know how to solve, and then we went.
00:28:49.424 - 00:28:53.352, Speaker A: To g. Oh, yeah, maybe I just, in my explanation, I might have switched them.
00:28:53.448 - 00:28:54.440, Speaker D: Okay. Okay, cool.
00:28:54.512 - 00:28:55.160, Speaker A: I'm sorry.
00:28:55.272 - 00:29:18.172, Speaker D: Yeah, this is good. And do these od solvers, I mean, I've used the Matlab one before, but I'm not super familiar with them. Do they have this property that we'd like that you can get more and more accurate just by, I don't know, decreasing the tolerance or something like that?
00:29:18.228 - 00:29:52.162, Speaker A: Oh, good question. In general, no, they don't, but for us they will. And so this is the brilliance of why this method is so useful. And let, so let me, let me go into more detail with them. Okay, so let's talk about Taylor series. So h of X plus delta x, t plus delta t. Okay.
00:29:52.162 - 00:30:42.586, Speaker A: And so from this Taylor series, we're going to see how to numerically solve the ode. And so what is it? Well, it's h of x, t plus. And by the way, just remember what h is. H just, it has built into it the, you know, the motion from f to g and back. Either way, I forget which way it's supposed to go, but it basically, it has the polynomial f, and it has the polynomial g built into it, and it's interpolating between the two. So h is what we're talking about. And so what is this? Well, this is dh dx at xt times delta x dh dt.
00:30:42.586 - 00:31:55.298, Speaker A: This is, again, the chain rule times delta t plus something of order, the norm of delta x. Delta t, like it goes to zero faster than any linear function. And so, you know, to first order, what we have is just this up here. Okay? So now say we know xt. So at first, this x will be, you know, x will be one of our roots of unity, just one of them, and then t will be one. Okay? Say we know we're at one of those points where h of x t equals zero, and we want to propagate it. We want to start following that solution path, you know, to see where this, this x of one goes.
00:31:55.298 - 00:32:46.984, Speaker A: And we want to see how to go. And so what we need to do is we need a delta x. We need to actually stage, we want delta x such that h of x plus delta x t plus delta t is zero. Okay? So then what we have is a zero equals. Well, that part is zero, right? Both of these, we want zero. And then we have, this is our unknown. So choose a small delta t and then solve for delta x in this equation.
00:32:46.984 - 00:33:27.684, Speaker A: Okay? And so this is, this is what would, I'll just call it an Euler step, because we know xt. So we can. We can evaluate, and we also assume we can evaluate this derivative at x t. We can evaluate this derivative at x comma t. We choose our delta t step size, and the only unknown is this delta x. And so we just solve for it. In particular, delta X equals, you know, dh dt delta t minus divided by dh dx.
00:33:27.684 - 00:34:23.750, Speaker A: Later, when these aren't just single complex numbers, we'll have to solve a linear system. But this is still just solving one linear system to discover delta t, or, sorry, to discover delta x. Okay, so this is the Euler step. And now here's the part that was brought up before, is, can we, you know, if you just do euler steps, then you have some solution path you're trying to follow. But your euler steps will kind of get progressively worse and worse, and the error will keep getting worse as you go. But for us, at every xt h of xt equals zero. And so this can use Newton's method, a Newton step.
00:34:23.750 - 00:35:09.607, Speaker A: So what's a Newton step? Well, if h of X t is not zero, so say h of X t is non zero. That's bad. That means that we're sort of, our euler steps are moving out x of t, maybe, and sort of. We're off a little bit. If we were on the true solution path, then h of x t would be zero. It would be exactly zero, because what is h, h, for us, is literally a polynomial. So at every moment, we have this, this extra fact that our point is a solution to a known polynomial.
00:35:09.607 - 00:35:41.374, Speaker A: Plug in the value of t where we're at, and we will get a single polynomial in X. And if we're on the solution path, our x solves that polynomial. And so we just look at the, you know, the same. Say this is non zero, but we want this to be zero. Delta T will take to be zero. We won't, in other words, we're not going to take an Euler step, but instead, we're going to correct. We're going to find our delta x such that these things are zero.
00:35:41.374 - 00:35:59.704, Speaker A: And so let me get rid of all that crap. Say h of X. T is nonzero. We want h of X plus, you know, this is at X plus delta x. T plus delta t. We want that to be zero. Want this zero.
00:35:59.704 - 00:36:19.184, Speaker A: So that's the left hand side. H of x. T is now non zero, because we've, we've made some error in our euler steps. We're getting sort of worse, and we're away from our true solution. So we want to correct it. We want to find a delta X that will correct. So this is a correction step.
00:36:19.184 - 00:37:13.462, Speaker A: And so what do we have? Well, you know, want that set delta t to be zero. We're not going to take an Euler step. Instead, we're just going to solve this equation for Delta X. And so our correction Delta X will just be minus the evaluation, this was non zero divided by the derivative. Okay. All right, so this is basically, you know, from this Taylor series right here, we sort of can see how to, at least very naively, how to solve this system of odes as we step time forward. When we see that our error is getting too bad, then we'll correct it with Newton's method.
00:37:13.462 - 00:37:47.854, Speaker A: And that's the idea. Any questions on this part? So, under which condition does this surgeon pass exist? So, yeah, so we haven't talked about that at all. So, good question. The key will be choosing a good g. In other words, like the g, we chose x to the fifth minus one. It turns out it'll work. And in general, this is called finding a start system.
00:37:47.854 - 00:38:23.344, Speaker A: And you can always find a start system. In particular, this sort of a start system here would be called a total degree start system. And these will always work. But for many cases, there'll be, you know, smaller start systems that will require less work, less computation. And those will use things like the Newton polytopes and combinatorial information to get better start systems. But to answer your question, yes, it will always work. Yeah.
00:38:23.344 - 00:38:39.624, Speaker A: Also for any other, for any GX, it will you. They will always exist. Solution pass. Yeah. Yeah. I mean here, let's. Let's see.
00:38:39.624 - 00:38:40.324, Speaker A: Just.
00:38:41.624 - 00:39:22.696, Speaker D: You should be careful, right? The. Isn't there. I mean, we can have the paths go off to infinity. Right? And we can also have some other kind of problems that can occur where the systems equations are not, are not solvable. Right? Like when you, when you try to. The numerical systems, when you're trying to solve for Delta X or things like that. Can't those become singular matrix, singular systems of equations?
00:39:22.880 - 00:39:25.484, Speaker A: Yeah. Okay. So let's.
00:39:25.864 - 00:39:27.024, Speaker D: You can get around this.
00:39:27.104 - 00:40:36.424, Speaker A: When I look at this picture, let's say that this solution, which is a solution to f, let's say that it's singular. Still, what we'll be able to do is we'll be able to guarantee that the entire solution path consists of non singular solutions and only at the very end will it become singular. And so even in these cases, we'll be able to find the solution, although we'll have to slow down and be much more careful and use things called end games. Now the other thing that could happen is that the endpoint goes off to infinity. But then we realized that, like our whole picture was actually in projective space and going off to infinity. You know, if that solution path was moving, here's one of our start solutions and it goes off to infinity. But really what we can do is just choose a different affine chart, make a change of coordinates and we'll find a finite solution.
00:40:36.424 - 00:40:54.384, Speaker A: So in other words, even if your endpoint, the solution of your original unknown system has solutions at infinity, we can still track those and we will still find them. So that's pretty nice.
00:40:54.884 - 00:41:05.924, Speaker C: So the g that you pick up in a way, represents all polynomials that with maximum degree five.
00:41:07.384 - 00:41:14.800, Speaker A: Yeah, exactly. It would be. It's a. You could say it's a start system for all the polynomials of degree five. Yep.
00:41:14.912 - 00:41:16.364, Speaker C: That's very elegant.
00:41:16.704 - 00:41:51.852, Speaker A: In particular, if we chose if f actually had degree four, then one of the solutions would go off to infinity. And so that situation that will mentioned would happen. But still this would work. And it would just be. We'd notice that our solution path was having extremely big coordinates. And so we'd switch to some other affine chart of projective space and follow it. Okay, but let's actually see this in action.
00:41:51.852 - 00:42:43.124, Speaker A: So I will switch and we'll actually do some programming and watch these solution paths. Okay, let's see, how do I do this? Okay, can everybody see? Yep. Okay, so I was going to just do it from scratch, but maybe I'll just. Okay, so maybe I'll zoom in. So I'm going to cheat a little bit. And I'm going to use the package homotopy continuation, just so I have variables, but I'm not actually going to use their bit built in things. So this first cell here, what did it do? Well, so first, let's look at the Zetas.
00:42:43.124 - 00:43:11.974, Speaker A: These are our start solutions. If you can see them. Here's the five points on that unit circle. Hopefully you can imagine where they are. These Zetas, these are going to be our five initial values. And we're going to track each of these initial values through time until it becomes an endpoint. Here's g.
00:43:11.974 - 00:43:43.414, Speaker A: G is our start system. Here's f. Now, I've written f so that you can explicitly see the solutions. But, you know, pretend that we didn't already have a factorization of f. Then we wouldn't know that it had a solution. At X is three, a solution at two plus I, another at two minus I, another at four plus two I, and another at four minus two I. And finally, here's our homotopy.
00:43:43.414 - 00:44:10.486, Speaker A: As you can see, I put this extra gamma in, but for right now, it's just a one. So it's doing literally nothing. And now I differentiate. So we can just take a look at those partial h. Oops, partial x. So this is again a polynomial. And so if I just evaluate it at some point.
00:44:10.486 - 00:44:44.316, Speaker A: Evaluate this at, I don't know, 10. Oh, wait. Oh, yeah, I forget, you have to do the variables. There we go. So then what I have is I have these derivatives, these two derivatives that we saw in the Taylor series, and we can evaluate them at specific parameter values, x, comma t. Okay, Alex, I'll.
00:44:44.340 - 00:45:00.410, Speaker D: Have many questions for you later about what you're doing inside the Jupyter notebook setup, because I haven't seen the Jupyter notebook used in this way before. But does the differentiate command come in the homotopy continuation package?
00:45:00.562 - 00:45:23.538, Speaker A: Yeah. So this is sort of how I'm cheating is I'm using the polynomials you could have instead of this, you could have just used something called dynamic polynomials, and then you could do it without. But you. Yeah, you. So in Julia, you invoke packages where other people have written code, in this case, to do symbolic differentiation of polynomials.
00:45:23.666 - 00:45:27.544, Speaker D: I'm sorry, I missed that you were writing Julia as opposed to Python.
00:45:27.714 - 00:45:32.732, Speaker A: Oh, yeah, yeah. This is a Julia notebook. Yeah.
00:45:32.868 - 00:45:33.544, Speaker D: Great.
00:45:34.404 - 00:46:06.034, Speaker A: Yep. Okay, so, because I didn't want to keep writing this, I just made a little a shorter eval function. And now here's our Euler step. So these are our current points wherever we are. And then here's our desired delta t. And it's going to return the new. So it's going to compute delta x as the solution of a linear system, and then it's going to update our old x for the new one and return the new one.
00:46:06.034 - 00:46:37.474, Speaker A: Okay. Similarly, our Newton step will just solve for delta x in the same equation, but with slightly different conditions. Here we're setting delta t is equal to zero. So this term then vanishes, and we solve for delta x in this equation, because this zero over here is like, you know, we want h of x plus delta x, t plus delta t to be zero. So we put zero there. Same thing. We just solve a linear system.
00:46:37.474 - 00:47:24.774, Speaker A: Right now, I can just literally divide because we have a single complex number. But in other, you know, for more variables, we would solve a linear system, but it would be a similar command. For example, in Julia, I think you could say delta x equals a backslash b to solve ax equals b, or a delta x equals b. So it's really, we could have done this in more variables. And so there's our Newton step. Now, here's our correct method. This will just apply Newton steps over and over until our point is within our specified tolerance of having zero norm.
00:47:24.774 - 00:48:18.684, Speaker A: So this is saying, if our euler steps were getting away from our path, then we're going to correct it until we're back on the path. This is really nice, because as long as we stay decently close to the path, Newton's method has some region of quadratic convergence, and so it'll converge fairly quickly to the true solution. And so in other systems of odes, you don't necessarily have such a nice corrector method, but here we do. Okay. And then our main thing is we're going to track the paths. We're going to do path track. And so we take time starting at one and going backwards by delta t, which we specify it's up to us and going to zero.
00:48:18.684 - 00:49:03.984, Speaker A: And then for each time step, we compute an Euler step. This might go away from our path a little bit, but then we correct it by using a bunch of Newton steps until we've gotten to our tolerance, and then we record our, our new solution at each time step. This gives the discrete version of that path that we're tracking here. We can do this. I took a time step of. I don't know why I took this time step, but it's small enough. Then I create an animation so we can watch it happen.
00:49:03.984 - 00:49:24.724, Speaker A: And here it goes. Hopefully it'll. Okay, so you can see the five solutions sort of go. I sped it up after a certain point, and there they land. There's the solution. Three. There was the two plus one minus one I and here was the.
00:49:24.724 - 00:50:05.168, Speaker A: I forget what they were. Probably four plus two I and four two I. Okay, can everyone see that? Good. Okay, now, I didn't actually talk about this, but to make it a little bit better behaved, you can spin it by a certain gamma and then you just get. It still works, but they take sort of loopier paths before they eventually reach the endpoints. Okay. And so I don't know, x is end or x is the first one.
00:50:05.168 - 00:50:26.004, Speaker A: And. Yeah, so here's the two. Here's two minus one I. Okay, and let's see the other, the second solution. Here's the three plus zero I. So this is the solution. Three, you know, the real number.
00:50:26.004 - 00:50:40.552, Speaker A: Where was it? Here's that solution. And so we can look at the others. And sure enough, two plus one I for plus two I, etcetera.
00:50:40.608 - 00:50:58.514, Speaker D: I was expecting to see numbers a little closer to, like, when you looked for the number. Let's just look at this one. It's often the. For the imaginary part, it's often the third decimal place, right?
00:50:58.934 - 00:50:59.534, Speaker A: Oh, yeah.
00:50:59.614 - 00:51:07.966, Speaker D: Well, this is just because was like one to the minus eight, right? So I was expecting to see like eight decimal places.
00:51:08.150 - 00:51:50.136, Speaker A: Oh, yeah. So, I mean, that was, my tolerance was for the norm of the solution. And also, in no way should anybody take this as a good implementation. I had never done this before, so I wanted to do it. And so this was the dumbest way I could do it. In one of those books that I'll show you in a moment, there's a whole chapter on how to do this. And of course, this package in homotopy continuation has implemented it with adaptive step sizes and all sorts of much smarter things that they can do.
00:51:50.136 - 00:51:53.672, Speaker A: And so this works much better than it's working right here.
00:51:53.848 - 00:52:04.004, Speaker D: Can you say. Okay, that's cool. Can you say a little bit more about the gamma trick? Why do we not so much like, how do we do it, but why do we do it?
00:52:04.384 - 00:52:37.742, Speaker A: Okay, good. So let's move back to the screen. Okay, so here I am. Okay, so we've accomplished these steps, the gamma trick, I would like to talk about it here. So if we can wait for just a moment.
00:52:37.878 - 00:52:38.754, Speaker D: No problem.
00:52:39.174 - 00:53:31.344, Speaker A: Okay, good. So just very briefly, we're talking about frameworks, and so I wanted to give a couple examples of how to use these tools. So, okay, so at this point, you have literally seen what is happening. This is the basic idea, those animations of following the solution paths. That is what home entopic continuation is doing. And so, in my opinion, once we understand that, then we sort of have the basic idea, and now we can start to think, how can we use this? How are, you know, how many different ways can we take advantage of this to obtain interesting geometric information or just practical solutions of equations? So that's sort of the rest. Okay, so just briefly.
00:53:31.344 - 00:54:11.614, Speaker A: Oh, yeah. And I should say that if you want to learn more about how to do this, you know, much more robustly, either of these two books would be an excellent choice. Bertini is a different system that you can use. There's many different software that's been already built that you can just use, but here. But in both books, you'll just learn the basic theory. And what I had shown you is a different one. In Julia, there's also packages already built in python and many other things.
00:54:11.614 - 00:55:18.824, Speaker A: So, okay, I want to get to the gamma trick, but first, let's do the rhombus. So just to divert for a moment, and I'll show how to use these tools on some silly examples. So consider a rhombus in the plane. So this is, all four sides are supposed to be equal. And in order to remove the translations and rotations, let's fix these two vertices in place, let's say coordinates 0010, and then leave these vertices open. And then the, you know, the configuration space of this framework, let's call it c. It lives inside of four reals.
00:55:18.824 - 00:55:38.844, Speaker A: Does everyone agree? And my question is to you, what does it look like? It is a subset of r four. What can you tell me about it? Does anybody know?
00:55:48.404 - 00:55:49.584, Speaker D: It's a curve.
00:55:50.084 - 00:56:01.704, Speaker A: It's a curve. So what is a curve? What does being a curve mean? Does that mean it's one dimensional? One dimensional? Is it a manifold?
00:56:06.484 - 00:56:08.298, Speaker D: You're asking whether it's smooth?
00:56:08.436 - 00:56:09.154, Speaker A: Yeah.
00:56:10.694 - 00:56:12.674, Speaker E: No, it shouldn't be, should it?
00:56:13.654 - 00:56:29.794, Speaker A: Okay, so we have a vote for no, but maybe, like, not entirely sure. Yeah, so if it's not smooth, then, then where is it not smooth? And how many points is it not smooth?
00:56:30.654 - 00:56:36.284, Speaker B: Alex, do you have the particular lengths for those other bars besides the one at the bottom?
00:56:36.444 - 00:56:37.884, Speaker A: Rhombus so they're all one.
00:56:37.964 - 00:56:43.464, Speaker B: One. I see, yeah. Okay, so then of course you have, well, I'm not going to answer, I'm going to let the class answer.
00:56:44.764 - 00:56:49.744, Speaker E: So then it's not smooth because it can fold up when it flattens out.
00:56:50.164 - 00:56:54.144, Speaker A: Okay, so you're picturing maybe something like.
00:56:55.684 - 00:56:59.028, Speaker E: Yeah, and then got two choices of where it can go.
00:56:59.156 - 00:57:06.354, Speaker A: Ah, two choices. Okay, so what would that, what does that translate to here? What does it look like?
00:57:06.894 - 00:57:20.942, Speaker D: Yeah, why does it not smooth. Why does some kind of weird singular, singular realization like this correspond to a singular realization and a singular point in the configuration space? That's.
00:57:20.998 - 00:57:25.794, Speaker A: Yeah, good question. This is in the plane and this is in r four. Shouldn't they be totally different?
00:57:28.994 - 00:57:48.454, Speaker D: I think you're probably right that there's some problem here, but, but it's not obvious to me that singular realizations of the framework correspond to singular points or problem points in the configuration space.
00:57:48.994 - 00:57:55.964, Speaker E: I think it was still just look like kind of two circles touching but embedded in four reals.
00:57:56.084 - 00:58:00.508, Speaker A: Oh, so you think a circle and a circle like that.
00:58:00.636 - 00:58:02.064, Speaker E: I think so, yeah.
00:58:02.564 - 00:58:04.344, Speaker A: And here's the singular point.
00:58:04.804 - 00:58:07.464, Speaker E: Yeah, I think it should look like that.
00:58:08.724 - 00:58:41.974, Speaker A: So that's okay. So this is really fun for me. Thank you guys for playing the game. I asked Bob Connelly a question via email and he sort of guided me through this, where I was wrong and wrong and wrong and wrong. Now let's see what it actually looks like. We're going to use homotopy continuation to just literally sample this thing at a bunch of points really quickly. And then we're just going to project it to a random three dimensional space and we're going to look at it.
00:58:41.974 - 00:58:49.134, Speaker A: We can do this very quickly in hobotopic continuation and we get this result.
00:58:50.064 - 00:59:01.744, Speaker D: Wait, Alex, I understand what you would mean by. No, I don't, I don't understand what you mean by sampling. What does that mean here?
00:59:01.824 - 00:59:06.152, Speaker A: Okay, so, okay, well, first, so this.
00:59:06.168 - 00:59:08.280, Speaker D: Is a curt look at the result, and then we can.
00:59:08.352 - 01:00:17.164, Speaker A: Yeah, and so how can you like what is a data structure for a curve? To me there's sort of three options, a parameterization, aka you write the curve as the image of a map. Secondly, you can have an implicit representation, which is you write down, you know, write down and store in your computer equations defining it. But a third way is just to just have a list of many points on the curve. And to me, that third representation of a curve is one that I don't see often, but is really useful for many, many things. And so first of all, here's one singular point. Here's a second and here's a third. These ones right here are actually just figments of the fact that I drew a three dimensional thing on a 2d screen.
01:00:17.164 - 01:00:47.834, Speaker A: So in other words, the circles don't cross at those four points. And so I hope you can sort of see. Now this is what it looks like. Okay. In particular, all these blue things here correspond to these exact points. So each of these points was a configuration and I plotted it. You know, that pink point might have been like this here.
01:00:47.834 - 01:00:51.914, Speaker A: Does this make sense?
01:00:53.734 - 01:01:02.754, Speaker D: This makes sense, but I'm still trying to understand what you're sampling.
01:01:03.384 - 01:02:10.094, Speaker A: Oh, okay, so, okay, so very explicitly, this is a picture of many points on v of the equation between 1234, I have this equation, this equation and this equation. So 2334-142-3414 and each of these says bar between Verdi vertices. Two three has length squared equal to one. So there's three edges that give three equations. And each of these has four variables. And so we have the variety cut out by these three polynomials in four variables. In other words like f is a map from c four to c three.
01:02:15.154 - 01:02:16.174, Speaker D: Okay, so.
01:02:19.554 - 01:02:21.014, Speaker A: So it's interesting because.
01:02:21.824 - 01:02:33.244, Speaker D: Right, so this is a curve. And so you'd rant you, are you randomly picking a point on this curve and then plotting it?
01:02:33.624 - 01:03:13.446, Speaker A: Yeah, so it's definitely, it has an element of randomness, but the randomness is. Yeah. Okay, so what we're going to do is we're going to see that when we compute a witness set. So one of the many ways that this can, this kind of a tool, homotopy continuation, can be used is to sample a variety. And in fact you can sample a variety according to different probability distributions, if you like. And this can be done rigorously with error bounds and or otherwise you can just sample a variety very quickly. And so what you do is you slice it with many, many different linear spaces.
01:03:13.446 - 01:03:27.414, Speaker A: And because you have a witness set, you can just move those points over and we'll sort of talk about this maybe on Thursday. But, but basically that's how I get so many points that it looks like a continuous curve.
01:03:29.514 - 01:03:48.334, Speaker D: I see, I see. So you're not. Well, maybe you are in, but you're not actually tracing a path from one point on the curve to another point on the curve. And then like using a homotopy continuation and then just plotting those.
01:03:49.194 - 01:03:53.534, Speaker A: Oh yeah, so I'm not doing that. However, I could do that.
01:03:54.114 - 01:03:54.786, Speaker D: Right.
01:03:54.930 - 01:04:32.234, Speaker A: And actually I did that for the strand beast, which is an example that we saw last week. Why don't I just even show you that right now? Well, okay, we'll just go with the plan that I had originally, but you can also do that. But this is a little different. I just wanted to give you a taste of some of the different things you could do. In particular, if you're wondering, what does this look like? And maybe, like Sean, you had sort of an idea that it was going to collapse, and then it should be able to go two ways, or really the two ways are more like that way or that way, Sean.
01:04:32.714 - 01:04:36.882, Speaker E: Yeah. So I guess it can fold up three times by the looks of it.
01:04:37.018 - 01:04:55.494, Speaker A: Exactly, yes. And so now then, you know, by. By doing this quick experiment, you will much quicker converge to the right answer, at least for me. I did not converge to the correct answer for a while. And I wish I had just plotted this first because I would have been faster.
01:04:55.954 - 01:05:07.934, Speaker E: So I think I can see it. You can go. So if you go, if you have the bottom fixed and you pivot to the right, you can eventually get to a point where you can fold it up.
01:05:10.074 - 01:05:10.578, Speaker A: Again.
01:05:10.666 - 01:05:16.258, Speaker E: Yeah. So something like this, then you can lift it so it folds up into just two points, basically.
01:05:16.426 - 01:05:16.890, Speaker A: Yep.
01:05:16.962 - 01:05:19.814, Speaker E: And then you can have it unfold in the other direction.
01:05:20.154 - 01:05:20.922, Speaker A: Yep.
01:05:21.058 - 01:05:31.646, Speaker E: And then yet again, go back to normal after that. And you can just cycle between those three different positions. Yeah, the three, I think.
01:05:31.830 - 01:05:46.834, Speaker A: So this is a really fun example to think about. And because you can, eventually, you can understand these three pictures that Sean just explained as corresponding to these three singular points. Yeah.
01:05:47.694 - 01:05:54.934, Speaker E: I guess if you did the. If the lengths were different, like Meera said, I guess this wouldn't be an issue. So you just circle something.
01:05:55.434 - 01:06:30.854, Speaker A: Yeah, yeah. So this is a very special, um, example, but it's a good one. Um, now a second example would be. Okay, so now we found. We saw singular points where basically two circles were touching. So this was a singular point. But a nice example that I also asked Bob Connelly, was, could we ever get a configuration space that has a cusp? And, well, just sent me to one of his papers, and there in that paper was this example.
01:06:30.854 - 01:07:15.244, Speaker A: So I'll draw it. So now we fix this one, fix this one, fix this one. And what we have right here would be a two dimensional mechanism, actually. And so we'll add one more bar. Oops. Between those. And now what happens is that, like, well, if we just had this fixed, a single, like this, this would be the watt mechanism, and it would sort of trace out one of those little curves or the watt link, the watt linkage.
01:07:15.244 - 01:08:25.742, Speaker A: But in this case, we have two of them connected to each other, and then they're sort of joined together by this middle bar. And so the end result is, it's claimed in the paper that this gives a configuration space with a cusp singularity. Now, if you'll, if you count dimensions 2468, dimensions 1012 1416. So this is, you know, a subset of r 16. And the claim is that this configuration right here is a singular configuration on the curve, which is the full configuration space. And what's more is that they claim is a cusp singularity. So let's say you doubt and you want to see the cusp.
01:08:25.742 - 01:09:24.801, Speaker A: Okay, well, then you can just, with not too much effort, go into Julia, and this is what you get. So here we see, I project to a random two dimensional subspace, oops, subspace of R 16. And here's the, you know, here's the singular configuration. And then these blue ones are, correspond to these points on the curve. And these red ones over here correspond to these red to orange points on the curve. And you can literally, you know, you can animate this and watch the cusp singularity occur, or you can project and look at the cusp. And this is pretty neat.
01:09:24.801 - 01:09:44.213, Speaker A: So I guess these two examples are meant to illustrate that if you want to do some experiments on a specific example, you can pretty quickly do them and come up with interesting results. Are there any questions on this one?
01:09:45.033 - 01:10:36.842, Speaker D: I have a pretty general question, actually. We've been talking about solving systems of equations that come up from these euclidean distance metrics, and those systems were often quite hard, right? I mean, take days to solve some of the systems, but here it seems almost like you're solving hundreds or thousands of such instances very quickly. Am I wrong that you're solving euclidean distance problems? Or is it because we start with a start point that allows us to do these kinds of things? What's going on?
01:10:37.018 - 01:11:01.134, Speaker A: Yeah, okay. Yes, this. So this is a question. How are we able to solve so many so quickly? Because, you know, each point is us is me solving. Right? And so that brings us to our next topic. So we're done with the rhombus. So thank you, will, for just moving me along.
01:11:01.134 - 01:11:45.002, Speaker A: How are we able to do that? Well, the answer is parameter homotopy. Okay, so let's talk about that. And actually monodromy, which we might get to today, is even more efficient. So first, let's talk about parameter homotopy. Parameter homotopy. Okay, so let's say we have a system of polynomials in n variables. And let's say that we have n polynomials.
01:11:45.002 - 01:14:04.804, Speaker A: So we'd say this is a square system of polynomials. But then let's actually embed it as just one system in a whole family of systems depending on p complex parameters. And so we have our variables, our parameters, and then our polynomial system, which, you know, has its components f one of xp, f two of Xp, all the way down to the nth polynomial of XP. And so this is going to, thinking about it in this framework is going to allow us to solve many, many instances very quickly because of this parameter space. So let me explain. So if you know, in this parameter space CP, if we pick a generic point, let's say p, okay, I don't know p generic, then we plug in those values for p and we get a square system of polynomials, n variables and equations, correct? Now solve that. This is a one time, perhaps difficult, perhaps difficult computation, okay? Now what will happen then is that at the end of that conversation now we have start solutions for any other system in that family, okay? And so what happens here is that in order to solve this for this generic point, we might have to use something like a total degree homotopy.
01:14:04.804 - 01:14:56.568, Speaker A: Essentially we'll need a start system to get these, to get the solutions to this one. And that start system might be way worse, it might be way bigger, it might require a lot more computation, but at the end we'll find some, you know, probably much less of the solution paths converge. And now we have start solutions there for this parameter point. Now the idea is that in our mind we had already like one, two, three, many, many, many other parameter values. Other parameter values, perhaps they are real numbers, real number parameters. In other words, they're special. And really we wanted to solve for every one of these purple points.
01:14:56.568 - 01:15:57.724, Speaker A: We wanted to solve a system of polynomials. And so the brilliant thing is we don't need to solve them each with a big computation. What we can do is now move this one to each of them and the moving of that of the generic one to all these. It will be very fast because we only have to track the much number, the much fewer number of paths. Okay? So I don't expect you to fully understand this, so let me try again. But this is the, that was the basic idea, is that when you put your polynomial system in some sort of a family, then you do one computation for a generic parameter value in that, or for a generic system in that family, and then you can move that generic system and its solutions to the systems that you care about. Which are also members of that family.
01:15:57.724 - 01:16:08.634, Speaker A: And the point is that this is much faster. And so in doing this, you can solve many systems very quickly.
01:16:09.334 - 01:16:28.934, Speaker D: Alex, you mentioned that there's, that this is much faster. And you said one of the reasons why it's faster is because you track fewer paths. Why are there fewer paths to track for the solutions?
01:16:29.354 - 01:17:18.714, Speaker A: Sure. Okay. So in one part. So I gave the single variable example because I felt that it was the easiest to understand because now I think everybody has the sort of the general idea of what is a start system. But for more variables. When you move up to more variables, the start systems that are sort of the analogous total degree start systems, they will have many, many more solutions than your original system. So, you know, in particular, that rhombus, the rhombus we did had three polynomials in four variables.
01:17:18.714 - 01:17:54.214, Speaker A: And so, okay, let's add a linear equation. So it had four polynomials and four variables. And so. But it might not. In fact, this variety has degree six. So this is a curve of dimension one, and degree six, it's an algebraic curve. Yet if we solve this system using a total degree homotopy, we would have degree two, degree two, degree two, degree one, which would a priori expect eight solutions.
01:17:54.214 - 01:17:58.974, Speaker A: But you see that there are only six solutions.
01:18:00.434 - 01:18:01.174, Speaker D: Right?
01:18:01.514 - 01:18:31.350, Speaker A: And so this is the phenomena in general, is that sort of the most naive start system, which in this case it would be like x three. One was one of our variables. So like x three, one minus one, x three, two squared minus one. X four, one squared minus one, x four, two squared minus one. This would be our total degree start system. And that this system right there, a start system, has eight solutions. However, our original system only had six.
01:18:31.350 - 01:19:06.254, Speaker A: And so in general, this is the case like, and it's, you know, usually it's much worse than this sometimes. Like, the naive start system is so many, has so many solutions that you can't even track them all. But your actual system that you cared about had so few solutions that if you could somehow just track that many solutions, you would be done in like two minutes or even like 10 seconds.
01:19:06.884 - 01:19:07.708, Speaker D: I see.
01:19:07.836 - 01:19:37.274, Speaker A: And so this is a common situation. And so the answer to this is either don't use such a dumb start system, use something that involves Newton, polytopes and mixed volumes, and get us a better start system. Or another, another method is to embed your system in a family, depending on parameters. So that's where we are sort of here. I see.
01:19:37.394 - 01:19:55.174, Speaker D: So we solve the generic start system in this family, or we start age, we solve there maybe we get six solutions and then we just have to track those six instead of tracking eight or 800,000.
01:19:55.474 - 01:20:35.144, Speaker A: Exactly. So like this is, maybe this will be our naive start system. It has eight solutions. And what we do is in order to, you know, this one time, perhaps difficult computation, we might have to use something like this and to get these six. But then at the end of that computation, we know that, you know, and there's theorems in algebraic geometry that guarantee that all the other polynomials in this family, in this particular family can only have fewer. In other words, we don't need all eight. We don't need to go like that.
01:20:35.144 - 01:21:00.650, Speaker A: We only need to track six and even these six. Because this was a generic parameter, these might end up having four or three. And so in this situation, eight and six isn't such a big difference. But in practical computations the difference is huge, usually because you have more variables and a higher degree. Yeah.
01:21:00.802 - 01:21:02.294, Speaker D: Thank you. This is great.
01:21:03.514 - 01:21:10.254, Speaker A: Yep. So in particular, if you was at 3002, how many conics?
01:21:11.274 - 01:21:13.134, Speaker D: 3364.
01:21:13.434 - 01:21:56.454, Speaker A: Okay. 3264 conics in a second. So if you go to, if you search that in Google, you'll find a website where you can compute the 3264 conics in just under a second. And the reason that this works is because they had already solved a generic system and they store those solutions. And then when you put in your favorite conic or your favorite equation for the conics that are tangent to it, then it will just move those precomputed solutions over to yours and it'll do that in under a second.
01:21:59.554 - 01:22:18.838, Speaker D: That's very cool. And if your situation happened to be one of those very strange singular systems where the number of conics actually drops, then those 3264 conics that they're tracking, some would come together and you'd just get a smaller number.
01:22:19.006 - 01:22:27.262, Speaker A: Yeah, exactly. And that's sort of in our, in our picture again, maybe this, instead of going over here, maybe it would have come here.
01:22:27.398 - 01:22:28.274, Speaker D: Uh huh.
01:22:28.694 - 01:22:55.034, Speaker A: And then you'd basically, you'd note it because when you get close to time zero, you're going to be much more careful and you're going to use those extra floating point numbers near zero and you're going to see that these two paths are coming together and you'll sort of handle it intelligently and you'll only need to do that right at the very end of the computation. All this is easy. All of this is easy.
01:22:58.214 - 01:22:59.834, Speaker D: This is great. Okay.
01:23:00.374 - 01:23:58.614, Speaker A: Okay. So let me just finish the parameter homotopy. We have this family of polynomial systems, one system for each choice of parameter value. And then what are these purple lines? Well, these purple lines then, well, I'll switch to purple, are some path in the parameter space cp. And so what's our homotopy? Well, our homotopy should be from cn cross r to cn, and it should take xt to h of x. Oops, x of t, comma q of t. And so now we just use our original methods on this homotopy, and everything works identically the same.
01:23:58.614 - 01:25:22.104, Speaker A: In other words, differentiate this with respect to time, we get zero. So that means that dh dx x dot plus dh dt equals zero. And so, you know, in this case, where we have n variables, this is an n by n jacobian, this is our unknown column vector, and this is a known, known, what is it? N by one. And so now we're in the same situation we had before, except when we discretize, we'll, you know, the x dot turns to delta x, and we'll solve a linear system, namely this matrix equals minus this vector here on the other side. And basically everything is the same. And in those functions that I wrote, the naive path tracking would literally just change the division to a linear system solve, which in Julia, you could even write with a division symbol, the backslash symbol. So really not much changes.
01:25:22.104 - 01:25:52.564, Speaker A: Okay, and I should mention that this queue, this queue is, you need to specify that in particular it can be a straight line from your generic point to your desired point. It can be just a straight line homotopy. And now finally, I'll get to the gamma issue. Okay, so.
01:25:54.904 - 01:26:14.730, Speaker B: What, yes, so what is known about the complexity of these things? I mean, something like rates of convergence. Let's say you start, have a nice starting system, used your Newton polytopes, etcetera, found that something with the right number of solutions.
01:26:14.922 - 01:26:15.734, Speaker A: Yeah.
01:26:17.114 - 01:26:37.894, Speaker B: And you start tracking, sampling, you know, your pads, using whatever gradient descent or whatever. And how long does it take to get to your system? I mean, what bounds are known, let's say, based on the coefficients of your start versus target system or something.
01:26:38.774 - 01:26:46.394, Speaker A: Okay, so let's see. So first of all, one thing you could inquire about is the number of solutions.
01:26:47.094 - 01:26:47.710, Speaker B: Yeah.
01:26:47.822 - 01:28:16.076, Speaker A: And I think this is essentially you'd have to look at each family of systems, and it would be a theorem to say the generic number of solutions for that family. I think that, for example, like people counting the realizations of Leman graphs over the complex numbers, would be an example of their taking a family of polynomial systems and finding out what is the worst case for the number of complex realizations and so that's sort of one thing that you could do is investigate your family, your specific family of systems. Of course, the total degree, like the bazoo number in general, you'll find systems of polynomials that have all the solutions they could possibly have when you just count by the degrees of the polynomials and multiply them together. But for special families, you can get less. And then it would take work to figure out how much less. And then as far as the path tracking there, I don't know. I don't really have much to say other than I know that numerically solving odes is typically very good because it's a problem that we have to solve a ton for real world problems.
01:28:16.076 - 01:28:28.574, Speaker A: So people have worked on it a lot. And so it's typically in practice it's fast. But I don't know what you can say, you know, precisely. I don't know.
01:28:28.994 - 01:28:42.054, Speaker B: Yeah. I mean, I guess to give a precise answer you sort of have to have an understanding of the bad cases. You know, I would even before counting, I would even go to a much simpler question of find one solution.
01:28:42.874 - 01:28:43.654, Speaker A: Yeah.
01:28:44.714 - 01:29:50.174, Speaker B: And if it exists. And then. Yeah, I was just looking as you were talking. Another question I had was you usually you have a family of inputs which a family of polynomial systems that grow in size and they have some structure, so maybe they have some initial symmetries, and then you just close on the action of that symmetric group by just adding more variables or whatever. So you get this infinite family of polynomial systems and you have some understanding of the solutions for the smaller systems and then you want to sort of preserve the structure. How does the, I mean, can, does the homotopy continuation permit that kind of thing? Or does it somehow destroy the structure of the system or doesn't preserve? If I know answers to smaller systems, can I sort of build on it?
01:29:50.294 - 01:30:36.080, Speaker A: Yes. So that is what the most intelligent use of parameter parameter homotopy can do. In particular, it doesn't have to be a parameter space. That's just c to the p. It can be a parameter space that's a quasi projective algebraic set. What you still have is that you're guaranteed that within that quasi projective algebraic set of parameters there is one single number of expected solutions, and that number is the most it could ever be. For that, you know, it, it will be, the number of solutions will be equal to that number almost everywhere in your set of parameters.
01:30:36.080 - 01:31:35.254, Speaker A: And it can only decrease, and it will decrease only for a sub variety of within your parameter space. And so basically the answer is absolutely. If you set up your system intelligently, then you can move within a space of parameters that has the low number of solutions, and that structure will be preserved. Yeah. Okay. So, yeah, so let me say maybe one more thing about what could go wrong, just very briefly. So obviously, like the, you'll get much more in depth here and also here if you'd like to sign up for this workshop.
01:31:35.254 - 01:32:28.024, Speaker A: But sort of briefly, what could go wrong? Well, here's one thing that can go wrong. Let's say you're doing a parameter homotopy, not from a generic point. This is in CP. This is my picture of c to the p, and you're not going from a generic point to a special point. But what if you're going from a special point to another special point? So the thing that can go wrong will be here. So possible trouble. So, but over here, no trouble.
01:32:28.024 - 01:33:38.864, Speaker A: And so the basic idea is that because within this parameter space, which could also be just a quasi, it could be something more general, like a quasi projective algebraic set. Within that parameter space, the parameter values which would cause issues. So bad parameter values form a set of real codimension two. And so if it's a real codimension two, like here in my cartoon of Cp, I've drawn three axes, so it's a c to the p that has three real dimensions, which obviously does not exist. But for the sake of the cartoon, the bad parameter values form a set of real codimension two. And that would look like a curve. It's a curve of bad parameter values.
01:33:38.864 - 01:35:10.444, Speaker A: And so now you can see that even whatever your special point is, if you take a generic point, the straight line segment between the generic point and the special point, it will not hit this curve, and so you'll be okay. And so this is sort of why parameter homotopy works so well is because of this, the idea that the bad parameter values form a set of real co dimension two, and so you can avoid them. Now, if you take two special parameter values and you try to do a homotopy between, you know, the system of equations corresponding to this parameter value and ending at the system of equations corresponding to the second parameter value there, you might be in trouble, because if you've, you know, if these points have been chosen in some special way, for example, maybe they're all real, that they have coordinates which are all real valued coordinates, then you could possibly be in trouble, because then the bad parameter values form a set of real codimension one. And so that would be like a bad point on your line segment. And so in order to deal with that, what you can do is, is very simple. I mean, here's a very simple thing you can do. Let's say you want to go from special to special, okay? We'll just choose a generic.
01:35:10.444 - 01:36:02.562, Speaker A: Go to the generic and then go there. And so this would be, I'd call this like a two step, and this will avoid the bad parameter. So it's very easy to avoid the other example or the other way that people usually do this. And this is finally, finally, answering Will's question about the gamma trick is they introduce. So, okay, so it's easiest to see when we're just in the simple situation of going from t equals one to t equals zero with our original homotopies h of x t. Um, you know, you could just go like this. And that's what we were doing when we defined tg plus one minus t f.
01:36:02.562 - 01:36:35.234, Speaker A: We were just following this, this straight line from t equals one to t equals zero, sort of in the space of, what did we start? T is one g def. So if this parameter value corresponds to the system g, this parameter corresponds to the system f. But as I said, real codimension one. That means there could be a problematic point. So it would be better is to sort of just go around it. And this is that factor gamma. It essentially reparametrizes a curve.
01:36:35.234 - 01:37:19.354, Speaker A: You have a one dimensional real curve inside of your parameter space, which is just c to the one for this very simple homotopy. And you just have it go and explore some part of the complex plane, and you still start at t equals one, and you end at t equals zero, and you just throw in a gamma. And. Okay, what's this gamma? So usually gamma is, like I said, you don't have to do this. You could just do a step and then do another step. But usually gamma is chosen from the, the unit circle or the unitary one dimensional grid is. It's a complex number of norm one.
01:37:19.354 - 01:38:00.224, Speaker A: And this little trick avoids the bad parameter values almost always. Yeah. So this was basically to answer Will's question about what is the gamma trick? Well, it's a way to avoid the real co dimension, one parameter, bad parameters, because if you use complex space, then it'll be real codimension two. And so sort of any loop in the parameter space will avoid it. Okay. Are there any questions about this? I'm not sure. I did such a great job there.
01:38:01.004 - 01:38:36.264, Speaker D: You explained the mechanism. But I, I still would like to know a little bit more about what, what actually is going wrong in the, in the kind of sketch outline, is it that the system that we're trying to solve when we're doing a Newton step could be, it could be a singular system or, you know, like, what is what really? What kind of things go wrong when you have a bad parameter and you're tracing along the path?
01:38:36.424 - 01:38:44.824, Speaker A: Yeah. Okay, so in this cartoon, like, every point corresponds to a system of polynomials.
01:38:44.984 - 01:38:45.664, Speaker D: Right.
01:38:45.824 - 01:39:50.794, Speaker A: So this g was chosen by us to be easy, and this f was what we originally wanted to solve. So f might be a bad system, it might have non singular solutions, but that doesn't matter, because if we choose this pink path at every single point, we get some other system, some other polynomial, namely, plug in the value for t here, and we get some polynomial h of x. And the claim is that all the solutions to h of x equals zero will be non singular. And if we plug in a different value of t, say right there, we're going to get a different h of x. And again, all of its solutions will be nonsingular. And so that's what we want. We want that at every single moment of time, the system h of x t is as nice as possible, every solution nonsingular, so that our Newton corrections work, our Euler step works.
01:39:50.794 - 01:39:58.934, Speaker A: Our DHDX Jacobian matrix is full rank. It's not badly conditioned.
01:40:00.314 - 01:40:02.770, Speaker D: These are all the kind of things that could go wrong.
01:40:02.882 - 01:40:03.654, Speaker A: Exactly.
01:40:04.314 - 01:40:05.334, Speaker D: Okay, good.
01:40:05.634 - 01:40:52.684, Speaker A: And so that's it. Sort of as long as you take sort of a random path through parameter space, then all your intermediate systems will be as nice as possible, and only, only at the very end, near t equals zero, will you approach your system, which is no guarantees that it has a non singular right. Some of its solutions might be singular solutions. And so some of the paths might, you know, as you evaluate the jacobian matrix nearer and nearer and nearer to f, this matrix is going to get worse and worse conditioned. And, you know, sort of, only at the very end will you have to be more careful. Let me see. Okay, this is great.
01:40:52.684 - 01:41:48.854, Speaker A: And I mean, the wonderful thing is that people have already been careful. And so all you need to do is just sort of go to hometopic continuation Julia website and look at their examples. And you'll find many, many, you know, you'll find applications that you wouldn't have thought of first of all. And you'll also find that most of the time, you simply call this solve function. And that's it. But I mean, honestly, for me, the most difficult part of using the software is just setting up the system of equations, which just literally means like writing down the polynomials, right? And so that's the most difficult part. If you can manage to write down the polynomials, then homotopy continuation will give you all the solutions pretty easily, just with this little solve function.
01:41:49.754 - 01:41:50.894, Speaker D: That's awesome.
01:41:53.194 - 01:42:25.710, Speaker A: Yeah. Okay, so today, my plan. Okay, good. I've got roughly half of the things done, and that's good, because I think that was all they got done in the first day. Yeah, parameter homotopies. So we've attempted to cover one day of the workshop. So obviously you'll get a better understanding if you attend this workshop now on Thursday, I might talk about some of these things.
01:42:25.710 - 01:42:58.708, Speaker A: And so let me give you a little preview. Monodromy is a really clever thing that will help to solve systems. All you need is you just need one solution and monodromy will perhaps be able to find all the other solutions for you to your system. And you don't even need to compute a start system. So this is pretty interesting. We'll talk about that. Everything we've been doing so far has spin square systems.
01:42:58.708 - 01:43:37.078, Speaker A: But what if you have not f from cn to cn. So n equations and unknowns. But what if you have more equations? Can you still do it? And the answer is yes, you can. And I'll explain that. Witness sets and numerical irreducible decomposition has to do with when you have n equations and, say, only n minus five, or, sorry, n variables and less equations. And so in general, you'd. The complex algebraic variety will have positive dimension.
01:43:37.078 - 01:44:18.164, Speaker A: It might be a curve, which we've already seen. It might be a surface or a threefold or something like this. And it turns out that you can handle this as well. And in fact, you can get the analog of the irreducible decomposition of an algebraic variety in the numerical setting. And it's still quite powerful. It can help you decompose your solutions into different pieces in each dimension and say, the degrees of each piece, and test membership. You can even start taking things and intersecting them and start doing intersection theory numerically.
01:44:18.164 - 01:44:29.812, Speaker A: And. Yeah, so that'll be my plan, sort of next week or, sorry, next two days. Okay.
01:44:29.868 - 01:44:30.464, Speaker C: Question.
01:44:31.004 - 01:44:32.144, Speaker A: Yes, go ahead.
01:44:32.844 - 01:44:42.144, Speaker C: In your HT straight line, before the gamma, it looks like some kind of convex combination.
01:44:43.004 - 01:44:46.128, Speaker A: It is. It is a convex, yes.
01:44:46.176 - 01:44:53.284, Speaker C: And the reason I'm asking that it is then very conducive to optimization.
01:44:55.064 - 01:44:59.192, Speaker A: So you're not trying to optimize over this convex set?
01:44:59.328 - 01:45:06.964, Speaker C: No, I'm referring to item 13 that you have in the plan optimization.
01:45:07.304 - 01:45:08.040, Speaker A: Yeah.
01:45:08.192 - 01:45:09.644, Speaker C: Is there any connection?
01:45:11.924 - 01:46:01.574, Speaker A: So yeah, I was maybe going to talk about how you could use these methods to solve optimization problems, and if that's something people are interested in, I can talk about that. However, we wouldn't be optimizing over the solution path. So in particular, that straight line homotopy between GnF, the only. Actually that is a bad homotopy. A non convex homotopy is better. It will be, you know, that's sort of the gamma function trick. So the only reason that I wrote down a convex set homotopy is because it's simpler for a human mind, but actually a non convex homotopy would be, you know, numerically better, because it's going to avoid the bad parameters.
01:46:02.394 - 01:46:40.594, Speaker C: Okay, back to the puzzle. Yes, it looks like the crossing was not allowed. However, later on, when you went few steps much further during the talk, you, the path, were happy to cross to meet. So it looks like something sort of anti symmetry in terms of crossing and non crossing.
01:46:40.714 - 01:46:42.882, Speaker A: Sure, I can comment inside.
01:46:42.938 - 01:46:46.754, Speaker C: I am not allowed outside. I am welcome to quote.
01:46:46.914 - 01:47:30.892, Speaker A: Yeah, I'm sorry, I sort of, I just really like this puzzle, but maybe it was more confusing. It's really not a literal analogy. It's just the idea of homotopy to simpler thing and come back and over here, like the paths can cross because they'll be crossing at different times. What would be a problem is if two paths happen to cross like the same point at the same time. But that won't happen if we choose our homotopy sort of generically. And so this sort of a crossing issue with path tracking. Okay, yeah, it basically won't happen if you set things up correctly.
01:47:30.988 - 01:48:05.400, Speaker C: Now back to your demo. Yes, it's similar picture, but in the demo you had two different ways to do things. First, look very. The upper one and the lower one path were very symmetrical. But when you played further step, if you still follow me, all this symmetry disappeared. Yeah, I think you had two major paths and then two smaller paths.
01:48:05.592 - 01:48:14.564, Speaker A: If I. Yeah, so maybe I should have. Basically, I chose the, the example symmetrically. Like the roots were complex conjugates of each other.
01:48:14.864 - 01:48:16.502, Speaker C: Okay, okay, fine.
01:48:16.648 - 01:48:21.754, Speaker A: If I had chosen a different example, the path wouldn't have looked, of course, clear.
01:48:21.834 - 01:48:22.494, Speaker C: Thanks.
01:48:23.514 - 01:49:02.314, Speaker A: Okay, now, thanks for the questions. So I have another question. So your solution pass converges to a singular point. So it is converge slower than the, than, say, a normal point, right? Yeah. Within this realm, you won't, you won't just use Newton, uh, Newton's method to correct, you'll use more advanced things. And so, like these are called end games. There's a whole chapter in.
01:49:02.314 - 01:49:27.992, Speaker A: In this book on end games. So if you knew Newton, then they converge very slow. Right? Yeah. I mean, it might still converge linearly or it might diverge, but the point is that you won't use a sort of naive Newton thing. Like the thing that I did in the code today was not what you would do. Yeah. Yeah.
01:49:27.992 - 01:49:53.848, Speaker A: Because I guess you have the singular point, so you have a condition, number is higher. If you perturb it, then it will affect the single number more than the normal point. There's some interesting things that you can do at singular points, like there's something called deflation. Yeah. Let's say the Jacobian has a null space. I don't know. This is my picture of a null space for chat.
01:49:53.848 - 01:50:26.356, Speaker A: This doesn't make any sense. But let's say it has a null space. Then you can add some, like some more linear equations, and you'll get a system that has more variables and is better, is full rank. And so the thing to look up is deflation, and you'll find it in that book again. Okay. Yeah. My feeling is that if you have a singular point, then.
01:50:26.356 - 01:50:40.876, Speaker A: Then it basically is hopeless. Right. It's. Yeah, that would be my impression as well. But in fact, it's. It's hopeful. Okay.
01:50:40.876 - 01:51:03.464, Speaker A: Yeah. Harder is if you start with a singular point. I've. This has happened in problems that I've tried to work with where I have a solution, but that solution is singular. And there. I think we need some new ideas in order to handle it because there's no way to sort of get started if you have a singular point.

00:00:01.400 - 00:00:57.100, Speaker A: Welcome back everybody. And, sorry, let me correct the sound. Okay, so welcome back. And today I wanted to start our discussion with, while continuing discussing radial SLE model. As we already discussed last time, this is a version of SLE which is more related to classical evolution the way we discussed it. And it describes a random curve going from some point of the boundary to a point inside. And the main thing which we want to prove about this is that essentially you can describe this in terms of chordal evolution in the following sense.
00:00:57.100 - 00:01:38.644, Speaker A: So let me specifically state the theorem. So, theorem is the following. So suppose that you have two boundary prime ends and the point inside, and you run radial sla kappa from a to c. And on the other hand, you also run cordially carpival from a to b. And what the theorem says that essentially they are kind of sort of the same. So of course they favor different curves, but the types of the curves they pick are the same. So let me be very precise here.
00:01:38.644 - 00:02:22.474, Speaker A: So suppose that we run this slicappa up to the first moment when it really cannot have anything to do with b, the first moment when you hit b. So you run it until you hit b. So let me just remark that for Kappa less or equal than four, it means that you run it just forever and the same. You do this quarterly solar kappa. You run it until the first moment you hit c. And then of course the curves are supposed to be different. And again, notice that since four kappa less or equal than four, the probability that you ever hit c is zero.
00:02:22.474 - 00:03:25.400, Speaker A: The probability that you hit any fixed point by Kappa when Kappa less equal than four is just zero. This t tilde is infinite for kappa less or equal than four, for Kappa bigger than four. Of course, this is a non trivial time. And then you look at these two curves. So this curve is run till you hit b, this curve run till you hit c. And it turns out that they are very similar in the following sense, that you can select increasing sequence of stopping times, this stopping time converging, so radial stopping time, t and convergence, global stopping time for radial oscillate, the same with chordal t until the converges to t tilde, such that if you look at these two curves, they have essentially the same law. Again, not, not exactly the same.
00:03:25.400 - 00:03:59.106, Speaker A: They have laws which are absolutely continuous. But in particular, it means that, for example, we know that this is a curve. So we know that this is a curve. See, I even keep when I formulate theorem. I talked about curve, but I shouldn't have. I should have said, well, Hal, generated by radial evolution and Hal generated by chordal, they have the same law. Well, not quite the same, absolutely continuous with respect to each other.
00:03:59.106 - 00:04:45.374, Speaker A: In particular, since this is almost surely generated by curves. This is almost surely generated by curves. So what this means is the following, essentially that if something is almost surely true for this, then the same thing would almost surely be true for here. So let me contrast it with another thing. If something is true for average, for Cordelia evolution, that doesn't necessarily hold here, because the laws are just absolutely continuous. So expectations would be different. But again, almost surely properties would be the same.
00:04:45.374 - 00:05:29.684, Speaker A: And what we started doing last time, and almost finished. So it will be a quick discussion today, is that we looked only in the case kappa equal to six, when the laws are actually the same. Up to this heating times t and t tilde. Okay, so remember also last time we discussed that Kappa equal to six is extremely special. It has this great locality property, which means that essentially it doesn't matter for the curve where you want it to end. You start the curve and you run it till certain stopping time. It's the same way you want it to end it.
00:05:29.684 - 00:06:19.254, Speaker A: So what I'm proving now is that actually it doesn't matter whether you run it as a chordal curve to the, one of the points of the boundary, or whether you run it to a point inside. Do the same thing. Okay. And so what we did last time was we noticed that it's enough to do everything in the situation when you are in a disk and as usual, point inside would be zero. And then you pick two points on the boundary. It's actually convenient to pick a, not to be one, the endpoint would be one, but the point, the starting point would be some point Ei theta, which of course depends on the original configuration. So you just have to prove this.
00:06:19.254 - 00:07:14.574, Speaker A: And to simplify things, again, it's easy to define radial levinor chain here. It's difficult to define chordal chain here. So for this, we map it, we map the whole picture to the half plane, and that what would help us, that one is mapped to infinity. So which means that the endpoint of corresponding chordal l chain would be infinite. And we just look at 1D brownian motion, which would run cordlessly. Well, this would be just brownian motion. We should start at the image of this point.
00:07:14.574 - 00:07:57.294, Speaker A: That's why it's Phi of a theta. And then we described cordlessly Kappa indie from Ei theta to one. Well, that's the equation that we would get. And notice that we need maps from d to disks to half plane. And then we described radius, let's say Kappa. So this is just the standard equation, but you are supposed to start. So that's why this rotation.
00:07:57.294 - 00:08:53.992, Speaker A: And if we write et is gt of one and then ht is this image under psi and mu t is the image of this. Well here I made a mistake, which I still haven't corrected. So let me correct it now. So this is of course e to the I b t over here. So this would be our muti. So what would happen here? So first you take this picture, you apply gt divided by et here to map this, here to map this point. So the tip under this map is mapped to this point b of Kappa t over et.
00:08:53.992 - 00:09:58.478, Speaker A: And then by psi it's map to this meteor. And the reason is that we wanted driving function for this. And so this would be our mity. Okay, then we can just take Leo equation and rewrite it here. So we just plug this in here, do the computations, and surprise, surprise, we get this. Okay, so now we have two objects, this guy and then this guy. So now they are both defining maps from outside of the curve to the upper half plane looks very different, but how would you see that they actually the same in law? So here we start with doing a linear transformation.
00:09:58.478 - 00:10:44.710, Speaker A: So this looks like a trick, but actually if you just try to do, to prove this thing, this would be very natural. So let's do this linear transformations, which satisfies the following equation. So we do linear transformational planning to itself, which is just a solution of this. So a of t, you start with one, and then it satisfies this exciting od. And then you also need to shift. And shift would satisfy this. So initially you just start with z, you don't move.
00:10:44.710 - 00:11:33.904, Speaker A: But then this time t, you want to start moving things around. Okay, and now let us define mt of z to be the composition of this shift. It's very interesting. Shift. So what, what it does, it specifically made it so that after this shift you would, your equation would resemble this. Okay, so mt would be yt of h t and b t, remember? Well, it's probably not very difficult to keep track, but mute was the image of the tip. Now on the new think empty battery is the image of the tip.
00:11:33.904 - 00:12:15.764, Speaker A: And then you plug in all of this in here, and you remember what the coefficients are here. And after the dust settles, this looks much, much better. Notice that ht just disappeared from here. That was the whole reason for this transformation. And what you are left with is this thing. And now how do you get rid of one plus muti here and then there is a two. So, well, you just change time.
00:12:15.764 - 00:13:24.484, Speaker A: So in u, time would satisfy this condition that it's one plus mu, t squared, a squared over u. And so after all the dust settles in this new time, look what happened. This look like chordal Sla. So this is amazing because remember we started this things which did not resemble chordal slates radial sla. But after we did some transformations and time changed, we exactly arrived to a cordial slice. So now the question is, well, this is all coated. Well, but this cordless le is driven by what? And that's where things would become different for different kappa.
00:13:24.484 - 00:14:12.254, Speaker A: So here, notice that up to this point, all I did was for all kappa, not only for kappa equal to six, but here finally kappa equals to six. Start playing a role and then I'll briefly explain what happens for other. Okay, so we want to find bit of here. So, well, again here I skip a lot of computations, but I still want to show you the result. So first you look at mu. You probably already forgot what mu is. So let me remind you that this is this guy.
00:14:12.254 - 00:15:22.484, Speaker A: And then you do eta computation. And you notice that Dmut satisfies this horrible sD. So this, well, let me not call it SD here, it just satisfies the following relations that it's the martingale factor is one plus meter squared over two square root of kappa. But then you also have this drift term. And what would happen here is that the drift term would die for very specific things. Again, now we are not working with mu, they are working with mu t. So, okay, so remember that beta t is phi t of mu t, which is just remember, what is phi t just a of t times mu t plus b of t, where all of them satisfy these equations which was specifically selected just to kill this ugly factor of one plus muti squared.
00:15:22.484 - 00:16:26.784, Speaker A: And indeed, what happens here is the following, that this becomes one plus gamma t squared t over two square root of kappa, dbt plus kappa over two minus three gamma t dt. Okay, so now very important things happen. Looks here, this is exactly the time change. Okay, this looks like you, it's actually four. So this is exactly the time change you did here to get rid of everything. So in when kappa equal to six, what happens? This term is dead. And after the time change, this whole thing become square root of six times dbu.
00:16:26.784 - 00:17:24.764, Speaker A: So beta of u is driven. It has the same law as brownian motion ran this time with speed six, so square root of six times db and that's it. Okay, so that's what happens for kappa equals to four. Now unfortunately for kappa not equal, sorry, when kappa equal to six, when this guy is dead. But what happens when kappa is not equal to six? Then you do have a drift. And then you have to be much more careful. You have to use Cameron Martin theorem to say that this driving force would still be absolutely continuous with respect to brownian motion.
00:17:24.764 - 00:18:28.656, Speaker A: So if the law of something is absolutely continuous, so let's be very careful, then the law of the resulting curves would also be absolutely continuous. But again, there is a gamma t factor here, which would lead us to start stopping this brownian motion before things collapse. And that's why there are the starting time. Otherwise you cannot use Cameron Martin. But again, this discussion of course is all irrelevant if you know what Cameron Martin theorem is, and I didn't cover it in this course. So the proof that I gave is only for kappa equals to six, but for the kappa, again, you should see the flavor that is just one. There is a drift which would lead to change of the law.
00:18:28.656 - 00:19:05.484, Speaker A: The law is different, but absolutely continue. So who cares? Still the same thing. But of course it leads to lots of complications. So for example, one of the things which is possible to compute is average dimension, and things like that, average multifractal spectrum. For one of these objects, the fact that they are just absolutely continuous means that this computation doesn't give you anything. For the other, you need an almost sure result. You need almost show results which are much, much more complicated.
00:19:05.484 - 00:20:15.834, Speaker A: With this, we finish for now, look at the geometric properties of silica, and let's try to remember why we wanted to introduce silica the first place. They were conjectured by Adet Schramm to be scaling limits of certain objects in mathematical physics and probability. And let me try to explain to you how to prove such things. So what we did in the introduction so far was for certain objects, we were able to say, okay, we have glimpses of conformal invariants. There. We have conformal invariant absorbers like fermionic absorbable for easing model, like Cardi Smirnov absorbable for critical percolation. But I claim that having one observable is enough.
00:20:15.834 - 00:21:25.224, Speaker A: This immediately leads to convergence, to sl of interfaces, to corresponding curves. Is a radial or cordial or maybe some other version? Depends on what you have. Now, this is a very bold claim, which is of course incorrect. There are lots of extra conditions, lots of extra properties of the models, which we need to check. But what I want to talk about next is the framework which needs to be checked and the results which can be obtained this way. So we first start with looking at the question of, well, how in general to establish such convergence without looking at examples. So again, what I want, I have a family of random curves which come from some model of statistical physics or somewhere, and I want to show that it converges to SLA.
00:21:25.224 - 00:22:19.820, Speaker A: All I know is that it has something which is conformal invariant, some conformal invariant property. And that should give me everything that should give me this convergence. So let me first carefully explain what it is we want to prove and how exactly we want to prove it. So the setup here would be the, you start with a simply connected domain, and you have two boundary primates. So this is a setup for cordal SLA convergence. Radial sla would be point on the boundary point inside. So again, for some reason this course, I am stuck with cordless Sla.
00:22:19.820 - 00:22:45.328, Speaker A: So let's continue here with code. First, we need a metric on curves. Remember, random curve is a measure on curves. So measures would converge weakly. You need some metric space, you need some metric structure. And this metric is the following. So I want ab to be prime ends.
00:22:45.328 - 00:23:56.040, Speaker A: So I need to use caratha dot de distance. So let me remind you that if you have a domain and you have two points and you have some fixed point w naught, then crossado redistance between these points is the diameter of shortest loop or crosscut, which separates a and b from w naught. So here, cursor resistance is just, well, distance between them. But say if I consider. So if I add something like this and I look at two points here, a and b, they are quite far away. But Crethadori distance between them is small because this is the shortest crosscut, which would separate them from w naught. Again, the reason I introduce this, because, remember, the boundary of simply connected domains, all ugly things could happen.
00:23:56.040 - 00:25:07.402, Speaker A: And I just don't want ugliness of a and b to affect anything. So here we look at crescentory distance, but crescendo distance between what you look at supremum distance between these two curves, gamma one of t and gamma two of t. Well, maybe they are far away because you incorrectly parameterize them. Remember, you really, really want to choose correct parameterization. And so we take infinum over all parameterizations of gamma one and gamma two of these supreme distances. Okay, now let me remark that for locally connected domains, you don't really need crossed or distance. This notion is equivalent to just uniform distance in the normal euclidean distance between them.
00:25:07.402 - 00:25:44.960, Speaker A: But this is not much of a difference. Again, for simply connected domains, it might be, sorry. For locally connected domains, it might be easier to walk or think about this for non locally connected domains. For general domains, that would be your friend. Okay, so this is uniform distance. Let me immediately explain why it's different from another very popular distance, which is more general. So this is Hausdorff distance.
00:25:44.960 - 00:26:13.234, Speaker A: This is distance between two compact sides. And this is the following. So you look first at all points in k one and look at the distance from them to k two. And then you look at points in k two and look at distance from them to k one. And you take the maximum of the supreme forces. So to be housed or close, well, this is a really strong condition. So let me draw a standard motivational picture.
00:26:13.234 - 00:27:09.294, Speaker A: So this and this are very close to each other, because for each point here, there is a close point here. So for each point here, there is a close point here. For each point here, there is a close point here. At the moment, I add a smile here to the second set and it stays, stay, smile, smile, stays there far away. So this is again extremely popular distance in metric geometry. And this is the right distance, but not for our problem. Our distance, the supreme distance is stronger, it's actually larger.
00:27:09.294 - 00:27:55.294, Speaker A: And let me give you an example. So these two curves here, gamma one and gamma two, let's look at them carefully. In house of distance, they are very close. For every point here, there is a close point here. For every point here, there is a close point here, very close curves, but you cannot parameterize them so that they are closed uniformly, because on this curve you just cannot go back and you need to go back here. So these two curves are very close in Hausdorff distance, but not in the supreme distance that we defined. Okay, so the right distance for us is this uniform of supreme distance between the curves.
00:27:55.294 - 00:29:00.058, Speaker A: It kind of doesn't care about parameterization, but it does care about how you traverse the curve. So another classical thing is that a curve which would travel around so called ones would be very far in uniform distance from curves which travels around circled twice or close to it. But they would be of course essentially the same in house of Matrix. Okay, so let's, with this introduction, let us continue our discussion. So we are usually given a random curve, let's call it the gamma delta, and then delta would go to zero. So this would be probability measurement curves, usually on curves from which join these two prime ends. Usually they come from some lightest.
00:29:00.058 - 00:29:53.204, Speaker A: Remember, we started with looking at lattice models. So if you have a lightest of size delta. You run your model, it generates this random curve somehow, and you want to see, well, okay, how do you prove that it converges to slicata? The first order of business is to show tightness. So pre compactness is the weak stack convergence of measures. What do I mean by this? Well, this is all probability measures. Every probability measure, every sequence of probability measures has weakly convergent subsequent sets. Our standard results from functional analysis Bangaloglo theorem.
00:29:53.204 - 00:30:45.622, Speaker A: But maybe I don't like this limit, because maybe it would live on something ugly. So this precompactness is not a trivial state. You actually need some a priori property which all of this gamma delta would be satisfied. And this is given by Isiman Barchart framework, which we will discuss in a moment. But suppose that you have the titans. Suppose that every sequence of gamma deltas has a subsequence which converge weakly to some gamma. Then life is easy.
00:30:45.622 - 00:31:43.956, Speaker A: All you have to prove is you have to prove that gamma is distributed like slicappa. So every subsequent limit is distributed like s o kappa. Okay, so what is this tightness I am alluding to? This is there is famous procurev theorem which says that family of probability measures is pre compact. If for every epsilon you can find compact a in the space of curves, such that for every delta probability that gamma delta belongs to, this compact is bigger than one minus epsilon. Because the space of curves is not compact, you can compactify it. And that's what I alluded to. And then by Banjalogu theorem, of course it converges.
00:31:43.956 - 00:32:31.380, Speaker A: But prochretherium says, well, not so fast. If you want your limit to be really living on curves and not on some ugly objects from your compensification space of curves, then you bet off proving something like this. So you need a priori estimate that in some compact set in the space of curves, all of them would belong with large probability. And the probability can be made arbitrary close to one. This is an if and only if criterion for pre compactness. And this is theorem due to Uri Procrov. I will not prove it as well.
00:32:31.380 - 00:33:05.808, Speaker A: It's actually not that complicated. Okay, but this is unfortunately not everything. This curves gamma delta, which you get usually. Usually they are just simple curves. But as we saw, even in the case that we love, even in the case of sla kappa, the limiting curves can be non simple. They can be self touching with space filling. Can you even describe this curves by the equation? That's question number two.
00:33:05.808 - 00:33:41.816, Speaker A: You want this limit to be supported only on Leovner curves. And what I mean by this is the. I really dislike situations like this. You start with the curve, it touches itself, but then it keeps just touching, it keeps following itself. So what happens here? Remember we looked at this compact house growing. They should be monitoring, growing, strictly growing. Here, there is no growth, there is no change in half plane capacity, if you wish, when you go here.
00:33:41.816 - 00:34:17.704, Speaker A: So we really hate this. This is even worse. And that you can imagine how it could happen for some models, that, again, is this too, right? So the curves just get closer and close together, and finally they collapse. But here, this is a bottleneck. So you go here, you attach itself, then the curve goes inside, does something, and return in the time when the curve is inside. Conformal map. Remember, we, looking at the conformal map from outside of the coffee, just doesn't see this part.
00:34:17.704 - 00:35:13.262, Speaker A: So this is something we really, really want to avoid. Okay. So that's another thing that we want to prove, is that not only it's tight in this sense, we want to prove that the limit is also supported on Leonard curve. And for this also, there is an axiomytic framework, which is due to campaigning in Smirnov and I will talk about it in a moment. Okay, so now, step three would be the following. And you want to show now, so you have this partial limit. You know, it's supported on the curve.
00:35:13.262 - 00:35:49.194, Speaker A: What is the driving function? You look at the driving function, lambda delta of gamma delta. It's again random function. And you want to show that it converges to b of capacity. How do you do it? Well, one of the methods which you do, you consider asymptotic expansion of absorbable atom fit. And I will show you exactly how it's done. Or you might consider asymptotic expansion at another point. Again, not a problem.
00:35:49.194 - 00:36:25.882, Speaker A: You can do this. And again, I will show a bit later how it's done. But you see, the moment you did this, you are done because this is a subsequential limit. You know that it lives on curves. And what is the driving function of this curves? Well, that's brownian motion. Run with pit kappa. So this subsequential limit is slic kappa.
00:36:25.882 - 00:37:33.784, Speaker A: And again, by tightness, now we know that the limit of the whole sequence, now of the whole delta, when delta goes to zero, it's not even a sequence. The limit is just a select kappa, just by taking this, because any subsequential limit is a select kappa. So this is kind of not constructive. And later today, next time, we would want to see, okay, what about rates of convergence? And there you need to be slightly more constructive. And another approach which also gives rate of convergence is the following. You start like in part three by showing that lambda delta of t is about b of kappa t for small delta, and in fact that they converge in probability to this b of kappa t or in law or they can be coupled to conversion probability. So this all the same thing.
00:37:33.784 - 00:38:56.568, Speaker A: And then you say, okay, you just know the driving functions can be obvious. How do you show that the limiting curves are actually SLA curves? Because in general convergence of driving functions does not imply convergence of interfaces. Okay, you can, you need additional properties, you need some, a priori properties of this curves gamma delta and you use them to show that actually your, so here is a fine point, your gamma of delta defined in the domain. You map them to model domain to disk or half plane, and in the model domain you use the properties of curves in the original domain to show that convergence of driving functions implies convergence to isola kappa. And here you can kind of, if you know rate of convergence here, you kind of would know rate of convergence here. And then if you are like, you can promote it to the convergence of interfaces in the domain. Again, when I say if you are lucky, this is only true to the rate of convergence.
00:38:56.568 - 00:39:56.984, Speaker A: Convergence here is obvious because remember, you just can make phi inverse here. Here you arrive to gamma of delta. Here by definition you arrive to slica in the domain. So part three is actually usually very easy. There are some kinks which can run, but in general that the idea that this is an easy part. So this approach in relies on subsequent improvement of the rate of convergence of the, sorry, of the mode of convergence. So you start with just converging driving functions and then using maybe axiomatic framework, maybe something else, you show that actually it implies conversion of interfaces first in model domain and then in the actual domain which you're looking at.
00:39:56.984 - 00:41:12.694, Speaker A: So that's how this all works. And again, let me emphasize this point. There is an example in companion book, which is a textbook for this course. I didn't want to reproduce it here. It's technical and lots of pictures, but basically it's relatively easy to construct a sequence of driving functions, lambda n, which converge to some driving function lambda of t, but corresponding curves would not converge, so gamma n would not converge to gamma of t. Okay, so again, in general this is not true, but as we will show later, it's true with some a priori regularity. So if you know something about your curve gamma n and about your curve gamma, maybe there will be framework for this, then there would be conversions.
00:41:12.694 - 00:42:14.482, Speaker A: Okay, so now I want to first talk about this tightness. And there is a beautiful geometric construction there, which is different on leaf. So there is geometric conditional curves, which makes them tight in this sense. And this framework is due to Michael Eisenman, who is in Princeton, Talmud Burchard, who is actually here at University of Toronto. And this is a really beautiful framework, simple and beautiful. So let's start this definition. What could make a curve non convergent? So what it is you should control to make a curve convergence? Well, one thing you would say we all know.
00:42:14.482 - 00:42:54.134, Speaker A: So curves are just continuous functions. So why don't you make them just uniformly continuous and user tell us color, they all defined in bounded domains, bounded in spherical matrix. Not should not be a problem. But the concern is that, remember we are doing things up to reprimand. How do you do uniform continuity up to reprimandarization. And here comes this notion of tortoises. Okay, so for now our curves will be parameterized by zero one.
00:42:54.134 - 00:43:52.334, Speaker A: So this is a curve. And let's pick a delta bigger than zero. And let us define some independent parameterization, independent quantity, which is called tortoise of this curve, or delta turtuosity of this curve is the following. You look at minimum number of curve points. You can partition this curve by such that diameter of every side of the partition is less or equal than delta. So you partition the curve in the segments of small diameter. And obviously this does not depend on parameterization, this just depends on curve.
00:43:52.334 - 00:44:37.494, Speaker A: And this I would want to be controlled in our settings. Again, let me remark that instead of diameter, you need to replace it by cursor diameter. But don't think about it too much. Definitions, object doesn't change. All of this can be defined in arbitrary metric space, including our domain with carthage metric. So now let's look at another tortosity measure. And the reason which I would want to consider is the following.
00:44:37.494 - 00:45:29.774, Speaker A: I would want to count to a limit, and since this is minimum of something, there is only one sided continuity. So I want to also describe the same tortosity as a maximum of something. It wouldn't be exactly the same object, but what you will see that what we would be interested in is the rate of decay when delta goes to zero. So this other tortoise measure is the following. You look at the maximum number of points that you can fit on the curve, such that the consequent one are at least delta from one another. So you see, this is very similar thing. So here you cover by sets of small diameter.
00:45:29.774 - 00:46:44.814, Speaker A: Here you look at the points which are consistently consequently far away from each other. And of course, if you look at m of gamma, delta minus epsilon, so slightly smaller things, then this is bigger equal than this m tilde. Because if you manage to pick this, well, if you manage to pick this number of points, you can, you need at least, you cannot cover two of them by one guy. So this is less or equal than this. And then you take infinum, overall epsilon. So essentially one side inequality is easier. But another direction is also easy, because if you manage to cover things by diameter, by things of diameter four delta, well, at least one point inside would be a distance at least delta from one of the insects.
00:46:44.814 - 00:47:56.276, Speaker A: So that's why you have this inequality. And then the thing is the following. If gamma n converges to gamma and convergence is in our metric, in supreme distance metric, then you have limits of m of gamma, and delta is at least m of gamma delta of this neutral toast, on the other hand, is less or equal than this m tilde of gamma delta. So basically the rates of decay, if you know them for curse gamma n, you know them for curse gamma. And let me again quickly go through the proof. So, as I said, first, inequality here is because every segment of diameter for delta contains a point distance which is at least delta from both sides. Okay? You have diameter for delta, there is a point which is at least distance delta.
00:47:56.276 - 00:48:25.884, Speaker A: So you can just, at each segment you insert a point and then you also add ends of segments to get this number of points which are far away from each other. So notice that we don't want the points like gamma two to be far away from gamma five. They can be essentially the same point. I don't care. Gamma two need to be far from gamma three and gamma one. That's very important. Fine point.
00:48:25.884 - 00:49:22.576, Speaker A: And again, this inequality holds that because if diameter of a segment is less than delta, it cannot have two points as the distance bigger equals than delta, of course. And then continuity, as I mentioned, this is lie means because m is defined as minimum of something. And when you have this convergence, you know, corresponding diameters would converge also. So if the diameters everywhere were less than delta, then in the limit, they would be less than delta. And the same here, if the distances were big or equal than delta, then would stay bigger equals than delta. So careful consideration, of course requires passing to the convergent subsequences. Not very interesting.
00:49:22.576 - 00:50:24.424, Speaker A: Just standard exercise. Okay, so now we are ready to state the next area, which we will prove after the break already. So we want to show that uniform tortuosity is the same as uniform continuity, but uniform continuity up to repairametrization. That's the beauty of it. So suppose that you have a strictly increasing function, and suppose that gamma has a parameterization gamma of t, which satisfies this uniform continuity thing. So psi of gamma of t one minus gamma of t two is always bounded by t one minus t two, at least when gamma of t one gamma of t two are by itself close to each other. And then we claim that tortuosity is also bounded by one over psi of delta.
00:50:24.424 - 00:51:06.344, Speaker A: And by this I mean the smallest integer which is larger or equal than this. And on the other hand, if you have a bounded tortosity, well, you would want to say that this holds not quite. You can find the parameterization gamma. So this is the keyword, remember? So tortoises did not depend on the parameterization. This also does not depend on parameterization. So you can find the parameterization gamma which satisfies this condition, which we will talk about after the break. So I'm already over time, so let's take a nine minute break.

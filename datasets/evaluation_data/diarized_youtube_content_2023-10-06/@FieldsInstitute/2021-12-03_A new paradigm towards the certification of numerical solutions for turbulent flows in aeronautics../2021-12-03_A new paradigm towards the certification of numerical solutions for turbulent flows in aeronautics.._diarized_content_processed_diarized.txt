00:00:00.120 - 00:00:45.050, Speaker A: Thank you, Yves, for the introduction. Okay, so, did you see my slide? It's okay. Okay. So, today, I will not present all the aspect of mesh adaptation, like Eve said, but we're going to focus on the latest work we have done for turbulent flow in aeronautics. And so I will try to give you the motivation of what we are doing and why we think this is important for industry today. So, it's a collaborative work, and you have many person, many people that are collaborated to this work. So, yes.
00:00:45.050 - 00:01:52.054, Speaker A: So, for us, the target, the main motivation is the error in numerical simulation, because they can cause trouble when we design a new, new project or new object in industry. So, on the left hand side, you have two examples of a roof collapse and the platform that sank in the North Sea, that are due to aero and numerical simulations. And another one, which was an issue when they designed the silvercrest engine for the Falcon five X, and what they obtained using numerical simulation, what was predicted was not the performance of the engine. And so, Dassault was not able to put this engine on their plane. And so we lose tons of money like saffron, and it was a big, big mess in France. So why we may have error in numerical simulations. So, usually, what we do when we develop a flow solver and the model that comes with it, we do what we call verification and validation.
00:01:52.054 - 00:02:54.198, Speaker A: So, verification, we are checking if the flow solver is solving the equations, so we can use a method of manufacturing solutions or comparison with overflow solver. You have, for example, the NASA turbulence modeling results for that and validation. It's when you start to compare with experiments or during workshops, and you try to model problem of real life. So you want to check that the model is correct, too. But even if you do that, and then you run numerical simulations where you don't have any information about the correct solution you may obtain. Or if you study a very innovative design that are not the classical one, where you have tuned your code, you have no guarantee that the solution you are computed are correct. And so, one of problematic is what we call geometry and numerical solution discretization errors.
00:02:54.198 - 00:03:51.424, Speaker A: So, it means that when you run your numerical simulation, you have error in the discretization you made to make the simulation, and then you can get errors. And so, the purpose of what we are doing with mesh adaptation and error estimate, et cetera, is to control this discretization error. We want to be able to quantify the uncertainty on the numerical solution and to mesh converge solution. So what we want to remove is the discretization error from the numerical solutions. So this is our main target. Another motivation that we, that is coming from industry is that engineers are paying for analysis and design and not meshing. And when you speak with them, usually, you know that they are spending months and months to generate measures by hand to, to try to be sure that the mesh is correct for their simulation.
00:03:51.424 - 00:04:44.184, Speaker A: And what we try to bring in industry is what they call the iden mesh. So it means that the meshing process is hidden from the engineers. And so engineers don't have to work on the meshing stuff during several months, and this is done automatically by algorithms. The aim here is to reduce the human labor and so the cost of numerical simulations. So, just to give you an example, on the left hand side, you have a flow around a multi element airfoil, and you have another flow over the same multi element airfoil. And the question I ask usually is that, is this the same flow? Do you have the same flow on the left and on the right hand side? So, usually when we have a real audience, people are saying, no, it's not the same flow. It's very different.
00:04:44.184 - 00:05:13.626, Speaker A: And in fact, it's exactly the same flow with the same flow solver. It's exactly the same. The only difference between these two images is a mesh. So we have changed the mesh. One is a classical mesh, and the other one is a mesh that has been tuned, knowing the exact solution, knowing the exact solution. And you see that the numerical solution you obtain is very, very, very different. And so the problem is that you cannot tune your mesh if you don't know the solution.
00:05:13.626 - 00:06:01.858, Speaker A: So the purpose of what we are doing is to do this automatically. So this is why you cannot tune your mesh automatically. It's because now we have a complexity of geometries that are very important. And the physical complexity coming with this complex geometry is very, is very important, too. And so this is why we have to develop methodologies that are able to generate this, these adapted meshes. So, just an example. If you take an airplane in landing configuration, you see that it's very complex because you have a slot and the flap deployed, many details on the geometry, you have a nacelle, landing gears and all this stuff, and so be able to deal with that kind of geometry.
00:06:01.858 - 00:06:41.794, Speaker A: Is today the state of the art applications? So, just to show you an increase of geometry, on the left hand side, you have the geometry used for the first AIA eyelid prediction workshop in 2010. And on the right hand side, the geometry we proposed in 2017. And you see that the complexity has increased a lot in this. And this is causing issue. Another point that we can talk about is about meshing guidelines. So in industry and for this workshop, there are guidelines. We need to do a mesh like this with this number of points on the leading edge, that normal point on the trading edge.
00:06:41.794 - 00:07:33.528, Speaker A: But these are adobe things, and we are not sure that this is the right mesh to make the right computation. And the last issue I want to speak about is, the thing is that which kind of flow solver we should consider, which kind of measures we should consider. So people think they are the best solver of the world, but they are not able to generate measures. And others are the best machine methods of the world, but they don't have any solver to run on it. And so the theorem is that the sum of travel is a constant and we have to find an equilibrium. And the flow solver should come with the meshing technology. For instance, a lot of people say, oh, we want to use mesh adaptation, but we want the structured boundary layer like in this example.
00:07:33.528 - 00:08:15.474, Speaker A: But what do we do in the transition between the adapted mesh and the structure boundary layer? What are we going to do? How many layers you want to put? And if you start to play with that, human is involved in the numerical loop and the human is a big source of error. So we want to remove a human from the simulation pipeline, if it's possible. So the new paradigm is that Mesh and solution are computed at the same time. So you can, you cannot dissociate the mesh and the solution. If you run different simulation, you will obtain different meshes. You cannot have one mesh for all your simulations. We will control the discretization error, and we want to achieve what we call mesh convergence.
00:08:15.474 - 00:09:15.100, Speaker A: So the solution is no more evolving when you refine your meshes, but for this, you need an automated process which is very flexible and very robust. And this is why we have considered only a full tetrahedral measures. So in the second part, I will describe very quickly the mesh adaptive platform before going to results. So in the mesh relative miracle simulation platform, it's a little bit different from classical ones, because you generate a first mesh, you compute the solution, but when you are done, you don't analyze the results. You go on with an error analysis like Marco presented yesterday, and then from that you generate a new adapted mesh and you iterate the process. And what we observed is that no step of this process can be neglected, and all of them are social improvement. So you can improve on the meshing process, but also on the flow solver, but also in the analysis.
00:09:15.100 - 00:09:44.620, Speaker A: And this is important. So we were able to apply this to inviscid flows. So here on the left, you have a sonic boom problem example. And for instance, we have done also unsteady problems. So this is a blast in the city. So you have a complexity of a blast, and you're going to see the adaptation of a mesh next. And we generate measures that are able to evolve in time and take into account all the complexity of the flow.
00:09:44.620 - 00:10:25.512, Speaker A: And we were able to extend that to moving bodies. And so here you have two aircraft crossing each other, and you have, this is coupled with mesh adaptation and it's coupled with numerical simulations. So we are able to do that. But all the people say you are not able to do turbulent flows. So then we start to work on turbulent flows, and it's what I'm going to present today. So on the flow solver part, the flow solver, his name is Wolf, so it's a mixed element volume method. So we solve the convective part with a finite volume and the diffusive part with neat elements.
00:10:25.512 - 00:11:16.836, Speaker A: The code is a vertex center, so degrees of freedom at the vertices of a mesh. And we use a classical method for null history equations. So I will not go into the details here, just to show you an example, we try to reduce as much as possible the dissipation of a numerical scheme. So just for example, if you use a classical mean mod limiters on a given mesh which is adapted, you will obtain that if you use less dissipative, like with an albadal emitter, you will obtain a flow like that one. And if you use a very low dissipative scheme and limiters, you are able, on the same mesh to increase a lot the accuracy of the solution. So you see that on the flow solver, you can improve a lot. So for the temporal discretization, we use implicit schemes.
00:11:16.836 - 00:12:22.084, Speaker A: So as it's a steady problem here, it will be a BDF one. And we worked a lot on the strong implicit solver that are very important for a steady problem when you solve the turbulent equations. And just to give you an example of improvement we can do in blue, it's the classical method we were using in the past and the new method we developed recently. You see you can convert to machine zero, the solution in less than 200 iterations instead of 1000, and you see the benefits in cpu time. So for instance, on my laptop, if I take this ilift configuration in 2d on the mesh with 20,000 vertices, I convert the solution in 100 iterations, it's 25 seconds on my laptop, and if I take a mesh of 40,000 nodes, it will be 80 seconds. In what we are doing for mesh adaptation, we did the adjoint. So we developed the adjoint solver.
00:12:22.084 - 00:13:22.126, Speaker A: And so it's a very complex problem to solve because you don't have any mathematics to help you. So it's very stiff, and it's very stiff on anisotropic meshes, and you need a very strong solver to be able to converge that, because you need to convert it to machine zero if you want to use it for mesh adaptation, because if your adjoint is not converged, then your goal oriented error estimate, it's not correct. So it's very important. So I will spend a little bit more time on the error estimate because it's the main purpose of this workshop. So, ten years ago, we have demonstrated a very interesting result, which is linking interpolation error on a discrete mesh with interpolation error with metric fields. So what we were able to demonstrate is that if you take a metric tensor m, so I don't describe what is metric tensor. I assume that everybody knows what is metric tensor.
00:13:22.126 - 00:14:31.444, Speaker A: You know that for the metric tensor, you have an infinity of unit elements, you have an infinity of unit triangles that are unique for this metric tensor. And if you take a positive quadratic form, what you can demonstrate is that the interpolation error of w in l, one norm on this element, it's equal to this relationship, which depends only on the hn of w and the metric tensor. And this is true for all unit elements in the metric m. And so with that you have, you have a duality between continuous things and the discrete things. So with that, we were able to design what we call a continuous interpolation error. So point wise interpolation error, which is a continuous function in space, and it depends only on the field w that you consider and on the metric terms on. And so the main point with that is that as we have a continuous function, we are able to set now a continuous problem that we are able to solve mathematically.
00:14:31.444 - 00:15:18.182, Speaker A: So in practice, what you want, you want the best mesh to minimize the interpolation error for a number of given number of vertices. And so this problem, you can recast it in continuous problem. And so you try to find the optimal metric field that minimizes the continuous interpolation error under the constraint that your continuous metric field is giving you a mesh with a complexity of n, which is the number of vertices. And this you can solve it analytically. And the optimal metric field is given by this relation. And so this is very interesting because we work continuously with mathematics and we are able to find the minimum of this. And so this is for the lp norm.
00:15:18.182 - 00:16:12.504, Speaker A: And when you deal with viscous application, we observe that l four norm is a better choice than l two to be able to capture the boundary layer. This was very important. And so once you have this analysis, you can use it to derive what we call the goal oriented overestimate. Sorry, I come back to a previous slide. So in that case, when you solve interpolation error, so the goal is to derive the best mesh to compute the given sensor, you choose which is the field over your whole domain. Now, if you want to do engineering applications, usually they evaluate design by the means of what we call output functionals. So if you go in aeronautics, it will be the drag, the list of an airplane, or if you do turbo machinery, it could be the edge, and you can use any kind of output functional.
00:16:12.504 - 00:17:42.792, Speaker A: But in that case, the functional is a scalar function, is a scalar function of your field w. So what we can do, we can look at the approximation error on this functional j, and we can prove that the approximation error is given by the difference between the discrete and your continuous operator weighted by the adjoint field. And for instance, if you apply this to the compressible order equations, you find that the approximation error on the cost output functional j is given by the interpolation error on the other fluxes weighted by the gradient of the adjunct state, and this in norm. And because here you have a sum of interpolation errors with the weights, you can apply exactly this formula to get the optimal metric, which is a function of euler fluxes and adjoints. So then you can extend that to viscous cases. So we had several iterations and you can end up, so I don't go through the wall proof, but the idea is that in the viscous case, when you solve navistopes, you have Euler fluxes and viscous fluxes. So what you can do, you can linearize the divergence operator like this on that side, and you linearize the same the divergence operator for the viscous fluxes, and you obtain that.
00:17:42.792 - 00:18:29.810, Speaker A: Then you can integrate part to put the derivative on the adjoins. And at the end what you obtain is interpolation error on your conservative variables and they are weighted by Jacobians times gradient of the adjoins. So, gradient of the adjoins forces and Asianovia joints for discrepes fluxes. And this is our goal oriented estimate for viscous flow. So on the mesh adaptation sites. So what we have shown is that it's better to use a local remesher, because if you use measures and you are not able to generate the mesh, because you are not able to recover the boundary or whatever, then you will not be able to do any computation. So we use local grid measure.
00:18:29.810 - 00:18:59.954, Speaker A: So like this, the existence problem is solved just at the beginning ons, and it's over for the geometry. And the main point for local measure is the obviousness, because when a local measure is doing a mesh modification, if this mesh modification is invalid, it's rejected. So you can guarantee that your mesh is always valid. And so this is very important for us for business. And so this is a process. But I will skip that. I will answer if you have any question at the end.
00:18:59.954 - 00:19:39.116, Speaker A: On the solution interpolation side, we use the classical things. If it's steady problem, we use a linear, quadratic or cubic interpolations. And if we deal with unsteady problems, we will use the conservative interpolation that marco spoke about yesterday. So now I present the mesh adaptation algorithm, because I think it's a very important point. So the key here is that mesh adaptation is a nonlinear problem. So you have to set up an iterative process to be able to converge. And you are not converging only the solution, you are converging the couple mesh solution.
00:19:39.116 - 00:20:28.144, Speaker A: As I told you, you compute the mesh and the solution at the same time. So what we can observe is that if you start to do that, you can have for free a mesh conversion studio, if you increase the mesh size during the mesh adaptation process. And if you do that, you have a kind of multi grid effect, because you start to solve on coarse meshes, and then you go to find a mesh. And so this accelerates the convergence of the whole process. And I will show in the numerical example, this is very advantageous. So the numerical mesh adaptation platform we are using is exactly that one. So here what you see, you have an outer loop here and an inner loop, where you have a classical mesh adaptation algorithm.
00:20:28.144 - 00:21:18.852, Speaker A: So in the inner loop you have a given complexity. So you say, I want to solve with 10,000 vertices, and you solve your problem with these 10,000 vertices. So you compute with your estimate the metric, you generate the new adapted mesh, you interpolate the solution on the new mesh to not restart from scratch the simulation. And then you solve the state and be a joint if you think you are conveyant. So, meaning that your solution is not in your mesh are not evolving anymore, you exit the loop, otherwise you iterate. And so when you are done with that, you obtain the best solution you can at this given complexity. And so what you can do, you can take this final solution meshes and adjoints as initial solution for a new loop where you will increase the complexity, so the size of mesh.
00:21:18.852 - 00:21:47.734, Speaker A: And so use that as initiation and you can compute for the next complexity, which is increase. And like this, you can perform your mesh convergence 3d for free. So it's exactly what we are doing today in our applications. So I will present only two applications, drag and addift applications. So on the drag, I take the oneiram six wing that marco shown yesterday. So it's very classical for characteristics. The Reynolds number is 14 million.
00:21:47.734 - 00:22:31.526, Speaker A: And you see we start from a very coarse mesh, there is only 20,000 vertices and 100,000 deaths. And we run the adaptive platform and we see the evolution of the drag with this. So on the left hand side you see in red it's all the runs, so each cross, it's a simulation on that adaptive mesh. In blue you have a final value at a given complexity. So you see that on the coarsest mesh with 20,000 vertices, we did a lot to get the drag. And then here we increase the complexity, we increase the complexity, etcetera. And you see that on the coarse meshes we need several runs to be able to converge.
00:22:31.526 - 00:23:29.558, Speaker A: But on the fine meshes we need just a few runs, because all values are always the same. Here on the left hand side, I show you a different error estimate, n limiters. And so what is interesting to see is that if you take estimates, it's the blue line here, the CN line, you see that with very coarse mesh you get a very good drag value, even if all other methodologies are converging exactly towards the same solution. So all the process is converging toward the same solution, but some of them are getting the values earlier than the other ones, so this is why they are better. So we can decompose the drug into the pressure drag and the viscous drug. So this is the convergence of a pressure drug. So you can see which methodology are better, and you can observe the convergence of the whole process again, and this is the viscose drag.
00:23:29.558 - 00:24:10.968, Speaker A: And you see exactly the same for this viscous dragon. And so what is important to see is that here the CP is not varying, so we push it to 2 million vertices. But we may have stopped the simulation there because it was already perfect. And what's interesting here is to compare what we obtained with the best practice and the state of the art code in the literature. And so these are simulation on non adapted meshes with the best as they can. And here it's our result with the mesh adaptation. And so you can see when you compare to non adapted meshes, you can get a very good value with very, very coarse meshes on this.
00:24:10.968 - 00:24:52.864, Speaker A: So you have the same for the lift, the coefficient, this is the CP and this is the viscous component. So now I show you some measures, so you can see the evolution between 40,002 million annual vertices and this is the mesh on the surface. So you see that the mesh is becoming black and very anisotropic. And this is the solution. So as we can see we have almost the perfect solution with 160,000 vertices and this is a solution with 2 million annual vertices. And you see that the solution is a mesh converge. It's not varying anymore when we increase mesh size.
00:24:52.864 - 00:25:31.844, Speaker A: So this is the evolution of a mesh in the volume with high anisotropy and the rife. So we see that we have it on coarse meshes and then it's refining, refining, and this is the solution inside your volume with a short boundary layer interaction. So in that case there is no structure boundary layer, it's fully unstructured everywhere. Okay, we don't call any boondary relay meshes. So what's important is that results are independent of initial mesh. It's fully automatic. The mesh are highly anisotropic and if we use a low dissipation scheme it improves, if we use better estimate it improve the predictions.
00:25:31.844 - 00:26:18.204, Speaker A: So now we go on highlift applications that are more complex. So this is first a 2d case. To illustrate again how it works, we start from a very coarse mesh, 2000 vertices, these are the flow characteristics, and we are going from 4000 vertices to 1 million in 2d. So on the left you have the meshes to show you the meshes and the solution on the right. So if you want I can show you very quickly the mesh. So this is a mesh with 600,000 vertices, the adapted mesh, and you can see how they look. And so what's interesting is if you zoom, you can zoom, you zoom in the boundary layer, you see it's full in structure.
00:26:18.204 - 00:27:02.804, Speaker A: And here we start to observe that we capture the linear part of lunar layer. So contrary of what is done in best practices, we have bigger elements close to the wall, then smaller element in the log layer, because this is the linear part of lunar layer. In the log layer we have smaller elements, and then it's growing, it's growing. And then this may change because we have the edge of moonlight layer and we have the interaction of the weaver shear layer here. So you can see, it's interesting to see how it occurs on the back here. And you have all the interaction and everything is captured automatically. And you can see that the mesh is extremely fine.
00:27:02.804 - 00:27:48.444, Speaker A: It's very, very very fine. Okay, so here are some view and here are some convergence plots that we obtain. And so just it was to show that with previous solver what were not too strong, we had some oscillations. And with a new solver we dont have any more in oscillation in the prediction. And also the prediction is very consistent with over prediction obtained by Boeing, MIT and NASA, with whom we are working. So you have exactly the same for the drag here. So we have to do zoom, because if you don't take zoom, you see that all the points are at the same place.
00:27:48.444 - 00:28:26.242, Speaker A: So we are looking at any details. So this is the viscous drag and this is the moment. So we have exactly the same for all the components, all the coefficients. And another thing that I can show you, this is the history of convergence on all the meshes. And you see the convergence of the list through all the iteration during the whole mesh adaptation process. And here we print the residual of the raw variable, and you see that for each mesh we are converging to machine zero. And so each peak you see it's a run on a new adapted mesh.
00:28:26.242 - 00:29:26.984, Speaker A: And so this is for the whole process. One very interesting point that I want to point out here is that if you look at the normal size prescribed at wall, and you look at an adapted mesh with 75k vertices, with respect to 600k vertices, you see that the size prescription normal to the wall is smaller when we have a larger meshes than the coarser meshes. But the thing which is interesting is to look at the white plus octane, and if you look at the white plus obtained at wall, it's exactly the same in both cases, you see it's exactly, sorry, the same shape. And in fact what we have is that the Y plus is consistent in the wall mesh adaptation process. It's the same whatever the mesh complexity, even if the normal size is changing. But the mesh adaptation process is providing exactly the same one plus. But you think it's optimal to compute what you want.
00:29:26.984 - 00:29:51.880, Speaker A: So I think this is a very interesting picture. So now we go on 3d. So this case is the one provided by the third. I give prediction workshop. So it's the HL CRM configuration, the common research model from NASA. So again we start with a coarse mesh, this is the flow characteristics, and then we go from half millions to 20 million mesh size. So this is the solution.
00:29:51.880 - 00:30:31.214, Speaker A: And what's interesting is to compare what we obtain with mesh adaptation with respect to what is done with the best practice meshing technology. So this is a major mesh with 26 million points. This is the fine mesh with 70 million points. They have an extra fine mesh with 200 million points. And this is what we obtain with mesh adaptation with 5 million points. And you see that we are not refining the surface completely different, it's completely different. And you see that the edges here of geometry are very refined because they impact a lot of the flows and the lineage edge is not refined similarly.
00:30:31.214 - 00:31:31.398, Speaker A: And we can observe exactly the same in the wake. So here, because they know that there is a wake, they put a big box with tons of elements and us, you have the wake that is completely captured by mesh adaptation and optimally with anisotropy. Another example, if you look near the slat, you see that because they have boundary layers that are structured, they have an ugly mesh in between where this can cause issues in the solution. But when you use mesh adaptation, you have this flow that is completely smooth. The mesh is smooth in that area and is able to capture very accurately in 3d that flow. The same here we have exactly the same, you see that the mesh here is not of good quality, you have big elements and there we have a very smooth mesh to be able to capture viscous, very complex flow. And if we look at details on that geometry, there is a gap between the two flap, okay.
00:31:31.398 - 00:32:18.690, Speaker A: And if you look at the best practice measures, they have a huge hole because they grow boondary layer and then you have a big hole. But if you measure a patient, then you see that there is a vertices in the gap, which is due to the gap, and you adapt around that gap to be able to capture this vertex that is going outside of the gap to be able to capture. So you see, and this, you don't predict it, it's done automatically and you let all the process to do it. So again, like in 2d, it's similar to 2d, you can observe the convergence of a lift. Again, a lot is done, of course on coarse meshes and then you don't have to do a lot of runs on verifying meshes. Here we compare our results to all the workshop results. So these are the workshop results and it's the mesh convergence.
00:32:18.690 - 00:32:49.704, Speaker A: We obtained. And I put this story because we improve the four solver. And so these are latest results, and it's what we were able to compute two years ago and last year. And so you see, we still making progress, making progress on that stuff. So on this picture, we don't see really the benefits of mesh adaptation, because we have this and at the Powell, blah, blah, blah. So it's more interesting to put it like that. All the red square are all the runs done by the participant of the workshops.
00:32:49.704 - 00:33:37.802, Speaker A: So this is the coarse mesh with 8 million points, medium mesh, fine mesh, 70 million, extra fine, 200 million. So the main point first is that on extra fine there is not a lot of people, most of them stop on the fine mesh. And what you can observe here is that if we put our result from half million points to 20 million, we put a star for each result and we compare to the extra fine grid. And you see that with 2.7 million points, we get exactly the same result as the extra fine grids. And what we show is that, in fact, the result is a ball, because their lift is increasing each time we find the grid. And with 20 million we found a lift, which is above what they expected, in fact.
00:33:37.802 - 00:34:10.966, Speaker A: And because they are not mesh converge with 200 million pounds. So these are exactly the same conclusion as previously. So I'm going to skip this. So, in conclusion, I have presented high fidelity turbulent flow obtained with unsecured mesh adaptation, with measures that are composed only of tetrahedral. So this simplified and to make the machine process and remove the human from the loop. So this is very important. We were able to obtain mesh convert solution in 3d.
00:34:10.966 - 00:34:44.096, Speaker A: So the discretization error is no more impacting the prediction. And we have results that are independent of initial mesh. As you can see, in the initial mesh, there is no machine gun lines, no boundary. Here they are there because the simplest as possible. So, in the perspective, we want to do MPI, because all these ones are done without MPI, they are done with multistreading. On the PCs, we have done work on certification and more complex geometries. And I just want to show you what is certification.
00:34:44.096 - 00:35:35.684, Speaker A: Very quickly, why we feel we can certify numerical solution. So this is a geometry that we get from the second AIAA sonic boom workshop. And when we run this simulation, we run the best practice grid of a workshop, and we run with a mesh adaptation, and we use what we call a corrector that is able to quantify the or you have at each point of a mesh. And we told them that we think that the signal in that area is incorrect, because we have a lot of uncertainty. And if we compare to what we obtained with mesh adaptation, it's very different. This is almost similar, but this is very different from that. And if we apply the same thing to our adapted measures, we say that there is not a lot of uncertainty in the solution.
00:35:35.684 - 00:36:31.994, Speaker A: So they didn't believe us because it was very different from all the participants. And so then NASA analyzed the error, so they made an error analysis on the solutions. And what we discover is that there was a huge error, because at the entrance of engine here, you have a shockwave that impacts the main wing. This shock wave is reflected toward the sky, but then it impacts this wing on the tail, so it's reflecting downward, and then it starts to interact with the engine. And if this happens, you end up with this very complex signal and you don't see it. And if you look at the adapted mesh we had, we have exactly this refinement here, there and there that capture all this interaction. And so this was missed by the best practice measures, but the mesh adaptation was able to obtain it automatically.
00:36:31.994 - 00:36:57.414, Speaker A: And so this is why we were able to have a good result and certify this was the result and not the other one. And this signal has a huge impact on the sound the sonic boom is making on the ground. And this was changing completely the Sony boom of the aircraft. So this is more complex geometries with brackets, et cetera. But I will skip. So I thank you for your attention, because I think I am already late.

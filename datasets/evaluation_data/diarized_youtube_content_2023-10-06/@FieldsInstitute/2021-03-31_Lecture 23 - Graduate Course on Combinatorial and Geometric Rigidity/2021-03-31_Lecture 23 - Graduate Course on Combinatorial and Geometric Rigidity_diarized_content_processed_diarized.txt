00:00:00.280 - 00:01:12.666, Speaker A: So I want to tell you a little bit about random graphs and why I think their rigidity properties are interesting. The first question is, what's a random graph? And I think what most people know is this random graph model where you're considering the probability space of all graphs on n vertices in which each edge is chosen independently with some probability p. And that probability space is denoted by this curly GNP. And I want to just show you what a standard theorem in random graphs looks like. So you say take a graph from this probability space, and now the probability is actually given by some function of n. And it sort of looks strange. But if you have ever read papers by erdos, and Erdos was really the one that started this random graph stuff.
00:01:12.666 - 00:02:07.904, Speaker A: It's full of these logs and log logs and other functions. And so you sort of try to comprehend how this probability is given as a function of the number of vertices. And so, okay, it's there, right? And don't overlook that divided by n. But as the vertices, the number of vertices goes to infinity. We want to say something. So it's important that there is such a function w of n that goes to infinity, divided by n. And so if you have this log n k times log n, and k is an integer greater or equal to two, and this limit as n tends to infinity of w of n goes to infinity, then you can actually say something.
00:02:07.904 - 00:03:29.500, Speaker A: Then, given any fixed integer t denote by s, sub t, for example, the set of vertices of g of degree at most t. So you take random graph g out of this probability space and you fix your integer t no matter what it is. Then as n tends to infinity, you can say something about these probabilities, namely s k minus one. And no matter if your k is given, then s, sub k minus one will be empty, no two vertices of s, sub t. Those are the vertices of your random graph g that have degree t at most t t or smaller. They are far apart, right? They are not joined by a path of length less than or equal to two. And also if you take out the vertices of low degree, low degree, when your t could be as large as it wants to be, but if you take them out, then the rest is t connected.
00:03:29.500 - 00:04:41.814, Speaker A: So if you take out the ones smaller than your given t, then the rest is actually t connected. So in some sense that's quite astounding. And why did this get my attention a long time ago? Because of this wonderful theorem by Lobas and Yemeni that you probably went over in the course already. I don't quite remember that in the plane every six connected graph is rigid. And this was actually the paper that introduced the rigidity metroid. Loewas recognized that the count for generic rigidity in the plane is actually a metroidal count, and then proved, using a nice formula for the rank function, that every six connected graph is rigid. Right, so you see, and what always sort of surprised me about this theorem is that the rigidity is proven with a contradiction that isn't tight.
00:04:41.814 - 00:06:17.872, Speaker A: So that leaves room for improvement. And what was not clear to us when we wrote the book back in the old dark ages of the last millennium, what is a natural property in sort of this probabilistic sense? If you take a large random graph, is it going to be rigid? Is it going to be, if it has enough edges to be rigid, is it going to be globally rigid? Or is globally rigid the odd man out? Or is it such a natural property that every random graph is going to have? So random graphs are in some sense difficult. You have to comprehend that probability function p. And I think that I like this concept of random regular graphs, where this is now a completely different probability space. We are looking at graphs on n vertices that have degree d. So all deregular graphs on n vertices, and they are chosen with uniform probability. So you're considering all of the graphs on n vertices, and usually in the model they are labeled graphs or labeled vertices, and they all have degree d and a sequence of graph properties.
00:06:17.872 - 00:07:09.964, Speaker A: Just to introduce that notation holds asymptotically almost to a limb in the probability space that you specify. If the limit is n tends to infinity, so the number of vertices tends to infinity if the probability that a sub n holds is going to one. So this is an important definition that we are going to use asymptotically, almost surely. So if you take a large graph, then you can rest assured that the probability is pretty large if that your property holds, if the limit tends to infinity, if the limit is equal to one, as n tends to infinity.
00:07:11.064 - 00:07:30.724, Speaker B: Brigitte, I've got a question about the previous slide. So you've mentioned. Yeah. GnD is the probability space for d, regular graphs and m vertices. Is this up to automorphism or are the vertices labeled?
00:07:31.104 - 00:07:44.684, Speaker A: The vertices are labeled, but I'm told by the random graph people that asymptotically it usually doesn't make too much of a difference, but the labeled versions are much easier to count.
00:07:45.064 - 00:07:46.848, Speaker B: Okay, that is true.
00:07:46.936 - 00:07:58.924, Speaker A: So it's much easier to work and get the probabilities in the labeled world. And we probably get to some computations so that you see how this works.
00:07:59.544 - 00:07:59.984, Speaker C: Okay.
00:08:00.024 - 00:08:11.804, Speaker A: But usually there's not much difference in the long run, even though isomorphism is hard. Right? So to get a hold of the asymptotics is much easier in the labeled world.
00:08:13.384 - 00:08:15.104, Speaker C: All right, thank you.
00:08:15.264 - 00:09:19.352, Speaker A: And here are some well known results. So this Lutrak guy, I really don't know how to pronounce his name, and there's a dash and the l, but he has marvelously interesting results. So he says D. So this degree d, the regularity of the graph can be a function of the number of vertices between three and n to the 0.02 small. Anyway, then the graph, if you take one at random from your deregular world, then it is de connected asymptotically, almost truly. If you say, okay, I want my d to just be a constant three, then you say the graph is deconnected asymptotically, almost truly.
00:09:19.352 - 00:10:10.464, Speaker A: And it's sort of strange. And wormholt remarked on this in his survey paper, I would strongly recommend it's sort of a 60 page paper, also from the last millennium. But it's very good to get started in this random graph business. And he remarks that this is actually strange, that it should be harder to prove for larger degrees, but it is. So it's actually easier to prove for the small degrees than for the large degrees that the graph is deconnected. So another nice theorem here is, and that's by wohmult himself. So he fixes d and k, and both of them are numbers larger than or equal to three.
00:10:10.464 - 00:12:08.324, Speaker A: Then he says the probabilities that some of the properties for some g in this random deregular world, so they behave asymptotically all the same. For example, the property that g is cyclically k vertex connected, d is fixed and k is fixed then. Or of cyclically k edge connected, or cyclically k vertex connected. And of course, at least k over d minus two. I can fix d and I fix k, and k could be larger than d or smaller than d. But now I want you to sort of examine this and get a feeling for it, considering that Loba's theorem, for example, where you say, I want six connectivity to prove rigidity, right? And the question is, how do I get my six connectivity? Can I cyclically k vertex connected? Does everybody know what that means? So what do you mean by cyclically k vertex connected? This something sort of strange. So you want to remove k vertices and disconnect the graph, but you want to disconnect in such a fashion that each part, each one of the at least two parts contains a cycle in it.
00:12:08.324 - 00:13:17.640, Speaker A: So it's not just a singleton vertex or a bunch of singleton vertices or just a couple of trees, but it contains a cycle. Each part that you have left of the graph contains a cycle. So you don't want to separate off trivial vertex sets or something loosely connected. The parts should have container cycle. So does that make sense? So if you, for example, go back, if I go back to my initial graph here, this would be cyclically quite a few edge connected. So if you want a cycle and it has lots of triangles left on one side and left on the other, then you would have to remove quite a few edges someplace. Maybe we want to separate edges here and edges over there.
00:13:17.640 - 00:14:14.984, Speaker A: But it sort of highly cyclically edge connected. But it's only cyclically four vertex connected because you can remove say two vertices here and two vertices on the bottom, and then still the left and the right part have a cycle contained in it. So this is not a random graph, of course. So it would not qualify for that theorem. This is not satisfying. Cyclically k vertex connected. But certainly the cyclic k edge connected is true for a larger k than for then for the edges.
00:14:14.984 - 00:15:51.124, Speaker A: Now what's the point here? So if I have my degree d fixed in my random regular graph, then how vertex connected and how edge connected can it be at most? So in the ordinary connectivity sense, a graph of degree d cannot be more than deconnected. But look at that, I can actually choose k larger than d. And I actually do get somewhere if I look at this asymptotics, because my I here goes from three to k over d minus two. That means if I, for example, look at degree four in the plane, if I take a four regular graph, I can hope that it is rigid because the average degree in a rigid graph in the plane is four. Yes. So if I now choose my k to be six, thinking of the loewers theorem, then what happens to six over d minus two? Six over d minus two is actually just three. So this product is empty.
00:15:51.124 - 00:17:28.014, Speaker A: That means everybody four regular random graph will be cyclically six vertex connected with probability one, right? So this tends to one, the product is empty and it will be cyclically six edge connected. And it will have girth at least k over d minus two. So it will have girth at least three, which is not surprising, right? So the graph on the COVID page has certainly lots of triangles, but also average degree a lot larger than four. Anyway, so you can look at this theorem and say I get quite a bit out of it, because maybe cyclically six vertex connected or six edge connected is enough to obtain local rigidity of such a four regular graph. Here is the theorem that we proved a while ago. But Bill Jackson, who knows quite a bit about random graphs, we have. This is the theorem in the ordinary random graph world where we have this probability function k log, log n and the w.
00:17:28.014 - 00:19:07.354, Speaker A: And if k is equal to two, then the graph is asymptotically almost surely rigid. And if k is equal to three in my probability function, then g is globally rigid asymptotically almost surely. But in the regular. Well, actually, maybe I want to mention these theorems first, but maybe I want to, well, no, maybe want to go back later for the random regular graph world. I want to just mention a couple of more results in this for random regular graphs, namely this interesting theorem by McDiarmid and Reid for fixed the linear algoricity of a random d regular graph is asymptotically almost surely the ceiling of one half times d plus one. So if we look at a random for a regular graph, then that ceiling would be one half times ceiling of five halves, right, three. So I could with asymptotically almost truly decompose the edge set into three paths.
00:19:07.354 - 00:20:39.054, Speaker A: So if you are thinking of looking at three decomposition theorems, and you probably have learned that, right? And I think I mentioned this later, that a rigid graph has a decomposition into two spanning trees or doubling any edge, right? It's the edge distraint union of two spanning trees such that no two subgraphs have the same span. And a path is a very nice tree that is sort of easy to use if no two subtrees have the same span. And wormholt proved this amazing theorem, which I really like, right, that in the deregular random graph world, a graph is the edge. Any deregular graph is actually the edge disjoint union of Hamilton cycles if d is even and is the edge disjoint union of Hamilton cycles plus a perfect matching if d is odd. This is, in my opinion, a great theorem. And maybe I can try to annotate. I'll try this.
00:20:39.054 - 00:21:29.280, Speaker A: But if I asked you, use this theorem to just draw me a random graph. So let's see if I can actually draw this. So what would you do? Right, so draw me a random four regular graph on seven vertices, right? And then you say okay, and I draw the vertices. And I don't know why it's blue, but so be it. And this is, I said seven. Right, but it doesn't really matter. And then I would start out with a Hamilton cycle, because after all, it's the edge distraught union of a Hamilton cycle.
00:21:29.280 - 00:23:11.462, Speaker A: Now I can think of 1234 and the random labeled is good, right? And now instead of using this permutation 123-4567 going around in the circle, I take a random permutation of 123-4567 and draw in my second Hamilton cycle. So maybe I can, but I don't know how to choose the colors, right? So I draw in something else and you can name the permutation for me. Maybe some student could join a second Hamilton cycle or maybe I can do it. I'm not doing it very randomly, but nevertheless, now I have a four regular graph and it's the edge disjoint union of two Hamilton cycles. It's not really terribly random, but you can check it out. It is actually a cycle in the two dimensional rigidity, actually another cycle that contains lots of cycles. And the nice thing in the plane is if you introduce vertices right at the crossing point, then it's still sort of, it's now a string of triangles.
00:23:11.462 - 00:24:42.974, Speaker A: And you can study properties and you have talked about partial two trees and all of this, right? So if you delete three edges here, then you get the string of triangles, so it's a two tree. And so this is really a cycle of triangles. And in my cover picture I had actually a cycle of tetrahedra. But if you ignore these vertices of degree four that I inserted later, it's really sort of easier to see that under those circumstances. The connectivity is four, right, because it's a four regular graph, but the cyclic connectivity goes up to six in the vertex sense, not if I insert these extra vertices. And in the age sense, in the age sense, even here, if I insert those extra vertices. But you can convince yourself in the other case, it's harder to see where are the cycles, but you have to remove quite a few vertices in order to get the graph separated into two pieces that contain still a cycle.
00:24:42.974 - 00:26:06.634, Speaker A: So in my opinion, this is a great theorem which tells you maybe four connectivity in the random graph world is already enough for rigidity. So let's see if I get my mouse back. Clear the drawings. So other properties of random graphs are actually, that are well studied are the spectral properties of the adjacency matrix or the various other matrices. The Laplacian is usually looked at. So the, the spectral properties of the Laplacians are something that is shared by Cayley graphs. Certain Cayley graphs, in particular Ramanujan graphs have the same spectral properties that the, the random graphs have.
00:26:06.634 - 00:26:45.598, Speaker A: These Ramanujan graphs, they are really large, and with respect to spectral properties, they behave like random graphs. I tested one of these Ramanujan graphs of degree six. The smallest one actually has 6800 vertices for its rigidity properties in three space. In three space. You want to have minimum degree or average degree six for a rigid graph. And sure enough, it is rigid, even rigid with respect to removal of one vertex. It has nice properties.
00:26:45.598 - 00:27:38.602, Speaker A: So if you want to have a nice large example of a rigid graph that is fairly sparse, then you can actually use Cayley graphs. Bthylatuses are well studied. Cayley trees are well studied. And you have this whole machinery of combinatorial group theory. So then you have this whole machinery of quotient graphs and coset diagrams at your disposal. And what is nice about these, because they are calligraphs and because you know that they are vertex transitive, you have an easy time setting up the rigidity matrix. The vertex transitivity, however, is absolutely non random.
00:27:38.602 - 00:28:25.774, Speaker A: So you can show that random graphs have asymptotically almost truly trivial automorphism group. That's in some sense, in my opinion, very interesting. What is shared by these objects? Calligraphs are also hamiltonian or there are some open problems, and people are studying these properties. So you can certainly know that they don't have small cycles. So the girth is large, that's along the lines of the random graph people. The regularity is there, the connectivity is there, the rigidity is there. But I think those are interesting classes of graphs to study.
00:28:25.774 - 00:29:06.390, Speaker A: And rigid percolation on these graphs is well studied. So let's see how to apply this in some sense to the rigidity world I've drawn here. The Cayley graph of the group Ab is equal to ba. So that's commutative group, where a to the fourth is equal to b to the fourth is equal to one. So the smallest cycle is of size four, and I've embedded it on the torus. So the red edges are just identified and the blue edges are identified. And then you can study that graph.
00:29:06.390 - 00:30:02.184, Speaker A: It's again just a four regular graph and it's globally rigid. Then here is my string of triangles, and I've decomposed it into two Hamilton cycles. The red one sort of goes around and the blue one. Usually if there is a decomposition into Hamilton cycles, there are many decompositions into Hamilton cycles. And what you can study is the cycles in the rigidity metroid. And you find that all the dependent sets are rather large. They contain almost all the vertices, all but one vertex, or they contain all the vertices and all but three edges, or any three edge set that doesn't create a vertex of degree two.
00:30:02.184 - 00:30:48.664, Speaker A: You can delete and get a rigidity cycle. So all the rigidity cycles of this object are large. And now you can push this into three dimensions. So you can take a five regular graph. And so I've put in a perfect matching in yellow. And if you take a six regular graph, that's the string of tetrahedral in three space, so that now contains three decomposes into three Hamilton cycles, the yellow one, the red one and the blue one. And of course it's perfectly globally rigid even in three space, because it's this cycle of tetrahedra and it has some of the random properties, but not all of them.
00:30:48.664 - 00:31:53.860, Speaker A: And here are these theorems that I wanted, or should have probably mentioned earlier. So these are the well known theorems of two dimensional rigidity metroids. An edge subset of a graph is a cycle, even only if it decomposes into two trees, such that each endpoint of an edge in c is in both trees, and no two subtrees have the same span. So that means C has a proper decomposition into two trees, both spanning the vertex set of c. So the hamiltonian cycles give you actually a tree decomposition by leaving out two edges, one from each Hamilton cycle. Then you get two Hamilton paths. And it's very easy to check if the Hamilton path have the same spanish.
00:31:53.860 - 00:32:49.484, Speaker A: That's only if the graph is not four connected, actually, just so if you have four separating vertices, then you could potentially have it. But if this is not the case, so it's very easy to check if the decomposition into the two Hamilton paths is proper or not. And then you have your rigidity properties from just that one. And there's this theorem that we proved with Bill Jackson. A graph is globally rigid. Well, actually, notice is the theorem, the Jackson Jordan theorem. The graph g is globally rigid, even only if it's either a complete graph on most three vertices, or it's both three connected and edge two rigid.
00:32:49.484 - 00:34:06.952, Speaker A: So if one can show that the graph is edge two rigid, then it's globally rigid if it's both three connected and edge to rigid. So it's very easy to show that the string of triangles or the decomposition into the graph consisting of two Hamilton cycles is actually globally rigid, because every edge is actually on every vertex, is contained in a rigidity cycle. So it's edge too rigid. You can leave off any three edges, in fact, and it is four connected. So these examples are actually easy to show to be globally rigid. One warning, though, for these proper three decompositions. So if I start out with my Cayley graph and I sort of subdivide four edges and put in, say, a wheel, I still have a four regular graph and it still has a two three decomposition, the red one and the blue one.
00:34:06.952 - 00:35:41.432, Speaker A: But it's not a proper two tree decomposition anymore, because the red sub tree here, consisting of the three edges of this four wheel and the blue, that's a subtree. Those two subtrees have the same span, so it has a small cycle here in the rigidity matrix. This is happening very often also in engineering, right? You think you're reinforcing or fixing something by putting these little patches of wheels here that look pretty rigid, but you actually weaken the graph. This is only just rigid, right? So it's. And this one actually will not be rigid. So you're increasing the number of vertices, but you're not increasing the count, but you're increasing the number of small cycles that this object has, and you are decreasing the fact that what you started out with was globally rigid. So what we wanted to avoid in the global rigid world is these small clumps of cycles in a random deregular graph.
00:35:41.432 - 00:37:03.740, Speaker A: They are with high probability, deconnected and cyclically three. D minus six connected asymptotically, almost truly. And they are the edge disjoint union of d over two Hamilton disjoint Hamilton cycles if d is even, and the edge disjoint union of Hamilton cycles, plus a perfect matching if d is odd. And that leads, and that is the paper with Jackson, to the fact that if d is greater than or equal to four, then, and g is a random deregular graph on n vertices, then it's asymptotically, almost truly globally rigid. So this is in some sense justifying global rigidity as the quality that a random graph has. As soon as it has enough edges to be actually rigid, then the global rigidity will kick in, in some sense, for free. In the random graph world, global rigidity is the natural property.
00:37:03.740 - 00:38:12.758, Speaker A: And most likely, if you take a graph that in the long run has large enough degree, then you are getting global rigidity for free. Rigidity and global rigidity more or less kick in at the same time. This is something that has been observed on these beefy lattices and also on the rigidity on the percolation of the. Why am I not saying this correctly? Well, so what am I looking for? Just, just annoying. Losing the. Right. So this percolation on Cayley graphs is actually well studied.
00:38:12.758 - 00:39:28.698, Speaker A: And so what I wanted to say that these properties that one wants to study and you are trying to, when you are talking about percolation, you start out with an empty graph and you drop in the edges one at a time and you are dropping them in under the condition that you want to create a deregular graph. Then nothing will happen in the beginning, right? You won't get rigid subgraphs, but all of a sudden, right, you will start to get, you will not see rigid graphs growing, but all of a sudden you will get a large rigid subgraph and all of a sudden you will get large stressed regions. And that's sort of rigidity transition. That is called first order because it doesn't, you don't see the rigid components growing. The rigidity kicks in suddenly. That first order phase transition. That has absolutely nothing to do with first order rigidity.
00:39:28.746 - 00:39:30.082, Speaker B: That's a different sort of meaning of.
00:39:30.098 - 00:39:31.754, Speaker C: The usage of the word.
00:39:31.914 - 00:40:25.994, Speaker A: Right? So nothing to do with first order rigidity, right. But you're looking at rigid components and the rigid components remain singleton edges, little triangles for a long time here and there. But you don't see, like in connectivity percolation, you see the trees growing but not here. So that phase transition for rigidity is distinct from the phase transition in the conic rigidity. Phase transition is different from connectivity phase transition. Something that is fairly well studied in random regular graphs is what's called the three core. That's a largest vertex induced subgraph of minimum degree three.
00:40:25.994 - 00:41:16.512, Speaker A: There are all these formulas tossed around. I don't want to spend too much time on this, but the number of edges in the three core divided by the number of overall vertices has a formula and it contains this probability p by which you percolate the edges in and the number of vertices divided by n. Complicated formula. And you can compute all of this. Then you can find what the three core is. So for regularity four, the three core is absolutely empty. There are no vertex induced subgraphs with degree.
00:41:16.512 - 00:42:12.624, Speaker A: At least three doesn't happen. For d is equal to five. Then when you take out edges with a certain probability, then we get the number of vertices. So these objects are fairly large, 0.57. So more than half of the edges for this three core of a five regular graph. And you can do the same thing for the six regular graphs. But I don't want to do too much of this, I want to just give you a flavor of which computations are going in if you are wanting to study, say, rigidity percolation in the rigid deregular graph world, or in the deregular random graph world.
00:42:12.624 - 00:43:43.292, Speaker A: So what Warmold uses is the pairing model of random deregular graphs. What you start out with, if you have number of vertices in, you start out with n bins and each bin contains d points, right? D is your regularity degree. And what you want to do is you want to choose a random pairing of the points, and that gives you your random deregular graph. So you pair these points off in any old fashion. And if your pair contains one point from bin one and one point from bin three, then vertex one and vertex three are adjacent, right? They have an edge from vertex one to vertex three. Of course, what you also get with in this model is actually not necessarily a simple graph because you can actually join two vertices from the same bin and then you get a loop. Or you can join pairs of vertices of the same two pins and then you get parallel edges, but you get them.
00:43:43.292 - 00:44:40.612, Speaker A: In the long run this won't make any difference. So for the asymptotics this is irrelevant. So what we want now to do is to compute, say the expected number of subgraphs of minimum degree three. So something like the three core. And I want to specify how many vertices I want to have in my subgraph and how many edges I want to have in my subgraph. So in order to be a rigid subgraph, if it on j vertices it ought to have two times j minus k edges. And you will see that the k is really not coming in in a reasonable fashion, it will more or less drop out of the consideration.
00:44:40.612 - 00:46:07.214, Speaker A: And that will mean that with a rigid subgraph, something that is large enough to be rigid, then it might as well also be globally rigid in a sense. But this is just sort of the initial counting. Are there subgraphs of the correct size and edge density that qualify for potentially being a rigid subgraph? And we want to take these in an m edge subgraph of this d regular graph. Random d regular graph. So I want to prescribe how large my edge density has to be in order to get one of these graphs that I want that qualify for potentially a rigid subgraph. So to compute this expected number, we just really use the spin model and say I want j vertices in my rigid, in my potentially rigid subgraph that potentially has enough edges on j vertices to satisfy the count. And so first choose my bins then I have this mysterious function f.
00:46:07.214 - 00:46:59.984, Speaker A: I want to know how to choose the vertices for the matching, but that will be explained a little later. But once I have chosen my vertices then I can do the matching of two j k edges. So I get my two j k edges. Now I match what's left over. First I choose I vertices that my vertices of f are. My vertices of the subgraph h are connected to in the outside world. So maybe I should make a schematic here of what's going on.
00:46:59.984 - 00:48:04.486, Speaker A: So I have my, I hope I can do this nicely. I have my subgraph h here and I have chosen the vertices of my subgraph and I've chosen the matching edges. So I have specified how to choose my subgraph and now I want to see if I of these vertices sort of might be connected to something in my image subgraph here that I haven't specified yet. So maybe none of them are. So I can go from zero to all the rest of the vertices that I haven't looked at yet. And once I've chosen what I is, then I can permute those. So the takes care of the I factorial and then to get my remaining m edges.
00:48:04.486 - 00:49:23.484, Speaker A: So I get I edges from that sort of thing, but the remaining m minus two j minus k edges in my m edged graph I just match off and I divide the whole thing by the total number of m edged subgraphs of my random deregular graph. So that's the dn, I have dn points to choose from. I choose two m from them for my m edge subgraph and I match them. So this is the expected number. Now this looks like a total mess and you wonder how you can actually get some computation going on the stuff. But it's actually sort of these random graph people have a lot of experience. And so what wormholt did, he said, well, let's first get rid of the sum, right? So the sum goes from I goes from zero to dj minus four j two k plus two k.
00:49:23.484 - 00:50:33.384, Speaker A: Let's first replace this I by some I zero that maximizes this expression, because this will be sort of taking the average and replacing the sum by just using this particular I zero. And that's done with Stirling's approximation for the factorials. And then you can sort of approximate all these binomial coefficients. And now you really want to concentrate on computing this f of j. And then you do this, in a sense, what you want this subgraph to be. You specified that the subgraph has to have degree, at least three at each vertex so I wanted to look at the generating function and I want to just say I have a deregular graph to find my subgraph h in. So I want to have this generating function x plus one to the d.
00:50:33.384 - 00:51:32.434, Speaker A: X means I take the edge or the plus one. I don't take the edge and I want to take at least three edges. So I want to subtract the negative one. I want to subtract one on the dx. So where x occurs to the exponent one and to the exponent two, so they want from each vertex of my sub graph at least three edges up. I wanted to take the jth power of that polynomial and look at the coefficient of x to the four j k, because I want to choose four j k edges. I want to have that number of edges in my subgraph, and I don't want any vertices of degree less than four.
00:51:32.434 - 00:52:50.550, Speaker A: I want to estimate this coefficient. And how do I estimate it? Because I know this is sort of a high degree polynomial and x is positive. And so I can say that this is less than or equal to the coefficient. If I divide by my x to the four j minus two k, I will get the exponent plus something more, the coefficient plus something else. To get a reasonable estimate for this w, take the logarithm, take the derivative, and then you can say your x is p prime of x divided by p of x, and that happens to be approximately equal to four. You see, that's where the k actually starts to make little difference. And so now you compute, right? So f of j becomes this expression, and for d is equal to four.
00:52:50.550 - 00:53:26.682, Speaker A: This equation that I showed on the previous thing has no solution. If I use this p of x, then I get, I compute p prime of x divided by whatever, and I get no solution. For d is equal to five. I do get a solution. It's actually an x zero of square root of ten. You compute, and for d is equal to six, then you get a solution. You want to one the one that is closest to one.
00:53:26.682 - 00:54:55.782, Speaker A: So, but it's all done in maple, right? And you get these graphs where you graph the logarithm divided by n as a function of m over n. So that's the number of edges in the d regular random graph that you percolate in. And the j over n is the fraction, the number of vertices that you allow in your subgraph. And now you ask yourself, when is there such a graph and how large is it? And you see that for m over n is actually sort of where the probability starts to get larger than zero is when m over n and j over n are actually both fairly large. A little bit more relaxed for six regular. And now you can also look at these m over n as a function of j over n graph. So what does this mean here? If you are looking for average valence four, so edge density two, then the size here for degree five will be my j.
00:54:55.782 - 00:55:59.012, Speaker A: My subgraph will be between 0.64 and 0.95. So they will be fairly large. And it's a little bit better over here where they are a little bit small when you get a larger range of sizes of subgraphs, but there are no really small ones for the edge density that you want. But those are sort of the dirty computations that you need to do. But it all makes sense if you are looking at these random graph papers. And so this intuition from the random deregular graphs that there aren't any rigid subgraphs to speak of, that reinforces this notion that the rigidity percolation will actually be first order.
00:55:59.012 - 00:57:11.740, Speaker A: So rigidity properties will kick in suddenly and you won't see any small rigid subgraphs someplace. So with high probability, but this is something that people want to know, but it needs a little bit more work, so that this always happens for degree four. For the small degree, it's actually much simpler than for the larger degrees, because of course there are more sort of rigid subgraphs that you intend to find. What did you could potentially find? Nothing said that those were rigid subgraphs, those were just dense enough in order to qualify. So there's a lot of work to still be done. But I want to just end with even yet another notion of the random graph world. Here I've drawn the sort of kagomi lattice in a geometric fashion by unit circles that touch.
00:57:11.740 - 00:58:18.394, Speaker A: And this is yet another random graph model, this geometric the probability space of all graphs on invertices in which the vertices are distributed uniformly at random in the unit square, and each pair of vertices of distance at most r are joined by an edge. So why am I alerting to this? So, so far we have not at all used the random stuff for any kind of geometry. But the embedding has never come in. We only have counted and there was no space involved. It was just probabilities and counting. But here, this is a random graph concept using the geometry. So now you take the unit square and you put your number of points in distributed uniformly at random, and you put an edge between two points if their distance is at most your given r.
00:58:18.394 - 00:59:24.604, Speaker A: And now that it was shown the bibliography is somewhere n PI r squared is equal to log n. And again, the log log and the w's are coming in for a fixed integer k. And this wn is again a function that goes to infinity. Then g is asymptotically, almost surely k connected. Now you can apply this to the rigidity world and say, if your k is nine, then you can assure global rigidity. And now the question is, can you relax this somehow to get rigidity? Can you do better than nine? And so you can get your hands dirty on that one if you try to get a homework example. But this is something that we asked at the end of the Jackson paper, and you have the bibliographies there.
00:59:24.604 - 01:00:44.314, Speaker A: So I would definitely recommend that you start with this survey paper by Nick Wormault. And it's really a nice paper, very readable, that gets you into the subject. And I've mentioned also a couple of Cayley trees, I think are something nice. And I think those Ramanujan graphs of Lubotsky, Phillips and Sarnak are something that should be studied for rigidity purposes. And Bill Jackson was really a lot of fun to write this paper, and I think he's working with WWE now on some of these rigidity questions, and I wonder how far they have gotten. And the three core, I think, is also a readable paper by Cooper, and that gets used very often, his concept and equations applied in many different aspects. But I think that should get you started in thinking randomly and thinking of global rigidity as the natural property.
01:00:44.314 - 01:01:05.314, Speaker A: And if you want deregular random graphs, start out with Hamilton cycles and perfect matchings and you'll see something. So thank you and enjoy the rest of the course.
01:01:12.034 - 01:01:23.066, Speaker C: Thanks, Brigitte, that was really great. So open the floor for questions. I know we're slightly past the hour, but I think, I hope Brigitte is happy to answer any questions, if there are any.
01:01:23.250 - 01:01:24.134, Speaker A: No problem.
01:01:27.114 - 01:02:00.594, Speaker C: So maybe I can start with a question. It's not completely related to what you talked about, but if we wanted to say something about the rigidity of a random regular graph in three dimensions asymptotically, almost surely, then probably in general, it's just very hard. But what if we wanted to look at a random regular graph and work out whether it was rigid in the cofactor matriarch or in the maximal abstract free rigidity matriarch instead? Would that be attractable target?
01:02:01.294 - 01:02:49.774, Speaker A: So there the question is, what random properties are you actually shooting for? So I think that the cycle decomposition is something that can be applied to rigidity. And the connectivity condition is something that can get applied to rigidity. That's why these things are, are nice. So I think in the cofactor matriarch you also have no connectivity condition. Yet, it's just conjectures. So the question is, which one of the well studied properties can you combine to imply rigidity?
01:02:50.594 - 01:03:08.174, Speaker C: So maybe I'm wrong, but I thought in the recent clinch Jackson Tanagawa papers, they come confirmed that twelve connected implied rigid in the c 21 cofactor matriarch. And so I was taking a almost surely a random graph and seeing if it was chap twelve connected.
01:03:09.954 - 01:04:01.734, Speaker A: Right. So this definitely can be applied. So the twelve connectivity, you would say, is definitely enough in the random graph world. Because if you have average degree or if you have six Hamilton cycles, that graph will definitely be asymptotically, almost truly rigid in the cofactor matrix. But twelve is most likely not best possible. I think you can relax this quite a bit. So maybe for the cofactor matriarch you can get a better decomposition into say, Hamilton cycles and prove the rigidity.
01:04:01.734 - 01:05:02.554, Speaker A: I would think that six connectivity. I fearlessly conjecture that six connectivity is enough for the cofactor metroid and the 3d rigidity matrix for a random regular graph. But you have the twelve connectivity for a twelve regular random graph. But I don't think it's best possible. But I think the six is best possible. And again, I would not know what extra thing to you need. And maybe you can do this again with the cyclically vertex connected, so that you get your in the lower dimensional rigidity matriarch, your cycles left over.
01:05:02.554 - 01:05:25.414, Speaker A: And that might help. But it would be an interesting thing to see how to apply this in higher dimensions. But I think that Walter doesn't believe six connectivity is enough. But I think that sort of computational evidence has it that six connectivity is enough.
01:05:27.714 - 01:05:28.814, Speaker C: Okay, thanks.
01:05:29.474 - 01:05:31.134, Speaker A: In the random world.
01:05:32.974 - 01:06:27.886, Speaker D: So I have two questions that are, that are kind of related. They're motivated by an application in statistics, but how difficult would it be to, I guess just like begin thinking about. Okay, so take one of your random graph models and then ask like, what is the expected minimum d such that your random graph is independent in the d dimensional rigidity matriid? Or maybe give some like upper bound on that. And then also what is the maximum d such that it's globally rigid in d dimensions? And then also giving a lower bound for this, like, I don't know, are either of these questions you think sort of like within reach?
01:06:28.070 - 01:06:36.470, Speaker A: So I'm a little bit confused about the d. So d in your case, is the dimension or the regularity.
01:06:36.662 - 01:06:38.554, Speaker D: Yeah, yeah, the dimension.
01:06:39.654 - 01:07:05.514, Speaker A: The dimension, right. So again, this, in my opinion, the deregularity, or if you want rigidity in dimension d, then the regularity should be equal to the dimension. That should be enough.
01:07:06.334 - 01:07:07.194, Speaker C: Okay.
01:07:08.294 - 01:07:41.334, Speaker A: Because what you are subtracting is of no consequence. That's asymptotic. Asymptotic. So that's what I would shoot for, but I'm not sure about the tools. What gets the tools so easy in dimension two is that the counting is enough.
01:07:41.764 - 01:07:42.780, Speaker C: Gotcha.
01:07:42.972 - 01:07:55.464, Speaker A: Cycles are rigid. Right. But independence, you are probably right. Independence should be easier. Right. When you are definitely under the threshold.
01:07:57.284 - 01:07:58.224, Speaker B: Gotcha.
01:08:00.964 - 01:08:01.744, Speaker D: Thanks.
01:08:08.624 - 01:08:43.764, Speaker B: So this is not a question or a comment. You mentioned Ramanujan graphs, and me and Sebastian Chaba and Jaofeng gu have a paper recently where we've shown that every k regular for k bigger than or equal to eight Ramanujan graph is globally rigid. So we do have that result in three space in 2d. In 2d, not three space, unfortunately. That would be a nice result. And we do have some results.
01:08:43.844 - 01:08:45.504, Speaker A: Right, so they are actually.
01:08:46.644 - 01:08:48.508, Speaker B: Yeah, they are globally rigid. Yeah.
01:08:48.636 - 01:09:03.466, Speaker A: Right. And they're globally rigid. But I think that holds for three space just the same. So that. So that's consistent with the. Right, so this is actually consistent with the random graph world in general.
01:09:03.530 - 01:09:05.106, Speaker D: The idea that revolution graphs sort of.
01:09:05.130 - 01:09:08.714, Speaker A: Act like random graphs. Right? So the Ramanujan graphs, although they're not random. Right?
01:09:08.794 - 01:09:12.254, Speaker B: So the randomist, in a way.
01:09:12.754 - 01:09:20.774, Speaker A: Right. So they have this wonderful eigenvalue that shows the connectivity. So are you going just for the connectivity?
01:09:23.434 - 01:09:49.803, Speaker B: No, it's slightly so if you just go for connectivity with the eigenvalue, you have to get very high regularity. It has to be quite large. I think it's like. Yeah, there's another way of doing it. It's kind of related to Bill Jackson's. Bill Jackson and T bought have that paper on. Was it six edge connected, four edge connected, two edge connected? It kind of stems from methods related to that.
01:09:49.803 - 01:09:56.424, Speaker B: And then some other stuff was used to get a spectral result. Result popped out from that.
01:09:57.964 - 01:10:37.020, Speaker A: Right. And I think that in 3D, that's also that the Ramanujan graphs are great to study. And I think that even the six regular ones are perfectly vertex birigit in three space just from that one example. But I think it's quite evident that the rigidity matrix, even if you delete it, vertex had full rank. And it's just really a nice spectacular thing. And so did you use the audomorphism group at all?
01:10:37.172 - 01:10:46.584, Speaker B: No, it wasn't used at all. It purely comes from the, just the spectrum and using spectral methods. And that's it.
01:10:48.004 - 01:11:14.044, Speaker A: Right. So, but I'd like you suggest to you, because the high automorphism group of these graphs, that you could use that for the rigidity of the, under certain automorphism groups with respect to symmetry, and they should behave very nicely.
01:11:15.184 - 01:11:16.044, Speaker B: Okay.
01:11:16.664 - 01:11:28.304, Speaker A: Even if you do the symmetric embedding, I find that interesting because they have this high out amorphism group.
01:11:30.884 - 01:11:32.252, Speaker B: Yeah. Okay. That'd be something.
01:11:32.308 - 01:11:47.384, Speaker A: And then you would get very interesting that are rigid even under the condition that they have. They're very symmetrically embedded. I didn't look at the, the quotient graphs.
01:11:49.684 - 01:11:50.036, Speaker B: Yeah.
01:11:50.060 - 01:11:55.544, Speaker A: Okay. And they are large. Right. So you get graphs with a huge automorphism group and they should look beautiful.
01:11:58.564 - 01:12:00.980, Speaker B: Yeah, I think you're probably right.
01:12:01.012 - 01:12:05.744, Speaker A: Yeah, I'd like to see that paper. Is it published already?
01:12:06.324 - 01:12:15.044, Speaker B: So we've got the paper on the spectral results is already out, and we're currently doing a paper on Ramanujan graphs in Java.
01:12:15.624 - 01:12:16.484, Speaker A: All right.
01:12:17.184 - 01:12:20.880, Speaker B: So that the looking at symmetry is a good idea, which we haven't considered yet.
01:12:20.952 - 01:12:27.644, Speaker A: So, so keep me in the loop. Right. Send me the paper when it's done.
01:12:28.064 - 01:12:28.808, Speaker B: Okay.
01:12:28.936 - 01:12:30.524, Speaker A: I'd like to see it.
01:12:32.784 - 01:12:44.224, Speaker C: Can I ask a naive question about Ramanujan graphs, because I'm not sure I understand what they are. You can pick whatever dimension you like. Does there exist a ramanusian graph as a flexible circuit?
01:12:48.244 - 01:13:09.744, Speaker A: Well, maybe Sean can answer this. So they are generated by prime numbers, pairs of prime numbers that have certain properties. So six regular is possible because seven is a prime number and six is seven minus one. Right.
01:13:10.804 - 01:13:12.604, Speaker B: So they don't have to be generated.
01:13:12.644 - 01:13:24.224, Speaker A: E minus one regular, and there is another q. Right. So you write the group in terms of the generators generated by particular pairs of prime numbers.
01:13:26.044 - 01:14:03.980, Speaker B: So they don't have to be generated this way. This is just one. This is one of the very few constructions that we know of Ramanujan graphs. They kind of like, they exist purely on their spectral properties. It's to do with the highest eigenvalue. But we only know that they exist. Yeah, we know they exist for certain prime numbers of degree, and we know that we can always find bipartite Ramanujan graphs, which is like slightly weaker, but we don't, yeah, they've, they're very, they're very abstract in some ways.
01:14:03.980 - 01:14:07.864, Speaker B: They're not known if they fully exist for all values.
01:14:08.524 - 01:14:15.444, Speaker A: But in the Lubotsky, Philips and Sarnak paper, they get actually described with generators.
01:14:15.604 - 01:14:17.820, Speaker B: Yeah. So they construct telegraphs.
01:14:17.852 - 01:14:24.172, Speaker A: Right, of, of these groups and they explicitly compute the spectrum.
01:14:24.308 - 01:14:40.104, Speaker B: Yes. Yeah. That's a wet method of doing it. Yeah. They've got like a certain type of name then type of graphs, I can't remember, but they're also like vertex transitive and everything. They've got loads of conditions. They're very nice graphs.
01:14:43.124 - 01:14:53.604, Speaker A: Right. And they have all these large girths and large connectivity. And so they have like results. Yeah, yeah.

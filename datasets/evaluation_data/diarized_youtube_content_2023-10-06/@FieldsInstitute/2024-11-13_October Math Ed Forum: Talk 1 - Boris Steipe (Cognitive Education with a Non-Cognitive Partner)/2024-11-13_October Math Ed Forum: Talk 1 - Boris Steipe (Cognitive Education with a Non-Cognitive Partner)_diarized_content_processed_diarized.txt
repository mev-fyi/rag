00:00:00.240 - 00:00:00.780, Speaker A: Foreign.
00:00:06.400 - 00:00:57.620, Speaker B: I have of course, the pleasure of introducing our first speaker, Dr. Boris Stripe. Dr. Boris, of course, is a MD, PhD and professor emeritus at the Temturi Faculty of Medicine, University of Toronto. He was an Associate professor of the Department of Biochem and Molecular Genetics at the University of Toronto and prior to which he received a PhD in Habilitation and held academic position positions, excuse me, in Germany at the Ludwig Maximilian University in Munich and the Max Planck Institute for Biochemistry. He has specializations, of course, looked at structural and computational biology, Confucian ethics, Japanese aesthetics and artificial intelligence, and education. He's dedicating his life work to bridge the domains of science, the humanities and the arts.
00:00:57.620 - 00:01:12.200, Speaker B: His talk is entitled Cognitive Education with a Non Cognitive Partner Addressing an Intrinsic Limitation of Generative AI. So Boris, I'm going to stop sharing and of course, if you're ready to start sharing, please go ahead.
00:01:13.060 - 00:02:24.880, Speaker A: Thank you. Thank you very much. Thank you for the kind introduction and I think you need to stop the sharing. Thank you. And I'm especially grateful to Stacy who invited me to this, this workshop because this gave me some opportunities to think about more deeply about a topic that I feel very strongly about, and that is how can we make AI a better collaborator? The issue here is of course, we are not even two years, quite two years into an absolute revolution of the use of computers, where computers that can speak with you and that can co think with you became a reality for all over the world. Of course I'm talking about ChatGPT and the many developments that have moved on from that. And there's some curious aspects about this particular way of using artificial intelligence to generate dialogue that also defines some of the limitations.
00:02:24.880 - 00:03:41.740, Speaker A: So I would like to talk today about a particular problem in computational biology that or in teaching computational biology, and ways how that problem of tutoring with AI can be addressed and can lead to better education. So cognition, when I think about cognition, I like to go back to the Latin roots of to think. And of course, the domain of cognitive education has its own definitions and its own paradigms. But what strikes me about cognition is that it's the category of thoughts that we can be aware of. And there's many of these things that I've collected here to abstract, to remember, to simplify, to articulate, and so on. But all of these are subject to introspection. And it is this introspection and the ability to become aware of our thoughts that allows us to abstract, to generalize, to refine, and ultimately to improve our thinking beyond what we have already been thinking.
00:03:41.740 - 00:04:18.262, Speaker A: So where does generative AI come in? Well, I like to think of generative AI as an absolutely wonderful tutoring device for our students and also for. For. For myself. It. I can overstate how fundamentally teaching with AI has changed to what we did before, especially when we teach computational biology. And students need to learn a computer language. They are not struggling with basic syntax and something that is unfamiliar with them anymore.
00:04:18.262 - 00:04:53.830, Speaker A: That's solved. They can always just ask the AI. But now the question is, how do we think about problems? And how do we implement the programs that are now so easy to write and enumerate? So I need to summarize just a very small number of aspects of how these language models are generated. Sorry, I've just lost my screen here. Click the wrong button. Oh, geez.
00:05:18.500 - 00:05:20.308, Speaker B: You stop sharing stories.
00:05:20.444 - 00:06:13.000, Speaker A: Yes, I know. I'm trying to reshare, but I've lost my window. Is it this one here? No. Okay, I'll need to go to a different window. Just a moment, please. It now. I should be back.
00:06:13.000 - 00:06:55.138, Speaker A: Yes. Okay. Just a few. I summarize very quickly how these artificial intelligence models are built. In principle, this is a machine that is a neural network based on the context window. And the context window contains some human prompt or some human dialogue. And it's trained with a large amount of training data in the way that there's a neural network, a transformer model that looks at the context window and based on relationships between the tokens it has stored in its network, figures out what probable continuations of the input context window would be.
00:06:55.138 - 00:07:26.698, Speaker A: So it decides on a number of possible words. The possible words are then evaluated against the truth, which we know because it's part of the training data. And the weights in the neural network are updated. And that is done many, many, many times. And after that is done, there's an additional step of tuning where there's a reward model about good dialogue that does the same thing. It takes the predicted word from the model and it updates the weights. And as a result, you have a machine that can do language.
00:07:26.698 - 00:08:17.038, Speaker A: And the important thing about this is that as a result, your dialogue, what you're producing, is actually an emergent phenomenon with three essential components. One of the components is the language model itself. One of the components is the dialogue model. But the third component, the essential component, is your prompt, that is your agency. And therefore, I think we need to think about these dialogue models as not an other. This is not a dichotomy between self and other here, but rather, the dialogue model is an extension of the self. What we're working with is a phenomenon that approaches the idea of a hybrid mind.
00:08:17.038 - 00:08:51.214, Speaker A: That is, the AI is a reflection of the self. And that's very important. And as Carl B. Reiter has put it recently, it ought to be a reflection of our better selves. This is our goal. One of the consequences of how these transformer models work is that the dialogue is actually latent because it's generated word after word after word from what's already present. So it doesn't introspect, at least not very extensively, into the contents of the.
00:08:51.214 - 00:09:31.880, Speaker A: Of the context window and then update it, but it generates it in a flow, in a sequence of steps along a probability gradient, I. E. This is something that is generated, which looks perfectly like human dialogue but is actually done without cognition because there is no awareness behind it and there's no refinement behind it. There's no analysis and no thinking and refining and improving the ideas. And we notice that in the dialogue because there's a number of small problems that arise. There's a lack of logical coherence. Often conclusions don't always follow cleanly from the premises.
00:09:31.880 - 00:10:05.034, Speaker A: It's weak at categorizing. So lists are not often cleanly separated by category or arguments may be redundant. It's very poor at prioritizing and distinguishing trivial from profound aspects. When it edits, it improves the writing, but it doesn't improve the ideas. There are limited returns on editing and then editing again and so on. And obviously that's the case because otherwise you could give it a bland statement and get at the end of iterations of editing a Pulitzer Prize worthy book. So that's not how it works.
00:10:05.034 - 00:10:35.714, Speaker A: There's a certain constancy of ideas or of intellectual values in there that can't easily be overcome. If you look at its creativity in some aspects, it's profoundly creative, very interestingly so. But in the end, if you analyze the creativity, it is a skillful yet unbiased, which is valuable collision of stereotypes. And it's not opening up new profound pathways of thoughts. And that also reflects in how you can play with it. It's meter great. It's not a good poet.
00:10:35.714 - 00:11:10.824, Speaker A: Its rhymes are forced and its jokes are usually not very funny. Geoff Hinton had a nice example. He started it off with the premise a priest and a badger walk into a bar. But then in the lecture that he was giving, he never got around to explore a punchline. Chatgpt won't give you very funny punchlines, and that's actually to be expected because the punchline of A joke is along a pathway of dialogue which is very highly improbable. It has to be surprising. So it's not in the scope of possibilities that the AI extends word by word.
00:11:10.824 - 00:11:58.090, Speaker A: I think this illustrates the problem very nicely. And the other problem, problems we're talking about here are just reflections on the same principle. You're walking along high probability gradients and there's an absence of introspection. So yet AI has important and enormous potential as a tutor, and we would like to use it. And for that I would, I need to introduce a little problem, a little question that I'm setting my first year course in introduction to Computational Biology. Is the genetic code the best it can be? And as you'll obviously immediately realize, it's an ill posed question. But let me talk briefly about where it comes from.
00:11:58.090 - 00:12:50.560, Speaker A: Not all of you might have a background in computational biology. So molecular life is based stories of information in molecules we call nucleotides. And these are arranged in long strands of DNA in triplets of information we call codons. And the genetic code takes, takes these codons and translates them into a set of 20 possible amino acids, which are then assembled to form proteins. And these chemical entities, the proteins, the molecules, spontaneously fold into a defined three dimensional structure. And these are the machines that underlie all of life and that manifest function. Now, in an analogy, which I find very informative of taking this molecular system and having an analogy for language, we could think of the nucleotides as letters, the DNA as some written text.
00:12:50.560 - 00:13:57.276, Speaker A: The writing system in that text defines the phonemes, and the phonemes come together to form words and phrases which ultimately establish meaning. So that's the level that we're talking about. But if we think about it in terms of information storage, at the core is this writing system. How do we store and then, then implement this passage of information, this thing, the genetic code. So the genetic code, I've mapped it out here is 64 possible codons, which are triplets of four letters. What the molecules behind these letters are is not relevant for our discussion, but you can get codons like TTT and GTT and AAT and so on. So 64 different possibilities, and each of them encodes one of 20 different amino acids which have different chemical formulas, different shapes, different properties, or a stop codon.
00:13:57.276 - 00:14:46.380, Speaker A: And this is where the sequence of assembled amino acids in a protein has to stop. So the question asking, is this the best it can be? Can requires a little bit of insight. So if you stare at this for long enough, you will notice that Code is redundant. Of course, it has to be redundant, because it maps 21 states into 64 possibilities. So if you look at how these redundant letters are arranged, you find that they tend to be very close to each other in the code table. That is, they tend to occupy what are fundamentally adjacent codons, that is, codons that can be reached from one codon in one single step. And that single step could be an error, or that single step could be a mutation.
00:14:46.380 - 00:15:40.460, Speaker A: But it turns out that if there are errors or mutations possible, as always in molecular systems, there's a certain tendency of trying to optimize that these lead to the same result that is making the code error redundant. And you can immediately see that simply from looking at the structure of the code. Moreover, we biochemists know that the letters for glutamine or asparagine actually encode very similar amino acids. They have similar shapes and similar solvent properties. And they're both uncharged, but can form hydrogen bonds and so on. So these two arrange in similar patterns. And again, this would be a hallmark of a code that is both error tolerant, but yet allows a certain degree of variability.
00:15:40.460 - 00:16:57.440, Speaker A: And that immediately suggests a computational approach to testing whether the genetic code is the best it can be. Because once we can quantify amino acid similarity, which is a nice excursion for an introductory course in computational biology, because we get to take data sets, and we apply principal component analysis, and we come up with a feature space, and we can define similarity rigorously and quantitatively as a Euclidean distance in that feature space. So once we have that, we have a similarity function, and we can take that similarity function and evaluate the entire genetic code, just iterate over all 64 codons. And for all of the 64 codons, we take the nine neighboring codons, and for each of the pairs between a codon and its nine neighbors, we calculate the the distance, and we sum that for the entire code. And this gives us a quality score. And we can then make random codes. The random code is simply a shuffle of positions and assignments, and we can compute and run a simulation and ask, well, how do these random codes behave? And here's such a simulation.
00:16:57.440 - 00:17:44.038, Speaker A: 100,000 random codes. It appears to be a normal distribution, so the normal distribution fits it very nicely, and it has a certain distribution of quality scores. However, the standard genetic code is nine sigma better than this one, corresponding to a probability of about 6 to 10 to the minus 20. So impossible. Not on this planet would it be possible to evolve the standard genetic code by random search. And that gives us a profound Insight A the topology of the genetic code appears to be non random. B We interpret this as a propensity for identical and similar amino acids to be encoded by adjacent codons.
00:17:44.038 - 00:18:54.322, Speaker A: We can show that this standard code performs many orders of magnitude better than randomly generated codes. And since all other features would be orthogonal to our model, they would not result in topologies that are so good. And thus the answer to our question resides in the topology of the code itself. Non random features are evidence for selection of a near optimal solution under a specific objective, and we can discern what that objective is simply from looking at this code table. We can learn an answer to an ill posed question whether the genetic code is the best it can be. So how would our students fare if they didn't have that background information and they tried to use the AI tutor to help them answer the question? I have a dialogue here which I've annotated in white for simply filler text and green that actually would lead us constructively to insights about how the genetic code has come to be and how it evolves. Yellow ones are, well, merely not wrong, but also kind of misleading.
00:18:54.322 - 00:19:40.732, Speaker A: But things that have annotated in red are irrelevant, misleading or outright wrong. And this is the result. This is a dialogue with three questions here. Is the genetic code the best it can be? What could I do to answer that question? Which one of those options here should I choose to answer my question better? Of course you don't have to read this, but note that most of it is read in the many dialogues I've had so far with quite many dialogues I've had so far with artificial intelligence. This one was one of the worst. Let me just pick out some of the details here. The first thing, it starts discussing error tolerance.
00:19:40.732 - 00:20:15.684, Speaker A: The genetic code is somewhat robust to mutations and so on. But then it says other configurations could exist that might improve this error tolerance further. So obviously it fixates on the question of what the best is in terms of hypothetically, there could be one that is even better. Well, that's not really the point here, because we haven't even defined what the best is. You can't answer that before you give some more thought to what the best could be. Then it starts discussing inefficiencies, which is a bit of a red herring. Then it looks at alternative genetic codes.
00:20:15.684 - 00:21:04.484, Speaker A: It's true, these do exist, but it's entirely irrelevant because just the fact that under some circumstances different codes could turn out differently doesn't change the fact that the standard genetic code is nearly universal through all domains of Life, they use the same code. It looks at evolutionary constraints. Perhaps the code is a result of frozen accidents. That's possibly the case, but it's also possibly quite likely, irrelevant. Then it speculates it might not be the best possible solution. And then it talks about theoretical optima and mentions that computations have been done, but to see if a better code could theoretically exist. That was not the point of these analyses.
00:21:04.484 - 00:21:45.262, Speaker A: These analyses were trying to figure out what the objective function behind or the selective pressure of evolution could have been. It makes something incorrect, and in its conclusion, it fixates on the best. And then it mentions something which hasn't mentioned so far. Advances in synthetic biology show that alternative or even enhanced genetic codes are possibly opening up questions about how life could function at different biological roles. And this is kind of just wrong. It just takes us into the completely wrong direction. So it speaks a lot more about these synthetic codes.
00:21:45.262 - 00:22:26.160, Speaker A: And then which one of those should I choose to answer my question best? Well, first it says, read others work. And that's not really what we were trying to do here. We were trying to see for ourselves, like scientists do. It asks us to philosophize, which I always love to do, but it doesn't give us a clear objective what we should be philosophizing about. It has pure fantasies about experimental approaches with synthetic biology. These experiments are exceedingly hard, and the results are exceedingly difficult to interpret. And I would vouch they are impossible to interpret in terms of the model that we're looking at here.
00:22:26.160 - 00:23:10.894, Speaker A: It asks us to model, but again, with the wrong goal. And in the end, if you want a balanced, reflective answer with minimal experimentation, choose the philosophical evolutionary argument combined with literature review, because you'll tackle the question conceptually, making it accessible without the need for intensive lab work or modeling. Well, that's not really the scientific method. We're not looking for our keys under the lamppost just because there's more light there. We're trying to find them wherever they are. So how can we improve this? For me, the answer is in this idea of cognitive dialogue. That's the missing component here.
00:23:10.894 - 00:24:00.690, Speaker A: Can we bring cognition back into this dialogue? And what are possible components of cognitive dialogue? Now, this is something that I will be thinking a lot more in the future, but essentially some. As a first approach, we need to reflect on what's been said and think about it. We need to identify what's valuable. And part of how we identify what's valuable is we identify what's beautiful about it, that is, which aspects resonate well with others. And lead us to see deeper connections and gain deeper insight. And then we summarize and then we ask some actionable questions. So I've re annotated the first passage here.
00:24:00.690 - 00:24:43.502, Speaker A: The answer genetic code is is it the best it can be? It evolved under specific constraints and some mutations that change a single nucleotide often result in similar amino acids. And that's. That's fascinating. And it's also universal or nearly universal, which is also non trivial. Why would it be? Why? Why? Since every organism is different and lives in a different context, why wouldn't they choose to have a different genetic code? Then that there are actually simulations that find that the standard genetic code is near optimal. Summarizing this into a cognitive summary, I could say. Here's how I think about your answer.
00:24:43.502 - 00:25:36.972, Speaker A: Clearly the genetic code evolved under specific constraints, which I take from here to become a nearly universal genetic code. It is intriguing that some mutations that change a single nucleotide often result in similar amino acids being encoded, which minimizes the impact. And A, I wonder how the code achieves that. You also mentioned that simulations often find that the standard genetic code is near optimal, particularly in terms of minimizing the effects of errors and mutations. And this resonates what we said about evolutionary constraints. So B, I would like to learn more about this connection, about this resonance here, and C, I would like to explore what it would take to reproduce such a simulation. The result is this here.
00:25:36.972 - 00:26:52.650, Speaker A: And I haven't even continued the discussion at this point because it's nearly perfect, setting out an entire detailed computational experimental agenda. So we're taking this discussion from something that is absolutely unusable and would be a detriment to the learning of our students to getting something which would be extremely helpful and explains how the genetic code minimizes mutation impact by codon groupings, schemalous similarities, synonymous codons, limiting things through a multiplicity of error stop codons. It talks about evolutionary constraints and non optimality, that we can simulate error tolerance. And then it talks about what it would take choose a programming platform, design the model, introduce mutations, compare fitness, essentially what we've done in the course. So there you go. Bringing cognition back into transformer models of artificial intelligence can make them perform profoundly better than if we just use a plain vanilla approach. Thank you.

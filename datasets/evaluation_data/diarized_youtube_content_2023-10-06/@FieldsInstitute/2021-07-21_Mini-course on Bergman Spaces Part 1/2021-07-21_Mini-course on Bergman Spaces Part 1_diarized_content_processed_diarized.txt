00:00:00.160 - 00:00:24.634, Speaker A: Steve Jobs. It is 10:00 so this is the first of three lectures on bourbon spaces offered to us by Stefan Richter at the University of Tennessee. So why don't we just jump in? So, Stephon.
00:00:25.894 - 00:01:31.682, Speaker B: All right, well, I would like to thank the organizers for setting up this great program this fall and for inviting me to be part of this. As I started thinking about what I was going to talk about, I realized that I hadn't actually worked on the Bergman space for about 15 years. And so I went to Mathsinet to see whether I had missed anything in these 15. And so here's what I came up with. So I typed in Bergmanspace and Bergman Kernel, and I came up with 6008 papers that had been published containing these words. And let's see, when did all this happen? So there we can see the annual distribution. Bergman wrote the first paper in 1933, and then Masan had started indexing papers in 1940.
00:01:31.682 - 00:02:17.694, Speaker B: So in the beginning, people were mentioning Bergman and his colonel, and so there were a few papers a year. Then this slowly increases. And then in the 1990s, it reaches about 100 papers a year. And then in the 15 years that I didn't work on this anymore, it started averaging about 200 papers a year. And even since I accepted the invitation to give these talks, roughly 300 papers have been written. So what is all this about? All right, so you can see that according to Math Synet, many of these papers are an operator theory. Many of them are on several complex variables and analytic spaces.
00:02:17.694 - 00:03:23.422, Speaker B: And then functions of a single complex variable and functional analysis seem to be more general ones. And I don't know, I guess maybe there must be a lot of papers that don't have a primary classification. But in any case, so what Bergman had done was he showed that the Bergman kernel and a conformal map from one region onto another are related to one another. And that works in one variable, and it works in several complex variables, and it's especially important in several complex variables where it is harder to construct the conformal mappings between regions in Cn. And so that's why there's a lot of papers in several complex variables. So in my talks, I will just focus on operator theory and function theory in the open unit disk. And even in the open unit disk, there's a wide variety of topics that I could have chosen to talk about, and I don't have time to cover all of these if I want to say something substantial.
00:03:23.422 - 00:04:07.454, Speaker B: So today we will talk about reproducing kernels and point wise estimates of functions in these Bergman spaces. The Bergmann projection and duality in the case from p between one and infinity zero sets. And then tomorrow we'll talk about the invariant subspace problem and what it has to do with the Bergmann space subspaces of infinite index. And then on Thursday, we'll talk about Bergman in f functions, lp theorems, and Schimorin's approach for the l two situation. And the goal is to show you some of the different flavors of the Bergman space theory. There's function theory, there's operator theory, and there's all kinds of things coming in. All right, here's a few references.
00:04:07.454 - 00:05:01.988, Speaker B: It started with Bergman's paper, 1933. I already mentioned that a classic on reproducing kernels that's still a good read is Ehrengern's paper from 1950. Sheldon Exler's overview paper from 1988 is also an excellent resource. And in fact, when I was a graduate student, I was privileged to listen to three lectures by Sheldon on Bergman's basis. And I have benefited from it very much. And so I recommend that that covers material that was done in the 1980s and before, and then in the early two thousands. We have three textbooks here, one by Haakon Hiddenmalm, Boris Kornbum, Keri Zoo, one by Peter and Alexander Shuster, and then a later book by K.
00:05:01.988 - 00:05:50.624, Speaker B: Zhu, which covers other material also. All right, so in my talks, we'll be talking about the Bergmann spaces of the disk. So P will be an index between zero and infinity, and Da will denote area measure, dx dy, and Da over PI is the normalized area measure. So we take the LP a norm, I'll call it of a function for p less than one. That's not a norm, but we'll still call it a norm. And then we can do a change of variables using polar coordinates. And we see that the LPA norm is sort of a doctor integral of the integral means, the pth integral means of the functions.
00:05:50.624 - 00:06:47.374, Speaker B: So, if you recall that the HP norm is defined to be the supremum of these integral means. And in fact, one can show it's a term of hardies, that these integral means are non decreasing as a function of R. And the HP norm is this supremum. Then you immediately see that Hp is contained in LP for each index, and you have the contractive norm inequality that the LPA norm is less than the suprema of this. So analytic functions that satisfy that. Now, this inequality was so easy to obtain, it's not the optimal inequality. So these spaces get smaller as p increases, and it turns out that you can use estimates of hard classical estimates of Hardy and Littlewood to prove that HP is actually contained in L two PA.
00:06:47.374 - 00:07:38.404, Speaker B: And you get the contractive norm inequality that you get exact equality as to what's observed by Vukovich in 2003. And what he is proof is the following. So he says, for p equals two, what you can do is you can notice that the four norm in the Bergmann space is actually equal to the square root of the two norm of the square of the function. And then you can write it out as a power series and do cushy Schwartz inequality. And you get, it's less than, than the h two norm of the function. All right. You can also, then from this situation at p equals two, you get the other values of p just by using inner outer factorizations and p rules and so on.
00:07:38.404 - 00:08:21.936, Speaker B: All right. Well, on the other hand, these lp spaces are very much larger than, than the Hardy spaces. So we learned that the Hardy spaces, every function has non tangential limits almost everywhere. And that was actually very important for the theory and most of the theorems that you prove about Hardy space functions. And so, unfortunately, even when you take the intersection of all the Bergman spaces, there are functions that have no tangential limits almost anywhere. So a function that you can take is the summation of z to the two to the n. So it's a lacquer series.
00:08:21.936 - 00:09:07.912, Speaker B: That means you skip a lot, you have a lot of the power series coefficients are zero. And then it's well known that those functions have very bad boundary behavior. And Sigmund showed that this function has radial limits almost nowhere. And on the other hand, you see immediately that if you take the sum of the squares of the power series coefficients, they're not square summable because they're all one. On the other hand, when you do the LPA norm, you have a triangle inequality there for p bigger than one, that is. And then when you integrate over the disk, the z to the k is less than, strictly less than one, and you can do the integral. Exactly.
00:09:07.912 - 00:09:53.984, Speaker B: And it just turns out that you can rig it with the two to the n. Here, you can see that it is always finite, no matter what. So there's your function that doesn't have radial limits anywhere. All right, there's another difference between the Bergmann spaces and the h two situation that's very significant, namely, in h two. You use a lot of times that h two is contained in the l two. And if you think of the Fourier coefficients of l two functions and h two functions, you realize that the other complement of h two in l two is sort of like a copy of h two itself. These are the complex conjugates of the h two functions that are zero at the origin.
00:09:53.984 - 00:10:54.052, Speaker B: On the other hand, l two, the whole space l two, is still the direct sum of l two a and its ortho complement. But the complex conjugates of the analytic functions in the Bergmann space are much, much smaller than this ortho complement. And so that frequently makes a big difference in the theory. And in particular, I want to mention that when you look at these powers of z bar to the n and z to the m by the Stone Weissrass theorem, linear combinations of those are, of course, dense in l two of the disk, but they're not orthogonal, and so you can't work with those functions as nicely as you can work with the single powers in the circle situation. All right, so first good theorem about Lp spaces is that the polynomials are dense. And you can prove that by just looking at the dilation. So you define a function f, sub r.
00:10:54.052 - 00:11:58.864, Speaker B: Say f, sub r of z is f, sub r z. And since those functions are analytic in the neighborhood of the closed disk, and those functions can be approximated uniformly by polynomials, it's enough to show that fr converges to f in the lp norm. And then, of course, a simple change of variables shows you that the fr norm, the p norm of fr, it convert into the p norm of f by just doing that simple change of variables with the rz equals w. And if p is bigger than one, then you done immediately, because now you can use weak convergence and say that there's some kind of convex combinations of these f, sub r's that will converge in norm. To fix if p is less than one, then you actually need to work a little bit harder. But that's still not much harder. There's a real analysis exercise that says that if you have a sequence of functions that converges almost everywhere, and if the norms converge in Lp, then you have actually lp convergence.
00:11:58.864 - 00:12:30.194, Speaker B: All right, so that shows that the polynomials are dense. Now, if p is equal to two, then you can express the Bergmann norm. And Tom has already mentioned that in terms of the Taylor coefficients. So you have the sum of the squares of the Taylor coefficients, and you need to divide it by n plus one. That's a Hilbert space l two. A is a Hilbert space within a product. Then by polarizing this expression, and you can now look at the partial sums of the functions f.
00:12:30.194 - 00:13:36.774, Speaker B: So the partial sum just goes from zero to capital n. And if you subtract that from f, then you see that you just get the tail end of this series here. And obviously the tail end of a convergent series converges to zero. So in the p two situation, the partial sums converge to f, and it turns out that that's true for all p strictly bigger than one and less than infinity. And the proof of that fact, you can actually use the fact that you can use a Zeger projection, Masa rhesus theorem that the Zeger projection is bounded on LP if LP is bigger than one. And then again, you use the fact that you can use polar coordinates to do this integral, and you work with the boundedness of the SNS for the HP situation, that turns out to be the analog of this turns out to be false if p is equal to one or p is less than one. Okay, Zoo has described that in his article 1991.
00:13:36.774 - 00:14:48.914, Speaker B: There's a recent paper where people work on questions of the type, well, let's say f is in lp, p bigger than one. Can you get the partial sums in l one to converge to zero in that case? Or some weighted Bergman space or something like that? All right, well, if you want to get away from the hardy space results, then the best method we have is to use a change of variables. So we define the disk automorphism Phi lambda of z lambda minus z over one minus lambda bar z. This has the property that its own inverse and it interchanges zero and lambda. And then, of course, the jacobian determinant of this function, phi lambda, is just the absolute value of phi prime squared. And when you do the calculation, what you get is one minus absolute lambda squared squared over one minus lambda bar z to the fourth da. And if you're like me, you constantly get confused with whether you're supposed to be using the function or its inverse.
00:14:48.914 - 00:15:32.024, Speaker B: That's the nice thing about this function, it's its own inverse. So when you change from z to w or w to z, it doesn't matter, you get the same factor here. All right. An immediate corollary is that when you take any p between zero and infinity and any lambda in the disk, then this operator v, which depends on p and lambda, where you take f, you compose with phi lambda and multiply it by, by the derivative to the two over pth power. So the derivative by the two over pth power is written out over here. Then that's isometric from lp to lp. So if you take the p power on both sides, you see, you get the f composed with phi lambda to the p.
00:15:32.024 - 00:16:10.960, Speaker B: And you take the p power of this absolute values, you get the term that you need for the change of variables. And so that's isometric on lp for any value of p. Notice when you plug in z equals zero, vf at zero is f of lambda. And then over here, you get this factor, one minus absolute lambda squared to the two over p. So if you raise it to the pth power, you get what I have down here. So with that, you immediately get a point wise estimate for the growth of functions in the Bergmann space. I say it's folklore.
00:16:10.960 - 00:16:52.084, Speaker B: Folklore is for when you have one minus absolute lambda quantity squared times f to the p. When you put the square here, you get the exact estimate that's observed by Vukovich, perhaps by other people too. But that's a reference we have. And what you do is you prove this first for lambda equals zero. So f of zero is less than this. And then for that you can use the integral means, as I used on my first slide again. And then once you have that, you can use this operator v that I just talked about, and you immediately get that, because v is isometry, you immediately get this result.
00:16:52.084 - 00:17:25.347, Speaker B: And it's sharp, because it's sharp for lambda equals zero. And then we've just transported this. So there's always a function where equality holds. Well, it's sharp, but can you do better? So it's sharp when we fix the lambda and change the f. But we can also do it the other way around. We can fix the f and change the lambda. So as we go with the lambda to one, then this estimate, which was a big o, actually turns into a little o condition.
00:17:25.347 - 00:18:06.804, Speaker B: And that's a standard fact in many spaces of functions when the polynomials are dense. So what you do is you look at the limb soup of this and you notice, because we have this f sub r available, these dilation functions, well, they're analytic in the neighborhood. So when I take the limb soup as lambda goes to one, the f sub r is bounded. So this doesn't change the limb soup here. But now I have the estimate from the previous slide that I can apply f minus fr, and so I get the norm here and I can make this less than epsilon for any epsilon. So that means that lim sub will have to be zero. So all right, so surely that's the best estimate that you can do.
00:18:06.804 - 00:18:55.858, Speaker B: But again, now, dependent on what it is you're looking for, if you can relax this some more. So if you want to take a non tangential limit instead of the unrestricted limit here, and you fix a point, almost every point on the boundary, then you can actually reduce the power here by one. So you get, instead of multiplying by a square of this, you multiply by just the first power, which is much larger, and you still get zero almost everywhere. All right, so here's the proof of that. So you write down this function g, sub lambda, of z. So there's an f in here, and then it has this factor, which again is analytic because the lambda is less than one. And I can take a p two over pth root for it.
00:18:55.858 - 00:19:38.514, Speaker B: And I'll notice, if I plug in lambda in this expression, I get the one over p and the two over p leave me with a one over p power in the denominator. So when I multiply it with, I raise it to the pth power, and I multiply it with a square, I just get a first power left. So I get one minus absolute lambda squared f to the p at lambda equals this thing with the square at the g. And now for the g, I can use the first estimate. Again, the point was estimate the wukume estimate to get it less than the norm. And now we write out the expression that we have here. All right, so we have a Poisson kernel.
00:19:38.514 - 00:20:28.702, Speaker B: And then over here we have a measure that's supported on the disk. So if you have a measure that's supported on the boundary, you know, the Poisson integral gives you the absolute value of the, I mean, the absolutely continuous part of the measure. Now, if you have a measure in the disk, then you can show that this converges to zero almost everywhere. And I learned that from greet and Trent from a paper. All right. Now this better estimate is significant because that's the best you can do, because you can almost get a converse there. So if you have a power that's slightly less than one in front of the f to the p, then, because one over that expression is integrable with respect to area measure, then the function will be an Lp.
00:20:28.702 - 00:21:48.820, Speaker B: So if you have any holomorphic function that satisfies an estimate, whether the power is just a little bit less than this, then the function has to be an Lp. All right, so much about the estimates on the boundary, there's one more thing that sort of is in line with the last thing that I just said, that if you, this is the theorem that I do know that if you have a function in the l two Bergmann space, you can factor it as an h two function that has the same norm as the Bergmann function. An outer function, in fact, and a function that satisfies this better growth estimate with less than or equal to one. So, as I was thinking about my talk, I know how to prove this using Herbert space and reproducing kernel methods. And I'm sure other people were aware of this also, that one can do that. But I'm not aware, I didn't know whether one can do this for general lp functions. So the analog of this for lp would be, can you find hp functions of the same norm or comparable norm to the lp norm of the f and that satisfy this better growth estimate? So if you get bored with my talk, you can work on that.
00:21:48.820 - 00:22:36.128, Speaker B: Or maybe you know the answer to this, and then you can let me know. If p is equal to one, then in fact, I do know the answer to this. Horowitz proved that every l one function, l one, a function is a product of two l two functions. And then you can use the Hilbert space result up here to prove this analog. If p is anything else, then I don't know. There are results of Conan Verbitsky where they consider functions whose derivative is in hp, and they prove that, say any function that whose first derivatives in hp can be written as an hp function times the derivative of a BMO function. And so that may be related to this, but I'm not aware of this result.
00:22:36.128 - 00:23:33.374, Speaker B: But it seems reasonable in light of the previous results that I mentioned. In fact, you might get that you get a little o condition here, as lambda goes to one almost everywhere, at least, because for p equals two, the previous results would imply that. All right, so then when you walk in the Bergman space, the first sort of non pleasant calculation that you come up with, that you come up against, is this kind of expression. So these are functions as functions of w. Let's say we're fixing a lambda in the disk, and we have two parameters here, t and s. T is bigger than negative one, and we're integrating expression in w. So the t here, being bigger than negative one, means that the measure of one minus w squared to the t da is a finite measure.
00:23:33.374 - 00:24:27.714, Speaker B: And then we're taking a product of the terms with the t and with the w and the lambda. And you take in the denominator, you get this mixed term here where you have the power t plus s plus two. And then when this is bounded, then, I mean, this is bounded independently of lambda in the disk. So when t is zero and s is two, then actually you get just again against the change of variable formula, and you get the expression is equal to one for all lambdas. But in general, you get this. So there's two proofs that I know of. Foreli and Rudin did a calculation for they needed the CD version of this.
00:24:27.714 - 00:25:08.416, Speaker B: So you get a D plus one instead of a two here, and they use power series. So you have a binomial expression here and you get expand the top. In the binomial series, you have gamma functions and Stirling's formula and all that. And you can get this. When you do the disk, there's an argument by Shields and Williams which is a little more straightforward. Basically, you again use the polar coordinate calculation and you first do the D theta integral. You use one of these powers here in the denominator, and then you get to the RDR integral.
00:25:08.416 - 00:25:53.696, Speaker B: And now if t is bigger than zero, there's no problem here at all. But if p is between negative one and zero, and that's the case, you actually need a lot of times, then you can do integration by parts one time, and that increases the t here. There's a term that is a non integrated term that's benign, because now the t plus one is bigger than zero, and you get an estimate of this type here. With a t plus one, you have to take a derivative on the denominator, so you increase there. But now you can use the fact that the one minus r is less than one minus r lambda, because t plus one is a positive power. Then you can cancel that. You get this estimate.
00:25:53.696 - 00:26:25.110, Speaker B: So you get this. I won't actually need that, but this estimate is useful in the background frequently. All right, so then the reproducing kernel property. Anytime you have an l two a function, you get this reproducing property that the f of lambda is the f of z integrated against this. And again, you can verify it. For lambda equals zero, it's just a mean value property. And then you use a change of variables.
00:26:25.110 - 00:27:20.928, Speaker B: So we'll call this function k, sub lambda, the reproducing kernel. And we get this nifty formula that f of lambda is the integral f against k lambda. All right, so for any l one function, analytic or not, then you can define the Bergmann projection pf of z, and it's the inner product of f with k lambda if you want. But f is an l one here. So, for example, if you calculate the Bergmann projection of these monomials, z bar to the n, z to the k, you get this expression here. Not necessarily very pretty, but this Bergmann projection has this nice property that when p is equal to two, I mean, the index is equal to two. Then the Bergmann projection acts as the orthogonal projection on the Hilbert space.
00:27:20.928 - 00:28:13.260, Speaker B: So l two a is a closed subspace of l two a. And so there's an orthogonal projection, and that's just given by this operator when p is between one and infinity, then it turns out this Bergmann projection takes lp function to lp functions. So that was proven in 1964 by Sahar, Utah and Yudovich, and they used the singular integral operator theory to do that. And then later, Foreli and Rudin. Oh, sorry. Foreli and Rudin proved this for in dimension d bigger than one, and they used this estimate that I had earlier there with the functions of maximal growth and the short test to prove that. That's the proof that you will find in the textbooks.
00:28:13.260 - 00:29:00.104, Speaker B: Now, so the Bergmann projection is not bounded on l infinity or l one. So, for example, you can take this function one minus absolute z squared over one minus c. That function, obviously is an l infinity. And a simple calculation shows that the Bergman projection of this has a logarithm in there, and that's an unbounded function. And so once you know that it's not bounded from l infinity to l infinity, then you can see that it cannot be bounded on l one either. Because if it were bounded on l one, then its adjoint would be a bounded operator on l infinity. And then you can prove that that adjoint would have to be the Bergmann projection on l infinity, which is unbounded.
00:29:00.104 - 00:29:49.114, Speaker B: All right, so then the LPA spaces are closed subspaces. Then you know their duals from functional analysis are quotient spaces in the duals of lp. So they're factor spaces in Lq. Now, in applications, it's often useful to actually represent the joules space as a space of functions, rather than equivalence classes of functions. And so you find that LPa has a dual LQ like you'd want it to be. And the proof is very simple now that we know the boundedness of the Bergmann projection. So it's clear that any LQA function defines a boundary linear function along LPa, just by the usual Lp LQA duality.
00:29:49.114 - 00:30:55.372, Speaker B: And if you have a functional on Lp, then by the handbandha theorem, you can extend it to a functional on the whole Lp space of the same norm. So there's some function h in Lq, not necessarily analytic, that represents this functional. And then you can take the Bergmann projection of that function, and you get a function g that's in this, and then you find that that's the function that works. Okay, so that that works for p between one and infinity, and it doesn't work for p equals one, because then we know the Bergman projection is not bounded. And I think Sheldon Exler, in his talk, will talk about the duality in case when p is equal to one. All right, so, next topic that I want to to talk about is zero sets of functions in these Bergman spaces. So, let's say you have a space of holomorphic functions in the disk space or a Hilbert space.
00:30:55.372 - 00:32:10.154, Speaker B: Then you say a sequence in the disk, and you might have some points repeated here. It's called a zero set for the space of functions. If there's a function that is equal to zero exactly at those points, and if a point has been repeated several times, then the derivative and second derivative and so on is also required to be zero exactly up to the number of times that this point's been repeated in the sequence. So, from the theory of analytic functions, you know that if you have a zero set, then you can't have an accumulation point inside of the disk. So if you have infinitely many of these points, they'll somehow have to converge to the boundary. So you call the sequence a Blaschke sequence if they converge to the boundary so fast that the summation of one minus absolute lambda n is finite. And it's a theorem that was mentioned in Tom's talk as well, that for hp, for all hp spaces p between zero and infinity, even equal infinity, the zero sets of the hp spaces are exactly the Blaschke sequences.
00:32:10.154 - 00:33:30.818, Speaker B: So, if this expression is finite, then you can form this Blaschke product here that I've written down at the bottom, and that defines a function in h infinity with exactly the zeros lambda n. And if you have a function in hp, then it turns out that you can factor it as a product of a Blaschke factor times a function that has the same norm in hp. And hence, the sequence has to be a Blaschke sequence, because what's the connection between the Blaschke product and this Blaschke sum? Well, if you take the value of the Blaschke product at zero, you plug in z equals zero, you get absolute lambda, the product of the absolute lambda. So, if you take the log of that, the log of a product is a sum, and so you get the sum of one over the lambda n's. And as the lambda n's converge to one, sorry, the log of the one over lambda n's. And as that converges to one that's approximately one minus lambda n. So the significance of the Plaschke sum here is that it is related to the value of the Plaschke product at zero, and you need that to converge.
00:33:30.818 - 00:34:11.494, Speaker B: Otherwise this would be identically equal to zero. All right, if you now go to the Bergmann space, perhaps it's not a surprise there'll be a zero set for the Bergmann space. That's not a Blaschke sequence. The space are bigger, so you get more functions. So perhaps that's not too surprising. Horowitz shows that the condition for Bergman zero sets has to depend on the index. So when you have different indices p and q, then the characterization of the zero sets for Lp and LQ would have to give you something different.
00:34:11.494 - 00:34:59.884, Speaker B: All right, so I have a proof here of the part a of this result that there's a zero set for Lp. That's not a zero set for any of the HP spaces. So we take a function of this type. We take a product of one minus two z to the nk, where I'll choose the nk's in a moment, but let's see where these functions equal to zero. So, first of all, it's easy to show that this product, no matter what you choose, for the nk, defines an analytic function in the disk. So this converges locally, uniformly, this product here, and where these equal to zero. Well, if you, I claim the zeros are located on concentric circles and distributed like these red dots here.
00:34:59.884 - 00:35:42.874, Speaker B: Let's go to the next page. So each factor is of the type one minus two times z to the nk, and that's equal to zero when z to the nk is equal to one, two. And so the absolute value of z to the nk is one half. So the z would have to be two to the minus one over nk in absolute values. And then you get the nth roots of unity that go with the points on the circle there. So that's the red dots that I had earlier. So you have a fixed radius, and then you have corresponding number nk points on the corresponding circle.
00:35:42.874 - 00:36:31.338, Speaker B: And then if you look at the contribution to the blaschke sum, that was one minus absolute lambda NK. So you have nk points on each circle, and you have this expression one minus r, and that's one minus two to the negative one over nk, you express that with an exponential function. So that we see that as Nk goes to infinity, the exponent goes to zero. And so this is like one minus the first term in the power series for the exponential function. And so that's minus there with the second minus gives you plus, the Nk cancels out. And so that converges to log of two. And as you now take a sum of this, that's infinite.
00:36:31.338 - 00:37:02.332, Speaker B: So it can't be a blaschkiff product, no matter what you choose for the n case. All right, now, how do we choose the n case to get the function to be an LPA? Well, we inductively choose the n case. So this is a product. So I call f sub m to be one of these partial products. Then Fm, one has one more factor. And if I now look at the norm of m plus one in Lp, let's say p is bigger than one. Again, we're having a triangle inequality there.
00:37:02.332 - 00:37:46.854, Speaker B: So that's the norm of fm times two, times z to the m plus one times the norm of fm. So if you have the fm chosen, then you can choose the n sub m plus one, remembering that this expression, it's an integral over the open disk. So this converges to zero. The Fm is fixed. As you let n go to infinity, this converges to zero. So you can make this term as small as you like, no matter what the Fm is. So if you make that smaller than one over two to the m, or something like that, that'll be summable in the end, then you get that the sum of all the terms is finite, and so you get the f amps to be bounded.
00:37:46.854 - 00:38:57.664, Speaker B: So, it's a very simple argument that gives you that such a function is in LPA and doesn't satisfy the Blaschke condition. The functions that Horowitz uses are of the type some products like this. Instead of the two, he takes a b, and instead of the nk, which I chose, arbitrary here, he chooses m to the k, and then he varies the b and the m, and he gets functions that are in Lq and not an Lp, or vice versa in the appropriate cases. So that, of course, gets more complicated. Now, if you believe what I just said, then what Horowitz actually showed is that these functions that he considers there satisfy this condition that when you look at the absolute values of their zeros, not only is the Blaschke condition violated, but when you divide the Blaschke, the terms that you have in the Blaschke condition, by this log of one over one minus n. So as n goes to infinity, the lambda n's go to the boundary, one over one minus lambda, n goes to infinity. So that's the log.
00:38:57.664 - 00:39:58.994, Speaker B: So you make this term smaller, and even that's still infinity. And again, why is that the case? Well, if you believe these functions, that you can take these functions, we've already looked at the blaschket condition, or you have a b in here, but that's the same that will converge now to the log of B. And what happens in the bottom here is that the lambda n's are like b to the absolute b to the minus one over mk. And knowing that the log of one minus z is like the log of z, you get this is sort of like a one over k. So you get a harmonic series here, which diverges. So all of these functions give you something where this expression is finite. Now, Horowitz also showed that if you make this denominator just a little bit bigger, then the sum will always have to be finite.
00:39:58.994 - 00:41:21.374, Speaker B: So if you have an LPA zero set, then for any epsilon, this sum would have to be finite. And notice now that even though we do know that the LPA zero set condition doesn't need to depend on the index p, neither one of these two conditions does depend on pull. So there is a whole lot of difference between these two conditions. All right? So Horowitz also showed some other results about zero sets, namely that subsets of zero sets with zero sets for fixed index p, he showed that the union of l two, l two a zero LPA zero sets may not be an LPA zero set. Of course, if you take the union of two LPA zero sets, then you have Lp a function u that's zero on the first set, and LPA function v that's zero on the second set. And the product is a lp over two a function, and it's zero on the union of the two sets. So, but he actually showed that you cannot do better than p over two with the union of two lp a zero set.
00:41:21.374 - 00:42:35.254, Speaker B: On the other hand, the result already mentioned that since the product of two l two a functions gives you all the l one a functions, the unions of l two a zero sets is exactly the union of l one a zero sets. Shapiro and shields, in the paper that Tom also mentioned in early sixties, proved another type of condition on the zero sets for the Bergmann spaces. Namely, if you assume that all the zeros of your Bergmann function lie in a non tangential approach region, so I'll call that lambda c. The c here is a parameter that tells me how wide the opening of this is, and then it's sort of ice cream cone looking region that has a vertex at the point z naught, which is a point in the unit circle. If all your zeros lie in there, then the sequence will have to satisfy the blaschky condition. And the proof of that result is also very simple. So I'll prove it to you here at the point where zero is equal to one.
00:42:35.254 - 00:43:24.294, Speaker B: So there's your ice cream cone, and I'll draw this auxiliary region r, the blue circle. It's a circle centered at one half and radius one half. So it's tangent at one, and that's that circle. And it turns out it's already mentioned by Tom. This is an oracyclic approach region at one. And so there's a small algebraic calculation that you can do that says that you can also represent this region by this condition, that the absolute value of one minus z quantity squared is strictly less than one minus absolute value of z squared. And so we now consider the function one minus z to the four over p power times f of z.
00:43:24.294 - 00:44:28.404, Speaker B: So f is this function that has zeros at the points lambda n that all lie in this non tangential approach region and our auxiliary function g. Now is this new function and its absolute values in the region in the blue region satisfies this inequality, that because the one minus absolute z squared is less than one minus z, absolute z squared is less than the f, and this to the two over p. And then we had this estimate on the pointwise estimate on the LPA functions, which said this is always less than the norm of the function p. So that means that the function g is bounded in this region r. So now that means the zeros of the function g, which are just some of the zeros of the function f. This extra factor here is not never zero. So there's only finitely many zeros in the part in the non tangential approach region that are not in g in r.
00:44:28.404 - 00:45:40.884, Speaker B: And so that means the zeros of g will satisfy the Blaschke condition with respect to this new circle here. So, for example, if the points lie on the radius, then it's very clear that they'll have to satisfy the Blaschke condition by themselves. But even if they don't lie on the radius, then you can take the conformal map from this little disk, move it over one half unit, blow it up by factor of two, and you get an analytic function in the disk, the non tangential approach region. That conformal map is just a linear map. So it takes this angle to another angle. So it doesn't change the fact that if the lambda n's lie in the non tangential approach regions, then the zeros of this new function lie in some non tangential approach region. And then you do just a calculation and it tells you that the Blaschke sum of the lambda M's, which by the reverse triangle inequality is less than one minus lambda n's and absolute values, and is bounded by the Blaschke expression that you get for the w ends.
00:45:40.884 - 00:46:45.084, Speaker B: Alright? So that's the proof of the Shapiro and shields result. And it, as a corollary, tells you that there can be no description of the LPA zero sets. That only depends on the moduli, because if you had such a condition, then the moduli would have to satisfy the Blaschke condition. And we know that's not the case. All right, now then, what can you do? All right, so if you look at this argument, of course, it tells us that if you have unions of finitely many non tangential approach region and all the zeros lie in there, they have to satisfy the Blaschke condition. But now this Blaschke expression here gets bigger. And so if you want to take a union of infinitely many of these non tangential approach region, then you will need to do a quantitative version of this estimate.
00:46:45.084 - 00:47:44.518, Speaker B: All right? When you do a quantitative version of this estimate, then remember what mattered somehow, what was related to the blasgarch per was the value at zero of these functions. And that comes up in Jensen's formula that you used to derive the Blaschke expression also. So you need the value at zero of these functions. Well, the value at zero of the h is the value at one half of this function g. And there you have the related to the function f that we started out with. We have this, this factor here, one half to the four over p. And so as you start wanting to do a quantitative version of this argument, what you find is that you'd want to make sure that you do as well as you can in the power here, the four over p.
00:47:44.518 - 00:48:35.630, Speaker B: And so you might want to take approach regions rather than then circles that have approach one. You may want to try regions that have tangency that's between one and two, like you take a power one plus epsilon or something like that. And that's what Horowitz did. And then he used some sort of estimates on conformal mappings that were known to, to get a quantitative version out of this. And then this was improved by SAP later on. And what they came up with is a condition that's almost necessary and sufficient. And so what they do is.
00:48:35.630 - 00:49:04.844, Speaker B: So let's take the gamma c at a boundary point. So we take f to be a finite subset of the unit circle. And then we, for each of these points in f, we form this Stoltz region. That's the non tangential approach region, the ice cream cone. And you take a union of these things. So you get what's called the stolse associated with this function f. And then you want to count all the zeros that are in the stall.
00:49:04.844 - 00:50:17.296, Speaker B: And then it turns out when you do this quantitative version, this Carlasson entropy shows up. So you have this finite subset, you take the complementary arcs, and you form this expression here, which is related to something that came up in the definition of the Carles and thinsets that Tom was mentioning in his talks. That comes up when you want to construct analytic functions that are zero on the set f, and you want to have control on there certain norms of them. And then as you take the ratio of these things and take the lim soup, as you take the finite sets going to infinity, the coliseum characteristic going to infinity, you call that the upper density. Now, because a stole star depends on the opening angle of the non tangential approach region, this expression appears to depend on c. But in fact, Kornblum shows it does not depend on c. And they show, Kornboom and SAP show that.
00:50:17.296 - 00:51:23.584, Speaker B: In fact, if you have a sequence in the disk, and if the upper density is strictly less than one over p, then it is an LPA zero set. And conversely, if it is an LPA zero set, then the upper density has to be less than or equal to p. So the case that's open is when the upper density is equal to one over p. All right, now, if you want to read about this, obviously, this is a difficult proof. In the book by hidden man, Kornbroom and Zoo, they have a nice approach to this where they don't use these things that I was talking about with the conformal mappings. They instead use estimates on harmonic functions on these approach regions there. And so it's a little bit easier than going back to the original papers when you read the proof of this in the background in the book, but it's still very complicated proof.
00:51:23.584 - 00:51:27.224, Speaker B: Okay, so that's my first talk.
00:51:36.324 - 00:51:54.264, Speaker A: Okay, so does anybody have any questions? You can either put it in the chat, and we'll try to keep track of it, but there are 123 of you, so maybe it's just easier if you just interrupt and shout out your question.
00:52:01.844 - 00:52:49.184, Speaker B: Can I ask Bill my question? Oh, yeah, go ahead, Stefan in the setting. There are conditions based on the argument of Zn, which guarantees it's a sufficient condition. The argument which says that if this condition is satisfied, then it is a zero set. Do we have something similar in the Bergmann space setting? Well, there are. I mean, so I didn't talk about sampling sequences and interpolating sequences at all. But there are some theorems that say that if the zero set is. Is somewhat more regularly distributed, then.
00:52:49.184 - 00:53:11.644, Speaker B: I mean, if the sequence is more regularly distributed, so if they're. If they're uniformly separated, for example, then there are simpler conditions and they turn out to be necessary and sufficient. But just sort of in general. I'm not aware of this.
00:53:12.904 - 00:53:16.512, Speaker A: Stefan. There are two questions in the chat. I don't know if you can.
00:53:16.608 - 00:53:51.714, Speaker B: Okay, I can see the chat now, is it possible to define Bergman's basis for compact surfaces like the Riemann sphere? How compact Riemann surfaces? Yes. You can, of course, define any time you have a measure, or you can define a weighted measure, if you like, on any space, and I'm sure I'm not aware of actual results on this, but then you'd want to consider the Bergmann kernel in these regions. Yeah.
00:53:52.094 - 00:53:55.594, Speaker A: And there's one more question in the chat just above that.
00:53:57.214 - 00:54:18.954, Speaker B: Yeah. So when the density is equal to one over P, as far as I know, that is open. So if something happened. I was saying that many papers in this last 15 years, or last two years even, have been written. I think I might have heard about this, but I'm not aware that it's been solved.
00:54:23.414 - 00:54:30.174, Speaker A: Okay, why don't we take a five minute break to get geared up for the next talk?

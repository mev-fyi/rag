00:00:01.880 - 00:01:23.094, Speaker A: Good. This is it, the last thrilling final lecture of this class. Thank God I'm done. So, yeah, I'm happy to reach the end of this. Today we shall examine the sphere sitting inside of Cn. Mostly, it's an example of a contact manifold. And so we will use this one example to explore a little bit about some of the generalizations of this theory of scalable operators that we've been discussing without getting, hopefully, into too much detail.
00:01:23.094 - 00:02:39.622, Speaker A: And the story begins in the 1960s with not the sphere, but the ball. And the problem was to say something about the complex, like the Durham complex, the Dolbeau complex, on the. Not the sphere, but on the interior of the sphere. So if you change notation, there it is. If you examine. Oh, yeah, we need that. We need.
00:02:39.622 - 00:03:46.994, Speaker A: Oh, dear. Were we okay? He was correctly lined up. To begin with. If you examine differential forms on the ball inside of Cn, so the two n dimensional unit, open unit ball, let's say, inside of cn, then these forms break up into, well, not in degree zero, but in subsequent degrees into types p comma q. They're not just r forms, they're p comma q, with p plus q equal to r forms. And so there's a complex. And the easiest part of the complex is this part here, which is, if you like, a complex analytic version of the Durham complex.
00:03:46.994 - 00:05:02.440, Speaker A: And so inquiring minds wanted to know something about the analysis of this complex, and in particular, the hodge theory of such a complex. Can you do operator theory with this complex in the same way that you can do operator theory with the Durham complex? You can break up differential forms into harmonic forms and each and their complement and each chromology class is represented by a unique harmonic form. Okay, so this is what people wanted to study for reasons having to do with complex analysis. For example, one of the things that emerges eventually out of this study is proof of the famous new land and ironburg theorem, which tells you when a manifold really is a complex manifold. And someone wanted to study this thing here. Yeah, yeah. That is a theorem.
00:05:02.440 - 00:06:01.044, Speaker A: It has to be proved, and it's not a simple theorem to prove. And the sort of analysis that was carried out on this complex that we're going to talk about in the most superficial possible way, that that sort of analysis leads to a proof of the new land and Arenberg theorem and other results in complex analysis, too. But you see, what makes this complicated is that this ball has a boundary. What's the sphere? The very sphere that we were talking about before. So we're not doing analysis on a closed manifold, which is where, you know, soft, weak, pure mathematicians like me like to be. It's on a manifold with boundary. And that makes the whole thing a lot more complicated.
00:06:01.044 - 00:08:16.146, Speaker A: And there's another complex that you could build which lives on the boundary, and it's based on the following observation, that inside of each point, inside of based, excuse me, inside of the tangent space, at each point on the sphere, there's a distinguished two n minus two dimensional subspace, a co dimensional one subspace. It's just all of those tangent vectors with the property that I times them is still tangent. Multiplication by I is an operator on the tangent space at p not of the sphere but of the ambient complex space. And when you multiply by I, when you rotate, so to speak, by 90 degrees, some vectors will rotate out of this space, which is tangent to the sphere and become normal to the sphere. And so that's what we're eliminating by making this definition. So you have, let's imagine, for example, we look at the three sphere inside of c two. There should be a two dimensional subspace of the three sphere, and what it is is the orthogonal complement of the one dimensional space inside of the tangent space that you get by taking the normal vector and rotating it, multiplying it by I.
00:08:16.146 - 00:08:46.202, Speaker A: So I times the unit normal vector at any point is tangent to that point because it's orthogonal to the normal vector. And inside the tangent space you can look at the orthogonal of I times the normal vector. Everything's orthogonal to the normal vector by definition, but not everything is orthogonal to I times the normal vector. And that's what we're talking about here. And so there is this subspace, really.
00:08:46.258 - 00:08:49.894, Speaker B: Stupid example of, if you look at s one.
00:08:52.314 - 00:09:48.954, Speaker A: Yeah, this is the zero subspace, so it's not terribly interesting. Actually, what we're going to talk about is also it's not exactly not interesting, but it's harder to think about. Even in the c two case, the easiest theorems come to life in c three. So for the five sphere and c three, as we'll see in a moment. All right, so now you can do the following thing. You can look at differential forms, meaning sections of the bundle which is dual to h, and the various exterior powers of h. Here's the 0th exterior power.
00:09:48.954 - 00:10:39.684, Speaker A: That's not very interesting. And then we can get more interesting ones, of course, by going a little higher. So there's a d bar operator down here. Maybe we'll call it d bar h. And it stands to reason that if you're interested in forms on the ball, you might be interested in forms on the closed ball. And if you're interested in forms on the closed ball, you might be interested in their restriction to forms on the boundary. In which case you'd be interested in this complex here.
00:10:39.684 - 00:11:55.474, Speaker A: I don't think it takes much imagination to believe that if you're interested in doing complex analysis on a ball, you'd be interested in also studying this complex here. Okay, and motivated by, let's call it box. Motivated by the classical theorems in the world of Durham differential forms, or in the world of these forms up here on a closed manifold, you might attempt to study the following Laplace operator, namely d bar. D bar. Maybe I'll call it d bar h as I did before. Oh, h means this family of subspaces, this vector bundle, it's just a. Oh, it means.
00:11:55.474 - 00:12:52.998, Speaker A: Well, this is just functions. This means smooth sections of the dual bundle, this means smooth sections of the second, actually smooth sections of the complex conjugate of the dual bundle, smooth sections of secondary exterior power of the complex conjugate of the dual bundle, etc. Etc. Etcetera. D bar is this Cauchy Riemann operator ddx plus iddy that you whose null space consists of holomorphic functions? I forgot to say that maybe I took it for granted. The value of this operator d bar, or whatever it is, is that the criterion for holomorphicity, a function on the ball is holomorphic, if and only if d bar of it is equal to zero by the, that's the, the Cauchy Riemann theorem. So you want to study the D bar operator from functions to one forms because it's an L space's holomorphic functions.
00:12:52.998 - 00:14:18.084, Speaker A: And in higher dimensions, once you've committed to studying this d bar operator, you really have to study the lot of them. That's just the way calculus works out. If you're interested in holomorphic functions, you ought to study this famous D bar operator, which in local coordinates just looks like ddx plus I ddy one half of ddx plus iddy. And if you're interested in the D bar complex on a ball, you ought to also study this d bar complex on the boundary of the ball. And if you're interested in this d bar complex on the boundary of the ball, you ought to be interested in this operator. That's the point I'm trying to make, that a simple chain of reasonable, plausible steps leads you to this operator here. Okay? And you might ask whether you can do for forms on the boundary these special sorts of forms on the boundary, what it's known you can do on a compact romanian manifold, namely associate to each chromology class in the chromology of this complex, an actual harmonic representative, an element in the kernel of a function or a form, which is in the kernel of this operator in a unique way.
00:14:18.084 - 00:15:11.304, Speaker A: And it's kind of interesting how this works out. So the answer is yes and no. And of course. And so the easiest theorem to state is the following one. So p here will refer to the index of the forms zero p forms. And if you're in this range between zero and n minus one exclusive, then something rather interesting happens. How many of these spaces are there? There's a zero zero space, a zero one space, a zero two space.
00:15:11.304 - 00:16:49.404, Speaker A: The top one is the zero n one space on the sphere, because this bundle h is n minus one dimensional as a complex vector bundle. Back here, the top dimension is n, but on the boundary, the top dimension is n minus one. And so these are the extreme cases. And this theorem, which is what Cohen proved sometime in the middle of the 1960s, that's why I said, well, I guess I just said sixties up there, I think this is from 65. So this operator box maps the conal placid maps p forms to p forms. And so you can just restrict it and ask how does it act on p forms, not including zero forms, which are just functions? It's maybe where it's most interesting, but all of the higher ones. And this operator has a pseudo local parametrics, to use language that we've discussed way, way back in the dark, not dark, but bright early fall when it was warm outside, we were all optimistic and young, we discussed these quant, these concepts, pseudo locality and parametrics, and these operators have them.
00:16:49.404 - 00:18:20.990, Speaker A: And so in this range, this operator is hypo elliptic and more. What is q? Q is p. I mean isn't. Thank you, sorry. And this theorem, which is important in the world of, I gather, in the world of complex, what do I know about complex analysis? This theorem, which is important, has been examined again and again and again. And so what I'll describe to you is, I think, what's the standard party line on this theorem now, which is not what Cohen did, it's what Poland and Holmander and many other people did to simplify, streamline the proof of this theorem. And in order to explain what's going on, maybe we'll, we'll just because we had so much fun over the last several lectures with Lee groups, let's just trot in a Lee group for an encore appearance, I wrote, I gave some examples in the notes of non trivial reductive lead groups.
00:18:20.990 - 00:19:16.144, Speaker A: I gave SPN one or actually sp eleven as an example, not thinking ahead, because what I'm going to describe is sun one, the sort of little, little brother of SpN one. But anyway, so let GBSU n one, which I'll tell you what it is in just a moment. And just for your, I could use un one. The s always means some matrix has determinant one, and that's not really the issue in this discussion. But anyway, this is a real reductive group, semi simple group of real rank one. So it's one of the groups we were just discussing. But that's just a parenthetical remark because we're not going to do representation theory with this group.
00:19:16.144 - 00:19:36.204, Speaker A: We're going to just do a little bit of geometry, a bit of lead theory with this group. We are going to do some representation theory, but not with this group, with some other group. Oh, first of all, what is it? Maybe I should tell you that.
00:19:38.464 - 00:19:38.848, Speaker B: Before.
00:19:38.896 - 00:20:44.194, Speaker A: I tell you what it does. So it's just matrices, invertible matrices of the right size, which is n plus one by n plus one with complex entries, let me call them t. What I'm going to write down here is a version of the identity matrix with n ones down the diagonal and one minus one like this. So it's like, yeah, that's what it is. And the condition on t is that it should preserve, in the sense of quadratic forms should preserve this matrix. Oh, and because the s condition, the determinant is one as well. So that's what this group is.
00:20:44.194 - 00:22:14.214, Speaker A: And if you have a matrix t, it's kind of natural to write it in block form as an a, b, c, d, like this. So a is an n by n matrix and b has what? N rows in one column and c has n columns in one row and d is just a one by one matrix, then this thing acts on the disk, excuse me, the bore, and for that matter the boundary of the bore in the usual way, just by fractional linear transformations like that, I'm dividing here by a one by one matrix, because I'm multiplying a row against, I'm thinking of z as a column vector. So the product of c and z is just a one by one matrix. So the numerator there is just a number and excuse me, that's the denominator, isn't it? The denominator is a number and the numerator is a vector. Sometimes the denominator can be zero, but if the denominator is zero, the numerator is also zero. And the whole thing may makes perfect sense. And it's a diffeomorphism from the closed ball to itself.
00:22:14.214 - 00:22:41.662, Speaker A: In fact, these are the only diffeomorphisms of the closed ball to itself, which preserve the complex structure. Ah, almost. That's true. Or maybe it is true. Yeah, I guess it is true. I was worried about the s, but what I said is true. Okay? In fact, this does have a point.
00:22:41.662 - 00:23:34.654, Speaker A: So the action on the boundary is transitive. The action on the interior is transitive too, but it's the boundary we're interested in right now. So what the sphere looks like is g divided by some isotropy subgroup, and the isotropy subgroup is our friend P. I mean, just for fun, we're not going to do anything where p is the non trivial parabolic subgroup. When we were mucking around with real reductive groups, we used this famous Iwasawa decomposition maximal compact subgroup. This is the unitary matrices in G. This was a, it happens, one dimensional maximal abelian group consisting of positive definite matrices.
00:23:34.654 - 00:24:25.062, Speaker A: And the n was some nil potent group, which is what we'll get to in a moment. Anyway, p was the corresponding parabolic subgroup, some m a n, like that. And it's a fun exercise to see that g mod p is a sphere. So maybe that makes what we were doing before a little more concrete. Principal series representations that we were talking about in this particular case are functions or sections of vector bundles over this particular odd sphere. Okay? Now, in representation theory, you always call the following things something like n bar. But what I mean by this is just the adjoint of n.
00:24:25.062 - 00:25:49.794, Speaker A: So just the set of all of those t in g, such that t is in this n subgroup. You take the Li algebra of G. Then you can break it up as the Lie algebra of n plus the Lie algebra of m, which in this case is a circle group, plus the Lie algebra of a, which is a line. So this is one dimensional, this is one dimensional plus n, like that. So that's a direct sum of the vector spaces. Each summer's a lie algebra, but they don't all commute with one another. We get the following thing that if you exponentiate and you look at the groups, I already told you what p is.
00:25:49.794 - 00:26:55.106, Speaker A: This thing here is an open dense subset of g, or if you like, n bar times the class of p in this homogeneous space, g mod p, there's an open dense subset of g mod p. So what this sphere looks like is, is a copy of n plus a little bit extra. If we were to drop down, maybe. I don't want to do this. I'm just going to take it back. I was going to talk about an analogous story, but it involves a different group and I think it'll just be confusing. It's like taking the two dimensional sphere.
00:26:55.106 - 00:27:21.174, Speaker A: Two dimensional sphere is the Riemann sphere. It looks like a point at infinity plus a copy of c. So there's a part that just looks like a copy of c, and then there's a point to infinity. And that's kind of what we're talking about here. There's a part which looks like a euclidean space, a three dimensional manifold home diffeomorphic to r cubed. That's the n bar part. And then the rest is some other thing that we don't particularly care about here.
00:27:21.174 - 00:28:53.274, Speaker A: So if we're trying to do geometry on g mod p or analysis on g mod p, which we are according to what's written here, it's like doing analysis on this nil potent group n bar. And as for n bar, I'm going to write this down because, damn it, I did the calculation and I'm just going to inflict the answer on you. This has no relevance for anything except it proves to you that I can multiply three by three matrices together. So let me just do the case here where n is two. This is the case which is pertinent to a three dimensional sphere. And, okay, you can amuse yourself or not, depending on your, I don't know, state of mind, and you can calculate what's in n. What did I say? Two.
00:28:53.274 - 00:29:27.800, Speaker A: I zero, two. I think of these as block matrices with a two by two block down the diagonal and a one by one block. And what you write on the diagonal blocks always has to be skewer joint. That follows from the definition here. But what you write in the off diagonal blocks always has to be self adjoint. So that's a clue. It tells you when you made some horrible mistake, which I made many times until I came up with this.
00:29:27.800 - 00:29:58.024, Speaker A: And then I stopped. I mean, the matrices had the right form, so I stopped multiplying three by three matrices together. Okay. And if you call these fellows x, y and z, then actually, I'm not sure about the order in which I wrote these down. Either the bracket of x and y is z, or the bracket of x and y is minus z. And that's it. That's the only non trivial bracket relation.
00:29:58.024 - 00:31:29.144, Speaker A: So this thing is the notorious Heisenberg Liaodzka, and the same thing is true in any dimension. You don't have to multiply matrices to check that. You can argue using root systems that it has to be at the Heisenberg liautchments. Quite easy, but this is what it is in this particular case. So the grand conclusion, which I guess I could write here, doing a similar calculation, or an easier version of it, easier but more sophisticated version of it in any dimension. This thing here is locally a Heisenberg group, the Heisenberg group of dimension two, n minus one. And how to write that h two, n minus one, I don't know.
00:31:29.144 - 00:33:03.262, Speaker A: That's the dimension of the overall dimension of the group. What does it mean? What kind of structure is preserved when you pass from the sphere to n bar? Well, this structure that we were discussing, this collection of hyperplanes, h, is easy to keep track of under these diffeomorphisms. So the identity, you can figure out what, maybe I'll just say here, what is the algebra? So there's a bunch of x's and a bunch of y's, and then the bracket relations, the only non and z, and the only non trivial brackets are that xi times yi. It's z. No, I guess it's the span of these guys. That's what I'm trying to explain. First of all, I just mean there's a diffiemorphism, a local diffiemorphism from an open den.
00:33:03.262 - 00:33:24.062, Speaker A: Given any point in the sphere around that point, you can find an open set and a diffumorphism from that open set to the Heisenberg group. Well, big deal. This is just a manifold. This is just r to n minus one. So of course you can do that. But now I'm going to tell you that there is a diffiemorphism with a decent property. So that's what I mean by locally.
00:33:24.062 - 00:34:55.674, Speaker A: So it's a good question, which I haven't answered yet, but now I'm trying to answer it. Okay, running out of space here at the base point. You can do the math yourself. And what you'll find is that the distinguished hyperplane is exactly the one spanned by these fellows. And the collection of all hyperplanes is actually, it's invariant under this group g as it acts on g mod p as it acts on the sphere. But in particular, it's invariant under n bar. Yeah.
00:34:55.674 - 00:36:04.082, Speaker A: Oh, thank you very much. I certainly do. Is g and hence n invariant. So the sphere together with its hyperplane bundle is, which is a, just remember, it's a sub bundle of the tangent bundle of the sphere is locally, is now locally diffumorphic. The Heisenberg group. Let's do the following thing. There are so many h's, at least temporarily.
00:36:04.082 - 00:36:16.974, Speaker A: Let's call this something a little more informative than h. Let's call it ice or Heisenberg, like that. What's that?
00:36:18.034 - 00:36:20.774, Speaker B: I don't like the thought about dots, but they're imports.
00:36:23.994 - 00:36:38.926, Speaker A: Oh, this thing. Well, I'm the professor here, so I'm not going to deduct any points. I mean, when you're writing this, well.
00:36:38.950 - 00:36:40.894, Speaker B: It makes sense on the board. It doesn't make sense on board.
00:36:40.974 - 00:37:59.394, Speaker A: Yeah, I agree with that. Yeah. Locally diffeomorphic to. Now, the Heisenberg group, in this case of dimension two, n minus one. And the collection of bundles here is the Heisenberg invariant left under the left action Heisenberg invariant subbundle generated by this particular space here. Where is it here, the above span at the identity. The whole business of building this cornel Laplacian involves this collection of vector bundles of this collection of hyperplanes inside of the tangent bundles in the world of the corona Laplacian.
00:37:59.394 - 00:38:46.280, Speaker A: These fellows all have complex structures. Well, so do these have, where are they here? This span, real span, also has an obvious complex structure in which I times x is y and I times y is minus x. So for better or for worse, and the jury is out at this moment in the lecture, the whole problem of understanding this operator, which is the cone Laplacian, can be modeled by a similar problem in which the, the underlying geometry is the geometry of a Heisenberg group, not a sphere. So it's not. It is. It could be about sun one, or it could be about spheres or unitary groups or stuff like that, but it can also be about the Heisenberg group. And of course, the jury is out whether or not that's a good idea.
00:38:46.280 - 00:39:02.164, Speaker A: But you could do it this way and attempt to use some Lee theory to understand this Heisenberg, Laplacian and Cone's theorem. Excuse me, this cone, Laplacian and Cone's theorem somehow using nilpoten groups. And of course, that's what we're going to try to do. Yeah, sorry.
00:39:05.584 - 00:39:09.724, Speaker B: So when you say it's locally a Heisenberg, you can just compare sqn.
00:39:09.764 - 00:39:10.384, Speaker A: Yeah.
00:39:11.044 - 00:39:15.384, Speaker B: There's a diffian morphism thinking sqn minus hydrometer group, which also like.
00:39:15.844 - 00:40:04.454, Speaker A: Exactly. Yeah. For any point in here, there's an open subset around that point and a diffie morphism from that open subset to, let's say, an open subset of the identity in here, which carries, whose derivative carries this hyperplane family of hyperplanes, this bundle, sub bundle of the tangent bundle to the one that's described here. Yeah, well, they're like Mobius transformations. Yeah. Everything sits inside of this group, G. Yeah.
00:40:04.454 - 00:40:33.554, Speaker A: Yeah. These are diffeomorphisms. The Heisenberg group, they're not, they're not autumn. I mean, it's not, they don't preserve the group structure on the Heisenberg group. They just preserve this hyperplane bundle. But there's a finite dimensional family of them and they all come from G. And I cannot say anything more informative than that off the top of my head, so we'll leave it at that.
00:40:33.554 - 00:41:22.874, Speaker A: All right, good. So our attention was supposed to have, you know, perked up at the mention of pseudo local parametrics because that's what the entire first half of the course was about. And our attention is almost going to perk up again when we think about all of this stuff. There's one extra ingredient that needs to be written down somewhere. Maybe we'll keep Cohen where he is. So we bid a fond farewell to sun one. It's fun to calculate in these examples, but I mean, it's not an intrinsic, as far as I know, it's not a.
00:41:22.874 - 00:42:04.762, Speaker A: It's not an intrinsic part of the subject. It's. I just brought it in because we made an investment in reductive groups. Okay, I guess my point I'm trying to make is that it's not obvious that the story of Cohen's operator has anything to do with nil potent groups, which it does. But one way of illuminating that is to use this little theoretic discussion to come up with the nil potent group. Okay. And then we'll see what's going on.
00:42:04.762 - 00:43:26.754, Speaker A: The nil potent group certainly speaks to this family of hyperplanes, h, in the way that's just described here, whether or not it speaks to Cone's theorem. That's what we're going to discuss. And on one of these Heisenberg lie algebras to begin with, there's a family of endomorphisms parameterized by t, t and r. We didn't have to go all the way over there. I'll go this way. Well, let me do it this way first. So these are just l algebra maps which smoothly vary with t.
00:43:26.754 - 00:44:55.670, Speaker A: And what are they? Well, all of the x's go to t times x and all of the y's go to t times y. But the lead bracket of x and y is z z in this country. So if you want this to be a lie algebra endomorphism, z has to go to t squared times z, like that, okay? And these fellows extend, or rather exponentiate exponential and shared to a family of mostly automorphisms. Alpha zero, of course, is kind of degenerate. But apart from that, these are automorphisms of a Heisenberg group to itself. And now it looks awfully like the situation that we were confronting earlier on in the class when we built the tangent groupoid. In order to build the tangent groupoid, we needed some reasonable geometric space.
00:44:55.670 - 00:46:01.588, Speaker A: Well, that was just rn and we needed a family of rescalings of that reasonable geometric space that was just multiplication by t. And apart from the t squared here we're in exactly the, the same situation. And if m denotes just the Manifold underlying the Heisenberg group. So this is just a copy of two n minus one dimensional Euclidean space. But I just want to think of it here as a Manifold for a moment. We can define a groupoid exactly like we did in the class. So it'll be a bunch of triples, actually, quadruples.
00:46:01.588 - 00:47:01.120, Speaker A: A point in the manifold, an element of the Heisenberg group, another point in the manifold, and a number t. And the condition is you can get from m one to m two by multiplying by h after you've rescaled it by alpha t. I mean, apart from telling you where these various bits and pieces lie, that's the, that's an object. And it's a groupoid. It's actually an action groupoid. What's going on here is that the group h is acting on the manifold m times r, like we were discussing before. And this is the action groupoid, the transformation groupoid.
00:47:01.120 - 00:48:35.946, Speaker A: And there are source and range maps which are kind of obvious from th of m down to m times r. One of them, the range one sends to, sends this, what is it? A four tuple to m two comma t. And the source sends it to m one comma t. And of course, there's a composition law too, which is hopefully self evident. I'll write it out anyway, like that. And we got ourselves a groupoid just like we had before. And what this depends on is not the, it's a bit exactly like what we saw in the world of regular manifolds.
00:48:35.946 - 00:51:06.534, Speaker A: This doesn't actually depend on M being a Heisenberg group, despite all of these group multiplications, like you see, where is it in the definition up there. And all of these rescalings, this only depends on m together with this hyperplane bundle, which is to say that if you have a diffeomorphism of m or a local diffeomorphism of m, which preserves the hyperplane bundle in the sense we were describing before, it naturally gives rise to a diffeomorphism between, well, parts of it. It's a local diffeomorphism, parts of the tangent groupoid, this h tangent groupoid. So we're in exactly the same situations before, and we can define this object for any m which is locally a Heisenberg group. So any m together with a hyperplane bundle, that is, in the sense we've been discussing locally Heisenberg. And this new object, like the old object, whatever m is, carries the zoom action of the group of positive real numbers as automorphisms of groupoids. If you're dealing with positive real numbers, I'll just write it like that.
00:51:06.534 - 00:51:47.254, Speaker A: What is alpha Lambda of gamma? Well, it's what you might expect from these fellows here. I think there's really only one way you could define it. So it's exactly like we were. It's that we have the same ingredients that we had before a certain groupoid. The groupoid is equipped with a one parameter group of automorphisms, the groupoid. It's a family of groupoids over the real line. And now we can define families of operators on the source fibers of this groupoid, which are equivariant and almost invariant or covariant under the zoom action, in the sense that we were discussing when we were talking about scaling families, and we can see what happens.
00:51:47.254 - 00:52:34.962, Speaker A: I just had a question Bob did. It's not exactly what they did, because they already knew what to do to build an interesting calculus, but they wanted to build it better. And it's an interesting feature of the work we were describing that it carries over immediately to this situation. Should I add a question almost immediately? There's one thing that needs to be mentioned as we proceed. So we have an object which is a Lee groupoid, and it's very like the lead groupoid we had before. It has more or less the same groupoid action as before. It has exactly the same space of objects as before, m times r, and we can define exactly as we did before, scalable operators.
00:52:34.962 - 00:53:04.154, Speaker A: And let's see what happens. Oh, thank you. I think he cannot hear you. Us. That's absolutely right. I cannot solve that problem. But if you want to ask a question, you can type it.
00:53:04.154 - 00:54:12.198, Speaker A: I do and Paul, you can read it and then you can ask it. I really do. Okay, at least I'm audible. So that's much better than usual. Okay, so the main, the main objects that came out of this previous study were what we call scaling families of order r. So those were families of operators on the source fibers, which we call them a's. I'm going to write m sub mt like I did before, to indicate the source fiber over the particular object, which is m t.
00:54:12.198 - 00:55:18.696, Speaker A: Where are the objects up there? So as we were discussing, oh, now there's an actual question. How is the Heisenberg group different from a group? Well, Heisenberg group is a group is the Lee group. Are you asking why is it special among groups? If you're asking that, then the answer is that what makes the Heisenberg group special among groups is the fact that there is such a one parameter family of automorphisms. Okay, good. I'm answering the right question. If you have such a one parameter family, maybe I should call them of endomorphisms, because something goes wrong at t is equal to zero. The lie algebra of the Heisenberg group has to break up, assuming that the, the action is non trivial everywhere.
00:55:18.696 - 00:56:08.228, Speaker A: It has to break up as a part of the Li algebra where the action is multiplication by t, and then another part where the action is multiplication by t squared. And in general, you could envisage in a more complicated situation, maybe there was a third part where the action was multiplication by t cubed, and so on. Not sure how to say this. There is. And so the Li algebra, whatever it is, is not just a lie algebra. It comes equipped with some extra structure which tells you where the action is multiplication by t and where is multiplication by t squared and so on. And that's a decomposition of the Li algebra into vector subspaces with the property.
00:56:08.228 - 00:57:03.320, Speaker A: And they're indexed by integers, positive integers and the property, the crucial property, because we want to exponentiate to regroup automorphisms. The crucial property is that the Li bracket of Hj with Hk should be inside of Hj plus K. If you have a Lie algebra, and it does have a grading like that, it has to be a nil potent lie algebra. So that's why we were casting around to find a nil potent retrospectively, why we were casting around to find a nil potent group, because it's only nil potent groups which can be broken up in this way so that we can build such a one parameter family of initially endomorphisms of the Li algebra, which then may be exponentiated to the lie group. So, inside of highs one, just to make it clear, that is x and y, all of the x's and all of y's. And inside of highs two is just the z. You have to be in the world of nilpotent lie algebras to do this.
00:57:03.320 - 00:57:07.388, Speaker A: And that's why we are in that world bracket.
00:57:07.476 - 00:57:14.344, Speaker B: Like necessarily is. Are you sort of envisioning that there's also a highest three, which is just zero?
00:57:14.724 - 00:57:21.704, Speaker A: Yeah. Yeah. Yeah. Yeah. Right? Yeah. You? Yeah.
00:57:22.484 - 00:57:26.304, Speaker B: It's like you could imagine that just landed to say.
00:57:30.964 - 00:58:03.978, Speaker A: No. If the action on highs two is multiplication by t squared, and you take a Lee bracket of two things in t squared, then on the Li bracket, the action has to be multiplication by t to the fourth, so you're not allowed to stay in t squared. If this is an actual action by lie algebra endomorphisms, then the bracket of something in t two and something else in t two has to be somewhere else, namely in h four. And eventually, no matter how big the nil potent group is, just by finite dimensionality, these guys have to be zero.
00:58:04.146 - 00:58:07.122, Speaker B: Is there a situated looking for one?
00:58:07.298 - 01:00:01.994, Speaker A: Maybe, but that's, you know, that's a whole other suitcase of trouble, isn't it? So, I don't know what one might expect then. Okay, so these fellows are supposed to be smooth in a sense that we discussed earlier. It's supposed to be an equivariant family for the groupoid action. And the crucial thing is that when you maneuver, these operators transform from one fiber to another using the zoom action. What you get is, oops, almost what you started with, plus the smoothing operator, which depends on m and lambda and t exactly as before, you can just make definitions. Does it do you any good to make such definitions? Well, let's go back to our friend, which was the conal placid, which is up there acting on p forms of this funny h type. Of course, this is an operator acting on some equivariant vector bundles.
01:00:01.994 - 01:01:02.738, Speaker A: So this is really a matrix of operators, not an actual operator, but let's just ignore that. And you get an example out of the conaloplasty on any one of these manifolds, which is locally Heisenberg and I guess it has to admit, also a little bit of complex structure in order to be able to define the conal Laplacian. Now, here's what you do. If you take a. What did I write it? Empty. If you define this to be t squared times the cone Laplacian. When t is not zero, then you get a family of operators which is only partially defined because I didn't tell you yet what happens when t is zero.
01:01:02.738 - 01:02:15.374, Speaker A: But this family of operators does have an extension now to t equals zero. And what you get at t is equal to zero is kind of interesting how to write this this way. There's a term which looks like a Laplacian. I'll try and explain what these things are in just a moment. And then there's a term which is lower order, and the z here, z is the bracket of the x's and the y's. And then there's a number which goes right here. And if I remember correctly, this is something like n minus two p.
01:02:15.374 - 01:03:07.290, Speaker A: Yeah, that's exactly what it is. Like that. Oh, there's one other small detail. We're actually writing down the correct formula. There's a one half here that look nicer. So what's going on here? What's going on is that this thing here is a translation invariant operator on the fibers that you get at t is equal to zero, which I wasn't very explicit about the fibers of the groupoid when t is equal to zero. Here's the composition law, and we have the source and range maps.
01:03:07.290 - 01:04:08.316, Speaker A: Well, I described what they were. The fibers are just copies of the Heisenberg group. Strictly speaking, there's some romanian metric in the background. We started off on a sphere, and the metric of the sphere is actually playing a role in telling you what is the Laplacian, because in the formula for the Laplacian, there is this adjoint operator, and that requires you to know what the metric is. So when I take xi squared plus y I squared, there should be some gI's here telling you exactly what this quantity is. But we'll just ignore that. Yeah, yeah, exactly.
01:04:08.316 - 01:04:48.084, Speaker A: In a coordinate chart inside the Heisenberg group, we have a beautiful global picture for what the tangent groupoid is. It's this thing up here. This picture of the tangent groupoid has source fibers which all look like h. And what I'm doing here is what we were discussing when I'm writing this fellow here is what we did when we were discussing usual tangent group mode and usual scalable operators. Namely, we're identifying the source fibers, which here are copies of the manifold m with h by a certain natural diffeomorphism. So that's what's going on. And then you just look at the formula and you see, yeah, there's a smooth extension.
01:04:48.084 - 01:05:45.530, Speaker A: And that's it. So there's one example, a scaling family of order two. And what about some theorems? What are we doing? Doing fine. Once you've defined scale in families like I mentioned, at the top there, you can talk about scale Abel operators. It means single operators which occur at the t equals one in a scale ing family. Scale Abel operator of order seven is what you get at t is equal to one. In the scale ing family of order seven, there's really only one operator when t is equal to one.
01:05:45.530 - 01:07:13.648, Speaker A: And because of equivariance, all of the operators and all of the different source fibers canonically identify with one another. All right, if you have an operator which is of sufficiently negative order, and the sufficientness of the negativity is a little bit interesting, it's actually minus two n. So this is minus one more than the dimension of the underlying manifold, which is two n minus one. Such operators have continuous integral kernels. Why do you get minus two n? Whereas before, which is minus the dimension of the manifold and minus another one? Whereas before, we just had minus the dimension of the manifold. Well, the reason we were getting minus the dimension of the manifold in this theorem was that there was a contribution to all of our explicit formulas from the Jacobian. It's disappeared.
01:07:13.648 - 01:07:50.024, Speaker A: Maybe it's here. Yeah. From the Jacobian of this scaling map. And the Jacobian, the derivative of the determinant of this scaling map is t to the two n, not t to the two n minus one because of the squared here. So that's why it's, the dimension is a little bit off. Any negative order operated therefore, by the same argument that we used. Well, maybe we should put it this way.
01:07:50.024 - 01:08:40.594, Speaker A: Maybe this is the second most important theorem, order minus infinity. Maybe it's the most important theorem operators. If you have an operator which is order minus k for every k, then these are actually smoothing operators. And if you're a c star person, you might want to know that negative order operators on a compact manifold. Compact. And nothing is involved in any of these proofs beyond what we already saw. You just do the same thing.
01:08:40.594 - 01:09:17.489, Speaker A: Well, there's a small footnote that I mentioned that the dimension changed here, but that's it. Yes, another question. Thank you. Can you please elaborate on how the romanian metric plays a role here? I mentioned, just out of honesty, that when you build, it's now disappeared when you build this cone Laplacian. The formula for the cone Laplacian involves not just the curly d operator, which is some canonical thing. It involves the adjoint of the curly d operator d bar star. And the formula for d bar star involves the metric.
01:09:17.489 - 01:09:57.301, Speaker A: In the case we were looking at, the metric on the round sphere. And so that's where the metric comes in. As for these theorems, the construction of the groupoid, et cetera, et cetera, the romanian metric isn't used there at all. The only place the romanian metric enters is in the construction of the conolar placion and this computation. Okay. And strictly speaking, there should be some formula here which involves some adjustment to this formula, which involves the gijs, which I haven't bothered to put in, but that's the only place everywhere else. It's not about the metric.
01:09:57.301 - 01:11:27.818, Speaker A: As we saw, we didn't mention the metric, romanian metrics when we were mucking around with scalable operators in the past. All right, good. If you have on, maybe I should say on L two of m, if m is compact, if it's a compact manifold which is locally Heisenberg in the sense we've been discussing. So m is equipped with this family of hyperplanes, then it's true that order zero operators in this calculus, built in this way, this way up here, using that version of the tangent groupoid over there, they're all bounded. But now, this is not so easy. And if you look back in the notes, you'll see that when we dealt with the issue of the boundedness of what is zero operators in the usual, for usual manifolds, not manifolds with boundaries of hyperplanes and so on, when we dealt with the issue of boundedness, we used the Fourier transform. There was a little calculation, and it used the Fourier transformation.
01:11:27.818 - 01:12:17.880, Speaker A: There's no way of fixing that argument the way I wrote it, so that it doesn't use the Fourier transform. This is actually a difficult point, and in fact, this is also, in fact, not even easy. I'd say it at t is equal to zero. Suppose you have one of the operators that you obtain at t equals zero from a scaling family, one of the operators in the symbol family for this calculus. So that's a translation invariant operator on the nil potent group. So it has a lot of symmetry. If it was a translation invariant operator on Rn, it would be a doddle to use the usual Fourier transform and see for sure when this operator was bounded.
01:12:17.880 - 01:12:56.724, Speaker A: And you'd see right away it's always bounded if the order is less than or equal to zero. But it's not so easy to do it here. There is such a thing as the Plancherel formula for a group like the Heisenberg group, a non abelian group like the Heisenberg group. But it's a little annoying that you can stare at the Heisenberg formula and just be stumped. It's not obvious from the Heisenberg formula how to use the Heisenberg formula to prove boundedness. It's just a one liner for the abelian groups, but it just doesn't work. The one liner argument doesn't work for non abelian groups, and so an entirely different argument here is needed.
01:12:56.724 - 01:13:58.154, Speaker A: And this was sorted out back in the world of representation theory, actually, by Naubenstein. So the way in which you understand this boundedness question is, first of all, you consider translation invariant operators. That's not enough to seal the deal. But you consider translation invariant operators. You make up an argument there which is very direct, using an ingenious method of Stein, basically, and then you go from t equals zero to all other t by another argument, which I'm not going to describe because I don't have time. But this is one place where there's a serious departure from what we did in our lectures, my lectures, our class, to what actually happens now in this new Heisenberg context here. No, no.
01:13:58.154 - 01:14:08.914, Speaker A: If you look at the paper of Eric and Bob, they discuss these two points, and this is not difficult at all. This is not discussed at all.
01:14:09.074 - 01:14:14.174, Speaker B: They have something about, I know they have some sort of comment about how.
01:14:18.834 - 01:14:46.944, Speaker A: Or maybe I'm sort of thinking there. I mean, it turns out to be. So that's this supplementary argument that I was talking about. It turns out to be the case that there is such an argument, and if you can handle t equals zero, then you're done. But I don't think that's actually mentioned in this initial paper of Bob and Eric. The ultimate results in this direction were figured out by Omar Mohsen. And so this problem is settled in great generality now.
01:14:46.944 - 01:15:30.864, Speaker A: But I'm just alerting you to the fact that there's a problem that has to be solved. This is, now you need Omar to call in Omar, have him drive up from State College to deal with this point in a car. I was explaining that he's driving up this weekend with, with our gangs. So that'll be interesting. I'd love to have a webcam in that car. Anyway. And one final point is ellipticity.
01:15:30.864 - 01:16:49.896, Speaker A: An operator is said to be elliptic if its symbol family of operators, let's say elliptic of order r if its symbol family is inverted modular smoothing operators by a symbol family of order minus r, the definition of elliptic. And it's a fact, it's a theorem that if an operator is elliptic, then it is, which is a symbol condition, a t equals zero condition, which you evaluate by looking at translation invariant operators and so on. If an operator is elliptic, then it does have a pseudo local. Parametrics can be inverted, so to speak, modular smoothing operators. And it's the same proof. So basically, this is fine, but there's an important gap here, which is, it's not so obvious how to test for ellipticity. When you want to know if an operator does have a symbol which really is invertible in the sense I just described, modular smoothing operators, then it's easy to answer that question in the classical situation by using fourier transforms.
01:16:49.896 - 01:17:33.604, Speaker A: That's actually what we did in the class. That's how we figured out that the Laplace operator on a manifold is elliptic. But here it's not so obvious, because, again, the Fourier transform is not here to help you in this particular case, however, there's a beautiful theorem, which I have to mention of Rockland. It's not so obvious what to do. But then Rockland comes to the rescue. So Rockland proved this theorem for differential operators, but there's a version of this for all possible symbol families, which aren't necessarily differential. So, but I'll state, I guess, the Rockland version here.
01:17:33.604 - 01:18:49.794, Speaker A: If D is a homogeneous for the scaling that we've been discussing, translation invariant, say, didn't actually, to be honest, think very carefully about whether it's most correct to talk about left translations or right translations. Barely matters for a Eisenberg group. But translation invariant differential operating on the Heisenberg group, then it's translation invariant. So we can ask, is it invertible modulo? Let's give it an homogeneous genius, let's say, of degree r. You can ask, is it invertible modulo, an operator of degree minus r? And the answer is yes, if and only if. So, d is elliptic in the sense that we're discussing if and only if. So, I take D.
01:18:49.794 - 01:20:05.540, Speaker A: It's a differential operator, but it's g equivariant and so or other Heisenberg group equivariance. So I can think of it as convolution by some distribution, just like we were talking about as recently as Tuesday. And now I can apply any representation to a translation invariant, to a distribution to convolution, exactly like I talked about before. When you do that, you get an operator which is only defined on the so called smooth vectors, which we talked about last time like that. And the condition is that this fellow here should be invertible should be or is invertible. Let's say as an operator between fresher spaces should have an inverse if for every irreducible PI, with one exception, which is the trivial representation. And if you think about it, this is the classical criterion for ellipticity.
01:20:05.540 - 01:20:50.052, Speaker A: In the abelian case, just expressed in group theoretic language. In the case of not the Heisenberg group, but Rn, all of the irreducible representations are one dimensional. And what's, and so PI of d here is just a number. And what the number is, is you take a formula for the operator with d dx's in it, and so on, and you just change each d dx to I times a new variable psi. And now you get a formula involving node d dx is just size. And that formula should return a non zero number for any collection of size xi one up to cyan, except for the zero collapse action. That's what it means for the symbol of an elliptic operator, a symbol of an operator to be elliptic, a homogeneous operator to be elliptic.
01:20:50.052 - 01:21:38.264, Speaker A: And that's the criterion here. So this is a beautiful theorem of Rockland. It's in many ways, I think, intellectually the centerpiece of this is really interesting to understand how this argument is proved. And I would have included in this class, but I could not fit this argument into tangent groupoids. It fits into the world of pseudo differential operators, actually, pseudo differential operators on a line, because for the Heisenberg group, three dimensional Heisenberg group, all of the irreducible representations are on l two over line, but the operators which are involved are just beyond the ten tangent groupoid. Anyway, I strongly recommend learning about this theorem. This is a.
01:21:38.264 - 01:22:05.754, Speaker A: It's a very rewarding experience to see how this is proved. Well, from Rockland's paper to begin with. And we made some notes with Ed and Shiqi. That's probably the best place to learn about it, because we were. Yeah, we made them for us, for people like us, dummies like us. So it's nice and easy to read. No, no, but we can.
01:22:05.754 - 01:22:26.254, Speaker A: I'll find a way to. I mean, I'll definitely give them to you. Okay. But Rockland's paper is readable, and you'll see what the ingredients are there. Yeah, from the 1970s, 1970, somewhere like that.
01:22:38.154 - 01:22:47.374, Speaker B: Makes some comments with the wait process of their distribution. If I recall, they sort of do like a local Fourier transport.
01:22:50.774 - 01:23:44.164, Speaker A: I don't have anything intelligent to say about that. Sorry. Let's just look at one example, and then we'll end with a beautiful formula due to Eric, let's go back to this fellow here. That's right. This is one half, some sort of h version of the Laplacian. I call it an H version of the Laplacian, because you're only differentiating here in two n minus two of the possible two n minus one directions. And then what do we have? We have I, and then we have some number alpha, and we have z.
01:23:44.164 - 01:24:27.402, Speaker A: And z is related to the x's and the y's by the bracket relation, the bracket of x and y z. So that's a particular operator. What is this thing? This is a homogeneous operator, because z is acting in this final direction inside of the Heisenberg group. It is a Lie algebra vector in the final direction of the Heisenberg group, which has weight two, not weight one. So when you rescale this operator out in front pops lambda squared for all of these terms. So delta h has differential order two and z has differential order one. But in terms of this homogeneity that we're now discussing, everything is homogeneous of order two.
01:24:27.402 - 01:25:09.626, Speaker A: It's a homogeneous operator. There are no lower order terms. And what else can you say about it? Oh, yeah, you want to know, is it elliptic? And it's rather beautiful, this thing here. So let's say we're on Heisenberg two, n minus one. So the conditions. So now you have to check, you have to take this operator, you have to evaluate it on an irreducible representation of the Heisenberg group. Fortunately, von Neumann and Stone figured out all of the irreducible representations of the Heisenberg group.
01:25:09.626 - 01:25:31.018, Speaker A: Unfortunately, there aren't that many of them. So you can actually do the check. And they all look like operators on L two of rn. Let's take, for example, n equals one. So it's just operators on L two of r. You can calculate what this operator is, and what it is is d squared, dx squared, or minus d squared. Dx squared plus x squared.
01:25:31.018 - 01:26:05.294, Speaker A: It's an operator on L two of R plus I alpha. Excuse me, plus alpha, just alpha z axis multiplication by minus one. So it's the harmonic oscillator. And so what you have to avoid are alphas which lie in the spectrum of the harmonic oscillator. And the final answer is like this. This should not belong to the collection n minus minus one. Let's get the n's right correct here.
01:26:05.294 - 01:26:38.414, Speaker A: I think I wrote this out. It's confusing because the ambience, the ambient space is called n. Yes, m minus one. This strange collection of numbers comes from calculating the spectrum of the harmonic oscillator, that's the reason they're there. And this is the criterion for ellipticity. Yes. Another question.
01:26:38.414 - 01:27:14.322, Speaker A: In other words, does the elliptic operator satisfy the equation of elliptic curve? No, no, no, nothing. No, I think the answer is no. There are too many ellipses and for that matter, parabolas and hyperbolas in the world. No, this is nothing to do with elliptic curves. No, it starts at n minus one. N minus three is fine. Yeah.
01:27:14.322 - 01:28:08.896, Speaker A: If alpha is n minus three, then no problem. And that's related to what we were discussing. It's no longer on the board. This operator is in fact elliptic if p is in this region, because you can figure out what alpha is. We had a formula for alpha in terms of p and minus two p. And if all the math works out correctly, if I have the shifts here correctly, you'll see that for alphas of the form n minus two p, this is okay. And so this operator has a pseudo local parametrics by all of the machinery that Bob and Eric invented in this range.
01:28:08.896 - 01:29:06.632, Speaker A: It's very interesting to understand what happens at the end. And that's another story. Let me just say a word about index theory, because it's so much fun. So in his thesis, Eric started off, kicked off this whole subject, or relaunched it, launched it in the world of non commutative geometry by thinking about index theory. Let's go back to spheres, in particular, the three dimensional sphere. We'll take the H. Laplacian that we were talking about before.
01:29:06.632 - 01:29:36.104, Speaker A: So you differentiate twice in all of the directions which are in the hyperplane bundle, and now let's add to it alpha times z. So this is a homogeneous. Well, it's an operator on the sphere. If it was an operator translation invariant operator, on a nil potent space, on a nil potent group, it would be homogeneous. In any case, this term here has the same order as delta, so you're not allowed to drop this term away. And what is alpha? Well, alpha here is a function. Let's imagine it varying.
01:29:36.104 - 01:30:43.650, Speaker A: If you want to get an index theorem with nonzero index values, it's no good to talk about operators which are alphas, rather which are scalar valued. The smallest non trivial examples come from matrix valued alphas like this. It's not important that these fellows be invertible, they're just matrices. So here's the theorem that emerges. Let's call this fellow v. If the spectrum of alpha of pull does not contain any odd integer, no matter where you are on the three sphere. Then this operator is elliptic in the calculus that we've just been describing.
01:30:43.650 - 01:31:39.126, Speaker A: What does it mean to be elliptic? Well, you have to take this operator, put it into a scaling family, and then see what the symbol family is. Another way of saying that is you have to take this operator, freeze the coefficients at a point, drop the lower order terms in some system of Heisenberg group coordinates, and see what you get. And so what you get is clearly going to be an operator of this type. And this condition up here turns out to be this fellow. Then b is Fredholm. So what is it? It's an operator from matrix valued functions on the sphere to matrix valued functions on the sphere. And there's a formula for the index.
01:31:39.126 - 01:32:21.314, Speaker A: And because this is such a special case, you can write down what the formula is. It's so nice that I'll just do it. There's a sum over the odd integers, and it's a sum of winding numbers like this. You take the trace of, what are we calling it? Alpha. Alpha minus k times the identity inverse D alpha. That's a one form, but we need a three form to integrate over three spheres. So let's just cube that.
01:32:21.314 - 01:32:51.882, Speaker A: Like that. That's it. Well, this is a matrix valued tree form, alpha tree form, freeform. Alpha is a map. So it's a matrix of functions, two by two, matrix of functions. And so alpha minus k inverse times D alpha is a matrix of one forms. If you cube it, then you get a matrix of three forms.
01:32:51.882 - 01:33:38.274, Speaker A: If you take the trace, that just means take the sum of the diagonal entries. Now it's an honest three form complex coefficients, and now you can integrate it as long as you've fixed the right orientation, which I don't remember which one it is. Yeah. The complex structure on this h hyperplane bundle in this case determines an orientation on the three sphere in a certain easy way. That's the one I'm talking about. As for the proof of this, it involves yet another version of the it involves the tangent group board we've been talking about, but also yet another two parameter family of group points. The usual tangent group point is a one parameter family of group points.
01:33:38.274 - 01:34:16.730, Speaker A: What you need to prove this index theorem is to reduce to the tir singer index theorem. And the way you do that is you look at the deformation to the normal cone. I just wanted to stick those words in. You look at the deformation to the normal cone for the embedding of the unit space for this particular groupoid, our groupoid in these lectures, in this lecture, into the tangent groupoid that we've been discussing in this lecture. That deformation to the normal cone by functorality of the normal cone is ANother groupoid. The original t sub h of m was a family of groupoids over the line. And then when you do the deformation space, there's another parameter that obtains.
01:34:16.730 - 01:34:40.406, Speaker A: And so you actually have a family of groupoids over the plane. And the groupoid sister algebra form a continuous field just like we saw. And so there are some natural maps in k theory. And this, by almost mAgic, reduces the question of what the index map is in the Heisenberg case to the usual case. And out pops this wonderful theorem just.
01:34:40.430 - 01:34:50.794, Speaker B: Described is you have this thing over r squared. Is it such that over. So your two parameters, if you restrict that t equals zero, do you get this ph?
01:34:53.694 - 01:35:24.346, Speaker A: Yep. So along here. So here's the origin of the plus. There's a one parameter family of groupoids. Which is just the Heisenberg tangent groupoid here. Everywhere else, it's a copy of the usual tangent groupoid. And if you go up here, you have a bundle at this zero point, a bundle of Heisenberg groups.
01:35:24.346 - 01:36:01.446, Speaker A: And it somehow degenerates to a bundle or deforms to a bundle of abelian groups. So going upwards, you have some interesting way in which nilpoten groups deform into abelian groups. Oh, excuse me. I have this completely screwed up like that. A special case is t of m. And all of the others are th of Ms. So the nil potent groups degenerate to abelian groups is what I should have said.
01:36:01.446 - 01:36:23.054, Speaker A: Uh, those, uh, abelian groups or that bundle of abelian groups deforms into m times m here, as it does here. So this point here, we just have m times m. Yeah. At this point we have th of m. And at this point we have usual tangent model again. And. Yeah.
01:36:23.094 - 01:36:23.754, Speaker B: Okay.
01:36:26.214 - 01:36:42.030, Speaker A: Oh, this is through some. So we have two parameters in this direction, I guess we have t. And in this direction we have a new parameter s. And here's s equals 17. I know. Something like that. It's just some line which is not s equals zero.
01:36:42.222 - 01:36:45.434, Speaker B: Oh, sorry. I understand. That line is.
01:36:50.414 - 01:37:11.370, Speaker A: Yeah. This is a family of bundles over m. Generically, the fibers of that bundle are nil potent groups. And at t equals zero, the fibers are. Yeah. It's also a definition. Let's stop.
01:37:11.370 - 01:37:23.114, Speaker A: Thank you. Thank you very much for your indulgence. We are done unless there's an order, in other words. Okay. Okay. We don't have to do that. We are done.
01:37:23.114 - 01:37:47.228, Speaker A: Been a wonderful audience. Thanks very much. There are notes, so you can read as much as you like online. And maybe I'll try to put this Rockland thing somewhere. It's in a sanitary condition. Just put it in the same place, something like that. Next week is conference here, a workshop on non commutative geometry for those who are interested.
01:37:47.228 - 01:38:07.844, Speaker A: I guess everything is beamed out to the Internet just like this. So you can continue to sit in your cold chamber, wherever you are on the Internet and continue to watch all throughout next week. But now it's over. It is Miller time here in Toronto. Thank you.

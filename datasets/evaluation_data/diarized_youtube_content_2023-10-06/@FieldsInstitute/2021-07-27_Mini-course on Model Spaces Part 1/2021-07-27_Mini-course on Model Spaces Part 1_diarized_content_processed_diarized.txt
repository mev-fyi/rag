00:00:00.120 - 00:00:26.688, Speaker A: Thank everybody, depending on where you are now, welcome to the week four focus program in virtue of fields Institute on analytic function spaces in the application, and this week will be devoted to model spaces. And it's my pleasure to introduce our first speaker today, Stefan Garcia from Pomona College, who will start his mini course on model spaces.
00:00:26.846 - 00:01:01.602, Speaker B: Welcome. Thank you. Hope everyone can hear me. I'd like to thank the organizers for having me, and I'd like to thank everyone here for continuing to attend these wonderful series of talks. So the numbering that you're going to see here refers to the book, chapter or paper that I believe Javad will send a link to at some point. So for those of you interested in following along, everything is numbered and you can look back at that chapter that'll be posted as a PDF quite soon. So it's a quick overview.
00:01:01.602 - 00:01:51.210, Speaker B: Model spaces are the backward shift invariant subspaces of the Hardy space H two. We're going to be interested in them because of their very interesting function theoretic behavior and also their connections to operator theory. So what we're going to see in these three lectures are a very brief and selective overview of the theory of model spaces. And I'm aiming this particularly at the novice rather than someone who's experienced in this. So, you know, if you're an expert in this, these lectures will probably appear quite elementary or superficial. But I'm trying to keep things short and suppress some of the difficult details because they're going to be pushed off to the references. And I'll often focus on very instructive finite dimensional examples because that's when you can really get your, your hands dirty and start understanding things, because things get rapidly, much more difficult to deal with in the infinite dimensional case.
00:01:51.210 - 00:02:43.472, Speaker B: So I always think you need a grounding in the simple examples before you move on to things that are more complicated. Now, another disclaimer is that we're going to focus on model spaces themselves rather than operators that interact with them. We will consider some operators, but, for example, Hankel operators and truncated toplitz operators won't appear in these lectures because, of course, those will be covered by some of the other lecturers. So this is not a comprehensive overview of everything connected to model spaces, but sort of a brief and selective survey. And so I need to go over a few preliminaries just to get our notation straight. A lot of this was covered in the first series of lectures by Javad, and so this is mostly notation refresher on Hardy space theory. So I'm going to assume that the audience is familiar with the Labaig spaces capital l two and capital l infinity on the unit circle, which I'm going to denote by t.
00:02:43.472 - 00:03:45.394, Speaker B: We're going to let z denote the integers little l two of z. That's going to be the space of square summable sequences, m is going to be normalized Lebeg measure, and the open unit disk is going to be d. So, pretty standard notation. Let's recall Parseval's theorem, which says that the capital l two norm of a function on the circle is equal to the little l two norm of the sequence of Fourier coefficients of that function. The Hardy space, you may recall, is going to be the set of all analytic functions on the open unit disk d, so that these integral means remain bounded as r tends to one from below again, I'm going to go through this rather quickly because I'm assuming that everyone has attended that first series of lectures on the Hardy space. For each hardy space function little f, the non tangential limit exists for almost every boundary point on the unit circle. And so we can consider the boundary function, which we're also going to denote little f.
00:03:45.394 - 00:04:50.184, Speaker B: And it turns out that that boundary function of an h two function also belongs to l two, and we have an equality of norm. So for every function f in little h two, we have this really, really nice connection here. The value of the boundary function at zeta for almost every zeta on the unit circle basically looks like plugging in zeta into the power series representation for the function little f. And in fact, the nth Fourier coefficients, which I denote here with f hat of n, actually equals the nth Taylor coefficient for f at the origin, which is what we're saying here. And the way you want to think of h two when we're thinking of it in terms of Fourier analysis, it consists of those Fourier series in capital l two with no negatively indexed two terms. And so we're going to think of h two as a subspace, a norm closed linear submanifold of capital l two and capital h two then becomes a Hilbert space endowed with this inner product that's compatible with the l two inner product. You can compute things on the boundary.
00:04:50.184 - 00:05:34.794, Speaker B: You can look at the boundary functions of h two functions, compute the inner product there. Or we can take a look at the Fourier coefficients or slides Taylor coefficients of the origin with equality of inner products. Now, analogous definitions exist for the other Hardy spaces hp, where p is between one and infinity, p equals infinity is a special case. In that case, we get the algebra h infinity of all bounded analytic functions and that's going to become endowed with the supremum norm. And it turns out the boundary function of an h two function belongs to l infinity, the bounded measurable functions on the circle. And we have again equality of norms. And we're going to regard h infinity as a Banach subalgebra of l infinity.
00:05:34.794 - 00:06:18.184, Speaker B: Now, another thing I'm going to need you to recall about the Hardy space that we're going to use over and over again is the reproducing property. And so this function here, which I'm going to note, c, sub lambda, where lambda is in the unit disk, that is going to be the Cauchy kernel, also called the zego kernel. And it has a remarkable property that it reproduces the value of a Hardy space function at lambda. So in other words, f of lambda is equal to f interproducted with this kernel. It's the reproducing kernel of h two, the Cauchy kernel, segu kernel. And in particular, we're going to use this fact over and over again. A function vanishes at lambda if and only if f is orthogonal to the corresponding Cauchy kernel.
00:06:18.184 - 00:07:03.464, Speaker B: And you can see that from this formula right here. We'll also use, and more refer to obliquely, the derivative kernels. So what happens? You also have reproducing kernels for the derivatives of your function. So the nth derivative of a hardy space function at lambda is given by taking the inner product of your function against this sort of modified Cauchy kernels, just the derivative of c lambda with respect to z the appropriate number of times. Another important fact, these Cauchy kernels are linearly independent. That's going to figure quite prominently into our study of finite dimensional model spaces. So if you have a distinct sequence of points in the disk, you take a look at the corresponding Cauchy kernels, they turn out to be linearly independent.
00:07:03.464 - 00:08:04.352, Speaker B: And I think aside from inner outer factorization, we're almost going to have everything needed to start dealing with model spaces. So in fact, there's going to be a whole lecture coming up on inner functions. I believe although inner functions were covered in that first series of lectures, we're going to look into them in much greater detail in some of the later lectures coming up in this lecture series, not mine, but one of the other speakers. So I'm just going to need you to recall really briefly, inner function is a bounded analytic function that has unimodular boundary values almost everywhere on the circle. You may recall that these come in a variety of flavors. They are, well, unimodular constants times a possible power of z times a Blaschke product, that is a product of disc automorphisms set up in such a way that it matches the disk to the disc and the circle almost everywhere to the circle. You have to have these zeros of this so called blaschka products satisfy the blaschka condition.
00:08:04.352 - 00:08:42.542, Speaker B: They have to tend to the circle rapidly enough to ensure convergence. And then we also have this singular inner factor that arises from a non negative singular measure over here. And so that is a typical inner function, an outer function. I hope you will recall it's a function of this form here, where phi is an l one function that is real valued, and gamma here is a constant. So we have a unit modulator constant times this complicated expression here. The point of this is that with inner and outer functions we have unique factorization in h two. And that's something that we're going to use very frequently.
00:08:42.542 - 00:09:28.470, Speaker B: A nonzero function in h two has a unique factorization of the form bsf, where b is a Blaschke product, s is a singular inner function, and f is an outer function, which happens to be in h two. And conversely, any product of things of this form belongs to h two. So an analogous factorization holds for hp, where the modification is the outer factor of f belongs to hp instead of h two. So now with all of that in hand, we can get on to model spaces. The model space corresponding to a non constant inner function u is this thing. You basically take h two, multiply every function in h two by u. That gives you a subspace of h two.
00:09:28.470 - 00:10:16.334, Speaker B: Then you take the orthogonal complement in h two, and that is going to give you a subspace of h two called the model space corresponding to u, and it's denoted script k sub u. So again, that's the orthogonal complement of this sort of Berlin type subspace, uh, two. The set of all function is h two multiplied by the inner function u. So, interesting fact that one can derive from the definition that a model space contains the constant functions if and only if the inner function vanishes at the origin. And in many applications one sort of sets things up so that u vanishes at the origin. This will come up quite a bit later. So just remember you can, the model space contains the constant functions if and only if the inner function vanishes at the origin.
00:10:16.334 - 00:11:34.430, Speaker B: There. It's a little bit of a philosophical problem with model spaces, however, that is that our definition is a little bit indirect. We're defining a model space to be the orthogonal complement of a very, very concrete subspace. So consequently, it can be a little bit difficult to determine whether a function belongs to a model space or not, or characterizing the functions that belong in model spaces. And so, fortunately, in the finite dimensional case, well, model spaces are explicitly realizable as concrete spaces of rational functions. It's in the infinite dimensional case that model spaces take quite a bit more work to understand because of this negative characterization as an ortho complement of something. So you may recall from Berling's theorem that the non zero invariant subspaces for the unilateral or forward shift operator, where we take f and just multiply it by z, well, the invariant subspaces of h two for this shift operator are these bearing type subspaces, uh, two, where u is inner, right? So it turns out because of this orthogonal complement characterization of model spaces, that the model spaces are the invariant subspaces for the backward shift operator on h two.
00:11:34.430 - 00:12:28.054, Speaker B: So that is this operator which I'm denoting s star, which has this funny definition where you subtract off the value of f at the origin, so that now the numerator vanishes at the origin so I can divide by z. That turns out to be the backward shift operator on h two. And it is the adjoint of the forward shift, because one can verify that the inner product of s f and g is the same as the inner product of f with s g for any h two functions, f and g. Now this is understandable quite a bit better in terms of Taylor coefficients. When you look at things in terms of Taylor coefficients, the origin, well, the forward shift operator is just shift forward and insert a zero here at the front. The backward shift is, as its name implies, the backward shift. You just chop off a zero and shift things to the left so you shift in the backwards direction.
00:12:28.054 - 00:13:20.594, Speaker B: So the model spaces are the backward shift invariant subspaces of h two. That is the point here. Now let me give you a couple basic containment properties here. How do model spaces relate to each other if u and v are non constant inner functions? We're going to say that u divides v, denoted u v, if the quotient v divided by u belongs to h two. Now, because of the inner, the inner function factorization theory, one can characterize exactly when that happens in terms of singular inner functions and blaschka factors. But we will just leave it at this. The point is u divides v if and only if v divides u happens to be an inner function in h two, right? Or happens to be an inner function at all.
00:13:20.594 - 00:14:19.230, Speaker B: Now, the containment of model spaces reflects the factorization of inner functions in a very natural and nice way. An inner function u divides an inner function v if and only if the model space ku is a subspace of the model space kv. That's a short exercise to prove, but it basically says that the factorization of inner function is perfectly reflected in the containment of model spaces. And this is something we'll use on occasion. The perspective that we're trying to develop and that we'll use over and over again in these talks, is that it pays not to think of h two as its own thing, but to think of h two as sitting in this larger ambient space, capital l two. In other words, we tend not to think of h two as a collection of analytic functions on the open unit disk. We tend to think about the boundary values of h two functions on the circle and work on the circle as much as possible.
00:14:19.230 - 00:15:02.178, Speaker B: And we'll see this in the next slide. So this interplay between analytic functions on a disk and their boundary values on t in this context of the larger ambient space, capital l two is a very, very, very common thing. And so, first proposition here in terms of boundary functions, we can characterize the model space ku. It is h two thinking of this as a subspace of capital l two of the circle. It's h two intersect this thing. So this makes no sense when you think about this in terms of analytic functions on the disk, because it looks like this is not analytic. But again, we're thinking about things on the boundary.
00:15:02.178 - 00:15:30.454, Speaker B: So we're thinking about Fourier series on the boundary. So you think of h two as Fourier series with non negatively indexed coefficients. So what we have is h two bars times z bar. So in other words, this z bar, h two bar, that is the l two functions with negative Fourier terms only. So we think of ku as this. It's a strange thing. You take this inner function u.
00:15:30.454 - 00:16:01.114, Speaker B: Take, multiply it by zh two bar, the negatively indexed Fourier function, or Fourier series, multiply it by u, which is an analytic function that jumbles things up. And you get this weird subspace of capital l two over here. You intersect it with h two. That happens to be the model space ku. It's a strange way of operating if you're not used to dealing with pushing things to the boundary and working in this larger ambient space. So here's the explanation. Let f be an h two function.
00:16:01.114 - 00:16:47.224, Speaker B: We know that u times u bar is equal to one almost everywhere, because u is an inner function, it has modulus one almost everywhere on the circle. And so f happens to be orthogonal to, uh, two, or in other words, to belong to the model space ku if and only if. Well, what I do here is I can move the u from one side to the other inside an inner product, because u times u bar is equal to one. So f is orthogonal to, uh, two, if and only if u bar f is orthogonal to h two. So what you need to do is write the relevant inner products in terms of integrals on the circle. Use the fact that uu bar is equal to one. That's what's going on here.
00:16:47.224 - 00:17:33.393, Speaker B: And what this means here is, okay, if I've got an l two function that's orthogonal to all of h two, think in terms of Fourier series. That means you can't contain any non negatively indexed Fourier terms. In other words, you must consist entirely of negatively indexed Fourier terms. So in other words, you must belong to zh two bar. So what that tells me is that, well, f belongs to the model space ku, the ortho complement of, uh, two if and only if f happens to belong to. Well, what am I doing here? I'm multiplying both sides of this expression by u. So I get if and only if f is an element of u times zh two bar.
00:17:33.393 - 00:18:06.412, Speaker B: So it's kind of an interesting thing. We've got a characterization in terms of boundary functions, thinking in terms of l two. So an important observation here is that f belongs to the model space ku if and only if. Well, we go back here. F has to look like this. It has to be something of this form. So in other words, there has to be some companion function, g in h two, so that f, this function in h two, happens to be equal to u times zg bar.
00:18:06.412 - 00:18:40.698, Speaker B: And again, those of you used to working entirely in the disk, this looks totally wrong. But remember, this is happening on the boundary, not on the interior of the disk. This is happening in capital l two of the circle. And it just so happens for some h two functions, this weird expression happens to multiply out and actually yield the boundary values of another h two function. Strange. It's unusual, but it works out. So we need to take a look at the reproducing kernels for model spaces.
00:18:40.698 - 00:19:14.998, Speaker B: So if f is in ku and lambda is in d, we're going to derive the formula for the reproducing kernel as follows. Well, the Cauchy kernel, you'll recall, reproduces the value of any h two function at lambda. So this is just the property of the Cauchy kernel. What I'm going to do next is say, well, I can subtract off this bit because f is in the model space. So that means f is orthogonal to everything in u h two. So what I have here is u times some h two function. So this inner product is zero.
00:19:14.998 - 00:19:52.484, Speaker B: So I'm allowed to tack this on and so I regroup terms as my next step. And so I have f times f inner product with this thing is equal to f of lambda. So I'm going to call this weird expression k lambda. So this happens to be the reproducing kernel for the model space ku. You can see the Cauchy kernel part right here, one over one minus lambda bar z. And then we've got this extra part here that contains information about the inner function. Uh, so we'll notice it's an outer function in h infinity.
00:19:52.484 - 00:20:21.996, Speaker B: So it's an invertible outer function in h infinity. We'll use that in the second lecture. It belongs to ku. So in other words, it is actually the reproducing kernel we're looking for because it has the reproducing property and it belongs to ku because of the following computation. Well, how do you show membership in script ku, you show that you're orthogonal to every function of the form. Uh, so you're orthogonal to u capital h two. The way you do that is as follows.
00:20:21.996 - 00:21:00.724, Speaker B: Well, use the formula for k lambda and split things up. And so, uh, inner product k lambda is, well, it is u lambda, h lambda minus u lambda times the inner product of h. With c lambda, we use the fact that c lambda is the reproducing kernel for any h two function. And so that tells me that we're just subtracting the same thing from itself and we get zero. So moral of the story, k lambda is orthogonal to everything in u capital h two. So that means k lambda is in the model space. Script ku.
00:21:00.724 - 00:21:39.692, Speaker B: So that is our reproducing kernel. This formula here is going to be very, very, very important for what we do. And those of you who are used to other types of operator theory, multivariable operator theory, higher dimensional things, you'll recognize that kernels of this form appear quite a lot in operator theory. And sort of model spaces are sort of a basic first time UC kernels that have this sort of appearance. And so let's take a look at the orthogonal projection from the big space capital l two onto the model space. Script Ku. So this is a standard fact that applies for any reproducing kernel Hilbert space.
00:21:39.692 - 00:22:22.912, Speaker B: But if I want to compute the value of p sub u of f, so if I want to take some function f in l two and project it into the model space script Ku. Well, I do that by just taking the inner product of f against k lambda, where k lambda is the model space reproducing kernel. And that just gives me the value of p sub u of f at lambda. And here's why. And so again, this argument is quite general, but I want to run through it, because there's a lot of things for students to get from this argument. We're going to note that an orthogonal projection is self adjoint. And so that means once it's inside of an inner product, we can move it from one side to the other without changing anything.
00:22:22.912 - 00:22:51.674, Speaker B: That is a legal maneuver. So f comma k lambda is going to be f comma pu times k lambda. The reason is pu is the orthogonal projection on the ku. So that means this orthogonal projection fixes every function in the model space. So k lambda is p times k lambda. And then I use self adjointness. I move this orthogonal projection from one side to the other inside the inner product.
00:22:51.674 - 00:23:30.674, Speaker B: And then what I have, I have p sub u of f, which is something in the model space. I don't know exactly what it is, but it's in the model space. So the reproducing kernel for the model space certainly reproduces the value of this function p, sub u of f at the point lambda. And again, this is a general argument that applies for reproducing colonel Hilbert spaces, but it involves some important ingredients. So what I can finally get to now are some characterizations of finite dimensional model spaces. And these are the model spaces for which we have a very, very nice concrete description. So here's an important fact.
00:23:30.674 - 00:24:14.882, Speaker B: You'll recall that u of h, that is some hardy space function. So the Cauchy kernel, the Cauchy Zeigo kernel reproduces its values. So since u of h inner product c lambda equals u lambda, h lambda for any h two function little h, what we can tell here is that, okay, you are orthogonal. Sorry, this Cauchy kernel, c lambda, belongs to ku. In other words, c lambda is orthogonal to every function of the form, uh, if and only if. Well, look at what happens over here. If this is zero for every function h in capital h two, that's the same thing as saying that u of lambda must be zero.
00:24:14.882 - 00:25:00.472, Speaker B: So the important fact is, a Koshizego kernel belongs to Kuhl. If and only if the inner function u vanishes at the corresponding point, lambda very, very important point. And that will lead us to the next proposition. Again, the numbering here refers to the numbering in the book chapter, which I believe the link to will be posted quite soon, if it hasn't been posted in the chat already. So the result here is if you've got a finite blasc product with zeros lambda one up to lambda n, you can write down every function in the corresponding model space. Ku, it looks like this. You got a polynomial of degree at most n minus one in the top, and then you've got these factors in the bottom.
00:25:00.472 - 00:25:49.696, Speaker B: And these are the sort of factors that look kind of familiar because those appear in the denominators of Cauchy kernels and the reproducing kernel for ku. So we basically have kind of like a weighted polynomial space. But in particular, this is a space of rational functions, very concrete space of rational functions. And in the case where you stack all of your zero, the zeros of your blaschka product at the origin, or in other words, u is of the form z to the n, well, then all of these things in the denominator just disappear, and you actually just have an honest space of polynomials. So here's the explanation, and I'm going to focus on the case with simple zeros. To do the more general case, you just use the derivative kernels so you know the details of that. I'll push off into the book chapter if you want to see the details.
00:25:49.696 - 00:26:28.164, Speaker B: I want to focus on the simplest version of each argument. So let's suppose that u has only simple zeros, no repeated roots. Now, this comment above about when a Cauchy kernel is contained in a model space, well, that tells us that each of the Cauchy kernels corresponding to the zeros of u belongs to the model space, so their span belongs to the model space. Ku. So we just need to look at that reverse containment. And so we note the following. Let's suppose that f vanishes at lambda I at one of the roots of the inner function u.
00:26:28.164 - 00:27:09.050, Speaker B: In other words, f is orthogonal to the Cauchy kernel at lambda I for each of the zeros of u. Well, okay, if f vanishes at each of the zeros of u, hardy space theory tells me that the finite blaschke product u has to be a divisor of f, right? So u divides f. And in other words, f is of the form u times some h two function. So f is in, uh, two. And what that tells me is that, well, oh, wait, uh, two, that's the orthogonal complement of the model space. That's how you define model spaces. They're the orthogonal complements of subspaces of the form uh, two.
00:27:09.050 - 00:28:13.304, Speaker B: And so that tells us that the orthogonal complement of the span of the Cauchy kernels corresponding to the zeros of the inner function u, is a subspace of, uh, two, and uh two is the orthogonal complement of the model space ku. And so when you take orthogonal complements of this line, you get a containment in both directions. And so you say, ah, the model space ku is just the span of those n Cauchy kernels. So the model space is automatically there, a subspace of rational functions. You know exactly where the poles are and their multiplicities. And so if you take a look at the span of these Cauchy kernels, use a partial fractions argument, you can see, well, when I collect things together, I'm going to get exactly something of this form. So this is a nice characterization of model spaces corresponding to finite Blaschkit products, at least in the case with simple zeros for repeated roots, you deal with not necessarily just the reproducing kernels, but also derivatives of reproducing kernels.
00:28:13.304 - 00:29:00.276, Speaker B: But again, I'll leave that to your imagination. So, generalization of that argument says that if I've got a finite Blaschke product with distinct zeros, z one up to ZD, where now I'm allowing the possibility of multiplicities, and I'll denote the multiplicities m one to mD, then the same sort of argument says, well, ku is just the span of a bunch of Cauchy kernels and the appropriate derivatives. So the derivatives up to a certain order here. So that's the generalization that I was speaking of, of the preceding result. Now, the thing I want us to recognize here is that this is possible really only because we've got a finite Blaschke product. If we had an infinite blaschey product. I have issues of convergence in that denominator from the preceding slide.
00:29:00.276 - 00:29:39.300, Speaker B: If I've got a singular inner function, I have no idea what's going to happen here. So these finite dimensional model spaces occur if and only if the inner function is a finite blatch key product. And there's an explanation for why this occurs. So what we really need to show that the model space is infinite dimensional whenever u happens to not be a finite blaschka product. There's a couple ways that can happen. If u has an infinite blaschke factor. Well then that means U has infinitely many zeros, right? So, by what we've seen in the previous slides, you take a look at the Cauchy kernels corresponding to those infinitely many zeros.
00:29:39.300 - 00:30:23.928, Speaker B: Cauchy kernels are linearly independent. So that means your model space contains an infinite linearly independent set. Once you have infinitely many zeros, infinitely many linearly independent Cauchy kernels, and you're done. Infinite dimensional. Now, if u has a singular inner factor s, well, what you can check is that, well, the subspaces of Ku correspond to the inner divisors of u. So s is an inner divisor of u, but also the nth root of that singular inner function is also an inner divisor of u. So that means ku contains an infinite chain of distinct subspaces, and that means that that model space, ku, is infinite dimensional.
00:30:23.928 - 00:31:03.854, Speaker B: So in either case, you're going to be infinite dimensional. The model space is finite dimensional if and only if it comes from a Blaschke product. Okay, now I want to tell you about the relationship between model spaces n Tauplitz operators, or at least conjugate analytic t operators. That's going to involve the Ries projection. Again, we're working in capital l two, we're thinking of h two, and all the model spaces is sitting inside capital l two. So I'm going to let p be the orthogonal projection, the Ries projection from the big space l two onto h two. So as an orthogonal projection, it's self adjoint and idempotent.
00:31:03.854 - 00:31:52.404, Speaker B: And in terms of Fourier coefficients, what you're really doing is you're taking this Fourier series in capital l two that's indexed by the integers. And I've highlighted the zero f coefficient and you're chopping off all the negative stuff. And that gives you a sequence of non negatively indexed Fourier terms that corresponds to the Taylor coefficients of an h two function, or in other words, the Fourier coefficients of an h two function. And so what the Ries projection does is kind of interesting. Here's an example. So we start with e to the I theta, and we're going to identify that with z, a complex variable on the unit circle. And if I have this l two function, one plus two cosine theta, and I want to project that into h two and find out what I get.
00:31:52.404 - 00:32:49.112, Speaker B: I do it this way, I say, well, two cosine theta, that's e to the I theta plus e to the minus I theta plus z. So now I've kind of got my Fourier series. Here I've got a negatively indexed Fourier term, and the Ries projection is going to kill that off. So I just get one plus e to the I theta, or in other words, when I think back in terms of complex variables, one plus z. So you see, we can project something in capital l two and recover an analytic function in capital h two from it. And this is a similar computation to what we saw before when we were projecting into model spaces, since p is equal to p star and the Cauchy kernel belongs to h two. Same sort of computation says that I can compute the Ries projection of f at lambda by just taking the inner product of this function, which is an l two, with the corresponding Cauchy kernel.
00:32:49.112 - 00:33:29.930, Speaker B: And if I wanted to, I could write this in terms of integrals, and in fact, get a Cauchy integral type of representation for the Ries projection operator. So now I need to tell you a little bit about tuplets operators. These will be covered in a lot more detail in a future lecture on operators on function spaces. But for right now, I think we can just cover what we need here. So the toplitz operator with symbol phi in l infinity is the map that goes from h two to h two, defined as follows. You basically multiply your function by phi, and that's going to be some function in capital l two now. And then you're going to project it back into the Hardy space.
00:33:29.930 - 00:34:05.384, Speaker B: So you start with a hardy space function, multiply it by some bounded, measurable function, and you get something in l two. Put that back in h two by projection. And so if the symbol is an h infinity, then you actually don't even need the projection. And this is what's called a analytic tupelets operator. We're going to be more interested when the symbol has the conjugate in h infinity, and that's going to be called a co analytic tuplets operator. Those are going to be the ones that are more important for us right now. And again, topelets operators, they'll appear in more detail in later lectures.
00:34:05.384 - 00:34:48.884, Speaker B: What we need to know now is, and this is a good exercise for students, prove that the adjoint of the topelets operator with symbol phi is the topelet's operator with symbol phi bar. We're going to need this little fact. And here's the connection with shift operators. The unilateral shift, which is just multiplication by z, is the topelet's operator tz. You basically just multiply by z, and you don't need to project, because you're already in h two. Now, if phi is in h infinity, the bounded analytic functions, then one can sort of come up with a functional calculus in this fashion. I can say, well, phi of the operator tz is going to be the topelet's operator t sub phi.
00:34:48.884 - 00:35:39.614, Speaker B: And it turns out that this respects and extends the standard polynomial functional calculus. Now, there's a lot of details to fill in there, but one can actually prove that this is isometric. The norm of t sub fee is actually the norm of phi in h infinity. So, in other words, one can regard these analytic tuplets operators as analytic functions of the shift operator analytic functions of t sub z. On the other hand, the backward shift, which is the adjoint of the forward shift, well, that's going to be t of z bar. And so now that we've got these definitions about tuplets operators, we can examine how conjugate analytic tuplets operators relate to model spaces. So, first of all, model spaces are invariant under conjugate analytic tuplets operators.
00:35:39.614 - 00:36:23.568, Speaker B: If you apply a conjugate analytic tuplets operator to a model space, you wind up in the same model space. And here's why. Again, cute computations on the boundary, working with Fourier stuff on the boundary circle, as opposed to dealing with analytic functions in the disk. So, if I've got a model space function f, and I have a little h in capital h two, we do the computation t sub feed bar of f. Well, let's check its inner product against u eight, find out when it's zero. Well, because the adjoint of t phi bar is t phi, we can move it to the other side of the inner product. The definition of the toplitz operator says, multiply by phi and then apply the Ries projection operator.
00:36:23.568 - 00:36:50.390, Speaker B: So that's what I've got here. Now, I use self adjointness of the Ries projection to move the p from one side to the other. And I say, okay, well, f is in the model space, so that means f is already in capital h two. So that means the Ries projection fixes f. So I can basically just drop the p there. And now I have f inner product u times something. What is this something? It's an h two.
00:36:50.390 - 00:37:46.084, Speaker B: Because phi is a bounded analytic function. F is in the model space, so that inner product is zero. So what does this tell me? This tells me that t phi bar times f is orthogonal to any function of the form u h. That tells me that t phi bar times f belongs to the model space ku and that gives me this invariance under conjugate analytic tuplets operators. So those of you who deal with binoc spaces of analytic functions might recognize this stability under removal of inner factors, as maybe I've gone ahead of myself. But the following thing we'll see is called the f property when you study bonox spaces of analytic functions, because a consequence of the previous proposition is that you can strip off inner factors of functions in model spaces, you can just remove them. Model spaces are invariant under removal of inner factors.
00:37:46.084 - 00:38:30.860, Speaker B: So precise statement is this, if theta is an inner function and f over theta happens to belong in h two, where f of course belongs to the model space, ku then I can just remove that inner factor f divided by theta also belongs to ku. So what this means, if you take it to the logical extreme, you can remove the inner factor of f. You can just strip it off completely. So the outer factor of a function in a model space belongs to the same model space. So you can basically keep removing inner factors until you just get to the outer factor at the end. And all of the functions that you had in between also belong to the model space. And so here's how we do it again, playing around with projections and boundary functions.
00:38:30.860 - 00:38:58.524, Speaker B: So take a look at t theta bar. So in other words, the projection, the Ries projection of theta bar f. Well, since I'm on the circle, theta bar makes sense. Theta bar is one over theta on the circle. So this I can write as f over theta. But I'm saying by hypothesis that f divided by theta is an h two, because theta is an inner factor of f. So the projection does nothing because I'm already in h two.
00:38:58.524 - 00:39:32.020, Speaker B: And so what this tells me is that, well, I am going to be in the model space, because we just said that the model space is invariant under any conjugate analytic tuplets operator. So it's a very important thing. The outer factor of a function in a model space belongs to the same model space. You can remove inner factors at will. So get onto the final topic of the day. And that is the compressed shift operator. So we're going to recall that pu, that is the orthogonal, that's not the Ries projection.
00:39:32.020 - 00:40:15.954, Speaker B: The substance view is denoting that this is the orthogonal projection from l two onto the model space, not h two. What we want to do is take a look at our favorite operator, the shift operator, and squeeze it down, compress it to the model space and look what happens there. And it's very, very, very interesting. And in fact, there's a whole series of lectures coming on later on in this lecture series on truncated topolitz operators. That's toward the end of the program, but it's basically all based on this particular operator. So you could really take this operator and run with it. The compressed shift is going to be, well, you perform the shift, multiply by z and then project back into the model space, because multiplying by z probably takes you out of the model space.
00:40:15.954 - 00:40:55.338, Speaker B: Model spaces are backward shift invariant, not forward shift invariant. So we got to project to get back into the model space. That's going to give me the compressed shift operator, a sub z, and then the superscript u just tells you what model space you're on. So we're usually going to write a sub z because we're going to know what the inner function u is from context. Now the important thing is that this works out pretty nicely. There's sort of poly, there's a nice polynomial functional calculus here, and you can go beyond that. The nth power of the compressed shift is really the compression of maybe, okay, maybe I didn't define what this notation would mean, but.
00:40:55.338 - 00:41:35.326, Speaker B: Well, stay tuned for the truncated topelets operator lectures. I don't want to dwell on this since I didn't define what it means to put a symbol down there. That would be a truncated topelet operator with symbol z to the n. Now, if you like the backward shift more, you can always work with a backward shift, because it turns out this compression of the shift operator to a model space is actually the backward shift restricted to a different model space. That's strange, because normally we think of the forward shift and the backward shift as being very, very, very different operators. They have very, very different properties. They're adjoints of each other, but they're weird operators and they're the standard counterexamples for basically everything.
00:41:35.326 - 00:42:24.638, Speaker B: But it turns out when you look at their compressions, they're more or less the same thing. The compressed shift on the model space Ku happens to be unitarily equivalent to the restriction of the backward shift to kv, where kv or v is the inner function that you get by just conjugating the coefficients of u. Sort of a strange thing. So the backward shift and the forward shift really are more or less the same. When you're dealing with model spaces, you just change the model space a little bit. You have essentially the same operator, and sometimes it's better to work with a backward shift because the model spaces are backward shift and variant, they're not forward shift invariant you have to put a projection if you want to deal with that. So sometimes it's better to deal with a backward shift, because model spaces are already backward shift invariant, s star invariant.
00:42:24.638 - 00:42:59.086, Speaker B: So that's one reason you might change perspective and deal with the backward shift. So I need to tell you about the spectrum of these operators. This is where the function theory of the model space interacts with operator theory of the compressed shift. So we're going to need to define the spectrum of an inner function. The spectrum of an inner function is that the lm zero set. It's going to be the set of points in the closed unit disk where this limit in female limit inferior is equal to zero. And there's a couple ways you can sneak into this.
00:42:59.086 - 00:43:09.354, Speaker B: I have to. I'm tuned into this other talk by Stephan Garcia. Let me see a minute. What I'm doing.
00:43:10.954 - 00:43:11.894, Speaker A: I can't.
00:43:12.434 - 00:43:47.190, Speaker B: I believe that's not meant to be a question. Okay, so I'll continue. I'll deal with questions if there is a question afterwards. So the spectrum of an inner function is defined to be this set, and it's called the spectrum for a very good reason. It turns out to be the spectrum of the compressed shift associated to you. How do you get in the spectrum of an inner function? Okay, well, the zeros of u are automatically in here. Also, the accumulation points on the unit circle of the zeros of u are going to be in this lim inf zero set.
00:43:47.190 - 00:44:53.042, Speaker B: A little bit harder to see is that the support of the singular measure that arises from the singular inner factor view is also in the spectrum. And it turns out that that's basically it. And an important theorem here, Lifsch Miller theorem says that if u is written as a Blaschke product with zero sequence lambda and singular interfactor s sub mu, where mu is a singular measure, then the spectrum of the compressed shift on that model space equals the spectrum of the inner function as defined up above, which is, of course why they called it the spectrum of the inner function. And it turns out the spectrum of the inner function is what you think it should be. Well, how do you get here? We only have two ways that we know how to get there. You're in the closure of the zero set of the Blaschke factor, or you're in the support of the measure from the singular inner factor. The other result here is that the point spectrum, the set of eigenvalues of a compressed shift, is the zero sequence of the Blaschke factor.
00:44:53.042 - 00:45:25.544, Speaker B: So here. Sup? Um, that's the support of the measure mu. So this is a really interesting result, basically tells you all about the spectrum and the spectral properties of the compressed shift, and relates it to the function theory of that particular inner functions. Really, really elegant results. So what I'd like to end on is a really, really cool result that tells you why these things are called model spaces. It's going to require a little bit of setup, but it's sort of going to be the big bang at the end. So we're going to let h now denote a separable complex Hilbert space.
00:45:25.544 - 00:45:56.664, Speaker B: An abstract Hilbert space B of H is going to be the set of bounded linear operators on h, and we're going to let squiggle equal denote unitary equivalence. So we're now not thinking about h two. We're dealing with abstract Hilbert spaces. So let's suppose that t is a contraction on H. In other words, its operator norm is at most one. It turns out that you can get a direct sum decomposition of t in a very, very nice way. T can be written as the direct sum of two operators, one of which is unitary.
00:45:56.664 - 00:46:34.708, Speaker B: Now might not actually exist. But this is the generic case here. And k is something called a completely non unitary contraction. Again, either sum and could be absent for a particular t. We have two types of contractions that we can split into unitaries which we're pretty comfortable with, and then these completely non unitary contractions. So those are contractions which don't have a reducing subspace upon which k happens to be unitary. So k is completely non unitary cnu if you cannot find a reducing subspace, a subspace invariant under k and its adjoint upon which k happens to be unitary.
00:46:34.708 - 00:47:12.348, Speaker B: So you've stripped off all possible unitary parts of t, and you've stuffed it into this factor. And what you're left with is something that is totally not unitary at all, and there's no reducing subspaces upon which that acts unitarily. So you split it into a good part and a bad part. So the reason we care about c and u contractions is because the spectral theorem tells us almost everything we could want to know about unitary operators. Unitary operators are pretty much handled by the spectral theorem. It's the CNU part that we're interested in. And so here's a seminal theorem of Nagy voyage, and it's a really, really beautiful theorem.
00:47:12.348 - 00:47:29.354, Speaker B: And in fact, I was prepared to give the proof, although I'm sure I'm not going to have enough time. However, the proof is going to be in the notes and also in the slides which I believe you will be provided. So if you want to see the details of this, I suggest you have a look. It's a really beautiful theorem. Really beautiful. Nice proof. And the theorem says this.
00:47:29.354 - 00:48:18.964, Speaker B: I start with a with a bounded operator on a Hilbert space. I probably need that to be a contraction there. Okay, but let's suppose that the powers of t tend strongly to zero, so t to the n tends to zero. Any strong operator topology of script h, or in other words, for every x, the norm of t to the nx tends to zero, so it's really making things smaller eventually, right? Every vector eventually gets sent to zero upon iteration yt, and you satisfy this defect one condition. In other words, t is close to being unitary. It's unitary ish, but it's not. Because if t were unitary, I minus t, t would be the zero operator, I minus tt would be the zero operator, but I'm assuming it's not.
00:48:18.964 - 00:49:01.400, Speaker B: But let's say it's close that the rank of these two self adjoint operators is not zero, but it's equal to one. So we're kind of close to being unitary. We're unitary ish. So if we satisfy these hypotheses, well, then it turns out t is basically the restriction of the backward shift to a model space. So out of this abstract hypothesis, t should be a contraction, satisfies the powers of t going strongly to zero, satisfies this so called defect one condition, or defect one one condition. Then out of that abstract hypothesis, there exists a concrete inner function. There is an inner function u, so that t is unitarily equivalent.
00:49:01.400 - 00:49:46.494, Speaker B: So for all practical purposes, t is the backward shift restricted to the model space. Ku so in other words, we have a functional model for defect one one contraction. So contractive operators which satisfy this have a model, a concrete operator that we can identify this abstract operator with. We can say, well, if I want to study operators that have these properties, I should be doing some concrete function theory, and I should be looking at the backward shift on this model space, a concrete subspace of the Hardy space H two. So this is what I mean by a functional model. By model spaces, these spaces help us model certain abstract operators. And again, I would show you the proof, but I am afraid I am out of time.
00:49:46.494 - 00:50:04.364, Speaker B: I will try and amend this to put the contraction hypothesis in there. But again, if you want to see any of the details, the slides will be provided to you, as well as the corresponding book chapter in the volume that I believe we are producing for this special season and thanks for your attention.
00:50:06.904 - 00:50:21.204, Speaker A: Thank you very much. Let us thank the speaker. Any questions for Stefan? So just shout them out because there are more than 100 participants.
00:50:24.344 - 00:50:31.614, Speaker B: I see some comments in the chat about people being unable to download the slides or the chapters.
00:50:32.114 - 00:50:39.934, Speaker A: So Java just put another version. Let me try. Yes, it works. So the new version is downloadable so try again.
00:50:40.434 - 00:50:49.002, Speaker B: I think the issue is you have to click on it and then wait for it to download and then after it downloads you have to click on it again and then it'll open.
00:50:49.058 - 00:50:58.784, Speaker A: So yeah, so there is a question in the chat, if the rank is greater than one, then is the result true?
00:50:59.444 - 00:51:36.098, Speaker B: Sure. Let me go back to the, let me go back to the slides then. So the answer is yes and no. It's going to become more complicated and force you to consider the matrix or operator valued inner functions. And you can't even in the case where these are equal, you basically have to deal with matrix or operator valued inner functions if they happen to be unequal. They're yet more complicated ways to handle things. But from my perspective, I really like the concrete function theory.
00:51:36.098 - 00:52:32.714, Speaker B: And it turns out once you step away and start dealing with matrix or operator valued inner functions, you don't have such a simple, nice way of saying oh, flash gate product, singular inner function and works out. Now of course there are substitutes for blaschki products and singular inner functions and those sort of things in these higher dimensional examples and higher dimensional settings, but they somehow they're great and they're probably about as best the best you could possibly do, but they're just not as concrete. And the function theory just happens to be a bit more abstract because oftentimes you just can't write down like oh, Lashkate product, the product of nice disc automorphisms that I can play with and use classical complex analysis tools on. So the answer is yes, there are many generalizations of this that apply for other pairs of defect indices, but they're none of them are as, as great and concrete as dealing with stuff in the classical hardy space.
00:52:34.894 - 00:52:42.714, Speaker A: Thank you. There is another question in the chat. Does the restriction of a stat or any model space satisfy condition one and two?
00:52:43.574 - 00:53:07.384, Speaker B: Yes, that is also true. I believe I have that in the book chapter as well. But it's something. Yeah, I believe it'll follow from the proof also. But yeah, I suppose I should have said that, that it does sort of work the other way around. If you look at the restriction of the backward shift to a model space, it does satisfy both of these criteria.
00:53:10.224 - 00:53:18.044, Speaker A: Another question in the chat what space do we obtain if we replace the thugger part of the model space reproducing kernel by the Berwyn kernel?
00:53:19.704 - 00:54:12.124, Speaker B: That is a really good question. I'll have to punt on that question. Probably give that to Stefan Richter or one of the other Bergman experts here. Now, my feeling is that most of this stuff falls apart because, as you can probably see, we're using the very special property that h two is sitting inside, capital l two, and we can deal with stuff on the boundary. Now, when you're dealing with the Bergman space, you don't necessarily have really nice, well behaved boundary values that sit inside some larger, nice ambient space. So a lot of the tricks and techniques for model spaces probably don't work out as nicely. Now, I'm not saying that nothing works out, but I'm saying that it's probably going to be quite a bit different just because that idea of just not even working on the disk but just pushing everything to the boundary and dealing with Fourier series and the boundary just isn't going to work.
00:54:13.464 - 00:54:24.944, Speaker A: Thank you. More questions or comments? If not, let's thank Stefan again. And we have.

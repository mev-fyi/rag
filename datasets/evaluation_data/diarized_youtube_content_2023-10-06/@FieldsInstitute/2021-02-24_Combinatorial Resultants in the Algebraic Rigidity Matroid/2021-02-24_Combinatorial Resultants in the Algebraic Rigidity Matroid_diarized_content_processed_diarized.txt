00:00:00.440 - 00:00:30.826, Speaker A: And this is the result of the work done with Goran Malic. He's been a postdoc in my group for a while, and it was good to have the pandemic to be able to sit down and write this all. Anyway, so the title is combinatorial resultants in the algebraic rigidity matriarch. And while the rigidity is the common theme that everybody recognizes, I'm not sure about the rest. So I'll go slowly. I'm going to start.
00:00:30.930 - 00:00:31.734, Speaker B: Whoops.
00:00:32.114 - 00:01:08.518, Speaker A: Okay, now what is this doing? Okay, excuse me, I guess I have to be 1 second. This is weird. Strange. Let me stop. Oh, okay, it's working. I don't know why. I don't know about the delay.
00:01:08.518 - 00:01:15.554, Speaker A: I don't know why. Sorry, I need to stop sharing. So it looks like it has a mind of its own.
00:01:16.414 - 00:01:17.274, Speaker B: Okay.
00:01:37.274 - 00:01:43.970, Speaker A: I'm going to try again. So can you see it now? Can you see anything?
00:01:44.042 - 00:01:45.620, Speaker C: No, it's just you.
00:01:45.802 - 00:02:07.364, Speaker A: Yeah. Okay, so I heard no. Right. Okay, so I need to do something else. It's. It's strange because I used it before, but I used it with a different zoom where I was the one controlling it. So it looks like there is a different thing right now.
00:02:07.364 - 00:02:27.344, Speaker A: Christoph, you could make Ileana a co host if that might help. The settings are that anyone can share their screen and she was sharing before, so. Yeah, I was sharing. It's just that I did not, I could not control it. So for some reason. Let's see if it works now. Yeah, you bet.
00:02:27.344 - 00:02:30.796, Speaker A: What's going on?
00:02:30.940 - 00:02:31.828, Speaker B: Make sure you.
00:02:31.956 - 00:03:03.844, Speaker A: Okay, okay. Okay. So I'm going to start with the motivation and I'll tell you how we get from the localization problem to circuit polynomials, which is the main topic behind this big title. So the localization problem is the following. You are given a graph and you are given some positive weights on its edges, and you want to find the placement of the vertices. And I'm going to work. Everything will be in the plane so that the edge length match the given weights.
00:03:03.844 - 00:03:51.480, Speaker A: Right. So that's a standard classical problem, very well studied. Here are some graphs, and you recognize from the rigidity point of view, there are some differences. I give you some weights and what do we know about it so we can solve the localization problem in principle. What does it mean? Well, here's an approach. You set up a system of quadratic equations, the unknowns being the cartesian coordinates, and write the conditions that the edges match the given length, so that the possible placements are among the real solutions of this system. Rigidity theory can help predict a priori whether the set of solutions will be discrete, if the graph will be rigid, or continuous if the graph is flexible.
00:03:51.480 - 00:04:31.158, Speaker A: And in the rigid case, we may run the Grosvenor basis algorithm, the double exponential graubner basis algorithm, in principle, to eliminate, let's say, all but one of the variables. And once we get a polynomial in a single variable, then we can use numerical methods to solve it. Then we select one of the solutions, we substitute it and repeat until we get all the solutions, all the coordinates. So that's in principle. Let me talk about a slightly apparently simpler problem. So I'm going to call it the single unknown distance problem. As before, we are given a graph.
00:04:31.158 - 00:05:03.932, Speaker A: Also, we have positive weights on its edges. Positive will not matter too much from now on. It's just the motivation comes from here. And what we want to find is all the possible values of a single unknown distance. Yeah, so this is the graph and this is the distance. And you recognize the given graph with the edge weights is a Laman graph. And we just ask what is, what are the possible values for this length? Okay.
00:05:03.932 - 00:05:47.206, Speaker A: And if we are able to solve this problem, then we can solve the localization problem by constructing a trilateration. So that's the motivation problem. And let's see, what could we do about this problem? Again, in principle, here's how we could solve it. So this time we're going to use kili coordinates, namely the coordinate. Now, coordinates are not the cartesian coordinates, but the square distances between points. And using a bunch of theorems. And that will be the part of the later in the talk from distance geometry, rigidity matrix theory, we reduce the problem to finding a certain irreducible polynomial in the Cayley Menger ideal.
00:05:47.206 - 00:06:18.640, Speaker A: And this is called the circuit polynomial. Now, it's a polynomial in these variables, the unknown distances. And the support of a polynomial corresponds to a graph. Yes. So each variable corresponds to an edge in the graph. So the support of this circuit polynomial corresponds to a circuit in the rigidity matrix. Now, if we substitute the given edge length in that circuit polynomial, we get a univariate polynomial, which can be solved for the unknown distance.
00:06:18.640 - 00:06:37.128, Speaker A: Yeah. So again, this is in principle. So here's an example. So the given graph, it's a minimally rigid graph. It's a collection of triangles. And if I place one edge here, you see my mouse? Do you, is my mouse busy? Yes. Okay.
00:06:37.176 - 00:06:38.160, Speaker C: Yeah, it is.
00:06:38.352 - 00:07:05.024, Speaker A: Good. So if we place this edge here, we have one small circuit. If we place it here, we have a slightly larger circuit. If we place it here, we have a circuit that spans the entire graph, and that is what we need. If we find the circuit polynomial of that particular circuit, then we can find the possible values of that particular distance. So that's the motivating problem. So here's our main problem.
00:07:05.024 - 00:07:26.590, Speaker A: So the main problem is now, given a rigidity circuit, compute this corresponding circuit polynomial. Okay, so that was the motivation. But this is the problem that this talk is about. It's not about the other problems. So here's an example. That's the smallest possible one. It's the tetrahedron k four.
00:07:26.590 - 00:08:14.934, Speaker A: This is its circuit polynomial. And variables x, I, j correspond to unknowns, right? Unknowns correspond to edges of the graph. So there is a one to one correspondence between the possible supports of the circuits and the edges of the complete graph. So the support of this particular graph are these variables, and as you see, they correspond to all the edges. And then we can use the circuit polynomial to solve the single unidistance problem. Right, okay, here's how we do is in this polynomial, you substitute values for all the variables except the unknown one. So let's say that we want to find the distance between vertices one and four.
00:08:14.934 - 00:08:53.254, Speaker A: We look at all the positions of one four, we see the polynomial is of degree two. So yes, it has two solutions, trivial. We know that, we knew that already, nothing new here. So let's see, how tractable is the problem of finding a circuit polynomial in principle. Again, we can use the double exponential time Grosvenor basis algorithm with an elimination order. And this is important. So, in practice, Grabner basis algorithms work with lexical graphic orders with various orders, but with an elimination order, they reportedly, they don't behave well.
00:08:53.254 - 00:09:33.186, Speaker A: And so we wanted to verify this and we tried a few examples. The largest we could do with the Grosvenor basis function in mathematica took five days and 6 hours. In all other cases, the execution timed out or crashed. So our goal was to make such calculations more tractable by taking advantage of structural information that is inherent in this problem. So let's see, here are our results. First of all, we have a new algorithm to compute a circuit polynomial with a known support. Yes, the support will be circuits in the sense of rigidity, and our algorithm relies on resultant based elimination steps.
00:09:33.186 - 00:10:15.964, Speaker A: So we'll do elimination, but not with grammar basis. We do it with resultants that the result, the elimination, is guided by a novel inductive construction for rigidity circuits. Yeah, so I guess for this audience, for the rigidity people, especially from the combinatorial point of view, this is the most attractive part, novel inductive construction. And now we also implemented the algorithms and let's see what we got. So the only previously known circuit polynomial, to the best of our knowledge, we searched through the literature everywhere. By the way, I'm going to give references towards the end. I just want to introduce the problem first.
00:10:15.964 - 00:11:02.056, Speaker A: So the only previously known circuit polynomial is for the k four circuit. We've seen it, it has four vertices, the polynomial has 22 terms, there is no need to compute it because it's already a generator of the Kalimanger ideal. What we obtain in practice computationally, we obtain all circuits with five and six vertices, a few with seven, and the largest we could get has something like 2 million terms. So here are the circuits on six vertices, let's give them some name. This is the banana, this is a wheel, this is the dessert graph plus one extra edge, and that's the k 33 plus one extra edge. So I call them the Czar plus one, k 33 plus one. And these are our results.
00:11:02.056 - 00:11:52.870, Speaker A: Right? So we put here for those where we could run Grosvenor just for you to see the difference. And this is with a grammar basis in mathematica. And we had a strong computer. I'm not claiming that we have the fastest computer in the world, but we rendered the algorithm on the same computer and it was, the details are in the paper, but it was a very recent and very powerful computer and you can start seeing the difference already. So you see how the number of terms grows very grammatically, this is the homogeneous degree of the polynomial. The polynomials are homogeneous and that's the largest we could compute. So this one is five days, 6 hours, and it has 600 plus terms.
00:11:52.870 - 00:12:36.602, Speaker A: And our algorithm solved it in 40 seconds. So we were very proud of this. Then we tried to compute k 33 plus one and there we ran into a lot of challenges, and if I have the time, I'll tell you about some of them, because that requires an extension of our method and. But today I'm going primarily to focus on what is, because a lot of this is completely new. So here's an overview of what I want to talk about. First of all, I want to talk about this new concept, the combinatorial resultant of two rigidity circuits. That's a construction, it's a step that to the best of my knowledge, of our knowledge, it has not been invented before.
00:12:36.602 - 00:13:15.580, Speaker A: Then we have a combinatorial theorem. So we proved the existence of an inductive construction of rigidity circuits based on combinatorial resultants. So every circuit has a construction with this operation then, and that's the bulk of the paper, the algebraic theorems. So we have, based on this method, now we have an algorithm, right? So we have an algorithm for computing the circuit polynomial based on the inductive construction. We use it as a blueprint for applying Sylvester resultants. But there are a number of tricks along the way. So we combine with polynomial factorization ideal membership.
00:13:15.580 - 00:13:47.114, Speaker A: I'll tell you more along the way. So the method, it's faster, but still exponential. We cannot expect anything else, even the polynomial explode. But it provides structural insights into algebraic elimination problems in the Caylemanger ideal. And probably for this workshop we'll have a lot of interesting open questions. Okay, so that's the plan. Okay, so let's get started.
00:13:47.114 - 00:14:44.128, Speaker A: There is a lot to cover in order to, just to explain the terminology. So the rigidity theory, I'm going to assume mostly that people in the audience know, except here and there I may mention a word and explain. I'll probably introduce everything and give the definitions in the end. So I'm introducing everything informally. But this is what you'll hear about, about the Cayley Menger ideal, about matriid theory, not just in the sense of combinatorial rigidity or linear matriid, but mostly about the algebraic matrix. We'll talk about algebraic matrix defined by a prime ideal and the connection with elimination theory, Grosvenor bases and so on. So let's start with the rigidity, combinatorial rigidity part and introduce this new concept, the combinatorial resultant of two rigidity circuits.
00:14:44.128 - 00:15:21.950, Speaker A: Okay, so let's look at a few small circuits. For n equals four, we have just the tetrahedron. For n equals five, we have the wheel, and then there are the four with the six vertices. So as graphs, all of them are three connected, except the double banana, which is three connected, but it can be decomposed into, sorry, it's two connected, but can be decomposed into three connected components. So let's look at this operation first. So this is a special case. It's two sum, the two sum of, in general, of two graphs.
00:15:21.950 - 00:15:50.674, Speaker A: I'll demonstrate it for circuits. Here we have two tetrahedra and the operation of two sum consists in selecting one edge in each of them and identifying it. So in other words, that you view the two graphs sharing the two vertices and the edge between them. And then I'm eliminating that edge. So that's the two sum operation. Here are some facts well known. The two sum of two circuits is a circuit.
00:15:50.674 - 00:16:30.382, Speaker A: And the inverse operation, the operation by which I take grab that is too connected and split it by essentially bringing back, splitting it into parts and bringing back that edge, is called a two split. So when you do a two split of a circuit, you get a pair of circuits. When you do a two sum of two circuits, you get a circuit. So a circuit that is not three connected can be decomposed into three connected pieces. So this is an example. So we have here a big one and we do a two sum here and the two sum here. And we have three pieces that each of them is three connected.
00:16:30.382 - 00:16:59.174, Speaker A: So now we have to focus on the three connected pieces. And we already know something about this. This is the famous inductive construction for circuits of Bergen Jordan. And after you split in three connected components, the three connected circuits admit, admit an inductive construction via Hennelberg two extensions. This is just illustrating the step. Yeah, so beautiful. So we actually wanted to use this example.
00:16:59.174 - 00:17:38.083, Speaker A: And the problem is with the Henneberg extensions is that we do not know how to find the circuit polynomial of the Henneberg extension. So our goal, however, is to find an inductive construction that has a direct algebraic interpretation. Okay, so that's the goal. So we are getting something different from Bergen Jordan with a different operation. And our operations have a direct algebraic interpretation. That's the result. So we define the combinatory resultant, actually as a generalization of the two sum.
00:17:38.083 - 00:18:14.414, Speaker A: So let's see how it goes. So let's take a small case. This is the smallest case that is not, that is three connected, right? So it cannot be obtained via two sums. So let's obtain this one via our operation, and then I'll define it formally. So we start with two k four circuits. It has to be something smaller, right? So, and they are only k four s. But this time, instead of identifying one edge in each and considering that to be the common part, we assume that they have a common triangle.
00:18:14.414 - 00:18:37.070, Speaker A: And in this common triangle, we choose to eliminate one of the common edges. Yeah. So that's what we do. We, these graphs, now put them together, eliminate that edge. And here you go, we obtain the wheel on four. Okay, so let's look at the general case. So the operation, of course, can be defined on graphs.
00:18:37.070 - 00:19:06.254, Speaker A: In general, we have two graphs. They overlap in at least one edge. So the graphs are on sets of vertices, they don't completely overlap as vertex sets. They have some, something in common. And on the common part there is one edge that you eliminate. Okay, so the combinatorial resultant of two circuits viewed as edge, as collections of edges. You take the union of edges and delete the common edge.
00:19:06.254 - 00:19:43.950, Speaker A: E. Okay. And the beauty of this is that the combinatorial resultant has a direct algebraic interpretation. It is the, the Sylvester resultant of two polynomials. What is it doing? I'm not going to go too much into the details of the algebraic elimination, but the idea is you have a poly, you have two polynomials, and the Sylvester resultant is the determinant in terms of the coefficients of the polynomial. Right. So the variable that we are eliminating, we are eliminating the variable in those two polynomials.
00:19:43.950 - 00:19:47.430, Speaker A: In other words, so it is, are.
00:19:47.462 - 00:19:54.234, Speaker C: You asking anything other than overlap on one edge, like for the vertex overlap, do all the edges have to agree or something like this?
00:19:54.694 - 00:20:15.980, Speaker A: Wait, wait, wait a little bit. Yeah. So, so far I'm not asking anything, I'm just defining it. Yeah. So I'll get a little better on for conditions under which we want to have something interesting happening, but so far nothing. Right. So think about having two polynomials with arbitrary number of variables, right.
00:20:15.980 - 00:20:45.438, Speaker A: You select there is a common variable in the two of them and you want to eliminate that variable. So that variable, all the other variables go into the coefficients, and the coefficients go into the Sylvester polynomial. You take the determinant, you get the polynomial without the variable that we want to eliminate. That's the idea, yeah. And this works in general, but for graphs, that's the interpretation. So I'll tell you more in a moment. So let's see, so far, operation is general graphs.
00:20:45.438 - 00:21:10.690, Speaker A: Let's see what happens for circuits, because that's our goal. Yeah. We want to understand what is happening with circuits. So now we take two rigidity circuits, c one and c two. They overlap on at least one edge. We define the combinatorial resultant in the same way, and we ask under what conditions is the combinatorial resultant, resultant of two circuits, also a circuit. Yeah.
00:21:10.690 - 00:21:40.182, Speaker A: So that's the question. And here we'll come up with some conditions. Okay, so let's see. That's, by the way, this is an open question. In full generality, it's an open question, but here we have a lemma and that would be enough for what we want to do. You'll see in a moment. So if the intersection of the two circuits is a Laman graph, if and only if, right.
00:21:40.182 - 00:22:21.514, Speaker A: Then the combinatorial resultant of two rigid circuits is a Laman plus one graphic. So we have a condition, but it's not sufficient. So let me give you some examples. So first of all, remind everybody, even graduate students, I know this has been beaten to death, but remind everybody, a Laman graph is two three sparse graph, and these are the minimally rigid graphs. And rigidity circuits are two three sparse on subsets, but the total number of edges is two, two, two, n minus two. Yeah, and that's, the terminology comes from the rigidity matrix. The bases are the Laman graphs.
00:22:21.514 - 00:23:04.266, Speaker A: We have independent, dependent and circuits, the minimally dependent ones, which are defined as above, and the laman plus one graph. It's one graph that you obtain by adding exactly one edge to a Laman graph, and this graph contains exactly one rigidity circuit on possibly a smaller set of vertices. But, but that's what you get, you get the laman plus one graph. Yeah. So these are, this is the condition that is here. So if you have two circuits and they overlap on a Laman graph, if they don't overlap on the Laman graph, you cannot even get a laman. If you don't, if they don't overlap on Laman graph, you don't even get a laman plus one graph.
00:23:04.266 - 00:23:37.054, Speaker A: And the circuit is a laman plus one graph that spans everything. Yeah. So the open question is, when is it always a circuit? So let me give you two examples. We call this circuit invalid combinatorial resultant. We take a combinatorial resultant of these two graphs, a wheel and a k four, and I overlay them so that the overlap is in this la man graph that is two triangles. Yeah. And I eliminate this edge and that's the result.
00:23:37.054 - 00:24:03.240, Speaker A: So the result has asserted here and Henneberg one here. So it's a laman plus one that is not a circuit. Yep. So the operation always gives a laman plus one, but not necessarily a circuit. And here's another one. We call it circuit valid combinatorial resultant. So in this case we have in fact the same operands, the wheel and the k four.
00:24:03.240 - 00:24:57.130, Speaker A: But this time the overlap is just on one triangle and we eliminate this edge and the result is a wheel of five, which is a circuit. Okay, so I promised that there will be a lot of interesting open questions. So let me start with the first one is we have a condition, a necessary condition, but is not, is not sufficient for the, so the goal is to find necessary and sufficient conditions for the combinatorial resultant of two circuits to be a circuit. So just give me conditions. Yeah, so that when you put them together, you always get a circuit. But it turns out that for our purpose, if we will not even need that, and there will be more, more open problems soon. So let's move on to what we have proven.
00:24:57.130 - 00:25:32.644, Speaker A: So our first result, the combinatorial theorem, call it we prove the existence of an inductive construction for rigidity circuits based on the combinatorial resultants. Yeah. So what does it say? So let's read it slowly. Each rigidity circuit can be obtained by applying combinatorial resultant operations starting from k four circuits. The construction is captured by a binary resultant. Read whose nodes are intermediate rigidity circuits and whose leaves are k four graphs. Right.
00:25:32.644 - 00:26:02.394, Speaker A: So here we start from k four. You cannot see the labels, but I'll go into more detail in the next image. But I want to illustrate that three, it's not linear as a Henenberg two or Heneberg operation. So it's a tree of possibilities. These two wheels are different. So this is a construction of the, what is this, the k 33 plus one. Yeah.
00:26:02.394 - 00:26:46.486, Speaker A: Circuit from two wheels of four, which themselves are constructed from each one from two k fourth. So first of all, the resultant tree is not unique. So this is the construction that I've shown you before. And each operation, actually you have to specify not just the graphs that enter, but actually the labeling on the vertices so that you know what is in common and what is the edge that you eliminate. So in this case, the two six is eliminated. So the operation is with a label here what you eliminate among the part that is in common. So here's one way of obtaining the k 33 plus one.
00:26:46.486 - 00:27:03.954, Speaker A: This is one tree, this is another tree. This is more linear. Right? So construct, add k fourth, this is another one, much bigger. Yeah. So it's not unique. There are many such trees. And I'm going to tell you the proof.
00:27:03.954 - 00:27:54.604, Speaker A: Actually, let me give you an overview. So of course, yeah, it's an induction. So for the inductive step, we use an adaptation of a weaker lemma from Bergen Jordan's proof that a three connected circuit, a three connected circuit has a inverse Henneberg step, but one lemma in their paper says that the three connected circuit has at least two non adjacent degree three vertices on which an inverse Hannenberg two operation can be performed. So we are using dyslima, but in fact we need something even weaker than that, which makes the algorithms a little faster. Yeah, so let me explain that. So the proof comes in the next slides. So this is the essence, right? So let's go slowly.
00:27:54.604 - 00:28:37.494, Speaker A: We have a circuit, three connected circuit with n plus one more than five vertices. Then in polynomial time we can find two circuits, a and b, such that a has just one fewer vertex. B can have at least one less, right, may have fewer. So one of them is exactly one fewer vertex, the other may be smaller. And c can be represented as the combinatorial resultant of a and b. Okay, and the proof is in these two pictures. So let me explain that.
00:28:37.494 - 00:29:11.714, Speaker A: So this is our circuit c. And according to Bergen Jordan, we can find two vertices of degree three non adjacent. So that if you do, you can do an inverse Hennelberg operation. In fact, we are going to use to do the Hanneberg operation only on this red vertex. And that's what is presented here. So on this graph, we do an inverse Henneberg on this vertex, on the red vertex. So we remove the three edges and we place this edge back.
00:29:11.714 - 00:29:45.624, Speaker A: And the result is a circuit. And this is our circuit a. Yeah. So one of them comes directly an inverse Henneberg, according to Bergen Jordan. The other we use the fact that we have another vertex of degree three that is not adjacent with this one. So here's how we will obtain the blue circuit. We remove the three edges incident to the blue vertex and we keep the edge that was added in the previous construction.
00:29:45.624 - 00:30:18.106, Speaker A: So remember we had to put red edge back to get the red circuit. So we keep it. Okay, we keep this red edge. So when we remove these three edges, the result is a laman graph because it was a circuit. Right? So I'm removing three edges from a circuit. So the result is a Laman graph and I am adding one edge. So I'm obtaining a laman plus one graph that spans a unique circuit.
00:30:18.106 - 00:30:51.614, Speaker A: And that would be my blue circuit. Okay, and you can verify that the combinatorial resultant of this red and blue produce exactly the original circuit. So that's the, that's the construction, that's the proof. Any questions? Okay, so let me move on then. Let me give you some open questions here, because there are many. So I added to the first one. First we'd like to have necessary.
00:30:51.614 - 00:31:37.006, Speaker A: So the construction goes backwards, right? So we know that there is a way. In fact, there are many ways, because the vertices of degree three, there may be several of them. So even inverse combinatorial resultant constructions are many trees. You can choose whatever it's convenient, but we'd like something to go bottom up. And for that we will need some necessary and sufficient conditions. When can we combine these two graphs? In what way? Well, we know we need a common laman graph, but how can we combine them so that we get a circuit without much ado? So that's the first problem. The other problems are all related to the algorithm.
00:31:37.006 - 00:32:03.404, Speaker A: So the algorithm, each step, each inductive step, it's relatively easy to obtain it. Yeah. So it's a combination of, you know, pebble games, whatever. So it is, it's easy to do the combinatorial step, but overall, because the tree can be balanced. So let me go back a little bit just to look here. Yeah, so this is an example. The tree in principle could be balanced.
00:32:03.404 - 00:32:51.026, Speaker A: It means that you might have to do an exponential number of steps. So the length, because the construction drops just one vertex at each step. In principle, the height of the tree can be linear, and if it is balanced, it is exponential. But the punchline is that we don't have such examples except for the trivial one that I have shown you. So here are some questions. Can you find non trivial infinite families of balanced or not even balanced exponential size resultant combinatorial resultant trees, if not, characterize the circuits obtained by the worst case size of the combinatory resultant trees. We don't know how big the tree is, and that will give the overall complexity of the algorithm.
00:32:51.026 - 00:33:31.624, Speaker A: So we want to refine the time complexity for the algorithm, and if not, analyze and find bounds on the number of combinatorial resultant trees, because sometimes you may want to get one that is better than the other. Remember, this is the cheap step. This is the combinatorial step. The expensive step is the computation of the resultant. And I'll show you in a moment. That's where the difficulty comes. But if we could at least understand the correlation between the combinatorial step and the algebraic step step better, we might simplify a lot these horrendous calculations that are involved in computing these polynomials.
00:33:31.624 - 00:34:13.074, Speaker A: I leave you to these combinatorial problems. I'll get back to them in the end for further questions. Let's move on now to the algebraic theorem. Now we want to use this inductive construction as a blueprint for applying the Sylvester resultants. So we will now start at the bottom and work our way up to the circuit, because we know we eliminate variables and eventually we'll get there. But how? Yeah, can we guarantee that we get circuits all throughout? So let's see, here's the algorithm. So let me walk you over the algorithm.
00:34:13.074 - 00:35:03.674, Speaker A: So the input is, so the algorithm, just for one step of the result and not for the whole inductive part, right? So it depends on the size of the tree, but just one step. Let's do one step. So the input is given by two circuits and an edge in such a way that given circles that the combinatorial resultant of a and b, by eliminating the edge e is a circuit, and we are given the circuit polynomials for a and for b, and we are given the elimination variable e and the output. We want to obtain this circuit polynomial for c. So the first step is, of course, compute the resultant. We already eliminate it. The problem is that the polynomial may not be irreducible.
00:35:03.674 - 00:35:26.448, Speaker A: If it is irreducible, we are done. That's exactly the circuit polynomial. Return it. By the way, I'm going to talk about the theory if I have the time towards the end, so, but right now I just present the algorithm. So if it is irreducible, return. In some of the cases, we got it immediately, in some other cases, no. Yeah, so here's a question.
00:35:26.448 - 00:36:04.516, Speaker A: Under what conditions on the circuits a and b, and given the circuit polynomial, is it guaranteed that the resultant actually is irreducible? Have no idea. Yeah. So more experimentation is required in order to even formulate a conjecture here. Good, so this is the first question. Identify conditions so that the resultant is irreducible. If it is irreducible, then it is the circuit polynomial. Otherwise you have to factor the polynomial, factorize it.
00:36:04.516 - 00:36:34.384, Speaker A: And we have examples where this is necessary even in the calculation that we carried out. So we factorize. Good. So now you have at least one of these factors will be your circuit polynomial. We know that because the resultant will be in the ideal, so the circuit polynomial will be there. But how can we get rid of the others? So here's a simple case. When you can get rid of the others, some of these factors will have support.
00:36:34.384 - 00:37:07.802, Speaker A: That is, a strict subset of the support of the circuit. And circuit is minimal, dependent in the ideal. So anything with support smaller than that is independence is not in the ideal, you can get rid of it. That's another simple case. Here's the fact is that in all of our examples, the extra factors had smaller support. We didn't have to examine. The rest of the algorithm is just conjectural.
00:37:07.802 - 00:37:39.120, Speaker A: We don't know whether we'll have to do anything beyond this. So of course these are discarded, as I said, because they are not in the ideal. So we don't know. This is another open question, under what condition? Or is this true? Since we don't know that, we need to get the algorithm all the way to the end. What can we do? Oops. So. Oh, yeah, yeah, so sorry, I hear, I wanted to put the open problem immediately.
00:37:39.120 - 00:38:33.150, Speaker A: So we want, who wants to work on this? So identify conditions for the resultant of two circuit polynomials to have exactly one factor that is supported on the combinatorial resultant circuit, one factor up to multiplicity. Yes, because the others are immediately eliminated. And again, it's very easy module of the factorization, which is not a trivial operation itself. And the punchline is that, as I said, we did not encounter examples where this was false. But if this is true, then you return the unique factor supported on C, otherwise you still have to continue. So what can we do? Well then let's say that we have some factors that are on the same support, and some of them, one of them may be in the ideal, the others may be extra factors. Right.
00:38:33.150 - 00:39:25.624, Speaker A: So we want to get rid of the others. The only way you could proceed, you can apply an ideal membership test, and this is still Grosvenor basis. However, it's not Grubner basis with elimination, it's with any order and in principle should work fast. Yeah, so this is the algorithm, and here are some of the remaining questions, and they seem to be very hard. But we hope that the Grobner basis community, which is very active and large and have beautiful tools and computers beyond what we had access to, may be interested in working on such problems. So, besides the two problems that I mentioned before, we like to identify conditions for the resultant of the circuits circuit polynomials to have more than one factor, right. Each one up to multiplicity.
00:39:25.624 - 00:39:59.174, Speaker A: That's how we count them, supported on the combinatorial resultant, at least one example. We'd like to see one example. We have not seen it, and in this case only one of them is the circuit polynomial. But if you find one example, it means that our algorithm has to go all the way to the end, and at least that puts it in a different category of complexity. Okay, so let's see. So now I am, oh, I have good time. So then, okay, any questions so far? Because if not, I'm going to tell you about the underlying theory.
00:40:01.074 - 00:40:02.362, Speaker C: Yeah, I do have a question.
00:40:02.498 - 00:40:03.266, Speaker A: Yes.
00:40:03.450 - 00:40:10.894, Speaker C: So what is the best upper bound that you know for your algorithm? If the complexity, you know, if all the steps are needed. Have you worked it out?
00:40:12.584 - 00:40:56.704, Speaker A: Yes. So there is a formula in our paper where we look at the, we look at the growth in the degree of the resultant. So it's a homogeneous degree, and we have some bounds we found in the literature, bounds on the degree that is obtained. So we have something, it's obviously explicit, exponential, I cannot tell you in detail, exponentially in this and this, because there are so many factors involved here. But obviously I said from the very beginning it's still exponential, but it is guided by something that, you know, where it leads. You are not doing a huge search like the Grosvenor basis does. Right.
00:40:56.784 - 00:40:58.800, Speaker C: I mean, but is it simply exponential?
00:40:58.992 - 00:41:00.124, Speaker A: I don't know.
00:41:00.464 - 00:41:01.112, Speaker C: Okay.
00:41:01.208 - 00:41:27.374, Speaker A: Yeah. I mean, we did not analyze it to that level of detail because everything that we could find was in the literature on, you know, it puts together algorithms of other people. Right. So if we want to do factorization, if we want to do grubner basis with this. If. Yeah, if in the end you have to apply everything, you'll have to use grubner basis for the ideal membership. Right.
00:41:27.374 - 00:41:32.130, Speaker A: So then criminal basis is doubly exponential. Yes.
00:41:32.202 - 00:41:43.642, Speaker C: So, okay, so we're back in the sort of thing where Grubner basis basically doesn't work on real problems. But people say that if you sacrifice a chicken and use the right term order, it will work in practice.
00:41:43.738 - 00:42:06.480, Speaker A: Yes, exactly. And here's the term order is essential. The term order is what, so what we do with the. Okay, so, yes, exactly. So the, the ideal membership is not, the elimination order is a bad one. Right. So that's, it's double exponential.
00:42:06.480 - 00:42:09.680, Speaker A: It seems to require double exponential time. Right.
00:42:09.832 - 00:42:12.944, Speaker C: So I've also tried, believe me, I agree with this.
00:42:13.064 - 00:42:41.432, Speaker A: Yes. Okay. So anyway, we can have a long conversation on this because we have tried for at least, well, a long time, and everything that we are talking about has been computed. Whatever we have been able to compute is on a GitHub and all the polynomials that we computed are there. It's huge. It's just storing one of them. So I'll, I'll get back to the table later with this fresh view, but.
00:42:41.608 - 00:43:25.108, Speaker D: Yeah, so, yes, I have a couple of questions. Yes, Mira, first, the algebraic question. So you get this polynomial, which is potentially not irreducible. So in other words, it's reducible. But you said that most of the time all the other factors except for one are supported on smaller than the circuit, so you can throw them away. But have you ever seen a case where that's not the, the situation that you actually get something that's reducible, that more than one factor is supported on the circuit?
00:43:25.276 - 00:43:31.380, Speaker A: That's an open problem. That's what we listed. We listed it an open problem. We did not encounter such examples.
00:43:31.532 - 00:43:35.700, Speaker D: And so you never have to get to that ideal membership step at all, because remain.
00:43:35.852 - 00:43:54.708, Speaker A: Yeah, we did not, but remember, we could only compute a few of them because if you want, I can get you back to the table. It's back in the beginning. So just so that you see what we were able to computing practice. Right. So give me a second. Okay, here it is. That's what we.
00:43:54.756 - 00:43:55.484, Speaker D: Those are the ones.
00:43:55.524 - 00:44:11.572, Speaker A: Yeah, these are the ones. Right. So look, the larger. So the last two are, are two sums. So these are the easiest one. Two sum is, is reasonable. I would say you have a chance there.
00:44:11.572 - 00:44:27.748, Speaker A: So. But the largest we could get was 2 million something. This is the largest k 33 plus one. We could not get it with this method that I described. We had to do something else. That's for another talk. So this is, I don't want, it's too technical to describe it here.
00:44:27.748 - 00:44:40.380, Speaker A: Right. So, and this is with Grosvenor basis. It took five days. We computed it with Grosvenor. No, with the Zarg, the k three plus one. We could not compute it with Grosvenor basis. The computer crashed after 40 days or something.
00:44:40.380 - 00:45:01.652, Speaker A: But even with the extent, with the resultant, we had to improve on our method in order to compute it. And when we managed to compute it, it took, you know, that many seconds. Yeah. So, and it has something like a million terms. So this one, which has also about a million terms, but it was in 38 seconds compared to this one. So you see the difference. Right.
00:45:01.652 - 00:45:24.134, Speaker A: So this is not necessarily only on the, on the number of terms, this is the homogeneous degree. And you expect this to be worse, but in fact it was faster. So it's the structure, the structure of the circuit. So if you have this construction, the individual steps can be computed with a result and relatively reasonably.
00:45:24.954 - 00:45:42.504, Speaker D: Okay, then the other second question is on the combinatorial part. Okay, so are you able to get your, I mean, I'm not exactly sure at this point how you define the optimal kind of, what we call the doctor plan, the equivalent of that.
00:45:43.844 - 00:45:47.932, Speaker A: But how do you, what is the Dr. Plan?
00:45:48.108 - 00:45:50.684, Speaker D: So this, this tree that you have.
00:45:50.844 - 00:45:51.524, Speaker A: Yes.
00:45:51.684 - 00:45:59.388, Speaker D: Circuits. We have rigid objects. You have circuits. Yeah. So do you know how to get the optimal one?
00:45:59.556 - 00:46:01.868, Speaker A: No, that's another open question. Right.
00:46:01.916 - 00:46:07.302, Speaker D: So, yeah, I couldn't figure out what you meant by optimal. So, optimal is depth.
00:46:07.438 - 00:46:38.842, Speaker A: I didn't say optimal. Right. So I said, let's analyze it. So essentially there is, these things are correlated with your goal. So if you only want to compute the trees, you define combinatorial, you define it the way you want, you can, the death is going to be, it can be less than nice, because, for instance, if you think about the two sum, the two sum splits in, can split it into parts that are half of the number of edges. So the tree doesn't have to have n. Right.
00:46:38.842 - 00:47:19.524, Speaker A: Our construction, however, goes one vertex down. So in our construction, what we proved in this inductive construction, the death is going to be n. What we don't know. It can be the def n, but it may be a very skinny n. This is a skinny path where at every step you make the resultant of a larger circuit plus a k four, and that is essentially a path. In some sense, this could be the ideal. But the challenge here is that we do not know exactly the correlation between the combinatorial resultant and the resultant calculations.
00:47:19.524 - 00:47:49.724, Speaker A: So some of them may produce good polynomials that you don't have to factor. So, you know, there are so many open questions here. Keep in mind, this is completely new. I'm not aware of anybody doing this work. It's just we propose a lot of open questions because we don't have time to work on all of them. So I think it's a very rich collection of problems because it's something both on the combinatorics, on the algebraic, and there is a very interesting relationship between the two.
00:47:50.064 - 00:47:58.072, Speaker D: Yeah. So there is no combinatorial definition of what is optimal. It's at the moment.
00:47:58.208 - 00:48:22.466, Speaker A: Not at the moment. Not at the moment. Okay. Yeah. Number one is that even the number one is that we also need a few more examples. And even enlarging this collection of examples is very time consuming. So maybe the people in, in Lindsay that have the, the best grammar basis software, they could help and compute more than and other people.
00:48:22.466 - 00:48:44.578, Speaker A: Right. So there are a lot of groups in Europe that have extraordinarily fast and super optimized algorithms for computing this. So if we could get a few more examples, that would be fantastic. Right. That's all we were able to compute. So it's a take. It is setting the foundations.
00:48:44.578 - 00:49:17.588, Speaker A: We have the theory laid out, we have variations on the algorithm, and then the rest is experimental work to collect more data in order to check whether some of these things are true or not. It can maybe, can be proved by counter examples or maybe needs a theorem. So it's a lot of work. So what we are presenting here is not closed work. It's rather the beginning of a lot of work that can possibly be done by many other people. And I think it's suitable for the topic of this workshop. Okay.
00:49:17.756 - 00:49:18.824, Speaker D: Okay, thanks.
00:49:20.764 - 00:49:53.196, Speaker A: So let me go to the last part. I want a little bit there because that's the only part where I get a chance to give some credits to people. And very quickly let me do a background tour of. So what are the things? Right, so, algebraic rigidity. Metroid gets into the title and it's essential in everything. What is it? It's the algebraic matrix defined by the Cayley Menger ideal. And the Cayley Menger ideal is the, it's a prime ideal, but it's the ideal generated by the five by five minors of the Klee matrix.
00:49:53.196 - 00:50:23.860, Speaker A: That's the first concept we need. So we need to talk about the Cayley Menger ideal first. So that's, the Cayley matrix is the matrix of distances, square distances between points for endpoints in euclidean space. And Cayley's theorem says that if the distances come from endpoints, then the rank of the matrix is at most D plus two. So, meaning that all five by five minors must vanish if we are in dimension two. And these are the generators of the Cayley Menger idea. That's our starting point.
00:50:23.860 - 00:51:03.944, Speaker A: So if you want to do grabner basis, the first thing you do, you get these polynomials and that you are ideal and then do all the calculations from there. So the important part is that it is a prime ideal. So the support of a polynomial corresponds to a graph. The ideal is prime, and prime ideals induce algebraic matriids. So let's see what these are. We talk about algebraic and linear matriids and combinatorial matriids. What I mean here are graph matrix, matrix over a collection of edges.
00:51:03.944 - 00:51:51.484, Speaker A: And if you have an algebraic matrix of a prime ideal, the dependent sets are supports of polynomials in the ideal, and independent ones are those for which no polynomial in the ideal is supported by them. That's why we could eliminate some of the factors that were not supported by the edges of the circuit. So the circuit polynomials are polynomials with minimal support. And these supports are exactly the circuits. Of course, this needs a proof. Yes. And here it's a famous result of Lova Sandra's from 87, that the circuit polynomials are essentially unique, essentially means up to multiplication by a scalar.
00:51:51.484 - 00:52:23.808, Speaker A: So now I wanted to point out here that matrix theory, when it started, it started with the algebraic ones. So it's van der Werden. And then there was a theorem by Ingleton and Main. And then if we put all this together with Cayley and Lamann and various folklore things, we get that in the rigidity case, these matrix are isomorphic. But we didn't find anywhere a complete proof. You will find in our paper. Also, we redid some of these proofs and we included the complete ones just for completeness.
00:52:23.808 - 00:52:53.858, Speaker A: We didn't find any way in the literature except little references to paper. So we put it together in the case of the rigidity matrix. Just for the community then. Lova, Sandra's right. So it's about circuit polynomials in arbitrary polynomial ideas. And the fact that they are essentially uniquely subdetermined by their support. So once you know the support, it's only one polynomial, of course, up to multiplication by a constant in the.
00:52:53.858 - 00:53:13.334, Speaker A: In the ring. So anyway, so now about algebraic matrix. So let me tell you. So Luis is in the audience. So we were inspired by your paper. So you, by the way. So the topic, to the best of our knowledge of computing circuit polynomials.
00:53:13.334 - 00:53:39.114, Speaker A: Came in the PhD thesis of Zeroz. And he actually had some Macaulay code for computing circuit polynomials in an arbitrary ideal. And you can work out a few small examples, but they are impractical in the Cayley ideal. No way. That's too big. But the topic was popularized. And we really like that paper in mathematical monthly last year.
00:53:39.114 - 00:54:21.556, Speaker A: Paper by Zvi Rosen, Luis Terran and Jessica Sitman. So that triggered an interest. And in the end, we connected them with Kelly and got these results. Now, on elimination theory, there is a huge theory, not much for the Cayley ideal, but you can find in the literature, especially in the robotics, kinematics. We found the papers hustig, this group in particular, where people want to get a polynomial. So that you plug in your space specific parameters of your robot. And it gets you one of the variables, the value of the one that you want.
00:54:21.556 - 00:54:42.540, Speaker A: So this idea of getting a single polynomial that you can parameter that is parametric and you can put values can be found in the literature. And each one of them. It's a lot of work. Right. So we have a method for computing one for all the circuits. Good. So that's essentially what I wanted to tell you.
00:54:42.540 - 00:55:04.392, Speaker A: So, there are lots of interesting questions. So, let me end with two collections of problems. One is combinatorial, one collection is algebraic. This is the reference. Our paper has just been accepted at SOCG. And that's about it. Yes.
00:55:04.392 - 00:55:25.260, Speaker A: And Goran? I don't know if Goran is in the audience. I don't know. Jessica is in the audience. I can't see everybody. But anyway, so that's the end of it. Any questions? Thank you, Ilyana. Yes, really interesting.
00:55:25.260 - 00:55:34.024, Speaker A: So Goran is there. I can see him on the. Okay, good. Goran, maybe you can say hello. Yeah, Goran is a postdoc in my group.
00:55:34.404 - 00:55:35.692, Speaker C: So just before I ask people if.
00:55:35.708 - 00:55:59.620, Speaker A: They want to ask questions, is the paper on the archive or. Yeah, it will be on the archive very soon. Yeah, it's written. In fact, the whole paper is ready but we always want one more thing to add to it. One more picture. Let's see if the last example that has been running for ten days. Maybe it's ended and we can add that one.
00:55:59.620 - 00:56:05.104, Speaker A: But it's there. Great. Thanks. So, are there any questions for Ileana?
00:56:09.124 - 00:56:40.744, Speaker E: Sorry, I have a question. Thanks for the talk. I wanted to ask you about these different constructions of the circuits. Cannot these different constructions be used to avoid this maybe necessary step of doing this membership test? Because you can then take the greatest common divisor of the polynomials. If you can construct it in different ways the circuit.
00:56:44.124 - 00:57:11.106, Speaker A: If you can construct in different ways the circuit. I'm not trying to understand what you are proposing, because this is what we have here, is just one step in the tree. Each algorithm that we presented is focusing on just one step of the construction. Right? One step. Yeah, one step. And in that step you have to decide, okay?
00:57:11.210 - 00:57:13.538, Speaker E: Not the complete one. Okay.
00:57:13.706 - 00:57:30.664, Speaker A: So how large the tree is, it will be how many times you'll have to apply these steps. Right. So that, that's why there is a combinatorial complexity and there is an algebraic complexity. And the algebraic complexity, we focus it at just one step, one node in this tree.
00:57:31.004 - 00:57:32.060, Speaker E: Okay, thanks.
00:57:32.212 - 00:57:37.544, Speaker A: Yeah. Jessica has her hand up, I think.
00:57:39.644 - 00:57:57.814, Speaker F: Hi Ileana. That was a beautiful talk. I have a question about degree bounds. I'm thinking about the ideal membership computations, like going in, if you know your. Like, do you. If you have two circuit polynomials and you're trying to eliminate. Do you have any degree bounds on what you think the new circuit is going to be?
00:57:57.884 - 00:58:13.386, Speaker A: Yes, yes, yes. We do have the bounds. I don't have them memorized. And I didn't think about putting them. If I had time, I can dig them up in the paper. So we found it's essentially applying a bound on. Let's see.
00:58:13.386 - 00:58:25.074, Speaker A: So the circuit polynomials are homogeneous. Right. And then we computed what would be the homogeneous degree of the. Of the resultant.
00:58:25.534 - 00:58:43.134, Speaker F: I see. Because I'm wondering like the. The Cayley Menger ideal is essentially the ideal of the secant variety of Veronese. And those resolutions are known. So it must be, I mean, I don't know off the top of my head, but people must know that. Castle Noble Mumford regularity.
00:58:43.214 - 00:58:43.662, Speaker A: Yeah.
00:58:43.758 - 00:58:55.432, Speaker F: So anyway, these you can. There, there's this regularity as a number that will sort of bound the complexity of computing. And the ideal membership problem for that ideal.
00:58:55.608 - 00:59:00.736, Speaker A: Jessica Goran raised the. And I'm sure Goran knows the answer. Goran, do you want to answer this?
00:59:00.840 - 00:59:01.644, Speaker F: Okay.
00:59:02.624 - 01:00:03.332, Speaker E: Yeah, I think I can answer this. So we know, given two circuit polynomials, or just given any two homogeneous polynomials, we know exactly the homogeneous degree of the resultant of those two polynomials. Okay. However, the issue more is, well, the main issue is in actually computing the resultant and then factorizing it. So we know what will, in terms of degrees, we know what will get. And if it's, if it's irreducible, great, then that's it. But there are, there are examples where we don't, where we don't get irreducible polynomials and there the ideal membership comes.
01:00:03.388 - 01:00:11.882, Speaker F: In because, I mean, I guess if you know the degrees you're looking for, you can like terminate these things earlier, you know what I mean? You can sort of.
01:00:11.988 - 01:00:15.006, Speaker A: Yeah, yeah, yeah, yeah.
01:00:15.070 - 01:00:28.954, Speaker E: And maybe I can quickly comment on a question that was before about the optimal tree. If Ileana, if you, if you can go to, to the table.
01:00:30.214 - 01:00:49.204, Speaker A: Yes, I was trying, I was looking in the paper trying to get the bound. Yeah. So let me go to the table. Ah, here it is.
01:00:49.904 - 01:01:36.808, Speaker E: Okay. So the question, if I understood it correctly, was, is there a concept of an optimal tree for these computations? And I guess you have to sort of settle on what kind of optimality you're looking for. If you're looking for optimal in the sense of what will get you the circuit polynomial the fastest, then it might be the case that actually a larger tree will be more useful. So, for example, if you can go to the table, back to the table, you're scrolling through. Okay.
01:01:36.856 - 01:01:47.176, Speaker A: Oh, sorry, you saw my, yeah, I was trying to find, sorry, I didn't know that it's visible. I was trying to get in the paper, the bound. Anyway. Yeah.
01:01:47.280 - 01:03:15.362, Speaker E: So for example, here in this k three plus one, this extended resultant, so what we did here is we modified the algorithm slightly so that it uses as many resultant computations with k four polynomials as possible, because those are the smallest, the simplest polynomials in the Klimanger ideal. So the resultant computation with the circuit polynomial of k four goes smoothly. So you can see this even on the 7th vertices, both computations are with k four s. So, but if you were thinking of defining optimal in terms of the smallest tree, then that tree might not have a lot of k four s in it. So for example, for the k three plus one, the smallest tree is the one that on the level of the leaves it has four k four s. Those combine into two wheels on five vertices, and those two wheels combine into a k three one. But no matter how hard we tried to compute the resultant of two wheels of five vertices, we couldn't do it.
01:03:15.362 - 01:03:22.854, Speaker E: So that was just too much for, for very, very strong computers.
01:03:28.754 - 01:03:35.054, Speaker A: Okay, we have more questions, louis.
01:03:36.514 - 01:03:52.854, Speaker C: Yeah, so I'm looking at this table, and so I guess the other is k 34, not a circuit with seven vertices. So you didn't get k 34.
01:03:54.714 - 01:03:55.450, Speaker A: Which one.
01:03:55.522 - 01:03:57.094, Speaker C: K 34.
01:04:00.634 - 01:04:25.686, Speaker A: Sorry, what is case? Oh, always seven vertices. Now with seven vertices, what you have here are the only ones that we could compute. Yeah, so far. Yeah, so we. This is an ongoing calculation. So it's, we, we can get the trees, the combinatorial trees, but the, the resultant calculation was not completed successfully. Makes sense.
01:04:25.870 - 01:04:27.902, Speaker C: Yeah, yeah. Okay, got it.
01:04:28.038 - 01:04:49.118, Speaker A: Yeah. So that we did not list here with seven vertices. There are plenty of, of circuits and they are harder, but you see even the simplest ones that we could compute where, where to some. And you see how large they are. So. Yeah, okay.
01:04:49.286 - 01:05:35.874, Speaker B: May I just make one remark that I. Thank you very much. This is an absolutely great advertisement for what I wanted to try to get across at my speed talk, because I think this works just the same in three space. If you start with k five s. This is exactly the cycle algebra that I wanted to propose, that you take two cycles. And what you do know about circuits in general in a matriid is that there are only two axioms that no cycle should contain one another. And if there are two cycles that intersect in anything, then their union minus any element of the intersection contains a cycle.
01:05:35.874 - 01:07:02.968, Speaker B: So that is the only thing. And Graver, in his 1966 paper, which I just republished in the Pioneer Epsilon journal, because I found it, I wanted to congratulate him on his 85th birthday. So he actually proved that a little lemma that says that if you start out with incomparable sets and you just make this second cycle axiom work, and then take minimal sets of the new collection, you get, then you get the circuits of a matriid, or you get both cycle axioms satisfied. And the original collection is among the dependent sets. So that he uses to a very nice degree to show for binary matriots this nice thing that if there is a three connected, or any three connected graph is uniquely determined by its cycle matriid. And I think those are the same things that Jordan and Kazanitsky used to show when a graph in 2d is actually uniquely determined by its rigidity, Metroid. So I think that is very interesting to start with cycles.
01:07:02.968 - 01:07:47.444, Speaker B: And I would fearlessly think that if you are actually using a sequence of k four s, so attaching a k four is actually equivalent to one extension, and then using the Berk Jordan thing to say that any cycle three connected cycle is just obtainable from k four by a sequence of one extensions that's gluing decay force together. And so if you have a non three connected cycle, you take it apart first into its by the reverse two sum. So then you can actually, Brigitte may.
01:07:47.484 - 01:07:53.572, Speaker A: Interrupt for a second. I just want to make sure that we speak the same language. When you say cycle, you mean what we call circuit.
01:07:53.748 - 01:07:56.024, Speaker B: Circuit. So, rigidity cycle.
01:07:58.084 - 01:08:00.788, Speaker A: I thought that it's called rigidity circuit.
01:08:00.956 - 01:08:25.480, Speaker B: That's, yeah, depends on, okay, it gets confusing, right. But, so I think that your algorithm should work fine on the three connected circuits, right? Don't you think? Just by sticking k four s on, right, so that it should be clear that you can work yourself up just one vertex at a time.
01:08:25.632 - 01:08:32.112, Speaker A: Yeah, I don't know what you mean. We proved that the algorithm works. So if you have another construction in mind.
01:08:32.168 - 01:08:39.204, Speaker B: No, no, I mean in terms of depth of the tree.
01:08:40.304 - 01:08:42.884, Speaker A: In terms of the depth of the tree, in what sense?
01:08:46.193 - 01:08:50.333, Speaker B: That you know which cycles to actually compute the.
01:08:56.033 - 01:09:11.514, Speaker A: So this is, this is the theorem. So the theorem is a construction, and we are not claiming the construction is unique. Right? But this is one construction. It's a proof that it can always be done. There are many ways to obtain the trees, but I don't quite understand, I don't get what your point is.
01:09:13.614 - 01:09:29.262, Speaker B: No, I think that, so then I didn't understand your conjecture of what tree to take or what the difficulty is to get the resultants for the larger graphs.
01:09:29.438 - 01:10:00.936, Speaker A: So the difficulty is algebraic. So there are two problems here. Collection of questions is combinatorial. A collection of problems is algebraic and the optimality. So Mira asked if we have any idea of what, how we could define the optimal tree, and we said that we didn't get to ask about this. I mean, people, by the way, I think that anybody can make their own optimality depending on the goal. Our goal is maybe not necessarily only combinatorial.
01:10:00.936 - 01:10:52.164, Speaker A: Our goal is in the context of the entire problem. And that's what Goran tried to, tried to say was that even if the tree looks better, in fact, the algebraic calculation, when you compute the corresponding resultants, it may be more work. So it's the combination of the two that is the encompassing big open question, whether this can be made faster. But what we did in terms of isolating the problems, we isolated some open questions that remain from our approach on the combinatorial side of this algorithm, of this approach, and some other questions that are on the algebraic side and of course, putting everything together. What I hear from you, you are saying that. Yes, so circuits can be obtained in some other ways and we are not. It's fine.
01:10:52.164 - 01:10:53.532, Speaker A: Yes, it will agree.
01:10:53.708 - 01:11:13.144, Speaker B: But what I'm saying is exactly that I proposed for 3D. So you take k five s and do the same thing. Exactly the same thing. Right. So I wonder if there's some algebraic method also here, because I think that was missing for characterizing 3d rigidity.
01:11:13.964 - 01:11:17.824, Speaker A: I'm here, I made this characterization.
01:11:18.924 - 01:11:21.908, Speaker B: Minimality of polynomials here.
01:11:21.956 - 01:11:57.836, Speaker A: I may disagree for the following reason. Everything we have presented works in dimension two, because we have Laman theorem, because we have a combinatorial characterization. So in dimension three, we do not have a combinatorial characterization. Maybe people have some subfamilies where something like this grows. In work that with Mira we did many years ago, we looked at circuits in dimension three that were not even rigid. So rigidity and circuits in 3D are so much more complex that I don't think it is the same method. No way.
01:11:57.836 - 01:12:39.940, Speaker A: Plus the theorems that are underlying this, it's something that I said very late in the talk. So let me get to that slide to make it clear. So the fact that we have this equivalence, that the algebraic matrix is isomorphic to the combinatorial matrix, is done by a algebraic, linear and linear combinatorial. It's via Lamann theorem. We do not have a Laman theorem in dimension three. So this cannot be, I'm not saying as a plan, it can be pursued, but we miss essential ingredients and we cannot go to dimension three. Just saying.
01:12:39.940 - 01:12:48.180, Speaker A: Oh, we do that. Maybe you can do something at the combinatorial level, but you cannot guarantee that you'll get exactly the rigidity matridian three.
01:12:48.212 - 01:12:56.670, Speaker B: D. I think I would fearlessly guess that you get the maximal, the maximum.
01:12:56.702 - 01:12:58.234, Speaker A: I don't know. I don't know.
01:13:00.694 - 01:13:02.714, Speaker B: Which k five s are circuits.
01:13:03.574 - 01:13:21.150, Speaker A: That's, that's fantastic. So if we managed to trigger thoughts and propose new problems, including problems proposed from the audience, I'm happy, because I guess the goal of this workshop was exactly this one. So that's wonderful. Thank you. Thanks. All of.

00:00:00.240 - 00:01:16.254, Speaker A: This is a continuation, in fact, the second in the sequence of two talks that I thought are lectures, I guess, really because I've tried to be careful about how sort of generic global rigidity and universal rigidity are interacting. And where we left off last time was that I wanted to prove this statement that I'm underlining here. Namely, I'm saying that if g is a generically globally rigid graph in dimension d, then there exists some generic configuration p, so that the framework GP is actually super stable and therefore universally rigid, has a max rank stress and so forth and so on. Okay? And so as I promised, I was going to deal only in like a special case for the purpose of proving things, which is, I'm going to say that g has n vertices one to n, and the first d plus one of them constitute a complete subgraph. So in dimension two, like a triangle in dimension three, is simplex. And I'm also only interested in n big enough, because if n is not big enough, first of all, it's not true. It doesn't have to have a stress.
00:01:16.254 - 00:01:58.854, Speaker A: It's a very boring statement. It's just a small complete graph. So just a fact is that g is d plus one connected. You've probably already seen this with the discussion of global rigidity, and so I'll use that later, which is why I thought I would recall it. And so from now on, this is when I talk about g, I'm always meaning a graph like this. Okay? So in order to prove this, I need to kind of refine my notion of what constitutes a nice stress matrix. And so I will say that a stress matrix omega is in general position.
00:01:58.854 - 00:03:11.188, Speaker A: Well, for dimension d, if, first of all, omega has a specific rank, namely n minus d minus one, which you should think of as n minus. Alternatively, it's like n minus whatever, d plus one, if you re bracket it. So this is, as we saw last time, the largest rank that any stress matrix with a d dimensional fully spanning configuration in its kernel could have. Furthermore, and this is why I'm calling it general position, that if I take any n minus d minus one columns of this stress matrix, they are linearly independent. So it's a kind of linear general position for stresses or really stress matrices. Okay? And so a useful lemma, and it kind of should explain the general position terminology. Is that right? If omega is a general position stress and gp is a stress satisfier for omega, and also p is affinely spanning, right? So p is not somehow flat.
00:03:11.188 - 00:04:41.836, Speaker A: I'm just throwing away some degenerate stuff as I go. Then, in fact, p is in general affine position. This is general position in the way that we usually know it. There's a kind of converse to this, which is that if omega has this maximum rank, and also there's a gp in its kernel, which is in general position, right? And it's worth noting that since n is big enough here, this implies affinely spanning. So I've got a kind of hidden non degeneracy. Then the stress omega, right, is in fact one of these general position stresses, okay? And the statement is a mouthful, but the proof is actually like essentially one line, right? And it brings back something that we discussed last time. So the proof is simply apply, Gail, duality to the matrix equation omega, p hat equals zero, right? And if you recall what p hat was, p hat was, you know, kind of transposed homogeneous coordinates.
00:04:41.836 - 00:06:00.944, Speaker A: So it was, you know, p, one transpose followed by one, down to p, and transpose followed by a one. And so the general position of omega tells you that, you know, any d plus one columns, right? So gp of omega tells you any d plus one row, sorry, of p hat, independent. Right? But that's just affinely general position, right? But of course, gale duality is, is like a fixie. It goes both ways, right? So general position of p tells you that any set of d plus one columns of omega. So the other way works, too. So the key thing to keep in mind, first of all, I think this is a cool and useful fact, maybe a little surprising. So in some sense, stresses are telling you something like the affine structure of p plus zero is in the right place if you have Max rank.
00:06:00.944 - 00:06:35.644, Speaker A: The crucial thing here is that I'm assuming always Max rank, I always have max rank. I always have Max rank if I don't have Max rank. So I'm stressing this because the lemma proof seemed trivial, but the non triviality is just packed into the definition. So the non triviality is that I was able kind of, to gale it here, and I can't do that if it's not Max rank. If p hat does not spend the kernel of omega, then all bets are off. Nothing is true. So somehow I'm combining several pieces, general position, Max rank, stress.
00:06:35.644 - 00:07:34.404, Speaker A: And then things are getting nicer than usual. Okay? And so my first proposition is that I'm going to try and understand sort of some nice configurations. And so the proposition is simply, there's a very big subset of configurations, p. So that GP has a general position stress, omega, and also that this framework is globally rigid. And this is where I'm assuming that g is ggr. Right? So this uses, this part here uses that g is ggr. And the reason is that I am about to hit it with my other sort of big theorem, or not my theorem, I mean, somebody else's theorem, the Scartler Healy Thurston theorem, sort of something I talked about last time.
00:07:34.404 - 00:08:08.604, Speaker A: Right. There exists a big Zariski open subset of configurations that have these Max rank stresses and are also globally rigid. This is the generic global rigidity. Global rigidity is a generic property of this graph. Well, global rigidity is a generic property, and I'm assuming this graph is generically globally rigid. And essentially, maybe there are somehow some non general position things in it. But that's also like a big, open, dense set.
00:08:08.604 - 00:08:47.602, Speaker A: I just take away the vanishing of some of these determinants. And so if I need to, I'll just cut away everything in non general position. And now I will just hit it with my lemma that whatever this Max rank stress omega was, it's in general position because it has general position satisfiers. And so I'll call this set of configurations, for lack of a better name, g stressable. So these are nice. Okay. And the way to understand.
00:08:47.602 - 00:09:21.862, Speaker A: Well, the first part of what we're doing is simply that infinitesimally flexible frameworks with the graph g is of lower dimension than g stressable is. So g stressable is, in fact, full dimensional. Right. And the proof is simply that GGR implies Glr. And by Asimov and Roth, generically speaking, local rigidity is infinitesimal rigidity. So I'm kind of breezing through this a bit because I have the advantage of. Of being near the end of the course.
00:09:21.862 - 00:10:39.888, Speaker A: And so you've already seen this. Okay. And so where we are at this point is that we have a good understanding of these, like, g stressable frameworks. In the case, I should say, you know, with all our hypotheses, you know, it turns out that you could substantially relax these hypotheses and still get some understanding. So this is sort of ongoing work with Connolly. And the ideas here that I'm presenting are kind of a viewpoint coming out of that work, but I'm kind of confining myself to a much more pleasant case that's still very suggestive. So, for the proof that I'm doing so far.
00:10:39.888 - 00:12:08.808, Speaker A: So, basically, the outline of the proof is, the first step was to describe these g stressable frameworks. It turns out there's just a lot of them and that's all I'm going to need to know. So, any questions so far? Anybody forgot the definition of gale duality and want to hear it again? Or statement of gale duality? So if not, let us move on to sort of the hard part, which is coming next, which is I want to somehow describe these general position stresses. And to that end, I will first define them. And I'll just say, I'll just call them the g stresses. I guess I should underline it in green, because I usually underline the thing I'm defining in green. And I am going to say that while the g stresses not in is a reasonably nice set, so it's irreducible, it's not a variety, but it's something called a constructable set.
00:12:08.808 - 00:13:31.664, Speaker A: And so, I'll try to explain why, what a constructible set is and why it's nice. So there's this notion of a quasi projective set, and this means that it's like open in its closure. And there's a risky topology, but maybe more informally, it's like a variety. Like take away a variety. So it's like an algebraic set that I took away an algebraic set, okay? And then constructable sets are finite unions of these, right? And so maybe sort of a useful fact, which we're not really going to use, but it's kind of important or it's helpful to know. So, Chevalier's theorem is that over an algebraically closed field like c, the image of a polynomial map is constructible, right? So these sets like these are sets that kind of appear in a lot of places. And so think of them if you don't care about any of the technical stuff, as it's just a nice set.
00:13:31.664 - 00:14:52.476, Speaker A: And it, more to the point, is irreducible. So if you close it up, it's not that closure is not the union of two algebraic sets. And also it has a dimension. And the dimension we'll see is actually pretty nice. But notice this is like the number of edges, right? Minus the number of edges in a kD plus one, okay? And in fact, that is, roughly speaking, how we're going to approach this parameterization is I'm going to argue that I can put whatever numbers I feel like, you know, up to some small genericity assumption on all of the edges not in my kd plus one, and then patch it up into a stress. Okay? So let's do the proof of the proposition, which is going to take us a little bit of time. So my first observation in the proof is what I just said before, right? So g, you can think of g as being, let's just give an example, such a graph, I don't know.
00:14:52.476 - 00:15:44.344, Speaker A: So it's this triangle. I have three more vertices here. Let's make it look a little bit more general, whatever. So, so I have some triangle, I have some other edges in my graph, something like this. This graph is globally rigid, right? And so, you know, here's my kg plus one. If d equals two, so it sort of looks like this. And so I've got these other edges, right, which are not inside of that yellow blob.
00:15:44.344 - 00:16:36.204, Speaker A: And those are the ones that I'm going to be interested in, right? So the sort of lemma is that over some very big subset of r to the m minus d plus one, choose two. But I'll give coordinates as like wij, with some vague hope that my omegas and my w's look at all different. So there is a unique stress omega that agrees with the w's. So once I've specified the w's, I can then complete it to an equilibrium stress, necessarily on that simplex. And that stress that I get is in general position. So this is going to be the kind of the work. So this is where we left off last time.
00:16:36.204 - 00:17:17.283, Speaker A: Alex asked how I plan to describe the stresses, and I plan to sort of describe them a bit implicitly. I'll say that there's a rational map between them and a subset of linear space. So here's a theorem. This is the rubber band embedding theorem. So I don't know if I plan to prove it or not. I actually have a proof written down, but so this is the rubber band theorem, right, of lineal lobos, I guess. Figures.
00:17:17.283 - 00:18:20.388, Speaker A: So at least they have written it down. And we'll use the form that they have. This is one part of their theorem. So for a d plus one connected graph and just sort of any subset of d plus one vertices, there's the risky open subset of edge weights, so that there's a unique configuration p that has the property that I should erase this plus one, that somehow the vertices in x are like pinned to the simplex. And that's the standard simplex. So in dimension two, the picture is that you have the x and the y coordinates, and, right, you pin your triangle there. So then p will be in equilibrium with respect to these weights, w.
00:18:20.388 - 00:18:57.464, Speaker A: Except it's really p. Sorry, take away, let me write it better. So I'll say that I'll restrict, pull to v, take away x. Right, so the pin down vertices do not have to be in equilibrium. And also this configuration is in general position. And this is really the substantive. This is somehow sort of the uniqueness and the general position.
00:18:57.464 - 00:19:19.054, Speaker A: These are the main points. Right. Um, and, and this connectivity hypothesis, uh, is important. Um, and I want to sort of take this for the moment as a black box. So let's just say later. And, um, if we don't get to it. Fine, I'll write one down.
00:19:19.054 - 00:19:49.912, Speaker A: It's a, it's a really nice proof. So the picture of how this works is that you want to think of this as what Bob calls a spiderweb. So Sean asks, is this an extension of tut embeddings? Yeah, it's an extension of tut embeddings. Right. And in fact, you can get everything in the convex hull of its neighbors if you put positive weights and so forth. I mean, this is a tut embedding, right? So think of this as a tut like embedding, and it also characterizes connectivity. If you want to go the other way.
00:19:49.912 - 00:20:31.504, Speaker A: Excuse me, let me 1 second here. Have a slightly upset puppy. So sorry. Yeah, so Sean's question is a good one. This is exactly a tut type theorem, right? But there's no planarity involved. Okay, so now let's go back to this lemma, which I'll use to prove the proposition. So let's just take this big w, you know, the sort of set of nice enough weights as in the rubber bound theorem.
00:20:31.504 - 00:21:11.196, Speaker A: Okay? So now if I, excuse me. So let's take little w, big w. And so now find p. That's sort of the application of the rubber band theorem. And now I'm going to make a statics argument. And then this is also a pretty well known argument that generalizes something that you see in the theory of drawing polyhedron, small grids and stuff. So this is like around Maxwell Cremona.
00:21:11.196 - 00:22:10.876, Speaker A: So I have this KD plus one subgraph h. The outer triangle, as it were, is in general position. It's statically rigid. And so now I think about, right, the load imparted on the vertices of the triangle by the, you know, by these weights, w and the PI minus PJ. Okay? And this should really be, I should say that I'm quantifying I as one of the vertices of the outer triangle, okay? And so it's resolvable by the outer triangle itself by this complete subgraph. And the resolution is unique. So I'm not sure how much statics you've gotten in this course.
00:22:10.876 - 00:22:51.804, Speaker A: So if it's not enough think of this is the dual theory of infinitesimal rigidity. This is stress free and infinitesimally rigid, so also statically, minimally rigid. And so the resolution tells me that I can somehow, with some nice system of tensions and compressions, like in my drawing here, these are all pluses. Say, is h the simplex here? What? Yeah. H is the simplex. Yeah. So I have my kd plus one subgraph hook, right? So h is the orange stuff.
00:22:51.804 - 00:24:06.674, Speaker A: Okay, good. And so if I take that resolution and I kind of combine it, whoops, with my original weight vector w, that I get equilibrium right at every vertex, and it must be of maximum rank, just because of this uniqueness of p. So basically, because I have pinned down this outer thing, I've removed any affine motions. And so p is unique after pinning, means it's unique up to affine, which means max rank, I come back. So why did I do that? Lemma? Well, the stress itself that I got also kind of post hoc, must be in general position by Gail duality, because p was in general position. And so what I've been able to do is parameterize the stresses almost. So the other thing I should say is that the map is subjective.
00:24:06.674 - 00:25:19.464, Speaker A: I can hit all of these general position stresses just by throwing away the stress weights on h, which is, again, just to be clear, the k D plus one subgraph. So, the argument that I had previously says you would have to get something, and uniqueness says that you have to get back to where you started. Okay? And so what that means is that, up to the proof of this rubber band theorem, the set of g stresses is an irreducible constructible set of the dimension I claimed. The dimension I claimed is simply because I know the dimension of the parameterization. But now I have rational maps to, as a risky open subset of a space of this dimension. The map is rational because I had to invert a matrix, but it's a bijection and it's defined everywhere. So life is actually pretty good.
00:25:19.464 - 00:26:32.318, Speaker A: So there's also a corollary, right, which is, I've been talking about all of the stresses of the right rank in general position. I could also restrict my attention to just the PSD ones, and I'll call them, for some reason, lss just see if Connolly ost paper about this topic, right. We call this set lss in general have the same dimension, but are not anymore a constructible set, or really any kind of as nice of a set at all. They are semi algebraic. They are defined by inequalities, now, right. The inequalities are the PSD ness, and the proof is simply, it follows from how the proof of rubber bands work. So here, Sean's question is very apropos.
00:26:32.318 - 00:27:35.994, Speaker A: So if you put a large positive weights, you get something PSD. So, from putting positive weights, right. And this is sort of like what you do in tut. So, so indeed, basically, and this is why I have played around, you know, this is why we're looking at this exact special cases, because we can use rubber bands to address it. The same statement is true in some more generality, but that's hard, actually, one shouldn't say that. You shouldn't say that your own theorems are hard. I will say that it would certainly not fit into two lectures, and probably you'd get bored going through the construction.
00:27:35.994 - 00:28:04.728, Speaker A: Where we are now in this proof is that, well, we described the g stressables because we assumed Ggr. That wasn't so hard. We described the general position stresses. This was substantial. This required some work. It required somebody else's theorems and maybe some statics as well. So, so now let's just finish the proof of the theorem.
00:28:04.728 - 00:28:49.654, Speaker A: The proof of the theorem is at this point kind of formal. Um, but let's go through it maybe a little bit carefully. So, the first proposition is that there's some dominant map which is rational, from the space of g stresses into a set that I'll call x. And x is like a subset of g stressables, but it has the simplex pinned down. So let me attempt to describe it by a picture. So here's my space of these g stresses. These are my nice stresses.
00:28:49.654 - 00:29:20.094, Speaker A: Maybe there's some omega in it. So there's some subset of it, the good ones, lss, that are PSD. And this is, it's meant to sort of really look like this. You know, it's defined by some inequalities, but it's of the same dimension. Then I don't really know how to write, so I'll try to make a schematic. So X just has the outer triangle kind of pinned to some specific place. Right.
00:29:20.094 - 00:30:54.988, Speaker A: And for each stress, I can assign the associated framework, which will be unique, that is, a full span, and has the outer triangle in the correct place. And if you change the pinning where the outer triangle is, you'll get different looking frameworks. And so the g stressables are actually themselves parameterized by copies of this x up to, you know, the affine orbits of X, essentially. And so the reason for this is that, you know, the kernel of Omega has, like, many frameworks, but they're all affinely equivalent if they are spanning. Okay? And a corollary of this is that the infinitesimally flexible frameworks in X are of lower dimension than x's, right? And the proof is simply that the rigidity matrix is affine invariant. Um, which I think that you've already learned. Rigidity matrix rank is affine invariant, you know? And, you know, every sort of spanning affine class has a representative in X, right? If it's spanning, you know, um, or maybe I'll say general position, right? Something could go wrong if the outer triangle itself went flat.
00:30:54.988 - 00:31:26.570, Speaker A: But I've already, like, cut this all away. So that's why I have been, that's why I sort of was at least somewhat careful with the construction of G stressable. So this game is that I have, like, a domain, I have a range. I want them to be at least reasonable to argue about. Okay? So let's now give the proof of the theorem. Let's call the infinitesimally flexible set in x. Let's just call it if to give it a name.
00:31:26.570 - 00:32:36.956, Speaker A: And the way you should think about if in my picture is that, oops, I didn't want to erase anything, is that since it's of lower dimension in my picture of blobs, you should think of it as some kind of a curve. It's got no interior at all, okay? And so it's lower dimensional, and it's also rationally defined and so forth. So, you know, I can find some polynomial that vanishes on if and not on all of x. It doesn't matter for my purposes, what it is, but it comes from the rigidity matrix. It's a minor. Okay? So I can then think of what happens if I apply my sort of rational map f, which is here, right, to some general position stress omega, and then use this polynomial, phi, phi, whatever. This is a polynomial which is not zero over all of the g stresses.
00:32:36.956 - 00:34:25.784, Speaker A: Because, of course, this map f hits some things that are outside of if. And so I can then think about looking at the preimage of this setifies. And what I know is that it is again, of lower dimension than this space of g stresses here, because the preimage is, in fact, all of these omegas where this thing vanishes, or at least it's contained in it. So now I'm basically done, or at least I'm in very good shape, because lss, on the other hand, was high dimensional. And so I just pick some omega here, like this pink one and push it through the map. I end up with a framework that is in general position and is also infinitesimally rigid, right? It has a PSD, equilibrium stress. And so if I take all of these conditions and kind of put them together, this framework GP is super stable, right? And now I get a, at least euclideanly open set of these super stable frameworks, right? Just a small neighborhood of this p.
00:34:25.784 - 00:36:18.254, Speaker A: And so any Euclidean, the open set will contain a point that is honestly generic in that sense of being algebraically independent coordinates. And if you notice, that was what I was trying to do. So, so with some decent amount of time left, um, we get to put a little box, right? So we've, we've proved the theorem that we want to, which is that, you know, GGR graphs have generic ur frameworks, right? And also along the way we've seen that this is like saying, you know, there exists, say, Euclidean open set, standard topology, open set of super stable frameworks, right? And of course in this talk, I have to give it a, I have to give it a star. So what's the little star? Is it that condition you had at the start? Sorry, did the KD plus one subgraph? Yeah. Right. So here I kind of did it for just having a complete subgraph. It turns out you don't need that.
00:36:18.254 - 00:37:26.714, Speaker A: But then it will require more work to construct the domain and the range. And there's some other approaches that you can use, but I think that this is suggestive of the plan at least. Okay, and so I guess I do want to pause here and ask if there are some questions. I can see the chat, so feel free to chat if you don't want to talk. If you replace KD plus one with a larger specific graph, could you make the same arguments work? Possibly? No, I don't think so. At least. Okay, so the argument would get more complicated.
00:37:26.714 - 00:38:06.824, Speaker A: This is a good question. So the statics argument would not change, but the kind of dimension would be more complicated because I would have to, you, you know the sort of edges. Right. So if you think about how I started, this is a good question. So somehow, way back up here, right. I just wanted to parameterize it by like putting any numbers at all on the edges. Right.
00:38:06.824 - 00:38:43.844, Speaker A: And so it just happened to be the case that the complete subgraph had the right number of edges. If I use some other rigid block, then I won't actually have the right number of edges. And so it'll, so the parameterization will get like very messy very quickly. Right. And in fact, so in essence, this is why we do something else for the general case. Right? So this number minus D plus one, choose two, is really the right number. It's not like it changes whether or not there's a complete subgraph.
00:38:43.844 - 00:39:32.784, Speaker A: But the parameterization, by just kind of doing what Bob calls form finding, which is like just sort of picking these wijs and seeing what happens, that's at least, I don't know how to make it work. So then the parameter space is better to kind of somehow take it off the edges of the graph. And if you look at the paper, we use these things called orthogonal representations. Right. But the dimension that we end up with, that's the same dimension. Helpful. Okay.
00:39:32.784 - 00:40:35.304, Speaker A: Yeah. And so, I mean, the other thing is that in a lot of applications, I don't know, like, if you're allowed to sort of create a frame like you saw in Bill Baker's talk, something like this is fine, right? You have to be sort of a picky theorist to want all. Okay, so the other thing that I think that's nice that comes up here is somehow that gale duality gives you so much traction, right? And that seems to be just because you. If you look at the right set of stresses, then it makes sense to use it. Okay, so I now have a couple of minutes. Okay, so now I can. All right, so.
00:40:35.304 - 00:41:08.940, Speaker A: And this will sort of. So I kind of actually talk about how the rubber band theorem works, at least in. In some generality. And this is useful because I got a question, I think, from Alex last time. Like, sort of, does convexity play a role in other concepts? So the answer is sort of. So the proof of the rubber bound theorem goes like this. So I am going to kind of use a trick, which is a sort of special position lemma, to get this rubber bound theorem.
00:41:08.940 - 00:42:21.364, Speaker A: So I'm going to fix, like, large positive weights to start with on the edges. And remember that h is, again, this. This is the kd plus one subgraph. Right? And so, you know, so this x, you know, is like v of h. Okay, sorry. I'm sort of mushing my notation so I can then define this potential, right? And I think Bob may have talked about a very similar potential, at least he did in his slides, where I think of w as fixed, p as variable, and I look at, like, the squared kind of edge lengths weighted by these w's. And this is a strictly convex function because I've pinned stuff down, right? Quadratic functions are strictly convex, and sums of, you know, positive sums of strictly convex functions are also strictly convex.
00:42:21.364 - 00:43:05.974, Speaker A: And so convex functions have unique minimizers. And so the minimizer will have to be a critical point of this convex potential. Right? But notice that the, the critical point, um, condition, if you just sort of take the derivative, right, the gradient condition is in fact this equilibrium at the other vertices. Right? And this is exactly the tut idea, by the way. So, so if you ask some people, they would say like, oh, tut knew this. I don't know. I'm giving the, whatever the paper that I know that has this in exactly this form.
00:43:05.974 - 00:43:54.656, Speaker A: So one thing is that popping out of this is that the Hessian, which is like the stress matrix, except reduced to the part where we have equilibrium, will be positive definite by the second derivative test. And that would lead us to the PSD stresses. So I'm just going to say that I'm going to wave my hands on this. But that's where we got the dimension of lss. So the uniqueness of the minimizer also tells us that we have like a full rank system. And having this system being full rank, this is like an algebraically defined property defined over Q. And so what that means is that now I have found a point where it is full rank.
00:43:54.656 - 00:44:42.518, Speaker A: And so for other numbers which are not positive, where I can't make this convexity argument, this high rank will still hold. I'll still have a unique solution to this system, even though it will no longer be minimizing in energy. This is the game that is being played. We use some geometric ideas or rubber bands, but then we deduce, because it's algebraically defined, that it's true in some much larger context. Oops. Okay. And so that was one part of my conclusion is that I wanted a unique solution to that equilibrium equation.
00:44:42.518 - 00:45:17.794, Speaker A: So the other one is that I want a general position to be the generic case. And so now I'm like really being quite bad. But let's take some subset x of D plus one vertices, which are not the ones I have pinned down. These are pinned. These are not pinned. And so somehow I want to say that these have not gone flat. But them being flat is also an algebraic condition.
00:45:17.794 - 00:46:10.784, Speaker A: It's the vanishing of a determinant. And so I just need to find some set of edge weights where it's definitely not flat. What do you mean by flat? Here? A defective affine span. Okay, so let's just say flat is that the collection PI for, say, I in x, right. Does not have d dimensional affine span. Right. And so the trick is to kind of just, just pick cleverly some weights.
00:46:10.784 - 00:47:25.164, Speaker A: And so my menger's theorem, if I think of, right, the vertices in it, xi. Or maybe I'll just call them I, whatever, x I and x, right. I can find paths, this is much easier to describe by a picture, which I will do like big p one to big pd plus one, that kind of go out to the pin vertices that are disjoint to each other. This is what connectivity is buying me, right. And so, so really I want to think like say I've got these three vertices, I've got some paths that go to the pin vertices and they're disjoint. And so now I just pick some like large constant capital k. And on an edge that's in one of these paths I give the weight capital k and on the other edges I just give one.
00:47:25.164 - 00:48:33.394, Speaker A: Okay, and now if I look at the solution that I get for this particular potential, you know, q is minimizing it, but I could put all the vertices on any of these paths like actually here, right. And then somehow all the other edges are of length at most root two. And so I'll just say that there's m of them at most. And so whatever, it's some bound which does not depend on k, right? So this does not depend capital k, right. Because I have kind of put everything with weight k on top of each other. So I made those contributions zero with weight k. Capital k is zero.
00:48:33.394 - 00:49:31.344, Speaker A: Good. But I can also get some other bound. And here it's not really important what it is, just think of it as this should be in any solution at all. You could just discard the contribution from those edges that have weight one and just sum up, oops, the contribution from the ones that have weight k. And the way to understand this is it's at least k times something that depends on like n and the largest edge distance of weight k. And so now you can compare these two things. This is independent of k.
00:49:31.344 - 00:50:24.264, Speaker A: This has to k can go off to infinity. So if k gets really, really large, then all of the edges of weight k must get really, really short. And if you go back to the schematic picture, what is happening is that these paths are kind of getting shorter and shorter. The real picture is like kind of, they look like this and then the rest of the graph is doing something else that's definitely not going to have defective affine span, just make k sufficiently huge. And these points here necessarily are close to these points here which are in general position. Now once again, this is algebraic. So you just do this finitely many times and you are done.
00:50:24.264 - 00:51:15.024, Speaker A: That is the sketchy idea of the rubber bound theorem. Right. And so once you have the rubber bound theorem, basically the proof is really done. Okay, so proof is really done. And so now we kind of have at least a broad strokes picture of all the ideas that go into to proving a result such as this one. And hopefully that also makes the statement a little bit more understandable. I guess I will stop here.

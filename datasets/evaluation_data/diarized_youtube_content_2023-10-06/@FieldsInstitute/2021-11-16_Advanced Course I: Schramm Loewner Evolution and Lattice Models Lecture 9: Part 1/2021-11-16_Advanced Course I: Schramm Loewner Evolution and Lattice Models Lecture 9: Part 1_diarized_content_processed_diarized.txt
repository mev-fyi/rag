00:01:24.434 - 00:01:37.618, Speaker A: Can you hear me now? Yeah. Okay. Sorry about that. Sorry. Okay. My mic was on mute, and I didn't. Sorry about that.
00:01:37.618 - 00:02:14.404, Speaker A: Okay, so. Well, luckily, I wasn't able to say much yet, so I was just saying that last time you defined SRAM. Leonard. Evolution. First, a chordal version of Schramjevner evolution. We first defined it in the upper half plane as a random curve with the driving function, which is a solution for Leovner equation with driving function equal to brownian motion, which is run with constant speed kappa. And then.
00:02:14.404 - 00:03:05.894, Speaker A: So here's the definition. So the driving force is brownian motion at kappa t, which is the same as square root of kappa times brownian motion. And then in arbitrary domain with two selected prime and boundary prime and sin b. This was simply defined as an image of this random curve under conformal map, which maps upper half plane with two selected .0 and infinity to outer my omega with two corresponding fragments. There are many such maps, but they are all the same. Up to scaling here in the upper half plane, just multiplication by some positive number, and again by brownian scaling.
00:03:05.894 - 00:03:56.934, Speaker A: We know. So by this property, we know that the definition here does not depend on the choice of. Okay, so this is all good. There is one fatal flow in all this discussion. I said a curve driven by brownian motion. So you solve equation, you plug in brownian motion there, and the solution is a curve. Well, why is it a curve? Let me remind you that if you would know that our brownian motion is one half further with corresponding constant less than one quarter, then we would know that it's indeed a curve.
00:03:56.934 - 00:04:51.524, Speaker A: But we don't know this more than that. Brownian motion almost surely does not satisfy this condition. Brownian motion almost surely is not one half helder curve. So we need an additional argument to show that actually, when we solve Leo equation, what we get is the curve. If again, driving function is brownian motion. And this is a surprisingly difficult theory by rode and schum that sle kappa in upper half plane is almost surely generated by a curve. And by Ljovnir Cursor, I mean the the curve which defines a Lerner hull.
00:04:51.524 - 00:05:30.734, Speaker A: So let me remind you that this curve can be self touching, space feeling, very simple curve. And we'll see that for certain values of kappa, we'll actually see it later today that for certain values of kappa, it will be space filling, for certain values it will be self touching, and for certain values it will be simple. They won't depend on Kappa. But this is the main thing. Why the takeoff? Okay, two comments here. First, that the proof will first prove it only in the upper half plane. We just defined Tessella in arbitrary domain.
00:05:30.734 - 00:06:10.804, Speaker A: Would it also be a curve? Turns out that the answer is yes, but it's slightly more complicated and we'll do it later, but only for couple less than a for Kappa PC. Why it actually cannot be careful with. And second, this is probably the most disappointing part. This proof is, well, now almost 20 years old. The proof only works for Kappa not equal to eight. As I explained last time, the proof for kappa equal to eight actually is totally different. It follows from the fact that SLA eight is a scaling limit of uniform spanning trees.
00:06:10.804 - 00:07:03.404, Speaker A: So, turns out that in the past 20 years, as far as I know, there was no direct proof. As you will see, for some reason, all the arguments here break up for kapo equal to eight. And so far it was impossible to correct. Also, again, for kappa equal to eight, the theorem is absolutely true, but the proof is very different. Okay, so now let us prove this exciting theorem of rod and schramm. My apologies. It will be somewhat technical proof, but let's try to slowly go through this.
00:07:03.404 - 00:07:53.930, Speaker A: Okay, so, as I promise, the proof is technical, so we'll need a special notation. First, let us introduce a notion of shrifted ft. So remember, if so, let me actually draw some pictures here. So this is my curve. The map here, which unzips it, would be gt. This would be the point gamma t. This is the image of this lambda t.
00:07:53.930 - 00:08:43.754, Speaker A: And now the inverse map is ft. So ft is a map from the upper half plane to upper half plane minus the beginning of our curve, or maybe just a hull. We are proving that it's a curve and this hydrodynamic parameterization. And now, the limitations that I want to introduce is that let us consider ft hat, which is ft shifted by the driving function, so that zero is mapped by ft head to gamma of t. If it exists, we don't yet know it. We don't yet know that gamma of t exists for every t. We have to prove it, that it exists, that it's continuous in t.
00:08:43.754 - 00:10:04.412, Speaker A: But what we need to prove is the following. Remember, we had the theorem, which was the condition of when your solution to Leonard equation is the curve. All you needed to show is that there exists the limit when t goes to zero of. Well, in this notation, ft head of iy for every t that this limit exists and continuous and t. So let me actually add, because I didn't write it exists and continuous entity. So again, why this is an untrievable statement, because you would also need some sort of, well, first of all, it's not t goes to y plus, it's y goes to zero plus. So in general, to have it to be a curve, you would need to add x plus iy, and then to show that the limit really exists, that it's extended up to the boundary.
00:10:04.412 - 00:10:42.784, Speaker A: But here it's not needed. Again, as we discussed when we talked about general evolution, all you need to do is to show that this limit exists and continuousity. And again, we don't need to show it for all t. We just need to show it first for t less than some given capital t, and then let this capital t go to infinity. But then what? We can do another trick. Well, luckily for us, we have scaling, so this t doesn't matter. We can just rescale the curve.
00:10:42.784 - 00:11:31.874, Speaker A: Brownian motion doesn't change when you rescale. It's still brownian motion, at least in law. So we can always take t equal to one. Okay, so what am I proving now? I am proving that this map ft hat of iy has boundary extension to y equal to zero, which is continuous, and t for all t between zero and one. Okay, so that's what we are trying to prove. That would mean that we are generated by a curve. Okay, and now let's define h of.
00:11:31.874 - 00:12:28.664, Speaker A: This is our ft of iy. So this is what we need to extend to t equal to zero. So this is initially defined when t is between zero and one and y is strictly bigger than zero. And the question is, can we extend it to y equal to zero? Okay, so now we also need to introduce rectangles. But look, this would be very interesting rectangles. They would be brownian scaled. The width in timescale would be something like two to the minus j.
00:12:28.664 - 00:13:17.960, Speaker A: But here, you see here, the width here would be two to the minus two j. So this is actually somewhat misleading picture. Sorry. The rectangle actually, well, should go here. Okay. And now diameter of this jk would be denoted by h of rjk. So, sorry.
00:13:17.960 - 00:13:47.424, Speaker A: Diameter of this h. So ft of this. So the diameter of image of this would be denoted by d of jk. Okay. And now. Okay, so I see where I. Sorry.
00:13:47.424 - 00:14:29.814, Speaker A: So this is time. This is y. So y would go to zero. Of course. So this is y, which is scaled like this and time which is scaled like this. So, okay, so trying to see how can I save this picture so that it looks normal? Because I really want space scaling to be two to the minus j and time scaling to be the square foot. Okay.
00:14:29.814 - 00:15:46.998, Speaker A: Anyway, the main claim here is the, you look at the diameter of these guys. Then I claim that there exists some positive sigma such that when you sum up over all possible case, so overall possible times, first probability that this is bigger than two to the minus j sigma, and then sum up overall possible j of this, this is less than infinity. Okay, so assume that we know the claim. That would be the main technical that we approximate. So this means that, well, this sum is finite, which means that starting from sum j, all of these diameters are less than two to the minus j theta. So almost. So this is Barel kantal lemma.
00:15:46.998 - 00:17:53.064, Speaker A: If the sum of these probabilities is finite, then almost surely only finitely many of these events happen. So, which means that again for all, but finally many j and k diameter of this image is less or equal than two to the minus j theta. So we can say that this diameter is less than constant times two to the minus j theta for some c, which is random, which depends on randomness of the curve. Okay, so now what would it mean? It means that if you want to compare ft one and ft two of iy one and iy two, this is the same as the difference between, in our notation, h of y one t one minus h of y two t two. And I claim that this is just bounded by this sum of diameters of various images of the rectangles where, and you summit over all j, where j is the minimum of log of y one log of y two, well, mod two base two logarithm and one half logarithm of t one minus t two. The reason for this is the following. So you want to compare value here and value here.
00:17:53.064 - 00:19:11.162, Speaker A: What you do, you go to common ancestor and you say that the difference between them is bounded by the sum of diameters of these rectangles. And then you carefully count the rectangles here and you know the diameter. So diameter of this, each of this rectangle is bounded by constant times two to the minus j sigma. So when the dust settles and all you sum up all I which are higher than this two to the minus j sigma, you get two to higher than level j. This would be less or equal than a times two to the minus j sigma, where j, remember, is this minimum. So what happens? It means that when yt approaches some zero t zero, there exists this limit, because they do form a cache sequence. So well, to be really careful, you get a conversion sequence here.
00:19:11.162 - 00:20:09.964, Speaker A: You take the image and you see that the image forms cache sequence. So there is a limit, the usual stuff. And this limiting is continuous. How do I know this again? Because I have this continuity in t here. Because when t one is close to t two, this limits would be close. So we get our statement if we assume the success and claim that probability of the fact. So the event, the probability of the event, the diameter of the scaled rectangle is large is actually finite.
00:20:09.964 - 00:21:22.608, Speaker A: Okay, so that's what we would be proving to prove the theorem. We would be actually proving that this sum converges. Okay, so again, we are just looking at little rectangles, which are correctly scaled, space scaling, time scaling, and then we just look at the probability that this is large. And of course, how can we estimate probabilities at something large? Well, let's think intuitively what we need to do. We have a rectangle in the plane. We want to map it somewhere. Well, the scale, the size of it would be the size of the original rectangle times the maximum of the derivative of the map.
00:21:22.608 - 00:22:02.044, Speaker A: Right? So we need to estimate the derivative of. And that is what is done in what I call key estimate. So, let me underscore it. Key estimate. And it's a serum of Roder Schram, which will prove later today. So, let me describe this technical theorem. So, suppose that b is between zero and one plus four over kappa.
00:22:02.044 - 00:22:54.338, Speaker A: And suppose that, well, a is this special function of b. It's two, b plus kappa. B times one minus b over two. And let lamb they gain the special function of b for b plus kappa b, one minus two, b over two. Then the claim of the theorem is that you can find some constant which depends only on kappa and on this b such that for every t in, for every positive phi, and for every delta between zero and one and every real x. So we really get uniform estimates here. Probability that the derivative of now map ft.
00:22:54.338 - 00:24:01.654, Speaker A: So we are not shifting anything, just ft prime at x plus iy. So, probability of this event that this derivative is bigger than delta over y is bounded by the following. It's this constant one over plus x squared over y squared to the power b y over delta to the lambda multiplied by this factor a of delta a minus lambda, where this depends on whether a is bigger than lambda or smaller than lambda. So if a is bigger than lambda, so which corresponds to this, it's simply delta to the minus mu. If they equal, it's one plus log delta. And if mu is, if mu is less than zero here. So which means that a is less than lambda, then just fine.
00:24:01.654 - 00:24:59.956, Speaker A: Looks extremely technical, I know. But as many technical statements, it would not be that difficult to prove. You'll see in a moment, not in a moment, probably next hour. But now let us use this theorem to prove our claim and hence the theorem that shamlovna revolution is indeed generated by Luvner Karf. So first we take the theorem and we apply it to very special value of B. So again, this is, now it looks like, of course. Well, why do we take exactly this value of B? But we'll see from the proof that this is exactly what is needed.
00:24:59.956 - 00:26:01.864, Speaker A: Again, we knew that we needed an estimate, but on the derivative, and this is the one which works. So we take this b, this produces this lambda couple plus eight squared over sixteen k and the same three k squared plus 32k plus four kappa, three kappa squared plus 32 kappa plus four over 32 kappa. And now we plug in in here, and we take it at a very special point, y equal to two to the minus j. And I want. So this is two to the minus j over. So this is our delta. And then we plug it in here and we get that this is actually bound that well, after Das settles that this is bounded by constant two to the minus two j.
00:26:01.864 - 00:26:53.144, Speaker A: And then there is this extra factor of two to the minus epsilon js, which would actually make everything converge. And this should be true for some epsilon bigger than zero. And that works. Again, you can check plug in here, provided that this, well, remember, this would be our delta for this estimate. But delta depends on this sigma. So for which sigma would it work? Again, a very easy, straightforward, just substitutions there shows that it works for this sigma sigma, which has less than kappa minus eight squared over maximum of kappa plus eight squared. One half of three kappa squared plus 32 kappa plus 64.
00:26:53.144 - 00:27:36.754, Speaker A: Again, I decided not to include this particular, relatively painful calculation here. But you see, the main point that I want to make here is that this all works for all kappa not equal to a. For some reason, this particular computation breaks down for Kappa equals to eight. And so far there is no substitute. Okay, so that's our main estimate. Let's call it star. It follows again directly from theorem of Rod and sham.
00:27:36.754 - 00:28:27.664, Speaker A: And this gives us control of distortion of the diameter. So, by the way, just a little remark, because here I use f without head, and here I suddenly use f with the head. It's okay because the difference is shift and x. And this is true for every x. So the only thing which would happen here is this factor. And the thing which I'm tacitly avoiding is that this x, well, when brownian motion is run up to time one, it cannot be too large. So this factor actually cannot be too large.
00:28:27.664 - 00:29:21.584, Speaker A: Anyway, as I mentioned, this estimate gives us control of intuitive distortion of the diameter. And as I mentioned again, it doesn't work for kappa equal to eight. Okay, so now, unfortunately, this is not that. Now we really need to start working hard to prove everything. So the idea here is to subdivide the interval here. So the time interval, you see, here comes another kick, you would say, okay, now he will use distortion theorems. Of course I will use distortion theorems, but I can use them only in y.
00:29:21.584 - 00:30:09.544, Speaker A: I cannot really use distortion theorems in t because for different t, I have different maps. All I know that they are continuous with respect to t, so they change continuously. But how do they change? And all this, again, something can be done if you know that our driving function changed a little, but maybe it didn't change a little. Brownian motion can jump while it's random curve after all. So here is a standard trick which actually will be repeated in this course over and over. And here I will try to do it carefully. We divide it into sub intervals with control change of the brownian motion.
00:30:09.544 - 00:31:20.584, Speaker A: Okay, so we start with z. So t naught would be z of our interval k plus one over two over two j. Now, tn plus one, by definition, would be the maximum side t such that we are jumped by at least two to the minus j. So b n plus one would be different from b of kappa tn by two to the minus j up or down. And in between, they jump by no more than two to the minus j. Again, what is the reason for this? I have control of time, and I know that approximately in the time two minus two j brownian motion, would an average jump by something like two to the minus j. But this is the keyword here, on average.
00:31:20.584 - 00:32:17.814, Speaker A: Now, I really need to divide into smaller such things. And so let's look at the number of times we do it. So n is the first time when tn is below the other end of the interval, k two two j. And so let us introduce the notation. T infinity would be this, k two minus two j, and t hat would be the maximum of tn and t infinity. So again, what happened here? We start with the right end of the interval. We keep subdividing it by little intervals where we jump by our brownian motion jumps by no more than two to the j.
00:32:17.814 - 00:32:52.224, Speaker A: And n would be the number of times we do it. So. And then again, the standard thing, we cannot guarantee that any bound on the sum capital. But we can take the expectation of this, and that will be good enough. And this is the thing. So by brownian scaling, as I mentioned. So let's look at the probability that this n is bigger than one.
00:32:52.224 - 00:33:55.422, Speaker A: Then we jump by two to the minus j at least twice. So I claim that this is just a constant, which is independent of j and k. Why? Because we can rescale the whole picture, rescale and shift the whole picture to the interval of the fixed size. So essentially, to square right, when we rescale space by two over two j, we rescale time by two to the power j. And so this probability, then n is bigger than one, is some row. But now, probability by Markov, by strong mark of probability of brownian motion, probability that n is bigger or equal than n plus one. If you already know that n is bigger, equals an m, it's bounded by rho, because this is the same as to say, okay, we already jumped m times.
00:33:55.422 - 00:34:22.907, Speaker A: Now, what is the probability that we would jump first time? Oh, it's no more than wrong, because we already jumped so many times to the interval. Probably some of it is already eaten up. And on this small interval, we want to jump by two to the minus J. Definitely. This probability is bounded by rho. It's not rho. It's actually strictly small than rho.
00:34:22.907 - 00:35:11.024, Speaker A: So by multiplying it out, you get that the probability that we jump at most, at least ten times is bounded by rho to them. That's what I said, that we cannot guarantee any bound on. Nice. But we can say that probability the ten is too large is very, very small. That would be enough for computations. Okay, so now observe the following. That this derivative is measurable with respect to sigma field generated by brownian motions up to time mass.
00:35:11.024 - 00:36:08.104, Speaker A: Right? Because we just solve the ovner knowing brownian motion up to timers. On the other hand, tn hat this guy, which is, you know, n's time, we jumped by two to the minus j before the end. This is by definition, generated by brownian motion for time bigger than the STM head, right? Because look at the definition, all views is what happens at the time before this tan hat. So this is a stopping time. So this is a very fine point. This tan hat is not at the stopping time for brownian motion. It's a stopping time for reverse brownian motion.
00:36:08.104 - 00:37:21.804, Speaker A: But this key thing, this independence, actually would help us. Okay, so what does it mean? Let's look at the probability that this derivative is bigger than delta. Well, as usual, I'm missing absolute value conditioned on the fact that this tn hat is equal to s. See the story independent event. This depends on what happened before. This fact depends that tn hat is equal to s on what happens after s. So the probability that ftn hat is bigger than delta condition on tn hat equal to s is the same as the probability that fs prime at this point is bigger than delta by this independence which we just discussed.
00:37:21.804 - 00:38:18.754, Speaker A: Okay, so this is another fine point. Here tn is some random point. So if you know the estimate on the derivative at arbitrary given time, why would this estimate be true for random time? Certainly wouldn't be. You, for example, can pick your random time to be the time where the derivative is largest. Then the expectation would be totally different. But for this particular random time, by this particular identity, this is a probability that we are bigger than delta at this time. Of course, conditions that we didn't hit t infinity that this little line is still less than our random n capital.
00:38:18.754 - 00:40:17.150, Speaker A: This is bounded by the supremum of probabilities of fs prime big than that supreme of all s. Again, why is it preferable? Because here this time is random, if you know anything about it, this probabilities we can estimate, that's something that we can start. Okay, so now let's look at the probability that the existence such that the derivative of this tn hat is bigger than delta. Well, let's just do union bound. This is a probability derivative at t infinity is bigger than delta plus sum of probabilities that tn derivative at tn hat is bigger than delta, conditioned on the fact that tn hat is bigger than t infinity. Okay, so how many guys are here? Expect the value of n plus one because twelve there are n guys here, capital n guys here plus this one. And each of these guys is bounded by the supreme bound on this probability that fs prime is bigger than delta, but expectation of n plus one.
00:40:17.150 - 00:40:44.922, Speaker A: Let's look. What is it? This is something which is bounded by rho to them probabilities. And m is bigger than m is bounded by row to the m. So expectations, just some of the probabilities that we have bigger equals an m. It's finite. So this is just constant multiplied by supreme of these probabilities. Again, I promise you that we'll go through this slowly and that's how it goes.
00:40:44.922 - 00:41:48.522, Speaker A: So we just reduced estimating probability that something is large in one of the many given point probability to estimating that something is large in one given point, as we need to uniform estimate of all sn zero one. But it's who cares, that will happen. Okay, so let's keep this estimate in mind, and let's now look at the following strip as capital. So we look, well, it's actually a rectangle. So we look at y, which is two to the minus j minus one, two minus j plus three. And x is between two to the minus j plus three and minus two to the minus j plus three. So we generously give an x.
00:41:48.522 - 00:42:55.028, Speaker A: We generously given y. And what I want to say, that image of this rectangle, remember that at the end, we estimate the size of this image. This lies in the union of the images on the ftns guy. So you need just n images of s under one map. Okay, so we have a spacetime rectangle rjk we want to replace it by space rectangle less to later use distortion theorems. And so that's what we are doing. So, we are saying that this rectangle is bound, is within collection of images of these rectangles, and that they don't intersect each other.
00:42:55.028 - 00:43:34.014, Speaker A: Sorry. Rather opposite that consecutive one intersect each other. So what does it mean? It means that to estimate the diameter of this, we just need to sum up the diameters of this, you know, things, consecutive ones intersect each other. So we just sum the diameters up. And again, we don't really need to sum the diameter. So we multiply n by the sum of, by the diameter of one of them. We can estimate diameter by estimating derivative.
00:43:34.014 - 00:44:00.354, Speaker A: And then everything would work out. But first, let us prove this little subclaim again, sorry. We now have claim within claim. It's already third level. Right? We have ethereum claim. And to prove the claim, we are proving yet another claim. But let's just do it.
00:44:00.354 - 00:44:46.522, Speaker A: Okay, so, to prove the claim, let t is between these two moments, tn plus one and t. So t is between two moments where the brownian motion jumped. But here we use the fact that it's a control jump between them. It couldn't jump by more than two to the minus j. And y is here. Then what is ft of iy? Let us use this fact. This is the Levner equation.
00:44:46.522 - 00:45:50.338, Speaker A: So let's use it. We take ft of iy, apply g, subtract b, subtract driving function, and then take ftm. Hat that's tautological identity, because this composed with this is almost identity. Well, this composed with this subtracted is identity by definition of f and g. So all we have to check is that this guy is an s. If we prove it, we are done, because, well, first statement, well, would follow from the fact that any t in Rgk belongs here. And y is, by definition of RGk is between two to the minus j minus one and two to the minus j.
00:45:50.338 - 00:47:00.904, Speaker A: So that's not interesting. And second, it will imply also second statement, because if you take t is equal to tn hat, it would belong to ftn plus one hat of s. So this entity definitely belongs here, because then 510 just of zero zero, so, well, not of zero zero, sorry, of two to the minus j, two to the minus j. So this just means that these two things would be intersecting. Because, again, this clearly belongs to both of them. Okay, so let's prove it. Let phi of s, by definition, would be j's of ft hat of iy for s less or equal than t.
00:47:00.904 - 00:47:37.174, Speaker A: Then let's see what happens when s is equal to t. Well, that's very interesting. So ft hat of iy would be some guy. And then we map it back. This is the same as I, y plus b of Kappa T. Again, because what is ft hat? It's ft of iy plus b of kappa t. And g t is in your store ft without hat.
00:47:37.174 - 00:48:15.514, Speaker A: So this is phi of t at the time t is equal to I, y plus b of kappa t. And finally, finally. So you see, we did all these computations, set up probabilistic estimates somewhere. We have to use log. That's why we use log. We finally look at the derivative of phi of s with respect to s and simply write down the luvner evaluation for this. Okay, so this is what happens then, if you take imaginary part of it.
00:48:15.514 - 00:48:38.658, Speaker A: Well, it's less than zero, because imaginary part of this is less than zero. So the function is decreasing. It means that imaginary part of phi of s, it's less or equal than imaginary part of phi of t, which is. Am I just. Yeah. Which is bigger, equals than two minus j minus one. Sorry.
00:48:38.658 - 00:49:34.484, Speaker A: It's minus j minus one. Okay, so now we plug this in back in, and we see that this minus this is at least two to the minus j minus one. So this derivative is bounded by two to the j plus two. And now we know that since t lies within this interval, t minus t is bounded by two to the minus j. So we have that phi of t plus one, hat minus five t is less than two to the power minus to the power two minus j. Because we'll multiply this by this. Okay.
00:49:34.484 - 00:51:07.434, Speaker A: And now since, well, this b of Kappa T minus b of ten hat is less or equal than two to the power one minus j, we see that I belongs to S again. So what is I? It's this minus this. Now, we just estimated this minus b of kappa T and we saw that it's not far away from phi of T, which is iy plus b of k t. Now we plug this in here and we see that we couldn't get far away from this point, so we are still in S because again, difference between this and this would be less than two to the one minus j. And we generously gave this x axis implement. And so if yt belongs to rgk, then y is between two to the minus one to minus j. T is in tn plus one hat, tn for some n.
00:51:07.434 - 00:51:36.874, Speaker A: And as I explained before, claim now follows because if you are here, then you are within between tn plus one hat and tn hat for some n. So you are inside this and we end up this claim. And this is a good moment for break until 11:00 so we'll reconvene in about eight and a half minutes.

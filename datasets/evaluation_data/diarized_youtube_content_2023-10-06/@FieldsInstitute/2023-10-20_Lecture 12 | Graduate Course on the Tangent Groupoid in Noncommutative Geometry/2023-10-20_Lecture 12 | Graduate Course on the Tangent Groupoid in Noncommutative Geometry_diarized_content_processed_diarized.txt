00:00:01.040 - 00:01:17.454, Speaker A: All right, so we're going to do some, good morning. We're going to do some integration today in the style of the French, and I'm English, and so it really pains me to say that this french approach to integration using densities is the best way of doing it. It's sad, but it's true that these guys have the right approach. I mean, they go overboard. And so we're not going to follow the French all the way into the murky depths of half densities. But when it comes to full densities, got to hand it to the French. They, they did the job, right? Oh, that's so painful to say.
00:01:17.454 - 00:02:54.246, Speaker A: Okay, so, yeah, what we're going to do, just as a, so you see where we're going, we've built in more than one way this tangent groupoid, and now we want to look at all functions on the tangent groupoid. And we want to make this thing into an algebra, in fact a star algebra. And the thing to keep in mind when we get into this is that we're copying what you do for a lie group. And so of course the functions on a regroup are in algebra just under point wise multiplication. But that's not what I'm talking about here. We'll use convolutional functions. If you're interested in the Lie group G for its representations, then it's not very useful to study cc infinity of g with the point wise multiplication because that's not really related to the representation theory of g in any meaningful way.
00:02:54.246 - 00:04:10.056, Speaker A: But with the convolution multiplication, however, cc infinity of g is kind of an interesting thing to study, and some funny things happen. It's worthwhile being alert to this. I'll try to remember to be so alert. There are some funny differences as well. So it's similar to what we're going to look to what you do do with lead groups, but not exactly so not identical. I mean, so what's this business with the French? Well, French love densities, which are things that you build on a real to begin with, finite dimensional vector space. And what's a density? Well, it's just a map.
00:04:10.056 - 00:05:20.204, Speaker A: A function to begin with, let's call the vector space v, a function defined on the n fold product of cartesian product of v with itself values in the reals. I want to emphasize it's just a function. It's not an item from linear algebra, it's just a function. But it has a property which I haven't or tin, which makes it a partially linear algebraic. Let's call this dimension n. So I don't have to keep writing dim v. But this thing transforms like you see in exterior algebra by the determinant, although not exactly by the absolute value of the determinant.
00:05:20.204 - 00:06:56.548, Speaker A: Like this, whatever v one up to vnr, and whatever a is. And it's traditional to say that a is invertible, although this is also true if a is not invertible. So this is what a density is. A density is a function with this property and the set of all densities grant many of these things, is a one dimensional vector space over r. If you have two densities, you can just add them one to the other. It's another function with exactly the same property, and you can scale and multiply. So it's a vector space and there's only one because this formula tells you what it tells you that if v one up to vn are linearly independent, then what lambda is on v one up to vn is completely specified by what lambda is on some standard fixed chosen basis, because you can always choose some a which maps any v one up to vn to the members of some standard fixed basis.
00:06:56.548 - 00:07:39.012, Speaker A: So there's just one lambda for each choice of real scalar, and that real scalar will be lambda evaluated on the standard basis. Okay, if you have a bunch of these which are not linearly independent, then lambda has to be zero on them. That's easy to see. So that's the whole story. Pretty easy. Okay. And oh, let's give this guy a name, I don't know, delta v delta.
00:07:39.012 - 00:08:09.272, Speaker A: With densities you can build any type of density that you like. Pretty much any complex number can be put right here. And now you have s densities. The particular case of s equals zero is a little bit special, but as long as s is not zero, this tells you what an s density is. But we're not going to follow the French that far. I mean, there are limits, so we won't do that. Okay, good.
00:08:09.272 - 00:09:16.240, Speaker A: So now if you have a manifold, then we can build this thing delta of m, maybe with brackets, maybe not maybe just, anyway, I'll write it. Maybe. I like that better. So this is the line bundle, the real line bundle of densities on the fibers tangent bundle, like that. And this is a smooth real line bundle. And it's also trivializable. It's not a complicated bundle.
00:09:16.240 - 00:11:19.618, Speaker A: And this is where densities show their strength. And the reason it's trivializable is that according to this condition, a density is either always positive or always negative. Positive, meaning bigger than or equal to zero, negative meaning less than or equal to zero. So densities divide into two types, positive densities and negative densities according to their whether the word positive and the word negative refer to what values the density takes on linearly independent interpols of vectors. Oh, I guess the zero density too. So you can easily build a global positive section of this bundle just by partitions of unity fission levels. Densities are obviously very closely related to nforms, and this is a small place where nforms are not quite as good as densities.
00:11:19.618 - 00:12:40.486, Speaker A: Yes. Basically you're saying canonical orientation. Yes, yes, it's, it's, that's true. It's more, it's, it's, yeah. There's a canonical connected family of trivializations, I feel like, of this bundle, canonical orientation, if you like this bundle. Yeah. And you can integrate with these things in the following way if, what's a good letter? I don't know, s if maybe a smooth, compactly supported section, just without making any further choice.
00:12:40.486 - 00:14:32.714, Speaker A: And the way you do that, I mean, if you actually want to do it in practice. Then again, you use partitions of unity in local as before. And now you can reduce using local coordinates to the case of integration of a density on rn. Now, I should say in this situation, we can write s as some function times whatever, lambda times whatever. We have four s on the standard basis of the tangent bundle of Rn. And then we define just the integral of s just to be the integral of f with respect to, just to emphasize what kind of integral we're talking about here. Just the integral with respect to Lebeg measure that type of integral.
00:14:32.714 - 00:15:19.934, Speaker A: And it's independent of everything. If you change variables on Rn, if you have a bunch of y's, which is another coordination of some part of Rn, then what you get from this formula is exactly the same number, thanks to the change of variables formula for integration. So it all works out nicely. I mean, there's a change of variables formula here, and there's also a change of variables here, and they cancel one another out. So that's nice. Got to hand it to the french, these guys can just be integrated, it's functorial, and you can just integrate. Good work.
00:15:19.934 - 00:16:53.854, Speaker A: Yeah. All right. So, yeah, so let's remember now, and if G is a lie group, then we can build interesting special integrals on the lead group using the group structure of G. And this involves picking a section of this density line bundle. And what you do is you just pick any positive element, positive in the sense we were talking about over there. Of the densities at the identity like that. Oh, let's give this a name.
00:16:53.854 - 00:17:51.354, Speaker A: Let's call densities a big lambda like this. I should have used a. Maybe I'll just change it right here. Like s all these guys there. There we go. And now I want to extend this one choice of one density on this one vector space to a family of densities on all of the tangent spaces. So I didn't say where this thing lives, but this is a section of an element of the tangent space in G and g, like that.
00:17:51.354 - 00:18:53.620, Speaker A: Well, if you have a group and you have an element, little g of a group, of course you can get a diffumorphism of the group to itself from it by either right multiplication or left multiplication. That'll map the group to itself. And the way that densities work is that they're contravariantly functorial. You can always pull back a density along a smooth map, and that's what we're going to do right here. So left multiplication by g sends e to g, and so it sends the densities at g to the densities at e. And so you have to write it like this. Or who's to say? Not sure the French have much have a position on this.
00:18:53.620 - 00:19:50.972, Speaker A: Who's to say you should use left multiplications? Maybe you should use right multiplications like that. It's up to you. I mean, if the group's not a billion, then apparently you should choose one over the other. So I think the way it works is correct. I puzzled it out before. So, all right, so now we have an integration map on functions. Let's, maybe we're talking about real functions.
00:19:50.972 - 00:21:13.586, Speaker A: Maybe we're talking about complex functions. I guess for the last little while we've been talking about real functions. Maybe we'll just, maybe I won't even bother worrying about that. By, so on the right hand side here is the integral we just defined that the french defined. And on the left hand side is an honest integral of just functions. And these are examples, the only examples of what are called left or right are integrals of functions. And let's maybe just summarize what properties they have.
00:21:13.586 - 00:22:51.784, Speaker A: So we're warming up, just reminding ourselves a little bit about how measures on groups or how integrals on groups. And we're going to jump to groupoids in just a moment. So here I depart from the French here I'm talking about actually integrating functions because, damn, I mean, that's what you want to integrate is functions, right? So these are just ordinary functions here. And these integrals have the following properties. Just use the standard notation for them. This is in the case of the right r integral which is the one we're going to favor in this class. And they're positive on positive functions and so on and so forth.
00:22:51.784 - 00:23:52.054, Speaker A: And as regards this problem which maybe disappeared of making the functions into an algebra. Now we can see solve it. There are two parallel theories. One for the left and one for the right. But let's just, rather than keep duplicating everything, let's favor the right. As you know, history has always done. Let's favor the right over the sinister.
00:23:52.054 - 00:25:26.850, Speaker A: And to go back to the problem of making a multiplication. Here's a formula for multiplication. This thing is an associative product on. It's also possible to build an involution on this associative algebra. And now there's more than one choice. But this does the job like that. And this is the formula that we're going to use.
00:25:26.850 - 00:26:13.682, Speaker A: But a little warning here which I'll come back to is that this is not the usual choice or I'll explain what's going on later. But it. It does define a conjugate linear operation on Cc infinity of G, which squares. You do it twice, you get back to where you started from. And it reverses the order of multiplication. Just like an adjoint operation should. The defects of this formula, such as they are, become apparent when you start to try to think about building seastar algebras.
00:26:13.682 - 00:27:06.074, Speaker A: And we'll come to that in due course. Great. Now onto groupoids. We're really only interested in one groupoid, which is the notorious tangent groupoid. But it doesn't hurt to talk about more general ones here for time being. In fact, maybe it even helps notation. So let big g be a Lee rupoid.
00:27:06.074 - 00:27:56.526, Speaker A: So this is like we know it's a smooth manifold. There is supposed to be two maps, source and range. Which is supposed to be submersions from g onto m. Maybe I shouldn't call it m because in the case of the t tangent groupoid the object space turns out to be m times r. Maybe we can just call this w like that. People usually write two arrows. One of them is source and the other is range.
00:27:56.526 - 00:28:54.864, Speaker A: And these are supposed to be submersions. And then there's a map which is a composition which goes from space g two to g. So this is the set of all pairs. Gamma one, gamma two in g times g. Which ought to be composable in the sense that the source of gamma one where gamma one starts is where gamma two ends. And if you assume that these maps here are submersions which you're supposed to in the definition, then this thing, g two, is a smooth manifold and a smooth submanifold of g times g. And this composition map is also supposed to be smooth.
00:28:54.864 - 00:29:44.364, Speaker A: And then it's a category. So there's also supposed to be a bunch of unit elements, identity morphisms, that would be an inclusion of m into g. That's supposed to be smooth as well. And it's supposed to be a groupoid, which means that every morphism, gamma has a gamma inverse attached to it. And the map which sends gamma to gamma in this is also supposed to be smooth. Okay? And now you need to make a choice about whether you're going to favor the source map or the range map like we've seen already. And we'll favorite the source map because we were doing that all along.
00:29:44.364 - 00:30:50.704, Speaker A: Okay? And now we want to define this convolution multiplication. And the idea is we'll just change the g's, the little g's here into gammas and we'll be in business. And what we'll be integrating over is all possible gamma one's, for which the formula here makes sense. So gamma one inverse has to end where gamma begins. And so gamma one has to begin at the same place that gamma begins. So we're going to be integrating over the source fibers that I've just written down there. So we need a bunch of measures, integrals defined on these things here.
00:30:50.704 - 00:32:45.760, Speaker A: Okay? And then we'll be in business, be able to write down some formulas at least. So just temporarily, let's get away from groupoids and just talk about any submersion of manifolds. We talked about densities on manifolds earlier on. We can equally well talk about, not quite sure how to write this densities on the fibers of PI. What should we call that? I don't know. Almost smooth as Eckhard rightly points out, oriented real line bundle, I don't know, like this. And so we're just doing everything fiber wise.
00:32:45.760 - 00:33:44.984, Speaker A: We're talking about now the fiber wise tangent bundle. So there is a bundle over z in this country whose fiber at any given point of z is just the tangent space in the fiber direction. And then the densities that I'm speaking of here are just fiber wise. The densities on those fiber wise tangent spaces, everything's fiber wise. You're in business. And then we can integrate reasonable, for example, smooth, compactly supported sections. And now the integration is taking place along each fiber.
00:33:44.984 - 00:34:37.968, Speaker A: So each fiber gives rise to an integral. So there'll be a number associated to each fiber. But the numbers, the fibers are indexed by the points of x. And if you started off with a smooth, compactly supported section, then what you'll end up with is, by differentiating under the integral sign, is a smooth, compact supported function on x. All right, so far so good. So let's just do it. Following now, after this abstract nonsense about submersions, let's go back to the groupoid situation.
00:34:37.968 - 00:36:45.640, Speaker A: The submersion in question is going to be the source map, and we want to build a good section of this bundle that I just talked about in order to proceed. So we'll look at this thing here in the case, maybe I should stick in a pie somewhere. And how are we going to do it? Well, as follows, following the prescription up there, we'll start at the identity elements, but now there's more than one, it's a groupoid, so there's more than one identity element. So for each one, we'll pick a positive density. So lambda, sub identity x, is an element. It's a density on the fiberwise tangent space at this point, identity x, this is a morphism. It's an element of big g.
00:36:45.640 - 00:37:22.084, Speaker A: It's one point in big g, and at that one point, there's one fiber wise tangent vector space. And we build on that one fiberized tangent vector space, one density, which is positive in the sense that we talked about before. And now we move x around as it moves through w. Maybe I should have called it not exponent little w. And I want these densities that I've just chosen to vary smoothly. I mean, why not? Okay, so we start with that. Can you build such a smooth section? Well, yeah, you can build such a smooth section because everything is orientable.
00:37:22.084 - 00:39:12.094, Speaker A: And then we'll just extend. But now we also want to define densities over every gamma densities in this fiber wise sense. And we'll just do it by right composition. So, right composition. Delta. Gamma is delta of source of gamma, lambda of the source of gamma. Okay, so this guy, this construction, sorry, just deciding how much of that I'm going to regret erasing leads us to what's called a ReiT system, and it defines an integral which goes from smooth, compactly supported functions on g to smooth, compactly supported functions on w.
00:39:12.094 - 00:39:53.908, Speaker A: Like that, by integrating over the source fibers. And it satisfies the analogous formula to the first formula, the top formula up there. So if you were integrating f of gamma, one gamma e gamma one. Kind of like integrating over gamma one. This is going to be the same as integrating f of gamma one. Gamma one. Not what I would.
00:39:53.908 - 00:41:40.778, Speaker A: I'm not going to write down the correct formula. Just leave it like that. And now we can define our convolution product on Cc infinity of g by exactly the same formula as before. And here we're going to integrate over the appropriate source fiber, which I guess is the source of gamma. And again, it needs to be checked, but it's easy exercise. And this is an associative product, is now an involution for this product, the one we've just defined. And now it's the usual involution.
00:41:40.778 - 00:42:38.174, Speaker A: This is what people always do. It wasn't the usual one before, but oddly enough, this is the correct choice for groupoids, even though it was arguably the incorrect choice for groups. And groups are just a special case of groupoids, but. Okay, we'll get to that in just a moment. All right, so this is the convolution algebra, convolution star algebra of smooth functions on a regrupoid. And there's something fishy going on with involutions that we'll explore in more detail in just a moment. So when you integrate the fiber, is that like applying this integration to evaluating an s of camera or something like, how should I think of this integral over the fibers? Because right now, integrals from the group where you.
00:42:38.174 - 00:43:34.048, Speaker A: Yeah, so the, if you evaluate this integral, the one at the top, at some point of w, then you will obtain an integral which only depends on the restriction of a function to the source fiber at w. And that's what I'm talking about here. You can write this down in a more systematic way. Wonder why it is that the convolution of two cc infinity functions is again a cc infinity function. That's not completely obvious. And the right way of thinking about this is the following thing. If you look at the space of composable morphisms, this thing here, then there's an obvious map from the space of composition.
00:43:34.048 - 00:44:21.204, Speaker A: In fact, it's written right down there from the space of composable morphisms down to g itself. And the fibers of this map can be identified in the obvious way with the source fibers of G. So the Haas system that we've built here becomes a ha system on the fibers of this map, the composition map. And what we're doing in order to define this convolution here is the following thing. You have two functions, f one and f two. The tensor product of those two functions gives you a function on g times g in the obvious way. If you have two functions, f one and f two, and they're both functions on g, then f one tensor f two is a function on g times g.
00:44:21.204 - 00:45:33.380, Speaker A: And if you have a function on g times g, you can restrict it to g two, which is just a sub manifold of g times g. And now f one tensor f two, is a smooth, compactly supported function on big g two. And what we're doing now is integrating along the fibers of the map from g two to g, which is just composition. And if you explain what is the multiplication in that sense, then you don't have to write down this point wise formula here that Jacob objected to, and it also explains why the convolution is a smooth, compactly supported function. If you believe that the operation of integration sends smooth, compactly supported sections of the fiber wise density bundle to smooth, compactly supported functions on the base, then you have to believe that this formula here defines a smooth, compactly supported function on G. You just have to, after you've done this whole construction. Okay, we've defined a convolution multiplication, but it depended on the choice of ha system, obviously.
00:45:33.380 - 00:46:14.844, Speaker A: And so you might ask, to what extent is this ha system unique? And the answer is, it's pretty much as unique as it was in the case of groups. In the case of groups, a har integral is completely characterized by the, in our case, the right invariance property and just one normalization. Any two har integrals which are right invariant, write har integrals, are multiples of one another. That's not quite true here, but it's almost true when we made this construction. Here we do. Here we go. We started out by choosing positive elements not there.
00:46:14.844 - 00:47:25.740, Speaker A: Here we chose a positive section of this half density bundle over the unit elements. And if you choose another section of the half density bundle over the unit elements, the difference between the two, or rather the ratio, the two, will be a smooth positive function on w. So any two Haas systems are unique up to multiplication by some smooth positive function on w, and by multiplying by that positive function. It's easy to see that although this algebra is not unique, it's unique up to isomorphism. There's an obvious conjugation isomorphism or multiplication isomorphism, which takes one product defined using one host system to the product using another half system. You could, if you wanted to, as the French do, make this thing completely canonical so that no choices are ever, ever have to be made but then in order to do that, you have to take square roots somewhere and it begins to look. See, he doesn't mind, he's french.
00:47:25.740 - 00:48:11.138, Speaker A: But, you know, for the rest of us, you know, from the. Anyway, I don't know, half densities, okay, they turned me off in this context. I mean, half densities, to make a Hilbert space, that's fine, but these, the sort of half densities you need to make a convolution algebra, that's not so good. I was going to say, would it work for to just look at resource fiber? It's not quite symmetric. Then you avoid how densities would it work to. I'm not sure quite what you mean to replace functions by densities. Yes, the answer to that question is no.
00:48:11.138 - 00:48:47.100, Speaker A: That wouldn't quite suffice for all of the purposes we have in mind. And in order to obtain a canonical representation on some canonical Hilbert species, to get a completely canonical groupoid, c star algebra, densities aren't going to do the job you need somewhere, some half densities, I guess inversion also inversion. Yeah. This as. Yeah, that would also be a clue that something's not quite right. So you have to talk about half densities in one direction, tensor with half densities in the other direction. It doesn't matter.
00:48:47.100 - 00:49:11.768, Speaker A: He's not bothered in the least. But the rest of us find that a bit troubled. You're not bothered? Okay. All right. You know, if you're ever going to calculate anything, you're going to make some choice. You're going to work in coordinates, you'll make some choice of measure and then it's just fixed. So why not make that choice anyway? Anyway, lost where I was.
00:49:11.768 - 00:49:48.832, Speaker A: Lost my train of thought. Yeah. So we have a product and we have an involution and we have a star algebra. Now let's just talk briefly about c star algebras. There's a lot of abstract stuff here, and there's much more in a way than we need, because we're only interested in the sea star algebra of the tangent groupoid. And there everything's much more concrete. So we'll look at something more reassuringly concrete in just a moment.
00:49:48.832 - 00:50:32.406, Speaker A: But let's continue with this abstract stuff for a while, maybe here. Well, the good news is that our algebra consists of honest to goodness, God fearing functions, not half densities and nonsense. It's just functions in this algebra that we've built. The bad news is the thing isn't completely canonical. The good news about the bad news is that in the one example that's of real interest to us. We'll see that the non canonicity is something very familiar. And it's not a big deal.
00:50:32.406 - 00:51:32.724, Speaker A: We're not going to be upset by it anymore once we've figured out what's going on in the case of the tangent groupoid. Okay, and now let's discuss sea str, as I said, which is all about representations on Hilbert spaces. So what Hilbert spaces are there for us to represent on? The answer is just the spaces l two of gw. We've fixed a section of the one density bundle here. We fixed, in other words, a measure on g sub W. So we can certainly define a Hilbert space. Maybe I should say what this guy is.
00:51:32.724 - 00:53:24.424, Speaker A: So what's an element of this Hilbert space? Well, it's just a function, you know, according to my prejudices, we're just integrating honestly God fearing functions here. And what's the inner product? Well, write down the norm. It's just going to be the integral of f of gamma squared times this density that we've built over here, which restricts to a one density on wood. So what you're integrating there is a smooth, compactly supported one density on GW. So it makes sense, and you have a well defined integral. So this is the algebra we've just defined over here. And we can put it inside of bounded operators on the Hilbert space we've just defined here.
00:53:24.424 - 00:54:08.258, Speaker A: There's going to be one, if you like, regular representation for each little w. And what do we have to do? We have to take such a function and evaluate it on one of these functions. Too many f's. Let's do it this way. There we go. And then the result is supposed to be another function. So what's this all going to be? The answer is it's going to be the integral of f one, just like it was before.
00:54:08.258 - 00:55:32.510, Speaker A: Gamma gamma one, inverse f two, gamma 1d, gamma one. And it all, oops, it all makes sense. And it's a little bit miraculous and almost paradoxical. In fact, it looks a little bit wrong. But it's an easy check that this guy here is a star representation. And the reason it might seem a little bit wrong is that the involution here is such a simple involution. And you might say to yourself, given a little bit of knowledge, which is always a dangerous thing, how can this be? Because in the case of groups, this involution is not the involution that people use when they define the sister algebra.
00:55:32.510 - 00:57:07.774, Speaker A: They use an involution which involves some crazy modular function if you have a group for which the left har measures are not the same thing as har integrals, are not the same thing as the right har integrals, then there's a problem. This involution, certainly an involution, but it's not the one which makes either the left or the right regular representation into a star representation. And the resolution is a little bit interesting, which is that this is not the right regular representation in the group case. So you see, when the group theorists, when the representation theorists think about the right regular representation, they want it to be a representation. And they have in their mind that some general formula for the way a group algebra should act on a unitary representation space, some general formula should specialize to give a formula for the right regular representation. So they define the right regular representation in such a way that that's true, but this is not it. This is a different formula, so there are no contradictions.
00:57:07.774 - 00:58:18.954, Speaker A: I'll put in the exercises what it is that distinguishes lambda w from the right representation. Right regular representation in the group case, but this is not it. Yeah, just not it. It's an algebraic issue, but, and it's very clever that it's just a funny fact that in groupoid theory, you're naturally led to this involution, and it's a perfectly respectable involution, which becomes an isometric involution, the usual Hilbert space eye joint under these regular representations. But these are not the standard right regular representations, which maybe is not so surprising because I called them lambda instead of rho for right, the lambda for left. So it's a mixture of left and right, which miraculously cancels out all of the modular functions. All we're concerned about here is that we have a collection of formulas which are consistent.
00:58:18.954 - 00:59:34.262, Speaker A: As for the formulas in the world of Lie groups which are not consistent with these formulas, we're not concerned about them because we're not doing representation theory if the word used half entities. So what do you want the. I'm not quite sure what you want the algebra to be. If the algebra is an algebra of one densities acting on the Hilbert space of half densities, is that what you'd like? If that's the case, then yeah, then you're sort of in business. Well, there would be no modular function, but there's no modular function anyway. So I think the, the tension comes in the group case because. Well, I think, I don't think you can completely get around it.
00:59:34.262 - 01:00:08.174, Speaker A: If you want formulas which are consistent with group representation theory, all right. I wrote down in ancient times an explanation of this to my own satisfaction. It goes on, you know, it takes. This is the reason I'm reluctant to talk about it now. It just goes on and on forever. But I will condense this into a bunch of exercises for your betterment. Okay? Ah.
01:00:08.174 - 01:02:41.610, Speaker A: Now, you can build a norm, which is called the reduced norm, or the sea star algebra of the group, or just to be the soup of the things we've just defined, which were. And the completion in this reduced norm is the reduced siesta algebra of the groupoid. I think it's time to look at the tangent group hood. So what was formerly called w here is now m times rub. And in order to build a right system, we were supposed to choose a density for each little m and for each point of w, which is to say, for each little m and for each little t. Let's do it in the following way, which is not obligatory, but it makes the formulas nicer. Back to m and its density bundle.
01:02:41.610 - 01:04:22.244, Speaker A: Let's choose a smooth, positive section of this thing. So everywhere, at each point, it's one of these positive densities, one of these weird density functions that we were talking about, which is non zero, in fact, positive. Okay? And then we were supposed to build a density, one of these fiberwise densities, at each identity element like this. And the good way of doing this is just to define this guy here, t to the minus n. And it's the dimension of m times what I just call it this guy here. And just, this is when t is not zero. Oh, lambda sub n is one of these strange would be multilinear functionals on the tangent space of the manifold M at the point little m.
01:04:22.244 - 01:04:50.762, Speaker A: When t is equal to zero, the source fiber is the tangent space. But the tangent space of t of M identifies with t of M in the obvious way. And so I can define this fellow here using the same notation that I used to define these other fellows. The source fibers are all copies of m away from t is equal to zero. So this makes perfect sense. The source fiber is not m. When t is equal to zero, the source fiber is a vector space.
01:04:50.762 - 01:05:59.498, Speaker A: But the vector space that it is is the tangent space at little mix. And so this density still makes sense as a density at any point of this space. Got it? And so this guy here is. So now what we've done is build a smooth, positive section of this fiber wise density bundle over the units of the tangent group, which was what we did in the start of our construction here. So everything just comes from a single measure on m. That doesn't sound so bad anymore. You just pick a single measure on m and then you're in business.
01:05:59.498 - 01:06:48.616, Speaker A: And we'll make that more explicit in just a moment. Yeah. Yes. Well, when we. Yeah, if you're thinking deformation to the normal space, you're using that. Initially we defined the tangent group so that the fibers really were just tangent vector spaces. So what is this multiplication? Well, it's, it's much easier than all of this abstract rubbish might suggest if you're evaluating at a point m two a.
01:06:48.616 - 01:07:46.360, Speaker A: Remember all of this, let's do it this way. M one, t with t zero. This is just the integral of f one of m. You know what? Let's call this m three. Stop the t like that. Oh, except I also missed off the, what we did at the top was we chose a one density, a fixed positive one density on m. In other words, we fixed a measure on m in the language of measure theory.
01:07:46.360 - 01:08:36.964, Speaker A: In the language of the, well, those guys are also french. But in the language of measure theory, we just picked a measure on m, which has the additional property that when you transform it to a measure on an open subset of rn using a coordinate patch, then it's a smooth function times Lebeg measure. In other words, it's a smooth measure on m. And all we're doing here is integrating functions using the usual formula for, if you like matrix multiplication, we're integrating functions with respect to that fixed smooth measure. And when t is equal to zero, you have to use a different formula because the groupoid looks different at t is equal to zero. Its elements are just tangent vectors like that. And here it's just ordinary.
01:08:36.964 - 01:09:10.404, Speaker A: Oopsie. Convolutional multiplication. You can write this. And I guess I was writing it in this way. So it's nothing complicated at all. It's just, that's it. It's just these formulas, could have just written down those formulas and then we'd have been done.
01:09:10.404 - 01:10:44.464, Speaker A: But maybe it's worthwhile to see the broader picture. Yeah. What does this mean? So let me just answer that right here. If you take the tangent space at any point y of the manifold, which is the tangent space of m, this may be identified with the tangent space at m because it's a vector space. There's a little formula which says if you have a vector here, well, if you have a vector here, there's an obvious curve through any point y at t is equal to zero in t of m, namely the straight line and differentiation on that line, along that line gives a tangent vector according to the abstract definition of tangent vector over here. So this is the standard isomorphism, and it works. It's not about tangent spaces per se, it's about vector spaces.
01:10:44.464 - 01:11:56.562, Speaker A: So a density at this particular point is in the sense maybe identified with a function. What I'm supposed to, what I'm really supposed to put here is the tangent space at y to this manifold. But since this manifold is a vector space, I'm going to identify that tangent space with the vector space itself. Okay, so if I have one of these guys already, which I am given, then I have one. That sentence wasn't going anywhere. We started off up here. We started off with a smooth positive section of delta of M.
01:11:56.562 - 01:13:59.054, Speaker A: So we have a lambda m for each point, little m. That is exactly one of these things. And I'm taking that thing and I'm thinking of it as a lambda sub y instead of a lambda sub m, using this identification. So it's this particular density that on the tangent space that we're using, this translational invariant density. And now in this particular case, we can figure out what are these representations, these ones, it's just the integral operator with integral kernel, well, t to the minus n f of x y d t is not zero. Or the integral operator kernel integral kernel f of x minus y. Yes, or convolution, if you like.
01:13:59.054 - 01:14:44.284, Speaker A: So the representations that we're talking about are really, really simple. In this case. Here, the C star Al, the convolutional algebra of smooth, compactly supported functions on the tangent groupoid is represented as an algebra of compact operators, in fact, the algebra of all smoothing operators to begin with. And then when you complete, you get the algebra of all compact operators. Here you get all convolution operators by smooth, compactly supported functions on the tangent space. And when you complete, you get the C star algebra of the tangent space as a group. And it's traditional to say that by Fourier transform that commutative C star algebra of convolution, algebra of functions on the tangent space is just the c zero functions on the cotangent space.
01:14:44.284 - 01:15:16.420, Speaker A: And the following picture emerges. Oh, yeah, yeah. I do want to say something about my friends, the scalable operators. Let me just say this rather quickly. How does it. Sorry, which. Oh yeah, it doesn't depend on m.
01:15:16.420 - 01:15:42.680, Speaker A: They're all the same. Yeah, yeah, that's a good point. Right. The source fiber is the set of all points, the m teeth. Source fiber is the set of all points, m two comma m t so it's really just functions of m, two, or whatever functions of y. I should have said. And.
01:15:42.680 - 01:16:48.686, Speaker A: Yeah, so there is no dependence on it. There's not really any real dependence on t. This just comes about because we had to vary the measures in order to have measures which smoothly extended to t is equal to zero. Here now is the sea star algebra, reduced sea star algebra, I guess, of the tangent groupoid. You can take an element of this sister algebra, or an element, let's say, of cc infinity t of m. And instead of representing it on any individual source fiber, or indeed, instead of representing it on all of the source fibers, you can just represent it on the source fibers where t is equal to zero. And then you'll get a bunch of convolution operators, like I said, on the fibers of the tangent bundle.
01:16:48.686 - 01:17:28.854, Speaker A: And their Fourier transforms will be functions on the cotangent bundle. And so you end up with such a morphism as this. Make it look nicer. I guess that looks pretty much exactly the same. And what's left are, there is an ideal of elements inside the sea star algebra which vanish under this evaluation at zero. And that's isomorphic to this fellow here. Let's try and make this look a little nicer.
01:17:28.854 - 01:18:25.540, Speaker A: So this sister algebra is pretty easy to understand. It has a component which is just functions on t of m, and components, maybe not the right word, a part of it which is just functions on t of m. And then there are parts which look like compact operators, and they all glued together in this way. And there's a lot you can say about this. An interesting thing to do is just to consider the positive real numbers here. So let's divide everything both by the ideal of functions which are supported on the negative real numbers. And what you'll be left with is functions supported on the positive real numbers.
01:18:25.540 - 01:19:59.754, Speaker A: This is the sister algebra of that part of the tangent groupoid which lives over the positive real numbers. Now, quotient is the same. So this second sequence is a quotient of the top sequence by the ideal inside of this sister algebra of functions which are supported only on the negative numbers. And this notation here is just notation for the quotient sea star algebra, if you like. Why might this be interesting? Well, let's remember that the tangent groupoid is equipped with all of these automorphisms, diffeomorphisms and isomorphisms in the sense of functus, from t of m to itself. And they're parameterized, by the way we did it by positive numbers. This is a smooth in fact, action of the group of positive numbers on the manifold Tm.
01:19:59.754 - 01:21:08.246, Speaker A: And these preserve almost all structure. These guys preserve the composition law of the category, they preserve the smooth structure they sort of preserve. That is to say, they're compatible with an action of the positive real numbers on m times r, just scale and multiplication in the r coordinate. One thing they don't preserve is this choice of harm measure here. So because of that, you need to make a small adjustment if you want these alphas to which I worked out, and I'm just, yeah, okay, good. Which you need to include if you want get an action on algebras. This, if I have a function on t of m, I can just compose it with alpha lambda, and then I'll get another function on t of m.
01:21:08.246 - 01:22:06.514, Speaker A: So that'll be an automorphism of the vector space cc infinity of t of m. But because the measures aren't preserved, that automorphism is not going to be a algebra automorphism. However, the extent to which the measures are not preserved is easy to work out, because this alpha action is only acting, if you like, on the t coordinate. So there's a very simple dependence on t here. And if you want to obtain an algebra automobile, you need to keep that small extra correction in in mind. This is the lambda n, which french don't have to worry about because of the wise use of densities. But here we have to throw it in.
01:22:06.514 - 01:23:32.126, Speaker A: And now something interesting happens, which I'll have to stop at. So let's just go back and look at these sequences. In particular, the second sequence is worth thinking about, these sequences or these extensions of sister algebras. Our equivariant for this action of the positive real numbers on the tangent groupoid by scaling automorphisms. And the way that the action works is a little bit interesting. The way that the action works here, it's a little bit complicated to describe what's going on, but at the ends it's really simple to describe what's going on. What's happening when you restrict the action that I've just described to this ideal is you're just moving around by the action of the positive real numbers on the group of all non zero real numbers.
01:23:32.126 - 01:24:02.284, Speaker A: So the action here is concentrated solely on this factor here. It's not doing anything here. Okay. And what's happening over here is also easy to describe. The action is just the action on the cotangent bundle by rescaling. Do you multiply by lambda, or do you multiply by lambda inverse? Well, I don't remember. Suppose you were to divide out by that action.
01:24:02.284 - 01:24:42.962, Speaker A: So that's something that the siesta algebraics know how to do using cross products, and we'll come to that at some point. If you were to divide out by this action, then something rather interesting happens. If you divide out the positive reals by the action of the positive reals by point wise multiplication, the answer is no more positive reals. You just get the compact operators here. And if you divide out the cotangent bundle by the action of scalar multiplication in the fibers, then pretty much, but not exactly. What you're left with is the cosphere bundle. Not exactly, because the action also in this case has some fixed points.
01:24:42.962 - 01:25:57.212, Speaker A: The zero cotangent vectors don't get moved around. Let's just ignore those for now. Roughly speaking, when you divide out by the action, just continue this remark. You can expect to get something which looks like what I'm now going to write down, just the compact operators on l two of m for the ideal, then some sea star algebra in the middle. Let's just call it mystery Phi like that. And here the continuous functions on the cosmology, which is interesting because that's what we got when we were looking at order zero scalable operators, pseudo differential operators. So it looks like the, I mean, we already know that we can get all of the theory of scalable operators just by starting with the tangent groupoid and the scaling action.
01:25:57.212 - 01:26:36.146, Speaker A: But now it looks like we see again explicitly what the algebra of pseudo differential operators is going to be. Scalable order zero operators is going to be, without ever mentioning the definition of a scalable operator at all. So that makes it all of a sudden look rather interesting, makes it seem kind of worthwhile to study these sister algebras in a bit more detail. All right, I had a couple more things to say, but there's no more time to save them, so I won't say them. Thank you very much. Thank you Internet, both of.

00:00:00.160 - 00:00:06.674, Speaker A: Okay. The next speaker is Thomas Sinclair, and he's actually. What was the title?
00:00:08.054 - 00:00:09.150, Speaker B: Operator spaces.
00:00:09.262 - 00:00:09.814, Speaker A: Thank you, Chris.
00:00:09.854 - 00:00:10.502, Speaker C: Yes.
00:00:10.678 - 00:00:11.662, Speaker D: Any jacks?
00:00:11.798 - 00:00:12.374, Speaker B: Yeah.
00:00:12.494 - 00:00:13.434, Speaker E: There we go.
00:00:14.614 - 00:00:19.662, Speaker B: Right. So, thank you very much for the.
00:00:19.758 - 00:00:22.434, Speaker E: Opportunity to speak at this workshop.
00:00:26.594 - 00:00:39.402, Speaker B: Sorry about getting the abstract in super late. I wanted to do something with more connections with logic than this, and I have some things to say, but they.
00:00:39.418 - 00:00:41.058, Speaker E: Were not kind of quite ready.
00:00:41.146 - 00:00:56.270, Speaker B: So I'm going to give this talk that I've been giving for a little bit now. There's lots of interesting questions, I think, that are floating around, some of which.
00:00:56.422 - 00:00:59.754, Speaker E: Are probably more tractable than the quasi trace problem.
00:01:01.854 - 00:01:05.246, Speaker B: And some of which, well, at least one of which I think maybe isn't.
00:01:05.310 - 00:01:05.914, Speaker E: So.
00:01:07.614 - 00:01:08.990, Speaker B: Let'S get into it.
00:01:09.022 - 00:01:09.994, Speaker E: So, this is.
00:01:12.094 - 00:01:14.166, Speaker B: Joint work with Roy.
00:01:14.190 - 00:01:22.414, Speaker E: Ariza, who is a former PhD student of mine, and Colton Griffin.
00:01:23.994 - 00:01:33.354, Speaker B: So Colton was an undergraduate at Purdue, actually, and this transitioned from an undergraduate.
00:01:33.394 - 00:01:45.242, Speaker E: Research project that we had previously done. So I'll talk a little bit about that and then I'll kind of get into the heart of it.
00:01:45.378 - 00:01:51.916, Speaker B: So, yeah, there's some things that I need to define. Maybe just quickly, I'll just say what operator systems are.
00:01:51.980 - 00:02:01.452, Speaker E: So there. So let's just quickly talk about what operator systems are, in case you haven't seen this before.
00:02:01.508 - 00:02:06.944, Speaker B: So an operator system is just some.
00:02:07.644 - 00:02:11.624, Speaker E: Closed, self adjoint subspace of the bounded operators.
00:02:16.384 - 00:02:23.280, Speaker B: Which contains the unit. And that's still not enough information because.
00:02:23.352 - 00:02:24.456, Speaker E: Well, that's the space.
00:02:24.520 - 00:02:27.096, Speaker B: But then you have to define the category.
00:02:27.160 - 00:02:30.800, Speaker E: So you look at matrix amplifications over these.
00:02:30.832 - 00:02:37.808, Speaker B: So these are normed spaces just from the operator norm. So you can embed the matrices over.
00:02:37.856 - 00:02:44.460, Speaker E: This into the matrices over the bounded operators, which, again, the bounded operators on.
00:02:44.492 - 00:02:54.364, Speaker B: Some full direct sum, and there's a norm structure. So there's a multilevel spatial structure with a multilevel norm structure.
00:02:54.444 - 00:02:59.956, Speaker E: And if you have linear maps between.
00:03:00.140 - 00:03:10.268, Speaker B: Operator systems, the correct category here is. Well, okay, so there's a norm structure, there's a positivity structure.
00:03:10.316 - 00:03:21.404, Speaker E: So the positive, maybe I'll just say that first, because they're self adjoint and unital. The positive part.
00:03:25.944 - 00:03:45.818, Speaker B: Is spanning, so the positive cone is spanning, it's the complex span of the positive part is the operator system itself. So you have positivity at every level. And so the current category for linear maps are the completely bounded maps.
00:03:45.866 - 00:04:01.906, Speaker E: So the ones where if you take the matrix amplification, it's the correct thing to do here. Identity on MN tensor phi from Mne to MNF.
00:04:02.090 - 00:04:05.734, Speaker B: So the norms of these things are uniformly bounded.
00:04:10.274 - 00:04:11.894, Speaker E: That's the CB norm.
00:04:13.914 - 00:04:20.114, Speaker B: And because we really have star structure and unitality, really the positivity is important.
00:04:20.194 - 00:04:35.246, Speaker E: So completely positive maps. So, so positivity preserving at all levels.
00:04:35.350 - 00:04:35.994, Speaker C: So.
00:04:49.494 - 00:04:57.628, Speaker B: And there are lots of examples of interesting maps, even in for simple.
00:04:57.676 - 00:05:06.184, Speaker E: Cases that are not completely positive, but are positive. So for instance, just the transpose map.
00:05:08.244 - 00:05:13.508, Speaker B: From m two to m two preserves positivity preserves the positive semi definite cone.
00:05:13.556 - 00:05:18.184, Speaker E: But not completely positive, not even too positive.
00:05:20.644 - 00:05:23.588, Speaker B: And that's in quantum information theory.
00:05:23.636 - 00:05:33.024, Speaker E: That's EPR, basically Einstein, Podolsky and Rosen. So this is entanglement, more or less.
00:05:33.764 - 00:05:45.532, Speaker B: Okay, so that's the category that we're going to be working in. And what is the genesis of this?
00:05:45.588 - 00:05:48.316, Speaker E: So how did this start?
00:05:48.380 - 00:05:57.582, Speaker B: Well, maybe some, just very simple examples of operator systems. So if you have a graph, just.
00:05:57.718 - 00:05:58.674, Speaker E: A simple.
00:06:01.134 - 00:06:03.094, Speaker B: Graph, no multi edges, no.
00:06:03.134 - 00:06:09.846, Speaker E: Loops, something like this finite graph, you.
00:06:09.870 - 00:06:12.598, Speaker B: Can construct an operator system or you.
00:06:12.606 - 00:06:15.102, Speaker E: Can construct a couple of operator systems.
00:06:15.278 - 00:06:18.634, Speaker B: So this s g, this is in.
00:06:19.914 - 00:06:24.134, Speaker E: Mn, where n is the cardinality of the vertex set.
00:06:25.074 - 00:06:27.854, Speaker B: So these are just all of the matrices.
00:06:35.074 - 00:06:41.194, Speaker E: Which are supported on the graph. So they're zero if I is not.
00:06:41.234 - 00:06:43.450, Speaker B: Adjacent to j, meaning it's either I.
00:06:43.482 - 00:06:44.054, Speaker E: Is.
00:06:47.334 - 00:06:49.054, Speaker B: Not j or they're, they're not.
00:06:49.094 - 00:06:51.074, Speaker E: That's it doesn't form an edge.
00:06:54.974 - 00:06:56.910, Speaker B: And you can do the same thing.
00:06:56.942 - 00:07:05.194, Speaker E: With a slightly smaller subspace, this e sub g. It's the same thing.
00:07:11.754 - 00:07:16.374, Speaker B: But then we also want to stipulate that the diagonal entries are all.
00:07:18.274 - 00:07:19.734, Speaker E: Equal to each other.
00:07:20.794 - 00:07:38.494, Speaker B: So these are very simple looking operator systems. They're just subsystems of finite dimensional operator algebras. Yet, in all honesty, these things are.
00:07:38.574 - 00:07:44.718, Speaker E: Actually nearly as complex to study as just general operator systems.
00:07:44.766 - 00:07:48.630, Speaker B: And I'll try to motivate that remark.
00:07:48.822 - 00:07:50.034, Speaker E: Here in a second.
00:07:51.934 - 00:08:07.772, Speaker B: But there are these operator systems and then from these you can construct sort of dual ones. So dual positivity structures. And the positivity structures here are from.
00:08:07.948 - 00:08:17.148, Speaker E: Projecting, just taking the orthogonal projection down to the subspace, okay, there's a natural.
00:08:17.196 - 00:08:20.144, Speaker B: Inner product here given by the trace.
00:08:21.324 - 00:08:22.944, Speaker E: The Frobenius inner product.
00:08:23.324 - 00:08:25.824, Speaker B: So you take the positive cone.
00:08:37.464 - 00:08:37.776, Speaker C: Or.
00:08:37.800 - 00:08:38.784, Speaker B: I should have done it the other.
00:08:38.824 - 00:08:40.724, Speaker E: Way since I named them in that order.
00:08:43.544 - 00:08:53.240, Speaker B: So you just take, at every level, you just take the positive matrix cone and you just take the orthogonal projection down and you get a larger cone.
00:08:53.272 - 00:08:56.936, Speaker E: Structure on these things than the cone structure that's inherited.
00:08:57.000 - 00:08:59.696, Speaker B: And this is for these examples, this.
00:08:59.720 - 00:09:09.156, Speaker E: Is the quotient structure. And already you get sort of universal.
00:09:09.260 - 00:09:11.944, Speaker B: Free product behavior that comes out of.
00:09:13.284 - 00:09:22.184, Speaker E: Taking the quotient structure on these things. So there's already interesting complexity that's apparent.
00:09:22.724 - 00:09:25.344, Speaker B: But I think just a general.
00:09:28.864 - 00:09:29.320, Speaker C: Problem.
00:09:29.392 - 00:09:37.656, Speaker B: Here is, okay, these cones are actually different. And the difference between the cones in general is lack of injectivity.
00:09:37.840 - 00:09:49.272, Speaker E: So really coming up with nice ways of quantifying injectivity, and I'll just say in a sec that is.
00:09:49.328 - 00:09:52.424, Speaker B: But the operator system would be injective.
00:09:52.464 - 00:10:03.334, Speaker E: In this case if the, the projection, we have some subsystem of the matrices and we take the projection.
00:10:05.314 - 00:10:05.922, Speaker C: Just again.
00:10:05.978 - 00:10:07.934, Speaker E: With the frabinius inner product.
00:10:12.634 - 00:10:15.122, Speaker B: Which way do I want to do conjugate linearity today?
00:10:15.178 - 00:10:26.114, Speaker E: I guess I chose that one. So you just take the projection here, and the question is, is this completely positive?
00:10:29.614 - 00:10:30.514, Speaker C: Okay.
00:10:31.694 - 00:10:34.702, Speaker B: And in general, the answer is no.
00:10:34.758 - 00:10:53.644, Speaker E: There's very simple examples you can do just for this graph system, you know, corresponding to this very simple graph, just three vertices in a line. There it is.
00:10:55.704 - 00:10:59.280, Speaker B: So this can't be an injective subsystem.
00:10:59.312 - 00:11:01.992, Speaker E: Of m three, because if it was.
00:11:02.048 - 00:11:06.564, Speaker B: Injective and this projection was even too positive.
00:11:07.584 - 00:11:21.028, Speaker E: Choi efros tells you that there's a C star structure on this. So there's a C star structure, and you have these non unital but nonetheless.
00:11:21.076 - 00:11:39.852, Speaker B: Copies of m two in the upper left and lower right corners. So the C star structure on those two things is preserved. So you have two different copies of m two in this purported sea star algebra, but it's seven dimensional because there.
00:11:39.868 - 00:11:53.132, Speaker E: Are seven asterisks there, and that just cannot be, that doesn't work. So, you know, it's, there are, you.
00:11:53.148 - 00:12:09.944, Speaker B: Know, generically, these things are not injective. So quantifying how far these things are from being injective, defining, like good metrics, this again has some connections with logic, at least in my thoughts, because this.
00:12:09.984 - 00:12:12.016, Speaker E: Was like, okay, is there, what are.
00:12:12.040 - 00:12:15.952, Speaker B: Sort of definable analogs of injectivity for.
00:12:16.048 - 00:12:22.808, Speaker E: Operator systems or operator algebra? Is there some way of matrizing things.
00:12:22.856 - 00:12:29.524, Speaker B: In some way just, just quantifying, like taking finite dimensional things and making them.
00:12:32.124 - 00:12:38.184, Speaker E: Injectivity, sort of a metrically describable notion, like degrees of injectivity?
00:12:39.924 - 00:12:40.716, Speaker C: Sure.
00:12:40.900 - 00:12:51.116, Speaker A: Are you talking about hyperfiner? This one is finite dimensional things. I mean, injectivity has several equivalent formulations. So which one are you referring to?
00:12:51.220 - 00:12:56.436, Speaker B: Well, just injective in the category of CP maps, which just means that there.
00:12:56.460 - 00:13:05.544, Speaker E: Is a, a completely positive projection from the bounded operators onto your operator system.
00:13:05.704 - 00:13:06.444, Speaker C: Yeah.
00:13:06.864 - 00:13:09.924, Speaker A: So where would definability sit exactly.
00:13:10.304 - 00:13:27.864, Speaker B: Well, that's not a definable notion, but trying to come up with a degree of like how far are you from being injective, quantifying injectivity in some way and in a way that is kind of compatible with ultra products.
00:13:28.524 - 00:13:29.148, Speaker C: Right.
00:13:29.276 - 00:13:43.944, Speaker E: Would be something that. Yeah, yeah.
00:13:46.564 - 00:14:00.124, Speaker B: So I didn't mention that to the undergrads, but like you can kind of play around with these things at the matrix level and try to get ideas. And we did come up with some sort of way of coming up with a metric for how injective things are.
00:14:00.164 - 00:14:04.184, Speaker E: And that's all in a nice little paper that we wrote.
00:14:04.564 - 00:14:06.564, Speaker B: But I think it's a much broader.
00:14:06.604 - 00:14:07.624, Speaker E: Question and.
00:14:10.004 - 00:14:13.828, Speaker B: It'S not a very concrete question, and you just let your imagination run wild.
00:14:13.876 - 00:14:30.714, Speaker E: What does like almost injectivity mean to you? Let's see where it goes. Yeah, but so that was one genesis of this line of thought.
00:14:31.494 - 00:14:35.358, Speaker B: So back to the difficulty of understanding.
00:14:35.406 - 00:14:37.190, Speaker E: Even these matricial systems.
00:14:37.262 - 00:14:40.782, Speaker B: I mean, there's lots of room, actually, the point of this talk maybe is.
00:14:40.798 - 00:14:43.774, Speaker E: There'S lots of room down here at the bottom.
00:14:43.814 - 00:14:45.966, Speaker B: We don't have to think about infinite dimensional things.
00:14:46.030 - 00:14:52.834, Speaker E: Finite dimensional things pose all sorts of very hard problems.
00:14:52.874 - 00:14:59.250, Speaker B: So here's a favorite problem of mine at the moment, and this also, okay.
00:14:59.282 - 00:15:02.294, Speaker E: There'S some connections with logic here, but.
00:15:03.314 - 00:15:05.694, Speaker B: If we look at the complete graph.
00:15:06.554 - 00:15:09.414, Speaker E: On n vertices.
00:15:12.674 - 00:15:13.810, Speaker B: So we have, let's.
00:15:13.842 - 00:15:18.588, Speaker E: Just call enable of this complete graph.
00:15:18.676 - 00:15:33.344, Speaker B: So this is really all of the matrices whose diagonal entries are constant. So these are like the positive ones are like probabilistic correlations or something like this.
00:15:33.884 - 00:15:38.468, Speaker E: And you have this, this dual structure.
00:15:38.516 - 00:15:42.924, Speaker B: Where you quotient out basically by the diagonal matrices of trace zero.
00:15:43.044 - 00:15:57.248, Speaker E: So this is asymmorphic to mn modulo diagonal trace zero. So it's some sort of projective cone.
00:15:57.296 - 00:16:16.034, Speaker B: So if you think about the completely positive maps between these things. So maps from like the e's to other e's, or from the duals of the east, other duals of the ease, those are all very boring. You can, you can figure all of that out.
00:16:16.414 - 00:16:17.154, Speaker E: But.
00:16:20.454 - 00:16:31.470, Speaker B: Describing the completely positive maps here is extremely difficult. So for n greater than or equal.
00:16:31.502 - 00:16:56.374, Speaker E: To three, what is the complexity? So this is a problem complexity of this set. Classical model theory question maybe is this set semi algebraic? No clue.
00:16:58.914 - 00:17:08.606, Speaker B: That'S stronger than con embedding. So if it wasn't semi algebraic, that.
00:17:08.630 - 00:17:10.114, Speaker E: Would be stronger than con.
00:17:14.294 - 00:17:26.406, Speaker B: So you get into extremely deep questions about the nature of objects. Even for n equals three. I have no idea what the structure.
00:17:26.430 - 00:17:27.674, Speaker E: Of this set is.
00:17:30.124 - 00:17:34.104, Speaker D: Want some uniform definition across all values?
00:17:35.284 - 00:17:36.784, Speaker B: Well, I mean.
00:17:39.124 - 00:17:40.084, Speaker E: Are any of them.
00:17:40.124 - 00:17:46.452, Speaker B: Is n equals three even is interesting. If n equals three is not semi algebraic.
00:17:46.508 - 00:17:47.744, Speaker E: That's crazy.
00:17:48.724 - 00:17:50.464, Speaker B: That's a crazy strong thing.
00:17:52.644 - 00:17:53.384, Speaker E: So.
00:17:56.664 - 00:18:01.696, Speaker B: So, okay, maybe there's something that.
00:18:01.720 - 00:18:08.204, Speaker E: Can be done here with classical model theory.
00:18:09.624 - 00:18:12.448, Speaker B: Why am I not saying continuous model theory?
00:18:12.536 - 00:18:14.044, Speaker E: Why is that no help?
00:18:16.464 - 00:18:25.484, Speaker B: You can't really talk about semi algebraically because for in the. So you can do a model theory for ops systems.
00:18:25.894 - 00:18:27.598, Speaker E: I'm trying to just kind of cram.
00:18:27.646 - 00:18:46.814, Speaker B: In logic in any way I can in this talk. So it's going to be kind of random. So here, the quantifier free definable things.
00:18:46.894 - 00:18:47.514, Speaker E: Are.
00:18:50.094 - 00:18:53.554, Speaker B: Actually statements.
00:18:56.654 - 00:18:57.914, Speaker E: Of this form.
00:18:59.414 - 00:19:02.034, Speaker B: Maybe I'll just phrase it as a. Yeah.
00:19:02.694 - 00:19:12.594, Speaker E: These are positivity checks for expressions of the form.
00:19:18.474 - 00:19:23.298, Speaker B: In b of H min.
00:19:23.346 - 00:19:27.290, Speaker E: Tensor, your operator system.
00:19:27.402 - 00:19:41.134, Speaker B: So I guess evaluating it in an operator system. So you start off with the quantifier free things being matrices here. So the a one through an are bounded.
00:19:42.994 - 00:19:45.814, Speaker E: These are self adjoint bounded operators.
00:19:55.034 - 00:20:08.346, Speaker B: So you start off with the a's being matrices, and you can take limits, uniform limits, uniform limits of definable things are definable. And when you take the uniform limits, you get the min tensor.
00:20:08.530 - 00:20:12.066, Speaker E: So you have min tensor of b.
00:20:12.090 - 00:20:14.250, Speaker B: Of h sitting in there.
00:20:14.322 - 00:20:22.282, Speaker E: And that's too much stuff. You would just only like the linear.
00:20:22.338 - 00:20:25.578, Speaker B: Matrix inequalities, not the linear operator inequalities.
00:20:25.666 - 00:20:28.586, Speaker E: To be definable if you ever want.
00:20:28.610 - 00:20:34.490, Speaker B: To take a crack at something like this. So in that case, you really want.
00:20:34.522 - 00:20:36.690, Speaker E: The classical ultra production.
00:20:36.792 - 00:20:44.358, Speaker B: But then, okay, you have to work on operator systems over real closed fields, which seems like an interesting thing to do. I don't think anybody's done it.
00:20:44.406 - 00:20:55.074, Speaker E: So here's another problem. What can you say about op systems over real closed fields?
00:20:58.054 - 00:21:03.984, Speaker B: There's some interesting work of Andreas Tom and his collaborators about a, a year or so ago, where they.
00:21:05.684 - 00:21:09.332, Speaker E: Showed that the set of co positive matrices wasn't.
00:21:09.468 - 00:21:13.236, Speaker B: Definable with linear matrix inequalities using some.
00:21:13.260 - 00:21:18.064, Speaker E: Very basic classical model theory.
00:21:20.004 - 00:21:26.548, Speaker B: But then you get into real closed fields, you can't work over r. That's why we take the metric ultra product.
00:21:26.636 - 00:21:29.714, Speaker E: Usually, so we don't deal with this business.
00:21:32.734 - 00:21:35.014, Speaker D: When you asked about cine algebraic thinking.
00:21:35.054 - 00:21:38.514, Speaker C: Of understanding this over.
00:21:40.254 - 00:21:46.774, Speaker B: Well, that's. Yeah, I mean, the only. If I'm talking about a model theoretic approach, right?
00:21:46.814 - 00:21:47.078, Speaker E: Yeah.
00:21:47.126 - 00:21:49.854, Speaker B: You would want to understand what these.
00:21:49.894 - 00:21:55.670, Speaker E: Things look like as subspaces of products.
00:21:55.742 - 00:22:04.630, Speaker B: Of some real closed field, and then maybe you can find some exotic automorphism or something that moves it around which would show it would not be definable.
00:22:04.822 - 00:22:06.274, Speaker E: Or something like this.
00:22:07.534 - 00:22:09.030, Speaker B: But yeah, you need to access some.
00:22:09.062 - 00:22:12.774, Speaker E: Sort of broader, or actually, well, more.
00:22:12.854 - 00:22:15.062, Speaker B: Automorphisms, less definable things.
00:22:15.118 - 00:22:21.674, Speaker E: Too many things are definable in continuous logic. It's a blessing and a curse.
00:22:23.624 - 00:22:24.524, Speaker C: Okay.
00:22:26.864 - 00:22:28.560, Speaker B: I think I've gone way off the map.
00:22:28.592 - 00:22:38.404, Speaker E: Let's talk about index. Yeah, I'm not going to eat into anybody's lunchtime, don't worry.
00:22:39.624 - 00:22:42.944, Speaker B: So that's just some things that are.
00:22:43.064 - 00:22:45.624, Speaker E: Sort of ancillary or things that were.
00:22:45.664 - 00:22:49.876, Speaker B: Sort of in my mind, um, even though it may not be apparent from.
00:22:49.900 - 00:23:03.464, Speaker E: The rest of the talk that are kind of motivating some of these things. But, um, and maybe that's just a state of my, just a comment on. Okay, I lost half my screen.
00:23:06.164 - 00:23:08.464, Speaker C: Go away. That didn't work.
00:23:11.924 - 00:23:13.656, Speaker E: No, there we go.
00:23:13.760 - 00:23:14.312, Speaker C: Okay.
00:23:14.408 - 00:23:16.536, Speaker E: You just press enough things randomly.
00:23:16.600 - 00:23:17.324, Speaker C: Okay.
00:23:17.704 - 00:23:18.564, Speaker B: Um.
00:23:22.224 - 00:23:27.724, Speaker E: So hack, let's talk about index.
00:23:29.984 - 00:23:43.818, Speaker B: So this, this notion is, uh, is kind of a simple or naive definition, but it, it again leads to kind of interesting places. And so I'll try to explain it and then loop back to what I.
00:23:43.826 - 00:23:45.294, Speaker E: Was talking about before.
00:23:47.594 - 00:23:50.130, Speaker B: But we're going to just work with.
00:23:50.282 - 00:24:03.034, Speaker E: Finite dimensional operator systems mostly here because for technical reasons, that's what we can do.
00:24:03.194 - 00:24:05.762, Speaker B: So if we have some inclusion of.
00:24:05.938 - 00:24:30.542, Speaker E: Finite dimensional operator systems, we can define some sort of index between them as well. It's the infamum over all lambdas, so that there exists some CP map from.
00:24:30.598 - 00:24:33.270, Speaker B: The larger one into the smaller one.
00:24:33.462 - 00:24:38.754, Speaker E: Let'S say unital, since I unitall completely positive.
00:24:40.864 - 00:24:47.712, Speaker B: So that this map minus the identity.
00:24:47.768 - 00:24:54.644, Speaker E: Map, well, one over lambda times this identity map is just positive.
00:24:55.304 - 00:24:56.164, Speaker C: Okay.
00:24:59.544 - 00:25:02.644, Speaker B: So this is coming from the usual.
00:25:04.874 - 00:25:08.614, Speaker E: Or the, the work of Pimsner.
00:25:10.314 - 00:25:16.294, Speaker B: And Popa, who gave this interpretation of the drones index.
00:25:21.314 - 00:25:24.458, Speaker E: For an inclusion of sub factors.
00:25:24.586 - 00:25:27.334, Speaker C: And, okay.
00:25:29.194 - 00:25:33.140, Speaker B: With phi being just restricted.
00:25:33.172 - 00:25:37.144, Speaker E: To the conditional expectation two one sub factors, I should say.
00:25:39.204 - 00:25:44.572, Speaker B: And then of course there's, there's work of many other people with extending this notion to other sorts of inclusions of.
00:25:44.588 - 00:26:00.604, Speaker E: C star algebras or type iii factors or things like this. So this is not quite a nice enough notion. So there's a completely positive version of this.
00:26:01.784 - 00:26:11.864, Speaker B: So what it is is that you're trying to find sort of the flattest map or the least entropic map, the map that most accurately represents your bigger.
00:26:11.904 - 00:26:15.044, Speaker E: Operator system and your smaller subsystem.
00:26:15.784 - 00:26:24.012, Speaker B: That's the metric that this is trying to capture. The smaller the lambda can get, the more faithfully this thing is sitting or.
00:26:24.028 - 00:26:40.584, Speaker E: The flatter compared to the identity this, this map is. So it's the same thing, except here you want the correct category, which is completely positive instead of positive.
00:26:43.044 - 00:26:59.924, Speaker B: And in his CBMS lecture notes, popa shows that these two things for the conditional expectation are, are equivalent. For t one sub factor inclusions, for just inclusions of two, one von Neumann.
00:26:59.964 - 00:27:06.624, Speaker E: Algebras, there's a difference between them, but for sub factor inclusions, they're the same thing.
00:27:07.604 - 00:27:15.732, Speaker B: So that's the notion of the index that I want to discuss.
00:27:15.868 - 00:27:19.258, Speaker E: And, okay, you can make definitions like.
00:27:19.306 - 00:27:22.050, Speaker B: This, but then the question is, okay.
00:27:22.082 - 00:27:27.294, Speaker E: Can you actually do something with the definitions?
00:27:27.754 - 00:27:30.266, Speaker B: And the answer is, surprisingly, even in.
00:27:30.290 - 00:27:37.226, Speaker E: This generality, you can say some interesting things. Yeah.
00:27:37.330 - 00:27:44.614, Speaker D: So the expectation minus one over lambda times the identity. If that is positive, then it's automatically counted.
00:27:47.424 - 00:27:51.192, Speaker B: That's for, that's for sub factor inclusions.
00:27:51.248 - 00:27:55.240, Speaker E: Yes. It's not true for just two, one inclusions.
00:27:55.432 - 00:27:56.204, Speaker C: Yeah.
00:28:02.144 - 00:28:16.274, Speaker B: So one thing you can show is that. So here's, I guess, the main theorem that we showed.
00:28:16.814 - 00:28:17.794, Speaker C: Approved.
00:28:19.694 - 00:28:24.822, Speaker E: So if you have inclusions, so pairs.
00:28:24.838 - 00:28:27.166, Speaker B: Of inclusions, for a finite dimensional operator.
00:28:27.230 - 00:28:28.034, Speaker C: Systems.
00:28:32.334 - 00:29:00.862, Speaker E: Then under min tensor, you have multiplicativity. Okay, so this, this doesn't actually use.
00:29:00.918 - 00:29:17.716, Speaker B: A lot of operator algebras. This uses basically linear optimization, like a minimax theorem. So the sub multiplicativity is kind of given by the definition. And then you come up with a.
00:29:17.740 - 00:29:22.852, Speaker E: Dual linear optimization problem that captures the index.
00:29:22.908 - 00:29:25.104, Speaker B: And this is where you need finite dimensionality.
00:29:26.724 - 00:29:32.918, Speaker E: And you can prove the dual program is also almost by definition super multiplicative.
00:29:33.006 - 00:29:38.494, Speaker B: And then the fact that the dual program corresponds with the original one is.
00:29:38.534 - 00:29:41.554, Speaker E: The minimax theorem of von Neumann, basically.
00:29:44.014 - 00:29:55.462, Speaker B: So you get that it is honestly multiplicative. And, you know, just as a quick corollary of this, this completely positive index.
00:29:55.518 - 00:30:10.184, Speaker E: Is stable under matrix amplifications. So here's another problem.
00:30:12.044 - 00:30:16.172, Speaker B: So you can just take the index.
00:30:16.228 - 00:30:50.068, Speaker E: The positive index, and you can define some new index here just by taking the soup. It is a, this is going to be an increasing sequence of numbers, the, the soup of the positive indices of the matrix amplifications. So does this equal the completely positive index?
00:30:50.116 - 00:30:52.612, Speaker B: It sits below the completely positive index.
00:30:52.708 - 00:30:58.064, Speaker E: By the stability result. But.
00:31:01.764 - 00:31:06.188, Speaker B: Yeah, it could be that there's two notions of index here, or maybe.
00:31:06.236 - 00:31:09.904, Speaker E: An uncountable number of notions of index.
00:31:11.244 - 00:31:14.100, Speaker B: Maybe that's something I wanted to say.
00:31:14.252 - 00:31:16.500, Speaker E: As just a comment going back here.
00:31:16.692 - 00:31:28.532, Speaker B: Is that because the min tensor with b of h is defined here in the continuous model theory? Another problem is, is there some sort.
00:31:28.548 - 00:31:30.964, Speaker E: Of model theoretic approach to the fact.
00:31:31.004 - 00:31:32.844, Speaker B: That the min tensor of b of.
00:31:32.884 - 00:31:34.944, Speaker E: H with itself is.
00:31:35.404 - 00:31:41.060, Speaker B: Well, there's uncountably many operator algebra tensor.
00:31:41.092 - 00:31:52.194, Speaker E: Products on b of h tensor b of h. Is there just some model theoretical way to approach this that's a result of Ozawa and pza?
00:31:52.894 - 00:32:05.910, Speaker B: But, yeah, does this thing actually equal the completely positive index? The connection, again with logic is, well, if you somehow knew this thing was.
00:32:05.942 - 00:32:14.604, Speaker E: Definable, you would win. But that's, yeah, that's a tall order.
00:32:15.944 - 00:32:18.084, Speaker B: Something more concrete at the.
00:32:20.864 - 00:32:21.648, Speaker E: Just the.
00:32:21.736 - 00:32:23.376, Speaker B: Maybe even the sort of the sea.
00:32:23.400 - 00:32:26.044, Speaker E: Star algebra level, is this thing just.
00:32:26.944 - 00:32:29.880, Speaker B: The positive index when you stabilize by.
00:32:29.912 - 00:32:39.044, Speaker E: Tensoring with the car algebra, that's also equivalent, basically. Okay.
00:32:42.784 - 00:32:49.832, Speaker B: So some sort of stabilization or ultra product continuity result or something like.
00:32:49.888 - 00:32:54.044, Speaker E: This is pretty much equivalent to this question.
00:32:54.984 - 00:33:00.608, Speaker B: But maybe it's also model theoretically possible to maybe just go the other way.
00:33:00.656 - 00:33:03.264, Speaker E: Since operator systems are very chaotic.
00:33:03.304 - 00:33:08.314, Speaker B: Maybe you can just write down some properties, some general properties that the index.
00:33:08.354 - 00:33:25.134, Speaker E: Should satisfy, and maybe there's just uncountably many different indices. I don't know, seems like it's a hard question. It's probably not definable. So there's probably lots of them, but I don't know how to get a handle on this.
00:33:30.254 - 00:33:47.086, Speaker B: Okay, so probably, when you define something new, you should probably explain why it's not trivial. Why isn't this just like the co dimension or something like this? That would be brilliant if we just.
00:33:47.190 - 00:34:06.874, Speaker E: Rediscovered co dimension or something. That's not the case. So maybe I'll say a little bit about that, just to, to keep everybody assured. So how do you connect this with other things?
00:34:08.054 - 00:34:09.566, Speaker B: So one thing you can do is.
00:34:09.590 - 00:34:23.694, Speaker E: You can define basically this dimensional invariant for a finite dimensional operator system, just as the completely positive index of the unit basically in there.
00:34:24.874 - 00:34:33.346, Speaker B: And this is multiplicative under minimal tensor. So it is some sort of nice.
00:34:33.530 - 00:34:41.454, Speaker E: Non commutative dimensional parameter. In just the.
00:34:43.714 - 00:34:50.053, Speaker B: Case of matrices, it gives you n, which, that's the correct.
00:34:50.093 - 00:34:55.633, Speaker E: Dimension of a matrix algebra if you're a non commutative analyst. Right.
00:34:56.453 - 00:34:57.433, Speaker B: So, great.
00:34:58.773 - 00:35:09.485, Speaker E: And this actually ends up being the same for the diagonal subalgebra, the masa in there.
00:35:09.549 - 00:35:18.334, Speaker A: Can you just give an example of how computations work? It would be somewhat illuminating, I guess, to just see how this, why is this so.
00:35:19.954 - 00:35:20.734, Speaker E: Yeah.
00:35:26.874 - 00:35:28.254, Speaker A: It'S not published.
00:35:29.034 - 00:35:37.626, Speaker B: Yeah. So the idea here is that if you do have this completely positive map, and this is maybe a good segue.
00:35:37.690 - 00:35:40.242, Speaker E: But if you do have the CP.
00:35:40.298 - 00:35:44.174, Speaker B: Map, you can always average it over the unitaries.
00:35:47.674 - 00:35:48.574, Speaker E: Okay?
00:35:49.114 - 00:35:56.378, Speaker B: And you can take convex combinations and you only improve this constant lambda by taking, well, it stays the same under.
00:35:56.426 - 00:36:02.214, Speaker E: Unitaries and it only improves under taking convex combinations, okay?
00:36:02.594 - 00:36:12.862, Speaker B: So once you pick like a fixed point for this, you're good. And the, the only fixed point when you average over all the unitaries for.
00:36:12.878 - 00:36:14.594, Speaker E: The matrices is the trace.
00:36:15.854 - 00:36:25.114, Speaker B: And so you think about what is the gap between the average and the max? And it's like one over n.
00:36:27.454 - 00:36:27.830, Speaker C: That's.
00:36:27.862 - 00:36:31.094, Speaker E: Really the computation in this. Yeah.
00:36:31.254 - 00:36:34.394, Speaker B: And actually that leads to another problem.
00:36:35.934 - 00:36:40.054, Speaker E: Which is, well, for an inclusion of sub factors.
00:36:47.994 - 00:36:49.842, Speaker B: Do you, does this thing.
00:36:49.898 - 00:36:58.374, Speaker E: Actually equal the Jones index? It's bigger.
00:36:59.274 - 00:37:01.858, Speaker B: So the question here really does actually.
00:37:01.946 - 00:37:05.028, Speaker E: Boil down again to, is there some.
00:37:05.076 - 00:37:10.996, Speaker B: Sort of fixed point theorem for completely positive or just normal?
00:37:11.100 - 00:37:14.108, Speaker E: If you want completely positive maps from.
00:37:14.156 - 00:37:33.492, Speaker B: Mn to n, if you have a fixed point, then that fixed point, when you restrict it to n, preserves commutativity. And that means it's just a linear combination of the trace and the identity, and then you can figure it out from there. So it is just trying to prove some sort of fixed point theorem for.
00:37:33.548 - 00:37:36.148, Speaker E: Unitary averages over the unitary group of.
00:37:36.196 - 00:37:43.268, Speaker B: N. The conditional expectation absolutely has to be like the most n, you know.
00:37:43.356 - 00:37:50.252, Speaker E: Or most, or least least entropic, completely.
00:37:50.308 - 00:37:53.596, Speaker B: Positive map from mn to n. So.
00:37:53.620 - 00:37:58.028, Speaker E: That'S, that's basically the conjecture or the problem. Yeah.
00:37:58.116 - 00:38:02.258, Speaker D: So the tensor product formula that you had, it's only for finite division.
00:38:02.396 - 00:38:14.314, Speaker B: Yeah, only for finite dimensional. Again, if you, if you had some definability or continuity properties under ultra products or things like that, you could just bootstrap it up.
00:38:16.614 - 00:38:20.310, Speaker E: But because every operator system just is.
00:38:20.382 - 00:38:22.822, Speaker B: An ultra product inside an ultra product.
00:38:22.878 - 00:38:29.880, Speaker E: Of matrix algebras, but don't know how to do that.
00:38:29.952 - 00:38:37.440, Speaker B: So maybe an idea here is you look at, and this is maybe just an interesting quantity, but you look at.
00:38:37.472 - 00:38:42.200, Speaker E: Some sort of, you know, Pimsner popa.
00:38:42.232 - 00:38:53.064, Speaker B: Basis, basically a basis for m as an n module. Maybe you want these things to be.
00:38:53.104 - 00:38:59.620, Speaker E: Positive and add up to one. And maybe you want to define some.
00:38:59.652 - 00:39:01.624, Speaker B: Sort of entropic thing like.
00:39:07.204 - 00:39:11.584, Speaker E: Sum over I log of trace of x.
00:39:13.444 - 00:39:13.924, Speaker C: Or.
00:39:14.004 - 00:39:16.068, Speaker B: Just trace of xi and then log.
00:39:16.116 - 00:39:26.964, Speaker E: Of trace of, well, Phi Xi Xi, something like this.
00:39:27.944 - 00:39:35.592, Speaker B: The fact that there's a lambda bound, you know, there's this lambda value multiple of the identity bounding this below from zero.
00:39:35.648 - 00:39:38.032, Speaker E: So this gives you a well defined.
00:39:38.088 - 00:39:40.200, Speaker B: Quantity and if there's some sort of.
00:39:40.232 - 00:39:42.284, Speaker E: Uniform convexity of this.
00:39:45.984 - 00:39:48.112, Speaker B: Entropy function over.
00:39:48.168 - 00:39:54.796, Speaker E: All Pimsner popa bases, something like this, that's probably enough to guarantee that you.
00:39:54.820 - 00:40:00.340, Speaker B: Have a fixed point, I think probably from the interest of maybe quantum information theory.
00:40:00.412 - 00:40:02.024, Speaker E: There's some interesting.
00:40:05.844 - 00:40:07.740, Speaker B: Thing going on here.
00:40:07.772 - 00:40:13.068, Speaker E: If it was like uniformly bounded in some sense, but. Okay, yes.
00:40:13.116 - 00:40:16.624, Speaker D: What if you had some snap basis of Unitarian.
00:40:16.964 - 00:40:20.024, Speaker B: Well, that's why I wanted positive ones.
00:40:20.364 - 00:40:23.268, Speaker E: So the positive ones that add up to one.
00:40:23.316 - 00:40:25.084, Speaker B: So this is a defined quantity over.
00:40:25.124 - 00:40:30.268, Speaker C: Those do something like that. Okay. Don't.
00:40:30.356 - 00:40:33.228, Speaker E: Yeah, I suppose you could just do it over.
00:40:33.276 - 00:40:42.516, Speaker B: Well, yeah, there's probably an analog for doing this, but. Well, no, you really want to define this entropy. So you want some sort of like povm or something like that.
00:40:42.540 - 00:40:44.268, Speaker E: These could just be, you know.
00:40:44.396 - 00:40:48.276, Speaker C: Yeah. So, I mean, one, one of the.
00:40:48.300 - 00:40:57.516, Speaker D: Things is that matrix algebraic indexes is n. Yeah. So it seems to me that I would be surprised if this problem has.
00:40:57.540 - 00:41:00.516, Speaker C: A positive answer, because you can take.
00:41:00.580 - 00:41:04.012, Speaker D: The hyperfinite drone factor tensor with the matrix algebra.
00:41:04.148 - 00:41:04.904, Speaker E: Yeah.
00:41:05.204 - 00:41:20.094, Speaker D: And take the hyperfinite drone factor tensor with the identity. If that index is, if that CP index is equal to n squared, something goes wrong with.
00:41:20.754 - 00:41:24.554, Speaker B: But I think in this simple case, it's just, you just get back and it's fine.
00:41:24.594 - 00:41:31.294, Speaker E: I mean, stabilizing is okay in this case, so. But.
00:41:35.234 - 00:41:40.762, Speaker B: Yeah, I mean, for simple inclusions, like group inclusions or just tensor inclusions.
00:41:40.938 - 00:41:47.042, Speaker E: It does check out. So, like group subgroup sub factors or.
00:41:47.058 - 00:41:49.730, Speaker B: Fixed point sub factors, that all is fine.
00:41:49.762 - 00:41:56.454, Speaker E: There's no problem. I just don't know what to do in general. Okay.
00:41:58.314 - 00:42:01.122, Speaker B: So yeah, you have the usual.
00:42:01.178 - 00:42:04.654, Speaker E: The answers you would expect just for these simple things.
00:42:06.074 - 00:42:13.490, Speaker B: The really interesting result is that when.
00:42:13.522 - 00:42:19.690, Speaker E: You look at for a graph, again, just a simple graph, if you look.
00:42:19.722 - 00:42:20.454, Speaker B: At the.
00:42:22.194 - 00:42:23.906, Speaker E: This dimensional function.
00:42:23.970 - 00:42:32.922, Speaker B: So the completely positive index of the identity in this e system for the graph, this is an already known quantity.
00:42:32.978 - 00:42:43.194, Speaker E: This is the Lovos theta number of the complement graph. So you switch adjacency to nonadjacency and vice versa.
00:42:45.974 - 00:42:50.542, Speaker B: So this is a well defined, this.
00:42:50.558 - 00:42:53.302, Speaker E: Is a well studied object.
00:42:53.358 - 00:42:54.486, Speaker B: In combinatorics.
00:42:54.550 - 00:42:59.046, Speaker E: It's useful in the sense that the.
00:42:59.070 - 00:43:01.326, Speaker B: Theta of the complement is between the.
00:43:01.350 - 00:43:10.094, Speaker E: Chromatic number on top and the clique number of the graph on the bottom. And both of these things are np hard.
00:43:11.034 - 00:43:12.254, Speaker B: And this is.
00:43:14.274 - 00:43:16.746, Speaker E: Semi definite programmable.
00:43:16.810 - 00:43:18.694, Speaker B: So up to epsilon, it's.
00:43:22.554 - 00:43:24.854, Speaker E: Polynomial in epsilon error.
00:43:26.194 - 00:43:30.014, Speaker B: So it's a remarkable thing.
00:43:32.204 - 00:43:32.740, Speaker C: That this.
00:43:32.772 - 00:43:34.224, Speaker E: Just kind of pops out.
00:43:35.604 - 00:43:46.988, Speaker B: In this case, it doesn't do it for. So this is where the diagonal entries are all equal. If you look at the s of g where you don't allow the entries.
00:43:47.036 - 00:43:49.100, Speaker E: On the diagonal to be equal, then.
00:43:49.132 - 00:43:51.916, Speaker B: You have the diagonal matrices in there.
00:43:51.940 - 00:43:52.504, Speaker E: And.
00:43:55.084 - 00:43:56.344, Speaker B: You just get the.
00:43:58.414 - 00:44:00.334, Speaker E: Cardinality of the vertex set.
00:44:00.494 - 00:44:01.194, Speaker C: So.
00:44:03.414 - 00:44:09.198, Speaker B: But yeah, this shows it's a non trivial invariant. This can take all sorts of irrational.
00:44:09.326 - 00:44:11.194, Speaker E: Answers and so on.
00:44:12.534 - 00:44:17.614, Speaker B: So it does compute something interesting, even.
00:44:17.654 - 00:44:22.382, Speaker E: For these, these simple graph type systems.
00:44:22.558 - 00:44:27.726, Speaker B: And in fact, there's already some sort.
00:44:27.750 - 00:44:33.646, Speaker E: Of, for quantum graphs, there's already, which are just subsystems of the matrices.
00:44:33.790 - 00:44:36.794, Speaker B: There's already some quantum lovos theta.
00:44:40.814 - 00:44:49.286, Speaker E: That was defined by duan, Severini, winter in.
00:44:49.310 - 00:45:07.674, Speaker B: Terms of complexity of communication for quantum channels. But the problem here is for general operator systems, for graph systems, these things, there's an agreement, there's a dictionary between these two.
00:45:09.574 - 00:45:14.446, Speaker E: But for general subsystems of the matrices.
00:45:14.550 - 00:45:19.806, Speaker B: This is only defined for subsystems of the matrices. I'll just say what it is.
00:45:19.990 - 00:45:36.854, Speaker E: It ends up actually being the CP index of this system inside of the matrices. So it's the flip. These two things end up being equal to each other. But.
00:45:41.714 - 00:45:52.688, Speaker B: I don't know if there's any correspondence between this quantum lovos theta and this, this dimensionality parameter.
00:45:52.736 - 00:46:06.684, Speaker E: For a general operator system where the complement is like the operator system version of the graph complement, you just take the orthogonal complement of your system and then you add back in the units.
00:46:10.304 - 00:46:29.820, Speaker B: So it could be the case that there's actually like a pair of different notions of dimension, or quantum dimension or index, or even matricial systems. That could very well be the case. These two things, I don't see why.
00:46:29.852 - 00:46:31.572, Speaker E: They would agree, but I don't have.
00:46:31.588 - 00:46:35.036, Speaker B: An example where they disagree either. It may be quite simple to come.
00:46:35.060 - 00:46:42.770, Speaker E: Up with an example, but I tried a little bit and it's, well, I feel like it's a little bit subtle.
00:46:42.932 - 00:46:43.634, Speaker C: So.
00:46:46.734 - 00:46:57.894, Speaker B: But yeah, so I don't, this, there might be multiple notions and they satisfy the same formal property, so they're even at the matrix level.
00:46:57.934 - 00:47:02.954, Speaker E: There might be sort of multiple notions floating around. I don't know.
00:47:06.174 - 00:47:11.702, Speaker B: Maybe just the last thing I'll say is just another computation.
00:47:11.758 - 00:47:13.234, Speaker E: That you can do here.
00:47:13.814 - 00:47:23.126, Speaker B: So there's a lot of similarities actually between graphs and generating operator systems for discrete groups.
00:47:23.190 - 00:47:28.654, Speaker E: So let's, instead of g, let gamma be a countable discrete group.
00:47:28.814 - 00:47:30.674, Speaker B: Let's just say finitely generated.
00:47:36.314 - 00:47:37.574, Speaker E: Discrete group.
00:47:42.834 - 00:47:45.614, Speaker B: And you take some finite generating set.
00:47:46.154 - 00:47:52.294, Speaker E: Which is equal to the inverse and contains the identity.
00:47:53.354 - 00:47:56.454, Speaker B: So you can look at this operator system.
00:47:58.514 - 00:48:01.614, Speaker E: Inside of the reduced C star algebra.
00:48:04.094 - 00:48:04.838, Speaker B: Of the group.
00:48:04.886 - 00:48:12.542, Speaker E: It's a perfectly good finite dimensional operator system, and you can compute what this thing is.
00:48:12.598 - 00:48:16.958, Speaker B: And actually it parallels in a remarkable.
00:48:17.006 - 00:48:17.594, Speaker E: Way.
00:48:19.454 - 00:48:21.982, Speaker B: What happens in the graph case.
00:48:22.118 - 00:48:40.644, Speaker E: So the answer here for this dimensional number is, it's the, it's again the minimal lambda. So that this map phi lambda just.
00:48:40.684 - 00:48:46.944, Speaker B: Defined on the identity to be one minus one over lambda. And then.
00:48:50.124 - 00:48:55.254, Speaker E: Or I should really say infinite. So I guess it's a min.
00:48:59.114 - 00:48:59.426, Speaker C: And.
00:48:59.450 - 00:49:04.898, Speaker E: That'S minus one over lambda for every.
00:49:04.946 - 00:49:07.762, Speaker B: Non identity element of the generating set.
00:49:07.938 - 00:49:16.934, Speaker E: That this is, this extends to a positive semi definite function on the group.
00:49:23.134 - 00:49:35.126, Speaker B: And so this is, this is ends up being there's like, you know, there's, there's many, many definitions of low loss theta. It's one of these things where you try to come up with a reasonable.
00:49:35.190 - 00:49:38.502, Speaker E: Graph parameter that uses like positivity and.
00:49:38.518 - 00:49:43.994, Speaker B: It just all goes to the same place. So there's, there's another.
00:49:45.754 - 00:50:01.534, Speaker E: Definition of the Lovos data for a graph that this like precisely copies in this, in this kind of, this generator subsystem for the reduced C star algebra.
00:50:02.394 - 00:50:27.664, Speaker B: And basically the reason is, is that in both the matrix case and the group case, you have some sort of co multiplication. The map that you're looking at in the matrix level is not really a co multiplication, but there's a complete order isomorphism of a canonical one from the.
00:50:28.364 - 00:50:32.020, Speaker E: Matrices into the matrices tensor themselves that.
00:50:32.052 - 00:50:37.244, Speaker B: Is maximally entangled in some sense. And the co multiplication on the group.
00:50:37.284 - 00:50:46.324, Speaker E: Is also some maximally entangled complete order embedding from the group into the tensor of the group with itself.
00:50:48.224 - 00:50:54.776, Speaker B: So there's some very interesting parallels that.
00:50:54.800 - 00:51:01.152, Speaker E: Are going on, and it's something I've been thinking about.
00:51:01.208 - 00:51:21.344, Speaker B: I think there are interesting things to say, but I won't say them now. I don't want to cut into anybody's lunch time. So I think I said basically what I wanted to say. So I'll just stop here and thank everybody for listening.

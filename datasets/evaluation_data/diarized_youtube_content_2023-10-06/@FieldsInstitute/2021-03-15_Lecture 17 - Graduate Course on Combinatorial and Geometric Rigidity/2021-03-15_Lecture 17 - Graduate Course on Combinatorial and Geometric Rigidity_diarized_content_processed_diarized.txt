00:00:00.080 - 00:01:34.234, Speaker A: We'd introduced linearly constrained frameworks which if you remember, are frameworks where, as well as having the usual distance constraints between points, say if we just think about two dimensional space, then some vertices may have additional constraints that restrict them to move on some affine subspace. So a line, or even if there was, maybe there was two of these constraints and then there were a pinned vertex. So in this context we're going to try and understand some rigidity and global rigidity properties. So the first one is the two dimensional characterization of rigidity, which is due to Strano and Ferran. And I told you this at the end of Friday's lecture, but I'm just going to repeat to make sure it's fresh in your head. So remember, our linearly constrained frameworks have a graph, a map assigning positions to the vertices and a map assigning normal vectors to the vertex containing any loop, okay? And the linearly constrained framework is generic if the entire set PQ is algebraically independent over the rationals, okay? And such a framework in two dimensions is minimally rigid if and only if a nice combinatorial condition. So if you imagine you have a framework in 2d, then if there's no linear constraints, then of course you can translate in two independent ways and you can rotate, and that's the minus three you see in the sort of laman condition.
00:01:34.234 - 00:02:24.710, Speaker A: And so this is a sort of standard condition from the polycheck Gerangeal Laman theorem for all subgraphs with no loops. But if you allow loops, then say you had one loop there and another loop there. So two loops at this one vertex, you can easily see that's forced this vertex to a specific location, and hence it's ruled out both the translations. So the only thing left is the rotation. And then if you put a loop on this vertex, so another linear constraint, then you'd rule out the rotation as well. So we can get rid of all of the isometries and have our rigidity condition is that the only infinitesimal motion is the zero motion. So in other words we have, we're in two dimensions, so it's two mod v for our count, but there's no minus anything, it's minus zero if you like, because all of the isometries can be ruled out.
00:02:24.710 - 00:03:07.656, Speaker A: There's no vectors that have to live in the kernel for any framework. So if we add up our edges and loops, we'll get twice the number of vertices for our minimally rigid framework. And we need a corresponding inequality for all subgraphs, whether they have edges or loops or not. But also, as I said, we are going to have this stronger inequality when you have no loops. And as I explained last time, the point is here, if we didn't have such a condition, then things like k four, which we know are dependent, would be okay, because they satisfy this inequality. So you could imagine you could have k four plus two loops, but this will be a. It's not minimal and it's not rigid, even in the linearly constrained context.
00:03:07.656 - 00:03:25.356, Speaker A: The two loops will rule out two of the free isometries, but not all three of them. Okay, so hopefully everyone understands the statement. I don't have that much to cover today, so do feel free to interrupt with questions even more than usual. Okay.
00:03:25.460 - 00:03:26.224, Speaker B: Tony.
00:03:27.124 - 00:03:34.084, Speaker A: Oh, my volume. Sorry, sorry. If anyone was asking a question, my volume was down. But I think Alex is trying now, so I'm okay.
00:03:34.244 - 00:03:41.874, Speaker B: Oh, yeah. Okay. I was just going to say, I mean, is the proof as simple as you just described? Basically, the minus three becomes the minus zero.
00:03:43.334 - 00:04:26.064, Speaker A: No. So what is as simple as I just described is if there is a spanning minimally rigid bar joint framework, so say something like this inside it, then it is generically as simple as if you have free loops in addition, you will become rigid. But we can have things that are flexible as a bar joint framework, but have more loops. And so, dealing with all these cases at the same time, it's not quite as simple as just adding the right number of loops. You have to know that you can add. You can imagine you had a cycle on a million vertices, and you've got to add many, many, many loops and check they're all independent. So it's not quite as easy as you said, but it's.
00:04:26.064 - 00:04:31.464, Speaker A: I mean, it's a genuine extension of the Polachek Geringer theorem.
00:04:33.384 - 00:04:34.564, Speaker B: Okay, thanks.
00:04:35.944 - 00:04:54.016, Speaker A: Yes. So, but you are right that the special case where the bar joint thing is minimally rigid. We are. It is just follows for free that that part of the theorem is. Does just follow from the, from adding the free loops to rule out the free isometries. Okay, so let's do the proof, I guess. I want to do a.
00:04:54.016 - 00:05:21.700, Speaker A: Maybe not the standard proof, because I'm not going to present the proof that. That Strenu and Ferran did. They did. They used frame matroids, and it's sort of a matriarch union kind of proof, but I haven't been giving that kind of proof in this course. So I want to give what I think of as a simpler proof from a recent paper with Jim Cruickshank. Hakangula and Bill Jackson. And it's simpler for the purposes of this course because it uses techniques we're familiar with in this course.
00:05:21.700 - 00:06:01.102, Speaker A: It uses recursive constructions, it uses the zero and one extensions, and it uses combinatorial reductions as well. Okay, so I will leave the easier direction that the, that if you're minimally rigid, then the counting conditions hold as an exercise, and I'll prove the sufficiency to you. I think I haven't actually written that many words for the sufficiency, so I might have to draw some pictures as we go. So suppose we have a graph with a vertex edge set and loop set. I said this last time, but maybe I haven't emphasized it this time. I'm deliberately keeping the loops separate from the edges. So e is just non loop edges, no multiple edges, just a nice simple, simple edges.
00:06:01.102 - 00:06:46.050, Speaker A: And l is the set of loops. So my looped graph has total count and the number of edges and loops. An inequality for all subgraphs and an inequality for loopless subgraphs, as usual, with at least one edge or at least two vertices, whichever you prefer to say. Okay, so what's the, the minimum degree in such a graph? Well, the number of edges plus loops is equal to 2 volts, so the average degree is exactly four. But we don't have to deal with a sort of degree four kind of move. We're still going to use degree two and three kind of moves because we're going to move from thinking of degree to thinking of the number of incident edges. Why? Because a loop adds two to the degree one for each edge, at least if you want handshaking, Lemmer and things to work.
00:06:46.050 - 00:07:49.590, Speaker A: But what we really care about in our rigidity kind of graph moves is the number of edges that you throw away or the number of edges you add in in one of these operations. So, for example, if you look at these two pictures here, this is degree two, this is degree three, but they're both really the same operation. I take some graph that maybe includes u or u and v, and I add a new vertex x and one two incident edges in either way. And so this is kind of a zero extension regardless of what the actual degree is. So we're going to move to thinking about the number of edges, incidentally edges and loops incident to a given vertex, okay? And so because of the two in these positions, the minimum degree will be at least two. And while the average degree is four, the number of incident edges to any vertex is strictly less. There exists a vertex with at most two or three incident edges or loops to it.
00:07:49.590 - 00:08:20.064, Speaker A: So some of those could be degree higher than four. Even so, this has got 1234 degree five, but it only had three incident edges. And so our options are the ones you see in, in this row. We could have a standard vertex of degree two or three. We could have a slightly stranger vertex of degree three. We could have a vertex of degree four or five, or even just a single vertex incident to two loops itself. But that would be in a separate connected component, the graph of wise, it would have higher degree.
00:08:20.064 - 00:09:12.314, Speaker A: So I guess this is something I haven't really mentioned, is that in one of these linearly constrained frameworks you don't have because there's no isometries after we. For example, if you go back to this picture, we ruled out all of the isometries, so there's no reason why connectivity is necessary for rigidity anymore. So this, this in blue, that framework was, was this graph and that's rigid. Another example of a rigid graph is a single vertex with two loops, because that just says the two linear constraints in the plane intersect in a fixed point. So now this entire graph here is rigid. This is locked in place in any generic realization, and so is the triangle. So even though it's not a connected graph, I can't do what I can do in bar joint world, which is fix one and just translate the other and get a trivial infinitesimal motion that shows it's not rigid.
00:09:12.314 - 00:09:37.556, Speaker A: So I can be rigid without being connected in linearly constrained frameworks. So for example, this kind of picture. Okay, so back to our degree things. These are all the options if you just think it through for yourself. You need to have either two or three incident edges or loops. And you go through these various options. In the case where you have two incident edges and loops.
00:09:37.556 - 00:10:13.184, Speaker A: So that's this one and this one then, exactly as I was saying before, this is a zero extension, zero reduction kind of argument. So we remove x and we get a smaller graph that, because we removed the vertex with two incident edges or edges and loops, we're still in the same combinatorial class, we still satisfy our conditions. It's not so hard to see. We've reduced v by one. So this side goes down by two. We remove either two from here or one from here and one from here. And similarly to the, the inequalities all work out.
00:10:13.184 - 00:10:47.284, Speaker A: Okay? And then from that we can say, well, the smaller graph is rigid by induction on the number of vertices. And then we use a zero extension argument. Okay, it's very slightly different when it's this kind of zero extension. But the same proof we talked about when we did the polycheck Geringer Leman theorem works in this case too. So we can suppose there are exactly free incident edges. So that's this picture, or this picture, or this one. And what we can do.
00:10:47.284 - 00:11:11.364, Speaker A: So let's first of all talk about this is the usual one. So we've seen this one before. So we're going to delete this vertex and we're going to add one of the three edges. This is just a standard one reduction. We're in the class of graphs where we already thought about this problem before we introduce linear constraints. So we just use the same ideas. I won't go through it now, but if you look back at that.
00:11:11.364 - 00:11:47.012, Speaker A: So just do this. Basically the same argument, and you also have to check that this inequality is satisfied. But I'm just going to say it's not so hard to check that either. And so we can find a one reduction at any such vertex like this one, to a smaller graph that satisfies the conditions. Check. Both inequalities must be true for at least one of the three possible reductions. And then again by induction, we have a smaller graph in the class, so we know the smaller graph is rigid.
00:11:47.012 - 00:12:19.094, Speaker A: And hence we can use the one extension preserves rigidity to see that the bigger graph is rigid. Okay, so looking out at our options, we've now dealt with these ones and with this one. So we're left with the case where our vertex with free incident edges is incident to a loop. It's either incident to one loop or to two loops. Okay? And if it's one loop, it's two simple edges. If it's two loops, it's one simple edge. Okay, so this one, let me say it in a bit more detail.
00:12:19.094 - 00:12:51.818, Speaker A: So we have one of these pictures. We have a vertex, I've changed the letters, sorry, from what I had five minutes ago. So I have a vertex V with three incident edges. It's either two edges in a loop or two loops in an edge. And what I want to do is delete V and it's free incident edges and loops and add a loop at a neighbor. So if it's only got one simple edge, my only option is to add a loop at x. If it's got two, I've got two options.
00:12:51.818 - 00:13:43.142, Speaker A: I could either do this one, or I could have added a loop y instead and call this a looped one reduction. And the inverse operation where you start down here and you delete a loop and add a new vertex with either one or two simple edges to the end of the vertex you remove the loop from, plus possibly one other, and then one or two loops, depending on which one you're in, will be called a looped one extension. Okay? So this looped one reduction adds a loop. So if we go back to our combinatorial condition, this inequality only cared about number of edges, so can never fail. When we add a loop, we can never, we don't add anything to the left hand side here. So this inequality can never be violated. So the only problem can be is if we violate this inequality, so we add one, one loop here.
00:13:43.142 - 00:14:51.954, Speaker A: And if that causes a problem in some subgraphs, okay, so that's what I say here. It's easy to check that the result of a looped one reduction is not sparse if and only if that condition fails, which means there's some subset x of v without the vertex we're getting rid of such that the number of edges and loops induced by that subset is equal to two x. So when we add the loop here or here, we get one extra and we violate the inequality. Okay, if v was incident to two loops, then I claim such a set cannot exist. So what happens here? So we'd have an x in v minus v, so it would have to contain x, and we're going to add a loop to it. But before we do, we know I of x is equal to twice x. So if we just look at in the big graph, including this, when we add v and its three incident edges or loops, we would find that x union v, the number of edges induced there is two x.
00:14:51.954 - 00:15:20.758, Speaker A: Sorry, I don't quite have enough space. Let me just move that across is two x union v plus one, because we added one vertex, but we added one, two, three edges. So we added needed to go to this. And this violates the inequality we have. So this set x like this can never have existed. Which means if we have a vertex like this, vertex v here, we can always do this reduction. And we're happy.
00:15:20.758 - 00:16:02.694, Speaker A: That reduction will keep us inside the combinatorial class. I'll talk about the rigidity step in a moment, but at least for the reduction step, we're happy. So we must be in this case. Okay, in this case, we can make exactly the same argument if the set x over here happened to contain both x and Y. Because here we'd have a two x edges or edges and loops, and we'd add one vertex and one, two, three edges and loops. So we'd get the same two x plus one. So the only problem we have to deal with is if the set x looks like this doesn't, not containing y.
00:16:02.694 - 00:16:42.516, Speaker A: And then we think about the reduction v adding y. And so then we'd have the same issue there and we'd end up with a set Y like this. So the only real thing we have to do is worry about x union Y in this case. Okay? So if we want to reduce v and add an a loop at x or a loop at Y, then the problem is if there is a set that is already too full containing little x but not Y, and another set containing little y but not x. However, if you have such a set, then I of x union Y is equal to two x union Y. This is just that. They're disjoint sets.
00:16:42.516 - 00:17:17.626, Speaker A: So you can just count up edges and loops in them and add them together. So this is not hard at all to check. And hence you do the same contradiction. If such a set exists, then x union Y plus v adds one vertex, but one, two, three edges and loops. Okay, so let's, let's see that a bit more written down. So if v is incident to one loop, then either x and y are in x and it can't exist. As we just said, we'd add v and the free incident edges and loops to find a contradiction.
00:17:17.626 - 00:18:07.366, Speaker A: Or y is not. And hence we can consider the other reduction at v that adds y instead. And this gives us another blocking subset y contained in v minus v with the same count, and this time of a y. And then x union Y has the total count, and we get a contradiction by adding v back again. So what I'm saying from all that is, if v has one loop and two simple edges, it must be possible to do a one reduction, adding one of the two loops. That one of the two must keep us within the combinatorial class. So in our final two cases, not that you can see much of the picture anymore, but whether there was one loop or two loops, we can always do a reduction that deletes our vertex with free incident edges and loops and add a loop among the neighbors.
00:18:07.366 - 00:18:45.386, Speaker A: So this looped one reduction must always work. Okay, but the looped one reduction is different to a loop to extension, sorry, is different to a one extension. So we don't yet know it preserves rigidity. So how do we show that? So if we can show it that one extension preserves rigidity, we're finished by induction again. And actually we've finished the proof of the theorem, so you can see that? I'm not going to prove it in detail, I'm just giving you a very brief hint, basically. But what we're going to do is if you remember, for the usual one extension. So let's draw a picture at the side.
00:18:45.386 - 00:19:47.342, Speaker A: So the usual one extension took an edge xy subdivided it by a new vertex v that we put p of v exactly on the midpoint of the line through p of x and p of y. And we used this with the edge xy kept to say this gave us a circuit. This collinear triangle was a minimal dependent set in the two dimensional bar joint rigidity matriarch. And so we could do the one extension. Remember in our one extension there'll be some other vertex z that this becomes adjacent to. We can think of it as a zero extension adding v, adding say like that degree two vertex as our addition. And then we can use the fact there is a collinear triangle on these three vertices to say whichever one of them we delete, we preserve the, we don't change the rank of the rigidity matrix.
00:19:47.342 - 00:20:31.168, Speaker A: The zero extension told us the rank went up the full amount it possibly could. And then we can just add this one in for free because it creates a circuit. And we can take this one away for free because it just removes the dependence from the circuit and doesn't change the rank. So that was our little collinear triangle argument we did for one extension before, very briefly and claiming to you that exactly the same argument works. And what we do here, we have a loop and we remove the loop and we add a new vertex and a loop. And then the final edge is either another loop or it's an edge. But whichever of these two it is, is irrelevant for the argument.
00:20:31.168 - 00:21:18.276, Speaker A: It's only going to play the role that this edge from pv to z played, which is just to give us a zero extension. And it doesn't matter if our zero extension looks like. Sorry, it doesn't matter if our zero extension looks like that or like that. It's just one of the, one of the two cases I talked about a few minutes ago. So how, what do we do? Well, we keep the loop that we started with and we have our new vertex here and new loop. So that two vertex graph of one edge and two loops, that is, this one, generically it's independent like a triangle is, but we pick a special position where it's a circuit, and the special position is where the two linear constraints are parallel. And we have a nice right angle for the edge.
00:21:18.276 - 00:22:18.298, Speaker A: So the edge is actually the exact distance between these two parallel linear constraints. And so it shouldn't be so hard to see that this, this is dependent if you, you want to write it out as a, a matrix. I guess what you do is you have pv and you say, so this is v and this is u, p u is pv plus the, the normal vector at v. So the normal vector that gives you the linear constraints, just add it on and put the same normal vector over here and you can just see you have a little matrix with three rows for your rigidity matrix for this particular graph. And you'll see it's easily dependent. Okay, so that's the end of the, the proof of their theorem. Any questions on that? Okay, so, oh, I should check in case there's anything in the chat.
00:22:18.298 - 00:23:06.474, Speaker A: No, there's not. So I said at the start of the theorem that we're talking about generic linear constraints. So the p and the q were both generic. In this two dimensional theorem. You can actually improve that the theorem to remove that assumption and just have generic points, not, not need the linear constraints to be generic particular. This is interesting because you can imagine the linear constraints are pinned vertices that make come up in applications, or maybe you force something to move along a track, say. And so you might want to say in advance, these are where my linear constraints are because they model the boundary condition of some particular real world situation.
00:23:06.474 - 00:24:18.764, Speaker A: And so this kind of motivation led Cato and Tanigawa to improve the theorem that we just said to allow non generic linear constraints by saying in advance I'm going to have these predetermined linear constraints and then the counting condition depends on the linear constraints. So for example, if I give you some particular graph, but I say that every vertex within the graph that contains a linear constraint, all those linear constraints are parallel, then now I can translate everything. And so the e plus l equals two v condition is not right anymore because we definitely have a motion that we can't rule out. So depending on the predetermined choice, the counting condition has to change a bit and depend on that. So that makes their result more complicated to describe. So I'm not going to go into any more details on that, but just this is a nice reference that does this and they do some other things as well, some of the higher dimensional boundary conditions in the linear constraint context. In fact I mentioned one of them just about now.
00:24:18.764 - 00:25:20.320, Speaker A: I talked and in fact Alex's question is relevant again here. So in two D, a special case that was true is that you take your understanding of a bar joint framework and you understand a particular kind of linear constraint framework when there are exactly free loops. It doesn't really matter where you add the free loops so much. And so, understanding linearly constrained frameworks with exactly free loops tells us the other way as well, about bar joint frameworks in the plane. So if I go up to dimension three, since we don't understand bar joint frameworks generically, we're not going to understand linearly constrained frameworks because it includes the bar joint framework as a special case. So it's going to be too much to ask for a full characterization without a substantial step towards the 3d rigidity problem, for example. But if you go to special cases, some results are known, and so I want to mention those a little bit.
00:25:20.320 - 00:26:23.224, Speaker A: So the same paper by Cato and Canon Tanigawa, they give results for body bar frameworks. So I don't think I've mentioned body bar frameworks in this course, and I probably won't, even though it's kind of on the outline still, but I probably won't get to them. But you should think of those as instead of having bars and joints where the joints just join two edges, you could have larger rigid bodies that then could be connected by many edges. Or if you like, what you could think of is that each of these bodies is really some sufficiently big complete graph. And you have a graph with lots of, let's say we're in three d, and you have lots of, I don't know, k five sub graphs, and you're interested in how you can connect them up in a way that makes the whole situation rigid. And so this is kind of intuition for body bar frameworks. And if you add linear constraints or boundary constraints to these things, then Cato and Tanigawa can give a, a nice characterization.
00:26:23.224 - 00:27:10.664, Speaker A: Okay, so I want to next mention one more result for linearly constrained frameworks in d dimensions. As I say, we can't solve the d dimensional rigidity problem in general. So I need an extra hypothesis. And hypothesis I want to add is that we have sufficiently many loops, so in particular, sufficiently many loops at every vertex of the graph. So each vertex is going to be constrained through these loops to move not in RD, but in a sufficiently smaller dimensional affine subspace, and then we can do it. So I first looked at this problem with Jim Cruickshank, Hakangula and Bill Jackson. But a more recent paper, we gave a sort of improved theorem, which was with Bill Jackson and Shinichi Tanigawa.
00:27:10.664 - 00:28:01.224, Speaker A: So what our theorem says is that, well, it actually applies in the plane. But we can think about it for a dimension at least three. But if you make every vertex incident to at least this number of loops, so say you reduce the dimension by half. Basically, then you can characterize rigidity as a linearly constrained framework as exactly those graphs. I have a spanning subgraph where the number of edges plus loops is equal to d times the number of vertices. That's common with the theorem of Stranu and Ferran for the plane, but the only other counting condition we have, there's a minor condition at the end, but the counting condition is just the number of edges is at most number of edges plus loops is at most d times mod x. Again, that's common with before.
00:28:01.224 - 00:29:05.368, Speaker A: But notice I've thrown away the condition that I of x is at most two x minus three. For simple the point here is I've got so many loops that I don't have to worry about, say, three dimensional double bananas and violating the three x minus six count. Or in general, the dx minus d plus one. Choose two, because I've chosen so many loops everywhere that I become sparse for free from the combination of the loop constraint and these constraints. Okay, but I do have to be slightly careful, because my floor of d over two allows, for example, frameworks in three dimensional space where there's exactly one loop at every vertex, and here k five becomes an issue. So what turns out in general is that there is a specific small graph that violates the count you would want, but isn't ruled out. So I just said it could rule out these things.
00:29:05.368 - 00:30:17.410, Speaker A: But it's, except in one very special case where you just have this one particular graph, which can't occur as a subgraph. So you have to be k five free when you're, when we're in r three, et cetera, in KD plus two free in RD. And also because we want to have the subgraphs to have this specific number of loops as well. Okay, so that is a bit more complicated, and I'm not going to go into any of the details, but just saying we can solve it if you have sufficiently many loops at every vertex. So, for example, if you believe, say some physicists who believe we live in 20 something dimensions, then we can solve the three dimensional rigidity problem by embedding it into a 20 something dimensional space and having lots and lots of loops everywhere except for the three dimensions you want in some sense by having a theorem like this. But that's probably even too vague to, but it's more of a jokey comment I guess, as well. So next I want to comment a little bit on global rigidity for linearly constrained frameworks.
00:30:17.410 - 00:31:07.924, Speaker A: So again, we can have the same sort of natural definitions. We want to be unique instead of now we really do mean unique because there are no translations or rotations or reflections. So we just want to find that the only way to draw the graph in a given dimension, subject to the edge length constraints and the linear constraints on the loop vertices, your drawing is the only one possible. Okay, so for this it turns out that we still care about redundant rigidity and we still care about a connectivity condition. By redundant rigidity, I put the definition, just to make 100% sure you're clear what I mean. We want to be rigid after deleting any edge, but also after deleting any loop. So the loops have to be redundant as well as the edges.
00:31:07.924 - 00:32:04.420, Speaker A: And the connectivity condition is actually a little bit different. So it does not. So say we're in the plane. We know for global rigidity that you have to be free connected, because if as a bar joint framework, if you have a two vertex separation, you can take a line through the two vertices and flip one component over, reflect through that, that line, and you get a second equivalent but non congruent realization. In the linearly constrained world, we can allow two vertex separations because the loops can help us. So we say that a graph is de balanced if for every subset of the vertex set of size d, every component of g minus x has at least one loop. So notice I didn't talk about x, this set of size d being a vertex separating set.
00:32:04.420 - 00:32:42.984, Speaker A: It could be that g minus x is just a connected graph. And that would be saying what you're saying there is. You don't want your d loops all to be so you don't want your loops all to only sit on D vertices. So if you're in the plane, you don't want it to be true that all the loops you have in your graph sit on these two vertices. Because if they do, then what's in the rest of it? You can do the same argument as here. You can put a line through through here and flip this part over here across the cut. Well, this is not a cut, because there could have been indifference.
00:32:42.984 - 00:33:33.758, Speaker A: But you don't want to have all your vertices, all your loops only on two vertices. And similarly, if you have a two vertex separation in your graph, that can still be okay for a globally rigid framework if on both sides you have at least one loop. So the loop over here would mean that this vertex moves on this fixed line. And the loop over here says this one moves on this fixed line. So this is going to prevent, unless you have some non generic coincidence, the reflection you would want to do through the line, through the two vertex separation. Okay? So hopefully, at least the sort of intuition for this is okay, the proof that redundant rigidity is necessary. Actually, I just wanted to draw one little picture to comment on this.
00:33:33.758 - 00:34:22.550, Speaker A: So imagine we have a rigid, but not redundantly rigid linearly constrained framework. So what that could look like is like this. So I have this vertex of degree two. So it's rigid if this thing is rigid, because I've done a zero extension, and this thing could even be redundantly rigid. But the whole thing is not redundantly rigid, because if I delete either one of these two edges or loops, then I will become flexible. If I delete the linear constraint, the vertex just moves on a circle centered over here, and that we're happy. But if I remove this, this edge, then the red vertex here is free to move along this line, and it can move along this line forever.
00:34:22.550 - 00:35:16.754, Speaker A: So that the configuration space, if you remember back to our redundant rigidity lecture, an important step was that the configuration space was bounded. And that's just not true anymore, because this vertex moves infinitely on along this line. So you have to deal with this as an additional complication. But it's not too hard. And here's the theorem from recent work with Hakangula and Bill Jackson, where it's basically an extension, a generalization of the two dimensional global rigidity result to include these linearly constrained frameworks. And the generalization, the special case of the bar joint frameworks is like, again, with an answer to Alex's question. If you take something that's redundantly rigid and free connected as a bar joint framework, and add sufficiently many loops, which would be at least four in this case, then that case sort of has to fall out of our proof as a special case.
00:35:16.754 - 00:36:11.288, Speaker A: So again, we need to worry about whether you need to be connected or not. So the reason I'm highlighting that in the statement here is not because it makes things particularly complicated, it just makes a statement more complicated. So, for example, this graph is globally rigid. So multiple copies of this graph are also globally rigid. And then you could have a sort of non trivial, globally rigid thing, maybe looks like this, and the whole thing is globally rigid, the whole union of them. But it's even more complicated than just thinking about each connected component, because this one is also minimally rigid. Because if I have a vertex with two linear constraints and I remove one of them, then you're free to move on a line just like we had over here.
00:36:11.288 - 00:36:58.246, Speaker A: So if you have just a single vertex, it's a bit odd. So let's say we're a connected graph with at least two vertices were generic, then the framework is globally rigid in two dimensions, if and only if the graph is too balanced and redundantly rigid. So these are conditions I already mentioned. I'm not going to say anything about the proof. I don't think so. You can think of it as following the same strategy we went through in detail for the Jackson Jordan paper. But there are particular complications, especially combinatorially, that come from having the two inequalities, the I of x at most two x minus three, and the at most two x when you include the loops.
00:36:58.246 - 00:37:42.622, Speaker A: So this is an e union l. So having the two different ways that you cannot satisfy the combinatorics leads to some complications. I wanted to mention this next thing, not because I think it's. It's sort of not necessarily something that would naturally fit in a graduate course, but I want to ask the question in case someone has an idea, and so I couldn't stop myself from throwing it in. So, linear constraints, in some sense you can think of them as being a spherical constraint where the center of the sphere is the point at infinity. Projectively. So you might also consider spherically constrained frameworks, whether the center of the spheres is a finite point.
00:37:42.622 - 00:38:43.374, Speaker A: So these would be, instead of having a linear constraint from a loop at a vertex, the loop could constrain the vertex to move on a fixed d damp minus one dimensional sphere instead, infinitesimally, as we talked about last time, frameworks on the sphere, you think about the constraint for the plane tangent to the sphere. So the same thing is true here. So infinitesimally, there is no change at all. The infinitesimal constraints are the same for linearly constrained as they are for these spherically constrained, and that's just easy. However, for global rigidity, they're potentially at least different. So if I have a framework including GP q, I guess, and the location of vertex v is here, if I want to find an equivalent but non congruent realization, is a linearly constrained framework. I have to find some other point on this line through the point pv in my equivalent framework.
00:38:43.374 - 00:39:24.904, Speaker A: Sorry, I need to change the letters, I guess. So maybe I want to make. Yeah, I should stick with GPQ and call this p. So in my equivalent framework, GPQ, where I'm taking the same linear constraints for both, I want to find a different p on the same line, but if I move to the spherically constrained case, then I want to find a different p on the circle instead. So at least it's conceivable that these questions are different. Right. So whether you're globally rigid as a linearly constrained framework or as a spherically constrained framework may well be different answers.
00:39:24.904 - 00:39:31.584, Speaker A: In the two dimensional case, we prove that they're the same. Sorry, Alex. Go on.
00:39:32.284 - 00:39:38.204, Speaker B: So, I mean, could you just think of this as a graph with one extra vertex and then another edge constraint.
00:39:39.624 - 00:39:41.384, Speaker A: For the spherical model?
00:39:41.504 - 00:39:42.888, Speaker B: Yeah, yeah.
00:39:42.936 - 00:40:51.684, Speaker A: So that's kind of how our proof goes, but it needs more than that as well. So you're right that if you have a spherically constrained one, you could put make a new graph by adding a vertex here, pin the vertex, and put an edge constraint to p of v, and then forget that the POV had a, a linear spherical constraint. And you could do that for every single loop that was a spherical constraint in your original graph and move from spherical constraints to linear constraints. But then you'd have to solve a linearly constrained problem with lots of vertices like this. And so that's how we show that for two dimensional spherically constrained, you get the same answer, you get balanced and redundantly rigid. But I don't think. And maybe I'm just remembering wrong, but I don't think this gives us a full answer in terms of understanding how to do spherically constrained global rigidity, apart from by using a two dimension, the fact we know more in two dimensions from the combinatorics.
00:40:51.684 - 00:41:35.666, Speaker A: So I don't think this tells us, for example, that spherical minimally constrained global rigidity are equivalent in all dimensions. Now you say it. I'm sort of worrying as to why. So I, I should read, read my own paper at the end, in case I've forgotten. But this is the. I think this is still an open question. Okay, so I have eight minutes, and since nobody is jumping in for the further comment there, I want to quickly mention one more thing that's very distinct from what we've just been talking about.
00:41:35.666 - 00:42:28.534, Speaker A: And it's kind of a small oddity that maybe is just saying things, you know, but again, asking a question towards the end, but just to fill in the time, because I didn't think I had enough for this hour. And I want to talk about independence in the d dimensional rigidity matriarchal for k regular graphs. Okay, so what's the point here? Well, we know if there's a vertex of very low degree. We can just do this zero extension zero reduction thing and everything's easy. You just, you can just not have to worry about vertices of degree at most d because you can just throw them away and you're independent if and only if you were before you threw it away. And it's also easy if you have a very high degree vertex that is a maximal degree vertex because we have the coning result. But in the middle there's obviously lots and lots of complications.
00:42:28.534 - 00:43:06.486, Speaker A: So I want to just to comment on the extreme where instead of having anything low or high degree, all the vertices have the same degree and see what happens there. So you're a regular graph. I can't really talk about rigidity in this case because we know minimally rigid graphs have to satisfy this equation. And that means that if you satisfy this and you're k regular, you'd just be able to work out, oh, I'm exactly quite a small graph, and then you could study it quite easily because it was very specific. So I want to focus on independence. So now if I'm independent, then I know I have an inequality. And so there's much more.
00:43:06.486 - 00:43:51.214, Speaker A: So I can have graphs of whatever size you like, as long as, for example, you don't have the silly things like wanting to have an odd number of odd degree vertices in your k regular graph. So now I'm thinking about independence instead of rigidity. When is a k regular graph independent? We know the answer for all graphs when d is at most two. So forget about that. I say last lecture here. It's not the last lecture. A while ago we saw a result of Jackson and Jordan that said every connected graph with minimum degree at most d plus one and maximum degree at most d plus two was independent if and only if it was sparse.
00:43:51.214 - 00:44:12.262, Speaker A: Okay, so that immediately tells us the answer. If our k regular graph has it. Well, is d. K is d plus one. So our k regular graph has k equals d plus one, or even at most d plus one. But at most d we already talked about was easy as well. It's still just independent if and only if it's sparse.
00:44:12.262 - 00:45:08.184, Speaker A: So kregular graphs so far up to d plus one are nice and easy. If we take dimension at least four, we can see that kregular graphs are hard in sense that they don't satisfy this thing. So I'm trying to look for when this is true and it becomes false for d greater than or equal to four, when k is equal to d plus two. So d plus two regular graphs are not always independent if and only if they're sparse. For example, the complete bipartite graph, kd plus 2d plus two, you can count the number of edges and vertices, and I do it here, but I'm not gonna go into it. You can see the number of edges, the number of vertices, and you can check sparsity by a little equation and it k 66 is four sparse, but it's dependent. We saw that earlier.
00:45:08.184 - 00:45:37.394, Speaker A: And remember Sean gave a nice lecture on the Bolkarov complete bipartite graph case. And so I'm not going to worry too much about that. But the take home for this is that if the k regular graph has k at least d plus two, then d sparsity is not sufficient to guarantee d independence. So there's. But there's one case left. And again, I'm just flagging this up in case anyone wants to solve it. So the case is when d is free.
00:45:37.394 - 00:46:09.974, Speaker A: So there. The complete bipartite graph doesn't give us a counterexample because k 55 violates the free v minus six count. It has free v minus five edges, ten vertices and 25 edges. So it's free v minus five rather than six. On the other hand, when dimension is free, we know this is true, so the average degree is strictly less than six. And we also know that d plus one we were happy with for k. So the only option left is that k is a five regular graph.
00:46:09.974 - 00:47:12.334, Speaker A: So here's a question. Is it true that a five regular graph is independent in the three dimensional rigidity context if and only if the graph is free sparse? Okay, so this was conjectured in the early two thousands, but to be honest, I think it's provable, but I haven't managed yet. So I'm just throwing it out there for anyone who wants to try. Well, let me stop for questions, basically, but I want to reemphasize that we have some guest lectures coming up. So this Wednesday and Friday, Bob Conley is going to talk about tensegrity frameworks. So tensegrity is, instead of having the distance between every pair of vertices joined by an edge is fixed, you have some that are fixed but some that are allowed to get shorter but not longer, and some that are allowed to get longer but not shorter. So you have some struts and you have some cables as well, and this gives you a generalization.
00:47:12.334 - 00:47:46.644, Speaker A: And next week on the Monday and Wednesday, Lewis Faram will give two guest lectures and his topic will be generic universal rigidity. So we haven't defined universal rigidity. Yet in this course. So Lewis will do that and he will tell you about how to understand generic universal rigidity in d dimensions. Okay, so I should stop there in case anyone has questions. So I do have a question about the conjecture at the end. Yeah.
00:47:46.644 - 00:48:49.080, Speaker A: Have you tried using the maximum metroid to determine whether it's independent there? Yes. So if we replace our free independence with independence in the c. I don't know which way around c twelve co factor matriarch, which is the unique maximal abstract free rigidity matriid. If you don't know what this is, I guess. Don't worry, I don't want to try and go into the explanation now, but these were the ones that were studied in Bill Jackson's winter school talks at the start of this course. If you do that replacement, then you have a tool you can use to try and solve this conjecture. Because we know that X replacement by Jackson, clinch and Tanigawa's recent papers that x replacement preserves independence in this matriid.
00:48:49.080 - 00:49:17.026, Speaker A: So I did try. I don't think anyone's checked my attempted proof, so take it with a pinch of salt. But I believe I can prove this conjecture is true in the cofactor matriarch using this operation. But using extra placement is kind of a cheat for this kind of thing because I want to solve the 3d rigidity problem and I can't solve extra placement there, so. Yeah, okay. But I mean, as a litmus test, it passes the litmus test. Yeah.
00:49:17.026 - 00:49:43.264, Speaker A: And a second litmus test is, I think, I believe Georg has done some computations for small graphs and I don't think he found any counterexamples. He tested huge numbers of graphs on small numbers of vertices, so we don't know of any obvious counter example. Yeah. Okay, cheers. Thank you so much.
00:49:48.284 - 00:49:49.396, Speaker B: Hey, Tony.
00:49:49.580 - 00:49:50.180, Speaker A: Yeah.
00:49:50.292 - 00:49:59.964, Speaker B: So you think it's provable, but do you mean like provable using the techniques that we've seen so far that you've demonstrated in the, in the class.
00:50:01.424 - 00:50:03.912, Speaker A: Oh. To resolve this conjecture.
00:50:04.088 - 00:50:04.844, Speaker B: Yeah.
00:50:07.824 - 00:50:33.624, Speaker A: Yeah. So the proof technique I have in mind is kind of, is recursive, but. And yeah, in some sense does use things we've been learning about in the, in the, the course. But I mean, I haven't. I haven't proved any result to you so far that would, that would get you partway to this, really.
00:50:36.044 - 00:50:41.868, Speaker B: Right. But I mean, like the, the basic ideas that you've shown in various proofs. Okay.
00:50:42.036 - 00:50:42.784, Speaker A: Yeah.
00:50:43.444 - 00:50:45.784, Speaker B: It just might be a very tricky argument.
00:50:48.844 - 00:51:05.184, Speaker A: I mean, I. When I say I think it's provable, I don't think if you give me a week, I could just write down and then say, here it is. But I sort of think that putting some of the ideas together we have, if I don't get unlucky, then you can make progress towards it.

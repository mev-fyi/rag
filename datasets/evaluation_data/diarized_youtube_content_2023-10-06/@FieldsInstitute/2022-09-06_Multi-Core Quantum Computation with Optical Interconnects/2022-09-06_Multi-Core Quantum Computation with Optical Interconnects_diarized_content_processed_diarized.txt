00:00:00.760 - 00:00:17.438, Speaker A: Okay. Yeah. I want to start by thanking the organizers for giving me the opportunity to present this work. This is my fifth CQIQC conference. I always love it, and this time is no exception. So, my name is Aaron. I am from Entanglementworks.
00:00:17.438 - 00:01:03.444, Speaker A: We're a startup based in Toronto, and we're building solutions for multi core quantum computation. So taking lots of small quantum computers and connecting them into one big machine, and that's what I'm going to talk about. This work was done by this wonderful team that we have. So it's definitely not just me, and we're a business, and so I am going to try and sell you something. I'm not going to try and sell interconnect. I'm going to try and sell you on the idea of the need for interconnect, and more importantly, on. On the idea that we're a lot closer than we think in terms of the performance metrics we need to reach.
00:01:03.444 - 00:02:03.338, Speaker A: But I'll start with something that everyone knows, and everyone in this room knows, at least, and that is that when we have a quantum system, it grows, or the number of states or the space grows exponentially with the number of subsystems. Everyone knows this, but this is not enough for quantum computation, or it's not enough for doing very heavy computation. What you need on top of having this huge space is the ability to actually span the space and explore it without an exponential number of knobs that you need to turn on your machine. And it's great in quantum mechanics because we don't need this exponential number of knobs. We can reach a pretty huge part of the subspace with a small number of knobs. And that was actually realized as a big problem, a computational problem, very early in quantum mechanics. Systems get very complicated very quickly with very simple hamiltonians.
00:02:03.338 - 00:02:54.934, Speaker A: But for a quantum computer, it's great because we don't need a ton of gate, we don't need extremely long circuits. It's also a huge problem because there is an exponential space for things to go wrong. We've already heard this earlier today. And so what we kind of always want to do with quantum computers is we want to isolate the problem. We don't want the space of problems to grow exponentially, and so we want to treat small subspaces, and we always make assumptions that this is true, but it stops being true as you kind of grow and grow and grow. And common wisdom says at some point, every single system will have to be modular. You have to break it down into small subsystems where you can to a very high level of confidence, believe that they're completely isolated.
00:02:54.934 - 00:04:10.594, Speaker A: And the big question, or two big questions that we have as a community is, what's the ultimate size of a single processor? How far can we grow? And the second question is, what's the optimal size if we are going to go modular? What's the optimal size of each one of these modules? No one knows the answer, but there are speculations, and certainly industry timelines are based on these kinds of speculations. So just to give an idea of the stuff we don't know, we've done this case study of Rydberg arrays. What's great about Rydberg arrays is you can take thousands of atoms, you put them in an array, and they can interact, and you can turn these interactions on and off. And what's really nice is the interactions are not nearest neighbor interactions necessarily. You can do long range interactions by going to a higher Rydberg level and having these big blockades, or you can interact with anything inside the blockade. That's fantastic. In theory, in practice, as you go to these higher Rydberg levels, you get more errors, because you're just more susceptible to things that can go wrong.
00:04:10.594 - 00:05:09.004, Speaker A: And one of these errors is loss. So what's loss? In a Rydberg, it means that you go to an excited state and then you fall down back to a state that's not in your qubit subspace, so you're no longer in the subspace. And so we modeled it and we said, what would happen if a qubit in position zero would try to interact with a qubit in some other position? What would be the fidelity of that interaction, given these different ranges for the Redberg interaction? So here we only have nearest neighbor, then we have next nearest neighbor, et cetera. And we allowed two methods to do it. One is you try to use the longest range interaction, you can, or maybe use a short range interaction and do swaps until you reach the point where you want to be. And it turns out that in all of these cases, the algorithm chose the nearest neighboring direction. And just the swaps, it doesn't pay off to go to these long range interactions under this specific parameter regime that you're seeing here.
00:05:09.004 - 00:05:59.324, Speaker A: But that's under the assumption that the only problem is this loss, and that's not realistic. In reality, gates suffer from other problems. And so we added technical noise. And you can see that once you add technical noise that is independent of the Redberg level, then you do get some advantage from going to longer range interactions. But again, at some point, you saturate and so we haven't quite made the paper available on archive yet, but it is available on this URL if you want to see sneak pre preprint. And so, when we try to connect quantum systems. So one thing we learned is that we're very unsure about the actual size of the Redberg array.
00:05:59.324 - 00:06:39.162, Speaker A: And the other is that a big problem is going to be connectivity. And so when we want to connect these different modules, we also don't want to lose too much connectivity. And that brings us very quickly to photons. So photons are fantastic, because once you get a photon in fiber, you can route it anywhere. And so you can get very high connectivity between modules. And everyone knows this since very early days of quantum computing with many proposals, and these two are from 2014, but there have been others before that. And so that's what I'm going to tell you about for the rest of the talk.
00:06:39.162 - 00:07:15.386, Speaker A: But I want to start with what is an optical interconnect? And if you get anything from this talk and you don't know anything about interconnects, you should get this line. So when we think naively of transmitting information between modules, we think of taking the information, encoding it in a photon, moving that photon to another module, and then dropping it off in that module. That's a problem. It's a problem because we cannot copy the information. So the information is now encoded in this photon. If that photon gets lost, that's a big problem. So that's one problem.
00:07:15.386 - 00:07:48.844, Speaker A: The other problem is actually encoding that information. A photon requires very strong interaction with the qubit, and that's very hard to engineer. And so there is a solution that gets around both of these problems, and that is we use spontaneous emission or some other mechanism to herald entanglement. So we create entanglement between the two qubits, and then we use that entanglement to transmit information. So if the heralding of entanglement fails, we can try again. No information is lost. So how does that work? Very, very high level.
00:07:48.844 - 00:08:32.720, Speaker A: We get two qubits. We get each one of them to emit a photon that is entangled with a qubit. If these were ions, this would be spontaneous emission. But for other systems, there are other ways to do it, and then use a beam splitter to sort of lose the distinguishability of where the photon came from. And you do a bell measurement, and you transfer the entanglement from the ion photon entanglement, or from the qubit photon entanglement into these two, into these qubit qubit entanglement, and then you can use that entanglement again to transmit information. Great in theory, very difficult in practice. And I'll kind of give an example of why it's difficult in ion traps.
00:08:32.720 - 00:09:15.298, Speaker A: So if you have an ion trap, you're trying to collect a photon that's spontaneously emitted from an ion, and you've only got this relatively small lens that you can fit in your apparatus. It doesn't capture most of the photons. Most of the photons just go everywhere. And this has to happen twice simultaneously. So that's not great. And state of the art is this experiment that was done in Oxford in 2019, and it reaches a rate of 200 hz for heralding entanglement. So, just to give a sense, we've heard this before, about 100 microseconds, to do a two qubit gate in an ion trap.
00:09:15.298 - 00:09:59.650, Speaker A: And so this is not great. We have designed an apparatus that can take us with the same ideas, optimistically, between one and 2 khz. But that's about as far as you can go with this kind of method, unless you try to find a trick to go around it. And the question is, is that good enough? Does that bring us to a point where we can actually show some advantage? So what is advantage? What is the advantage of an interconnect? And that's kind of easy to think about. Imagine that I give you two quantum processors and I give you an interconnect. Do you want to use it? Well, why would you not want to use it? I give you some algorithm. If the algorithm is small enough to run on one machine, you're not going to use the interconnect.
00:09:59.650 - 00:10:43.384, Speaker A: Very clear. If the algorithm is bigger, then you have two choices. One is use the interconnect, and the other one is use one of many techniques that people have devised to do this, by querying the one computer multiple times and simulating the quantum computation. But that comes at a cost, and the cost is roughly exponential in the number of times you would have used the interconnect if you had an interconnect. Not many uses of the interconnect already pay off. And that's, in a sense, good news for the interconnect, because if the interconnect is kind of bad, we do not want to use it many, many, many times. And maybe with a few times, we already get a nice advantage.
00:10:43.384 - 00:11:30.460, Speaker A: And so, to model that, our first attempt at modeling that was with VQE circuit. So trying to reach the ground state of a twelve qubit Hamiltonian using two six qubit machines and a variational circuit, which is, I'm not going to go into the details, but it's a very good variational circuit. It reaches very good results. The first bar you're seeing here is what would happen if we did not allow these processors to interact at all. It's the best product state that we can reach, and you get some result there. Then you ask, what's the best result we can get if it's not a product state? If the interconnects are perfect, we can get to the ground state or extremely close to the ground state. Not a surprise.
00:11:30.460 - 00:12:03.592, Speaker A: And so what we did was we added these interconnect, or we added these ZZ gates. But each time you use a ZZ gate, you get a penalty or decoherence, because it takes a while to generate the entanglement, it mediates this state. Sorry, how did I go back? Okay. And so we don't get quite to the ground state, but we get. We get a pretty good answer, a lot better than this one. So that's fantastic. And then once we got that, we said, how much better can we do by taking the exact circuit and just recompiling it in a smart way? And we got a further improvement.
00:12:03.592 - 00:12:29.576, Speaker A: And so, overall, you can see this tenfold improvement, more or less, by using an interconnect. So that's a good indication. And then we went a little bit further and did a transfers field ising model. And again, we compared to the product state. So best product state versus the best variational state we can get. And now we didn't add the coherence. Instead, we just limited ourselves to three uses of the interconnect.
00:12:29.576 - 00:13:16.076, Speaker A: So you're only using the interconnect three times, and we get extremely, extremely good results. And so that's very promising. Another work we did, and I'm going to go over this very quickly, is looking at quantum time evolution. So this was done with Dvira at U of T. And what Finn, Dvira and Ilya did, I wasn't involved in this work, was they took the usual trotter formulation or the trotter circuit that you see here. And instead of having all of these uses of what would be inter QPU operations, they spread them out thinly. And so you cut the problem into multiple QPU's.
00:13:16.076 - 00:13:59.612, Speaker A: So multiple quantum computers, and each one does a long operation on itself. And then another long opera, there's another long operation between them. And so you minimize the number of operations to do between them. And the results are pretty good. You can kind of have a look at the paper or ask me after and I can get into more details. And so that's great news, but it's great news with kind of algorithms that were very, very specifically tailored to show that we don't need to use multiple interconnects. What happens with more generic circuits? In order to understand that, we are developing all the tools that are needed to sort of not only take the circuit and spread it out, but do it very, very efficiently.
00:13:59.612 - 00:14:38.424, Speaker A: And the centerpiece of that is a compiler that compiles onto a multicore architecture, so it spreads the problem onto multiple cores. Here you're seeing a two core topology, so you've got these two cores, and you take a logical circuit in. These logical circuits were taken from a standard library on GitHub that people use for benchmarking. And what the optimizer does is it reduces the number of times information goes from one side to the other. In dark blue is the original circuit. In light blue is Qiskit, IBM's compiler, which can also compile for this. It's just not optimized to do it in a good way.
00:14:38.424 - 00:15:21.770, Speaker A: And in orange is our compiler. And you can see that our compiler does a lot better than Qiskit in this case. We go from 164 uses of the interconnect, which is absolute science fiction for near term devices, down to 24. 24 is borderline possible. And so with this tool, we can now study sort of more realistic circuits. And so we took two circuits. The quantum phase estimation are these squares and the quantum Fourier transform are these triangles, and we use that to measure something called the algorithmic qubits.
00:15:21.770 - 00:16:12.134, Speaker A: You don't need to understand the details. If anyone has questions, I'm happy to get into them. But basically it gives you a number at the end, and that number is the number of algorithms within this square that successfully pass a certain threshold of fidelity. We took 210 qubit processors, and we said, how far can we get with them? And you can see that we can get to 14 algorithmic qubits. So these processors, the numbers we took, are realistic numbers that are advertised on sort of standard machines on azure. And we do get this very nice improvement, a few more qubits, and that. It's nice having a few more qubits on your machine.
00:16:12.134 - 00:16:50.524, Speaker A: And we compared this to a monolithic machine with the same parameters. The monolithic machine goes up to 16. Not surprisingly, the interconnect is a bottleneck, but it's not a terrible bottleneck. And then we ask ourselves, what's the problem? What can we improve to get this better. And so we took another interconnect, this time with a slightly more optimistic number. So 99% entanglement fidelity. And we said, what would happen in that case? And in that case, we see almost no improvement.
00:16:50.524 - 00:17:15.388, Speaker A: So we don't get a jump in the number of algorithmic qubits. We do get a slight jump in fidelity. It's a bit hard to see, but if I gave the numbers, you'd know. And so this improvement in fidelity doesn't give us a huge boost. Perfect. And the reason it doesn't give us a huge boost is the real problem here is actually the gates we're adding. So we do need to add a few more gates.
00:17:15.388 - 00:18:12.544, Speaker A: When we do either teleportation or remote gates, we have an extra number of cnots. And those are the things that are really hurting us. And so if you want to, if you want the interconnect to be better, either find a different trick to move information around, or reduce the number of interconnect uses, or get better gates, which is always true, get better gates, you'll have better performance. And so, at the end of the day, we are seeing that if we were to deploy our current interconnect, it would give an advantage on realistic computations on existing devices. The takeaway message is when interconnects are incredibly important to scale quantum computers up. And two, we can fix a lot of the problems using software rather than hardware to get quality quite a lot further. Thank you.

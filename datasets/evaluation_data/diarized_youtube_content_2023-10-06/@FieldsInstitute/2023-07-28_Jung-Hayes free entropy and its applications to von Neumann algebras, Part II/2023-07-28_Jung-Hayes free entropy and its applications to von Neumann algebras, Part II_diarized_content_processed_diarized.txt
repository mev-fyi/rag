00:00:00.160 - 00:00:00.392, Speaker A: Great.
00:00:00.392 - 00:00:03.686, Speaker B: So, um, yeah, I think I'm just.
00:00:03.750 - 00:00:16.794, Speaker C: Puzzled about, .2 because presumably diffuse means that the center is part, there's no factor direction.
00:00:18.494 - 00:00:24.274, Speaker A: Okay, so I'm saying that, I'm not saying the center is diffuse. I'm saying the algebra itself is diffuse.
00:00:24.694 - 00:00:25.434, Speaker D: Well.
00:00:27.674 - 00:00:34.734, Speaker C: So I wonder, I'm not quite sure if I'm familiar with the term diffuse for dynamology.
00:00:35.954 - 00:00:39.614, Speaker E: So diffuse means it has no minimal projection.
00:00:40.954 - 00:00:47.666, Speaker C: Oh, right, okay. So it's center is diffuse.
00:00:47.690 - 00:00:50.434, Speaker A: And also it's, no, no, no, the.
00:00:50.474 - 00:00:55.068, Speaker E: Center is not diffused. The center might be trivial. The center might just be the complex.
00:00:55.116 - 00:00:59.624, Speaker B: Numbers, but the algebra itself doesn't have any minimal projections.
00:01:00.444 - 00:01:03.108, Speaker E: This doesn't, I didn't say anything about the center.
00:01:03.236 - 00:01:05.224, Speaker D: Yeah. Okay.
00:01:06.644 - 00:01:08.684, Speaker A: Okay, so now, now that you asked.
00:01:08.724 - 00:01:12.904, Speaker E: The question about that statement, how about I actually, like, present the statement.
00:01:17.524 - 00:01:17.884, Speaker A: All.
00:01:17.924 - 00:01:20.932, Speaker E: These are with spatial states, so all.
00:01:20.988 - 00:01:23.824, Speaker C: Type two factor here.
00:01:25.044 - 00:01:25.404, Speaker D: Sure.
00:01:25.444 - 00:01:27.504, Speaker B: Yes, yes, that's true.
00:01:28.484 - 00:01:33.424, Speaker C: Isn't that going to be true? If it's true for n one, isn't it going to be true for the tensor product?
00:01:34.684 - 00:01:44.988, Speaker A: Yeah, the tensor product will be diffuse. But diffuse doesn't imply that h equals zero. Right. Like free group algebra is diffuse and h is infinite.
00:01:45.156 - 00:01:47.424, Speaker C: That's not enough for the entropy to be.
00:01:48.914 - 00:01:49.250, Speaker A: Yeah.
00:01:49.282 - 00:01:52.802, Speaker E: So the main point in here is tensor products.
00:01:52.978 - 00:01:53.314, Speaker D: Yes.
00:01:53.354 - 00:01:59.894, Speaker E: But, and making them diffuse is just sort of saying it's, you know, that it's, that we're not in a trivial situation.
00:02:00.514 - 00:02:02.370, Speaker A: Stuff that is not diffused we don't.
00:02:02.402 - 00:02:16.050, Speaker E: Really care about in this study. So the main point is a Tensor product and in fact, commutative. Okay, so now that we've spent like a couple minutes answering Questions about the statement, now I'm going to tell you the statement.
00:02:16.202 - 00:02:23.614, Speaker A: So the, so first of all, so this is similar to the ones I did before. It can be deduced from these properties.
00:02:24.434 - 00:02:28.698, Speaker E: If you have the commutant of n.
00:02:28.746 - 00:02:30.986, Speaker A: Inside of m is diffused, meaning it.
00:02:31.010 - 00:02:35.298, Speaker E: Has no minimal projections. Then this h of n in the.
00:02:35.306 - 00:02:38.122, Speaker A: Presence of m is zero. And then also the h of a.
00:02:38.138 - 00:02:49.114, Speaker E: Tensor product is zero. So these are also basic examples. And then after this, I'll tell you something. You know, another, an application of this philosophy as well.
00:02:49.654 - 00:02:50.394, Speaker A: So.
00:02:52.494 - 00:02:57.590, Speaker B: Here, okay, so if n intersect.
00:02:57.662 - 00:03:00.094, Speaker E: N, or if the n.com intersect m.
00:03:00.134 - 00:03:01.034, Speaker A: Is diffused.
00:03:04.174 - 00:03:09.174, Speaker B: Then there exists some.
00:03:12.194 - 00:03:12.986, Speaker A: A.
00:03:13.170 - 00:03:16.482, Speaker E: Diffuse abelian which is contained inside this.
00:03:16.658 - 00:03:17.374, Speaker D: Here.
00:03:22.074 - 00:03:25.290, Speaker E: A inside n prime intersect m.
00:03:25.482 - 00:03:29.378, Speaker A: And so then what we say is, well, okay, so this n is then.
00:03:29.426 - 00:03:33.202, Speaker B: Contained inside the comuton of a and.
00:03:33.218 - 00:03:34.266, Speaker A: The commutant of a.
00:03:34.330 - 00:03:36.214, Speaker E: Is inside the normalizer.
00:03:40.844 - 00:03:41.864, Speaker B: Of a.
00:03:43.444 - 00:03:45.364, Speaker A: And so then you apply the monotonicity.
00:03:45.404 - 00:03:47.428, Speaker E: Property and say, well, h of n.
00:03:47.516 - 00:03:50.424, Speaker B: In the presence of m is.
00:03:52.844 - 00:03:53.180, Speaker D: Less.
00:03:53.212 - 00:03:57.184, Speaker E: Than or equal to h of the normalizer of a.
00:03:59.724 - 00:04:03.866, Speaker B: Of anoyman algebra of the normalizer, and that's h of a.
00:04:03.890 - 00:04:07.974, Speaker E: In the presence of M. And then a is abelian. So then this is less than or equal to zero.
00:04:09.834 - 00:04:10.186, Speaker D: Yeah.
00:04:10.210 - 00:04:13.490, Speaker A: So if you have diffuse stuff which commutes with you, then that means that.
00:04:13.562 - 00:04:17.882, Speaker E: You can't have that many matrix approximations. And at root, I mean, if you.
00:04:17.898 - 00:04:20.170, Speaker A: Think about this property, this is already.
00:04:20.242 - 00:04:59.256, Speaker E: Present in Voikilescu's paper and in fact, also in von Neumann's paper about generic choices of matrices and trying to like solve problems with commutators of those. And the idea is, yeah, if you pick something in the matrix algebra which has diffused spectrum, then you could imagine, like you could assume it's diagonalized. So say, assume itself adjoining is diagonalized. And then things that commute with that are going to basically the commutant of a diagonal subalgebra in major C's is a diagonal subalgebra.
00:04:59.280 - 00:05:01.436, Speaker A: But also, if you're close to commuting.
00:05:01.460 - 00:05:11.364, Speaker E: With the diagonal subalgebra, then you can kind of be, you'll, you can be approximated by, you know, you.
00:05:11.484 - 00:05:11.796, Speaker D: Yeah.
00:05:11.820 - 00:05:16.492, Speaker E: So you can kind of estimate how big these, this space is.
00:05:16.668 - 00:05:18.948, Speaker A: The gist of it is there's, there's.
00:05:18.996 - 00:05:25.332, Speaker E: Not that many matrices that would commute with something that's diffuse. And so that kind of underlies a.
00:05:25.348 - 00:05:26.980, Speaker A: Lot of these properties, at least the.
00:05:27.012 - 00:05:29.188, Speaker E: Basic versions here is that you, you.
00:05:29.196 - 00:05:32.116, Speaker A: Know, having too much computation means you.
00:05:32.140 - 00:05:34.424, Speaker E: Can'T have that many matrix approximations.
00:05:35.484 - 00:05:39.028, Speaker B: Okay? So with that first property in hand.
00:05:39.076 - 00:05:42.264, Speaker E: Well, let's consider the second property.
00:05:45.084 - 00:05:47.064, Speaker A: So now if you have tensor products.
00:05:48.044 - 00:05:54.384, Speaker E: So two, if you have tensor product here, then this is less than or equal to zero.
00:05:54.784 - 00:05:56.884, Speaker A: And so here you could consider, well.
00:05:59.104 - 00:06:04.564, Speaker E: Let'S say let a subset m two be diffuse abelian.
00:06:09.864 - 00:06:12.368, Speaker A: So then if you consider m one.
00:06:12.416 - 00:06:26.144, Speaker B: Tensor a, right, this, the computant of this contains a, and so it's diffuse.
00:06:29.404 - 00:06:30.144, Speaker A: So.
00:06:33.164 - 00:06:38.584, Speaker B: H of m one tensor a.
00:06:39.564 - 00:06:43.104, Speaker E: Inside m one tensor m two is less than or equal to zero.
00:06:43.564 - 00:06:45.544, Speaker A: But then you also consider that.
00:06:46.144 - 00:06:50.524, Speaker E: Yeah, and then actually, maybe I say a two here.
00:06:50.904 - 00:06:51.288, Speaker D: Right?
00:06:51.336 - 00:06:53.616, Speaker A: And so then similarly, you can do.
00:06:53.640 - 00:06:57.864, Speaker E: The other way around. You can consider a one tensor.
00:06:57.944 - 00:07:01.248, Speaker A: You could consider a one inside m one, which is diffuse abelian.
00:07:01.296 - 00:07:11.846, Speaker E: And you can consider a one tensor m two, and this will be less than or equal to zero.
00:07:12.000 - 00:07:13.810, Speaker A: And then finally you say, well, oh.
00:07:13.842 - 00:07:24.898, Speaker B: Well, a one tensor m two intersect, m one tensor a two is diffuse, right?
00:07:24.946 - 00:07:44.624, Speaker E: Because this equals a one tensor a two. And so then you use the sub additivity property. And then it'll tell you the von Neumann algebra generated by both of these things together as h less than or equal to zero, which gives you what you want.
00:07:46.084 - 00:07:54.356, Speaker A: Okay, but then there's more you can do with this because, well, what if, what if you aren't simply studying a tensor product?
00:07:54.460 - 00:07:57.784, Speaker E: There's other situations where this could happen, such as graph product.
00:07:58.724 - 00:07:59.464, Speaker A: So.
00:08:15.224 - 00:08:23.928, Speaker E: So a bit about graph products. So in the group case, graph product.
00:08:24.096 - 00:08:26.048, Speaker A: Is sort of a mixture of free.
00:08:26.096 - 00:08:42.264, Speaker E: Product and cartesian product of groups. And so what does this mean? So you take a graph and you've got vertices and edges.
00:08:42.884 - 00:08:45.300, Speaker A: And so then, so the graph products.
00:08:45.452 - 00:08:53.424, Speaker E: Let'S call the graph gamma. The graph product over the vertices of the graph of groups would be.
00:08:55.724 - 00:08:56.036, Speaker D: You.
00:08:56.060 - 00:09:03.384, Speaker E: Take the free product of these groups and then you quotient by the relations.
00:09:03.844 - 00:09:14.944, Speaker B: That the copies of GV and GW commute if the vertices are adjacent.
00:09:16.124 - 00:09:18.676, Speaker A: And so when you take the graph product of groups, if you have two.
00:09:18.700 - 00:09:28.214, Speaker E: Vertices that are not adjacent, then those two groups are in free position. And then if they're, if the vertices are adjacent, then they're in a, a direct product position.
00:09:30.314 - 00:09:32.654, Speaker A: So the long history of this.
00:09:33.154 - 00:09:43.294, Speaker E: So this was defined by Edith Green. There's been also many papers analyzing the siesta algebra and von Neumann algebra analogs of this.
00:09:43.674 - 00:09:45.954, Speaker A: And so in particular, you can consider.
00:09:46.034 - 00:09:54.594, Speaker E: Graph product of von Neumann algebras with a state. Here we'll take a tracial state.
00:09:59.294 - 00:10:01.726, Speaker B: And in that case, I mean, you.
00:10:01.750 - 00:10:09.550, Speaker E: Have to specify what the state is. It gets a bit complicated, but in the group case, you know what it is.
00:10:09.742 - 00:10:15.274, Speaker A: Okay, so what you can say about these graph products.
00:10:17.114 - 00:10:27.854, Speaker E: So here's another proposition. So if gamma is a connected graph.
00:10:31.594 - 00:10:35.934, Speaker B: And if you choose.
00:10:37.874 - 00:10:39.414, Speaker A: Von Neumann algebras.
00:10:39.714 - 00:10:44.506, Speaker B: With tracial states for each vertex which.
00:10:44.530 - 00:10:45.574, Speaker E: Are diffuse.
00:10:48.314 - 00:10:49.694, Speaker B: Then the.
00:10:51.474 - 00:10:52.706, Speaker E: H of the.
00:10:52.730 - 00:10:53.654, Speaker A: Graph product.
00:10:56.434 - 00:10:58.414, Speaker B: Will be less than or equal to zero.
00:11:01.474 - 00:11:11.094, Speaker E: And the reasoning for this is sort of taking this idea here and using the sub additivity property and kind of chaining things together.
00:11:15.234 - 00:11:15.594, Speaker D: Yeah.
00:11:15.634 - 00:11:20.130, Speaker A: So by the way, this here proposition.
00:11:20.202 - 00:11:38.008, Speaker E: Here is in joint work with a bunch of people with me and Ben Hayes and Ian Charlesworth and Brent Nelson and Srivatesa can welcome Eli and Rolando de Santiago. And we have this six person project studying many properties of graph products.
00:11:38.146 - 00:11:40.984, Speaker A: And here's just one of them that basically.
00:11:44.084 - 00:11:47.064, Speaker E: Doesn'T have that many matrix approximations.
00:11:47.564 - 00:11:50.980, Speaker A: So earlier, Ian Charlesworth and Benoit Collins.
00:11:51.052 - 00:12:03.304, Speaker E: Gave a method of constructing random matrix models for these things. And it involved like looking at tensor products of several different things.
00:12:05.024 - 00:12:07.464, Speaker A: But in terms of comparing to the.
00:12:07.504 - 00:12:26.724, Speaker E: To the ambient matrix algebra, those things lived on like much lower dimensional spaces. And so they, the random matrix models there that despite having random matrix models, they don't give you an abundance of matrix approximations in the sense of this h because they're living in lower dimensional spaces. And.
00:12:27.264 - 00:12:29.638, Speaker A: Okay, well, let me prove this proposition.
00:12:29.816 - 00:12:33.174, Speaker E: So let's consider m to be this graph product.
00:12:43.674 - 00:12:47.414, Speaker B: Okay, and then let's consider.
00:12:51.114 - 00:12:57.126, Speaker E: Yeah, so then for each vertex we have. Okay, and then let's say for, let.
00:12:57.150 - 00:12:59.194, Speaker B: Me say this for, for.
00:13:02.494 - 00:13:03.206, Speaker D: W, which.
00:13:03.230 - 00:13:05.526, Speaker A: Is a subset of the vertex set.
00:13:05.710 - 00:13:16.754, Speaker E: Let mw be the fundamental immunologene by the things in this, in the set w, which is inside this.
00:13:17.774 - 00:13:18.742, Speaker B: So what we're going to do is.
00:13:18.758 - 00:13:22.624, Speaker A: A reason about, right, so our goal.
00:13:24.204 - 00:13:29.304, Speaker E: Is we're going to show that.
00:13:35.404 - 00:13:35.812, Speaker D: H.
00:13:35.868 - 00:13:37.864, Speaker B: Of mw.
00:13:39.724 - 00:13:44.464, Speaker E: In the presence of m equals zero, and we basically are going to do it by induction.
00:13:47.224 - 00:13:47.856, Speaker D: On the.
00:13:47.880 - 00:13:48.964, Speaker E: Size of the w.
00:13:52.264 - 00:13:53.344, Speaker D: So if you.
00:13:53.424 - 00:13:57.164, Speaker E: So starting with two things, right, so.
00:14:07.064 - 00:14:08.216, Speaker B: And here I guess we're going to.
00:14:08.240 - 00:14:14.188, Speaker E: Have w here connect. So if we start with just two.
00:14:14.236 - 00:14:25.464, Speaker B: Things, and if you have two things, right, then you have two vertices connected to each other. So that means.
00:14:28.044 - 00:14:29.564, Speaker A: That these two subalgebras.
00:14:29.604 - 00:14:32.348, Speaker E: Here form a tensor product inside of.
00:14:32.396 - 00:14:33.144, Speaker B: The m.
00:14:35.204 - 00:14:37.484, Speaker A: So this here is just.
00:14:37.524 - 00:14:42.874, Speaker E: Going to be mv one tensor mv two. And then that's going to be inside out.
00:14:43.414 - 00:14:45.390, Speaker A: And I just told you tensor products.
00:14:45.542 - 00:14:53.194, Speaker B: Has h less than or equal to zero, right? So, so this, this works.
00:14:56.334 - 00:15:00.110, Speaker A: And then, well, then you just want to go inductively.
00:15:00.302 - 00:15:09.964, Speaker E: And so, so we're going to add on one vertex at a time and just to make sure that you're adding on a vertex that's connected to the previous one.
00:15:10.544 - 00:15:13.444, Speaker B: So now take w.
00:15:16.504 - 00:15:18.520, Speaker A: Big w, say.
00:15:18.672 - 00:15:27.284, Speaker E: Union, some other vertex v, and then what? This v will be adjacent to some w that's in the original set w.
00:15:30.104 - 00:15:33.406, Speaker A: And so then we consider that by.
00:15:33.430 - 00:15:35.074, Speaker E: The induction hypothesis.
00:15:39.174 - 00:15:42.982, Speaker A: This is less than.
00:15:42.998 - 00:15:51.622, Speaker E: Or equal to zero. And then also if you were to take just these two vertices, this new vertex v that you're adding and the.
00:15:51.638 - 00:15:54.222, Speaker B: Vertex that it's adjacent to, you have.
00:15:54.238 - 00:15:58.154, Speaker E: A tensor product of those things. So this has entropy less than or equal to zero.
00:15:59.704 - 00:16:04.284, Speaker A: And then you consider, well, mw intersects.
00:16:04.744 - 00:16:06.124, Speaker E: This tensor product.
00:16:10.184 - 00:16:15.392, Speaker B: Is just going to be the algebra for that vertex, the.
00:16:15.408 - 00:16:21.840, Speaker E: Vertex that your new one is connected to. So I guess maybe for a picture, right, you have this w have this.
00:16:21.872 - 00:16:25.100, Speaker B: Lowercase w here and your new vertex.
00:16:25.132 - 00:16:26.188, Speaker E: That you're adding on.
00:16:26.316 - 00:16:28.116, Speaker A: And the intersection between the von Neumann.
00:16:28.140 - 00:16:34.864, Speaker E: Algebra is generated by these things. And this thing will be the von Neumann algebra that's assigned to that vertex there.
00:16:35.804 - 00:16:37.060, Speaker B: And that's diffuse.
00:16:37.172 - 00:16:39.076, Speaker E: So the intersection is diffuse.
00:16:39.220 - 00:16:41.436, Speaker A: We apply some additivity, and so we.
00:16:41.460 - 00:16:43.264, Speaker E: Get this as less than or equal to zero.
00:16:44.124 - 00:16:44.476, Speaker D: Yeah.
00:16:44.500 - 00:16:53.994, Speaker E: So by chaining together this properties, these properties with the commutants and normalizers and whatever, you can inductively show that these.
00:16:54.114 - 00:17:03.226, Speaker B: Centropy will be zero. Yeah, yeah.
00:17:03.250 - 00:17:04.354, Speaker A: So here, you know.
00:17:04.514 - 00:17:05.770, Speaker E: Yeah, as usual, right.
00:17:05.802 - 00:17:07.362, Speaker A: If you have something else that had.
00:17:07.378 - 00:17:10.402, Speaker B: A similar properties, then, you know, the.
00:17:10.418 - 00:17:11.814, Speaker E: Same arguments would work.
00:17:14.314 - 00:17:20.226, Speaker A: So that's what happens with graph products. These basically all have this one bounded.
00:17:20.250 - 00:17:23.362, Speaker B: Entropy zero, despite the fact that the.
00:17:23.378 - 00:17:27.694, Speaker E: Graph products might have many features in common with free group. With free products.
00:17:30.594 - 00:17:39.266, Speaker A: What happens though, if you take your graph products? If I assume, if I don't assume.
00:17:39.290 - 00:17:42.290, Speaker B: These are diffuse, for instance, what if.
00:17:42.362 - 00:17:46.054, Speaker E: I assume I took finite dimensional algebras on the individual vertices?
00:17:47.584 - 00:17:50.792, Speaker B: Then other things can happen, like if.
00:17:50.808 - 00:18:16.734, Speaker E: Your graph is a tree and you put a matrix algebra on each vertex. Then using the work of dicama on free products with amalgamation over finite dimensional things, you can show that this is going to produce an interpolated free group phenomenal algebra. This in particular will have h, which is infinite. So you can get this to be infinite for some cases when you have finite dimensional things on the vertices.
00:18:17.194 - 00:18:23.098, Speaker A: We don't fully understand under what circumstances this is true, but what we can.
00:18:23.146 - 00:18:28.374, Speaker B: Say is if, now let me erase this.
00:18:29.234 - 00:18:30.854, Speaker A: If you have a graph product.
00:18:34.234 - 00:18:56.254, Speaker B: And let's say no, for instance, mv finite dimensional. And so then if the first l two Betty number of the.
00:19:01.994 - 00:19:04.578, Speaker A: I don't know if you know about l two Betty numbers or not.
00:19:04.666 - 00:19:09.258, Speaker E: It's basically like thing for groups.
00:19:09.386 - 00:19:11.334, Speaker A: It generalizes the algebras.
00:19:11.754 - 00:19:14.034, Speaker E: And here I want to say the.
00:19:14.114 - 00:19:25.694, Speaker B: Betty number of the tracial star algebra graph product. If this is zero.
00:19:34.894 - 00:19:37.514, Speaker C: What'S the mean that v is equivalent to w?
00:19:38.254 - 00:19:42.606, Speaker E: I mean, that means adjacent in the graph. Adjacent.
00:19:42.710 - 00:19:45.286, Speaker B: Oh yeah.
00:19:45.350 - 00:19:46.034, Speaker E: Okay.
00:19:47.854 - 00:19:48.166, Speaker D: Yeah.
00:19:48.190 - 00:19:49.790, Speaker A: That's not an equivalence relation.
00:19:49.942 - 00:19:53.394, Speaker E: I'm sorry, I didn't invent this notation.
00:19:57.354 - 00:19:58.134, Speaker F: Relation.
00:20:00.514 - 00:20:13.146, Speaker A: Okay. Anyway, so this is irrelevant. Okay, this is irrelevant. Let's talk about the results. Well, I mean, your question, like clarifying.
00:20:13.210 - 00:20:17.706, Speaker E: Questions are fine, but of course we don't need to debate about notation.
00:20:17.770 - 00:20:18.974, Speaker A: It is what it is.
00:20:20.114 - 00:20:22.854, Speaker E: Anyway, so if the Betty number is zero.
00:20:23.614 - 00:20:27.190, Speaker B: Then also, in this case, the h.
00:20:27.222 - 00:20:27.914, Speaker E: Is zero.
00:20:32.374 - 00:20:34.074, Speaker B: Is less than or equal to zero.
00:20:35.494 - 00:20:39.110, Speaker A: So I'm not going to go into the proof of this because I want to get to some other stuff, but.
00:20:39.262 - 00:20:43.554, Speaker B: This is also a cool result it uses.
00:20:45.894 - 00:20:48.382, Speaker A: So one of the main ingredients is.
00:20:48.398 - 00:20:51.504, Speaker E: A result of slioktenko, which is in general.
00:20:56.444 - 00:20:57.084, Speaker A: Which is.
00:20:57.164 - 00:21:10.104, Speaker B: Which is proved that for groups. So if the first cell two ready number of a group is zero, then the group.
00:21:11.084 - 00:21:11.532, Speaker D: Yeah.
00:21:11.588 - 00:21:15.024, Speaker E: Then the group von ore and algebra.
00:21:15.664 - 00:21:16.136, Speaker D: Oh, yeah.
00:21:16.160 - 00:21:17.204, Speaker E: It's not actually.
00:21:17.584 - 00:21:19.032, Speaker A: I actually don't know that it's less.
00:21:19.048 - 00:21:20.032, Speaker E: Than or equal to zero, but I.
00:21:20.048 - 00:21:21.524, Speaker B: Know it's less than infinity.
00:21:26.944 - 00:21:32.804, Speaker C: Numbers are not invariants of reality. They're not known to be variance of the algebra.
00:21:34.784 - 00:21:36.800, Speaker A: They're not known to be van Neumann.
00:21:36.832 - 00:21:42.770, Speaker E: Algebra invariants, which is why I talked about the tracial star algebra.
00:21:42.922 - 00:21:43.786, Speaker D: What do you mean?
00:21:43.930 - 00:21:45.722, Speaker C: If you fix the trace, then they are.
00:21:45.818 - 00:21:46.454, Speaker E: No.
00:21:48.394 - 00:21:49.834, Speaker A: The key point here is I'm.
00:21:49.874 - 00:21:58.374, Speaker E: Not trying to take the von Neumann algebra. I'm not claiming that I have a von Neumann algebra cohomology. I'm just saying I take the star algebra generated by.
00:21:58.794 - 00:22:00.010, Speaker D: Oh, oh, okay.
00:22:00.042 - 00:22:03.074, Speaker A: Right. Okay, good. So without taking the completion.
00:22:03.234 - 00:22:05.202, Speaker B: And for that, it makes sense to.
00:22:05.218 - 00:22:06.754, Speaker E: Talk about l two Betty number.
00:22:06.914 - 00:22:09.026, Speaker A: So l two Betty numbers are algebra.
00:22:09.050 - 00:22:14.794, Speaker E: Invariant, but not von Neumann algebra. Anyway, though.
00:22:15.574 - 00:22:16.022, Speaker D: Yeah.
00:22:16.078 - 00:22:22.782, Speaker A: So such a result here uses the result of Sviaktenko. Well, Sri ak Tenko applied it to.
00:22:22.798 - 00:22:26.874, Speaker E: The group case, but basically the same machinery applies in a more general situation.
00:22:30.334 - 00:22:34.550, Speaker B: But the interesting part in our paper.
00:22:34.742 - 00:22:40.070, Speaker E: Is how to deal with sophisticity.
00:22:40.222 - 00:22:43.878, Speaker A: So Sriktenko's result uses sophisticity of the group to do this.
00:22:44.006 - 00:22:55.914, Speaker E: And so we had to come up with some sort of analog for algebras. And that, I think, can be its own talk. But no, this is just a. Yes, I just wanted to mention this here.
00:22:58.494 - 00:23:01.314, Speaker A: So it's another result about the h.
00:23:01.614 - 00:23:05.084, Speaker E: And another situation that we know is.
00:23:05.384 - 00:23:06.124, Speaker B: From.
00:23:07.824 - 00:23:16.856, Speaker E: Myself and Ben Hayes and three bots of Kuna. Welcome, Aliyamali, which, unfortunately, I will abbreviate.
00:23:17.040 - 00:23:21.632, Speaker B: And that is that if m is.
00:23:21.648 - 00:23:32.664, Speaker E: A two one factor with property t, then h is less than incident.
00:23:36.204 - 00:23:44.224, Speaker C: By the way, I'm sorry, I got him mixed up with, don't ask me why, with Caleb Eckert or k spelling.
00:23:45.964 - 00:23:47.144, Speaker B: Oh, okay.
00:23:47.604 - 00:23:48.252, Speaker D: Okay.
00:23:48.348 - 00:23:48.984, Speaker C: So.
00:23:51.484 - 00:24:00.342, Speaker A: Anyway, though. Yeah. So. So these two are two nontrivial results here. And so this result here, this first.
00:24:00.398 - 00:24:07.750, Speaker E: One, this also has, like, precursors in Zhang's work, and then say, I can't go prove this version.
00:24:07.902 - 00:24:10.194, Speaker A: Also, this one here about property t.
00:24:10.974 - 00:24:22.938, Speaker E: So, weaker statement saying that it had a free entropy dimension. At most one was proved by Zhang Angeliquenko. And so then we have gotten to guess the strongest version known so far.
00:24:23.106 - 00:24:24.450, Speaker A: That if you have property t, then.
00:24:24.482 - 00:24:26.534, Speaker E: H is less than infinite.
00:24:27.034 - 00:24:29.294, Speaker A: But in both of these instances here.
00:24:29.634 - 00:24:33.654, Speaker E: We don't necessarily know whether it's equal to zero or not.
00:24:34.154 - 00:24:37.242, Speaker A: So this is a potential case where.
00:24:37.378 - 00:24:42.454, Speaker E: Maybe there is something in here where it could be finite and positive, but we just don't know.
00:24:47.334 - 00:24:50.274, Speaker B: Yes, yes, yes.
00:24:51.174 - 00:24:51.526, Speaker D: Yeah.
00:24:51.550 - 00:24:52.942, Speaker A: So maybe it's, uh.
00:24:53.118 - 00:24:54.834, Speaker C: My thoughts are good at zero.
00:24:56.374 - 00:24:56.726, Speaker D: Yeah.
00:24:56.750 - 00:24:59.554, Speaker E: So maybe it's finite and non zero.
00:25:02.174 - 00:25:05.054, Speaker A: Because, you know, looking at these people.
00:25:05.094 - 00:25:12.314, Speaker E: Have tried, like, it doesn't seem like you can show that h equals to zero. Like, at least not. Not with any of those methods.
00:25:13.434 - 00:25:14.294, Speaker D: Okay.
00:25:17.114 - 00:25:30.530, Speaker F: Can you interpret the results? So you write these inequalities. So you have. So what does it. Like, what does it mean? So you're saying that. So, again, this inequality is, again, to me, very confusing because you're just telling me that it's not infinite.
00:25:30.602 - 00:25:31.214, Speaker E: Right?
00:25:32.274 - 00:25:33.082, Speaker D: So what.
00:25:33.178 - 00:25:38.694, Speaker F: So what's. What does that kind of. What does that tell me? What does it tell me about the algebra?
00:25:39.624 - 00:25:39.984, Speaker D: Yeah.
00:25:40.024 - 00:25:40.696, Speaker E: Okay, so.
00:25:40.760 - 00:25:43.164, Speaker A: So that's a good question. I think the most.
00:25:43.504 - 00:25:45.520, Speaker E: The most relevant information you can get.
00:25:45.552 - 00:25:46.824, Speaker A: Out of this is kind of the.
00:25:46.864 - 00:25:51.008, Speaker E: Interaction between things where it's infinite and the things where it's finite.
00:25:51.136 - 00:25:56.680, Speaker F: So, again, infinite. So if I take it. So you were saying that if I take a free product, I would get infinity.
00:25:56.752 - 00:25:57.056, Speaker E: Yeah.
00:25:57.120 - 00:25:57.728, Speaker D: Right.
00:25:57.896 - 00:26:03.120, Speaker F: If I have minus infinity, that corresponds to non common variable things.
00:26:03.312 - 00:26:03.784, Speaker D: Right?
00:26:03.864 - 00:26:04.456, Speaker E: Yeah.
00:26:04.600 - 00:26:09.124, Speaker F: And then zero maybe corresponds to something similar to amenability.
00:26:10.944 - 00:26:11.304, Speaker D: Yeah.
00:26:11.344 - 00:26:11.664, Speaker A: Not.
00:26:11.744 - 00:26:14.964, Speaker E: I mean, only in a very weak sense.
00:26:15.264 - 00:26:15.616, Speaker D: Yeah.
00:26:15.640 - 00:26:19.184, Speaker B: So, okay, so why do we care.
00:26:19.224 - 00:26:21.808, Speaker A: About showing is finite? That's maybe the question.
00:26:21.896 - 00:26:23.112, Speaker E: One question you want to address.
00:26:23.168 - 00:26:27.056, Speaker B: Okay, so it comes from, you know.
00:26:27.080 - 00:26:29.528, Speaker E: Playing off the infinite case versus the finite case.
00:26:29.656 - 00:26:32.496, Speaker A: So if you have. So, like I said, if you have.
00:26:32.520 - 00:26:36.084, Speaker E: Things with diffuse intersection, then you have sub additivity.
00:26:36.664 - 00:26:38.456, Speaker A: So, in particular, if you said, okay.
00:26:38.480 - 00:26:40.304, Speaker E: Well, as I said before, you can't.
00:26:40.344 - 00:26:42.776, Speaker A: Take a free group phenomenon, algebra, and.
00:26:42.800 - 00:26:56.644, Speaker E: Generate it with two amenable things that intersect diffusely. But now, the same is true for property t. You take property, two things with property t that intersect diffusely, then they have to generate something where h is finite. So they couldn't generate a free product, for instance.
00:26:58.124 - 00:26:58.628, Speaker D: Another.
00:26:58.716 - 00:26:59.344, Speaker A: Another.
00:27:00.484 - 00:27:01.292, Speaker B: Yeah.
00:27:01.468 - 00:27:06.556, Speaker A: And so, in a sense, so the overarching plot is.
00:27:06.660 - 00:27:07.036, Speaker B: Yeah.
00:27:07.100 - 00:27:11.244, Speaker E: Things where the h is infinite cannot be decomposed and built out of things.
00:27:11.284 - 00:27:14.944, Speaker B: Where the h is final using any of these operations.
00:27:16.884 - 00:27:18.316, Speaker A: And in terms of things where the.
00:27:18.340 - 00:27:21.876, Speaker B: H is infinite, free products are the.
00:27:21.900 - 00:27:22.940, Speaker E: Main example that we know.
00:27:22.972 - 00:27:26.592, Speaker A: But it's also true that, that, I.
00:27:26.608 - 00:27:31.524, Speaker E: Guess, with certain additional hypotheses. There's a sort of converse to this.
00:27:31.864 - 00:27:34.160, Speaker A: That if the first l two Betty.
00:27:34.192 - 00:27:37.304, Speaker E: Number is strictly positive, that corresponds to.
00:27:37.424 - 00:27:40.480, Speaker A: Some kind of co cycles existing. And if you get these co cycles.
00:27:40.512 - 00:27:58.204, Speaker E: To exist that actually take values in a group algebra instead of in the completion, then shliachenko has shown that then in that case, you can actually deduce that there will be generators with the free entropy dimension, which is bigger than one. And so the age is infinite.
00:27:59.224 - 00:28:02.168, Speaker A: Now, for many of these questions, you.
00:28:02.176 - 00:28:06.632, Speaker E: Could ask, are there any examples known that are conclusively not free products?
00:28:06.808 - 00:28:08.280, Speaker A: I mean, this is actually an open.
00:28:08.352 - 00:28:16.044, Speaker E: Question in the group literature. Like, if the first cell through Betty number is positive. And are there any examples where it's not a free product?
00:28:16.704 - 00:28:19.100, Speaker A: This is a big unknown, but certainly.
00:28:19.132 - 00:28:32.784, Speaker E: It'S, you know, there are other hypotheses that could be invoked other than simply being a free product, which would still get you h to be infinite, but a lot of them are things which are kind of a similar flavor to free products.
00:28:33.124 - 00:28:34.844, Speaker A: I mean, you can also take free.
00:28:34.884 - 00:28:40.224, Speaker E: Products with amalgamation over something amenable, and that works just as well as a plain free product.
00:28:40.924 - 00:28:41.744, Speaker D: Yeah.
00:28:44.104 - 00:28:45.524, Speaker B: Okay, so.
00:28:47.744 - 00:28:56.684, Speaker E: I have maybe, like 15 minutes left. The other main thing I wanted to get to was getting somehow into what's the actual definition of the stage.
00:28:57.544 - 00:28:58.284, Speaker A: So.
00:29:00.024 - 00:29:03.564, Speaker E: Let me erase some space and start up.
00:29:18.164 - 00:29:21.460, Speaker A: Okay, so, as mentioned before, we have.
00:29:21.492 - 00:29:23.476, Speaker E: This space of laws for D. Tubles.
00:29:23.540 - 00:29:28.304, Speaker B: Okay, so space of non commutative loss.
00:29:35.004 - 00:29:45.464, Speaker E: And so then if you had so. And then a given such a law, you all, you could consider neighborhoods, right? You could consider.
00:29:49.004 - 00:29:50.984, Speaker B: O, which is a.
00:29:51.324 - 00:29:58.260, Speaker E: Neighborhood in the space. And then you can define your microstate space.
00:29:58.332 - 00:30:10.112, Speaker B: So gamma n of o is a tuples in matrices. So alpha joint to the d such.
00:30:10.168 - 00:30:14.844, Speaker E: That their non commutative distribution is in the neighborhood o.
00:30:16.504 - 00:30:24.240, Speaker B: Okay, so then when we define this h, the h for the, say x.
00:30:24.272 - 00:30:47.224, Speaker E: One through xd, you want to take a. You take this space right over here. Then you want to consider a covering number of it. So we consider a covering number.
00:30:55.024 - 00:30:55.360, Speaker D: With.
00:30:55.392 - 00:30:59.844, Speaker E: Respect to the two norm, right, the l two norm corresponding to the trace.
00:31:01.624 - 00:31:04.608, Speaker A: And when you take the covering number, right, it's a.
00:31:04.776 - 00:31:08.672, Speaker E: You want to consider an epsilon covering number for a certain radius epsilon so.
00:31:08.688 - 00:31:10.592, Speaker A: You figure out how many epsilon balls.
00:31:10.608 - 00:31:11.604, Speaker E: Do you need to cover?
00:31:12.584 - 00:31:14.696, Speaker A: But then, as I mentioned before, we.
00:31:14.720 - 00:31:22.164, Speaker E: Only, if two things are conjugate by a fixed unitary, by a single unitary, then we consider them to be the same.
00:31:22.464 - 00:31:27.044, Speaker A: So then this here is orbital, meaning.
00:31:27.904 - 00:31:42.824, Speaker E: This is considered modulo unitary conjugation. So that's the covering number that we consider.
00:31:42.904 - 00:31:46.716, Speaker B: Well, then we consider logarithm of it.
00:31:46.740 - 00:31:50.904, Speaker E: And one over n squared. And then the soup as n goes to infinity.
00:31:53.044 - 00:31:54.544, Speaker C: Why is it n squared?
00:31:55.284 - 00:31:57.876, Speaker A: Yeah, so n squared has to do.
00:31:57.900 - 00:32:01.484, Speaker E: With the fact that the dimension of this space is d times n squared.
00:32:01.564 - 00:32:01.756, Speaker D: Right?
00:32:01.780 - 00:32:06.904, Speaker E: So the n by n matrix is n squared dimensional. And so this is the natural choice of the normalization.
00:32:08.804 - 00:32:11.506, Speaker A: Okay, so we have that.
00:32:11.700 - 00:32:25.794, Speaker E: And then, just as in the definition of the free entropy, you take the infamum over the neighborhood's o. But then there's another parameter here, which is this epsilon. So at the end, you take the soup over epsilon, like so.
00:32:27.974 - 00:32:28.446, Speaker D: And there's.
00:32:28.470 - 00:32:31.678, Speaker A: Various nice monotonicity properties of this that.
00:32:31.726 - 00:32:36.794, Speaker E: For instance, you know, if you make your epsilon smaller than the covering number, can only get larger.
00:32:37.314 - 00:32:39.266, Speaker A: So taking the soup over epsilon is.
00:32:39.290 - 00:32:41.974, Speaker E: The same as taking the limit as epsilon goes to zero.
00:32:43.394 - 00:32:45.854, Speaker C: Is this related to degree or not?
00:32:47.514 - 00:32:48.334, Speaker B: Hmm.
00:32:53.554 - 00:32:54.210, Speaker E: Covering.
00:32:54.282 - 00:32:55.786, Speaker A: No, I mean, this is not, this.
00:32:55.810 - 00:33:00.938, Speaker E: Is not like a covering map in topology, right? This is like, how many things do you need to cover the set?
00:33:00.986 - 00:33:03.214, Speaker C: Okay, covering dimensional.
00:33:04.124 - 00:33:07.348, Speaker A: Yeah, yeah, yeah. I mean, covering dimension is based on.
00:33:07.396 - 00:33:09.304, Speaker E: Such covering like this.
00:33:11.324 - 00:33:11.972, Speaker D: But here, I.
00:33:11.988 - 00:33:14.332, Speaker E: Mean, I don't care about the overlap.
00:33:14.508 - 00:33:18.756, Speaker F: Well, okay, is it like a covering dimension or is it like a volume?
00:33:18.940 - 00:33:19.356, Speaker D: No.
00:33:19.420 - 00:33:21.540, Speaker E: So it's just a covering number.
00:33:21.692 - 00:33:22.052, Speaker D: Right.
00:33:22.108 - 00:33:35.144, Speaker E: So covering dimension would be like if I were to consider like how many of these balls overlap each other, right? But here, I'm not considering any of that. I'm just saying how many balls do you need?
00:33:37.084 - 00:33:38.944, Speaker B: It's not the same as volume.
00:33:42.844 - 00:33:44.852, Speaker E: You could bound it above and below.
00:33:44.908 - 00:33:49.676, Speaker B: By the volume, but this is, it.
00:33:49.700 - 00:33:51.940, Speaker E: Ultimately gives you a different quantity, because.
00:33:51.972 - 00:33:53.028, Speaker A: If you only were to look at.
00:33:53.036 - 00:33:54.264, Speaker B: The volume of it.
00:33:55.164 - 00:33:57.172, Speaker A: So if you took the volume and.
00:33:57.228 - 00:34:03.714, Speaker E: Divided by log, epsilon or something, then this might be kind of comparable to that.
00:34:04.174 - 00:34:05.622, Speaker A: But when you take the limits, it.
00:34:05.638 - 00:34:18.246, Speaker E: Doesn'T give you the same answer. So this doesn't give you the same answer as like such volume limits, which is, which are like the definition of free entropy, dimension. This is like a different quantity, but.
00:34:18.350 - 00:34:20.166, Speaker A: It'S not, you know, it's not a.
00:34:20.190 - 00:34:29.373, Speaker E: Covering dimension per se because you're not considering overlaps. Yeah, something Lebaig number for a cover.
00:34:35.153 - 00:34:36.009, Speaker B: Yeah.
00:34:36.201 - 00:34:39.513, Speaker A: Anyway, so this. So, I mean, it's kind of similar.
00:34:39.593 - 00:34:44.369, Speaker E: To what happens in looking at dynamical entropy or sophic entropy, because.
00:34:44.521 - 00:34:47.905, Speaker B: So, yeah, so, so say when you're.
00:34:47.929 - 00:34:54.504, Speaker E: Studying, for instance, topological. Okay, here's another analogy, right? Which is top topological entropy. So topological entropy of an action.
00:34:54.664 - 00:34:55.800, Speaker A: And when you do that, what you're.
00:34:55.832 - 00:34:58.840, Speaker B: Looking at is you look at basically.
00:34:58.912 - 00:35:04.604, Speaker E: How many, like, orbits of length n you can distinguish up to epsilon.
00:35:05.224 - 00:35:09.144, Speaker A: And so in this case, instead of saying you look at orbit of length.
00:35:09.184 - 00:35:10.336, Speaker E: N, you say you look at n.
00:35:10.360 - 00:35:13.648, Speaker B: By n matrix approximation, but it's still.
00:35:13.696 - 00:35:18.404, Speaker E: Like, for each n, you're looking at somehow how many epsilon separated things there are.
00:35:19.424 - 00:35:20.936, Speaker A: So that's one way you can think.
00:35:20.960 - 00:35:29.964, Speaker E: Of it as kind of similar to topological entropy. And then if you look at the case of, like, dynamical entropy and sophic entropy, there's connections you can make there as well.
00:35:31.904 - 00:35:32.624, Speaker D: Right?
00:35:32.784 - 00:35:33.192, Speaker E: Yeah.
00:35:33.248 - 00:35:35.472, Speaker A: So that's. Those are all good points of, like.
00:35:35.528 - 00:35:39.004, Speaker E: How to think about this intuitively, like, what kind of object it is.
00:35:39.344 - 00:35:43.224, Speaker A: And the question, you know, that you brought up of, well, what if you.
00:35:43.264 - 00:35:45.810, Speaker E: Actually try to do a covering dimension.
00:35:45.842 - 00:35:48.186, Speaker B: Of this instead of just looking at.
00:35:48.210 - 00:35:49.490, Speaker E: How many balls you need?
00:35:49.642 - 00:35:51.154, Speaker A: I mean, that could be a useful.
00:35:51.194 - 00:35:55.614, Speaker E: Quantity that could be useful for studying various things like this.
00:35:56.034 - 00:36:00.866, Speaker A: So it's definitely a good question to investigate. But at the moment here, this is.
00:36:00.890 - 00:36:09.934, Speaker E: Simply, how many balls do you need to cover it? Like you have a question.
00:36:10.774 - 00:36:12.274, Speaker A: So this is specific value.
00:36:13.454 - 00:36:14.758, Speaker D: Yeah, yeah.
00:36:14.806 - 00:36:15.966, Speaker A: And so that's the theorem, right?
00:36:15.990 - 00:36:17.878, Speaker E: That if you have two different generating.
00:36:17.926 - 00:36:19.674, Speaker B: Sets, that you get the same answer.
00:36:20.614 - 00:36:22.934, Speaker E: Now, I should also tell you what.
00:36:22.974 - 00:36:38.994, Speaker B: Happens when you do it in the presence. Okay, so there's several.
00:36:39.114 - 00:36:40.294, Speaker E: I guess there's several.
00:36:40.794 - 00:36:43.122, Speaker A: You know, there's several versions of the definition.
00:36:43.178 - 00:36:50.626, Speaker E: And I presented you the simplest case first, right? We have a finite generating set, and you don't worry about it being in the presence of a larger algebra.
00:36:50.770 - 00:36:51.106, Speaker D: Okay?
00:36:51.130 - 00:36:55.154, Speaker E: But now let me consider this, right? So let's consider a to X, one.
00:36:55.194 - 00:37:02.754, Speaker B: Through XD, and, I don't know, in the presence of Y, one through yknow.
00:37:03.964 - 00:37:11.332, Speaker A: So what do you do in this case? Well, here, then, what you want to consider is you consider O, which is.
00:37:11.348 - 00:37:17.864, Speaker E: A neighborhood of the joint distribution of the X's and the Y's.
00:37:24.364 - 00:37:26.188, Speaker A: And so then you consider your microstate.
00:37:26.236 - 00:37:31.274, Speaker E: Space for that, for the joint tuples X and Y.
00:37:31.774 - 00:37:35.574, Speaker A: But what we measure is just how.
00:37:35.614 - 00:37:39.870, Speaker E: Many different values of x you get, not how many different values of Y.
00:37:40.022 - 00:37:41.614, Speaker A: So you want to take this thing.
00:37:41.734 - 00:37:45.034, Speaker E: And then you want to project it onto the x coordinates.
00:37:47.494 - 00:37:48.142, Speaker D: And then you.
00:37:48.158 - 00:37:49.474, Speaker E: Take your covering number.
00:37:52.134 - 00:37:52.806, Speaker D: And then you.
00:37:52.830 - 00:37:56.734, Speaker E: Take your logarithms and limits.
00:38:09.754 - 00:38:10.178, Speaker D: Yeah.
00:38:10.226 - 00:38:20.894, Speaker E: So this here represents, okay, this represents matrix approximations for x, which came from this space here where you consider joint approximations of x and y.
00:38:21.414 - 00:38:23.494, Speaker A: And so this is exactly, you know.
00:38:23.534 - 00:38:35.834, Speaker E: Matrix approximations for x such that there exists an extension to a matrix approximation for y. And so this is how you define this entropy of this thing in the presence of this.
00:38:37.974 - 00:38:39.766, Speaker A: So another wrinkle, there's another wrinkle in.
00:38:39.790 - 00:39:07.310, Speaker E: Here, which is what if you do infinite tuple instead of finite tuple? And I don't have time to go into detail on this, but it works out just fine. Basically, now, instead of just picking an epsilon to do covering numbers, when you have your infinite tuple, first you pick finitely many coordinates and then measure an epsilon of error in those finitely many coordinates. And so then you're replacing your parameter epsilon by the choice of a finite.
00:39:07.342 - 00:39:09.114, Speaker B: Set of coordinates in an epsilon.
00:39:09.734 - 00:39:16.314, Speaker E: And you do that, and then everything still goes through. Definition still makes sense, and the proofs work in that sense.
00:39:17.104 - 00:39:23.896, Speaker A: But let me stick with the finite case for now. So now I want to wrap up.
00:39:23.920 - 00:39:25.920, Speaker E: By giving a hint of, like, why.
00:39:26.072 - 00:39:27.924, Speaker B: This is actually an invariant.
00:39:30.664 - 00:39:31.168, Speaker D: Okay.
00:39:31.216 - 00:39:31.804, Speaker E: So.
00:39:38.104 - 00:39:39.440, Speaker A: And in fact, I mean, you could.
00:39:39.472 - 00:39:45.524, Speaker E: Consider showing that it's an invariant and also showing the monotonicity properties at the same time.
00:39:48.144 - 00:39:50.864, Speaker B: So for the invariants and then, and.
00:39:50.904 - 00:39:52.896, Speaker E: The monotonicity properties, you would want to.
00:39:52.920 - 00:40:03.080, Speaker B: Show a statement like this that. So if you have a w star.
00:40:03.112 - 00:40:05.296, Speaker E: Of x contained inside w star of.
00:40:05.320 - 00:40:09.178, Speaker B: X prime and a w star of.
00:40:09.376 - 00:40:13.314, Speaker E: X prime and Y prime contained inside w star of Xy.
00:40:16.334 - 00:40:21.878, Speaker D: Then this is.
00:40:21.926 - 00:40:30.502, Speaker E: Less than or equal to this. So here, the x Y and x prime and y prime are all tuples. They can each have different numbers of.
00:40:30.638 - 00:40:31.994, Speaker B: Elements in the tuple.
00:40:33.374 - 00:40:36.378, Speaker A: This one here, this shows the monotonicity.
00:40:36.426 - 00:40:47.738, Speaker E: Property and the invariance at the same time. Because if these are equal to each other, then you get the inequality in both directions. You get the invariance. But then here, this is generally saying.
00:40:47.906 - 00:40:49.354, Speaker A: This is contained to this.
00:40:49.514 - 00:40:53.346, Speaker B: So this is where you take the.
00:40:53.370 - 00:41:03.364, Speaker E: First subalgebra and enlarge it. And then here you take the second subalgebra and you shrink it. So this is, this would contain all of them at once.
00:41:03.904 - 00:41:11.804, Speaker A: And then the idea here for proving this is essentially, you want to take microstate spaces.
00:41:13.464 - 00:41:13.880, Speaker D: Yeah.
00:41:13.912 - 00:41:17.524, Speaker E: So then, so the idea here is basically like a.
00:41:19.264 - 00:41:21.104, Speaker B: Okay, first of all.
00:41:21.144 - 00:41:22.284, Speaker E: You take x.
00:41:26.084 - 00:41:26.996, Speaker A: X is like a.
00:41:27.020 - 00:41:29.344, Speaker E: Function of x prime for some f.
00:41:30.924 - 00:41:32.300, Speaker B: And I have to make sense of.
00:41:32.332 - 00:41:33.876, Speaker E: What such an f would be.
00:41:34.020 - 00:41:36.436, Speaker A: But so if f was a polynomial.
00:41:36.540 - 00:41:45.864, Speaker E: I mean, this kind of would make sense. Now, if x was actually in the algebra generated by x prime, then you could take f to be a polynomial and so forth.
00:41:47.044 - 00:41:50.500, Speaker A: But the way that I do this.
00:41:50.532 - 00:41:56.284, Speaker E: Is by using a more general type of function, which is some kind of completion of space of polynomials, which is.
00:41:56.324 - 00:41:58.660, Speaker A: Actually a very nice space because it.
00:41:58.692 - 00:42:03.068, Speaker E: Enables you to express anything in the von Neumann algebra as a function of the generators.
00:42:03.196 - 00:42:05.188, Speaker A: And then this function itself is something.
00:42:05.236 - 00:42:09.504, Speaker E: That makes sense to evaluate on any tuples from any tracial von Leibn algebra.
00:42:12.204 - 00:42:30.334, Speaker A: But I don't have time to go into that in more detail. But then the idea here is that then you want to take the f, you want to take your function, and then you want to take like a microstate space.
00:42:30.754 - 00:42:38.242, Speaker E: Or here I want to take a microstate space for the o prime, and then I'm taking the projection onto the x's.
00:42:38.418 - 00:42:42.034, Speaker A: And then I want to take this f and apply it to this microstate.
00:42:42.074 - 00:42:56.664, Speaker E: Space, and then map this into the microstate space for the x. So this one here is for x in the presence of y, and this one here is for the x prime.
00:42:57.404 - 00:42:58.984, Speaker B: The presence of y prime.
00:42:59.644 - 00:43:02.428, Speaker A: So if you have can express your x as a function of x prime.
00:43:02.476 - 00:43:03.580, Speaker E: Like this, then you could take that.
00:43:03.612 - 00:43:05.220, Speaker A: Same function and apply it to all.
00:43:05.252 - 00:43:06.864, Speaker E: The matrix tuples in here.
00:43:07.164 - 00:43:08.876, Speaker A: And so you're taking this function and.
00:43:08.900 - 00:43:10.824, Speaker E: Using it to transform this set.
00:43:11.744 - 00:43:17.480, Speaker A: And then there's basically two parts to the argument. One is to show that, like the.
00:43:17.632 - 00:43:26.244, Speaker E: Image of this transformation, the image of this thing is approximately contains this.
00:43:26.864 - 00:43:28.416, Speaker A: And then the other part is to.
00:43:28.440 - 00:43:43.044, Speaker E: Show that you can cover the image, you know, by, you can pick some bulb and then use, apply f to the center points and get poles that cover the image.
00:43:44.544 - 00:43:50.964, Speaker B: So, well, I'll just kind of sketch this here.
00:43:56.744 - 00:44:16.514, Speaker E: So it's kind of two, then two parts. So the point is, okay, so f is the f that I create is uniformly continuous with respect to two norm.
00:44:20.134 - 00:44:21.414, Speaker A: And so then if you have some.
00:44:21.454 - 00:44:24.830, Speaker E: Statement here like a minus b less.
00:44:24.862 - 00:44:33.534, Speaker B: Than delta implies in two, norm implies f of a minus f of b less than epsilon.
00:44:34.314 - 00:44:36.734, Speaker A: Then this would say that something like.
00:44:37.594 - 00:44:59.334, Speaker E: That, if you have a delta covering of your microstate space for x prime, then you get an epsilon covering of.
00:45:00.554 - 00:45:02.170, Speaker A: You know, by applying the function f.
00:45:02.202 - 00:45:04.134, Speaker E: You get an epsilon covering of.
00:45:06.954 - 00:45:07.242, Speaker D: The.
00:45:07.258 - 00:45:11.794, Speaker E: Microstate space for x. Sorry, sorry.
00:45:11.834 - 00:45:13.626, Speaker A: An epsilon covering of the image of.
00:45:13.650 - 00:45:16.614, Speaker E: This, you get an epsilon covering of the image.
00:45:22.774 - 00:45:25.834, Speaker B: So that's one part.
00:45:27.454 - 00:45:32.886, Speaker A: And you can basically do this using the uniform continuity. And then the other part is to.
00:45:32.910 - 00:45:49.256, Speaker B: Show that the microstate states for x is contained inside the neighborhood of, you.
00:45:49.280 - 00:45:56.760, Speaker E: Know, some, you know, say, I don't know, you do. You do like some epsilon over two or something, and you say you want.
00:45:56.792 - 00:45:58.968, Speaker A: This to be in the neighborhood of.
00:45:59.016 - 00:46:00.924, Speaker E: The image of the other one.
00:46:07.424 - 00:46:12.764, Speaker A: And so how do you achieve that? Well, you need to know that. So basically you want to show that everything.
00:46:14.654 - 00:46:19.766, Speaker E: Everything, which is a microstate space, which is a matrix approximation for x.
00:46:19.870 - 00:46:23.074, Speaker B: In the presence of y, is close.
00:46:23.854 - 00:46:30.714, Speaker E: To f of something. Right. So the idea, okay, so the matrix approximation.
00:46:33.254 - 00:46:40.344, Speaker B: For x in the presence of y is close to some.
00:46:42.044 - 00:46:42.492, Speaker D: F of.
00:46:42.508 - 00:46:47.884, Speaker B: X, maybe alpha x n prime, where.
00:46:47.924 - 00:46:51.104, Speaker E: This thing here is a matrix approximation.
00:46:52.164 - 00:46:52.904, Speaker D: For.
00:46:56.924 - 00:46:59.344, Speaker E: X prime in the presence of y prime.
00:47:00.924 - 00:47:02.784, Speaker A: How do we know that? Well.
00:47:17.784 - 00:47:21.608, Speaker B: Okay, so how do, how do we achieve that?
00:47:21.656 - 00:47:21.944, Speaker A: Yeah.
00:47:21.984 - 00:47:29.088, Speaker E: That the matrix approximations here are approximately close to f of some matrix approximation for the other.
00:47:29.256 - 00:47:33.484, Speaker B: Well, here we now use the fact.
00:47:33.564 - 00:47:44.944, Speaker E: That x prime and y prime can be expressed as a function of x and y.
00:47:57.024 - 00:47:58.200, Speaker A: So this is true.
00:47:58.352 - 00:48:12.684, Speaker E: You can choose this for some g. And so in particular, right, then x would be f of x prime, which would be f of the projection onto the first coordinates of g of x y.
00:48:14.704 - 00:48:15.444, Speaker D: And.
00:48:18.144 - 00:48:21.804, Speaker E: You can choose your neighborhood o small enough.
00:48:26.514 - 00:48:32.410, Speaker B: That this kind of f composed with PI, x prime composed with.
00:48:32.442 - 00:48:33.014, Speaker A: G.
00:48:35.914 - 00:48:38.450, Speaker E: Is kind of close to maybe.
00:48:38.482 - 00:48:41.854, Speaker B: If y is close to x.
00:48:45.554 - 00:48:50.464, Speaker A: And so then when you do this, then you're going to say that, well.
00:48:51.404 - 00:49:01.704, Speaker B: Your matrix approximation for x is going to be close to f composed with g of itself.
00:49:02.844 - 00:49:05.236, Speaker A: And g of that thing is going.
00:49:05.260 - 00:49:08.908, Speaker B: To be one of these matrix approximations.
00:49:08.996 - 00:49:10.984, Speaker E: For the x prime and y prime.
00:49:12.484 - 00:49:14.012, Speaker A: So this is how you guarantee that.
00:49:14.068 - 00:49:33.116, Speaker E: Actually taking this function and take up and kind of apply, taking the image of this other microstate space, actually gets you everything in the first microstate space up to some epsilon over two error. So maybe this is a rough sketch, but hopefully you get the idea of.
00:49:33.140 - 00:49:35.664, Speaker B: This, of kind of, you know, how.
00:49:36.244 - 00:49:46.124, Speaker E: Having functions that have nice properties like this uniform continuity, gives you a nice way to transform, kind of change coordinates in your generators. And this in turn gets you these.
00:49:46.164 - 00:49:50.620, Speaker B: Invariance properties for this h. So this.
00:49:50.652 - 00:50:29.112, Speaker E: Type of function, it's a nice space that you construct, and it actually has a lot, a lot to do with tracial completions of sea star algebra. So the construction of this kind of, in a sense, can be realized as an example of a tracial completion. So the idea here is just, you know, you want to take not just non commutative polynomials, but you want to take a completion of them, and you want it to be flexible enough that it actually will give you, you know, you're taking a completion with respect to a limit and two norm, but then you do it uniformly over the different non commutative laws.
00:50:29.248 - 00:50:33.576, Speaker A: But then you also allow scalar valued.
00:50:33.600 - 00:50:43.044, Speaker E: Coefficients of your functions that kind of depend on the non commutative law, which enables you to break down, you know, kind of isolate parts of the space of non commutative loss.
00:50:43.704 - 00:50:51.640, Speaker A: So anyway, there's a complicated whole construction of those functions. But the utility of these functions is exactly that.
00:50:51.792 - 00:51:16.524, Speaker E: It has all these nice properties like continuity, ML two continuity with respect to, you know, of the law of f, of x depends continuously on the law of x. And other properties like this. These properties tell you, enable you to do things with this h. So I will end it there. You're welcome to ask more detail and talk with me later about it.
00:51:24.864 - 00:51:31.380, Speaker B: So, let's see. So this, so this proof itself has.
00:51:31.412 - 00:51:37.700, Speaker A: Not been published yet, but the types of functions that are being used, and.
00:51:37.812 - 00:51:42.692, Speaker E: Another application of a kind of showing some, some property is invariant.
00:51:42.868 - 00:51:46.664, Speaker B: This is in the paper with.
00:51:48.564 - 00:51:49.348, Speaker D: Hayes.
00:51:49.476 - 00:51:56.504, Speaker E: And myself and Brent Nelson and Thomas Sinclair, which is on the called a.
00:51:58.064 - 00:51:58.964, Speaker A: Random.
00:52:00.824 - 00:52:02.724, Speaker E: Random matrix approach.
00:52:10.224 - 00:52:15.044, Speaker B: To absorption in three products.
00:52:17.024 - 00:52:24.540, Speaker A: So this absorption in this paper is like the idea of absorbing amenability, right?
00:52:24.572 - 00:52:32.284, Speaker E: So we talk about certain subalgebras now. So inside of. So, so I guess the main result.
00:52:32.444 - 00:52:36.372, Speaker B: Is, well, I guess it's a result.
00:52:36.428 - 00:52:42.228, Speaker E: That has been known before, but we give a different proof of it. It's essentially if you have a free.
00:52:42.276 - 00:52:45.852, Speaker B: Product and you have something which is.
00:52:45.868 - 00:52:53.358, Speaker E: Amenable and intersects one of the things, the free products, diffusely, then it actually is forced to be contained in there. So it's absorbed.
00:52:53.526 - 00:52:56.118, Speaker A: Yeah. So we give an argument for this.
00:52:56.166 - 00:53:01.074, Speaker E: Which is based on the one bounded entropy and based on other aspects of random matrix.
00:53:06.174 - 00:53:06.982, Speaker A: Absorption.
00:53:07.038 - 00:53:12.894, Speaker E: Yes, absorption in the sense of if it intersects diffusely, then it's forced to be contained inside.

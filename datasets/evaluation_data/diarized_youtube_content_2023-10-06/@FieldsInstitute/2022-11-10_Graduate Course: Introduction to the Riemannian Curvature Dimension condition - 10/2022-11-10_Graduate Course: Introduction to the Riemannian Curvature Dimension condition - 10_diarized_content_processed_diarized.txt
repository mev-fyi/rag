00:00:01.760 - 00:00:17.398, Speaker A: On, well, not easy, but certainly more classical tools in convex analysis and in Hilbert space analysis, namely the existence and uniqueness of gradient flows of convex functions on Hilbert spaces. So the theorem for us is the following.
00:00:17.566 - 00:00:20.674, Speaker B: For every f in l two.
00:00:22.654 - 00:00:23.014, Speaker C: There.
00:00:23.054 - 00:00:32.290, Speaker A: Exists a unique curve with radius in l two, which is, you know, continuous.
00:00:32.402 - 00:00:38.234, Speaker B: On the whole half line and absolutely.
00:00:38.274 - 00:00:43.210, Speaker A: Continues in the open half line. So a priori, one might lose absolute.
00:00:43.242 - 00:00:47.962, Speaker B: Continuity in zero such that, well, f.
00:00:48.098 - 00:00:51.046, Speaker A: Times zero is our given initial datum.
00:00:51.210 - 00:00:55.086, Speaker B: And dt of ft is equal to.
00:00:55.110 - 00:00:58.074, Speaker A: The Laplacian of ft for almost everything.
00:01:02.454 - 00:01:03.150, Speaker C: Right?
00:01:03.302 - 00:01:05.194, Speaker A: And in fact, we have seen that.
00:01:05.534 - 00:01:09.194, Speaker B: For every t positive, moreover.
00:01:11.614 - 00:01:12.110, Speaker C: For every.
00:01:12.142 - 00:01:15.726, Speaker B: T positive, the limit as h goes.
00:01:15.750 - 00:01:32.000, Speaker A: To zero from above of f t plus h minus ft divided by h equals exactly the Laplacian over the tangent, right? So I can get an improvement from almost every, to every provider, take the right derived derivative.
00:01:32.112 - 00:01:39.128, Speaker B: All right, very well. Now let me, let me start collecting.
00:01:39.176 - 00:01:52.494, Speaker A: A couple of easy to prove properties of this, okay? Of course, I'm very tempted to call this the heat flow, right? What else? But I already called the heat flow the other guy. So for the moment, I will resist this temptation. The gradient flow of the, of the relative entropy.
00:01:52.614 - 00:01:55.342, Speaker B: Let me just list a couple of.
00:01:55.358 - 00:02:01.834, Speaker A: Properties for, you know, ft as above.
00:02:05.694 - 00:02:17.702, Speaker B: We have. So first of all, well, actually, let.
00:02:17.718 - 00:02:21.834, Speaker A: Me, let me assume, let me assume, let me assume, for simplicity, assume.
00:02:24.374 - 00:02:24.710, Speaker C: That.
00:02:24.742 - 00:02:29.150, Speaker A: Our metric measure space. Let me exaggerate with the assumption is.
00:02:29.182 - 00:02:33.230, Speaker B: So that the reference measure m not.
00:02:33.262 - 00:02:38.702, Speaker A: Only is probability, but it's a probability measure. We find a second moment, if you wish, x is copied.
00:02:38.838 - 00:02:39.634, Speaker B: Okay.
00:02:41.694 - 00:02:52.534, Speaker A: Then, for this and a flow of t or a curve ft, as in this previous statement, we have. So, first of all, you know, mass.
00:02:52.574 - 00:02:53.474, Speaker B: Preservation.
00:02:59.774 - 00:03:22.094, Speaker A: That is to say, the integral of ftdm is the same as the integral of the original FDM for everything. This makes sense, of course, because m is probability measure. So, a function which is in l two results in l one, and the interval is by defined weak maximum principle.
00:03:27.754 - 00:03:37.464, Speaker B: So if f is greater or equal than some constant or less or equal than some constant, then.
00:03:39.524 - 00:03:44.196, Speaker A: Ft is greater or equal than the same constant, less or equal than the big constant.
00:03:44.340 - 00:03:53.916, Speaker B: For every t, positive and almost negative upper and lower bounds, either taken alone.
00:03:54.060 - 00:03:57.424, Speaker A: Or jointly, they are preserved along this block.
00:03:58.824 - 00:03:59.576, Speaker C: All right.
00:03:59.720 - 00:04:00.844, Speaker A: And finally.
00:04:03.304 - 00:04:06.136, Speaker B: Three entropy.
00:04:06.160 - 00:04:22.592, Speaker A: This equation, let's say, let's say that. Let's say that f, the original f.
00:04:22.728 - 00:04:25.444, Speaker B: As you know, is bounded.
00:04:28.464 - 00:04:29.056, Speaker C: And let.
00:04:29.120 - 00:04:32.168, Speaker A: U be a function from c capital.
00:04:32.256 - 00:04:41.644, Speaker B: C to r. Let's say smooth, smooth, convex, convex.
00:04:42.384 - 00:04:50.192, Speaker A: Just move. Okay, then I take the map that takes t and returns the interval of.
00:04:50.208 - 00:04:53.702, Speaker B: U of f t. The m. This.
00:04:53.758 - 00:05:04.314, Speaker A: Is, you know, continuous in zero plus infinity, absolutely continuous. On the open half line with derivative.
00:05:12.174 - 00:05:38.884, Speaker B: This is equal to minus new second DfT scored relaxed gradient. All right, let's prove all of this. Okay, the first.
00:05:38.964 - 00:05:48.474, Speaker A: The first is trivial. In fact, all of these are trivial. But let's do one at a time. So, the integral. Notice that the integral of ft.
00:05:50.294 - 00:05:50.606, Speaker C: Of.
00:05:50.630 - 00:05:54.262, Speaker A: Course, that's the same as, you know, actually, first of all, let me.
00:05:54.278 - 00:05:57.974, Speaker B: Let me notice that the map that.
00:05:58.014 - 00:06:06.550, Speaker A: Takes t and returns. Well, yes, the integral of ft dm. This is the same as, you know, the scanner product between the function one.
00:06:06.622 - 00:06:10.390, Speaker B: And ft in a two. Right.
00:06:10.582 - 00:06:22.940, Speaker A: The master is fine. Mm. Finite mass. So the constant one is in l two. This makes sense. And now this curve, as a curve in l two is continuous and absolutely continuous on the. On the half line.
00:06:22.940 - 00:06:24.824, Speaker A: So the same is true for this map.
00:06:25.964 - 00:06:27.972, Speaker B: Okay, so if I want to prove.
00:06:27.988 - 00:06:37.532, Speaker A: That this map is constant, it just sufficiently prove that this derivative is equal to zero, mostly. Okay, so let's compute this derivative. So who is this derivative?
00:06:37.588 - 00:06:40.772, Speaker B: Well, let me look at this expression.
00:06:40.828 - 00:06:42.172, Speaker A: I can certainly, you know, drop the.
00:06:42.188 - 00:06:44.788, Speaker B: Derivative in here, right?
00:06:44.916 - 00:06:45.300, Speaker C: So.
00:06:45.372 - 00:06:45.700, Speaker B: So.
00:06:45.772 - 00:06:48.340, Speaker A: So that's. So this derivative is equal to one.
00:06:48.412 - 00:06:51.344, Speaker B: Dot Laplacian f d.
00:06:54.044 - 00:06:54.784, Speaker C: Right?
00:06:56.244 - 00:07:02.780, Speaker A: And now, according to play, this weak integration by parts formula that you seen last time. Remember that?
00:07:02.932 - 00:07:03.476, Speaker C: Remember that?
00:07:03.500 - 00:07:05.380, Speaker A: We proved that the integral of g.
00:07:05.412 - 00:07:12.644, Speaker B: Laplacian f. This was less or equal than the integral of relaxed, the slope.
00:07:12.724 - 00:07:20.652, Speaker A: Of f. Relaxed, the slope of g, whenever f as a Laplacian. And both f and g are in the domain of the trigger energy.
00:07:20.828 - 00:07:21.544, Speaker C: Right?
00:07:23.084 - 00:07:29.676, Speaker B: But the constant function one certainly is in l two, and certainly easy domain.
00:07:29.700 - 00:07:32.136, Speaker A: Of the trigger energy, you know, with zero energy.
00:07:32.220 - 00:07:32.464, Speaker B: Right?
00:07:32.504 - 00:07:44.880, Speaker A: So all constant functions, as far as the reference measure is finite. Constant function certainly belongs. Is Lipschitz, you know? And certainly, certainly, you know, it has zero minimum wick up agreement.
00:07:44.992 - 00:07:45.360, Speaker C: Right?
00:07:45.432 - 00:07:46.444, Speaker A: So this is zero.
00:07:50.024 - 00:07:50.964, Speaker B: Makes sense.
00:07:53.104 - 00:07:56.968, Speaker A: Nicolas, the camera doesn't.
00:07:57.096 - 00:08:04.508, Speaker B: Doesn't move to the right blackboard. Somehow, to the one on the right. It doesn't show it.
00:08:04.596 - 00:08:09.892, Speaker A: Ah, yes. So let me see if I can handle this by myself. I mean, I try.
00:08:09.948 - 00:08:10.984, Speaker B: Let me prove this.
00:08:11.524 - 00:08:12.164, Speaker A: Okay, good.
00:08:12.204 - 00:08:12.612, Speaker C: Yeah.
00:08:12.708 - 00:08:14.904, Speaker B: Okay, I've done it. Okay.
00:08:15.724 - 00:08:39.340, Speaker A: I was just recalling the weak integration of Pars format that I proved last time. So, in proving that the. So, if you are bothered by the fact that I've been a bit sloppy in this approximation, we are lipid functions. Sometimes I said that I want to approximate with lipid function with bonded supports, sometimes that will lift this function. So if you're bothered by the fact.
00:08:39.372 - 00:08:42.300, Speaker B: That, okay, how do I approximate a.
00:08:42.372 - 00:08:57.784, Speaker A: Constant function that has not bounded support in my setting in order to approximate the trigger energy? If you're bothered by this, think that the space is complex. Things can be, I mean, I'm slightly cheating over here. I'm being a little bit low. The space is compact. There is no such issue.
00:08:57.864 - 00:09:02.352, Speaker B: Okay, so first, now second, okay, the.
00:09:02.368 - 00:09:23.100, Speaker A: Proof of the second property is trivial if you know, you know one thing about how this flow is constructed that I've mentioned the other time, and this flow is constructed, of course I mentioned without proving. So I'm asking you to believe me. So how do you build this flow of t? Well, you start from a function f.
00:09:23.172 - 00:09:26.004, Speaker B: You fix a parameter tau bigger than.
00:09:26.044 - 00:09:36.700, Speaker A: Zero, and then you recursively minimize. You first define, you know, f tau zero to be your given f. And then, and then you define f t o, say n plus one to be.
00:09:36.732 - 00:09:40.484, Speaker B: You know, the minimum, the argument of.
00:09:40.524 - 00:09:42.260, Speaker A: The energy, in this case the chigger.
00:09:42.292 - 00:09:51.014, Speaker B: Energy plus distance squared from the previous guy, l, two divided by two tropes.
00:09:51.474 - 00:10:14.462, Speaker A: Okay, we have discussed this in the case of RD for functions on RD that basically defining, you know, this sequence, this sequence is in a sense, solves a kind of time discretization of the, of the gradient flow equation. And when Tau goes to zero, if you properly rescale, rescale time over here, you are converging actually to the gradient flow.
00:10:14.658 - 00:10:18.742, Speaker B: Okay, I'm mentioning this or without, I.
00:10:18.758 - 00:10:27.190, Speaker A: Mentioned it without proof. But just for you to know, basically that if I'm able to prove that the weak maximum principle holds at this.
00:10:27.222 - 00:10:31.714, Speaker B: Discrete level, then it passes through the limit, okay?
00:10:32.214 - 00:10:40.422, Speaker A: Of course, if you don't know that this converges to the gradient flow, there is still sometimes a hole in the proof. But at least this should be a convincing argument that this should be true.
00:10:40.598 - 00:10:44.670, Speaker B: Okay, so let's see why this is the case.
00:10:44.742 - 00:10:47.022, Speaker A: So now, so now what I want to prove is the following.
00:10:47.198 - 00:10:56.314, Speaker B: F has a bound from, say, below, okay? So is a positive parameter fixed, I minimize this function.
00:10:57.134 - 00:11:37.938, Speaker A: And my claim is that the minimizer, which is clearly unique, right? Because this guy is convex, the Chig energy, and this guy is strictly convex, okay? The strictly convex function can have at most one minimizer, right? And the minimizer exists because this is lower semicontinuous convex. Lower semicontinuous means weakly lower semicontinuous. This is also weakly over semicontinuous and these sublevels must be bounded, because if you go far from zero, not this term increases. So any minimizing sequence lives in a bounded set. All right, so let me, you know.
00:11:38.066 - 00:11:41.586, Speaker B: Say, you know, say that f is.
00:11:41.610 - 00:12:00.374, Speaker A: Greater ego than some constant almost everywhere. And let's say, let's pretend that by contradiction, assume that the minimizer, let's call it, you know, f one.
00:12:02.364 - 00:12:03.404, Speaker B: Is strictly.
00:12:03.444 - 00:12:08.864, Speaker A: Smaller than c somewhere on a set, you know, on some positive measure, something.
00:12:16.204 - 00:12:17.064, Speaker B: Okay.
00:12:18.924 - 00:12:19.724, Speaker C: So what is.
00:12:19.764 - 00:12:20.864, Speaker A: Let me draw a picture.
00:12:22.884 - 00:12:25.156, Speaker B: This is the threshold c. Here is.
00:12:25.180 - 00:12:30.374, Speaker A: My function f. And, and, and.
00:12:32.834 - 00:12:33.194, Speaker C: So.
00:12:33.234 - 00:13:04.292, Speaker A: Here is my threshold. F stays above this, and then f for some reason, you know, f two drops below, below this sublevel at some point. Okay, now I want to build, you know, by contradiction, I want to build a better, you know, another function which does better than f two in minimizing this guy. And what it is that I do. Well, certainly, I mean, simply, I just truncated. And I say that it has been unwise to go below this level.
00:13:04.388 - 00:13:07.988, Speaker B: So I define g to be just.
00:13:08.036 - 00:13:18.120, Speaker A: The, you know, the. What is the max between c and f two? So if g does strictly better than f two, I'm done.
00:13:18.232 - 00:13:19.004, Speaker C: Okay.
00:13:21.024 - 00:13:28.016, Speaker B: Now, of course, the l two distance between g and f is less.
00:13:28.040 - 00:13:38.864, Speaker A: Or equal than the l two distance between f to one. I hope this is clear from the picture. You know, f is above c. F two is below. So if I increase a little bit, f two.
00:13:38.944 - 00:13:39.480, Speaker B: That's true.
00:13:39.552 - 00:13:41.804, Speaker A: In fact, it is, you know, strictly less.
00:13:43.724 - 00:13:46.904, Speaker B: Okay, what about the energy?
00:13:47.564 - 00:14:10.784, Speaker A: Well, first of all, is g sober? Yes, it is, because g is obtained by f toe, by post composing with the function that is the one ips function, which is, I don't know, this is identical, equal to c. And then is the. This is phi. You know, g is equal to phi. Composition after one.
00:14:12.914 - 00:14:14.466, Speaker B: Right, PI is one.
00:14:14.490 - 00:14:26.094, Speaker A: Leipzig. And we have already proved that if I post compose a sublet function, your only chips are remains sober. So at least g is sober. And what about, what about its weak upper gradient?
00:14:26.554 - 00:14:29.370, Speaker B: Well, on the region on the set.
00:14:29.562 - 00:14:36.482, Speaker A: Where f one is strictly smaller than c, we have that g is identically.
00:14:36.538 - 00:14:39.624, Speaker B: Equal to c. Right?
00:14:40.444 - 00:14:52.104, Speaker A: But we also know that if two sublet functions agree on a Borrell set, their minimal weak upper gradients agree on the same set. So g agrees with the constant function which has zero gradient.
00:14:52.524 - 00:14:55.404, Speaker B: Okay, so on this set, the minimal.
00:14:55.444 - 00:15:01.024, Speaker A: Weak upper gradient, the minimal relaxed slope of g is identically zero on this set.
00:15:03.264 - 00:15:04.004, Speaker C: Right?
00:15:05.144 - 00:15:09.720, Speaker A: And what about, what about on the other set on, on the set where.
00:15:09.912 - 00:15:13.840, Speaker B: F two, one is greater ego than.
00:15:13.872 - 00:15:22.084, Speaker A: C. Well, on this set, g and this function agree. So the minimum we can pregnant agree for the same reason that I've just discussed.
00:15:27.584 - 00:15:30.220, Speaker B: Right? Well, by then I'm done.
00:15:30.252 - 00:15:45.620, Speaker A: Because the energy of any function is just the integral of this squared relaxed loop, right? So the energy of g is just the sum. Let me say that is the sum of. So let's give a name.
00:15:45.652 - 00:15:48.252, Speaker B: So this is a, is the integral.
00:15:48.308 - 00:15:53.544, Speaker A: Over a of dgr squared plus the integral over the complement of a.
00:15:55.664 - 00:15:56.404, Speaker B: Right.
00:15:57.664 - 00:16:03.736, Speaker A: But this is zero. And this is the same as the integral of, you know, the axis loop.
00:16:03.760 - 00:16:06.352, Speaker B: Of f. But for the luxury slope.
00:16:06.368 - 00:16:13.144, Speaker A: Of f, f pays in principle, or could pay something also on a. You see what I mean? So this is less or equal.
00:16:13.224 - 00:16:21.636, Speaker B: Make sense of f two does make any sense. It could be that old swept over.
00:16:21.700 - 00:16:28.940, Speaker A: Zero we cap gradient on this set. I'm not fitting otherwise, but certainly we have already such as earned something at this level.
00:16:29.092 - 00:16:29.980, Speaker C: Okay?
00:16:30.172 - 00:16:34.372, Speaker A: So that proves my claim. And if you believe me, that this.
00:16:34.428 - 00:16:36.692, Speaker B: So in particular, this stable, you know.
00:16:36.708 - 00:17:05.964, Speaker A: You can iterate this, you know, this two for f two one, f two, f two three, et cetera, et cetera. And for any toe, okay, it's almost like the proof. Of course, I didn't prove the convergence of the scheme, but, you know, I won't. Okay, now, now it remains to prove this last statement about this entropy dissipation. I will only use this statement for u equals z log z. But this is very general. So let me prove three.
00:17:05.964 - 00:17:26.523, Speaker A: So first of all, if, you know, let's let me prove this statement over here. Why, why these map should be continuous. Well, this is by dominate convergence.
00:17:26.643 - 00:17:29.663, Speaker B: You know, f, you know, if ft.
00:17:30.563 - 00:17:34.355, Speaker A: Goes to ft bar, you know, when t goes to t bar f, t.
00:17:34.379 - 00:17:38.944, Speaker B: Goes to as, as t goes to t bar.
00:17:39.064 - 00:17:47.284, Speaker A: This is true. Nil two. Okay, in particular, let's say every subsequence as a partner extraction that converges almost everywhere.
00:17:47.904 - 00:17:55.328, Speaker B: Now the integral, now, u of f t is bounded by the previous step.
00:17:55.376 - 00:18:02.472, Speaker A: Once I know that f is between two constants, the same is true for ft. So you, so first of all, this.
00:18:02.488 - 00:18:04.302, Speaker B: Is well defined, okay?
00:18:04.478 - 00:18:32.184, Speaker A: U compose ft is well defined almost everywhere. And this is a bounded function, because u is a smooth function from a compact interval to r. So this is bounded, right? But what I know, what I know is that, you know, this converges, you know, basically measure, or if you wish, you know, f u of f t, you know, for every sequence t going to t bar, you have some sequence ftn, so that this converges almost everywhere, you agree?
00:18:33.284 - 00:18:33.668, Speaker C: Right?
00:18:33.716 - 00:18:41.504, Speaker A: And if this convergent or material, the measure is finite and all these functions are bounded, then the integrals, you know, I have continuity of this.
00:18:43.684 - 00:18:44.624, Speaker C: Make sense?
00:18:47.844 - 00:18:55.508, Speaker A: All right, so what about absolute continuity then? Well, let me, you know, let me compute the integral of u f t.
00:18:55.596 - 00:19:01.516, Speaker B: Minus ufs the m. Well, this is.
00:19:01.540 - 00:19:16.932, Speaker A: Bound by the Lipschitz constant of u times the integral of ft minus fsm, which of course, is bounded by the ellipsis constant of u times the l.
00:19:16.948 - 00:19:23.552, Speaker B: Two norm of t minus fs, right? Because m is probability, right?
00:19:23.608 - 00:19:33.968, Speaker A: So if the curve fd is absolutely continuous on some interval, on that same interval, both composing with you preserves, preserves absolute continuity.
00:19:34.096 - 00:19:36.776, Speaker C: Okay? Right.
00:19:36.880 - 00:19:47.244, Speaker A: So let's compute this derivative, and again, as before, you know, dt of the integral. Well, actually, so.
00:19:52.204 - 00:19:53.412, Speaker B: Let me write this formula.
00:19:53.468 - 00:20:21.004, Speaker A: Let me see, what should I do to convince you that this is true? So what it is that I'm using over here, I'm just saying, well, I could write here dtft. Does this make any sense? You could prove this, for instance.
00:20:23.504 - 00:20:23.792, Speaker C: You.
00:20:23.808 - 00:20:27.352, Speaker B: Know, by looking at different quotients and.
00:20:27.528 - 00:20:31.004, Speaker A: You know, u f t plus h.
00:20:32.784 - 00:20:35.880, Speaker B: Minus u of t divided by h.
00:20:35.912 - 00:21:05.302, Speaker A: And arguing by point wise convergence of subsequences. The fact that, the fact that ft is absolutely continuous tells me that for almost every t f t plus h minus ft divided by h. Or actually, if you want, by using this limiting, actually, we can use this, this guy over here. So this converging converges in l two to Laplacian of ft, you know, as.
00:21:05.478 - 00:21:10.234, Speaker B: H goes to zero from above, right?
00:21:12.254 - 00:21:18.102, Speaker A: So fixed t where, you know, fixed t positive. Look at this limit. Look at sequence of h. Take a.
00:21:18.118 - 00:21:22.214, Speaker B: Subsequence where this convergence is almost everywhere, right?
00:21:22.374 - 00:21:40.318, Speaker A: So then, then you get that you have convergence almost everywhere of the integer. So these converges almost everywhere, you know, up to subsequences. This converges almost everywhere to, uh, prime of ft. Laplacian of ft, just by, you know, post composition of real value.
00:21:40.366 - 00:21:43.414, Speaker B: Functions, you know, the standard chain rule.
00:21:43.574 - 00:21:52.674, Speaker A: Rule, most of the x chain rule, and, and then by an argument by dominate convergence again, you can, you can pass to the integrated version.
00:21:53.734 - 00:21:57.502, Speaker B: Okay, makes sense.
00:21:57.678 - 00:22:00.342, Speaker A: And then, but this is true for any sequence of h. So this is.
00:22:00.358 - 00:22:03.924, Speaker B: True, you know, for the full derivative, right?
00:22:06.384 - 00:22:20.176, Speaker A: So, but once you have this, we are done, right? Because now I apply the other integration by parts formula that I approved last time. And the integration of a performer was.
00:22:20.240 - 00:22:25.152, Speaker B: That whenever I integrate effect Laplacian, and.
00:22:25.168 - 00:22:37.928, Speaker A: I mean, again, Laplacian of f engaged a function g, which is of the form, you know, phi composition f. Here, phi is u prime. Then this is equal to minus the integral of the, you know, the derivative of phi in this case is u.
00:22:37.976 - 00:22:42.244, Speaker B: Second, and then dft squared.
00:22:45.744 - 00:22:46.240, Speaker C: Which is.
00:22:46.272 - 00:22:47.844, Speaker A: Exactly the formula that I wrote.
00:22:52.064 - 00:22:55.264, Speaker B: All right, so, end of the proof.
00:22:59.724 - 00:23:00.544, Speaker C: All right.
00:23:05.564 - 00:23:09.564, Speaker A: So this works extremely generally. You know, we have seen, we have.
00:23:09.604 - 00:23:13.180, Speaker B: Used just the basic calculus.
00:23:13.212 - 00:23:28.044, Speaker A: So there is no. There is. There is no. So there is no miracle. What is happening over here. Basically, what happened is that we've defined the Laplacian as this variational approach to Laplacian. So, sub differential of the Chiga energy.
00:23:28.044 - 00:23:37.304, Speaker A: And from there to all these statements is basically just, you know, algebraic manipulation of this property. That approach to the Laplacian gives for free.
00:23:37.424 - 00:23:38.244, Speaker B: All this.
00:23:43.864 - 00:23:57.426, Speaker A: Here becomes a theorem, perhaps the most important theorem about sober function that I've mentioned so far. Perhaps the only theorem, basically. So, that's the difference between proving theorems and playing with definitions.
00:23:57.530 - 00:23:58.814, Speaker B: So, this is a theorem.
00:24:02.074 - 00:24:12.026, Speaker A: It goes by the name of Povada's lemma. This has been proved. This has been proved by myself, Kuval.
00:24:12.050 - 00:24:18.004, Speaker B: And Otta, and in our paper on Alexandro spaces.
00:24:18.544 - 00:24:47.344, Speaker A: But the basic idea has been, you know, it's due to Kuvada. And so, in agreement with OTa, we decided to call this Kuvada's lemma. And this has been later, you know, utilized used by Ambrosio, myself and stavare in our studies about city spaces and gradient flows and the heat flow that. But, you know, the proof, I mean, this is really, it comes really for me.
00:24:48.204 - 00:25:05.376, Speaker B: And here is the theorem, same assumption before. So m, in particular, this take the.
00:25:05.400 - 00:25:07.264, Speaker A: Space complex if you wish, if that.
00:25:07.424 - 00:25:09.884, Speaker B: You know, helps you.
00:25:13.464 - 00:25:38.504, Speaker A: And say that the initial density f is actually is, you know, is a probability measure, is a probability density. So this guy, a priority is in l two, right? But let me also assume that these are probably tends to with, you know, say, less rigor than some constant.
00:25:39.644 - 00:25:44.468, Speaker B: Okay, then by what we know, what.
00:25:44.516 - 00:25:46.580, Speaker A: We, you know, already proved, then we.
00:25:46.612 - 00:25:50.904, Speaker B: Know that, you know, let me define muti.
00:25:52.724 - 00:25:54.024, Speaker A: FTM.
00:25:55.264 - 00:25:57.632, Speaker B: I know that this guy is a.
00:25:57.648 - 00:25:59.924, Speaker A: Probability measure with finite second moment.
00:26:01.464 - 00:26:02.204, Speaker B: Why?
00:26:03.664 - 00:26:25.384, Speaker A: Well, first of all, if this is a probability density, means that it is greater or equal than zero, almost everywhere. And so also f t is greater than zero, almost zero by the weak maximum principle. Now, this is also, by assumption less regard than some constant. So also f t is less regular than some constant. Therefore, given that this measure has finite second moment, the same is true for this.
00:26:28.884 - 00:26:29.884, Speaker B: What about the mass?
00:26:29.964 - 00:26:35.184, Speaker A: Well, I just proved that the mass is preserved, so fts must one. So this is a probability density with finite second moment.
00:26:36.004 - 00:26:45.852, Speaker B: Okay, now, quadratus lemma tells the, does the t into mu t is, you.
00:26:45.868 - 00:26:51.058, Speaker A: Know, in, you know, let me say.
00:26:51.106 - 00:26:55.218, Speaker B: Continuous with values, you know, zero plus.
00:26:55.266 - 00:26:59.770, Speaker A: Infinity and absolutely continuous in zero plus.
00:26:59.802 - 00:27:18.434, Speaker B: Infinity with respect to the vast strength distance w two. And I have a sharp control on the matrix speed. This is bound probable by the integral.
00:27:19.254 - 00:27:44.834, Speaker A: Let me, let me actually, let me also, let me exactly, let me exaggerate a little bit. Let me also say that this is also bigger than some constant. So I have easier time writing this. So this scored vast time speed is.
00:27:44.874 - 00:27:50.734, Speaker B: Bounded from above by what is called Fisher information for almost everything.
00:28:03.474 - 00:28:12.894, Speaker A: I will skip for a moment the proof of this fact and see and want to show you how powerful it is by showing the conclusion. But first, let me comment on the, on this statement.
00:28:13.434 - 00:28:16.754, Speaker B: So up to 1 second ago, all.
00:28:16.834 - 00:28:30.334, Speaker A: That this heat flow was doing, or gradient flow that she grew energy was doing, was related to properties in some sense, vertical properties, vertical interpolation, it has to do with l two functions and both compositions with l two functions.
00:28:31.234 - 00:28:34.624, Speaker B: Now, Kubada's lemma tells that this guy.
00:28:34.704 - 00:28:36.152, Speaker A: Which has been produced by taking the.
00:28:36.168 - 00:28:39.192, Speaker B: Gradient flow of the shear energy, in.
00:28:39.208 - 00:28:53.764, Speaker A: Fact is related in some way, and in fact in a sharp way to the wastestein, to the optimal transport joint, we can bound really the vast distance between mutual nas in a sharp way with efficient information.
00:28:55.704 - 00:28:59.848, Speaker B: Okay, of course you can wonder why is this sharp?
00:28:59.896 - 00:29:10.574, Speaker A: But this will be clear from the proof that I'm going to do now. Okay, so this is yet another link between the vertical interpolation and horizontal interpolation.
00:29:10.614 - 00:29:14.830, Speaker B: If you will, between the l two world and the w two world, between.
00:29:14.862 - 00:29:17.914, Speaker A: The lagrangian side of the story and the eulerian side of the story.
00:29:22.254 - 00:29:26.994, Speaker B: Let me show two crucial consequences of this result.
00:29:32.844 - 00:29:36.664, Speaker A: And then, and then later on, I will prove this lemma.
00:29:38.684 - 00:29:39.664, Speaker C: Corolla.
00:29:47.764 - 00:29:49.332, Speaker A: The, you know, basically the corollary is.
00:29:49.348 - 00:29:49.904, Speaker B: This.
00:29:52.404 - 00:29:56.424, Speaker A: Weak relaxed slope and a minimal weak upgraded coincides.
00:29:56.934 - 00:30:07.030, Speaker B: In other words, more precisely, more precisely, if you know, f is in l.
00:30:07.062 - 00:30:15.474, Speaker A: Two and also in s two, then f is in the domain of the chigger energy.
00:30:16.334 - 00:30:19.274, Speaker B: And this equality holds.
00:30:24.714 - 00:30:46.094, Speaker A: You might remember that during the last lecture I proved that if f is the magnet shear energy, then it belongs to this space. And we had this inequality, which was basically trivial, right? Almost everywhere. I'm telling you that the other one is true. Make sense?
00:30:49.254 - 00:30:50.594, Speaker B: Okay, let's prove this.
00:30:58.494 - 00:31:09.314, Speaker A: Let me, let me assume, let me assume, say for the moment that f is bounded from above and from below by some constants.
00:31:11.294 - 00:31:18.338, Speaker B: And, uh, and, um, let me think 1 second.
00:31:18.506 - 00:31:25.650, Speaker A: Um. Do I want. Yeah, and they have to say the integral one.
00:31:25.682 - 00:31:28.974, Speaker B: So the probability density.
00:31:30.074 - 00:31:31.014, Speaker C: Let me see.
00:31:31.474 - 00:31:41.854, Speaker A: Then we discuss the general case. But once we settle the conclusion for these sort of functions that the rest will be seen. Okay, then I build, I build this gradient for the shear energy.
00:31:42.014 - 00:31:47.542, Speaker B: I pick, you know, ft, a gradient.
00:31:47.598 - 00:31:50.806, Speaker A: Flow trajectory of the Chiga energy starting.
00:31:50.830 - 00:32:05.014, Speaker B: From f and let mu tilde b.
00:32:06.114 - 00:32:08.334, Speaker A: You know, ft push or ftm.
00:32:10.354 - 00:32:10.642, Speaker C: You.
00:32:10.658 - 00:32:11.934, Speaker A: Know, so this leaves.
00:32:13.914 - 00:32:14.530, Speaker B: In p two.
00:32:14.562 - 00:32:15.134, Speaker C: X.
00:32:18.234 - 00:32:27.614, Speaker A: Because I'm assuming for simplicity, them belongs, you know, as finite second moment. If not, some approximation result has to be called into play.
00:32:32.374 - 00:32:33.194, Speaker C: Um.
00:32:44.414 - 00:32:48.074, Speaker A: Let me think. Um.
00:32:54.294 - 00:32:55.194, Speaker B: Oh, yes.
00:32:55.554 - 00:32:56.414, Speaker C: Okay.
00:32:57.594 - 00:33:00.234, Speaker B: First of all, let me look at.
00:33:00.274 - 00:33:11.882, Speaker A: How much, let's have a look at the quantity integral of f log. Or if you want, f log f naught, log of f naught minus integral.
00:33:11.938 - 00:33:17.054, Speaker B: Of ft log ft. You know, the mdf.
00:33:19.874 - 00:33:21.414, Speaker A: How much is this difference?
00:33:21.814 - 00:33:26.438, Speaker B: Well, I'm really under the assumptions, you.
00:33:26.446 - 00:33:41.854, Speaker A: Know, f is bounded from above and from below. I'm post composing f with a smooth function which is z log z. So I'm really, you know, in the setting of this entropy dissipation result that I've mentioned previously.
00:33:41.934 - 00:33:44.286, Speaker B: So this is equal, this is equal.
00:33:44.310 - 00:34:00.434, Speaker A: To the integral from zero to t of the integral of the second derivative of z log z, which is, you know, one over z, so divided by fs. And here I have df's lax dm.
00:34:00.474 - 00:34:03.774, Speaker B: Ds make sense.
00:34:06.154 - 00:34:07.578, Speaker A: By the entropy dissipation.
00:34:07.666 - 00:34:10.794, Speaker B: For, you know, u of z equals.
00:34:10.834 - 00:34:20.909, Speaker A: Z log z. I should have, now I should have the difference. The derivative dt of the inter u.
00:34:20.941 - 00:34:23.189, Speaker B: Of t is equal.
00:34:23.221 - 00:34:28.033, Speaker A: You remember minus u second Laplace dft squared.
00:34:30.053 - 00:34:30.653, Speaker B: Right.
00:34:30.773 - 00:34:37.269, Speaker A: Now the minus here is, you know, it's taken care because I did the energy at times zero minus at time.
00:34:37.301 - 00:34:40.494, Speaker B: T. And u second is one over.
00:34:41.354 - 00:34:45.026, Speaker C: Okay. Okay.
00:34:45.050 - 00:34:47.186, Speaker B: On the other end, this is less.
00:34:47.210 - 00:34:51.810, Speaker A: Or equal for trivial reason. Let me write it included. And then we comment, this is less or equal.
00:34:51.842 - 00:34:55.834, Speaker B: Then u prime of f naught times.
00:34:55.994 - 00:35:14.414, Speaker A: Ft minus f naught. Here I just used the trivial inequality that, you know, tells that u, if u is convex, u of b is greater or equal than u of a plus u prime of a times b minus a.
00:35:16.114 - 00:35:23.162, Speaker B: Um, maybe there's a minus somewhere or f f zero with a.
00:35:23.178 - 00:35:23.734, Speaker A: Second.
00:35:32.274 - 00:35:34.682, Speaker B: U of b, u of a.
00:35:34.738 - 00:35:37.334, Speaker A: Minus zero b. Yeah, maybe it's this.
00:35:39.114 - 00:35:40.894, Speaker B: Okay, this should be okay.
00:35:41.594 - 00:35:51.746, Speaker A: You see, a is f times zero, b is f time t, and this is basically the integral. So the integrated version of u of.
00:35:51.810 - 00:35:59.894, Speaker B: A minus u of b is less than or equal than u prime at a times dimension.
00:36:02.124 - 00:36:07.164, Speaker C: All right. Okay.
00:36:07.204 - 00:36:20.452, Speaker A: But now let me observe the following, so let me observe what. Well, let me first of all call.
00:36:20.508 - 00:36:23.556, Speaker B: So this is the same as the.
00:36:23.620 - 00:36:38.024, Speaker A: Integral of u prime of f naught. Let's say up to a sine gamma naught, minus u prime of f naught, in gamma t d PI of gamma.
00:36:38.104 - 00:36:44.204, Speaker B: Where PI for PI, you know, lifting.
00:36:45.704 - 00:37:31.424, Speaker A: In the sense of the superposition principle of the cap t maps to muti. Let me comment about this. Do I know? Let me come, let me think 1 second, I'm thinking whether I know already that this quantity is finite or not. Maybe I don't yet.
00:37:43.804 - 00:37:45.332, Speaker B: Oh, surely, surely.
00:37:45.428 - 00:37:57.388, Speaker A: So in particular, surely. So, so, so this integral, this integral in particular, say from zero to one, is finite because it's equal to, you know, the value of this guy minus f of one.
00:37:57.476 - 00:37:58.044, Speaker B: Okay?
00:37:58.164 - 00:37:59.932, Speaker A: So in particular, so now let me.
00:37:59.948 - 00:38:02.812, Speaker B: Look at quad as lemme and let.
00:38:02.828 - 00:38:05.036, Speaker A: Me notice, actually, let me, let me grab it here.
00:38:05.220 - 00:38:14.576, Speaker B: So I have, so this curve is a continuous curve, right? Because Kubada's the limit, it is absolutely.
00:38:14.600 - 00:38:35.920, Speaker A: Continuous with squared speed bounded by this quantity. But this quantity is in l one of zero one. The integral of mu t dot squared from zero to one dt is less or equal than the integral from zero to one of these, of these Fisher.
00:38:35.952 - 00:38:41.844, Speaker B: Information, which is finite because it is equal to this quad, right?
00:38:44.664 - 00:38:59.136, Speaker A: So make sense. So in particular, this curve, this curve not only is absolutely continuous, let's say, on the open interval, but this is, you know, this is in, you know, ac of the interval zero one with values.
00:38:59.160 - 00:39:02.560, Speaker B: In this bursting space, we square the.
00:39:02.592 - 00:39:37.674, Speaker A: Speed, which is, which is in l one. So the speed is in l two. So I'm really in position to apply the superposition principle and lift this curve to a, to a lamb PI in the space of continuous curves with, and I know that the integral, you know, PI has the following two properties. Et PI is mu t, and the integral for every t in zero one. And the integral of gamma e dot squared d PI gamma is equal to mu t dot squared, you know, for almost every t.
00:39:40.294 - 00:39:41.674, Speaker B: Makes sense what I'm saying.
00:39:42.454 - 00:39:58.550, Speaker A: The three position principle tells you that whatever, whenever you have a curve of measures which is absolutely continuous with speed in f two, you can lift it, you can lift it to a probability measure on the space of curves that it has the correct marginals. And since I have the same kinetic.
00:39:58.582 - 00:39:59.554, Speaker B: Energy to it.
00:40:01.344 - 00:40:02.084, Speaker C: Right?
00:40:03.224 - 00:40:04.484, Speaker B: So this I can do.
00:40:05.704 - 00:40:12.484, Speaker A: So I can the research PI is non unique. In general, I don't care. This search PI. I pick search PI and I plug it here.
00:40:15.784 - 00:40:18.600, Speaker B: Okay, and now, what is that?
00:40:18.632 - 00:40:29.004, Speaker A: Observe. I observe that PI is a test plan, actually. And by the way, this trick of lifting probability measures is the only way we will ever build the test plans.
00:40:31.064 - 00:40:35.808, Speaker B: So this condition, if I integrate between.
00:40:35.856 - 00:40:39.976, Speaker A: Zero and one and I use this guy, I see that the plan has.
00:40:40.000 - 00:40:43.484, Speaker B: Finite kinetic energy, right?
00:40:44.784 - 00:40:47.764, Speaker A: So the kinetic energy, the double integral.
00:40:53.204 - 00:40:57.364, Speaker B: This is equal to mu t dot squared dt.
00:40:57.404 - 00:41:00.748, Speaker A: So it is finite. And what about the marginals?
00:41:00.876 - 00:41:03.188, Speaker B: Et push forward PI, well, this is.
00:41:03.196 - 00:41:09.108, Speaker A: Equal to mu t, but this is, this is equal to fdm, which by the maximum principle is less or equal.
00:41:09.116 - 00:41:10.264, Speaker B: Than a constant f.
00:41:12.644 - 00:41:13.892, Speaker A: The same constant.
00:41:14.028 - 00:41:23.862, Speaker B: That was true for f times zero, right? So PI test PI is test, and.
00:41:23.878 - 00:41:25.182, Speaker A: The function u prime.
00:41:25.238 - 00:41:26.314, Speaker B: So PI is test.
00:41:29.254 - 00:41:29.710, Speaker C: And.
00:41:29.782 - 00:41:46.828, Speaker A: And the function u prime composed f naught, is in, in the solve class, you know, in this space, because f zero is in this space, and I composing f zero with a smooth function that is smooth in its image. But the calculus would have seen the.
00:41:46.836 - 00:41:49.864, Speaker B: Other time is true, right?
00:41:52.164 - 00:42:09.600, Speaker A: So I can. So, by the very definition of table functions, in the sense of weak upper gradients in divided with test plants, I can bounce from above this guy. This quantity is less or equal. Let me continue over here. This is less or equal.
00:42:09.772 - 00:42:15.640, Speaker B: Then what? Then the integral from zero to one.
00:42:15.712 - 00:42:18.904, Speaker A: Let me say the integral of the integral to one of the weak upper.
00:42:18.944 - 00:42:27.864, Speaker B: Gradient of u, prime composition f naught at gamma s gamma s dot d.
00:42:27.904 - 00:42:30.124, Speaker A: S d PI of gamma.
00:42:30.624 - 00:42:37.108, Speaker B: And the m integrated from zero to t, right? Because this is gamma t, right?
00:42:37.156 - 00:42:45.544, Speaker A: If you want, I'm using, I'm starting from this plan PI, and then I'm restricting it to the interval zero t. Here, this is register operator, right?
00:42:46.284 - 00:42:47.384, Speaker B: So I have this.
00:42:50.684 - 00:42:55.860, Speaker A: Let me apply Young's, Young's inequality. This is less or equal than one.
00:42:55.892 - 00:43:08.552, Speaker B: R. The integral of the integral from zero to t of d d u, prime composition f naught squared f gamma.
00:43:08.608 - 00:43:16.712, Speaker A: S d s d PI, plus the.
00:43:16.728 - 00:43:20.204, Speaker B: Double integral of the kinetic energy.
00:43:23.504 - 00:43:26.844, Speaker A: I'm almost done. Then we take a break. But let me conclude the proof.
00:43:28.724 - 00:43:32.660, Speaker B: Okay, but now I know with this guy, right?
00:43:32.732 - 00:43:54.148, Speaker A: This is the energy of the plan. This is exactly the speed of the curve. And I know how to bound the speed of the curve. So, I mean, the inequality goes in the correct direction. I can replace this with the integral from zero to t of this relaxed.
00:43:54.196 - 00:44:00.978, Speaker B: Slope, s squared divided f s the.
00:44:01.026 - 00:44:01.614, Speaker A: S.
00:44:04.194 - 00:44:08.074, Speaker B: Okay, and who is this guy?
00:44:08.154 - 00:44:09.898, Speaker A: So u prime is log, right?
00:44:09.986 - 00:44:14.674, Speaker B: U was log plus one, whatever the.
00:44:14.714 - 00:44:25.038, Speaker A: Derivative of log is. Again I get u second, this is, so this is df's week squared divided.
00:44:25.086 - 00:44:32.994, Speaker B: By fs squared, because there is a square, right? So let me wrap everything up.
00:44:34.254 - 00:44:35.230, Speaker A: Let me write it.
00:44:35.302 - 00:44:49.714, Speaker B: Say here what approved. What I proved is that the integral.
00:44:49.754 - 00:44:55.746, Speaker A: This integral integral from zero to t of the integral of df's. Relax.
00:44:55.810 - 00:45:00.402, Speaker B: The square divided fs dm ds.
00:45:00.578 - 00:45:09.930, Speaker A: This is less, sorry, because this is equal to this difference in entropy. But the difference in entropy is bounded from above by this quantity. So this is less or equal than.
00:45:09.962 - 00:45:14.790, Speaker B: One half the integral of the integral.
00:45:14.822 - 00:45:26.638, Speaker A: From zero to t of the original f weak squared. I will correct that in a second times. And then I have, if you want. Well, let me write this way.
00:45:26.726 - 00:45:29.702, Speaker B: S d s d m plus the.
00:45:29.718 - 00:46:00.434, Speaker A: Double integral, the same content that s weak squared. Fsdm. So this was u prime composition f zero. So this was f zero. There is no s. And when I compute this function in gamma s, and then I enter it in the PI by the, you know, push the rule of the push forward. This is the same as integrating this.
00:46:00.474 - 00:46:03.974, Speaker B: Function times fs in the l, right?
00:46:04.034 - 00:46:07.914, Speaker A: Because the push for the s marginal of PI is fsDm.
00:46:08.734 - 00:46:14.790, Speaker B: Okay, so all this work allowed us to put, you know, the weak derivative.
00:46:14.822 - 00:46:16.514, Speaker A: On the right hand side of the inequality.
00:46:17.334 - 00:46:17.950, Speaker C: You see?
00:46:18.022 - 00:46:25.714, Speaker A: Now this quantity is the same as this quantity here. There is a one half. So let me erase this guy.
00:46:27.494 - 00:46:27.758, Speaker C: And.
00:46:27.766 - 00:46:32.374, Speaker A: Let me put a one half over here that then simplifies. What we get is this.
00:46:37.034 - 00:46:40.946, Speaker B: Okay, and now we are done, because.
00:46:41.010 - 00:46:43.002, Speaker A: What happens when s goes to zero?
00:46:43.058 - 00:46:52.818, Speaker B: Let me divide by t. Let me take the average. This is in l one, because this.
00:46:52.866 - 00:47:10.410, Speaker A: Quantity by this quantity in substrate was in l two, I square. It is in L1, and I'm dividing it by a function which is bounded from over, from below. So this code is in one. These are uniformly bounded functions by the maximum principle. And they are converging in, in l.
00:47:10.442 - 00:47:13.594, Speaker B: Two to f. But so, you know.
00:47:13.754 - 00:47:36.086, Speaker A: Up to subsequent is, they converge almost everywhere. So this quantity converges to this guy when s goes to zero. When t goes to zero, sorry. This quantity, you can rewrite it as this quantity is nothing but four times the trigger energy of the square root.
00:47:36.110 - 00:47:39.754, Speaker B: Of fs by the chain rule.
00:47:43.574 - 00:47:46.686, Speaker A: So now the fs are converging in.
00:47:46.710 - 00:47:50.854, Speaker B: L two to f, uniformly bounded.
00:47:51.474 - 00:48:01.338, Speaker A: So also the square root. Also the square root. The square root of fs is also converging in L two to the square root of f. In general, this is.
00:48:01.346 - 00:48:03.106, Speaker B: Of course totally false.
00:48:03.130 - 00:48:34.920, Speaker A: But in this case, we have uniform bounds from above and from below. The reference measure is a probability measure. So, convergence in L two is the same as convergence in AVLP. Once you have a uniform bound from lower, from below, right. And if this is true, by the lower semiconturity of the Chigar energy, you know that the Chigar energy of this co root of f is less or equal than the lyme of the trigger energy of this core root of fs. And the same is, here we take the average integral, you know, by fatu, we get the average integral between zero.
00:48:34.952 - 00:48:38.560, Speaker B: And t. So the conclusion, the conclusion.
00:48:38.592 - 00:48:43.674, Speaker A: Is that the chigger energy of the square root of f is less or equal than this quantity.
00:48:46.294 - 00:48:51.766, Speaker B: Right? In particular, square root of f lives.
00:48:51.830 - 00:48:53.390, Speaker A: In the relaxed double space.
00:48:53.462 - 00:48:57.574, Speaker B: So to say f is bounded from below.
00:48:57.654 - 00:49:00.714, Speaker A: So now I can, you know, say.
00:49:01.174 - 00:49:03.366, Speaker B: That, you know, the trigger energy of.
00:49:03.390 - 00:49:21.746, Speaker A: The square root of f is equal to this four times. The shearing is equal to this. This makes sense because now I know that, no, the square root is in the middle of the shear energy. The square also is. So, because the square root in any way is bounded. So I can write this, and I know that this is less or equal.
00:49:21.770 - 00:49:27.802, Speaker B: Than the f weak square divided by f. Okay.
00:49:27.978 - 00:49:36.090, Speaker A: But of course, I knew that point wise, this guy was less rigor than this almost everywhere. So after integration and multiplication by function that are positive.
00:49:36.242 - 00:49:37.334, Speaker B: No, I'm done.
00:49:39.714 - 00:50:06.542, Speaker A: You see? So that's the line of thought uses basically all of what we have learned so far on sovereign functions. Of course, this concludes the proof under this, you know, also under the assumption that f is bounded from below, from above, from below, and as a probability measure. But you can easily reduce to that case, you know, by first truncating and if necessary, adding a constant. And then, you know, you let the.
00:50:06.558 - 00:50:10.078, Speaker B: Truncation go to, you know, from, I.
00:50:10.086 - 00:50:15.834, Speaker A: Mean, that's, that's the core of the argument that rest is simple. So let's take a break.
00:50:16.174 - 00:50:16.854, Speaker C: Five minutes.
00:50:16.934 - 00:51:10.422, Speaker A: And then, and then, and then we continue. I pick this and I show that this also solves the equation. So if this is also a gradient flow and. Right, because, because it starts from the.
00:51:10.438 - 00:51:12.278, Speaker B: Same guy by you.
00:51:12.406 - 00:51:14.150, Speaker A: Is this, is this what you were telling?
00:51:14.222 - 00:51:15.230, Speaker C: So what I want to do.
00:51:15.262 - 00:51:18.826, Speaker A: Yeah. For instance, this is the composition with the function with.
00:51:18.970 - 00:51:19.654, Speaker B: Yes.
00:51:22.074 - 00:51:35.290, Speaker A: Yeah. I don't know. So you should work a little bit. So, of course, this, what you can prove without much work is that this derivative is equal to the positive part of this derivative. I think. Well, now on.
00:51:35.482 - 00:51:40.574, Speaker B: No, it's not like this. No, it's not like this.
00:51:42.934 - 00:51:43.674, Speaker C: No.
00:51:45.374 - 00:51:46.474, Speaker A: This is what's.
00:51:50.134 - 00:51:50.734, Speaker C: It'S a little.
00:51:50.774 - 00:52:21.274, Speaker A: Bit technical, I think. Oh, just of the integral. Okay, I see what you mean then. Okay, okay, okay, okay, okay, okay, okay. Okay.
00:52:21.394 - 00:52:22.494, Speaker C: How does it work?
00:52:25.394 - 00:52:33.970, Speaker A: But then phi is convex, and therefore this. Ah, makes sense.
00:52:34.042 - 00:52:34.684, Speaker B: You're right.
00:52:34.794 - 00:52:35.160, Speaker C: All right.
00:52:35.192 - 00:52:35.800, Speaker A: That's another way.
00:52:35.832 - 00:52:36.976, Speaker B: Yes, that's true.
00:52:37.040 - 00:52:37.840, Speaker A: That's, that's another way.
00:52:37.872 - 00:52:38.976, Speaker B: Yes, you're right.
00:52:39.000 - 00:52:39.768, Speaker A: Do you think about this?
00:52:39.816 - 00:52:40.444, Speaker B: Yeah.
00:52:42.144 - 00:52:43.032, Speaker A: Yeah, yeah. Okay.
00:52:43.088 - 00:52:45.936, Speaker B: Sure. So we have a better proof now.
00:52:45.960 - 00:52:53.584, Speaker A: That does not use the fact that the gradient, this flow is, you know, the limit of the discrete schema.
00:52:53.704 - 00:52:55.084, Speaker B: All right, thanks.
00:52:58.224 - 00:53:30.332, Speaker A: Okay, I think we can start. So, the first powerful consequence of the quadramma is this identification between weak and relaxed slopes. So from now on, of course, I will never write anymore R or W. Okay. And so the two spaces are the same. Notice in particular, you know, that, you know, we gain this approximation result out of this, out of this, out of this theorem, which is a priority, absolutely non triggered. That is, you take a function that is, I mean, by definition, you take a function that is sublet in the.
00:53:30.348 - 00:53:31.620, Speaker B: Sense of test plans.
00:53:31.812 - 00:53:34.540, Speaker A: Well, then there exists a sequence of.
00:53:34.572 - 00:53:37.420, Speaker B: Lipschitz functions converging to it such that.
00:53:37.452 - 00:54:20.048, Speaker A: The asymptotic Lipschitz constant converging to the minimal reduction slope, it's totally, you know, a priori, unclear how to, you know, in some sense, where this sequence comes from. It will be a little bit more clear once we see the proof of Quadra's lemma. This has to do with the hoplux formula and the hemitantial equation. But let me, you know, postpone for a second, for a second, this part. Let me, let me now prove one other thing. So, because I still have a problem of, with the heat flow, right, because I call the heat flow the gradient flow of the entropy with respect to the distance w two. And certainly now I'm, you know, willing to call heat flow also this gradient flow of the Chig energy.
00:54:20.048 - 00:54:48.214, Speaker A: So, of course, now we'll prove that they are the same. And the proof is based, among other things, beside quadrant lemma is based on the following observable lemma and the lemma. The following. Let me say that X is compact. It's not needed at all. But let me just say that X is compact. And then let's say that ErP is a probability density.
00:54:51.194 - 00:54:53.934, Speaker B: Probability density.
00:54:57.474 - 00:55:07.242, Speaker A: With Lipschitz probability density. And let me say that f is bounded from below by some strictly positive.
00:55:07.298 - 00:55:10.906, Speaker B: Constant and finite because it is leach.
00:55:10.930 - 00:55:12.874, Speaker A: It'S on a composite. Well, then.
00:55:17.294 - 00:55:20.782, Speaker B: I can compute f is the property density.
00:55:20.958 - 00:55:33.874, Speaker A: Of course, the entropy of the measure f mu. Let me, let me put, let me call mu is the measure fm. Of course, this measure mu lives in the domain of the entropy.
00:55:36.614 - 00:55:37.022, Speaker C: Right?
00:55:37.078 - 00:55:42.002, Speaker A: Because it is, it has, it is absolutely continuous with the density such that.
00:55:42.058 - 00:55:44.370, Speaker B: You know, f log f is certainly.
00:55:44.402 - 00:55:52.338, Speaker A: Interval with respect to l because it's bounded, right? So it makes sense given that it is indeed the entropy, it makes sense.
00:55:52.506 - 00:56:01.914, Speaker B: To wonder who is or abandoned from above this slope and this guy is.
00:56:01.954 - 00:56:19.448, Speaker A: Less or equal than the integral of the something that looks suspiciously close to an object that we have already seen a few times here with the, here there is ellipsis quantity. Not really a sobered one, but, you.
00:56:19.456 - 00:56:31.764, Speaker B: Know, okay, in particular, if this load.
00:56:35.684 - 00:56:47.104, Speaker A: Is, you know, lower weakly lower semicontinuous, weakly lower semicontinuous, then.
00:56:51.044 - 00:56:58.044, Speaker B: The slope of the entropy is less or equal than.
00:56:58.084 - 00:57:19.634, Speaker A: Four times the checker energy of f. You know, every time, every time f is square root of f for any f in l two with, you know, non negative, and the integral of f is equal to.
00:57:31.794 - 00:57:32.614, Speaker B: Okay.
00:57:37.354 - 00:57:38.506, Speaker A: Now you might remember that I.
00:57:38.530 - 00:57:42.082, Speaker B: Gave you an exercise to the know.
00:57:42.098 - 00:57:48.494, Speaker A: If bound from above or prove some equality concerning the slope of the entropy. And now we are approaching the solution of that exercise.
00:57:49.754 - 00:57:52.314, Speaker B: So let's see proof.
00:57:54.694 - 00:58:04.566, Speaker A: So mu is given, let's say the nu is another probability density of the form interval gm. And let me, you know, I want.
00:58:04.590 - 00:58:07.814, Speaker B: To bound from above the entropy of.
00:58:07.854 - 00:58:10.754, Speaker A: Mu minus the entropy of nu.
00:58:14.494 - 00:58:18.002, Speaker B: And this is, this is less or.
00:58:18.018 - 00:58:26.554, Speaker A: Equal than the integral, you know, as before, u of z is z log z. And this is less or equal than u.
00:58:26.594 - 00:58:29.922, Speaker B: Prime composition f times.
00:58:30.058 - 00:58:33.554, Speaker A: Okay, let me see the signs over here. Times.
00:58:33.674 - 00:58:41.214, Speaker B: I think it should be f minus g dm. It doesn't matter, but it should be this way.
00:58:41.634 - 00:58:50.254, Speaker A: Okay, because this is, again, this is the interval u of f minus u of g. I use the convexity of u to get to this.
00:58:52.434 - 00:58:53.174, Speaker C: Right.
00:58:53.954 - 00:58:56.694, Speaker B: You agree at every point.
00:59:02.394 - 00:59:05.454, Speaker A: By the convexity of u. So I integrate this and I get this.
00:59:05.834 - 00:59:15.198, Speaker B: Okay, um. And they would, I don't recall. Haha, yes.
00:59:15.366 - 00:59:16.234, Speaker A: Let me.
00:59:19.494 - 00:59:27.558, Speaker B: Let'S now let alpha be an optimal plan between mu and u. It exists.
00:59:27.606 - 00:59:35.820, Speaker A: These are probability measures. There is in a compass space. So the, certainly there is an optimizer for the, you know, quadratic transportation problem.
00:59:35.982 - 00:59:38.032, Speaker B: And so this guy is equal to.
00:59:38.048 - 00:59:44.008, Speaker A: The integral of u prime f in I guess, x or y whatever minus.
00:59:44.056 - 00:59:55.044, Speaker B: U prime fy d alpha xy. All right.
00:59:57.064 - 00:59:59.496, Speaker A: Which, okay, this is called, let me actually be a little bit bold.
00:59:59.560 - 01:00:02.164, Speaker B: This is log f minus log f.
01:00:05.174 - 01:00:08.474, Speaker A: The plus one gets simplified because there is a minus, right?
01:00:10.774 - 01:00:13.438, Speaker B: Okay, so this is less or equal then.
01:00:13.486 - 01:00:26.854, Speaker A: Okay, let me divide if you want. Let me divide and multiply by the distance xy times distance square. And then I. What do I do? I do hold it cosish wax. This is less or equal than the.
01:00:26.894 - 01:00:32.370, Speaker B: Integral of log f x minus log.
01:00:32.522 - 01:00:36.026, Speaker A: Y squared divided by the distance scored.
01:00:36.090 - 01:00:41.294, Speaker B: Xy the alpha times w two newton.
01:00:46.394 - 01:00:47.134, Speaker C: Right?
01:00:49.114 - 01:00:51.090, Speaker A: So now let me introduce a function.
01:00:51.122 - 01:00:54.670, Speaker B: Let me call lucky of xy, that.
01:00:54.702 - 01:00:56.030, Speaker A: This is the function which is equal.
01:00:56.062 - 01:01:00.646, Speaker B: To log f x minus log f.
01:01:00.710 - 01:01:04.194, Speaker A: Y divided distance between x and y.
01:01:04.654 - 01:01:09.150, Speaker B: If x is not y and is.
01:01:09.262 - 01:01:16.686, Speaker A: Equal to the asymptote Lipschitz constant of f at x. If x is equal to.
01:01:16.710 - 01:01:19.464, Speaker B: Yeah.
01:01:20.234 - 01:01:34.614, Speaker A: Is a function of two variables. If x and y are different, it's just this different quotient if you wish. Actually, let me put also the absolute value just in case. And I think the asymptote is a constant if not.
01:01:35.634 - 01:01:40.534, Speaker B: Okay, notice this is upper semicontinuous.
01:01:44.194 - 01:02:00.914, Speaker A: Basically it is continuous outside of the diagonal because f is continuous. But if you approach the same base point, you know, by the definition of absence, sorry. Of the lip divided by f. Sorry, I wanted to say the acidification constant.
01:02:00.954 - 01:02:05.534, Speaker B: Of log f. So, yeah, sorry.
01:02:06.074 - 01:02:09.134, Speaker A: I should divide by f of x.
01:02:20.614 - 01:02:21.022, Speaker C: Right?
01:02:21.078 - 01:02:42.114, Speaker A: Should log fx minus log f y divided distance xy in absolute value. And there is the, you know, the derivative of log f, which I'm writing as the asymptote constant of f of x divided by f of x. This coincides, this coincides with the asymptote elucidate constant of log of f.
01:02:44.564 - 01:02:44.924, Speaker C: These.
01:02:44.964 - 01:02:47.504, Speaker B: Upper semicontini makes sense.
01:02:48.644 - 01:02:58.636, Speaker A: Okay, but if this is upper semicontinuous. Now, now let, now, now we have. So this is, you know, this is equal. So what, what, let me rewrite what.
01:02:58.660 - 01:03:02.628, Speaker B: I just, you know, this previous computation.
01:03:02.676 - 01:03:42.052, Speaker A: That I just pointed out. So I just proved that the entropy of mu minus the entropy of mu is bounded from above by the distance between mu and nu in the sense of Boston space Times square root of the interval of l squared d r. Of course, this quantity is positive, so there's no harm in taking here the positive part. This is true for every new and.
01:03:42.068 - 01:03:45.036, Speaker B: New, basically, or let's say let's fix nu.
01:03:45.060 - 01:03:55.748, Speaker A: And this is true for every target measured. So now let's write this for a sequence of nu's converging to our measurement.
01:03:55.916 - 01:04:00.312, Speaker B: In the western sense, what we get.
01:04:00.408 - 01:04:16.552, Speaker A: So write nu equal new n equals, say, gnm, you know, converging w two to mu. Okay, then this is telling us that.
01:04:16.728 - 01:04:25.870, Speaker B: You know that the limb soup of the entropy of mu minus the entropy.
01:04:25.952 - 01:04:28.770, Speaker A: Of new positive part divided by the.
01:04:28.802 - 01:04:40.034, Speaker B: Distance, this is less or equal than the rim soup of the int square.
01:04:40.074 - 01:04:42.890, Speaker A: Root of the integral l squared d.
01:04:42.922 - 01:04:52.044, Speaker B: Alpha n. Okay, where alpha n is optimal between nu and the measure new. Nice.
01:04:52.534 - 01:04:53.174, Speaker A: It's the same.
01:04:53.214 - 01:04:55.514, Speaker B: You know I've done nothing, right?
01:04:57.174 - 01:04:58.190, Speaker C: Okay, but what's the point?
01:04:58.222 - 01:05:01.350, Speaker B: Now, the point is that if mu.
01:05:01.462 - 01:05:12.662, Speaker A: N is converted to mu, this plans alpha n. This will converge weakly to the identity comm, identity push or nu. I mean, in the limit, they won't change anything.
01:05:12.758 - 01:05:13.554, Speaker B: Anything.
01:05:14.134 - 01:05:24.874, Speaker A: Now, effect is as in the assumptions. This lf is upper semi continuous and bounded from above. L was leaches far from zero, so there is no problem in this.
01:05:26.134 - 01:05:26.446, Speaker C: But.
01:05:26.470 - 01:05:28.254, Speaker A: So, we have an upper semiconductor taking.
01:05:28.294 - 01:05:30.518, Speaker B: The square, of course, of a positive.
01:05:30.566 - 01:05:40.406, Speaker A: Function preserves upper semi continuity. So, I have an upper semi continuous function and the sequence of measures converging weakly to a limit measure.
01:05:40.590 - 01:05:44.820, Speaker B: So, of course, this is less or equal than the square root of the.
01:05:44.852 - 01:05:49.424, Speaker A: Integral of l squared d. You know, identity, comma, identity.
01:05:55.124 - 01:05:55.864, Speaker C: Right.
01:05:58.284 - 01:05:59.636, Speaker A: Which. Which proves this.
01:05:59.740 - 01:06:00.220, Speaker B: This.
01:06:00.332 - 01:06:00.984, Speaker C: Right.
01:06:01.924 - 01:06:05.756, Speaker B: I'm done, right, because l squared in.
01:06:05.780 - 01:06:25.712, Speaker A: This measure, this is the same, the square root. This is concentrated on the diagonal where l is equal to this. So this is equal to the interval of Lipschitz constant, asymptotic of f squared. I should write divided f squared integrated in d mu. But mu carries an f in some sense inside.
01:06:25.768 - 01:06:26.032, Speaker C: Right?
01:06:26.088 - 01:06:31.004, Speaker A: So one f at the denominator disappears and remain with the integration with f.
01:06:33.224 - 01:06:34.084, Speaker C: Okay.
01:06:37.804 - 01:06:46.484, Speaker A: How do I pass? So that's proved. Now, from here to here, this is trigger, right? Because. No, this sound is.
01:06:46.524 - 01:06:48.184, Speaker B: Okay, makes sense.
01:06:49.124 - 01:06:58.828, Speaker A: So. So from here to here, what do I do? Well, basically, what I want to do is, look, I pick my arbitrary function f, and I approximate the trigger energy.
01:06:58.876 - 01:07:02.588, Speaker B: Of square root of f. That exists.
01:07:02.676 - 01:07:08.334, Speaker A: There exists a sequence of functions of Liffey's functions, let me call them square root of fn.
01:07:08.494 - 01:07:14.270, Speaker B: These are converging in l two to square root of f with the asymptotic.
01:07:14.302 - 01:07:43.706, Speaker A: Ellipsis constant of square root of fn converging in l two. The minimal weak upper gradient of f. I don't write rw. Okay, well, but now, you see, this guy is positive. So these guys, certainly I can think them positive. There is no need of taking, you know, taking when approximating a positive function. If I truncate, I can certainly assume that the approximating sequence is also positive.
01:07:43.706 - 01:08:05.832, Speaker A: And I can certainly add a little bit of a constant that goes to zero, in order to be sure that each of these is bounded from rho by a positive. These are leap sheets, so in a compass set, they are certainly also bounded from rho. There's no problem. And in adding this little constant, this, I will not perch up too much. So, basically, basically what I'm doing here. And then I concluded by passing to.
01:08:05.848 - 01:08:07.936, Speaker B: The limit, you know, in the, in.
01:08:07.960 - 01:08:10.736, Speaker A: The right hand side, using the fact that the left hand side is weakly.
01:08:10.760 - 01:08:14.880, Speaker B: Or semicontinous, you know, in, but if.
01:08:14.912 - 01:08:16.964, Speaker A: This is true, in particular, in particular.
01:08:17.864 - 01:08:18.764, Speaker B: In particular.
01:08:20.664 - 01:08:31.764, Speaker A: The square root of fn m weakly converges, in particular to square root of n. What am I doing of, sorry, fn.
01:08:31.924 - 01:08:34.348, Speaker B: We can converge to this in particular.
01:08:34.436 - 01:08:45.236, Speaker A: Because it converges in l one, right? So, by approximation, using the, basically, I put the assumption in such a way that this is true that I can approximate.
01:08:45.340 - 01:08:52.164, Speaker C: Okay, all right.
01:08:57.424 - 01:09:07.884, Speaker A: By the way, this computation of the slope in the metric setting, I think, at least in the Litch's case, I think has been done at first by villany. You should find it in his book opinion transport.
01:09:09.864 - 01:09:12.924, Speaker B: That the relaxation part comes.
01:09:14.304 - 01:09:16.204, Speaker A: From my paper with kuvadian dot.
01:09:23.054 - 01:09:25.074, Speaker B: Okay, now here is the theorem.
01:09:26.934 - 01:09:40.006, Speaker A: It's more of a corollary of Quadra's lemma, but this is important. So let's take, this is a theorem this comes from, comes from the paper with Kuvada.
01:09:40.030 - 01:09:46.954, Speaker B: And, um, the generalization, uh, to, so.
01:09:46.994 - 01:10:01.614, Speaker A: We quite, we only worked on Alexandra spaces, but the generalization, uh, to general metric, uh, metric measure spaces is basically trivial. At least once, once one knows a little bit something about the obflux formula that. We discuss this in a second.
01:10:02.234 - 01:10:09.258, Speaker B: Now, the thing is this, let x dm be.
01:10:09.386 - 01:10:14.694, Speaker A: Okay, let me exaggerate here. Compact is absolutely no needed, but just CD k infinity spaces.
01:10:20.274 - 01:10:21.134, Speaker B: Okay.
01:10:24.114 - 01:10:30.454, Speaker A: So what we know about this space, by the definition given by the knee, is that the entropy is k convex right in the vast network.
01:10:31.034 - 01:10:37.354, Speaker B: Now let's mu equal fm, you know.
01:10:38.134 - 01:10:51.606, Speaker A: A probability measure with finite second moment with f in actually in l two. So, not only l one, but actually.
01:10:51.630 - 01:10:52.514, Speaker B: Is in l two.
01:10:54.534 - 01:10:57.494, Speaker A: Now, we have two ways of flowing.
01:10:57.534 - 01:11:01.314, Speaker B: This, so we can consider the curve.
01:11:01.394 - 01:11:09.294, Speaker A: T into ft be, you know, the gradient flow trajectory of the Chigger energy.
01:11:09.914 - 01:11:17.042, Speaker B: With respect, you know, to the l two distance starting from f. That's, you.
01:11:17.058 - 01:11:24.952, Speaker A: Know, the heat flow in the sense that we have discussed today. And also let t into mu tilde.
01:11:25.118 - 01:11:35.516, Speaker B: Be the gradient flow trajectory of the relative entropy with respect to the versus.
01:11:35.540 - 01:11:45.316, Speaker A: Ten distance w two starting from u, assuming it exists. Okay, we proved the uniqueness statement of.
01:11:45.340 - 01:11:45.904, Speaker C: This.
01:11:47.724 - 01:11:49.236, Speaker B: But there is at most one of these.
01:11:49.300 - 01:11:50.744, Speaker A: Say that there is one, then.
01:11:53.704 - 01:11:54.080, Speaker C: Nu.
01:11:54.112 - 01:11:57.008, Speaker A: T is actually equal to ftm, whatever.
01:11:57.056 - 01:11:57.644, Speaker C: T.
01:11:59.784 - 01:12:04.564, Speaker B: Okay, so these two heat flows.
01:12:05.144 - 01:12:36.708, Speaker A: Actually coincide whenever they can coincide. One is a flow of probability measures, the other one is a flow of l two functions. But if I start from a guy, which is both the probability measure and l two function and the flow, then they agree. Okay, to be a little bit more precise, given that I did not show, I only showed uniqueness for the level, for degrading for the relative entropy. I can formulate this theorem in an equivalent, you know, not in a weaker sense, by saying, look, if I take this gradient flow trajectory and I define.
01:12:36.756 - 01:12:39.284, Speaker B: Mu t in this way, then this.
01:12:39.404 - 01:12:41.304, Speaker A: Is a gradient flow derivative entropy.
01:12:43.064 - 01:12:47.004, Speaker B: Because this guy exists, ftm exists.
01:12:47.624 - 01:13:06.664, Speaker A: You get it from the gradient flow theory of converse, functional inverse spaces so exist in a sentence in an easier way. Okay, so you define muti. This happens to be a gradient flow of the entropy. In fact, this is our proof. Now, given that the agreement for the entropy is unique, that's the only one, right? And in particular, we approved existence. You know, this guy by, you know.
01:13:06.704 - 01:13:10.114, Speaker B: In some sense, by doing some, you know.
01:13:11.894 - 01:13:14.274, Speaker A: By, in a very not, not direct way.
01:13:15.054 - 01:13:19.510, Speaker B: Okay, so this, now, so we have.
01:13:19.542 - 01:13:20.518, Speaker A: So what are comments?
01:13:20.566 - 01:13:23.966, Speaker B: So we have seen that the optimal.
01:13:23.990 - 01:13:35.070, Speaker A: Transfer point of view gives more or less for free. I mean, once you've write down the definition, gives you more or less for free the stability of this gradient flow with respect to, you know, convergence, convergence.
01:13:35.102 - 01:13:38.526, Speaker B: Of basic spaces because of the loss.
01:13:38.550 - 01:13:41.782, Speaker A: Of Milan instability result and my stability result for the gradient flow.
01:13:41.958 - 01:13:49.934, Speaker B: Okay, so once optimal transfer gives the beauty of this, this theorem is telling.
01:13:49.974 - 01:13:53.278, Speaker A: You that this gradient flow is the same as the gradient flow.
01:13:53.446 - 01:13:55.726, Speaker B: So in some sense, in some sense.
01:13:55.830 - 01:14:12.074, Speaker A: From this statement, it should follow that the Laplacian basically converges along, along a sequence of spaces. And if the Laplacian converges, well, you know, you are in a very good spot for passing to limiting basically whatever differential identity or inequality you happen to handle.
01:14:13.614 - 01:14:16.686, Speaker B: So this is basically the root of.
01:14:16.710 - 01:14:26.434, Speaker A: The stability of differential quantities in the CD or RcD setting. It's based on this plus the stability of the system.
01:14:27.194 - 01:14:31.690, Speaker B: All right, let's do this theorem. Okay, now, this theorem is surprisingly, with.
01:14:31.722 - 01:14:40.654, Speaker A: All these work that you've done so far, the proof is surprisingly simple, because let me define, you know, define.
01:14:42.714 - 01:14:43.002, Speaker C: You.
01:14:43.018 - 01:14:51.374, Speaker A: Know, mu t via, you know, star. Okay, let me forget, instead, let me forget about this line, if you wish.
01:14:51.674 - 01:14:54.326, Speaker B: Let's move that I define mutant this.
01:14:54.350 - 01:14:59.926, Speaker A: Way, if I prove that this guy, you know, satisfies our definition of gradient.
01:14:59.950 - 01:15:04.726, Speaker B: Flow analytology, then we're done, because we.
01:15:04.750 - 01:15:09.034, Speaker A: Knew by, we already proved that this gradient flow directive is unique.
01:15:09.414 - 01:15:10.154, Speaker C: Right?
01:15:14.174 - 01:15:25.426, Speaker B: So, aim, the aim is to prove that the entropy of mu zero is.
01:15:25.450 - 01:15:29.706, Speaker A: The same as, actually, I should put it this way, is the greater equal.
01:15:29.730 - 01:15:33.426, Speaker B: Than the entropy of mu t plus.
01:15:33.490 - 01:15:38.814, Speaker A: One half the integral of mu s dot squared plus the slope.
01:15:40.754 - 01:15:46.554, Speaker B: Squared of mu s, right? For everything.
01:15:49.294 - 01:15:58.194, Speaker A: You remember, because. Because the other inequality is always satisfied. So if I get this, I get the gradient flow, and it's sufficient to check this.
01:15:59.654 - 01:16:04.754, Speaker B: Okay, now let me write three things that we know. On one side.
01:16:08.574 - 01:16:10.956, Speaker A: We know that this guy is equal to minus.
01:16:11.070 - 01:16:14.044, Speaker B: Okay, let me assume.
01:16:16.144 - 01:16:24.152, Speaker A: Let me assume that mu zero, you know, that if.
01:16:24.168 - 01:16:26.856, Speaker B: You wanted f, as usual, is bounded.
01:16:26.880 - 01:16:45.832, Speaker A: From below by a positive constant and bounded from above by another constant. For simplicity, then, I mean, we can conclude under this assumption. Then by, you want the stability of the gradient flows. In both cases, you know, both in the l two sense and reverse sense, we can conclude. So let me just allow me to be a little bit lazy and assume.
01:16:45.888 - 01:16:50.424, Speaker B: This, make this assumption, and then, notice.
01:16:50.464 - 01:16:57.164, Speaker A: That we do know the dissolves.
01:17:03.244 - 01:17:11.356, Speaker B: We do know that these also, let me write this way, the minus, this.
01:17:11.460 - 01:17:13.704, Speaker A: This is less or equal than the same quantity.
01:17:14.244 - 01:17:22.344, Speaker B: And also that this law of the entropy is less or equal than the same quantity.
01:17:24.924 - 01:17:37.424, Speaker A: So this, so we know that the entropy, no, the map that takes t, that has the entropy of mu t, is really the same as the map that takes t and returns and returns the integral of ft log ft.
01:17:39.484 - 01:17:39.772, Speaker C: And.
01:17:39.788 - 01:17:43.804, Speaker A: We'Ve already seen that this map is absolutely continuous with derivative, that is given.
01:17:43.844 - 01:17:44.904, Speaker B: By this expression.
01:17:47.364 - 01:17:48.104, Speaker C: Right?
01:17:49.844 - 01:17:53.984, Speaker B: So this we know this is Quadruple's lemma.
01:17:56.944 - 01:18:09.736, Speaker A: And this is the statement that we just proved. If you remember that under the assumption of k convexity, this slope is actually w two lower semicontinuous. So in particular, also, you know, weakly.
01:18:09.760 - 01:18:12.592, Speaker B: Lower semicontinuous, remember this.
01:18:12.648 - 01:18:13.864, Speaker A: So k comma. Now, because.
01:18:13.904 - 01:18:17.112, Speaker B: Because you can write the slope as a soup, right?
01:18:17.168 - 01:18:18.920, Speaker A: Not as a limb soup, and therefore.
01:18:18.952 - 01:18:21.864, Speaker B: It'S lower semicontino, right?
01:18:24.004 - 01:18:30.100, Speaker A: So these three together give the entropy, time zero minus the entropy at time.
01:18:30.132 - 01:18:34.556, Speaker B: T is the same as the inter, from zero degree of this expression, but.
01:18:34.580 - 01:18:38.544, Speaker A: This expression bounce from above both the speed and the entropy and the slope of the entropy.
01:18:40.204 - 01:18:42.988, Speaker B: Okay, and by the way, this is.
01:18:42.996 - 01:18:56.988, Speaker A: A further confirmation that this inequality in Quadra's lemma must be sharp for most of the team, because there's no rumor of getting a snake in the code. But this perhaps was clear also from the proof of identification of the relaxed slope and the weaker, the weak of the.
01:18:57.156 - 01:18:57.716, Speaker C: Makes sense.
01:18:57.780 - 01:19:24.772, Speaker A: I mean, there's nothing else to be done. It's done. Okay, I should, I should, I should discuss what happens if my original density is not, is not bounded from above or from below. And what I would do, I will truncate and be sure that everything passes through the, and everything does, because basically at the right hand side we have something which has the tendency of being lower semicont, the slope is lower semicontinuous. This is a vastness speed. The vastness speed tends to be lower semicontinuous. With respect to weak convergence, the entropy.
01:19:24.788 - 01:19:28.140, Speaker B: Is passed the limit plus details.
01:19:28.172 - 01:19:32.784, Speaker A: But, you know, already for positive initial datum, this is, you know, quite strong.
01:19:34.924 - 01:19:35.864, Speaker C: Makes sense.
01:19:36.804 - 01:19:39.652, Speaker B: So that, you know, so we basically.
01:19:39.708 - 01:19:54.234, Speaker A: Have now, okay, I have to predict what dilemma. But basically now we have all the tools to really start, you know, making serious analysis. On CDK species we have this identification. These two words now communicate, l two and w two. They communicate in a very strong way.
01:19:54.974 - 01:19:55.834, Speaker C: Okay.
01:20:00.094 - 01:20:03.470, Speaker B: Okay, it remains to look, what does lemma, this, this.
01:20:03.542 - 01:20:13.574, Speaker A: So, which is, you see the corners? And so this is where, this is where, you know, I start with something related, l two related, and approve something w two related.
01:20:14.074 - 01:20:17.066, Speaker B: Okay, so this is where the magic.
01:20:17.090 - 01:20:36.446, Speaker A: Happens, if you wish. And, and, and I will. So, I don't think so today we, I don't think I will have time to prove this, but at least let me show you how to reduce quadrant.
01:20:36.510 - 01:20:42.594, Speaker B: Lemma to another statement, namely this hoplux.
01:20:45.534 - 01:20:47.474, Speaker A: Formula, Hamilton Jacobi equation.
01:20:48.054 - 01:20:53.606, Speaker B: Let me give a definition. So for, you know, a given.
01:20:53.670 - 01:20:58.034, Speaker A: So if you have a function x on your preferred metric space value here.
01:20:58.734 - 01:21:05.266, Speaker B: And you have t positive, let me define q t of f at the point x.
01:21:05.450 - 01:21:20.194, Speaker A: This is the Hoflux formula, inf convolution model. You see the approximation, there's a lot of different names. And this proves, of course, that this is quite an important thing. So, let me take the inf over.
01:21:20.234 - 01:21:23.506, Speaker B: Y'S of f of y plus the.
01:21:23.530 - 01:21:26.626, Speaker A: Distance squared between x and y divided by two.
01:21:26.650 - 01:21:28.794, Speaker B: T is a problem.
01:21:31.574 - 01:22:06.654, Speaker A: Now, if you have a little bit of familiarity with PDE's, first order PDE's, and Hamilton Djokovic equation, you know that this is called the hopflux formula in Rb, say. And perhaps you know that this formula provides the unique viscosity solution of the Hamilton Jacobi equation with initial datum f, at least under appropriate assumptions on f. Interestingly, this concept of viscosity solution, you know, is retained. It can be pushed, if you want, even to the metric setting. I don't want to go that far. For me, I'm satisfied. I will be satisfied with the following statement, which in this form, I think.
01:22:07.914 - 01:22:18.694, Speaker B: I think this goes back to my paper with Ambrose and Savare, but there are, I should quote other colleagues.
01:22:25.414 - 01:22:50.964, Speaker A: Okay, now I don't remember the names. On Friday, I will. There are other names to be added here. Let me just point out, so that on PI spaces, this was known. On PI spaces, this was also observed by Lotta and Milani, more or less on this data. Okay. Anyway, the statement is this.
01:22:51.084 - 01:22:57.904, Speaker B: So let's assume that f is lip sheets and bounded on x.
01:22:59.844 - 01:23:05.932, Speaker A: You start with a function which is bounded, of course. I mean, here, if I don't put assumption, it could be that this inference identically minus infinity.
01:23:05.988 - 01:23:10.084, Speaker B: Let's say that the function f is.
01:23:10.124 - 01:23:18.434, Speaker A: Unbounded from below, you know, in a very bad way. But let me say that I start from an, then the map that takes.
01:23:18.474 - 01:23:22.450, Speaker B: T and returns the qtf as a.
01:23:22.482 - 01:23:36.774, Speaker A: Map takes value in the space of continuous bounded functions. I mean, where, you know, in the target space, we take, we take the subnorm.
01:23:37.234 - 01:23:37.974, Speaker C: And.
01:23:39.754 - 01:23:42.836, Speaker B: For every x in x, if.
01:23:42.860 - 01:23:44.236, Speaker A: I look at the curve, of course.
01:23:44.300 - 01:23:46.588, Speaker B: So now, if I put the subnaum.
01:23:46.636 - 01:23:49.916, Speaker A: Here, and I know, and I'm telling you that this map is Lipschitz, it.
01:23:49.940 - 01:23:52.100, Speaker B: Means that for every x, the curve.
01:23:52.132 - 01:23:55.544, Speaker A: That takes t and returns qtf at x is Lipschitz.
01:23:56.324 - 01:23:57.068, Speaker C: Right.
01:23:57.236 - 01:24:07.116, Speaker A: But what I'm telling you is that Dt of qtf at x plus the asymptotic ellipses constant squared of qtf at.
01:24:07.140 - 01:24:10.730, Speaker B: X divided by two, this is less.
01:24:10.762 - 01:24:11.934, Speaker A: Or equal than zero.
01:24:13.554 - 01:24:16.738, Speaker B: Let me say for almost every, I.
01:24:16.746 - 01:24:19.786, Speaker A: Mean, I could say more than this, but let me just be content with this.
01:24:19.850 - 01:24:25.774, Speaker B: Do you have a question? Okay, so you see, up to these.
01:24:27.994 - 01:24:32.914, Speaker A: You know, inequality on RD, this would be an equality. And here you would have grada QTF.
01:24:32.954 - 01:24:37.302, Speaker B: Squared, if you know about the hemitone equation.
01:24:37.358 - 01:24:42.950, Speaker A: So in some sense, this, this inequality is retained even, even in the normal.
01:24:42.982 - 01:24:48.046, Speaker B: Setting, in the metric setting. Okay, now what I do today, I.
01:24:48.070 - 01:25:02.914, Speaker A: Conclude by showing how this proves corvados lemon. So then on Friday, I will prove, I will just stick to the hoplux, you know, formula that, by the way, has nothing to do with reference measures. This is a statement of metric spaces. There is no measure.
01:25:04.294 - 01:25:05.114, Speaker C: Okay.
01:25:26.094 - 01:25:51.530, Speaker A: So let me repeat this did not quad as lemma. So given that I stated it maybe 1 hour ago. So we have a metric measure space with m, the reference measure, which is a pro, which is a probability measure with bound with finite second moment, bound at second moment on x. Okay, we start from a probability density, which happens to be, you know, bounded from below and from above by positive constants. We're strictly positive.
01:25:51.622 - 01:25:54.494, Speaker B: Okay, I take the measure.
01:25:55.074 - 01:25:58.386, Speaker A: I take the, you know, the gradient flow trajectory of the trigger energy starting.
01:25:58.410 - 01:26:03.106, Speaker B: From m. And I define this measure of mu t. And the statement of.
01:26:03.130 - 01:26:04.626, Speaker A: Quadratic is that the map that takes.
01:26:04.650 - 01:26:07.834, Speaker B: The mu t is continuous on the.
01:26:07.874 - 01:26:09.938, Speaker A: Bull half line and absolutely continuous on.
01:26:09.946 - 01:26:11.818, Speaker B: The open half line with respect to.
01:26:11.826 - 01:26:14.694, Speaker A: The velocity and distance with this precise estimate on the speed.
01:26:16.514 - 01:26:21.784, Speaker B: Okay, now, the continuity estimate is trivial.
01:26:22.964 - 01:26:25.636, Speaker A: Because ft is continuous in l two.
01:26:25.740 - 01:26:28.956, Speaker B: Up to zero the space, the reference.
01:26:28.980 - 01:26:35.700, Speaker A: Measure m is finite. So continuity in l two implies continuity in l one, which implies weak continuity in the sense of measures.
01:26:35.812 - 01:26:37.580, Speaker B: There's the second moment.
01:26:37.612 - 01:26:59.594, Speaker A: The second moment are uniformly bounded. There is nothing that goes wrong in there. We won't take, you know, if you're bothered by the difference between weak convergence w convergence, just, just say that the space is compact. So that's, that's not really the point. Now, the hard point is in this and this estimate. So let's, let's have a look at this. So let's proof.
01:26:59.594 - 01:27:09.222, Speaker A: So, pick a t, strictly positive, s bigger than t, and, you know, we.
01:27:09.238 - 01:27:13.224, Speaker B: Need to estimate from above this guy.
01:27:15.604 - 01:27:29.924, Speaker A: Yeah, from a ball. And how can we. So, here we have a situation where you know how to build an optimal plan, admissible optimal a priori. We have no idea. And the trick is to use the dual formulation.
01:27:30.084 - 01:27:34.644, Speaker B: So this is the same as the soup over phi.
01:27:34.764 - 01:27:36.772, Speaker A: Let's say continuous and bound, actually lipsticks.
01:27:36.788 - 01:27:40.784, Speaker B: And bounded of the integral of phi.
01:27:41.124 - 01:27:41.716, Speaker A: What is this?
01:27:41.740 - 01:27:44.828, Speaker B: D mu t plus the integral of.
01:27:44.836 - 01:28:07.634, Speaker A: The c transform of phi dim us, where c for the cost function, which is distance squared over two. This is the dual formulation. Okay, while it is unbounded by an approximation argument a priori, I said no among all fives. But let me, let me just, you know, by approximation, can you do this?
01:28:08.094 - 01:28:10.630, Speaker B: And now what this has to do.
01:28:10.662 - 01:28:15.366, Speaker A: With the oplux formula? Well, this is the same as the soup among psi that are leap sheets.
01:28:15.390 - 01:28:18.950, Speaker B: And bounded of the integral of q.
01:28:19.102 - 01:28:26.194, Speaker A: One psi d mu s minus the integral of psi d mu t.
01:28:28.494 - 01:28:31.624, Speaker B: Think psi to be equal to minus five.
01:28:31.744 - 01:28:33.032, Speaker A: And notice that, you know, if you.
01:28:33.048 - 01:28:35.880, Speaker B: Recall the definition of c transform with.
01:28:35.912 - 01:28:48.204, Speaker A: This cost, you have that q one of minus phi is the same as phi C. So there's no, there is just algebra.
01:28:50.704 - 01:28:51.564, Speaker B: All right.
01:28:56.684 - 01:29:01.364, Speaker A: And why this makes our life easier?
01:29:01.524 - 01:29:02.224, Speaker C: Well.
01:29:13.684 - 01:29:22.164, Speaker A: Because now, if I want to bind from above w two squared between these two measures, it's just sufficient to bind from above this difference, any psi.
01:29:22.744 - 01:29:23.484, Speaker C: Right?
01:29:25.064 - 01:29:43.544, Speaker A: And now notice, so let me, let me write once again what it is that I want to bound from above. I have q one psi d mu s minus the integral of psi d mu t. Okay? Which, let me write it in a different way. I mean, it's q one psi fs.
01:29:43.664 - 01:29:48.268, Speaker B: Minus psi ft dm, right?
01:29:48.396 - 01:29:49.932, Speaker A: By the definition of mu s and.
01:29:49.948 - 01:29:55.492, Speaker B: Mu t. Okay, now notice that, you.
01:29:55.508 - 01:30:05.740, Speaker A: Know, by construction, so the map that takes t and returns ft. Actually, put this way, r and return fr is, you know, absolutely continuous on the interval.
01:30:05.772 - 01:30:08.704, Speaker B: T'S with values in l two.
01:30:10.844 - 01:30:19.934, Speaker A: But it's a second protractor. So on that interval, it's absolutely continuous. And the map that takes r and.
01:30:19.974 - 01:30:24.750, Speaker B: Returns q r psi is, by this.
01:30:24.782 - 01:30:27.914, Speaker A: Lemma, is absolutely continuous with values.
01:30:29.774 - 01:30:30.110, Speaker C: From.
01:30:30.142 - 01:30:31.806, Speaker A: Zero one with values in Cb.
01:30:31.950 - 01:30:35.038, Speaker B: But then for theory, with values in.
01:30:35.046 - 01:30:35.754, Speaker A: F two.
01:30:37.694 - 01:30:40.412, Speaker B: M is a probability measure, right?
01:30:40.548 - 01:30:44.636, Speaker A: So if I have a bound on the l infinity norm, it's a bound on the l two norm.
01:30:44.660 - 01:30:45.224, Speaker B: So.
01:30:46.004 - 01:30:47.796, Speaker C: Right, okay.
01:30:47.820 - 01:31:12.952, Speaker A: But therefore, the map that takes r and returns and returns, you know, fr times q arc psi, this is absolutely continuous with values, you know, t with values in l one. Let's, let's, you know, have two cars with residential to I take this color product of these two guys, I guess something, which is, okay, so.
01:31:13.088 - 01:31:22.352, Speaker B: So this guy is equal to the integral from zero to one of the derivative in r of what?
01:31:22.448 - 01:31:37.784, Speaker A: Of the integral. Okay, now should pay. So qr psi f times one minus rt plus r r s. This is integrated in the m, doctor.
01:31:40.924 - 01:31:41.664, Speaker B: Right?
01:31:43.324 - 01:32:05.174, Speaker A: Because in such a. So this is so at time r equal one, this guy is equal to this. At time r equals zero. This guy is equal to this. And I have enough regularity by either, you know, gradient flow theory or this statement about offlux formula. And. And I forgot.
01:32:07.954 - 01:32:08.814, Speaker C: Okay.
01:32:10.634 - 01:32:13.874, Speaker A: And, and, and we can write this.
01:32:13.994 - 01:32:19.626, Speaker B: Okay, now, again, so when I differentiate.
01:32:19.730 - 01:32:31.344, Speaker A: You know, if I, if I have to differentiate, you know, if vt and wt are vectors on a hybrid space. And I want absolutely continuous in time and I want to differentiate. The labyrinth formula is in place, right?
01:32:34.764 - 01:32:35.504, Speaker C: Right.
01:32:37.524 - 01:32:40.340, Speaker A: Or absolutely continuous curves on a Hilbert space.
01:32:40.452 - 01:32:41.104, Speaker C: Right.
01:32:42.444 - 01:32:52.772, Speaker A: So I applied this labyrinth formula here, and what it is that I get? Well, this is equal to the integral double integral, say zero, one. If the limit drops in here I.
01:32:52.788 - 01:33:03.536, Speaker B: Have doctor qr psi and. And then I have f blah blah blah. And then I have plus, I get.
01:33:03.560 - 01:33:10.764, Speaker A: A factor s minus t because of this rescaling q r psi, doctor of f blah blah blah.
01:33:13.024 - 01:33:13.964, Speaker C: Makes sense.
01:33:15.304 - 01:33:22.496, Speaker B: Okay, so, meaning this derivative is bounded.
01:33:22.520 - 01:33:23.704, Speaker A: From both by this guy for almost.
01:33:23.744 - 01:33:28.528, Speaker B: Every t and for any x. So I swap.
01:33:28.696 - 01:33:32.280, Speaker A: This is certainly bounded from above by the integral, you know, from zero one.
01:33:32.312 - 01:33:47.592, Speaker B: Of the integral of leap minus lip r squared q r sine divided by two f one minus rt plus rs, the inequality.
01:33:47.688 - 01:33:50.512, Speaker A: So f is non negative. So I'm not destroying the inequality, but.
01:33:50.528 - 01:33:54.968, Speaker B: Multiply by f. Okay, and what is this guy?
01:33:55.096 - 01:34:01.176, Speaker A: Then I have plus s minus t q r psi laplacian of f to.
01:34:01.200 - 01:34:12.064, Speaker B: One minus rt plus rs d m. Doctor, makes sense. I've done nothing.
01:34:12.104 - 01:34:31.554, Speaker A: Just apply labyrinth for one weak integration by parts for te laplacian. This guy, this guy is less or equal then. Okay, the interval from zero to one of the intro, I keep the first guy dip a squared u r psi.
01:34:31.714 - 01:34:36.614, Speaker B: Divided by two f at one minus rp plus rs.
01:34:36.954 - 01:34:44.130, Speaker A: And this guy, what do I get? I get a plus s minus t, minimal weak upper gradient of q t.
01:34:44.202 - 01:34:54.184, Speaker B: Q r psi minima. We can pregnant of f at the, you know, indicator plane. Makes sense.
01:34:56.924 - 01:35:00.860, Speaker A: All right, let me, let me divide by the square root of f, multiply.
01:35:00.892 - 01:35:04.332, Speaker B: By this root of f, and now.
01:35:04.428 - 01:35:14.510, Speaker A: And now I apply young inequality. I split. So I give this guy to this factor and squared. So this is less or equal.
01:35:14.542 - 01:35:21.958, Speaker B: Then let's look what happens. Minus leap a squared q rhapsine divided.
01:35:22.006 - 01:35:30.814, Speaker A: By two f at this point this time. And then I get a plus one half, the minimal weak upper gradient of.
01:35:30.854 - 01:35:39.490, Speaker B: Q r psi squared f plus s minus t squared over two, the minimum.
01:35:39.522 - 01:35:43.014, Speaker A: Weaker per unit of f squared divided by f. The MdR.
01:35:46.594 - 01:35:56.894, Speaker B: Makes sense. These times square root of f squared times one half. You know this guy makes sense.
01:35:57.834 - 01:36:04.662, Speaker A: This guy, this is this. And you know this guy.
01:36:04.718 - 01:36:08.074, Speaker B: This guy is this. Okay.
01:36:10.574 - 01:36:14.126, Speaker A: But now we are saying a couple space. F is non negative.
01:36:14.270 - 01:36:16.382, Speaker B: This is a relaxed slope and this.
01:36:16.398 - 01:36:20.714, Speaker A: Is the absolute obligation constant. Clearly this quadrant is bigger than this.
01:36:22.934 - 01:36:28.038, Speaker B: Qr is literally okay if you want.
01:36:28.086 - 01:36:32.854, Speaker A: Let me add this qr and lipids. Ur is lipids.
01:36:35.234 - 01:36:36.954, Speaker B: Okay, let me add to the conclusion.
01:36:36.994 - 01:36:42.618, Speaker A: So it's true, the minimum complex boundary from the residential constant, so I can.
01:36:42.666 - 01:36:45.694, Speaker B: Erase these two and the inequality is still true.
01:36:46.234 - 01:37:00.634, Speaker A: And now I am extremely happy because there is no psi anymore in here. This is true for any psi, lipids unbounded. The difference above is bounded by this. In this guy, there is no psi. So when I take the super psi.
01:37:01.454 - 01:37:05.634, Speaker B: What I get, let me write here above.
01:37:07.214 - 01:37:11.954, Speaker A: This quantity is less or equal.
01:37:12.454 - 01:37:15.486, Speaker B: So this quantity is less or equal.
01:37:15.510 - 01:37:23.484, Speaker A: Than s minus t squared over two. The integral from zero to one of the integral of d f one minus.
01:37:23.564 - 01:37:27.636, Speaker B: Rt plus rs squared divided by f.
01:37:27.660 - 01:37:30.104, Speaker A: In this here dm, doctor.
01:37:31.044 - 01:37:33.780, Speaker B: Right, that's, there's this guy over here.
01:37:33.812 - 01:37:35.424, Speaker A: That I copied over there.
01:37:36.004 - 01:37:36.904, Speaker B: Okay.
01:37:39.284 - 01:37:40.012, Speaker C: And I'm done.
01:37:40.068 - 01:38:02.464, Speaker A: You see that? So that's already, you know, this quantity in particular, by the maximum principle, f at later time is always bounded from below by this constant. So, and I'm writing a bed inequality is less or equal than some constant s minus t squared.
01:38:02.544 - 01:38:05.480, Speaker B: The integral, you know, of the minimum.
01:38:05.512 - 01:38:07.064, Speaker A: Weak per gate of f at this.
01:38:07.104 - 01:38:08.968, Speaker B: Later time, the r, right?
01:38:09.096 - 01:38:09.804, Speaker C: Yeah.
01:38:10.744 - 01:38:13.672, Speaker B: Okay, this is the energy, this is.
01:38:13.688 - 01:38:20.884, Speaker A: The chigger energy, the chigger energy of, you know, f at later times.
01:38:24.504 - 01:38:25.360, Speaker B: All right?
01:38:25.512 - 01:38:40.960, Speaker A: But the trigger energy of f at later times, you know, is bounded from below. But the trigger energy of f at initial time. So this makes sense. So this proves, this proves, this proves that this is less or equal than constant times s minus t squared times.
01:38:40.992 - 01:38:44.414, Speaker B: The trigger energy of f at times zero, right?
01:38:46.994 - 01:39:12.864, Speaker A: Okay, which, okay, at least, at least if f, if slip sheet is already bounded. Otherwise I have to add by approximation, okay, and once, you know, so, so, so this was the vast distance scored between mu a time t and mu times s. This distance squared is bounded by s minus t squared times the number. So this prove lips discontinuity of the.
01:39:13.524 - 01:39:17.944, Speaker B: Of this curve on this compact interval makes sense.
01:39:19.084 - 01:39:26.732, Speaker A: And once I release elliptic continuity, this bound comes from, you know, I just proved, you know, I proved that one.
01:39:26.788 - 01:39:29.492, Speaker B: Half, you know, if you want, if.
01:39:29.508 - 01:39:42.880, Speaker A: You want to prove that one half w two squared mu t mu s is bounded by this quantity. So now you divide by s minus squared, you let s go to t, and by a big argument, by an argument on the back points, you do.
01:39:42.912 - 01:39:46.544, Speaker B: This, okay, so you first have elite.
01:39:46.624 - 01:39:54.640, Speaker A: Bound, just because, just because you exaggerated a bit. You put here, if you want, if not, the trigger energy times zero, you can also put here the trigger energy.
01:39:54.752 - 01:40:01.044, Speaker B: At time t. If you wish. Okay. Makes sense, right?
01:40:03.284 - 01:40:24.220, Speaker A: And perhaps, let me, let me be, let me be a bit more precise over these steps so that I don't have to, you know, to show them and I'm not cheating. So this is the interval from zero to one of this quantity. Now, the denominator is uniformly bounded from below. Let me put this constant over here. And then we put also the two in here. And here you have the integral between zero and one of the energy of.
01:40:24.332 - 01:40:27.292, Speaker B: One minus rt plus rs.
01:40:27.428 - 01:40:36.472, Speaker A: Okay, but is it. So this is the same as c s minus t squared. The interval to zero one of the chigger energy of f at one minus.
01:40:36.528 - 01:40:47.524, Speaker B: R t plus rs. Doctor. Okay, but for ar, this quantity is less or equal than the trigger energy, time t. Okay.
01:40:49.144 - 01:40:55.232, Speaker A: Because the energy decreases the longer flow. Okay, and this is finite, right?
01:40:55.368 - 01:40:58.282, Speaker B: I mean, this quantity is finite because.
01:40:58.378 - 01:41:01.626, Speaker A: At any positive time you fall, you fall into domain of the nf.
01:41:01.770 - 01:41:04.666, Speaker B: Okay, so now I.
01:41:04.730 - 01:41:09.834, Speaker A: So I proved that the curve is local elib sheets and with a sharp bound on the spit.
01:41:09.994 - 01:41:10.814, Speaker B: Okay?
01:41:11.914 - 01:41:23.054, Speaker A: So anything is reduced. And last time we start from this from to the study of the hopflux formula and the Hamilton Jacobi semic group in arbitrary matrix spaces.
01:41:24.614 - 01:41:28.954, Speaker B: Okay? And that's all for today.

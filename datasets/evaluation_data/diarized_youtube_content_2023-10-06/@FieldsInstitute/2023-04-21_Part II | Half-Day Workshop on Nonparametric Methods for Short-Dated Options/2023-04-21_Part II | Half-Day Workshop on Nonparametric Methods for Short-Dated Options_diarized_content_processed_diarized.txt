00:00:00.320 - 00:00:13.446, Speaker A: Okay, I will start now. So this will be part two. And then there will be drinks.
00:00:13.630 - 00:00:15.134, Speaker B: Yes. And food.
00:00:15.254 - 00:00:35.084, Speaker A: And food. Equal proportions. We know that. Okay. All right, so by what I'm going to do in the second half, in a way, that's probably the easier problem, but. Well, yeah, it's somewhat easier. It relates to things which many more people probably have studied.
00:00:35.084 - 00:01:09.566, Speaker A: So what I'll be talking about is spot volatility now. And so I'll not be estimating the jump part, but I will be basically trying to estimate the other component, or the remaining component in the price dynamics that we saw. Okay, so let's just remind ourselves. Well, we will go through those things. What I will cover, you will see in a minute. Well, not in a minute, but in the next hour and a half. So, okay, so what was the dynamics? I switched now to lock price before it was the price.
00:01:09.566 - 00:01:29.554, Speaker A: This is now just the lock price. And so remember the dynamics which we had for the process. X, we have a drift, we have the volatility, we have the jumps. Okay. This horrible piece here. Now we will just try to forget about it. So I'm not going to talk about its notation and stuff.
00:01:29.554 - 00:01:50.226, Speaker A: And instead we will focus basically on the, on the stochastic volatility. Okay, stochastic volatility. The nice thing also about the volatility and which makes it also very directly a way easier to test. What, what I'm going to do is actually kind of gut or well done.
00:01:50.290 - 00:01:53.866, Speaker B: Is that that sigma should be the.
00:01:53.890 - 00:02:18.814, Speaker A: Same on the p or under q. And so if I recover it correctly from the option data, that should actually compare with what I can see returns and actual volatility of returns. Okay. And so my goal will be basically the non parametric recovery of the non parametric recovery of the spot volatility from the options.
00:02:19.374 - 00:02:23.070, Speaker B: Now how is that different from black Scholes?
00:02:23.102 - 00:03:12.764, Speaker A: I mean, if you think about black Scholes implied volatility, that's basically what the goal of the black Scholes implied volatility calculation was. Right? I mean, you have an option pricing model and you try to invert back from the option price, the volatility. Okay, the only thing is that the black Scholes implied volume is basically, is derived under model which we know doesn't work, meaning that the volatility varies over time. And so what I will do, basically is we will take advantage now of short datedness of the options and try to recover from these options, basically the spot volatility that essentially is the goal. And then you can do many things with this and I will show you some of these applications.
00:03:12.844 - 00:03:16.824, Speaker B: Okay, so what's the idea?
00:03:17.164 - 00:03:49.262, Speaker A: Very similar motivation as before. So if time to maturity is short, then you can pretend basically that the volatility stays constant, that the drift term doesn't change. And then the measure here is constant. In other words, doesn't depend on time. It's the same jump measure. So in other words, the model is approximately what we call levy. And these three terms here, the a, the sigma and the nu, uniquely identify its law.
00:03:49.262 - 00:04:08.664, Speaker A: And again, I'm interested, I'm interested in sigma. Again, I will be using out of the money options. So it's for symmetry. I put also the notation here. That's the, the option price for puts and calls. Okay. Okay.
00:04:08.664 - 00:04:39.382, Speaker A: And so now we start thinking basically, how can we extract from the options information about the spot volatility? First thing, actually, to realize, which was in a way, it was already true in the previous presentation, but I didn't highlight it. But for what we are going to do now, it's relevant is that how this option prices decay as time to maturity goes down to zero.
00:04:39.558 - 00:04:40.014, Speaker B: Okay.
00:04:40.054 - 00:04:50.262, Speaker A: And so I'll just spend a little bit of time to discuss this because this will be related to how we extract volatility. So if your option price, if you're looking at, at the money option price.
00:04:50.358 - 00:04:53.974, Speaker B: Okay, or option with a strike very.
00:04:54.014 - 00:05:39.714, Speaker A: Close to the money in an asymptotic sense, you can be very formal here, basically, and say how close that is. But. Okay, but just think about it. If you're looking at the money option price, for simplicity, then the way option price decays as time to maturity goes down to zero is actually square root of t, t is the time to maturity. And the way the option, if you are in the tails, if you are away from the money, if you're looking at out of the money, deep out of the money puts these option prices actually decay much faster. They decay at t, right? Remember, even though this is this capital, t here is the time to maturity, and that thing is going down to zero. So if this number is very close to zero, when you take the square root of it, it's much bigger than the t.
00:05:39.714 - 00:06:38.544, Speaker A: So the option surface or the option as a function of the strike, it's all kind of going down to zero, but it's not doing it in a uniform way. It's actually rather uneven and kind of complicated. Okay, so then if I, now the first thing which we can try to do is basically say, okay, well, let's specialize the problem or restrict the problem and say, you can only use one option to extract information about the spot volatility, basically option with one strike. So I just time my hands and say, I will use only one strike to extract the volatility. So which ONe do you think that will be? Which strike would you pick? Where do you think is the strongest signal about the spot volatility? This is like a ClassIc. Any guess which strike. This one special strike.
00:06:38.544 - 00:06:55.174, Speaker A: Right. Add the money. Right. Why? Because basically, the MOney is like you are. That option is very sensitive to even small perturbations in the stock price. You can get you in or out of the money. So it's kind of very sensitive to even SmAll movements in the stock price.
00:06:55.174 - 00:07:20.590, Speaker A: And basically, this Brownian piece here is capturing exactly that. Right. I mean, it's kind of this. A lot of it. A lot of the variation generated from this PieCE here is from a lot of small moves in the STocK price. And so that's a natural place, basically, to look at the money option prices. And so somebody asked me here about what you would do with what will happen with the black scholes implied volume.
00:07:20.590 - 00:08:04.424, Speaker A: And so, for once, and that's ProBaBLY the ONly slide in all of these 3 hours of Lecturing where I have black scholes implied volume. Okay. Maybe there's a second slide, I think, later on. Okay, so, in any case, what I did here is the following thing. I simulated from a Heston model with jumps, okay? And I basically. And then, because it's a simulation, I calculated options with different, the black scholars implied volts from that model for options with different times to expiration. Okay? And so here, the units of time here are days, which means that trading days, t one is one day, two days, five days, eight days.
00:08:04.424 - 00:08:17.240, Speaker A: When I did that, of course, I was thinking that's kind of. Of course, mostly for pedagogical purposes, because I wasn't thinking, we will be trading one day options, but here we are. That actually is kind of relevant now.
00:08:17.312 - 00:08:18.084, Speaker B: Oops.
00:08:18.424 - 00:08:52.818, Speaker A: And so what you can see is, where is the true volatility? The true volatility is somewhere close to 1012 percent. I forgot what was the number I put. And you can see that different maturities really differ a lot here in the tails. But they do actually, they do share a lot of similarities here. And this is where the true. Well, the true volatility is somewhat closer, basically, to the black Scholes implied volatility you see at the money. And so that's a natural thing.
00:08:52.818 - 00:09:26.282, Speaker A: And actually, people have used in the past, in somewhat informal sense, basically said, okay, we know black Scholes doesn't work, but black Scholes implied volume at the money is sort of close to the true volatility. It's a good proxy. And so how good of a proxy is this? Indeed? You can do a very simple expansion that's really just like a Taylor expansion of the option price at the money, and you can get it. So option price, add the money.
00:09:26.458 - 00:09:29.282, Speaker B: You can see basically that, by the.
00:09:29.298 - 00:10:00.934, Speaker A: Way, here, this is a log strike, but I have normalized the current stock price to one. So k, little k, which is a log strike equal to zero, means that I am at the money. So that's kind of an easier normalization. So k equals zero means at the money. Okay? And so forget about this kt, which is kind of something which approaches. So think about k here, kt, replace it with zero. And what you're getting is f of zero, which is the standard normal density evaluated at zero Times square root of sigma t.
00:10:00.934 - 00:10:48.344, Speaker A: This thing drops out, and then you have something of order approximation error for the, which basically means that the spot volatility, you can recover it square root of two PI times the option price at the money. Option price. Or if you prefer, you can just say implied volume at the money. Implied volume is basically an approximation for the spot volatility. So if time to maturity goes down to zero, it's basically at the money. Black scholes is giving you the, it's an approximation for the spot volatility. So then I ask myself, well, how good is this approximation? And so again, I use the same model that I used.
00:10:48.344 - 00:11:09.984, Speaker A: I used the same model that I used for generating these plots here. And I simulated it, but I just simulated it over a number of days. Okay, so not just a single day, I simulated over number of days. And this is time in days. So this is business day convention. So that's basically one year of data. I simulated one year of data.
00:11:09.984 - 00:11:23.084, Speaker A: What you see the blue line is the true volatility, and the dashed line is the money spot volume. At the money. Black shows volatility for option, which has a one week to expiration.
00:11:23.624 - 00:11:24.344, Speaker B: Okay.
00:11:24.464 - 00:11:47.612, Speaker A: Option with one week to. This is really short. Right. This is one week to expiration. And I'm looking at the money black shows. Okay, so what you can see is that that approximation actually, well, it's an approximation, but it's not a very good approximation because the gap is really nearly 50%.
00:11:47.708 - 00:11:47.940, Speaker B: Right.
00:11:47.972 - 00:12:04.120, Speaker A: I mean, you are kind of almost. Well, or rather. Yeah, yeah. Some over 50%. Basically, you have over 50% bias. And what's worse about it is that the dynamics, that the gap is actually kind of varying over time. So it's not like a level shift to something like this.
00:12:04.120 - 00:12:25.976, Speaker A: Neither. It's proportional. So it's kind of basically, they have something. This model, by the way, was a model where you had Heston volatility and then you had jump intensity proportional to volatility. So in some sense, everything is very close to volatility. So the dynamics even should be very close. But, you know, and while they are first order, they are similar.
00:12:25.976 - 00:12:59.894, Speaker A: There's still quite a big difference. And then, okay, so then you say, okay, well, at this point, then you say maybe. Well, that's basically it. I mean, I know that if I take the time to maturity very close here because of this derivation, because of this derivation that I showed you here, I know that eventually, when capital t becomes very small, that approximation should work. And indeed, if I take t to less than a day, this approximation starts working somewhat.
00:13:00.354 - 00:13:01.254, Speaker B: But then.
00:13:01.754 - 00:13:39.678, Speaker A: Yeah, but then that will be not useful or practical for most of the options we have. Or rather, if I restrict myself just to use it for a couple of hours during the expiration date, I don't think that's very practical. Okay, so, so, yeah, so there were two options from. To conclude from that. Either that's a dead end and basically that's it, or maybe just the black Scholes was not implied. Volume at the money was not the optimal thing to do. And so, and luckily, it turned out that this is the case, meaning that there's something else you can do which is better than this, which can get you closer to the true volatility.
00:13:39.678 - 00:13:50.554, Speaker A: And that's what we're going to do now. And you know what? It will be based on the same type of analysis that we saw in the first part today. So in that sense, everything is kind of.
00:13:52.694 - 00:13:53.514, Speaker B: Connected.
00:13:54.854 - 00:14:35.650, Speaker A: So again, I will apply that formula. I will apply that formula that we've seen before that I showed you from Karan Madan, which basically allows you to do option spanning and to span any smooth function of the terminal price. And now what I will be looking at, I will be looking. Okay, so I'll ask myself, what is a convenient. So when I'm doing this now, of course, we have to realize that I'm going to, I'm more expensive in terms of the data, right? Because I'm saying I will use all strikes, but already I'm using the strikes when I'm calculating the vix. And I have no problem with that. So I'll do the same thing here.
00:14:35.650 - 00:14:53.024, Speaker A: Okay? So I'm not just picking one option now. I'm going to use more strikes. But if we have them, why not let's go and use them? And so now I'm going to ask myself, what is the function f, which will basically separate the volatility from the jumps in an easiest way?
00:14:53.184 - 00:14:54.008, Speaker B: Okay?
00:14:54.176 - 00:15:16.644, Speaker A: And when you start thinking and start putting these things in this context, then of course, I have done, in my earlier part, earlier academic life, a lot of work on high frequency data, high frequency returns. And that, exactly that same question we've asked ourselves, or people before me asked themselves rather, because I came a little bit late.
00:15:18.354 - 00:15:18.778, Speaker B: Yeah.
00:15:18.826 - 00:15:21.186, Speaker A: And so people were doing already things like that.
00:15:21.290 - 00:15:24.770, Speaker B: And so then the first guess is.
00:15:24.962 - 00:15:31.570, Speaker A: To do this thing which we, I call basically smooth truncation, okay?
00:15:31.682 - 00:15:33.354, Speaker B: So it's very natural.
00:15:33.394 - 00:16:10.864, Speaker A: So if I look at returns, okay, the way people done in the high frequency literature is the following. You look at high frequency returns over five minutes, you calculate volatility, and you say, if it's more than three standard deviation movement, normal return will not generate this with a very high probability, okay? And so you say, if it's a more three standard deviation move, that must be a jump. That's it. I mean, that's such a simple thing, right? Intuitive thing. And so you can try to do the same thing here. And so that's the first attempt I had, which is basically this smooth truncation function. So you see why calling it, well, first of all, this is a smooth function of x.
00:16:10.864 - 00:16:17.380, Speaker A: That's why it's smooth. Why is it truncation? I mean, think about what you're doing when you are picking ETA, when you.
00:16:17.412 - 00:16:20.852, Speaker B: Start increasing the ETA, okay, basically what.
00:16:20.868 - 00:16:43.754, Speaker A: You'Re doing is you are leaving, you are down, you're putting, you are downplaying or you're kind of putting lower weight on returns. Anything but zero, anything but vicinity of zero. So that's the way basically you can tease out or separate, and the movements around zero are basically controlled by the diffusion. The rest is controlled by the jump. So you can do that. And so I did that.
00:16:43.794 - 00:16:45.922, Speaker B: So basically I can apply, I can.
00:16:45.938 - 00:17:20.114, Speaker A: Just apply this thing here. I can just apply this formula with this function that you see this, what I call smooth truncation. And then you basically you play with the truncation parameter according to the length of the time to expiration. And that will basically, theoretically it will give you what you want. But at the same time, I was actually working in the high frequency world. What you can do, and turns out is actually it's better in the sense it allows you better to separate the volatility from the jumps. You can use characteristic functions.
00:17:20.114 - 00:18:09.484, Speaker A: And so why not do it here too? In fact, we already did it with the jumps, as you see. So now I will do it with the spot volatility. Okay, so I'm, so again, you can do this thing here, this part, I'm not going to pursue this, but it's in one of the papers, I have written it. I might go back and just revisit because I just. The characteristic function is somewhat easier to do, I think. Okay, so let's go back to the characteristic function and see now how can you tease out from the characteristic function the volatility signal? Well, so remember, this is how you will span it, or span, meaning estimated from the option data. This is what I'm trying to recover, the characteristic, characteristic function.
00:18:09.484 - 00:18:24.096, Speaker A: And this is the integral, which is basically from the option data. So everything here is known, assuming that you also know the option data. So everything here is observable. And so basically you get a direct estimator of the conditional expectation.
00:18:24.220 - 00:18:24.964, Speaker B: Okay?
00:18:25.264 - 00:18:54.422, Speaker A: So that's unique to option data because it's a forward looking kind of variable. And so you can't get the same thing from the returns. There. You get the empirical characteristic function, not the real, not the true conditional characteristic function. Okay? And now again, remember this approximation that I told you that if time to maturity is close to zero, you can pretend that the world is levy. In other words, for our purposes here, that volatility is constant.
00:18:54.518 - 00:18:55.274, Speaker B: Okay?
00:18:55.574 - 00:19:35.034, Speaker A: Now note one thing that I did here, unlike what I was doing before, now I'm looking at the conditional characteristic function, but I'm standardizing by square root of t. Why? Because this way, this term here, there's no dependence on t anymore, right? So, and this is the guy I'm after. Okay? So in other words, what you are looking at here, now, unlike what I was doing before with the jumps, I start looking at, because I'm dividing by square root of t. And so if u is fixed and t goes to zero, that means that I'm looking at higher and higher characteristic exponents, right? Exponents which go to infinity.
00:19:35.694 - 00:19:36.910, Speaker B: Does that make sense?
00:19:37.022 - 00:20:29.148, Speaker A: Oh, it actually makes sense because if you, if you, if you go back and look at this Levi kinshin theorem and see how it's proved, the way basically it's proved that you have a one to one mapping between the law of the levee process and the characteristic exponents is just to say that actually the way you separate the volatilities from the jumps, you look at asymptotically increasing exponents and they uniquely identify this because this becomes negligible. That's how that theorem is proved. And that's what we are going to use in this analysis to. So the behavior of the characteristic function at infinity is controlled only by the diffusion and the jumps. That's intuitive, right? The jumps are the big moves, and so they capture the behavior around zero of the characteristic function. That's basically the logic. But now we can do it a little, now you can see it a little bit more formally.
00:20:29.148 - 00:20:51.666, Speaker A: So what I'm going to say here is, okay, so you have this expression, I'm after this guy, okay? And if I, now look, what I can do is I can look at the real part of the characteristic function or the log characteristic function. This guy is left, it's gone. I don't need to worry about this guy anymore. I have the guy which I want, and I have a mass coming from.
00:20:51.690 - 00:20:56.074, Speaker B: The jumps, which you can hope, basically small, right?
00:20:56.234 - 00:21:31.270, Speaker A: So now let's see it one more time here. So I take now the real part of the characteristic function. I divide it by u squared multiplied by minus two. So that, you know, to take care of this, this, this business here, okay? And, and with that, I basically, I recover what I wanted to recover, which is the spot volatility plus this thing which is coming from the jumps. And I'm hoping that this thing is small. Okay. And is this thing small? Okay, yes, it is.
00:21:31.270 - 00:21:43.620, Speaker A: But why? And so look, y. And it's very easy to do it in the simple case. And then I will show in the other case, it actually works in the most general case, too. But why is that thing small?
00:21:43.732 - 00:21:47.980, Speaker B: Because first off, look, t goes to.
00:21:48.012 - 00:22:26.936, Speaker A: Zero, so that thing goes to zero. And let's just look at the normal case. What most people think of the jumps are finite activity, which means that if nu is like x, like a probability measure, if it's just a probability measure. So that basically means that this function here is bounded and then this integral, then so this is bounded by a constant times the times one if this was a true probability measure, right? And so the fact that there's a division by square root of t doesn't matter here because this is in a co enters in a cosine. That's a bounded function. So this whole thing is bounded and it's bounded. It's bounded by t, which goes down to zero.
00:22:26.936 - 00:22:49.728, Speaker A: So that thing becomes negligible. So, yes, so it has to be small. And now, of course, we know that there are much more general processes for jump measures, not just this finite activity. Compound Poisson type models. And so then what you have to do is basically, you have to see.
00:22:49.816 - 00:22:53.874, Speaker B: Well, at what rate is this measure?
00:22:54.694 - 00:23:26.356, Speaker A: This, okay. Jump measure exploding at zero. Okay. And the way you characterize it, you basically say, look for the power r. What is the smallest power of r that this measure can integrate against? Okay, so this thing is called jump activity. It's a technical term, but you have to know that it lies between zero and two, and zero just basically says that this is finite activity. That just means that the expected number of jumps is finite over finite interval.
00:23:26.500 - 00:23:27.548, Speaker B: And that's more.
00:23:27.636 - 00:24:13.700, Speaker A: So r equals zero is what I was explaining you before. But if you're looking for more general things, then you have to basically, then you have to kind of deal with this business with r and have that thing, it will still be bounded. But now the bigger the r, the more the small jumps are, the bigger the error is here, basically. So I think that it's much easier to just to be thinking for the purposes of what we are doing here is just to be thinking of r equals zero. Okay? R equals zero. You get an approximation. So now let's just compare then this type of estimation with what I just showed you with black scholes implied wall.
00:24:13.700 - 00:24:44.280, Speaker A: Okay? And so first, theoretically, before we go into practice. So the first part here is, the first equation is what I had before. This is the black scholes, okay? This is the add the money option price, but it's equivalent if you write it with terms of black scholes implied volume. Okay? So I just used the option price. And so the error you commit here by treating the at the money option price of the black scholes implied volume as the true volatility is of order.
00:24:44.352 - 00:24:47.736, Speaker B: Square root of t. While here, if.
00:24:47.760 - 00:24:55.444, Speaker A: You use that alternative method with the characteristic function, what you get is an error which is distinct t to the power one minus r over two.
00:24:55.824 - 00:25:00.368, Speaker B: Okay, now I forgot to mention here.
00:25:00.416 - 00:25:34.284, Speaker A: And that actually, this is probably not so smart of me to present it this way. This error is derived for the case when the jumps are finite activity. So this error, what I derived here is for r equals zero. So you have to be looking at this with r equals to zero. So what you see here in this case is that this error is t, while the error here is square root of t. So in an asymptotic sense, this is a much smaller error than this. Okay? So asymptotically, you have to justify basically that tells you that you are having a smaller error when you're doing the separation this way.
00:25:34.284 - 00:25:57.048, Speaker A: And so theoretically it should be better. And we can now look at it at, in reality, basically what kind of job it does. Okay. But in terms of estimation. So that will be my estimate of volatility. I will generalize it a little bit later on, but all I'm doing is the following. You calculate the characteristic function from the options.
00:25:57.048 - 00:26:23.072, Speaker A: Take the logarithm minus two over u squared and just pick the u, which is relatively high. And that's it. And I will tell you how to pick the u afterwards. But that's basically, that's all it is. So here's a calculation of this quantity with using data. So what do I plot here? Okay, let me show you. Let me tell you.
00:26:23.248 - 00:26:31.704, Speaker B: So I've plotted the, so let me go back. So what I plotted is, is this.
00:26:31.744 - 00:27:00.432, Speaker A: Quantity, this quantity, okay, for all variables of u or for a range of values of u, and I used different capital t. Okay, so let's go back here. So this is for all values of u from zero to a high number. Okay, well, whatever, to a number of 25. Okay. And this is, okay. And so what you see on the y axis is my estimator of volatility, which is basically this quantity.
00:27:00.432 - 00:27:16.444, Speaker A: Right. This quantity here, this is my estimate of volatility. All right. And what you see the blue line correspond. So this thing corresponds to, I forgot, one thing correspond to one week and this thing to two weeks.
00:27:16.544 - 00:27:17.344, Speaker B: Okay.
00:27:17.804 - 00:27:58.090, Speaker A: The true level of volatility. So, because this is a controlled experiment in Monte Carlo, I know what the true level of volatility is, and that's basically the solid line here. So what do you see? Basically, as u goes to infinity, this estimator is approaching the true volatility. It's basically converging to the true level of volatility. And if you pick a value around here, basically the approximation error in percentage terms will be less than a percent or something like this, which is pretty, pretty good. It's not 50% as we had it before, but it's more like 1% or something like this. Okay.
00:27:58.090 - 00:27:59.082, Speaker A: That's theoretically.
00:27:59.178 - 00:28:06.746, Speaker B: Yeah. So before the rate option error.
00:28:06.890 - 00:28:22.494, Speaker A: Right. So there's no error right now here. Yeah, that's true. So this is a simulation which option prices were the true option prices, no error, no anything. So that will play a role because for where I picked the u. So I'll come back to this. Yeah, I'll come back to this.
00:28:22.494 - 00:28:36.886, Speaker A: Yeah. You're not going to see them in the data. So, smooth those lines. But before I do that, just to draw your attention, just to see where the things are, because this. I think it's quite intuitive. Well, after I've been so much used.
00:28:36.910 - 00:28:40.150, Speaker B: To seeing this, do you know what.
00:28:40.342 - 00:28:54.350, Speaker A: See, actually, these guys start at the same point. Do you know what that point is? So, basically, do you know what happens if I take. In other words, do you know what happens if I take the limit now of this thing, but u goes to.
00:28:54.382 - 00:28:56.846, Speaker B: Zero, what do you get?
00:28:56.910 - 00:29:19.494, Speaker A: You get the return variance, the total variance. So basically, the limit of the characteristic function of this quantity when u goes to zero. It's a very simple algebra to derive. You will derive the second moment of the return and standardized. So you annualize it. And so what you are basically, in other words, what you are getting here, when u is equal to zero, you're getting the VIX index.
00:29:19.834 - 00:29:20.694, Speaker B: Okay.
00:29:21.154 - 00:29:38.574, Speaker A: But the VIX index contains the jumps and all that kind of mess. Okay. And as you increase u, you basically. You separate the jumps and risk premium, all of the other stuff which is not in the true data, and you're getting down to the spot. Volatility to a true volatility, basically.
00:29:39.074 - 00:29:39.814, Speaker B: So.
00:29:45.394 - 00:30:00.942, Speaker A: I'm not going to pursue. I know I didn't. No, I did derive. I did derive results for it, but I did not do anything. I think that. I think that this is better. I think that this is better, but I'm not so sure whether.
00:30:01.118 - 00:30:08.006, Speaker B: Well, okay, I think that this one is better because it's much easier to.
00:30:08.030 - 00:30:17.446, Speaker A: Characterize the biases in this thing and then to bias correct the other one. Maybe. Yeah. I don't know. I didn't pursue it. Basically. It's smooth.
00:30:17.446 - 00:30:27.414, Speaker A: So maybe. Maybe it's not that bad, either. So I. But I was heavily influenced by characteristic functions back then, so I persisted with this.
00:30:39.914 - 00:30:41.906, Speaker B: Correspond to anything on this picture?
00:30:42.010 - 00:30:58.664, Speaker A: No. That's a difficult connection to make. No, unfortunately. So this is there. The top is Vix, but I can't point to black Scholes, where that will be on the picture. No, I think it's kind of. I thought about this and there was.
00:30:58.664 - 00:31:30.816, Speaker A: Anyways, it's. Yeah, I had some ideas and something to connect with the implied vols, because I vaguely remember something Peter Carr mentioning to me, something about this back in the day, but then I just couldn't recover. There was some ways of. You can represent the Vix alternatively with the black Scholes formulas, implied volts, but then I couldn't recover that kind of. I remember him mentioning this to me at some conference. And then I couldn't see. I didn't have any record of that.
00:31:30.816 - 00:31:39.124, Speaker A: So I. So I don't know. I didn't explore this further, but there must be some ways to connect. It's just not so obvious to me.
00:31:41.964 - 00:31:45.900, Speaker B: Okay, so now, all right, so this.
00:31:45.932 - 00:32:15.248, Speaker A: Is basically, this was a very kind of. Obviously, this is, this was all stylized. No observation error, no anything. I didn't tell you even how to choose U. So the hope is that if I can actually, if I'm very free to choose high values of u, I should be able to recover, well, the true level of volatility. Okay, so now what you have to remember that this observation error, there's finite strike grid. There's all sorts of things like this.
00:32:15.248 - 00:32:40.804, Speaker A: And so we will need to deal with that. So the same notation as I had before. So we don't need to worry about this. So they have the delta, the strike grid, discrete strike grid. You have observation errors. They are centered, they have volatility and things like this. And your estimator then will become basically the discretized version of the integral we saw before.
00:32:40.804 - 00:32:59.184, Speaker A: So this is what you will get. So this is your conditional characteristic function, but basically the Riemann sum version of the integral we saw before. And then I will define my estimate of the variance by this transformation of the conditional characteristics function.
00:33:00.364 - 00:33:03.424, Speaker B: Right. Okay. So.
00:33:05.684 - 00:33:37.626, Speaker A: And then you can derive and characterize the behavior of this characteristic function and say, what is the approximation error? It's the different sources of approximation error. You can say, what is driving this? Maybe we should skip that slide and not, not worry too much about the, there's a CLT associated with this, but that's probably not so important. So what's more important, if you want to apply this thing, is just basically, how do you pick the U? And then here we have a classical bias variance trade off, because if you.
00:33:37.650 - 00:33:41.922, Speaker B: Remember from this plot what you want.
00:33:41.938 - 00:34:00.808, Speaker A: To do, if you want to minimize the bias, what you want to do is pick you as high as possible, because this is where the information about the jumps is gone or any kind of, this PQ edge kind of stuff. It's gone. And so this is, you're getting the true volatility. But of course, the problem with picking.
00:34:00.856 - 00:34:04.232, Speaker B: Very, very high U is that if.
00:34:04.248 - 00:34:28.486, Speaker A: You have tried to estimate conditional, if you have tried to estimate characteristic functions from data, empirical characteristic functions, you know that for very high values of the characteristic argument, they become very noisy because what they're doing is they're kind of doing these oscillations and then basically any small noise gets kind of flared up. And so you can't just do that. And so what you have to do is something sensible like this.
00:34:28.670 - 00:34:32.758, Speaker B: You just say, okay, so I will stop.
00:34:32.846 - 00:34:42.182, Speaker A: The first time, the conditional characteristic function takes a relatively small value, but which is not that small to kind of make the estimation bad. And so you basically, you compute a.
00:34:42.198 - 00:34:45.138, Speaker B: Characteristic function, take the norm of it.
00:34:45.186 - 00:35:02.774, Speaker A: And see the first. It usually kind of doesn't need to be monotone, but it kind of monotonously, typically the case. And the first times it crosses a relatively low threshold, but not as low as you kind of, to think that this is super noisy. You basically, you stop. Okay, and. And that's it. And so, uh.
00:35:02.774 - 00:35:17.188, Speaker A: And that's how we are choosing. That's how we are choosing. That's how we're choosing. The, um. 0.3 is what I experiment, I've tried with 0.20.25, whatever, these kinds of things.
00:35:17.188 - 00:35:56.810, Speaker A: It doesn't, yeah, I think it's fine. It doesn't make much of a difference afterwards, but something where you want to pick it high, but not high enough to be too noisy, basically. Okay, so let me just show you a little bit on data, what gets in and what gets out of this estimation. Okay, so here's one snapshot of a data which we basically out of the money options that we are going to use to calculate spot volatility for that date. January 20, 2016. This is five, I think this was just a week to expiration. Look how beautiful.
00:35:56.810 - 00:37:02.244, Speaker A: Nice and smooth the data looks, by the way, data quality has increased a lot, although, of course, because the scale, everything, any small kind of perturbations are hidden because, you see, I'm plotting option prices, not black scholes, implied volatilities and things like this. But nevertheless, it is relatively smooth, the data, as you can see. So this is at the money here, and here are the puts and here the calls. We have a lot of them, as you can see. By the way, one thing just to, I mentioned this before, but I said that now, this expansion that basically here that we are doing, uses all options with all strikes. And so you're kind of thinking, but how the heck is there any information left in deep, deep, deep out of the money options? So something which is ten sigmas down, put about the spot volatility. And the answer there is none.
00:37:02.244 - 00:37:23.344, Speaker A: And although I'm including it, the weights you are assigning to those options, deep, deep. Altogether, lumen is very low. And so, in fact, asymptotically, you can show that if you can, you can just use a fixed range and everything will work. You don't need to go that much. The intuition is correct. Deep out of the inputs have nothing to do with the spot volatility.
00:37:23.964 - 00:37:24.744, Speaker B: Sorry.
00:37:25.484 - 00:37:31.852, Speaker A: Yeah, it doesn't matter because that's the first order effect, is the spot volume. This is volatility dynamics. Right. The volatility jump.
00:37:31.908 - 00:37:32.544, Speaker B: Yeah.
00:37:33.964 - 00:37:55.296, Speaker A: So, and now, and the reason why I'm bringing this up is just to, because if you're thinking a little bit, you might be confused why all of a sudden I'm kind of making use of all of these options going all the way out, deep out of the money, like these strikes here. They're just pure speculation about what might happen in detail, but nothing to do probably, with reality.
00:37:55.480 - 00:37:57.840, Speaker B: Okay. Okay.
00:37:57.872 - 00:38:07.404, Speaker A: And so this is the data. Then what you do is you do this calculation, you put this data, the option prices, you plug those option prices here.
00:38:07.984 - 00:38:11.568, Speaker B: You calculate this characteristic function, and then.
00:38:11.616 - 00:38:36.736, Speaker A: You plot it against u, and you choose the value of u, for which the characteristic function or the norm of it is 0.3, and you stick with it. And so here's what I plot now. Here is basically, then I can do, I can look at, well, let me look at, let me. That's basically a portfolio, right? A portfolio of options. And I can look at the real part of the characteristic function and the imaginary part. Okay.
00:38:36.736 - 00:39:27.274, Speaker A: The real part is what actually gets calculated or used in the calculation of the spot volatility. And this is the weight you put in that portfolio. Two different options with different strikes. Remember, this is add the money, and then basically to the left you are seeing out of the money puts, and to the right you are seeing out of the money calls, and see what this estimator is doing is basically the following. It puts the highest weight of options, which are around the money, and then this weight starts dropping. And in fact, it becomes like a long, short portfolio, because here you are long, these options, and then you become a little bit short, some of these options, which are closer to the money but not that far from the money. And then you go a little bit long again, and then it basically become flat.
00:39:27.274 - 00:40:28.156, Speaker A: So it's like a long, short portfolio. And the way to think about this shorting part is basically, is that you are bias correcting. This is kind of, this is the estimator's effort to kind of clean for the effect from the jumps. Well, at least this is how I think about this. And exactly as I told you, the very, very high, kind of deep out of the money options don't contribute to this estimator. If you were to kind of compare this with, say, the weights that you are assigning in a VIX index calculation, then you will see basically that the VIX index is, in relative terms, it's putting more weight on the options which go out of the money, because it's trying to capture the total volatility, not just the volatility coming from the diffusive piece, but also from the jumps. Okay? And now if you look at also the imaginary part, although we are not using the imaginary part in our calculations, but it's nice to see what's happening with the imaginary part of the portfolio.
00:40:28.156 - 00:40:39.080, Speaker A: And that the characteristic function. And you see that's like a long short. That's like you are going here, you along the calls, you are short the puts, but you along the call, short the puts around the money.
00:40:39.232 - 00:40:39.904, Speaker B: Okay.
00:40:40.024 - 00:40:46.144, Speaker A: And around the money, this option, prices are nearly symmetric, and so they cancel out and you get something, a number close to zero.
00:40:46.304 - 00:40:47.164, Speaker B: Okay?
00:40:49.024 - 00:41:10.024, Speaker A: Which is good, because that's another way to confirm kind of the approximation is working because that's what should happen. For high values of u, the jumps should not matter and there's no other symmetry left in the return distribution because the diffusion is symmetric. And so, and so that's, but that's how it kind of cancels. Cancels out.
00:41:10.324 - 00:41:10.732, Speaker B: Yeah.
00:41:10.788 - 00:41:24.144, Speaker A: So that's, that's basically the magic of these calculations. So I think it's kind of useful to see how the, these calculations map into the data. And it's not a very, so I think it's a relatively intuitive thing.
00:41:24.764 - 00:41:25.180, Speaker B: Okay.
00:41:25.212 - 00:41:55.808, Speaker A: So when you calculate it on the data. So this is calculation from 2010. So now, okay, so in this case, as I said, remember spot volatility? Well, you can also estimate it potentially from returns. And in fact, I will have a little bit more to say about this in a few minutes. Okay, so you can compare now. I can actually, before, when I'm estimating jump tails, well, they are on the queue, nothing to do with P. I can always hide myself.
00:41:55.808 - 00:42:06.704, Speaker A: Well, that's basically what the option data told you. There's no way to cross validate and to check that this is the real thing other than run this kind of return predictability things that I showed you.
00:42:06.784 - 00:42:08.976, Speaker B: But here, if this is the true.
00:42:09.000 - 00:43:05.138, Speaker A: Volatility, it should be comparable with the thing which you can measure from returns. I can use squared returns over some short window of time and basically get my estimator volatility. And so what you see on this plot is basically, what you recover with the black line, which is the option based estimator, and the red circles are return based ones. I deliberately put the red circles, the return based one, because they are obviously and visibly much noisier than the option based ones. And in fact, one of the reasons, one of the motivations for doing this, black Scholes implied volume, the literature, was the idea that because these are forward looking measures, the expectations, they should be much less noisier than the return based measures. And that's why you prefer to extract these volatility measures from the options. And so there are that indeed, it's confirmed.
00:43:05.138 - 00:43:41.424, Speaker A: You can see that the black is more or less in the middle of this kind of red cloudiness. But you can see that the levels are actually pretty similar. Yeah, I mean, we need to scrutinize and we will look a little bit deeper into this. So whether it's all rosy. And one way to look deeper into this is to look in the year of 2020, when in one year we had very low volatility and very high volatility. So that's basically an ideal laboratory for kind of all sorts of things, whether they are working properly. And so now I'm zooming in on 2020.
00:43:41.424 - 00:43:53.740, Speaker A: And so you can much clearly see the red circles and the black line, and that's what you get. And I think that actually this works pretty well in the sense that if you look at this, the black line.
00:43:53.812 - 00:43:59.340, Speaker B: Is shadowing the red circles, both when.
00:43:59.372 - 00:44:35.256, Speaker A: The volatility really spiked up crazily high, but also when it went down by a lot. So it's basically. So what that means is that unlike that. So if I was to plot the VIX or the black Scholes at the money volatility, as you saw in the simulation, there will be just a level up kind of elevated by a 40, 50% above. So that's kind of. There will be way above the true volatility or the measures of true volatility. So I will go now to.
00:44:35.256 - 00:44:52.152, Speaker A: Now I'm going to this. Okay, so, okay, so now let's go to this. Because now. So, of course, you can ask yourself at this point. So, okay, so what's the big deal? So, I mean, okay, so it's kind of nice. You can estimate volatility from options spot volatility. It's good.
00:44:52.152 - 00:45:56.918, Speaker A: In a way. It's kind of comforting to know that in spite of all that craziness in the options and overpricing. I don't know, overpricing, but pricing things, all these premiums building to the option price is actually that when you do the analysis, you can go back to the true riskiness of the return. So that's, I was happy about that. But then you ask yourself, okay, it looks like the black line is much smoother than the red line, which it should be, because again, this black line is based on options, which are expectations, and expectations should be much less noisy than realization. So you would think that it should give you an advantage. Okay? But then what we should do is put them on the same footing and basically say, okay, think what is the optimal way basically to combine those two estimators, right? Because that's the ultimate, that we have two alternative measures of the same thing.
00:45:56.918 - 00:46:52.858, Speaker A: And so they should be an optimal way to combine the two things into producing the best estimator. Right? I mean, from a theoretical point of view, econometric point of view, that's the thing to do. And so first, to remind those of you who don't deal with returns and high frequency stuff, that the estimators, which were the red lines or the red dots that you were seeing before, what the ones formed from this, these are just sum of squared returns, okay? And then you truncate them to get rid of the jumps, okay? So basically this is a non smooth truncation because you see, it's an indicator function. And if the return, you keep the returns only if they are a certain level, a certain threshold, below a certain threshold, if they are, say, three sigmas, three standard deviation moves. So anything which is below three standard deviation moves, you keep it, okay? And the rest, you chop it off because it's due to jumps. Okay?
00:46:53.026 - 00:46:53.734, Speaker B: So.
00:46:55.634 - 00:47:23.382, Speaker A: That'S your return based estimator volatility. And if you want to, I mean, what I was looking at the options is the spot volatility. So if you want to be calculating spot volatility here, well, you have to be the window over which you are calculating. This should be relatively short. Basically you should be looking over a small window. And so, but of course, you know, okay, so if I'm using five minutes, as I use here, five minutes, what's the short window? Maybe 5 hours or something like this. Otherwise the estimate is too noisy.
00:47:23.382 - 00:47:24.270, Speaker A: Something like this.
00:47:24.342 - 00:47:25.074, Speaker B: Okay.
00:47:28.054 - 00:47:34.262, Speaker A: You can go to, I don't know, you can go to seconds, but then you'll have to deal with noise and things like this. So I didn't do that.
00:47:34.318 - 00:47:34.966, Speaker B: Okay.
00:47:35.110 - 00:48:24.706, Speaker A: In any ways, what comes. So the beautiful thing of all of this analysis is that from the analysis we are doing here and from the analysis, what others have done about these measures here, you can summarize it, and basically in these two lines here, that OV stands for the option based estimator volatility. And tv, I should have stands for the truncated volatility or the realized volatility. Basically the return based estimate of volatility. They all estimate, they all estimate the volatility, the spot volatility, the true volatility, but they all have an extra error term, which is an extra error term, which approximately, so this is not exact, but it's an approximate sense. Okay, which is something which is standard normal. Standard normal here.
00:48:24.706 - 00:49:00.884, Speaker A: And basically asymptotic variance. So some kind of the variance of the measurement error, which you kind of can quantify. Okay? So, and the nice thing about this is that this, these errors here, this are asymptotically independent. So these two things are independent from each other. Okay, so the option, the error in the option data comes from the measurement error in the options, right? It's just at the point in time I'm looking at options with different strikes and there's measurement error, bid, ask spreads and things like this. This is basically the equivalent of microstructure noise in the return data. And here.
00:49:02.784 - 00:49:03.568, Speaker B: Sorry.
00:49:03.736 - 00:49:32.288, Speaker A: So, okay, just a second. So let's, let me finish and I'll come back to this. Yeah, yeah, yeah. No, no, that's fine. You're also being recorded this way. Okay. And so this one here, it's driven by the Martingale component of the price, right? That's basically what drives the, well, if you, I assume that there's no microstructure noise in the return data now, okay, so the error in the option.
00:49:32.288 - 00:50:10.968, Speaker A: In the options, yes. So, okay, so it is indeed true that what I'm saying is that the error in the observation, error in the options is or total to the price movements. Okay, that's, that's an assumption. Okay. Now it's not a crazy assumption because especially if you are thinking of this estimate of volatility being before the time of the, so this time, usually, how do you form this? You form a local window. And if this local window is before time t, then actually this will be. So this is like an innovation term, right? So that will be uncorrelated.
00:50:10.968 - 00:50:18.400, Speaker A: So in that sense, I don't think this is a crazy thing to assume this way, but it is indeed true.
00:50:18.432 - 00:50:21.308, Speaker B: That it's an assumption that the observation.
00:50:21.356 - 00:50:55.894, Speaker A: Error in the options conditionally on the price path is centered at zero and independent. And so basically just, that's what gives you the result. If you have this result though, then the optimal thing to do is what? You combine the two forecasts. They're not forecasts, sorry. The two estimators of volatility and the estimator, and basically the weights according to the precision and estimation. Right. And this thing, time varies because the precision and estimation can change over time.
00:50:55.894 - 00:51:32.630, Speaker A: So on some day, I don't have enough option data, probably you will tilt more towards the return based estimator. On other days it can be the opposite and things like this. So we can compute those asymptotic variances and we can compute this ratio for the SPX. This is more like 80%, basically is driven by options and the remaining part is by returns. If you do it for individual names, it's more like 50 50. Basically, that's how the breakdown is. That will be the optimal thing to do.
00:51:32.630 - 00:51:45.326, Speaker A: But again, if you're looking at the market index options, so if you look at market index volatility, most of this efficient volatility estimated will be basically determined essentially from the options.
00:51:45.430 - 00:51:46.194, Speaker B: Okay.
00:51:46.854 - 00:51:55.246, Speaker A: All right. So now I will consider one short application, okay, to volatility forecasting, because, so there are different.
00:51:55.310 - 00:51:58.894, Speaker B: So, okay, option data, at the very.
00:51:58.934 - 00:52:33.918, Speaker A: Least should give you a more precise estimator of volatility, spot volatility at a given point in time. You can use it for event studies and things like this, or you can do it and just say, okay, if it is a good estimate, if it's a better estimate of volatility, I should improve in forecasting sense. Maybe that's not the best application because we can generate better forecasts using different proxies and things like this. The way to control for these kinds of things. I'm saying, what's your best forecasting model?
00:52:34.006 - 00:52:38.766, Speaker B: And I don't know, the popular one.
00:52:38.790 - 00:53:11.392, Speaker A: That people use is this car model. I don't know. Have you heard of this? Hetero. How is that hetero? Heterogeneous, no. Autoregressive model. Basically the idea that instead of doing the many legs, you constrained the legs in the forecasting exercise. And so you say you look at the past day volatility, past week volatility, and past month volatility, and that's kind of a nice way to proxy for the kind of long run, kind of long run, long memory feature of volatility.
00:53:11.392 - 00:53:51.842, Speaker A: I don't care what's the best forecasting model? So, but let's say that this is the forecasting model, which most people use, actually. And so then I will say, okay, well, if that's the best forecasting model, I should improve on it by just using better volatility proxy net. Okay, so in other words, if people were using realized volatility, that's what they were doing for most part. Okay, if I substitute the realized volatility with my option based estimator or with my efficient estimator, which combines return and options, I should improve. Okay. People have used also the truncated volatility, and then we also compare with that. Okay.
00:53:51.842 - 00:54:30.608, Speaker A: And so here's what you will get when you do this. Okay, so here's one table which summarizes this. Let me, let's see, what do we see here? Basically, these are forecasting losses, comparison of forecasting losses over one day horizon, one week horizon, and one month horizon. So this is the standard type of horizons people have looked for. Volatility forecasting. Okay. And then, boy, there's a lot, there's a lot happening here.
00:54:30.608 - 00:55:06.194, Speaker A: So you can use a window, a rolling window, to forecast the volatility. Basically, you're estimating the model over a rolling window, say a period of five years, and then you move it five years and five years. Or you can do an increasing window if you just believe that the model parameters are not shifting around. Okay, we can do it either way. Then you can use different criteria for judging the forecasting performance. Mean squared error is the common one, but it's very sensitive to outliers. So you can use this Q like basically criterion as well.
00:55:06.814 - 00:55:07.554, Speaker B: And.
00:55:08.414 - 00:55:31.212, Speaker A: Yeah, and then you have the different models. Now forecasting losses. The numbers to me don't mean anything. So I normalize things or we normalize things. And the benchmark will be this model in which I'm using the return based estimator volatility. Okay, so that's why you have, you see in this column everywhere once. So number below one means that you.
00:55:31.228 - 00:55:33.700, Speaker B: Are beating that model in an out.
00:55:33.732 - 00:56:18.676, Speaker A: Of sample sense, forecasting error sense, and the number above one means that you are losing against the model. Okay, so, okay, so if you look at this, rv is the original specification in some sense. And so it's very close to this hard tv, which truncated variance models so that they're similar. So I'm not making any point about this. Har Q is something that Tim and Andrew have proposed as a way to tame the realized variance or the measurement error in the realized variance. You see that actually sometimes it works, but sometimes really not. And then here comes the one in which you plug in just the option based estimator volatility.
00:56:18.676 - 00:57:12.664, Speaker A: Okay, so you tend to see numbers below one, not always. Once in a while you get this kind of, basically on this increasing window and queue like criterion, you are seeing actually sometimes numbers above one. And my guess for that is that, well, basically the measurement error in the volatility, the option based volatility has shifted over time, and this must have contributed. And when you're using an increasing window, that's basically, you're tying your hands or you're confusing the data. But when you do the ones where you combine the option volatility and the return based ones, they are uniformly basically below one. And you see improvements around 20%, basically, which 20% on something which has been claimed to be already improved a lot. It's quite non trivial.
00:57:12.664 - 00:57:51.824, Speaker A: Sorry. So, yeah, okay, so you do pay attention to the details, ilse, very good. So what is MV? Did I say it? Let's see. Yeah, I do say it, yeah, that's basically so, yes, sorry. Okay, so what I did is one way to get the two data sources together, the option based and the return based one is to put them like in this way.
00:57:52.844 - 00:57:53.704, Speaker B: Oops.
00:57:56.764 - 00:58:07.380, Speaker A: Is to put them in this way, the weights, according to the estimators for the asymptotic variance. Okay, now this unfortunately relies on precise estimators of asymptotic variance, which is variance.
00:58:07.412 - 00:58:11.084, Speaker B: Of variance, which not so good.
00:58:11.244 - 00:58:22.576, Speaker A: People have written a lot about these quarticities and all that kind of stuff, which is really problematic. And so what I decided instead, what we decided is one way is, okay, so I can constrain it.
00:58:22.760 - 00:58:23.484, Speaker B: And.
00:58:25.544 - 00:59:11.384, Speaker A: So again, put it basically unconstraint. I'll just put the option based estimator and the return base estimator without forcing the weights in them being driven by the estimated asymptotic variances. And so the goal of this was just not to, if the estimators of the asymptotic variances of these measures is polluted, I don't want that to be impacting a forecasting model. And so you just left them unrestricted. And then that thing tends to, I think it tends to work best. If I look at the numbers here, if I remember, it is comparable when you're using rolling windows with the EV estimator, but when you start using the increasing window, you start seeing deviations, basically. So, which tells you you probably want to.
00:59:11.384 - 01:00:07.816, Speaker A: Yeah, the estimators of the asymptotic variance can be somewhat poorer, and so you probably don't want to pollute it. In any case, what you, by and large, what you see from this is that there's a scope for improvement, even though already volatility forecasting has been a topic beaten kind of to death. And I don't know whether you can keep squeezing more improvements. Okay, so now I will do one more application here, and that will be to return predictability just to. And so this is more like if you want kind of a, kind of economically motivated one. And so remember that what I did in the previous lecture before the break is I told you how equity returns can be predicted with variance risk premium. People have claimed this in earlier work.
01:00:07.816 - 01:00:47.716, Speaker A: And I said, okay, well, the tell parameter, the tell component of the jumps is actually should be the predictor if it's real, if it's really something which is only from the q coming and not from the p, that's basically, it should predict equity returns going forward. Okay, we did this thing. And so now what? I will go, and basically I will go back to this predictive regression, but I will go to the original variance risk premium predictive regression that people did without questioning why they are doing it this way. Okay? And so basically, remember what that thing was, was so what? Here you see, it actually defined what variance risk premium is. For those of you who haven't seen.
01:00:47.740 - 01:00:50.540, Speaker B: It, you take the VIX, you square.
01:00:50.572 - 01:00:53.484, Speaker A: It, because VIX is reported in standard deviation units.
01:00:53.604 - 01:00:54.428, Speaker B: Okay?
01:00:54.596 - 01:01:04.164, Speaker A: And then you subtract from it realized volatility over months. This subscript m there stands for a month. So that basically means a monthly volatility.
01:01:04.324 - 01:01:09.140, Speaker B: Okay? And so now what I can do.
01:01:09.172 - 01:01:26.656, Speaker A: Now is basically I can get a much better now that I, the problem, and this, in this, if you have paid attention to this literature, people have criticized the authors a lot for using this because this is a very noisy measure.
01:01:26.840 - 01:01:31.152, Speaker B: Basically, they use past month volatility in.
01:01:31.168 - 01:02:10.200, Speaker A: The construction of this, which is a very poor proxy for actually the actual volatility going forward, or can be a, basically, volatility over a month is not a unit route. Okay? That's what, in a nutshell, the criticism was about. And so now if I have a much better estimate of volatility, I can just basically substitute their realized volatility with my estimate of volatility. Right? Because what I. Okay, so the realized volatility has two components, one coming from the jumps. These are realized jumps. I have nothing to say about them.
01:02:10.200 - 01:02:36.424, Speaker A: So this is this difference realized variance minus the truncated variance. And this just captures basically whatever jumps you have over that month. That's what it is. We can't do anything about it. But then the second piece is the one coming from the estimator of volatility. And I can plug in here my estimated or efficient volatility estimator. And so that will be my alternative measure of variance risk premium.
01:02:36.424 - 01:03:26.584, Speaker A: So variance risk premier one, which is the original one, and variance risk premier two, which is my improved estimator, because now I have a better estimate of volatility. And then of course I can also adjust the jump risk premium measure, which is the jump variation, which is vix minus the spot volatility, minus the realized volatility, minus truncated volatility from the returns. So that's just the jump variation measure. Okay, so I can do that. And now let's see what kind of return predictability you get from this. Okay, so, and so here the results. So let's just stare at them for a little bit and see whether we can see whether you can actually spot things.
01:03:26.584 - 01:03:51.824, Speaker A: Okay, so these are the t statistics. So we can actually focus on t statistics. So, and what is on the x axis, these are return predictability regressions. But what you see on the x axis is the horizon in months. So you are looking at return predictability over the next month all the way to twelve months into the future, which basically in one year from now.
01:03:51.864 - 01:03:52.040, Speaker B: Right?
01:03:52.072 - 01:04:19.804, Speaker A: So that's what you're looking at. All right, and remember what I'm predicting future equity returns. And I'm using this as predictors. The VRP one is the class, the one that have been used and have been talked a lot in the literature. This is my improved version of it. Just without questioning why you are subtracting here, past month volatility, but just a better version of this. And then the jump premium kind of component.
01:04:19.804 - 01:05:14.744, Speaker A: So the VRP one, which is the original predictor, is the one with the stars. So you see the star here at one month it looks like five, then it drops down to three, then it goes down to five, then it goes to five and a half or six, then it drops down basically, and it tanks down. So it's like that typical thing that they have seen, that kind of the predictive, the predictive ability spikes around three, four months, and then it drips down, down very, very sharply. And it looked a little bit suspicious. Why is exactly kind of spiking up there and kind of then disappearing. If you change just the way you calculate this realized volatility, you see with kind of what I argue is a more efficient estimate of volatility, then that feature of the data is gone. Ways that VRP two is the circles.
01:05:14.744 - 01:06:03.970, Speaker A: You basically start here and you're just climbing in a much more controlled way. So you still I mean, you still exceed the critical value of two or 1.96 or whatever that number is here, but in a much smoother way. You don't have this kind of spike and go down in any case, it just looks very, very different. And in addition to that, this is much more in line with what you get with a jump risk premium estimator, where basically that the thing is kind of. They shadow each other very closely. So measurement of volatility, or precise measurement of volatility can make a big difference of all these kinds of conclusions, especially when you start doing this kind of analysis where you claim that the variance risk premium is a predictor.
01:06:03.970 - 01:06:25.290, Speaker A: And people try to rationalize this in an equilibrium settings and things like that. So, yeah, this can have a real impact. Yeah. So what I replace, the only change is. Yeah. There's a lot of. A lot of unnecessary number of notations here, I guess, but.
01:06:25.290 - 01:06:38.790, Speaker A: So they are the same in terms of the vix. Right. The q thing is the same. I replaced the realized volatility, which they used with one. Okay. So I split it into two parts. One is due to the jumps.
01:06:38.790 - 01:07:13.084, Speaker A: I can't say anything about this. But then the one which is coming from the true volatility, the diffusive volatility, I replace it with the one which I estimated from the options data. Right. Is the spot. Yeah, the spot. You mean the vix.
01:07:13.384 - 01:07:14.644, Speaker B: Yeah, you're right.
01:07:15.304 - 01:07:28.296, Speaker A: So it's the viX. No, but I can do it with the short dated thing. But you are right. Right. No, no. That makes total sense. And the point of this is just to say there was no.
01:07:28.296 - 01:07:40.014, Speaker A: What was the argument for them to use the monthly volatility? You say that monthly volatility just doesn't change much. And if that's the argument, then actually I should be okay with the spot volatility. Plug it there.
01:07:40.714 - 01:07:44.674, Speaker B: And what that shows is just that.
01:07:44.834 - 01:07:59.920, Speaker A: It makes a very, very big difference. So some of this return predictability that they are seeing spiking up around months one, two, three, it's actually coming from the realization of volatility shocks. It's not about risk premium, it's volatility shocks. And so.
01:08:00.112 - 01:08:05.032, Speaker B: Yeah, yeah, yeah.
01:08:05.048 - 01:08:15.496, Speaker A: I'm not, I'm not making economic, much more economic interpretations of that. But just. Just the measurement thing is a non trivial thing. It's just. Yeah. One can't just underestimate that.
01:08:15.640 - 01:08:16.364, Speaker B: Yeah.
01:08:19.664 - 01:08:44.823, Speaker A: Okay. Now some of you might have asked me, but you didn't. Let's see. By the way, can I drink this water or not? That's not for me, probably. Okay, so let's, let's not, let's not. I got thirsty, but this water will be good. Okay.
01:08:44.823 - 01:09:30.619, Speaker A: Now this is probably less critical now that I can go all the way down to zero DTE or one day options and things like this. But before, for the earlier part of the sample, when I'm applying this estimators, I'm very conservative and I use very conservative and it looks like a five day option or two weeks options, etcetera. And then the whole argument I was doing here was pretending that volatility over that interval of time is constant. Right. Now it's not as bad if you're doing it in a high frequency context because here you are looking at expectations and expectations is probably not so bad, but nevertheless it isn't. Yeah, it's a little bit. There's some smoothing going on, right.
01:09:30.619 - 01:10:10.364, Speaker A: Because you're kind of, you are smoothing if you're expecting a kind of a volatility spike over the next ten minutes, that's probably in the five days to expiration, it will be smoothed out, right. Something like this. So it is a. Yeah. How much is there? Basically a bias due to the fact that the time to maturity is short, but not as short. And so what that means now is basically I need to go and try to expand even more the characteristic function and to see what kind of biases I can get from the mean reversion. Essentially a volatility kind of kicking in here.
01:10:10.364 - 01:10:45.140, Speaker A: And it turns out this is possible to be done much more complicated. But it's doable. It's complicated to derive, but when you derive it, it's actually, the expression is intuitive. So what you get is, remember, this is my estimator of the volatility, the log of the characteristic function standardized here. So I have the spot volatility. I have this contribution due to the jumps which I told you we can successfully more or less ignore it. And then when you do the expansion, you get a term which looks like this.
01:10:45.140 - 01:11:10.232, Speaker A: It's proportional to time times something which depends on the characteristic exponent. Okay. And then you have some even higher order terms. So what does that mean? Is, okay, yes. This, all of this, by the way, is coming from mean reversion and volatility. If volatility is higher today, it's reverting back to its unconditional mean and vice versa. And so, but then if now I.
01:11:10.248 - 01:11:13.682, Speaker B: Allow myself to use two maturities, right.
01:11:13.738 - 01:11:32.298, Speaker A: Two maturities, I can cancel that bias term because it's like, you see, this is the. This is the thing, which I did here. So it's like, is that, for me, did the best we can do. What is that? Cold water. Cold water. Oh, thank you. Oh, thank you so much.
01:11:32.298 - 01:11:33.210, Speaker A: Thank you so much.
01:11:33.242 - 01:11:33.934, Speaker B: Okay.
01:11:36.634 - 01:11:49.166, Speaker A: It's very good. And maybe there will be even better drinks later on. Maybe. Maybe. Okay. If we work hard. All right, so you see, this is really an easy estimate.
01:11:49.166 - 01:12:01.102, Speaker A: So it's not a forward variance, but you see, what you're doing by this is you're trying to cancel this piece here, this bias term here. So these things due to mean reversion.
01:12:01.158 - 01:12:01.914, Speaker B: Okay?
01:12:02.334 - 01:12:41.394, Speaker A: So you can do it, and we did it. And if you're really picky and if you're really afraid that the jumps can matter and that actually they can matter in the way that there are a lot of small jumps of them. So this is more like for the theoretically oriented people. So you can try and bias correct for this thing as well. The way to do it is just look at how this function behaves as u changes. And you can get a sense of this piece here if it's present, and try to get rid of it, too. So you can do that, too.
01:12:41.394 - 01:12:57.500, Speaker A: And so, and then, so we did that. And basically what we wanted to see is, does this improve our estimators of volatility? Does this reduce potential biases in our estimators of volatility?
01:12:57.542 - 01:12:58.256, Speaker B: Easy.
01:12:58.440 - 01:13:21.624, Speaker A: So how do you measure that? And so I'll be paying attention to time, so don't worry. So, basically, what you can do is there are different ways to quantify this, but you can look at your true, your estimator from the returns. Okay. And you can compare it with the estimator you get from the options. And if the difference between the two.
01:13:21.744 - 01:13:25.182, Speaker B: Is just measurement error, if you expect.
01:13:25.278 - 01:13:27.374, Speaker A: That that measurement error is not persistent.
01:13:27.414 - 01:13:29.742, Speaker B: Over time, you should see that the.
01:13:29.758 - 01:13:54.098, Speaker A: Autocorrelation of this gap is zero. Right? Or it's kind of weak. Okay. That's one way to measure this, whether you are capturing this effect. And so this is what we did here. So we plotted the autocorrelation of the difference between the spot volatility estimator from the options. So I guess this guy and a return based estimator.
01:13:54.098 - 01:14:26.036, Speaker A: We did it in logs, because if you don't do it in logs, basically the data, it's kind of noisy, and then nothing is significant. Okay. So, but in logs, it's a much more difficult challenge. It's a much higher threshold. Okay. And so this is the original estimator that I was showing you until now. And this is one in which you correct for these biases, potential biases, which are basically given by this maturity, this kind of combining these two maturities.
01:14:26.140 - 01:14:26.980, Speaker B: Okay.
01:14:27.172 - 01:15:06.318, Speaker A: And so you do indeed see that the autocorrelation starts dropping. They don't completely disappear, but they're much weaker now. And if you compare with the black Scholes one, they're actually much smaller. If you correct for the jumps, you get probably a tiny bit of reduction, but not by much. So there's still a little bit of, there's still a little bit of, you know, autocorrelation. So there's some persistence in this error, but I don't think it's, I don't think it's that big. What you can do also now this thing is a little bit, okay, so you might say that the observation error is autocorrelated and that's a possibility too, so that I cannot split from that.
01:15:06.318 - 01:15:09.574, Speaker A: But what I can do to control for that is just to look at.
01:15:09.734 - 01:15:13.050, Speaker B: The gap between the, the return base.
01:15:13.082 - 01:15:18.194, Speaker A: Estimator and option based estimator and see whether it depends on past volatility.
01:15:18.314 - 01:15:19.658, Speaker B: Okay? It should.
01:15:19.746 - 01:15:52.260, Speaker A: If that's truly observation error, it should not matter on the true thing, which is the true volatility. And so this plots basically for the different option based estimators. Just compare this. The statistics are with the blue circles. If you do the original estimator, you get a t statistic of around twelve. Then when you do the bias correction, you reduce it for the mean reversion, you reduce it to six. And when you do this thing for the jumps, you reduce it even more to four.
01:15:52.260 - 01:16:35.074, Speaker A: And basically it's essentially gone almost no dependence. If you look at the black Scholes implied volume, it's much higher and it kind of persists. Basically it doesn't disappear with the leg, which tells you that, you know, that basically this gap is capturing something which is true about true volatility, which is not supposed, it's not just a measurement error in the different estimators. Okay, so in a nutshell, basically these bias reductions can give you a little bit of improvement. They're not that critical most of the time, but if you are running into an extreme period and when volatility was very high, say during the pandemic, this type of bias corrections are useful.
01:16:35.694 - 01:16:57.034, Speaker B: Okay. Yeah. Around the events, is there more specimen, you might think that at the event it will signal something in the model might change quicker instantly at the time of the day.
01:16:57.174 - 01:17:14.650, Speaker A: It's a very good question. Very very good question. So let me come back to that. Let me come back to that. I will tell you one more thing, and then I'll come back to that and relate. And that's a good point. So, I'll come back to this, and that's how I'll conclude.
01:17:14.650 - 01:17:53.794, Speaker A: But so, just before I do that, just to tell you, once you have the spot volatility estimator, you can do any sort of things. And so, for example, one thing that you can do is you can do volume. And that's like, people try to do that too, because apparently there's some recent literature which tells you that this is a kind of a source of risk, which is orthogonal to the volatility risk itself. Okay? And what I'm talking about, really, is this. Coffee. If you look at the volatility dynamics, volatility also has this brownian shocks here. And basically, volatility of volatility will be this piece.
01:17:53.794 - 01:18:00.694, Speaker A: That's what I'm talking about. That's volatility of volatility. So if I have high frequency now.
01:18:00.734 - 01:18:03.678, Speaker B: Option data, I can do, well, I.
01:18:03.686 - 01:18:38.974, Speaker A: Can try to do what people have done. Estimating realized volatility. I mean, that's essentially in a nutshell here, except that what I'll be plugging is not the true volatility, but some kind of a noisy proxy for that. So, I'll not tell you much about this, or rather, I will not go in much detail about this. Just say that. Okay, so now here you will have to have high frequency option data, which we do, and then just look at the increments of volatility. Increments of volatility.
01:18:38.974 - 01:19:21.784, Speaker A: And then you square them, and that's it. The only thing that will be the natural estimator. But the only thing which complicates matters here is the fact that what I really have is a noisy proxy of the true volatility and not the true one. Bottom line, there is an epsilon here. And so what you need to do is you need to effectively bias correct or just remove that effect from the volatility. And so, the way to do it is just to estimate the first order out of covariance of your s, of the volatility increments. And then they give you an estimator of the noise squared, or the negative of the noise squared.
01:19:21.784 - 01:19:57.144, Speaker A: And then your final estimator basically becomes this. It's just the squared returns of the volatility plus two times the first order out of covariance. That's assuming that the noise in the option data is not autocorrelated LZ. So if it was autocorrelated, we need to do something else. We need to basically continue with more autocorrelations to undo that kind of. To undo that kind of thing. So, yeah, and so you can do this.
01:19:57.144 - 01:20:44.004, Speaker A: If you do it on the data, this is what you get. So this is a more recent thing from 2016 till as far as option metric goes, which is 2021. And this, what you see here is a volume here, by the way, doing the bias correction makes a hell of a difference. This is if I use just the original estimator with the shortest maturity, and if I bias correct for the mean reversions, this is what you get, basically, you get a much higher volatility or volatility. Why? Because basically, the mean reversion effects, they kind of smooth out the estimator and you have less volatility and volatility.
01:20:44.164 - 01:20:44.748, Speaker B: Okay.
01:20:44.836 - 01:21:01.844, Speaker A: And it blows up. If you know of. If you know of the vivex. Have you heard of the vivix? The volatility of the VIX index and things like that. You might wonder, how is that related to that? Well, it's very related to that, except that's the volatility of the risk neutral.
01:21:01.924 - 01:21:05.412, Speaker B: One month VIX index and what you.
01:21:05.428 - 01:21:45.366, Speaker A: Will get if you calculate it here. I didn't plot it here because it's ten times smaller. Why is it ten times smaller? Because VIX is a one month conditional expectation. So you're smoothing so much that basically this becomes like ten times smaller. At the beginning I said, you got to be kidding me. You know, like, this is probably not reasonable, and this might still not be reasonable, but then within the simulation I did with my model, you had that effect ten to one, basically, within the model, vix volatility of viX versus volatility of spot volatility. So it seems like it's a real effect, but it's really like ten times larger.
01:21:45.390 - 01:21:46.074, Speaker B: Basically.
01:21:50.834 - 01:22:13.654, Speaker A: Yeah. Then I actually. Wasn't that the point of this paper, that I was like Ivan Sholiastovich and these guys, that they were saying that Volvo is actually very weakly related to volatility. That was. I thought that was their conclusion. The reasons they were writing this equilibrium models, kind of just to explain why is that correlation so weak? And so what you are saying is that.
01:22:13.774 - 01:22:14.006, Speaker B: Yeah.
01:22:14.030 - 01:22:37.470, Speaker A: With the vix. With the vivix. So what you are saying. I have to go back and check, really? But I thought that's what I was using as some of the motivation that basically vivix. There's evidence that volatility and volatility is a separate source of risk. Essentially, what they were saying is very low, especially in this period, 2017, which is volatility was very low. And look at this angle.
01:22:37.470 - 01:22:45.174, Speaker A: Action. Yeah. Going on. Yeah, yeah. Striking and somewhat unbelievable. Right. So somehow something.
01:22:45.174 - 01:23:01.790, Speaker A: Yeah. No, no. Well, when you see spikes like that, you might be really worried about things happening. That's why I restricted myself from 2016 on. So I don't know. Yeah, I mean, look at this kind of spikes and then dropping down. I agree.
01:23:01.790 - 01:23:25.514, Speaker A: I agree. But so maybe there are scope for further improvement. Although I don't. I mean, volatility doesn't look crazy. But of course, when you're looking, this is. You're looking at increments of volatility. So even small kind of things can matter a lot for this type of estimators, but, yeah.
01:23:25.674 - 01:23:34.794, Speaker B: So double check. Yes. Yeah, it is.
01:23:35.214 - 01:23:51.194, Speaker A: So, yeah, so the VIX is giving you some. But the point is that the VIX is giving you something very different because. Because of all of this min reversion, you're really getting a series which is, by design, much, much smoother. And so you should get something which is very different.
01:23:51.934 - 01:23:52.834, Speaker B: Okay.
01:23:53.254 - 01:24:13.964, Speaker A: Now, I don't want to torture you more with that, but, you know, but there are a lot more to be done with these things. And in particular with applications. I think I had, like, little applications here and there without actually really kind of showing the beauty of this one comment on that question that you asked me, though. What happens around events?
01:24:14.944 - 01:24:17.684, Speaker B: Around events, this.
01:24:19.384 - 01:24:51.374, Speaker A: Basically. So around events, when there is a. Essentially, there is an extra term here. Okay? Around events, there's an extra term, which is these jumps. This event jumps, because they are not. They don't have this intensity, which is proportional to time. And if I'm looking, zooming in over very, very short intervals of time around the event, they dominate.
01:24:51.874 - 01:24:52.546, Speaker B: Okay?
01:24:52.650 - 01:25:11.602, Speaker A: And so if you want to recover, then if you're still interested to recover the volatility around the event, what you have to do is you have to use two maturities which bracket the event. Take the ratio of the two, and then they will knock out the event, and you will be left with the volatility. Otherwise, if you do what you're doing.
01:25:11.658 - 01:25:14.242, Speaker B: Here, some of the volatility which you.
01:25:14.258 - 01:25:22.934, Speaker A: Will recover will be part of due to the event. It's not as much as the total. It's not as much as the VIX, but nevertheless, it will be still polluted.
01:25:23.714 - 01:25:24.494, Speaker B: Yeah.
01:25:29.234 - 01:26:07.038, Speaker A: Or upward jump, because. Yeah. Okay, so now that's another good question. And if you doubt that you can design a test for that. And that's what I did, actually, in one of my recent papers. Now, basically what we were interested is, is there a volatility jump at the earning announcements for individual stocks? It's funny that you are saying downward jump. I would have guessed an upward jump, because usually when Tesla announces, and then it takes a while for the market to calm down, but sometimes it depends on the type of announcement.
01:26:07.038 - 01:26:25.854, Speaker A: Sometimes it's a resolution of uncertainty. Yeah. And the answer was that, yeah, there's a little bit of volatility jump, which is priced in, but it's not as big as one would have guessed. It's not that big, but there is some. For some stocks. For some stocks which are really the influential ones. Yes, you can see some of that showing up.
01:26:25.894 - 01:26:30.510, Speaker B: Yeah. So thank you for asking these questions.
01:26:30.542 - 01:26:33.034, Speaker A: Because that shows that there's a lot more to be done.
01:26:35.074 - 01:26:38.482, Speaker B: Okay. Yeah, Chris? No, no, no.
01:26:38.498 - 01:26:39.174, Speaker A: Go ahead.
01:26:39.514 - 01:27:00.334, Speaker B: So what we did after the break is estimated for data. What if I took my traditional. Intuitively, how is that related to what we did before?
01:27:00.814 - 01:27:26.920, Speaker A: Ah, okay. That's a good question, too. So basically, now, it's funny that it's good that you mentioned Bakshi Madame Kapadia estimator, because I called this thing here. Remember when I come here and I called this point here, the VIX. Actually, it's not the vixes, but it's the Bakshik Madame Kapodia estimator. They're slightly different, but they're almost the same. Same thing.
01:27:26.920 - 01:27:44.040, Speaker A: Yeah. So that's basically this. And so if I. So, so when I do this and I subtract the spot volatility, then you're getting the jump variance right now. The jump variance. So what I did before the break, I gave you the whole distribution, not just the second. So that will be just the second moment.
01:27:44.040 - 01:27:50.496, Speaker A: So if you're interested in the second moment, then that's it basically. Just stay with that. And then basically the second moment of the jumps and.
01:27:50.560 - 01:27:54.250, Speaker B: Yeah, that's right. That's right. That's a.
01:27:54.282 - 01:28:08.374, Speaker A: That's so, in fact, that basically is. Sorry for this flipping around, but that's. It's, it's good that you, you're connecting the things, but this is exactly what this JV is. That's what that thing is.
01:28:12.994 - 01:28:26.250, Speaker B: Okay, Victor, for excellent workshop.
01:28:26.402 - 01:28:27.634, Speaker A: Thank you. Thank you.

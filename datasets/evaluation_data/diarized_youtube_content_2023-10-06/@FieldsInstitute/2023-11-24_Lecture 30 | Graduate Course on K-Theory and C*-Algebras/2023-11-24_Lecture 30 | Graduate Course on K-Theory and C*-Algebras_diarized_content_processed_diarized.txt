00:00:02.960 - 00:00:40.510, Speaker A: We're looking at discourses of what's called K theory and sister algebra. Priority. Those are different things. There's a certain amount of connection between. Certain amount of connections between them. Anyone want to suggest a connection? Are you justin?
00:00:40.582 - 00:00:41.794, Speaker B: Yes. Okay.
00:00:42.934 - 00:01:04.054, Speaker A: Do you want to suggest a connection between K theory and sister algebras, for instance? Well, some idea of why they're both in the same course. Okay, good. Vincent, do you have any ideas?
00:01:04.674 - 00:01:13.374, Speaker C: I guess depends on K theory. Like provides, like structures and things you can study about c star algebra categories.
00:01:15.314 - 00:01:50.516, Speaker A: Well, I'm not quite sure about the category. I guess that's one way. That's one way of looking at it. In fact, you're almost talking about. You're almost getting into one particular aspect of K theory and seastrogen, namely, the sort of classification that if you look at a seastro algebra, then at least if it's what's called a well behaved. That's what might be called well behaved. Well behaved.
00:01:50.516 - 00:02:14.784, Speaker A: Simplicity is outward. We have discussed briefly it won't be on the exam, but I mean, it's. The classification of well behaved has just very recently been finished. But it's.
00:02:15.804 - 00:02:16.784, Speaker B: And it's.
00:02:20.244 - 00:03:06.324, Speaker A: Important chapter of mathematics, I think. But it'd be hard to fit into a course in its entirety, 5000 pages, with everything that's been written related to that. 30 steps along the way the last 60 years. Goes back to the beginning of the subject in 1943 paper. Gelfand and Nymar. 1943. Someone say, yes, that's pretty slow.
00:03:06.324 - 00:04:31.554, Speaker A: I thought you're supposed to be able to look it up quite quickly. Anyway, just look up. Your friend and the girlfriend had already been talking about Banach. Algebras, commuters of panic algebras and the idea of spectrum. Korea. What generalizes the classical Fourier transform? Have I mentioned, established the subject single major. He found this spanish algebra proof, a short, short proof of the theorem of Weiner.
00:04:31.554 - 00:05:37.034, Speaker A: Have I mentioned that? Does anyone remember the theorem of Weiner? Functions on the circle and every, every such function has. It has a Fourier series, not a Fourier series convergence. If it's an individual function, continuous function, the continuous function and the Fourier series converges in the center. But doesn't necessarily. There's a special case which. Look at the Fourier coefficients. So they're labeled by the integers, right? Fourier coefficients are numbered by the integers.
00:05:37.034 - 00:06:04.254, Speaker A: By integration, modify that by this function, integrate that. And that's the way, whether you take plus n or minus n or.
00:06:07.814 - 00:06:08.554, Speaker B: But.
00:06:10.534 - 00:06:12.494, Speaker A: You have the Fourier coefficients.
00:06:12.654 - 00:06:13.354, Speaker B: Well.
00:06:16.014 - 00:06:44.214, Speaker A: A very important property is that they be absolutely convergent in the series. If you add up the absolute values, you got a finite number, and these, I guess I call them. What was the name for such a function? Continuous function for a series.
00:06:51.354 - 00:06:51.882, Speaker B: Of sum.
00:06:51.898 - 00:07:49.444, Speaker A: Of all Fourier cities. Because the absolute value of the nth term, since the exponential function has absolute value, one, the absolute value of the nth term is the same as the absolute value of the coefficient. If you look at the absolutely summable Fourier series in the later course of the beginning this month, the question is, these things form an algebra. And the question is, do you have such a function? And it's not zero anywhere on the circle? It's a function on the circle. If it's not zero anywhere, then you can invert it. In a sense, you can, or you can invert it as a continuous function. The point wise inverse, you take the inverse of the values of the function.
00:07:49.444 - 00:08:34.798, Speaker A: One function is f. You call it one over f. That's a continuous function. The question is that, does that have an absolutely summer Fourier series? Okay, that's a good exercise using thin air. And that was kind of a miracle. But once one person has done something like that, it's like once one person has discovered North America. Well, okay, actually I was going to say it's not such a big deal until my else bro.
00:08:34.798 - 00:09:23.564, Speaker A: But that's not quite true, is it? Through the centuries, different people have discovered North America coming at it from both sides because it's quite complicated. All right, well, interesting to trace the history of manic algebra. How far before Johann as a goal bandaic look at Manikov. He certainly looked at Bannock spaces. He didn't call them Banach space, but he called them be spacers.
00:09:26.264 - 00:09:34.264, Speaker B: All right. But something special.
00:09:42.284 - 00:10:03.564, Speaker A: For algebras, either concrete algebras or operators or just abstract out you're theory of elders, of peers.
00:10:07.424 - 00:10:13.524, Speaker B: Both and kicking.
00:10:18.504 - 00:10:21.844, Speaker A: And then that's like.
00:10:24.604 - 00:10:25.344, Speaker B: Better.
00:10:29.764 - 00:10:55.264, Speaker A: Finding history entirely into the history of roald first and then operator algebra theory of operator album in the geometry of this concentrated services outbreak geometry is studying these zero sets of polynomials.
00:10:55.304 - 00:10:55.884, Speaker B: Right?
00:10:57.104 - 00:11:18.732, Speaker A: That's summary about brachiome we would see now Descartes had the idea that you should instead of studying spaces, you should study algebra as a function on the spaces. And I think that's what was one.
00:11:18.748 - 00:11:19.304, Speaker B: Of.
00:11:21.244 - 00:12:20.724, Speaker A: Innovations rodenting I think because of the background in our theory, what he called case theory very helpful tool in studying the algebras of arising in geometry. Noticed that this could work just for the following too.
00:12:21.784 - 00:12:27.284, Speaker B: Are you not looking at something?
00:12:31.704 - 00:13:03.914, Speaker A: And this again, it's more or less interpreted in terms of algebra. More or less looking at certain algebras, namely the algebra is a continuous function instead of algebraic functions. So that's a commutative vedic algorithm.
00:13:18.014 - 00:13:18.302, Speaker B: On.
00:13:18.318 - 00:13:53.182, Speaker A: An extra basis as part of the general, which arose first as concrete algebras and operators on the hill space. And then once you had them on one hilt space, they were often crying out to be represented on a different hilt space. People got the idea of representing characteristics and abstract out and geofant and nightmare.
00:13:53.238 - 00:14:02.914, Speaker B: From your lead in that from finding simple oxygen.
00:14:04.774 - 00:16:43.664, Speaker A: Secure abstract star algebraic to somehow it turned out that k theory not only did it notice soon after the algebra systematized again, it was noticed that this worked just as well for a non communist and. And then it was noticed that for sea strippers this was almost the only. I think I might have put it this way before. It was almost the only game in town. Full circle to the well behaved simple seas down prison. Well, you have to agree that by the last ten minutes is lessons it's simpler than 5000 pagan. But it just happens that the straightforward case theory information suggested in terms of a functor, always a functor and k one is a function and the tracial simplex, the unit philosopher or the tracial cone, if it's not unital, the trace will cone bounded or not finite on the positive, not finite on all positive omens then doesn't quite make sense that are not positive because you'd end up subtracting infinities.
00:16:43.664 - 00:17:14.434, Speaker A: Notice for operators and Hilbert space, how many people have come across the idea of the traits of an operator on the coverage space. Yes, good class of operators, positive operators called trace class. Well, in the first instance, positive operation extended trace class operators form a subalge reflect an ideal, just like foam back operator.
00:17:15.334 - 00:17:17.394, Speaker B: It's not a normal ideal.
00:17:21.244 - 00:18:36.084, Speaker A: It is a Bannock space. Every bandic space has a dual space, right? Okay, in the Hilbert space, what's the dual space? Yeah, in a strong sense it's the Hilbert space itself. Actually it's the opposite Hilbert space. In the complex, real, real numbers, real scalars, there's no difference between the Hilbert space and the opposite. In the case of the complex Hilbert space, the opposite Hilbert space, you flip the inner product and that's one way to say where you flip the complex. At the same time you flip the complex modification multiplying by I in the opposite hover space, it's the same with multiplying by minus I in. And you have to say that because there's an economical isomer between the dual of a Hilbert space, dual complex planning space, dual space and the opposite.
00:18:36.084 - 00:19:21.858, Speaker A: Not so much the original, of course. In the real case, it's the same. Well, that's an example of balance based. Another example is when you take the dual of the organic space of trace class operators. You might want to try their luck. Where are you? No, you know, I'm just terrible with names. I should go through.
00:19:21.858 - 00:19:45.006, Speaker A: Why don't I go through? Okay, so. And you can tell me what I got to you. No, no, no. I'm very. I may not. I try to make it not look like it, but I'm very embarrassed.
00:19:45.030 - 00:19:45.714, Speaker B: Okay.
00:19:49.334 - 00:19:54.554, Speaker A: Hussein. Andrew. Abigail. Arsenal, I think.
00:19:54.854 - 00:19:55.302, Speaker B: Jack.
00:19:55.358 - 00:19:59.038, Speaker A: Cerone. Okay. Yuid.
00:19:59.126 - 00:20:00.264, Speaker B: Changing.
00:20:11.794 - 00:20:21.854, Speaker A: Some people I know that they're very often here, and some people I haven't even met, I don't think, but. Daniel. Dimon.
00:20:25.634 - 00:20:26.010, Speaker B: Yeah.
00:20:26.042 - 00:20:39.330, Speaker A: Justin. That a good. Okay. Pronunciation. Okay. Savak. Trouble is, I get to.
00:20:39.330 - 00:20:59.664, Speaker A: I get exposed. I travel too much and I get exposed to languages in different places. And then I try to imitate the pronunciation and. Except I don't know which one to imitate. Okay. That was you.
00:20:59.744 - 00:21:00.152, Speaker B: Okay.
00:21:00.208 - 00:21:12.684, Speaker A: You know, I was. I was trying. I was going to say Sadbak because I didn't say it, but trouble was, that was after. Right pronunciation. Sorry.
00:21:14.264 - 00:21:15.084, Speaker B: All right.
00:21:20.404 - 00:22:44.058, Speaker A: It's like. I think it's almost a bit like computers. I mean, 50 years ago, didn't have to learn about computers. Well, 50 years ago, almost everyone you met had grown up and went and gone to the same school as you, and it was a smaller world. Alexandrico, how would you like. You're going to get to know people's names better than me. I don't want the young people.
00:22:44.058 - 00:23:08.834, Speaker A: But the two people I just mentioned haven't given me any homework yet, so. And who does the homework hurt more? Sorry? Well, I just checked and the number of people on caucus is still 28.
00:23:08.874 - 00:23:12.694, Speaker B: Okay. For undergraduates. Actually.
00:23:21.194 - 00:23:42.890, Speaker A: More undergraduates than has been for a while. And fewer. I started out with a graduate report. Thank you. You know, I was going to. I knew. I knew who you were.
00:23:42.890 - 00:23:50.614, Speaker A: I knew your name, and I was going to ask you. Well, you're not the person sitting farther back.
00:23:51.194 - 00:23:55.934, Speaker B: But then I asked you if you had a reason.
00:24:16.294 - 00:24:23.354, Speaker A: Okay, but you have an answer to my question at the beginning. Any kind of answer.
00:24:23.974 - 00:24:28.234, Speaker B: The relationship is possible.
00:24:32.774 - 00:25:32.964, Speaker A: If you want. And you have a map. In the case of the tracial cone, well, if you look at affine functions on the tracial cone, then that's a vector space. And again, it's a forward function. That's pretty good, actually. It's determined by the outbreak. One might want to look at a paper called case area and traces last couple years.
00:25:32.964 - 00:25:37.604, Speaker A: Nowadays you don't have to know anymore.
00:25:51.464 - 00:25:51.896, Speaker B: Okay.
00:25:51.920 - 00:26:07.724, Speaker A: So did I get your name? Yeah, we'll go halfway through. Are you in the first half or the second half? Well, what letter does your name begin with? I should know your name, but.
00:26:10.644 - 00:26:10.932, Speaker B: If.
00:26:10.948 - 00:26:38.844, Speaker A: You'Re in the course. Well, then I'll come first. You're not. May I ask your name? Oh, oh, right. Well, okay. Well, now I remember you. In fact, that was one of the very last names that I mentioned.
00:26:39.144 - 00:26:39.616, Speaker B: Hopefully.
00:26:39.640 - 00:28:47.870, Speaker A: What it's worth if you have any questions about the course and about the subject. Of course there's seastrogen on one hand, K theory on the other hand, and we're supposed to be talking about both, right? Somehow it's like the question, can you put the following two words in the same sentence? Well, the one way of saying it maybe, is that k theory helps to study the structure of sea star algebra. You can see already from matrix algebras and infinite tensor products of matrix algebra, and the conductive limits of finite direct sums of matrix algebra. So those are all classified by k zero. Okay. It almost seems that the number of people are deciding informally to. By the way, what does, what does staying in the course? What does being in the course involved?
00:28:47.902 - 00:28:48.474, Speaker B: Well.
00:28:50.974 - 00:29:34.854, Speaker A: Recently marks for the course haven't been due until a month after. A month after the end of term. So what I'm hoping is that I can extend that much latitude to people at this time too. I'll have to clear that and see what Joshua law, he's married time is up to affect the plant gesture.
00:29:35.694 - 00:29:40.846, Speaker B: I was just kind of suggesting.
00:29:41.030 - 00:30:29.754, Speaker A: Well, yeah, I was just going to say like, is there anything worse with the fact that k theory is just like a hunter from categories? Yeah, well, that's what it is in groups. And, and it's not the, if it's the classifiable altitudes or sometimes called classifiable algebra. Tight unit, well behaved, synchronously drought. You only need the grooves. You don't need the orange flux because that comes from the traces. If you look at the.
00:30:32.374 - 00:30:32.782, Speaker B: Look at.
00:30:32.798 - 00:32:02.154, Speaker A: The traces, then those are basically functions on the trace of state space. If you have a projection, then it gives you an affine function on the trace space. That gives you an order of relation if you want. It gives you an order of relation on the productions that people sometimes consider without even mentioning traces. In this well behaved simple case, you don't need to look at the order structure separately, just keeping track, just keep track of the fact that k zero match into the function. So, for instance, if you have matrix algebra and there's a unique trace. So the spatial syntax is a single point in the affine functions, affine real value functions, real number and number, and every, if you have a projection in the matrix algebra, or in the matrix algebra over the matrix algebra, and it has a trace, right? And furthermore, two equivalent projections are going to have the same trace.
00:32:02.154 - 00:32:27.974, Speaker A: The equivalent projection says one x star x and the other is xx star, and the trace is exactly the same one on two elements, x rx. So linear function, that's the same value. Okay?
00:32:29.394 - 00:32:30.134, Speaker B: And.
00:32:32.434 - 00:33:55.354, Speaker A: This is, turns out that the k functor is one. It's almost the only functor on the sister algebra, which has certain simple properties. I won't go into the exact properties now, but it's more, they're quite elementary properties. You can service the compact operators, it doesn't change. And in some way healthy and very, you have only copy between two algebraic, then also it's what's called half exact, the six term exact sequence. But you see, first, before you worry about the index maps connecting the k zero, you have the map k zero given extension ideal in the big algebra in the quotient, and you map a functor, you map the function on the ideal end of the function on the big algebra, and then onto the, into the function for the quotient. And the middle of these three terms, you have exactness there.
00:33:55.354 - 00:34:14.076, Speaker A: Well, first of all, the function we're talking about, if you do, you do both of those maps, the ideal of the algebra, you get zero, right? Graph the ideal into the algebra and divide out by the ideal. You always get zero.
00:34:14.220 - 00:34:15.636, Speaker B: Start with the idea.
00:34:15.780 - 00:34:25.624, Speaker A: Well, the functor has that property. Actually, if it's a functor, then it has to have that property, because.
00:34:27.584 - 00:34:28.324, Speaker B: The.
00:34:29.384 - 00:34:38.464, Speaker A: Composition of the two maps from the functor has to be equal to the map coming from the functor, composition of.
00:34:38.504 - 00:34:43.204, Speaker B: Two maps, which is zero, and then.
00:34:46.144 - 00:34:54.505, Speaker A: It'S not a big surprise between groups.
00:34:54.639 - 00:34:55.313, Speaker B: But.
00:35:13.293 - 00:35:42.434, Speaker A: Two things really go together especially well in the complex case one is mentioned, the ingredient should be talk about k star, k zero and k one unit. By the way, good reference to someone who's fearless. Fall Field Institute. He's the island of the field.
00:35:46.834 - 00:35:47.146, Speaker B: By.
00:35:47.170 - 00:36:38.264, Speaker A: The way, not next week, but week, not this, not next week, but the week after. There's a work of a meeting, a workshop at the institute. Professor Cohen will be giving a series of three lectures. See, field Institute has a lecture series called the Coxsworth Lecture series. Everyone recognized him properly. He came to Europe. This was a picture of him in the.
00:36:38.264 - 00:37:16.354, Speaker A: In the Fields institute, but sitting on top of piano and it shows him was the kind of age where you'd expect the picture to be. A picture of Mozart reminds me of. Well, I shouldn't. Reminds me of another person and a couple of people Clancy from here and then Tom never, who was almost from here because I think probably.
00:37:19.374 - 00:37:20.274, Speaker B: Harvard.
00:37:25.374 - 00:38:05.994, Speaker A: It's worth looking up. Tom never. I'm not. I don't know about his mathematical work, but his artistic work. At one point he was. And he was musical because he accompanied himself on the piano. His story is.
00:38:05.994 - 00:38:23.074, Speaker A: Have I mentioned him before? The particular before or after.
00:38:27.694 - 00:38:28.318, Speaker B: One of them?
00:38:28.366 - 00:39:19.086, Speaker A: He happened to be comparing himself with Mozart. And he said when Mozart was my age, he'd been dead three years. Okay, so maybe I'd like to say more about these 5000 pages. But your classification. Yeah. Yes. Take a projection and take the trace of that.
00:39:19.086 - 00:39:22.270, Speaker A: Would that be the druid? Okay, I left that open.
00:39:22.422 - 00:39:22.806, Speaker B: Okay.
00:39:22.830 - 00:39:23.766, Speaker A: Do you have a suggestion?
00:39:23.830 - 00:39:28.554, Speaker B: Yes. So you can take the traces operator.
00:39:29.334 - 00:39:32.846, Speaker A: Yeah, you have the trace class operators. Let's just review what they are.
00:39:32.870 - 00:39:33.558, Speaker B: Okay.
00:39:33.726 - 00:39:57.916, Speaker A: So it's. They're self adjoint and positive. Which means that since they're also compact, they have by. When you look at a definition, it doesn't say it has to be consequence. They have to be compact operators. So let's say certain compact operators are self adjoint. If they're self adjoint, they're diagonalizable.
00:39:57.916 - 00:40:30.890, Speaker A: Right unitarian, equivalent to diagonal, compact operators. That means the eigenvalues on the diagonal go down to zero. That's your operator. And if it's positive, that's the same eigenvalues are positive. And saying its trace class is equivalent to what? Yeah, so if the trace is reasonable, it should just be the sum of the diagonal. You want that to be finite. Positive eigenvalues sitting down the diagonal.
00:40:30.890 - 00:40:35.914, Speaker A: If the sum is finite, then it's a trace class up here. That's a definition. That's a good definition.
00:40:36.374 - 00:40:37.234, Speaker B: Okay.
00:40:37.654 - 00:41:09.774, Speaker A: And then you can extend it to the whole linear space if you want. But that's just because that's what we're talking about, by the way. The norm for the positive one is just the sum of the eigenvalue. That's the norm. And if it's, you can extend it to the non positive ones too. Okay, so it's a Banach space in that norm. And so what should they do? I was thinking finitely many diagonal entries.
00:41:09.774 - 00:41:40.164, Speaker A: Let me mention one property of these trace class operators. Compact operators are an ideal two sided ideal. Well, that's true for the trace class operators too. It means you have an arbitrary operator and you multiply it by a trace class operator. Then you get another trace class operator.
00:41:40.204 - 00:41:40.784, Speaker B: Right?
00:41:41.124 - 00:42:40.354, Speaker A: What has a trace, so that means if you have a fixed trace class operator, then you get a linear functional on all operators, all bounded operators. By just doing that, you modify and take the trace, okay, so that's, I can see a beginning relationship with what you were saying, okay, because if you look at part of the diagonal and that's cutting down by, so if you want to know what your function is on, if you take your projections on the diagonal, arbitrary ones and zeros down the diagonal, and you multi, that's just take the trace of the product would just be the sum of certain eigenvalues, right? Okay. Yeah, that's sort of what you were suggesting. Yeah, that's an arbitrary continuous norm continuous linear functional on the.
00:42:43.334 - 00:42:44.274, Speaker B: Hold on.
00:42:47.014 - 00:43:07.874, Speaker A: Actually we're talking about the, it's a linear form. It depends on two operators, the boundary operator and the trace class operator. And what I meant to do was consider it as a linear function on the trace class operators. That's what we're going to do with this. Okay? Then it's a continuous linear function in the sum of the eigenvalues less than equal to the sum of all of them, right?
00:43:07.914 - 00:43:10.574, Speaker B: Some of the sum of the less than equal to sum of all.
00:43:13.774 - 00:43:52.762, Speaker A: And so that's what the dual is of the trans class operator. It's the space of all bounded operators. And furthermore, if you look at the, you can linear, if you fix the trace class operator the way I was thinking of, and you then get linear functional and bounded operators. Well, this is an arbitrary, what's called the ultra weakly continuous function rule. Any phenomena, algebra has a pre dual. It's a dual of some Bannock space, okay? And that's unique. It's a unique bandic space.
00:43:52.762 - 00:44:06.308, Speaker A: And duality is really normal and everything is unique as it could be in the case of b, of h, case of propellant algebra operators, as a bandwidth speed. It's pre dual, just a trace class.
00:44:06.466 - 00:44:07.244, Speaker B: Okay.
00:44:07.664 - 00:44:21.952, Speaker A: And so that's quite structured. Oh, thank you for the question. Any more questions?
00:44:22.088 - 00:44:28.376, Speaker C: I guess my question was like, it's like how exactly do we think about like infinite dimensional tree space? And how does that have to do.
00:44:28.400 - 00:44:29.568, Speaker A: With, like, you know, it's like how.
00:44:29.576 - 00:44:44.104, Speaker C: Do we like extract information? Because like in some states, the tree, like the tree state interdimensional is like say the c star algebra above is like it has no finite representation, like fine dimensional orbit, like how do I look at infinite dimensional physics, right?
00:44:44.144 - 00:45:20.676, Speaker A: Well, that's a good question. Don't forget the case we're talking about, the algebra bound in operators. The trace is looking at a positive operator. The trace is only going to be finite if it's trace class, it's compact and the sum of the eigenvalues is finite. But if it's a matrix algebra, then any both cases is a unique trace. For matrix algebra. Every, every operator, it's a finite dimensional hybrid space.
00:45:20.676 - 00:46:00.780, Speaker A: Then the operator is there, it's the same as matrices. The trace there is, everything is trace class, a linear function of hydrogen. The norm behavior is still truly, you look at the norm of the mound and operators on the funding dimensional hybrid space, and that's the dual norm for the norm of the trace class, or two norms on the matrices. So a whole lot of norms. One of them is the positive matrix, you take some of the eigenvalues and the other is you take the norm. Those are quite different. It's a diagonal matrix.
00:46:00.780 - 00:47:16.438, Speaker A: What's the norm? Well, come on, if it's one by you always don't worry about being on the spot. But remember how mouse is dictum, always look at the simpler problem. So if it's a one by one matrix, what's the norm? If it's diagonal, always diagonal, right? If it's one by one, and what's the norm in terms of the eigenvalues? Well, it's equal, right? It equals to the absolute value of the eigenvalue, right? Okay, that's true for any normal operator on a finite dimensional hyper space. And if it's diagonal, then you just take the absolute values of what's on the diagonal and you take the largest one. And if it's an infinite operator, the infinite matrix, and you look at this diagonal, then you look at all the complex numbers on the diagonal, and if they're bounded, the operator is bounded and they ignore them. As an operator on the hook space, it's the. Well, there isn't any largest one.
00:47:16.438 - 00:47:24.354, Speaker A: Maybe there's a soup. But.
00:47:27.094 - 00:47:29.830, Speaker B: If people had done, someone had.
00:47:29.862 - 00:48:23.196, Speaker A: Done all of the problems that Mister Lowell is suggesting people do, I bet you they would know this. That's the advantage of doing everything. And by the way, it's not quite everything, is it? He did everything. I'm not suggesting that everyone, even just Hapley suggested once pick out the depending on how you feel on a particular day, pick out the easy problems and do those next day. You can do pick out one of the difficulties, but you know, you're just looking at them and deciding which ones you are easy or which parts of which ones are easy, which parts are not. That's almost as good as doing them. It's certainly, that's called beginning.
00:48:23.196 - 00:49:06.404, Speaker A: That's how you begin. What I learned about an examination was the first thing you should do when you get the exam paper is look through it, read it carefully, read all the questions, because then you have all that extra time to think about them secretly sort of automatically while you're doing the other one. I guess everyone knows. Okay, so getting down to the more specific question of thought previously.
00:49:10.064 - 00:49:10.600, Speaker B: It'S true.
00:49:10.632 - 00:50:42.064, Speaker A: For the complex numbers, just like any other complex. And I was saying that it's not quite trivial. For the complex numbers, there is a proof which is a little easier than the proof in the book. For General Bannock Alpha, it's a proof which is special for vacancies. I mean, of course, if you're looking at complex numbers, looking at anything, you have to look at matrices too, because that's how the k groups are defined. The reason they're defined that way is it didn't look at matrices to define the, and you wouldn't have any such thing as index maps. So question, specific question that came up was you have codes, curve, vertical or unitary, this is homo topic to one of the special ones coming from a projection in the algebra itself where you have to go to a larger algebra.
00:50:42.064 - 00:51:14.514, Speaker A: Well, it depends what if you're trying to homo how many people? Okay, so here two times n.
00:51:18.174 - 00:51:18.914, Speaker B: Then.
00:51:24.934 - 00:51:43.614, Speaker A: You'Re never going to get, well, that's an example of what you get from the production in the album. You might also look at.
00:51:50.194 - 00:51:51.414, Speaker B: Also look at.
00:51:56.314 - 00:51:59.854, Speaker A: Okay, so you look at p times.
00:52:01.574 - 00:52:02.314, Speaker B: Then.
00:52:05.934 - 00:52:51.494, Speaker A: One by one matrices, you're not going to be inside one by one matrices over the complex numbers. The only way, the only production, the only path you get this way is just z. You get to z, and that would give you an arbitrary path. But if you look at z to the n in the complex numbers, then it works. Okay, so that's the question. You look at a path, not just p z, but p z to the n, some production of the output. Now it's still not true for an arbitrary manic algebra and every closed path of the vertical one of these for some, even for some ends.
00:52:51.494 - 00:52:59.704, Speaker A: But for a matrix, if you start with a matrix algebra with complex numbers, and it's true. If you have a path in.
00:53:05.284 - 00:53:05.780, Speaker B: Closed.
00:53:05.812 - 00:53:38.724, Speaker A: Path, beginning and ending unit of the unit, then this is homo topic to a special one like this, entirely inside the outer, which is not true for an arbitrary system, but so you might say, you might think it's easier. That's the main statement. What we just did is every coast path, this is k, that's k one in the suspension. So v zero maps to.
00:53:40.744 - 00:53:41.764, Speaker B: Suspension.
00:53:43.624 - 00:54:07.494, Speaker A: B maps towards. By the way, it's relatively easy.
00:54:09.274 - 00:54:09.610, Speaker B: Just.
00:54:09.642 - 00:55:08.944, Speaker A: One by one matrices, it's relatively easy to see that not everything is homotopic. Just take Z itself and there's no way you can homotope that to a constant path in the circle, just inside the circle, inside matrices. Someone suggested earlier, take the determinant. I've forgotten who it was. Someone hear me. If you take the determinant and that's, I guess you get you down to one to one by one matrix, and if it's invertible matrix, it'll be determined will be non zero, right? So we have a path of non zero complex numbers, and we know it will not be homotopic through such paths to a constant one necessarily. But if it was, well, that means there are certain paths which even if you go to matrices, you can't overlook.
00:55:08.944 - 00:56:28.460, Speaker A: That tells you that k zero, it shows you that k one is of suspension is non zero. You get from that k one c of t. If you want to get that, it's actually, but it is just once you get it from the data point. Okay, but then you have to prove the difference other than that, for you to do it in a special way, just from a vacancy. Okay, well, the trick for matrices is quite simple to describe. The trick for adrenal vanik algebra is a little, it's a little complicated linear algebra. Then you trade off, you make a polynomial approximation to the curve, then you make the matrices larger, reduce the degree of the polynomial to a linear polynomial, and improve using functional calculus.
00:56:28.460 - 00:57:22.224, Speaker A: It doesn't fall linear, then it is homo topic to this. That's how you do that, that's how you prove projectivity in the general case. And by the way, injectivity is very, very, it's described in the book. I'll talk about it again. But what do you do for matrices? By the way, I'm sure Mister Lau will be happy to see people upstairs by now. There probably could be very well beyond. That's a bit of an exaggeration, perhaps not that small room, but let me just say very quickly what the strategy is for unitary matrices.
00:57:22.224 - 00:58:02.574, Speaker A: Well, if it's curved unitary matrices, then you know that each one is diagonalizable. Each single unitary matrix is diagonalizable, and the eigenvalues may or may not be distinct. But you can hit it a little tiny bit so that the eigenvalues are distinct. That's what you do to the whole curve. You hit it a bit, you kick it a bit, you kick the tire, it looks like a tire, right? So you kick it a bit. That's supposed to be something you're not supposed to do in your car, but you can do it. Here you have, don't tell them I said.
00:58:02.574 - 00:58:46.984, Speaker A: And then you get all the eigenvalues everywhere, at every point, at every one of these unitary matrices, except at the beginning, very beginning, where it's just eigenvalues to be distinct. Then you just trace them around. Think about it. This reduces the problem to the case that there's just complex numbers by itself. It's a single curve inside the circles, single closed curve inside the circle, because you can always separate out, you can label the distinct eigenvalues. Continuous functions are always distinct except at the endpoints. So each one has its own identity.
00:58:46.984 - 00:59:15.964, Speaker A: You can label it and you just work with them, you can stretch them out. So there are, each one is a power of z, okay? There are unitary matrices and the eigenvalues and absolute value, one, some z, okay? That's what you do. And by the way, how to do that is in my paper, in my paper on the classification of Cc altitude rank zero in 1993.

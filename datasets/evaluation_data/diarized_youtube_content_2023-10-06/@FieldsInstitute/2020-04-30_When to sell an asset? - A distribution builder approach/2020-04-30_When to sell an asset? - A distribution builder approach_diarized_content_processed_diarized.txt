00:00:00.520 - 00:01:22.334, Speaker A: Okay, well, I think we should probably get started. So I'd like to welcome everybody to the Fields Quantitative Finance Seminar series, the monthly event that we have and an event that Fields has been hosting for, I'm going to say, 25 years now. It's going to be their 25th anniversary, probably this year, of this seminar series. And maybe some of the visitors today are new to the program or to our seminar series. So, like I say, it was started in 1995, and it's been a flagship event at the Fields Institute that's drawn in people from industry, in person, and to hear some of the top speakers worldwide in all areas of quantitative finance, mathematical finance. So today we're running a Zoom meeting. Unfortunately, our second speaker, who is scheduled to have to speak today, was unable to join the Zoom format that we've got, but we're very happy to have Stefan Sturm giving a talk today.
00:01:22.334 - 00:01:58.784, Speaker A: So, Stefan's from Germany originally, and he's an associate or assistant professor at Worcester Polytechnic Institute in Massachusetts. He finds himself currently in New York City on sabbatical. He's having an interesting experience there at NYU. I think he's been collaborating with Peter Carr, who's. Who's a familiar face in our series. This is, I think, the first time Stefan's talked in our series. So it's a great pleasure to have Stefan here to give a talk about when to sell an asset.
00:01:58.784 - 00:02:00.944, Speaker A: So, Stefan, welcome.
00:02:01.764 - 00:02:38.078, Speaker B: Okay, thank you, Tom, for the really nice introduction. So, I have to correct you on a small point. While I indeed did my PhD in Germany, I'm austrian citizen, but. Okay, this is a minor point. Thank you. And also, Sebastian, very much for inviting me. And as you said, what I'm presenting is joint work with Peter Carr from NYU, who was so kind to host my second half of my sabbatical.
00:02:38.078 - 00:03:40.394, Speaker B: And, yeah, what I'm presenting today is some preliminary work on what we started to work together. And, yeah, Peter is somewhere else in this call, so if there are any questions which I'm unable to answer, I hope people jump to my side and help me with that. Okay. To get started, what, already? The title says when to sell an asset. The questions which we want to discuss today is the following. Pretty simple one. Assume you own an asset which has some price currently, and you consider that you want to sell this asset, and assuming that you know the future dynamics, of course, not deterministically, but in a stochastic sense of this asset, well, one is the best time to sell this asset.
00:03:40.394 - 00:04:33.774, Speaker B: And this sounds, at first, as a pretty simple problem, and you might think, do I miss something? People are doing currently something much more complicated doing in microstructure, optimal execution, and looking on how price impact affects optimal selling and so on. No, we are not doing this. We are doing something really, really simple. All we have is one asset and we try to sell this asset on some optimal time. Also, you can think about this asset of course, as shares of a stock. But then there's a question why you should sell altogether. So I would suggest that as your example in mind, you can think something more like a home or real estate or another asset, where it's clear you want to sell the whole asset at one time time.
00:04:33.774 - 00:05:23.206, Speaker B: And as I said, the goal is just to determine what is the best time. And best time is of course not a deterministic time, but can be some kind of random time, a stopping time. What is the best time to sell this asset? As I said, this question sounds simple. And you ask, of course, is this not something what has already been answered? Well, this question has been answered of course, in many different ways. And I would say philosophically say, rely on two different approaches. One approach is basically to try a universal perspective and try to determine from an objective point of view when is the best answer. Well, this comes follows basically the intuitive.
00:05:23.206 - 00:06:46.580, Speaker B: Hence, where? Well, the best time to sell an asset is when its price is the highest. Well, when is the price the highest? Well, if you look on a fixed time period, and you are looking just at the running maximum of the asset, and you would like to sell the asset when it is at its running maximum, you will soon realize that this is a nice goal. But in reality, this will not work since well, we're at this point when asset process reaches the maximum. You don't know if you are at the maximum since there is still time left. Meaning this, mathematically speaking, this is a random time which is not a stopping time. So the goal of this universal approach is to say, okay, can we not try instead finding stopping time, which is as good, as close as possible to this random time? And how this is usually done is to say, okay, let's try to look just on the relative error you are making by taking the stopping time instead of the random time. And then you just try to minimize the expected relative error.
00:06:46.580 - 00:07:49.148, Speaker B: This is something what has been pioneered by Shiraiya, FSU and Zhou in a paper with a nice title, thou shalt buy and hold, which was published twelve years ago or so. And they come to the conclusion in a geometric boundary motion model, that depending on the model parameter, either you should sell immediately or you should hold assets indefinitely. This analysis has then been refined by Dutour and Pasquia, also in a geometric brownian motion model. But after that, I'm not aware of any work in this direction. Contrary to this universal approach, there exists a subjective approach. And by subjective approach I mean approaches that try to take into account the personal preferences by the seller. The classical way to formulate preferences is some kind of utility function.
00:07:49.148 - 00:08:43.424, Speaker B: So this problem turns out to be of this type. I don't say exactly of this form where it's written down, but of this type, you try to maximize expected utility of SAS advice at your stopping time. This is something what has been done quite a lot in the literature. For instance, as a relatively recent paper by Tim Leung and Wang will look on this for different utility functions and geometric brown in motion. Once the Nuremberg processes literature on how you can do this using mean variance criteria, well, I send variance and risk aversions. I send just simplifications of proxies utilities. There's some pre science work by Vicki Henderson using prospect theory, but this is basically the second counterpoint, taking a subjective prospect.
00:08:43.424 - 00:10:04.896, Speaker B: This basically mimics a separation of work people have done in portfolio optimization, which is maybe the more well known work where you have also a universal approach, usually calibatting, and the Kelly criterion, which doesn't care about preferences, and subjective expected utility maximization. Now, when all this exists, what is our goal here? So, the point I take is that I believe that the point of, of you taking personal preferences into account when devising an optimal strategy is a correct point of view of thinking. You want that as the preferences of people are reflected in the optimal selling strategy. However, the classical way which is done is utility functions and or risk aversion coefficients. And this is something where I'm a little bit skeptical about. Let me explain about it. This whole theory of utility function has actually a very, very long history, actually much longer than mathematical finance.
00:10:04.896 - 00:11:20.844, Speaker B: It goes back to work by Daniel Bernoulli in the first half of the 18th century, and was then later axiomatized by von Neumann and Morgenstern, which shows that if you have preferences which are in a certain way rational, this corresponds exactly to utility functions. And then from the 60 zones, there exists a really long strain on financial mathematics literature using utility functions as representation of preferences. Of course, the paradigmatic example is Bob Martin's treatment of portfolio optimization. And everything came from it, but also this optimal selling literature. And what lies behind this is the idea of utility function. And this here, what I show you is the original utility function, how it appears in Bernoulli's paper. And what Bernoulli argues already, such a function which is describing the utility that people get out of a certain random amount of wealth, is something which should be measured by a function which is increasing and concave.
00:11:20.844 - 00:12:45.080, Speaker B: Well, about the increasing part, I think we will have quick understandings that this is something pretty logical. Well, everybody prefers more money over less money, so increasing, I think, is not much contested. But the question is, why should we such a function concave? Well, Bernoulli goes back to example and says, he speaks about a poor man and a rich man in his paper, and he says, well, this poor man finds a lottery ticket on the street. And to make things simple, let's say this lottery ticket is already filled out. He has not to pay for it, and it pays off either a million dollar or zero dollar, both with probability one half. And then a rich man comes along and asks a poor man if he would like to sell the lottery ticket for $400,000. And Bernoulli then argues, this trade is something what would be very much in the interest both of the poor guy as well as of the rich fellow? Well, you could say, well, on bare face values, the expected payoff of this lottery ticket is $500,000, which is more than 400,000.
00:12:45.080 - 00:14:16.994, Speaker B: But for this poor guy, which has maybe already to look how they get something to eat this evening, having $400,000 for sure, is something which helps really a lot and might help them to be the best of their life, not have to worry about getting something to eat. Whereas if they keep the ticket, well, if they get 1 million of dollars, it's from their perspective, not so much difference in 400,000, whereas in half of the cases, they will get absolutely nothing, and in this case, say, we'll still suffer. So it's pretty much a no brainer to accept. Whereas for the rich guy, for whom having another million or not is maybe not a big difference, for them, it's a clear deal to say, well, an expected $500,000, clearly better than an expected $400,000, and, well, we will have still many deals in our life where we can do similar bets. So it's pretty much a good option to opt for the higher expected payoff with more uncertainty. And this is exactly what is the phenomenon which say, catch in this concavity of the utility function. This is the reason, basically, why utility functions have become something like the mainstay of economic and financial analysis.
00:14:16.994 - 00:15:07.218, Speaker B: However, Sara has in the last, and I would say now, 40 or maybe even 50 years, but maybe 40 been mounted quite some different kind of criticism of the philosophy of utility function. And I would look on two different strains of criticism of utility. So one is coming from people which usually are associated with what we call behavioral finance. Kahneman and Tversky, some very well known people. Kahneman won a Nobel prize. Quiggin did some early work. Also Richard Taller, who won a Nobel prize, who phrases this utility function as something like what econs, how he calls economically thinking.
00:15:07.218 - 00:15:47.972, Speaker B: People consider. But real people don't think in this term. And real people make different decisions. And based on the findings, these people come up with slightly different conclusion, but which you can phrase in generally as utility functions are not concave in contrary for losses. Usually people behave as utility functions would be convex. And in particularly rare extreme events in classical models, not adequately considered. And people think that they have a much higher likelihood than sedu in reality.
00:15:47.972 - 00:16:58.514, Speaker B: So you have to do some distortion of probability, or using shock integrals to account for this. I think this is a very interesting criticism, but I don't think it pertains very much to our point. Since the question I would pose is, should utility functions be something descriptive or something prescriptive? And if we speak here about advice we give to people how people should act, this doesn't mean necessarily we have to take the preferences, how they acted in the past, as face value, since people act irrationally. And I don't know why one should base decisions on irrational behavior and the past. So this is a very good criticism if we want to understand how people act and describe them. But if we want to give some advice, I think is a good point to make. That actual and rational economic analysis as it is behind the classical utility theory is reasonable.
00:16:58.514 - 00:17:48.446, Speaker B: However, there is also a second strain of criticism, which is not a criticism on the framework by itself, but on its implementation. It's just that utility functions, or even risk aversion, is something that is extremely hard to measure. For an economist, it's pretty easy to say somebody has a certain utility function. But if I ask each of you, what is your utility function? Or even what is your risk aversion coefficient? I'm not sure if you have a good answer to it. I definitely don't have it. And of course, people came up with many different ways to come to proxies to this, to come to tests, to make experiments. It's a new trend also.
00:17:48.446 - 00:18:47.914, Speaker B: Now again in robo advising to get information which gives information about the risk behavior of people. But nevertheless, I would say it is a point that this is something where estimates are usually not very good and which usually are not very consistent. So as nice utility functions are in theory, I think it is something what is in practice not really useful tool. Now what we can do instead of utility function and we don't have to do something anew. There is something what is called the distribution builder. This is an approach which has been developed 15 years ago by Bell Sharp, Goldstein and others. You might know Bell Sharp, also Nobel Prize winner for the ubiquiti from the sharp ratio.
00:18:47.914 - 00:20:43.234, Speaker B: Dan Goldstein is a very well known cognitive psychologist working at Microsoft who has done a very nice TED talk on this topic. And their reasoning is exactly from where I based my rationing on investors are notoriously bad in estimating the utility function and instead of trying to get better methods out. So utility functions is a also using a lot of psychological research that at sand we should try to solicit some different information from economic agents from investors. We should try to get direct information about which distributions of wealth they would like. And this was something that was particular developed for questions of retirement planning, where you have optimization problem with fixed terminal time horizon. And they say it's much, much more intuitive to let say agents directly choose the desired distribution of terminal wealth, which is satisfying a budget condition, meaning is possible to be achieved with the initial capital. This is something what is very beautifully described in this book by Belsharp Investors and Markets, which is based on his Princeton lectures where he says, okay, what classical portfolio optimization is doing is said they work under these conditions, they have a certain budget, they have no ledge about prices, I would say about stochastic price dynamics of the future.
00:20:43.234 - 00:22:09.876, Speaker B: They have an input about investors preferences, say utility functions of risk aversion. And out of this, say, calculate an optimal investment strategy, which at the end is just a distribution of wealth at terminal time, and say, suggest that we should do actually something inverse. Well, of course, we should still consider, say original budget, which somebody has for investing. And one should consider surprise dynamics. But instead of specifying preferences, one should specify, or let's specify the investor directly as a distribution of the terminal wealth and basically invest with this regard, and nearly accidentally, say investors preferences or utility falls out as collateral gain. What one gets, let's look on it a little bit more practically. They have built up this tool, what they call a distribution builder, and this is just a graphical tool which helps investors to choose the optimal portfolio at retirement time.
00:22:09.876 - 00:23:54.730, Speaker B: And this consists of these small blocks like DwiZ, which the investor can move around describing basically here, density function of the terminal wealth. And there might be some additional features like a minimum level or some reference point. But the crucial thing is that there exists some cost meter which tells you how much of your budget is used to achieve a specific distribution. Well, of course, if the distribution is too high, well, you want for sure double your current wealth, then this budget will be extremely high. But you want somehow to find a distribution which is using exactly all or nearly all your terminal wealth, and in this way is achievable and uses nearly everything. And in this way people can just, with a cursor, move around this kind of t twist buttons and find their optimal wealth allocation for the future and have a very intuitive way to deal with this problem. Well, now one might ask, how does from this intuitive data playing how this works actually, how is the cost behind this cost meter calculated? Well, this is actually, they don't specify it very clearly in the paper, but if one thinks about, it's a little bit, not too hard, all what one has to do is one has to think about what is the cheapest strategy to get a distribution.
00:23:54.730 - 00:25:05.454, Speaker B: And we are here in a complete market. We know in a complete market we have a unique pricing kernel, or call it rather nicotine derivative, and we want to get the distribution. Well, this is not what we are used usually in math finance. Usually we are used to speak about random variables. And a random variable can be in a completely market of course be hatched. But what about distributions? Well, the thinking is random variable distribution can be achieved by many different random variables. And of course we would like to find the way which is the cheapest to achieve the distributions meaning of all potential random variables which have this target distribution f, we try to find that one which is the cheapest, meaning it minimizes the costs where the cost is nothing else than just the risk neutral expectation of this random variable.
00:25:05.454 - 00:26:43.470, Speaker B: In these complete markets, under some mild conditions, this problem has even a very nice and intuitive solution based on the bounds that the optimal random variable which corresponds to this distribution can be displayed just as an inverse cdf of one minus cdf of the pricing kernel applied to the pricing kernel. It's not the main point of this talk, so we can discuss it later if you want. But the point to make is what is the mechanism behind this distribution builder is relatively easy and brings us back just to classical hedging by doing some rationalization. How you go from distributions to random variables. And all this is mathematically built on a long strain of literature, which is built on this distributional approach to portfolio optimization, which has been pioneered by Phil Dipwig already in the late eighties, and goes then in things like the quantile approach by her and Xu, and a lot of work by Carol Bernard, Steven van Duffel and the co author. And however, this is to a good way, limited to what I said, complete markets and terminal distributions. And there exists only few generalizations of this.
00:26:43.470 - 00:27:45.834, Speaker B: One. Very noticeable is a dynamic version of the distribution builder in this forward performance measure framework by Musehler and sarifopoulos, which was done by Philip Monin and sends us some ongoing work by myself and Carol Bernard and Mauricio Elizalde. Mejir on incomplete markets and intertemporal consumption and success tells us some ongoing work by Carol Stephen and Thibault Lux on a robust version. But this is all pretty tricky stuff. And so the question is, can we adapt? Can we harness this distribution builder approach to our problem of optimal selling? This is what is the main point I want to talk about. But before I do this, I think this is a good point, Tom, to take questions on this background explaining what we want to do if there's something unclear about.
00:27:46.694 - 00:28:04.934, Speaker A: Yes, thank you for giving a minute to yes. So Agostino Capponi has asked a question, and I guess I would ask the same question. Agostino, I'll just. Do you want to ask it yourself? You have to turn your mic on.
00:28:09.674 - 00:28:10.974, Speaker C: Can you hear me now?
00:28:11.394 - 00:28:12.650, Speaker B: Yes, Agostino, I can hear you.
00:28:12.682 - 00:29:08.510, Speaker C: Perfect. Okay, so my main question is, why would the distribution approach be easier and easier than specifying like a risk aversion? The idea is that as an investor, maybe I have some ideas on how much weight I want to put on some area of the density of this distribution. Let's say, for instance, I want to put very little weight on very large values or very small value of wealth. But if I look at intermediate values, maybe I'm not sure if I want to have, let's say, 20 or 30% probability on a wealth level in the range of $50 to $70 versus $70 to $100. So I'm very uncertain, I think, about how much weight I want to give to some distribution of wealth versus others. So I have the same. I mean, I think it's the same to me.
00:29:08.510 - 00:29:13.634, Speaker C: Seems as difficult as saying, am I risk averse with 1.5 or 1.6 or 1.7?
00:29:15.814 - 00:30:48.238, Speaker B: I would say this is maybe true for you, as you have worked very long in this framework of risk aversion. And as I said, this work is, to a good part coming from psychologists. So there's a financial part, which Bill Sharp is leading. But the other part is coming by Dan Goldstein, who is a cognitive psychologist, and he's basing this also a lot of empirical work, which he has done before with Gert Gigerentzer, who is doing a lot on how people perceive probabilities. What is the easiest way to specify it? Is it speaking in terms of art, speaking in terms of distributions and so on, and fair conclusion based a lot on experimental evidence from clinical psychology, is that at least average people in the perception of probabilities can give much easier estimates of distributions. In particular, if they have tools where they can really allocate amounts of money. Basically one, each one of these status blocks corresponds to $1 or $1,000, which they can move around to a certain thing.
00:30:48.238 - 00:31:06.034, Speaker B: So it's not something, what I want to explain you, but where I would say this is something what is done by psychological research. But as far as I know, the psychological research is done mainly on a general public and not in academics, in this feat.
00:31:09.824 - 00:31:11.608, Speaker A: Yeah. Okay. Thank you, Stephanie.
00:31:11.616 - 00:31:12.244, Speaker C: Thank you.
00:31:13.624 - 00:31:20.244, Speaker A: I see there's a bit of discussion. Sebastian and Simon, do either of you want to ask a question at this point?
00:31:21.464 - 00:31:27.244, Speaker D: Actually, I think I'll just delay it to the end instead. I don't want to bog down the presentation too much.
00:31:29.184 - 00:31:32.644, Speaker A: Okay, I'm not hearing from Simon, so thank you, Stefan. Let's move on.
00:31:33.224 - 00:32:25.180, Speaker B: Okay, so we have now basically our question when we shouldn't sell an asset. And I have made an argument for the decision theoretic framework, which we want to use. This is a distribution builder approach. So the question is how we can harness the distribution builder approach for the question of optimal selling. Well, if you start to think about. We have to adopt the approach a little bit. We can still let people specify distribution, but this should be, of course, now, not distribution at a fixed point in time, but it should be a distribution of the asset value at the time of a sale, of a stopping time.
00:32:25.180 - 00:33:22.430, Speaker B: Of course, if we speak in this way, then any asset dynamics we think about should be asset dynamics, not in dollar terms, but asset dynamics, which already include, say, discounting, or which describes time preferences of the investor. And then following this approach, we can say, well, what we should say. Or what's a distribution builder? Well, now we don't have a budget. No. Since we know already what is the value of the asset now. So all what the distribution builder should tell the investor is if the investor tries to move to a distribution by moving the Tetris blocks, is. Yes, this distribution is a distribution which is attainable, or it is a distribution which is not attainable.
00:33:22.430 - 00:34:40.836, Speaker B: And by attainable, we mean nothing else than exists a stopping time. Almost surely finite sets asset value at this stopping time corresponds exactly to the desired distribution f. So, goal of the distribution builder is, first of all, finding out if a given distribution is attainable. Second, if you think a little bit more about this, this might not be enough, since it might be actually that you could get something what is strictly better than the desired distribution. We don't know if all distributions are attainable, and maybe you could get something which is strictly better than the proposed distribution. So actually the notion which we want to work is a notion of super attainability, where we say a distribution is super attainable if it is small or equal. In first order stochastic dominance send asset value at the stopping time t.
00:34:40.836 - 00:35:56.954, Speaker B: Put it differently, if we can find a stopping time t sets asset value at the stopping time, dominates, in first order stochastic dominance, the prescribed distribution. Then we say the distribution is super attainable. You might see that this is a little bit a mimicking of what we speak about in hedging, like hedging and super hedging, except that our order here, since we don't speak about random variables, but we speak about distributions, is not an order, almost surely, but it is first order stochastic dominance, meaning strict everywhere orders of the according cdfs. And then besides this question, another reasonable question is, of course, is a proposed distribution optimal? Well, that's a good question. If we speak about optimality, we will have also to ask, in which sense optimal. So let's keep this question a little bit in the back of our mind. But it's something for sure, a good question today, if the investor proposes something, it's a good distribution or not.
00:35:56.954 - 00:37:21.394, Speaker B: And the last guiding question should be, well, is resulting stopping strategy, actually a strategy which is practically implemented, since if I just tell you somehow, abstractly, that exists a stopping time, but you don't know how you can implement it practically, it's not really helpful. So you want stopping time, which is somehow nicely described as first hitting time of something. And if you look a little bit about the math behind this question, in particular on the first question of attainability, then this might remind you something about having a diffusion at a random time equal to distribution. And this is exactly what comes as a Scoverhot embedding problem. Well, the scowhard embedding problem in its classical form says if we have a boundary motion and a distribution f, does there exist stopping time tall such that the brownian motion stopped if the stopping time corresponds to this distribution. So you can think graphically about this if you have here a coordinate system. Let me just quickly go out to full screens, and it's easy to draw.
00:37:21.394 - 00:39:03.494, Speaker B: And then you have different pulses of brownian motion, which are going around and which are getting stopped at different times. This is a different path, which is now stopped at this time. Here is another pass, let's say a path like this, which is stopped at this time. And then, of course, the goal of this question is, can we determine the stopping time set? If I just look on the stopper versus at the different times, corresponds exactly to this distribution function f, which I prescribe. And this is, as I said, a very old and longstanding problem in probability theory, which has many, many different solutions. We, in our case are mostly interested not in boundary motion itself, since our asset process will be seldom a boundary in motion, but in generalization to diffusion processes, which is something which builds very much on a solution by Asima and yor back from the late seventies, which was then first generalized to drifted brownian motion by Grunditz and Faulkner, and then to general one dimensional diffusion processes by Pedersen and Peskier, and also Cox and Hobson. And this is basically the mathematical vehicle which we will employ to solve this problem.
00:39:03.494 - 00:39:57.894, Speaker B: Well, we can do everything for general diffusion processes one dimensional, but I would ask if we can just mainly consider a simple example, which is very well known to you, geometric boundary in motion, since here we have much more intuition about it. And let's review this problem and geometric boundary in motion. And in the last minutes, I will tell you a little bit about more general results. So, let's assume the asset price follows a geometric boundary motion. Let's assume the investor discounts using a discount rate r. This discount rate doesn't have to be an interest rate, it can be a market interest rate. But we have no hedging here going on.
00:39:57.894 - 00:41:00.284, Speaker B: All what we are doing is we want to determine an optimal time for selling, no hedging at all. So it can be a very subjective discount rate, just describing the time preferences of the investor. And then we know that the discounted asset prices follow zelda boundary in motion. Now, where the drift is something what we would usually call the asset returns, nu minus r. Now, if we use the results of the scoval embedding problem for geometric boundary motion, which was, I think, never actually everywhere written down, but it can be basically simply derived from the results for drifted boundary motion, by just making an exponential change of variables, we get the following results. We have basically two cases. Either the excess return is higher than variance over two, or the excess return is lower than variance over two.
00:41:00.284 - 00:42:19.166, Speaker B: If success return is higher than variance over two, then any distribution, what we want is super attainable means in particular, if the current asset value is 100, you want to say you want to get for sure 200. Yes, it's possible. You want 300? Yes, it's possible. Why this is possible? Well, basically, in this regime, the geometric boundary in motion is a submariting gale and automatically drifting upwards, whereas in the other regime, when the excess returns are smaller than variance over two, then not all distributions are super attainable, but only distributions which satisfy a moment condition. And this moment condition says just set the ace moment just v scaled by dividing by the initial asset price should be smaller or equal by one, where a is just a number which is calculated using model parameters. Basically, one minus two excess returns over variance. Now this case, we can split again into two different cases.
00:42:19.166 - 00:43:22.558, Speaker B: One case, the case b, which is a little bit, not so much interesting, where the interest or the discount rate is actually higher than the drift. In this case, all distributions you can achieve will have a mean which is lower since the initial asset price, whereas in the case its excess return is between zero and variance over two. Then we have some distributions which have actually a mean which is higher than the current asset price. And this is something what has of course, financial implications. Let's just start with the last case. Like I said, the discount rate is relatively high. Well, in this case, if all your future distribution have a mean smaller than your current asset price, and you have some variance, of course you want to avoid volatility and you don't want to get a worse mean.
00:43:22.558 - 00:44:23.230, Speaker B: So the only thing what you can do is sell immediately. Don't hold this asset any longer. In the exact contrary, we are in the case one, the submartingale case. Well, if you can achieve distributions as high as possible, well, then there is no reason to specify an explicit cell rule, since basically over time, what you might get can getting better and better. So for this case, our answer is just don't sell. We give exactly the same answer, like Shiriya, if you and Zhou gave you shalt buy and hold, what is actually the most interesting case is the case in the middle and most likely case, I would say, where our excess return is between zero and variance over two. In this case, we can do somehow better initial asset value.
00:44:23.230 - 00:45:31.546, Speaker B: And the question of course is how we should do it, in which way we should do it. Sorry. And of course, this brings us back to the question what an optimal distribution for the investor, and in this case, a distribution we say is optimal. If this moment condition we have does not only hold as an inequality, but if this moment condition holds true with inequality, why? Just think about an easy case. If f has a continuous distribution. Well, if f has a continuous distribution, and you have an inequality here, you could just move your whole CDF rightwards until equality is reached. So you could get a distribution which is in first order dominance, better than your original distribution, which is still super attainable, and therefore it's definitely better.
00:45:31.546 - 00:45:54.442, Speaker B: And the best possible. What you can get is, of course, if you're at the optimum, is if you're inequality. Well, if f has atom, you have to split the atom split at sand. It's only a little bit different. Technically difficult. I want to stress that there is a difference between optimal and attainable distributions. First, you might think this is the same, but no, it's basically a three way thing.
00:45:54.442 - 00:46:38.944, Speaker B: We have all super attainable distributions, which are the largest class, some of them attainable, not all of them, and of some attainable, only some of them are optimal. And of course, we would like to give the investors the advice to pick only among the optimal distributions. How can this be implemented? I said we would like to have something which is nicely implemented as a stopping time. Well, you don't have to follow all these formulas here. The basic message is, you can get it. And this is a basic SMA, your construction to the, to the scoreboard embedding problem. You can get it as a hitting time.
00:46:38.944 - 00:47:22.604, Speaker B: But this hitting time is based not only on the asset price process, but also on the running minimum of the asset price process. Basically, you have to look where is your asset price. You have to look what is the historical minimum value of your asset price. And based on this, you can get your decision if you should sell at a given time or not. Lastly, we can also use this to get explicit formulas for the expected selling. Let's look on some very specific examples, which give you a little bit more intuition. This is when we restrict a little bit of choices of n.
00:47:22.604 - 00:48:19.854, Speaker B: Let's say cannot choose between all distributions, but only between distributions in a parameterized family. Think log normal or pareto, or weibol or gamma, but where they can calculate parameters. And it turns out that in this case, this problem turns out to be a simple mean variance, or mean standard deviation trade off, which is very similar to the efficient frontier in the Markowitz model. I have here three graphs for different families left is log normal, middle is pareto, right is gamma. And we have this for different parameters of this parameter a, which was basically just giving a summary statistics of the geometric boundary motion. Let's just look on this blue line in the log normal model. This is something like an efficient frontier.
00:48:19.854 - 00:49:04.900, Speaker B: X axis is a standard deviation, y axis is mean. And we see if we increase all these distributions, which is in this red area, attainable. But of course, only those one which are actually on the blue line are optimal. And you see, if you increase the standard deviation, you can get a better mean. And, well, if you have something like 30% standard deviation, you can get only 3% above the mean. But if you go to 100% standard deviation, you can go to something like 16% above the mean. Similar for pareto and gamma, there's only one slight difference for pareto.
00:49:04.900 - 00:49:51.986, Speaker B: For pareto, you cannot get large means. There's basically an upper bound on the means which you can attain. Whereas for log normal and for gamma, you can always get means as large as you want as soon as you are ready to buy surprise in a high standard. Okay, let's look on a very specific example. Let's say log normal. And I show you that, well, we can phrase attainability condition very easily in terms of model parameters. If your mean of the log normal distribution or the mean of the normal distribution behind is smaller than log x minus a times a squared over two distribute, it's attainable.
00:49:51.986 - 00:50:06.494, Speaker B: And of course, you're optimal if you have equality. In this case, you can calculate the optimal barrier function. Slightly complicated, but it's okay. And the expected cell time.
00:50:06.794 - 00:50:11.570, Speaker A: Can I just jump in and let you know we have about five more minutes to finish?
00:50:11.682 - 00:50:13.074, Speaker B: That's completely fine.
00:50:13.194 - 00:50:14.322, Speaker A: Okay, thank you.
00:50:14.418 - 00:50:58.798, Speaker B: I want just to give you a nice illustration about this. The formulas are abstract, but I think a picture tells you more than 100 more formulas. Let's look on the left picture. The blue line is just our geometric boundary and motion process. Well, until the stopping time, from which one it stays constant. The red line is the running minimum process, and the green line is this barrier function, which is just a function which we apply to the geometric boundary motion. And we see this is always below the red line.
00:50:58.798 - 00:52:10.364, Speaker B: And as soon as the green line hits the red line, this is the selling signal. And here we sell on the right side, we showed this now, not on a time dependent, but in a space graph where we have basically the x axis is asset price, the y axis is the running minimum, and the green line is exactly this barrier function, which we have calculated before. And now where you are starting of course, is this blue point here on top. And now well over time, boss, the minimum and the asset price are moving. And you see in the beginning the asset price is going down and the minimum is going down. And this part here you are basically going only with a little bit, sometimes moving up down, and then you have here an excursion moving upwards, and only quite a little bit later the minimum is moving above. This is exactly the spike here where the minimum value stays the same and only the acid value goes up, meaning the geometric boundary in motion is jittering here along.
00:52:10.364 - 00:53:33.510, Speaker B: And then again for sometimes the minimum is going down until we are at this point here, which is this point here. From one on we have a very long upwards excursion, meaning things are going here parallel to the x axis, until at some point it hits a barrier giving the selling signal. This is how things can be easily seen and easily implemented. Lastly, let me just show you in two slides that what we have done for geometric boundary in motion works pretty analogously for general diffusion processes. If we understand everything in the right sense, in the right sense is building up on the scale function. If you don't know much about scale functions of diffusions, the scale function is just a function that if you apply it to a diffusion, you get a local martingale, which is nothing else than the time change boundary motion, and you can work in the usual framework. And then our criterion, what is attainable or not attainable depends only what the left interval of the diffusion is doing.
00:53:33.510 - 00:55:19.854, Speaker B: Under scale function, if the endpoint, the left endpoint of the interval is scaled to minus infinity, then all distributions are attainable. Whereas if it is strictly right of minus infinity, distribution is attainable if and only if the scaled mean is small or equal to zero, whereas a scaled mean is just the mean where we apply the scale function to the distribution. And in the same spirit, we can get some conclusions that if the scale function is convex, which in the geometric boundary motion case means nothing like nu minus r is bigger or equal to zero, then we should smaller than zero, sorry, should sell immediately. Whereas if the function is concave, then it might be worthwhile to wait, since exists non degenerated distributions which have a higher mean than ish lesser value. And we have also a general representation of this hitting time, of this random time as a hitting time in terms of a scaled area function. I don't go in it since we had the end of our time. So I just want to conclude what we can do is we basically can harness this distribution builder methodology to really say something about, say, optimal selling problem, we can get something what is easily implementable.
00:55:19.854 - 00:55:49.954, Speaker B: It's based on mathematical analysis of suscoro hot embedding problem. And I think from the results on the geometric boundary motion, you see that this is something what is very much in line with economic intuition, and which I would say is even more in line with economic intuition than the solutions using different methodologies. So thank you very much for your attention, and I'm happy to answer any questions.
00:55:51.394 - 00:56:12.774, Speaker A: Well, thank you very much, Stefan. So there's been a couple of questions and comments that were put out in the, during your talk, but other people in the audience, if you would like to type a question to everyone, then hopefully we'll have enough time to deal with them in order. So, Sebastian, did you want to make your comment?
00:56:14.074 - 00:57:08.984, Speaker D: Sure. I think it was partly, I think Peter and Stephen addressed it to an extent, but I'll just say it anyway and see what Stefan's interpretation or response is. So, one thing I was thinking is that if I give you a distribution, then you can come up with a strategy that would generate some payoff in a particular scenario where, for example, the market goes up, but my strategy is down, and probably yet the strategy does generate the correct distribution. However, as an investor, I probably wouldn't be so happy with that kind of strategy where the market's going well, but my strategy is poorly, even though if I rerun the experiment again and again and again, I will still generate the correct distribution. So how do you, how does the distribution approach address this kind of issue? Well.
00:57:10.884 - 00:58:16.650, Speaker B: Everything told is it addresses it in a certain way. So this is where I skipped a little bit in the hand over, we are basing our stopping time on the asema, you're embedding. And well, besides the technicalities, what this asema, your embedding is doing, it has this nice property said, it minimizes, say, running minimum at terminal time over all stopping times. So compared to all other stopping times, what would achieve the same thing? It has the advantage that the running minimum is the smallest. The minimum being the smallest means, well, the investor is in a market environment where the minimum was already pretty much down. So they should be pretty much happy at executing on the current price. Since you are quite a little bit up from the minimum.
00:58:16.650 - 00:59:24.554, Speaker B: And this is actually what you also see in this implementations. You see sets of execution is happening at a point where you're actually drawing up and going quite away from the minimum. So this is something what investors psychologically like. Now, I have to tell you the caveat, I tell you, is this is, of course, something what is based on a stochastic interpretation of surrounding minimum and not of a pathwise interpretation. So what I would really like is, maybe I write it here on the bottom. What I would really like is that I have a distribution which minimizes not the minimum itself, but something like pathwise ratio of the minimum over the terminal asset price. If I could get something like this, I would have a better pathwise interpretation of everything.
00:59:24.554 - 01:00:08.374, Speaker B: I'm not an expert on the scoreboard embedding problem. What I have found out from the screening on the literature, I haven't found a solution to the scoreboard embedding problem, which has this property. I think, however, that in recent years, there was a lot on advance using optimal transport on this cohort embedding problem. So I think it's a very good open question if one can construct a score hot embedding problem, which has additional property to minimize this ratio, and one possible way might be optimal transport.
01:00:11.354 - 01:00:24.594, Speaker A: Okay, I'm not seeing any other questions, so I'll jump in with just a practical question. I expected to do this on a finite fixed time horizon. And do you have anything to say about that?
01:00:26.294 - 01:01:28.374, Speaker B: I don't have to say more that, yes, it is on my mind. It is somewhere on the to do list. I know that there exists papers on scorehod embedding in finite time. I don't know how nicely tractable solution is. One thing, for instance, what is in a similar spirit, can we do time in homogeneous solutions? Yes, exists literature, but this is usually based on very complicated forward backward SDE's where you don't have this nice implementation which you have an interpretation which you have from the same. So my answer would be yes. I'm pretty sure you can solve it on a finite time horizon, but I'm not sure how much of the nice representations and the nice intuition you have on this problem you can salvage if you are on the finite time horizon.
01:01:28.374 - 01:01:30.654, Speaker B: But technically, yes.
01:01:31.314 - 01:01:32.626, Speaker A: Okay. Okay.
01:01:32.730 - 01:01:35.858, Speaker D: I think Simon Cliff had a question as well.
01:01:36.026 - 01:01:40.974, Speaker A: Yeah, I know Simon came in. Simon, would you like to ask a question?
01:01:44.654 - 01:01:46.714, Speaker D: He says no answered. Thanks.
01:01:49.174 - 01:02:17.772, Speaker A: Okay, so I'm going to just. Again, let's have a round of applause. You can find the reactions button on your lower right corner of those things, and we can give a clap to our speaker. Thank you, Stefan. And I just did want to say that I didn't thank the sponsors for the quantitative finance seminar series who are waterfront international. So I should say that. So thank you all for joining us.
01:02:17.772 - 01:02:32.436, Speaker A: We will continue with Zoom in the autumn if we're in a difficult situation that we can't meet in person. But thank you all for participating. I think. I hope it went well. Yes. Sebastian, would you like to say something?
01:02:32.540 - 01:02:34.544, Speaker D: Yeah, once if you're all done.
01:02:34.864 - 01:02:35.552, Speaker A: Yes.
01:02:35.688 - 01:02:51.684, Speaker D: Okay. I just wanted to also thank, thank Stefan as well for his wonderful, interesting talk. I really like this repositioning of the question and the way that you're attacking it. I think it's really, really interesting, worthwhile. Is there a paper out right now on it?
01:02:52.184 - 01:03:13.948, Speaker B: No, we just need to answer all questions. If anybody might have by email, just email me ssturm.edu or you'll find it easily by googling and just me all questions and I'm happy to reply.
01:03:14.116 - 01:03:51.676, Speaker D: Excellent. Great. And the one last thing I wanted to let everyone online who may not know, but tomorrow afternoon at 01:00 p.m. as well, the SIAM financial, math and engineering group is having their bi weekly seminar series and you can find information both online on the SIAM website as well as on my LinkedIn. There's a link there for those interested. It's also interwoven every week so you can be entertained all summer long with some with seminars from also SiAM financial, math and engineering and as well the Bachelor of Finance Society. And alternating every two weeks there will be seminars at 01:00 p.m.
01:03:51.676 - 01:04:01.436, Speaker D: so take a keep an eye out for all of those and we'll be looking forward to seeing everyone back in the field seminar in the fall as well. Thanks a lot.
01:04:01.540 - 01:04:06.084, Speaker A: Thank you, Sebastian. Thank you everyone. Thank you, Stefan, thank you.

00:00:00.280 - 00:00:01.436, Speaker A: Alrighty. Howdy, everyone.
00:00:02.134 - 00:00:02.854, Speaker B: Howdy.
00:00:02.934 - 00:00:03.414, Speaker A: Howdy.
00:00:03.494 - 00:00:03.902, Speaker B: Howdy.
00:00:03.958 - 00:00:19.510, Speaker A: From a and M. I just. It's part of me now. I cannot say. I need to say it now. And you probably got a howdy from me in the emails. So we will begin in a minute, but before that, just a couple of logistics.
00:00:19.510 - 00:00:50.992, Speaker A: So as you know, we will have a photo pic, a picture today. It won't be during lunch because our lunch is quite short, like an hour or so. So please plan accordingly. But we will have our photo at 330. So that's in our coffee break in the afternoon. Does that make sense? Okay, well, we have our first speaker of the day today. We have a full lineup today, so it'll be a busy day, but Anton is going to talk to us about wanted solutions of squared polynomial systems.
00:00:50.992 - 00:00:51.848, Speaker A: Take it away.
00:00:51.936 - 00:01:32.504, Speaker B: Yeah. Thank you. Thank you very much. So the story starts on a sunny day in Minnesota. And imagine I'm sitting in my office there at IMA, a less fortunate institution than this, and a guy barges in my office. He's like, wearing some thick glasses, maybe a hat, although a hat maybe is over dermatization. Definitely no canadian flag, but yeah.
00:01:32.504 - 00:02:01.274, Speaker B: So he goes and says, well, I have a problem. And I recognize the guy, you know, he's like. I've seen him as a grad student in many conferences. He sits in the front row, usually asks a lot of questions. Sometimes they're not questions. So, yeah, he says, I have a problem. And I say, yeah, you do have a problem.
00:02:01.274 - 00:02:36.557, Speaker B: And he says, no, no, that's not what I mean. And he shows me his hyperboloid, right? So, yeah. And then he asks, well, I cannot see in this thing. And then he asks, well, here's the hyperboloid. He asks something like this. You don't see this line that is black. So I'll put.
00:02:36.557 - 00:03:25.756, Speaker B: Put it in pink. He says, like, can you rotate this line? And I say, yeah, with the power vested in me by the state of Minnesota, the line rotates. And he says, well, no, don't do it like a pure mathematician. By any power vested in you, can you do homotopy continuation? And can you move it by homotopy continuation? And I say, well. And then he starts, like, doing this. So that means excitement. So I said, yeah, I can scratch each, maybe.
00:03:25.756 - 00:04:25.924, Speaker B: So I tell him, yes, this line could be moved there and wrong screen. So the line could be rotated 180 degrees. And what's the meaning of that? So let me explain to you. For the people who see the hyperboloid, maybe for the first time, just a minority here. So we have a problem of four lines in three dimensional space, the red, blue, green and the one that is purple, the one that is kind of pink now. And we want to find lines that are intersecting all four lines, assuming that these four lines are in general positions. So the hyperboloid appears by taking the first three lines, drawing one hyperboloid uniquely through these three lines, they would be in the same ruling of the hyperboloid.
00:04:25.924 - 00:05:14.594, Speaker B: The fourth line that is here, it pokes the hyperboloid at two points. And these two points give rise to two solutions, two solutions that are also not so visible here. So let me draw them. So these are just the lines in the opposite ruling of the hyperboloid of one sheet. And by rotating the line, what we do, we permute the solutions. So yeah, when I said yes, I can do it, I did not know what I was getting into. So towards the end of the talk, I'll tell you what, in the second picture, what is on the second picture here.
00:05:14.594 - 00:05:53.242, Speaker B: All right. So without further ado, let's see, how do we set up this problem. So this problem could be set up on a Grossmanian 2.4 by thinking of our lines as two planes, two dimensional spaces, subspaces of c four, and to coordinator that we could maybe fix some of the lines. So l one and l two are column spans of the corresponding columns made out of standard basis vectors l three, l four. Let me just throw the dice and pick a's and b's to represent them. Ok.
00:05:53.242 - 00:06:35.258, Speaker B: The solution is going to be of this form. I want to write this solution in such a way that a prioria intersects the first two lines, l one and l two. And I'm going to write conditions for intersecting l three and l four. Well, what does it mean in terms of columns? In terms of basic linear algebra, you can stack. Well, I guess you can write next to each other the lines that you are trying to intersect. And this determinant is going to be non zero if they don't intersect. And it would be, the matrix would be rank deficient if they do.
00:06:35.258 - 00:07:26.974, Speaker B: So outcome two equations that I have here, and these mean, and this mean that the intersection of my s with l three and l four is not empty. And by design, I designed my chart on the, on the solutions in such a way that it does intersect l one and l two. Automatically the determinants vanish, the other two vanish by construction. Ok, so what do we have? We have a system of equations. Two equations in two unknowns. That's how you set up a square system, as many equations as unknowns for this problem. Let's see what we want to do with it.
00:07:26.974 - 00:08:34.484, Speaker B: So then I was not, at that time, I was not speaking this language, but now I do. I speak of branch covering corresponding to this problem. So in some more real world problems areas, they may talk about the problem space, which is the base space of this, the base space of this map, phi, and the problem solution manifold, which is what you see upstairs. And let me write that maybe I have p's, a problem solution pair mapping to problem. That's my mental image of this branch covering. Well, there is one simple example with an illustration for you. The problem solution manifold is the solutions to x cubed equals p, where p is a parameter and the projection is natural onto p.
00:08:34.484 - 00:09:37.696, Speaker B: And the picture that you see here says that if you take one point in the base, it could be lifted to three solutions, which is true if the point is general. If you look, if you look at the point here in the middle, it's going to have only one point in the fiber. It's a branch locus of this map. Okay, so again, in some less pure societies, they may call such a problem minimal. What does it mean? Problem is minimal if the map is dominant, say surjective, almost surjective. And the fiber, the inverse image, the preimage of p, is finite for any generic p. Okay, what other things we can associate to this map? Well, this is the degree of the map.
00:09:37.696 - 00:10:09.228, Speaker B: Here it's three. So here I have three points in the fiber. The degree of that map is three. And if I take example number two, which is my example with a hyperboloid, and let's say I fix l one, l two, l three, and do what the guy told me, do something. Rotate or massage the l four. Then I should make this l four my parameter. This is my l four.
00:10:09.228 - 00:10:58.364, Speaker B: And, well, the projection is going to be from. So this is my p project. Projection is going to be from the pair p's to p, and the degree here is two. Okay, clear. By the way, questions are welcome as well as anecdotes, stories we can roast if you like. All right, so I'll give you a little bit more complicated problem coming from a real world application of orbit estimation. This is more recent work with my aerospace engineer friends and my student, Tim Duff.
00:10:58.364 - 00:11:59.114, Speaker B: So we want to estimate orbits of celestial bodies, satellites, planets, whatnot, stars, distant stars, maybe. So what we do, we go about it in a very peculiar way. So instead of doing like classical high, not high school, college, I guess, algebra, with considering, say, ellipses in a plane representing our problem like that, we would consider the dualization of this problem, the dual of this problem. So if we imagine this ellipse somewhere in 3d, then you can construct what is essentially project is going to be a projective dual in p three projective space. But you can think of it as follows. You can think of it as planes. So technically they're in p three.
00:11:59.114 - 00:12:42.070, Speaker B: Check in p three dual, the planes that are tangent planes at points of this ellipse. So you can think of this PI as a plane that touches your orbit. And well, it turns out that all such planes form a quadric in the dual space. And that quadric could be encoded by a four by four matrix. And since we started with a curve, is going to be rank deficient matrix. They have a special peak for it. They call it disk quadric.
00:12:42.070 - 00:13:31.544, Speaker B: I don't know why. I think they think about kind of taken a very, very much squished ellipsoid and then squishing it in the limit. And then somehow that's a disk. Well, anyway, so terminology apart, we need to find a way to represent this q in terms of some parameters. And the parameters we have in the game are, well, first of all, I mean, let's say a satellite orbits the earth. The earth is in the focal point of this ellipse. There is a frame, orthogonal frame, pqw with p pointed in the major axis direction, semi major axis direction.
00:13:31.544 - 00:14:20.554, Speaker B: And out of that, what can we say? We can say that we have this equations on pq W. Well, we have equations, quadratic equations on p and q. And w can be computed from p, q as a cross product. Okay. Now if you do some relative elementary, but not so elementary linear algebra, you'll come up with this expression. So you can encode here q is going to be a multiple. That's, that's what this sign means of this matrix where alpha and beta are some parameters that are basically derived from b and c, where these are the lengths in the picture, focal length and semi minor axis.
00:14:20.554 - 00:14:50.624, Speaker B: And then you have this expression, or you can sort of replace it with analogous equivalent expression on the right. Okay, so. Well, all right. So is the setup clear? Yeah. Okay. Here you see Mother Earth and a low orbit satellite, which is the real problem for them. Like a lot of orbits come from this kind of satellites.
00:14:50.624 - 00:15:47.944, Speaker B: The problem with this problem, the problem with the low orbit satellite is, is that the eccentricity of such orbit is very low. In other words, it's almost a circle. So in that case, this parameter alpha, that participates here turns into zero. And actually the direction of vector p, which was the direction it was pointed towards the furthest point on the ellipse, it loses its meaning in a circle case. So it turns out that if you just do a simple trick of replacing alpha p with some new vector, let's say g, things become better. It works. So the model starts to work for every, all possible keplerian orbits.
00:15:47.944 - 00:16:57.432, Speaker B: And, and you know, like there are some of course, numerical instabilities that are expected for circular orbits. Your solutions might become singular and so on. But basically, and you don't need to observe as many times as like here you have, you see our observers here on the earth and they observe sort of more times than three. And I think in case of a circle, three is enough. But anyway, like this, let me sweep under the rug this considerations and continue with the setup. I just wanted to draw a parallel pointing out that whatever we learned about presenting lines with matrices in Schubert calculus actually works out pretty nicely here. So if you think about an observer, say one, the data that we have is the position of the observer and the direction of the view of the line that being observed.
00:16:57.432 - 00:17:54.064, Speaker B: So these are xi is the position and ui is the direction. Well, what do we have? How do we verbalize this condition? So the line is going to be tangent to the ellipse, to the orbit. But all we know is that there is some plane, we are working with planes, we're not working with lines in our model. So we know that some plane containing this line is going to be tangent, is going to belong to our model. So we can do the following thing. We can represent, we can represent the line dually. So instead of the span of these two columns, we can represent it by matrix AI for the ice observation, which basically gives us zero if multiplied by that.
00:17:54.064 - 00:18:58.754, Speaker B: So then if we took AI and picked a parameter vector CI, a two by one vector, then AI. Let me draw this here. AI multiplied AI multiplied by CI is basically parameterizing all the line, all the planes that contain the given line in the dual formulation. Right. Well, what does it mean for us? If this is an observation of a point on the orbit? It means that it satisfies our equation, it satisfies our disk quadric, and in turn, you know, it satisfies it if and only if the determinant is zero. We can prove that. Okay, so therefore we derive this equation, one observation, one equation.
00:18:58.754 - 00:19:41.570, Speaker B: Yep. All right, so to finish it off, here's our, to summarize the setup, we do need five observations. Let's count the variables in the system and equations that we need carefully. So we have in the matrix, we do have w and g unknowns here. Both of them are three dimensional. So six variables, and we do have one equation on W. It needs to be a unit vector, and therefore we need five more equations.
00:19:41.570 - 00:20:11.304, Speaker B: In general, we can hope we prove that. Indeed, we need five. Right. So, actually, one point to make is that we, in our model, in our data, we consider timeless observation. So a time of the observation is not recorded. It's a completely geometric problem. You have just lines incident to an orbit.
00:20:11.304 - 00:21:03.864, Speaker B: Whereas Mister Gauss in 1801 became really famous. It was the first case of a mathematician becoming famous for solving something practical. So he was trying to use the astronomic data, something like 20, couple of dozens of measurements of asteroid or planetoid, ceres or planetoid. That's what we. Well, okay, so it appears in the sky got measured and disappeared, and the astronomers were wondering where to look for it again. Yeah. Behind is a relative condition, but, okay, it went somewhere.
00:21:03.864 - 00:21:43.908, Speaker B: Yeah, it became invisible. It also has pretty, you know, long orbit. So Gauss. Gauss used time, and his model is different, and he needs only three observations and that. So he only needs three observations. He actually derives, like, it's a complicated method, but he derives one linear equation and one unknown that he has to. That he has to solve with this method.
00:21:43.908 - 00:22:10.844, Speaker B: And that's where he introduced least squares. That's the moment of invention of least squares. Yeah, he did. Yeah, that's right. Gauss did many things well. If he knew how to do this kind of stuff, maybe he would do that, too. But he didn't have a machinery.
00:22:10.844 - 00:23:08.780, Speaker B: I'll explain why. Well, okay, so before I explain why Gauss could not do it, let me explain how Davidenko in the Soviet Union could do it without the computer. So, homotopic continuation is the name of the game, as I said, and this is a mandatory slide to explain to you that a start system could be deformed in a start system, f could be deformed in a target system, g, with the parameter varying from zero to one. And you can sort of do numerical continuation here. You can just employ your favorite od solvers using Davidenko's differential equation. Just do implicit differentiation of the homotopy equation, and you'll get it. But there is an added part.
00:23:08.780 - 00:23:39.834, Speaker B: You can also autocorrect if you make mistakes. Not so big. You can. As you move along, you can correct yourself with a Newton's method. Okay. Davidenko actually is a nice piece of history. I didn't know, a year ago, but he published something in the, he published three page or four page paper in the Academy of Sciences of the Soviet Union.
00:23:39.834 - 00:24:30.364, Speaker B: And then he actually published a full algebraic worked out case in the Ukrainian Academy publication, Ukrainian Republic of the Soviet Union then, and actually in Ukrainian, where he carries out calculations for a quartic equation, something that you could solve with Cortana formulas at the time. And he does it by hand. Computers were not available and gets the same result. So that was pretty convincing. That's the first time an algebraic equation has been used with model recontinuation. No computer is harmed. Okay, well, so here I drew, the things came out darker.
00:24:30.364 - 00:25:35.384, Speaker B: Well, here I drew the branch covering picture. If you take a straight line in the parameter space from point a to point b, suppose you had, suppose you had three points in the fiber in the beginning, all of these three points, you can hope that all three points map to three points to the point b. Well, I mean, there are some problems and you should be aware of this. This is numerical analysis. So everything that is implemented may fail, in particular if it goes close to singularities. So in some sense, we want some freedom to move around, not necessarily in straight lines. And if you're familiar with monodromy solvent, there is a technique, I'm not going to explain, but there is a technique that can generate all three points in the fiber, starting from just one by walking around in the parameter space.
00:25:35.384 - 00:26:09.414, Speaker B: Basically a walk around singularity is in a random fashion and you get them all. Right, so in a nutshell, homotopy continuation. Everybody uses it now. And the trick is very simple. You have to find a way to construct some solutions for a generic instance of your problem. And for example, monothermy solver will do it more or less automatically. But there are some combinatorial constructions you can employ.
00:26:09.414 - 00:27:12.180, Speaker B: And step two, once you found the solutions for this reference anchor instance, you can deform them to solutions of any other problem somehow. So you can get your any solutions or solutions to any target system once you have stashed degree many solutions of a reference system. So here the number of solutions is two. Here it turns out to be 66. We actually jokingly called this method of solving for Conex root 66, therefore. Yeah, I mean, not every person in astrodynamics bought the method, actually. They say that cannot work because the system is inherently nonlinear.
00:27:12.180 - 00:27:58.284, Speaker B: So nonlinear for them is like just do not enter a sign. They say it's impossible, but it is, and we have code to prove it. Okay, let's see. Have time for certification I made one slide for rigorous, to point out that rigorous verification of end solutions is possible if they are regular, for sure. And I plan to speak a long time about it, but I maybe shouldn't. So let me just point out several things from this slide. So.
00:27:58.284 - 00:28:47.304, Speaker B: Well, the first thing, of course, is that Frank is a very kind mentor to many people. And I think when John was a postdoc at Texas in a and m, they embarked on a project that was more computer science than mathematics. They took Smale's alpha theory, analyzed every single bit, and made an efficient implementation of. Of Smale's method of alpha certification. This paper is quite well referenced, I think more than 100 papers. Yeah. So the reason.
00:28:47.304 - 00:29:38.348, Speaker B: Right, so this. That goes a long way to say that papers without theorems could be gold, and mathematicians are needed in that realm. So, for example, I mean, many papers refer to this paper on alpha certify. For example, there is this nice puzzle problem of seven touch and cylinders in three space. Can you position seven infinite cylinders like infinite pencils, in a way that they touch each other? And. Well, the solution was found numerically by a couple of people, and they used alpha certify out of the box software. It's a library written in C.
00:29:38.348 - 00:30:08.426, Speaker B: Right. So they used it to just do it, just prove that what they found is correct, is nearby, a correct solution. Okay. I'm not sure what that is about, but maybe I have a zoom call. I already have one zoom appointment. That's enough. So, yeah, let me just mention briefly that things are getting very bad.
00:30:08.426 - 00:30:47.472, Speaker B: So there is a craft trick method that kind of now is more considered, more efficient way to deal with it. It actually was suggested first by Michael, who was. Who is in the audience, and there is a lot of work on singular solutions. Deflation is not going to keep us square. Or if it's isingular deflation due to John and Charles in the back there, then it's not going to keep us square either. It's going to increase the number of equations. So that somehow is not keeping squareness.
00:30:47.472 - 00:31:25.944, Speaker B: But we found several situations where we can do something that we called inflation for certain reasons. And that's, together with Michael and Lee, is Keith and Lee, who is also in the audience. So, bug Keyson, about this onion picture, please. But I'll move on. All right. So one other thing, scenario I wanted to point out, which is kind of. So this orbit stuff is very real world, but then this is more real world.
00:31:25.944 - 00:32:17.474, Speaker B: So these are problems coming from computer science, computer vision, more precisely. And they have to be solved in microseconds, that's the requirement. So we call them point line mineral problems. Well, the typical, the first introductory problem that you need to know about is a problem of seeing five points, let's say five of your fingertips from two eyes and trying to figure out, well, what is the position of the right eye with respect to the left eye and also the orientation. So you have to find an element of se three that coordinates two eyes. And then you can do many things like 3d reconstruction, which our brain actually does. So here's a dragon, let's see if I blow it up on the screen.
00:32:17.474 - 00:33:12.764, Speaker B: It doesn't blow up. Here's a dragon with five points marked on it and you know they're matched. So you have a lot of, you see those five points in two planes, two vision planes, and then you run your algorithm. The thing is, why do you have to run in microseconds? You have all this. Well, it's hard to see in this depiction, especially on zoom, but you have a lot of points matched here in the second picture. So you have a lot of matches produced by some other heuristic algorithm which has a lot of noise, makes a lot of mistakes, and you need to basically sample from that mass and sample five points, solve your problem, sample again, solve another problem. And hopefully some of those solutions are not junk.
00:33:12.764 - 00:34:09.412, Speaker B: Close, not junk, close to what it really should be. So it actually channeled through the pipeline called dransec random sample consensus, which you should imagine something that Gauss should have invented but didn't because it's least squares and classification of points at the same time. So the points are classified into, well, customarily red and blue. The blue points are good, the red bad and the red are outliers. So they do not conform to the model according to this classification. So the algorithm classifies them and actually constructs more or less like least squares approximation on the inliers. Right? So that's how.
00:34:09.412 - 00:34:54.734, Speaker B: But we do need a lot of samples to, to feed into this pipeline. That's why we're solving the minimal problem of five points. Let me just say perhaps very little about this. Yeah. When I got introduced to this problem, it was not set up in the way it's set up on this slide. In this slide, it's set up through the depth, the notion of depth. And the depth means the scalar, like say if this is our y, what is it then? This is mu one y eleven.
00:34:54.734 - 00:35:45.954, Speaker B: Basically how much you need to scale out of the vision plane to get the actual point in 3d. So a lot of things in the applied world depend on formulation. In this formulation, somehow fired. I mean, I've heard about this first, actually, from Mimi Bouton, who's a mathematician of canadian descent. And yeah, somehow it sat in my mind, and sometime at some point, it fired in this formulation, let me just skip it. But in this formulation, you can come up with nine equations and nine unknowns, but they're all quadrics, and the degree of the system is lower than you may expect. It's 20 instead of two to the 9th.
00:35:45.954 - 00:36:55.592, Speaker B: So this problem is considered to be easy and easy for computer scientists because they do have a stock algorithm that does it in five microseconds or less. It finds all the 20 solutions. We actually analyzed all the point line problems together with Tim, Kathleen and Thomas some time ago and figured out all the configurations that could be explored as minimal problems and full visibility. And then we switched our attention to partial visibility in three views. And this one represents, actually the picture. This is a schematic combinatorial representation, one of the gazillions that we obtained, that has a low degree, relatively low degree, 272 problems. And it represents a relaxation of a problem with four points.
00:36:55.592 - 00:37:56.702, Speaker B: So it's four points and three eyes. If you have three eyes, you see four points, but then you need to kind of drop one of the points and like, say, one coordinates of one of the points in one of the eyes to get only a line correspondence as opposed to a point correspondence. So with this relaxation, the reason for this relaxation is to square up the system, because otherwise it's over determined for four points only. And once you square it up, it has not so large 272, but large degree. So that was actually, we worked on it in another institution in iCerm, and Ricardo Fabrizio produced a nice piece of software, the homotopy continuation software, that does it in 0.5 seconds. Everybody in the community of vision said, no, no good.
00:37:56.702 - 00:38:29.994, Speaker B: 0.5 seconds is not good for one sample. So what was implemented in Ricardo software is our usual one step, one step, two strategy. You compute some stock solutions, 272 solutions, and then continue all of them, and then one of them is happy. You have to pick one. After all. You have, like, for example, one equation that you dropped from the system that you can use.
00:38:29.994 - 00:39:53.438, Speaker B: Okay, but here's the paradigm that I would like to promote. So what does solving mean in the real world? What it could mean? Like, when we're solving a quadratic equation, do we want to have two solutions exactly like with the formula represented with a formula? Or we want some rough approximation of the roots. Or maybe we want like the largest real root, or, well, especially if you're teaching it to students, you use only five examples. Maybe we want to know a and b when they come from a very small set. What more importantly for this setup is that, and this is very common setup in engineering, is that failure of your algorithm does not mean it's bad. I mean, failure 100% is bad, but non failure in nonzero number of cases is pretty good because it's, remember, mapping it back to random sampling, you have a lot of samples, and if you succeed on one fifth of them, that's fine. So what we have to imagine is now some kind of a real geometry map.
00:39:53.438 - 00:40:32.776, Speaker B: So for example, here there are solutions of a cubic together with the problem mapped on the problem space. And you should imagine some kind of a distribution, which I tried to construct with the shading. The distribution actually lives upstairs, the distribution lives upstairs on the problem solution manifold. And these are problem solution pairs that actually occur in nature, and they occur in nature with some probability. There is no way to model it. So it's on manifold. It's on manifold.
00:40:32.776 - 00:41:19.992, Speaker B: It's messy. So we did the only thing that the computer scientists would do in such a case. We said data is our distribution. We took many, many, they have humongous databases marked by humans points, and we created something that constructs. So what, I'm not going to explain this in full detail, but what we construct is a small set of problem solution pro, problem solution pairs f and x. We call them anchors. I think for this problem, this was on the order of something like 160.
00:41:19.992 - 00:42:06.424, Speaker B: So not a small number, but not a very large number. So we construct anchors that are good with respect to our method. Our method is homotopy continuation, so we could jump with high probability, practical probability, from one anchor to the problem that we want to solve. Except we need to know which anchor is sort of closest in whatever. It's not even a metric, it's just sort of a methodological metric. So we need to pick an anchor, and we constructed a small neural network. It had to execute really fast, but it had to produce some non zero result.
00:42:06.424 - 00:42:55.362, Speaker B: So we constructed, we trained the classifier, neural network classifier that executed in microseconds and picked the anchor. And then the homotopy continuation took over. And it was easy to do because it was tracking the real pass. It could fail, of course, and it did it with a success rate, which is non zero, let's put it this way. So it did it at pretty good speed and effective speed is basically that divided by the success rate. So effective speed is something that you can compare with other algorithms. Well, 65 milli microseconds is much faster than 0.5
00:42:55.362 - 00:43:24.588, Speaker B: seconds. And that's what made this project a very big success. So we called it pick and solve strategy. Because we are not continuing all the paths. We actually pick some anchor and track only one pass and get to a happy solution with some probability. Sometimes we are not very happy, but we do get somewhere. Okay, let me see.
00:43:24.588 - 00:43:57.796, Speaker B: So should I aim at 50 minutes? Yeah. Okay, so I'm gonna skip the other slide, which says do invariant theory or learn it. So that was actually crucial for that invariantization, to some extent of that problem was crucial before we did machine learning. So it was not a blind machine learning. Machine learning was just a tiny part of the procedure. So, going back to. I wanted to end with Schubert calculus, of course.
00:43:57.796 - 00:44:36.624, Speaker B: So going back to Schubert calculus. Well, so we did follow up on this each of Frank to get gala groups of simple distributed problems. Of course, galois group for the hyperboloid case is just a group of two elements. It's a full symmetric group. But look at this one. We could get for simple Schubert problems, which basically are problems where only two conditions are non simple. The other ones look like simple intersections.
00:44:36.624 - 00:45:07.536, Speaker B: Yeah, these are. Right. Okay. Yeah. Frank is a great expert on that, and he can also explain you this notation, which I did not introduce. But there was one, one problem in the zoo of G 39, problems that gave a particularly large number of solutions. And we actually, by tracking many paths, we could prove.
00:45:07.536 - 00:45:34.924, Speaker B: Okay, prove with a star. Because of potential numerical errors, they also can always can happen. So the theorem star says that we can prove. Confirm at least that this is a full symmetric group. Okay. And the picture on the right just says, this was early days. I was doing it with PHC Maple, which was an interface to PHC.
00:45:34.924 - 00:46:01.512, Speaker B: It ran relatively slow, but it was good for this size of a problem. Already, that one took seven days. Let me write it down. Seven days? Yeah. It's written down somewhere. Yeah. So the point is, like here you have two solutions marked a, and then you can take them for a spin.
00:46:01.512 - 00:46:49.664, Speaker B: So with some, you take them for. I think we did like some square paths in the parameter space, but what. But basically this, right? Yeah. We did something simplistic, but it worked. So we walked in a square, came to the same point, and discovered that two solutions were permuted. That was enough for that problem. What you see on the screen is basically maybe the real parts of x and y, as they move along the path, of course, the square in the parameter space is piecewise linear, but the path that they are unpredictable, to say at least.
00:46:49.664 - 00:47:53.944, Speaker B: Okay, so let me say that that led to my involvement in longest project in history. So, this paper with Abram, Frank, Ravi and Jan, it uses, I mean, the idea is kind of expressed in the theoretical paper of Ravi, and this is in the annals. So I think the idea emerged maybe like in the beginning of 2000. So it took. Yeah, so I think my estimate is not very wrong. This took about 20 years to complete, pretty much. Although one of our papers is still unpublished, the implementation paper is still unpublished, but I think it's likely the most involved piece of homotherapy continuation code.
00:47:53.944 - 00:48:47.850, Speaker B: Let me explain you why. This picture shows ten different checkerboard moves that you can make and they translate into chromatopy, just to show you how the hyperbola cases being solved. You have this checker, we call it checkerboard tournament. So you have checkerboards that you see, these black and red dots represent some flags and what we're doing, some flags on the standard basis vectors. And what we're doing is kind of bubble sorting the black flag, and let the red dots move accordingly according to the recipes that we. According to geometric degenerations that Ravi prescribes. Right.
00:48:47.850 - 00:49:22.214, Speaker B: And. Well, this problem degenerates into two problems with one solution, and then Ravi would call it on degeneration. What we do. So we do on the generation, we go backwards in this diagram to take these two solutions and bring them back to the original problem. Yeah, there is a lot of combinatorics. You have to do this. And each move corresponds to some one call to a homotopy continuation tracker.
00:49:22.214 - 00:50:26.700, Speaker B: And they're not boards of four x four like this appears in our paper. You have to consider a general case where you have big boards, stifled coordinates for parameterizing some Schubert cells, or checkerboard varieties, more generally look horrendous in the first view, but we're able to operate with this. So let's see. Let me say that in conclusion that every talk is not complete without the joke. Theorem star and maybe Macaulay two presentation. Where is my Macaulay two? Here. So what do we see here? We see some Macaulay two code in the Macaulay two web that you should try.
00:50:26.700 - 00:51:11.394, Speaker B: If you haven't tried Macaulay, try the web version of it. So you need a package called Schuberth calculus. Here's your two four. Oh, it's thinking something. Something went wrong on my side. Oh, actually, no, the output is suppressed. Let's see.
00:51:11.394 - 00:51:47.026, Speaker B: Yeah, here. So here, you see, I took flags, some flags that have to participate in alarmotopy. You have two special flags and two random flags. And then you solve Schubert problem, and after a while you get two solutions. Actually, they fall into some pattern that are similar with what I began. And you can take another random flag and do it again. And.
00:51:47.026 - 00:52:04.124, Speaker B: Wait, what's going on? Had purple where it appeared for some reason. I don't know what. Anyway, I just think it's the end. It's a sign that I should stop my talk.
00:52:11.624 - 00:52:17.888, Speaker A: So, are there any questions? And remember, if you have a question, raise your hand and I'll go to you so that you can use the mic for the zoom audience.
00:52:17.936 - 00:52:25.844, Speaker B: Okay, let me put my glasses on, so I see you better. Or Kirsten.
00:52:26.424 - 00:52:38.334, Speaker C: So, in the gala groups for these Schubert calculus solutions, are you taking the complex points and looking at the gala group of that branched cover?
00:52:39.114 - 00:52:39.894, Speaker B: Yes.
00:52:40.594 - 00:52:57.314, Speaker C: Can you try to add, if you restricted to the real points for both the problem space and the branched cover, you could ask what happens for each of the connected components for those gala groups. Monodermy groups.
00:52:57.734 - 00:52:58.474, Speaker B: Right.
00:52:58.934 - 00:53:05.634, Speaker C: You can imagine doing that with the c points, with the whole c two action on the whole kit and caboodle there.
00:53:06.814 - 00:53:41.984, Speaker B: We can imagine that. Although this would lead to some trouble. Let me explain. So, in those connected components. Well, first of all, we will have to find them somehow, and that would not be numerical. In those two connected components, your discriminant lockers, your branch lockers, does it disconnect the space? Yeah, maybe, surely. Oh, well, we have a comment.
00:53:41.984 - 00:54:10.794, Speaker B: Well, so it depends on whether it's co dimension one or more. Co dimension one is kind of expected, and co dimension one is not a problem in a complex case, for obvious reasons. It's real co dimension two. So it does not disconnect the space. But we basically have real algebraic geometry is hard. And that's one of the reasons we cannot jump the barrier sometimes.
00:54:12.574 - 00:54:19.934, Speaker A: In one formulation of the bronze app, in terms of the roots of polymphysics, it appears to be codimental, two or three.
00:54:21.074 - 00:55:29.618, Speaker B: Yeah, I've come across. Well, maybe that's. So, any posdogs here with a nice office that Frank could barge in? Yeah. So, actually, in my career, I come across some problems where not only you have a singular locus, drop in code, dimension not dropping, dropping dimension, but also, even if your space is some kind of a weird semi algebraic variety, you may be able to construct an algorithm to find a path that connects two points in other words, in some curvy spaces where you cannot go in straight lines. We go in straight lines in Cn, basically. But if it's curvy, you need some recipe to how to navigate. So those cases do appear in nature.
00:55:29.618 - 00:55:41.794, Speaker B: And maybe Frank can tell more about co dimension of the discriminant locus here. Thanks. Yeah.
00:55:42.294 - 00:55:43.314, Speaker A: Anyone else?
00:55:45.654 - 00:56:12.584, Speaker D: Since this very fast microseconds computer vision problem is motivated by application, you would have some kind of constraints on the hardware, but maybe you can, maybe there's more hardware you can access than you're using. I wonder if testing like four cases at once using more processors would give you a better effective speed, because this paralyzes in a really natural, not perfectly efficient way.
00:56:12.704 - 00:56:26.404, Speaker B: That's a valid point. You could parallelize many things, and here homotopy continuation is trivially parallelizable, so it gives you almost perfect speedups. Although people who implemented it made this.
00:56:26.524 - 00:56:32.308, Speaker D: Almost, well, almost perfect, but not perfect in the way that you're measuring the efficiency here. Because if your efficiency.
00:56:32.476 - 00:56:34.644, Speaker B: Right, I'm not measuring the.
00:56:34.724 - 00:56:36.236, Speaker D: I agree with everything you said.
00:56:36.420 - 00:57:14.354, Speaker B: The usual counter argument that computers, vision people would give is that it's already like a small piece of a big pipeline and you're processing many samples, so you have a much more coarse parallelism to explore. And the more coarse it is, the better. But I can see the point, like say, there are GPU implementations which could reap the benefits. There's some simple linear algebra going on billions of times, so why not do it on a GPU? So that's a valid point.
00:57:16.434 - 00:57:17.974, Speaker A: Thanks. Any other questions.
00:57:21.794 - 00:58:34.794, Speaker B: For the neural network pipeline that you described in the pick and solve algorithm, how does the speed compare to if you just have the neural network do the whole problem and output the se three element? Well, we didn't find, we didn't find a good way for, for just the neural network solution of that. The magic here is, so what we tried is substituting, well, homotopy continuation secretly is just a glorified Newton's method, more or less. But. So we tried to substitute homotopy continuation with a local method, like Newton's method, say one step of Newton's method, and that didn't work really well. So somehow you have to strike the sweet spot in this methodology. You have to strike a sweet spot of how many anchors you need for your problem to get traction with the method you have. And for homotopy continuation, that sort of gold was struck.
00:58:34.794 - 00:59:01.964, Speaker B: But with the. Yeah, I mean, with the neural network complete neural network solution, I don't know how to proceed. There are some attempts, but they're not. They usually take in just images and produce just the final answer. Yeah, that's not the method of choice in the industry right now, at least for this problem.
00:59:04.604 - 00:59:15.724, Speaker D: Would you mind clarifying, in this last stage for this numerical Schubert calculus package, what are the spaces involved? In what space is the homotopy continuation taking place? Are you working over a flag variety.
00:59:15.764 - 01:00:01.124, Speaker B: Or something like that? Oh, yeah. So the input for that is, there are four flags that were in this example, but there are also, there are also partitions that are fed as a part of the input, more general input. And, well, the incidences are set up only using parts of the flag. If the incidences are simple, then not the whole flag is used. If you want to deal with more flag variety problems, I know a guy. They're more complicated.
01:00:04.384 - 01:00:24.910, Speaker A: It's having steeple coordinates for the grass lining. But what's unusual in bed at heart, is the coordinates of a parameterizing have to change with the homotopy. And that took a while to understand that was an issue. It's not like a fixed space homotopy is happening on the space changes with the homotopy.
01:00:25.102 - 01:01:21.964, Speaker B: Right, right. So this, I mean, that is sort of a technical point there. But in Ravi's algorithm, there is one flag that stays fixed, and then basically two flags interact with each other. Like this flag that you see the inverse flag represented by the matrix here. The second matrix here is getting straightened out, like bubble sorted into the first flag, and then the degeneration happens. But at each point, the degeneration has to be coordinateized. And what was very tricky is to coordinator in such a way that we don't end up with just geometrically correct solutions which are singular in a numerical way, let's say.
01:01:21.964 - 01:01:36.004, Speaker B: So you have to pick your coordinates very carefully for the transitions. Speaking of mathematic institutes, it was in aim that we had three squares on doing this.
01:01:39.704 - 01:01:43.824, Speaker A: All right, well, let's thank Anton, and we'll have discussions in copy break.

00:00:01.600 - 00:01:34.924, Speaker A: So welcome to the joint Fields Waterloo seminar and just like to mention before we start that Adi Ben Israel is here and Adi is my mathematical grandfather and Samuel Zobeck would have joined us but unfortunately he's not well, couldn't join us. And Miguel. I was lucky enough to have Miguel as a PhD student and Bissan is Miguel student and this is all a coincidence, believe it or not, and not a coincidence that we're related, but a coincidence that Miguel and Bisson are presenting today. They're both interested in a very similar area. So it's my pleasure to first introduce Miguel. So if you look at the webpage, the field's webpage, you can see that it's a pleasure and it's so nice that I can be so proud of my mathematical son, all the things that he's done over the years. Miguel is now holds the chair of operational research at the School of Mathematics at the University of Edinburgh and he's also an InRIA international chair.
00:01:34.924 - 00:02:03.444, Speaker A: There's a long list of things that he's done. He's got more than 100 refereed publications in optimization and he also currently serves as president of the inform section on energy, natural resources and the environment. So there's too many things to mention. So please take a look at the bio that Miguel has kindly put there. So Miguel, can you share your screen?
00:02:04.304 - 00:02:12.688, Speaker B: Yes, thanks. Thanks Henry. I'm going to try to do this before. There you go. That should be working.
00:02:12.816 - 00:02:17.066, Speaker A: Yes, thank you. So Miguel, please go ahead.
00:02:17.250 - 00:02:51.734, Speaker B: Good. Thanks Henry. It is a pleasure to be here. Thank you for the invitation. And it's always very nice to think back of the influence that an academic father or parent or even an academic descendant has had in one's work. So I've been privileged to be working with you and BSan and many other people along the way who have helped a lot. And I think that working as groups and teams is a very nice feature of this job.
00:02:51.734 - 00:04:07.012, Speaker B: What I want to present to you today is about semi definite optimization approaches for reactive optimal power flow problems. You won't be surprised to know that this involves a whole bunch of people. I'll talk about the results that are in a total of about five different papers along the way and I've highlighted the two PhD students that have made a lot of contributions to this work. One of them is Christian Bingeni, who was a PhD student at Polytechnique and the other one is Julie Slivak who was a double PhD student between polytechnique and Sorbonne Parinor and then the other co authors that were, in most cases, supervisors or co supervisors are Sebastian Digabelle, Lucale Toccar, Emiliano Traversi, Manuel Ruiz and Erling Anderson. And they all contributed to the work that I'm going to present. What I'm going to do is first give you some motivation background and explain the contributions that we've made as a group over this piece of work. If you don't know very much about optimal power flow, and if you don't know much about reactive optimal power flow, that's perfectly fine.
00:04:07.012 - 00:04:53.914, Speaker B: I will give you a very quick introduction about what we're talking about. And then I will essentially show that you can write it as a polynomial optimization problem. And this is together with the convex relaxation park, the link between the presentation that I'm giving and Bsan's presentation as well, and the link through the power system side. So that's how all this is going to connect together. I'll then talk about the problem, talk about semi definite convex relaxations from the literature to give you again a bit of background. And then I'll talk about several things. First, I'm going to talk about what are called chordal relaxations and how to do improved clique merging.
00:04:53.914 - 00:05:52.514, Speaker B: Then I'll talk about more general approaches to semi definite relaxations for reactive power flow, and then talk about some practical constraints that can be added. Finally, a branch and bound algorithm with some computational results on that, and then a wrap up section. The first couple of sections here don't talk about reactive power yet. They basically talk about the AC optimal power flow without the reactive component, and they really lay the basis for what comes afterwards. So it's all about reactive without necessarily being explicit in the first couple of sections of the talk. So let's forget about reactive optimal power flow and just talk about optimal power flow in the AC context or the alternating current context. What we're talking about is finding what's called a network operating point that optimizes some objective, which is usually generation cost.
00:05:52.514 - 00:06:48.414, Speaker B: So what we have is we have a power system, we have a network for electricity, we have generation at certain points in the network, and we have demand at certain other points in the network. These points in the network are usually called buses. And so they're the nodes of our graph of the network and the links between the buses. The lines are the edges in the network. So in mathematical terms, we will talk about nodes and edges in the power systems literature, we talk about buses and lines, but it's exactly the same thing from a structural perspective. Now, it's known that solving this kind of problem with AC networks is a difficult problem, in particular because we have power flow constraints that describe the behavior of electricity in the system. And these are non convex constraints, and they're usually rather challenging to work with.
00:06:48.414 - 00:07:49.404, Speaker B: One interesting point that I find is that this problem was first written down essentially in the way that we still talk about it back in 1962 in a paper by Carpentier, and is still challenging. So we're still working on how to attack this problem. More recently, Beanstalk and Verma showed that even testing feasibility for the problem is strongly np hard. Now, an additional feature of these problems, if we can call it that, is that it is possible to have local optima. So not only is it a non convex problem, but we can have local optima, we can have feasible regions that are disconnected. Um, and it's difficult to really converge to the global optimal solution, which is what we want to do not only from a mathematical perspective, but of course, also from a mathematical perspective. Um, and there was some work done some years ago here in Edinburgh about these, uh, challenges from the problem.
00:07:49.404 - 00:08:28.374, Speaker B: The basic point, from a practical point of view, is that there is a lack of fast and robust solution techniques for this problem. Now, that's interesting. From a mathematical point of view, it's a challenging problem. It's fun to work on that, but it's also important from a practical point of view. From a practical point of view, what we really want is be able to find a global optimal solution with a running time that's about three to five orders of magnitude faster. So not three to five times faster, three to five orders of magnitude faster. We need something that runs a lot faster than what we can do nowadays.
00:08:28.374 - 00:09:01.042, Speaker B: And the economic impact could be huge only for the US. We talk about billions of dollars annually that this could save in the operation of power systems. The realization of this importance led to something called the Arpai grid optimization competition that's going on. Challenge one had the results announced in February of last year. Challenge two has been going on, and people already talking about challenge. Challenge three. What does this mean? Well, challenge one is basically the core.
00:09:01.042 - 00:09:43.818, Speaker B: It's this acopf problem with some additional constraints that are called security constraints. Challenge two is this security constraint, OpF, plus a whole bunch of other things that move the formulation closer to reality. And then challenge three, well, guess what, it's going to be even more things added on to move the problem closer and closer to reality. But of course, it makes it harder as we go. It just keeps getting more complex, even just a challenge too. We talk about a whole bunch of things like price responsive demand rate, ramp constraint generations and loads, fast start unit commitment, transformer tap ratios, phase shifting transformers and switchable shunts. I won't go through what all of these mean.
00:09:43.818 - 00:10:42.584, Speaker B: I'll focus on the two in blue, because if we look at Acopf plus the two in blue, this is what's usually been considered the reactive optimal power flow problem in the literature. So what does this mean? Well, it means that we have an acopf with these extra devices to essentially regulate what's called reactive power in the system. From an optimization perspective, what this adds is a bunch of integer or discrete variables. So not only do we now have a non convex optimization problem, we now have discrete variables on top of that. And in particular, of course, this makes it harder than just a basic opf. And what we do is, in part of the work that I'm going to show, I'm going to look just at shunt elements and say, actually there are restrictions on what we can do with these things. So we can have limits on the number that can be activated or deactivated at a certain point in time.
00:10:42.584 - 00:11:29.278, Speaker B: And we can also use them to simulate what's called primary frequency control. There's a lot of terms that I'm throwing out, but as we go along, I'll explain from a mathematical perspective what these things mean and how they come into the picture for the optimization. First, let me summarize what I'm going to present to you. What I'm going to present is the following contributions. We're going to first look at this improved clique merging algorithm for semi definite chordal relaxations of AcopF. We're then going to look at different relaxations for the reactive optimal power flow, and in particular a new type convex model for the tap changers. I'm going to also discuss the practical aspects that I've mentioned.
00:11:29.278 - 00:12:19.064, Speaker B: And then we actually implemented a branch and bound approach for the reactive optimal power flow. So we have a non convex problem with integer or binary constraints. In this case, if we restrict only to the chance that our binary, we actually ran a branch and bound approach, and to the best of our knowledge, is the first time that this has been done. And we show that we can get very good results on large instances with up to 10,000 buses. So 10,000 nodes in the system. And not only that, but even if we can't quite close the gap, we get feasible solutions that have the global guarantee of how close we are to optimality and are better than those that are obtained using other methods from the literature for this problem. Let's start putting some mathematics on this.
00:12:19.064 - 00:12:52.166, Speaker B: So if I'm talking about acopf, what am I talking about? Well, here's an optimization problem for the AC optimal power flow. I want to minimize the generation cost. So I have a sum over all the buses where there's generation of the cost of generation times the output of that generator. That's the variable p. Now, this is what's called the active power. That's output from that generator. There's also something called q, which is the reactive power.
00:12:52.166 - 00:14:07.664, Speaker B: And the way this works is that the power generation is a complex number, is represented as a complex number, where p is the real part and q is the reactive part. And the real part is the part that we actually use to turn on lights and run engines and run motors and do all sorts of other things with electricity. The reactive part is essential for the system to actually run. So when we talk about managing reactive power, what we're talking about is essentially managing a quantity that we're not directly interested in, but we have to manage that quantity in order to maximize the throughput of active power through the system, which is what we actually care about. So we want to minimize the generation cost for the active power. We have power balance equations that essentially say that at each node, at each bus, you have to balance the real or active power and the reactive or complex component of power. We have line flow equations that link the power that flows both active and reactive through a line in terms of the difference of voltages at the two endpoints of the line.
00:14:07.664 - 00:14:38.546, Speaker B: And there's two equations because one is for what happens in one direction and the other is for what happens in the other direction. Then we have the generator power capacity. So the generation has to be within given bounds. We have thermal limits on the line. So there's, as you put electricity through a line, the line heats up. So you have a physical limit on how much you can put through. You have limits on the voltage magnitude at each bus in the system.
00:14:38.546 - 00:15:13.256, Speaker B: And you also generally don't want to have large differences at the angles between the voltages. Now, the angles between the voltages are the complex part of the voltage. So there's some, sorry, this is, if I think of it as polar coordinates. So the angles of the voltages are the angles in the complex number sense. We want them to not differ too much between buses, um, in the same line. And then finally, because the Voltages are essentially relative to each other, we can fix one of the angles to zero. And that just grounds the, the problem.
00:15:13.256 - 00:15:45.044, Speaker B: Okay, so this is what the problem looks like as the, let's say the basic acopf problem. The constraints down here are all basically linear constraints. There's nothing much of difficulty here. What we're really concerned about are the power balance and the line flow equations. And what happens here is that we have quadratic terms in the voltages. Here we have the norm of the voltages squared, and here we have voltage outside this bracket with another Voltage inside. So we end up with quadratic terms in the voltages.
00:15:45.044 - 00:16:37.564, Speaker B: All the blue quantities here are parameters, and the others are the variables that we have to optimize over. So we're really optimizing over the power p, the active power p, the reactive power q, and the voltages v. Okay, everything else is basically a parameter, but we're going to turn some of them into variables when we get into reactive optimal power flow. Now, if I want to solve this kind of problem, there's at least three different ways I can attack it. One of them is to basically say, well, this is a nonlinear Problem. I just deploy a nonlinear solver, I get a starting point, and I run my favorite nonlinear solver, and I get a local optimum to the problem. And oftentimes that works pretty well in practice, especially if one has a good starting point for the optimization.
00:16:37.564 - 00:17:24.911, Speaker B: More generally, if we want to look at global optimality, one thing we can do is linearize the nonlinear equations. And one way to do this is to do what's called DC optimal power flow, which is direct current instead of alternating current. But one of the things that happens when we do that is that we lose basically all the information on reactive power. That makes it difficult to do reactive optimal power flow if we don't have that. The third approach, which is the one that we're interested in, is to exploit convex relaxations of the non convex constraints. That's really what we're interested in. There's been quite a bit of work already done in that direction on Acopf.
00:17:24.911 - 00:18:11.220, Speaker B: I've mentioned that there's linear relaxations. There's a specifically designed quadratic convex relaxation. There's some spatial branch and bound algorithms that use these convex relaxations. There's the idea of a laser hierarchy of relaxations for this problem. There's lots of stuff which unfortunately, I don't have time to mention. But I'll point you to this recent survey paper in the European Journal of Operational Research that has a lot of references and gives a good overview of the action in this space, this is convex approaches for the basic acopf problem. What I want to do is talk a little bit about that and then move to the reactive setting.
00:18:11.220 - 00:18:45.412, Speaker B: As a refresher for everyone about semi definite optimization. We're going to look at semi definite optimization problem in this form. I want to minimize some linear functionality, a matrix v subject to linear constraints on v and v being positive semi definite. Now, v is a matrix. It's going to be a matrix of voltages. So it's no coincidence that quadratic terms of voltages, so it's no coincidence that it's called v. But because I can look at this as a problem in complex numbers, my v is going to be a hermitian matrix.
00:18:45.412 - 00:19:47.394, Speaker B: Not just symmetric, but with complex numbers, it's going to be a hermitian matrix. And I can do semi definite optimization over the hermitian matrix in pretty much the same way as usual, the inner product is just defined in the equivalent way for complex numbers. And because the matrices are hermitian, the eigenvalues are all real, and the positive semi definite constraint is just the same that we're used to. I'm going to now build this matrix variable with the voltage products. If I first cast the problem as a non convex polynomial optimization problem in complex variables. So if I just back up here for a couple of slides, you will see that in some of these constraints, like here, I have this j, j is the square root of minus one. So this is already indicating that there's complex variable, there's the unit complex variable, complex unit is showing up.
00:19:47.394 - 00:20:57.824, Speaker B: I can write the whole thing as a polynomial optimization problem in complex variables. So now I can think of the v's and the power as complex variables, and the nonlinearities only involve the voltage variable. So what I can do is build my usual friendly rank one matrix for a semi definite relaxation using the outer product of a vector v of the voltages. This gives me the norm squared of the voltages on the diagonal of v and the product of the voltages with the appropriate conjugate transpose for the complex numbers of the diagonal. And now I can use the entries of v to linearize the quadratic terms of my acopf. And most of the solvers, if not all by now for semi definite optimization, don't support directly convex variables. And one of the things that Julie did as part of her PhD is to develop a Julia module that facilitates this use of polynomial problems with complex numbers and linking to SDP solvers.
00:20:57.824 - 00:21:37.724, Speaker B: Now what happens when I do this linearization using the entries of the matrix v. Well, these are my equations from before. I replace the norm of v squared with entries of v. I replace the products of voltages here with terms of the matrix v. I also have them in some of these constraints, I can square the bound constraints to bound the diagonal of my matrix v. I can write my phase angle limits as well, and I just have this rank one constraint on the matrix v. If I relax this, everything else is now linear and I have a semi definite relaxation of the problem.
00:21:37.724 - 00:22:44.484, Speaker B: So that gives me the basic semi definite relaxation. This was an idea that dates back to 2008 in a paper by Bai and co authors, where they really just apply this to the Acopf and showed that you get some very good results. Of course, if we solve the semi definite relaxation and you get a rank one matrix, it means you have zero optimality gap and you have the global optimal solution. In general, you get a global bound, and then you have to find a way to round in some sense the matrix variable to the v voltage values. This idea really got a lot of attention after some work by lavais and Lowe where it was observed that if you apply this directly to the standard IEEE benchmarks at the time, you got the global optimal solution. So this was fantastic. You just solve all these problems to global optimality in one go, and the paper studies the structure of these relaxations and give some insight on what's happening.
00:22:44.484 - 00:24:19.324, Speaker B: Now, this is not a magic solution to the problem. At just about the same time, some work that followed showed that this can fail for some practical cases that were not part of the benchmarks, but basically confirms that this sounded like a really good idea. And that's what got a lot of the work that I mentioned in particular in the survey paper that got a lot of people excited about this idea. Now, from a practical perspective, the main limitation is something that we're used to from the semi definite optimization side, it's computationally very expensive for large scale networks. So the challenge now becomes how do we apply this for very large cases, which is what real power systems look like? One idea that dates back to Yabir in 2006 is to use a second order cone relaxation that basically says my large matrix of voltage squared terms is positive semi definite implies that the principle two by two minors have to be positive semi definite, and these are second order cone constraints. I can just relax then further from rank one not only to positive, but only to this group of second order cone constraints. One interesting observation is that this is equivalent to the full relaxation if I have a radial network, which means if I don't have cycles in my power system, if I do have cycles, then this doesn't guarantee equivalence anymore.
00:24:19.324 - 00:25:02.052, Speaker B: It is obviously less tight than the full relaxation in general, but it is much less expensive. And so this is an interesting tool to have in the toolkit for these kinds of problems. There's another relaxation that was proposed by Hejazi and co authors that's called the quadratic convex relaxation. This is based on working with the polar representation of voltages. So instead of using real and imaginary components, we use the polar representation. We have the norm of the voltages and the angle of the voltages, and we can rewrite things in terms of those quantities. And then basically we go through some exercise of linearizing these things.
00:25:02.052 - 00:26:09.348, Speaker B: We define variables for the cosines and signs and for the products of the norms. And then we assume that we have that we stay with relatively small signs of the angles, and the voltages behave in a way that is usually the case in practice. Then what we can do is we can write this whole thing as a large convex quadratic problem with these linearized versions of the quantities. This is something that works very, very well, in particular because there's very effective ways of linearizing these cosines and sines, under the assumption that we're working in a relatively small range for the values of these variables. So it's a really nice idea that goes quite a long way in terms of attacking opf using quadratic convex. No semi definite part in this problem. Getting back to a semi definite approach, this is work that was done with Christian Bingeni and Sebastian le D.
00:26:09.348 - 00:26:53.400, Speaker B: We looked at what we call the tight and cheap relaxation for Ac optimal power flow. Again, we go back to the matrix v. The first thing we do is rewrite the rank one matrix as an extended matrix with an extra row and column being positive semi definite. This is also a well known fact from semi definite optimization. And now what we do is we do something like the second order cone relaxation. We look at two by two principal submatrix of the matrix V, but we add the corresponding bit from this extra row and column. And so we end up with these three by three positive semi definite blocks that are the relaxation of the Acopf problem.
00:26:53.400 - 00:27:42.924, Speaker B: And we have one of these per line in the network. Okay. And then for the, we can also do a small application of RLT to the reference node. If we take the constraints of the reference node with the angle fixed to one, we can come up with some tightening constraints that are very simple but do make a difference in the optimization. Then when we put all this together, we get what's called the tight and sheep relaxation. And then we can observe that if the diagonal entries are exactly the squares of the norms, then we have global optimality, so we don't have to check rank of a matrix. It suffices to check that we have this condition holding.
00:27:42.924 - 00:28:21.600, Speaker B: This is not true for QCR. Even if we have this constraint, you may not be exact. So it's something that's a little bit different between the two, and it's also not true for the SoC relaxation. Computationally, it's hard to compare TCR and QCR. Sometimes one's better, sometimes the other's better. But certainly if the angle difference bounds are tight. So if we are working in a small range for the angles of the voltages, then QCR does a really good job.
00:28:21.600 - 00:29:09.482, Speaker B: It's really well tailored for that purpose, and that's a good point to to know as well. And then we can talk more generally about, okay, I have some power system. I'm doing a semi definite relaxation, and I want to improve this without doing these small blocks or without doing special assumptions on the voltage angles and so on. What can I do? Well, one thing that is a general tool is what are called chordal relaxations. And the motivation here is to say, well, I start with some network. Let's imagine that this five cycle is my power network. What the semi definite approach does, the full semi definite approach is add basically all the lines in the system, all the edges, and so it works with the complete extension.
00:29:09.482 - 00:30:11.994, Speaker B: What we can think about doing is doing what's called a quartile extension, which is only adding a limited number of edges, but in such a way that this graph is quartile, which means that there is no cycle of four or more edges without a chord being present as well. That's the technical definition of chordality. Why do we care? Well, because chordality is a useful technique for exploiting sparsity and semi definite optimization. The idea is to replace the large positive semi definite constraint by again a bunch of smaller blocks being positive semi definite. But to make sure that this is valid and this is actually equivalent and not a relaxation, we need to define these blocks carefully in terms of the chordal structure of the chordal extension. And we have to have these constraints linking the entries common to two or more of these matrices. These matrices excited the blocks.
00:30:11.994 - 00:30:56.300, Speaker B: This is an idea that dates back to some work of yabra in 2012. The basic idea is the following. Let's take this matrix here in the middle in black as the sparsity matrix for my voltage matrix. I just wrote it as a general matrix for an interior point. For a semi definite problem, I take every nonzero element here except those in the diagonal, and I build a graph that represents an edge. If there is a non zero between in the entry index by the row and column of the two nodes, and this matrix is symmetric. So the graph is undirected.
00:30:56.300 - 00:32:19.684, Speaker B: In general, what I then do is I want to add edges to this graph to make it quartile. And when I'm doing that, I am essentially adding non zeros to the matrix. If you think of it that way, what I want to do is add them in such a way that I have a nice structure resulting something like this, where this is now linked to the sparsity pattern, now gives me a chordal graph, and I only have four much smaller blocks that need to be positive semi definite. And if these four are because the corresponding structural graph for this matrix is quartile, the whole matrix will be positive semi definite as well, without having to know what these other menstrual entries that are written as zeros for the moment have to be. So the steps to follow is to take the aggregate sparsity pattern, look at a quarterly extension, find all these maximal cliques, and then we can build what's called a clique tree to define the linking constraints. Because if you look, for example, here we have a three by three sort, we have a three by three matrix here and another three by three where they share the same entry. And so we have to make sure that we link these two blocks so that the value is indeed the same when we solve these are what are called the linking constraints.
00:32:19.684 - 00:33:30.724, Speaker B: Now, the challenge here is that this quarterly extension is not unique and it always exists. But different quarterly extensions lead to different reformulations of the semi definite problem. And the solution time of the resulting approach to solve the semi definite problem depends strongly on the choice of extension. So there's been a lot of work done on quarterly extensions, but mostly from the point of view of numerical linear algebra. But very little has been done saying, if we're talking about solving block semi definite problems, which quarterly extension do we want to choose? One idea that's been looked at is clique merging. The idea is to start with the initial graph and have some clicks, add some, and then if we have a lot of small cliques, like here, we have these two cliques, we can add this edge between these two nodes and we get a slightly bigger clique. But we've gotten rid of linking constraints between the two clicks because they are connected in the graph.
00:33:30.724 - 00:34:18.084, Speaker B: The basic idea here is that if we have too many linking constraints, it's not good for the semi definite problem. If the blocks are too big, it's also not good for the semi definite problem. So if we have very small blocks, we can reduce the linking constraints by merging them. But we want to make sure that we don't merge them in a way that gives very large blocks. And this idea of clique merging for AcoPF was first looked at by Molson and co authors in 2013. What they did is they choose this merging by looking at an estimate of the computational cost of solving a block semidefinite problem. And they basically say, we use this as an indicator to decide if it's a good idea to merge two cliques or not.
00:34:18.084 - 00:35:21.526, Speaker B: What we did is look at a different estimate that says let's look at the cost of a single interior point iteration for that problem. So we have a different function in terms of the parameters that are the size of the cliques and the number of linear constraints in the original problem, and the number of linking constraints that we're adding. Number of linear constraints that we're adding from doing this transformation. And what happens is that in some sense, the looking at a single iteration is a better estimate for the cost. But it happens that it also results in having very large cliques coming out if we just use this estimate. So what we do as an improved clique merging is flip between the two, where we first use our estimate to merge cliques in the first few iterations, and then we switch to the other estimate as a means to decide which cliques to merge. And that seems to result in a better approach overall.
00:35:21.526 - 00:36:02.224, Speaker B: So what we can do now is, given any acopf problem, we can write down the semi definite relaxation, the basic approach. We take the sparsity pattern coming from the power system network. We find a quarterly extension, and then we can apply this clique merging algorithm to reduce the number of cliques while not increasing the number of leaking constraints too much. This seems to be particularly helpful in the Acopf case. Now let's get on to reactive power flow. All of this hasn't really talked about managing reactive power flow. It's only about solving the acopf as a basic problem.
00:36:02.224 - 00:36:39.188, Speaker B: We're now going to add discrete variables to the game. What I'm going to talk about is the two recent developments in this direction that I was involved in. One is the work of Bengane et al. And the other one is the work of Slivak et al. Where we do the full branch and bound approach. So let's get back to these power balance equations. What happens when I introduce these shunts that I've mentioned before is that essentially I add binary variables to this term.
00:36:39.188 - 00:37:07.616, Speaker B: And these are variables that are zero one. So I have at the bus k, a device called the shunt. And if I turn it off, then this term vanishes from the equation. If I turn it on, then this term is present in the equation and that changes the behavior of the system. The other device that I look at are what are called tap changes, or transformers. And these are the parameters t that I had before in blue. They now become variable.
00:37:07.616 - 00:37:58.670, Speaker B: So now we have ratios of voltage and tap settings, tap ratios as they're called. And these tap ratios are integers from some set of integer values that depend on the characteristics of your transformer. So now we have not just quadratic terms in v, but we have ratios of v over t to deal with. And here we have not only squares of voltages, but we have products of u times the squares of voltages as well. We have cubic terms to deal with. One idea is to do the semi definite relaxation that basically says, do the v as before, define a new variable for the ratio of v over t. And then define a three by three matrix, a bit like what we did before, for the variables coming from these ratios.
00:37:58.670 - 00:38:39.414, Speaker B: And linearize the u times the v matrix term for the cubic terms. This is a quadratic term. Now, because I've linearized the square of the v's. This is pretty standard as an approach to linearize these things. Then the only thing we need to be careful is make sure we have appropriate bounds on these new variables, the W's and the xis. Starting from the bounds that we have on the voltages, we can derive bounds on the elements of the matrix W, which automatically bound the ratio v over t. For our problem, we can put all this in and we can run this as a semi definite relaxation.
00:38:39.414 - 00:39:14.434, Speaker B: We can do a tight and cheap version where instead of doing the whole big matrix, we do three by three blocks. So the same idea, but it makes the solving a lot more efficient. That's basically all there is. And then this is the RLT as we did before. There's nothing new compared to what I've already mentioned. And then we have a second approach to do this, which is to say, instead of looking just at v over t, we can look at matrix VKK diagonal term over t squared. And v kk over t.
00:39:14.434 - 00:40:15.954, Speaker B: And you can rewrite things in terms of these quantities, but now you have to find the convex hull of a much complicated expression. And one of the really interesting results is that we can define this set in three reals that we're interested in looking at, which is a non polyhedral set, and we can express exactly the convex hull for this set. And so this gives a very nice way to linearize this approach that does become more complicated, but tends to work better. And then we have a tight and cheap equivalent, and we can just solve the relaxation and do a basic rounding on these integer variables. And once we fixed the integer variables, we can just take the solution to the SDP relaxation plus the fixed integer variables. We have a non linear optimization problem. We just run a nonlinear solver and we get a solution.
00:40:15.954 - 00:41:04.404, Speaker B: So we don't get a guarantee of global optimality, but we get something that usually gets us pretty close to a very good solution, and oftentimes to the optimal solution. And this tight and cheap approach works very well. So the basic idea is really, how do you linearize the terms in the reactive optimal power flow in a way that you can have a tight relaxation and get better results. That's what this is about. The last topic that I want to mention is this idea of practical constraints for reactive optimal power flow. So we can put limits on how many of these shunts we can use, that can be on. We can say if we already had some initial status for the shunts, there's only so many that can change.
00:41:04.404 - 00:41:55.184, Speaker B: And then we can also do what's called simulating primary frequency control, which basically means that we may need to adjust the level of generation to facilitate the operation of the network. And this gives us a way to decide whether we should move everyone that's generating a little bit up or a little bit down in such a way to support the operation. And this can be done using the decisions in reactive power as well. I'll skip this bit because I'm running a little bit out of time. But essentially we do use again the hermitian matrix on, on this problem to linearize, we have bounds on the US and the V's. We do a McCormick approach. This is all fairly standard things.
00:41:55.184 - 00:42:38.162, Speaker B: The really nice thing is we can now plug this into a branch and bound. We have a non convex optimization problem with discrete variables thrown on top. If we only work with shunts, which are binary variables, that simplifies things. We can do a zero, one branch and bound algorithm. For this we solved at each node the semi definite relaxation. Using Mosec, we applied the clique decomposition that I've mentioned to speed up the solution of the relaxations. We then do something in terms of generating a good feasible solution by using nitro.
00:42:38.162 - 00:43:13.272, Speaker B: Specifically after solving the semi definite relaxation. So we solve the semi definite relaxation, we get a solution which is fractional, and then we use nitro to clean up that solution. Using the nitro MPEG option allows us to push the binary variables to zero or one and to get a full solution to the problem. And then we still have the bound from the semi definite relaxation. So this is the root node. Then we start branching, but we don't do spatial branch and bound, at least not yet. So we don't guarantee global optimality.
00:43:13.272 - 00:43:56.632, Speaker B: In other words, even if I fix all the binary variables to all the combinations, I may not be able to find the optimal solution because of the non convexity in the nonlinear part. Nevertheless, it works pretty well. We do a depth first search. We branch very simply on the variable closest to one. So we try to fix the variables as quickly as possible, and then we have a time limit of an hour, and we also fix variables when they get very close to zero or very close to one. The best strategy for this depends on the type of constraint that I have added to the problem, because that helps bias things in particular ways. But the really nice thing, as I mentioned, is that we are able to get to very large problems.
00:43:56.632 - 00:44:46.662, Speaker B: If I look, for example, at just maximizing the number of shunts, I can look at a problem here with 13,000 bus, more than 13,000 buses, and I can get a solution that is within 1.3% of global optimality in a fairly reasonable time using the branch and bound nodes. After an hour I get a very, very good solution. If I move to one of the other constraints, then I also get very good results with running these large problems for up to an hour. And for the smaller problems, even a case here, for example, with more than 3000 buses in 830 seconds, I have a solution that's less than 0.1% of the optimum. So this gives very, very nice results.
00:44:46.662 - 00:46:03.314, Speaker B: Certainly in practice, these are excellent from the practitioner point of view. And then for the part that I want to do the primary frequency control, this is very difficult even just to find optimal solutions. And often the rounding, the traditional rounding fails for more than half the cases, whereas with the branch and bound approach, even if we can't solve the problem, we are able to find feasible solutions. So these problems are getting so hard that just finding a feasible solution is a challenge, and this is where the variant bound approach becomes really interesting. In summary, semi definite optimization can find definitely global optimal solutions for what are now becoming realistic acopf and reactive opf instances. Because we're starting to look at thousands of nodes, the computational times are still high, and that remains the challenge, one of the challenges. So in terms of research directions, certainly I think this whole question of quarterly extensions for this particular purpose still needs work.
00:46:03.314 - 00:47:11.404, Speaker B: There's the idea of using improved polynomial optimization techniques and the laser hierarchy, which we didn't coordinate, but I suspect that this may connect to Bisan's presentation afterwards. Mixed integer semi definite optimization is something that can definitely benefit from extra work, particularly for the reactive optimal power flow. There's the whole question of uncertainty that I haven't mentioned at all in this presentation. But if we look at power systems in real life nowadays, uncertainty is part of life, and that has gonna have to be factored in, in all of these problems, sooner rather than later. And if you want very challenging problems, look at what the RPE competition is bringing in, because these are really, really difficult problems that move you in the direction of what's necessary in the real world. That completes the presentation. Thank you for your attention, and you're welcome to contact me by email or to look up information on my website as indicated.
00:47:11.404 - 00:47:12.644, Speaker B: Thank you.
00:47:21.084 - 00:47:37.784, Speaker A: I'm muted. Thank you very much, Miguel, for a very interesting talk. And well, I'm gonna let anybody have any questions. I'll let some other people go, I have a couple myself.
00:47:40.324 - 00:47:48.294, Speaker B: Okay. Hello wala. How are you, Miguel? Good, good, thanks.
00:47:51.514 - 00:47:55.114, Speaker A: So, so, very nice talk.
00:47:55.154 - 00:47:55.906, Speaker B: Thank you.
00:47:56.050 - 00:47:57.882, Speaker A: You have something, wala, go ahead.
00:47:57.938 - 00:48:05.214, Speaker B: No, I don't have questions. I did. I waived by mistake. No, no, I think we were just saying hi.
00:48:08.994 - 00:48:25.544, Speaker A: Yeah, so I had a couple of questions. So it's sort of interesting that in the news, the last, I guess, especially the last week, I've been hearing a lot about the energy crunch that's coming. I don't know if you've been hearing both this in Scotland as well.
00:48:26.364 - 00:49:11.818, Speaker B: Oh, it's all over the news here. Yeah, we have energy suppliers that are going bankrupt. But what's basically happening is that, in a nutshell, the price of gas, natural gas has been going up a lot. And in the UK, we still have always somewhere between 30% to 50% of power generation using natural gas. So the price of electricity consequentially also goes up in the market. And there's a cap on how much companies can charge the customers. So when the cost of electricity is higher than the cap, bankruptcy follows.
00:49:11.818 - 00:49:22.930, Speaker B: And that's essentially what's happening at the moment. But the fundamental problem is the price of gas is going up and there is no way to pass on the cost to the customers.
00:49:22.962 - 00:49:28.854, Speaker A: This is what I heard is happening in China as well, and they're getting big power cuts on the cost.
00:49:32.914 - 00:50:03.394, Speaker B: Then we get into issues of security, of supply and storage of gas, and a whole bunch of other related topics. But none of that has to do with operating the power system per se. It is purely a case of the prices are going up and unless theres a way to pass on the costs to somebody, even if its the government that has to pay a big bill to cover this, somebodys got to pay. Otherwise the economics dont make sense.
00:50:05.154 - 00:50:29.794, Speaker A: In terms of a question about your talk. More detail about your talk. So you're using branch and bound a lot. Have you ever thought of maybe using splitting methods to try to try to get more of the integer values while you're solving the SDP like Douglas Ratchford or Admiral?
00:50:30.844 - 00:51:12.332, Speaker B: Well I mean the short answer is yes, we can think about it, but we haven't got to that point yet. It certainly would make sense. I mean at the moment, if you look at the literature on these reactive power flow problems, it really boils down to find a solution and round it by whatever means you can find. These are really tough problems and there's a lot of things that can still be tried. Just getting this very simple setup with only shunts, so only binary variables, no spatial branch and bound. Just find me a feasible solution, even if not in some of the harder cases. Even this is challenging.
00:51:12.332 - 00:52:11.282, Speaker B: This was already quite a lot of work for Julie Slivak to get this to work. So yeah, if anyone here in the call is interested, there's lots to do. There's lots and lots to do. And this is really relevant, you may have noticed from the initial slide, which I mentioned briefly at the beginning, and I can just pull it up very quickly if you look at the initial slide, this work, I didn't write it explicitly, but it was Julie was supported by Hertieux, which are the power system operators in France, and Manuel Huiz works for as well. So these people are really interested in solving these problems. And the same thing is true in Quebec and in the US and in other places. This stuff really matters, and that's what the ARPa e challenge is all about as well.
00:52:11.282 - 00:52:23.464, Speaker B: So lots of very challenging problems, very easily found. If you look in this direction and then it opens the gate to all of these techniques that we know.
00:52:24.004 - 00:52:54.934, Speaker A: So, I think my question woke Jonathan up. I think I'll just add a quick question that will wake Jonathan up. When you said you have a gap, to get a gap, you need an upper bound. You were talking about the upper bound. Then you also need an accurate lower bound for a gap. Yes, I've seen a recent paper by Jonathan on this. Are you getting a very accurate, reliable, theoretically proven lower boundaries to get the gap, or are you just using numbers that come out of the solver?
00:52:55.394 - 00:53:33.298, Speaker B: This is gaps in the sense of computational gaps. So, we solve the semi definite relaxation at the root, which is a global bound, on the problem, and then we look for a feasible solution by, in some way, rounding the solution. The only. And that's it. That's what I mean by a gap. So it's not a theoretical gap, it's a purely computational gap between the global bound and a feasible solution. The only slightly, I would say, perhaps, interesting thing in what we've done in the branch and bound is that at the root node, we use this feature of nitro for solving mpegs.
00:53:33.298 - 00:54:29.824, Speaker B: We run the SDP, we get a completely fractional solution, and then we take the binary variables, and we write them as x squared equals x, which is x times x minus one equal to zero, which is a complementarity constraint. We give this to nitro as a complementarity constraint. Nitro for mpegs. So, for problems with complementarity constraints, has a specialized technique to give you a solution that is complementary. And so we get a solution from nitro based on the initial starting point. From the SDP, which is completely fractional, we get a solution that is local, but with the binaries fixed to zero or one, according to the MPEG approach. And so that gives us a feasible solution right at the root node, which, first of all, sometimes it's hard to find one if you try to just round.
00:54:29.824 - 00:54:49.714, Speaker B: So, here you're guaranteed that it's feasible. And so we get that computational gap right at the start. So, that, I think, is the really slight twist that's interesting in how this is done after that is a heck of a lot of work just to make it run and make it happen.
00:54:51.894 - 00:55:34.034, Speaker C: Yeah. So, just to respond a little to Henry, when you have integer variables in ADMM, Douglas, Ratchford, etcetera, it can get a little messy. There's been a lot of work done for stochastic problems. So this thing called progressive hedging, which is actually just ADMM in a certain, certain space. Okay. And you know, so like John Paul Watson and Dave Woodruff have, have played with this a lot as a way to avoid, you know, doing branch and bound on the extensive form of some jacket giant stochastic program. But it can cycle.
00:55:34.934 - 00:55:37.534, Speaker B: Ah, that I didn't know. That's interesting.
00:55:37.614 - 00:56:09.842, Speaker C: It can cycle. It's, it's, it's pretty much heuristic. Now there was some nice work. I mean there is a technique, there's a paper with many, many authors. The first one is Jim Lutke. Okay. Where they show if you do this certain, you do decomposition, you solve a bunch of individual integer programs and then you do a certain operation at the end to kind of convexify it.
00:56:09.842 - 00:56:20.414, Speaker C: You are solving a certain lagrangian relaxation which is, you know, tighter than the plain old lp relaxation. So I don't know if all this stuff would transfer over.
00:56:22.274 - 00:56:37.448, Speaker B: Yeah, that's a good question. That's. I don't know either. That's. I mean, I haven't really looked at it in any, in any detail. It was interesting just to be able at this point to get feasible solutions for these very large problems.
00:56:37.576 - 00:56:41.664, Speaker C: But. Yeah, maybe when I visit there's all sorts of things we could talk about. Yeah.

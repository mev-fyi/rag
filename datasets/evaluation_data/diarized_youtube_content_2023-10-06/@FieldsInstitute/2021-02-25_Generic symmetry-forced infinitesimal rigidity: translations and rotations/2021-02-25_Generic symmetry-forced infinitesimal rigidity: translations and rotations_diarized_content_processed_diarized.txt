00:00:00.200 - 00:00:41.294, Speaker A: I'm going to talk about symmetry, force rigidity. So I know this is review probably for most people here, but just in case it isn't, we'll go through the very basics of rigidity theory. So the classical setup is you have a bar and joint framework, which is really just building a graph in d dimensions. So more precisely, you have a graph and then a function that just sends the vertices into RD. And such frameworks can be rigid or flexible where you're treating your edges as incompressible rigid bars that are free to move around the vertex that they're attached to. So here are three examples in the plane, all on the same graph. These two are flexible, so that's easy to see with a square, right, you can sort of shear it.
00:00:41.294 - 00:01:31.764, Speaker A: But if I were to do something obnoxious and say, put two of the vertices at the same point, then it becomes rigid. I'm going to be talking about generic rigidity. So I'm going to assume that you don't do anything obnoxious like that. And if that's the case, then, you know, as long as I'm, as long as I choose this p function sufficiently generically, then whether or not the graph becomes rigid in d dimensional space really only depends on the graph. All right? And I guess, you know, I'm talking about local rigidity here. So here's an example. If I take, you know, this four cycle with a chord and stick it in two dimensions, then as long as I'm not doing anything to, you know, trying to break things, as long as I don't, like, put for example, these two vertices on top of each other, this is always going to be rigid.
00:01:31.764 - 00:02:26.750, Speaker A: All right? So yeah, classical rigidity theory, the most basic question is which graphs are minimally, generically rigid in RD in r one, this is an easy characterization. Minimally generically rigid graphs are trees. And of course there's this well known theorem of Bolczyk Geirringer Leman's theorem in two dimensions, which just gives this necessary and sufficient condition for a graph to be minimally, generically rigid in r two. So where I'm going with this talk is I want to take this story and talk about it for frameworks that are forced to have some kind of symmetry. Um, and I'll go through a history of this after this. Um, you know, this has been, um, you know, I guess considered going back like 2010, I think. Um, but anyway, the setup is as follows.
00:02:26.750 - 00:03:09.534, Speaker A: Um, in symmetry, force rigidity, uh, you only care about flexes of the framework that preserve symmetry. So here, for example, is a framework in two dimensions. It has symmetry with respect to the wallpaper group that has translations in two dimensions. And it also has a fourfold rotation, and it's symmetry force flexible, I claim. And what that means is that there is a way to deform this framework so that the symmetry is preserved at every point in that deformation. I have a video here showing this. There we go.
00:03:09.534 - 00:04:13.746, Speaker A: So, yeah, notice the, here's a flex of the framework, and at every point in this little animation, the framework still has the same symmetry. Okay? And so the goal here now is to characterize generic symmetry, force rigidity, and RD. And I'll define what I mean by this. But before I can do that, I need a compact way to talk about frameworks that have symmetry and graphs that have symmetry. And it's been noticed by a handful of different authors that maybe the most compact way to do this is with something from, I think, topological graph theories, where it originated on something called a gain graph. And what a gain graph is, is it's just a directed multigraph whose arcs are labeled by the elements of some group. And now here's what I mean.
00:04:13.746 - 00:04:55.678, Speaker A: Here's the formal definition of what it means for a graph to have symmetry with respect to some group. So either you know the definition and this is, you just know it, and there's, there's no point in reading it, or you don't. And this is going to be confusing. So let's just look at an example. This graph in the lower left, it has symmetry with respect to, for example, the cyclic group of order four. And that just reflects the fact that if you were to rotate this graph 90 degrees counterclockwise, it would look the same. Now, because of this, I can actually, knowing this, I can represent this a little bit more compactly with a gain graph.
00:04:55.678 - 00:05:59.364, Speaker A: So, um, you know, which is again, just a directed multigraph whose arcs are labeled by elements of some group. In this case, the group is going to be the symmetry group of this graph here. And, you know, the way to go between a gain graph and a symmetric graph is, is not particularly difficult, but it's, it's messy. So I'll just, you know, hopefully get everyone to understand this example. But the way it works is that your vertices of the gain graph are going to be in bijection with the vertex orbits of the symmetric graph, right? So since you have the cyclic group of order four acting on this graph, every vertex is in some orbit. Those orbits are represented by single vertices in the gain graph. And the edges, or, sorry, the arcs of the gain graph correspond to edge orbits in the symmetric graph.
00:05:59.364 - 00:06:42.054, Speaker A: So now in this and in order to. So, okay, I guess it's clear, I guess hopefully how the vertices of this correspond to vertex orbits of this. So the black vertex orbit here is the black vertex here. The white vertex orbit is the. Sorry, yeah, the white vertex orbit is the white vertex here. And to get the arcs on this, what I'm going to do is I first need to pick some representative of each orbit in the symmetric graph. So here I'm picking this upper right vertex as a representative from the black vertex orbit and this lower left vertex as a representative from the white orbit.
00:06:42.054 - 00:07:35.024, Speaker A: And once I do that, note that if I were to, say, apply the group element that is a 180 degree rotation to this white vertex, it would lie at this, which is then adjacent to the representative of the black vertex. And in my gain graph, this is reflected by having this arc labeled by a squared, in other words, the group element that takes this white by the representative of the white orbit to something adjacent to the representative of the black orbit. And, okay, I can also have edges that connect vertices within a single orbit. And that's why we have self loops here. So are there any questions about. Yeah, I should say at any point, please feel free to unmute yourself and just interrupt. Or you can write in the chat if you're more comfortable.
00:07:35.024 - 00:08:53.134, Speaker A: I will try to pay attention to the chat. Okay, so given the setup, you can ask the question for each dimension d and each subgroup s of euclidean isometries of RD characterize the s gain graphs that are minimally, generically rigid. And so by generic I basically mean like, if you are to fix the position of something in each vertex orbit. Well, when you apply symmetry, that gives you positions for everything in the framework. So you can really ask like, even though there is symmetry here, you can actually ask about like generic rigidity. And so this has been a problem that has been thought about going back to, you know, at least 2010. As far as I know, the first sort of papers looking at this in a sort of rigorous way were one paper of Schultze and Whiteley talking about the case of finite groups, and then another paper of Borcha and Stranu in 2010 focusing more on the case of having lattice symmetries.
00:08:53.134 - 00:09:46.454, Speaker A: And since then there was this sort of flurry of activity trying to solve this problem in as many specific instances as possible. Yes. So independently, Malstine and Thran in 2013 and Ross in 2015 were able to characterize rigidity for two dimensional lattices. So mousine and the Ran's result has a little bit more flexibility. They allow the representation of the lattice to vary. Ross in 2015 solved the generic symmetry force ridiculous problem for three dimensional body bar frameworks. The case of all rotation groups and odd dihedral groups was done again independently by mousing and Thuran and Jordan, Kezanitski and Tanigawa.
00:09:46.454 - 00:10:48.534, Speaker A: And then also paper 2015 of mousing and the Ran characterizes generic symmetry force rigidity in the case for wallpaper groups with flexible lattices. So I'm going to talk about a recent result of mine from that basically generalizes a handful of things in here. And what sort of excites me the most about it, more than anything, is the proof technique, which uses tropical geometry. So yeah, I'm going to tell you what that result is. I need to introduce a few definitions before I can do that. So, within a gain graph, some of the more important for various applications, combinatorial data that you get from it is in what's known as balanced cycles. So here are the sort of relevant definitions.
00:10:48.534 - 00:11:43.888, Speaker A: If you have a walk in a gain graph, the gain of that walk is just the product of the labels in it, inverting whenever you traverse an arc backwards. So for example, if I were to go around this four cycle along the outside, maybe starting from here, but not closing it up clockwise, the resulting gain of that walk would be a times a inverse times r. So the gain of that walk would be r. I'll say that a cycle is balanced if the gain of any walk around that cycle is the identity. So for instance, if I were to close that walk up and go all the way around that cycle, the gain would be a a inverse r r inverse, which is the identity. So that cycle is balanced. Sort of implicit in that definition.
00:11:43.888 - 00:12:28.974, Speaker A: There is the claim that it doesn't matter which vertex I start at. So we can see that in this example. Say if I start here and go around, I'll get a inverse r inverse a, which is also the identity. So this is a sensible definition, I claim. Yeah, and just to see sort of a non balanced cycle, right. If I were to take this three cycle here, and if I were to go around starting at this vertex in the clockwise direction, I would get ar inverse r, which is not the identity. If I were to start here and go around, I would get r r inverse a, which is different, which is a, which is a different group element, but it's also not the identity.
00:12:28.974 - 00:13:13.274, Speaker A: Okay, so that's what it means for a cycle. To be balanced. And then two other definitions I need are as follows. So a bicyclic graph is a subdivision of one of these three graphs, and a bicyclic game graph is dutch if each pair of closed walks based at the same vertex have gains that commute. And just the reason why I picked the term Dutch is because some authors call bicyclic graphs bicycles, but it's spelled bicycle. And in the US at least, bicycles that are designed specifically for commuting are often called Dutch. So a bicycle that commutes is Dutch.
00:13:13.274 - 00:14:02.646, Speaker A: And then the other definition I need is that of a complete gain graph. So given a group s, the complete gain graph case of n of s, it just has vertex at one through n, and it's gonna have an arc between every pair of vertices for each element of the group, and it's gonna have a loop at every vertex for each non identity element. So here's maybe the simplest interesting example. This is k two of z two. It has two vertices and a arc between them for each element of z two, and it's going to have a loop at each vertex for the one non identity element of z two. So with all that in mind, here's the theorem. Let s be a subgroup of the semi direct product of r two and sr two.
00:14:02.646 - 00:15:32.910, Speaker A: So these are just euclidean isometries that are orientation preserving. So in other words, I just don't allow reflections in my group. Then for each s gain graph h, I'm going to define alpha of h to be three if every cycle in h is balanced, two if not, and the gain of each cycle is a translation, one if none of the above and all bicyclic subgraphs are dutch and zero otherwise, then g is minimally, generically, infinitesimally rigid in two reals if and only if the number of edges is twice the number of vertices minus alpha of the complete gain graph on that vertex set, and for all subgraphs g prime of g, I get this inequality. So this looks a lot like Le mans theorem, or like a Maxwell kind of count, except instead of, you know, 2 volts minus three, I have two v minus some function that depends on the game labels. So since open problems was specified in the title of this workshop, I should mention, I guess, two things to do next from this. So based on Walter's talk yesterday, I think it might actually be pretty easy to turn into a result about rigidity on any orientable surface. I need to think about this a little more and maybe talk to someone who knows the relevant like classical topology stuff.
00:15:32.910 - 00:16:48.392, Speaker A: But, yeah, if you're at Walter's talk yesterday, among other things, he said that if you have a metric that is projectively equivalent to the Euclidean metric, then basically, rigidity theory on the infinitesimal level is invariant. And so, you know, if you were to take this result and say, you know, for the group consisting of an Eightfold rotation, and then, you know, a two dimensional lattice, okay, so euclidean plane, this group is a mess. It doesn't really have a, you know, it can have infinitesimally small translation vectors. But if you take that same group in the hyperbolic plane, then I guess it looks better. But in particular, you can take an octagon in it and sort of identify opposite edges. And that gives you, if you fold it up like that, the two torus. So assuming things sort of work well, maybe you can use this to get, this just gives you whatever Lamont's theorem should be on a torus with two holes in the intrinsic metric.
00:16:48.392 - 00:17:33.724, Speaker A: I don't know if this is of interest to anybody, but it seems like sort of an easy consequence, assuming things that I think should work out, will work out. But anyway, and then the other thing to do with this next is to extend the proof technique to accommodate reflections. Um, so I'm gonna, I'm gonna talk about the proof of this and in the rest of the talk, and I'll show you precisely where the proof breaks down for, um, you know, if you allow orientation reversing group elements, and, you know, if you try to allow reflections, it makes things harder, but not completely hopeless. At least it seems right now. Yeah. So I'll. Yeah.
00:17:33.724 - 00:18:17.444, Speaker A: But, yeah. Are there any questions about, about the theorem or anything before I go on to talking about its proof? All right, I'm gonna skip the example. I don't actually think that's that enlightening. Here's, here's the broad outline of a proof. So I like to think about rigidity in terms of matriids. And so, asymmetry, forced rigid graphs are the spanning sets in the algebraic matriid of something I call the asymmetric heli manger variety. I'll define this later, but it's sort of this, you know, symmetry force analog of the Caylee Manger variety, which I will also define later.
00:18:17.444 - 00:19:06.774, Speaker A: But anyway, when s doesn't contain reflections, then this variety is a Hadamard product of affine spaces. Again, I'll define what a Hadamard product is later, but it's a nice way to sort of take two varieties and stick them together in some way. And then each affine space, it defines two matriids, one of which is an elementary lift of each other. And given this, I can describe the algebraic matriarch of a Hadamard product of affine spaces in terms of these two matriids for each. And the proof of this uses tropical geometry. And then once I have this formula for just, you know, the algorithm of an arbitrary product of affine spaces, I can just apply it into the setting and that theorem just falls out. Yeah.
00:19:06.774 - 00:20:08.374, Speaker A: So let's start defining some terms here. So I'm going to use this notation c to the e to denote the complex vector space whose coordinates are indexed by the elements in some set e. So e is a set, in this case, every subset of e, it defines a coordinate projection onto those coordinates. Now, given an irreducible variety, a given subset of coordinates is going to be independent if the dimension of the projection onto those coordinates of the variety v has dimension equal to the cardinality of square. So in other words, your independent sets now correspond to projections that give you something full dimensional when you restrict it just to the variety. A set of coordinates is going to be spanning if the dimension of the projection is equal to the dimension of the original variety. And this set will be called a basis if it's both independent and spanning.
00:20:08.374 - 00:20:55.064, Speaker A: And then the common and combinatorial destructure described by any one of these three set systems is what's called the algebraic matrix of v. Now here's an example. If e is, say, the entries of a three by three matrix and v is the variety of three by three matrices of rank one, then if I let s be this set of coordinates, I claim that s is spanning but not independent. So to see that it's not independent, well, okay, this is a set of coordinates I'm projecting onto. It's not independent because this two by two minor has to be zero. And in particular, the projection has to satisfy an equation. So it's not going to be full dimensional in this image space.
00:20:55.064 - 00:22:36.534, Speaker A: And then to see that it's spanning, well, I claim that the variety of three by three matrices of rank, at most one, has dimension five. But as you can see, there are six coordinates here and one equation. So this image under the projection also has dimension five, right? So this projection, its dimension is the same as the dimension of the original variety. So, any questions? All right, so this is maybe review to the people in the audience who like thinking about rigidity theory in terms of algebraic geometry. And for the rest of the audience, so given a pair of integers Dnn, the Cayley mengar variety of n points in Rd, denoted like this is the affine variety embedded in c to the intrus two as the Zyrisci closure of the set of possible pairwise euclidean distances between endpoints and rd. So just for concrete example, right, this is just so for d equals two, say, right, if you pick endpoints in two reals, and then you look at all of the pairwise distances among them, then this gives you one point in the Caylee manga variety. And then, now if you sort of do this for every set of endpoints in R s two, this sweeps out some set in r to the n, choose two, and then you can just take, it's a risky closure, and c to the n choose two, and this gives you some variety, which is called the Caylee Manger variety.
00:22:36.534 - 00:23:29.640, Speaker A: And now, given this, a graph I claim is generically minimally rigid, or, sorry, generically rigid in our d, if and only if e is spanning in the Caylee Manger variety. And sort of just, you know, the way to see this is to note that a spanning set. So a set s is spanning if the corresponding coordinate projection preserves dimension. But that also means that your fibers of this projection, you know, the inverse image of a single point, is zero dimensional. In other words, just a finite set of points. Now, a flex of your graph corresponds to, you know, within a single point in this projection. A bunch of stuff, sort of like in the fiber in the unprojected space that contains a curve.
00:23:29.640 - 00:24:04.604, Speaker A: And that curve upstairs is the flex. So if your projection is zero dimensional, sorry, if your fibers are zero dimensional, there's no curves in there. So, yeah, that's if you haven't seen this before. That's why this is true. Vaguely. So, I'm also going to, just to talk about the proof of this result here, I'm going to need to be able to talk about matriids in general. So here's the definition of a matriid.
00:24:04.604 - 00:25:09.024, Speaker A: It's just a pair consisting of this set e, often called the ground set, and then a subset of sets that are independent. And then there are three combinatorial axioms they can satisfy. Either you've seen this and this is review and unhelpful, or you haven't seen this and it's. At least a third axiom is maybe going to be too much to digest in 30 seconds. So a matriid, it just consists of a ground set and then a collection of sets that you just say are independent and they satisfy some axioms and, you know, examples include the algebraic matrioid of an irreducible variety. Um, given a matriid, the rank function is just the function from the set of subsets of your ground set to the positive integers or non negative integers that maps a set to the cardinality of the largest independent subset of it. And a spanning set of a matriid is just a set of maximum rank, and a basis is a spanning independent set.
00:25:09.024 - 00:26:15.244, Speaker A: So this is just sort of a commentarial abstraction of this definition of algebraic matriarch. I had two slides ago, and the reason that I introduced this in general is to tell you about a construction of edmunds that I'm going to use. Or it might actually be edmunds and rota. But anyway, if I have a function, a set function that is increasing n submodular, in other words, satisfies these two axioms, then I will define this matrix m to be the matriid on ground set e, where I is independent if and only if for all subsets. Either that subset is empty or its cardinality is bounded above by this function f. So sort of the important thing to get from here is, you know, you give me a set function satisfying two axioms, whatever they are. You know, I claim that that defines matriid in this way, where your independent sets are the sets whose cardinality is bounded above x value on them.
00:26:15.244 - 00:27:13.106, Speaker A: So I'll give you a rigidity theoretic reason to care about this in a minute. But if you like matriids, then it turns out that the matriid union of, you know, a set of matriids is an example of this. If you just take the sum of the rank functions of d different matriids, and then do this construction on it, the resulting matriarch that gets spit out is the union. But here's why you should care about it from a rigidity theoretic perspective. So I guess, okay, jumping right down to the bottom, and then I'll go back. So this big result of lavash and in 1982, um, can be more succinctly phrased as follows. So if r is the rank function of the graphic matriarch underlying kn, then this matriarch you get from the function twice that minus one is the algebraic metroid underlying the Kelly Manger variety of endpoints in r cubed.
00:27:13.106 - 00:28:23.658, Speaker A: Or in other words, it's the rigidity matriid in two dimensions. And here's why, at least from a geometric perspective. So Lovash and Umini have a, have a more combinatorial proof, but from a geometric perspective, the Hadamard product of two points in f to the e is just the point you get by just multiplying corresponding coordinates together, right? So if this is just like the Minkowski sum of two points, except instead of adding things, you're multiplying them, and then the Hadamard product of two varieties is just, well, take every pair of points in your two varieties, take the Hadamard product of those two points, and then take the risky closure of the set of points you get from this. So this is the Hadamard product of these two varieties. So here's a theorem. If u and v are linear spaces, then the algebraic matriid of the Hadamard product of them is just the matriid you get using that construction of Bedmans and rota, where your function is just the sum of the two rank functions minus one. And.
00:28:23.658 - 00:29:32.884, Speaker A: Okay, why this is relevant for rigidity theory is because it turns out that the Catley Menger variety of endpoints in r two is a Hadamard product of two copies of this linear space u, where u is the linear space spanned by the incidence matrix of the complete graph on n vertices. And from these two together, this result of lobotomy falls out. Are there any questions? All right. Okay, so now that hopefully this makes some sense, I hope, for the Kaylee Menger variety, case or non symmetry force rigidity, I'm going to ratchet up the complexity a little bit and talk about how this applies in the symmetry force setting. Okay, so now, as before, s is just going to be a group of euclidean isometries of RD. I'm going to use this notation. So for a field f, f to the kn of s is just going to be the vector space with coordinates indexed by arcs of kns.
00:29:32.884 - 00:30:41.744, Speaker A: So note that if s is, is infinite, then this is going to be an infinite dimensional space. So I'm going to define now the analog of this map that, so in the non symmetric case, you just have a set of endpoints in RD and you map it to all the pairwise distances between them. Here I'm going to have a map that takes, again endpoints in RD, but it's not just going to match. It's going to give me more than just the pairwise distances between every pair of them. It's going to, you know, for every pair of points and then every group element, it's going to take one of those points, apply the group element to it, and then give me the pairwise distances between those two points. So this includes all the pairwise distances, but then also, you know, pairwise distance, you know, more than that, distances between a point and then the group, a group element applied to each other point. And then, as before, I'm going to define this c m c m, sub n of s to be this risky closure of the image of D.
00:30:41.744 - 00:31:39.348, Speaker A: And, you know, it turns out that an s gain graph G is generically infinitesimally rigid if and only if it corresponds to a spanning set in this Cayleen Manger variety. And for basically the same reason as before. You know, I will say things are a little bit more complicated here, right? Because you can potentially have infinite dimensional, or you can potentially live in an infinite dimensional space. These varieties are finite dimensional. So a lot of algebraic geometry still works, but there are potentially complicating things that arise. But anyway, let me just give you an example of this construction here. If s is just the group generated by this 180 degree rotation, and I'm only dealing with two points, then the resulting Kaylee Menger variety looks like this.
00:31:39.348 - 00:32:22.824, Speaker A: So here is the coordinate corresponding to that one pair of points and then the identity element. So this corresponds to this arc, and it's just the distance between those two points. This is the distance between the point x one, y one, and then the point I get by applying a to it. And then this is the point I get, or, sorry. Yeah, this coordinate corresponds to this arc. And it's what I get when I look at the distance between x one, y one, and then x two, y two after applying a to it. And then finally this coordinate corresponds to this arc.
00:32:22.824 - 00:33:25.474, Speaker A: And it's the distance between the point x two, y two, and then the point I get by applying a to it. Okay, so now in the d equals two case, in the case where s is a subgroup of the orientation preserving isometries, then I can express gains as follows. So there will be a translation part and then a rotation part. And, you know, if it's a rotation of angle theta, the matrix is going to look like this. And if I do this, then under this change of parameters, then the entry of this variety corresponding to some arc e is going to look like this. So sort of the important thing to take away from this is that this is an affine function of x and y, sorry, of your x coordinates. This is an affine function of your y coordinates.
00:33:25.474 - 00:33:57.018, Speaker A: And. Well, yeah, yeah. So this tells you that this variety is a Hadamard product of affine spaces. And now this is precisely the part that breaks down when you try to allow reflections. What happens is your x. What's really nice here is your x coordinates, and y coordinates just get completely separated across this Hadamard product. But when you allow reflections, they start to mix.
00:33:57.018 - 00:34:49.003, Speaker A: And so it's no longer a Hadamard product, but it still just is a product of affine forms. Um, so not all hope is lost, but it is more complicated. Um, but anyway, so now this, this, this raises the question, well, what is the algebraic metroid of a Hadamard product of affine spaces? Um, and I'll tell you. So if v is this affine space. So if I'm going to think about an affine space, is just the range of a matrix plus some constant vector. The algebraic matriid of this affine space, just thought of as a variety, is just going to be the rho matriid of a. Now, if I define m to the elev, to be the rho matriid of this augmented matrix, then m to the Lv is an elementary lift of Mv.
00:34:49.003 - 00:36:02.756, Speaker A: So this is elementary lifts are a construction in matroid theory, but if you don't, if you haven't seen it before, that's fine. The sort of important feature of lifts is that this tells me now that if I is independent in this matriid, then it's also independent in the lifted matriarch. Now, and here's the general form of the theorem just for Hadamard products of affine spaces. If u and v are finite dimensional affine spaces, then I'm going to define this function f to be the sum of the rank functions. If the rank, sorry, f of a given s is going to be the sum of the ranks of s in the matrix of each of those affine spaces, if the rank of one of them increases when you go to this left, right. So if your rank, if your rank of s in either u or v is bigger in ML than it is in m, then it's going to be the sum, and otherwise it's going to be the sum minus one. So, okay, this is some function.
00:36:02.756 - 00:37:02.592, Speaker A: It turns out it's submodular, it's increasing. So I can, you know, use that construction of Edmunds and rota to define a matrix from it. And it turns out that the matriarch defined by this function is the algebraic matriarch of this Hadamard product. So, yeah, and then where I'm going from here, I'm almost done. I just need now to apply this to this particular example, these symmetric Cayley mengar varieties. So, another community besides topological graph theorists that care about gain graphs are metroid theorists, and I think this definition goes to Zaslavsky. But it says that the gain graphic matriarch of a gain graph g, is the matrix supported on the arc set of g, whose independent sets are sets of arcs.
00:37:02.592 - 00:38:01.734, Speaker A: Such as each connected component has at most one cycle which is not balanced. So if I were to. So yeah, if I were to look at this graph, say, the bases of it are just going to be spanning trees plus either a loop or. Yeah, just this loop. Right? So yeah, if I were to take. Yeah, so, so the gain of this particular cycle, that loop is not balanced. So if I were to take, you know, say, these three arcs and then that loop, I would get a basis, but I would not get a basis, say, if I were to take just like the four cycle, because the gain of the four cycle is the identity in particular, that's a balanced cycle.
00:38:01.734 - 00:38:57.950, Speaker A: And then, okay, now that I have this, I can sort of put things all together. So now, if s is an orientation preserving subgroup of euclidean isometries in the plane, the corresponding Caylee Manger variety is a Hadamard product of affine spaces, where they're different affine spaces, but they have the same matriids. In particular, the matroids of each is just the gain graphic matriid of the gain graph obtained from the complete gain graph just by ignoring the translation part of each gain. And the corresponding lifts that I described earlier is obtained from the gain graph just by. Or, sorry, the gain graphic matriid of this just by making. By asserting that non dutch bicyclic subgraphs are independent. All right.
00:38:57.950 - 00:39:14.286, Speaker A: And then putting that all together, this theorem just falls out. Right. So, um. Yeah, I mean, I guess this is, this is. Yeah. If you're interested, you can piece this together either from the slides or from the paper, but it, it really does just sort of fall out. Um.
00:39:14.286 - 00:39:20.594, Speaker A: Yeah. And I guess I'll end a little early. Yeah. That's all I have to say. Thank you all for your attention.
00:39:22.294 - 00:39:31.726, Speaker B: Thanks, Daniel. So, are there any questions for Daniel? So, I like the explanation of Dutch.
00:39:31.750 - 00:39:32.926, Speaker A: I had wondered last time I heard.
00:39:32.950 - 00:39:37.854, Speaker B: You talk similar, but it was good to know. Thanks.
00:39:37.974 - 00:39:43.110, Speaker A: Do they call bicycles Dutch in other commuting bicycles Dutch in other countries? Or is that just an american thing?
00:39:43.182 - 00:39:44.454, Speaker B: I hadn't heard that before.
00:39:44.574 - 00:39:45.394, Speaker A: Okay.
00:39:52.154 - 00:40:36.268, Speaker B: Walter. So, Daniel, yesterday I talked a little bit about the projectile transformations in the plane that take half turns to mirror symmetry and vice versa. So that's really working. In the symmetries of the elliptic space, the projector the elliptic model of projective space where you are able to switch the orientations and so on. Does that kind of correspondence transfer into your methods at all? So you don't. You're no longer saying mirrors are really different than rotations because they're interchangeable in the plane in three space. What it.
00:40:36.268 - 00:40:52.092, Speaker B: What's interchangeable is a mirror and inversion about a point. And you get similar kinds of pairings all the way up. So yeah, I.
00:40:52.148 - 00:41:02.824, Speaker A: So yeah, I can. I can see how that. Sort of like the. The. I can see how that probably manifests itself in this setting. Yeah. So go back to, you know, like in.
00:41:02.824 - 00:41:28.192, Speaker A: Where is it? Ah. Over here. Okay, so. So the thing that. That makes things difficult when you start bringing in reflections is. So here I have, you know, s source minus e to the I theta x target, and same for y. What winds up getting messed up is if you.
00:41:28.192 - 00:42:06.816, Speaker A: You know, if. Um. Yeah, so, yeah, this is sort of like the expression for a point at the coordinate corresponding to a particular arc. So this is what it looks like. If that arc has a group label that's orientation preserving. If that arc is orientation reversing, then this x target e and y target e switch, which doesn't matter if you don't have any reflection part in the sense that like, you can just switch the roles of x and y in a certain way, and then things will not be changed, at least on a matrix level. I think I have to think about that a little bit more.
00:42:06.816 - 00:42:25.164, Speaker A: But I. I think that's how that. What you're saying would manifest here. But then I'll also say it doesn't really, like, help for more complicated things. Because when you start putting, you know, reflections and rotations together, that's. I mean, unless there's like some kind of projective way to get around that.
00:42:28.744 - 00:42:58.384, Speaker B: Well, the way would be the. On this. On the sphere. On the sphere with antipodal points identified that it might at some point be worth looking at. The chapter in Conway's book on. What was it called? I'm not coming up with the full title, but he had a whole quaternions. What was quaternions? And quaternions.
00:42:58.384 - 00:42:59.244, Speaker B: Yes.
00:43:00.264 - 00:43:07.924, Speaker A: So quaternions. And I'm writing this down. Conway. Quaternions and Octonians.
00:43:08.224 - 00:43:10.136, Speaker B: I think so. I think so.
00:43:10.280 - 00:43:10.920, Speaker A: Okay.
00:43:11.032 - 00:43:35.798, Speaker B: But it's. So that's what Barrington, Tony and I, and Kate were using for this, exploring a particular example of the pairing. But I hadn't really thought a lot about whether that pairing takes force. I think it takes for symmetry to force symmetry. But Berndt might be able to answer that. Let me make one comment. You.
00:43:35.798 - 00:43:48.834, Speaker B: At times you were saying Edmonds and Rhoda and Edmonds. My understanding of the history is Edmondson wrote it, published an abstract with that statement in it, and Edmunds published the proof.
00:43:49.134 - 00:43:50.034, Speaker A: Okay.
00:43:51.614 - 00:43:54.014, Speaker B: It is Edmunds, Rhoda in some sense.
00:43:54.174 - 00:43:59.710, Speaker A: Okay. Okay. Yeah. Because I've never been able to find that Edmunds and Rhoda thing.
00:43:59.862 - 00:44:01.710, Speaker B: It's an abstract only.
00:44:01.902 - 00:44:05.214, Speaker A: Yeah. Okay. Okay. Yes. Okay. All right. Good to know.
00:44:05.214 - 00:44:06.074, Speaker A: Good to know.
00:44:08.854 - 00:44:17.404, Speaker B: There's a question in the chat. What are the applications that you can envision? Re chirality of atomic structure of amino acids.
00:44:23.944 - 00:45:02.502, Speaker A: So, yeah, I don't really know. I sort of came at this from the perspective of, like, the. I know, I know this. I had this tool for looking at varieties of hadamard products of linear spaces. And I basically just searched the rigidity theory literature to find some kind of thing that could fit that mold. And it seemed like other people had thought about this. It seems like the applications come from material science, and in particular a type of material called, I think, a zeolite.
00:45:02.502 - 00:45:13.624, Speaker A: But I don't really know. Yeah, I don't really know much. I can't really say much about the applications. And I'm. There are other people in here who could maybe.
00:45:16.364 - 00:45:46.444, Speaker B: I can say a little bit. We looked at some, at the symmetry questions for biomolecules and so on. For example, take a current example. The spike protein of the coronavirus is a trimer, three copies of identical protein twisted together. And so that's likely to have threefold symmetry.
00:45:46.784 - 00:45:50.764, Speaker A: Oh, cool. I'm giving a job talk in a week. I'm going to mention that.
00:45:52.544 - 00:46:50.892, Speaker B: I could. This is stuff I got from Adnan Schlocke, who's doing a lot of protein related stuff, but. But I don't think the chirality in the backbone of proteins and so on immediately fits into that. There's a bunch of history and errors in databases and so on about what's chiral and what's left handed and right handed up the backbone of a protein. Their algorithms introduce systematic errors that underestimated how many swap things. So I don't think it's immediately symmetric. There is a paper that Adnan and Behrendt and I published on the question of, does symmetry in a protein make a difference to its flexibility and its rigidity and so on.
00:46:50.892 - 00:48:03.636, Speaker B: And it's fairly superficial at the sense that, in detail, some of the symmetry is not quite there. Right. The common situation is that you got a protein. You have a protein produced by two copy identical copies of the protein. It's likely to hitch up with twofolds symmetry, but there can be small variations that turn out to make a lot of difference in function and so on. But there is a paper you can look at just for if you're interested. And of course, the talk this morning showed the carbon rings, six fold ring of carbon, where two different symmetries in the ring produced two different experiences.
00:48:03.636 - 00:48:13.964, Speaker B: So the boat in the chair you can look for in the rings, it appeared in the motivational stuff of the first talk this morning.

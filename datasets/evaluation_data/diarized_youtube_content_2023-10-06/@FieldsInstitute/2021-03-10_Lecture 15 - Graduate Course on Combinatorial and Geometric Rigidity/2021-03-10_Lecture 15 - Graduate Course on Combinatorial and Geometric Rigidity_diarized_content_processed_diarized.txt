00:00:00.360 - 00:01:05.706, Speaker A: What we're doing, we're still trying to understand generic global rigidity in two dimensional space. And so in particular we're trying, we're looking at the sufficient conditions for global rigidity, which we know, which are free connectivity and redundant rigidity. And we're trying to show that every graph that has both those properties can be generated from the smallest such graph by this fundamental one extension operation and edge addition. So some sequence of these two operations, and we've already seen, which was the real sort of technical detail part that I went into the proofs for, that this result is true in the special case where the redundantly rigid graph is a circuit in the two dimensional rigidity matriid. And then last time we showed that in general, redundant rigidity for free connected graphs, redundant rigidity can be translated into a matroidal property that the rigidity matriid is connected. And the matriarch being connected means that for any pair of elements in the the matriarch, there is a circuit that contains that pair. For example, if you're a circuit, if the whole graph is a circuit, then clearly this is true.
00:01:05.706 - 00:01:57.874, Speaker A: But it's a generalization of circuits, and it's analogous to k connectivity in graphs. This is r two connected would be equivalent to, analogous to the cycle matrix. So two connectivity for just graphs, but you can have analogous higher connectivity versions of matrix connectivity that, analogous to k connectivity, if you like. But that's a bit of a diversion from the content today. So what we finished the last lecture on Monday with was that we proved that if the graph is pre connected and its rigidity matriarch, two dimensional rigidity matriarch is connected and it's also minimal. So we can't throw any edge away without destroying one of these two properties, then it must be true that the graph has a vertex of degree free. So remember, we're trying to show that we can always do one extensions in edge additions.
00:01:57.874 - 00:02:40.274, Speaker A: So if we to give some big graph in the class, and I can't do edge additions because it's not, it's not minimum, it is minimal, then I must have a vertex of degree free to do a one reduction on. So this was a big step forward towards that. And it's not obvious to me at least, why you would have this degree free vertex in a redundantly rigid graph. And we're, we'll see towards the end of this lecture what the number of edges in a redundantly rigid graph in the plane can be, and it's quite a lot higher than you might expect. And doesn't automatically guarantee a degree free for just an account. And so having this connectivity condition that guarantees it has got us a big step forward. And in fact that's the last kind of detail that we're going to do.
00:02:40.274 - 00:03:29.980, Speaker A: We're going to really not do very much else before we're finished. So I'm just going to give a bit of a, a sketch from here on. Okay, so as I say here, this degree free gives us a chance to apply a one reduction and hopefully we can do that to a smaller free connected and two reals connected graph. So just like it was for circuits, there'll be a sort of an admissibility step preserving r two connectivity, and a feasible step where you want to find an admissible node that's also preserves free connectivity as well. And so what we did last time to find the vertex of degree free was we used the fact that our two connected graphs have ERD compositions. And so our a decomposition, say as graphs was h one, h two up to ht, say. And we suppose it's not a circuit, so t is at least two.
00:03:29.980 - 00:04:12.914, Speaker A: And then we looked at all of the previous h I's and that gave us something. And then we looked at the way the last year the HTML interferes with the rest of the graph. So it has some set x with the overlap and some set y, which is what's in HT but not in didn't occur already because it wasn't, the graph is not minimal. Ht didn't just add a single edge, so it did add at least some new vertices. And then we were able to show there was a node outside. And basically that's about all I want to say about the general case, because now you sort of have this picture here which says Ht is a circuit, it has a node in it, some vertex are degree free. We want to do a one reduction on that node.
00:04:12.914 - 00:05:02.654, Speaker A: And what I'm basically going to say is that we can use the fact that most of this, that some part of Ht is this set y which doesn't interfere with the rest of the graph. To translate the results we proved for circuits to apply them to this circuit Ht, but find the admissibility and the feasibility apply to the entire graph rather than just Ht itself. So we don't introduce any problem that ruins the properties we had for the previous years in the decomposition as we go. This is not at all obvious if you try and start trying to prove it. And the theorem that Jackson and Jordan did prove, this takes a lot of effort and it's very intricate. But I don't want to go into the details. I just want you to believe that it can be done using similar techniques to what we did for the circuits.
00:05:02.654 - 00:06:11.460, Speaker A: Okay, so that's what I say here, that it's similar but significantly more complicated. And I'm not going to go into the details, but here's the theorem of Jackson and Jordan from 2005. If you are a pre connected r two connected graph and you're minimal in the sense that g minus e fails to be one of the two things, then either you're the complete graph on four vertices, or there's a degree free vertex, a node, we already know that bit, but there is a node such that when we do the one reduction at that node, adding some edge among the neighbors. So one reduction at v adding xy for some x y in the neighbor set, you can do such a reduction that maintains free connectivity and two reals connectivity. Okay, so this gives us the recursive construction that we were building towards that basically. Now it's a very simple induction argument, or on what we already know to show the global rigidity d theorem. But on the other hand, there are still some little things that I'm basically going to sweep under the rug, so to speak.
00:06:11.460 - 00:07:05.878, Speaker A: So one of them is an exercise. So if I take a redundantly rigid graph and apply a one extension operation, it's relatively easy to see that the new graph will have the properties you want, infinitesimally rigid or rigid. These ones we've already talked about before, but it's not necessarily so obvious that if you take an two reals connected graph. So I mean, it's not hard, sort of a couple of paragraphs. But an exercise would be to show that if a graph is two reals connected and g is obtained by even an edge addition is not necessarily trivial or a one extension, then the resulting graph is r two connected. And so the, I think I even give a hint for this. So my hint is to think about the two reals connectivity definition in a very slightly different way.
00:07:05.878 - 00:08:10.676, Speaker A: So think about it as defining an equivalence relation on the set of edges, saying that two elements, two edges are related if they're the same, or there exists a circuit containing the pair of them. So it's a very small reformulation of the definition I gave. But if you try the exercise, and then the way I see, see the proof going transitivity of this equivalence relation will, will help you to make the proof work. Okay? So with that exercise and what we just said about the reduction step the theorem you get is the recursive construction theorem, which is here, which says a graph is free connected and two reals connected if and only if it can be obtained from k four by one extensions and edge additions. And we've already previously seen that k four is globally rigid. Edge addition obviously preserves global rigidity. And we talked about when we looked at stress matrices showing that one extension preserved global rigidity as well.
00:08:10.676 - 00:08:56.246, Speaker A: So we basically know, as a corollary to this theorem, the characterization of global rigidity. But still, I'm going to write it as a theorem and proof, just to hammer home the theorem, because I think it's one of the most important theorems in rigidity theory. So you take a generic framework, GP in two dimensional space. Sadly, this proof doesn't work in any higher dimension. Then the framework is globally rigid if and only if there's a trivial case where you're a very small complete graph, because, for example, a triangle is certainly not redundantly rigid. If you throw an edge away from a triangle in the plane, it will definitely be flexible. But if you have at least four vertices, even if you're complete, it coincides with the other conditions.
00:08:56.246 - 00:09:32.124, Speaker A: So all the graph is free, connected and redundantly rigid. Okay, so it's very easy to deal with the case of small graphs. It's just globally rigid if and only if the graph is complete. So we can suppose we have at least four vertices. The first lecture we started with global rigidity. Whenever that was, we proved Hendrickson's conditions which showed that in any dimension, global rigidity implies redundant rigidity and d plus one connectivity. So the fact that our globally rigid framework must have an underlying graph which is free, connected and redundantly rigid, followed from that.
00:09:32.124 - 00:10:33.982, Speaker A: For the sufficiency, we start with a free, connected and redundantly rigid graph. And we proved last time that for free connected graphs, in fact, for nearly three connected graphs, we don't need to worry about that last time, that redundant rigidity and two reals connectivity are the same for free connected graphs. So our free, connected, redundantly rigid graph is exactly a free connected two reals connected graph. So the recursive construction theorem I just mentioned, that said, all three connected two reals connected graphs can be generated by edge additions in one. Extensions from k four tells us that if our graph is not k four, then it can be reduced to a smaller, pre connected two reals connected graph by one reduction or edge deletion, we can go back. And so the way I phrased it is to avoid using the Gottlieheli first inference, because I think that's complicated. So I've expressed it by talking about stresses.
00:10:33.982 - 00:11:33.790, Speaker A: So we can use the fact that K four has a full rank stress. So we check that in the stress matrix lecture, and we checked that one extension and edge addition preserved the property of having a full rank stress. So by induction, and since we're doing edge additions and one extension sits on the number of vertices plus edges, we can generate a full rank stress for any r two connected, free connected graph g. And then we showed Connelly's results, which was that if you have a full rank stress, then generically you are globally rigid. And so the final graph at the end of the construction will always be globally rigid, because the first one was. And the operations that we used that generate every graph in the class preserved full rank stress, and hence were globally rigid. I could have talked about global rigidity directly without stresses by using the Gaultly Healey Thurston theorem, but I wanted to avoid it, because, as I say, I haven't gone into anything of the proof of that.
00:11:33.790 - 00:12:08.824, Speaker A: Or I could have used an alternative proof technique that was due to Jackson, Jordan and Zabadka, where they talked about one extensions without using stress matrices. So again, I could have avoided stress matrices that way, but I thought they were nice. And they're gonna be relevant to a couple of the guest lectures we have, I think, coming up next week. Okay, so that's the proof of the firm, and that's basically what the aim of the last four or five lectures has been. So maybe it's a good time, even though it's early in the lecture, to stop in case anyone has a question.
00:12:12.524 - 00:12:37.484, Speaker B: So, Tony, I have a question, actually. So I think. Yeah, so Connolly's result shows that a generic framework with a full rank stress is globally rigid. Yeah, but you're actually proving, I guess it's slightly stronger than that, because it's saying that if you have one framework with a generic, one generic framework with a full rank stress, and all generic frameworks will have a full rank stress.
00:12:38.784 - 00:13:30.104, Speaker A: Yes. So in the stress matrix lecture, I gave a result, I don't think I gave the proof, but if you have a infinitesimally rigid realization in any dimension of a graph and you have a full rank stress, then, then you know automatically that every generic realization of that graph has a full rank stress as well. So, because it was infinitesimally rigid as well. And in the. So in the lecture where I talked about one extensions preserving full rank stress, we had this result that, first of all, one extension preserves infinitesimal rigidity at special position collinear, and it also preserves full rank stress. And then you can perturb and preserve, broke both properties as you do to a generic location. But more strongly than that, you can also show that all generic realizations who have a full rank stress as well.
00:13:30.444 - 00:13:39.184, Speaker B: I think I must have forgotten that. What's the general reasoning behind that? Is it some sort of algebraic geometry stuff or something else?
00:13:39.844 - 00:14:12.578, Speaker A: Remember, rightly, it's just a case of thinking of rational functions in the coordinates, because the entries in the stress matrix are rational functions of the coordinates of the points, because they come from the co kernel of the rigidity matrix. And so I think you can just get a violation of algebraic independence if this kind of thing wasn't true. So this is a lemma in. So you can check if you want that. I'm not talking nonsense. It's a lemma. And Connelly Whiteley, they have a paper called global rigidity, the effect of coning.
00:14:12.578 - 00:14:29.018, Speaker A: So they have the same statement I said, where they perturb for global rigidity, but they have a slightly easier, so that one uses the averaging technique, but they have a slightly earlier lemma in that paper where they preserve full rank stress, as long as you're infinitesimally rigid. Okay. All right.
00:14:29.066 - 00:14:30.122, Speaker B: Thank you. Cheers.
00:14:30.258 - 00:15:05.834, Speaker A: Okay. Yeah. So this paper is something like 2010, if anyone wants to look at it. It's called global rigidity, the effect of coning, although what I said is not relevant to coning, but we'll come to Koning on Friday, I think, if I, if I get there in time. Okay. So I want to mention one other alternative proof of the characterization, which is due to Shinichi Tanegawa. So he came up with a relatively recently, a stronger move than one extension, basically, which.
00:15:05.834 - 00:15:55.434, Speaker A: Well, I won't try and get it exactly right, but it's just a slightly stronger move than one extension, which allows him to make the combinatoric significantly easier. It still uses a lot of the combinatorics that I presented, but it gets around some of the more technical bits that I didn't present and almost reduces the combinatorial step to finding a vertex of degree free. So, still going into the a decompositions of the r two connected graphs, as we did, but then not having to worry so much about the admissibility and feasibility in general. So there's a nice, it's a paper called sufficient conditions for global rigidity, or something close to that. So this is a nice proof to look at, if you like. Yeah. So I've sort of covered mentioned this about Jackson.
00:15:55.434 - 00:16:30.794, Speaker A: Jordan's a bad crow already. But I also want to mention another result from Shinichi, which is a different sufficient condition for global rigidity from the same paper. So we talked about redundant rigidity in terms of edges. So if you delete an edge, you should still be rigid. You can alternatively think about redundant rigidity for vertices. And so there was a talk on this sort of topic at the workshop a couple of weeks ago. The idea is that a graph is vertex redundantly rigid if for every vertex in the graph from that one vertex and all its incident edges away, maintains rigidity.
00:16:30.794 - 00:17:21.054, Speaker A: So, for example, if you have a very high degree vertex, it's quite a strong condition, saying that throwing it away, you don't lose the rigidity. But given this condition, Shinichi was able to prove that all vertex redundantly rigid graphs are globally rigid in any dimension. So I think this is a nice result. I won't go into any of the proof, but I just wanted to flag up the result for those of you interested. Okay, so we've talked about two dimensional global rigidity. I want to say a little bit. We already showed that there exists k 55, for example, in 3D is an example of a four connected, redundantly rigid graph which is not globally rigid.
00:17:21.054 - 00:18:05.740, Speaker A: And I mentioned a couple of references for higher dimensional families of examples where those Hendrickson conditions fail to be sufficient. But there are some special cases. So I thought, like we did for rigidity in three dimensions, I would just point out at least one special case where we understand global rigidity. So in the special case is triangulations of the sphere or maximal planar graphs. At least this is the one I'm going to flag up today. So this is a recent result of t boy Jordan and Shinichi Tanigawa. So what we saw several lectures ago now was that if you're a triangulation of a sphere, you have exactly 3 volts, minus six edges, and you will be minimally rigid.
00:18:05.740 - 00:18:38.240, Speaker A: And this was a vertex splitting, proof that we went through. But if I take such a graph, a maximal planar graph, and then I add a set of edges. So the set of edges you add to your maximal planar graph will be called braces. And I'll call the graph resulting from the adding these edges to a maximal planar graph. I'll call it a brace triangulation. Okay, so clearly we need to satisfy Hendrickson's conditions. So our brace triangulation has to be four connected d plus one connected in three d, and it has to be redundantly rigid.
00:18:38.240 - 00:19:33.944, Speaker A: But it turns out if you just make your brace triangulation four connected, then it will be globally rigid in three d. And this is one reason this is interesting, is because, as I say, when we talk about maximal planar graphs or triangulations in rigidity, it tends to boil down to showing vertex splitting preserves rigidity, which Walter Whiteley did in the eighties, and then showing that you can get everything in some class of graphs by this vertex splitting operation. But it's still open in general, even now, where the vertex splitting preserves global rigidity. So, let me draw a picture. So the vertex splitting operation, in case you've forgotten, looks like this. So I had some vertex in the middle that, say, u and I want to split it into u and u. So these two special neighbors, say v one and v two become adjacent to both.
00:19:33.944 - 00:20:26.424, Speaker A: There's an edge between u and u double dash, and then the other neighbors of u are split in some way among the two. So this vertex, if you forget, these two neighbors would have degree free. So I have to say the vertex split is non trivial in the sense that out of these five guys, or however many neighbors there are, at least one goes on each side. Just prevent just having too low a degree to have a chance of being globally rigid. But it's conjectured that as long as the vertex split is non trivial in that sense, that it preserves global rigidity. And so, in this paper, they were able to prove this is true in a sufficiently general, special case to confirm this theorem. But it's still open in full generality to show that this always takes one globally rigid graph to another globally rigid graph in free and any higher dimension.
00:20:26.424 - 00:20:47.454, Speaker A: Okay, so, redundantly rigid graphs. So again, it's a good time, if anyone has a question, but if not, I'll spend the next maybe 20 minutes talking about redundant rigidity in two dimensional space. Okay.
00:20:49.314 - 00:20:50.146, Speaker C: Tony?
00:20:50.290 - 00:20:51.002, Speaker A: Yeah.
00:20:51.178 - 00:21:18.584, Speaker C: I have a bit of a question. So, we've spent a lot of time trying to figure out when graphs are rigid. Do we spend, is there any interest in the community in trying to understand kind of the degree of freedom of various flexes? I mean, you could imagine, say, kind of trying to cut up the remaining non rigid cases into some classes and characterizing those.
00:21:19.324 - 00:22:12.266, Speaker A: So we're interested, well, at least so far in the course, we're interested in generic rigidity. So when, for example, we give the Leman theorem or the polycharinger theorem in 2D, which said minimally rigid if and only if, this counting condition, which I can't remember what I actually called it, but let me call it two free type. This equals 2 volts free condition, etcetera. And so this also characterizes independence. So the minimal rigidity is the case when the rank is equal to 2 volts minus three, and the rows of the matrix are linearly independent. But the theorem as well, it sort of, maybe I go over here to have a bit of space. The theorem is automatically a bit more general than that, and says that the graph is independent if and only if it's two free sparse.
00:22:12.266 - 00:22:59.594, Speaker A: So if and only if you have at most two x minus three edges for all x greater than or equal to with at least two elements. And so if I, so what that's saying is if I give you a graph that happens to have, say, 2 volts -20 edges, if it satisfies the sparsity condition, then we know it's got exactly 17 degrees of freedom. So there'll be exactly a 17 dimensional space of infinitesimal motions. And so in some sense, by understanding the rigidity, you get this independence. And so you understand the sort of dimensions, at least in linear algebraic sense, of what the, that the motions are generically. So in some sense, we are doing the same thing. We are doing what you asked at the same time.
00:22:59.594 - 00:23:34.144, Speaker A: But I guess you're more interested in the case, actually understanding what the configuration space looks like as a variety. And there, it's probably more interesting to think about the non generic case. And so if you take the word generic out, and then maybe you look at graphs, say you're in the plane and you look at graphs that do satisfy the combinatorics but have some flexibility. And when do they have a nice motion? When do they have a nice configuration space with cusps or singularities that are of interest? And that's a whole different ballgame to the generic theory we've done so far.
00:23:35.404 - 00:23:36.580, Speaker C: Okay, that's it.
00:23:36.692 - 00:23:43.064, Speaker A: Great. Thanks. Okay, any other questions?
00:23:44.324 - 00:23:53.734, Speaker D: Yeah, just a follow up on Will's question. So, if you don't satisfy that sparsity condition, then you don't necessarily know.
00:23:55.674 - 00:24:21.384, Speaker A: You'Re talking about this thing I was saying. Yeah. Yes. So say I give you a graph with two v -20 edges. Then if you don't satisfy this condition, then the rows of the rigidity matrix are dependent. But you can check from how much of a maximal size sub spanning subgraph does satisfy it to still know that the, you have at least 17 dimensions of flexibility. I don't know why I've picked 20 and 17.
00:24:21.384 - 00:24:48.524, Speaker A: This is just a random number, but each dependence will give you one more, and so you'll still be able to count how many degrees of flexibility you have. But I mean, I'm not telling you anything about what it looks like. Even in a very small simple graph, I wouldn't be able to tell you what the, precisely the topology or anything like that of the configuration space. All I'm doing is looking at the linear algebra for the dimensions of the, the kernel, etc. Of the rigidity matrix and saying that there must be this much independent flexibility.
00:24:49.664 - 00:24:57.544, Speaker D: Okay, but then to determine that, you'd have to look at what subgraphs are sparse in this sense.
00:24:57.704 - 00:25:26.734, Speaker A: Yeah, so I guess you, I mean, the co kernel of the matrix will tell you the dependencies, so you'll know, the rank will tell you. I mean, from the dimensions of the kernel, the co kernel and the rank, you basically get the, in some sense the information to know something. But then you probably like will would be more interested in deeper algebraic properties of what's going on in those, for those graphs. And that's something this theorem doesn't tell you much at all about.
00:25:27.954 - 00:25:37.334, Speaker D: Right, okay, thanks. Oh, I did have another question.
00:25:37.794 - 00:25:38.418, Speaker A: Sure.
00:25:38.546 - 00:26:01.334, Speaker D: A really long time ago you mentioned that r two connectedness is just a special case of like a matrix connectedness condition. And I was wondering then, does that matriid connectedness condition get decorated with a number of like, in this case two, because we have two edges.
00:26:07.294 - 00:26:53.898, Speaker A: Sorry. So there was a lot of banging, drilling above my head, but I think you asked about generalizing this. So the first sort of simple generalization is, I've always picked one particular matriid here, so that there's this trivial generalization to other matriids. But I did say that. So if you take a general matriid, then m connected as I defined, is the sort of natural equivalent of a graph being too connected. You can have a sort of, I don't know how to even to notate it, let's say km connected, whatever that means, which is a natural generalization of a graph being k connected, and it is something like the number of edges within each common circuit. But I don't know the precise definition off the top of my head to look at it.
00:26:53.898 - 00:27:32.104, Speaker A: There is a paper and rigidity about highly connected rigidity matriids by Victoria Kazanitsky, who I'm going to have to apologize for misspelling her name. I was in red. I'll get there at some point. Nitsuki, something like this, plus maybe Chabukirai or maybe Tibor Jordan. But it's something like highly connected rigidity matroids. And so they go into whatever this actually is. So if you're interested, it's a, that would be a place to look.
00:27:32.104 - 00:27:35.524, Speaker A: Hopefully. That answered enough of your question, Alex.
00:27:35.604 - 00:27:37.572, Speaker D: Yeah, that was my question, basically.
00:27:37.668 - 00:28:06.260, Speaker A: Thanks. Okay, so in the hope of getting through it, this lecture, let this continue. So I want to talk about redundantly rigid graphs. So it's obvious if you're minimally rigid from the rigidity matrix, you have exactly e equals two, v minus three. If you're globally rigid, you have at least two v minus two. If you're redundantly rigid, you have at least two v minus two. But it's not so obvious what an upper bound on the number of edges in a redundantly rigid graph is.
00:28:06.260 - 00:28:44.714, Speaker A: But I want to use the fact that we understand a little bit now about two reals connected graphs to prove an upper bound on how many edges a redundantly rigid graph in the plane can have. Okay? Okay. So obviously redundantly rigid graphs, you complete graphs satisfy it. You can just keep throwing in edges. So to make sense of this, I need to include this word minimal. So a minimal redundantly rigid graph is a redundantly rigid graph such that if you delete any edge, you fail to be redundantly rigid. So it's like the minimal rigid, rigid graphs, the minimal version of redundantly rigid graphs.
00:28:44.714 - 00:29:32.306, Speaker A: We know we have to be redundantly rigid, so we need at least two, v minus two. But how big can we get? Okay, so first of all, I'm going to solve the, in this lemma, I'm going to solve the problem for our two reals connected graphs. Okay? And I think this lemma, at least in my head, is due to Tbor Jordan from 2014, and I should have checked if it goes a bit earlier, but that's the reference that I used. So take a minimally r two connected graph. So minimally, meaning if I delete any edge, it fails to be connected, connected. Then the number of edges, remember, we're in two dimensions, but the count is what you see for 3d rigidity, the number of edges is at most three, b minus six. Okay, so let's prove this.
00:29:32.306 - 00:30:04.052, Speaker A: We saw last time that every two reals connected graph has an ear decomposition. So let's let the ears of the decomposition be the circuit c one up to ct and we're going to do induction on the number of ears in the decomposition. If t equals one, then it's just a circuit. There's only the one circuit. We know circuits have two v minus two edges. And since we may as well assume, I may as well have assumed up here that v is at least four. Well, in fact v is always at least four because it's two reals connected.
00:30:04.052 - 00:30:49.424, Speaker A: So it must be redundantly rigid. So we know this, and having at least four vertices tells us that 2 volts minus two is at most three, v minus six. So the conclusion is true in the special case where the, there is exactly one circuit. Okay, so we can suppose our ed composition has at least two elements and our circuits as edge sets were c one up to ct. Let's let h one up to ht be the graphs. They are two circuits of gift induced by these circuits in the matroid. Okay, so I'm going to use a fact, which I leave the proof as an exercise.
00:30:49.424 - 00:31:33.620, Speaker A: So I define the subgraph of g induced by the first s ears. So I'm taking, I take the first s is h one up to hs, take their union and let g be that, that union for some s between one and t. Then the fact is that this is a minimally two reals connected graph. So there's a, I mean this is, this is an exercise. So I won't say much about it, but basically it's sort of like the fact that partial ad compositions can be extended to fully ad compositions. So I take my ad composition c one up to ct. If I just forget the last one, the previous part was an ad composition of a smaller graph.
00:31:33.620 - 00:32:25.234, Speaker A: And if I forget the last four, the first, however many, was near decomposition as well. So I'll let you confirm that for yourself if you you want. But the, the upshot of the fact is, and by the, the induction is that if this g, which is the, the union of the first s is, if I call that v e dash, then I have the bound we want for that particular, um, subgraph. Okay, by induction. So what we need to do is look at the, the last one, basically. So let y be the, the vertices of the, the last year minus the vertices that exist in the, the first t minus one ears. And we need to work out that adding this on is still going to give us the, the right count we want for g.
00:32:25.234 - 00:33:41.924, Speaker A: So now we have to use a lemma we had last time, but I haven't repeated. So, so apologies if it's not quite so clear, but with one of the lemmas said, if y is empty, then actually by the third e decomposition axiom, all you're adding in the last lobe is just one single edge, and hence that last edge is redundant because you take it away and you go back to a smaller r two connected graph, which would contradict the minimality we chosen. So we know that y is not empty, and hence by the same lemma we have, wherever it is we have that the lobe has this size, but we'll use that in a second. So now that y is not empty, we know that the number of edges is at most the number of edges we had in the first t minus one ears, plus the number of edges we add in the last year, edges in the last year that weren't in the existing ones. We know that the number of edges here we know that was equal to three v dash minus six. But v dash is really the number of vertices in the whole thing, minus y. So remember we have our union of the first however many years the first t minus one is.
00:33:41.924 - 00:34:22.654, Speaker A: And then we have the last bit. X was the intersection and y was the new bit. So the vertex set here, which I'd called v earlier in the proof, is really v minus y. So it's everything but the new bit here. So that was just from here, Ct tilde, as I just said at the bottom, from the same lemme where I was mentioning earlier from last time, is equal to two y plus one. And then it's easy because I'm putting an inequality to see that if I put the two y in here, the two and the three difference cancels out this, and we get the inequality we want. And hence we've shown that any minimal r two connected graph has at most three v minus six edges.
00:34:22.654 - 00:34:58.732, Speaker A: Okay. Okay. So then the theorem is to give the same bound for minimally redundantly rigid graphs. Okay, so again, this is due to Tibur Jourdan. So you're minimally redundantly rigid in two dimensions. So probably I should, I should emphasize again that this is in r two, then the number of edges is at most freebie minus six. And as I say, this is kind of why I think it was important to emphasize that the ad composition stuff found us a vertex of degree free.
00:34:58.732 - 00:35:50.144, Speaker A: Because if you're a graph that meets this bound, which I'll show you, you can do, or at least you can get very close to for large families, then this bound is close to saying the average degree is nearly six. So finding a vertex to degree free is not obviously going to be possible. But the special structure of three connected redundantly rigid graphs allowed us to do that. In any case, we want to go into why this theorem is true. So I'm a minimally redundantly rigid graph. If I was just r two connected, I could just apply the theorem straight away. So suppose I have some numbers of two reals connected components, so the maximal two reals connected subgraphs, and let's call each of these q components gi equals vi ei.
00:35:50.144 - 00:36:44.962, Speaker A: Okay, so here's an obvious statement to get us started. Since I'm redundantly rigid. The rank of the rigidity matrix is full. It's equal to the two v minus three, if any generic p. And now I'm just going to multiply that by three over two to turn 2 volts three into 3 volts minus nine over two. You'll see that just is going to help the calculations in a moment. Okay, so I'm going to use this little fact for matriid theory that if you take, you have a matriid on ground set e with independence condition I, and you take the components like the m components in the matrix m, like the r two components e, one up to et, and you take the rank function r of this matriid.
00:36:44.962 - 00:38:05.710, Speaker A: Then you can express the rank of the matriid as the sum of the ranks of each of the components. So our rigidity matriid has this rank up here, and I'm going to express 3 volts minus nine over two in terms of the sum of the ranks of each of the q r two components gi equals vi. Okay, so that's exactly what I do here. So the rank of the rigidity matrix is equal to the, the sum of the ranks of each of the components. And so each of the components were to, well, in fact, I haven't quite done that yet, have I? I guess I got confused. Oh yeah, yeah, that's true. So I'm using this, but for each of the components, what I'm doing is replacing the vertices, really?
00:38:05.782 - 00:38:06.110, Speaker C: Right.
00:38:06.182 - 00:38:20.234, Speaker A: So e equals, so am I being silly? Why is this equality true?
00:38:26.514 - 00:38:29.734, Speaker E: Is this the rank function in the rigidity matrix?
00:38:31.154 - 00:38:31.934, Speaker A: Sorry?
00:38:32.514 - 00:38:49.044, Speaker E: Is this the rank, are we applying the rank function in the rigidity metroid? Yeah, so that would be the rank of the generic rigidity matrix, which is 3 volts nine over two. And then.
00:38:52.344 - 00:39:09.524, Speaker A: We definitely took this and replaced the rank with this one. Yeah, I want to apply this to say that this is equal to this, but I'm probably understating it's true.
00:39:14.724 - 00:39:23.588, Speaker E: So these are the rigidity matri matrices of the induced subgraphs, right?
00:39:23.756 - 00:39:26.384, Speaker C: Yeah, those should be generic too.
00:39:26.964 - 00:39:27.744, Speaker E: Yeah.
00:39:29.244 - 00:39:45.044, Speaker A: So what I'm really, what I'm really doing is saying the rank of this whole thing should be equal to the rank of this k four plus this k four plus this k four for the three components. So I missed a. Was it will? Was it you that made a comment there?
00:39:45.504 - 00:39:54.804, Speaker C: Yeah, well, I was just saying that the components are generic too. Right. So then you're.
00:39:55.784 - 00:40:00.164, Speaker A: Oh, so you're just applying this to each of the different components and getting the same.
00:40:00.504 - 00:40:16.504, Speaker C: Right. I mean, the real question is, why is the rank break up on the. Why does the rank of, of the rigidity matrix break up onto components in this sum like fashion? You've got Rv equals the sum of Rvi's.
00:40:16.804 - 00:40:29.596, Speaker A: Yeah. So this, this is a matrix figure factor I'm taking for granted. But I thought. So you're saying I don't need that to give this, this equality. And that's what's confusing.
00:40:29.780 - 00:40:32.824, Speaker C: No, I think you need it. And then I think you just plug in.
00:40:35.984 - 00:40:48.960, Speaker A: Oh, you're right. So sorry for this delayed one. So this is re. And this is re. Some of Rei. Yeah. Yeah.
00:40:48.960 - 00:41:28.464, Speaker A: So I'm sorry, this is, this was just me being silly. So what I was worried about is I didn't seem to be using this, but I am. I wonder if Christophe can do some fancy editing to the video or you can all just watch me struggle if anyone rewatches later. Okay, so hopefully everyone's now happy with this equation. And then the next one's obvious because I just took nine over two outside the sum, so I times it by Q. Okay. And now I know from the previous lemma that EI is at most three vi minus six.
00:41:28.464 - 00:42:04.364, Speaker A: And so I can replace free vi with ei plus six. Yeah. So that's what I say here was justifying this part. And so now I'm going to continue with this, but all I'm going to do is take the six out. So six q, which is really twelve over two, q minus nine over two. Q is three over two q. And then every edge was in some components, some two reals, connected components.
00:42:04.364 - 00:42:27.320, Speaker A: So the sum of the ei is equal to e, and hence we can rearrange. So we have this thing which if we go up, is equal, equal, less than, or equal to equal, equal. This thing. I think that's where we're going to. Yeah. And so we rearrange and say e is at most the free v minus nine over two we had there minus the free q over two. That's here.
00:42:27.320 - 00:42:49.694, Speaker A: And then these nine and three give me minus twelve over. Sorry. Well, if q is one, but q is obviously at least one. And so another inequality gives me the minus six. I want to finish the theorem. Lemmer, whatever it was. We were, we were proving.
00:42:49.694 - 00:43:30.624, Speaker A: Okay, so I got lost in that. But did everyone manage to follow? So we were proving minimally, redundantly. Rigid graphs have at most three v minus six edges. We looked at all the possible r two connected components and we used our, basically just a standard factor matriarch theory that I was omitting and asking you to believe. And we used the lemma before, which told us how many edges you upper bound in the number of edges in an two reals connected component and then just did some calculations and it came out with the number we wanted.
00:43:31.684 - 00:43:35.344, Speaker D: Could you repeat the standard fact from matroid theory?
00:43:35.764 - 00:44:29.844, Speaker A: Yeah. So it tells us that if you take the rank function of a set, then you can express that as the sum of the rank functions of each of the components. So the matriarch may not be two reals connected itself. So the graph of the matrix may not be, but it will have some number of two reals connected components. It might be that some of these are just single edges that don't really go into any, any component of a wise, but you get that this equation happens. So I guess my first direction would be to this reference to see where. I'm not sure if teabour proves it or if he references this off somewhere as well, but maybe it's not so hard to prove.
00:44:30.384 - 00:44:35.044, Speaker D: And the components e, sub I, they have to be r two connected.
00:44:35.424 - 00:44:38.112, Speaker A: Yeah. Or single edges if they're, they're not.
00:44:38.288 - 00:44:39.164, Speaker D: Okay.
00:44:42.384 - 00:45:09.564, Speaker A: Oh, I've gone too far. Yeah. Okay. So I thought I'd try and get you guys thinking a little bit. So can we achieve this free? V minus six is basically a little thing I wanted you to, just to think for a minute about. So we know you need to have at least this, which is satisfied if you're a circuit. And we know k four can be achieved because it is achieved for the very smallest one just by, by chance.
00:45:09.564 - 00:45:39.044, Speaker A: But that's because the k four satisfies both this and this. And obviously as b gets larger, this one gets much, much bigger than this one. So is it possible we could actually do better than if we assume that v is large? So as I say, if you want to have a think for 30 seconds or so and see if you can come up with anything, and then I'll show you some examples.
00:45:42.824 - 00:46:13.660, Speaker B: Would it be true that if you took, if you took something that was minimally rigid in 3D with a vertex of degree three and then considered it in 2D? So I think that would be redundantly rigid, but I don't know if that says I don't know if that'd be minimal, actually thinking about it. Well, no, forget it.
00:46:13.692 - 00:46:26.924, Speaker A: Sorry. If you're minimally rigid in 3D, then you're free connected. It's not so obvious you're going to be redundantly rigid down a dimension, though.
00:46:30.624 - 00:46:45.874, Speaker B: I think that would follow from Gaultler, Healy and Thurston's second result. In their paper, they show global flexibility implies. I don't know if that's a good term. Not globally rigid implies not rigid.
00:46:45.914 - 00:46:55.134, Speaker A: The dimension above, I think. Yeah, yeah. And so then, then what? You said the minimality suddenly becomes.
00:46:56.154 - 00:47:01.210, Speaker B: Yeah, maybe it's not minimal, though, because you're looking for minimally redundantly rigid, aren't you? So that's.
00:47:01.402 - 00:47:11.066, Speaker A: Yeah, okay. Yeah, sorry. So what's a specific question?
00:47:11.130 - 00:47:32.684, Speaker C: Actually, though, I like that. If you take something that's minimally redundantly rigid and in three space and you project it, do you automatically get something that's got some redundancy in the rigidity? Is that forced on you? It's not at all clear to me.
00:47:33.504 - 00:47:50.544, Speaker A: If it's minimally rigid in 3D, then I think Sean's saying from a gottliehealth first time result, it will be redundantly rigid in 2D. If you're redundantly rigid in dimension D, you're definitely going to be redundantly rigid in dimension D. Minus one or anything lower.
00:47:51.124 - 00:48:05.024, Speaker B: It's not a completely trivial result. It's not just immediate. Oh, sorry, I had an amber alert or something. Yes. I don't think it's immediately obvious.
00:48:06.884 - 00:48:07.624, Speaker A: But.
00:48:09.304 - 00:48:11.648, Speaker B: Yeah, I guess it's the minimality is the problem.
00:48:11.696 - 00:48:13.088, Speaker A: I don't know if you would keep.
00:48:13.256 - 00:48:16.168, Speaker B: I don't know if you'd be minimally, redundantly rigid when you.
00:48:16.216 - 00:48:17.404, Speaker C: In the projection.
00:48:18.224 - 00:48:25.912, Speaker B: Yeah, maybe if you're like planar or something. I guess if it's like a triangulation of the sphere and you flatten it.
00:48:25.928 - 00:48:49.694, Speaker A: Out, maybe that's true, that we can draw one. Just draw a simple one. So there's a. There's a triangulation of the sphere. So think about that in the plane. Surely I can throw an edge away and still be. I just wanted to throw one.
00:48:49.694 - 00:48:52.666, Speaker A: This is probably still redundantly rigid, isn't it?
00:48:52.850 - 00:48:56.854, Speaker B: Yeah, I think you're right. That might even be globally rigid.
00:48:57.794 - 00:49:00.294, Speaker A: Yeah, yeah. Sorry.
00:49:00.334 - 00:49:02.030, Speaker B: Yeah, no, I'm wrong.
00:49:02.222 - 00:49:38.634, Speaker A: You don't get the minimality, unfortunately, for free. Anyway. There must be some condition, maybe guarantees it. But I guess if you're large enough. I don't know. Anyway, since there's not that long left, maybe I can show you an example so the example that I was going to show is the family of complete bipartite graphs with one part of size three. So first of all, k three free is even independent, so we have to go at least t, at least four.
00:49:38.634 - 00:50:30.210, Speaker A: So I've got some x's and some y's. K three four itself is a circuit, so you can check that the number of edges is two v minus two. It's got three times four edges and seven vertices. So that's easy. But what that means is that if your k three t for some larger t, then you're definitely going to be rigid, because the Leman theorem will apply. And every edge is going to be in some copy of k three four, so in some circuit, and so you're going to be redundantly rigid. So this is, this is relatively easy to check as a nice redundantly rigid graph, but it's a special kind of redundantly rigid graph, because every single vertex down here, all of the y eyes have degree free and every edge is incident to one of the y eyes.
00:50:30.210 - 00:51:07.920, Speaker A: So if you take any edge away, you get a vertex of degree two, and hence you're not redundantly rigid anymore. So every edge is needed for it to be redundant, so it's minimally redundantly rigid. So this is a family of minimally redundantly rigid graphs. But notice that k three four had two v minus two edges. But if I add one more vertex on into the part of size four, it has three more neighbors. And so I sort of go from two v minus two to 2 volts one. And then when I add another one on, I go to 2 volts plus zero, and then I can keep going.
00:51:07.920 - 00:51:43.814, Speaker A: So if I keep the scalar as a two, each time t goes up, I just add one one to the constant each time. So I get 2 volts plus something. I have to think about how that works as a free v minus something count. So this is what I said about the minimality of k three t. So how many edges does k three t have? Free t, and it's got three plus t vertices. And so you can see relatively easily. That means it's got exactly 3 volts minus nine edges for large t.
00:51:43.814 - 00:52:37.302, Speaker A: So this is a family of examples that get somewhere close to the freebie minus six. It's only three edges away, and it could be very large. And in fact, what Tibor was able to show is that free v minus nine is a bound. So you can improve the bound I gave from free v minus six to 3 volts minus nine, as long as you look at graphs on at least seven vertices. Okay, so there's a small exercise if anyone wants to get comfortable with very small, redundantly rigid graphs, is to check what happens on five and six vertices. What's, what happens in the middle? So k four is the unique redundantly rigid graph on at most four vertices. If you have at least seven, then you have this, this better bound, which is achieved for bipartite graphs k three, t of any size, but on five and six vertices.
00:52:37.302 - 00:53:31.286, Speaker A: What happens in the middle? I didn't do the exercise myself, to be honest, but it is just checking a finite number of small things. So you could try that if you like. If people are willing to bear with me for the last five minutes, I want to mention one more result, which is a bit different flavour, but it is just to finish off talking about global rigidity in two dimensions, essentially. Okay, so again, this is a result from Bill Jackson and T Boy Jordan. And what it says is if the minimum degree in your graph is sufficiently large, then you're globally rigid. Okay, so we're going to take a graph on at least five vertices and we're going to suppose the minimum degree is at least n plus one over two. So the minimum degree is just about half the number of vertices, and that's enough to guarantee global rigidity.
00:53:31.286 - 00:54:27.322, Speaker A: And the proof, which I won't go into, I'm just gonna give you a very quick comment about it, is to show the conditions we've been proving to show redundant rigidity and free connectivity. One of those is easy. So to show free connectivity, here's another exercise for anyone who wants it. And this is actually a lemma from my third year undergraduate graph theory course, which says if the minimum degree in a graph is at least this, whatever that is, then the graph on n vertices must be k connected. And obviously for free connectivity that they want, you just plug in k equals free and you get n plus one over two, which is exactly the degree bound in their theorem. So applying this elementary graph theory result tells us that the graph will be free connected. And so all that remains is to show that this condition guarantees redundant rigidity.
00:54:27.322 - 00:55:15.260, Speaker A: But I will leave that out. But I think it's kind of nice to have these sort of results that guarantee global rigidity or guarantee redundant rigidity because they're not the simplest combinatorial properties. And so having simple combinatorial things like this and other results exist are kind of nice, I think. Think. So next time on, on Friday, what do I plan to do? It's going to be the 12th isn't it? Yeah. So on Friday I plan to return to rigidity rather than global rigidity, but I want to start thinking about non generic rigidity in certain sense. So I'll talk about frameworks in three dimensional space that are embedded on the sphere.
00:55:15.260 - 00:55:42.224, Speaker A: So I'll talk about frameworks on the sphere and do this by what's called coning, which we talked about a bit. And if I have time, I'll talk about vertices that aren't just free to move wherever you like, but they're pinned or they're restricted in some way to a smaller dimensional, say, an affine subspace. So we'll get into that kind of topic from Friday. Does anyone have any questions before we finish for today?
00:55:45.494 - 00:55:47.114, Speaker C: There's a question in the chat.
00:55:47.414 - 00:56:02.594, Speaker A: Oh, yes, let me just. Do we require that removal of any edge gives a, I guess red is redundantly rigid graph.
00:56:03.534 - 00:56:15.254, Speaker E: So like when we say redundantly rigid, we say that you g minus nee is rigid still, right?
00:56:15.594 - 00:56:25.242, Speaker A: Yeah. So it's redundantly rigid if G minus e is rigid, but it has to be true for every single edge. So you look at g minus e, g minus f and so on, and they all have to be rigid.
00:56:25.378 - 00:56:29.534, Speaker E: So for minimally redundantly rigid, is that, is it still for ne?
00:56:31.034 - 00:56:50.354, Speaker A: So for minimally redundantly rigid, yes. So let me, let me write it. So G is minimally redundantly rigid if G minus E is not redundantly rigid for all edges. So every edge you pick has to be needed to make it redundant.
00:56:50.654 - 00:56:53.594, Speaker E: Yeah. Okay. Thank you.
00:57:00.954 - 00:57:26.654, Speaker C: I had a question. It's kind of a dumb question, but is it possible to characterize the graphs that are both rigid and also have rigid complements so they can't have too few edges? But they can't have too many edges either.
00:57:27.724 - 00:57:34.304, Speaker A: So by rigid components, are you happy that this is a rigid component of this graph?
00:57:34.724 - 00:57:35.940, Speaker C: Sure. Sure.
00:57:36.092 - 00:57:39.344, Speaker A: But I guess you're not happy that this is a rigid component.
00:57:40.284 - 00:57:44.624, Speaker C: No. So all I'm asking is the g and g complement.
00:57:45.164 - 00:57:46.204, Speaker A: Oh, the complement.
00:57:46.284 - 00:57:50.144, Speaker C: The complement of G should both be rigid.
00:57:54.984 - 00:58:03.416, Speaker A: So I never thought about this. So the complement, meaning you take or say if this is the graph, then the complement is this one.
00:58:03.520 - 00:58:04.764, Speaker C: That's right, yeah.
00:58:05.304 - 00:58:28.704, Speaker A: Yeah. So I mean, we know the number of edges in G plus. The complement is the number of edges in the complete graph and say we're in the plane, then they both have to be at least this, right? So probably you can do some trivial counting to get an idea of what might be possible. I've never tried this. Yeah.
00:58:31.604 - 00:59:01.284, Speaker C: I mean, I just did exactly what you did. Kind of a quick thing. If we require equality, if we're looking at like minimally rigid g and minimally rigid g compliment, you can't find such a thing. But if you, if you allow yourself a little bit extra flexibility, it strikes me that we maybe could find such things. And in fact, it might even be pretty, almost kind of ubiquitous if you, if you had v really large.
00:59:01.704 - 00:59:08.284, Speaker A: So you're saying you can't have minimal for both, so that this equation has no solutions. No. Okay.
00:59:09.584 - 00:59:11.244, Speaker C: Or no integer solution.
00:59:11.634 - 00:59:38.902, Speaker A: No integer. Yeah. So I guess, I mean, two v minus three is so much less than this, the number of edges in the complete graph. So if you're sufficiently big, it's probably likely that both G and its complement are. If you just put one down at random. I mean, that's right. But I mean, that's just talking about the total number of edges.
00:59:38.902 - 00:59:41.994, Speaker A: We're checking that they're also sparse.
00:59:42.494 - 00:59:43.278, Speaker C: Yeah.
00:59:43.446 - 00:59:43.790, Speaker A: Yeah.
00:59:43.822 - 00:59:45.462, Speaker C: I mean, it's good.
00:59:45.478 - 00:59:49.438, Speaker A: Amusing. I'm not sure what it would be useful for, but it's kind of a fun little question.
00:59:49.606 - 00:59:50.294, Speaker C: Right.
00:59:50.454 - 00:59:53.154, Speaker A: It might be nice to establish.
00:59:54.254 - 01:00:18.294, Speaker C: Yeah, I wonder, there may be like the first case where you can get such a thing may turn out to be something that you can actually classify. I'm not sure what number that would be, but they're like, you need v equals eight or something like that, or whatever to be able to even possibly get such a thing. But then once you do, maybe there's not that much room.
01:00:18.674 - 01:00:45.224, Speaker A: So probably the one dimensional question, because there what? You want each graph to be connected. That's probably been studied and probably in the trivial undergraduate results somewhere. Saying some condition that forces G and its complement to both be connected fails to immediately what it would be. Yeah, I should get rid of this because I thought you said component rather than complement, so I was just being silly with my answer there.
01:00:48.524 - 01:01:01.914, Speaker C: Yeah, well, Alex's comment is good one, too. Might be interesting to consider how many rigid graphs a large complete graph can be partitioned into. That's actually a lot closer to the thing that we just scribbled out.
01:01:02.454 - 01:01:03.234, Speaker A: Yes.
01:01:03.614 - 01:01:09.142, Speaker C: Anyway, kind of amusing. It just occurred to me during the talk and I thought, I wonder if.
01:01:09.158 - 01:01:33.394, Speaker A: It'S just Alex's comment. I mean, if you can, if you got a one dimension, then there are a lot. Then there are results, sort of easy results. Talking about decomposing complete graphs into two factorizations, say, and so into cycles, into Hamilton cycles. So they would all be rigid on the line, but into two dimensional rigid things say yes. Could be interesting too.

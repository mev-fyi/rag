00:00:01.720 - 00:00:59.334, Speaker A: Okay, so we are continuing discussing forced and forced crossings. So again, what is avoidable set here? So here for this analysis here, the avoidable set is everything. Notice that this analog, if you start at time t equal to zero, this is totally non avoidable angles. Nothing intersects the boundary you can cross at any time. But at this time t. Now this is already conditioned, right? So you condition on what happened up to time t. And then this Anole, its intersection with omega T consists of two parts.
00:00:59.334 - 00:01:45.094, Speaker A: Both of them are avoidable. Let's look at this example. So here this is absolutely unavoidable. So here the avoidable set is empty because again, this intersection has one component and this component, well, disconnects gamma of t from b and it was unavoidable to begin with. Now let us look at more interesting picture. So this is our analysis here. And our curve crossed it already by time t and returned.
00:01:45.094 - 00:02:57.394, Speaker A: Then this part, the blue part of the curve, is avoidable. So you see this has three connected components, intersection of the anoles with the domain one, two, three. So one and three are not avoidable. You have to cross them to get to b, but this one is avoidable. Again, why is this whole discussion? Because as I mentioned, what we would want to do is to make sure that avoidable crossings don't happen too often. The curve can try to double back on itself, but it does, it chooses not. But on the other hand, unavoidable crossings, while that's easy, okay, so now we say that gamma from t to one.
00:02:57.394 - 00:03:28.564, Speaker A: So the remaining of the curve makes an unforced crossing of the angle. Say if it has a crossing which is contained in aut. So for example, this is not unforced crossing. This is very much forced crossing. On the other hand, this crossing is very much unforced. So we want to avoid unforced crossings of the crossings which would be entirely contained in AeT. Of course, remember, curve doesn't cross itself.
00:03:28.564 - 00:04:32.783, Speaker A: So the crossing is either entirely contained in a UT or doesn't intersect it at all. So remember this, that crossing contained is the same as crossing intersected in this context. And now the formulation of case condition. We say that the family gamma del satisfies companions Smirnov condition if there exists some c bigger than one and p bigger than one, such that for any stopping time for any delta and for any analysis of modules at least c. So Cr is less or equal than r capital probability that gamma delta of t one makes an unforced crossing of a. So crossing in the unforced region condition. Of course on gamma of zero t, this is less than p.
00:04:32.783 - 00:05:35.212, Speaker A: Okay, so p can be arbitrary close to one, but it's less than one. So you cannot make enforced crossings. This probability, this probability equal to one. Okay, now there is equivalent reformulation is that the probability of making this crossing is bounded by constant times r over r to the power. So that is a polynomial rate of decay of this probability. So this is actually pretty standard in this business. The moment you have less than one, you immediately get a huge rate of decay.
00:05:35.212 - 00:06:20.544, Speaker A: Alpha can be a small number, but still, it's already polynomial rate of decay. Okay, so let me prove the equivalency. Of course, we only have to prove that this implies this. This is definitely much stronger. So the idea of the proof of equivalence is the following. You cut off r over r to about log r over r of concentric links with ratio c with the c, okay? And then to cross it unforcefully, you need to cross log r over rings. Each of them happens with probability p.
00:06:20.544 - 00:07:42.074, Speaker A: So the probability that all of this happens is the product, because, you know, the probability to make next force crossing is pulled and they just start piling up. So p times p times p is bounded by p to the power log r over r, and this p to the power log r over can be rewritten as r over r to some power. That's all. Okay, so if in the future I will need to make a comment like this, that if you know that you can cross all the anomaly of certain ratio with probability no greater than something, then it immediately implies this. Another thing that they observed that actually this condition is conformally invariant, at least while it's equivalent to conformally invariant condition, then you really don't need to cross real annually. You can cross any sets which are conformally equivalent to annually sets, doubly connected sets. And again, condition cyclone, you can prove it.
00:07:42.074 - 00:08:44.134, Speaker A: And now, so this case condition implies the following theorem, which is obviously due to Campanian and Smirnov, and which gives us finally what we want in terms of tightness, completely. So suppose that you have a family of random curves. So for each delta you have a random curve gamma delta. So for each delta you have a measure. And suppose that this family satisfies uniform case condition means that case condition, say here with uniform p and c, which would lead of course, to uniform crossings here. Then the first thing to notice is that it satisfies Eisenman Berchard condition. So it is pre compact, so it has uniform tortoise bound.
00:08:44.134 - 00:09:36.444, Speaker A: And then from this you can also derive that lambda k tends to infinity. Again, this just follows from case condition and sum walk. Now let us map our domain to the half plane and let's define new random curve. Well, it would be a random curve in the upper half plane. So this is just the images of this. So it's a curve from now zero to infinity, kth it's corresponding hals. So remember that kth it's component.
00:09:36.444 - 00:10:48.436, Speaker A: So instead of unbounded component of h minus gamma hat from zero to t. No, okay, sorry, it's. Let me be more careful here. Omega t hat, those are some bounded components and kt hat would be h minus omega t hat. So this is all which is swallowed by the curve, remember? And then the claim is that almost surely this is really what we want. So this is strictly increasing and a of t tends to infinity. So which means that you can parameterize this kt.
00:10:48.436 - 00:12:17.934, Speaker A: So you know there are no followings, no double crossings here. Now, condition number three already deals with driving process. So you can have driving process for this, because this condition hold half plane capacity is strictly increasing. So now if you look at the driving process for kt head, then turns out that this is alpha holder for any alpha less than one half. So this is again something like brownian motion already appearing here. And again, it's with random constants, but the bounds would actually depend on ks constant, then not just that, they would be would have bounded moments, more than that, bounded exponential moments. Remember that even in Schramm's theorem, we had to assume that expectations driving force exists, otherwise there was nothing to discuss.
00:12:17.934 - 00:14:06.714, Speaker A: And then here we can say much more that similar to brownian motion, expectation of epsilon times ws normalized by square root of t. So normally not only you can take driving for function at certain moment, you can take maximum of driving function, divide by square root of t, and then exponent for small epsilon is actually integrable and bounded by some uniform constant. So this is very important for again all the proofs of convergence, as you will see. And now, if gamma delta satisfies this case, and this is as above, then if gamma del ten weakly converge to gamma with respect to uniform conversion, so, meaning that weekly converge in the distance of the metric space of uniform convergence, this is the same as the driving forces converge uniformly on every compact. So for any finite time. So remember I told you these two are in general very different things. But if you know a priori that you satisfy case conditions, then life is great.
00:14:06.714 - 00:15:44.668, Speaker A: You just know that one convergence applies the other. So, which means the following, if you have weak limit, then it is supported on Levner curves, because for any weak limit, well, you can first take weak limits for convergence of driving functions. And voila, there would be convergence of curves to some curve, which would be Levner curve. So then there is a fine point which I tried to avoid for the duration of this course, but it will come eventually to buy. You see, all our models we take, okay, so we have domain usually. So let me draw a picture of domain. We have point above, and then we can see the lightest approximation to this, right? So say lightest approximation, and we take some lightest domain here, and the curves which we consider they are not in the domain omega, and they are not running from a to b.
00:15:44.668 - 00:17:09.414, Speaker A: They enlighten approximation of our domain, and they are running on the lightest from some approximation to point a to some approximation of point b. And so the question is, how do I address this? All these convergences are nice, of course, but can you say that these curves which are not running from a to b would converge somewhere? And so here comes this very important step. So suppose that omega n a and b n converge to omega Ab in cursor, which means that conformal, corresponding conformal maps can be chosen to converge uniformly on compact sets. So you can select here and here map sites that phi and converges to phi, uniform and compact sets. Why am I so careful? This thing can be chosen because of course, this is, there are many maps like this. Remember, you can multiplying by any positive number, it still would be a good find. So there is no way to canonically choose it.
00:17:09.414 - 00:17:53.214, Speaker A: So I'm saying, okay, you can choose a map size that this would converge here, and this would. So this would converge to this. So you can choose maps of n five such that this is true. And now we want convergence. And convergence would be very interesting. So we fix some neighborhoods of a and b, and let's define Omega Tilde to be omega without this neighborhood, and omega n would be the. You map this omega Tilde by phi, and then we do fine, inverse.
00:17:53.214 - 00:18:51.754, Speaker A: And you get this, so sorry, it's not till that's hat. So, so you can formally redo it. So let me try to draw the pictures here. So you take two neighborhoods here, you map it by phi to h. So this would, okay, so let me map it by Phi. They would be mapped to neighborhood of zero and infinity. And then you map things back by phi and inverse.
00:18:51.754 - 00:19:32.654, Speaker A: And you are kind of excluding neighborhoods of n and bn. So you take a domino again, and you exclude corresponding neighborhoods of n and b n. So conformally crisp. Okay, now here comes the kicker. So let gamma n from n and b n satisfy uniform companions, burn off condition. But here is the real life situation. These gamma are not running the same domain, omega.
00:19:32.654 - 00:20:20.944, Speaker A: Then they kind of have a limit. But you need to exclude these neighborhoods of a and b, because who knows what happened there. So the claim is that they have this consequential weak sub limit satisfying companion Smirnov condition outside of Ponzi. And you can actually improve it to the whole thing if you forget about uniform condition and introduce new metrics. For example, if you introduce uniform cursor, then you can deal with the whole domain. But let's not do it here. Okay, so that's it.
00:20:20.944 - 00:21:08.864, Speaker A: That's finally, this condition six is exactly what we need. There is a subsequential limit, maybe outside of some neighborhoods of points a and b. And there is definitely a limit in the model domain, the half plane here. And as I promised, I stated everything for chordal revolution here. But that is not important. Absolutely, you can do exactly the same for it. And the same theorem holds.
00:21:08.864 - 00:22:18.494, Speaker A: Okay, so now, armed with this exciting theorem, I want to give you finally an example of how it all works, because this is how you have theorem. So far, we haven't proved convergence of anything. And let me prove the theorem, which is the convergence of exploration process for critical probability. Historically, this was the first result which says that interface converges to sla Kappa. So, well, it was first proven, it wasn't the first written, but this is where it all started. And of course, the proof I will give is more modern than the original proof, because, for example, it relies on the companions Mernov result. So in original versions, Smirnov had to essentially prove everything by hand.
00:22:18.494 - 00:23:18.002, Speaker A: And there were lots of technical details. But again, most of the technical details are now in the saxyamatic campaign in Smirnov framework. And the main thing we actually already did, we already proved in the very beginning of the course that card is Smirnova observable converges to the limit. Let us prove that exploration process for critical percolation converges to SLA six. So this is very special SLA. But again, we would only be able to do it in one situation where we know that Cardi Smirnov observable does indeed converge. That happens only for now, for this sort of percolation.
00:23:18.002 - 00:24:06.226, Speaker A: So, let me remind you what we are doing here. So, we consider hexagonal lattice. For each face of this hexagonal lattice, we flip a coin and we color a face blue or yellow, depending on the outcome of the flip. So, that's critical percolation on hexagonal lattice. Now we introduce boundary condition. We can say that in our domain omega, all the hexagons, which stage are from a to b here will be blue. All hexagons from b two a would be yellow.
00:24:06.226 - 00:25:02.134, Speaker A: And then we flip coin for all other hexagons. And then we can draw a unique interface between blue and yellow path. So the interface which would have yellow on the left and blue on the right. And this would be our interface from a to b. Notice very carefully indeed, we already had this discussion that this is not in general interface from original a to original b, this interface to an, on the lightest approximation of a to bN, on the lightest approximation of b. But again, we already know how to handle this. And as we discussed again in the beginning of the course, this process can be thought of as the following.
00:25:02.134 - 00:25:28.366, Speaker A: We do. We start doing it dynamically. So, initially all the field is white, except for the boundary, which is blue and yellow. And then we started, say, at this point, yellow on the left, blue on the right. And we see what to do. We come to the hexagon. So we face a hexagon.
00:25:28.366 - 00:26:00.124, Speaker A: Now, if it was already colored blue, we turn left. If it was already covered yellow, we turn right. If it wasn't color, then we go left or right with probability one half. According to what, we flip a coin, we color this guy, and we turn left or right. And we keep doing this. Eventually we have to end up at point b, because that is, this is the only place where we cannot. So this is our exploration process.
00:26:00.124 - 00:26:55.468, Speaker A: Again, to get it, you don't really need to know the whole picture. You just can exploit that. The reason for exploration, and the first statement that I want to prove, is that this critical percolation exploration process is Fischer condition. Well, proof is probably a glorified statement of what I will say. I will just explain why it is true. So, remember that we had in the very beginning of the course, a lem of Russo, Simon Welch, that if you have an analyst, and sorry for inconsistent notations, I just noticed that from the beginning of the course, I changed notation too. So there is sub index here.
00:26:55.468 - 00:28:30.766, Speaker A: So, okay, so you have an animal of inner radius r ater range to r, and r is much bigger than size of your percolation. Then the exist q such that probability of blue crossing, of having a crossing of the sandals is between one minus q and q. So generally you just cannot always cross. And it's kind of obvious, right? So that something like this should hold. But then what does it mean? It means that if you want to cross this annulus unforcedly by this guy, so what does it mean that you cross it? Unfortunately, you can say, okay, I already know my guy up to certain model the speculation. So why don't I just color everything inside of this analysis by just flipping coins? I color it and with certain probability I don't get across it where I shouldn't have it. So maybe again, if I am in region where I am forced to cross something, what does it mean? It means that there was already crossing at the boundary.
00:28:30.766 - 00:29:23.524, Speaker A: So you have a blue crossing at the boundary somewhere. But if I'm not forced to do it, the probability that this forcing appears is less than one. That this crossing appears, it's less than one. So, probability of unforced crossing is bounded by one minus Q four, say this capital r, which are much bigger than. So, okay, so we have case condition. So this already gives us a lot. We don't have to prove that subsequential limits live on Leonard curves.
00:29:23.524 - 00:30:14.214, Speaker A: All we have to show is that if we take a subsequential limit and take a driving function of the subsequential limit, then this driving function should be brownian motion. That's all you have to prove, because everything else is now taken care of. Convergence. So, one more thing. You take subsequential limit of driving functions, you don't even need to take subsequential limits of curves because convergence of driving functions is equivalent, in the presence of case condition, to the convergence of curve of curves. So you just take subsequential limit of driving functions. They would be, this subsequential limit would be brownian motion.
00:30:14.214 - 00:31:22.418, Speaker A: This would mean that driving functions would converge to brownian motion, run with speed six. And that would give us everything, because this would mean that the curve converge in our nice topology to the curve there. Okay, so now let us try to look. How do we get this convergence of training functions? And the only thing we know so far is the Cardiff formula, or as a Cardi Smirnoff observable. So let's revisit it. So we have a conformal rectangle. And suppose, and as before, this c delta of omega ABCD would be the probability of having a blue crossing from Ab to CD.
00:31:22.418 - 00:32:11.874, Speaker A: Let me try to draw a picture here. So this is my conformal rectangle. Okay, sorry. ABCD. And we look at the probability that we have a blue crossing here, and we know that this probability, when delta goes to zero, tends to conform an invariant limit. That's Smirnov theorem, which we already proved. So let me remind you that if you don't have blue crossing here, you have.
00:32:11.874 - 00:33:22.054, Speaker A: So alternative is to have a yellow crossing here. So either you have a blue crossing or do you have a yellow crossing outside. Now remember, we used to parameterize all of this by map to the triangle. And things were exceedingly nice because then this limit when delta goes to zero was just the position of image of d on this triangle section on the side of the triangle. Now we want to do something very different. I want to consider the map of our conformal rectangle to the upper half plane with the following normalization. So I want to map a to some one minus x, b to one, c to infinity and d to zero.
00:33:22.054 - 00:34:06.154, Speaker A: So that's how they go. And by the way, this is a bad picture. Let me immediately correct it. So ABCD, wrong orientation. Okay, so you have this. Now the thing is the, I drew a blue crossing here, I shouldn't, because I look at the probability of having a crossing here and I claim that when delta goes to zero. So let me immediately rise.
00:34:06.154 - 00:34:55.963, Speaker A: There is no crossing here. I don't know that if I now do the percolation here, something, it would be in any way related to percolation here. I just know that the crossing probability for said percolation would be the same in the limit when delta goes to zero. Okay, and finally, what would be this limit? B. That's the usual thing you do. Christopher Schwartz we already know then when your parameterization is that you move this to the triangle. So a, b, c, d.
00:34:55.963 - 00:35:52.294, Speaker A: So when you map this to the triangle, then this probability is simply the length of this guy, as I mentioned. And so in this parameterization you just use Christopher Schwartz and you see that this is a function of this x. And again, this is specifically chosen to be one minus x because the computations are easier. So if image of a is one minus x, then the limit of this crossing probability is this f of x, which is, well, this hypergyometric function. So this is essentially just the integral s one minus s, two minus two. So normalized. Okay, so not very exciting so far.
00:35:52.294 - 00:36:42.060, Speaker A: But now I want to say that C delta is not just absorb. I kept saying absorbable. Nice. Absorbable. So what is absorbable? So here it is supposed to satisfy this domain martingale property. And that's what we really want from our observable, not that, it just that it is something which tends to something which is conformally invariant. The thing itself should be a martingale.
00:36:42.060 - 00:37:44.894, Speaker A: With respect to our exploration process, let me explain what it means. So gamma delta, let it be exploration process from a to c. So in my picture I want to run it from. Let me. So I want to run exploration process from a to c. And again, and we want to say the following thing. I claim that the crossing probability, the probability that we have a crossing if we already had some exploration.
00:37:44.894 - 00:38:37.504, Speaker A: So suppose that you do some exploration for some time t. So you started drawing your curve and you want to see, okay, what is the probability that I will join this part with this part. So I go from here to here. Okay, so I go from explore part. Remember that on this side I have yellow, on this side I have blue. So I look at this probability and I claim that this is the same as the probability that I have crossing of the original rectangle. If I know that the exploration process was exactly this curve.
00:38:37.504 - 00:39:49.234, Speaker A: Okay, so that's the martingale property that if I run my process for some time and look at this observable in the resulting domain, this is the same as the probability of having the same in the original domain, knowing that my exploration process or another path was exactly this. Because remember, this exploration process doesn't appear out of the care. It appeared from the same things which determine crossing. Crossing is determined whether you have collection of blue hexagons which go from site ab to site cd. Exploration process also cares about these blue hexagons. Okay, so why these two things are the same? Well, because we can just pair them up. So we have two cases.
00:39:49.234 - 00:40:37.716, Speaker A: Case one for side crossing in gamma and Omega would be just blue crossing, which has nothing to do with our exploration process. Just doesn't use anything at the boundary. Okay, so this would still be crossing of this domain from here to here because nothing affects it. Interesting cases, case two. And let me draw more realistic pictures. This is also part of case two. So in case two, your blue crossing intersected.
00:40:37.716 - 00:41:21.898, Speaker A: What happened with gamma intersected gamma of zero two. But you see, it intersected it exciting. But it couldn't cross it. Why? Because remember, gamma itself would be constructed from the same hexagons. And it has blue on the left, yellow on the right it has a wall of yellows which prevents you from crossing. So you intersect it. It means you look at the last point of intersection and from the last point of intersection to cd, you have a blue crossing of now new domain and vice versa.
00:41:21.898 - 00:42:23.360, Speaker A: If you had a crossing here, you can continue it using blue things on the left side of the interface to get to ab. So the probability, indeed this defines the same event. So the probability of this event is the same, so conditioned on what happened before time t, this crossing of the new domain is the same as crossing of the old domain. Now, if, or if we could say this about c naught, immediately the same thing. There is a concern here. The concern is that c naught would live on scaling limits. So remember what we would do now.
00:42:23.360 - 00:43:10.754, Speaker A: We would take a subsequential scaling limit. Some delta n goes to zero. And this condition is true for curve, which is typical for the law of c delta. So, well, it's true for any curve from the law of Z delta. But we want this condition to be true for any curve, well, or typical curve from the law of c zero. And that requires, sorry, not the law of c zero, the law of gamma zero, the law of exponential limit. That requires something.
00:43:10.754 - 00:44:02.230, Speaker A: And so let me explain what we need. Okay, so one thing from here is that expectation of these crossings of the domain. So we take the crossings of the domain. So this, again, this is random domain, right? So we take expected run up to time t or even up to stopping time t. This proof doesn't see it. And this expectation is a regional crossing probability. So, expectation of having crossings from this random domains is the same as original crossing probability.
00:44:02.230 - 00:45:10.370, Speaker A: And more than that, that's the real domain martingale condition. That expectation of the c delta conditioned on the beginning curve is the same as the crossing in the domain where we already remove the curve up to time s. Of course. Okay, so this is since, well, this is true because we can do exactly the same reasoning for the domain omega minus gamma up to time s. So this, this is indeed the same. And now what we want to do is want to take delta zero. So, as I explained, this is non trivial because here we take expectation with respect to speed delta.
00:45:10.370 - 00:45:44.330, Speaker A: And in the limit, we have to take expectation with respect to something which is totally different. Well, not totally, that's a weak limit of the things. But it's another thing. So we have to take it for a period, prime typical curve. And here, to even contemplate this, we need this a priori estimate for percolation. And I will not prove it. It will make this course too percolational.
00:45:44.330 - 00:46:50.330, Speaker A: And it will probably take me a few lectures just to introduce necessary concepts. So let me just state it for now. And this is what is called rigidity, lemma rigidity of crossings. So suppose that you have a Leonard curve phenomena starting at a such that it doesn't enter some fixed neighborhood of c, capital of c. So some fixed delta neighborhood of c. Then for every l delta I can find delta, which depends on epsilon in this neighborhood, and some d of gamma, which depends now on the k of gamma, such as the following holes. For every l curve which is close to val, this is still d of gamma.
00:46:50.330 - 00:47:42.096, Speaker A: Sorry. Which is d close. So d is a small number, which, in addition, depends on gamma. But if you are close to curve gamma, and if delta is small enough, again, this delta depends only on this epsilon that we would want to get. Then crossing probability of the new curve and crossing probability of the original curve. But continuous crossing probability would be less than delta. Would be.
00:47:42.096 - 00:48:30.128, Speaker A: Sorry, it's not less than delta, less than epsilon. So we want to make sure that not only our c delta converges to c node for one curve. For one curve, it's easy. It's. Well, it's already part of Smirnov's theorem. We want to say that in very small neighborhood, in d, gamma neighborhood, for small enough delta, delta does not. So this is very important, that delta does not depend on the curve, but distance does.
00:48:30.128 - 00:49:20.654, Speaker A: Unfortunately, because you can imagine that curve can do certain tricks which would require such that any curve which would be far away would completely avoid this trick. For example, gamma could be very close to the boundary here. And then if the curve, which would be far away, still close, but far away, would have bigger distance from the boundary and totally different corrosion probability. So there is no uniformity here. This d depends on the curve. But so this is still a would be less than epsilon. So let me again emphasize this, that c delta tends to zero rigidly.
00:49:20.654 - 00:49:46.708, Speaker A: Not only tends for one curve, it cans in some neighborhood. And it's true. Even. So, this statement now is true even if c naught is equal to zero. So when b is absorbed, o c naught is equal to one when d is absorbed. So, you see, our exploration process cannot. Well, it's a simple curve, so it can't absorb anything.
00:49:46.708 - 00:50:26.094, Speaker A: On the other hand, our Leonard curve, gamma, well, that would be SLa six. So we know that they would absorb things. So we have to prepare for this. And so, for example, if it it's b, then you cannot cross from a, from here to here, simply, well, there is nothing to cross. Or if you d, you will always cross that there is a crossing. But even in this situation, rigidity is true. Okay, and I will continue the proof of percolation next time.
00:50:26.094 - 00:50:28.234, Speaker A: Thank you. Let me stop the recording.

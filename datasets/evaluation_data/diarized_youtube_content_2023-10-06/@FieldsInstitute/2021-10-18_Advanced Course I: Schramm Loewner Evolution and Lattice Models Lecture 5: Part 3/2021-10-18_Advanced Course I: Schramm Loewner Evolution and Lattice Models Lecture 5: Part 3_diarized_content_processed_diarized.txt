00:00:03.280 - 00:01:05.590, Speaker A: Welcome back everybody. And for the last hour I will talk about things which are totally different from what we talked during two previous hours. Again, this will be some background needed to introduce sirmoleven revolution. And I'll start with a very brief review of one dimensional brownian motion. Again, we'll talk a lot about object generated by brownian motion, so it makes sense to remember what it is. So one dimensional brownian motion is a process defined on some probability space. So as usual for us, omega would be just a set f sigma algebra of subsets and p the probability measure on the sigma algebra such that for all omega and omega this bt of omega.
00:01:05.590 - 00:02:48.634, Speaker A: So when we talk about process on probability space, it means that it really function of two variables, time and random variable, which exact nature of each will not be important for us. And we will assume we always start at zero, and always our function is continuous. And then the last property will characterize it that if you have a sequence of times increase sequence of times finite sequence, then all this variables brownian motion at time t one b t two minus bt one btn minus btn minus one be independent of each other. Normal normally distributed zero mean and variance of them quadratic variance would be t one t two minus t one t one correspondingly. So from elementary properties of normal distributions, it's actually easy to see that instead of assuming c, we could have assumed much less we could have assumed that faulty of expected value of brownian motion is equal to zero for every t, and that the correlation between them expectation of btbs is just minimum of t and s. Again, from this probes you can easily derive this. Okay, so that's by definition the brownian motion.
00:02:48.634 - 00:04:05.256, Speaker A: And the first thing first is that we can have another point of view here is that this is just a probability measure of all continuous functions on zero infinity, such that almost surely follow always b of zero is equal to zero and such that if you pick any time t, then either this c or this c, which is equivalent to satisfied. So again, you can either look at it as a two parameter random family, or you can look at it as a probability measure on the space of continuous functions itself leads to the same object and well, such thing exists. This is Ethereum of Norbert Wiener and I will not prove it here. It's surprisingly not that easy. But again, I will not spend time on this. So we'll have to just believe me or read the proof somewhere that running motion exists. And more than that, it's unique.
00:04:05.256 - 00:05:15.920, Speaker A: So let's look at some elementary properties of it so if you have two random processes which satisfy this on different probability spaces, maybe then there is a measure preserving transformation between omega and omega, one which would map one to the other. So it is unique in this sense. It doesn't mean that we cannot do independent copies, any number of independent copies of this continuum of independent copies. But as an object, it's unique up to this measure preserving transformation. Another very important property is Markov property. So it states that if you pick any time s and you look at increments of brownian motion, b of t plus s minus b of S, it's again a brownian motion. How would you establish this? You just need to check the three properties, and they are almost obvious.
00:05:15.920 - 00:06:04.294, Speaker A: You start at zero. Check because you are continuous. The trajectories are still continuous. You just keep going from b of S and then correlations are the same. Well, simply because this is actually easier to check because the differences are the same. So this is indeed a brownian motion. Again, by the same reasoning, if you reflect brownian motion minus bt, it's again brownian motion, because all the correlations stay the same, and normal distribution is invariant with respect to reflection symmetrically.
00:06:04.294 - 00:07:38.442, Speaker A: Okay, so here is, remember where we finished this chordal l that there is brownian scaling for driving function. And here is the reason why it is called brownian scaling. If you take any positive c and you consider brownian motion multiplied by c, but then taken at the time t over c squared, that's, again, brownian motion. Again, the proof is very easy because this is clearly starts at zero, goes continuously, and then for the correlations, when you multiply the process by c, its quadratic correlation is multiplied by c squared. So you really need to divide time by c squared to keep, say, this identity true. Okay? And now the first thing that I will kind of prove is time reversal. So suppose that you, instead of brownian motion, you consider t b of one over t for t bigger than zero and zero at zero.
00:07:38.442 - 00:08:38.094, Speaker A: Then I claim that xt is a brownian motion. So you can reverse time, you can run from infinity and you, well, this is running from infinity and you get to zero. Okay? So now all you need to do is to check first covariances. So, expectation of tbo one over t s b of one os is well, stout expectation of b one over t one. This is just minimum of st, because again, this expectation of this would be minimum of one over t, one over s. So one over maximum over st. So st divided by maximum is equal to minimum.
00:08:38.094 - 00:09:29.266, Speaker A: So, okay, so correlations are good. Continuity for positive t is obvious. What about continuity at zero, to look at rational times. So at rational times xt has exactly the same distribution as brownian. So for rational times, limit of x t when t goes to zero and t is rational. And we need countability here is the same as limit of Browning and Mosch, because again they, since they distributed the same, they agree almost surely. So that's why again we need, so this would be a recurrent topic.
00:09:29.266 - 00:10:00.624, Speaker A: That's why we need countable set here. Because if I do almost surely, uncountably many times, I can get sick of full measure, of full probability. So that doesn't work. But if I do it countably often, this still would hold almost surely. So x t almost surely has the same distribution as bt. For every given t b, t goes to zero. So x t goes to zero.
00:10:00.624 - 00:10:54.784, Speaker A: And now since q is densenar, we see that the limit when t goes to zero of x t is equal to zero, because again, for continuous function, it's enough to prove the limit only at rational point, only on that side. And this is x of zero. So x of t is actually continuous. That finishes the proof. And of course, this immediately implies, in easy version of growth at infinity, that bt grows slower than t will have much better theorem later, that with probability one, bt over t goes to zero, because bt over t is x of one over t. And as we know, x of one over t goes to zero. Okay, so this is time reversal.
00:10:54.784 - 00:11:44.774, Speaker A: And now very important property of brownian motion, which is existence of quadratic variation. So, let me first define the quadratic variation for a general process. So, suppose that x t is a real valid process. We say that x has a finite quadratic variation, time t. If for. If we can do the following. Take a partition of the interval from zero to t and look simply at the sum of the squares xti minus xti minus one squared.
00:11:44.774 - 00:12:42.274, Speaker A: And now let the size of the partition, the maximum distance, as usual, between ti and ti minus one, go to zero. Then we claim, well, that's the definition that limit and probability of this sum of xti minus xti minus one squared. Well, it's actually the quadratic ratio. So that's the notation. So let me draw the contrast with what we usually know. So we usually like to integrate with respect to functions of bounded variation, where instead of square, you have absolute value here. So, having finite quadratic variation on zero quadratic variation means that of course, we cannot have bounded acceleration.
00:12:42.274 - 00:13:45.006, Speaker A: So, one of the challenges of Italy, integration of stochastic integration would be to integrate with respect to objects, we just have quadratic variation. So all we know for now is that if it exists, it's an increasing and in general, random function. Except that, of course, this random part disappears for brownian motion. So, the first interesting theorem which I would present here is that quadratic variation of brownian motion is actually just t. So it's nothing else, just t. And the proof uses very important formula, which will actually be useful to us at the end of the course. It's Vicks formula, and it tells us how to take expectation of product of centered normal variables.
00:13:45.006 - 00:14:33.366, Speaker A: So, let me remind you that centered means that expectation is zero. And it's due to italian mathematician Jan Karlovic. And so actually, well, he's not mathematician, he's a physicist, mostly, yes. So, expectation of the product of n variables is the following. You consider all perfect matchings of one and n, so you separate it in two pairs in all possible ways. In particular, when n is odd, there is no such separation. So you consider all these pairings, let's call them IKJK, and then you take the products of expectations over all these pairings.
00:14:33.366 - 00:15:38.500, Speaker A: So, pairwise expectations, as you know, for normal variables, they define all other properties, they define total distribution of them. But this particular formula actually tells us how to find this product. So, the expectation of the product is just, you take perfect pairings, you take the product of expectations over pairs, so, products of correlations, and then you just sum it up. So, in particular, that's what we will use here. But again later, we'll use the full formula, that expected value of x to the four. How to obtain it? By this formula, there are four instances of x. There are three ways to perfectly pair them, right? So, these are four times three divided by four, three ways to perfectly pair them.
00:15:38.500 - 00:16:51.964, Speaker A: But each of them, each of the perfect pairings, involve pairing x's with x's twice. So, three times e of expectation of x squared squared. So, expectation of fourth power is just three squares of quadratic correlation. Let's prove fixed formula. And for this, we will use the standard machinery here, characteristic functions. So, let me remind that if x is a normal variable, then expectation of t is just e to the minus t squared sigma over two, where sigma is just quadratic variation, expectation of x squared. Okay, so for now, let's look at expectation of the product of e to the ti xi, where ti just variables.
00:16:51.964 - 00:18:10.134, Speaker A: So now let's remember that this guy, sum of the normals with coefficients, is still normal. So, expectation of this by this exciting formula is just expectation of one half times expectation of sum of ti xi squared. And so this would become expectation of one half sum of ti tj, expectation of x I xj. Okay, so now let us try to expand it in two ways. One way is we look this expectation, we write this guy, so we expand each of them separately. So this is expectation of the product of one plus ti, xi plus one ti squared, xi squared, and so on. So we just do the expectation.
00:18:10.134 - 00:19:03.864, Speaker A: And so what we're interested in is a coefficient in front of t one t two up to t. That's why I said that this would be variables. And this is expectation of the just product of xi. Of course, because the only way to get t one t t is just to take this times this times this. Okay? So we can either expand this term immediately, or we can try to look here. So let's expand this guy. So this would be just expectation of sum of I less than j t I t j plus one half, expectation of xi with x I.
00:19:03.864 - 00:19:40.252, Speaker A: And now we just expand each of the exponents, right? So this is a product of exponents. We just expand them. So we just expand each of them in the Taylor series. And we look for a coefficient in front of t one t two t. And the only way to get the coefficient in front of t one t to tan, well, you cannot get it from here. No, not from here. So the only way to get it is to look at perfect pairing.
00:19:40.252 - 00:20:42.374, Speaker A: So you take the product of the guys here, which include all the coefficients, and that would be exactly this, and you are done. So again, we just look at the Taylor expansion of this with respect to t I s. And if you look at the coefficients in front of t one t two tn, you can easily see that you can get lots of other formulas this way, if you look at other coefficients. But yeah, this is Vicks formula. And again, out of the whole Bqs machinery, we'll just use this identity. Okay, so now let us improve the quadrate equation formula. What we'll prove is slightly more.
00:20:42.374 - 00:21:18.384, Speaker A: So, here we want to show that this converges here in probability. It actually shows that it converges on l two. So we'll show that the expectation of the sum minus t, expectation of the square, tends to zero. So, which means that it converges an l two norm. So since it converges n, it converges in probability. Of course. Okay, and so how do we do it? We simply write it down as well.
00:21:18.384 - 00:22:02.764, Speaker A: We just separate t. So we just give b of ti minus b of ti minus one. And here we get ti minus ti minus one. So we just entered different parts of t corresponding to the intervals in the summation. And so now let's take the square, let's open the bracket. So this would become expectation of the sums of bti minus bti minus one to the fourth minus two sums. Expectation of minus two sum of bti minus one squared.
00:22:02.764 - 00:22:46.334, Speaker A: Ti minus ti minus one plus sum of ti minus ti minus one squared. Okay, so now let's computed, you know, that expectation of bti minus bti minus one squared is ti minus ti minus one. So, by week's formula, expectation of the fourth power is three times ti minus ti minus one. So this sum after you take expectation becomes three sum of ti minus ti minus one. Now here, this is deterministic. So you just take expectation of this guy. So this becomes ti minus ti minus one squared.
00:22:46.334 - 00:23:28.874, Speaker A: And then finally we add this sum of ti minus ti minus one. And this is twice sum of ti minus one squared. So, which is bounded by two times the maximum number, the maximum distance between times the sum of ti minus ti minus one, which is t. And this tends to zero. So that's it. So, brownian motion has quadratic variation. And this quadratic variation is just very deterministic.
00:23:28.874 - 00:24:26.764, Speaker A: As we will see, quadratic creation is kind of natural time for processes like brownian motion, for martingales and local martingales. And brownian motion is immediately kind of in this natural parameterization. So the usual corollary of such results would be that almost surely brownian motion has infinite variation. So it's not bounded variation, it's infinite variation of any interval ab. Well, that's easy. We know that sum of bti minus bti minus one squared tends on probability to b minus a when size of the partition decreases to zero. So we can select a subsequence which stands almost surely.
00:24:26.764 - 00:25:30.604, Speaker A: And now observe that the sum is bounded by the maximum of bti minus bti minus one multiplied by variance of b from a to b. Right? Because again, square is bounded by supreme times. The sum of absolute follow. Now pass to the limit and notice that brownian motionless continuous of this happily tends to zero. And we just see that b minus a is less equal than zero times variance. So if variance less than infinity, we arrive to a contradiction. So not only brownian motion is sometimes not nice, it's always almost surely it's not nice on any interval.
00:25:30.604 - 00:26:37.054, Speaker A: It's infinite variation. But still we would be able to integrate with respect to it. And here, let me list some continuity properties of brownian motion without proving it. So first, let's look at oscillation of brownian motion. So let's take brownian maximum difference between brownian motion in two points, which are at most epsilon from each other. Then with probability one, this maximal oscillation behaves like square root of t. Well, with this very precise format, the theorem of Lv, that it's actually two t log one over t to the one half.
00:26:37.054 - 00:27:59.266, Speaker A: So this probability one oscillation, epsilon oscillation of brownian motion, about two epsilon log of one epsilon to the one half, and actually to the point that ratio of them tends to one, exactly one. More than that, we have a law of iterated logarithm. So when t goes to zero, brownian motion isolates like square root of two t, log log of an over t. Okay? And so when you apply time reversal, you see that the same behavior persists at infinity. It also at infinity what we proved that it behaves slowly than t, but actually it behaves like square root of two t, log log of t. And more than that, for a given t, it's very important, it's forgiven. T truly b of t plus s minus b of t behaves like square root of two s log log s.
00:27:59.266 - 00:28:49.854, Speaker A: And in limb soup, brownian motion oscillate. So there will be lots of points where b of t plus s is equal to b of t. But when you take limb soup, this deviation would be about square root of two s over log log s. So, remember when we discussed shoulder continuity of brownian motion? It barely, barely fails to be one half continuous. It's slightly worse than one half helder, because there is also logistics term here. So definitely brownian motion as a driving function would not satisfy lean theorem. So that's what I wanted to say about general brownian motion.
00:28:49.854 - 00:29:36.884, Speaker A: Now let's talk about some notation, which would be of crucial interest to us later. So let's talk about filtrations and adapted processes. So let's look at measurable space. So f adjust the sigma algebra of subsets of omega. And filtration is an increasing family of sigma algebras, which are subsigma algebras of S. So if t is less or equal than SFT subset of fs. So measurable space with filtration is called filtered space.
00:29:36.884 - 00:30:33.334, Speaker A: And this index I can be, and it can be two sided z. So it can be discrete time, or it can be even half line or the whole real line. And my favorite filtration is this. So our omega now is interval zero one. And our sigma algebra is borl sigma algebra. And bn is sigma algebra generated by all the diadic interval of length one over two n. So let me add the title.
00:30:33.334 - 00:31:43.684, Speaker A: So it's a minimal sigma algebra which contains all these guys. So it's finite. And the standard situation here is that each of these sigma algebra was finite, but together they generated the whole borrow of sigma algebra. So this would be a very nice filtration, which will use a lot actually, which is very useful analysis to not only probability and now very important definition of adapted process. So a process is adapted to filtration ft if xt is ft measurable. That's all. So for example, process adapted to dyadic filtration is simply a process which is constant on every diadic interval kk plus one, from k two zen to k plus one to two x.
00:31:43.684 - 00:32:56.124, Speaker A: Because again, what does it mean that it's adapted? It means that pre image of every open set should be a subset of this, should be an element of this TFT. And here it means that you should be constant here. And in that direction. If you are given a process, then there is a smallest filtration, which we call natural filtration, such that fault t x t is ft measure. And this filtration is, again, this is the smallest sigma algebra, such that all the sets x s less than a are measurable for all s less or equal t and a in r. So that would be your natural filtration for the profits process. And then you also have left and right filtration.
00:32:56.124 - 00:34:02.924, Speaker A: So left filtration is simply signals regenerated by all previous guys. And right filtration, just intersection of all the guys here. So because intersection of sigma algebras is sigma algebras, union is not, but intersection is. And finally, of infinity is sigma algebra generated by a loss. And now very important, probabilistic. And again, now not only probabilistic concept of stopping time. So if you have a filtration, then stopping time is a function such that this set t of t belong to ft.
00:34:02.924 - 00:35:03.524, Speaker A: So heuristically, it means that at time t, you know, whether you already stopped or should keep going. That's why it's called stopping time. So if time t, if your knowledge is ft, is given by ft, then you know, okay, so are we already less than t or are we bigger than t? And let me give you some examples. First, start with discrete time. And suppose that xn is valid in some metric space, a subset of this metric space. And let's look for the first time when xn belongs to a. So with the assumption that infinite set is infinity can be infinite.
00:35:03.524 - 00:35:59.114, Speaker A: Then it's pretty clear that this set omega size, that t of omega is less or equal than n. Well, what does it mean? It means that one two is less than equal to. It means that one of the x and belong to a rather one of the x case when k is less or equal than n. And this is union of fn measurable sets. So this is indeed stopping time in natural filtration. Now, with continuous heating time, you need to assume something. With continuous heating time, you need to assume, for example, that xt is left continuous.
00:35:59.114 - 00:37:16.726, Speaker A: Then this is first heating time infinity, such that xt is an a is a stopping time. So this is, again, we will need left continuity here. And here is the proof. So what does it mean that t omega is less or equal than t? It means that xt is an a union with the following that you can find rational q, which is less than one over k, such as the distance from Zxxq to a is less than one over, is bigger than one over n. And then you take the union over n intersections over k. And so this is definitely an element of f t. Here I use the fact that it's enough to just check rational number.
00:37:16.726 - 00:38:12.222, Speaker A: So again, you want to check that you hear, you hit it before, and you cannot check at all times because that would be the union of uncountably many sets. You can take accountable union, but countable unions are key. Here you are. Okay, now let's discuss relation of stopping times and brownian motions. It's actually quite exciting. So let Bt be a process adapted to a filtration ft. So this doesn't need to be a natural filtration.
00:38:12.222 - 00:39:20.406, Speaker A: This would be very, very important, because again, the bigger the filtration, the finer the filtration, the more stopping times you have, the weaker the condition for things to be stopping time. And so suppose that t is a stopping time with respect to ft, and which is less than infinity, almost solar. Then we can define a new process at time t. This would be brownian motion at time little t, plus the stopping time minus brownian motion at time t. Then the claim is that this is still a brownian motion, which is independent of all the things which happens before the stopping time t. So this is called strong Markov property. So remember, Markov property was that when this little t is a constant, then we have brownian motion.
00:39:20.406 - 00:39:53.624, Speaker A: Here. I'm saying that even instead of constant, you assume that this capital t is just stopping time. Maybe with this respect to some big filtration this is still brownian motion. I will not prove that this is not difficult, but let me save time here. Let me just do this, which again, is very nice. It's called reflection principle for brownian motion. So let C be stopping time.
00:39:53.624 - 00:40:51.884, Speaker A: And let's consider reflected brownian motion up to time t. It's just your usual. You run it, but then after time, you reflect it. So this is t minus bt. So you reflect it with respect to Bt. And the claim is that bt is a brownian motion. Well, how do we check this continuity of this process? Obvious.
00:40:51.884 - 00:42:06.064, Speaker A: And now let us see, by strong Markov property, both this guy and this guy are brownian motions, which are independent of B of S when s is less or equal than the stopping time. Right? Because this is just by standard mark of property, strong Markov property. And this is because minus brownian motion is, again, brownian motion. So the brownian motions independent. So which means that b of t, which is just this process, brownian motion here and brownian motion plus b one. That's our standard brownian motion. And now, reflected brownian motion, which is bt plus b two after time t, well, they have the same correlations.
00:42:06.064 - 00:43:08.414, Speaker A: Because when you create things well before and after the time t, that the correlations of the same object, they consist of two parts. Brownian motion before bt plus independent brownian motion after independent of this. So they have the same finite correlations, which means that they have the same distribution. So it means that they are both brownian motions. Remember, brownian mon is determined by just pairwise correlations of B's and Bt if it is continuous. And again, continuities because this reflection makes it continuous at t capital. Okay, so one of the corollaries of this is distribution of maximum of brownian motion.
00:43:08.414 - 00:44:07.296, Speaker A: So let St be the maximum of brownian motion supreme of brownian motion when s less or equal than t. So remember, brownian motion is this highly oscillating thing. So, amazingly, we can say everything about the distribution of this. So, first of all, probability that St is less or equal than a, but Bt is bigger equal than b. This is the same the probability that the brownian motion at time t is big or equal than two a minus b. Second is that probability that St is bigger than a is just probability that absolute value of Bt bigger equals than a. This is the same as twice the probability that bigger equals than a.
00:44:07.296 - 00:45:01.424, Speaker A: Well, this equal to this just by reflexivity of brownian motion. But by symmetry of normal distribution, this is equal to this. So we know the distribution of st probability that St is bigger than a is just wise. The probability that Bt is bigger than I. So it's kind of half normal, because, again, positive. Okay, so to prove it, let us look at the first time we hit a. Then probability that St is bigger, equal than a, and bt is equal, less or equal than b.
00:45:01.424 - 00:45:46.004, Speaker A: It. Okay, so here actually made a mistake, as usual. See, I didn't like it. So here what is t is bigger equals an a, and b t is less equal than p. Yes, that would be better. This is the probability that you hit this level a before time t, and b t is less or equal than b. Now, this is a probability that Ta is less or equal than T.
00:45:46.004 - 00:46:09.370, Speaker A: And then let's do the reflection. So let's. Well, first, sorry, not reflection yet. Let's do the stop brownian motion. Let's start brown motion at the time ta. And this is. So this is exactly the same as b of Ta.
00:46:09.370 - 00:46:39.354, Speaker A: T minus t is less than equal than b minus a. And so b of Ta. Let's remember it's b of t minus b of Ta. So this is the probability that Ta is less or equal than T. And now we reflect it. So bt less or equals than b. It's the same as Bt star is bigger than or equal than two a minus b.
00:46:39.354 - 00:48:33.694, Speaker A: Okay? And now this is exactly the same as the probability that Bt is bigger or equal than two a minus b. Because, again, if t less than t, then b t star, which is if Ta is bigger than T. Then what we have is that Bt is less than a. So bt is less than bigger than two a minus b. And so this is, since this is the same object as this, we have that the probability of St bigger than n b, t less or equal than b is the same as the probability that Bt is bigger or equal than two a minus b. Okay, so this is, again, so we are done now to establish two probability that St bigger equals n a. It's, well, the probability that St bigger equals an a b t bigger equals an a plus probability that St bigger equals than a, bt less equal than a.
00:48:33.694 - 00:49:15.494, Speaker A: But now we can reflect it with respect to ta. So this is a probability that St big equals ni, bt plus probabilities that st big equals ni, bt. Right? So one of them should be bigger than a. So this is probability of Bt bigger than a. This probability of Bt static or bigger equals than a. And so this is just twice probability of Bt bigger equals na. And we know that this probability, that absolute value of Bt is bigger, equal than a.
00:49:15.494 - 00:50:08.444, Speaker A: And we are done. Okay, so that gives us the distribution of brownian motion. Of maximum. Of brownian motion. Now, I will, I guess, begin the next lecture. This discussion of more general objects than brownian motions, which eventually, it is in the continuous version, will turn out to be re parameterized brownian motions. So we'll start with a careful discussion of conditional expectations and martingales, and then we'll go from there.
00:50:08.444 - 00:50:11.184, Speaker A: Okay, so let me stop the recording here.

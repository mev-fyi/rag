00:00:00.200 - 00:00:17.662, Speaker A: Now we may start. Good morning, good afternoon, or good evening, everybody. Welcome to week 15 of our focus program, and we start with lectures by Michael Hartz from Sutherland University on the Drury, Arizona space.
00:00:17.838 - 00:00:51.166, Speaker B: Michael, please. Well, thanks, Javad, for the, for the introduction. And actually, thank you to Javad and Ilya and Damia for organizing this whole focus program. I've really been enjoying it, and I think it's also very good for the field to have so much activity over the course of several months. So thanks a lot for that. Also, thanks for inviting me to give these talks, and thanks to you for coming to them. So, yes, I'm going to talk about the Drury Avison space.
00:00:51.166 - 00:01:52.464, Speaker B: And let me begin by giving you sort of a very rough overview of what I'm going to talk about. So I'm going to denote the open unit ball in C to the D by BD. So this is just a set of all vectors in CD which have a euclidean norm strictly less than one. And then sort of very informally, you can define the durialisin space, or you can say that the durialisin space is a space of holomorphic functions on the unit ball, which in some sense generalizes the classical Hardy space, h two on the unit disk. So we had sort of, the first week in this program was a week on the Hardy space by Javad, and I'm going to try to convince you that this Joy Aveson space is a reasonable generalization of this hottie space to several variables. By the way, if you're worried about this word here, holomorphic functions on the ball. If you're not so familiar with several complex variables, don't worry about it.
00:01:52.464 - 00:02:31.494, Speaker B: If you just work on the unit ball, a lot of these non trivial phenomena like extensions, never appear. And you can just take, as a working definitions, power series that converge on the open ball. So just think of power series, if you like, here. So convergent power series on the ball. Okay, so why do people study this space? Well, if it's a reasonable generalization of the Hardy space, then it's reasonable to look at it. But there are actually deeper reasons. And in these lectures I'm going to focus on two reasons, one operator theory and one function theory.
00:02:31.494 - 00:03:24.080, Speaker B: So the operator theory reason is that on this dualiston space, there is a distinguished tuple of operators, which generalizes the, the unilateral shift to several variables. So right on the Hardy space, you have multiplication by the variable, which is nothing else in the unilateral shift. And this plays a crucial role in the study of operators in Hilbert space, especially contraction operators. And there is a version of this on this gray Allison space, which plays a similar role for certain tuples of operators they called commuting role contractions. And I'll make this precise. The second reason, which essentially comes from function theory, is that this space is an example of a very particular class of Hilbert function spaces called complete pick spaces. And it's more than just an example.
00:03:24.080 - 00:04:03.408, Speaker B: It's a universal such space. So, amazingly, this space plays two universal roles. It plays a universal role in operator theory when you study these row contractions, in this study of these special Hilbert function spaces. So, in my opinion, either one of these reasons would be good enough to look at this in great detail, but we actually have both of these reasons. So this also sort of gives a rough plan for my lecture. So I'm going to start by trying to make this definition precise, and then I'm going to talk about the operator theory aspects. And then I'm going to talk about the function theory aspects.
00:04:03.408 - 00:04:51.804, Speaker B: Okay, that's the plan. Okay, so where can you learn more about this? I thought I'd give you some references, but I only wanted to give you a very short list, so I only picked out three. So, apologies if I left out your favorite paper on the Dreavesson space, but the first thing I want to highly recommend is this survey by, or charlit, operator theory and function theory in the Druyavason space. And it's quite. So everything I'm going to talk about that happened before 2015, which is essentially, which is when this paper appeared, is covered and explained very nicely in this survey. So I highly recommend looking at that paper. Another survey, which I also recommend is due to Shelley Fang and Jing Bo Cha, where they.
00:04:51.804 - 00:05:23.720, Speaker B: So, this is from 2019, and you can find some of the more recent material in there. And then for this second motivation, to study the space. So, this complete pick spaces, the book on the subject is this book by Aglaan McCarthy. Pick interpolation and Hilbert function spaces. And so the reason why the duriavas in space comes up there is explained in a lot of material surrounding this. Okay, so these are three places you can look at the others, but I think this is a good place to start.
00:05:23.752 - 00:05:24.324, Speaker A: Start.
00:05:26.424 - 00:06:06.350, Speaker B: Okay, so, when I prepared for these, for these lectures, I looked at some of the early papers where the Drury Allison space appears. And so it has its name from two papers in the area, one by Drury in 78 and one by Arviss in 98. And so Sam Drury was interested in extending von Neumann's inequality to certain tuples of arpetes. And he realized that you can do this on this space, which is now called the dreyal space. Of course, he didn't call it that. And he also proved some version of a dilation theorem. And then this 98 paper of Arvisson was very influential.
00:06:06.350 - 00:06:42.024, Speaker B: He proved sort of a better version of Drury's theorem, a lot of theorem surrounding it. And in particular, he also put this space really into context. So it's, as far as I can tell, he was the first one to actually realize that it's a reproducing Colonel Hilbert space. He computed the reproducing kernel and showed that it's something meaningful. And he also connected it to symmetric fox space, which I'm going to mention later. So the space got its name from these two papers, but the other papers where it appeared as well. So here's just some selection of them.
00:06:42.024 - 00:07:31.844, Speaker B: So there are actually two earlier papers by Lubin, one from 76 and one from 77, the first 176 in that he also proves a version of a dilation theorem. And knowing what we know today, you can sort of see that it actually gets pretty close to Drury's and Argus installation theorem. And in the 77 paper, he was interested in subnormal operators. And so he used the Druiavesen space to give an example of two commuting subnormal operators whose product is not subnormal. Then there is a 93 paper by Muller and Vasilescu where they prove a whole scale of dilation theorems. And the one for the durialisin space is one of them. And then let me just mention three more papers.
00:07:31.844 - 00:07:59.814, Speaker B: So two which are related. So one by Davidson and Pitts and one by Arias and Popescu, where they come to this space from a non commutative point of view. So this is closely related to what Mike Drury talked about last week when he talked about the NC hardy space and what happens if you take NC functions and restrict them to commuting variables. And. Yeah, so I should say that the dates here are a bit fuzzy. I mean, the. I think these are publication dates, but these two papers cite each other.
00:07:59.814 - 00:08:41.904, Speaker B: So I assume they were written around the same time. And then there are two papers in 2000 by Agla and McCarthy, where they come to this space from studying certain interpolation problems. And I'll also say more about this. And afterwards, this really exploded, and it's hard to keep track of how many other things appeared. So I'm going to leave this at the three dots at the end. Okay. So you can also see, in comparison to some of the other spaces that we covered in this focus program, this one is comparatively young, right? I mean, it's certainly much younger than the space or the Bergmann space, for instance.
00:08:41.904 - 00:09:26.494, Speaker B: Okay, so what is this royalist in space then? Well, I thought instead of just writing down the definition and then trying to convince you afterwards that it's something reasonable, it might be fun to try to come up with a definition ourselves. So, before we do this, let me remind you of the hardy space on the disk. So this is, after all, this is supposed, this Drury Avesen space is supposed to be a generalization of h two to several variables. So let's look at h two again. So, we've seen this in many talks, but just as a reminder, you can define it to be the space of all holomorphic functions on the disk. So this curly o is holomorphic functions. So you might also want to write it like this.
00:09:26.494 - 00:10:23.734, Speaker B: So all holomorphic functions on the disk whose l two norms over circles centered at the origin, when you take them with respect to arc length measure, are bounded. And there's also a description in terms of Taylor coefficients, so consists of all holomorphic functions whose Taylor coefficients are in little l two. And we also know that it's a reproducing Colonel Hilbert space. So this means that point evaluations are continuous, and so they're given by some in a product against some vector in the Hilbert space. And this vector has a very nice form here. It's the Shager kernel, which is one over one minus z w bar. So the point is, if you take a function in the Hardy space and you take the inner product against the kernel of the function that you get by fixing the second variable to be w and letting the first variable run, then this reproduces the value of your function at the point w.
00:10:23.734 - 00:11:26.698, Speaker B: Okay, so how can we come up with a generalization of this space to several variables? Well, I should acknowledge that there is a generalization which is appropriately called the Hardy space on the ball. And you get this generalization just by taking the first definition above so that the function theoretic definition and replacing arc length measure with surface measure. So the surface measure is the unique probability measure on the sphere, which is invariant under unitaries, so d by d unitaries. And then you can just copy this definition essentially, right? You just say all holomorphic functions in the ball for which these l two norms, but now you compute them with respect to surface measure state bound. And this is certainly a very reasonable thing to do. But it turns out that this space doesn't quite play the role that the Hardy space plays in one variable. For instance, in operator theory, it doesn't work out to be the same thing.
00:11:26.698 - 00:12:12.114, Speaker B: And the actual reasons for why this happens are maybe I cannot explain them in one line. But let's do a one line computation, which is supposed to convince you that maybe the relationship between the one variable hardy space and this hardy space on the ball is not as tight as you might hope. And so, to see this, let's just look at what the norm of, let's say, z one to the n, is in this hottie space on the ball. So the Hardy space on the disk, the norm of z to the n, is always one. If you do this in the Hardy space on the ball, well, then you have to compute the soup here. But if you just do it for monomial, it's easy. The r to the n, you can pull it out, and then the soup is just attained at r equals one.
00:12:12.114 - 00:13:13.084, Speaker B: So this is nothing else than this integral over mod z one to the two n. And then, well, you can compute the integral explicitly, but you don't even have to, because even if you don't compute anything, you can see from the dominated convergence theorem that this tends to zero as n goes to infinity, right, because the margins of z one is equal to one on a one dimensional circle, and it's strictly less than one everywhere else. And so this one dimensional circle is as soon as d is at least two, is a is a null set. And so by dominating convergence is tends to zero. So this shows that. Well, it is true that if you plug in d equals one, then you recover the hardy space on the disk, but you don't recover the hardy space in the disk in the strong sense that if you take a function that just depends on one variable, let's say z one, then the norms are the same. So I want to use this as a sort of motivation for coming up with a dualux in space.
00:13:13.084 - 00:13:57.444, Speaker B: So, suppose we try to do this. So, our goal is now to find a Hilbert space of holomorphic functions on the ball, which satisfies three things. So, the first thing is what I just discussed. If you have a function of a single variable, let's just say z one, then the norm is really, then the norm in h two. So, in other words, if f is g of z one for some h two function g, then I want f to belong to the Hilbert space, and I want the norm of f in the Hilbert space to be the same as the h two norm of g. Now I want to really recover h two in one variable. Or in other words, I want to have an isometric embedding of h two in this space.
00:13:57.444 - 00:14:50.154, Speaker B: Okay, then the second property I want is that the space should reflect the underlying symmetry of the domain. So I want, if I take a d by d unitary matrix u and the function in this space, then the composition should be again in the space, and I want the norm to be the same. I think that's fairly reasonable if you think of the Hardy space on the disk that's invariant under rotations. And I just want the higher variable angle of this, and mostly to make my life easier. I also want to assume that the polynomials are dense in this space, so there's some flexibility in these assumptions. Well, of course there's nothing special about z one in the first assumption, because if you have unitarian variance, you can replace it by any other zi. Also, one really says that you have an isometric embedding of the hardy space.
00:14:50.154 - 00:15:36.284, Speaker B: If you like, you can turn the arrows around and you can say, if I take a function on the ball and I restrict it to a one dimensional slice, then I want to recover Hardy space in this way. That also works. I decided to go with one, because most people find subspaces slightly more intuitive than quotients, but it doesn't matter. And three, actually under some mild assumptions like boundedness of point evaluations, actually turns out to be automatic. But I want to assume it so that, just to make my life a bit easier. Okay, so the claim is, if I take these three things, then there's a unique space that satisfies these three things, and this turns out to be the duality space. Okay, so let's try to see if we, if we can come up with what this space is going to look like.
00:15:36.284 - 00:16:27.814, Speaker B: So the first 1st, we need some notation. So just like in multivariable calculus, we're going to use a multi index notation. If I have multi index alpha, then I'm denoting by z to the alpha to be the product of the individual z I to the alpha I. So the usual monomials alpha factorial is going to be the product of the factorials of the entries, and the absolute value of alpha is just the sum of the entries. So this is the usual multi index notation. Now the claim is that the monomials z to the alpha have to form an orthogonal basis because of unitary invariance, essentially. Well, I mean the linear span of the monomial is dense by assumption three, and I claim that distinct monomials, or different monomials are also orthogonal.
00:16:27.814 - 00:17:55.156, Speaker B: So let's have a quick look at why this is the case. So suppose we have two multi indices, alpha and beta, that are different, and then, without loss of generality, let's say they differ in the first entry. So let's say alpha one is not equal to beta one. And then what you can do is you can look at a unitary ut which is e to the it in the first slot, and then you just have one down the diagonal, okay? And then you use unitarian variance, because then if we compute z to the alpha in our product, z to the beta, then by unitarian variance, this is the same as z to the alpha composed with ut in our product, z to the beta composed with ut. And if you think about what this composition does well, z to the alpha composed with ut is going to be e to the I, alpha one t, and similarly for the beta. So here we get e to the I, alpha one minus beta one t, z to the alpha in our product, z to the beta. And now you integrate in t, and if you integrate from zero to to two PI, then you get that the right hand side is equal to zero, and the left hand side is two PI times the inner product.
00:17:55.156 - 00:18:17.974, Speaker B: So the inner product has to be zero. This is the usual. So you integrate from zero to two PI, and then you get that the different monomials have to be orthogonal. That's the usual argument. Okay, so the monomials form an orthogonal basis. And so all we need to figure out is what the norm of z to the alpha should be, and then the space is uniquely determined. So let's try to do this next.
00:18:17.974 - 00:18:54.524, Speaker B: Let's clear this. Okay, so what should the normal z to the alpha be? Well, there are multiple ways to work it out, but here's one of them, which uses essentially reproducing kernels. So the idea is we're demanding that all functions of a single variable that come from h, two functions, are in the space. In particular, we can do this with the Schegel kernel. So we take one over one minus lambda bar z one. This has to be in a space by assumption. And let's work out what the inner product against an arbitrary power series f is going to be.
00:18:54.524 - 00:19:46.814, Speaker B: Well, we just worked out that different monomials have to be orthogonal. So if you just expand everything into a power series, then you get the sum n equals zero. So the only thing that survives are the coefficients of z one to the n on the left. So what you get is the sum a n zero zero, and then you get lambda to the n from the kernel. And then you get the inner product of z one to the n with z one to the n, all the other coefficients, or the identity zero. But we defined it so that this is equal to one, because it should look like the hardy space in one variable. So this is nothing else than f of lambda times e one, where e one is the usual first unit vector.
00:19:46.814 - 00:20:42.114, Speaker B: So this looks pretty promising, right? Because this says that if you take the one variable sego kernel and you take the inner product against it, then you reproduce the values of your function, well, at least along the first coordinate axis. But then we have unitary invariant. So you can move around this lambda e one over the whole ball. So if you have an arbitrary point w in the ball, you can find a d by d unitary, let's say, so that u star w is of the form lambda e one. You just move it into the first coordinate axis. And then if you apply this, this thing we just worked out to f compose with, uh, then on the one hand, you can see so f composed with u of lambda times e one is f of w because u of lambda e one is w. And so you can use unitary invariance to move this, this unitary to the other side as a U star.
00:20:42.114 - 00:21:28.434, Speaker B: And then you just have to work out what you get. And to work out what you get, you should really think of this thing as now look like looking like one over one minus the inner product of z with Lambda e one. So if you think about it this way, if you pre compose with u star, you have to write a u star z. You move the U on the other side, and then you get this thing on the right hand side. So this thing, all right, that's also meaningful, because this means that if this scheme is going to work, then this has to be a reproducing kernel Hilbert space. And this formula here will be the reproducing kernel at the point double. So we're going to get back to this in a minute, but let's now work out what the norm of z to the alpha is going to be.
00:21:28.434 - 00:22:02.428, Speaker B: So you can apply this identity here with f equals z to the alpha. Then on the one hand, you get w to the alpha is the inner product of z to the alpha against the kernel, and then do the same thing again. You write everything out in power series. So if you write this, first you do the geometric series. So this is z w to the n, and then you can expand the inner product using the multinomial theorem. So this is sum over n and then the sum over. Well, I guess I should use beta now.
00:22:02.428 - 00:22:42.438, Speaker B: So multi indices beta of length n. And then I get these multinomial coefficients, beta factorial times z to the beta, w bar to the beta. And then I use again that monomials of so distinct monomials are orthogonal. So the only thing that survives in this thing is the coefficient of z to the alpha, which turns out to be. So this is this mod alpha factorial divided by alpha factorial w to the alpha. And then you're left with the norm of z to the alpha squared. Right? So this is true for all w.
00:22:42.438 - 00:23:23.746, Speaker B: So this tells you what the norm of z to the alpha has to be, because then the conclusion is that the norm of z to the alpha has to be alpha factorial divided by absolute value of alpha factorial. Well, that the norm of z to the alpha squared. And we already worked out that different monomials have to be automated. So this could uniquely determines a space. And so we're going to take this as our definition. We're going to define, um, the durias in space now as the space of, well, for now, formal power series. Uh, so that the coefficients are in some weighted l two space, and the weights are the ones we just came up with.
00:23:23.746 - 00:23:58.370, Speaker B: Right, these alpha factorial divided by absolute alpha factorial. Okay, so, uh, this, I mean, if this, we still have to have, have to convince ourselves that this works. But this was sort of forced upon us by this requirement that we have unitarian variance. And in one variable, it looks like the Holly space on the disk. So usually when you define this, sometimes people object. Why do the weights look the way they do? And there are multiple ways of motivating these weights. The motivation I just gave you is essentially it comes from the geometry of the underlying domain.
00:23:58.370 - 00:24:47.800, Speaker B: It comes from unitary invariants on the. All right, so if you do this, then, well, we don't just get formal power series, just like in the case of the Hardy space. You can use Cauchy Schwartz to work out that these power series actually converge on the ball, and you get a point wise estimate, which should look familiar from Hardy's space theory. So these things actually converge uniformly on every ball of radius, strictly less than one. And so they are actually holomorphic functions on the ball. And we have continuity of point evaluations. Now, if you read the argument I gave you on the previous slide backwards, then this argument tells you that if you define the derives in space this way, then the reproducing kernel has this form.
00:24:47.800 - 00:25:26.744, Speaker B: So this is the same formula we saw earlier. And if you take this above now as the definition, then you have to read the argument backwards. But it's the same computation. So we get a reproducing kernel, Herbert space of holomorphic functions, and the reproducing kernel is this guy. And so, knowing that this is the reproducing kernel also shows that the space is really unitarily invariant, because this kernel is clearly unital invariant. Right? If you look at Kuz uw, where u is a d by d unitary, then this is the same thing as kz w. And so if the kernel is unitarily invariant, then this gives you that the whole space has to be unitarily invariant as well.
00:25:26.744 - 00:26:01.000, Speaker B: And so this thing really fits the bill. This thing, this space is the unique space that looks like Hardy space and one variable and is unitarian. Right. By the way, you can also take this proposition as a definition. So you can just define the realisin space to be the reproducing kernel Hilbert space with this kernel. And the way this works is you can convince yourself that this function is a positive semidefinite function on the ball. And so you can evoke the more Ehrensheim construction that there has to be some, some space of functions.
00:26:01.000 - 00:26:44.204, Speaker B: Who's reproducing kernel as this function? This is also fine definition, and it also makes sense in some way, because this is the most obvious generalization of the Hardy space kernel to the ball. You could write down, right, if you, if you compare this to the kernel of the Hardy space that the, the Sego kernel, it was this function. So you just replace zw bar with this in our product. Okay? So that's the definition of the, of the Dray Allison space. Now, for the Hardy space and the digital space on these other spaces, we, they weren't just defined in terms of power series. There was a function theoretic description. And so let me talk about that for a minute.
00:26:44.204 - 00:27:18.884, Speaker B: So, I want to compare this space to spaces on the ball that have a function theoretic description. So one possibility would be the Hardy space on the ball. But it turns out that the computation is slightly nicer if you take the Bergman space on the ball. And so that's just as well. So let's take the Bergman space. So, just to remind you, the Bergman space consists of holomorphic functions whose. Well, holomorphic functions that are in l two with respect to volume measure on the ball so we had a whole week mostly on the one variable Hardy space.
00:27:18.884 - 00:27:41.054, Speaker B: The mini course was given by Stefan Greysta. And so this is the obvious generalization to the unit ball here. And in particular, this is a pretty concrete function. Theoretic description l two norm is finite. So, let's try to compare the duriades in space to this space. And to make my life a bit easier, let's assume we're in dimension two. This is the first thing where things look kind of different.
00:27:41.054 - 00:28:13.758, Speaker B: So the Bergman space is also unitarily invariant. So, by the same argument I gave you earlier, monomials form an orthogonal basis of the Bergman space. And one can compute the norm. It's a little tricky, but you can work it out. You can actually compute this integral. And what you get is this formula here. So we see our familiar weight that we had in the definition of the triavesin space.
00:28:13.758 - 00:29:05.854, Speaker B: And then there is some extra factor, which, at least if alpha is nonzero, is comparable to one over absolute alpha squared. So the norm of a monomial in the Bergmann space is smaller by a factor of one over absolute alpha than the norm in the Dualson space. In other words, the norm in the Duralisson space is bigger by a factor of the degree than the norm in the Bergmann space. Okay, now the point is that this factor, mod alpha, actually has function theoretic meaning. And you can get this factor by looking at the radial derivative. So the radial derivative of a function f. What you do is you take the derivative with respect to one of the variables, you multiply by the variable again, and then you sum the whole thing up.
00:29:05.854 - 00:30:06.394, Speaker B: And it's easy to work out that if you apply the radial derivative to z to the alpha, then you just get absolute alpha times z to the alpha. Because the point is, if you take the derivative of the jth variable and multiply by z j again, then it just gives you alpha j times z to the alpha. And then if you sum over all of the variables, then you get the absolute value. So in other words, this is saying that the norm of a monomial in the Dryaveson space is comparable to the norm of its radial derivative in the Bergmann space. And so, if you put this all of this together, you see that the function is in the Druyaveson space in two variables, if and only if its radial derivative is in the Bergmann space in two variables, and you get equivalents of norms. Well, you have to be a little careful, because this doesn't work for the constant functions, right the radial derivative takes constant functions to zero. But as soon as you add the value of your function at the origin to this, then you get an equivalent norm on the realison space in dimension two.
00:30:06.394 - 00:30:53.604, Speaker B: This computation works if d equals two. But hopefully you can believe that if you're a little more careful, then you can make this work in higher variables. Let me just tell you the result that you get if you work this out in higher variables, and it's the following theorem. So what you have to do is you have to take an integer m. So this is how many derivatives you take, and you want m to be so big so that two m d is bigger than minus one. And then the dualisin space consists of all holomorphic functions on the ball, so that the mth radial derivative is in l two with respect to this, this weight here. So the condition two mm minus d bigger than minus one just guarantees that this weight is integrable so that this makes sense.
00:30:53.604 - 00:31:50.204, Speaker B: And also you have equivalents of norms. So the norm of a function in the dualison space is comparable to. Well, once you add the value of the origin to this l two norm of the radial derivative, so this formula becomes cleanest if d is even, because if d is even, then you're allowed to take m to be a d over two, and then this weight here just becomes one, so you don't have to worry about it. And then you get this pretty concrete description. So you have function is in the Dreyalveson space f dimensions. If d is even if and only if d over two radial derivatives belong to the Bergmann space. Okay, this suggests a heuristic, namely, if you do function theory, the duration space behaves more like the Dirichlet space than like the Hardy space in one variable.
00:31:50.204 - 00:32:25.374, Speaker B: This is maybe not so obvious from the way I motivated it. Right. If you think about it as well, it looks like the Hardy space in one variable, and then you add unitary invariants. Then it sounds like maybe the function theory is like in the Hardy space. But because you have this derivative here, the function theory actually turns out to look more like the function theory in the Dirichlet space. So in particular, if d is two, then the condition is really that one radial derivative belongs to the Bergmann space, which looks a lot like the definition of the Dhar space. And we're going to see some instances of this behavior later on.
00:32:25.374 - 00:33:29.894, Speaker B: I also want to mention that these formulas that I have above here, they're not exact in the sense that they're not equality, so they're just equivalences of norms. But you can actually work out an exact formula, a function theory formula, if you're a little more careful. So you have to modify the definition of the radial derivative. And so this is actually done in a recent paper by Arcoti, Mangozzi, Piloso and Salvatore. So if you want to have a formula where there are no hidden constants, you can look at that paper. Okay, now this is also a good place to mention that the Durya wisen space belongs to a whole scale of spaces, and you can index them in various ways. I've indexed them now here by a real parameter, a, and I've chosen the index so that realise in space sits at a equals one, and in the scale then at a equals zero, you have the Dirichlet space and a equals d, you have the hardy space on the ball, so the one I mentioned at the very beginning.
00:33:29.894 - 00:34:02.684, Speaker B: And at D plus one, you have the Birkeland space on the ball. So you can see if D is one, then the dualisin space and the hardy space collapse as they should. But if D is bigger than one, then they move apart. And also, in this picture, for what it's worth, the drozen space, at least for large D's, it's closer to Dirichlet space than to Harley space. So how are these spaces defined? Well, just like in the Dualison space, there are multiple descriptions. At least if a is bigger than zero, you can just write down the kernel. That's usually the quickest way of doing it.
00:34:02.684 - 00:34:43.984, Speaker B: And it just, you take the Drury Allison kernel to the a. If a is equal to zero, you have to take logarithms instead of powers. But I'm not writing it down here. There's also the power series characterization. So a function is in such a space if and only if something that looks like the Dryavicen space norm, but now includes an additional weight here, is finite. And both of these descriptions also suggest, at least to my mind, that the Dualison space plays a distinguished role in this, in this scale, because it just happens when you take the power to be one, or when you take the weight to be equal to one. So that seems pretty natural.
00:34:43.984 - 00:35:36.384, Speaker B: And there's a function theory description, which I'm just going to mention in passing. So it kind of looks like the Druyavicen space definition, but you have to adjust the weight up here depending on which place in the scale you're at. Either one of the power series definition or the function theory definition, also shows that you have inclusions. So if a gets bigger, then the weight in the power series definition gets smaller. So the norm gets smaller, and therefore the space gets bigger, the bigger a gets. So we have inclusions this way, and you can also see it in this function theory definition fairly easily. So the dualison space is contained in the Holly space, and in particular in the Berken space.
00:35:36.384 - 00:36:38.744, Speaker B: All right, now, in the Dualison space, there is another picture which turns out to be extremely useful, and this is the non commutative approach. Mike Jury last week gave a lecture series on non commutative function theory, and in particular he talked about the NC Hardy space, and he also mentioned how it relates to the dualisin space. So I want to recall some of the things that he said, because there are one or two points that I want to make in how this relates to the durialisin space. So, as Mike explained last week, you start with a detuple of freely non committing indeterminate. So these are variables, but we're not assuming that x one, x two is the same as x two x one. And then if you want to form things like polynomials or even monomials, just what you should do is you should look at the free monoid on d letters. So this is the set of all finite words in the variables one through d, and the empty word is allowed.
00:36:38.744 - 00:37:31.264, Speaker B: And if you have such a word in these letters one through d, then you can form the corresponding monomial, which I'm denoting by x to the w, just by picking these non commuting indeterminants according to the entries of your work. And as Mike defined, you have this non commutative hardy space, which consists of, well, a priority consists of all formal power series and these non committing variables. And the condition is that these coefficients should belong to little l two. So in the non committing world, we don't have to worry about these weights, which is one of the, the nice things. But there are much deeper reasons why some things here are a bit easier. So Mike also explained that these are not just formal power series. You can evaluate them at certain matrices, particularly you can evaluate them at scalars and by scalars in unit ball.
00:37:31.264 - 00:38:18.274, Speaker B: And then you get a map from the non commutative hardy space into the duriavasan space, which you just get by taking an NC power series and evaluating it on the ball. Mike explained last week that this is a co isometry, meaning it's a subjective partial isometry, or the adjoint is an isometry. Same thing. And by the way, you can also take this as the definition of the durialisin space. Because what you can do is you can just say, well, you look at the space of all holomorphic functions that you get by taking NC power series in the NC Hardy space, restricting them to level one. And the norm you give it is the quotient norm. So the info norms of NC power series that give you your given commutative power series at level one, that's also a reasonable thing to do.
00:38:18.274 - 00:39:04.254, Speaker B: So let me look at the reason for why this map is a quasometry. Again, because I want to make a couple of points that are related to this. So one way to do it, which is essentially what Mike did last week, is to define something like a reproducing kernel for a point lambda in the open ball. So you look at this NC power series x to the w lambda bar to the w. This is in the NC harder space. And what it does for you is if you take an NC function f and you take the inner product against this little k lambda, then it reproduces the value of f at the point lambda. So it works like a reproducing kernel, at least at level one.
00:39:04.254 - 00:40:18.620, Speaker B: And then Mike also showed us this computation here. Namely, if you take the inner product of two of these things, well, okay, so you get the sum, and then the reasonable thing to do is to group the terms in the sum, so that you first sum over all words of length n, and then you sum over all n outside. And then you realize that if you sum over words of length n, this is the same as taking all possible products of mu I lambda, I bar of length n, which, if you think about it, is nothing else than the inner product of lambda with mu, with lambda in c to the d to the n. Because if you take the inner product and you raise it to the power n and you multiply everything out, you get all possible products of length n, and then you have a geometric series. And this you discover, again as the reproducing kernel of the Dray Allison space. So the point is that this reproducing kernel at level one of this NC hardy space, they have the same in our products as the reproducing kernels of the durialis in space. By the way, this is one place where Nc things become a bit easier, because, if you remember, we had a similar computation in the commutative world.
00:40:18.620 - 00:40:48.754, Speaker B: But they're the justification for why this thing, or the analog of this thing equals. This was a bit more difficult. We needed the multinomial theorem, right? And this is exactly what happens in the commutative world. In the commutative world, some of these things collapse. They turn out to be the same thing. But then you have to count, you have to count how many things are the same, whereas in the non commutative world, you don't care about which things are the same because typically they're non committing, so they're not the same. And then you just have all potential products, which is actually a bit easier in this case.
00:40:48.754 - 00:41:38.984, Speaker B: Okay. Anyway, the fact that these in our products are the same here tells us that we get an isometry that takes the kernel in the droias in space onto this kernel in the NC hardy space. Then if you take the argent of this isometry, this is the cooisometry that I mentioned earlier. So if you take a function in the NC hardy space, you can evaluate it at this point, lambda, by taking the inner product against a little k lambda. Little k lambda is v of big k lambda. You pull the v on the other side, and then you get the value of v star f at lambda. Okay, so one reason why I want to look at this again is because we have now this isometry from the Drury Allison space into the Nc hardy space.
00:41:38.984 - 00:42:13.004, Speaker B: So if you figure out what the range is, then you get a unitary from the drury harvest space onto the range of this isometry. And so you could identify the drury harvest space with a subspace of the NC Hardy space. And I want to figure out what this subspace is. So this is why I wanted to look at this again. So, up top, I've just written out the isometry again. So the crucial point here is, or the crucial definition is that of a symmetric power series. So, formal power series in noncommuting variables is symmetric.
00:42:13.004 - 00:42:52.694, Speaker B: Well, if it's invariant under permutations of the entries of the words. So what this means is, if you have two words, w and w prime, and you can get w prime by permuting the entries of w in some way, then the coefficient should be the same. So then aw should be the same as aw prime. And you can see that everything or everything in the range of this isometry v. So in particular, these vectors here, they are symmetrical, because the lambdas are just scalars. So the entries of lambda, they do commute, and so they don't see if you commute the word or not. So these things, everything in the range of this v is a symmetric power series.
00:42:52.694 - 00:43:36.450, Speaker B: And it turns out that this is exactly what you get. Oh, sorry. I had an example, which I should have mentioned so the baby example here is x one, x two is not symmetric, obviously, because if you permute it, then you get x two x one, but you can symmetrize it so that x one x two plus x two x one over two. And then this turns out to be symmetric. The other example is there are these things in the range, and so this is exactly what you get. V defines a unitary from the duraivasan space onto the space of symmetric power series in non committing variables. And so one way to see that you get all symmetric power series is you can work out what V does on commutative polynomials.
00:43:36.450 - 00:44:28.026, Speaker B: And so then you get all symmetric NC polynomials and then limit, you get all symmetric Nc power series. Actually, let's look at this polynomial idea for a minute more. So, if you have a commutative monomial, so something like z to the alpha, then in general there are many NC monomials that give you your commutative monomial at level one. So on scales, in fact, you can count how in this example you can see this. If you look at the monomial z one z two, then you have two monomials that give you this x one x two and x two x one. In general, you can count how many there are. And the number of these monomials is exactly this weight that we've seen before, absolute alpha factorial divided by alpha factorial.
00:44:28.026 - 00:45:12.704, Speaker B: And the reason is, if you look at z to the alpha, this is a product of length, absolute value of alpha. And so you have that many factorial permutations of it. But then you overcount it, because if you just permute the x one s among each other, then amongst themselves, then it doesn't change. So you have to divide out by alpha one factorial. And then if you just permute the x two s among themselves, you overcount by a factor of alpha two factorial. So you get this weight here. Then it shouldn't come as a big surprise that this map v takes a commutative monomial z to the alpha and sends it to the average overall non commutative monomials that agree with your given commutative monomial at level one.
00:45:12.704 - 00:46:06.222, Speaker B: One way to see this formally is you can look at this definition up top here, and you expand both sides in the power series in lambda, and you compare coefficients. And if you compare the coefficients, this is exactly the formula you get. So this is another way to explain where these coefficients or these weights and the definition of the briars and space come from, because they are precisely the number of NC monomials that give you your given commutative monomial. So that's another way of seeing it. Okay, let me make a quick aside here. So the, this point of view of the NC hardy space and that they're really non committal holomorphic functions is somewhat recent. I think it's an extremely helpful point of view.
00:46:06.222 - 00:47:02.220, Speaker B: But there's another point of view which you can also see in some of the older literature, and this is Fox space. So I want to briefly mention this to also explain why this space is sometimes called symmetric fox space. So the full fog space over c to the d is the space you get by taking all tensor powers off c to the d, and then you take the l two direct sum of those. So each e to the tensor n is a Hilbert space, and you can take the l two direct sum of those. And the point is that this is really just this Nc hardy space in disguise, because you can identify the NC hardy space with this full fog space just by identifying a non commutative monomial with the corresponding tensor of basis vectors. So the way that this works is, for instance, if you have x one, x two x one, then this gets mapped to e one, tensor e, two, tensor e one. And then you can extend this by linearity.
00:47:02.220 - 00:47:48.752, Speaker B: And there's an argument to be made that it's slightly more natural to make it conjugate linear as opposed to linear, because, for instance, if you look at what happens at degree one, then in the NC Hardy space, you get homogeneous polynomials of degree one. And in the full foce, you get just vectors of c to the D. And so the natural thing is that polynomials of degree one are linear forms on c to the d. But anyway, it's not so crucial for what I'm going to talk about. You can also make it linear, if you prefer that. So, we had identified the dualison space as a subspace of this NC Hardy space, namely the symmetric power series. And then on the other side, on the fox based side, you get what are called symmetric tensors.
00:47:48.752 - 00:48:21.760, Speaker B: So you can imagine what the definition is. And this gives an identification of this drury Alison space with symmetric fox space. So this is just a set of all symmetric tensors in this full fog space. And so this was, for instance, Alvins point of view in his 98 paper. So this is why people sometimes call it symmetric fox space, because you have this identification here. Okay, so let me summarize what we've seen so far. So we've seen many different descriptions of the Dryaveson space.
00:48:21.760 - 00:49:07.684, Speaker B: And so here I'm just summarizing them again. So, first, you can define it using power series. You can say all the power series or holomorphic functions, if you like, so that the Taylor coefficients are in some weighted l two space, and the weights are these things that we've seen many times. Now, you can describe it in terms of the reproducing kernel. The reproducing kernel is the most obvious generalization of the Hardy space kernel you can think of. We had a function theory description which roughly says, if you take dimension over two radial derivatives, then you should be in the Bergmann space. And there is this NC characterization, which says it's precisely what you get when you take functions in this NC Hardy space and restrict them to level one.
00:49:07.684 - 00:49:41.644, Speaker B: Or alternatively, it's the same thing. It's symmetric fox space. So this is one of the reasons why the theory is so rich, because there are all these different points of view. And depending on your particular problem, different points of view can be more useful or not, or more useful than others. And so often, choosing the right point of view is sort of half the battle. And as you can imagine, um, so this power series and RKhs point of view is useful if you want to use Hilbert space arguments and if you want to use operator theory or operator algebras. And something similar can be said about the NC point of view.
00:49:41.644 - 00:50:07.864, Speaker B: And this function theory point of view is. Is quite useful if you actually want to do, you know, explicit estimates, harmonic analysis, and so on. And so the fact that we have these. These different approaches to these spaces, to this particular space has made for a very rich theory. Okay? So I think this is a good place to stop for today. So tomorrow, I'm going to talk about why this space is actually interesting from the point of view of operator theory. And I'm also going to talk about multipliers.
00:50:07.864 - 00:50:09.964, Speaker B: But for today, that's it.
00:50:11.304 - 00:50:29.244, Speaker A: Thanks a lot, Michael. Let's thank the speaker first. Any question or comments? I think Marco started with something in the chat. Do you see it, Michael?
00:50:29.404 - 00:51:03.366, Speaker B: Yes, I believe so. But maybe someone who has worked on the classical hearty space more than I have wants to chime in. I don't think they're the same as the harmonic major ones on the ball, because in Rudin's book, he's got these lumer hardy spaces. Ah. Which are defined by harmonic majorance. And my dim memory is that they might be different, but I would have to look in the book. But Rudin's book on function theory of the unit ball treats that, but I think they're different.
00:51:03.366 - 00:51:05.114, Speaker B: Okay, thanks. Thanks a lot.
00:51:12.214 - 00:51:13.994, Speaker A: Further question or comments?
00:51:15.734 - 00:52:23.614, Speaker C: Sure. I'd like to make one comment. I mean, I guess this will come out. Maybe it comes out in tomorrow's talk, but the von Neumann inequalities for row contractions that Drury proved and then Mueller and Vasilescu proved and generalized, both of them only recognize this space in the first version, the power series. But that's probably the least useful one, because you don't recognize it as an interesting space, whereas all of the others have proven pretty important for various ways of attack. So just proving the theorem and saying, okay, you've got a universal model, which is a bunch of weighted shifts, didn't turn out to catch people's attention. It wasn't until these other connections were made that people got interested in the space.
00:52:26.754 - 00:52:36.174, Speaker B: Yeah, I think artisan was, as far as I can tell, the first one to actually realize that it's a reproducing kernel Hilbert space with a natural reproducing kernel and this connection to symmetric fox space and so on.
00:52:36.514 - 00:52:37.854, Speaker C: That's true, I think.
00:52:42.174 - 00:53:02.234, Speaker A: Thanks, Ken, for explanation. Further questions or comments? Somebody asked for. I think it was in chat. Yeah, Fouad asked for the slides. You can share it today, or.
00:53:03.974 - 00:53:11.994, Speaker B: I give you the slides at the end. Then I can give you sort of the final version of the whole thing, if that's okay. Does that work?
00:53:12.154 - 00:53:13.294, Speaker A: Yeah, perfect.
00:53:13.714 - 00:53:14.774, Speaker B: Okay, thanks.
00:53:15.434 - 00:53:17.634, Speaker A: Thank you. Let's thank Michael again.

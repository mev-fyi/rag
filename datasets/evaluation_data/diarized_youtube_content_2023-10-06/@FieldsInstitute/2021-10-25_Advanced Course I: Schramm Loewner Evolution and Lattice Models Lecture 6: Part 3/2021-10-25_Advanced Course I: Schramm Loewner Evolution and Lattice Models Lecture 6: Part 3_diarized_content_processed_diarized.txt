00:00:01.280 - 00:00:34.974, Speaker A: Okay, welcome back. And now, as I promised, we'll talk about quadratic variation. So let me kind of try to outline general direction where we're going. We are trying to introduce a way to integrate with respect to a martingale. Well, we all can integrate with respect to a process with bounded variation. So let's try with this. So, suppose that you have filtration and you have a process adapted to ft.
00:00:34.974 - 00:01:43.992, Speaker A: We say that the process has bounded variation. If this is this function t to e t for almost every omega is right continuous and has bounded variation on every finite interval. And then for every x which is measurable with respect to the set ft times libc. So for every t, this is called progressively measurable, we can define integral from zero to t of x s with respect to s. Well, it's a random variable, but for each omega, the integral is very well defined. And it's a nice usual riemann til cs or integral, whatever you like. So if a is a process of bounded variation, we can integrate with respect to it.
00:01:43.992 - 00:02:38.004, Speaker A: And, well, there is nothing new here. We just objects under the integral are random. But the integral itself is very much deterministic, well known to us, and just standard three months celsius or the back celsius. Again, standard probabilistic notation is x dot a. Unfortunately, it doesn't help us much with artengales. So the next level is, which says that if you have a continuous martingale and it happened to have bounded variation, then it's constant. So there is nothing interesting here.
00:02:38.004 - 00:03:28.488, Speaker A: And the reason for this lemma is the following theorem. Remember, for brownian motion, the reason why brownian motion has infinite variation was that it has actually quadratic variation, that for bounded variation you need to take sum of absolute value of btu minus bti minus one. And actually, if you take the sum of squares, which is significantly smaller, this has a limit. And this is true for any continuous bounded martin. So if you have continuous bounded martingale, then it has a quadratic variation. This is probabilistic limit of these guys. This is not just so.
00:03:28.488 - 00:04:20.334, Speaker A: Good news is that this quadratic variation itself is not just bound iteration. It's increasing function. It's continuous increasing function, which obviously starts at zero by definition. And this is unique, such process of bounded variation such that mt squared minus mmt is a martingale. So remember, for brownian motion, we had this example that brownian motion squared minus t was a martingale. This is generalization process. Again, as I promised, eventually will come full circle and see that this is all just repairmeterized brownian motion, every continuous Martin Gabal, at least with infinite variation of infinity.
00:04:20.334 - 00:05:23.686, Speaker A: The proof is rather technical, so I decided not to include all the details, but I just wanted to give you a flavor of what is used. So, let me quickly go through this. So, let's look at a partition of positive real line, and let us define t delta t of m, or we call it t t delta. This is just some of the guys in the partition up to the time that we hit t times mt minus mtn squared. Okay, so this is what would eventually converge to this process. But this, of course, is not yet the process of bound iteration. More than that, let's look at this difference.
00:05:23.686 - 00:06:31.604, Speaker A: I claim that this is a continuous margin. So our mt squared minus tt delta, this guy, it's always a continuous marginal for every partition delta. Let's prove it. Expectation of mt squared minus tt delta is what, with respect to fs? Well, this is expectation of mt squared minus m squared plus expectation of m squared with respect to fs minus expectation of t t delta minus ts delta with respect to fs. Right? So all I did, I simply added and subtracted m squared minus ts delta. And I claim that this is just, again, sum of all those expectations is m squared minus ts delta. Okay, so I forgot to write here, minus ts delta, of course.
00:06:31.604 - 00:07:41.484, Speaker A: And here, you don't really need to take expectations with respect to fs, like here. And I claim that this is just m squared minus t s delta. Because what happens when you have ti s between ti and ti plus one, expectation of mti squared minus ti with respect to f s. Let's write it down as this plus ms minus mti squared minus two, well, products of this. And after you take the expectation and the dust settles, this thing becomes expectation of mti plus one squared minus, sorry, mti minus ms minus mti. And if, on the other hand, Ti is less than s, then this expectation is the same expectation of this with respect to fs. This expectation of mti plus one squared minus mti with respect to f s.
00:07:41.484 - 00:08:42.074, Speaker A: And then you sum this up. So expectation of this is equal to expectation of this. So these two terms happily cancel, and all you left is m squared minus t s delta. So now all we need to show is that when size of the partition turns to zero, then this converges in l two local, and then we'll take subsequences, or, well, convergence in l two local actually imply conversion probability. And to see that it's increasing will take subsequence. But okay, first thing first, let's consider two subdivisions, two different subdivisions, and let's take a look at the difference between them. So this is mt squared minus t t delta prime minus mt squared minus tt delta.
00:08:42.074 - 00:09:54.746, Speaker A: The smartingale expectation of it squared is, well, what it is. We can apply operation tt delta to this Martingale, tt delta minus tt delta prime. Again, we know that this minus, this is a martingale. So expectation of this is expectation of this thing. And using the fact that, well, of the connection between quadratic and charismatic mutation, we see that this difference is bounded by twice t t prime of t delta minus t delta delta prime of t delta prime. So to show, well, okay, actually minus, it's plus. Sorry? Ah, no, minus minus minus.
00:09:54.746 - 00:10:56.674, Speaker A: So, to show this l two convergence, all we need to show that expectation of this guy tends to zero as delta plus delta prime times to zero. And this just follows from Duke theorem, plus Schwarz inequality. Okay, so after the dust settles, we see that the existing limit, which is some function ft of these guys. Now, by dupe, maximum inequality, this implies that the supremum of them tends to zero. So you take maximum function for this guy, and it all stands to zero. Now you can find. So here, expectation of supreme tends to zero.
00:10:56.674 - 00:11:48.164, Speaker A: So you can find a sequence of partitions, one refinement of the next such that it converges to fs, almost surely that supremum. So it converges to fs uniformly on zero t. On the shoulder, each of these guys is continuous. So fs is also continuous. Moreover, if s and t belongs to the union of these partitions and s less than t, then there exists a partition such that they both belong to it. And then it's easy to see that t's is less or equal than tt. So fs is then increasing on the set union of delta n, which means that by continuity, fs is also increasing on the whole zero t.
00:11:48.164 - 00:12:38.524, Speaker A: Note that this was non trivial, because t's delta itself is not increasing, right? It's only, look at the formula. So it's only increasing at the end. But here, when you are between the ends, mt can be actually less than Mt minus epsilon, right? Mt can go up and down. So this difference can actually go up and down. But the moment you hit the next one, yes, there is a next return. So it is increasing on elements of the partition. Now, the observations that I already made, this converges on l two.
00:12:38.524 - 00:13:22.154, Speaker A: This is a martingale. So this is also a martingale. And finally, we know that this f is the limit of the partitions. So our quadratic variation is just our f. And then uniqueness just follows that. If you found two such processes which you can subtract from the square to get a martingale, then surprise, surprise, difference is also a bounded martingale, but it's also a martingale of bounded variation, which is zero. Notice that it's almost a circular reasoning.
00:13:22.154 - 00:13:56.654, Speaker A: But what we do, we use existence. And from existence we prove that every continuous martingale of bounded variation is actually constant. And then from this we derive this uniqueness. Okay, now let's look at the corollary. Suppose the t is a stopping time. Then we can look at stopped Martingale empty. So the martingale, remember, which is stopped at the stopping time.
00:13:56.654 - 00:14:39.054, Speaker A: I claim that quadratic variation of this martingale is the same as quadratic variation of original martingale stopped at time t. So it's just mm at the time minimum of TMT. And the reason is the following. Let us take Martingale Mt squared minus MMT, and let's stop it at time capital t. We get this by observational stopping time theorem. Stop martingale is a martingale. Again, remember that we are talking about bounded Martingales now.
00:14:39.054 - 00:15:38.878, Speaker A: So everything is uniformly integrable. So this is indeed a martingale. So if you subtract from MTT squared mm, t stopped at time capital t, you get a martingale. So by uniqueness, it's actually a quadratic variation of the stopped martingale empty. Okay, this was a nice theorem with long proof, which we mostly skipped, but it doesn't even work for brownian motion. Brownian motion is not a bound at Martingale. Well, you say, oh, come on, that's trivial, because you just stop browning and motion at any time, and then up to this time it is bounded Martingale.
00:15:38.878 - 00:16:39.024, Speaker A: So you can apply this theorem that actually leads to a notion of local martingale. This is not necessary martingale, but if you stop it at some stopping time, it becomes a martingale. More than that, it becomes a nice martingale bound martingale. Okay, so here is the definition. Let MTB Ft adapted process such that there exists a sequence of stopping times tm, which are increasing, tends to infinity almost surely. And on the set where the stopping time is positive, your stopped martingale. So your process stopped at time ten is uniformly integrable martingale.
00:16:39.024 - 00:17:32.478, Speaker A: So for now, let it be uniformly integral. Okay, so local martingale does not have to be a martingale. It can happen that expectation of absolute value of MT is actually infinite at any time t. Yet you can find a sequence of stopping times which would make it into not just martingales, but nice martingales. So let us first observe that, of course, every martingale is a local martingale, because if you stop at a time n, remember, we already discussed that up to time n, it's uniform integral. So every martingale becomes local Martin. Now, remember, I said that we want to approximate our guy by bounded martingales, not just uniformly integrable.
00:17:32.478 - 00:18:11.114, Speaker A: That's very easy to do. That sn would be minimum of this time tn, and the first time we hit n. So it's minimum of two stopping times, stopping times. Then martingale Mtsn is bounded by n. Sn, happily goes to infinity, because either you cannot hit all the n's in arbitrary short time. So on every finite interval, you have continuous trajectory. So on every finite interval, you are bounded for any instance.
00:18:11.114 - 00:18:39.008, Speaker A: So this sn would go to infinity, since t n goes to infinity. Again, this goes to infinity. Sn is less or equal than sn one. Again, this has this inequality. This has. And so this means that we can replace this condition by this being bound at Martin. Again, sometimes it's easier to talk about uniformly integrable.
00:18:39.008 - 00:19:18.584, Speaker A: Sometimes it's easier to talk about bounded. But this is the same thing, because every bounded is uniformly integrable, and vice versa. Every uniform integral can be approximated by this easy procedure, which I just outlined by bounded. Now, of course, I need to give you an example of local Martin gale, which is not Martingale. Otherwise, you might start thinking that this was just a normal, interesting concept. So, standard example is the following. Let's look at the standard brownian motion, and let's look at the first time it hits minus one.
00:19:18.584 - 00:19:57.074, Speaker A: Well, almost surely it's less than infinity. Now let's stop our brownian motion, the stopping time t. That's of course, a martingale. Stop martingale, the martingale, not uniformly integral, of course, but we didn't expect it. And the limit when t goes to infinity of BTT is of course, minus one, almost ruler, because t actually doesn't go to infinity. T goes up to t. And the time this capital t, you hit negative five.
00:19:57.074 - 00:20:55.990, Speaker A: And now let us consider xt to be b of t of one minus t when t is between zero and one, and minus one when one is between, t is between one and infinity. Okay, so what I should have written here that this is stopped. So because of this observation, so when t approaches one, this approaches to infinity. This goes to minus one. So this is just, xt has trajectories which are continuous homo shoreline. For t less than one, xt is just repairametrized brownian motion. So expectation of xt is the same as expectation of x.
00:20:55.990 - 00:21:28.694, Speaker A: Naught is equal to zero. Well, it's not quite brownian motion. It stopped brownian motion, but it's still Marc. But for t, which are big or equal, expectation of x, t is of course, negative one, which is not zero. So this is not a marten. On the other hand, let us define tn be the first time that xt hits n. And if it doesn't hit n, then it's just n.
00:21:28.694 - 00:22:29.134, Speaker A: So this is the same, this process exceeds, not n is the same as when brownian motion is not equal to n for all the times up to time t capital. Then of course t n goes to infinity because tn is actually equal to n. When n is bigger than maximum of the brownian motion, up to this compact interval, almost surely compact interval from zero to t capital. So for almost all omega, t n of omega is equal to n for n bigger than n of omega, which is this maximum. So it does tend to infinity. And of course it's increasing. Xt is the brownian motion repairametrized.
00:22:29.134 - 00:23:19.574, Speaker A: And it's bounded. So it's bounded between minus one and n. So xttn is actually reaper parameterized stop brownian motion. So it's marting. So we created a sequence of stopping time which went to infinity, which made our non martingale into a bounded martingale. But again, the process itself is not a martingale. Okay, with this in mind, the next theorem generalizes now the existence of quadratic variation to the more general situation.
00:23:19.574 - 00:24:09.610, Speaker A: Suppose that Mt can be a continuous local martyr. Then I claim that you can find unique continuous adapted increasing process which starts at zero such that this guy is a continuous local Martingale. And I forgot to put a square here. So this is a continuous local martingale. And moreover, we also have this convergence of this mti minus one squared. So remember this ts del ten s were exactly the sums. So we have exactly the same conversion.
00:24:09.610 - 00:25:18.684, Speaker A: So there is increasing process, and this averages go to it. Okay, so let's prove it. The main ingredient of the proof would be actually this very easy observation. So this corollary that for stopped martingale quadratic variation, just quadratic variation of the big martingale stopped at this time. Okay, so let us choose this increasing sequence of stopping times, such that this stopped martingale is indeed a martingale. So we started with local martingale, we stopped it. It became a bounded martingale.
00:25:18.684 - 00:26:11.034, Speaker A: Then for every n there exists this process n. This is just quadratic variation increasing process with n of zero is equal to zero such that mt tn squared minus n of t is a bounded martin. That's by the previous theorem. And now observe that this guy on tn bigger than zero. So this martingale stopped at tn on the set tn bigger than zero. This is also a martin, because it's just this martingale, because on the side ytm is equal to zero. Well, this is zero.
00:26:11.034 - 00:27:29.604, Speaker A: So by uniqueness it means that an plus, so that the process n plus one stopped at the time tn is n as long as tn is big. And now we define mm of t to be a t on the set t less than t. The definition is consistent because of this observation. Then this mtn squared minus mmt, this is just m squared minus mm stopped at time t. This is a bounded martingale, which means that this is a local martingale. Okay, so the idea of defining quadratic variation for local martingale is very simple. You take, make it into make a sequence of bounded martingales, which define it, take quadratic equation for them and define the quadratic equation to be the quadratic variation of the bounded guy.
00:27:29.604 - 00:28:59.324, Speaker A: And this is consistent as long as your stopping time is bigger than t. And now let us prove moreover part so we fix epsilon delta time t, find stopping time such that this is a bounded martingale, and probability that u is less or equal than t is small. So we just take time stopping time t and follow hm. Then this again by definition is bounded martingale. And since this tends to infinity, eventually probabilities at t and less or equal would be less than delta. So notice that on the interval zero u, both t delta of m and then mm, they are the same if you stop them on time u as long as you are up to u. So if you look at the probabilities at this is bigger than epsilon that ts minus mm, this is first bounded, well, of course by delta, by the event that u was less or equal than t plus the probability that this is true for stopped martingale mu up to time s.
00:28:59.324 - 00:29:57.720, Speaker A: And this term happily tends to zero when delta tends to zero. And that of course implies everything, because then we let delta go to zero and type some go to zero. And finally, uniqueness follows from existence of quadratic variation exactly as before, because the difference would be local martingale is bounded variation. Okay, so one point here, we can't integrate with respect to martingale. We cannot yet integrate with respect to local martingale, but we can integrate with respect to quadratic variation because it's an increasing function. Again, stochastic looking integral, but it's actually standardly based lcs integral. More than that, let's do polarization.
00:29:57.720 - 00:31:04.804, Speaker A: Suppose that we have two continuous local martingales. Then I claim that there exists unique process mnt of bounded variation which starts with zero such that it corrects mn. So mn minus this process is again continuous local martingale. And okay, let me correct the springs here. More than that, if you look at this. So if you look at polarized, thanks. So instead of the square, you took the product of m minus m n, and then this converges to this mn in probability.
00:31:04.804 - 00:32:02.644, Speaker A: Okay, so proof is very easy. Now, existence, you simply take this process, as I said, it's polarization. So this is m plus n and plus n minus m minus n and minus n, and take one quarter of this because Mn is one quarter of n plus n squared, minus m minus n squared, you get this result. So, uniqueness again follows from existence of quadratic variation. Difference between two such guys would be local martingale bounded variation and limit is indeed both sides satisfy polarization. Sum of squares converges to this, sum of squares of m minus m converges to this. You take one quarter of the difference, you get exactly some of this.
00:32:02.644 - 00:33:07.414, Speaker A: So this essentially is already proven, but this identity is actually would be important for us in the near future. So just some remarks here. If t is the stocking time, then this quadratic variation or quadratic correlation of mt and nt stopped martingales is the same as quadratic correlation of m and nt is the same as mn stopped at time t. So let us observe that of course one is equal to three. So this, and this, this is obvious because we already know that the same is true for non polarized version. And again, we just polarized. So now let's observe that two is equal to three.
00:33:07.414 - 00:34:08.544, Speaker A: This is because this guy converge here. And so for s, then this guy mt and t is the same as mtn and the same as minus. Of course, when t is bigger than t. But on this set, the difference between them is the same as the difference between these two guys. And this is zero, because look again here after the time. If s is bigger than capital t, then these differences would all be equal to zero. When you are between a little less and little t.
00:34:08.544 - 00:35:19.824, Speaker A: So this means that this is equal to this. So, amazingly, this, by the way, this implies that mt and t minus m n t is a local martingale. So which by itself is not easy to prove. And again, some books claim that it's easy to prove, and they give this as a justification of this identity that one is equal to two. I wasn't able to easily prove it, so instead. So this is a standard proof using probabilistic. Anyway, now, let us observe that if MMT is identically zero, then, well, m is identically constantly.
00:35:19.824 - 00:36:18.974, Speaker A: Because what does it mean that it's zero? It means that mt squared itself is a martingale. So expectation of mt squared is expectation of m naught squared, which is the same as expectation of mt minus m naught squared. Remember, expectation of mt squared minus m naught squared is expectation of mt minus m naught squared, because it's a multiple. So it means that Mt is identically equal to m and as a direction surface. Okay, so now we are ready to talk about integrals with respect to quadratic variation, quadratic correlation. So, first of all, what are we integrating? We're integrating functions which are measurable, fast and fast. Measurable means that h t of omega is measurable with respect to f infinity.
00:36:18.974 - 00:37:16.124, Speaker A: Tensor product with barrel sigma algebra. So this is just barrel measurement, guys. So, for each omega, your trajectory is barrel measurable for each t, your f infinity measure. And suppose that Mn would be continuous, local martingales, h and k would be measurable process. Then I claim that for every t, we have that integral of h of s, k of s with respect to total variation. So it's usually denoted by absolute value of dm and s. So remember, this is a process of bounded variation.
00:37:16.124 - 00:38:19.408, Speaker A: So this whole integral is bounded by the integral of h squared to the one half multiplied by the integral of k squared. Also square root. Okay, so this is very reminiscent to cash free inequality and proven the same way. So let us do it carefully. So, let us first note that we only need to prove it for t less than infinity, and boundaries and key take limits, because these are honest to goodness integrals with respect to positive measures. So, all the limits here exist when you go. Well, when you tend to infinity.
00:38:19.408 - 00:39:23.706, Speaker A: So if you bound this for each t less than infinity, you can go to infinity. And again, another thing, we can change signs of Hs and ks. So we just need to prove that absolute value of this integral of HsKs DMNs is bounded, again by selecting the sign such that they, that, you know, this is positive, so to say, and then we do the usual cachetype argument. So for every r in r m r n m r n from s plus to t, that's quadratic variation, it's non negative. Open the brackets. This is quadratic variation from s to t plus two r quadratic variation of mn from s to t plus r squared. Quadratic variation of mn non negative discriminant argument.
00:39:23.706 - 00:40:45.288, Speaker A: Discriminant is negative. So this means that absolute value of mn from s to t is bounded by mm squared mm to the one half and n to the one half. Now, if you take k to be sum of characteristic functions, h sum of characteristic functions. Well, let's take the same partitions, then what do we have? This integral is bounded by absolute value of hi ki absolute value of mn from ti to ti plus one. We just use this inequality to write that this is hi mm times km. So we just bound this by this times this. Okay, so now we use cashier to see that this sum is bounded by sum of squared ha squared mm k squared mn.
00:40:45.288 - 00:41:28.228, Speaker A: So again here we use honestokudm's cash sum of AI bi is less or equal to sum of I squared one two sum. And this is this integral. This is this integral. So we proved this for all all step functions. And then from step functions we can pass to the limit to bounded functions. And again, as I outlined before, pass to the limit to any functions and then let t go to infinity. Okay, so we will need a corollary of this.
00:41:28.228 - 00:42:42.550, Speaker A: Corollary of this will be crucial for proof of existence of it integral and this inequality of these two japanese mathematicians, Kunita and Watanabe, Hiroshi Kunita and Shinzo watanabe. And it says the following. Suppose that you have p less or equal than one, one over p plus one over q is one. So standard conjugate stuff. Then I claim that if you take this integral and take its expectation, then the same as to take integral hs squared with respect to mms to the one half and take lp norm of this. So this is a bit, became a bit overwhelming. So again, what is it I'm really doing? This is a random integral, right? So for each omega you have an integral here, and then you take expectation over all omegas of p's power of this, and take this to the power of one over p.
00:42:42.550 - 00:43:35.150, Speaker A: So this is LP now. So it's Lp with respect to probability, the same here. So you take l two norm with respect to mm with respect to quadratic correlation, and then Lp norm with respect to probability, and here two norm and q norm and this bound expected value of this integral with respect to two guys. The proof is indeed easier. So you know that this is bounded by this times this, and expectation of the product. Well, it's bounded by Lp norm times Lq norm, lp norm of one side, Lq normal side. So this is totally trivial.
00:43:35.150 - 00:45:00.094, Speaker A: But again, it's a consequence of non trivial inequality, which we just proved. Now, we'll use this inequality in a very special case, when, remember I told you l two norm with respect to mm, and then l two norm with respect to probability. So this inequality, let me write it down now very carefully. So, expectation of hs times ks of integrals from zero to infinity, hs ks with respect to total variation of the correlation is bounded by square root of the expectation of the integrals from zero to infinity, h squared with respect to quadratic variation of m times the same thing for ks with quadratic variation of m. Okay, so, so this is what unit meta Namidas was. And here we are, ready to do ita calculus. Well, almost ready.
00:45:00.094 - 00:45:52.504, Speaker A: We need one more concept. Well, two more concepts. We need semi martingales and we need hard spaces. So let me start talking about this and then I will continue next time. So we call a continuous ft adapted process same martingale if, well, it is a continuous process which can be written as xt, which is mt plus at, where Mt is a continuous local martingale, and at is continuous bounded variation adapted process. So this would be the processes with respect to which we will integrate. We'll integrate with respect to semi martingales.
00:45:52.504 - 00:47:01.064, Speaker A: And again, we already know how to integrate with respect to 80 reward Celsius integration with respect to this. That would be interesting and exciting. Now observe that of course, quadratic variation of process with bounded variation as well as quadratic correlation of process with bounded variation, and anything continuous that would be zero. Because again, look at the guys, you multiply finite sum of absolute values by decreasing jumps of functionality. So this is zero. So every same martingale has a quadratic variation which would be the same as quadratic variation of this local Martin gal. And as before, we can do polarization.
00:47:01.064 - 00:47:52.274, Speaker A: And now let me define a hard space, so we can define hard space as hp. For this exposition, I will only need hard space h two. So this would be the following. This would be continuous martingales, which are uniformly in alto. So alto norm is supreme of EmT squared. It's bound. So by Martingale convergence theorem, of course exists m infinity.
00:47:52.274 - 00:48:46.664, Speaker A: We generate this Martingale and expectation of m infinity is supreme of expectation of mt squared, just the limit of expectation of m t squared, and they conversion at l two. So you can look at h two is a subspace of l two on f infinity. So let me talk about it more precisely. So h two is would be this l two. But let's look at it now as a process. H two is a Hilbert space of Martingales. The form ft is equal to ft is equal to conditional expectation of f infinity with respect to ft for sum f infinity in l two.
00:48:46.664 - 00:49:45.700, Speaker A: For most of them, of course, these functions would not be continuous. And what I claim is that this is a closed subspace of this h two, or equivalently m infinity. We generate continuous martingals. They are closed subspace of l two. Let's check it. Indeed, if mn infinity converges to m infinity in l two by martingale inequality, maximal function inequality, expectation of supremum of them mtn minus mt squared, this also goes to zero. So one can select a subsequence such that mt and k converges to mt uniformity.
00:49:45.700 - 00:50:20.964, Speaker A: Because again, expectation of supreme tends to zero, so supreme goes to zero in probability. So there exists a subsequence which would converge uniformly in t. So since this were continuous, this limit would also be continuous. Okay, and next time we start with more careful study of hard spaces. So let me stop recording.

00:00:01.040 - 00:00:30.930, Speaker A: All right, so thanks, everyone, for coming. Familiar and less familiar people. It's nice to get you all together here for a somewhat different quantum information talk. I'm really pleased to be able to introduce to you Professor Mankey Tsang, who's visiting us for two months from the National University of Singapore. And please take the time to reach out. He'll be here till, I think, December 8 and take the time to talk to him. Mankei did his undergraduate work at UCLA and went on to do his PhD at Caltech.
00:00:30.930 - 00:01:40.704, Speaker A: If I got things in the right order before moving into quantum optics and working with a lot of names that are famous to us, some pioneers of the field, like Jeff Shapiro and Seth Lloyd, and then Carl Caves, and along the way, just pioneered so many different things that our group is particularly grateful. We've had at least two different projects really inspired directly by Manke's work. When I first, I forget if we actually met that time or if it was just when I first started seeing monkeys name. It was because he was the one who finally proved that a lot of these ideas about using quantum mechanics to improve lithography really didn't make sense, and a lot of people had suspected that, but Manke really kind of put the nail in the coffin for some of that work. But as though that wasn't enough, he went on to say, but if you wanted to save it and get quantum super resolution for some other interferometry tasks and make it truly scalable, this is how you would do it. And that excited us enough that we did one experiment on that. But then he went on a number of years later to come up with such a wild idea for improving the resolution of optical instruments that, if I remember correctly, I know that I learned about it on Facebook, and I think you posted something like, either we're completely stupid or my postdoc deserves a Nobel prize or something like that.
00:01:40.704 - 00:02:03.554, Speaker A: And I don't know if I'd quite go that far. But honestly, if this work had been done before the, what was it, 2014 chemistry Nobel Prize for super resolution, it certainly would have been in the running for that kind of thing. I think this is in some ways a game changer. For the past ten years or so, Manke has been at the National University of Singapore, and he's going to tell us about some of this exciting work. So please join me in welcoming Mike.
00:02:07.894 - 00:02:51.928, Speaker B: All right, thank you for the kind introduction. Thanks for having me. This talk is about the fundamental resolution of imaging. Let's say you are looking at stars, looking at fluorescent particles how do you even define or look at the fundamental resolution? How well can you see these objects? Clearly, we are going to attack this problem from the perspective of quantum information theory, estimation theory in particular. We will have some surprising results, and then we'll look for measurements that satisfy or saturate these true limits. That's the gist of the talk. First of all, can everyone hear me? Can people on zoom also hear me? I hope so.
00:02:51.928 - 00:03:12.012, Speaker B: No one is complaining. So. All right, all right. Someone is. All people are smiling. So, all right, let me just go over the brief introduction. Let's start with the basic problem in optics, which is the diffraction limit.
00:03:12.012 - 00:03:50.500, Speaker B: Let's say you just have just very tiny object, a small point source. You image it in the far field. You collect the light using a lens with some aperture size. The problem is that some light that is going off at a large angle is not going to be collected by the lens. So your aperture has a finite size. And according to wave optics, according to diffraction theory, what you see on the image plane, even though everything is in principle perfect, you don't actually see a very sharp spot. You're going to see a blurred spot.
00:03:50.500 - 00:05:06.686, Speaker B: And the width of this blurred spot measured in the coordinates on the object plane, is going to be determined by the wavelength of light divided by the numerical aperture of the system. Or if you're doing astronomy, you're looking at angular resolution. It's just divided by the diameter of the aperture. This is called the diffraction limit, tells you that there's blurring in your imaging system due to the wave nature of light. Obviously a big problem in microscopy, big problem in space telescopes, and even for ground based telescopes, adaptive optics has become so good in recent years that they can correct for the atmospheric turbulence very well, and they can get very close to the diffraction limit. So when you have ground based, ground based telescopes, the blurring is not just due to the diffraction limit, you also have atmospheric turbulence, but nowadays they have ways to correct for that so that they can get quite close to diffraction limit. So that's the reason why they build these big telescopes, right? That's why they need bigger apertures, because they're close to the diffraction limit.
00:05:06.686 - 00:05:54.974, Speaker B: And now it makes sense to build bigger apertures so that you improve the resolution of your telescopes. I put the price tags of these telescopes here to show you that it's really expensive to make larger apertures. Yes, you can make larger apertures or go to shorter wavelengths to improve the resolution. But at the end of the day, it's really expensive and not to mention all the political problems and planning and all the challenging science that you need to do to build large telescope. So it would be nice to have a simpler way to beat the diffraction limit. I need to emphasize the fact that the diffraction limit is not the ultimate limit to resolution. You need to realize that it's a rough idea.
00:05:54.974 - 00:06:19.718, Speaker B: If you learn optics from the right people, from the right books, you will find that. I'm sure you learned that at Toronto. You have fantastic professors. They will tell you that it's a diffraction limit. It's really a rough idea. It's not the fundamental limit. A better resolution can be achieved if sufficiently careful measurements of the exact intensity distribution.
00:06:19.718 - 00:07:02.768, Speaker B: So assume that you have a perfect CCD, no dark count at all, and it has infinite signal to noise ratio. So everything, according to classical optics, you measure those blur spots perfectly, according to classical optics, then you can have a better resolution beyond the diffraction limit. Already's criterion. All these similar ideas based on wave optics, based on the blurring introduced by the direction limit. I want to emphasize that Feynman is not a researcher in image processing. He didn't do work on super resolution. It's just that everyone loves the Feynman quote in physics.
00:07:02.768 - 00:08:03.064, Speaker B: So that's my Feynman quote. In image processing and statistics, people call these techniques super resolution, the convolution, the blurring, depending on which field you are in, basically, you take the image and then you do some data processing to get higher resolution than what the diffraction limit or what the Rayleigh's criterion would suggest. The problem with these techniques, actually, if you have a Google phone, they have very advanced image processing that they can do a little bit of super resolution already on your typical images. Nowadays, we know that you can do super resolution. The problem is that it's very sensitive to the signal, to noise ratio. Any kind of noise in your image, it's going to harm your super resolution techniques. So the enhancement that you get in practice is severely limited by the signal to noise ratio.
00:08:03.064 - 00:08:52.654, Speaker B: And many people have studied this problem, super resolution. And this is a nice book that I recommend. All right, I mentioned that signal to noise ratio is an important factor. So we now need to look at what kind of noises fundamentally limiting your imaging apparatus. And when you're looking at optical frequencies, visible, infrared, and beyond, one major noise source is photon shock noise. You can basically just model it as Poisson. Poisson using Poisson distribution, Poisson statistics at optical frequencies, I should emphasize optical frequencies.
00:08:52.654 - 00:09:37.012, Speaker B: If you assume it's Poisson, the noise is very simple to understand. Just think of light as random arrivals of photons. Okay, so you look at some typical image. This is a simulation, like five point sources. Then it's not just the blurring, but you also see noise, and it's kind of like raindrops coming to your CCD. I should emphasize that if you've learned about this bunching effect in the quantum optics course, of course, it's fascinating, but it turns out to be a very small effect. So people outside quantum optics don't really care about it.
00:09:37.012 - 00:10:22.746, Speaker B: I'm sorry to say that, but Poisson statistics is usually good enough. Of course, there are some people who think bunching Henbury Brown twist would be useful, but yes, useful in some technical sense. But fundamentally, Poisson statistics is a good enough approximation. I should also mention the fact that if you're looking at, for instance, microscopy, imaging, molecules, imaging proteins, they also have Poisson photon shot noise. If you try hard enough, if you cool everything down, you can actually see a little bit of anti bunching. But again, it's usually negligible. All right, you have noise.
00:10:22.746 - 00:11:23.554, Speaker B: Yes, it's just that the effect of bunching, you get super Poissonian. I think basically it's just that the variance is a bit higher than the average photon number. If you have Poisson random variable, the variance is equal to the mean photon number. But when you have bunching, the variance turns out to be slightly higher than the Poisson variance. If you have anti bunching, it's called sub Poissonian, the variance is slightly smaller than the Poisson variance, but that variation is so small, usually that it's not noticeable. So feel free to ask me any question and interrupt me. That's a good question.
00:11:23.554 - 00:12:04.844, Speaker B: What can we do if we have noise and we have blurring? Well, we can go to classical statistics. I'll just talk about one simple problem, one simple method in classical statistics, because I only have one slide to introduce it. So imagine that you have two point sources. Let's be concrete, two point sources. On average, you see two blurred spots very close to each other. Let's say I want to estimate their separation. That's usually a very hard task, especially if the two blurred spots overlap significantly or they violate release criterion.
00:12:04.844 - 00:12:41.554, Speaker B: That's usually. And if you have noise, if you have noise, photon short noise, then it's even harder. But you can still do so given your noisy data. Given your data from the CCD, you form a guess or estimator about the parameter, you can look at the mean square error. A very useful tool in classical statistics is the so called crime or bound. It's a lower bound on the error, so the error cannot go below this bound. So there's a fundamental limit to the precision.
00:12:41.554 - 00:13:31.698, Speaker B: It's valid for a certain class of estimators obeying a certain technical condition called the unbiased estimation. If you want to discuss this with, we can discuss about this later, but just consider this as a technical condition. But anyway, this is a lower bound for any unbiased estimator. So you can think of this as a limit to how well you can estimate this parameter given the noisy data. It's in terms of the inverse of something called a Fisher information. And that basically depends on the average intensity distribution. So if on average, you get this and you assume Poisson statistics, this is a simple formula for the Fisher information.
00:13:31.698 - 00:13:55.634, Speaker B: So the higher fish information, the lower the bound. And you have, roughly speaking, higher signature noise ratio. So Fisher information is a good thing. And also, if you do maximum likelihood estimator, asymptotically, it approaches the Kramer outbound. So this is very simple statistics. I'm just going to focus on Cramer outbounds and generalize it. Yes, please.
00:13:55.634 - 00:14:22.414, Speaker B: Is that based on. Some have two signals separated by the data, so there's so noisy, maybe it's just one gaussian. Yes, because in practice, we don't know whether it's one or two, but I'll just assume that it's two. Equally bright for now. And we assume that we don't know the separation. But the assumption is that there are two. Yes.
00:14:22.754 - 00:14:25.384, Speaker A: The theta equals zero would be a valid solution.
00:14:26.644 - 00:14:59.918, Speaker B: You could imagine 300 being your best guess. So if you want. Right. So if you. I'm trying to just look at this problem that there have been many other calculations doing hypothesis testing to see whether you have one or two point sources to discriminate between the two cases. So it turns out that the statistics is, the mathematics is different, but you have similar results at the end of the day. I'll show you a slide later to show the relevant papers.
00:14:59.918 - 00:15:16.014, Speaker B: Okay, that's a great question. Any other question? All right. Okay. Okay. This is classical. So far, I'm assuming that you've done the measurements, you have noisy data, and I'm just doing data processing. But we are quantum physicists.
00:15:16.014 - 00:16:10.794, Speaker B: Our playground is a lot bigger. Instead of just doing normal imaging, we can just think of performing some other kind of quantum measurement on the image plane. We can pass the light through some linear optics nonlinear optics, any kind of photonics, or even a quantum computer, right. We can do any kind of measurement as long as it obeys quantum mechanics. Then there are a lot of different ways we can measure the quantum state. One very fundamental result by Hellstrom, Karl Hellstrom back in 1967, is that just by looking at the quantum state of light, regardless of any measurement that you make on the light, there is a fundamental lower bound on the classical. So this is a classical criminal outbound.
00:16:10.794 - 00:17:07.714, Speaker B: This is the quantum crime rate outbound. And this quantum cranberry outbound is basically valid for any measurement that obeys quantum mechanics. It depends only on the density operator of the light on the image plane. And then you just need to solve these equations to find this equation, find this lower bound quantum bound. It's expressed in terms of the inverse of something called a quantum Fisher information. You can think of this quantity as the ultimate amount of fissure information in the photons, regardless of what measurement you are applying to the light. So that's how we are going to study attack de resolution problem, looking at the wave nature of light, looking at the particle nature of light, looking at statistics, data processing, and frame the problem in terms of a parameter estimation problem or statistical problem.
00:17:07.714 - 00:17:38.844, Speaker B: It's a little bit more complicated than the diffraction limit, or at least criterion, the things that you learn at basic undergraduate level, but, well, the problem is complicated to begin with. So we have to have a rigorous solution to the problem. S is an operator is the solution to this equation. So you have a density operator of light. It depends on the parameter. You can do a derivative on it. S is the solution to this equation.
00:17:38.844 - 00:18:31.724, Speaker B: Exactly. It's defined by this equation. So this is called the Lapanov equation. You can solve it numerically, or in simple cases, you can solve it by hand, and then you plug in into this expression, then you get the quantum fishing information. Okay. All right, we'll do a warm up exercise focusing on a very simple scenario of two point sources, two equally bright sources, and I'm just going to assume that the only unknown parameter in this problem is the separation between the two point sources. I want to go through this exercise doing classical statistics, quantum parameter estimation theory, and look at what the limit would be.
00:18:31.724 - 00:19:33.620, Speaker B: The first thing we need to do is to write down the density operator of light. Well, that's how Glober got his Nobel Prize, writing down the quantum state of light for thermal states and for many other states. But just using globers expression for the thermal state, assuming that you have two point sources, thermal distribution or thermal statistics, for the light using his original quantum state is not easy. If I want to apply Hahlstrms, Haustrom's bound, if I want to do these calculations for the thermal state is not easy. So what we did is to simplify the quantum state even further. I want to make this approximation that the average photon number per mole is much smaller than one. That is an excellent assumption in classical optics.
00:19:33.620 - 00:20:21.442, Speaker B: That's how you get Poisson statistics. And it turns out that if you apply this sort of approximation to the quantum case, it also simplifies the quantum state by a lot, such that in each spectral modes, for a high probability, you just get vacuum. Okay, so no photon. For a very small probability, you get one photon. And if you get one photon, it can come from either of the two sources, and we have an incorporated mixture of the two possibilities. And then I'm just going to ignore higher photon number events. And if the photon comes from one of the sources, then the wave function of the photon, we are making paraxial approximation here.
00:20:21.442 - 00:20:54.242, Speaker B: So it's okay to talk about wave function of the photon. It's just given by the point spread function of the imaging system. Okay? So some wave function of the photon is determined by the imaging system. So that is introduced by the blurring, the diffraction limit of the imaging system. So this is an approximation we did many years ago. It's consistent with Poisson counting statistics. If you want to look at bunching, anti bunching effect, you have to go to higher orders.
00:20:54.242 - 00:21:29.114, Speaker B: But as I said before, it's kind of negligible. The first calculation you can do is to calculate the classical fisher information for direct imaging. Basically, you just look at the light on the image plane and just do perfect intensity measurement. You have a CCD photodetector array, infinitesimal pixels, no dark counts or anything. So everything is perfect. But you're doing direct imaging, okay, just measuring the intensity on the image plane. So you get something like this.
00:21:29.114 - 00:22:16.684, Speaker B: This is the classical fissure information during direct imaging. This is fissure information per photon on the vertical axis. This is the true separation between the two sources. This part is when you have two spots, basically, that are very well separated relative to Rayleigh's criterion. This part is when you start to have significant overlap between two spots. So the more overlap you get, the lower the fish information. Okay? So, once upon a time, people doing fluorescence microscopy think that, okay, this is the fundamental limit to the resolution.
00:22:16.684 - 00:23:00.180, Speaker B: Well, but as I said, you can calculate the quantum bound for any measurement. This orange curve is just for one measurement. I can calculate the quantum fissure information for any measurement. Actually, I gave this problem to my postdocs, Ranchif Nair and Xiaomi Lu, and I gave this problem to them. I gave them the model, and I said, okay, this seems to be a hard problem. Please helped me to do this. And to be fair, after two days, they said, okay, the problem is actually very simple mathematically.
00:23:00.180 - 00:23:31.756, Speaker B: And then they just solved it. So it turns out that the mathematical calculation of all these formulas, this formula is quite simple after we've made this approximation. And then they came back with this calculation, this quantum bound here. And I was so excited. Yes, it's some operator. I'll talk about the measurement later. I'll talk about the quantum limit first.
00:23:31.756 - 00:24:12.874, Speaker B: I was so excited about this result. I put myself as the first author in this paper. I need to tell this story, if you have heard about it, I need to tell this story every time, because I feel bad now, like, you know, I should have put them as first authors. That should be nice. But anyway, so the interesting thing here is that the quantum fissure information per photon is just a constant. Okay? And if you look at the cramer outbound, which is the inverse of these quantities, you see a huge gap here. So the point is that if you can do the measurement, then there's a significant improvement that you can achieve over what people used to think is the resolution limit.
00:24:12.874 - 00:24:39.758, Speaker B: Okay. All right, now we come back to your question, optimal measurements. What do you do? So, and then we have another. We had another stroke of luck. We just tried to look at different measurements and see if we can calculate efficient information and hope that we can achieve the quantum limit. And a few days later, we came up with this, and that turns out to be optimal. Take the light on the image plane.
00:24:39.758 - 00:25:20.420, Speaker B: Instead of doing intensity measurement, use a special optical device that is called moh sorter. The idea is that I take the photons and I ask which mode in the hermetic gaussian basis the photons are in. And then I channel these photons into different channels depending on the mode. So these are just basically tem modes that we know and love in classical electromagnetics. And at the end of each channel, you do photon counting. We give it a fancy name, spatial multi multiplexing, or spade. And you calculate the classical fissure information of this measurement.
00:25:20.420 - 00:26:02.938, Speaker B: It turns out to be exactly equal to the quantum Fisher information at all parameter values. So that turns out to be the optimal thing to do. Okay, well, this is difficult, but not that difficult. Okay. People have been studying this sort of measurement or this sort of device for many decades, especially in optical communications, you can use photonic circuits, interferometers, spatial light modulators to implement this sort. So the key takeaway, take home message of this whole talk. I will talk about generalizations later, but the important point of this whole talk is that we are dealing with classical sources here.
00:26:02.938 - 00:26:29.628, Speaker B: We are not dealing with entangled source, non classical source or anything. We are dealing with basically the most classical sources in the universe. So they are more robust to losses, decoherence and all that. The measurement we propose can be implemented just using linear optics and photon counting. Again, just most order and photon counting. And we know how to do these things. And last but not the least, I think this is very important.
00:26:29.628 - 00:27:08.280, Speaker B: We have important applications, okay, now that we have the measurement, we have classical sources of light. Everything is linear optics, photon counting. So that we can go backwards and ask, okay, is there a semi classical explanation of the whole thing? Why is this measurement so good? Give you an explanation really quick. So again, two point sources. If you have one point source, it creates a wave function. On the image plane. Displaced by d over 2d is the separation between the two.
00:27:08.280 - 00:27:39.584, Speaker B: Use theta. Again, theta is the separation between the two sources. And let's say you know the centroid very well. Centroid is usually very easy to estimate. So you can do image intense image plane direct imaging, or you can expand the optical field in a Taylor series. This is the fundamental mode. This is the first order mode, just Taylor series of this displaced airy disk or gaussian optical field.
00:27:39.584 - 00:28:12.980, Speaker B: The amplitude of the first order mode is proportional to theta squared, theta over two. Do the same thing for the other two point. Other point source. Again, fundamental mode, first order mode, amplitude is minus d over two. The first thing you should realize is that all the signal is in the first order mode. These are incoherent sources. The optical fields are incoherent with respect to each other.
00:28:12.980 - 00:28:47.804, Speaker B: So I'm supposed to square the amplitudes first before I add them together. So the total energy is, after all, d squared over two, I guess theta squared over two. So first order mode contains all the most important information about theta contains the signal. Another thing to notice here is that the C mode, at least in this approximation, is not sensitive to theta. It's just there. It's not really that sensitive to theta. It's basically just background.
00:28:47.804 - 00:29:16.220, Speaker B: Okay? It's not signal, it's just background. Because we are dealing with Poisson statistics. Here is, if you have a background, it's increasing the variance of your photon counting. Without increasing the signal. If you can remove the background, remove the seal order mode, channel it to somewhere else, and you can measure it if you want. Filtering it improves the signal to noise ratio. That's the rough idea.
00:29:16.220 - 00:29:55.670, Speaker B: Okay, well, there's a semicolonical explanation. That's why we call it quantum inspired super resolution. It's inspired by our calculations in quantum information. Okay, so there, we discovered this in 2015, and there have been 30 plus experiments so far. As I said, the experiments are not the most difficult experiments in the world. So there have been a lot of experiments since then. Still proof of concept, but at least the experiments show you that the idea is not so crazy.
00:29:55.670 - 00:30:31.324, Speaker B: I really want to mention the fact that Ephraim's group did one of the pioneering experiments. It's not just because I'm here, but I really think it's a really nice, nice experiment. They measure only the first order mold, and the idea is to pass the light through a faceplate and then use a single mold fiber. Think about a fundamental mold. After passing through the faceplate becomes this odd mold not coupled into the fiber. What is actually coupled into the fiber is just one mold. So this is the optical fiber mold before the faceplate.
00:30:31.324 - 00:31:08.044, Speaker B: After the faceplate, but before the face plate is this odd looking thing. And this is the mold that is going to be coupled into the fiber and measured by the whole thing. You can ask him for more experimental details, but they managed to get somewhat close to the quantum crime or outbound and beat the experimental direct imaging mean square error. I copied these numbers down very many years ago. I don't remember exactly whether they are correct. So please go to him if you want to check the numbers. They also talked about bias estimators in their paper.
00:31:08.044 - 00:32:11.584, Speaker B: But if you want to deal with these rigorously, I'll need another 3 hours to talk about the statistics. But anyway, so after all these papers, someone told me that actually astronomers have been doing something very similar. You look at this nulling interferometer, a fiber null at the polymar observatory. They take the aperture light, pass it through two apertures, two holes, basically apply some phase shift, relative phase shift, to the two paths, and then just bring them into a single mode fiber. If you think about it, this is very similar to what ephraim script did. Well, astronomers are fantastic opticians. Of course, it's not so surprising that they have come up with something that is quite close to optimal.
00:32:11.584 - 00:32:41.254, Speaker B: But I just like to emphasize why our work is still interesting, because, number one, we have derived quantum limits. It's not just for this or that measurement. It's valid for any measurement. So our work is analogous to the laws of thermodynamics. You cannot violate that using any kind of clever scheme. So that's one thing. Also, we looked at exactly optimal modes.
00:32:41.254 - 00:33:20.968, Speaker B: What would be the optimal modes that you need to measure to achieve the quantum limit? Exactly. That's analogous to the kernel engine that people study in thermodynamics, is optimal. You can argue whether it's practical or not, but it's good to know that there is an optimal scheme to achieve your quantum limits. And last but not the least, we have found that other modes are the basis of optical spatial modes. Could also be useful, so we can generalize this whole thing for more. General imaging has been another experiment. Nicola traps did a very recent experiment using a different device that they invented.
00:33:20.968 - 00:33:37.544, Speaker B: But since they are not here, I'll skip here. Okay, part three. How much time do I have left? 20 minutes. Okay. All right. I have time to talk about this. Okay.
00:33:37.544 - 00:34:14.354, Speaker B: I gave the talk in Singapore many years ago about this two point source problem. The great quantum information theorist Masahito Hayashi. I'm not sure if you heard of this name, but fantastic mathematician. He's famous for writing this really nightmare of a book, quantum information, that is almost impossible to read. So great mathematician, but his English was very concise. So. So he was there, and he gave a comment about the two point source problem.
00:34:14.354 - 00:35:12.982, Speaker B: He just gave two words, so simple, I'm not sure if it's an insult or a compliment. He's just saying, well, the problem is so simple mathematically, why didn't people do it before? You know, I wanted to ask him, if you're so great, why didn't you do it before? But anyway, it annoys me, this question a lot. So I'm going to go directly to the other extreme scenario. Okay, so the last part was just warm up exercise. Okay, I'm going to go into another extreme scenario where I absolutely don't know any. What is the number of the incoherent, incoherent point sources? I just assume, in general, that I have a distribution of these incoherent sources. In optics, we call this an extended object.
00:35:12.982 - 00:36:13.974, Speaker B: Let's say you look at the sun as this, or look at a galaxy. We don't know the number of the point sources. If you just look at the density operator as a function of the distribution, instead of a mixture between the two possibilities of photons coming from the two point sources, now we have a continuous sum of all these possibilities. Of course, you can generalize our previous work a little bit by looking at two unequal sources or three sources, or look at exoplanets, look at slightly more general cases, but like to jump directly into this really difficult problem, assuming that I don't know anything about this distribution. Okay, so basically unknown infinite number of point sources, and basically you have an infinite number of parameters. Okay. Yes.
00:36:13.974 - 00:36:45.038, Speaker B: So now, I think, I talked to him recently. I didn't directly mention his comments, but I think he has a bit more respect for me now. Okay, so let's, now I'm going to go backwards, okay. Instead of starting with the quantum limit and ask what is the measurement that's going to achieve it? I'm going to go backwards. I say spade is going to be good. It's promising. I'm just going to study what Spade is going to do when I have a general distribution of sources and then I go backwards.
00:36:45.038 - 00:37:31.240, Speaker B: Okay, so let's look at what happens if you're looking at the first order mode for a distribution of point sources. If you have one point source, again, you do the Taylor series expansion. There's a displacement of the point source, same thing as before. Energy in first order mode is proportional to x squared. A distribution of spatially incoherent sources, you're supposed to sum all the contributions from the whole distribution. So instead of doing a sum for two point sources, you need to do an integral using this density function. You look at this quantity, you see that Spade is still measuring something interesting about this distribution.
00:37:31.240 - 00:38:11.724, Speaker B: Even though you don't assume anything particular about f, about the distribution. It tells you the first order mode tells you the second moment. Okay, this is the second moment of the distribution. So just looking at the first order mode tells you something interesting about the distribution. By similar arguments, second mode is going to give you the fourth moment. Third mode is going to give you the 6th moment. It's just somehow a quirk of incoherent imaging that, that the moment, the first order mode gives you the second moment, the second order mode gives you the fourth moment, et cetera.
00:38:11.724 - 00:38:42.584, Speaker B: Okay, so I just use my spade on any distribution of sources, and I can measure the moments of the distribution, but that just gives me even moments in 2d. It just gives me the even order moments if I want the other moments as well. I need to do something extra. I cannot just measure in the tem basis anymore. I need to do something extra. So this is a TEM basis. These are the mole indices.
00:38:42.584 - 00:39:45.554, Speaker B: Each dot represents one tem mole. If I just measure in this basis, I make a mole sorter that the multiplexes, the spatial mode. In terms of this basis, then I just only get moments in even orders. If I want to get the other moments, what I need to do is I take a pair of these tem modes, I pass them through a two port interferometer, a max sender interferometer, for example, and then I do full time counting measurements, and it turns out that I can get the other moments this way. So the idea here is that in theory, in principle at least, if I get all the moments, all the moments of the distribution, there's a one to one correspondence between the set of moments and the distribution function. In mathematics, this is called the moment problem. So the idea is that if I can measure all these moments, in principle, I need seven bases.
00:39:45.554 - 00:40:21.384, Speaker B: Seven bases. If I get all these moments, then I can basically retrieve the distribution. In principle. But of course, I'll talk about the caveats later. Any questions so far? Okay, well, that's the principle, but of course you would ask. Okay, is this good compared to benchmark, direct imaging? Benchmark, is this an improvement? So now we need to do statistics. So that's quite difficult.
00:40:21.384 - 00:41:15.128, Speaker B: So I'm going to express the result in terms of the object size so that the formulas become simpler, and I'm going to focus on the regime where the object size is so much smaller than the point spread function width. Okay, so if you had two point sources, it's just a separation, the sub railing for an extended object, many point sources. I still assume that the object size is very small. That simplifies the result a lot. And I'm just going to define the parameter of interest as a moment of the object intensity distribution. By the way, in classical statistics, people call this the semi parametric, a semi parametric problem, mean square error. So at this point, you don't really need to worry too much about the formulas.
00:41:15.128 - 00:42:02.694, Speaker B: I know that you may be burnt out by now, but I just will tell you the qualitative features of these results. You can calculate the mean square area of spade doing estimation of one moment. You can compare it with the cranial outbound of direct imaging. And the good news is that if you're looking at very small objects and looking at second or higher moments, there's still a huge gap between what spade can achieve and the criminal outbound of direct imaging. There's a log lot plot. This mean square error of spade estimating the second moment. This is the criminal outbound for direct imaging.
00:42:02.694 - 00:42:47.074, Speaker B: The important point about this plot, again, this is object size delta the important point about this calculation is to show you that there's a huge gap between the two. So the area of spade can go much lower than what you can achieve using direct imaging and visual information and all that, especially for small objects. Okay, so that's the point. Huge gap in log plot. That's the good news. Bad news. When you have really small object, the parameter that you are interested in turns out to be very small as well.
00:42:47.074 - 00:43:38.674, Speaker B: If you look at the signal to noise ratio, look at the ratio between the parameters squared and the mean square error that turns out to be small for small objects and large moments. So you do need more and more photons if you want to estimate higher and higher order moments. Beta is basically this guy. I forget about this. I'm just going to say I'm interested in one of the moments, okay? I'm trying to estimate beta, so not object size, it's just, I'm trying to estimate one of the moments, the object. So the second moment would be related to size. That's true.
00:43:38.674 - 00:44:13.302, Speaker B: But you can also estimate the third order moment, fourth order moment, etcetera. That's a good question. Any other question? Yes, please. Right. Because if you think about statistics, you look at population like a general distribution, right? It's going to be very complicated in general. Okay, this is my f of x. So if, of course, if it happens to be gaussian, then I just need the first and the second moment.
00:44:13.302 - 00:44:55.624, Speaker B: But in general, it's very complicated. So sometimes we want to look at its skewness or kurtosis, you know, higher and higher order moments tell you interesting properties about distribution in general, and also in terms of image reconstruction. If you want to reconstruct this guy from moments, the more moments, you know, the more accurate your reconstruction is going to be. Okay, that's a good question. Okay, so, huge gap. And again, we are just studying two measurements so far, right? Spade direct imaging. We still haven't calculated the quantum limits.
00:44:55.624 - 00:45:37.114, Speaker B: Is spate really the optimal thing to do? Or maybe there will be some other fancy measurements that allow you to do even better. We need to calculate the quantum limit for any measurement. So that's a really difficult question, because even in classical statistics, we are looking at this sort of problem called semi parametric estimation problem. You have an infinite dimensional parameter space. The classical theory is done by these people, mathematical statisticians. They put all their theory in this book. It's really a nightmare to read.
00:45:37.114 - 00:46:11.214, Speaker B: It's just a terrible book. You have to know abstract hubrispace theory, analysis and all that. But it was the pandemic. And I had a lot of time in my room. You know, I could not talk to experimentalists or anything. I just have to book with me. So I read it and I understood it, and I was smart, so I understood the classical theory, and that's how I calculated the criminal outbound for direct image.
00:46:11.214 - 00:46:51.604, Speaker B: Okay. Anyway, so, all right, coming back to the quantum limit. Okay, the problem is that the quantum theory for semi parametric bounds was not even invented yet. But again, good news. I had a lot of time, so we managed to just invent the quantum theory for semi parametric bounds. And eventually you have to use a lot of geometric math concepts. I'm not going to talk about all the math, but this is the final result, quantum cranial bound.
00:46:51.604 - 00:47:31.114, Speaker B: You can compare it with the mean square error of spade in estimating one of the moments of the object distribution. They turn out, turn out to have the same scaling with respect to the object size. So from the perspective of the scaling, from the perspective of the slope of these lines, in a lot more plots, spade is really optimal. So that really is almost the end of the story. That spade, in estimating the moments, really is the optimal thing to do. In principle. We've done some numerics as well to confirm the theory.
00:47:31.114 - 00:48:28.174, Speaker B: And finally, if you just have, as I said, the higher order moments are difficult to estimate, very poor signal to noise ratio. If you just have a finite number of moments and you want to do reconstruction of the image, what can you do? We managed to have some rough ideas about how you can use the moments, a finite number of moments, to reconstruct the object distribution. It's related to the idea of super oscillation, but I don't really have time to talk about it. And finally, we did an experiment. We got some money from the Singapore government and we did a proof of concept experiment. It's really very proof of concept, but that's the best we could do. Just laser beam go through this mole sorted device, which we just bought it from the french company.
00:48:28.174 - 00:49:30.610, Speaker B: It's able to give us these modes, six molds. So to simulate the distribution of incoherent sources or the optical fields of the incoherent sources, we just move the gaussian beam around. Because if I just add the power at each output for different displacements, it's kind of like the total output from many incoherent sources at different displacements. Again, very proof of concept, but that's the best we could do. So the total output from each mode is basically, that's basically the same as the distribution of incoherent point sources at different displacements. And we managed to resolve two point sources and also do this semi parametric estimation as well. We are using a laser beam, so nowhere near the quantum limit.
00:49:30.610 - 00:50:14.330, Speaker B: This is, again very proof of concept that we managed to get very good signal to noise ratio. I think my time would be up. Minutes, you mean? What do you have to make? All right, this is another talk I could give another time. I just want to brag about this really quickly. It turns out that the mathematics behind incoherent imaging can also be applied to optical interferometry. In imaging, you have randomly displaced photons. In coherent imaging, you can think of the photons as a random displacement.
00:50:14.330 - 00:50:55.754, Speaker B: With the photons, you can also apply the same idea to randomly displaced fields. And you say, okay, this random process is created by some probability law, and it depends on some parameter that I'm interested in. So you look at these two problems. They don't look similar physically, but mathematically they look, they turn out to have very similar physics and statistics. So another thing we discovered back in 2016 in the context of Microson interferometry, is that, let's say you think about Ligo. You have a Microson interferometer, you have random phase. It's a stationary process.
00:50:55.754 - 00:51:38.156, Speaker B: You want to estimate some parameters, or you want to measure its power spectral density. So let's say you have stochastic gravitational wave background, and you just want to estimate its statistics. What we discover is that this measurement, called spectrophoton counting, turns out to have a big improvement compared to what people usually do in Ligo, which is homodyne measurement. So the kind of enhancement you can achieve for microscent interferometers, for this problem, noise spectroscopy turns out to be very big. The enhancement is very big. Again, this is a lot plot. So very big.
00:51:38.156 - 00:52:13.136, Speaker B: So we published this in 2016. We didn't impress the high impact factor journal editors. It got very few citations. We didn't impress the world, but we managed to impress people who actually matter. Experimentalist at Caltech. And a few years later, our idea was picked up by these people, Lee McCuller and collaborators. They did a more detailed technical analysis of our idea as applied to microscon interferometer.
00:52:13.136 - 00:53:06.434, Speaker B: And they also realized that, okay, doing photon counting to this conclusion in their technical paper, photon counting with stochastic noise like signals within the right basis, basically just spectral domain, it allows you to achieve enhancement. So they are going to do a new experiment at Caltech, build a new experiment. Michelson and Photon counting in spectrum modes to detect signatures of quantum gravity. This part, I have no clue what that's going to work or what it is, but the optical part is our idea. Okay. Just want to give you a very big picture of what we are trying to do. Of course, in Toronto, elsewhere in the world, we've been talking about quantum technology 2.0
00:53:06.434 - 00:53:43.094, Speaker B: with quantum sources, quantum processing, quantum measurement, and you can do a lot of great things. Quantum enhancement trilogy, quantum computing, quantum Internet. In Toronto, you even have companies Sanadu trying to do this. It's a big dream, but it's also very difficult. So what we have been trying to do is to take a step back and try to do quantum technology 1.5. Basically, we are dealing with classical sources. You still need to do a little bit of processing using linear optics and quantum limited measurements.
00:53:43.094 - 00:54:22.958, Speaker B: So of course it's not as fancy as 2.0, but we like to think that this is a bit more practical with more important near term applications. And if we can be successful in terms of 1.5, then give people more confidence going into 2.0. Let me end on a positive note. You can ask all sorts of questions about whether our proposals would be practical in the near term. But first of all, if you believe that 2.0
00:54:22.958 - 00:55:18.276, Speaker B: is five years away, then, well, our scheme is even more practical. Right? But it's a valid question. So it's good to look back and look at all the quantum metrology work 30, 40 years ago and recognize that, okay, squeeze light was also not very easy as recognized by car. Not easy. But eventually, in terms of sensing or imaging, eventually, if you want to achieve that sort of sensitivity within a certain photon budget or error budget, experimenters have no choice but be forced to do a technique. They don't have to like you. They don't have to, they don't have to be, they don't have to like the idea, but they will be forced eventually.
00:55:18.276 - 00:55:34.408, Speaker B: I don't know how many years it would take, but they will be forced to do that eventually. All right, thank you so much for your attention. It's been a great pleasure. Thanks for the questions. And please ask me.
00:55:34.576 - 00:55:35.624, Speaker A: Yeah, thanks for a great talk.

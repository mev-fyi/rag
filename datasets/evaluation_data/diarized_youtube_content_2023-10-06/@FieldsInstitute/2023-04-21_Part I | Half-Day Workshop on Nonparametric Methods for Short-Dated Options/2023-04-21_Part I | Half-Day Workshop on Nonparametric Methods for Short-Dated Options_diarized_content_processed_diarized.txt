00:00:00.440 - 00:00:16.094, Speaker A: Thank you for having me. And so let's see if I got this one. Okay. Yeah, that's right. Okay. It's good to be back in Canada and in the Fields institute. This is a mathematics institute.
00:00:16.094 - 00:00:42.024, Speaker A: You see the blackboards with the chalk and stuff. But I will restrict myself to the. To my slides. But there will be formulas in the slides. Okay, so. So, yeah, so what this. So, given the format and how many of you are around here, just please feel free to interrupt me if something is not clear when I define things, because everything builds on things gradually.
00:00:42.024 - 00:01:25.434, Speaker A: And so you can just feel free to interrupt me in this format. It's easy. So what this talk will be about is I will spend time basically discussing the so called short dated options. And I will develop, well, in series of some of my work. I've basically been working over the last few years of developing various methods, non parametric, or in finance, they like to call this thing model free, basically, ways to analyze this option data. And I'll show you what I've done so far on this. Now, just to give you a sense of these short edit options.
00:01:25.434 - 00:02:04.616, Speaker A: And what is a shorted option? Okay. Short edit option is just like the name says. It's an option which has a short time to expiration. Basically, you're looking at options which expire very close to very soon. Okay. And so when I started doing research with options many years ago, when I was a graduate student, I remember that the rule was drop any observations or any options which have less than two weeks to expiration. That was kind of the norm, because the common wisdom was that there's just not much liquidity in these option contracts.
00:02:04.616 - 00:02:37.562, Speaker A: Then we accidentally found in the data that we. At some point, we start throwing half of the data with this room, and then we revisit it. And then we kind of got surprised what's going on here. Luckily, when I say we, my colleague Torben Andersen and myself, we went to one of the exchanges downtown in Chicago and asked them about this. And, yeah, they said, yeah, that's real. There's a lot of liquidity in these things, and people are trading them. And this has gotten even more extreme.
00:02:37.562 - 00:03:06.804, Speaker A: I think Lars mentioned this thing about the zero DTE. So if you google it, you will find it, too. Now, what happened was that they introduced the weeklies. They call those options weeklies with weekly expiration cycle, which means that these options are issued on a Friday and expire next Friday. So that's considered a short dated option. They started initially with the Friday expirations. People like them, and then they start issuing Monday and Wednesday and expiration dates.
00:03:06.804 - 00:03:10.796, Speaker A: And now if you look at the s and p 500 index, which is.
00:03:10.820 - 00:03:13.156, Speaker B: This proxy for the market index in.
00:03:13.180 - 00:03:40.684, Speaker A: Us, you have actually, as of now, we have options which expire every day of the business week. So Monday through Friday. Okay, so we have, every day there's an expiration date. So you can basically trade really this short dated risk. And the volume has gradually picked up. So this is one plot in which, just to summarize this, just look at SPX, the s and p 500 index. And what I plotted here is.
00:03:40.684 - 00:03:55.384, Speaker A: Now, that was not the right button. Okay, so now let's see the three buttons. How can you get it wrong? But apparently. Now let's see, how do I get myself back into the full screen view?
00:03:56.084 - 00:03:59.244, Speaker B: All right. Okay, so I'm back.
00:03:59.284 - 00:04:07.444, Speaker A: I'm good, thank you. I'm not that illiterate. I can sort of manage to full screen mode. Okay.
00:04:07.484 - 00:04:10.516, Speaker B: So, yeah, initially, if you go back.
00:04:10.540 - 00:04:53.816, Speaker A: In 2007, you will see that the volume of options traded with one week to expiration was a little bit less than 10%, and then it gradually increased to 20%. It's a little bit downplaying the importance of the short dated options because what this thing is, in a lot of these dates here, they were just none of them. Right? And so you're dividing on something which is, by definition, zero because they didn't have those short maturities issued. And so if you zoom in now and you just look at now conditions and do it slightly differently, the data and look at volume of options traded on days when. Days on expiration date. Basically they are options which expire on the same day, zero day. And you can see this volume has started picking up.
00:04:53.816 - 00:05:33.822, Speaker A: I'm using option metrics here, and for whatever reason, they can't update their data. But if you look at 2022, this has even shooted up even more. It's like, right now, what I'm seeing here, it's over 30% from zero date options. And I read it in because when I teach, I usually follow the financial press. And then that zero dtes have picked up a lot over the last year, mainly facilitated by this daily expiration dates that were introduced. Yeah, yeah, that's a. I'm sorry.
00:05:33.822 - 00:05:44.354, Speaker A: Yeah. So these are here. So the axis are 2010, and we go all the way to 2021. So these are just years. These are by years. Oh, sorry. Oh, you mean here.
00:05:44.354 - 00:06:27.550, Speaker A: So what are the bars? The blue is zero day, and then the red one is from zero day to one week. And then you get from one week to one month, the next chart and then you get from one month to three months. And then at the very top, that little piece is something which is more than a year after expiration volume. Volume traded volume of options on the S and P 500, which is the biggest contract. This is not just constrained to zero day. If I condition on a day when there's one day to exploration option and then you will see that those guys also kind of concentrated. So if you're thinking that this might be because people are closing their positions, that's not what's driving that.
00:06:27.550 - 00:06:59.142, Speaker A: It's just real trading of options with very short time to exploration. So we got inspired by this, well, this thing, the zero day is a very recent thing. And so I did get inspired by that to do something which I'm not going to show you today because it's too preliminary. So we looked at this data and the volume was one way to measure liquidity. But for many of the things which we need to do, you just also interested with the option data and how many strikes you have.
00:06:59.198 - 00:06:59.390, Speaker B: Right.
00:06:59.422 - 00:07:27.994, Speaker A: So strikes per maturity and so basically how many options with different strikes. That, that's what matters to you. As you will see for some of the expansions that I'm going to do later on. And those are out of the money options because basically either you take only puts or you take only calls or you just take out of the money options a put to a call. And that's, that's how we count those. And these are zero what you see on the, what you see on the top plot here. Yeah, I keep doing that.
00:07:27.994 - 00:07:51.822, Speaker A: So. Sorry. So these are zero date options on the, on the, on the screen. All right, so these are, these are, this what is on the x axis. This is the time of the trading of the trading day. So we are looking at starting in the morning and going all the way. This is the options.
00:07:51.822 - 00:08:06.422, Speaker A: Actually they close it here. They expire at 04:00. Okay. And so look, this is a zero day option. And then you're getting the 50th quantile is the one that. The dots in the middle or the circles in the middle. Okay.
00:08:06.422 - 00:08:38.074, Speaker A: And what you see here is that you basically start with on average something like 30 strikes. That's a lot, right? I mean, and then you go all the way down only when you approach 04:00. Basically this starts shrinking. Really? Why? Because you have a minimum tick size and then that all of a sudden becomes a very big move if you are like 1 minute to expiration. But even just 1 minute to expiration, you will still see a lot of volume. If you look at the one day option. Now, of course, they will have, at the end of the trading day, they will have one more day to expiration.
00:08:38.074 - 00:08:56.388, Speaker A: It's a very healthy, stable, basically strike count of 70 options. So that's a lot. I mean, that's a lot for us to play with. Okay. And if you look at the. Yeah. Do we have an idea how many of these are drawn by algorithms? This is very difficult to know.
00:08:56.388 - 00:09:21.184, Speaker A: I don't know. Yeah, yeah, I would, I would, I would. Especially since I'm recorded, I would not say anything more. Yeah. We should have taken this option off the table, you know, the recording. And so, yeah, I say some kind of anecdotal evidence, but, you know, I wouldn't. Yeah, I don't think it's only algo trading here.
00:09:21.184 - 00:09:37.636, Speaker A: Okay. And then the other dimension on which we can measure for us, liquidity is important is how big is the range of the strikes? And what I mean by this is basically say that the strike, you compare it to the stock price and you.
00:09:37.660 - 00:09:40.806, Speaker B: Think, how big is that gap in.
00:09:40.830 - 00:10:27.728, Speaker A: Terms of standard deviations? Okay, how many standard deviations? And so, you know, and if you look at the strike gap for the zero date options, what you can see is that they're pretty good. Strike range from five sigmas, five standard deviations all the way to three sigmas, and only at the very end, it starts basically kind of narrowing a little bit. But even at the very end, you're still like two sigmas, which is not, not so bad. So that's pretty good. And then when you're looking, of course, at the one day options, they actually have no problem on that dimension. So overall, this is just suggestive evidence that it's just a lot of trading, a lot of volume. Bid ask spreads are normal.
00:10:27.728 - 00:11:25.306, Speaker A: They are not that different from any other options you see with any other expirations and the strike range. And the number of strikes is pretty good. And so basically, I will develop now what I will do now in this talk will discuss with you methods for doing all sorts of non parametric analysis with these short dated options. Okay, those were the plots for now. Then I will go to math a little bit, but again, it will be not that much, so don't worry. So then you ask yourself, what can we learn from these options? So let's just basically, just think about what we can learn from this, what is the best thing we can hope for? And then try to see methods or ways to separate or analyze the data. And so we will work in continuous time, because it's much easier when you work with options to cast things in continuous time.
00:11:25.306 - 00:11:48.324, Speaker A: And so we will have an underlying price here which will evolve according to this equation. So what we have is the stochastic volatility. So many of you are familiar with this terminology here. So this is the stochastic volatility. This is DW, is a brownian motion increment. And this thing is a jump part of the process.
00:11:49.704 - 00:11:53.872, Speaker B: So a little bit of, so I.
00:11:53.888 - 00:12:30.974, Speaker A: Will not spend much time with explaining notation, but just to say a little bit here about this notation of jumps, you might not be familiar with, but it's actually not a very complicated thing. Mu is a measure which counts how many jumps took place over an interval of length DT and of size DX. That's all it means. Mu is just, it counts. It's a counting measure. It's about the realization, and nu is how many jumps of this size over that interval you expect to happen. So mu is about the realization and nu is about the expectation.
00:12:30.974 - 00:13:03.474, Speaker A: And so when I look at mu minus mu, what happens is basically, that's like a martingale measure. And that puts this piece here, the jump is here on equal footing with the continuous piece here, which is also a martingale. So it's just a convenient way of representing the jumps in this setting. Okay, now everything here. Yeah, we were talking about the description of the data.
00:13:04.134 - 00:13:06.598, Speaker B: Now I want to focus on short dated options.
00:13:06.646 - 00:13:08.942, Speaker A: Yes. I don't look any more to the others.
00:13:09.038 - 00:13:13.654, Speaker B: And is that specific for that combination there? Or this is a more general.
00:13:15.234 - 00:13:39.150, Speaker A: Oh no, you mean this? No, no, again, I keep doing that. Okay. No, no, no, this doesn't, this, obviously there's an underlying dynamics which holds. So this is not related to the short dated options, but what will be related to the short dated options. What I will tell you is what we can learn about these dynamics from the short dated options in a model free way. Right? I mean, this thing, there's an underlying model dynamics. It does.
00:13:39.150 - 00:14:09.698, Speaker A: And from seeing options written on the price, we will be able to extract something about these pieces here of the model. Just to clarify, again, if you are familiar with optional data, this should be no surprise. But of course there is a risk neutral measure, and then there is a statistical probability measure. The usual rotation. P is for the true probability and q is for the risk neutral probability. Pricing of options will be under the risk neutral probability. But the good thing is that at least if you're interested in this piece.
00:14:09.746 - 00:14:11.834, Speaker B: Here is that, that's the same under.
00:14:11.874 - 00:14:52.016, Speaker A: P and q, right? I mean, so sigma T doesn't because of equivalence of the two probability measures. That's not true for the jumps and the jumps. Basically, in fact, what this new is, can be very different. Basically what your expectation, because it's an expectation and expectation can be different under the true probability measures. And in fact, typically that's a very different, this new, this compensator or how many jumps you expect under the risk neutral probability measure is just very, very, very different from the true realization of jumps. And basically that's a risk premium component.
00:14:52.040 - 00:14:57.432, Speaker B: That I will come back to. Okay, so there's the underlying dynamics.
00:14:57.488 - 00:15:29.428, Speaker A: And now let's see what we have and what we are going to use is just introduce here notation option data. So hopefully my notation is intuitive. C stands for call and p for put. Okay, put. Theoretically, the value of these other options, as you are familiar, this is the payoff of a call. And then you just take the conditional expectation and the same thing for the puts. Hopefully this is no surprise here for you.
00:15:29.428 - 00:15:59.760, Speaker A: And what I've done, of course you might have noticed that I have forgotten about discounting. It's because we will be looking at short edit options and I can just pretend it's not there. It really makes no difference and just simplifies the notation. So I don't carry around risk free interest rates and dividend yields and things like this, but it makes no difference. This is just to simplify exposition. Okay, so this is what we have. So this is what we are going to work with.
00:15:59.760 - 00:16:31.944, Speaker A: We have a bunch of calls and puts with different strikes. That's basically what we will be given access to. And what I'll be interested, when I say short dated options, I mean that the capital t, which is the time to expiration, is short. And if you do asymptotics with this thing, it means that you are thinking of what happens when t goes to zero. That's basically what I will be using here. All right, so again, I'm kind of continuing on this topic of what can we extract from shorter topions. So now many of you know that.
00:16:31.944 - 00:17:31.928, Speaker A: So that's a well known fact that if you take the second derivative of the call price, and that's a trivial algebra, you can differentiate under the integral conditions. Of course, you recover the risk neutral density. So now risk neutral density, which means that basically if I observe all strikes for a given capital t, and here there's no assumptions on how big is t, then I can recover the whole risk neutral density, right? I mean, we can invert and recover the risk neutral density. Now here comes on the one, two, three, the fourth bullet point. The second to last is where the time to maturity starts playing a role. Because if the model is levy, and so I don't know how, whether you know what levy means. Levy basically means, let me just go back here.
00:17:31.928 - 00:18:05.596, Speaker A: Levy means that the sigma doesn't depend on t. So the volatility is constant and that the jump intensity is constant. So in other words, if the model is iid, it has IID returns. Okay? So in this case, it's a well known fact that actually the law over one increment identifies uniquely the law of the process. Okay? So there's a one to one mapping between knowing the distribution over one increment of the process and knowing the whole distribution of the process, characterizing completely the process. This is a one to one map.
00:18:05.700 - 00:18:08.212, Speaker B: If the model is levy, model is.
00:18:08.228 - 00:18:34.188, Speaker A: Not levy because volatility changes over time. We know that in reality that's not the case. But if time to maturity is short, actually we can pretend basically if time to maturity is short, it's the same, approximately volatility remains constant over the interval and so does the jump intensity. And so what that means is what can we identify from the short edit options?
00:18:34.276 - 00:18:40.704, Speaker B: We should be able to identify from the short dated options both sigma t.
00:18:41.024 - 00:19:14.500, Speaker A: Just the value of sigma t. It's a random number, but I should be able to identify at time t its value. Okay. And I should be able to identify even perhaps more importantly, because you can't do it from returns the value of the jump compensator. That's a function, right? Nu is a function, sigma or sigma t is a value. It's a real number, positive number. But new is a function which tells you what is the distribution, the jump distribution, the distribution over the jump size.
00:19:14.500 - 00:20:11.022, Speaker A: So you can identify both those two things from short edit options. This is what's basically unique about the short edit options. We should be able, from following that logic which I showed you here, I know that if I have all the strikes, I can identify the risk neutral distribution because over short intervals of time, the model has to be approximately levy, or in other words with IID increments. Then I should be able to identify both the volatility and the jump distribution, the distribution over jump sizes from the short dated options. That's as much as I can get from the data and that's what we are going basically to achieve. Well, that's what we are going to do here. Actually, that's not all.
00:20:11.022 - 00:20:38.056, Speaker A: What you can identify with this, but the first order effect. So the first thing is this. What you can identify, I'll afterwards hope to do. But it gets a little bit more difficult, is things which capture how sigma t varies over time or how nu t varies over time and things like that. Actually, there's a second layer of things you can identify as well, but it gets a little bit more evolved. The things which I will show you.
00:20:38.080 - 00:20:40.952, Speaker B: Here, I think are relatively straightforward, at.
00:20:40.968 - 00:21:06.712, Speaker A: Least in terms of methods in implementation. So it's not going to be that difficult. So my first part of the talk. So basically, before we have coffee, I will talk about somehow I will reverse them. I'll start from the jumps and then I'll go back to the volatility. Somehow the jumps is a little bit more tricky. And so I will start from there and then I'll go back to the volatility.
00:21:06.712 - 00:21:19.016, Speaker A: Although probably, given the size of the literature on volatility, I should have probably start with volatility and then go to jumps. Okay, so I'll do it this way. Okay, so I'll start with this.
00:21:19.200 - 00:21:20.084, Speaker B: Okay.
00:21:21.684 - 00:21:49.804, Speaker A: Okay. Yeah, that's the first part. So something about the jumps. Okay. And so how do we recover the, how do we recover this jump distribution? It's from the short dated options and they are different. So there are different ways you can approach that problem. And the way I'm going to, basically, what I'm going to show you is the way I.
00:21:49.804 - 00:22:02.052, Speaker A: And some of my, by the way, this is based on a lot of papers that I have written with many people. And so, and so the way I started thinking about this was from something.
00:22:02.108 - 00:22:08.116, Speaker B: Which should be probably easier and arguably.
00:22:08.180 - 00:22:27.520, Speaker A: Probably important because it is about tail risk. So something about the tail. So I'll just try to recover this function here, which captures, again, this is a function over the jump size. I'll just try to characterize it in details for the extremes. Okay. For the extreme sizes. Okay.
00:22:27.520 - 00:22:33.724, Speaker A: So I will try. We will do this. This should be an easier thing. And it is.
00:22:35.544 - 00:22:36.664, Speaker B: But requires a little.
00:22:36.704 - 00:23:06.528, Speaker A: Bit more assumptions, as you will see later on. And so then what I will do, actually. And then I will go and recover the whole function. So, turns out, actually, that's not that difficult. And finally, I will spend a little bit of time on talking of distinct, which probably, when I write it like this, it doesn't tell you much, fixed times of discontinuity. But here I just follow probability literature and fixed times of discontinuity. Time, that's how they are defined.
00:23:06.528 - 00:23:41.944, Speaker A: And what I'm talking in simple words about, these are the so called event risk. If there's an FOMC announcement or if you have an earnings announcement and things like this, this is the thing which is pre announced where you basically know when the jump will arrive. The typical, the standard jumps which we use in our continuous time models, they usually say they are like Poisson distributed, right? Randomly distributed arrive. But actually for a lot of the jumps that of interest, maybe this type of the ones like fomcs and things like this, this is actually.
00:23:44.324 - 00:23:44.796, Speaker B: There'S no.
00:23:44.820 - 00:24:27.490, Speaker A: Uncertainty about the time of the jump. Okay. So I will discuss this because again, I just think that the techniques there are a little bit different, but I think that it's actually quite practical, this topic, because in addition to that, if you have look at option data, I don't know whether you have looked at this type of data for individual stocks before announcements. It's just an explosion of trading because it's like an auction on what's going to happen. Basically, to read what's happening with the earning, let's get started. Then. The first thing is, as I said, I will try and talk about this parameter distill component of the, of the, of the measure.
00:24:27.490 - 00:24:32.930, Speaker A: Okay. And so, so something about the big, something about the big size.
00:24:33.002 - 00:24:37.106, Speaker B: Okay, so how do we do that?
00:24:37.210 - 00:25:12.790, Speaker A: Okay. And that's the option data I'm going to use. I already defined them. But so basically for you. So I don't need to spend much time here to explain just to say that what I'll be looking at, I will looking out of the money options, which means that options, you take either the call, if the strike is above the spot price today, or you take the put, if the strike is below the stock price today, these options, if they are expiring today, they will be worth zero. Okay, so these are cheap options. And as the time to maturity approaches zero, these guys decline in value, right? There's a time value which decay kind of, of the option.
00:25:12.790 - 00:25:38.610, Speaker A: So we are just using out of the money, out of the many options. All right, so here's the one way to, an easy way to identify these tails is the following. Basically you say that the thought process is captured by the two bullet points. So you say, okay, if I'm looking over a very small interval of time, then the only way I can generate.
00:25:38.642 - 00:25:42.550, Speaker B: A big move of a big return.
00:25:42.702 - 00:26:39.944, Speaker A: Is if there was a jump, right? And so, in fact, the jump truncation in high frequency data return data procedures are based on the same idea. And so of course there's a specific threshold which is considered big and which is considered small. And so basically if I'm looking at larger and larger thresholds and over smaller and smaller intervals of time, returns over small, small intervals of time, the only way they can be triggered or happened is basically if there was a jump. So if I'm looking just to give you a sense, if I'm looking at one day to expiration option and I have ten standard deviation move, that cannot not going to happen with a diffusive volatility move, it has to be a jump, okay? And so technically there is an asymptotic formal argument which basically tells you, allows you to link the tail behavior of the return with the tail behavior of the jump component, okay?
00:26:41.204 - 00:26:43.420, Speaker B: Even if you don't know.
00:26:43.492 - 00:27:52.054, Speaker A: So of course there's an approximation error in this, right? I mean, so I will tell you that the return over two days, a 5% can be generated only by a jump. I mean, immediately you can see how there's some kind of a wild volatility move which can generate probably something like this. Even if you're not happy and don't buy this assumption, what I'm going to show you here works perfectly, meaning that I will be always recovering the tail of the return, of the short return over a short interval of time. Whether you want to link it all the jumps, it's up to you. There will be an approximation error. We can improve on that once we go to the alternative method that I'm going to tell you. But what this, this will do, it will give me just a very simple thing to identify the tail, as you will see now, okay, so I will assume the usual thing, regular variation of the, of the, if you have worked with this tails or extreme value theory, then the natural thing which you do is you assume that there's a regular variation of the levy measure in the tails.
00:27:52.054 - 00:28:22.244, Speaker A: But you have to be careful. You have to do it. You can't assume a power law decay for log jumps, for jumps in the log price because then the price will be infinite and so infinite moment. So that's not going to work. And so what I will going to assume is that this is technical detail. So in some sense this is not so important. But I will assume that the regular variation is for the jump in the level, not in the log in the low price.
00:28:22.324 - 00:28:22.780, Speaker B: Okay?
00:28:22.852 - 00:29:09.004, Speaker A: So that, so this transformation, fancy transformation, complicated transformation is just for that. So this side is just to capture that, okay? And then all I'm saying is, and is that the functions, which is basically the behavior of these jump measures in the tails. You see, it's like this. It's x to the power minus alpha times something, which is a slowly varying function. And because of this function l of x, I can call it a non parametric procedure. Okay? That's what extreme value theory people do. Okay? They call this thing non parametric, but in reality, you basically just forget, you say you forget about this l and you do like, basically the tail of the measure is like x to the power minus alpha, which is a parametric law.
00:29:09.004 - 00:29:30.692, Speaker A: And what a parametric model, if you have worked with this, this is the double exponential model. That's basically what it is for the jumps. Double exponential model. In details, that's all we assume. Okay, there's a lot of fanciness here, which we don't need to spend. Basically, how much is the slowly varying function deviating from one and things like this. In a way, these are details.
00:29:30.692 - 00:29:31.524, Speaker A: They're not important.
00:29:31.644 - 00:29:34.396, Speaker B: But what this thing does is, you.
00:29:34.420 - 00:29:35.652, Speaker A: See, if I look at now at.
00:29:35.668 - 00:29:38.812, Speaker B: The option price and I normalize it.
00:29:38.828 - 00:29:53.650, Speaker A: By the stock price, it's basically driven by two parameters. I don't know whether this becomes obvious because there's just a lot of pluses and minuses, but there are two parameters. One is the level and this is at. And the other one is the alpha, which is the tail decay parameter.
00:29:53.722 - 00:29:54.050, Speaker B: Okay?
00:29:54.082 - 00:30:40.494, Speaker A: So you have a tail decay parameter on the left and take care parameter on the right. Okay? And that's basically you're saying that approximately the option prices in the tails, when you're looking at deep out of the money, deep out of the money puts and calls, they have this kind of a parametric, parametric law. Or even more explicit, just to show you what's happening here, if I take the log of the option price, the log of the option price is a linear function of the log of the strike. It's a linear function, just a simple linear function. And so how can I estimate these parameters? Well, just run the OLS. Basically a low option price against log strike. So in some sense, this is, again, if you have done anything with extreme value theory, this is basically like the hill estimator.
00:30:40.494 - 00:31:16.454, Speaker A: It's the same thing, but you apply it with option prices. So let me show you how this thing looks on data. This is one point observations. These are short dated options from ancient times when we didn't have zero dtes or they were there, but probably not traded that much. And so what I plotted on what you're seeing is on the x axis, you're seeing log moneyness. So if you're familiar with this, what that means is that basically, this is the log of the strike over the spot price. Okay? And so zero means that you are at the money.
00:31:16.454 - 00:31:48.038, Speaker A: That's the money option. And to the left, you are looking at out of the money puts, and to the right, you're looking out of the money calls. And so basically, that means here that this option that I'm looking here is four standard deviations down. Strike, which is four standard deviations down. It's just easier to quote with standard deviations because you kind of think about returns and how big are those moves? And so the stars or the dots on the, on the plot, these are the log option prices. The log option prices. Okay.
00:31:48.038 - 00:32:12.600, Speaker A: And as you see, on the top is the highest one. That's basically the add the money option price. And then you're seeing kind of. They are gradually decaying, the monotonicity restriction on the option prices. And then here they also gradually decaying. And what is remarkable is that this thing fits pretty well, right? I mean, it's just such a simple thing in the tail. You see, for the calls, it fits pretty much from the.
00:32:12.600 - 00:32:38.984, Speaker A: At the money. But what's happening with the right tail, it's so thin that you see it's kind of dropping very fast. With the left tail, it's not as thin. And definitely, we are not the fun. The log option price is not linear in the log strike over the whole range. But that's fine, because the extreme value theory is telling you that you should have familiarity in the tails. And look, you pretty much from two and a half sigmas on, it does look like a.
00:32:38.984 - 00:33:04.612, Speaker A: Like a straight line. Yeah. Do I run that for all my log strikes or. I'll tell. Yeah. So I just, I just basically, the usual thing that we do with the high frequency thing, we take three sigmas down, basically something like here, because the asymptotics should kick in. You see, there's a kink.
00:33:04.612 - 00:33:12.388, Speaker A: Actually, it's. And you should kind of do it that way. So.
00:33:12.556 - 00:33:13.202, Speaker B: Okay.
00:33:13.308 - 00:33:40.912, Speaker A: And then now, one thing is that's basically. So. I mean, if you want, you can call that thing that. Okay, so I'm going in the wrong direction. So you can call that thing a parametric model. Or if you don't like the parametric model, basically, there is the non parametric error approximation coming from deviations from the power law. But, yeah, so it's a very simple law.
00:33:40.912 - 00:34:10.336, Speaker A: And the way the jumps can vary over time here can happen from two sources. One is level shifts. So the whole levee measure can shift up and down, or the shape of the tails can move over time. This level shifts. Basically, think about, this is the standard way in which we model time varying jump distribution. So you're saying that the jump intensity is varying. Right.
00:34:10.336 - 00:34:48.740, Speaker A: It's proportional to volatility. Right. That's the traditional models that we write in continuous time because of analytical tractability. They will tell you that basically, the only way we can get this jump distribution to vary over time is if we shift the whole intensity for jumps of all sizes shifts up and down. Within this non parametric setup, however, you can have also situations in which the shape of the distribution can change. And, for example, we can get scared. And only the big jumps in size can become kind of more likely, in other words.
00:34:48.740 - 00:35:09.714, Speaker A: And so that's basically an illustration of what I'm saying. That's the level shift. This is the traditional parametric affine models that will do you this. So you can kind of shift them up and down, but you shift the whole level of the jump intensity. And the shape one is basically, you're just twisting it, right. So you're doing this.
00:35:09.794 - 00:35:10.534, Speaker B: Okay.
00:35:11.154 - 00:35:32.034, Speaker A: Okay, so we've done so. Okay, so that's it. And that estimation is super simple. As you can imagine, this is just running a bunch of OLS regressions over different days. And so when we estimated this, this is what we got. I mean, as you can see here, my data ends in 2014. That's a little bit dated.
00:35:32.034 - 00:36:01.622, Speaker A: It's taken from a paper that I've written with Tim Boleslav many years ago. But this is what you will get if you estimate the tail parameter. Remember the shape parameter. The shape parameter, okay, sorry. The shape parameter will be the tink, which is appearing here, which depends on the, on the moneyness, okay. It tells you how fast the option prices decay in strikes. Okay.
00:36:01.622 - 00:36:06.918, Speaker A: As we get out of the money. Okay. And so that parameter, what we've done.
00:36:07.046 - 00:36:10.686, Speaker B: We took the inverse of that, and.
00:36:10.750 - 00:36:12.150, Speaker A: That'S what we plotted here.
00:36:12.262 - 00:36:12.790, Speaker B: Okay?
00:36:12.862 - 00:36:31.206, Speaker A: So one over that index. And so the reason why we did it, one over the index is when you do it that way, high value means that the tail becomes fatter, becomes more fatter. And you can see, basically, when we do our parametric models, we assume that.
00:36:31.230 - 00:36:33.550, Speaker B: That thing is constant.
00:36:33.662 - 00:37:25.660, Speaker A: We just force this thing to be constant, and we put all the variation to come here from this intensity part. The data very clearly tells you, when you get to these periods of the crisis of zero, eight, et cetera. And later on that there's actually, there's a lot of, if you want, in relative terms, the dip out of the money puts become much more expensive than, say, add the money options. Something like this basically is captured by this. And that unaffined model basically cannot, parametric model, cannot do it, cannot capture it. Now, once we have, so basically with these two parameters and on the right tail, I don't want to say much because it, if you look at especially the intensity parameter, you see how choppy it looks. So clearly it's not very reliably estimated because it's very small.
00:37:25.660 - 00:38:00.760, Speaker A: So maybe I don't care so much about it because it's just tiny. It's tiny. And so, in fact, I'm going to concentrate on the left tail part here. And now these two parameters characterize the whole tail. I can map it into tail variation, or in other words, I can basically calculate how much of the volatility, of the return, volatility comes from this left tail part. That's easy to do. Basically just calculate the second truncated moment from this model.
00:38:00.760 - 00:38:43.662, Speaker A: That's not that difficult to do. These are the formulas here. And here's how it looks. It looks like the VIX index, except that it's much more spiked during the crisis and in the crisis. And this is where the difference with the VIX index will actually come from when we go to return predictability, because that's basically what I'm going to do next. So one application of this analysis is basically, look, now what I have is I have, what is this? This is the risk neutral expected tail variation. Okay? Jump tail variation.
00:38:43.662 - 00:39:11.914, Speaker A: And that's risk neutral. But if you look at the sigmas and this is for how many, for, what did I say? For ten sigma move. For ten standard deviation move. Okay, that thing, if you look at in the terms, it's pretty much zero. So what we decided is we just pretend that the counterpart of this quantity under the true probability zero, you just ignore it. And if that's the case, then what I'm looking at here should be just a risk premium. It's just a risk premium.
00:39:12.034 - 00:39:14.210, Speaker B: But if it's a risk premium, it.
00:39:14.242 - 00:39:26.082, Speaker A: Should help predict the returns. And so that's one way economically to test that. What I'm capturing is real. And so what we did is we.
00:39:26.098 - 00:39:29.022, Speaker B: Said, okay, well, I identified in a.
00:39:29.038 - 00:40:09.580, Speaker A: Model free way a tail variation from options. And now let's see if that thing predicts returns. And so this is from a paper I published in 2015 about this and so we run the usual horse race predictive regression with all the caveats and all the things about these predictive regressions. And that's basically the measure which I was using on the previous slides, which I was showing you, is the first one here. And it does very well. And it's kind of highlighted. I wouldn't highlight, I don't know, we should not have put the red on the r squared because r squared is exactly, probably the last thing you want to look at in these predictive regressions, but it's more driven by outliers and stuff.
00:40:09.580 - 00:40:56.226, Speaker A: But if you look at the t statistics, they're pretty, pretty high for this type of predictive regressions, and it holds up well. Again, basically, it holds up well against alternative predictors used in the literature. One of them is the so called variance risk premium. Okay? So I don't know whether you guys have heard about it, but various risk premium. So one of the quotas on this paper, meaning dollars left, he has written about that, that variance risk premium, which is basically, you look at the VIX, which you take from CBO, and you subtract from it the realized volatility over the month. Okay? And that thing, they've discovered in some of their earlier work that it's a very good predictor for stock returns going forward. Okay.
00:40:56.226 - 00:41:11.754, Speaker A: Variance risk premium. So these days, you will actually probably see a lot used as a controls and checks as one of the potential candidates. And so, but now what this jump variation that I'm extracting here, which is.
00:41:11.834 - 00:41:15.362, Speaker B: Okay, so now it's completely messed up.
00:41:15.378 - 00:41:28.070, Speaker A: Okay. So, no. Yeah. Okay, so let me get back to this. Okay. This jump variation here is just a component of the VIX index. And in fact, it's the tail part of the VIX index.
00:41:28.070 - 00:42:16.342, Speaker A: And so what happens if you remove from this variance risk premium, this tail component, and you basically, you will see that this guy is basically almost driven out to almost nothing. Basically no predictability. So in other words, this variance risk premium, that the source which we attribute for this predictability or success of the various risk premium is coming from this tail part of the jump distribution, a large piece of it should be at least corresponding to it. So if you do over different horizons. So that what I showed you was for six months, but if you can do it for any horizon starting from one month and going all the way down to one year. So this is measured in months. And so you see the black line is the t statistic corresponding to the left tail measure.
00:42:16.342 - 00:42:38.274, Speaker A: Okay? And then the dashed line is the one corresponding to what remains from the variance risk premium. So varian. So VRP minus LJV. So that the other component of the variance risk premium. And see that the other component of the variance risk premium, it's very, very tiny, basically, compared to the, to the tail parts. So, yeah, so that tail piece, it's.
00:42:38.314 - 00:42:43.090, Speaker B: Big, it's significant, and just like it's.
00:42:43.122 - 00:42:52.014, Speaker A: Internally consistent because it actually, it helps kind of, it drives also some of the predictability or some of the dynamics, at least of the equatorial.
00:42:53.034 - 00:42:57.814, Speaker B: Okay. All right. So is that.
00:42:58.634 - 00:42:59.534, Speaker A: Okay?
00:43:00.074 - 00:43:00.894, Speaker B: Ish.
00:43:01.654 - 00:43:20.046, Speaker A: Okay, so what I'm going to do now, I'm going to do is. So that's a simple analysis and. Okay, so let's see, if I say it here. Yeah. Okay, I say it here. Yeah. Theoretically, at least, to develop this analysis, I did two things.
00:43:20.046 - 00:43:53.804, Speaker A: I needed my time to maturity to go down to zero. And then I also had to use deep, deep out of the money options. Okay. Now, so this kind of like a double asymptotic type of, kind of argument where you're going really deep in the tails at the same time as you're shrinking the time to maturity. If you don't want to kind of, if you don't want to be making this, if you. If you want to drop the first part of the assumption, then what I did so far is just estimating you the tails of the returns. And that's fine.
00:43:53.934 - 00:43:54.560, Speaker B: You can.
00:43:54.672 - 00:44:02.764, Speaker A: Ten is perfectly interpretable. The part which requires t to go down to zero is the part which connects this with the jump behavior.
00:44:04.384 - 00:44:08.192, Speaker B: But now what I will do is.
00:44:08.288 - 00:44:34.820, Speaker A: First of all, you just estimate only part of the jump distribution. And so what I will do now is an alternative method which basically gives you the whole jump distribution, not just the tail part of it. And so I will not, I will not require anything about strikes going to infinity. Well, I will require them to increase to infinity, but this component will not be such critical in all of this and all of this analysis.
00:44:34.892 - 00:44:41.940, Speaker B: Okay, so in that sense, it's a more, it's a more robust method.
00:44:41.972 - 00:45:07.416, Speaker A: It's prone to less error, basically approximation error of approximating. If you're interested in, again, approximating the jump distribution and not just the return distribution. Okay, so what will be that? So let me remind you again, one more slide here. Just to remind you. That's a repetition. So what I'm interested in, remember, is the jump distribution. So basically this function, which I called.
00:45:07.480 - 00:45:10.160, Speaker B: Nu over x, the jump size.
00:45:10.192 - 00:45:56.924, Speaker A: So I'm trying to see what is the distribution over jumps of different size. I keep calling it jump distribution, but in technical terms, that's not a jump distribution, because this measure might explode in zero around zero. So in actually, only the x squared is integrable around zero. But in some sense, this is probably a technical detail which we don't need to get into, because most of the applications, you will probably have this finite activity specifications. So, in any case, I will be interested now in estimating the whole function for any value of x, basically. So, for any value of the size, I want to know this thing. So how can you recover that? So, now, this is a little bit more involved at first glance, but actually, as you will see, it's not that complicated.
00:45:56.924 - 00:46:23.884, Speaker A: And the idea is very simple. And I will basically heavily rely on this expansion or option spanning result that you might be aware of. So, if you look at this thing, what is this? So, conditional expectation of a function of the stock price at expiration is equal to the function of the futures price today. So you know this thing, you know today, right? This thing you know today, plus an.
00:46:23.924 - 00:46:28.412, Speaker B: Integral over options with different strikes, right?
00:46:28.548 - 00:46:49.250, Speaker A: And so, if you look at this, okay, leaving aside the fact that we don't have optional observations for any strike, okay? But if you suppose that for a minute that we have that thing, then this integral, this integral is actually, this integral is actually known. If you have the option observations, this thing is known. And what that thing does is allows.
00:46:49.282 - 00:46:53.418, Speaker B: You to estimate the conditional expectation of.
00:46:53.466 - 00:47:16.226, Speaker A: Any smooth function of the terminal payoff. So it's a very useful result, and it's also not very difficult to derive, but simple results. So that was kind of a. It's a very nice result. I don't. I saw it in Karl and madame. Maybe early iterations appeared somewhere.
00:47:16.226 - 00:47:45.504, Speaker A: I don't know, Chris, whether you know that, but I think that bakshi also had something. So I don't know. I hope I'm giving the right credit to people, but this shows up in there, in somewhere hidden in the appendix. It's a simple result and very useful. So I'm going to use this result. This applies for general function, but what I will going to use it for is the following. I will apply this thing with the function, with the characteristic function.
00:47:45.804 - 00:47:46.236, Speaker B: Why?
00:47:46.300 - 00:47:52.644, Speaker A: Because characteristic function preserves all the information about the return distribution. And so I should be able from.
00:47:52.684 - 00:47:56.260, Speaker B: There to recover somehow the levy measure.
00:47:56.292 - 00:48:41.342, Speaker A: Or this jump intensity or jump distribution function, whatever you want to call it. Okay, so apply again this formula, and I will apply it for the characteristic function. So, basically, I will apply it for the function e to the power iu, the specific formula is here written, okay? And here for any value of the characteristic function of the characteristic exponent. Right? So you have this function. It's a simple thing which you can just code up in one or two lines is this thing. Okay, and now what is the connection, what is the connection with the levy measure? How do you connect with the levy measure? Well, there is the thing, the thing which I told you, now we are looking at over very small interval of time, you can pretend that volatility and the jump measure remain constant. They don't change.
00:48:41.342 - 00:49:16.330, Speaker A: Or in other words, we are in a levy case, if you want. And there's this formula called the Levy kinshin formula, which is written up here, which relates the conditional characteristic function with the drift term, the volatility and the jump measure. So again, I have access to this. From the data, I can estimate this conditional characteristic function. But what it really does, the logarithm of it is just this expression here. I don't know a, I don't know sigma and I don't know nu. What I'm trying to learn is nuke.
00:49:16.330 - 00:49:43.154, Speaker A: That's what I'm trying to learn from this. So how do I do it from this? And what I give myself, the freedom is to observe for any value of u, okay? For any value of u, I have access to any value of u of this characteristic function. Well, it has to be possible because we know from the Levy kinshin formula there's a one to one law between this conditional characteristic function and sigma and nu. Okay? So there has to be a way to do it.
00:49:43.784 - 00:49:47.344, Speaker B: And one way to do it is actually very simple.
00:49:47.384 - 00:50:14.434, Speaker A: So look the way this, what is from my point of view now, nuisance parameters is very simple. This enters in u to the power one and here enters to u to the power two. So why don't I differentiate the function here? If I differentiate once, this becomes I times a. If I differentiate twice, this thing disappears. If I differentiate three times, this thing goes away.
00:50:14.974 - 00:50:16.478, Speaker B: This, however, doesn't.
00:50:16.646 - 00:50:33.646, Speaker A: In fact, if you differentiate this under the integral, what you will get is this. See, the third derivative of the conditional characteristic function is just this. Now I say, well, what is this? But if you look at this, well, if you look at this, this is.
00:50:33.670 - 00:50:36.782, Speaker B: Just the characteristic function because it's e.
00:50:36.798 - 00:50:49.582, Speaker A: To the power iu, x is the characteristic function of not my measure new, but my measure nu multiplied by x to the power three, x to the power three is known, right? So I can recover x to the.
00:50:49.598 - 00:50:52.382, Speaker B: Power three times nu from this, because.
00:50:52.438 - 00:51:02.166, Speaker A: This is, again, the characteristic function. I can just apply Fourier inversion. Right. The usual kind of results. So just. Just do a Fourier inversion. And so that's basically it.
00:51:02.166 - 00:51:09.506, Speaker A: So what I will do is, in a nutshell, is the following. I will estimate from the options. And so I will just fill you in with the details.
00:51:09.530 - 00:51:12.450, Speaker B: Now, I'll estimate from the options the.
00:51:12.482 - 00:51:30.964, Speaker A: Conditional characteristic function here. Okay. Differentiated three times. And this will give me the characteristic function of x to the power three times the function I'm interested in. And then I will just apply for classical Fourier inversion. And that's basically. That recovers the function.
00:51:30.964 - 00:51:33.704, Speaker A: It recovers the function. This function here.
00:51:33.784 - 00:51:36.564, Speaker B: Okay, now.
00:51:37.944 - 00:52:01.644, Speaker A: Yeah, well, I already. Yeah, the t. The part where. Okay, if the model was levy. In other words, if I was assuming. So in the model. In the model is levy, then it is for any t model, levy means that this thing doesn't change as I change the capital t.
00:52:01.644 - 00:52:22.044, Speaker A: But if you. If you believe that this thing changes over time, I need the capital t to be small, so that approximately stays constant. So that's why I need the capital t to be going down to zero for a levy model. You don't. You don't need any of that. Yeah. So you are not making.
00:52:22.044 - 00:52:28.522, Speaker A: Or you are making. I am making. No. No, because. No, because. Okay. So this is just to motivate the things.
00:52:28.522 - 00:53:01.184, Speaker A: Afterwards, there's an approximation error, and then I control and derive the approximation error. So it's done for a general process, but it's much easier to explain in the levy case, in the IID case. So. Okay, now, if you have done some of this type of analysis, you know that it's not a good idea to differentiate estimators. Okay. It's not very good. So, yeah, I got very excited because it's so easy now.
00:53:01.184 - 00:53:28.464, Speaker A: It becomes like second derivative, third derivative, and then you are kind of. You directly kind of estimate the thing and you basically separate. You don't need to make a stand on the. You don't need to make a stand on the volume on the volatility and any of this stuff here. But, yeah, you probably prefer not to differentiate that many times. Estimators. And so if you try to minimize it, what you can do is you can do the following.
00:53:28.464 - 00:53:40.160, Speaker A: Alternatively, differentiate twice. And so you will get rid of this guy. And then if you differentiate twice, let me see here. This is what you will get.
00:53:40.192 - 00:53:43.720, Speaker B: You will get the volatility plus the.
00:53:43.752 - 00:54:08.354, Speaker A: Second kind of the characteristic function, but f squared times nu. Then the thing is that volatility, we don't know. But we can actually form estimators for. And so you can bias correct and do these kinds of things. So you can do it that way, too. Our first goal was to do this third derivative business, because theoretically, it's easier to handle and do the stuff. Okay.
00:54:08.354 - 00:54:35.706, Speaker A: Now, of course, in reality, you don't have. You don't have a continuum of strikes, but the same way the VIX index is calculated, we do the same thing here. There's. We have options on the grid of strikes, which is relatively dense. And so you're thinking that the gap between the strikes is small. So basically. And then what I can do, I.
00:54:35.730 - 00:54:40.818, Speaker B: Can just get those. Let me get here. This.
00:54:40.866 - 00:54:47.212, Speaker A: Basically, I can estimate from the observed data, I can estimate these integrals by just simple Riemann sum.
00:54:47.268 - 00:54:47.460, Speaker B: Right.
00:54:47.492 - 00:54:57.708, Speaker A: The discretization of the. Over the grid. Right. So that's kind of. That's what we will do. And hopefully, the discretization error is not very big. Okay.
00:54:57.708 - 00:55:17.586, Speaker A: And then, of course, options are observed with error. And the error, you want to be as little as parsimonious. Assume as little as possible about the error. But one thing which is kind of critical is, of course, that the option, the error is centered. Otherwise it's not really an error. It's like a bias. So this thing is centered at zero.
00:55:17.730 - 00:55:18.386, Speaker B: Okay.
00:55:18.490 - 00:55:38.338, Speaker A: And it has variance and things like that. Okay. And this slide looks more scary than it actually is. It should be, because there's really nothing. Nothing tricky going on here. I plugged in. Basically, this is the Riemann sum discretization of the integral that I showed you before.
00:55:38.338 - 00:55:54.762, Speaker A: I just. I just did it here. So you see, you're just summing up over the options multiplied here, and then this is the increments of the log strike. Okay? And that's all it is. And this is the third derivative of the log characteristic function. And then you just keep track of all of this.
00:55:54.818 - 00:55:55.534, Speaker B: Okay.
00:55:56.434 - 00:56:23.488, Speaker A: So this is really not difficult to compute either. And then you do just Fourier inversion. So you have to invert. So this is your. This is my estimator for the Fourier transform of the function I'm trying to estimate. And then you multiply it by e to the power minus iux, you see? And then you integrate over an interval, which is kind of expanding. So you just drop the highest frequencies because they are estimated with imprecision.
00:56:23.488 - 00:56:41.840, Speaker A: And the idea is that if the function you're trying to estimate is smooth. The Fourier version. The Fourier. Sorry. The Fourier transform of the function decays fast. And that's basically how this thing is based on. So, for this key estimation, you do need smoothness, basically, of the thing you are estimating.
00:56:41.840 - 00:57:01.736, Speaker A: Otherwise, it's not going to, not going to work. And so, yeah, this is technicality. So I'm not going to get into the detail just to say that the function needs to be in a class, which is a smooth class, and the smoothness is controlled by how fast is the Fourier transform of the function decaying.
00:57:01.880 - 00:57:02.304, Speaker B: Okay.
00:57:02.344 - 00:57:20.592, Speaker A: At infinity. That's basically what that thing is capturing. These are sobolev classes of spaces. Okay. So technical details. And then basically this is the result. So, if you look at the integrated squared error, right, remember, we're estimating a function.
00:57:20.592 - 00:57:48.850, Speaker A: So you're trying to say how precise is the function, not only at the point globally. And so, one way to characterize this is just to look at the integrated squared error. So this is my estimator minus the true thing. And then it depends on a bunch of things. It depends on how smooth is the function. You're trying to estimate typical classical non parametric estimation of functions. And then it depends on the precision of the estimators on the strike grid, on the time to maturity, and on and on and on.
00:57:48.850 - 00:57:50.014, Speaker A: But. Okay, it's.
00:57:50.714 - 00:57:52.546, Speaker B: Yeah, we spent quite a bit of.
00:57:52.570 - 00:57:55.558, Speaker A: Time getting those, each of those components.
00:57:55.646 - 00:57:56.394, Speaker B: Okay.
00:57:57.974 - 00:58:33.984, Speaker A: If you do it, this is what you will get. And actually, I thought that this was pretty, pretty good. So we estimated with, this is from Monte Carlo. We estimated. So we simulated from a model which was fairly. This is basically the model which we used, the parametric model we used here is this model called car Gemman Madan, your model. Have you heard of this CGMy model? Okay, so basically it's a very general model for the jumps where you have a parameter which controls the size of the small jump, a parameter of this big jumps, a parameter for the.
00:58:33.984 - 00:59:27.616, Speaker A: Anyways, skewness. It's a lot of richly parameterized model, which was popularized, what, 1520 years ago, nests a lot of models that have been used in practice. And so we simulated from those models. This is an affine model with time varying stochastic volatility and things like this. And then what we did is we applied that procedure to the option data generated from it and what we plot here, the levy. So are the jump distribution measures coming from the model, which is the solid line against its estimator, which is the dashed line. Different specifications depending on whether we are in the low volatility regime, high volatility regime, etcetera, different values of the jump size.
00:59:27.760 - 00:59:32.440, Speaker B: So what is remarkable about this is.
00:59:32.472 - 01:00:22.674, Speaker A: That this thing works. Even if you look at specifications for which you have a lot of small jumps which you have entered into the model, which is something that the previous method is not going to handle very well, because two small jumps might be confused for one big jump, basically, if they're in the same direction, and that procedure is going to separate and tease out those things. I thought that it's remarkably. Well, I mean, of course you can see the gap between the lines. You can see the gap between the lines, especially if you look at the right tail. And so the right tail, I think, is just hopeless to recover. Well, just because there's no meat there, right? I mean, if the right tail, if you calibrate it correctly to the data, it's very thin and then there's just not information, enough information in the data, you just can't nail it.
01:00:22.674 - 01:00:29.266, Speaker A: But the left tail, you can recover. You can recover relatively, I think relatively, relatively.
01:00:29.290 - 01:00:33.426, Speaker B: Well, what I've done here, what we've.
01:00:33.450 - 01:00:43.492, Speaker A: Done here is that we stopped here. We looked at really, we didn't go all the way down to zero to zero jump size. Why?
01:00:43.588 - 01:00:48.372, Speaker B: Because you see, what you're doing here.
01:00:48.428 - 01:01:20.868, Speaker A: Is if you want really the true jump distribution, which might be exploding, by the way, at zero, you are dividing your estimator by x to the power three and x goes to zero, that thing is going to explode. So any small difference is going to be blown up. And so that's why I told you that this kind of idea of keep differentiating is probably not the best thing to do. And you might want to do a second moment. And so, but in any case, we implemented it here this way. We implemented it on the data. You can see you get something reasonable out of this.
01:01:20.868 - 01:02:33.974, Speaker A: Then we said, you know, I mean, in some sense, it's nice from a theoretical point of view. So for a statistician, that's, that's what they want, right? I mean, that's the function I want to recover the whole function. And I'm kind of happy we managed to do that. But in a way, from a practical point of view, and if you followed my analysis early on on these tell measures, what you probably, most likely what you really want is some measure which captures that amount of the variation, the tail variation of the jump. So you really, what you probably want is, what you probably want is something like this, to recover the x squared new Dx for some higher threshold, for arbitrary threshold, but for higher threshold. Right? And so just like what I did initially with these tail approximations, and so then you can ask yourself, well, I mean, how about this, right? This actually, because you are. Can I just plug in the new estimate I got here? I plug it in and integrate it? You can do that, but it's kind of difficult to know what exactly or to prove actually the behavior of that estimator.
01:02:33.974 - 01:02:55.770, Speaker A: Alternatively, you can just realize that, in fact, this tail integrals, they can be nicely expressed as integrals against Fourier transforms of the levy measure. And we already know how to estimate these Fourier transforms, just the conditional characteristic function of the levy measure, and just plug them in here.
01:02:55.962 - 01:02:58.826, Speaker B: And because you are integrating now, this.
01:02:58.850 - 01:03:34.354, Speaker A: Is much more precisely estimated, right? Because the integration is smoothing things out. And so you got actually a much more something which is much more reliably estimated. But from a practical point of view, probably that's what I need, right? I mean, it's these integrals and not so much the function. So you can do this using this integration business, and you can prove this, the behavior of these estimators as well. We did it in a follow up work. Yeah. So that's just repeating what I said here.
01:03:35.574 - 01:03:36.434, Speaker B: Okay.
01:03:37.254 - 01:03:47.350, Speaker A: And so now, before we take the break, let me just. The last part here. Let me just talk a little bit about these fixed times of discontinuity, which.
01:03:47.382 - 01:03:51.366, Speaker B: I think that they are arguably, probably.
01:03:51.430 - 01:04:42.634, Speaker A: Well, they're quite interesting in their own right, okay? So these jumps, they are not typically the ones we model in our continuous time models. We don't model them usually, but I actually think that they're quite, you will see a few plots later on anyways, illustrating that. So just to say, okay, it's a technique, as I told you, this is a technical jargon which is used here, fixed times of discontinuity. Okay. And just all it says is that it says that I know at a certain point that the jump will arrive, okay? With positive probability. The models that we were looking so far has this feature that if I just look before the jump occurs, if I look at t star minus. Okay, that is, the t star is the time when the jump happens.
01:04:42.634 - 01:04:51.522, Speaker A: And if I look just before the jump occurs, then Xante expects the probability of jump happening exactly at that point in time is zero.
01:04:51.658 - 01:04:52.306, Speaker B: Okay?
01:04:52.410 - 01:05:24.504, Speaker A: That's all of this. Basically, it comes from the fact that you see the jump compensator or the jump method. We were looking at this form, DT DX. In technical terms, it's Lebeque in terms of time, which means that the jumps are uniformly distributed over time. And so that's why the probability that the jump will land exactly at this point in time is zero. That's the feature of these models. In other words, if I'm looking over shorter and shorter and shorter intervals of time, the probability that the jump takes place gets smaller and smaller and smaller.
01:05:24.504 - 01:06:39.750, Speaker A: It's proportional to the length of the interval, okay? Which is fine for many of the things which we are looking at, especially for the market index, is probably fine. But there are situations in which you actually, if I'm sitting today, I know that at 02:00 p.m. Eastern time, there will be a jump when the, when the Fed announces, issues the FOMC announcement, right? That's kind of a, it's very likely. And so exante, you will expect that exactly 02:00 p.m. There will be a jump or another, another situation is when you, when you learning announcements that they're probably even more, they generate even, they are much, much bigger, as you will see in a plot later on. So, well, how do things change in this case? Well, things actually change non trivially in this particular case when we are looking, when we have forward looking kind of data like options. And in fact, if you, right now, the characteristic function of the increment with that time of something happening.
01:06:39.750 - 01:07:06.398, Speaker A: Okay, here's how it will look. You will have, basically, see, you look at the, again, conditional characteristic function. And let's say that there is a time t star between little t and little t plus capital t where you know that a jump will arrive. Okay? There will be announcement. Okay, think about it this way. There will be an announcement. Then the conditional characteristic function now will have this form.
01:07:06.398 - 01:07:45.362, Speaker A: It will be e to the power t times. Some function which depends on nu, not on time anymore, and something which depends only on u and the, basically the jump distance. So this is, okay, so to make things, to simplify things, this is just the characteristic function of the jump at the announcements. Okay? This is just the character. Just think about, this is the characteristic function of the jump at the announcement. That's all that thing, that thing in the parenthesis, it kind of in a, in a, in a fancy, in a fancy notation. So what does that mean? Basically, it means that if I don't.
01:07:45.418 - 01:07:51.700, Speaker B: Have this kind of fixed announcements, then.
01:07:51.772 - 01:08:21.016, Speaker A: The characteristic function, or the logarithm of the characteristic function, I highlighted this thing in blue, will scale up with the horizon. Another way to say it is think about what happens with the second moment. It's easier. The variance is proportional to time, right? The shorter the time, the shorter, the smaller the variance. Just think about of a brownian motion, right. The variance of the brownian motion is equal to time to the length of the time. And so, but then think what we are doing.
01:08:21.016 - 01:08:42.456, Speaker A: So if I'm looking now over a small interval of time, I'm looking over a day. What do you do how people treat quote options in black shawls? Implied volts. They annualize, right? Annualize. And so if I'm. You're computing volatility over one day, you annualize it by multiplying by 252 or 365, whatever you come convention you use. Right. Now, think about what happens here.
01:08:42.456 - 01:08:44.680, Speaker A: If I'm expecting an announcement, you multiply.
01:08:44.712 - 01:08:48.824, Speaker B: It by 252, you will blow it up. Right.
01:08:48.864 - 01:09:06.786, Speaker A: Because that's a fixed event. The risk in it doesn't scale in time. So you should not be scaling this thing in time. Just to illustrate to you that this thing has a real byte. Here's what you will do. If you were to compute the consequences of this.
01:09:06.930 - 01:09:09.130, Speaker B: If you were to compute black Scholes.
01:09:09.162 - 01:09:20.554, Speaker A: Implied volume or the VIX. Basically I did here the vix. But the same thing happens with the black Scholes implied wall for Facebook. For one, individual stock, name stock.
01:09:20.674 - 01:09:23.170, Speaker B: If you calculate the black Scholes implied.
01:09:23.202 - 01:10:17.796, Speaker A: Volume from the short dated options. Now what you see is something, which is insanity, right? I mean, so I did not know again, until I started looking at individual names that these effects are so prevalent. That's why I start looking at these earning announcements in follow up work, because look at this. I mean, what is going on here? If you look at these spikes, they're really huge. I mean, we're talking about volatility going from 40 to 120 and then going down. Right? It's not because really people expected what kind of volatility model will give you that, right? I mean, think about it, right? I mean, we usually try to fit the traditional volatility ar one process, et cetera, on this type of dynamics. It's not going to work very well, right? I mean, that's going to be a, that's going to be a disaster, in fact.
01:10:17.796 - 01:10:33.298, Speaker A: So what's happening here? What are these spikes? Well, these are spikes driven by earning announcements which happen every quarter, right. Four quarters per year. Okay. And that's why you approximately see them. That frequency basically is the length of a quarter. Okay.
01:10:33.466 - 01:10:34.174, Speaker B: And.
01:10:35.994 - 01:10:59.406, Speaker A: Each quarter. And then when you're looking at, I'm looking at one week, that's a non trivial event. But then you multiply if it's a one week to expiration, to annualize it. Because these are annualized volatility numbers as usual, you have to multiply that number by, by 52, right. Because they are 52 weeks. And so you just blow it up. So it's not like I expect the volatility to persist like this for a year.
01:10:59.406 - 01:11:24.818, Speaker A: It's just over that short interval of time. But annualizing that thing is the wrong thing to, is the wrong thing to do. So it is amazing. So if you go and look at, so I was stuck for most of the stuff I've done, I've done with market, market index options. You don't see this type of plots. Okay. I mean, so you, otherwise, if you, I mean people, yeah.
01:11:24.818 - 01:11:37.842, Speaker A: Anyways, people have noticed this, I guess, with individual name options, but I wasn't aware of that, okay. That this was so big for spx. You can still see that thing happening around the fomcs and around a bunch of announcements.
01:11:37.938 - 01:11:40.826, Speaker B: Sometimes I'm being recorded.
01:11:40.850 - 01:11:54.662, Speaker A: I was going to make a joke, but now you see, because I'm being recorded, I'm not going to make a political joke. So there are some other announcements which generated in 2020 and 2016 and stuff. Option markets to move by a lot.
01:11:54.758 - 01:11:59.366, Speaker B: You can guess, make wild guesses, okay.
01:11:59.550 - 01:12:08.750, Speaker A: About what was happening. So even there, but the size of this type of effects are going to be much, much smaller.
01:12:08.902 - 01:12:14.406, Speaker B: So the first thing, okay, so what.
01:12:14.430 - 01:12:52.208, Speaker A: I wanted to do in as a first thing is for the S and P 500 options where this is really not as extreme, is just to see, are there a lot of these events? Because you might even ask, you might, if you think about this, you might say that, well, I mean, how do we treat the weekends, right? Aren't they exactly events like this. I know they're coming. I know markets are closed, it's limited time. And they just like a jump like that, right? Treat it like this. So that's why I was thinking originally, I wasn't expecting that for individual names. This is so obvious and apparent and so there's no need to test for it. Okay.
01:12:52.208 - 01:13:30.774, Speaker A: And so what I'm going to do is just here, what I'm going to do is basically tell you how to test or how to look in the option data and say, well, there is an event like this, the market is expecting something like this to be happening over the next period. Again, for the market index options, it's not so obvious. You have those even at fomcs. Not all fomcs trigger this type of event. But the more important question afterwards is actually, well, measure those, extract the information about those and actually think what happens to volatility at those announcements. And that's something that I've been working afterwards on. Start working on this.
01:13:30.774 - 01:14:04.024, Speaker A: Okay? So let me just tell you that's not very complicated. And basically builds on, again, this conditional characteristic function. So it's not very complicated thing to do. And so here, though, what I will do, I will now allow myself to use two maturities, not only one maturity, as I was using until now, but basically I will use two times two expiration, capital t one and capital t two. Okay? And what I will say, basically, is the following thing. Look, if you go. Let me go back here.
01:14:04.024 - 01:14:30.766, Speaker A: If this mess was not here, so if this fixed time, fixed jump was not here, as I told you, the conditional characteristic function grows linearly in time just like the variance grows linearly in time. Okay? And so I will ask myself, okay, well, if I look at the conditional characteristic function, does it scale, scale across horizons proportional to the time to maturity, to the time to expiration? And that will be my test.
01:14:30.950 - 01:14:33.942, Speaker B: So if there's no such event.
01:14:33.998 - 01:15:04.970, Speaker A: So if those who are pricing the options were not expecting any of these type of events to occur, then what you should see is that the characteristic function scales linearly in time. That is, if I take the logarithm of the characteristic function, and you will see that it's basically, it's proportional to time, just like variance is proportional to time. So I do it with characteristic functions so that I can, so that this is really a one to one. The variance is just an implication of this, okay?
01:15:05.162 - 01:15:07.626, Speaker B: And if there is an event, if.
01:15:07.650 - 01:15:16.320, Speaker A: There is a, if I, if there is this type of event, kind of an event risk, okay? Then the thing doesn't scale up linearly in time.
01:15:16.442 - 01:15:16.980, Speaker B: Okay?
01:15:17.052 - 01:15:51.400, Speaker A: So that will be my test. That, in a nutshell, is the test. And so what I can do is I can look at my, I can calculate this conditional characteristic function from one maturity, I can calculate it from the other maturity, scale it up appropriately and look at the difference. And if this is really no event is expected, then this thing is just measurement error. Okay? And I can hope and characterize the behavior of this thing because this, basically, if it's a measurement error, you can derive a kind of a central limit theorem. So it's like a chi square type statistic. Basically, it will be something like this.
01:15:51.512 - 01:15:53.824, Speaker B: Okay? Okay.
01:15:53.944 - 01:15:54.804, Speaker A: This is.
01:15:57.384 - 01:15:57.968, Speaker B: Yeah.
01:15:58.056 - 01:16:36.352, Speaker A: Some fancy econometrics related to that is basically you are looking at functions. So you're looking at functions because over the characteristic exponent. And then you can say that there's a central limit theorem for that thing. And on the basis of this, you can characterize the behavior of this function here under the null. It's some kind of, you are squaring normals, which are correlated across the U's, but you know how much they're correlated. So you can characterize this, the asymptotic variance in the end of the day, and. Well, this probably sounds very intimidating, but it should not be because the way you do it.
01:16:36.352 - 01:17:10.572, Speaker A: Okay, so I keep going in there, pressing the wrong button. But the way you do it is just, you simulate this distribution. So it's very, it's not really at all difficult. Okay, and what happens under the alternative? Well, under the alternative, there can be two. It depends on where you, where that event is. Does this event happen before the two options expire, or it happens when the first, after the first option has expired, but not the second maturity. Okay.
01:17:10.572 - 01:17:31.870, Speaker A: And so if it's in the first case, if it expires before both of the option expiration dates, then basically what will happen? Or rather if it expires after the first option has. Okay, if the event happens after the first option has expired, then this, the first conditional characteristic function converges to one, to the number one.
01:17:32.012 - 01:17:32.578, Speaker B: Okay.
01:17:32.666 - 01:17:52.978, Speaker A: And then the second one just converges to the characteristic function of the jump size. Okay. And if this is not the case, in this case, both are converging to the same thing. If the event happens before even the first option, the first expiration has taken place, then basically they both converge to the same thing.
01:17:53.106 - 01:17:55.602, Speaker B: Either way, this gap, which I showed.
01:17:55.618 - 01:18:34.362, Speaker A: You on the previous slide, is going to be a non negligible number. And that's going to give you, basically, that's going to give you power of the test. So you can formulate the testing whether there is an event or no event, and it's properly sized asymptotically, at least, I applied it in year 2017. Okay, so to s and p 500 index options. Okay? And these are the p values, because you wouldn't know what the critical values are. So it's easier to report p values and remember p values. Higher p values means that you don't reject.
01:18:34.362 - 01:19:07.056, Speaker A: And so if we have a conventional size of, say, 5%. So what you will see here is that there are a bunch of guys which are absolutely unambiguously on the bottom with the p value of zero. So where there's absolutely no doubt something was expected to happen, basically. And then I went back and checked. These are done by weeks. So you have 52 weeks in 2017. Okay? Because back then I can use only Monday, Wednesday, and Friday option expiration.
01:19:07.056 - 01:19:23.834, Speaker A: I cannot do what I can do now every day of the week. Okay. So I was doing Monday, Wednesday, Friday. And so a lot of, a number of those events were fomCs, actually. But there were also some events which were actually not directly related to.
01:19:24.254 - 01:19:28.694, Speaker B: Well, yeah, you can, that can be so confusing.
01:19:28.734 - 01:19:50.886, Speaker A: You can kind of think, okay, something this is telling me, something must have been expected. And then you can go and search for this news. Right. And then always, there's always something. Okay, but was that really the thing? I don't know. So for example, yeah, I will show you one, one observation later on. There was no FOMC, no anything, but I think it was the European Central bank was issuing something.
01:19:50.886 - 01:20:29.334, Speaker A: Now, I don't know why this was affecting so much the US market, but it triggered it anyways. So the point is that these events here, they're not that big. As for the individual stocks, they're not like day and night type events, but there are a few of them out on them. Yeah, there was one of them, for example, was the IMF conference, which happens in April in one of the years. The IMF conference, for some reason it was affecting, basically it was happening over the weekend and it was affecting kind of this scaling property was basically completely off. So they were expecting that there will be quite a bit of big chunk of news released. Yeah.
01:20:36.514 - 01:20:37.414, Speaker B: You mean.
01:20:42.934 - 01:21:06.344, Speaker A: Like what measures you have. Ah, okay, no, no, I didn't think, no, I didn't think about that. Okay, so you're saying, okay, if this, okay, so you're thinking, okay, if basically they're telling you market participants are expecting something to happen, so it should be reflected in something else as well basically. Right? Yeah, that's a good point. No, no, I did not think of in this way. Yeah, that's a good point.
01:21:06.964 - 01:21:09.196, Speaker B: Yeah, that can be.
01:21:09.260 - 01:21:25.836, Speaker A: Yeah. In any case, I mean, you can think about applying this thing. Now. Before I couldn't apply it so much because we didn't have maturities expiring every day. But now you kind of be thinking, well, are we treating the weekends differently from the way we treat regular days because markets are closed or semi closed?
01:21:25.980 - 01:21:26.664, Speaker B: Right.
01:21:27.284 - 01:21:44.848, Speaker A: It's a jump, but is it the same type of jump that we have in kind of in regular times? So there's more. I think that with the data now, I think one can do a little bit more. Okay. And I will wrap it up so that we can have coffee. But we just say, okay, you can.
01:21:44.896 - 01:21:47.644, Speaker B: Test whether there was an event.
01:21:49.224 - 01:22:14.732, Speaker A: If you're looking at individual stocks, there's no need to test, because, you know, when the event is. So, basically, there's no point to test whether the event. So it's much more interesting is just to recover. That's basically that event or the distribution of that event. And so now. But in any case, the way I've written it here is assume that I really. The econometrician is really doesn't.
01:22:14.732 - 01:22:40.938, Speaker A: Is clueless, and basically doesn't know even when the event happened. And so the first thing is, well, figure out whether the event happened before the first expiration or after the first expiration. So it's not that difficult. You basically have to see how the characteristic function scales. So let's just not spend time on this. But basically, once you figure out where is the event, is it before the first expiration or after the first expiration.
01:22:40.986 - 01:22:44.306, Speaker B: Date, then you will assign.
01:22:44.370 - 01:23:05.364, Speaker A: Basically, you need to do a bias correction type thing to remove the normal type of risk, which is around the event time. Okay. And that depends on where this event happened. So there's this. These are bias correction terms, but they're all based on this characteristic function. So that's not that really difficult, in reality to do. And then you just do the Fourier transform, and that's it.
01:23:05.364 - 01:23:09.176, Speaker A: There's really nothing which is going on here.
01:23:09.280 - 01:23:09.808, Speaker B: Okay.
01:23:09.896 - 01:23:37.354, Speaker A: So these are the bias correction terms, but I don't want to scare you with those. And so you can do the same thing. You can just, basically, it's a function you're estimating, and then you can look at the integrated squared error of the function. Okay. And you recover it in June 5 of 2017. If I remember right, this was a date when something happened in Europe. ECB was issuing something, and it triggered basically a jump like this.
01:23:37.354 - 01:23:55.258, Speaker A: You look at it, it looks very symmetric at that type of jump. It's not like this heavily left tail, skew type of jump that we usually recover in the normal time. So it looks more like an uncertainty type of thing, basically, that's generated and not very big in size. You see this is like a 1% kind of spread.
01:23:55.426 - 01:23:56.174, Speaker B: Yeah.
01:23:57.354 - 01:24:07.174, Speaker A: Okay, so. Okay, well, that's the end of this set of slides. Exactly at the time for the break, more or less. Maybe I'll just.
01:24:08.234 - 01:24:08.986, Speaker B: Any questions?
01:24:09.010 - 01:24:10.034, Speaker A: Actually, maybe I should ask. Yes.

00:00:00.800 - 00:01:06.434, Speaker A: So my plan is to try to give an introduction to the combinatorial theory of the rigidity of frameworks. So my original plan was to kind of do a survey talk of lots of different frameworks. But while I was preparing these three lectures, I decided it would be better just to concentrate on bar joint frameworks in d dimensional neocladium space. So I think these are in some sense the simplest and yet at the same time the most intriguing kind of framework. And I think they reflect most of the, they give a good introduction to the most the ideas we need for a theory. So that's what I'll do. And today's lecture, which is the first lecture, will introduce basic concepts and notation for bar joint frameworks in three dimensional space.
00:01:06.434 - 00:02:22.682, Speaker A: And then I will, towards the end of the lecture I will focus on two dimensional spheres and present some important results and proof techniques for this two dimensional chaos. And then I decided that I would use the second and third lectures to address the important unsolved problem of generic rigidity in three dimensional oblivion space. So this was mentioned by Mera as a fundamental problem earlier on today. And so I'd like to give an indication of what's known and what is conjectured to be true about this three dimensional case. So before I start, so Tony is chairing this session and he's kindly agreed to keep an eye on the chat. So I can't see the chat. So Tony, if somebody has a question, then they can put it on the chat and Tony will either answer it directly or he will interrupt me and tell me to answer it.
00:02:22.682 - 00:03:48.074, Speaker A: I hope that's okay. So to start off with the basic definition, so a d dimensional framework by joint framework is a pair, and it's a pair where the first thing in the pair is a graph and the second thing is a map which maps the vertices into d dimensional euclidean spheres. And we think of this as a realization of the graph in a dimensional euclidean spheres. So the map gives us the location of the vertices and we think of the edges as being straight line segments joining the end vertices. The length of an edge is given by the euclidean distance between the two anverg sets. So the framework said to be rigid if every continuous motion of the vertices, which preserves the lengths of the edges, actually preserves the distances between all pairs of vertices. So this is equivalent to saying that every continuous motion or the result of every continuous motion can be obtained by a rigid motion of a dimension in the opiates isometry.
00:03:48.074 - 00:05:11.640, Speaker A: So here's an example. So the first two frameworks on the left are examples of two dimensional frameworks which are not rigid. So the rectangle, we can continuously move the vertices into the parallelogram, keeping the lengths of all of the edges. But it's not a rigid motion because it changes the distance between the vertex v two and v four. The framework on the right is rigid, and in fact it's what we obtained from the framework on the left by adding an extra edge or a brace which kills the motion into the parallelogram. So just to finish this example, it's worth noting that the framework on the right is a rigid framework in two dimensional spheres. But if we imagine that we're in this, the framework was actually in three dimensional spheres and the vertices just happened, lying in a plane in three dimensional space, then it would not be rigid.
00:05:11.640 - 00:06:29.666, Speaker A: So it's not rigid because we can rotate the vertex v two about the line through v one and v three, and that will preserve the lengths of all the edges, but it will change the distance between v two and v four. So I guess rigidity depends on which dimension we're working in. That's strange. All right, I got distracted because I can't say the title of the slide because I've got the zone stuff in front, but never mind. So this is about algorithmic complexity of frameworks. So I think another thing that Mira said this morning is the people working in the area are very interested in whether their results can be turned into efficient algorithms for deciding rigidity or flexibility. And this is a negative slide in that sense.
00:06:29.666 - 00:07:52.704, Speaker A: So if we have a one dimensional framework, so the framework is on the line, then it's very easy to decide whether it's rigid or not rigid or not, if only if the graph is connected. So the idea is if the graph is not connected, then we can choose a component of the graph and it can move freely along the line without changing the length of the edges, but it will change the distance between a vertex in this connected component and any of the vertices in any of the other connected components. So in order to be rigid in one dimension, the graph needs to be connected, rigid in any dimension. And you can also show it's sufficient. And that one way of doing that will be to use an easy induction. So if the graph is connected, it has a spanning tray, and you could use induction on the number of end vertex on an end vertex spanning tray using induction on the number of earth signs. So the negative result is due to Abbott in 2008 in his MSc thesis, and he showed that for any d grid or equal to two, it's entry hard to determine whether a given framework is rigid.
00:07:52.704 - 00:09:17.634, Speaker A: So there aren't going to be any efficient algorithms for world which will work for an arbitrary framework. So that tells us we have to concentrate on particular frameworks and one particular family that the combinatorial theory is particularly appropriate to is the idea of generic frameworks. So the np hardness for a general framework seems to depend on algebraic dependencies between the coordinates of the vertices. So one way to get around this is to restrict our attention to generic frameworks in which the set of all coordinates of the vertices is algebraically independent of the rationales. So we'll see in a few slides time that if we restrict the generic frameworks, then the actual realization p doesn't matter as long as it's generic. So deciding or not whether a generic framework JP is rigid or not just depends on the graph j. So this gives us an algorithmic problem of determining which graphs are generically rigid in dimensional euclidean spheres.
00:09:17.634 - 00:10:43.874, Speaker A: And as we saw in the first bullet point, this is easy for g equals one. In fact, it can be solved for arbitrary frameworks, not just generic frameworks, and it was also solved, it can also be solved algorithmically for d equals two, using a theoretical result of polar cek Geringer, which again we will see towards the end of the lecture. So that's d equals one and d equals two. As soon as we get the d equals greater or equal to three, it becomes an important problem generically, it would be nice to see what the title of my slides were. So the rigidity of maybe if I go out of. Sorry. So is that better? Tony.
00:10:46.814 - 00:10:53.046, Speaker B: You'Ve come out of full screen, so it's worse for us, but if it's better for you, it's readable, I think it's big enough.
00:10:53.190 - 00:10:54.502, Speaker A: But could you say the title of.
00:10:54.518 - 00:10:57.194, Speaker B: The slides before we could see it? Yes.
00:10:57.494 - 00:12:00.636, Speaker A: Oh, all right, so I won't worry about it then, should I not? Yeah. Okay, so I think this is about the, I think this is about the rigidity matrix. Oh, it's confusing right now. I think I really neatly know what the title is. Sorry, so the. Sorry. So we can.
00:12:00.636 - 00:14:16.674, Speaker A: The decision problem of deciding whether a particular framework is rigid or not is related to determining the solution spheres of a system of quadratic equations. So the idea is that we imagine that the vertices are moving around in d dimensional euclidean space and that the position of a particular vertex at time t is given by pt of a p zero of a would be the initial time, which is so p is equal to p zero and so the constraint that the length of the edges should not change as the vertices move can be formulated as this system of quadratic equations where we have one equation for each edge. And we can simplify this system by, we can linearize the system by thinking of the motion as being in a smooth motion and differentiating with respect to time t and then putting t equal to zero. So if we do this, then at time zero the instantaneous velocity of each vertex is given by p dot u and the system of quadratic equations one is transformed into trans, transformed into the system of linear equations two. And linear equations are much easier to solve and quadratic coefficients. So of a linear system, we look at the matrix of coefficients and we call the matrix coefficients of this system the rigidity matrix. So because we've got, because we've got, the number of equations is equal to the number of edges, the matrix of coefficients will have, the number of rows will be the number of edges and the number of columns will be the number of variables.
00:14:16.674 - 00:15:42.574, Speaker A: The number of variables is just the, so the unknowns are the instantaneous velocities p dot, and each vertex has its instantaneous velocity has d coordinates. So we get d times b columns corresponding to the d times v, unknown coordinates of the instantaneous velocities of the vertices and the entries in the rigidity matrix. So the coefficient of p u will be p of u minus p of v, and the coefficient of p dot v will be p of v minus p of u. And the other coordinates in the row corresponding to the edge uv will be zero. So it's an e by dv matrix and its entries are given by these rows. So for example, if we go back to our square framework, then this is the corresponding rigidity matrix. And if we're interested in the number of solutions to this linear system of equations, then we're interested in the rank of this matrix.
00:15:42.574 - 00:17:23.384, Speaker A: And the rank, well, it depends on where the vertices are placed. So if, assuming that none of the vertices are on top of each other, so these are on the p of vi minus p of v, j entries are all non zero, then the rank of this matrix will be three. If all four vertices are core planar, if our four vertices are collinear, sorry, and otherwise it would be four. So this tells us that the generic rank of this matrix, if we imagine that the point is based generically in a dimensional space, then if d is one the rank will be three, and if d is greater or equal to two, the rank will be four and the roars will be linearly independent. So an infinitesimal motion of a particular bar joint framework is the vector p dot we get by concatenating all the instantaneous velocities. So it's, this is a vector in the null space of the kernel of the rigidity matrix. And fundamental observation of James Clerk Maxwell from 1864 was that each trans, each rigid motion of three dimensional euclidean spheres gives rise to an infinitesimal motion of the framework.
00:17:23.384 - 00:18:41.214, Speaker A: And it's not difficult to say that the dimension of the space of infinitesimal motions, coming from translations or rotations, will be at least d plus one. Choose two at least whenever the point span the whole spheres. If not, then we get some kind of degeneracy. So this tells us that the dimension of the null space or the kernel of the rigidity matrix will be at least d plus one shears down. So using the rank nullity formula, it tells us that the rank of the rigidity matrix will be at most the number of columns minus this lower bound on the dimension of the kernel. It tells us more than that. It tells us that if we actually have equality here, then every infinitesimal motion comes from a rigid motion of dimensional euclidean space.
00:18:41.214 - 00:19:52.194, Speaker A: So all of the infinitesimal motions are rigid motions, and it tells us that the framework will be rigid. So it's actually, it's a sufficient condition for rigidity, but it's not equivalent. So depending on, there are particular frameworks which can be rigid but are not infinitesimally rigid. So it's a stronger property. And we said that the framework is infinitesimally rigid if we have equality. So a kind of a result of Gluck, which probably gave rise to people working on generic rigidity, was that for generic frameworks, infinitesimal rigidity and rigidity are equivalent. So this, this is a kind of elementary result from differential geometry.
00:19:52.194 - 00:21:15.714, Speaker A: So it means that if we're interested in the generic rigidity of graphs, then it's, then it's okay to take the linearization quadratic system of equations and we won't lose anything. So it implies that for a generic framework, it's rigid, if and only if. Either it's a small complaint graph, which is this degenerate case when the vertices don't span the whole space, or it has at least d plus one vertices, which because it's generic, will span the whole spheres, then the rigidity matrix has rank. What it is, by max observation, d times the number of x minus d plus one chose ten. So this tells us, so this is the point that I made earlier. This tells us that what generic frameworks, the rigidity just depends on the graph, because for any generic realization, the entries in the rigidity matrix will be algebraically independent. So the rank of the rigidity matrix will be the same for all generic.
00:21:15.714 - 00:22:43.854, Speaker A: And another kind of algorithmic observation is that if we can determine, if we want to determine whether a graph is rigid in day dimensional space, it's sufficient to determine for a particular generic realization whether the roars of the rigidity matrix are linearly independent or not. So the idea is that to determine the rank, we need to, to find a maximum number of linearly independent rows. And if we can, we can construct a maximum, a maximum set of linear, linearly independent rows gradually. So if we can, if we know how to decide when a given set of rows is linearly independent, we can choose a rule which we haven't considered yet and try to get a larger independent set. And if it does give us a larger independent set, then we grow the independent set. And if it doesn't, then we throw it away and we keep on going until we have a maximum independence set. So determined rigidity is equivalent to determined independence of the roles of generic rigidity metrics.
00:22:43.854 - 00:23:06.014, Speaker A: So that's nice, but it's a toe edged sword, I guess. We can't tell our students to use gaussian elimination to determine the ranks of macrosaics, but this won't work for a generic matrix. If the entries are indeterminate, then the entries will blow gaussian emanation.
00:23:07.994 - 00:23:17.014, Speaker B: Bill, sorry, there's a question in the chat Itama. Sorry, could you repeat the question? Because I'm not quite clear what motion you're referring to.
00:23:22.824 - 00:23:52.074, Speaker C: Well, I'm not too versed in what's going on, but the other day I asked you about dynamics, I got some answer from Mira. But now that you mentioned explicitly motion. Okay, the question is, time plays any role here, or we are talking about something that I would call semi static motion.
00:23:58.774 - 00:24:04.794, Speaker A: So I think I'm talking about a static motion. So an infinitesimal motion. Okay.
00:24:05.774 - 00:24:07.926, Speaker C: Okay, that's great. Thank you.
00:24:07.990 - 00:24:12.300, Speaker A: So a dynamic motion would be much more complicated.
00:24:12.462 - 00:24:16.280, Speaker C: Absolutely. Okay, thanks.
00:24:16.432 - 00:24:20.164, Speaker A: That's okay. It's nice to say that somebody's out there.
00:24:22.504 - 00:24:40.132, Speaker C: Yes. You know, there is static friction and dynamic friction, and if you move the framework, there could be implicit, hidden friction. But let's leave the physics out of it.
00:24:40.288 - 00:24:41.476, Speaker A: Yes, yes.
00:24:41.660 - 00:24:42.624, Speaker C: Thank you.
00:24:43.564 - 00:25:46.986, Speaker A: It's hard enough without it, I think. So there is already a well established theory of combinatorial independence, and we can, this is metroid theory. And again, Meyer mentioned this this morning, and we can get a lot of, we can make a lot of progress by applying the results of metroid theory to try to decide when rows of the rigidity matrix are independent or not. So here's a quick introduction to a metroid. So, a metroid is a very elementary system which is based on linear independence. So it consists of a pair. Again, we have a pair, we have a ground set a, and then we have a family of subsets of a, which I'll call I.
00:25:46.986 - 00:26:45.140, Speaker A: And we think of I as being the independent sets. And in order to put the independent sets to use a metroid, we need three axioms. So we want the empty set to be independent. We want any subset of an independent set to be independent. And then the thing, the third axiom which really makes them work is that if we have two independent sets and a and b, and the size of a is less than b, then we can find some element of b which, when we add it to air, we get a larger independent set. So this tells us that we can construct maximal independent sets gradually, and it also tells us that every maximal independent set will have the same size. So some more terminology.
00:26:45.140 - 00:27:38.734, Speaker A: So, as I said, the subsets of e which belong to I are called independent sets, and the subsets of e which don't belong to I, are called dependence sets. A circuit is a minimal dependent set. So it's a dependent set for which our proper subsets are independent. We have the idea of a base of any subset of a. So given, given a subset a of a, then a, a base, sorry, this should say base, it should not say basis. A base of air is a maximal independent subset of air. And the third, the third axiom tells us that all bases of air have the same size.
00:27:38.734 - 00:28:52.420, Speaker A: And this size, this cardinality allows us to define a rank function which maps the subsets of air into the integers or negative integers. So the rank of any subset is the size of a maximum independent set of the subset. And so I'd like to apply this terminology to the whole metroid. So any, any base of the ground set a, I will also refer to as a base of the metroid n, and to the maximum size of a maximum in independent set subset of a base of a. I was also referred to that as the rank of n, and I'll denote it by r of n. So, a classical example of a matroid comes from a matrix. So if we're given a matrix r, the row metroid of r, it's a metroid we get from the rows of the matrix.
00:28:52.420 - 00:30:09.964, Speaker A: The max is the metroid in which the ground set is the set of rows of the matrix, and which any subset of rows is independent in the metroid if and only if it's linearly independent set of vectors. So this immediately gives us a metroid corresponding to rigidity in d dimensions. So the dimensional rigidity metroid of a graph j is the, is the raw matriid of the rigidity matrix for any generic realization of the graph. And I'll say that the graph is rd independent. So the symbol I'm given for this metroid on the edge set of the graph j is r day of j. And I'll say that the graph is rd independent if its edge set is independent in its rigidity of the trial. This is the stem of stemma.
00:30:09.964 - 00:31:04.282, Speaker A: The rows of the rigidity matrix are linearly independent. So we can use Maxwells observation on the rank of the rigidity matrix to obtain a necessary condition for independence in the rigidity metroid. So given any subset x of vertices of the graph, we let I of x denote the number of edges of the graph which are induced by x. So the number of edges, both of those endpoints belong to x. And then Maxwell's observation tells us that if we have a graph, oh sorry. So this two should be a d. That's the problem with quitting and piercing.
00:31:04.282 - 00:32:24.504, Speaker A: So if we have a graph, it's independent in the d dimensional rigidity natural, right? So the rules of its generic digit matrix are linearly independent. Then the number of edges induced by any set of at least three plus one vertices is at most d times the number of vertices minus d plus one shows two. So the d plus one shows two, comes from the rigid motions dimension. So it turns out that the Maxwell's condition is necessary. Condition for independence in the rigidity matrix is it's also sufficient when d equals one, since it implies that the graph is a forest. So the one dimensional rigidity metroid is well known in graph theory and metroid theory, and it's called the cycle metroid of a graphic. So a set of edges is independent if and only if it's a forest.
00:32:24.504 - 00:33:36.378, Speaker A: So Maxwell's condition is also sufficient when day it was toe this is where the cutting and pears thing went wrong. So now this, this till really is a turtle. So Polachak Geringer showed many, many years ago in 1927, that a graph is independent. The generic two dimensional rigidity metroid, if and only if it satisfies even only if each set of at least two vertices induces at most twice the number of vertices minus three ages. So independence in day eight was one and day eight was two is given by a sparsity condition on the ground. It's independent as long as no subset induces too many edges. And this famous theorem was actually known for a long time as Laman's theorem.
00:33:36.378 - 00:35:08.744, Speaker A: So it was rediscovered by Lahmann in the 1970s, and then cricketer Servetius discovered that it had been originally proved by Polojack Geringer many years earlier. So it does not, because this is a condition which works for all subsets. It's not immediately obvious that it will give us an efficient algorithm for testing independence or rigidity, but actually it does. So Jacobs and Hendrickson in 1997, they used this condition to give up an efficient pebble game algorithm for testing whether a graph is generically rigid in tow space. So unfortunately, fortunately for us, things get more complicated in three space. So here's a famous example called the banana graph, which shows that Maxwell's necessary condition for three dimensional sphere euclidean spheres, or independence, does not give independence. So the three dimensional condition is that any set of at least three vertices should induce at most three times the number of vertices minus six agents.
00:35:08.744 - 00:36:13.694, Speaker A: And it's satisfied for this graph, but it does not imply independence. So this, this set of edges constraints is dependent. And to say it's dependent, we notice that the number of edges in this graph is 18, which is equal to the magic number of three times the number of vertices minus six. So if it was independent, then this graph would be generically rigid in three dimensional euclidean spheres. But it clearly isn't generically rigid because if we look at the line going through v one and v two, we can choose the right hand component, right hand part of the graph and rotate it about this line. And it won't change the lengths of any of the edges, but it will change the distance between the vertices on the left hand side and the vertices on the right hand side.
00:36:14.374 - 00:36:26.234, Speaker B: Sorry, Bill, there's another question in the chat. I could answer this one, but I thought you'd like to know people are out there. Yeah, sure, but could you remind Alex of the notation ix and also rd independence?
00:36:28.774 - 00:37:38.814, Speaker A: So ix is the number of vertices, so x is a set of vertices and I of x is the number of edges induced by those vertices. So if I took x to the v one, v two, v three, v four, v five, then I of x would be the number of edges in this part of the graph, which is nine and three reals. Independence would be I would take a generic realization of this graph in three spares. I would construct its three dimensional, its rigidity metroid for this generic realization. And then I would say that the graph is three reals independent. If the rows of the rigidity matrix of this generic realization are linearly independent, is that okay, Alex?
00:37:40.634 - 00:37:42.346, Speaker B: He said yes in the chat.
00:37:42.490 - 00:39:14.060, Speaker A: Ah, good. So a closely related result is called the Henneberg construction for, I guess, the basis in the two dimension generic two dimensional rigidity metric. So the idea is, rather than just thinking of a particular graph, we would like to think of all graphs. And one way of doing that is to think of all subgraphs of a large complete graph. So I imagine that, so k is a large complete graphs, n is large, and all the graphs that I'm interested in are going to be subsets, subgraphs of kn. So it makes sense to look at the rigidity metroid r two k n. So the Polycheck Geringer characterization of independence implies that the rigidity matrix, sorry, the rigidity meteorite of a large complete graph is two n minus three.
00:39:14.060 - 00:40:30.386, Speaker A: So this just comes from Maxwell's theorem, given that there exists rigid graphs, and that the bases of the rigidity metroid will be the edge sets of all minimally rigid spanning subgraphs of k. So these will be all the rigid graphs with n vertices and exactly two n minus three edges. So I guess this is wrong. This is just Maxwell's observation and the observation that chain is generically rigid. So Polchek Geringer comes into it, because a probe is actually inductive, and it gives us a recursive construction for constructing all of the minimally rigid graphs, minimally rigid spanish graphs. And it's based on a graph operations which were first suggested by Henneberg in 1911. So the first operation is called zero extension.
00:40:30.386 - 00:41:22.624, Speaker A: So it's actually the two dimensional version of zero extension. And here this is a very simple observation. We just add a vertex of degree two to a graph and two new edges. The one extension operation, slightly more complicated. We delete an existing age and then add a vertex of degree three. But when we add the vertex of degree three, we have to make sure that we join the new vertex to both end vertices of the deleted edge. So you should notice that both these operations preserve, would preserve the condition that we have a graph with n vertices if the number of vertices that the number of edges is twice the number of vertices minus three.
00:41:22.624 - 00:42:18.102, Speaker A: So the theorem that follows from Olacek Geranger's Prof. Is that the graph is minimally rigid in, in two dimensional, two dimensional in two days, if and only if we can be constructed from a triangle by recursively applying these two operations. Oh, I thought I had an example. That's right, I seem to have missed my example. Maybe just going to come there. Sorry. So I'd like to show you, sorry for jumping around so much.
00:42:18.102 - 00:43:30.544, Speaker A: I'd like to show you why these two operations preserve independence in the two dimensional rigidity metro. So the first result is, is a bit more general. So for reasons which become clear, I would like to state it as a result for arbitrary frameworks and not just generic frameworks. So the idea is that we have a graph j which is attained from another graph edge by a zero extension, and we add a new vertex of degree two and two new edges from the new vertex to two existing vertices. And now we take an arbitrary realization of the graph, the large graph g. Not necessarily generic, but we would like it to have the condition we like to satisfy, the condition that the position of the new vertex and the position of its two neighbors are not collinear. And we suppose also that if we restrict p to the smaller graph, then the rigidity matrix has independent rules.
00:43:30.544 - 00:44:54.044, Speaker A: Then the conclusion is that the rigidity matrix of the larger framework has independent laws. And this follows easily by just looking at the rigidity matrix. So the rigidity matrix of the larger framework we get from the rigidity matrix of the smaller framework by adding two new rows. And this star will be, the entries in this star will be mostly zero, but underneath the column of w there will be a p of w minus p of a, and underneath the column of x there will be a p of x minus a. But the important point is that we have zeros here because these two columns correspond to the vertex v and v only has two nearbys. So it's easy to see from, from the structure of this that and the fact that p of v and p of w and p of x are not collinear, that these two vectors will be linearly independent. And hence, because this is linearly independent and this is zero, the roars of the larger matrix will be linearly independent.
00:44:54.044 - 00:46:01.434, Speaker A: So r j will have independent roars. And if we, if we restrict ourselves to p, which is generic, then we will naturally have this condition that these work segs are not collinear. So it will tell us that zero extension operation preserves independence in the generic rigidity network. So I'd like to show that it's slightly more complicated. Operation of one extension preserves independence in the generic two dimensional utility matrix. Oh yeah, we suppose h is independent and the j is obtained from h by a one extension which adds a vertex b, three new edges vwbx and v y, and then deletes an existing edge xy. And I would like to show that if h is independent, then j is generically independent.
00:46:01.434 - 00:47:10.594, Speaker A: So the construction is the two end graphs in the figure. So this is h and this is g, and I get g by deleting the edge xy, adding the vertex b and edge is from v to x, b to y and b to w. So to prove this, we go through two intermediate frameworks. So the first thing we do is we add v on the line going through x and y, and we join v to y and w and keep the edge xy. Then this is a non generic zero extension. We're working in this framework. So we start with the generic realization p of h, and then we do a non generic we construct a non generic framework p, in which b lies on the line between x and y.
00:47:10.594 - 00:48:18.934, Speaker A: But because we have a non generic version of zero extension v, y and w are not collinear because p is generic and v is on the line through x and y. So when we add v, we end up with this independent non generic framework. And now we add the edge vx. And we notice that a core linear triangle is a circuit. So the three rows in the rigidity matrix corresponding to vx, vy and xy are minimally dependent. So when we add the edge vx, we have this, it's minimally dependent set. And then we construct j by galating the edge xy from the minimally dependent set.
00:48:18.934 - 00:49:34.384, Speaker A: So I guess maybe it, sorry, this is, this hasn't turned out so well. So because the positions of x, y and v are collinear, we have a circuit in the Roh matriid of the rigidity matrix. So when we add the xy, we do not, when we add the edge xy, we do not increase the rank of the corresponding rigidity matrix. And then when we delete the edge. So if we start, sorry, I'm starting from the right. So we start off with the rigidity matrix of Gp and we do not change its rank if we add the edge xy. And we do not change its rank if after we add the edge xy, you delete the edge vx because we have this minimum dependency given by this triangle.
00:49:34.384 - 00:50:29.764, Speaker A: So this tells us that the rank of GP is just the number of edges of the graph J. And so it tells us that the rows of the rigidity matrix of GP are linearly independent. And this statement of the lemma is about a generic realization. This is a non generic realization. But if we have a non generic realization which has linearly independent rows, then any generic realization will have linearly independent rows. So it tells us that generically we have preserved independence by the extension operation. And this is the slide that I thought came earlier.
00:50:29.764 - 00:51:20.944, Speaker A: So we can use the inverse of these operations to certify that a graph is minimally rigid or independent. So for example, if we start with k 33 and we, we first use the inverse one reduction inverse of a one extension operation, which is a one reduction. So we delete this vertex and add an edge between two of its neighbors, and then we perform a zero reduction. So we take a vertex of degree two and delete it. And then we do another zero reduction to have a vertex integrity two, and we delete it. Then we end up with a triangle. It's easy to see that the triangle is minimally rigid independent.
00:51:20.944 - 00:52:31.244, Speaker A: And we also know that when we move from the right to the left by doing the zero extension and a zero extension and a one extension, we preserve independence. So that is a. This sequence of four graphs gives us a combinatorial certificate that tier three three is independent. And because it's got nine edges, this means it's minimally rigid. So to finish off with, I would like to give a slightly more complicated result of novas and yemeni, which characterizes the rank function of two dimensional rigidity matrix. So there are direct derivations of this formula. But I think it's illustrative to show, to use some machinery from metroid theory to give you the normal scheming formula.
00:52:31.244 - 00:53:55.364, Speaker A: So in particular, it uses a classical result of Jack Edmonds from metroid theory. So to state the result, which is maybe making it slight more complicated than it has to be, we introduce the idea of a one thin cover. So we have a family of subs where we have a graph j, and we have a family of subsets of the vertices of j, and each subset has size at least two, and each edge of g belongs to one of the is induced by at least one of the subsets. This makes it a cover. And one thing means that any two subsets intersect in at most one vertex. So the loewas Gemny formula from 1982 tells us that the rank of any set of edges in the two dimensional rigidity metroid is given by the minimum of the sum of these numbers, and the minimum is taken over all one thin covers of the graph. Sorry, it's taken over all one thin covers of the subgraph of the graph in just by n.
00:53:55.364 - 00:55:03.798, Speaker A: So the idea is that we have a set of vertices which induce all of the edges in f. And then for each vertex we take twice the size of x minus three, which is the maximum rank of any subset on this set of vertices. And then we sum that, we sum that over all terms, the sets in the COVID So here's an example of how we would use this. So we saw before that we could use the Henneberg construction to demonstrate that something is minimally rigid. So we can use the law of Ashiemani construction to demonstrate that something is not rigid. So it's clear that this graph is not rigid in two spheres because we can keep this complete graph on four vertices fixed and then this will swing around on these two edges. It's not going to be rigid.
00:55:03.798 - 00:55:58.194, Speaker A: But to give a combinatorial certificate that it's not rigid, we cover the edges of this graph with four sets of vertices. So the first set, x one is the left hand plate, x two is the right hand plate, and x three and x four are the edges which join the two plates. Then the Lorvas Gemini formula tells us that the rank of g in the two dimensional generic two dimensional rigidity metroid is at most this sum which turns out to be twelve. So the rank is at most twelve. So the maximum size of an independent set of constraints in this graph is twelve. But to be rigid it must have 13 independent constraints. It must have rank 13.
00:55:58.194 - 00:57:06.118, Speaker A: So this is a commentarial certificate that this graph is not rigid generically. So to finish, I'd like to tell, I'd like to tell the state Jack Edmond's theorem. So a fundamental property of metroids is that the rank function is a sub modular function. So more generally a set function which maps the subsets for set a into the integers is submodular. If for any two subsets n, b, f of f of b is at least f of the union plus f of the intersection. And Jack Edmonds theorem tells us that we can use submodular functions to produce metroids and tells us what the rank function of these metroids are. So the idea is, well, we don't have just any sub modular function.
00:57:06.118 - 00:57:52.244, Speaker A: We have a function which is so modular and non decreasing. So it appears contained in B. F of a is less than or equal to f of a. And I'd also like it to be non negative on the subsets of a other than the empty set. So this idea of excluding the Mp set is the useful so I'm going to get a metroid. And to tell you what the metroid is, I tell you what its independent sets are. So the set is independent if it's a subset of the ground set, a property that for all subsets j of I, the size of j is less than or equal to f of j.
00:57:52.244 - 00:58:56.544, Speaker A: So then Jack shows that this is the independent sets of a metroid. And maybe it's more interestingly, he shows that subject to the condition that f of e is less than or equal to one for all elements of the ground set, it gives us a precise formula for the rank function of what this measure. But the rank function is given by checking all partitions. The rank of a set f is given by checking all partitions of f and then summing this, the f value of the sets in the partition, overall sets in the partition. So the condition that f of a should be less than or equal to one is not necessary. So we can remove this and get slightly more complicated formula for the rank function. But for the application, the current application to two dimensional rigidity, we have this condition.
00:58:56.544 - 00:59:37.534, Speaker A: So here's how we, we apply the formula. So we're interested in sub graphs of the complete graph and n vertices and we define a set f. We define a function f, mapping all subsets of a into the integers by putting f of any particular set of edges equal to twice the number of vertices. Incident with that set of edges minus three.
00:59:38.434 - 00:59:59.086, Speaker B: Sorry bill, there's a couple of questions now. Could you go back to the formula? I guess it means the previous slide. Okay, so I guess will, will have had time to look at it. The other question is, are you willing to share the slides so that people can refer to them later?
00:59:59.230 - 01:00:03.914, Speaker A: Yeah, yeah. So I'll send them to you. Sure.
01:00:10.154 - 01:00:11.774, Speaker B: I think that's plenty of time.
01:00:15.034 - 01:01:43.276, Speaker A: Okay, so we define our function f from the subsets of the edge set of our large complaint graph by putting f of the subset of edges f equal to twice the number of vertices incident f minus three, the kind of magic Maxwell number. Then it's, it's, it's not so hard to show that this function f is submodular on e on the subsets of a, and it's non decreasing and it's non negative on everything except the empty set. So this, this empty set condition is important because if f is the empty set, then this would be negative two times eight or minus three. So it's important that we allow to be negative on the NPC. And now Polijek Geringer's characterization of independence in the two dimensional rigidity metroid tells us that the two dimensional rigidity metroid is actually the metroid induced by this function f. So it tells us politic Geringer tells us exactly what it means for a set of edges or a subgraph of kn to be independent. And it turns out that it's actually this.
01:01:43.276 - 01:03:08.714, Speaker A: This is the condition for independence in the rigidity. So the subgraph induced by f, the metroid induced by f, is two dimensional rigidity metroid. And so Edmunds theorem immediately gives this rank formula. And then to get lower. Vas Gemini there is a slightly small amount of work to do to show that if we take any partition of a f which minimizes the right hand side, and we can turn that into a one thin cover of the vertex set by letting the set of vertices and the one thin cover to be actually the sets of vertices which are incident with the edge sets in the partition of n. And then the last thing is just to show that any two of these vertex sets have at most one vertex in common. And that follows from the fact that we've chosen something to minimize the right hand side, making sure if it doesn't satisfy this condition, you can make the right hand side smaller.
01:03:08.714 - 01:03:15.654, Speaker A: So I've gone on too long, sorry, I'd like to finish there.
01:03:17.914 - 01:03:28.054, Speaker B: Okay, thank you, Bill, for a really great talk. There was a question already in the chat. Does the minimizing partition have some intuitive interpretation or meaning?
01:03:29.514 - 01:05:06.024, Speaker A: Yes, that's a really good question. So if we, let's go back to the Loews German and Khan version. So if you imagine that you have a graph which is not rigid generically in two dimensions, then if it's not rigid, then you can look at its maximum rigid subgraphs, and the maximum rigid subgraphs give you a partition which minimizes the right hand side. If we take the vertex sets of the maximum rigid subgraphs, then this will give us one cover which minimizes the right hand side. And the fact that it's worn thin corresponds to the fact that if you take two rigid subgraphs which have two vertices in common, then their union will be rigid. So when we take the maximal rigid subgraphs, it's one thing, and in fact that gives us the COVID which has the fewest number of sets in it. So the other x strain we can take there is the notion of redundant rigidity.
01:05:06.024 - 01:05:48.594, Speaker A: So a graph is redundantly rigid if, when we delete any edge, yeah. So a graph is redundantly rigid if, when we delete any edge, it stays rigid. And the redundantly rigid, maximal redundantly rigid subgraphs will give us another cover, which minimizes the right hand side. And it's a refinement of the COVID that we get using the rigid subcurrent. Is that okay?
01:05:50.254 - 01:06:05.664, Speaker B: Yes, you got a thanks and reply for that. There are several more questions. So is this choice of the submodular function the only choice to obtain the rigidity matriid? Also, what if we picked a different function that is not two v minus three?
01:06:21.224 - 01:07:21.614, Speaker A: So essentially, I think it is the only choice. So as I said, the rank function of a metroid is so modular, so we could choose our submodular function to be actually the rank function of the matriid rather than this simple version of the rank function. So if we chose f to be two reals, then the metroid induced by two reals will be the two dimensional rigidity metroid. Clearly. But the advantage of taking this f is that it's simpler than this formula. So the rank formula is quite complicated, but we can understand the metroid by a simpler submodular function. Is that okay?
01:07:24.114 - 01:07:35.974, Speaker B: I think so. Hank, you asked the question, is that okay? He also asked about if you picked a different function. So I guess if you change the two and the three, for example, it's okay, you get, just get different matriids.
01:07:37.454 - 01:08:44.384, Speaker A: Uh, yes. So if you take any, um, if you could take air times v of f minus b, and you would have, um, I guess a sub modular non detracing, well, you'd want it to be non negative on two p minus the anti cell, but yes. So, so that would give you a metrid and some of the, quite a lot of these metroids in rigidity theory. So if you take twice the number of vertices of f minus two, then it corresponds to rigidity on the cylinder. It's a bit more complicated than that. But if you have a framework embedded on the cylinder, then rather than having three rigid motions, you have two rigid motions corresponding to rotation around the cylinder and translation up and down the cylinder. So the two three f minus two metroid is significant.
01:08:44.384 - 01:09:42.614, Speaker A: It's more complicated because one thing you have to worry about is if you use the two vf minus two count, then it allows multiple edges. So, so you could take two parallel edges with the same n vertices, and they will satisfy this count. So we have twice two times two minus two is four minus two, which is two. And so you would allow two parallel edges, but clearly two identical constraints are not independent. So you have to add, you use the 2 volts minus two count. But then you have to add the extra constraint that if the number of vertices is only two, then you do not have two parallel ages. And that thing makes things more complicated.
01:09:42.614 - 01:10:49.614, Speaker A: So if instead we tried using the three times the number of vertices minus six count, which is what corresponds to three dimensional ligidity, then if we took just two vertices, that would tell us that 3 volts three times two minus six is zero. So if we just use 3 volts minus six count, no edges would be independent. And so this makes the theory very difficult to apply, or more difficult to apply in three dimensions, because we don't only have to worry about the count being, being wrong for the empty set, but it's also wrong when the number of vertices is two. And somehow we have to take account. Feel as though I've been rambling? Did that make any sense?
01:10:49.914 - 01:10:54.974, Speaker B: It did to me, at least. Lewis, do you want to ask your question?
01:10:58.474 - 01:11:31.994, Speaker D: Sure. So I had to go away, sorry. So in this slide here, which is actually staring in front of us, so what's the. So Edmund's theorem tells you that you get a matriid out of this two n minus three, I guess. And is it true that like essentially Maxwell gives you then that this two reals function is an upper bound for the rank function for the rigidity matrix, is that correct?
01:11:35.274 - 01:11:36.098, Speaker A: Yes.
01:11:36.266 - 01:11:53.614, Speaker D: Okay, so the main sentence here is that this Mf is actually equal to the rank function, I guess needs a lower bound, is that right?
01:11:54.674 - 01:11:56.254, Speaker A: Sorry, you said mf.
01:11:56.834 - 01:12:04.158, Speaker D: I mean, so I'm reading your slides. So you have, you have two reals, which is like your rigidity metroid, right?
01:12:04.246 - 01:12:07.230, Speaker A: Yeah, okay, sorry. Mf. Yeah, yeah, yeah.
01:12:07.262 - 01:12:10.694, Speaker D: So, and then Mf is your Edmunds matroid.
01:12:10.814 - 01:12:11.734, Speaker A: Yeah, yeah.
01:12:11.814 - 01:12:24.194, Speaker D: Right. Okay, so, so the equality. So, so I guess, at what point do you use Polachek Geringer? Right, maybe that's the.
01:12:27.274 - 01:13:12.244, Speaker A: So Edmunds gives me this metroid mf. Good. And if I can just go. If I look at the definition of the independent sets in Mf, it tells me that a set is independent only if all subsets satisfy the count. The size of the subset is less than or equal to twice the number of vertices incident with j minus three. Okay, and this is the same as the polych Geringer therem. So it tells us that a set is independent in the rigidity metroid.
01:13:12.244 - 01:13:31.354, Speaker A: So Polycheck Geringer theorem tells us that a set is independent in the rigidity matriarch, if and only that satisfies this condition. And this is the same condition that defines the independent sets in Edmunds metroid. So it tells us that the two matrix are the same.
01:13:31.974 - 01:13:37.274, Speaker D: So the forcefulness on the next slide is simply that Edmonds also gives you the rank function.
01:13:40.974 - 01:13:55.174, Speaker A: Yes. So once we have the independence characterized by this simple submodular function, then Edmunds gives us the rank function for free. Got it. Thank you.
01:13:56.114 - 01:13:56.938, Speaker D: That was my question.
01:13:56.986 - 01:14:22.134, Speaker B: Okay, okay, okay. So there's several more comments and questions, but we're. I mean, I guess we can continue. And anyone who wants to have a break before the next talk can have their own break. So maybe we just continue. So, Tibor says, it may be interesting to note that you don't need Edmund's theorem, that you can do a simple, direct proof just using Polachak Geringer.
01:14:22.794 - 01:14:52.994, Speaker A: Yes, yes. In fact, I think when we first got into. So T. Bodan was the one that rejoiced, made to rigidity theory. And one of the first things he showed me was a simple graph theoretical proof of Nova's Yemeni. So, yes, there is. We do not need to use the machinery from metroid theory, but I wanted to introduce this machinery so people were aware of it.
01:14:52.994 - 01:14:58.194, Speaker A: But yes, it's nice to point out that we do not.
01:15:09.944 - 01:15:17.844, Speaker B: Another question. So will asks, which graphs are generically rigid for all d? So how common are graphs satisfying this condition?
01:15:19.064 - 01:15:21.072, Speaker A: Sorry, Tony, can you still hear me?
01:15:21.208 - 01:15:21.924, Speaker B: Yes.
01:15:22.304 - 01:15:32.896, Speaker A: So for some reason, my. I stopped staring my slough to come back. I don't know what happened. Maybe as I was fiddling about with the mouse. So, sorry, what did we last?
01:15:32.960 - 01:15:40.204, Speaker B: If we'll ask which graphs are generically rigid for all d, and how common are the other graphs satisfying this condition?
01:15:42.474 - 01:15:48.294, Speaker A: So you want a particular graph to be generically rigid for all day.
01:15:49.154 - 01:15:56.574, Speaker B: So I guess he's saying that simplex is generically rigid, but whichever graphs can be, how common is it to be rigid?
01:15:56.954 - 01:16:21.014, Speaker A: Well, I don't think any other graph could be rigid for all d, because as soon as you have two non adjacent vertices, if d is large enough, you can use the other vertices as a hinge, and you can flex the two non adjacent vertices about the image. So, complete graphs are the only graphs that are rigid for all time.
01:16:25.474 - 01:16:34.054, Speaker B: Alex asks, is there a characterization of the set of graphs from which all minimally rigid graphs can be obtained through zero extensions and one extensions?
01:16:38.734 - 01:16:53.394, Speaker A: So I guess care three. So you have to allow care three and you can obtain all minimally rigid graphs from k three. Presumably we're talking about two dimensions, aren't we?
01:16:53.974 - 01:17:10.534, Speaker B: I guess so it doesn't say in the question. Alex, do you want to comment? Yes. He was assuming d equals two.
01:17:11.274 - 01:17:46.554, Speaker A: Yeah. So we have to include k three. Or if you prefer, you could start off with k two, and then once you get k three, you get everything. And if you don't have k three, then you don't get everything. So a minimal set would be care three or care two. And then if you wanted other sets, then, then you could do some. You could do a zero extension or a one extension of care three, and you would get bigger sets, but they're a bit redundant.
01:17:46.554 - 01:17:50.194, Speaker A: Is that okay?
01:17:51.414 - 01:18:05.444, Speaker B: I was wondering if the question was sort of asking like, so it's true that you can get all minimally rigid graphs from a minimally rigid subgraph of it. So, starting the recursive construction from a rigid subgraph.
01:18:05.484 - 01:18:06.396, Speaker A: Oh, yeah, yeah.
01:18:06.540 - 01:18:09.264, Speaker B: So that was what it was getting at, the question.
01:18:13.844 - 01:18:34.364, Speaker A: Yes, that's true. So if we're interested in constructing a particular minimally rigid graph, and we have a particular minimally rigid subgraph of that graph, then we can construct the larger graph from the smaller minimally rigid subgraph using zero and one extensions.
01:18:41.904 - 01:19:20.844, Speaker B: And Bob asks, what happens if you take free v minus six for graphs in free space? It does not correspond to rigidity, but does it correspond to anything? And I think Walter and Jim have sort of answered and, oh, and asking a new question, I'm guessing that Bob means, what do we get with free six sparsity for sufficiently large vertex sets? Oh, and then T Boy's answered that. Answered that. In some cases, free six sparsity characterizes independence in free space, say, for planar graphs or for squares of graphs. So I don't know if you want to add anything to that discussion.
01:19:22.144 - 01:20:14.964, Speaker A: Well, only that you have to be careful when you say a three six parsity, that you do not imply it for sets of size two, because then nothing is independent. So it's, it's, it's, it's, it's three six sparsity with the added condition that you only apply it to a set of size of lace tray. Then, as you said, for planar graphs, it gives you a metroid. But you can't use Edmunds there on this metroid because. Because the only exclusion allowed by Edmunds theorem is the antisemit.

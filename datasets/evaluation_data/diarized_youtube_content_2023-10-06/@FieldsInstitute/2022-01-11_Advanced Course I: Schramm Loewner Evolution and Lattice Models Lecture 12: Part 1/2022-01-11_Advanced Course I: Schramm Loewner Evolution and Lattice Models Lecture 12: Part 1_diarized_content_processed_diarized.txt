00:00:01.440 - 00:00:41.374, Speaker A: Welcome everyone to the last lecture. Okay, I hope my microphone works. Yeah, it does. Okay, so today I wanted to continue discussing the proof of convergence of the interface of critical percolation to SLS six. And let me very quickly remind you what is going on here. So, we have the exploration process for critical percolation. Remember, you go around hexagonal lattice here and you flip the coin every time you encounter unexplored hexagon.
00:00:41.374 - 00:01:59.454, Speaker A: And depending on outcome of the flip, you color blue or yellow and you turn left if you encounter blue. You turn right if you encounter yellow. And we are trying to show that when we rescale things in weak topology, this random curve we just selected, we just created, converges to slide domain. And as we saw last time, this critical percolation process, critical percolation exploration process, rather satisfies a companion Smirnoff condition, so it satisfies tightness. And now all we have to prove, to prove this convergence is to show that if you take any subsequential limit of this random curves, weak subsequential limit, it lives on SLS. So it is a solid six. And for this, we would use cardis formula, which is the first conformal invariant object we observed about percolation.
00:01:59.454 - 00:03:21.994, Speaker A: Well, this is what Smirnov proved, that if you look at the crossing probability of a rectangle, then independently of the shape of the rectangle, this probability depends only on the models of the extremal length of this rectangle. And so, there is a precise formula there. And we would like to exploit this formula, but we need a property, which is Martingale property of this crossing probability. And let me remind you what it is. So, we know that if you look at discrete scale, then crossing probability of the original rectangle, conditioned on the fact that the beginning of the exploration process is, well, what it is. This gamma is the same as to do the crossing in the new domain, where you just remove part. So you remove explored part of the curve.
00:03:21.994 - 00:04:14.964, Speaker A: And of course, you want to cross from this side, this blue side here, to this side here. And as we saw, these two probabilities are equal. And unfortunately, unfortunately, there is a huge technical problem, which I want to discuss now. And the problem is that, well, this is true for Delta. When Delta goes to zero, we know that this converges to continuous crossing probabilities. This is, we know that this converges to corresponding card smell of probability. The thing is, we conditioned on the curve here, on the curve on the lattice.
00:04:14.964 - 00:05:13.144, Speaker A: Suppose that now our exploration process starts with this curve, which is not on the lattice. How would you know that this is still satisfied when delta is equal to zero. Okay, so this is the technicality, and let me explain how to deal with it. And the main lemma here, which I will not prove, but this is actually relatively easy to believe. We discussed this lemma last time, is that if you have two curves which are close to each other, then the crossing probabilities are also close. But you see, there are lots of nuances here. So we have a Leonard curve, gamma, which starts from a and goes to c.
00:05:13.144 - 00:06:29.862, Speaker A: But let it, let us stop it before it enters some fixed neighborhood of c, capital delta neighborhood of c. Then I claim that for every epsilon, you can find delta, which depends only on the epsilon and this delta neighborhood, and d of gamma, which depends on the curve. This is very important. It depends on the curve, because really, curves, this rigidity statement that we want for curves which are almost touching the boundary, this d of gamma would be very small. But anyway, so if the distance to another l curve to gamma and the distance, remember, in the sense of crescendo distance that we discussed is less than j of gamma and delta is smaller than this universal delta, then not only crossing probability for the curve gamma is close to the crossing probability. Zero crossing probability, continuous crossing probability. But it's, it's still true when we perturb the curve slightly.
00:06:29.862 - 00:07:38.214, Speaker A: So for perturbed curve, as long as gamma prime and gamma are close, these two crossing probabilities are about the same. Okay, so that's something we already discussed last time. So again, if that c delta converged to c zero not only for gamma, but for some neighborhood, and neighborhood is shrinking. So this is exactly in the sense that I described, that d depends on gamma. And I should have probably written that it also depends of cosm epsilon. Okay, so now let us consider a conformal map. Remember, to define SLA, we need a conformal map which maps our domain omega with two boundary prime and, say, and c to the upper half plane and their boundary prime and, very exciting, zero and infinity.
00:07:38.214 - 00:08:20.564, Speaker A: Now what do we do? We look at this psi of gamma, our Leonard curve. We parameterize it by half plane Leonard capacity. So we parameterize gamma such that half plane capacity of the image of this curve in the upper half plane and upside is two t. Remember, this is ljovna repairametrization. And this is called liovniperimeterization of gamma. And what is very, very important, that it actually depends on psi. If you choose another psi, you have another Leonard perimeterization.
00:08:20.564 - 00:09:37.034, Speaker A: So somewhere behind the scene here is the fact that actually not only we chose a domain and two boundary points. We also fixed a conformal map back to upper half plane because again, remember they are different by dilation and if we redilate, gamma would be parameterized differently. But the next lemma essentially says that, remember our distance between curves is the we take the best reprimand which makes them close. We don't need to do this. So that's the lemma. Suppose that gamma is the luvner curve with Leonard parameterization that goes again from a to c and delta is, as in the previous lemma, some positive number such that if that our curve up to time t does not approach c too much. So again we stay outside of some neighborhood of c.
00:09:37.034 - 00:10:14.484, Speaker A: So this is a bad picture. Well, unless delta is a very small neighborhood then the exist at which depends on epsilon, this delta and the curve such that if gamma prime is another ljovnir curve which is at a close to our curve and you run gamma prime in. It's Leovner parameterization. Right. It's a Leovner curve. So again, map to the half plane parameterize. You have your parameterization.
00:10:14.484 - 00:11:07.814, Speaker A: But what it says is the following. If this distance is smaller than epsilon Zaneta then in lieu of null parameterization, there will be epsilon clause. Okay, so this says that you can, instead of thinking about all possible parameterizations of gamma and gamma prime when they are close you can think only about ljovner parameterization. So there is this canonical parameterization which still makes the curve clause. Now, another very important remark here. Gamma itself has to be ljovnar curve. Gamma prime has to be Leonard curve.
00:11:07.814 - 00:11:34.166, Speaker A: Otherwise there is no lithium. Eta depends on curve gamma. For different curves, it would be different. So imagine a curve which barely fails to be non Leonard. Something like this. This is a Levner curve. It's the way I drew it.
00:11:34.166 - 00:12:04.914, Speaker A: It's not self touching. Oops, it disappeared. But perturb it slightly. It stops being levner. So of course Leo parameterization would well change dramatically if you perturb too much. So this eta is really co dependent. Okay, so now these are two preparation lemmas which I will not prove.
00:12:04.914 - 00:12:40.978, Speaker A: But now I want to give you an idea of how the proof of the convergence goes. So this is the classical proof which goes back to Smirnov. Well, with some modifications. So for this, I will introduce this notation. So let gamma tilde by definition be psi of gamma. So if gamma is a Leonard curve from a to c in the domain and psi is our fixed conformal map psi of gamma will become lrfnh and let it be driven by lambda of t. So let's look at this picture.
00:12:40.978 - 00:13:45.474, Speaker A: Here we have this curve from a to c. We map it top psi, we stop it at the time t. When the capacity of this curve, half length capacity of this curve is two t, we unwrap it by gt and lambda t would be this gt of gamma tilde of t. So this would be the image of the tip. And then we know that this gamma tilde is this laminar core driven by this lambda tilde. What do we need to show? We need to show that if gamma of tilde is now a random curve which is a subsequential limit of this gamma delta tilde, then lambda of t has the law of brownian motion. And by the way, here another technicality, because in general we wanted subsequential limits of gammas, not gamma of tilde.
00:13:45.474 - 00:14:57.102, Speaker A: But we are talking about crescentoi distance crossed is conformally environed. So it doesn't matter which you consider. So if, let me be careful, it's, well, it's not exactly conformally invariant, but tending to zero and one is the same as tending to zero in the image. So if the sequential limit of gamma tilde deltas is gamma tilde in the upper half plane in uniform distance, then by this just mentioned conformal variance, the same would be true in crusade metric in the image. Okay, so now to observe this, as I mentioned, one of the technicalities, which was surprisingly difficult. So for some reason people thought that it would be triviality. Then it turned out that, well, it required a proof.
00:14:57.102 - 00:16:04.392, Speaker A: So here, let me explain how the proof goes. So if you look at this martingale property, and so let me state it here. So, expectation of the crossing probability of the card domain given the beginning up to time. So conditional expectation is the same as crossing probability of the domain up to time s. And again, we only need to prove it, of course, for s equal to zero and delta zero, right? Because then we just say, okay, let's just consider our domain up to time as look at this. Okay, so let's go back here and let us look at this. So fix this capital delta epsilon and let us consider this event.
00:16:04.392 - 00:17:22.954, Speaker A: This are ljovnir curves in omega from a not intersecting delta neighborhood of c. Okay? So if you look at all such curves which do not yet enter the sniper. Okay, now this is a metric space. So we can choose a countable collection of curves such that l, delta is covered by countably many balls centered at this curves, gamma n of radius d of gamma n epsilon well, again, countable compactness here. And so what we do around each curve, we consider a ball in the space of curves of radius d of gamma, epsilon, and these chosenness and this rigidity lemma. So we'll look at the curve for each. And now again, by meterizability, we can select countably many of such guys.
00:17:22.954 - 00:18:43.160, Speaker A: Okay, and then what does it mean? If we are our curve is in one of these balls, then c delta minus c zero is less than epsilon. So we call this crossing probability k delta of gamma prime, this continuous crossing probability k zero of gamma n. Okay, so the thing is, now that we have to deal with only countably many of them. That's the beauty. Okay, and so now let p node be the law of a subsequential limit. Let us fix a very, very small alpha and choose n capital disjoint sets such that the probability that you outside of these sets is less than this very small alpha. And the sets are what? Well, the first set is b one, the second set is b two minus b one, and so on.
00:18:43.160 - 00:20:17.820, Speaker A: So the usual trick, you have a cover by balls. You create non intersecting ones, but inside each of these balls in each of the sets, rather you have this rigidity. Now for small delta probability, that exploration process at level delta is not in one of the set is less than alpha, because again, the standard property of the weak limit, lim soup of this is bounded by the probability of this complement as a close set. So limit of probabilities of closed set. When you have subsequent weak convergence, everything is true. So here I should have been slightly more careful because of course we only have subsequential limits of this p del tens of course, only for this sequence which defines p zero. Okay, so now remember this k delta is our crossing probability.
00:20:17.820 - 00:21:31.604, Speaker A: I just didn't want to write all the stuff. Then what do we have? I want to compute expected value of this crossing probability of chi delta up to time t. Well, this close to just the, you take probability that your curve is in Dj and then you take k delta of gamma j, the center of this wall. And this is just bounded by Alpha plus delta because again, here we have rigidity inside. The probability that you are not here is alpha. So the difference is bounded by alpha plus delta. But the same is true for p zero, right? So when you, you can do exactly the same trick for delta equal to zero.
00:21:31.604 - 00:22:29.244, Speaker A: So it's also less than half plus epsilon. And so now all we have to do, so we want to show that this converges to this. But, okay, I see that I'm missing a bracket, sorry, this is not a bracket, that's a bracket. Good. Okay, so now we want to estimate the difference between this and this. So again, we want to show that this is close to that. Now we want to just show that this is close to this well, but that's easier because this converges to this and this is close to this well by rigidity or by Smirnov's convergence.
00:22:29.244 - 00:23:32.984, Speaker A: And so again, we just need to be slightly careful here. We know that since the j open of probability of the j is bigger equals than p zero, so this is bounded by two alpha above and minus alpha. Well, so we can say that eventually that it's bounded by three alpha. And now in all of this, we let delta goes to zero, epsilon goes to zero, and alpha goes to zero. And we get eventually this. So it was a sequential limit, we have this property. And of course we also, as I mentioned, need the version of this for gamma zero s.
00:23:32.984 - 00:25:16.278, Speaker A: So we need a version of this for curve stopped at some time s. And the proof goes essentially the same way as I mentioned. But there is a little twist. We have to take into account the event that either b of d as followed before time s. And so let this be the event that needs b or D as followed before time size, and then condition, well, expectation of this, given that we are not swallowed by time t is equal to this. Okay, so trivial statement, right, that, just remember, it was really easy to prove that for discrete crossings you have this Markov or Martingale property, but proof that it's true for continuous, it's actually this complicated. But so what we did just establish, we established the fact that characteristic function of the event that no point b or d is followed multiplied by the zero crossing probability.
00:25:16.278 - 00:26:33.924, Speaker A: So continuous crossing probability, the martingale with respect to p zero. So that is what we will need, as you will see in a moment, to prove convergence to Slsx. Okay, so now let's try to exploit it. So now let's remember in the Cardi formula, Cardi's formula, we normalized it. We said, okay, let us, instead of looking at the map to the triangle, let us do like cardiac originally did, let us map this whole picture to the upper half plane. And where one minus x is mapped a is mapped to one minus x, zero is mapped to, is mapped to five b, and rather b is mapped to one, sorry. And c is mapped to infinity.
00:26:33.924 - 00:27:58.378, Speaker A: And then the crossing probability in this picture is just this hypergeometric function f. What happens when we start moving along the curve, this x changes so let's return to the picture. The crossing probability for gamma up to time t. This would be f of this xt of the x corresponding to unwripening of the curve up to time t. And now we want to see what equation this x t satisfies. Okay, for this we consider our map psi, which maps our domain to the upper half plane in the sense. So a is mapped to zero, which we denote by tilde.
00:27:58.378 - 00:28:38.396, Speaker A: C is mapped to infinity and this is, aha, this would change. So b is mapped to b tilde, d is mapped to detail and then there would be invaluable. So let's see what, what happens there. So now this map psi doesn't map with the right normalization. Remember that we want to in particular map a to this one minus x. So for this we consider this map ht of z is the following. This is gt of z minus gt of d tilde divided by gt of b tilde minus gt of d tilde.
00:28:38.396 - 00:29:14.554, Speaker A: Okay, why do I want this? Let's see what it does with our domain omega gamma of TBCD. What does it do to be, for example, it maps it to, well, gt of b tilde minus. Okay, so now I see what I have to do. So. No, no, no no. Okay, rank ahead of myself. This is the t of Z.
00:29:14.554 - 00:29:52.500, Speaker A: Ht compose with psi of Z. What would it do for this b? For example, it would map b to be tilde by psi and then this would map it to one same. C would be mapped to infinity, d would be mapped to zero and then gamma of t would be mapped to one minus xt. So let's plug in gamma of t here. So this is ht of psi of gamma t. So this would be gt of psi of gamma T. Remember what it is? It's lambda t.
00:29:52.500 - 00:31:01.244, Speaker A: So x t is one minus lambda t gt minus gt of g tilde divided by gt of b tilde minus gt of d tilde. And so this is what this x t is. So what we just proved, we proved that this crossing probability is a martingale, essentially. So we just need to plug in this xt and here to get that f of this on the event that nothing has followed characteristic function of sait. This is a martingale. Now I said, well, okay, it's a technicality, but let us ignore it for now because essentially we can actually deal with it. We can select t small enough and say that, well, for small enough t's, t's depending on d and b.
00:31:01.244 - 00:32:04.114, Speaker A: That's essentially negligible. And let's d and b go to c. That's what will happen here anyway. So for simplicity, we'll just acknowledge this part. Okay, and then what is, let's rewrite our main observation for continuous crossing probability sources for the subsequential link. Expected value of f of gt of b tilde minus lambda t divided by dt of b tilde minus gt of d tilde conditioned on the beginning of the curve, it's f of j's of b tilde minus lambda s divided by j's of b tilde minus j's of d tilde. Again, if we ignore this part, which has very small, this not been true, has very small probability.
00:32:04.114 - 00:32:48.884, Speaker A: But if we ignore this part, that's essentially what we get. We get this property and that's all. So let me explain why this proves everything. So we fix s and t and we take very special d tilde, which is minus two b tilde. So we are varying b and d. We know that this property is true anyway. Then for large b tilde, the following things would happen.
00:32:48.884 - 00:33:49.564, Speaker A: So what I do, I remember that these things gt has hydrodynamic parameterization. So why don't I just use it? Why don't I just write the gt tilde of b tilde is b tilde plus two t of one over b tilde squared plus or capital of one over b tilde squared. And then we do the same with the bottom. And remember, d tilde is minus two b tilde. So if we plug everything there and we get this expression and we see that this is actually, this whole thing is close to one third, right? So essentially, barring other terms, this is something like b tilde over three b tilde. So it's like one third. So the first term here in this expansion is always f of one third.
00:33:49.564 - 00:34:43.654, Speaker A: But now let's see, we can just expand it. Volunteer the correction. So this is lambda t over three f prime of one third, one over b tilde minus t over three, f prime over one third, one over b tilde prime plus lambda t squared over twelve f w prime of one. So final b tilde squared plus o capital, final b tilde cubed. So well, this all horrible terms. So why don't we just call this term a, this term b? And now one over b tilde terminology, let's call it c. So there is 60 here.
00:34:43.654 - 00:35:39.304, Speaker A: Nice. So you see, we didn't really care what these values are, a, b and c, as long as they're not zero. And it's really easy to check for this function f they are not zero. Things are great. Now, what does it mean? Let's remember that we know that expectation of this expansion at time t given s, is this expansion at time s. So we compare the corresponding terms and we see that expectation of lambda t condition on gamma zero s is lambda s and expectation of lambda t squared -60 and lambda squared minus six s. Now, this is something that we would like, right? Because this first property shows that lambda t is a continuous time martingale.
00:35:39.304 - 00:36:18.524, Speaker A: But it also shows that the second, that lambda t squared -60 is also in martingale. So quadratic variation of lambda t is, surprise, surprise, at 60. So what is a continuous martingale with quadratic variation 60? That's the brownian motion run with six levy theorem. That's it. We are done. Okay, so of course I lied. And this is again, I've seen this mistake in likely the papers that I've referred but were not yet published.
00:36:18.524 - 00:36:59.592, Speaker A: You still need to look at this term I wrote o capital of one over b tilde squared, b tilde cube. But if you look carefully, there is a lambda t. So in this capital, lambda t would be present. Lambda t could be huge, right? Even if you think that it's brownian mosh, then this lambda t can be arbitrarily large. The probability of this is vanishingly small. So you need to deal with this term. And what helps here, there are two ways to do it.
00:36:59.592 - 00:37:39.274, Speaker A: So first, let me show you the new way, kind of. So this just follows from campaign Smirnov serum. So essentially, you see that this driving term we call that ws here it has bound at exponential models. And that's enough to actually show that with small probability. With large probability, this term is small. But let me show you specifically percolation. I think it's also cool.
00:37:39.274 - 00:38:26.154, Speaker A: And this is, we estimate the probability that lambda of t is bigger than n. We estimated to be. Well, that is essentially the case exponentially. So when t is fixed. So this is just exponential decay and probability that the curve ventured too far away. This is also small. Okay, so I was trying to explain to you that we just need this.
00:38:26.154 - 00:39:14.804, Speaker A: But actually you will see that this is what we will prove. And to prove this, we need an auxiliary estimate, which of course is also being used in companions. They use the same sort of estimate. I just wanted to show you an estimate which has nothing to do with stochastic. So this is adjust a property of Leonard evaluation. First of all, that imaginary part of gamma t up to time t. So you're curve in parameterization up to time t, you cannot get higher than two square root of t.
00:39:14.804 - 00:40:14.144, Speaker A: And second is that supremum of gamma is tilde. So that's the maximum here is bigger than lambda t over four. So if you have this second estimate, you automatically get false estimate because if supreme of the curve is small, then you're dragging. Okay, let us first prove the statement and then lemma. So as I said, the proof of the lemma would be percolation. The statement has nothing to do with the heisticity at all. Okay, so, well, proof of first is an easy calculation.
00:40:14.144 - 00:40:45.664, Speaker A: Let's look at the derivative of imaginary part of j of t. So this is minus two imaginary part of gt of z, gt of z minus lambda t squared. So that's calculation that we already had. And clearly this is bigger than minus two over imaginary part of gt. So imaginary part of gt of z squared. Put it here. You integrate, it's simply imaginary part of z squared minus four t.
00:40:45.664 - 00:41:46.424, Speaker A: So if z is bigger than z is equal to gamma tilde of t, then imaginary part of this, it's zero. So we just plug it in here and we get that imaginary part of gamma tilde of t is less or equal than two square root of tth. So essentially this calculation just shows that in time t you cannot hit zero if you are above this level square root of t. Okay, now let's look at the supreme of gamma tilde phase. And then let's look at the corresponding compact hole. So remember, fact hole is everything, which was followed by the curve up to time t. Of course it's subset of rt of d intersect with h.
00:41:46.424 - 00:42:57.694, Speaker A: Okay? Then if g of z is this Jakowski map which maps it back to h. So in parameterization then gt d g. Remember this, we had this property of domination, so one domain subset of the other. Then remember, one of the properties of domination is that for every x bigger than r of t, g of x is less or equal than g of x, which is just x plus rt squared over x. So this is true for all real x. So outside of kt we have that gt of x minus x is less or equal than r of t on kt, on the other hand, we of course have the gt of x is less or equal than two r of t. Again, just plug in things here.
00:42:57.694 - 00:44:05.274, Speaker A: So gt of x minus x is then less or equal than three r of t, because on kt we are less than r of t. So by maximum principle, for all z gt of z minus z is bounded by three r of t and now let me let z go to gamma of t. This becomes lambda of t, this becomes gamma of t. So lambda of T minus gamma of T is less or equal than three r of T. But gamma of T is also less than r of T. So lambda, this means that lambda of T is at most, sorry, is at most four supremums. And that's exactly what we want to prove.
00:44:05.274 - 00:45:08.534, Speaker A: Okay, so we know that to estimate this, we need to estimate this. So to estimate this probability, we just need to estimate this probability. Let's just do this. So as I said, second statement implies, first statement, so supreme, if you know that supreme is bigger than n, is small probability. Same is true for lambda of T. Okay, but what does it mean that supreme gamma of s is bigger than n? Let's see your imaginary part of gamma of S. It's below two square root of t.
00:45:08.534 - 00:46:05.594, Speaker A: On the other hand, you got up to level n. So what just happened? Your path crossed a rectangle here, a rectangle here, gamma tilde crossed a rectangle this height, two square root of tilde and this length. Well, again, we want modulus bigger than n. So let us be generous. Put n minus two square root of t here. So you see, gamma tilde crossed this huge rectangle, which means that gamma crossed the pre image of this very long rectangle, which has a small model. This rectangle has models n minus two square root of t divided by two square root of t.
00:46:05.594 - 00:46:51.864, Speaker A: So you crossed the rectangle of this modulus. But then you can just use Cardi's formula. What is the probability of crossing a rectangle of this huge modulus by Cardi's formula? As I said, this is a percolation proof. This probability is bounded by e to the minus one third n over two square root of t PI. So that's, again, you can unwrap it from the card, this formula that this is exactly the rate of decay. You crossed a rectangle essentially of size n over two square root of t. Well, there is a small correction here.
00:46:51.864 - 00:47:35.942, Speaker A: Well, n over square root of two of t minus one. That's the fact. Then it's just a constant here. But the probability again decays exactly as we want. And so this explains this over square root of t here, here and here. Okay, so this finishes the proof of convergence. So we just established that exploration process for critical percalation.
00:47:35.942 - 00:49:03.670, Speaker A: Hexagonal lattice converges to SLS six. Question is, can we do more? So let me state what was predicted by physicists, what was predicted by renormalization theory, which I mentioned tangentially was the following, that if you consider your random curve on some lattice of size one over n. So let me use m here instead of delta, then the distance from this random curve generated by interface on the slices to corresponding SLA, not only photocalation for everything, should be something like n to the minus alpha for some alpha. So you have not just convergent, you have a polynomial rate of convergence. Okay, so here, of course. Well, as I said, it was prediction from physics, so nothing is. We need to define in what sense this is true.
00:49:03.670 - 00:49:59.364, Speaker A: This again, two random objects. There is standard way to measure distances between them, which is called prokaryov distance. And I will elaborate on this. And so what I want to do in the next tile, after we take a short break, I want to discuss our result with my former PhD student Larissa Richardson, which essentially gives axiomatic approach to this. And then I will explain how it applies to percolation. Okay, so this is my plan for the next hour. Now let me take a ten minute break, and we'll reconvene at 11:00 around the time.

00:00:00.320 - 00:00:37.524, Speaker A: For the introduction. It's a great pleasure to have this opportunity. Let me start thanking the organizers for this great invitation. Let me thank Alessio for winning the Fields medal. You're welcome. And also for allowing to finish a work that I started in 1996, as I will tell you later. And it's about this business of stable solutions to some linearly equations.
00:00:37.524 - 00:01:11.706, Speaker A: So I will present a recent paper by myself, Alessio Xavier Rosoton and Joaquin Serra. And it's now already published, but you can find it in archive also, if more convenient. So. So let me tell you the. So let me tell you the story. Sorry, I don't know how to pass. I don't know how to go through.
00:01:11.706 - 00:01:32.208, Speaker A: Next slide, you click on the PDF and then you go with the arrows. Yes, thank you. It was not clicked. Thanks. So, okay, everybody knows what a SEM linearly TPD is. This is the simplest one. They are also called reaction diffusion equations.
00:01:32.208 - 00:02:31.134, Speaker A: Right? So simplest, because the diffusion will be given by the Laplace operator. And here you have the reaction term and will be always, the equation will be posed always in a bounded domain over n, omega over n, right? So this equation is the Euler Lagrange equation of a functional that we call the energy functional. And here you have it. It's the Dirichlet energy minus the integral of capital f of u. Capital f is primitive of small f. Small f is the nonlinearity, right? So you do the variation, the first variation of this functional, you get the equation, and then you can do also the second variation of the energy functional, which is the same as the linearization or the first variation of the equation. And therefore, it's going to be a linear operator, which is the linearization of this one.
00:02:31.134 - 00:03:43.754, Speaker A: So it will be minus Laplace minus f prime at u u. Here is given, is a given solution. So this is an operator of second order. It has the second order term, and then it has a zero order term, right? And then if, and then what you would look is that solutions which have non negative second variation. And this means that the operator is non negative definite in the Dirichlet sense, which is the same as saying that the first Dirichlet eigenvalue in omega is non negative. And if you look at the quadratic form, of course, associated to it, what you will find is that the quadratic form must be non negative, which is the same as this condition here, f prime of u times psi squared for any test function psi. So say c infinity function that vanishes on the boundary or with compact support, doesn't matter, this quantity will be smaller or equal than the grad psi square.
00:03:43.754 - 00:05:06.404, Speaker A: And this is the condition of the second variation being non negative, non negative at u, the second variation at u. And this will be our definition of stability of u being the function, u being the solution, u being a stable solution, right? So of course, if you have a minimizer, an absolute minimizer, or even a local minimizer, if the equation have local minimizers, of course they would be stable solutions, because at the local minimizer, so minimizer under small perturbations, the second variation will be non negative, right? So it is just the basic definition, say, of stability. And now some important remarks. So, the game that we are playing for the energy is among competitors that have all the same boundary values as the solution u itself. So, note that I defined stability without talking about boundary values. I didn't impose any boundary value on u. The perturbations are u plus a small parameter, say, tan psi.
00:05:06.404 - 00:06:21.264, Speaker A: And since psi vanishes on the boundary, they all have the same boundary values as you. So the game is this, comparing energies of u with functions that have the same boundary values. This is the dbk sense. All right? And the important thing now also is to have in mind that our interests are bad non linearities for regularity. What does it mean? Bad nonlinearities for regularities? Well, nonlinearities that grow big reaction terms, reaction terms, f that are non negative, say, and superlinear at plus infinity, they beat the linearity of the Laplacian. They are super linear. And then at this point, one realizes that there is no absolute minimizer of the energy, because the energy computed, say, on multiples of a function, any function, take any function theta scale it, multiply it by t, the energy is going to go like a quadratic term minus the potential energy.
00:06:21.264 - 00:07:00.814, Speaker A: But since small f is superlinear, capital f is super quadratic. So this potential energy will be the Dirichlet one and the energy functional. And then you see that the energy functional is unbounded below. So it goes at two minus infinity as t goes to plus infinity. Therefore no absolute minimizer. Now one can. So now, so that everything makes sense, one asks oneself, are there stable solutions or are there local minimizers? Not to be speaking about the antiset right about nothing.
00:07:00.814 - 00:07:46.034, Speaker A: And this is true. And in fact, our questions were motivated by this problem posed by Galphin 1963, which is the same equation, but now with boundary values. But now you add a parameter, lambda multiplicative factor in front of the reaction term. His interest was mainly on this nonlinearity. Down here, the exponential of u that comes from a. This is a simplified model in combustion. In combustion theory, more generally, you could consider non linearities which are positive even at the origin.
00:07:46.034 - 00:08:21.564, Speaker A: This is important. This makes that zero is not a solution of the problem. You see, for lambda positive, lambda will be positive. Once f of zero is strictly positive, then zero is not a solution. So there is not a trivial solution of the problem. We will take also f non decreasing convex and superlinear at plus infinity. And this setup already appeared in many papers that I will be mentioning later on.
00:08:21.564 - 00:09:33.934, Speaker A: So these are old, say sixties, from the sixties setting. And since lambda and f are positive, you will be a positive solution. And then it is very simple and is also known since back then, it's very simple to prove that there is a parameter lambda star that we call the extremal parameter, which is positive, it's finite, and such that for lambda less than lambda star, the problem admits a solution which is first classical, which means once a solution is bounded by elliptic regularity f of u, the right hand side f of u is also bounded. The solution becomes smooth. For instance, if f, think of smooth f stable, stable, so kind of a local minimizer. But now we know what it means stable. And this branch of stable solutions is increasing in lambda and to a function u star.
00:09:33.934 - 00:11:00.584, Speaker A: In fact, let me say this solution here is called, what is also called the minimal solution of the problem. For the parameter lambda, minimal in the sense of smallest, it's the smallest solution of this problem. Once you fix the parameter lambda, and you can obtain it from zero, which is a subsolution by monotonic iteration, you put here, you do monoton iteration, if you know what is that, and the scheme will converge to the smallest possible solution for the parameter lambda, which is this u lambda, and which turns out to be stable, like a local minimizer, okay, by minimality, the branch is going to be increasing in lambda. And as I said, it will converge to a function, then it's easy to prove that it's in l one, and therefore it's at the same time that it's a distributional or a weak solution. Say the distribution of sense, say for the extremal problem, the, the extremal problem is the problem corresponding to lambda equals the extrema parameter. We call it the extremal solution of the problem, right? And it corresponds to lambda equals lambda star. And then it's not difficult to prove that for lambda bigger than lambda star, there are no classical solutions.
00:11:00.584 - 00:12:21.384, Speaker A: And then in the nineties, Breziz and his group Perisix got really interested by this problem because of some connections also with the parabolic problem, ut minus Laplace u equals f of u. And we're able to prove more difficult things related to it. And for instance, one of them was that for lambda bigger than lambda star, there are no distributional solutions of the problem. Not only there are no classical solutions, but also no distributional solution. So that was the starting time, say 96, more or less 95 of the revival, say, and the new interest, as you will see later when I give you the bibliography, about this Galphin problem or Bareblatt Gelfand problem. Okay, so the model non linearity is, as I told you, the exponential. Another one would be a power, but not the pure power, because we need f of zero positive one plus u to the power p with p bigger than one.
00:12:21.384 - 00:13:15.094, Speaker A: So the first paper, in fact, is a paper by Joseph Anngren 72. The first paper with some results, and the paper concerns the radial case. So we take omega to be the unit ball. All solutions, all these solutions will be radially symmetric, and they consider both the exponential and the power. But let's focus on the exponential non linearity. And through all the techniques, say, face plane analysis, they proved that the picture of solutions, the pictures were these ones, depending on the dimension. They found that for dimensions between three and nine, let's forget about dimension two, now mention three and nine.
00:13:15.094 - 00:14:14.960, Speaker A: The branch of minimal solution is this one, is this one that I'm pointing out here, right, the extrema solution, they were able to prove that was bounded in the unit ball in these dimensions. And then, by the implicit function theorem, the branch would turn back, because the linearized, the first eigenvalue at the extremal solution, the first eigenvalue of the linearized operator at the extremal solution is zero. And then this corresponds to a turning point. And then they showed in addition, that the, the branch would continue and turn infinitely many times and cross infinitely many times. This vertical axis that corresponds to a parameter here, which is less than lambda star. On top of the branch, there is a solution which is unbounded, l one. It's a distributional solution, but it's not stable.
00:14:14.960 - 00:14:52.366, Speaker A: So, in fact, here the picture is that these first branch of solutions are stable. And then the first eigenvalue of the linearized operator becomes negative here. So these ones are already all unstable. Instead, in dimension, I'm picturing here, as you saw, the infinity norm of the solutions. Instead, in dimension ten and higher, the branch is simpler and just does like this, there are no other solutions in the case of the unit ball and the exponential nonlinearity. And the extrema solution is not bounded. It's not bounded.
00:14:52.366 - 00:16:03.950, Speaker A: It's a distributional l one solution which is unbounded. Okay, so one of the things that Brezism collaborators did at that time, that time, I mean, in the second half of the 1995, say around then, is to explain or partially explain this dimension 910 dichotomy with a simple PD computation, which is first realize that the logarithm is a solution of these, of the problem for some parameters. So take the logarithm minus two times the logarithm, right? It's a positive function in the unit volume. It vanishes. It vanishes on the boundary. Then compute the laplace, each laplace, and you will see that it satisfies the Gelfand problem with the parameter lambda equals two times n minus two. I need to be in dimension three and higher.
00:16:03.950 - 00:16:58.624, Speaker A: Now compute the linearized operator at this particular solution, and you obtain minus Laplace minus two times n minus two, exponential of u, exponential of u is one over x squared. So the lineage operator is very nice because it's of Harvey type. These rescales the same. Both terms rescale in the same way. And therefore, thanks to Harvey's inequality, it's very simple to know if it's non negative definite or not, and it will be non negative definite whenever this constant here, two and minus two is not larger than the Hardy constant, which is n minus two square over four. Now you make the algebra, right, and you get n minus two greater or equal than eight, n greater equal than ten. So in dimension ten and higher, you already have a singular stable solution.
00:16:58.624 - 00:17:54.154, Speaker A: And then it's not difficult to prove that for every given parameter, there is at most one stable solution. And therefore in dimension ten and higher, this guy, this explicit guy must be connected to the branch of minimal stable solutions, and therefore the branch must blow up in an infinity norm as lambda goes to lambda star. So at least this computation gives you some explanation of this picture. Of course, the pictures are more precise. The same thing can be done for the powers. Now here you have the powers, and then the explicit solutions are also powers of the distance to the origin, negative powers and explicit singular solutions. Now you can make an exercise.
00:17:54.154 - 00:18:55.832, Speaker A: Compute. Compute the parameter for which they are solutions. There is a parameter in front here. Then compute the linearized operator. And look when the solution is stable, and you will get that the exponent alpha p is given by p. Given any p, the exponent is two over p minus one, and then you will find that you can make this singular solution stable only in dimensions eleven and higher, eleven and higher, but never before, never in smaller dimensions. So at that time, say, the late nineties, it's when brzee and collaborators posed several questions, and probably for me, the most important one was this one.
00:18:55.832 - 00:20:28.246, Speaker A: When is the extremal solution bounded, depending, say, on the domain and the nonlinearity, which are our ingredients. And another question would be, when is the extremal solution in the energy space? So h one or w twelve or more generally, you forget about extremal solutions. You go back now to my first slide, and you ask yourself, when are stable solutions stable in some weak sense? When are stable solutions bounded? When are they h one? All right, just starting from l one solution, of course, let me say something important. If you forget about stability for general solutions, l infinity estimates, something like what we are asking here, exist in general. I should say that in general exists only when the non linearity is subcritical or critical. So it grows at most like a power, and the power is less than the critical Sovalev power, which is n plus two over n minus two. Otherwise you cannot expect l infinity estimates, perhaps for some specific nonlinearities with some very peculiar structure or some domains.
00:20:28.246 - 00:21:25.244, Speaker A: Okay, anulus or things like this. But in general, this is the answer for general solutions. And as you will see, the picture changes very much when you have stability on your hands. Let me just say also, let me say also that there is, that this problem can be considered like a PD semilinear analog of a very famous problem in minimal surface theory, which is the regularity of stable minimal surfaces. And this, in fact, is a very important open problem still, because, well, it's not, it's known to be, to be, the regularity is known to be false in dimensions ten and higher, which means that in dimension ten, sorry, not ten and higher, eight and higher. Before we had the ten. Now we have here an eight.
00:21:25.244 - 00:22:29.102, Speaker A: In dimension eight and higher, there are explicit singular stable minimal surfaces and even minimizing minimal surfaces. The simplest one is the Simon's cone, which is also some kind of radial object like the one I had in the previous slide, explicit. That becomes stable in dimension ten and dimension eight, sorry. And higher. So this is well known. The problem has an answer, and it's known to be true in dimension only in dimension three. So for two dimensional surfaces, in three reals, which are stable minimal surfaces, so they have zero mean curvature and they are stable in the sense, second, non negative second variation for the classical perimeter or surface area, the result is true.
00:22:29.102 - 00:24:02.330, Speaker A: And this was proved independently by Fischer, Colby Chan 80, and the Carman pen. The problem is still open in dimensions from four to seven. It's a problem that many, many people have tried. Some people, and people would die, say they would die for proving this, but still open. By the way, if you change stability by something stronger, which is minimizing, if the minimal surface is not only stable, but is an absolute minimizer of perimeter, then the result is quite easy, and it is known to be true up to the optimal dimension, which is seven. The stability hypothesis is nice, but it's tough to deal with, for instance, to start with, to get energy estimates, to get energy estimates or area estimates in this setting, for stable objects, it's not easy, right? So, after the radial paper of Joseph and Andgren, the next paper is a beautiful one by Crandall and Ravinovitz, two years later. So, same time, more or less 75, and here they start getting results in the general case of non radial solutions.
00:24:02.330 - 00:25:13.010, Speaker A: So, any domain omega, and they prove that the external solution will be bounded up to dimension nine, when the nonlinearity is very close to the exponential or to a power. In fact, they get a relation between f f prime and f double prime. So the nonlinearity, its derivative, and its second derivative at infinity, that they have a condition, an hypothesis that is satisfied pretty much only for these nonlinearities. If a nonlinearity satisfies that, it must be an exponential or a power. So the condition is quite strong, but it gives something nice in these cases. For these non linearities, in particular, the extrema solution is always bounded up to dimension nine. And of course, it was this result that we had in mind in the nineties already for more general nonlinearity.
00:25:13.010 - 00:27:00.534, Speaker A: So here you wonder, what about other nonlinearities? Right? So these are the papers where they post these kind of questions. For instance, literally, Breziz, in one of his papers, he writes, is there something sacred about dimension ten? But he also writes, is it possible to construct a singular stable solution in some dimension less or equal than nine, for some domain and some nonlinearity? So I have to say that at that point, we were not sure at all. Even in the beginning of the 21st century, say, the two thousands, we were not sure if this, what was the answer say? So the first after, say, Breziz and his group comes in, the first nice result is by one of the PhD students of Chaim Breziz, Gregor Nedev. So this was, he worked on this during his thesis. So this is 2000, and he was able to prove that the extremal solution is bounded in any domain up to dimension three, and for any nonlinearity, say, of the type of the bad and blood Gelfan setting, say, positive increasing, convex and superlinear at infinity. So just keep in mind things like this, right, that grow and are convex. And also, he had an answer about the extreme resolution being an energy solution, and he proved that that was true up to dimension five, or in every dimension, if the domain was convex.
00:27:00.534 - 00:28:13.774, Speaker A: And this was already a very big, a very nice result. I mean, I have to say, he was a PhD student, but I was a postdoc at that time in perisigs. I thought about it, many other people thought about it within the group, and this was a very nice PhD result, in fact, and not an easy one. Some years later, well, five years later, I was able to prove with one of my PhD students, Antonio Capella, that in the radial case, the extremal solution is always bounded up to dimension nine for every non linearity, for every non linearity. So I'll tell you about proofs later on. So, this is a nice result. And it was at this point when at least myself, I started to believe that the result could be true up to dimension nine for all nonlinearities, or many nonlinearities, say, the Gelfan type nonlinearities, in other domains, because this was radial, this is the radial case.
00:28:13.774 - 00:29:06.554, Speaker A: But this still, 2005, I kept working on it. And then some years later, 2010, I was able to prove the l infinity bound up to dimension four, at least in convex domains, and an interior infinity bound in any. Of course, if it's interior, it doesn't matter what the domain is. And this was true also for every non linearity. No condition at all, in fact, just that f prime to define the stability f prime makes sense, but no condition at all on f. Then Salvador Villegas from Granada was able to combine my proof and medef proof and remove the convexity assumption. Here.
00:29:06.554 - 00:29:51.984, Speaker A: It's a nice paper, combining both my proof and proof. So the extrema solution is bounded in every domain and for every non linearity. I know he uses NETF, so maybe here one needs f to be convex and increasing, because my result up to dimension four does not require anything on f. All right, but that's not so, not so big. These are details. Now, continue working on the problem with some other, with some other people, but we just got, say, partial results. So nothing really as relevant as these things here.
00:29:51.984 - 00:30:38.248, Speaker A: But anyway, nice. For instance, this one with this paper with Javier Rosettan, I think it's a nice result. We consider the case of domains of double revolution. Double revolution means that you don't have a radial variable, but you have two. You take a domain in two dimensions and you rotate it right with respect to one of the two axes, and then with respect to the other, and with different number of variables in this axis and this. And then we were able to prove that, in this case, we were able to prove the l infinity bound for every nonlinearity up to dimension seven. I also discussed the problem with Joel Sprack and in this paper with Manuel Sanchon.
00:30:38.248 - 00:32:08.594, Speaker A: Joel Sprack, we got up to dimension five, but something that we don't like, say, a condition on the derivative of the derivative of f, right? So, let me show you now the main result in the paper with Alessio Xavier Rosoton and Joachim Serra. This is the interior bound, and it says that. So, the key point is to get a priority bounds, right? Once you have a priority bounds, you can use them, say, for the branch of minimal solutions, which are smooth solutions, then pass to the limit and get it for the extrema solution, for instance, in the Gelfand problem. So, we care about the priori estimate. So, let's take a smooth solution, if you want, of the equation, which is stable in the unit ball. And the assumption that we need is that the nonlinearity is non negative. Then we are able to prove that in every dimension, the gradient of u is in l two, even a little more l two plus gamma, and in the interior, in half, the ball and the corresponding norm is bounded only by the l one norm of the function in a larger ball with a universal constant here, and a universal exponent gamma.
00:32:08.594 - 00:32:53.394, Speaker A: And about the l infinity norm, that we know that it will hold at most up to dimension nine. We are able to prove it up to dimension nine. And in fact, we get not only an l infinity, but a beautiful holder estimate in half the ball in the interior with control just by the l one. So, some comments. First, you see, there is no dependence on the, of the constants or anything on the nonlinearity. It's like the nonlinearity disappeared, and the estimates look like linear estimates for linear problems, right? Like in Gilbert Trudinger say. But this is a nonlinear problem.
00:32:53.394 - 00:34:11.210, Speaker A: So you will see later in the proofs. How is this miracle, right, that f disappears and the estimates look like linear for this class of solutions. So, in fact, you are working with a class of, of functions which are those functions which are stable solutions of this equation. For some f, for some f, right? This is the class where you work, and f non negative, okay? From this interior estimate is very simple to deduce a globalist l infinity estimate in convex domains, because with zero dedicated boundary, because near the boundary there will be no singularities in a way. And this is proved by the moving planes, so that in a convex domain you can always start moving planes near the boundary and it will ensure that the solution is increasing for a while near the boundary, and therefore it cannot blow up near the boundary. So this was known, this is easy. But now you wonder what happens if the domain is not convex.
00:34:11.210 - 00:35:07.304, Speaker A: You would like to have a global l infinity or holder estimate, and that we can also prove. But there are some new things here. So take now a general domain. We need it to be c. Three, take a solution of the problem now with zero boundary values, and the same estimates are true up to the boundary. But we need the nonlinearity to be in addition to non negative, to be non decreasing and complex. So our proof requires all three ingredients, f non negative, f prime, non negative and f second non negative, which in fact makes us fall in the class of Gelfan and I would say Breziz, also the Breziz class, because he always insisted that this was a very natural class.
00:35:07.304 - 00:35:55.284, Speaker A: And at the end, in fact, for the global bound, we need all these assumptions. So, let me go into the proofs. Well, there is some more comments. All these. The corollary is that this regularity holds for the extrema solution. Then, in the paper, you also find a section where we treat the dimensions ten and higher, and here l infinity bounds, as we know, do not hold. But then the same methods lead oneself to quite sharp, in fact, quite sharp, maury estimates for the solution, for the stable solution, and for each gradient also.
00:35:55.284 - 00:36:28.724, Speaker A: All right, I will not enter into details and go into the proofs. Okay, so the point is to use two things, right, the equation and the stability condition. The stability condition is here. The difficulty in a way to combine them is that the equation concerns f and the stability condition concerns f prime. And if f is general. Well, there are some relations between f and f f prime, but not so clear. I mean, these are different, different things.
00:36:28.724 - 00:37:14.588, Speaker A: But the third thing is to look for test functions, psi. So the point is to use stability for certain test functions. And the first step is to realize that if the test functions psi is the product of two, of, of two other functions, say arbitrary functions, c and eta, this is not very well written. The product must be zero on the boundary. But what I meant here is that later what we will take is eta to be zero on the boundary. In this way, c is not assumed to be zero on the boundary. But take psi, theta equals c times zeta, put it here on the stability, and then just integrate by parts.
00:37:14.588 - 00:38:53.794, Speaker A: And the stability condition looks in a nicer way, I would say. Why I say nicer because the linearized operator appears computed at c. This is the linearized operator, which is related to stability. Of course, as we said, the linearized operator acting on c, then another time, c here, eta squared, and on the right is a delicate norm, but not the Dirichlet norm. As before, with a weight, the weight will be c squared. So this is a good starting point that I took in my paper with Antonio Capella thinking and motivated by the Simon dilemma on minimal surface theory, on minimal cones, which also takes, takes test functions, which are product of two things, and one of the things, the c function is crucial later on, and it will be a function chosen in an appropriate way, such that it satisfies something nice for the linearized operator. And in minimal surface theory, Simon takes c to be the second fundamental form of the surface of the hyper surface, say the principal, the sum of the square, the square root of the sum of the squares of all the principal curvatures.
00:38:53.794 - 00:39:41.700, Speaker A: So let's go ahead. Let me say, by the way, that the papers by Krandal Ravinovitz and by Nedevich did not use this way of writing stability. And they took as test functions directly in the original formulation for psi, a function psi, which is simply a nonlinear function of u, h of u. And you can do that. But okay, then one needs to use, needs to choose age. And when choosing h, it is very important to know what f is. It's not easy to choose h in the right way.
00:39:41.700 - 00:40:37.652, Speaker A: And that's why this works well when f is the exponential or some specific non linearity, but not for, for all of them. And my paper with capella, it's the first time, say, when we go to other test functions. And in the radial paper, the test function was r u r or u r. You could take c equals r u r, or we took c equals ur is the same because in fact, like in minimal surfaces, the other function will be essentially a negative power of the distance to the origin. Also, in the Simon's lemma on minimal cones, it's a function like this and then a cutoff. But don't worry about this theta, which is just cut off near the boundary. The important thing is that the eta will be a negative power of the distance to the origin, and the c is r u r.
00:40:37.652 - 00:41:06.984, Speaker A: Why? Because. Well, if laplace of u is f of u. You expect ur to satisfy something nice for the linearized operator. I will write this later in a second. By the way, in the non radial case, the corresponding function to rur is just x gradu. I mean, rur is the same as x gradu. And this makes sense also in non radial domains.
00:41:06.984 - 00:41:49.004, Speaker A: But here we were in the radial case. Stud my paper up to dimension four used another very different function, which was c equals the modulus of the gradient of u. Right? And in fact, in my, in our paper, we will use up to dimension nine the paper with Alessio, Gabriel and Joaquin. We will use both x value and c equals the models of the gradient. We need both. So what do you have to do? You have, you choose such a c. And what you have to look now is that the stability has, which is here on top.
00:41:49.004 - 00:43:13.750, Speaker A: Therefore, you have to compute the linearized operator acting on c. But this is very simple. And for extra du, it's just a very simple object, twice the Laplacian of U. And for the modulus of the gradient, it's also simple. And you simply compute and you get the full hessian square minus the hessian on the normal direction to the level sets square inside this quantity here, this right hand side, this right hand side, which is positive, includes the curvature of all level sets of the level sets of the function. And this information, geometric information, plus a geometric inequality, which is the Michael Simon Sovolev inequality, is what I used in dimension up to dimension four to prove the estimate in general domains up to dimension up to dimension four. So this proof that I had up to dimension four is very geometric in the sense that you work with the Coeria formula and you look really at the level sets of the solution, which are hyper surfaces, and the curvature comes in and you use a Sovolev inequality, which is geometric.
00:43:13.750 - 00:44:27.680, Speaker A: The Michael Simon, for those of you who know the Michael Simon Sovolf inequality, which holds in any hyper surface. All right, we will, as I tell you, we will distribute both functions in our proofs in the new paper. But the starting point is the other non linearity, which the other choice for C, which is x gradu, you put it on the stability. You get x graduate times the linearized operator computed at x graduate that we said it was two times the Laplacian of U. Now, here you see second derivatives of u, first derivatives, but most of you probably know the Pogosaf trick. You can integrate this by parts using the positive trick or identity, and then right away from the stability, nothing else, you arrive at this lemma that holds in every dimension, every nonlinearity, every stable solution and every test function, eta. And it looks like this, a certain integral is going to be non positive.
00:44:27.680 - 00:45:00.976, Speaker A: And there are three. The zero term, the first term, the second term, there are 3012. All right, the zero term has graduated as a factor. The first term, the second term, which is the term number one, it has the radial derivative. You see, this is r u r, the radial derivative of u. And since eta will also be radial, this will also be ur times a power of r, but it will involve ur. So u r squared.
00:45:00.976 - 00:45:50.200, Speaker A: Gradu squared. U r squared. And here you have also u r squared. So, to get information from this, it's very important that the zero, that the zero. Parenthesis, the parenthesis here, the factor in the zero term to be non negative, because if it were negative, if it were negative, right, it would go to the right hand side and then you would have controlled u r squared by the grad, u squared on the right hand side. But this is not so interesting, right? Because the radial derivative, ur, is always smaller than the grad, than the grade, the full gradient. So we need, we need really to get information from this.
00:45:50.200 - 00:46:32.094, Speaker A: We need the parenthesis to be non negative. And now, since eta is a power, you check when is this non negative? And one gets that the power, the most negative power is this one, r to the power, two minus n over two. This is the most negative one you want to get. You want to take powers as negative as possible, as you will see in a second. So at the end, this is our test function, c times eta. All right, it makes the first term non negative. In fact, you must throw it pretty much.
00:46:32.094 - 00:46:58.276, Speaker A: And then you have to look at the first and second terms. First and second terms. Well, the first, the square of eta squared, it will bring n minus two times two, two, n minus two. And the term number two, it will have the gradient of d. So n minus two over two over four. And with the correct signs, this is what you get. You make the algebra now.
00:46:58.276 - 00:47:57.500, Speaker A: And funny. Surprisingly well, or not, but surprisingly, say you get n minus two times ten minus n. So this first lemma gives you this estimate on the left hand side, n minus two times ten minus n, but which, by the way, it will give you some information when n is less or equal to nine, right? So that's the point. And this comes, and here with u r squared, the radial derivative squared, and the power of r, which turns out to be two minus n. And then there is an error that goes to the right hand side. That comes from differentiating this function here, the cutoff function, theta, which is a function which is one. But it must die near the boundary because things must be zero.
00:47:57.500 - 00:48:28.414, Speaker A: Psi had to be zero on the boundary. It has to die near the boundary or in an anolus. Here we take it to die that the cutoff on an anolus and therefore the right hand side. The important thing is that the right hand side is concentrated on an anolus. This is a solid integral in all b rho, rho is any radius rho small enough. And here you have the annulus and the same quantity as in the left hand side, but, but with the full gradient squared, unfortunately, instead of u r squared. All right.
00:48:28.414 - 00:48:31.934, Speaker A: And, uh. Okay, this.
00:48:33.074 - 00:48:38.154, Speaker B: We are nearing. We are about 1010 to eleven now. So we have a few more minutes.
00:48:38.194 - 00:48:54.160, Speaker A: Yeah, okay. Okay. Yeah, I thought I had a little more of time, but.
00:48:54.192 - 00:49:01.204, Speaker B: Okay, it's fine. So I think we end officially at eleven. Yes, we have about ten minutes time left.
00:49:01.984 - 00:49:30.384, Speaker A: Just give me some five minutes. All right, thank you. Okay. If in the right hand side we had the radial derivative of u instead of the full gradient, then you can iterate this inequality, right? You can iterate it in anulose like this. And get holder. Well, get decay. Let me say it here.
00:49:30.384 - 00:50:15.330, Speaker A: If we had this, if we had on the right hand side, say we had that the full gradient square with this weight could be controlled, could be controlled by the radial derivative. Then we would have this, look here. And then there is the whole filling technique, which means that once you have this, you can get that the quantity in b rho is the, is controlled by the quantity in B. Two rho with a constant less than one, with a constant less than one. And therefore you, you iterate and you obtain power decay in Rho. In Rho, maybe it's written here. No, in Rho for this quantity.
00:50:15.330 - 00:51:10.994, Speaker A: Note that this quantity is a dimensional, right. The ur square and the x square in terms of scaling or dimensions go away. And then the minus n takes care of the measure. So this quantity is already scales like the l infinity norm, right? So, but it doesn't give you l infinity. But once you prove that this decays in Rho with a small power, you have beat the l infinity scaling and you are right away into colder continuity. And that's very easy without all these just having up here the information, this information here that the radial derivatives. Now here I'm moving the base point.
00:51:10.994 - 00:51:54.462, Speaker A: We did all the previous computations with y equals zero. But now the point is that you can move the center and you have the same information for every y. This information is not enough to guarantee l infinity, even for solutions of semilinear equations. It just brings you to BMO, and this computation that brings this factor n minus two times ten minus n, and that brings you to BMO. I knew how to do this already in 2013 or 14. So. So we were stuck.
00:51:54.462 - 00:52:32.226, Speaker A: I was stuck. And then I spoke with collaborators, in particular, Xavier Rosaton and Jokim Serra, and other people. We discussed the problem, saying, we have this information and something is missing to arrive to l infinity. And we were unsuccessful for many years. And it was when I went to Zurich. Once I told the plan to Alessio for the first time, he got very interested. He didn't know about the plan, got very interested.
00:52:32.226 - 00:53:46.794, Speaker A: We worked for a week, made some progress, but no result. And then, in a second visit, we insisted. And with the help of Xavier and Joaquin, the four of us, after some sessions, we could. We could find the solution. And the solution comes from trying to prove, trying to prove, trying to prove this right, that, well, once you rescale, you rescale this quantity to the unit to unit draw, being the to be one or one half the weight, then, doesn't play any role. And the point is to try to see if this could be true. Can you bound for a stable solution? Can you bound the full gradient in an analysis by the radial derivative? May it be true? The argument came, and I will finish here, came by saying our ideas came and the same.
00:53:46.794 - 00:54:32.174, Speaker A: Our hope came from this observation. If this was false, in the extreme case, we would have the gradient to be one. After a compactness argument, we would have the gradient to be one, say, and u r squared to be zero. If this inequality was not true, say, in the extreme case. But if ur is zero, then u is zero homogeneous. And therefore, you have a zero homogeneous function, which is super harmonic, because minus Laplace is greater or equal than zero on the unit sphere. And this, there is no superharmonic function on the sphere, except for constants.
00:54:32.174 - 00:55:32.016, Speaker A: But then the gradient is not one, so it's a contradiction. And what we are able to do is, the first part of the paper is to prove this inequality under a certain doubling assumption. That is okay, it does not bother the argument. We prove this by compactness, using a higher integrability estimate for the gradient. And so here it's where the other test function comes in. C equals the modulus of the gradient of u brings into the game the curvature of the level sets the full Hessian of the Hessian or part of the Hessian of the solution. Part of the Hessian of the solution, which that we use, I would say in a clever way to, to get an a priori, the declare energy, not.
00:55:32.016 - 00:55:55.904, Speaker A: The declare would be not enough. The gradient of u being in l two plus gamma. And this gamma is what will give compactness in h one. It will be when you have bounded sequences in h one. But you know that the gradient of u in l two plus gamma is bounded. Then you have compounds. And then it's when you, you can make this argument rigorous.
00:55:55.904 - 00:56:22.054, Speaker A: And finish. Finish the interior, the interior estimate. I will finish just saying that the boundary estimate is more involved, but follows the same lines. But it is more involved because this fact here, this fact here is not true anymore on the, on the, on the. Near the, near the boundary. So thanks for your attention. Sorry almut, for the extra time.
00:56:24.674 - 00:56:55.114, Speaker B: Thank you very much, Xavier, for a great talk. I think we have time perhaps for two questions. You can just. Audience, you can just unmute yourself and ask, or if you prefer, you can send a chat and I will call on you. It's just about eleven. Next talk is at 1115 and I'm hearing a very soft. Whoever speaking is very soft.
00:56:55.114 - 00:57:05.634, Speaker B: So, so I'm getting. Go ahead, please.
00:57:06.934 - 00:58:01.082, Speaker A: You mentioned the analogy with minimal surfaces. And the question for stable minimal surfaces, is there something of the, of your results that you can borrow in that case, also of our results that you can borrow in the minimal surface for minimum, to apply it to minimal surfaces, you mean? Yes, I see. Well, not really. It has not been done. We. It has not been done, but it has not been done. The point in minimal surfaces would be to get curvature.
00:58:01.082 - 00:58:26.190, Speaker A: Curvature, curvature. Well, first. And then the energy. The perimeter estimate. Yeah, the perimeter estimate, that would be like at this level, how to get an energy and an energy estimate. So, in minimal surfaces, the difficult point is to get a perimeter estimate. One of the main points is to get a perimeter estimate for a stable surface.
00:58:26.190 - 00:58:46.748, Speaker A: And this is only known, this is only known up to four surfaces in r three. So for two dimensional surfaces, I don't know. Here we proceed in a different way. I'm not sure. There are two more questions.
00:58:46.836 - 00:58:48.156, Speaker B: We have two more questions here.
00:58:48.180 - 00:58:49.264, Speaker A: Yes, in the chat.
00:58:49.724 - 00:58:55.744, Speaker B: So the first one, there's one question that is actually not specified. It says small question.
00:58:56.684 - 00:59:38.070, Speaker A: Yeah, I had a small question, which was, is the gamma in this last inequality improved inequality for the gradients, or say, reverse elder for the gradients? Is the gamma explicit? You said that this is uniform in n. But is it explicit or is it obtained by just to. No, Mateo, this one, this one is completely explicit. I can even in a paper for the pilaplascian, that there is a pilaplascian version of all these results. By now it is written. You will find it there. Thank you.
00:59:38.070 - 00:59:44.910, Speaker A: It's not the optimal one, probably, but it's very simple expression. Yes, thank you.
00:59:45.022 - 00:59:50.046, Speaker B: I cannot resist the last question that's Francesco is asking. What about nonlinear operators?
00:59:50.150 - 01:00:07.746, Speaker C: Okay, maybe let me make it a bit more defined. So, of course, I mean, it's. But for example, so do you anticipate, I don't know, for certain classes of nonlinear operators, like, I don't know, pill applauchants or even measurable coefficients elliptically.
01:00:07.850 - 01:00:08.282, Speaker A: Right.
01:00:08.378 - 01:00:28.434, Speaker C: So that is not a nonlinear operator, but we know what it's useful for. So, do you anticipate a more close interaction between the properties of the operator and the kind of nonlinearity or some other intuition is that it's just elliptic, and then, whatever the non linearity, one should see results.
01:00:30.214 - 01:01:23.230, Speaker A: Okay. No, the things depend on the, on the, on the operator, if the operator is linear. For I have a student, there are some papers, and now I have a student who is doing it much nicer. There are some papers extending the previous results of NetEf, crandal, Rabinowitz, two other linear operators. And now for this recent work, a student of me is doing also more general linear operators. And then the dimension will always be nine and other zero first order coefficients, or zero order should not matter. But then, once you have a nonlinear operator here, yes, the dimensions change, the dimensions change, and it depends on its structure.
01:01:23.230 - 01:02:22.190, Speaker A: For instance, for the p Laplacian, things look similar to this, but the sharp dimension depends on p. It's around 910 eleven, but it depends on p. And if here, for instance, you put the mean curvature for graphs, so, minus divergence of grad u over square root of one plus grad u squared, things become quite different in terms of dimensions. And l infinity estimates are simpler, in fact. So, but there is always. But you can play the same game for many nonlinear operators, I would say. And let me just say here now, that probably one of the main open problems that remain to be understood is that if the non negativeness of f is needed or not in this interior estimate, in the sense we need it, of course.
01:02:22.190 - 01:02:56.828, Speaker A: But in the radial case, the l infinity bound does not require f to be non negative. And my proof up to dimension four, which is another proof, it also does not require the non negative. So this is just an open problem. And for the boundary irregularity, of course, if all this, then the convexity of f mainly is also needed. Or not. This could be a nice result if somebody finds something.
01:02:56.956 - 01:02:58.304, Speaker C: Even for the Laplacian?
01:02:58.804 - 01:03:00.772, Speaker A: Even for the Laplacian. Sure, sure.
01:03:00.948 - 01:03:03.244, Speaker C: Understand. Thank you.
01:03:03.324 - 01:03:07.364, Speaker B: Well, thank you very much for the great talk and interesting discussion.

00:00:03.440 - 00:00:53.844, Speaker A: Hello. Good morning, afternoon, or evening, depending, of course, on where you are. And today, we'll continue talking about phases of sla kappa. So, last time, let me remind you, we stated this theorem that for different values of kappa, sla kappa curve behaves quite differently, namely, when kappa is less or equal than four. It's a simple curve, almost surely, which goes to infinity. When kappa is between four and eight, it's self touching curve, but it's not space filling. So there are blobs like this, and we proved it last time also.
00:00:53.844 - 00:02:05.986, Speaker A: But the union of all the blobs is almost surely the whole complex plane, half plane, rather. And then finally, what we'll prove today is that it is a space filling curve. For Kappa, bigger equals than eight. So, let me remind you, the key point of all our observations here is that was that if we change our map slightly. So instead of usual unripened map gt this hydrodynamic normalization, we consider map ht, which still unwraps, but which maps tip to zero. So it maps tip of the curve to zero, and we need to change time slightly. But after that, we see that our lieutenant revolution becomes nothing else's BISC process with parameters to over Kappa, but this complex starting value.
00:02:05.986 - 00:03:12.374, Speaker A: And that introduces some difficulties. But the main thing which is used in the proof, of course, is this behavior of the corresponding Bessel process for different values of kappa. So today we'll concentrate on this case. What happens when Kappa is bigger equal than n? So, let me remind you that tx and ty are the times for here x and y, when the corresponding Bessel process hit zero. And we know that it's almost surely finite for this regime of Kappa, and for different values, it's different. So it's true, almost surely, that for all different x and y, we have different values of tx and ty. So, let us now go to the proof for Kappa bigger than eight.
00:03:12.374 - 00:04:29.720, Speaker A: And as I remarked, tx less than t, y less than infinity for every y and x. And the same is true by symmetry for negative x and y. So the curve would kind of COVID all the real line. But remember, we want to prove that it's space filling, so we need to show that it will eventually cover every point of the half plane. Okay, so one thing here we can use argument, which is very similar to what we did for the case for Kappa between four and eight, to show that every point will eventually be absorbed by this growing family of health. So that's argument actually exactly the same as what we had here, just using the fact that essentially for the real line, everything is hit infinite time. So it means that sum disk is hit infinite time by scaling.
00:04:29.720 - 00:05:52.406, Speaker A: It means that everything is hit infinite time. So now the question is, why does it always line the curve? Why it's not gets followed like what was happening in the case up between four and eight. And here, for this, we look at the distance from a point to the curve. And let me emphasize that this is exactly the same as the distance from x plus I to the curve run up to the heating time. So we want at this time, the curve to really hit point x plus I to be a distance zero from it. We don't want the situation like we had for kappa between four and eight, where the point could be swallowed. Okay, so we look at this distance and notice that we only look at the distance from points which are lying on this horizontal line.
00:05:52.406 - 00:06:39.274, Speaker A: X plus I y x is real. Why are we doing this? Because we can use scaling. If we prove that delta x is equal to zero for all x almost surely, then by this same, by the scaling argument for every z and h, this distance is zero. So it means that gamma is space filling. Again, every point is swallowed by this growing family of compacts in finite time. And the distance from this point to the corresponding curve is zero, which means that the point is on the curve. Okay, so let's do this.
00:06:39.274 - 00:07:42.332, Speaker A: And for this, we'll need some finer analysis of this curve. So, first, let's remind you, well, what I already said, that we are looking at this re parameterized Leonard family. We now re parameterize it to make it easier to work with Bessel like arguments. And let's represent ht as xt plus iyt. So, real part of this map would be x t, imaginary part would be iyt. Xt is real, part of h, y, t is imaginary part of h. And now, again, probably the standard argument for you by now is that we introduce in u time, which we call sigma of t, which would be defined by this condition.
00:07:42.332 - 00:08:45.214, Speaker A: So, sigma of t is the time when this integral is equal to t integral of one over x squared plus y squared. This is the same as integral of h t squared. Of course, h s rather squared, absolute value of h squared. Okay, so now assume that for sum x, this positive probability we have this delta of x is not equal to zero. Now, okay, so I don't know why I wrote this. This we already know did not happen. Okay, by Kerber theorem, distance from a point z to gamma of zero t is the following.
00:08:45.214 - 00:09:53.698, Speaker A: Let's look at the picture. So we have our curve, we have our point z. Then we mapped it by h here. So this is h t of zero. And now bicycle distance here is comparable to the distance from here to the boundary. Okay, so again, one thing. Of course, that distance from z to the boundary of the domain omega t could be the distance to the boundary here.
00:09:53.698 - 00:11:07.074, Speaker A: But of course, let us, we know that eventually z would be swallowed. So at some time, t this distance would indeed become distance just to the curve. And now, again, if you just look at the cube, this distance is just this divided by imaginary part of ht. Okay, so let's define Dx now to be the limit when t goes to infinity. Again for the computations, it would be. Okay, what have I wrote here? I see that this actually doesn't quite make sense. So this is imaginary part of ht of z divided by ht prime of z.
00:11:07.074 - 00:12:26.794, Speaker A: Yes. So now this makes sense. So let me again write it down correctly. So dt of z I define to be logarithm of ht prime of z divided by imaginary part of ht of z. And then, so what, what does ht does? So remember, remember that it maps this disk to a disk approximately size ht prime multiplied by the size of this disk. Again, this is very non rigorous, but by Kirby theorem and Schwarz theorem, it's actually true up to constants one on one side and one quarter on the other side. So the image of this covers disk of the size absolute value of h t over four multiplied by the radius of this disk.
00:12:26.794 - 00:13:15.754, Speaker A: But it cannot be more than ht prime multiplied by the radius of the disk by Schwarz lemma. And so now with this in mind, of course, now this is correct. So, distance is imaginary power divided by hd prime. Sorry for initial mishap. And so dt of z, again, for computations, I would consider logarithm of one of this, and dt of z would be this. Now, I define d of x. Remember, I only look at the point x plus I as the limit of this guy, as t goes, sorry, to tz t.
00:13:15.754 - 00:14:36.220, Speaker A: And then what this observation said is that delta x is exponent of minus dx. So we have to show that dx is almost solid. So let me write it down. Dx equal to infinity. Okay, so now let's rewrite our times. So let's notice that from l equation, we simply get the dt of log h t prime satisfies two over kappa y t squared minus x t squared x t squared plus yt squared squared. It's really easy to again see from leo's equation, if you want to do dt of log yt that we actually already did when we proved that Jovener sle generates a curve.
00:14:36.220 - 00:15:30.844, Speaker A: So we had exactly this formula. So after we plug this in, we have that dt of d. T is, well, it's the difference of these two guys. So it's for over kappa y t squared x t squared plus yt squared squared. And so this thing d of x is simply this integral. Well, again, strictly speaking, not to infinity but up to heating time, but will change time anyway. So let me just leave this infinity here.
00:15:30.844 - 00:16:24.114, Speaker A: And again, dt is just the integral up to time t of the derivative. Okay, now let us change time to the sigma of t. Okay, so y t tilde would be by definition y of sigma of t x t tilde x of sigma of t, the same with dt tilde. But of course dx is the same as dt tilde x. Nothing changes now because, well, it's still essentially logarithm distance. Now let's consider the ratio. Mt tilde would be x tilde over yt tilde and t tilde would be logarithm of mt tilde.
00:16:24.114 - 00:17:36.542, Speaker A: Ok, so we'll look at the ratio of x to y and c t would be logarithm of this ratio. Okay, so, okay, why am I writing this again? Okay then by ether we can again rewrite m t tilde. So this is four over kappa mt tilde dt plus square root of m t tilde squared plus one dbt tilde. Let's take logarithm of this. So it's this divided by mt tilde. And so you just get that this is four over kappa minus one half, minus one half e to the minus two c tilde. Again, why we have such nice terms here? Because what is, for example, e to the two c tilde? Well this is m t tilde squared.
00:17:36.542 - 00:18:42.254, Speaker A: This is x squared over y squared. And so, well again, this is, this now just follows from all those derivatives. And here this term becomes this because again we divide by m t tilde. Okay, so now we can rewrite that. This whole procedure was to rewrite, of course this so differential of this would simply be four over kappa y t squared of x squared y t squared dt, which is again, let's remember that this is just for kappa one divided by one plus e to the two cc delta dt. Now let's remember that at time zero, the very distance one, so logarithm of all these guys would be zero. So d zero x is zero.
00:18:42.254 - 00:19:26.044, Speaker A: So d tilde x. Now we integrate to infinity, because in due time we have to integrate to infinity. We already discussed it actually when we proved that it's a curve that in this same new time we have to integrate to infinity. This is just four over kappa integral from zero to infinity, ds over this. So we are just integrating this guy. Okay, now let us notice that. And here we finally have to use the fact that kappa is bigger equal than eight, that this is strictly less than zero.
00:19:26.044 - 00:20:31.436, Speaker A: It can approach zero arbitrary close if the city tilde is large, meaning that this guy would be small. Ok, so the thing again is not negative, is not positive rather. So let's look at this guy. This is a weighted brownian motion with negative drift. So what does it mean? That's one of the properties of the brownian motion that if you pick any time, then you can find time after that where this guy would become negative. Eventually it will go to infinity, to minus infinity because of this negative drift. But what I am saying is slightly less.
00:20:31.436 - 00:21:24.314, Speaker A: It would become negative for some interval from t to t plus one. Essentially because it was negative, it would vary. This drift would suddenly become minus one, two, and it would take time for it to recover. So this is again just one of the properties of brownian motionless drift. And so you look at it and you say, okay, so here we integrate this guy and there are infinitely many intervals where this is non negative, not positive. Why am I going not negative? So what you divide by is no more than two. So this guy is bigger, equal than one half.
00:21:24.314 - 00:22:11.196, Speaker A: So this means that this integral is infinite. So this integral is actually infinite. And that's exactly, exactly what we wanted, right? Remember, we wanted to show the d of x is equal to infinity after we change time. You know, this d of x and d tilde of x is the same. So in this new change time, this d of x is infinite. And that's exactly what we want. So again, what was used here? Lots of, of course, eta calculus.
00:22:11.196 - 00:23:01.784, Speaker A: Lots of calculations using eta calculus and some properties of drifted brownian motion. Essentially, if you don't want to think about drifted brownian motion, think about just brownian motion, which, as you know, goes to plus minus infinity. So everything is cool. But it goes there slowly, slow than square root of t. And now when you introduce, when you subtract t from it, it of course, very rapidly grows to minus, goes to minus infinity more than that. So that's what happens. Why, for example, I could say this, you see, our process is measurated by brownian motion.
00:23:01.784 - 00:23:59.942, Speaker A: It has negative drift. So at some time indeed, it would become negative, because brownian motion, after every time it has to become negative, it cannot stay positive, it becomes negative. But then this positive probability, after that it would stay. Since the drift now became negative one half it would stay negative, and the whole process will stay negative for quite some time, for the interval of length one or interval of any fixed length. So that's the argument. Okay, so now, next part I was very hesitant to discuss, but because, well, it becomes even more technical than what we just did. But as you will see in a moment, the consequences are so interesting.
00:23:59.942 - 00:25:15.126, Speaker A: Basically, we'll be able to feel the dimension of brownian motion that I thought that this computation, well, it's important to see. Plus, it will use some technique from some probabilistic technique, which originated actually in physics, the famous Feynman Katz formula. Okay, so this starts with remark, okay, what happens when kappa is less than eight? So now I know that for copper, big or equal, the distance to the curve is zero d of x. Remember, it's essentially logarithm of the distance minus, well, logarithm of one over distance. So I want to study the distribution of this d of x. And turns out that exactly the same things, which I already did, allows us to compute the moments of this exciting function. So namely.
00:25:15.126 - 00:25:59.374, Speaker A: Well, that's the formula. So there is gamma function involved here, and there is hypergyometric function here. Remember it just the sum of the corresponding things and corresponding powers. I don't want to reproduce the definition here. You will see it in the profile. And again, we will need this, admittedly not the easiest looking formal to compute the dimension of oscillocouple curves. So, let's just do this.
00:25:59.374 - 00:27:03.804, Speaker A: Okay, so here I said that it's exactly the same argument. Well, it's not quite, because we need yet another time now, because now we, we hope that this d would be finite. Well, we already know that most of the time it will be fine from the description of the curve, but we'll need to introduce new time to study it. And the new time is the following. So this time is called sigma t hat. It satisfies this property, that derivative of sigma t hat with respect to t is one over m t Tilde. Well, let me remind you that it's just yt tilde squared over x t tilde squared plus y t tilde squared.
00:27:03.804 - 00:28:01.174, Speaker A: Ok, this is the you take argument of h t tldeso time changed. You take sine of it yt over square root of x squared plus yt square root. And you take a square root of it. So this is sine of the argument, and this is what we actually will spread. And so the claim is that now, this thing which we discussed mt, which is, you remember, was xt over yt, this thing would suddenly become just brownian motion in this new time. We didn't need it there for the case, kappa b gray for the night. But let's look at it here.
00:28:01.174 - 00:28:19.194, Speaker A: Okay. So again, this is just iter calculation. Well, sorry, sorry, sorry. It would not be common because. Right. What the only thing which we. Sorry, browning.
00:28:19.194 - 00:28:59.988, Speaker A: When we look at the equation for mt tilde, this is the one. And this exactly makes it to a brownian motion in the new variable. So that's why we introduce this new variable. Sorry. The non drift term would be just dbt hat, where bthat is brownian motion in this new variable. And this would be non drift term. So again, you just look at this equation, you gain something here, you lose something here.
00:28:59.988 - 00:29:32.764, Speaker A: So non drift part became brownian motion. Drift part became something more complicated. And let's now remember what it is. So this is forward kappa xt hat yt hat xt hat squared plus yt squared. Dt plus the brownian drift. And now let's see what this is. So, okay, let me write it down.
00:29:32.764 - 00:30:44.684, Speaker A: So, xth over square root of xthat plus ythat. This is by definition coincidence of argument of h t y t hat. Well, again, by hat, with the node, the time change thing. So this is again sign of argument of hd head. So what is written here, it's just cosine multiplied by sine. So it's sign of twice the argument of ht hat plus brownian motion. So it's brownian motion with this drift, why sign the argument? And so now let us remember the formula for d that would become integral from zero to infinity.
00:30:44.684 - 00:31:29.442, Speaker A: Again, all these times are now running to infinity. Dt over one over mth squared. Squared dt. Again, we know this just for example, from this formula. And we do one more change of variables here and now. So we need to study this, given that this is given by this stochastic differential equation. And here we need help from two physicists who invented a Feynman Katz formula.
00:31:29.442 - 00:32:15.684, Speaker A: There are many versions of Feynman Katz formula used in probability elsewhere. We will use the following version. So, let we have yt, which satisfies stochastic differential equation dyt is f of yt dt plus dbt, and start at y. Suppose that v is continuous. Suppose that yt tends to infinity almost surely. And suppose that v on phi t. On the other hand, when you integrate it, it's bounded.
00:32:15.684 - 00:33:31.894, Speaker A: And now suppose that psi is a solution of this differential equation. Okay, so m should be f, sorry. So it's solution of this differential equation, which tends to one when y tends to infinity. Then suppose that you want to compute moments of v of y t. So you want to integrate v at random points. Okay, that actually looks like this thing. So you want to integrate this from zero to infinity, and then this psi of phi is the solution.
00:33:31.894 - 00:35:07.734, Speaker A: Okay, looks awkward, but it gives a precise value of this integral. So, okay, so if you want to compute this integral. And again, that's why I wanted this to be bounded, because otherwise this thing would blow up. But if it doesn't, and I want to compute the moments of this, all I want to do, I want to solve this OD and find the solution which tends to one at infinity. Okay? So as usual, when you have so many conditions, the formula, the proof is not too complicated, because what we do, we just use it a calculus to show that if you look at this guy, psi of it, exponent of I, zero to t, v of y as ds. So we just look at this guy and we just notice that first of all, again, by Eta calculation, which I mean this is a local martingale, but it's also bounded martingale, because this is finite, this tends to one. So this is bounded.
00:35:07.734 - 00:35:45.314, Speaker A: So bounded times finite. Well, this is a bounded martingale, bounded for every t. So it's, sorry, not for every t, it's bounded for every omega, for every moment. So it just bounded Martingale. So, well, again, it's bound at local Martingale, bounded local martingales are by definition martingale. And so this equation actually is exactly the equation for drift term to be zero. So that's why we needed it.
00:35:45.314 - 00:36:29.514, Speaker A: Again, I don't want to do it, but you can in your spare time, just try to do it and you'll see the drift term would exactly die if you have solution to this. Now, let's take it at time zero. This is m zero. This is the psi of phi, right? Because y of zero is y, this thing is just zero. Well, that's just one exponent of zero. But by Martingale convergence theorem, this is expectation of the limit of mts when t goes to infinity. Remember, it's true for even for l one martingales here.
00:36:29.514 - 00:37:13.224, Speaker A: Well, for l one, uniformly integrable martingales. But here we have more. We have bounded, uniformly bounded. So this is expectation of what so let's say psi of yt tends to y t when t goes to infinity. Remember, it tends to infinity. So this thing, psi of it would tend to one. So this term, just one, and this term would become integral from zero to infinity, v of it dt.
00:37:13.224 - 00:38:30.104, Speaker A: Okay, so again, this is, the key word here is that this is uniformly bounded local Martin galaxy, uniformly bounded by, essentially the bound on this, because this is real, this is I. So this is just one by absent. But again, so that's, here we use the fact that this converges and it converges to this. Okay, so this is in one of the versions of Feynman cards. You essentially reduce computations for sd to the solving od. And let me demonstrate how to use it here in the computation of moments of D. So, we just look at the solution to this equation, which is bounded and which tends to one at infinity.
00:38:30.104 - 00:39:48.994, Speaker A: And let's pick c such that c x naught over y zero is equal to b. Okay, so this is very unfortunate notation, because yt was already used here. So let me denote it by something else. Let me, okay, so here I use it, let me call it little white. And this function v here. Okay, so if we just solve this equation and do this discussion, voila, will get exactly this solution. So, because again, our process, so we have our, so we know that this is finite, and so we can apply all these techniques here.
00:39:48.994 - 00:40:48.124, Speaker A: And the sum t. Again, we look at the equation, which is, which it satisfies here. So this would be our function f. So the function is exactly y one plus y squared. Make it slightly more palatable. Okay, so this was a long computation, but again, I skipped most of the details. I wanted just to show you that when you are facing with something like this, you can always use Feynman cuts.
00:40:48.124 - 00:41:49.674, Speaker A: And now I want to talk about dimension of sle Kappa curves. So this was actually quite a big deal when it appeared. Well, the next area by Vincent Bifara, which stated that Hausdorff dimension of slic apoc orifice, one plus kappa over eight, at least for kappa, less or equal than eight. And then it's obviously two. For Kappa, bigger equals an eight, because it's space filling. So, let me remind you what Hausdorff dimension is. By definition, Hausdorff dimension is the, you cover your set by balls of radius delta j, and you look for alphas for which the sum can be made as small as possible.
00:41:49.674 - 00:42:40.064, Speaker A: So when alpha is small, of course, it's impossible when alpha is big. So, for example, bigger than two, it's always the case because you can always covered by the sum with finite delta j squared. So each set has finite area. And now when alpha is bigger than two, this extra factors can be made small and small, so it can be made less than epsilon. But now for a set, you look at infinum of all such alpha. So there is a rich theory behind it. And it's beautiful theory, but I don't want to discuss it here.
00:42:40.064 - 00:43:33.594, Speaker A: Just wanted to give you the definition. So this is an optimal exponent. So below it, actually every covering, if you make it small enough, would have some tending to infinity if you make delta J small enough. So when size of delta J small enough and you are less than house of dimension, the sums would become, would be tending to infinity, even the infinite mobile sums. Okay, and so Vincent befar proved that all almost surely the housed earth dimension is one plus kappa weight. What I will prove here is not the full theorem, this is too complicated. I will prove an easier statement.
00:43:33.594 - 00:44:34.842, Speaker A: Basically, I want to convince you that Hausorf dimension is no bigger than this, than one plus couple weight. And this was actually done by rod and sham. The great achievement of Vincent was that he managed to establish the lower bound. So in house door dimension business, actually, upper bounds are usually easy, well, easy, you need to take it with a grain of salt here. But lower bounds is what makes it complicated. And he discovered some new martingale related to two point martingale related to sla kappa, which again is beyond the scope of this course. Okay, so as I said, we are going to prove an upper bound and let set things up.
00:44:34.842 - 00:45:28.354, Speaker A: So we'll prove actually a bit more. So the upper bound would be an upper bound, not on Hausdorff dimension, but on an object which is usually bigger than Hausdorff dimension. And it's called Minkowski dimension. So for this, let us take set k, which we presume is compact, and n of Delta K would be the minimum number of disks of fixed radius delta, which you need to cover this. So for a square, for example, this n of Delta K is one over delta squared. For middle third counter set, it's one over delta to the power log two over log three. Well, that needs to be proven, but that's the thing.
00:45:28.354 - 00:46:15.920, Speaker A: So Minkowski dimension is usually easier to estimate than Hausdorff, but it has its own problems. And then, so what is the Minkowski dimension? The upper Minkowski dimension is upper limit lim sub of logarithm of this divided by log one over delta. So you take the number of balls, you look how it scales and you look at the upper scale and low box or low Minkowski dimension is the Lyman. And when they're equal, it's called Minkowski dimension. But for general sets, of course, they are not equal. And let us just observe that. Well, of course, by definition this is higher than this.
00:46:15.920 - 00:47:14.930, Speaker A: But I want to say that Hausdorff dimension is even smaller. Indeed, if alpha is bigger than low Minkowski dimension, then what do you know? That there is a sequence of delta j which tends to zero, such that n of delta jk is less than one over delta j to the alpha minus epsilon. Right? So look at the definition. Okay, then it means that sum of delta j to the alpha. Well, let's forgot to write some. So this is sum. Ah, sorry, there is no sum here because we just take the number of them.
00:47:14.930 - 00:47:41.654, Speaker A: So the number of them is delta j to the alpha minus epsilon. So this is delta j to the minus alpha plus epsilon multiplied by delta j to the alpha. This cancels with this. So it's delta j to the epsilon tends to zero as delta j tends to zero. Okay, so alpha is bigger equals in house or dimension. Remember, household dimension is infinite of such alpha. And for this alpha we were able to find coverings by the disks of the same radius.
00:47:41.654 - 00:48:21.754, Speaker A: So again, the risk of stating obvious for Hausdorff dimension there covering by sets of different radius. And that's what makes us powerful. For Milkowski dimension, we consider covering by sets of the same radius. And that's actually what makes it easy to compute, but sometimes not very acceptable. For example, Minkowski dimension of the set of all rational numbers is one, which is not what we want. It's countable set. Okay, now look at yet another upper bound.
00:48:21.754 - 00:49:04.194, Speaker A: Suppose that you have a random set. And suppose that you know that lim soup of expected value of such balls divided by log of one over delta is bounded by alpha. I claim that upper Minkowski dimensions less or equal than alpha. So eventually that's what we will compute. So actually for a random set, SLE curve will show that this is less or equal than one plus couple weight. So we are giving a bound. An upper bound would be not just in Hawthorne dimension, but something potentially much bigger.
00:49:04.194 - 00:50:35.748, Speaker A: And before ethereum shows that for sle curve, all of these are equal. Okay, so let us at least start the proof of it of this very easy upper bound first. So we want to show that if this limb soup of expected value of the number of balls divided by log one over delta is less or equal than alpha, then Milkowski dimension is also less equal than alpha. For this we take alpha one and alpha two, which are bigger than alpha. Then for small delta, expected value of this number of balls is bounded by delta to the alpha two. And there is a minus sign here, which I am missing. Okay, so, probability that this number is bigger than delta to the now minus alpha one, it's bounded by delta to the power alpha one expected number of these guys.
00:50:35.748 - 00:51:07.434, Speaker A: Right? So this is just inequality. Probability that you are bigger than something is bounded by expected value divided by the something. And so this is delta to the alpha one minus alpha two. Now, let us take delta n equal to two to the minus n. And actually, let us take this delta n after a short break. So, let us take a nine minute break, and I'll see you at eleven taranta time.

00:00:03.160 - 00:01:02.600, Speaker A: Okay, thank you, Sumitra. Again, let's continue. And today we start with another series of examples still in the complex plane, mostly on the open unit disk, which are important for our course and also for the focus program. If you have looked at the first few weeks, we talked about earlier spaces, Dirichlet, Bergmann, and all of them are examples of rkhs. And there are more model spaces which Bill Ross will talk about them, Dobranch, Rovniac spaces, and I mean, there are many examples. All of them live on the open unit disk. We start with, even though I don't know if everybody has participated in the first speaker, I believe the students from Laval who participate in this course, they did not.
00:01:02.600 - 00:02:22.054, Speaker A: So I need to repeat, and I apologize for those who have already seen this. So we start with Hardy space age two, which is the most classical one, is the mother of all other examples of the open unit disc that we know. In the lectures I gave in July mentioned, there are at least four methods to define h two for equivalent, and each way has its own merits. And when we generalize those definitions, we obtain different spaces. I mentioned just one of them here, which help us very rapidly to show that h two, or more precisely, h two of d, is an rkhs. Here is the definition. So h two is defined to be the space of function f with the power series expansion a nz ten such that a n is in little l two, or the sum from n zero to infinity.
00:02:22.054 - 00:03:27.994, Speaker A: Absolute value of n squared is less than infinity. So this power series with a restriction on the coefficients. The restriction is easy to to see that it implies f is analytic on the open unit disk, and I show more than that. I show evaluation or continuous. But before that I need to say what is the inner product? The inner product on h two is a copy of inner product in Lidl l two. More explicitly, this means that we define distribution sum from zero to infinity anbn bar, where a n are the coefficients of f written and bn are the coefficients of g. And I repeat here, f is sum of a n z and g is sum of Bnz.
00:03:27.994 - 00:04:15.798, Speaker A: It's very easy to to show that it's an inner product and it's complete, because little l two is complete. So we have a Hilbert space. So that that's a Hilbert space is an easy exercise. Make sure that h two is Hilbert space. That part is elementary. Also, it's an rkhs. It means that the evaluation functionals are continuous, and to do so, look at absolute value.
00:04:15.798 - 00:05:26.544, Speaker A: F of z is absolute value of anzn absolute value inside. And then, oh not, not a square yet. And then we do the Cauchy Schwarz is less than or equal to the sum n equal to zero infinity a n squared, one over n z n squared, one over two. I make too many mistakes, which I mean as indication that I'm tired now, I try to be more focused. So what is the first sum absolute value of a n squared then root square, it's the same thing here, f equal to g. So it's the normal f. So this is equal to the normal f in h two.
00:05:26.544 - 00:06:47.166, Speaker A: And the other one is absolute value of z, exponent two n. So it's one over one minus r r here is mod z squared, and then there is a root square for everything. So root square. So this shows that the evaluation function at point z in the disk is bounded, and moreover an upper bound for that, and moreover norm of z as a functional from h two to c is bounded by one over one minus z squared. We have done this for all previous spaces. And to verify if this is an optimal estimation, as we saw before in five examples, the only way is to find the kernel. So what is the kernel here? The property of the kernel is this.
00:06:47.166 - 00:08:01.624, Speaker A: If you do the inner product of f and k z, you should obtain the value of f at point z. True. And now we use the, the formula that we had here at the very beginning. This one f of z at the point z is given by a Taylor series. So on one hand, we know that f of z is given by some a n zn. On the other hand, the question is this, if k of z is also k of z, ah, z will be mixed. We had this, this problem before.
00:08:01.624 - 00:08:53.384, Speaker A: Let me write k at the point w for not mixing z with w. This is also given by the formula bnw. And the question is, what are the wn? What are the Bm? We have to find them such that. No, I don't like the way it's written here. Let me change it this way I change this to vw and here. Now it's good. Now kw at point z.
00:08:53.384 - 00:09:39.600, Speaker A: No, this is good. Now I mean, I like this better. Kw has this representation, f has the other representation. And so if I want to use the formula for the inner product k, the inner product f and k w, based on this, is the sum n from zero to infinity anbn bar. That's good. That's one formula. But on the other hand, I also know that also I write this formula in terms of w two.
00:09:39.600 - 00:10:59.316, Speaker A: Also, f at the point w is the sum n from zero to infinity a n w exponent. It's the same formula as here, but I replace that by w. And what I want, what I want is this part to be equal to this part. Therefore, the only choice, the bm bar should be equal to the wbn, is w bar exponent n. And now I go back to the formula for kw. At point z is the sum n from zero to infinity bm times zn. Bm is w bar n, if I put them together, is w bar z exponent n, and it's one over one minus w bar z.
00:10:59.316 - 00:11:52.500, Speaker A: It's a very celebrated kernel here. Z and w are indeed, some people call it Cauchy kernel, some people ziggle kernel, and even some Cauchy Ziggler kernel. I mean, depends which book you use. In the book, which is our reference, Paulson and Ragopati book, they call it Zigo kernel. But in many other places you see Koshikernel. Anyhow, it's a kernel for the h two space. And in particular, you see that k z is one over one minus mod z squared.
00:11:52.500 - 00:12:20.992, Speaker A: And so norm of e z, which is the root square of this, is one over root of one minus mod z squared. Go back to the estimation we had. Here it is. It's a very precise estimation. It's a very good morning. Cannot do better than that. Equality holds.
00:12:20.992 - 00:13:00.394, Speaker A: And remember the previous examples. We had four examples in the Sobelov case and one in the pale levina. In just one of them, either Subalov two or Sobolov three, the estimation was good. In all other cases, we were away from optimality. And here is another example for which we have an optimal estimation. In a sense, the calculation, we did a very good calculation. So this is just, I mean, even, even if I say tip of the iceberg, I have not done the justice.
00:13:00.394 - 00:13:56.874, Speaker A: Hardy spaces is a very rich subject, started more than 100 years ago in 1914 by Hardy, and it's well developed. Many, many, many theorems on this. Just one page about it is, as I said, it's not even tip of the iceberg. We will come back to this space many times in future, and also two subspaces of it. In particular, model and branch spaces. I just make some comments about this. We saw before, after we finished several of the spaces that if you have a reproducing colonel Hilbert space and m is a subspace such that m is closed in h.
00:13:56.874 - 00:15:07.264, Speaker A: So this is an Rkhs with kernel k, call it x. To distinguish, I put h here. If m is closing h then m by itself becomes rkhs, and therefore it has a kernel for itself, kmx. And we explored the relation between this kernel and this kernel, the orthogonal projection of h onto m. If we use this, the theorem we had, the theorem said that k, the kernel for m, is the projection of the kernel for h. And even in the Soborov case, I invited you to verify this, even though we obtained it explicitly. Now we want to practice this in the context of hardy spaces.
00:15:07.264 - 00:16:25.884, Speaker A: We know our h is h two, and so what is our m to do this? Here is a definition. Definition a function theta from this to c is called in n. If two properties f is bounded, the theta is bounded. In technical language, the right theta is in h infinity. But I mean it means it's bounded. And when it's bounded, we know that the radial limits, when we go to what the boundary exists, we assume that theta zeta, which is lean r goes to one theta r zeta is unimodular, almost unimodular means absolute value of theta is equal to one. Such a function is called an inner function.
00:16:25.884 - 00:17:08.854, Speaker A: Well, that's my difficulty here. For those who are familiar with the subject, this is a piece of bread. For them it's very easy. And for those who don't know the subject, just giving this definition, it gives no clue what we are talking about. But at least let me give an example, maybe the simplest one, an email function. The simplest one is theta z is equal to z or z square or z q. These functions, as you see all of them are bounded on the disk.
00:17:08.854 - 00:18:05.066, Speaker A: And when we go to the boundary zeta or zeta squared or zeta q, they are unimodular. So these are inner functions. Another example for this function, the zero is at the origin, theta of zero is equal to zero. But if a is a fixed point of the disk, then theta z is equal to a minus c, one minus a bar z. That's another function which I leave as an exercise for the students to show that it's an inner function, even exponent of this, I mean either this or like z cube and exponent of this are good too. It's a function which is unimodular on the boundary bounded. So it's an inner function.
00:18:05.066 - 00:18:48.272, Speaker A: So having inner function, we can multiply them together and obtain other inner functions. So it gives opportunities to build more and more up to here it's really elementary, even though it might. But it might be strange for you at the beginning of theory. But if you want to go beyond that and recognize the family of inner functions, then you need more tools. The first is the theory of products, how to product infinitely many of them together and still obtain a function. And the second is how to use singular measure to create. And it's another category.
00:18:48.272 - 00:19:26.642, Speaker A: There is a theorem which is called the canonical factorization theorem which gives us all the inner functions. I don't mention. Write the theorem here. For the time being, I don't need that because our goal is to study the abstract theory of Rkhs. But from abstract point of view, just stick into these two definitions, these two conditions. On the definitions, theta is bounded unimodulate on the boundary. Now I can tell you what is our m.
00:19:26.642 - 00:20:14.404, Speaker A: We consider two families of m. The first family m is equal to theta times h two. These are called Berlin subspaces of burning subspaces of h two and show, I mean, it's based on this unimodular property. It is easy to show that they are closed. That's the easy part. Therefore it is an Rkhs by itself. Question for you find k.
00:20:14.404 - 00:21:22.104, Speaker A: What is the kernel for bearing subspaces of h two? This formula in a sense can help you. I mean, you can find the projection and then project the Koshijigo kernel and find the kernel you are looking for. Direct verification also is possible. I mean, you guess a formula and directly verify that second category is the complement of this space. We know that if a space, if a subspace is given either closed or not, its orthogonal complement is for sure a closed subspace. So the second category is theta h two, but the orthogonal complement. And to emphasize that the orthogonal complement is taken in h two, it is better to write it as h two minus theta h two.
00:21:22.104 - 00:22:18.204, Speaker A: And for these spaces there is a special notation so they don't mix with the k we had about k theta. They denote these spaces by k theta. K is not for kernel here. I mean, I don't know where it comes from, but they are called model subspaces of h two. Let me look at the program model subspaces. Ah, model subspaces was a part of our program, but it was on week four. By Stephan Garcia July 2728 29.
00:22:18.204 - 00:23:05.912, Speaker A: The videos are available on the website of Fields Institute. If you want to have a look at what this means. I said, bill, I made a mistake. Lectures by Stefan Raman Garcia so these are also close up spaces of h two. So they have a kernel. And the same question as about find the kernel for these spaces. And this time, even though I can write here k k theta here, this is a bit too much.
00:23:05.912 - 00:24:31.398, Speaker A: K z k theta up there usually to distinguish, they write k z theta to say that this is the kernel for the model space. In particular, try to find this one, which is important, and I will talk, not today, I mean near future, about the generalization of this, which will include this part as a special case. When we talk about hb spaces, the branch Rodnyaki spaces. In the previous case, K theta is a closed subspaces of h two. So we know in advance, without any verification, since it is closed, it is an rkhs, but there are some space subspaces like HP, which are not closed in h two. But still we can define a kernel and on these spaces the kernel is such that it is complete and it gives us an rths. When is this? Week eight.
00:24:31.398 - 00:25:47.264, Speaker A: Week eight means October 5, October 6 and October 7. It's on Dobranch Govnyaki spaces lectures will be given by Dan Timothy. You can listen and learn about these spaces. We want another point which is interesting for us as, as a course on Rkhs, is that in all previous examples, all five seats that we have seen up to now, even on these two, which I gave as an example and asked you to explore, we have an explicit formula for the inner product, which means an explicit formula for the norm, and also an explicit formula we obtained for the kernel. So two things, two important piece of information. Formula for norm, formula for the kernel we will see later when we talk about HP spaces. In this case, it's rather surprising to see that we have an explicit formula for the kernel, but we do not have, say, a good formula for the norm.
00:25:47.264 - 00:26:16.174, Speaker A: So 50% of the information is missing. I don't say that we do not define the norm. Yeah, we will, we'll give a, even a method to calculate the norm, but we do not have an explicit. The word explicit is important. We don't, we don't have an explicit. This is formula for the norm like the previous one. In all previous cases, all the time either.
00:26:16.174 - 00:26:47.706, Speaker A: We had a formula based on the, I mean an integral formula, the one we just saw, the one we just show. Here it is. Yeah. By this I mean an explicit formula. I have an explicit formula for the calculation of the inner product. And if f is equal to g, I have an explicit formula for the calculation of the norm. It becomes, it becomes something like this.
00:26:47.706 - 00:27:32.574, Speaker A: I know how to do it. Previous examples like that, even this, and this is like that. In HB spaces, we will see that we do not have a formula as explicit as we wish for the norm. That's one category of examples, another category is about local derish bases and weighted deerishly spaces. I will talk about deerishly spaces in a few minutes. But the classical one there are generalized versions, and it's interesting to know that the other 50% is missing. For them, it means that they are rkhs.
00:27:32.574 - 00:28:11.092, Speaker A: We know that evaluation functions are continuous. We have an explicit formula for the norm. We do not have a formula for the kernel. It's an interesting phenomenon. So not all the time. We have all the information in some spaces of information. Is music good? So this, when I finish here, just, I mean two, three pages about hardy spaces and some subspaces of it.
00:28:11.092 - 00:29:18.834, Speaker A: The subject which is more than 100 years old. And we move to the next one, which is diraclet space d. Recall the definition of f. We put a restriction on the coefficient here is the same, and in the Bergman space is also the same. But we add a weight if f is given by formula a and z, and dariusly is the collection of function f such that n from zero to infinity, either n or n plus one, it really doesn't matter. A n squared is finite. So here we have a weight here, and this makes the whole theory different.
00:29:18.834 - 00:30:10.424, Speaker A: You remember the first week I said that from a structural point of view, we have just one separable Hilbert space. So if you just look at these guys as Hilbert spaces, there is no difference between h, 2d, hb, or even model spaces. All of them are the same. But there are other features which make them different, and the kernels are one of them. So first, to show that this is a Hilbert space standard, I leave it to you. It's not something difficult to show that I didn't mention the inner product. The inner product if.
00:30:10.424 - 00:31:24.036, Speaker A: Oh my goodness, not again. Okay, good. If f is given by some a, n, zn and g by some Bnz. This is an indication of how we should define the inner product in t. We should define it such that if f is equal to g, we obtain this combination, which is the norm. So it's defined by n plus one anbn bar. And as you see, if f is equal to g, we obtain the same combination as above.
00:31:24.036 - 00:32:39.898, Speaker A: So in other words, the norm of f in the dirtless space norm squared is a n squared. So that it's a Hilbert space is straightforward. But y functional evaluation functional are continuous. Y e at point z is bounded. We start with f as before, we take the absolute value inside. If we apply Cauchy shorts here, it's not good because we end up with the combination we had in the hardest base saving, we obtained sum of mod a n squared and times sum of mod zn two n squared. You don't want mod a n squared, one n plus one times this.
00:32:39.898 - 00:34:01.172, Speaker A: To obtain this, I do this trick. I add here n plus one root squared an, and I have to divide by that too. And now, now I apply Cauchy Schwartz with these as say my xn, this as my yn. So it's less than or equal xn squared sum. Then root square times sum of y n squared two n n plus one two. And as you see, n from zero to infinity. This is precisely what we called normal f.
00:34:01.172 - 00:34:58.454, Speaker A: At point d times this. You can keep it as it is. It really doesn't matter what function is, it's a function of z. But if you are familiar with the development of log like of one plus t in the calculus one or analysis one, this is one. The whole thing here is one over mods z squared, log of one over one minus z squared, the whole thing squared. But this is not really important. We can write it as a constant which depends on z fd and so f of z is less than.
00:34:58.454 - 00:35:55.282, Speaker A: This implies that ez is bounded. And I mean again an estimation for for its norm. Last step is to to find our kernel and we do calculations similar to this one, similar to here it is similar to this one. We know the development of f. We assume the development of kw. We do the inner product and we explore what the n should be. So similar calculation we need to find kz.
00:35:55.282 - 00:36:35.778, Speaker A: But in d. Well f of z is the sum n from zero to infinity a nz k z. Did I write kz? Ok, I think I wrote kw up there. Not to mistake. I think it was kw. Yes, kw of z. Kw of z is sum n from zero to infinity bn zn bn we need to find it.
00:36:35.778 - 00:37:32.766, Speaker A: We don't know what it is. The inner product of f and k w in d by definition is the sum from zero to infinity n plus one anbn bar that's the definition of which I write it as sum from zero to infinity. A n times n plus one with p and bar. This is one thing, the other thing, the same formula is here. I write it with z replaced by w. F of w is also sum from zero to infinity am times w exponent m. So that's one formula for the inner product.
00:37:32.766 - 00:38:52.212, Speaker A: That's another formula for f of w. And we want these to be equal to each other. Therefore the only possibility is to have this coefficient to be equal to this coefficient. So f of w is equal to f inner product of kw in d if and only if. For each mix n plus one bn bar is equal to w to w n, or pn equal to w bar exponent n divided by n plus one. Therefore, our kernel is the sum, and from zero to infinity coefficient w bar n plus one times zn. And this is the sum from zero to infinity z w bar.
00:38:52.212 - 00:39:37.764, Speaker A: Or I always wrote w bar z. So that's, write w. Was it here too? Divided by n plus one. We can, we can leave it as it is. Or I mean, use, this is equal to one over w z bar log, one minus w z w bar z. It's not indeed difficult to see why this is the case. Let me explain why this is the case.
00:39:37.764 - 00:40:50.478, Speaker A: One plus z plus z two is one over one minus z. You can consider z to be the real number. And then you take the integral of this, say from zero to z. What do we obtain? So here is z plus z, two over two plus z, three over three, and this becomes log of one minus z minus true. Either you think it this way, or you say that if you take the derivative of this, you obtain the previous one, and at the point z equal to zero, they coincide. This calculation is valid as long as z is inside t. And now divide both side by z.
00:40:50.478 - 00:42:00.594, Speaker A: So one plus z over two plus two over three, and so on, is one over z. And instead of minus log, write log of one over one minus z. That's the formula which I used here. And instead of z, I have w bar z altogether. So this is the formula for kw of z. And if w is equal to z, if w is equal to z, k, z of z is one over z bar one over z squared, mod z squared, log of one minus mod z squared. And we know from the first week that the norm of e z is root square of k, as I said.
00:42:00.594 - 00:42:39.494, Speaker A: So it's the whole combination here, square. And we obtained this before. Indeed. So again, our estimation is sharp. We, here it is. It's rather surprising that, I mean, even in this example, our estimation is sharp. And we see that in the, in the Bergman space, it's the same story.
00:42:39.494 - 00:43:38.808, Speaker A: So here we obtain the formula for norm, formula for the kernel, and we have an rkhs. I mentioned weighted Dirichlet spaces. The reason is this. Here my definition is based on the coefficient. Here it is, it's based on the coefficient. But there is a reason why I put n or n plus one here. And the reason is discovered by means, this formula used by Dirichlet himself in his solution of the Dirichlet equation is integral over d unit s f prime of z squared d a z.
00:43:38.808 - 00:44:24.232, Speaker A: Or it's more clear here, dx dynamic and you normalize one over PI. We calculate this integral. And if you do the calculation and use the parcel identity, you see, this is equal to n mod a n squared. That is why this Dirichlet was called Dirichlet space. Dirichlet started from here. This is called Dirichlet integral. For the generalization, we can use this formula and put a weight here, another weight.
00:44:24.232 - 00:45:18.974, Speaker A: So dw r spaces function f such that one over PI mean PI is really not necessary. Here. The important thing is omega. Here, omega z f prime z squared dx dy is less than infinity true. And omega is something positive is it can be equal to zero, but not on a big set. That's not our concern. Here we can show with the same line of reasoning we saw before, very similar to that indeed, that this is an rkhs.
00:45:18.974 - 00:46:24.314, Speaker A: What does it mean? It means that it's a Hilbert space. And in this Hilbert space, the evaluation functionals are continuous, good up to here. The bad part is that we don't have a formula for k. What is kz? Of course, except for the special cases like w is equal to one, which gives us the classical case we studied before. In the general setting, we do not have an explicit formula for the kernel, so it's our first example for which we know it's an Rkhs. But we do not have a formula for k, but we have a formula for the norm. Completely opposite to this will come probably next week when we, or the week after, when we study Moore's theorem.
00:46:24.314 - 00:47:11.210, Speaker A: And by Moore's theorem, we will see that when we have a kernel, we can construct a space. So we start with the kernel. So kernel is there, it's the first line. We construct a space, but at the end of the day we have an Rkhs for which we do not have a formula for the norm. And there is an interplay between these two made by the great master Dan Sarasson. He was the first one who found the bridge between Dirichlet spaces and Dobranche Wozniak spaces and showed that in some cases they coincide. And out of this he mim.
00:47:11.210 - 00:47:53.154, Speaker A: Lots of interesting results. Hopefully we reach to this at the end of the semester. Thank you very much. And now for today, if there is any question. Well, if not, we see you tomorrow. With whose lecture? I forgot, Danielle. Daniel Guerrella gives lectures on BMO tomorrow morning at ten.
00:47:53.154 - 00:47:59.494, Speaker A: So see you then. Hi, Anatolia. How are you doing? You're fine.

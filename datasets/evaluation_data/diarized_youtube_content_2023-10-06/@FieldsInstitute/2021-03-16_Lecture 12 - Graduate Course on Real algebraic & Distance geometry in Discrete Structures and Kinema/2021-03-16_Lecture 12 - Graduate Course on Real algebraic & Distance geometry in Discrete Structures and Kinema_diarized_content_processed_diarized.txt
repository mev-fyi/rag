00:00:00.120 - 00:00:40.236, Speaker A: The topic we're going to be looking at, flattenability is closely linked to rigidity, but at the same time not the same thing. So I'm going to jump into some definitions. So we're just going to use kind of the normal notation. So all the graphs are going to be finite and simple. We're not going to do anything too weird. We're going to have d dimensional realizations that just maps from the vertex set to whatever space we're talking about. So RD in this case, importantly, we're going to allow zero distance edges.
00:00:40.236 - 00:01:25.414, Speaker A: So that'd be two points, two vertices connected by an edge. We're going to allow them to sit on top of each other. Okay? And then just a pair GP is going to be a d dimensional framework. Okay? So yeah, like I mentioned here, importantly, we're going to allow zero length edges and I mean, if we don't, then we're going to run into some immediate problems which we'll see very soon. Okay, we're going to use the d dimensional rigidity map. I'm using the squared version, which will hopefully come apparent later. So this just takes any d dimensional realization of a graph and then just maps it to its set of edge lengths squared.
00:01:25.414 - 00:02:22.184, Speaker A: Okay, we can use this to kind of also identify when two frameworks are basically the same thing. So if I've got a k dimensional framework and a d dimensional framework, if they're mapped to, if they have the same edge length score, then I'm going to say they're equivalent. Now, importantly, I'm saying k dimensional, d dimensional, they don't have to be in the same dimension. Okay? So GP could be in a lot larger dimension or a lot smaller. Doesn't really matter in some ways. You can take, if K is bigger than D, you can just embed the smaller one in the bigger dimensional space because everything's euclidean, so everything's nice. Now when lefty covers this later on with LP and stuff, this is not entirely the case, but still sort of the case, but that's for a later day.
00:02:22.184 - 00:03:19.522, Speaker A: Okay, if we have a framework, a k dimensional framework, we're going to say it's deflattenable if you can effectively just flatten it out into d dimensions. Okay? So if we have a k dimensional framework, it's deflattenable if there exists an equivalent d dimensional framework. Now if k is smaller than d, this is immediately true. So if k is less than or equal to d, then the framework itself can just be embedded in d dimensions. And you find the problems are obviously when k is bigger than. Okay, we can also take k to just be equal to the size of the vertex set, minus one, because that's as basically as big as the framework can possibly get. It can't span more than that many dimensions, so we kind of have a bound on what k can possibly be.
00:03:19.522 - 00:03:58.724, Speaker A: Okay, we're now just going to also say that a graph is deflattenable if every k dimensional framework is deflattenable. So every, for every framework ever, any realization of this graph can always be flattened down into d dimensions. Always. So this is not like how we usually do rigidity, when we say, okay, if you can do this for a generic point, and we'll go into the link between the generic points and stuff like this. And this, there is a link here, but it's a slightly different problem.
00:03:59.224 - 00:04:00.180, Speaker B: Hey, Sean.
00:04:00.352 - 00:04:01.108, Speaker A: Yeah.
00:04:01.276 - 00:04:06.224, Speaker B: So is every graph v minus one flattenable?
00:04:06.644 - 00:04:29.788, Speaker A: Yes. Okay. Because they're automatically in dimension v minus one. So you already know that every graph is in some way flattenable. It has to be flattenable for some k, which is a nice property. And I've just got a picture here of flattening a tree. So trees can always be flattened into any dimension.
00:04:29.788 - 00:05:04.084, Speaker A: So they're always k flattenable for any k. And you can kind of see why here. So I've just got my framework here in two d, and I've just flattened out into 1d. Okay. It's also worth noting that if you're, if you're d flattenable, then you're also d plus one flattenable, and d plus two flattenable, and so on and so forth. Because if you can flatten it into d dimensions, then you've trivially also flattened it into d plus one dimensions and d plus two dimensions and so on and so forth. Okay.
00:05:04.084 - 00:05:19.364, Speaker A: Right. Now, this is kind of why we're assuming that edge lengths are going to be non zero. Oh, I've got a question. In fact, a graph is.
00:05:20.524 - 00:05:30.304, Speaker C: Yeah. It's flattenable to dimension, approximately square root of the number of edges. We'll come to that. It's not hard to see. Once you get to the appropriate theorem. We can talk about it.
00:05:33.404 - 00:05:34.264, Speaker A: I guess.
00:05:35.724 - 00:05:37.812, Speaker D: Hi, Sean. Can I ask a question?
00:05:37.988 - 00:05:38.744, Speaker A: Yeah.
00:05:39.724 - 00:05:54.754, Speaker D: So if a graph is different in D. Sorry, your number, like, say, in k one and in k two in between there is all flexible. Right. In between there's two numbers.
00:05:55.774 - 00:05:57.750, Speaker A: So sorry, if you're saying if it's.
00:05:57.782 - 00:06:02.334, Speaker D: Flattenable in ky and k two, yes.
00:06:02.374 - 00:06:09.758, Speaker C: It'S flattenable in all the numbers, if it's flattenable to k two, then it's flattenable to any number be above it.
00:06:09.886 - 00:06:26.084, Speaker A: Yes. Yeah. So you only need to flattenable, like it gives you a lower back. So if you show that something's deflatable, then it's d plus one flattenable, d plus two flattenable, so on and so forth. But it could also be d minus one flattenable. But then you would need to prove that separately, I guess, if you know what I mean.
00:06:27.344 - 00:06:29.004, Speaker D: Okay. Yeah. Thank you.
00:06:31.104 - 00:07:13.998, Speaker A: Okay, so the reason why we were doing zero length edges is because we kind of want to talk about this being a minor property, a minor closed property. So a minor of a graph, if you've not seen this before, is any graph that we can reach. So if we have a graph g, we can reach a minor by, the only things we do is either edge deletion. So we just delete edges or edge contractions. So that's, if we have an edge, we just identify the endpoints as being the same vertex, any doubled edges. So any edges that become parallel. So that will be an edge that's, you'd have a vertex adjacent to both of them, would give two edges.
00:07:13.998 - 00:08:03.104, Speaker A: When you do the edge contraction, we just delete one of the edges, and the edge itself that's been endpoint will become a loop, which we then also delete. There's versions of this which you do for multi graphs, we don't do this, but we're doing finite simple graphs. So yeah, we get rid of all doubles and all loops when we do this edge contraction. Okay. Yeah. The important thing about minor graph miners is we can talk about graph like graph properties that are minor closed. So this would be if we have some property of graphs that we want to know, does the graph have this property or not? If we can say it's minor closed, if whenever a graph has the property.
00:08:03.104 - 00:08:31.484, Speaker A: I haven't got this the right way around. If every minor of a graph with a property p will also. Yeah. So if a graph has property p, then every minor of that graph will also have to have property p. Okay. So no matter how you remove edges or contract edges and stuff like this, it stays a property. Okay, now the important reason why we look at this sort of thing, so for an example before I carry on a classical example, is planar graphs.
00:08:31.484 - 00:09:06.124, Speaker A: The planarity of a graph is a minor closed property. If you have a planar graph, if you delete edge, it's still going to be planar. If you contract edge is still going to be planar. And that means planarial graphs is a minor closed property. And we can then identify miners that basically determine whether your graph is or is not planar, what we call forbidden miners. Okay. So this also can be extended to this nice theorem here.
00:09:06.124 - 00:09:38.394, Speaker A: So if we have a property that's a minor closed property, and we say m is a set of all minimal forbidden miners. So these are all the graphs that do not have the property. But if you remove any edge or you contract any edge, it will have the property. Then the set m has to be a finite set. So in the plainer case I gave, the two classical ones is k five, and the bipartite graph, k 33. They're the two minimal forbidden miners. Okay.
00:09:38.514 - 00:09:39.282, Speaker B: Hey, Sean.
00:09:39.418 - 00:09:40.174, Speaker A: Yep.
00:09:40.514 - 00:09:47.404, Speaker B: The proof of this theorem, would it follow from, like, like, does this like from the partial order?
00:09:49.224 - 00:10:21.200, Speaker A: Yeah, it's to do with. So I don't know the details on this, but it is to do with, you prove it has a kind of a well ordering. And I can't remember the details on this. It's quite a complicated proof. I think it was about 500 pages or something. It's effectively a book, the proof, for certain cases, you can make it a lot simpler. So the, I think it's Kuritowski's theorem for the planar graph is a lot more simple.
00:10:21.200 - 00:10:30.364, Speaker A: This is a very general theorem. This just says, whenever you have a minimal, whenever you have a minor closed property, it has to have a finite set of minimal forbidden minus.
00:10:30.784 - 00:10:36.344, Speaker B: Okay. And then can we give another example of minor closed property?
00:10:36.464 - 00:11:00.304, Speaker A: Yes. So I was going to get into this. So I just mentioned previously, planar graphs. There's also toroidal graphs. So toroidal graphs are graphs that can be embedded on the torus so that none of the edges cross. That's also going to be a forbidden minor property because you can show edge deletion isn't going to change anything. Edge contraction isn't going to change anything.
00:11:00.304 - 00:11:34.996, Speaker A: So it's a minor closed property. We have a minimal, we have a finite set of minimal forbidden miners. At the moment, they know there's at least 17,000, but that number is probably higher. There is no actual, they don't know how many there are. They know it's a finite set, but these finite sets can get extremely large. Another example, which is a bit more manageable will be projected planar graphs. It's the same, but you do it with the projected plane, and that's around 30 something.
00:11:34.996 - 00:11:49.572, Speaker A: Forbidden, minimal forbidden miners, who's a bit more tractable now fortunately, what we're going to deal with is going to have a hell of a lot less forbidden miners, at least for the lower cases. But I'll go into that. Does that help? Does that answer your question?
00:11:49.708 - 00:11:57.668, Speaker B: Yeah, that was good. As far as non examples, I can think of connectivity. But are there any other non examples that you can mention?
00:11:57.836 - 00:12:22.254, Speaker C: Oh, there are lots of them. I mean, all kinds of things end up being not. Yeah, essentially you can find complete grass up graphs one way or the other that have the property and don't have the property. Things that are equivalent to homeomorphic, to complete subgraphs. Then you don't have the forbidden. Minor property.
00:12:22.594 - 00:12:25.346, Speaker A: Yeah, it's a bit of a special property.
00:12:25.490 - 00:12:28.454, Speaker B: Well, so if there's many of them, can we name two?
00:12:29.194 - 00:12:36.810, Speaker A: Rigidity. So that's one. So if you're rigid, then it's not a. Okay, so independence. It might be a better one.
00:12:36.962 - 00:12:39.850, Speaker C: Yeah. 3d composability graph, then.
00:12:39.882 - 00:12:54.014, Speaker A: That does not mean. So if your graph is too independent, then edge deletions. Yep. You're still going to be, you still going to be independent, but edge contractions, no, you could contract and become dependent. So that's not a minor closed property.
00:12:55.074 - 00:13:00.276, Speaker C: So tree decomposability is another one. Alex, since you're familiar with that now.
00:13:00.420 - 00:13:04.544, Speaker B: Okay, now I have three non examples that's good.
00:13:04.884 - 00:13:17.780, Speaker A: Containing a cycle we actually will deal with is kind of the one flattenable case. So I'll get into that soon. Is that, is that enough for the moment, yeah.
00:13:17.812 - 00:13:18.624, Speaker B: Thank you.
00:13:20.084 - 00:13:21.756, Speaker D: So can I ask another question?
00:13:21.900 - 00:13:22.904, Speaker A: Yeah, yeah, sure.
00:13:23.204 - 00:13:36.594, Speaker D: So this is saying that for graphs, that largely enough, then if every property minor have this property p, then this graph will have property p. Is this.
00:13:37.654 - 00:14:22.284, Speaker A: No, no. So this is saying that the minor closed property is a property on every single finite simple graph ever, all of them. And what this says is that if you know that a property p is if you know you have a property that's a minor closed property. If you want to check if a graph has the property, all you have to do is determine whether it has one of a finite set of forbidden miners. So for planarity, if you want to check if your graph's planar, you just have to check that it doesn't contain k five as a minor and it doesn't contain k 33 as a minor. That's all you need to check.
00:14:26.584 - 00:14:27.440, Speaker D: Thank you.
00:14:27.592 - 00:15:08.664, Speaker A: Okay. Okay. What I was building up to is deflatanability is a minor closed property, which is important for what we're doing. It kind of also immediately shows you that this can't be the same as independence, because I just said that independence is like independence in the rigidity sense is not a minor closed property. So the two things are definitely distinct. And the proof's fairly simple. If you take a graph, we just have to show that both removing an edge and contracting an edge will preserve flexibility.
00:15:08.664 - 00:15:34.572, Speaker A: Because if we can do it once, then we can just keep doing it. So we just have to show we can do it once. So the first job is we pick some realization. I've just picked it in dimension v minus one, because that's as big as it possibly can get. I mean, yeah, that's as much as it can span. So we might as well just think of it here. I could have put anything, to be honest.
00:15:34.572 - 00:16:23.112, Speaker A: But yeah, so we got some realization. Basically because the graph is deflattable, we know that there is an equivalent framework, GQ. And then what we notice is that, okay, if it's equivalent with all the edges including e, then just removing e is not going to stop the two frameworks being equivalent. They're still going to be the same framework. Okay, it's not complicated. The next one is a tiny bit more complicated. But what we basically do is say, okay, if it's deflattenable, then if I take a realization, if I take a realization where I say that, well, I'm contracting the edge xy.
00:16:23.112 - 00:17:15.560, Speaker A: If I take such a realization, and I assume that Px and py in my realization are the same point, this has to be flattenable because I've said that the graph is deflattable, so it flattens all graphs, and this includes ones with zero length edges. Okay, so that's the only stipulation we're putting on our realization. It's just any realization. But px has to be equal to py because g is deflatable. Then we have an equivalent d dimensional framework, gq. And we notice that because the length of x, y has to be zero, that means that qx and qi have to be the same thing as well. And then all we do is we just, our new realization would be this p, where we're just removing the vertex y and q is the same.
00:17:15.560 - 00:17:44.963, Speaker A: We're just removing vertex y. Now I can get from any realization of the contraction of g along xy by forming these p realizations. And then that's basically what you're doing. So you're basically just saying that, yeah, I've got my realization p p. So I've worked it kind of backwards a bit, but this is the rough idea. Of why this works. I've got a question in the chat.
00:17:44.963 - 00:17:48.923, Speaker A: Typo. Typo, where probably a typo, but I'm not.
00:17:49.343 - 00:17:51.043, Speaker B: The last line twice.
00:17:52.354 - 00:18:00.134, Speaker A: We now know that. Hence what's twice?
00:18:00.554 - 00:18:04.774, Speaker B: Should it be not g minus e, but g divided by e?
00:18:05.274 - 00:18:07.842, Speaker C: Yeah, it should be d e. Yes.
00:18:07.898 - 00:18:08.874, Speaker A: Yes it should be.
00:18:08.994 - 00:18:17.648, Speaker B: And then my question is, what about a realization where the two vertices are not coincident? How do we show that that's flattenable?
00:18:17.826 - 00:18:50.704, Speaker A: Well, we don't care basically, because we just need to show that the contraction. So if we contract the edge xy, we just need to show that. I've got a massive thing in the chat. Yeah. I just need to show that when the edges, when the two vertices are considered to be the same thing, I just need to show that that's flattenable, because when I can track the edge, that's more effectively done, if you get what I mean. So I don't really need to care about when they're separate. I mean, ge already covers that case.
00:18:53.124 - 00:19:01.540, Speaker C: Yeah, but Sean, I think it's an interesting question whether some of these properties can still be shown if we don't permit.
00:19:01.732 - 00:19:04.228, Speaker A: Oh, sorry, I misunderstood the question, sorry.
00:19:04.356 - 00:19:04.804, Speaker C: Yeah.
00:19:04.884 - 00:19:41.438, Speaker A: Okay, so if you don't permit zero length edges, then things get very difficult very fast. Basically, we can't use this argument that we've used here for the edge contractions. So then we're kind of in a bit of a position where we don't really know if it's a minor closed property or not, and it probably is not. So we have to be a bit careful. Yeah, I think if we don't allow zero length edges, there are graphs that won't be. They will no longer be deflattable. I just can't think of one off the top of my head.
00:19:41.438 - 00:19:43.366, Speaker A: Mira, do you happen to know one?
00:19:43.510 - 00:20:44.786, Speaker C: No, I don't. And I actually think that some of these other properties that you will be talking about later in the week, maybe about the Cayley configuration spaces. The question as to whether the same theorems that we show when certain graphs don't have convex scaly configuration spaces can still be shown for, you know, for graphs where the miners don't exist necessarily. So in other words, that you don't contract down to the minor, you keep the edges from becoming zero length edges, but still, somehow you end up with this disconnected configuration spaces. You know what I'm saying? Yeah, no, maybe it's too early to talk about it.
00:20:44.890 - 00:20:46.954, Speaker A: Yeah, I'll try.
00:20:46.994 - 00:21:34.004, Speaker C: I think the question is, in general interesting as to can we prove some of the negative results that we are able to show when a forbidden minor exists? Whether some of these results can be. One of the problems with allowing edge contractions is that necessarily you're making everything non generic. So whether or not, whether some of these results can be shown for generic positioning of the vertices is an interesting question. The question may not make sense for every instance of the, every theorem instance that he's going to be talking about, but for some of them it does. And I think it's an interesting question.
00:21:34.304 - 00:22:31.300, Speaker A: So I'm a bit. Yeah, so it doesn't really answer the question, but there is. We'll go on later on about something called the k 222, which is the octahedron graph. Now, as I far as I know, if you assume that the realization you're flattening from doesn't have collinear points, so it's in general position, I think that is always three flattenable, but I'm not totally 100% certain on that. It doesn't answer the question about coincident points, but it kind of shows some of the issues involved. You can have similar problems cropping up, but we'll. Yeah, I guess, yeah, I'll talk about this more next lesson, actually, once I've done a bit of research on the topic.
00:22:31.452 - 00:23:40.414, Speaker E: Okay, Sean, can I ask a question about the proof? I think I understand the contraction proof that you've given, but it seems to me that, and this is inspired by what Mira was saying in the chat, if you just make the realization so that Px is not equal to p y, the distance between them isn't zero, but it's equal to some small number r. Right. And then you let r go to zero. For each r, you get one of these embeddings. I guess it's not so clear how you're supposed to patch them together. I was kind of hoping to keep the rest of the vertices fixed and just have the x and the y moving closer and closer together. But that's not so clear that you can kind of do that.
00:23:41.274 - 00:24:15.302, Speaker A: I don't think you always can. So. I think you can sometimes I don't think you always can. So I'm hoping to do for next week is I'm going to construct an example where for it to be, it's going to be a not flattenable graph. But if you allow non coincidence points, then it's fine. If you assume that. If you define flattenability as all realizations that have non zero edges can be flattened, then it can be flattened.
00:24:15.302 - 00:24:17.534, Speaker A: That's what I'm hoping to do for next week.
00:24:17.654 - 00:24:44.114, Speaker E: Okay, that's cool. It seems like this question about whether you can do things with the vertices just moving slightly. It would be interesting to understand, like a kind of parameterization of these flattenings.
00:24:44.274 - 00:24:44.618, Speaker B: Right.
00:24:44.666 - 00:25:05.686, Speaker E: For each r, for each distance you've got flattening. And so for each r you get a position of each vertex. And. And so we get a kind of, I want to think of it as a path that each vertex is tracing as r changes.
00:25:05.750 - 00:25:06.286, Speaker A: Right.
00:25:06.430 - 00:25:21.974, Speaker E: And so then I want, then I want to claim that there's a limiting configuration. It's not so obvious, but I think it might happen. Um.
00:25:22.754 - 00:25:27.090, Speaker A: And maybe I'd have to think about it.
00:25:27.242 - 00:25:30.650, Speaker E: Yeah, I think this could be an interesting thing to think about anyway.
00:25:30.762 - 00:25:53.462, Speaker A: Yeah. Okay. And Alex, your question about stresses. Stresses do come into this later, actually, so you're not completely wrong. They are used, maybe not for everything, but they are used for specific examples. Okay, but I'll leave that for later. There we go.
00:25:53.462 - 00:26:28.922, Speaker A: Okay, so I think it's time we had some examples of these graphs. So I'm going to talk about something called a d clique sum. This, all you do is you take two graphs, both with a clique of size d, and you identify the two cliques and you just glue the graphs along those cliques. We're not removing any edges or anything. Any doubled edges obviously are just getting removed. Okay. A d tree has a few different definitions, which is why they're quite nice graphs.
00:26:28.922 - 00:27:07.290, Speaker A: So one of them is the one that we're most likely to use is this top one. So it's any graph. Oh, well, this second one actually. So any graph that can be formed from kd plus one, what you do is you do a sequence of d dimensional zero extensions. We only doing the zero extension at cliques. Now, if you don't know what zero extensions is, that's fine, because the definition we're going to be using really is the second one. So to form this graph, all you do is you do d cliques of copies of kd plus one.
00:27:07.290 - 00:27:59.322, Speaker A: So you start with a copy of KD plus one. You do a d clique sum, you've got a new graph, you then do another d clique sum, you do another d clique sum, so on and so forth. And just to get to a picture, this is an example of a two tree. So I've started with k three, and then I've done a two clique sum, another two, click sum, another two clicks sum, another two, click sum, another two clicks sum, and I've got this graph. Okay? And a partial d tree is just any subgraph of a d tree. Okay? So they're very well behaved graphs mainly in some ways because of this last condition that you can also define them to just be deconnected. Chordal graphs with a maximal clique size of d plus one.
00:27:59.322 - 00:28:19.722, Speaker A: That's an alternative characterization of a d tree. And that just means. Yeah, they're very good at computing stuff. Obviously how they're constructed makes them very useful for rigidity. Every d tree will be rigid and minimally rigid. It's kind of easy to see why, because we're just doing a sequence of zero extensions. So, yeah, they're very well behaved.
00:28:19.722 - 00:29:00.146, Speaker A: And all partial d trees will be independent. Right? Every partial d tree is deflattable. Okay, I've got a proof here, but. Yeah, well, we'll go through it. So, observation, if we have two graphs that are deflattenable and we join them at a clique, so we do some sort of click some, then the new graph must be deflattenable. Okay? Because in some sense the, you're having to flatten one side and the other side, and it only works if you can flatten both sides in some sense. So I'll leave you to think about that.
00:29:00.146 - 00:29:42.024, Speaker A: But this is true. If you take two graphs are deflatable, you join them at a clique, you still got something that's deflatable. Okay, this doesn't work if two graphs are not glued at a clique. The important thing is the clique. Now the kind of the reasoning for this is if you imagine two things glued at a clique, say two vertices, like so, two graphs, like so. There's no edge here, there's no edge here, and we glue them together, okay? Now if there's a clique, which in this case will be a line, when we flatten it out, we're going to flatten out this part. We're going to flatten out this part, and this edge stops these two vertices from moving apart.
00:29:42.024 - 00:30:19.680, Speaker A: Now if there's no edge, what can happen is we flatten out this part and it goes to some length like this. But maybe we flatten out this part and it forces these two vertices to get very close together or get very far apart, and they can no longer match up again. So the rule stops working. It's a very hand wavy explanation, but this is an actual actual example. This is not too flattenable, but you can see that this half of the graph is actually too well, okay, take my word for it. This half of the graph is too flattenable. And this half of the graph is also too flattenable.
00:30:19.680 - 00:30:25.444, Speaker A: So we've taken two flattenable graphs, joined, glued them together at two vertices, and we've got something that's not too flattenable.
00:30:26.224 - 00:30:32.084, Speaker B: Okay, wait. Really silly question. Two flattenable or one flattenable?
00:30:34.704 - 00:30:39.080, Speaker A: Two flattenable. One flattenable. No, but one flattenable is always too flattenable.
00:30:39.192 - 00:30:44.204, Speaker B: I mean, you drew it in the plane. So isn't it too flattenable, this graph?
00:30:45.864 - 00:30:53.544, Speaker A: No. So this framework, I guess, will be too. How? As many dimensions?
00:30:53.584 - 00:31:08.270, Speaker C: Yeah, it's. Alex, there's a quantifier here. Too flattenable means for every edge lengths, set of edge lengths for which there's a realization you need to be able to find for the same edge lengths, a realization in two dimensions.
00:31:08.422 - 00:31:18.534, Speaker A: So, for instance, what I would do here is I would make all these edges length one, this edge length one, and this edge length zero, zero.
00:31:18.654 - 00:31:19.190, Speaker C: Yeah.
00:31:19.302 - 00:31:41.774, Speaker A: And what I've effectively got is a 3d simplex. Okay? Now this can't be flattened into 2d because that would require, basically it would look like a k four and I'd have a k four where every edge has distance one from each other. And that's not realizable in the euclidean plane. So this is not the too flattenable.
00:31:42.634 - 00:31:44.854, Speaker B: Okay, I see. That was really helpful.
00:31:47.154 - 00:31:52.054, Speaker D: So the click site, there's no requirement for the size of click.
00:31:54.694 - 00:32:09.914, Speaker A: I guess because we're doing partial dtrees. We're doing dtrees. It's d cliques. Is there a requirement on the size of the cliques? No, actually. No, there's not. No, you are correct. So what I said here will work for any click sums.
00:32:09.914 - 00:32:46.514, Speaker A: But the problem is, after a certain point, you'll see later, after a certain point, really big clicks stop you being able to be flattened, if you get what I mean. So the size of the clique doesn't necessarily stop the rule being true. But it does in a way. Later. I'm explaining it badly. But yes, the clique scums are kind of limited in size just because the cliques themselves will limit flattenability. What we'll see later is if you have a clique on d two vertices, then you are not deflattable.
00:32:47.374 - 00:32:53.714, Speaker D: I see, yeah. So d, right. I draw that click of size d.
00:32:55.614 - 00:33:09.514, Speaker A: Yeah. I guess you could have a clique of size d plus one. And you could, you could do clique sums of that. But with partial d trees we don't. With d trees, we're just gluing it size d, I guess. So for this result here, we don't need anything bigger.
00:33:12.434 - 00:33:14.494, Speaker D: Yeah, I see.
00:33:14.794 - 00:34:03.036, Speaker A: Okay, so the proof is just basically, I've written it out, but all it says is that kd plus one is deflattable. And then all we're doing is gluing together. And kd plus one, you can see, is deflattable because it can only exist in d dimensions. So it's automatically deflattable. And then all we're doing is gluing together copies of kd plus one together. And I just said that gluing along cliques is fine, so nothing's going to possibly go wrong. Now here, if we did a click sum of d two, what you'll notice is that all we're doing is effectively just identifying a kd plus one with a kd plus one that already exists inside the graph.
00:34:03.036 - 00:34:27.064, Speaker A: So it's kind of a trivial move. It doesn't do anything. So we need to do d sums. And because we're not looking at partial d trees, if we prove the result for d trees, then it's true for partial d trees because it's a minor closed property. So we only have to really consider d sums. It doesn't make much difference to the proof, but yeah, but yeah, so partial d trees, always deflattenable. So we've got a nice class of deflattable graphs.
00:34:30.144 - 00:34:50.880, Speaker E: Can I ask a question? Just remind me again of the definition of deflattenable. It means that every, I have it down as every set of distance constraints has a realization in RD for a graph. But is that only true for realizable distance constraints?
00:34:50.912 - 00:35:33.710, Speaker A: Yes, it has realizable, yes. Actually there's some research ongoing about this sort of thing. So if you say, okay, so if you say your distance constraints can be any distance constraints, maybe you just have non negative edge weights on your graph like this, then the definition of flattenability completely changes, because what you're effectively doing is you're flattening a graph from l infinity into l two right more what left he's going to go on about. So I don't want to dwell on it too much, but yeah, it does change what you're talking about.
00:35:33.822 - 00:35:40.354, Speaker E: So what then do you mean by saying that a graph is deflattenable?
00:35:40.854 - 00:35:58.374, Speaker A: You just, any, any realization can be. So if you want to think about edge weights, any euclidean distance matrix, if you take some edge weights that are euclidean distance matrix, that can always be realized in d dimensions, if that's preferable.
00:36:00.234 - 00:36:14.962, Speaker E: Okay, if I don't want to think that way, can I just think that any realization of this graph can be, there's an equivalent realization in dimension D.
00:36:15.138 - 00:36:16.886, Speaker C: Yeah, that's exactly it.
00:36:16.990 - 00:36:18.030, Speaker A: That was the definition I gave.
00:36:18.062 - 00:36:31.318, Speaker E: That's the definition. Okay. So I mean, of course that doesn't make any sense. If the realization is originally is in smaller dimension, then there's nothing to do.
00:36:31.486 - 00:36:32.446, Speaker A: It's trivially true.
00:36:32.470 - 00:36:50.034, Speaker E: Yes, it's trivially true. So, so it's that kind of, any high dimensional realization has this property. And then your comment about, um, about, uh, the, there's a kind of maximum dimension for, for.
00:36:50.374 - 00:36:51.110, Speaker A: Yeah.
00:36:51.262 - 00:36:54.710, Speaker E: Given whatever the number of vertices in g or something.
00:36:54.862 - 00:36:55.406, Speaker A: Yeah.
00:36:55.510 - 00:36:56.478, Speaker E: Okay, now I understand.
00:36:56.566 - 00:36:56.958, Speaker A: Okay.
00:36:57.006 - 00:36:58.086, Speaker B: Every set of.
00:36:58.270 - 00:36:59.594, Speaker E: Okay, cool, thanks.
00:37:00.974 - 00:37:46.566, Speaker A: Um, what was gonna say. Yeah, so now we're gonna say what I was mentioning before. Kd plus two is not deflattable. There's a few ways of proving this. So the one I've gone for is basically you pick, you've got your vertex set. I'm going to label it v naught to vd plus one. So that's d plus two vertices, because I'll start at zero, go to d plus one, and I'm going to define the framework in rd plus one where I just put v naught at the origin and pvi is going to be the vector with a one at the I th coordinate and then zeros everywhere else.
00:37:46.566 - 00:38:45.594, Speaker A: Okay, so it's kind of like you've got zero here, you've got one. Got what? You got one. And then higher up through the dimensions, okay, so the distance between any vertex vi and v zero going to be one, and the distance between any two of the vi's is going to be root two. Now you can actually kind of show that that means this set has to be an orthonormal basis. So this set of vectors I get. Yeah, so the p, the PVis, not the pv zero, the PVis are going to be an orthonormal basis of RD plus one. Now what's going to happen is if we can flatten into RD, then this set, so there's a realization qv, and by applying some translations we can assume that qv naught is at the origin.
00:38:45.594 - 00:39:18.994, Speaker A: Then the vector set qv one to qvd plus one are all going to be vectors of length one and distance root two away from each other, which means they have to be an orthonormal basis of RD. But that means that RD has an orthonormal basis of size d plus one, which means it's d plus one dimensional, which is not. Okay. It's kind of a contradiction. There's other ways of doing it. So now I'm looking at it, it's probably not the best method. I think another one is.
00:39:18.994 - 00:40:01.096, Speaker A: You just say that you take the framework in RD plus one, where every edge has length one, and that cannot be realized in RD. That's an alternative way. In fact, there's quite a lot of them that can't be realized in lower dimension. And you think about it, it kind of ties to the fact that Rd, Kd plus two p, is going to be globally rigid in Rd plus one. So if it could have an equivalent realization in Rd, that would mean it wasn't globally rigid, which is a contradiction. Okay, I don't want to dwell on this too much. Yeah.
00:40:01.096 - 00:40:25.124, Speaker A: So we now got two types of graphs. Two types of graphs. We know one of them is flattenable and one of them is not flattenable. Okay, so what does this mean? We can say we can do this. Nice ordering. Now. So we can now say we know that every partial d tree is deflatable, and we know that if you have a kd plus two minor, then you can't be deflattenable.
00:40:25.124 - 00:40:47.706, Speaker A: So that means that every deflattable graph has to be kd plus two minor three. So we've got this nice bookending. We've got it in between. Okay, so this is our starting point for kind of identifying what these graphs are. We know what we've got, like a minimum bound. We've got a maximum bound and we know it's in between. So.
00:40:47.850 - 00:40:48.666, Speaker B: Hey, Sean?
00:40:48.810 - 00:40:49.362, Speaker A: Yep.
00:40:49.458 - 00:41:02.614, Speaker B: I have a silly question. Can you help me see? I mean, obviously the definition of orthonormal is not what you wrote on the last sentence. Can you help me see how one, how what you wrote implies orthonormal?
00:41:05.494 - 00:41:35.294, Speaker A: Okay, so they're all distance one away from each other. You can show that. Okay, so if two points, so, because I'm saying they're all, they all have length one, they all have to lie on the unit sphere of RD. If two points lie on the unit sphere of RD and they're root two distance away from each other, the only way that can happen is if one of them is 90 degrees to the other. 90 degrees is a bad way, but if we just imagine it in 3d, they have to be 90 degrees, if you think about it.
00:41:35.414 - 00:41:40.350, Speaker B: Okay, that did it. Thank you. You can just look at the plane. They span, and then everything is now in the plane.
00:41:40.382 - 00:41:55.194, Speaker A: And. Yeah, and that makes it orthonormal. Yeah. Okay. So characterizing one flattenability and two flat ability. So one flattenability is very easy. So a graph is going to be one flattenable if and only if it's a forest.
00:41:55.194 - 00:42:22.774, Speaker A: That is a partial one tree. A partial one tree is, is a forest. So the same thing. So this is kind of easy to see because a partial one tree you can very quickly see as a forest because all you're doing is taking copies of k two and gluing them together. So, sorry, a one tree would be. You're taking copies of k two and gluing them together at copies of k one, which is just vertices. Well, that's going to give you a tree.
00:42:22.774 - 00:42:46.824, Speaker A: So a partial d tree is going to be a forest. If we plug in d over here, we're going to get k three minor free. Well, anything that's a k three minor three just means it doesn't have a cycle. So these are exactly the forests. So this property and this property is exactly the same. The whole thing collapses. So you get that one flatten ability is identical to these two.
00:42:46.824 - 00:43:17.898, Speaker A: So that's the first one. The second one. We're going to use the, basically the same technique. We're going to prove that. Well, we're not going to prove it because I want to skim over this, but we're going to show that partial two trees and k four minor three is the same thing. Okay, like I said, I'm going to skim over this. The result that partial two trees are exactly the k four free graphs is a result of Wagner.
00:43:17.898 - 00:43:41.922, Speaker A: But you can also find it in. I'm going to pronounce this wrong. Diesel's graph theory, it's quite a nice book, and he has quite a nice proof for it as well. It's only about a bit less than a page long. He calls them series parallel graphs. So if you like to think about those sort of things, series parallel graphs are. They are two trees.
00:43:41.922 - 00:44:26.650, Speaker A: Off the top of my head, yes. Yeah, they're two trees. And this is how he proves the result, basically. But, yeah, so we got a nice characterization of one flat ability and two flat ability already. So our technique was to show that this is equal to this. Does this work for three D? And the answer is no, this does not work. So in 3D, you can show that a graph is a partial three tree if and only if it doesn't contain k five, which is this one, k 222, which is this one, v eight, which is this one, and c five cross with c two.
00:44:26.650 - 00:44:57.874, Speaker A: So this is the cartesian product of two graphs, which is this one. I won't go into it too much, we only need it for this. So we now know that being a partial three tree is a strictly stronger condition than being k five minor free, because there's a lesser them. So we can't use this, we can't use this method anymore. We can't just say the top bound and the lower bound are the same thing and we're in between. So we're done. We're going to come back to this later on.
00:44:57.874 - 00:45:46.374, Speaker A: This result will help us in a way, and for a bit of a spoiler, we know that this is not three flattenable. We can show that this is not three flattenable. We can show that this is three flattenable and this is three flattenable. And what it's going to turn out is, so it's not immediate from this, but what it turns out is that the forbidden miners are just these two. But we'll go into that later on. Okay, I've given some definitions of flattenability, but it'd be quite nice to have some alternative definitions. Okay, so there's been a few things bounded around in the chat talking about, like if I take a set of edge slimes that are realizable, blah, blah, blah.
00:45:46.374 - 00:46:27.734, Speaker A: So it's nice to think about these sort of things in a multiple different ways. So we're going to prove that there are alternate definitions and we're going to prove that they're equivalent. Okay, first, one is quite easy. So given that k is equal to v minus one, a graph is deflattenable if only if the set of edge lengths squared for every placement in every realization. Sorry. Every d dimensional realization is exactly the same as the set of edge lengths of every k damaged realization. Okay, so that's just exactly the same as what I said about flattenability.
00:46:27.734 - 00:46:44.098, Speaker A: Why is this? Well, any, any graph that is. So I guess I probably should have put that d is less than or equal to k. Would that matter? No, it probably doesn't matter, actually. No, it won't.
00:46:44.266 - 00:46:52.778, Speaker B: So this is saying that the image of the squared edge length maps is the exact same set.
00:46:52.946 - 00:47:09.812, Speaker A: Yes, they're exactly the same thing. If you want to think about it as these kind of euclidean distance matrix cones, you've got these two different types of cones, and one of them is to do with the rank of the matrix. It's saying that they're the same thing. That's exactly what it means to be.
00:47:09.828 - 00:47:23.268, Speaker C: Deflantable well, one of them is not a cone. Oh yeah. If you're looking at it on g, yeah. It becomes a cone. Well, you're asserting that it becomes the same cone.
00:47:23.316 - 00:47:26.244, Speaker A: Yeah, yeah. So this is always a convex cone.
00:47:26.364 - 00:47:26.876, Speaker C: Yes.
00:47:26.980 - 00:47:39.220, Speaker A: And then this, because we're deflattable. This is a convex cone. This is not always a convex cone. This is another characterization. I think it's the next one. Yes. Here we go.
00:47:39.220 - 00:48:13.114, Speaker A: So a graph is deflatable if and only if this set is convex. So it's kind of easy to see one way. So as we said, this set is convex. So if you're deflattenable and this is equal to this, then this set is convex as well. In fact, that's actually the first thing we say. So this is a projection of the cone of euclidean distance matrices. As Mira's gone about, we're just projecting it onto the edge lengths of g, because the cone of euclidean distance matrices gives you all the possible different edge lengths.
00:48:13.114 - 00:48:41.344, Speaker A: We only care about the ones with g. So it's a projection. The projection of a convex set is always convex. So this means that this set has to be convex. And we just said by the previous proposition that g is deflattable if and only if this is equal to this. So if g is deflattenable, then this is equal to this. So this also has to be convex.
00:48:41.344 - 00:49:14.984, Speaker A: Okay. Otherwise a bit more complicated, quite interesting, actually. So now we're going to say, we're going to assume that this is convex. What we're going to now do is we're going to pick k dimensional realization. And I've just defined here the kind of the coordinate functions. So PI will take a vertex to its 8th coordinate. Okay, now what we notice here is that f g of k.
00:49:14.984 - 00:50:27.964, Speaker A: So the edge lengths of the k dimensional realization p, that's equal to this, just by definition of the function. Well, the Euclidean distance can be rewritten as this, basically. Okay, so what I've done is just that this is literally this, okay, now this summation can come out and we end up with this. So this is all the, if you think of PI, so the I th coordinate map, you can think of that as a one dimensional, a one dimensional realization. And what we're saying is that the edge lengths of the one dimensional realizations added together will give this, okay, so this means that this is the linear sum of some one dimensional realizations. Bit odd, but yeah. Okay, since this set is convex, by our assumption, and this set is convex.
00:50:27.964 - 00:50:54.984, Speaker A: Now what we're going to have is if you ignore the convex here. The convex here. This set lies inside here. And this lies inside here. Okay? And we've just shown that. Sorry. The convex part here, this lies inside here, because every realization would be rewritten as, like, a convex combination, okay? So if I then apply.
00:50:54.984 - 00:51:17.264, Speaker A: If I then take the convex hull of all these sets, that will preserve subsets, it preserves inclusion. So now what we have is the convex hull of this lies inside. This set lies inside. This set lies inside the convex hull of itself, which means that this set has to be equal to this set.
00:51:17.864 - 00:51:18.560, Speaker B: Sean.
00:51:18.712 - 00:51:19.444, Speaker A: Yep.
00:51:20.304 - 00:51:28.848, Speaker B: You said, okay, so a convex combination, to me, is a linear combination where the coefficients sum to one.
00:51:29.016 - 00:51:41.444, Speaker A: Yes. Now, the clever part here, Alex, actually, is that this is a convex cone. So I was going to get to this. This is a convex. Well, I was supposed to get to it before, so I do apologize. This is a convex cone. So it includes zero.
00:51:41.444 - 00:52:04.714, Speaker A: So the. What you're saying about the scalar multiples having to sum to zero. Well, all we've got here is the scalar multiples of one each time, and then we just have minus k of zero. So it's a convex. It's a convex combination. Does that make sense?
00:52:04.874 - 00:52:11.986, Speaker B: Like an affine combination, a convex combination is all non negative coefficients and they sum to one, isn't it?
00:52:12.010 - 00:52:14.170, Speaker A: Oh, hang on. Yes, you're right.
00:52:14.362 - 00:52:19.690, Speaker C: Yeah, it's okay. Just divide by one over n or whatever the number. Yeah, just divide it.
00:52:19.722 - 00:52:21.482, Speaker A: Yeah, yeah, that's right. Yeah.
00:52:21.578 - 00:52:22.258, Speaker C: Yeah.
00:52:22.426 - 00:52:29.014, Speaker A: Because it's a convex cone, so it has scalar multiples, including zero. That's fine. Does that make sense now?
00:52:29.634 - 00:52:34.614, Speaker B: No, I'm still confused, because don't that coefficients have to be all non negative?
00:52:35.114 - 00:52:39.174, Speaker C: They're non negative. You simply scale the coefficients.
00:52:40.714 - 00:52:42.682, Speaker B: Didn't Shawn say minus k?
00:52:42.818 - 00:52:47.186, Speaker C: No, just get rid of them. But don't worry about the minus k. Just scale the coefficients.
00:52:47.370 - 00:52:48.890, Speaker A: Yeah, I think mirror's right, actually.
00:52:49.042 - 00:52:49.774, Speaker C: Yeah.
00:52:50.194 - 00:52:52.186, Speaker B: Okay, so now all the ones become.
00:52:52.250 - 00:52:54.554, Speaker C: One over k, one over n, or whatever. Yeah.
00:52:54.714 - 00:52:55.322, Speaker B: Okay.
00:52:55.418 - 00:52:57.370, Speaker C: One over k, or what is the number he has there?
00:52:57.402 - 00:53:00.854, Speaker A: Yeah, another k. Yeah. Sorry. Apologies.
00:53:01.394 - 00:53:04.774, Speaker B: Okay, then can you continue? Because I got distracted.
00:53:05.504 - 00:53:48.108, Speaker A: Oh, okay. Sorry. What I was going to say is, if you ignore the word convex hull here, the set of one dimensional realizations lies inside the edge lengths of the one dimensional realizations lies inside the set of the edge lengths of the d dimensional realizations. Because every one dimensional realization is a d dimensional realization. This, in the same way, lies inside the set of k dimensional realizations. Edge length, edge lengths off the k dimensional realizations. And just from what we proved here, this set lies inside the convex hull of the one dimensional realizations, because we can.
00:53:48.156 - 00:53:59.184, Speaker D: I have a question. So, yeah, yeah. So is this f g d r d v, just the projection of the d stratum.
00:54:02.224 - 00:54:06.096, Speaker A: So not good. So mira may be.
00:54:06.280 - 00:54:10.884, Speaker C: Yeah. The Rdv is the projection of the d stratum. Yeah.
00:54:12.504 - 00:54:13.568, Speaker D: Ftd. Rdv.
00:54:13.616 - 00:54:14.416, Speaker A: Right. Is the correct.
00:54:14.440 - 00:54:18.804, Speaker C: Yes, exactly. Projection on g. I see, yeah, yeah.
00:54:19.864 - 00:55:01.524, Speaker F: Can I make a quick comment? I don't know if this is the correct way to think about this, but a way that made that last equality kind of make sense in my head. Was that really all you're saying is that you have these realizable edge lengths and you're just considering them one at a time and kind of like creating your bigger edge length by almost, you know, combining them one by one. So really you can give me any graph with any edge length vector that's realizable, and I can just consider each edge by itself in like the one, I guess, dimensional realization of that edge and then put them all together.
00:55:04.064 - 00:55:05.920, Speaker A: Okay, fair enough.
00:55:06.032 - 00:55:11.884, Speaker F: I don't know if that's the correct way to think about it, but it makes the last equality less surprising, I suppose.
00:55:14.104 - 00:55:32.892, Speaker A: Yeah, I guess. I mean, the last equality. Yeah. Okay, fair enough. I kind of like the surprisingness of it because this sum is quite clever. So I quite like it because you can actually change this from. Okay, I'm probably going off topic, but you can change this to LP norms and this to be p and do the same thing.
00:55:32.892 - 00:56:05.304, Speaker A: I guess I should probably say q or something instead, but yeah, you can do a similar argument with the LP stuff, which is quite interesting. But yeah, anyway, like I said. Yeah, so this is the proof of the deflatable. So you're deflattable if and only if your set of d dimensional realizations, the edge lengths of them is convex. Right. Now we're going to have a few notational heavy stuff going on for the next slide. So I do apologize.
00:56:05.304 - 00:56:40.572, Speaker A: First, we're going to find some projections. So we're going to have a graph, we're going to have some d. This is going to be what we're kind of thinking about our deflatability and stuff. And we're going to have a set of edges, f inside e. Okay, so we can now define a projection. All this does is it takes our, so we've got our realization, it's our realization is going to give us a set of edge length squared. And then this just says, okay, we only care about the edge is f.
00:56:40.572 - 00:57:13.826, Speaker A: We don't care about the rest. So that's exactly what happens here. Okay, I'm making an assumption here. Basically, this set isn't very well defined. So this map isn't very well defined because we have no edge lamp. So it's kind of unclear what you would do because you're taking a realization and taking it to a set of edge lengths, but it has no edges. So what you do, so what you're just going to say it's the linear map that just takes everything to the.
00:57:13.826 - 00:57:19.770, Speaker A: .0 so it just takes it to the zero dimensional, the unique zero dimensional vector space.
00:57:19.922 - 00:57:21.854, Speaker B: It's not a linear map, is it?
00:57:24.594 - 00:57:46.420, Speaker A: Yes, usually not, but in this special case, it technically is, I guess, just because we're only mapping to zero. Okay, yeah, you're right. Sorry. This map is not linear. It's only in this very, very special case, because we're just mapping to one point which is zero. That makes it linear. That's true.
00:57:46.420 - 00:58:13.394, Speaker A: So I was thinking of this map, which is linear. So a projection is linear. This map is also going to just have code domain zero. You don't have to think about it too much. It's just if there's some special cases and you're wondering, what does this really mean? Just this is the technicality stuff. Okay. So we've got this thing here, which is kind of ugly looking.
00:58:13.394 - 00:58:47.904, Speaker A: So we've got a graph is going to be deflattable if and only if the following holds. So for every edge sets and every realization, this set here is going to be convex. Now, what does this actually mean? Because what we've done is we've took our realization p, our d dimensional realization. We're looking at all the edges. We look at all the possible edge lengths that aren't in f. That's all we're looking at. So we have all those possible edge lengths.
00:58:47.904 - 00:59:40.816, Speaker A: We've now said we're going from that set, and we are. Hang on, if I got this right. Yes. So we're now looking at this set, and then we're doing the inverse of the projection. So what this gives us is we've given a set of edge lengths, ignoring the set of edge lengths f, and we've projected up into the, the set of realizations with all the edge lengths of G. So what we're going to have is we're basically going to have all the realizations, all the possible edge lengths, all the possible d dimensional edge lengths, which have the set of edges e equal to the set of edge lengths of p. And the rest of them.
00:59:40.816 - 01:00:33.934, Speaker A: So it's kind of, we're looking at, it's like we've got our framework GP, we've deleted the edges f, and then we've seen what possible realizations, what possible edge lengths can we get for f? And then the last step of projecting down to f just gives us only the edge lengths f. That's what we're doing here. So what this set does is it takes a realizer, it takes a framework GP, and then it spits out all the possible edge lengths of f. If we were to delete that, those edges f from GP and we let that we look at all equivalent frameworks to this new framework GP. Minus f, sorry, g minus fp. We look at all these possible equivalent things, we're going to get a set of edge lengths that possibly can be achieved. And this is our set CFP.
01:00:33.934 - 01:00:58.114, Speaker A: Okay. This is also called the Cayley configuration space of the framework. You can also define it via edge lamps, just directly. So you can just start off with this and define it that way. So if we call this delta, it would be CF delta. That's an alternative way of characterizing it. So if you have any questions, please do ask, because this is quite a lot of information to take in right now.
01:00:59.894 - 01:01:42.726, Speaker E: Let me ask if I can I just try to paraphrase. So CFP, the image of a realization of G is going to be obtained. I start with G and its realization kind of erase the edge lengths on the edges f. And then I see what things could I plug back in for those edge, edge lengths and still make and get a realization in deep space. And those are essentially the things I'm recording, the things that I could fill back in. Okay, cool.
01:01:42.830 - 01:01:45.674, Speaker A: Yeah, that's a really good way explaining, actually. So thank you for that.
01:01:49.774 - 01:01:50.554, Speaker E: Yeah.
01:01:52.334 - 01:02:56.086, Speaker A: So these things are quite important for quite a lot of things, because it kind of tells us, well, if you're interested in how things flex and stuff like this gives a lot of information on how they flex and stuff. So it's quite an important thing. Okay. Okay, so as I've said before, the projection of a convex set will always be convex, right? We're going to start with something that's deflatable, and we're just going to fix k to be equal to this. For previous reasons, we don't need to bother considering anything bigger or smaller. Okay, so what we're trying to now show, if you remember, we're going to show that if g is deflattenable, then for every edge set, this set is going to be convex. Okay, so we choose any edge set f and any realization p.
01:02:56.086 - 01:04:00.322, Speaker A: Okay, I'm just going to define delta dash to be this map here. So this is all the edge lengths of Gp, ignoring the f edges. And I'm going to find x to be the affine subspace of points of delta. So these points line side re, slightly bigger space where they agree with delta dash. Okay, so this is kind of basically this set here. Okay, well, it's not this set exactly, but it's going to be this set. What we now notice is that this is going to be equal to, like I said, this right here, because all this is saying is we're taking the realizations, the possible edge lengths of all the realizations of Gp, but we're fixing all the edge lengths that aren't in f.
01:04:00.322 - 01:04:32.184, Speaker A: They're all being fixed to be equal to this. This is what we're saying here. Okay, well, because g is deflattable, this is equal to this. So we now have that this is equal to this. Okay, now this is, this is an affine subspace intersected with a convex set, and we're projecting it. So that means that this still has to be a convex set, and therefore this is convex. And we're done.
01:04:32.184 - 01:05:07.794, Speaker A: The other way is just very easy. We basically now say, okay, suppose every set is convex. Then we just pick the set of all edges, and we just notice that this is then going to be equal to this, which is then just equal to this. We said that this is convex, so this is convex. And then we can go all the way back to this result, and this gives us that g is deflammable. And we're done. That's it.
01:05:07.794 - 01:05:52.134, Speaker A: Any questions about that? Nope. Okay. Right, we're now going to move on to independence. Yeah, we're now going to move on to independence and genericity of how and how they're linked, how we can link these to flattenability. So if you've done Tony's course, you'll be more familiar with a lot of this stuff. But we're going to say that a d dimensional framework is independent if one of the following holds. So we can either say it's got an equilibrium stress.
01:05:52.134 - 01:06:23.124, Speaker A: So if. Sorry, if it has an equilibrium stress, it has to be the zero one. So an equilibrium stress is just anything that satisfies this condition here. Okay, so for every vertex, the set of, you look at the set of neighbors, all the vertices are adjacent. You look at this sum and you want this to be equal to zero. That's for a, to be an equilibrium stress. And if you're, you're independent if and only if, every equilibrium stress has to be equal to zero.
01:06:23.124 - 01:06:51.184, Speaker A: Yeah. So I'll mention that in a second. The other one you might have seen is that the jacobian of this map, FGD, has rank e. Now, this is just actually the rigidity matrix times two, actually, I think. Yeah. So this is just a rigidity matrix times two. So if you prefer that method, that's an alternative one.
01:06:51.184 - 01:07:19.112, Speaker A: Okay. I don't want to dwell on it too much, I guess, because it's more rigidity based. And I think a lot of you taking that course too. Okay. Otherwise the framework is going to be dependent. Okay, so I've got some stuff in the chat. Do people want to discuss that or would they rather just keep it in the chat?
01:07:19.208 - 01:07:28.112, Speaker C: I guess we can talk about it later. I guess this is just, you switch to this slide. This is all about the previous slide.
01:07:28.288 - 01:07:30.084, Speaker A: Yeah, that's what I was thinking.
01:07:30.384 - 01:07:33.200, Speaker C: Yeah. So we can come back to it at the end of something. Yeah.
01:07:33.312 - 01:08:16.926, Speaker A: Okay. I'll answer these questions later. Okay, so a graph is going to be d independent if it has a d dimensional independent realization, and it's going to be d dependent if all d dimensional realizations are dependent. In fact, if it's d independent, then pretty much all of its d dimensional realizations will be independent. This is a rigidity theory result. This is basically tied into this stuff here. So a d dimensional realization GP, or a d dimensional framework, I guess, is going to be generic if the set of coordinates is algebraically independent.
01:08:16.926 - 01:08:37.328, Speaker A: So this is a very strong version of generic. You've probably seen quite a few. This is the one that you usually use for global rigidity, I guess. But yeah, when I mean algebraically independent, I mean algebraically independent of the rationals. Okay. Um. Because it's algebraic, because the coordinates algebraically independent.
01:08:37.328 - 01:09:24.704, Speaker A: When you look at the rigidity matrix, anything that's generic, any generic realization of a d independent graph will be independent. And likewise, if it's d dependent, then it's going to be dependent bit more obvious. Most realizations will in fact be generic. They're like an open, sorry, no, open dense. They're a, they're a dense, they're a dense set where the complement has measure zero. There's a few other ways of defining them, but, yeah, they've got quite a lot of nice properties. Okay, why have I brought this up? Okay, so I'm just going to be using this lemma.
01:09:24.704 - 01:10:02.580, Speaker A: It's kind of easy to see why this is true in some ways, if you think about it via this projection of certain things stuff. One way to think about it, actually, have I given a proof? No, I haven't. So one way to think about it is if you have a set of edge lengths that converge. If you have a set of realizations that converge to some edge length, then that edge length has to be realizable. You kind of have to be able to reach it. I don't want to go into it, but yeah, this is true. Okay, this is a result I do want to talk about.
01:10:02.580 - 01:10:53.294, Speaker A: So a graph is going to be deflattenable if and only if every generic k dimensional realization is deflattable. So we only have to kind of consider a certain class of realization, which is namely these generic k dimensional ones. So as I said here, the only if direction. So if a graph is deflatable, then every generic k dimensional realization of g is deflatable. That's obvious, because if a graph is deflatantable, then every realization is deflatable. So that's immediate. So the only direction we have to go is show that if every generic k dimensional realization of g is deflatable, then g is deflantable.
01:10:53.294 - 01:11:24.684, Speaker A: I don't know if I want to bother too much on the proof, but the idea is basically that, okay, yeah, we'll go through it. Choose any k dimensional framework GP. Okay. Since the generic realizations are going to be dense in this set, we can always find a sequence that converges to GP. I've called it GPN. And each one of them, we're going to assume is a generic k dimensional framework. Okay? By our assumption, each one of them is going to be deflatable.
01:11:24.684 - 01:12:22.790, Speaker A: So what we have here is there's going to exist a d dimensional framework, gQn, equivalent to gpn for every n, okay? Because every gpn can be flattened into gQn. Okay, what we now notice is that because the edge lengths of gqn is equivalent to gpn, the edge lengths of gqn will converge to the edge lengths of GP. So then the last thing we do is we just take gq to, to be equal to the limit of these gqns. There's a bit of technicality on this because. Yeah, okay. Actually I've got rounded by saying this thing. So it follows that Gkp lies in the closure of this set here, because it's the limit of these gqns.
01:12:22.790 - 01:13:09.424, Speaker A: The edge lengths is the limit of these GPU edge lengths. And then I'm just using this lemma here that says this is closed to now say that this is closed as well. Okay, does this make sense? Okay, so actually, just to briefly go back to this, some of the reason why this is just immediately true is because the set of realizations, you can kind of quotient out the, the kind of the isometries and stuff. And you can also quote now by scaling, and that will give you a compact set. And then the image of a compact set on the continuous map will be compact. That's kind of the reason why we can say this is true. I didn't want to go into that too much.
01:13:09.424 - 01:13:58.326, Speaker A: Right. So we've just said that the, it's going to be deflatable if and only if every generic k dimensional realization is deflatable. So what happens if we just have one? So if we just have, there is a generic k dimensional realization that's deflattable. Then the graph has to be independent. Okay, so this is just saying that G has one generic k dimensional realization that's deflantable. Now, you'll notice that previously I said that being de independent is not a minor closed property. So this is kind of hinting at the idea that deflatanability is not a generic property.
01:13:58.326 - 01:14:30.134, Speaker A: Because if it was a generic property, as in one generic framework has it, then they all have it. That's what happens with rigidity, global rigidity, some other things. Um, this would mean that being d independent will be equivalent to be deflattable, which is not. So this is already hinting at some slight weirdness going on. Okay. Um, so we want to show that this is equal to this. So first we're going to suppose that the graph is, uh, d independent.
01:14:30.134 - 01:15:12.224, Speaker A: Okay. And just choose any generic d dimensional realization, GQ. Okay, actually I got this correct. Yes. Okay. So because GQ is going to be independent, I won't go into it too much, but you can use some differential geometry to basically say that there's going to exist an open neighborhood u of q. So that this, the image of u, this open neighborhood is going to be a e dimensional smooth manifold.
01:15:12.224 - 01:15:52.614, Speaker A: An e dimensional smooth manifold is just going to be an open subset of re. Okay, so we're saying that there is some open neighborhood of q, so that this is an open set. Okay, what we're now going to basically say is that we can kind of fit something in with this. So we're now going to say that let gq be the embedding of gq in Rk. So all we've done is we've just taken our d dimensional framework and considered it as lying in Rk. Right. That's all we've done since the rigidity map.
01:15:52.614 - 01:16:20.786, Speaker A: This gdp, sorry, this fgd is going to be, is continuous. We can basically take a sequence of generic says d dimensional. It should be k dimensional, I guess. Yes. So sorry. This should be k dimensional. So we can take a sequence of generic k dimensional realizations that approximate gq tilde.
01:16:20.786 - 01:17:32.992, Speaker A: Okay. They just keep getting closer and closer and closer. Now what's gonna happen is when, if we get sufficiently close, so with this framework, this realization gp, when we're sufficiently close, g k of p is gonna lie inside gd of u because the g k of p of q tilde lies inside gd of u because it's exactly the same as f g d of q. So this means that because we've got sufficiently close, the set of edge lengths has to lie inside this open set that we've already found. Well, if we have a framework which lies inside this open set, that means that there is a d dimensional realization with the same edge lengths. So that means that gp is deflattable and we're done. Okay, so it's just kind of saying that if you're independent, the image, if you're independent, then your set of edge lines has to contain an open set.
01:17:32.992 - 01:17:46.374, Speaker A: And then what you can do is you can always just approximately some flattenable, some, some de independent graph and find the edge lengths and always flatten this generic realization.
01:17:47.954 - 01:17:48.778, Speaker B: Hey, Sean.
01:17:48.906 - 01:17:49.614, Speaker A: Yeah?
01:17:49.994 - 01:18:03.814, Speaker B: Q tilde is the embedding of RD into RK. Uh, or the realization that comes by embedding the smaller Rd into the bigger Rk.
01:18:04.804 - 01:18:10.984, Speaker A: So I don't, so it's q tilde is just the single framework. So it's not an embedding of the whole space.
01:18:12.684 - 01:18:16.144, Speaker B: It says let q tilde be the embedding of.
01:18:17.764 - 01:18:19.892, Speaker A: Oh, so I mean the embedded framework.
01:18:19.948 - 01:18:23.684, Speaker B: I guess, if just by seeing RD inside of RK.
01:18:23.804 - 01:18:38.034, Speaker A: Yes. Yeah, yeah, yeah. So that's all we've done there. It's a technicality. I guess you could just go with GQ. Yeah, doesn't really matter, I guess. Any other questions about this?
01:18:39.734 - 01:18:47.062, Speaker B: Can you explain the next sentence? Since f is continuous, we can choose a generic D dimensional, it's supposed to.
01:18:47.078 - 01:19:01.604, Speaker A: Be k. This is a typo. So this is supposed to be a generic k dimensional realization GP that is sufficiently close to this so that a set of edge lamps lies inside this open set here.
01:19:02.544 - 01:19:08.440, Speaker B: So we're thinking that the coordinates are very near zero in all the extra coordinates.
01:19:08.552 - 01:19:37.564, Speaker A: Yes. Of RK we've got something that's very flat. It will still not lie in RD because it's generic. So the genericness stops it from lying in RD, but it's going to be very, very close. What we've said is this GP framework is so close that basically it becomes so close that it just can immediately get flattened is kind of the idea. It's quite a nice result in that way, I guess. Okay.
01:19:39.704 - 01:19:43.844, Speaker D: So a projection open set is also open set, right?
01:19:45.744 - 01:20:25.718, Speaker A: Oh, I want to be careful on that. Hang on, an open set, it's always open. Yes, that's true, because it's a subjective linear map, but it's not guaranteed that. So what we have here is just because it's independent, because GQ is independent, we could find an open neighborhood of Q so that the image of this open set is, I said an e dimensional smooth manifold, which just means, it means it's going to be an open set. That's not, that's actually not true if you're not open. If you're not open, this is not true. So then the proof falls apart immediately.
01:20:25.718 - 01:20:48.304, Speaker A: The method that we use to prove it falls apart because we can't find this open set. So we can approximate GQ Tilde by GP however much we want. But it doesn't necessarily guarantee that this is going to lie inside this set like we want. So we need the independence for this part of the proof.
01:20:49.444 - 01:20:55.584, Speaker D: So independent implies guarantees. F GDO is open, right?
01:20:56.724 - 01:21:46.094, Speaker A: Open. Not necessarily because you can still have dependent realizations. So I wouldn't want to call the map open because there could be some other framework which is not generic, that I guess that is not, the map is not opener. So you got to be a bit careful, I guess, because it doesn't mean that if a graph is independent, it doesn't necessarily mean that the rigidity mAp, Gd, FGd is going to be an open mAp. It could still have some bad points. In some ways it'll be open at, I guess, if you want to, of it, that it'll be open on every. So what I've basically shown is that it's open at every neighborhood of an independent point.
01:21:46.094 - 01:21:55.354, Speaker A: So if you take an independent point, you take an open neighborhood of that point. FGD will be open on this restriction. And that's what I've used here.
01:21:57.174 - 01:22:00.074, Speaker D: I see. Okay. Yeah.
01:22:02.594 - 01:22:32.674, Speaker A: Okay. So I'm going to use this lemma here. So if we have a generic deno dimensional framework, then. Sorry, n dimensional framework. Hang on, what am I saying? Oh yeah. So it's just saying that if you have a generic n dimensional framework and you take any other equivalent n dimensional framework, then they have the same rank. So you probably have maybe seen this in Tony's course.
01:22:32.674 - 01:22:45.394, Speaker A: So this is a result of Bob? I guess, but I've seen it previously. Oh, hang on. What's Mira saying?
01:22:46.894 - 01:23:08.404, Speaker C: Yeah, again, I. By the time I typed, you moved on to the next thing. So this is a statement about the previous slide where you were showing about the e dimensional neighborhood. So the same, pretty much the same argument, or portion of the argument is used to show that any graph is square root of e, of g flattenable.
01:23:11.144 - 01:23:11.884, Speaker A: So.
01:23:14.624 - 01:23:21.600, Speaker C: So if you chose your. Maybe this is a little too much to digest right now. Maybe we can do this later.
01:23:21.752 - 01:23:22.368, Speaker A: Okay.
01:23:22.496 - 01:23:23.204, Speaker C: Yeah.
01:23:23.624 - 01:23:24.632, Speaker B: Hey, mira?
01:23:24.768 - 01:23:25.296, Speaker C: Yeah?
01:23:25.400 - 01:23:33.000, Speaker B: Would you just read it so that it has it for the video and I can think about it later because the chat will disappear. But if you say it.
01:23:33.192 - 01:23:35.404, Speaker C: Oh, the chat.
01:23:36.024 - 01:23:38.404, Speaker A: I see, that will disappear from the YouTube video.
01:23:38.984 - 01:24:19.374, Speaker C: Okay, so I can read it. A part of this argument is used to show that any graph is square root of e, of g flattenable. It's kind of a simple argument, but as far as I know, the first person who wrote it down was a guy called Barwinoke. It's in a, in a Barbie, not paper from the eighties or something like this. Okay, so the. So that is the d stratum is. The d stratum means the set of all pairwise distances of points that live in d dimensions, right? So this is dv minus d plus one, choose two dimensional.
01:24:19.374 - 01:25:29.544, Speaker C: And if we can choose d large enough so that that dimension is at least e, the length of, I mean, the number of edges of the graph, then the projection is a full dimensional projection on e, on the graph. So once you get the full dimensional projection, then you know, then you know that it has, at least the projection has the same dimension as the projection of the entire cone. And that's exactly the definition of deflattenability, along with that little argument that he talked about before, saying, you know, the projection, you can, if you project the one dimensional strata and take their convex hull, that's exactly what you get as the projection of the d dimensional stratum on the cone. So on the graph. So essentially the same argument. And now you just take this inequality Dv d plus one, choose two, is at least e. And then that tells you that if, you know, if you plug in your d to be something like square root of e, then that's sufficient to make that happen.
01:25:29.544 - 01:25:39.816, Speaker C: And that's how you get the deflattenability. Okay. Hopefully that helps later when you, when you listen to it.
01:25:39.920 - 01:25:41.032, Speaker B: Okay, thank you.
01:25:41.208 - 01:25:46.392, Speaker A: When you say o, when you're using the O notation, is that the one where there's.
01:25:46.448 - 01:25:49.480, Speaker C: Yeah, I'm just not, not being careful about the constants.
01:25:49.632 - 01:25:50.408, Speaker A: Yeah.
01:25:50.576 - 01:25:51.764, Speaker C: That's all it means.
01:25:52.104 - 01:26:03.144, Speaker A: I mean, is it then not just going to follow from the fact that you can say that the graph is independent in some very high dimension or something?
01:26:03.184 - 01:26:16.390, Speaker C: Yeah, that's all it is. Yeah. But to show deflatenability, you would have to do more than just show independence. Right, as you just said a moment ago.
01:26:16.502 - 01:26:17.154, Speaker A: Yeah.
01:26:18.374 - 01:26:23.174, Speaker C: So you need a little tiny bit more to say, but that's all it is. Yeah.
01:26:23.334 - 01:26:45.334, Speaker A: Okay. Yeah. Okay. So what I was saying here, this just means that if you have a generic framework, the rigidity matrix you can actually show will have maximum rank. And in fact anything equivalent to it will also have maximal rank. It's basically the gist. You've probably seen it in Tony's course, you might have seen it earlier mirrors.
01:26:45.334 - 01:27:54.524, Speaker A: It's fairly well known results and we're going to use that here. So we're going to suppose there is a generic k dimensional framework that is deflattable. What we're basically going to notice, just to give you a gist of what we're going to do, like I said, a couple of paragraphs, so it's not that much, but you have your generic K dimensional framework and we know it's deflattenable. Now what this means is because the equivalent realizations are always going to have the same rank, we can kind of think that there is some path, maybe not from GP, maybe just something equivalent, but there's some kind of continuous path that flattens out into D dimensions, which is quite a nice way to think about it in some ways. So it like continuously flattens down. And what we're going to notice is that it's going to kind of carry a lot of properties. Well, I guess the proof is slightly different to that, but that's one way to think about what happens here.
01:27:54.524 - 01:28:35.254, Speaker A: If you have a generic framework that a k dimensional framework that is deflattenable, then maybe it won't, but something equivalent will just flatten down. It'll have a continuous motion that flattens it down. Right. Anyway, I'm going to be off topic, but so we're going to have our generic K dimensional framework that's deflatable and we know that because of that, it's going to have a d dimensional equivalent realization, GQ. Okay, we're now going to do what I said before. So we're going to do GQ. Tilde is going to be the embedding of GQ in RK.
01:28:35.254 - 01:29:05.954, Speaker A: Now. It's kind of, this is really why it's important we have to kind of here, it's more important why we have to distinguish between a framework in RD and a framework in the hyperplane RD with a load of zeros on the end. We have to be a bit careful. So this is just. Yeah, we've embedded GQ into rK again. Okay. By our above lemma, we know that the rank of this should be a k.
01:29:05.954 - 01:29:46.174, Speaker A: So the rank of the jacobian of q is going to be equal to the rank of the Jacobian of Q. Tilde, with respect to this being a kick right here, we can kind of just see that this is true because this rigidity matrix is literally just going to be adding columns of zeros in. That's all we're doing. Okay. We just added a load of columns that are just zeros in them. This, by our lemma is equal to this, remembering that this d is supposed to be a k. So this is equal to this because GP is generic.
01:29:46.174 - 01:30:13.306, Speaker A: And we know that the rank of this is. Thank you, Faye. Thank you. And we know that this is equal to e because we. Because it's a generic k dimensional framework. Because it's in k dimensions, it has to be independent because the dimensions is so high, it's just automatically independent. So the rank of this is equal to e.
01:30:13.306 - 01:31:05.694, Speaker A: Okay? And like I've said, this matrix is just formed from adding a load of zero columns to this. Okay? So we know that this is equal to this, but that's literally the definition of being independent. So this means that GQ is independent in RD. Therefore G is d independent. Okay, any questions about that? Okay, actually, how do I get rid of this? Now? Clear all drawings. There we go. Perfect.
01:31:05.694 - 01:31:51.940, Speaker A: Okay, so an immediate corollary from this, any deflattenable graph is going to be d independent. You can kind of see why just here, if we have a graph that is deflattenable, that means that all the generic k dimensional realizations are going to be deflattenable, hence is going to be d independent. So this is a very quick, nice corollary. It limits what we're looking at. So this is kind of why rigidity, and this is the reason why rigidity and flat ability are linked. They're not the same thing, but they're very closely linked. Rigidity is kind of almost looking at, or the rigidity matriarch is almost looking at the generic flat ability.
01:31:51.940 - 01:32:22.204, Speaker A: Does there exist a generic framework that can be flattened? Okay, the reverse is, like I said, not necessarily true. And here is an example. So this graph is too independent but not too flattenable. It's not too flattenable because it contains k four as a minor. Because we can contract this edge here we've got k four, and we just said that k four can't. It is not too flattenable. And in fact, you can take, you can kind of think about this in any way.
01:32:22.204 - 01:33:31.914, Speaker A: You can take something that's not, say, deflattable and then you can just subdivide its edges. So each edge you can just replace by vertex connected to two endpoints. So you just subdivide every single edge. If you do that, then you've definitely got something that is d independent, but it will not be deflattable because we obtained it from a not deflatable graph. That's the kind of the idea. Any questions on that? Okay, is flattenability a generic property? Well, I've kind of already hinted the answer is definitely no because otherwise those theorems would all combine and would say that the flattenability would be equivalent to being d independent. Because if you think about it, if we were d independent, we'd have a generic deflatable, generic deflatable realization.
01:33:31.914 - 01:33:53.884, Speaker A: And if we had one of these realizations, if we said it was a generic property, that would mean all of them are. And we know from another theorem that if all of them are, then that's equivalent to being D flat one. So we can't. It can't be a generic property. So this slide is maybe not too much of a surprise. No, that's the answer. Here is an example.
01:33:53.884 - 01:34:31.744, Speaker A: I'm going to leave it as a bit of an exercise because it's quite a nice one. So this graph is not too flattable. And you can see why just because it contains k four as a minor. Okay, so I can contract, say, this edge, and then I've got k four minor. But it does have quite a lot, actually, of generic. Two flattenable four dimensional realizations. Okay, now what you want to really think about is if you ignore this vertex here, all we can do is kind of, we've got a hinge and we can flip it.
01:34:31.744 - 01:35:10.950, Speaker A: We've got two triangles attached, and this has to be basically three dimensional. What we can kind of do is we can make these edge lengths so long that they won't affect the flattenability of this one particular generic realization in a way. And then we have to pick the last vertex to be in the fourth dimension. But the other vertices can just be in, will be in three dimensions, the last one being the fourth dimension. We can pick it so far away that it's going to be. Well, we can pick it so it's generic and we can also pick it so it's so far away. In some sense these edges don't really do anything.
01:35:10.950 - 01:35:37.338, Speaker A: But I'll leave that as an exercise. It's quite a nice, it's quite an easy one to do in some ways. Okay, we've got a lot further than I thought we would actually, but I don't know how much. So maybe it's worth covering a tiny bit of this, not too much, and then we can do some questions for a while. But yeah, I'll set up the problem at least. So we. For the three flattenability stuff we're going to.
01:35:37.338 - 01:36:39.424, Speaker A: We remember that g is a partial tree if and only if it doesn't contain one of these four graphs from a previous result. Okay, what we want to now do is identify what is three flattenable. Now this was proved by Bob Connelly and Maria Belk about ten years ago. I think roughly what we're going to do is prove that three flattenability is equivalent to not containing one of these two miners. Okay, so yeah, as I said, some of these are actually three flattenable. Hint is these two. So our method for characterizing three flattenability, I guess in the next lecture will be we want to prove that the minimal forbidden minus for three flattenability are some combination of these four.
01:36:39.424 - 01:37:29.294, Speaker A: So we want to say that, okay, we don't have to because it could be, maybe these two are three flattenable, these two are not. But it could be that there's some hidden minor of these two in some sense, or some other hidden minor that would have been covered by these cases. So maybe something that is a lot bigger than these two, but doesn't contain these, that is not three flattable. But we're going to prove that that's not. We can't have this case. So we're going to prove that if you have three flattenability is going to be some, the forbidden miners will be some set subset of this four of these four. Okay, the next thing is then to just determine which of the above four are three flattenable and which are not.
01:37:29.294 - 01:38:14.730, Speaker A: Now this method was actually covered in basically two papers. So this one was done by Belkin Connolly. They proved that it, if you like any, the forbidden miners for three flattenability, have to be some subset of these four, is what they proved, because Belk was also working on this, proving which ones are flattenable and which arms aren't. They already knew that these two weren't, but they didn't have that in the paper. So they have the assumption that these two are flattenable, basically three flattable. But. But yeah, this was that part one was covered in one paper and the second paper was just literally proving that this and this are both three flattenable, which are very non trivial results.
01:38:14.730 - 01:38:57.452, Speaker A: It's about a 30 page paper just to prove these two graphs are three flattenable. And this is kind of the reason why flattenability is quite a difficult thing to say, because you can give me a graph and say, is this for flattenable? And I probably won't have a clue. It's very difficult to do. And this was the problem I was in three flat ability. I think I'll probably leave it there for now because we've got a whole section which is all tied together with this three flat ability. So I'll leave that for Thursday. So if anyone has any questions or discussion right now, because there was a few things in the chat, and now would be the time, I guess.
01:38:57.452 - 01:38:58.044, Speaker A: Yes.
01:38:58.424 - 01:39:13.964, Speaker E: I've got a quick question. You called this second graph on the left, K 222. What does that mean? Like, why is it called that? How did I construct it?
01:39:16.624 - 01:40:02.832, Speaker A: So you know of bipartite graphs, and you can extend bipartite to tripartite graphs. So a tripartite graph is you can separate the vertices into three sets and each one of those three sets has no edges between them between themselves. And then the complete tripartite graph will involve you have your three sets and every vertex here is connected to every vertex here and every vertex here and the same for the other two sets. So k two two is going to be. You have two vertices not connected. Two vertices not connected, two vertices not connected. And then.
01:40:02.832 - 01:40:05.084, Speaker A: But they're all connected to everything else.
01:40:06.184 - 01:40:08.040, Speaker E: Okay, I see.
01:40:08.192 - 01:40:28.184, Speaker A: So here it would be, this is not connected to this. This is not connected to this. And this is not. Not connected to this. You can also think of it as the octahedron is kind of the classic. So you have a vertex, four vertices and your other four vertices joined together. If we do that properly.
01:40:28.184 - 01:40:59.964, Speaker A: And then the edges that aren't included are basically the edge between these two, the edge between these two and the edge between the top and the bottom. So any of the opposite ones are not connected by an edge. So there's a few ways of describing it. You can describe it as k six minus three edges that aren't. None of them share an edge. There's a few other ways. This is graphically the nicest and easiest way of drawing it, as a planar triangulation.
01:41:02.744 - 01:41:03.844, Speaker E: Cool, thanks.
01:41:07.844 - 01:41:28.944, Speaker A: It also shows that you can have forbidden minors which are independent, because this graph is actually independent. So you can't just use independence. You can't say that the. Because. Yeah, okay. Independence is not going to be the same as findability, but maybe the forbidden miners are always independent. But that's not true.
01:41:28.944 - 01:41:40.664, Speaker A: That's also not true. Sorry. Dependent. That's not true. You can have dependent ones like this and independent ones like this. Sweet.
01:41:40.704 - 01:41:41.324, Speaker E: Thanks.
01:41:49.904 - 01:41:58.084, Speaker B: Hey, Sean, a while ago now you had mentioned subdividing edges.
01:41:58.394 - 01:41:59.034, Speaker A: Yep.
01:41:59.154 - 01:42:03.614, Speaker B: And that the resulting graph would still be independent.
01:42:04.394 - 01:42:07.454, Speaker A: No, the resulting graph will become independent.
01:42:08.234 - 01:42:11.554, Speaker B: Will become. Can you explain that a little bit? That confused me.
01:42:11.674 - 01:42:40.594, Speaker A: Yeah, sure. Okay, so try and get this annotate thing working. I've not tried it. Is this working? Yeah. Okay, so say we've got our, we've got our dependent graph and we do this subdivision. So this is, we have an edge. And every edge that we have, we're going to replace it with something like this.
01:42:40.594 - 01:43:16.434, Speaker A: Okay, so we've got three vertices for every two. So this was the original two vertices. Okay, now assume we've done this to every edge. Okay, what's going to happen now is. So I guess this would only work for d flattenable for d, greater than equal to two. But what we can notice here is if we delete this edge here. Sorry, delete this vertex here, that will.
01:43:16.434 - 01:43:35.834, Speaker A: So, yeah, so deleting this vertex here will get you something smaller. And if something smaller was independent in the first place, the new framework will be independent because this is basically like a zero extension, maybe without all the edges involved. Does that make sense?
01:43:38.374 - 01:43:40.394, Speaker B: No, unfortunately.
01:43:40.774 - 01:44:11.990, Speaker A: So it's kind of like, what I can say is once I've done the subdivision, I'll have some graph. If I just think of the original set of vertices I had for the first graph. So G. So say we're going from g to g. So G is just our normal graph. And if we remove all the edges and we continually apply zero extensions. So if we just do the 2d case, we just continually apply zero extensions.
01:44:11.990 - 01:44:45.144, Speaker A: So this vertex was connected to this vertex originally in G. They're now not because we got rid of all the edges and we do a zero extension between the two edges, okay, between the two vertices, okay. If we keep doing this, we'll end up with G. Now a graph with no edges has to be independent, so doing these zero extensions has to give us something that's independent. So G has to be independent. That's basically the reasoning. And then for high dimensions it's a zero extension but with less edges, so it's still going to be independent.
01:44:45.144 - 01:44:49.504, Speaker A: Is that slightly better?
01:44:49.844 - 01:44:51.624, Speaker B: Okay, yeah, I'll think about it.
01:44:52.564 - 01:46:06.574, Speaker A: If you draw it out, it becomes quite obvious, but just draw it out and think of like zero reduction. So that's removing vertices. And all you're doing every time is you're removing, moving these types of vertices that you've added. And when you do that, you'll eventually get back to a graph, that's, you'll get back to the empty graph, you'll have no edges, so you must have, if you do the process in reverse, it has to preserve independence at every step. So you must have had your graph with the subdivision must have been independent. So is there any other questions about this? Because I know it's quite complicated and I probably not explained it amazingly at times, so maybe, Mira, you could elaborate maybe for five minutes on the point you made in the chat.
01:46:12.554 - 01:46:42.284, Speaker C: Yeah, that's probably a good idea. So some of the questions that were asked, I think William asked me a question which kind of relates to the initial question about, you know, do you have to contract edges to show some of these things, you know.
01:46:43.184 - 01:46:47.084, Speaker A: Ah, yeah, so that was, that was very early on.
01:46:47.404 - 01:46:48.184, Speaker C: Yeah.
01:46:50.844 - 01:47:30.708, Speaker A: Yeah, yeah. It's quite a good question that. So, I mean, I get a bit. Yeah, so, yeah, so there's a few things in rigidity about, if you just talk about the existence of a rigid graph and stuff, and if you allow coincident points and you're just saying about any, any graph being rigid with coincident points, it's actually quite easy to show that every connected graph has a rigid realization and stuff. I'm kind of waffling. So maybe Mira, you can take over.
01:47:30.796 - 01:48:33.474, Speaker C: Yeah, so, I mean, he asked me the question, I think he. It came from him misunderstanding somebody else's question. But I think what Will was asking and maybe some, maybe you even mentioned, I don't remember who, that, you know, maybe we can just talk about edge length settings which don't make any edge length to be zero. So in other words. So one example of a question would be, if you think about showing that a graph is not too flattenable, one way to witness or give a certificate that it's not too flattenable is the setting of edge lengths. That's realizable in some high dimension, but not in two dimensions. And, you know, the thing that you would say is, well, set some of those edge lengths to zero so that you end up with just the k four.
01:48:33.474 - 01:49:22.374, Speaker C: And for the k four, it's easy to show that there's a setting of edge lengths, which Sean actually said during his lecture, which is all ones or something like that, which is not too flattenable. Now, the question would be, if I start with this larger graph, which happens to have a k four minor, but I don't sort of mimic the path contraction, the homeomorphism, by setting edge lengths to zero. Instead, I force the edge lengths to be non zero. So maybe, Sean, you can draw a slightly larger graph which has some non. Which has some. Which contracts to a k four, but has some other extra edges, and then.
01:49:24.774 - 01:49:25.934, Speaker A: Maybe something like.
01:49:26.014 - 01:49:49.634, Speaker C: And then put some extra edges there or something. Yeah, yeah. So the question would be, yeah, those ones probably don't make a difference. The ones. Okay, so the question would be whether you can give non zero edge lengths to all of these edges and still have a non flattenable.
01:49:51.054 - 01:50:20.666, Speaker A: So I was thinking about this mirror. I think it might be covered by this lemma. Possibly. I'd have to think about it. But basically the idea would be, if you say that. If you say that you can flatten every zero dimensional. If you can flatten everything with non zero edge lengths, then the ones with zero edge lengths are going to be in the closure.
01:50:20.850 - 01:50:24.426, Speaker C: Yeah, something like that. Exactly. Yeah, that would do it.
01:50:24.530 - 01:50:44.248, Speaker A: I think it is true. If you can. What am I talking about? It's just immediately true. We don't even need that. We can just use the results here. It's going to be deflatable if and only if every generic.
01:50:44.296 - 01:50:45.848, Speaker C: Every generic, yeah.
01:50:45.976 - 01:50:57.924, Speaker A: Yeah. So we've just taken a slightly bigger set, but yeah, it'd be still. Yeah, so, yeah, sorry, will, you are correct. Yeah, flat ability. So he was asking, edge length is the same.
01:50:59.184 - 01:51:39.894, Speaker C: So the answer to this is obviously yes, which is what I told him, but I said no. But the other. You could ask all kinds of other questions of the same type. I don't know whether you're going to cover this next time. I mean, going beyond deflattenability to convex, scaly configuration, spaces, single interval property, all of these things, you could ask exactly the same questions. So there's one question in the Sitaramgara paper, which I think you're going to talk about tomorrow is asking for witnesses witnessing edge lengths that are non zero for the single. For the single interval property or convexity or something.
01:51:39.894 - 01:51:40.634, Speaker C: Yeah.
01:51:43.014 - 01:52:07.184, Speaker A: Yeah. Which is a more. Yeah, yeah, yeah. My plan for Thursday, by the way, for everyone is to cover three flatten ability and then cover single interval frameworks. That's the last topic, which I will not more detail then. Which is why we brought up Klee configuration spaces earlier. Yeah, the reasons.
01:52:07.184 - 01:52:14.264, Speaker A: Yeah, yeah. So does anyone else have any more questions?
01:52:19.324 - 01:52:23.144, Speaker E: Do we know about the dimension of the Kley configuration space?
01:52:25.304 - 01:52:28.648, Speaker C: Say that again? I couldn't hear you.
01:52:28.736 - 01:52:35.704, Speaker E: The dimension of the Cayley configuration space. It's a cone, but not.
01:52:35.824 - 01:52:38.768, Speaker A: Not necessarily a cone, I guess.
01:52:38.816 - 01:52:39.804, Speaker E: Oh, I'm sorry.
01:52:41.184 - 01:52:44.328, Speaker A: It is if you've got, like, all this flattenability stuff going on.
01:52:44.456 - 01:52:44.864, Speaker F: Right.
01:52:44.944 - 01:52:46.324, Speaker A: Okay. Yeah.
01:52:46.744 - 01:52:52.144, Speaker E: Even in that case. Do you know that? So you've got a deflattenable.
01:52:55.284 - 01:52:56.556, Speaker A: G. And.
01:52:56.580 - 01:52:57.704, Speaker E: Then we look at.
01:52:58.924 - 01:53:32.884, Speaker C: Yeah, yeah. There's something called the complete Klee configuration space we defined, which is basically sufficiently many non edges in f. So that g union f is independent, is minimally rigid. Yeah, yeah. Then the dimension of the Kaylee configuration space is exactly the degrees of freedom of the framework, g difference f. Okay, so the rank deficiency in its rigid rigidity matrix.
01:53:32.924 - 01:53:38.744, Speaker A: Yeah. Good. Yeah, that's nice.
01:53:41.964 - 01:53:52.274, Speaker C: So if you just had like, a one one dimensional mechanism, then the dimension of the complete Kaylee configuration space is exactly one. I mean, one doth mechanism. Yeah.
01:53:52.314 - 01:53:52.978, Speaker E: That makes sense.
01:53:53.066 - 01:54:15.664, Speaker A: Yeah, yeah, yeah. So the single interval is going to be. Actually, I can show it. Yeah, it's going to be. We're looking at the Cayley configuration space, but f is going to be a single edge. That's what we're interested. So.
01:54:17.444 - 01:54:29.756, Speaker C: When we just say Kaylee configuration space, well, it's basically you look at how many ever edges you want. So it's going to have that dimension.
01:54:29.820 - 01:54:34.224, Speaker A: Yeah, yeah, I think that's it.
01:54:34.564 - 01:54:56.754, Speaker C: But if we say complete Klee configuration space, you're adding sufficiently many edges, independent edges, so to speak, that will make the whole thing minimally rigid. G union f. I mean, I guess he was talking about g difference f, in which case I would say g. Hopefully he'll talk about this on.
01:54:58.694 - 01:55:02.474, Speaker A: I was only going to cover the single interval case, to be honest. I guess.
01:55:04.274 - 01:55:06.450, Speaker E: I can see that's okay.
01:55:06.482 - 01:55:11.454, Speaker C: But we have that theorem about convexity of daily configuration space earlier. Right.
01:55:12.274 - 01:55:13.610, Speaker A: Uh. This one.
01:55:13.722 - 01:55:15.130, Speaker C: This one, yeah, this one.
01:55:15.162 - 01:55:36.474, Speaker A: Yeah, yeah, yeah. Um. Yeah. So I was going to stick to the single interval because we can kind of do some combinatorics, basically combat stuff. I think we've done a lot of, a lot of horrible looking maps, I guess. Nice stuff. But yeah.
01:55:38.014 - 01:55:59.428, Speaker D: I have a question. So, so if we define d, like the minimum d such that a graph g is d flat tenable? Yep, it is. What's the relation with the, you know, the matrix, the maximum, uh, like code, thread code above our graph of a.
01:55:59.436 - 01:56:03.264, Speaker A: Graph g. That's the box. Sorry, I missed that.
01:56:04.204 - 01:56:20.372, Speaker D: So, so if you define, define the, let's say the minimum d, our graph g, which is different, flat, flattenable. So the minimum d such that this graph is flattenable in d dimension, right?
01:56:20.508 - 01:56:21.264, Speaker A: Yep.
01:56:21.784 - 01:56:28.240, Speaker D: So is this any, is there any connection to the MLT of the maximum, like threshold?
01:56:28.432 - 01:56:40.604, Speaker C: Oh, oh, it's related somehow to the WMLt. I put that in that manuscript somewhere. I mean, but it's not, it's not wholly related.
01:56:41.384 - 01:56:43.840, Speaker A: It's kind of the opposite direction.
01:56:43.952 - 01:56:45.644, Speaker C: In the opposite direction? Yeah.
01:56:45.944 - 01:57:02.204, Speaker A: Flatten ability is you're taking something in high dimensions and flattening it down. But MlT is looking at when can you take something in this dimension and lift it up and lift it back up again? It's linked but it's not the same thing. There are like.
01:57:04.264 - 01:57:12.912, Speaker D: Minimum d is greater than or it's great, or equal to the minimum d such that this graph g definable is.
01:57:13.008 - 01:57:17.320, Speaker C: Yes, there is a. That inequality is there for sure. Yeah, yeah.
01:57:17.512 - 01:57:44.044, Speaker A: I can't remember. So, um, I'm trying to think. You're trying to just because you're only focusing on the, in the generic stuff when you're doing the lifting. So that probably makes everything fine. Um, yeah, yeah, but they're linked but yeah, they're not the same thing, but they are very much linked, very intertwined.
01:57:45.864 - 01:57:47.124, Speaker D: Equality, something.
01:57:47.544 - 01:57:53.240, Speaker C: I guess there's only an inequality but it's not, it can, the gap can be quite large.
01:57:53.392 - 01:57:57.044, Speaker D: Yeah, yeah, because you can see.
01:57:57.744 - 01:58:33.488, Speaker A: Okay, so this subdivision process I talked about will, you can, okay, so if you subdivide something loads and loads and load to say MLT will change. Basically if you just keep subdividing edges, you can just subdivide it. So it's just so loose. It's like a load of chains. It can go into any dimension it wants, which obviously with flat ability. I've already said that subdividing will not change the flat ability of a graph. So there are some things that don't work, some things that do.
01:58:33.488 - 01:58:42.564, Speaker A: Yeah, it's quite weird. It's an interesting question. Yeah. Yeah. So the quality, but it can't be stripped, basically. It can't be.
01:58:46.744 - 01:58:51.924, Speaker D: With this something with the dividing operation, the scat crate can be very large.
01:58:53.424 - 01:59:22.314, Speaker A: Yeah. So you, basically, the idea would be you would take something that get, I guess can't. If you have something that can't lift into higher dimensions for some generic realization, what you would then do is you would just keep subdividing the edges a lot. A lot. Like just keep subdividing it a lot and then it will be able to just lift into whatever dimension it wants. Because what you've effectively done is you turned, if you subdivide it enough, you've turned every edge into like a chain, like a cable.
01:59:22.894 - 01:59:23.318, Speaker D: Yeah.
01:59:23.366 - 01:59:46.984, Speaker A: So what then can happen is points can get closer together and stuff and you can kind of contract it and then the chains, you can just move the chain. So it's nice and, um. Nice and loose and spanning sort of thing. And this is all very linked to the MLT stuff, but, yeah. So, yeah. Subdivision will not preserve MLT. So I'm taking the long way to get.
01:59:53.284 - 01:59:57.988, Speaker C: Yeah. Because that's, that's how you. It's a forbidden minor property.
01:59:58.036 - 01:59:58.220, Speaker A: Right.
01:59:58.252 - 02:00:00.356, Speaker C: It's preserved under homeomorphism.
02:00:00.540 - 02:00:11.980, Speaker A: Yeah. So yeah. An MLT of some number is not a forbidden minor property. That's not, that's what I'm trying to say and. Thanks.
02:00:12.012 - 02:00:37.768, Speaker F: Will, can I ask a question real quick? So going back to the, think about finding a witness for non deflattenability that doesn't require zero edge links. You said it followed just from the closeness of. I forget where it was. There was that lemma you showed. Yeah, that one.
02:00:37.936 - 02:00:43.444, Speaker A: Yeah. Use this result instead, which will just give you the same result.
02:00:44.744 - 02:00:45.964, Speaker C: Yeah, that's right.
02:00:46.274 - 02:00:50.354, Speaker A: Yeah. I was just being silly. I saw this and I forgot to scroll down one and see.
02:00:50.434 - 02:00:59.254, Speaker F: Okay, so next result, deflatable. If and only if every generic is deflatable.
02:00:59.674 - 02:01:00.454, Speaker A: Yeah.
02:01:01.034 - 02:01:17.046, Speaker F: So if you take a. So if it's not deflattenable. Oh, okay. So if it's not deflattenable, then there's a generic k dimensional realization that's not deflattenable. Is that what that's saying?
02:01:17.190 - 02:01:18.542, Speaker A: Yep. Yeah.
02:01:18.718 - 02:01:23.118, Speaker C: So it can't be the case that you have to contract in order to get a witness.
02:01:23.246 - 02:01:23.878, Speaker A: Yes.
02:01:24.006 - 02:01:24.294, Speaker F: Right.
02:01:24.334 - 02:01:26.854, Speaker A: Because it doesn't have to have a zero length edge.
02:01:26.974 - 02:01:29.934, Speaker F: Right. Because a generic point won't have a zero length edge.
02:01:30.014 - 02:01:31.194, Speaker A: Right. Yeah. Okay.
02:01:31.494 - 02:01:32.354, Speaker F: Okay.
02:01:33.574 - 02:01:47.784, Speaker C: Yeah. So flattenability, the answer to this is straightforward, but you know, you can ask the same question for other things where you end up using heavily, using the reduction to the forbidden minor, right?
02:01:49.164 - 02:01:51.228, Speaker A: Basically, yeah.
02:01:51.276 - 02:02:19.062, Speaker C: So whether or not in all of those cases. So the strategy of many of those proofs is you sort of reduce to the forbidden minor and then you say, okay, set all those edge lengths to zero. Right. And now the question is, can you now say, well, well, I can find a non zero setting which will still give you whatever the property the forbidden miner had that you were using. You know, does it make sense what I'm saying?
02:02:19.198 - 02:02:29.950, Speaker A: Yeah, yeah. It's kind of linked to this idea that the single frameworks and stuff isn't a minor closed property in a way.
02:02:30.102 - 02:02:30.590, Speaker C: Yeah.
02:02:30.662 - 02:02:43.904, Speaker A: I mean you're not the talking about a graph. You're talking about graph and the knowledge. So it's already a bit dicey to call it a minor thing, but it's, yeah, it's, yeah, it's interesting.
02:02:44.244 - 02:03:17.480, Speaker F: I was just thinking, and this is maybe a little bit too specific, but when you're looking at forbidden minor for d flatten ability, we know that no single edge has the single integral property. But more specifically we know that, um, for the witness for that, uh, requires no edge length to be zero by the definition, by the minimality of your forbidden minor. Um, so I'm just wondering if that's, uh, you know, that could be useful.
02:03:17.512 - 02:03:20.644, Speaker A: At all, but maybe.
02:03:21.024 - 02:03:49.904, Speaker F: Yeah, um. Well, I'm just wondering because like if you have an arbitrary graph, then, and you have an edge that doesn't have the single interval property. I don't know. I'd have to think about it more, but it would just, you know, you may have a witness that has a zero length edge or a zero link zero entry, right? So I wonder what that says about that edge. But I don't know.
02:03:51.184 - 02:04:11.000, Speaker C: Yeah, okay. I think I know what you're saying. You're saying that somehow the minimality of the forbidden minor, which forces you so that the edge of the forbidden minor has a single interval property only if you do not contract any of the other edges, right? Is that what you're saying?
02:04:11.112 - 02:04:20.280, Speaker F: Yeah, that's what I'm saying. And then if you consider an arbitrary graph and you have an edge without the single interval property and one of those witnesses has a zero entry.
02:04:20.432 - 02:04:21.048, Speaker C: Yeah.
02:04:21.176 - 02:04:27.384, Speaker F: Then that other edge, I guess, couldn't possibly be part of the forbidden minor.
02:04:27.424 - 02:04:28.264, Speaker C: Or something like that.
02:04:28.304 - 02:04:29.964, Speaker F: Yeah, yeah.
02:04:31.784 - 02:04:34.176, Speaker C: What could be retained in the forbidden minor or something.
02:04:34.240 - 02:04:35.444, Speaker F: Yeah, right.
02:04:36.944 - 02:04:38.904, Speaker C: I don't know. We have to be careful with the quantifiers.

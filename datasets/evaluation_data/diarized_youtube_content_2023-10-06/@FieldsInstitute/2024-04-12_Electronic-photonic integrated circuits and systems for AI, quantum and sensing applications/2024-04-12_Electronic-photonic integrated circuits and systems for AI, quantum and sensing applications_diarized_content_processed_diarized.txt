00:00:00.080 - 00:00:23.176, Speaker A: And he did his actually undergraduate work at Queen's University just sort of down the road and then did his master's and PhD at MIT. And he's now an associate professor at Boston University, although he's on sabbatical this year where he's spending some time at what he called. If I'm pronouncing it correct, is it I A, how is it actually pronounced?
00:00:23.368 - 00:00:24.120, Speaker B: IRL.
00:00:24.200 - 00:00:27.692, Speaker A: IRLs. Nobody knows that pronouncing of which he's a co founder.
00:00:27.816 - 00:00:28.244, Speaker B: Okay.
00:00:28.292 - 00:00:56.370, Speaker A: And he's, he's, he's. There were a number of awards, including a fellow of the National Academy of Inventors. I'm not sure we have that. I mean, I know we have inventors. I'm not sure whether we have National Academy. But anyway, he's doing a lot of work on photonics and work on chiplets, whichever hadn't their death raised and looking forward to hearing about it. So please join me in Robin.
00:00:59.590 - 00:01:40.574, Speaker B: Let me just check in case, Let me just check a few people online to make sure that I don't leave them in the dust. Can people hear me on the, on the zoom? I think they can because the microphone is flashing. So hopefully that it is good. Let's see. So yeah, thanks very much everybody for coming and for having me and John for inviting me to visit you. So I work on integrated optics. This is I guess a quantum seminar.
00:01:40.574 - 00:02:40.954, Speaker B: And so maybe it's a little bit, this will be a little bit application level. I had too many slides and I took some device level things and put them after because I thought it'd be interesting to give sort of, you know, for discussions or whatever if people want to stick around. But I'll, I'll give you a high level perspective on what I've been doing with photonic integrated circuits. So I titled this Electronic Photonic Integrated Circuits and Systems for AI Quantum and Sensing Applications. I'll tell you why AI, because integrated photonics is being used in industry. But you know, it's not chips with zillions of components the way that electronic chips have, you know, billions of transistors. Intel sells pluggable transceivers for data centers.
00:02:40.954 - 00:03:15.350, Speaker B: And there's a chip on there, it has like four optical modulators on the, you know, huge chip that's sort of the scale of these things. And what I'm going to be talking about is sort of the equivalent of vlsi, very large scale integration integrated Platonics. And that's in a second wave that's now sort of on the cusp of Entering actual use, let's say we'll see if it actually does or doesn't. You know, it's always like near, but it's not as bad as cold fusion, always 50 years away. I mean, not cold fusion, real fusion. Different thing. Anyway.
00:03:15.350 - 00:04:05.994, Speaker B: Sorry. Yeah, yeah, yeah. But so reason why I mentioned AI is that artificial intelligence is, you know, whether you think it will have a lasting massive impact or is sort of going to be big for a little while and then sort of slow down. It is the driving force behind all of the highest performance microprocessors and the scale of compute being installed. In data science. People are trying to train and fine tune and then run these large language models and other AI systems. You know, kind of like Google was trying to do in the mid-90s for search zillions of people putting in queries.
00:04:05.994 - 00:04:57.372, Speaker B: And now you want to have these LLMs basically sort of put this machine capability into various jobs. So optics has a role to play here because there's, you need a huge amount of computation and you need a huge amount of data flow. Because processor chips add and multiply. They don't move data from the multiplier to the memory where it's sitting there. Memory chips are separate and you huge bandwidth between processors and memory. So in classical, if anybody does scientific simulation, you'll know that takes a lot of coding and you love it when you know your memory is right next to your processor and when your processor has to go to the next processor's memory already, that's way slower. And that limits the scale of what you can do.
00:04:57.372 - 00:05:47.032, Speaker B: And with these AI applications, you really basically want the whole data center to be one large processor. And that can only be done with optics. And you cannot use these pluggable transceivers or this scale of optical communication equipment that's used for, let's say, fiber to the home or even for data centers where you go from one server to another server. And that's because the whole conversion from the electrical signal domain to the optical signal domain uses. So they go to high speeds, the signal is very weak. Then they use a lot of DSP digital signal processing to sort of, you know, get signal noise ratio or the bit error rate down. And what that means is the data throughput is huge or is fine, but.
00:05:47.032 - 00:06:15.878, Speaker B: But there's a large latency because you have all this computation that you have to do. And so you have to strip away all of this stuff that costs you both latency and energy. If you want to get terabits and terabytes out of every processor package and between all CPUs and integrated optics has a big role to play in this. So I'm going to tell you a little bit about it probably. And so I know there's a lot of quantum people here, and this is a quantum seminar. So at the end I have a quantum story, something that I'm working on. But actually I'm not a quantum person.
00:06:15.878 - 00:07:03.796, Speaker B: I've spent the last almost decade trying to learn more about it, just in the process of, you know, trying to contribute a little bit. So let's see. Yeah, so, okay, I don't need to do the Moore's law thing except one interesting fact. So in the early 90s, the world's fastest supercomputer, that's the red line, was as fast as your iPhone is in your pocket. Just to illustrate the scale of improvement of transistors. And this is the sum of all the computers. And you know, another way to look at this is how many transistors are on a single piece of silicon.
00:07:03.796 - 00:07:36.630, Speaker B: By the way, single chip can only be 2 x 3 cm in size. That's all of the infrastructure, trillions of dollars invested. Our optical equipment projecting a mask down to an inch by inch piece of silicon. So if you want more area, you have to make multiple separate chips. There are now companies like Cerebras and I'll show you a picture making these wafer scale processors where they sort of never dice up the chip into separate chips. They stitch together and try to make an interconnect between all these little radicals on the wafer. But these are the exception of the rule.
00:07:36.630 - 00:08:12.822, Speaker B: But anyway, huge increase in the count of transistors. The only reason why I want to show you this is that's happened in part by reducing the size of the transistor from you know, five microns to five nanometers, factor of a thousand in 25 years. And you know, that's what used to be a Mosfet looked like this and you know, then kind of like this in 45 nanometer technology. So this is the polysilicon gates, the crystalline silicon body of a transistor. So you have source drain and this is the channel. And you apply voltage here and you know, here the, this channel becomes conductive or not. That's how MOSFETs work.
00:08:12.822 - 00:08:53.252, Speaker B: And you get a billion of them. And then Nowadays the latest technologies, 3nm are gate all around so that you can, you have basically a channel going this way and you apply a voltage between the middle and the outside. So you have the the cleanest, on off, switching in the smallest size. So anyway, three nanometer transistors. So factor of a thousand. What I wanted to say about this is just to compare it to integrated optics, which is so ring resonator, somebody said the word. That's a kind of a building block of, let's say, a large class of integrated optical circuits.
00:08:53.252 - 00:09:28.360, Speaker B: And the first ones were thought up already in Bell Labs in some patents in the late 60s. And people played with them. But they can become small. You can take tight turns when you use high index contrast. So silicon surrounded by an oxide as a large index contrast system, 3 to 1 refractive index ratio that allows you to go to micron scale rather than sort of centimeter scale resonators. The first one was demonstrated in the mid-90s. So I showed you the transistors in mid-90s.
00:09:28.360 - 00:10:02.270, Speaker B: And then if you look at transistors around today, sorry, rings around today, 5 micron radius. 5 micron radius. So there's no scaling. And it's because these are, you know, their performance is determined by Maxwell's equations. They work on the scale of the optical wavelength and the refractive index determines the confinement of solid. But there is kind of a scaling law that has changed what we can do with optics. And that is, you know, everybody that, that does something in physics that uses the Fourier transform.
00:10:02.270 - 00:10:39.910, Speaker B: So this was, you know, thousand x reduction in the spatial scale. We take the Fourier transform. That would be the spectral domain. The first rings were Q q factor of 250 and you know, now or, or 500 and I have 500,000. So there's been a change in a factor of a thousand in the optical loss in the optical line width that you can, that you can realize. And you know, for example, the band pass filter bandwidth that you can create. And this is sort of a performance metric for what you can do.
00:10:39.910 - 00:11:25.830, Speaker B: You don't need a, you know, a 1 GHz line width only. If you want to make a 1 GHz filter, you need a 1 GHz internal intrinsic line with that's sort of descriptive of the losses inside. Even if you want to make a 50 GHz bandwidth filter, but with low loss, the sort of ratio of the bandwidth to the intrinsic line width tells you something about the performance level of the device. So you can. But it also limits sort of the ultimate line. So there are optical communication systems where you can make band pass filters. Out of these, you can make optical modulators and detectors that are wavelength selective and compact because you wrap around sort of a lot of optical path length into a small physical space and so on.
00:11:25.830 - 00:12:09.148, Speaker B: And actually, you know, in silicon photonics you can even make. These are resonators that have cues of the order of 5 to 10 million. So even higher than this still in silicon and sort of CMOS platforms. I want to put up my advisor because he died 30 years ago or 20 years ago last year. And I just thought it was interesting because he got into integrated optics in the early 90s when you know, the time I showed you by the way, if you're interested, very interested to learn just some of his thoughts. He had prepared an after dinner talk for one of these Gordon Nonlinear conferences for that year and he died before he could give it. But he had it prepared.
00:12:09.148 - 00:12:41.380, Speaker B: So we sent it to this Journal of Modern Optics and Bob Boyd somebody mentioned they were working with. Bob Boyd was editor at the time, so he just had to publish. So I think it's interesting, I just thought it sort of side comment but. So this was one of these early papers Brent Little and House wrote on these ring resonators in 95. And Brent asked House at that time, well, you know, when do you think this will be an industry? And the answer paraphrase roughly was about 10 years. It hasn't been quite 10, it's been almost 30. So you know, things take longer than you think.
00:12:41.380 - 00:13:13.800, Speaker B: But okay, so I'm going to skip some of these things. I told you the story. Oh yeah, that's my group at BU and some collaborators. So let me. So I'll tell you a little bit about more about this AI stuff but just a bit about kind of research I do. So I'm a device designer at heart and a theorist at heart. So maybe I feel some camaraderie with you.
00:13:13.800 - 00:14:20.520, Speaker B: But I spent the better part of the last 15 years working on devices that enable some sort of system demonstration circuit and system level solution for this or that problem. And so I'll tell you about these data communication but some of the other things we're doing are also not digital data communication, but analog links where you take an RF signal and put it onto an optical carrier. And that's a way to for example 5th and 6th generation wireless, when you have many antennas on an optic, on a RF based array antenna which is be forming, trying to find multiple user cell phones, things like that, you would have to have. There's a lot, it takes a lot of power. Optics can help that. Then one interesting thing, with the coming compute demands, it's a little bit more pie in the sky is superconducting electronics based on superconducting logic. So Josephson junction based so called RSFQ logic is orders of magnitude more efficient than CMOs.
00:14:20.520 - 00:15:04.082, Speaker B: But there's no memory for Kelvin and optics. If you can get the data out, you can basically make upon Neumann architecture computer out of this technology and then tell you a little bit about quantum electronic photonic systems on chips. So this, all this stuff has to do with combining optics and electronics. This thing here is about making optical apertures of a new kind, sort of optical space arrays, but maybe in a different way than people do it. But I won't have time to talk about it today. So I have my slides after the talk. I just pick and choose I guess just some pictures since I won't be talking about individual devices of the kind of things we're doing.
00:15:04.082 - 00:15:35.228, Speaker B: So we build, you know, ring resonator based modulators out of silicon. So this is a MOS capacitor modulator. There's the gate of the transistor which is a 1 nanometer thick oxide here. That's where the charge collects and the light goes around. And so if you put in charge, you know, it moves the resonance. And so that's how we electrically control the resonance and enclose information. And then we built for example gradings that send light in only one direction by engineering multiple levels here and things like that.
00:15:35.228 - 00:16:26.880, Speaker B: So I was just telling Boris somebody's interested. The adiabatic evolution is a big things in many physical systems. In physics, in optics, we use adiabatic evolution often to build devices that are invariant to different things. And this is a device that's a new kind of adiabatic evolution concept that doesn't occur sort of in nature because you have to specially engineer how the potential evolves, evolves which doesn't quite happen by accident. So I call it rapid adiabatic evolution. So I have slides on this too, but I won't talk about it now but and then magic teas, new types of cavities and things like that. So it gives you an idea of what my students work on.
00:16:26.880 - 00:17:27.777, Speaker B: Okay, so the three topics I chose to talk about today, well first give you a bit of an introduction to monolithic integration of electronics and photons. Kind of an applied topic. But I think it's interesting for you to know what's happening and, and then I'll, I'll give you a summary of this millimeter wave RFB forming, the cryogenic interconnects and the quantum. So I don't skip over the millimeter wave quickly and, and focus on these two because that might be what's most interesting to people. I'm not diving deep into any one device, but yeah, we can. So you know why Monolithic integration on a single chip of transistors and photonics. This, this is by the way, something that's unique in what I and a colleague of mine who's at Berkeley, Vladimir Stanovich and, and another guy at mit, Bridgie Bram, did that's sort of unique in, in our field at least, at least was.
00:17:27.777 - 00:18:18.146, Speaker B: And now it's being done more and may maybe it'll be supplanted soon and sort of run out of fashion again. But most of integrated optics, you design photonic devices, you either build them yourself or send them to a foundry, but basically the chip has only optics. And we tried to build optical devices in an existing CMOS foundry process that can yield a billion transistors on a chip. And the reason for this is that optical components, especially resonators, are extremely sensitive to everything. So you need to have a control system around every resonator in order for this to be able to scale to the hundreds of devices to make a whole system up chip and do something useful. And so, you know, there's precedence of people messing around and trying to do things in CMOs. So let's give you here a little bit of a timeline.
00:18:18.146 - 00:19:08.182, Speaker B: CMOS means digital transistors, MOSFETs, you know, a bunch of them on a chip. But basically all it is is, is you know, a bunch of transistors and then a bunch of dielectric and metal levels that interconnect them. Because you have only one layer of transistors to create complicated circuits, you cannot do it with a single level of metal interconnect. There's like seven or eight levels of interconnect in a, in a modern microprocessor just for power delivery and all the interconnection to create the circuits. So but that's what you got. And then people said, well, let's use these back end interconnects to make inductors. So it's not really even an idea, but it was an idea in the sense that it enabled in RF circuits you need inductors and you know, you'd have to sort of put them off chip on a board or something like this.
00:19:08.182 - 00:19:49.012, Speaker B: But when you once you could make an inductor in the chip, you could make complicated and scale to many RF circuits. And so people made CMOS radios. And even though bipolar technology was the sort of the go to technology for analog circuits. CMOS took over once you could do this because it's inexpensive. And so all your cell phones have CMOS radios, not bipolar chips. And then this is not even that long ago, like early 2000s people built transmission lines. And so then they could do millimeter wave amplifiers and things like that.
00:19:49.012 - 00:20:43.954, Speaker B: And so what this enabled is for example, the next generation wireless technology. Both for military things like radar and whatever and for communications like Ericsson puts up these, you know, towers for the, for wireless they're trying to go to higher frequencies so they can serve more users with higher bandwidth and beamform and find your phone and things like that. And so that's going to be in the sort of 20-80 GHz tiny frequencies, right. And so, so a lot of these components will be on silicon chips. So the idea was can we put optical modulators, detectors, things like that in a process that can yield a billion transistors? And why do it? Because you can then build whole systems on chip. So we spent a decade taking out different chips and, and that was pain, a painful experience. But I'll just show you the, the outcome.
00:20:43.954 - 00:21:40.090, Speaker B: By the way, it's a hard thing to do a PhD in because you know, when I was doing a PhD, you learn Maxwell's equations, you figure out how a ring resonator works. You a couple mode theory level, you do like maybe circuit level models and design of the component that you want. And then you design the devices, somebody else does the layout, fabricates it, you've got your device, you measure it. That's it. If you need to build a system on chip. Now my students, besides these things learning E M have to learn about CMOS technology and transistors and process design kits and they have to interact with the foundry, understand what the foundry engineers are talking about and they don't understand optics and things like that in in turn and all kinds of things to do with chip design. So anyway, there's a lot if you want to, to be able to design one of these electronic photon systems, which makes it hard to both, you know, do deep work on a single device and, and push it up to like a system level.
00:21:40.090 - 00:22:48.110, Speaker B: But that's the kind of thing we have to struggle with, I guess. Anyway, if you cut one of these chips in a cross section, here's the NNP type MOSFET transistor. And so we're reusing the either the body of the transistor or the polysilicon gate or both in the case of let's say some of the grading couplers also for, for light. So and here you can see a cross section of that MOS capacitor ring modulator that I mentioned to you. So, so this was kind of actually a hacker activity in the sense that IBM didn't know we were doing this in their fab. We just would meet the design rules, go on a multi project wafer run along with other writers who are circuit design groups that do their PhDs on new types of AOD converters or whatever circuits people do. And we would design this, meet all the design rules, pass the design rule checks, chips would come back and the only thing we have to do is remove the substrate, the silicon substrate, because the oxide under the waveguide was too thin.
00:22:48.110 - 00:23:40.160, Speaker B: If you want to confine light in the wave guide, you need a couple microns of oxide at these wavelengths so that you don't couple into the high index substrate and radiate all the light down there. And that's done in silicon photonics kind of fabrication facilities. But in CMOS technology you need the silicon substrate nearby because all these transistors need to conduct heat into the substrate and you don't want to put a huge oxide thermal insulator in between. So anyway, so that was sort of on the way. But then eventually we started, we started this company that John mentioned and we started working together with Global foundries who bought IBM's semiconductor business in the meantime. And so this process became translated and they optimized it for photonics. So now it's sort of, at the time we didn't have germanium, which is an absorber at 1.5
00:23:40.160 - 00:24:27.580, Speaker B: micron wavelength to use as a detector because you need both a transparent material for wave guiding and an absorbing material for, for, for detector. So turns out that the P type mosfet had a silicon germanium alloy in the source and drain regions to squish the channel and increase the mobile carrier mobility in these small process nodes. And we reused that as a detector, but you had to use it at these weird wavelengths, about 1100-1200 nanometer wavelength, not quite the telecom wavelengths. So then they added germanium. And so you have these transistors, they don't actually work quite as well in photonics because you know, trade offs when you, when you add sort of a specialized photonics process. But anyway, now you can, you can design in this process. It's cool, commercially available.
00:24:27.580 - 00:25:11.578, Speaker B: And so this is kind of old worth now let's see what's going on. So it's been a while already, but so we built a microprocessor as a demonstration. So it has two cores and then here you have integrated optics that make the microprocessor talk to memory. And this here is sort of an emulation for memory. It's CPUs talk to DRAM memory, but this is static RAM because DRAM are these long capacitors. Anyway, so we had two of these chips and they would talk to each other. And so the way that it would work is these two vector cores.
00:25:11.578 - 00:26:05.592, Speaker B: By the way, anybody heard the company Sci Fi, it has a presence here, they do new kind of architecture of processors. So their first processors are these because we had free space and said, hey, you want to put some cores here? We'll put optics next just by accident. But so what you see in the optics here is actually this is not visible very well, but it's a waveguide. And then it has 11 ring based modulators over here actually here you can see one. So the light goes in, modulator goes out and then this is a tap that if the light is on resonance, a little bit of it goes here to a photodiode so that we know that there's light in the resonator. And then there are circuits here that lock the cavity, that thermally tune its wavelength so that it stays on the wavelength of laser. And I'll explain to you in a minute why, why, why you do that.
00:26:05.592 - 00:26:39.170, Speaker B: And then these are drivers for the heaters and for the high speed data signal. And this here, this grass stuff is digital logic and so on. So then you replicate this 11 times because the light coming in is 11 wavelengths. So wavelength division multiplexing on one optical fiber and it goes through, it comes out. So this was the world's first microprocessor that spoke to the outside world using optical ringage. And so I don't know if I have. Why do I click? Let's see.
00:26:39.170 - 00:27:11.452, Speaker B: Yes. So, so this is sort of two of these connected. And so you know, we could run hello World, Boot Linux and I made a little rendering demo and things like that. So there's a seven minute video, you can watch about it. So then then from 2015, around that time we started Irlabs. And this is a chiplet that I'll show you in a minute that basically is next to a high performance processor. In this case it's Intel's highest end FPGA from a couple years ago.
00:27:11.452 - 00:27:51.814, Speaker B: It's called the static stand. Now the newest versions are called Agilex series. Anyway, but so these are FPGA field programmable gate Arrays which are programmable processors. And so they, they need a lot of bandwidth. So there are five of these chiplets. And what they do, I'll show you in a, in a next slide is all the electrical domain data here gets encoded onto optical and comes out of optical fibers through these chiplets. So the big thing happening in microchips these days is this chiplet paradigm, which is not just for optical I O, which I'm talking about here, but for various functions.
00:27:51.814 - 00:28:37.570, Speaker B: For example, and it started a few years ago, but recently with AMD saying TSMC is the world's biggest foundry. We're gonna build digital logic in 3 nanometer, the 3 nanometer node. It's super expensive. So we, we should not be taking up chip space with IO functions or memory or whatever. So the, they, they have one chip which is the memory, another chip which is the digital, digital logic, another chip which does something else, or the GPU and the cpu, for example. And so chips have, processor chips have gone from a single piece of silicon in just a package with pins to multiple silicon chips on a substrate. So advanced packaging.
00:28:37.570 - 00:29:03.578, Speaker B: And so these little chips around are called chiplets. So they can be, for example, so called HBM High Bandwidth Memory. So if you watch Nvidia a couple of weeks ago gave a talk, I'm sure everybody's aware from the TV news and stuff that Nvidia went over a billion in valuation six or seven years ago. They were 10 million values. And they announced their. So Jensen Huang, their CEO, gave like an hour and a half talk or something. So if you can sit through it, you'll see what they're doing.
00:29:03.578 - 00:29:40.238, Speaker B: So they, they unveiled their latest GPU graphics processing unit, Blackwell. And if you look at that, you will see it's a, it's a big board and there are two big processors, but they're actually packages. And then there's like a chip and lots of little memory chips around. So that's what these chiplets are. And so we're building an optical communication chiplet that can basically make it have no difference whether you're talking to another processor next to you or a football field away. Because once you pay the price of going into the optical domain, optical fiber losses are 0.2 dB per km.
00:29:40.238 - 00:30:05.030, Speaker B: So you know, 100 km, 20 decibels, okay, but 5 km, 1 degree, that's not so it's a pretty, pretty large area. You can sort of make synchronous. There is a latency of about a nanosecond per meter or so. And so you know that's that is something you take into account. So. Oh, I see. That's what happened.
00:30:05.030 - 00:30:42.898, Speaker B: Let me just skip through this stuff. So yeah. So okay, one of the. So why. Why optical in a connection? So one you cannot make the processor bigger. They already are taking up the whole silicon reticle and you need more compute and it needs to be all seeing all the memory sort of as local memory. The other part of it is that the total power that one chip package can handle has been growing but not as fast as the power for communication of all the data.
00:30:42.898 - 00:31:06.168, Speaker B: You because the processors get faster and as they can multiply and add more. For every multiply and add you need to bring in the X and Y and take out the Z answer. You know, the memory is where it goes. So you have, you need more and more bandwidth. And as that's been growing, that's actually been going faster. So this is 20, 20 something. So basically all of your power that the package can handle is going to be IO.
00:31:06.168 - 00:31:31.898, Speaker B: So that doesn't work. And so you need a new technology to to support this scaling. So and the reason to go optical is that the way electrical communication goes to higher bandwidths is higher speed and that's very painful. And it frequency is already of a few tens of gigahertz. Metals become lossy. You don't can't go a very far distance. But more than that you have to go from the.
00:31:31.898 - 00:31:55.504, Speaker B: You know, all the processors in 2005 were going 1 or 2 gigahertz. All the processors in your laptops right now still 1 of 2, 3 gigahertz. So that wasn't the case before 2005. There was a more slow scaling and then because power it stopped. And then you went to multi core and all these other other ways to keep getting more performance. Right. More, more transistors on a chip, but not higher pot frequency.
00:31:55.504 - 00:32:35.994, Speaker B: So increasing the clock frequency costs a pound. And with light you don't have to increase the clock frequency. You can have multiple wavelengths and they can all go down one wire and you can go an infinite distance almost. And so that's the reason why it works. So the way it works is go from one processor parallel electrical connections go to this triplet and then this data gets modulated onto wavelengths and then goes optically to another chip. The light source for this is not in a silicon chip. Why silicon doesn't emit.
00:32:35.994 - 00:32:57.926, Speaker B: It's an indirect band gap. Semiconductor people are trying to put three, five semiconductors in here. Intel does that. What we're doing at IR Labs is a remote light source. The reason for this is that this here is in the package together with a microprocessor. This is a very high power thing. We just talked about the limits of what a package can handle.
00:32:57.926 - 00:33:36.290, Speaker B: So you want all of the power you expend to be spent on computation a laser wall plug efficiency, meaning the fraction of power out in light compared to what you're drawing from electricity to power, it is 10% at best. So most of the power in a laser is heat. So it's not a very good thing to put in here for power efficiency. It's also not a very good thing to put in here into the power processor package for the laser's life because that's the thing that fails most easily. Lasers don't like high temperatures. So so remote light source, just like, you know, you put in a. You plug it into the wall, you also plug it into a laser.
00:33:36.290 - 00:34:04.740, Speaker B: And so this is what this whole thing looks like. So you have the device level, then you have the photonic circuit level, then you have this chiplet. And then this is what it looks like when it's when that CPU with these chiplets is packaged. So there's a little fiber ribbon here that takes out this data. But I'll show you what the chiplet looks like over here. So this is next to the cpu. So just take this away.
00:34:04.740 - 00:34:41.282, Speaker B: This is the electrical interface. This, these are these ring resonator optical, we call them macros. I'll explain. And then the fiber chip coupling. So this thing here just takes electrical signals and basically translates them sort of there's some protocol and whatever just translates it to basically voltage that drives each of the modulators. And then here you see 1, 2, 3, 4, 5, 6, 7, 8 modulators. Each of them having sort of these circuits that lock the modulator to its wavelength so that you have an eight wavelength communication system.
00:34:41.282 - 00:35:02.924, Speaker B: And the way it works is light enters here with eight wavelengths. Each of these modulators encodes a different data stream. Let's say you have a. Like a one byte comes in at a time. So each bit goes to a different modulator. Let's say. So it's parallel, right? Bus goes in here and so you encode that data and then it comes out and that's the transmit to the other direction.
00:35:02.924 - 00:35:31.646, Speaker B: And then the other guy sends you data and that comes into the receive. And then there's another set of eight detectors here. So this is called one macro. You can do transmit and receive. So let's say right now this chip is 32 gigabits per second data speed for each modulator times eight wavelengths. So that's 256 gigabits total times then eight fibers. So there's eight of these replicated across the chip.
00:35:31.646 - 00:36:14.780, Speaker B: So you have 24 fibers. And so that's, that's 2 terabits per second for one of these chiplets. Two, two out, two in. And then you can put 10 of these around. So you can get 10 terabits out of one chip package. So why is energy important? Energy is important because once you have a terabyte per second, if the, if this costs you, let's say ten picojoules per bit. Ten picojoules per bit times one terabit per second is ten E minus twelve times one E twelve, that's ten watts, right? And so if you, it costs you fifty, fifty watts.
00:36:14.780 - 00:36:43.026, Speaker B: So the point is, it scales quickly. So we have 10 terabits times 10, 10 picojoules per bit, which is the typical. 20 picojoules per bit is actually the typical electrical communication cost. That's 200 watts. These CPUs are only a few hundred watts. So you know you're going to eat all of the, your energy budget just with the, with the communication. The optics right now is at 5 and it can go down to a couple of picojoules.
00:36:43.026 - 00:37:30.886, Speaker B: And so that's, you know, that's, that's why, why, why is it low? So one of these little ring resonators is a PN junction, which is a capacitor, like, you know, PN diode has a depletion region and has a junction capacitance. So when you put a voltage on it, you need to store charge on it. And so the energy that you use to keep the charge there is a half CD squared. And then when you go from a one to a zero, that charge goes, goes, gets burned through some resistance, then you do it again. And so the, the energy per bit is a quarter CV squared, because half CV squared is the energy. But then half the time you're not doing transitions. When you have random data, you go from a one to a one, from a zero to a zero, right? Anyways.
00:37:30.886 - 00:38:21.560, Speaker B: And so if you make this capacitor large, the energy per bit is large. If these modulators are tiny, then the capacitance is tiny. And so the energy per bit to drive this is small. So that's why going from larger optical devices to tiny ones helps you with the energy profit. And so here you can see this laser, you know, there are eight fibers and each one has eight wavelengths. So one interesting thing about it, I don't want to talk about this in detail, is if you want to stable, stabilize the laser wavelengths against temperature changes because there might be from 50 to 120 degrees C things like that. And these are semiconductors, you know, the refractive index changes, self heating effects, whatever.
00:38:21.560 - 00:38:57.810, Speaker B: So you might have to put it on thermoelectric cooler. Once you put it on a thermoelectric cooler, that's a, that's a fridge. That's a whole other huge amount of power you're consuming. So we let the lasers float freely and then the little ring resonators are tracking them. So they're basically at all times following the laser wavelengths. And that's how we get away from the energy costs of, of, of keeping laser wavelength stable. And, and yeah, this is, you can see here for example at 20 and 100Â°C how much the wavelengths shift like several channels worth.
00:38:57.810 - 00:39:57.920, Speaker B: Anyway, so that's, you know, that's what I O labs is doing. And you know, now it's not in these GPUs but in the next four to five years these, this kind of technology might be, or, or it might be out of business and I'll be back teaching something else, you know, but, but now is the time that this is needed. So I think it's interesting just to share with you that there is a place where integrated optics and large scale integrated optics, many components on a chip like this has a relevant place. And you know, there's still, if you go to like optical fiber communication conference, which is a big optical conference, you know, there's still sort of debates about, you know, whether this, this or that is better, whether integrated optics is needed now or later. But I think nobody doubts that optics will have to come in. Sort of electrical solutions have been gone to, for, for a while and they're, they're definitely acknowledged to be out of juice. Let me see here how I'm doing with time so that I know how to plan mine because I'm chatty.
00:39:57.920 - 00:40:08.268, Speaker B: Let's see. Oh wow. Yeah, so okay, so. Oh yeah, just so. Yeah, a little bit of bragging too. So, so this is here. Well actually this is interesting.
00:40:08.268 - 00:40:39.862, Speaker B: So this is two of these light sources. This is built together with Intel. So this is one of their FPGA chips. And then there are these two chiplets like I showed you. And so the light source goes here, goes in here, powers up on these chiplets and then the chiplet, you can't see it here, but the fiber comes out to this port. And so you just plug in a fiber connector, which is actually a fiber array. So it's like the 24 fibers, or actually not 24, some of them are here.
00:40:39.862 - 00:41:32.098, Speaker B: So 16 fiber connectors and that goes between two of these. So that was demonstrated last year and it was actually demonstrated to Joe Biden at the White House in November. There was this American possibilities demo day and they picked like six microelectronics technologies. Anyway, so, okay, so that's, that's what's happening at I Labs and that's digital data communication using integrated outlets. So I'm gonna just give you a high level overview of the RF because I want to spend more time on the quantum superconductors. So with RF technology, this 560 wireless people are going to beam forming with, in, in the radio wave regime. So 40 gigahertz, 75 gigahertz or 28 or whatever.
00:41:32.098 - 00:42:30.018, Speaker B: And so phased array antenna, you know, is, is a device like this where you basically have many elements and if you phase them up in a certain way, you, you emit all the light in a narrow beam in a certain direction. You can steer that by controlling the patients. So the idea is, you know, you're in a football stadium and there's 10,000 cell phones and so there's a few towers and they're trying to manage all of this traffic and everybody's watching videos or recording videos and posting on Facebook or whatever, you know. So, so the idea is you, you have, if you want to do beam forming and you have, let's say at these high frequencies, this millimeter wave. So the wavelength is a millimeter order. So you have to put the elements a millimeter apart and the aperture is yay size, let's say. So you know, a thousand elements, 32 by 32 or something that's, that's actually like that minimum.
00:42:30.018 - 00:43:07.106, Speaker B: So a thousand elements, a lot of cables and a lot of control. But moreover, let's say you're receiving a weak signal at this antenna from somewhere. So you either have to transmit that signal at 60 gigahertz. That's hard. Electrical signals are lossy or metals are lossy at these frequencies. So then your other option is to have communication links, like digital optical communication links like just talked about. But then you have to put an analog to digital converter, a thousand of them, which is going to cost you a thousand A to D converters and also the power for a thousand A to D converters.
00:43:07.106 - 00:43:45.936, Speaker B: And that's on the order of kilowatts. So you have like this little antenna and then you spend a kilowatt on the A to D converters. And so the idea of this project, and you know, it's a little bit further out, is to use similar kind of wavelength multiplexing. So you have many wavelengths coming here, 16. And then you divide this thousand element array, 32 by 32 elements into little patches of 8 by 8 elements times 4, times 4. And each patch gets an optical fiber. So this 8 by 8, each two rows is actually sort of unwrapped into 16.
00:43:45.936 - 00:44:18.514, Speaker B: So 16 by 4 anyway. But we need the analog signal from each antenna to be imprinted onto a, an optical signal and processed somewhere in the central office. And so if you use multiple wavelengths, you don't have so many fibers. And then, okay, maybe it's not realistic to have, I mean, people work on optical frequency cones as soon as they make them, you know, power efficient. Maybe you can have only one fiber and 64 wavelengths. But in the foreseeable future, maybe 8, 16, 32 wavelengths. So maybe you need to use multiple fibers.
00:44:18.514 - 00:44:54.400, Speaker B: But then you need, you use these ring modulators because they are wavelength selective when in imprinting information. So this modulator tunes to one wavelength, will only imprint that the drive signal onto that wavelength. Then the next one will imprint the next antenna signal onto the next wavelength, and so on. And so lots of requirements for linearity and so on when you try to transmit an analog signal. That's why it's a hard project. But so we're using coherent detection here. We split the lights, send some of it out here, and then interfere to have a sensitive detection of what comes back.
00:44:54.400 - 00:45:30.908, Speaker B: So it's sort of tricky because you're both trying to do sensitive detection and high frequency, meaning you want both speed and sensitivity. You don't have a lot of integration time, but you need to be sensitive. So the one thing that I think is interesting about this just to mention to you is here we use a dual cavity modulator. And the reason for that is that this is for an RF signal. It's coming through the air, it's at 60 gigahertz and maybe it has a few gigahertz bandwidth around. That's unlike data communication at, let's say, 10 gigabits per second from a processor, which is baseband. So it's just ones and zeros.
00:45:30.908 - 00:46:08.382, Speaker B: And so if you look at the Fourier spectrum of the data signal of 10 gigabits, it takes up all the frequencies from DC up to 10 gigabits. But in an RF signal, from 0 up to 58 gigahertz is empty. And then from 58 to 62 is where the spectrum is, and then the rest is empty again. Right. So it's a narrowband sort of signal. And so if you use a ring modulator, what happens is it has a resonance. And you need to put both the laser carrier and then the modulator, when you drive it at 60 GHz, it creates a sideband 60 GHz away.
00:46:08.382 - 00:46:44.752, Speaker B: The higher the frequency, the, the further apart these two are. So, but the problem is you want to use a high Q resonator to enhance this process. On the other hand, if you use a high Q resonator, it gets narrow and you can't put either the pump or the sideband in them. So you're kind of between a rock and a hard place. But what we do is we couple two resonators. And what happens, just like two quantum wells, when you couple them, you split states here, you couple these, you split resonances. And if you couple them just the right amount, you Split by exactly 60 or 70 GHz or whatever your carrier frequency is.
00:46:44.752 - 00:47:14.348, Speaker B: And then the line width can be as narrow as you, as your losses will allow. And you keep enhancing efficiency, conversion efficiency. The only thing that limits you is the modulation bandwidth on the RF signal. The, you know, the, the data, and that might be a couple of gigahertz. So basically you want this one to be at least a couple gigahertz wide. And then this one can be super narrow because the signal coming in is just a CW laser. And, and that's how you squeeze the most out of sort of the resources that you're given, you know, with the optics.
00:47:14.348 - 00:47:41.354, Speaker B: So that's just a little different in that regard. And so I'll just show you what we're doing. Yeah, this is, let's skip this, some other things. So this is a low noise amplifier. So the signal comes in, this is a circuit low noise amplifier. And then it drives one of these modulators. And what we're showing here is just the noise figure in the final RF link versus the laser power.
00:47:41.354 - 00:48:06.486, Speaker B: So you know, you want a low noise figure, you want about 10 decibels. We're at 25. So it's not great. It's the first, first result. So that's, that's this, and this is a, three resonators. Actually the middle one is a passive tunable one. So it allows us to, to adjust the splitting between these two that are modulated cavities and that are coupled.
00:48:06.486 - 00:48:24.572, Speaker B: So that way, because you don't know exactly which frequency the low nose amplifier will peak at. And so you have to make it a little bit adjustable so it's still. That's what's going on here. Let me see. I probably ran out of time. One second. It's a 158.
00:48:24.572 - 00:49:00.364, Speaker B: Oh perfect. So I think this is a, this is an interesting topic. This, these cryogenic transmitters we worked on optical communication links. But for me the interesting thing is actually the bigger picture here. So irpa, the Intelligence Advanced Research Project Agency, you know, invested a lot of effort into developing cryogenic electronics for different things they're used in like as radar amplifiers or I don't know, whatever. But these circuits are small scale. There are a few companies that make them based on Joseph's injunctions.
00:49:00.364 - 00:49:41.964, Speaker B: There's a guy Lykarev who started singleplux Quantum logic based on the magnetics box quantum. And the interesting thing is based on Joseph's adjunctions instead of, you know, field effect transistors and silicon. The cool thing is that the energy for one of these things is like 7 orders of magnitude lower than CMOS. But it has to work at 4 Kelvin. So you have to put it in a fridge. When you put something in a fridge and it burns energy to keep it at four kelvin you have to pay a thousand watts powering the fridge for every watt you dissipate in the fridge. So, so but that's still three orders of magnitude.
00:49:41.964 - 00:50:03.286, Speaker B: So you, you're back to four. And when you, you know, all the non ideal things and whatever, there's still a couple of orders of magnitude to win there. And that's cool there, there are foundries for this. Like MIT Lincoln Lab has a foundry. You know, these do injections are like 10 by 10 microns. They're not 45 nanometers in size. So like the same size chip would be, you know, the size of a, this room instead of this size.
00:50:03.286 - 00:50:51.526, Speaker B: But that's a few generations of, of improving this and, and you know that can be fixed. And so the cool thing then is can you build a supercomputer out of this? Because the way that the Department of Energy works is they, they go, okay, we have a 20 megawatt budget. Whatever you can do in this budget, go for it. So it's sort of power constrained. You, you put your computer next to a, you know, a hydroelectric power plant and of Nixon Power Dam in Oregon in Gulfar. So the question is basically, and you know when this research and superconducting logic was starting in the 80s and 90s, people were thinking, well, you know, I'm not going to put like a cryogenic cooler in my laptop. But now everything's in the cloud, so who cares, like whether it's a rack of LA servers or like, you know, a fridge with stuff in it.
00:50:51.526 - 00:51:33.596, Speaker B: It doesn't matter. Whatever, whatever costs, costs and performs better. And so one other interesting data point here coming back to AI is this, is this Cerebras wafer scale processor. That's the size of a wafer, you can see the size of a dinner plate. So these are all processors and they interconnect them together and these are made to handle these AI computations. And same with Tesla, the car company. So they're doing also robotics and so they do something similar that they do silicon, but then they dice it up into dyes and because of yield issues they find all the good dyes and then they put them back into a wafer just so that they have better performance.
00:51:33.596 - 00:52:13.996, Speaker B: But same idea. And so the way this works is, you know, they have all these tiles that are connected together at high bandwidth. And what this means is all the people working on computer architecture, they've moved to having the processors all together and the memory disaggregated outside. So here's the DRAM memory outside. And so the point is, all the computer architectures already are separating all the compute and all the memory. So with the superconducting logic, the problem is you can't build a computer because you put a zillion transistors based on superconducting logic in a 4K bridge. But there's no superconducting memory.
00:52:13.996 - 00:52:58.532, Speaker B: Or there is, you know, there are nature papers on superconducting memories, but it's like 8 bits, 64 bits. To do a supercomputer, you need terabytes, not, you know, and one of these little chips in your computer is 4 gigabytes, not 8 bits. So for any, any reasonable computer system, you, you need DRAM memory, which is semiconductor. So but now you can just put all the compute in the fridge. And as long as you can talk to the outside memories at reasonable energy cost, that's fine. You put a bunch of electrical cables, you saw how many cables it takes to, to get bandwidth out. That's metal that conducts heat out, that costs you more in the thousand watts per watt problem.
00:52:58.532 - 00:53:26.350, Speaker B: So it's not. But if you have optical fiber, that's great, that's an insulator. Huge amount of bandwidth the only problem is superconducting logic voltage levels are not one bolt like cmos, they're two millivolts, these single flux column things. And so you have to make the modulators very, very sensitive. So anyway, so that was the, you know, the part do optical links. And so let's skip this stuff basically. So we have a coherent link where the light goes into the fridge.
00:53:26.350 - 00:54:00.340, Speaker B: This superconducting logic, 3 to 5 millivolts drives a little tiny amplifier, just a few transistors and goes from 3 millivolts up to 100 millivolts. And then the we optimize this modulator to be able to work at 100 millivolts. And that was the idea. And I'm just going to skip the circuit. But this is. So this is a superconducting chip driving one of these things with a 4 millivolt signal. And you can see the, you know, the ones and zeros outside in the optical finding.
00:54:00.340 - 00:54:33.200, Speaker B: So it is sort of. That was a demonstration that we can do this and this was in silicon because you have the control to make these components. So you can have many wavelengths and components. Okay, so I think I gotta stop here maybe or can I give you the overview of the quantum thing in about five minutes. What do you think? Maybe I'll let people leave who need to leave or ask a question or two. I have a boring question. That's okay.
00:54:33.200 - 00:55:17.640, Speaker B: So slide 14. Oh, hold on. Yep. So you mentioned this kind of hybrid CMOS and silicon photonics 5 door. Now my limited knowledge of M7 and smaller techn places density requirements on these transistors. And my question then is, I mean, I assume you're using some kind of planar CMOS technology. How do you come to terms between the density requirements and give the place of your transistors? Then also the effects of this might place in your optical sort of thing you have less space.
00:55:17.640 - 00:56:06.960, Speaker B: Yeah, very quick question. So the question was in 7 nanometer transistor technology, TSMC you have, you put, you have to have transistors at a certain density because like silicon versus no silicon. Sort of the average density to be about the same because they do certain polishing steps so they don't want dishing in wafers and whatever things. So first of all we are in 45 nanometer technology which is much larger and these rules for density exist. But These are planar mosfets rather than thin fats, which is the 7 nanometer. The I'll mention why that's important. So this is silicon on insulator which Makes it easy to make wave guides because you have an oxide underneath.
00:56:06.960 - 00:56:46.950, Speaker B: And for density issues, there's density fill, which is dummy silicon basically, which people already put in places. So it just means, you know, your ring resonator is there guiding light, but then there are a bunch of silicon squares inside it and also on the side. And you just sort of make sure that it passes this, these average density requirements and all that. I mean, for a single experiment, of course you don't have to do that and you can get the rule wave. But. But if you want something to, to have sort of high consistency and not bring tools down because of slivers of silicon falling off the waste and stuff like that, then you have to meet these rules. And you can using this kind of thing.
00:56:46.950 - 00:57:24.898, Speaker B: N7 though. And these sort of very advanced process nodes, they are bulk silicon wafers, meaning there's just silicon and then the transistors are in the silicon, not on an insulator. So then there's not an easy way to put integrated optics in. And actually that's what we're doing here. This is an approach to do this in these advanced nodes where, where anyway we can talk about that after. But so you can, I think in principle put photonics next to 7 nanometer transistors, whether you would want to do that. Different story.
00:57:24.898 - 00:58:14.716, Speaker B: And so it could be that this goes from monolithic back to separate electronic and optical chips. Because there's a lot of work now in industry being put into advanced packaging that can make the mating between these very low capacitance. You can have tiny sort of bump pads and that was the reason for us to go monolithic, that you have these huge pads, lots of parasitic capacitance. So I mentioned before that the energy per bit has to do with, you know, this ring modulator having a tiny capacitance, for example. And so the quarter CD squared that you burn per bit is that capacitance, but not. That's like 10 pentofarrens let's say. But now you have a 250 femtofar pad that has a big solder ball and another 250 femtofarad pad and that your electronic driver is driving through that.
00:58:14.716 - 00:59:15.980, Speaker B: Now you 25x the the energy that it takes. But this advanced packaging is making this much smaller. And so, you know, might, it might be fine for certain applications. So yeah, hey, since you stuck around, I'm gonna give you just a quick oversaw what we're doing quantum optics. That was over here. Yeah, so, so the. There's a lot of work in quantum optics trying to generate source or build sources of quantum light as John Sykes group and some of the rest of you maybe work on as well as then I was just visiting Xanadu so people trying to build quantum computers, you know of this technology into single photon detectors, these kind of things.
00:59:15.980 - 01:00:17.930, Speaker B: The angle that I took into this just to learn more about quantum optics was can I just pick the simplest, simplest thing and try to get it to a level where we can do something sort of semi useful like. So we can do generate photon pairs with a ring resonator. But the problem is it takes a lab of equipment around that ring resonator just to tune it, to give it laser light, all these things to filter out all the Raman noise and all these things. You know, it's sort of. So can we basically put an entire little system on a chip that you just push the button and outcome photon pairs and you can use them in the lab or in some test bed or whatever. And so you know a ring resonator can use. You pump green lights and you get out a red and a blue photon using four way mixing or this is all in the infrared region, I guess infra green rather than blue.
01:00:17.930 - 01:00:50.618, Speaker B: And you know, so you think okay, so a ring resonator is, is a photon pair source. But it's not really because you know, it's sort of laser light comes in. You have to tune the ring to the frequency of the laser. That's thermal tuning. You need to know whether it's at that wavelength. So you need to sense whether there's light in there and put it to some control system to be able to lock that. If you pump too hard and you're using silicon, you have two photon absorption or you have self heating effects.
01:00:50.618 - 01:01:26.732, Speaker B: These self heating effects make this sort of a bi stable cavity. So to get the highest convert efficiency is not so trivial. Then the other part is if you send CW light you get correlated photons and for some applications you might want or factorizable states. So then you have to send in a pulse. That pulse has to be tuned exactly sort of to the right pulse length. You know, to make this factorizable you might have some amplified spontaneous emission. It's not a CW perfect sinusoidal waveform that a laser is.
01:01:26.732 - 01:01:43.360, Speaker B: So you have to filter out the noise, then pump this cavity. Then when it comes out there's some pump left. So you have to reject this pump. Turns out it's a classical pump. There's only two single photons here. It's not so easy to get rid of that light. And so we wanted to see if we can put do this all on a single chip.
01:01:43.360 - 01:02:26.940, Speaker B: So this is from a while back, just putting a source and a pump filter with about 100dB rejection where we could basically put in light, generate photon pairs, filter out the pump and use the pairs directly without off chip filtering, which was so I think the first time that was the case without the aid of filters. And then this is a franchise interferometer quantum interference demonstration. So but this is all passive. So this is just cavities. The reason. Yeah, we can talk later. Why there's many.
01:02:26.940 - 01:03:09.396, Speaker B: And so where we are now is just like that optical communication system. We have circuits that tune these cavities. So light goes in here, passes through a band pass filter so that all the amplified spontaneous emission is filtered. Then it goes to anomaly cavity which produces the pairs. Then each of the generated pairs comes out through a filter here and the pump is taken away. And so I'll just show you here how it looks like. So this system, what it's doing is it's scanning A to B converter and this here is the photocurrent and it goes up that you're sensing how much light there is in the ring width.
01:03:09.396 - 01:03:55.570, Speaker B: And so what happens is over here there's a self heating effect. So as you tune the resonator through the cavity as it heats, its refractive index is moving and so the resonance is shifting. So there's a bistable condition and it snaps at some point. And then so basically then this thing figures that out, goes back, knows what where that sweet spot is and locks and maximizes the pair generation. So this is about let's say 20,000 pairs per second outside the chip. And coincidence to accidentals ratio which is like signal noise ratio about 40 or 50. That's actually not the newest one.
01:03:55.570 - 01:04:41.876, Speaker B: And I'll end I just have two slides left here to show you. So yeah, this is by the way what these experiments look like. So there's the chip that we have and then these circuits do something on here, but we have to talk to them. So so we have a little board that we plug in. So there's like an FPGA that programs this and tells it what to do. So you can from Matlab or Python or whatever talk to it, skip these things, just details. So the, the resonator has built in PN diodes so that when the pump light is going through, if there's two photon absorption we, we extract the carriers so that we don't get additional free carrier absorption from carriers hanging around in the plasma absorbing light.
01:04:41.876 - 01:05:27.594, Speaker B: And then there's some sweet spot for maximizing the power. But let me just show you the interesting part. So, okay, so this was this locking. And then the other part is. So what we really want is to have like a little building block here and then Turn on like 10 of these sources and be able to multiplex so that you can improve the rate at which you're getting heralded photons or whatever it is that you're, you know, sort of the guy from nis, Gaisberg, I forget his name now to propose this first Al. Amygdala, his scheme, for example. So, so here we have 12 of these.
01:05:27.594 - 01:05:59.280, Speaker B: And the point is, you know, when you're thermally tuning one of them, this thermal crosstalk to the outputs. And so what you want is to lock one of these guys. And then what we're doing is turning on and off these other ones and showing that it's stable. And then if you turn off the feedback locking, then we see where I'm showing that. Oh, I don't actually have it here. Well, so. Or I'm not seeing it, but if you turn it off, then it goes haywire is the point.
01:05:59.280 - 01:06:35.920, Speaker B: So anyway, that's what we're doing with this. And I guess the other part we've spent some time on just most recently is just trying to make sure that what we're predicting and what we're measuring makes sense and are corresponding to each other. And we're getting pretty close with that. So one thing that we still struggle with some of these chips is figuring out where some Raman generation is coming from. It's. I don't know whether it's, you know, because in a CMOS platform there are these nitrides that are there because of sort of stress management in transistors and stuff. You know, there's all kinds of materials that are there.
01:06:35.920 - 01:07:04.390, Speaker B: So that's kind of the, the long, the short story of it. I don't wanna. Yeah, this is a new, newer chip that fixes some of the problems that we had in the previous one. So we haven't measured it yet, but that's, that's where we are. So. Thanks for giving me a chance to, to tell you what, what I've been working on and what we're doing. And yeah, I'd love to find out what's going on here more.
01:07:04.390 - 01:07:16.270, Speaker B: And I guess if you're in Washington D.C. which is where I live, believe it or not, feel free to drop me a line. Or if you're in Boston sometime, you know, happy to have you visit my group.

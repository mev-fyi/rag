00:00:00.160 - 00:00:44.594, Speaker A: So I'm going to be talking about the configuration spaces of certain types of linkages. And this talk is actually based on two papers that were written a good while ago by these authors, miraculous Ming and Wang and Heiping Gao, but they haven't been published. So I'm actually helping kind of revise these papers. And so I'm just going to go through kind of the most significant results in them for you guys. And please do ask a lot of questions. It's not like the most complicated stuff, but there is a lot to keep track of. So stop with any questions.
00:00:44.594 - 00:01:35.724, Speaker A: I'll try to watch the chat, but if anybody puts questions in chat, I guess just somebody let me know. Okay, so we'll start off just by stating the most general form of this problem. So we're given a linkage, and we're primarily interested in linkages that are generically flexible or graphs that are generically flexible. And g is going to be simple, generically flexible. And then our edge length or our delta is going to be a realizable edge length vector. Okay, so that's nothing new. But the first question is to describe the configuration space of this linkage.
00:01:35.724 - 00:02:21.224, Speaker A: So that's all this says right here. So we've got the configuration space. We're going to denote by calligraphic c of the linkage g delta. And then you've seen definitions of realizations before, right? So this is just saying that our embeddings of g are going to satisfy the distance constraints we want to describe this set. Another thing that we are interested in doing is if we're given two realizations in this set, then we want to determine if they live in the same connected component. Our configuration space could be one big component, it could be multiple components. And we want to determine where p and q live relative to each other.
00:02:21.224 - 00:03:29.474, Speaker A: If they do live in the same connected component, we want to be able to find a continuous motion path in the configuration space between these two realizations. Okay, so those are kind of the big three questions that we're interested in. And then just a note here. Determining if the configuration space is non empty is np hard. So for a lot of this, we're going to assume that we have some realization of this linkage. Okay, so I figured I'd show you a video and let me know if you can see the web browser that kind of shows a linkage and how it moves based on some techniques that we're going to talk about, not for this specific graph, but in this case. And I'll go through the details of how this works, but this is one method for realizing continuous motions of a generically flexible linkage.
00:03:29.474 - 00:04:35.610, Speaker A: And I won't go into the details of everything you're seeing, but this is just kind of one example of how or describing a configuration space. Okay, so, first, let's talk about where this problem arises. So, one good sign that the problem is important is that there's kind of a textbook on it. And this is probably a very broad textbook, but the idea is that it's going to talk about configuration spaces for mechanisms. So you can check the textbook out, but that's just one place where they discuss it in depth. Another application of this problem is in this problem called the robot reachability problem. And basically, in this setting, we're given what's called a robot manipulator with n links and n joins, and you can kind of see it pictured here.
00:04:35.610 - 00:05:38.010, Speaker A: This is a robot manipulator with two links and one joint. In our setting, this is just kind of a path. And in this problem, they want to know all of the points that the end of this link here can reach. You can rephrase this in terms of our problem as seeing what all configurations this robotic arm can take. And so, even for a problem such as this, which seems like a very simple setup, it's not the easiest problem to solve. And this paper from actually a while ago, solved it for linkages, the general problem for n links and end joints in three dimensional space by transforming the problem into a nonlinear optimization problem and then just applying a well known algorithm called the tunneling algorithm. But, so I won't go into those details.
00:05:38.010 - 00:06:32.406, Speaker A: But the point is, a problem in our general problem has been studied, and it's been seen that these problems are not easy to solve. Okay. Another place where this kind of general problem appears is in molecular assembly. So this is actually from a paper by Raul and Doctor Sithram and, I think, several others. And in this setting, you're given two rigid molecules as input, and you're given bonds between pairs of molecules, pairs of atoms within the molecules. Then you want to remove bonds one at a time and describe the configuration space that these molecules can take relative to each other. Over here on the right.
00:06:32.406 - 00:07:12.316, Speaker A: On the left, we see the two rigid molecules. On the right, we see we keep the blue molecule fixed. And then this sweeping pattern are all of the configurations that the green molecule can take with respect to the blue molecule. All right? And then this is closer to the class of graphs that we are going to be dealing with. Or it is the class of graphs we're going to be dealing with. This is called the strand beast. And it was, I forget the guy's name, but this guy created all these kind of cool walking mechanisms.
00:07:12.316 - 00:07:50.620, Speaker A: And I'll show you a video, just so you can see, because this kind of looks very complicated. But let me see if. So I think his name's right here, actually. Theo Jansen, I believe, is the creator of these things. So they look like three dimensional. I mean, they are in three dimensions, but the interesting mechanisms behind this are actually two dimensional linkages kind of pasted in parallel next to each other. So this is wind powered kind of linkages.
00:07:50.620 - 00:08:30.134, Speaker A: So they're able to move just by wind hitting these things. And it looks kind of crazy. So I think the one from the picture is later on, the one that I had somewhere around here. But anyways, so the point is there's all these kind of crazy linkages that have generically one degree of freedom, and they're able to move in very strange ways. Okay. Yeah. So a note here, it looks 3d, but it's really just parallel copies of 2d linkages kind of glued together.
00:08:30.134 - 00:09:18.956, Speaker A: And the underlying 2d linkage, which is shown over here in the top right, is what we call tree decomposable minus one edge. So we're going to rigorously define treaty composable, but all it really means is that it has a nice recursive structure, and three decomposable graphs are minimally rigid. So you take a treaty composable graph and you remove an edge, and now it generically has one degree of freedom. So this is kind of the class of graphs we're going to study. And this is just saying kind of where we're going to be working. So we're going to be working in two dimensions. Like we just said, we're going to be working with graphs that are one DOF tree decomposable.
00:09:18.956 - 00:10:14.314, Speaker A: So this means three decomposable minus one edge. And just to repeat, all this really means is that they have a nice recursive structure. We'll formally define what tree decomposable means, and then we're also going to have some genericity conditions on delta. So we want our linkages to be generic, but we're going to define what genericity conditions we need later, just because it'll be easier to define once we've talked about tree decomposable graphs. So this is the setting we're going to be working in. And now the main tool that we're going to use to solve the problem of describing the configuration spaces and motions between realizations is the Cayley configuration space. So Raul and I think Doctor Sithram and Sean have all talked about this, but I'm just going to go over it again.
00:10:14.314 - 00:10:49.234, Speaker A: Oh, I see there is chat here. Okay, doctor Sithram is just pointing out it was, yeah, Theo Janssen, we encountered these. Yeah, right. So we've encountered them in the context of size one, doctor. Plans and triangularized systems of quadratics. Referring to the triangle decomposable graphs. Okay, so the main tool that we're going to use to describe configuration spaces is the Cayley configuration space.
00:10:49.234 - 00:12:06.474, Speaker A: So given a linkage, g delta and a set of independent non edges, so non edges of our graph whose distances are not determined by the edges of the graph, the Cayley configuration space of this linkage over the set of non edges in two dimensions is the set of lengths attained by the non edges over all realizations of our linkage. So basically you can kind of just imagine from that first video that I showed you with the motion of that linkage, there were some dashed lines in it. Those were our non edges and we're just keeping track of what those distances are for those non edges as our frameworks move basically or between different realizations. Yes, independent in the 2d generic rigidity matriid is what we mean by independent set of non edges. Right? So we're going to denote this set by Phi raised to the two sub f of g delta. So f is our set of independent non edges. Two just denotes we're working in two d and g in delta is our linkage.
00:12:06.474 - 00:12:57.958, Speaker A: So as an example, over here on the bottom left. Oh, another chat. Yes, g union f is independent in the 2d rigidity matriid. Right. Okay, so as an example, down here on the bottom left, we've got this graph on five vertices and our delta is just unit distances on all of the edges. Then we're choosing our independent non edges to be these two red dashed edges or non edges. And when we do this, we can very, very easily compute the Cayley configuration space over these two red dashed edges just by looking at the immediate triangle inequalities that you get.
00:12:57.958 - 00:13:47.054, Speaker A: Because by choosing these two red non edges we've kind of triangulated our graph. And when you compute these triangle inequalities, they're going to give you relationships between these non edges and maybe one edge here with a distance one. So over here on the right is the Cayley configuration space on the x axis we've got the non edge delta v two, v four. So this one, if you can see my cursor. And on the y axis, we've got the non edge delta v one, v four. So this one and these boundary lines here, the shaded region is the Cayley configuration space. Notice in this case it's convex.
00:13:47.054 - 00:14:21.404, Speaker A: And the boundary lines here can be easily computed from the triangle inequalities. So I won't go through the details, but it's very easy to find this space. Okay. Over on the right is another example, a different graph on five vertices. This time our non edge is v one, v three. And this time. So our Kayley configuration space is going to be a one dimensional space as opposed to over here, where it was two, because we chose two non edges, here we're choosing one.
00:14:21.404 - 00:15:20.108, Speaker A: So our Kali configuration space is just going to be some set of intervals on the real line, and in this case it is two disjoint intervals. So I won't go into detail about this figure on the right. But the important thing here is this is just another example where rather than getting a convex Kayley configuration space, we've now got a disconnected Kayley configuration space. So something a little bit more interesting and some, you know, non trivial to kind of sample in many cases or to move around in. So in this case over here, our problem is a little easier because for all points in the Cayley configuration space, they're in the same connected interval. So really we're just trying to find motion paths between them, whereas over here we may have two points that are in different intervals. Okay, so any questions on this? Nope.
00:15:20.108 - 00:16:11.704, Speaker A: Okay, so this is the main thing that we're going to be working with. So if you have any questions about it later, just let me know. Okay, so we want to have some complexity measures on this space, the Kaylee configuration space, which, by the way, we're going to shorten it in many places to just ccs. So, Kaylee configuration space, and here are the complexity measures that we are going to be interested in. So for all of these three, we're going to maximize over delta. So we're going to basically find the delta that makes these complexity measures the worst. So the maximum size of the ccs or the Kayley configuration space is going to be the number of connected components.
00:16:11.704 - 00:16:51.546, Speaker A: So just to reemphasize, we're looking for the delta that maximizes the number of connected components. That's going to kind of give us our worst case complexity measure for these Kayley configuration spaces. So that's our first one. The second one is maximum algebraic complexity. So this just means the algebraic descriptive complexity of the components boundaries. So for example up here you can get these boundaries for the Cayley configuration space through simple linear inequalities. So that's what we're interested in.
00:16:51.546 - 00:17:30.744, Speaker A: We're interested in how hard is it to describe these boundaries. Okay, so the third one is maximum computational complexity. And this is just the overall time complexity for computing this space, the Cayley configuration space. Alright, so those are the three complexity measures that we want to keep in mind. Now for our problem, since we're working with one DOF treaty composable graphs. And remember that means tree decomposable, which is minimally rigid minus an edge. We're just going to take our set of independent non edges to be a single edge.
00:17:30.744 - 00:18:23.984, Speaker A: And in particular it's going to be a single edge such that our graph, which is one DOF treaty composable, when we add this edge non edge in, it's going to become tree decomposable again. So you can take a treaty composable graph, remove an edge and you can let that be your non edge. But you could also take your treaty composable graph, remove an edge and there could be some other non edge that when you add it back makes it three decomposable again. But the point is we're going to be working with a single non edge. So these are the same complexity measures just kind of restated for our problem. So for a one DOF treaty composable graph and a non edge f single non edge instead of this kind of not simplifies some things but it makes some difference. So maximum size, remember before was number of connected components in the space.
00:18:23.984 - 00:19:04.764, Speaker A: Well, when we're dealing with a single non edge, we're going to be dealing with a one dimensional Cayley configuration space. So we're going to be talking about the number of intervals. Similarly, for the algebraic complexity, we're going to be talking about the algebraic descriptive complexity of the intervals endpoints. So how hard is it to describe the endpoints of our intervals? So for example, back up here, this is actually a one DOF treaty composable graph. So this is a graph that we're interested in over here on the right. And we're interested in, first off, how many intervals there are. So in this case two.
00:19:04.764 - 00:19:52.224, Speaker A: And in the second complexity measure how hard it is to describe a, B, C and D. Okay. And then the third complexity measure is the same. The overall time complexity of computing this Cayley configuration space. All right, so, for our particular class of graphs, we're going to be interested in a special type of algebraic complexity. So, the second complexity measure up here to describe the intervals endpoints. So we're going to say that the pair g f, where g is our one DOF treaty composable graph, f, is our one non edge.
00:19:52.224 - 00:20:47.734, Speaker A: We're going to say that this pair has QRS complexity. If, when we look at an interval endpoint in the Cayley configuration space, and we consider its corresponding realization of the linkage in Cartesian, the cartesian plane, we can solve for the coordinates of that realization p using a treaty composition. And like I said, we're going to define treaty composable graph and treaty composition. But the point is, we are going to have a really nice and easy way to describe the interval endpoints that uses the structure of tree decompositions. So the structure of our graph will play a very important role. So, this complexity measures kind of very specific to our class of graphs. And I want to point out.
00:20:47.734 - 00:21:43.924, Speaker A: So this definition is a little misleading. What I mean by that is, if a realization is tree decomposable, then it is quadratically radically solvable. So, we've talked about what this means, but this basically just means that the coordinates of the realization belong to an extension field of the rationals with nested square roots. So you can solve them using a triangularized system of quadratic equations that just involves one quadratic equation at a time. Okay, so the point here is we're talking about treaty composable in this complexity. Now, tree decomposable implies qrs. However, it is not yet known whether qrs implies tree decomposability.
00:21:43.924 - 00:22:07.334, Speaker A: So, in the converse direction, it's true for planar graphs. If you are planar in qrs, then you are treaty composable. And I think Doctor Sitherin put in here, that's due to Owen and power. So sorry about that. I forgot to add that in there. And it's strongly conjectured in general. So we're just going to make our lives a little easier here and say QRs complexity.
00:22:07.334 - 00:23:14.854, Speaker A: But I should say that it is possible that the two are not equivalent. In which case, we would specifically be talking about tree decomposable complexity here. Okay, so this complexity measure will become a little bit more clear in a moment, but let me know if there are any immediate questions. Okay, so we've defined our problem, the types of graphs and non types of graphs we're interested in, and we've defined the main mathematical tool we're going to be using, which is the Cayley configuration space and some complexity measures on that space. So now recall, we want to solve the problem of describing the overall configuration space, and we want to be able to find continuous motion paths between realizations in this space. So here are kind of the results from the paper that I'm talking about. So the first one, and these are algorithmic results here.
00:23:14.854 - 00:23:51.954, Speaker A: So the first one is an algorithm to compute this space. I haven't mentioned complexity here, computational complexities here, I'll mention them later on. But it can be quite bad. But this is an algorithm to compute this space. Then we're not going to get to this one today. But there's another algorithm to compute this space that has polynomial time, a quadratic and the number of vertices if our graph in non edge pair has QRS complexity. So that's why this complexity measure is important.
00:23:51.954 - 00:24:50.294, Speaker A: It allows us to get a very fast algorithm for computing this configuration space. Kaylee configuration space. Okay, then we're going to show this interesting result that there are at most two continuous motion paths between realizations, and we'll give an algorithm to compute them. Kind of immediately follows from the fact that there are most, at most two, or from the proof method to show this rather. Okay, so those are the algorithmic results. And then there are a few interesting combinatorial results which are both useful for the algorithmic results, but also just kind of independently interesting. Okay, so first we're going to be able to give a characterization of graphs with QRS complexity.
00:24:50.294 - 00:26:08.844, Speaker A: So this is helpful because previously we talked about an algorithm that computes KL configuration spaces for this graphs with this complexity. So it'd be helpful to know when we're dealing with graphs with this complexity. Second, and this is very, one of the most interesting in my opinion, is that graphs with or QRS complexity is a property of the graph g. So what I mean by this is that if g f has qrs complexity for some non edge, then it has qrs complexity for all possible non edges that turn such that gunion f is 3d composable. This essentially says that we don't have to be careful about the non edge that we choose to compute our Kayley configuration space. This is a very nice property to have. Then another result, which we won't get to today, is that for a subclass of the graphs that we're dealing with, QRS complexity is equivalent to planarity, and in particular there's a forbidden minor characterization.
00:26:08.844 - 00:27:02.026, Speaker A: However, if we look outside the subclass, no forbidden minor characterization exists. So this is kind of changing from looking at kind of more structural combinatorial characterizations of these graphs to forbidden minor characterizations of these graphs. And it's kind of interesting that while there is one for a subclass of these graphs, in general, you can't come up with such a characterization. Okay, so those are the overall results. The first one we're going to look at is just a general algorithm to compute the Cayley configuration space. And we're going to heavily take advantage of the structure of treaty composable graphs. So now I will define them.
00:27:02.026 - 00:27:48.854, Speaker A: All right. The reason I didn't want to is because earlier is because there's kind of a lot to talk about. There's a lot known about these graphs. So I wanted to present the results first just because otherwise it'll take quite a while to get to the results. Okay, so please ask questions if any of these definitions are not clear, because we're going to be using the structure of these graphs very strongly in our proofs. So it's kind of easier to look at the pictures first before delving into this kind of definition over here on the left. Basically this over here in a, this entire thing is our graph g.
00:27:48.854 - 00:28:38.014, Speaker A: And we're going to talk about tree decomposable, not one dof yet. So this entire g, one g union is our tree decomposable graph. And our graph is tree decomposable if we can decompose it into three components, g one, g two and g three, such that each pair of components shares a single vertex. And the three of these shared vertices are distinct and our components are themselves three decomposable. So you can perform as it's showing in this figure over here on the right. You can perform this decomposition again on any of these components. So this is what I mean by a really nice recursive structure.
00:28:38.014 - 00:29:24.104, Speaker A: Okay, and then over here on the left is just kind of the rigorous definition of tree decomposable. It basically says the same thing. So our graph in the base case is just an edge k two. And then this recursive step just says exactly what I said over here, our three components that pairwise share a single vertex and the vertices are distinct. Okay, so this is kind of a general picture. So I've got a more concrete example, and for our purposes right now, just pretend this v one, v three isn't a red dashed edge, it's just an edge. So this is a tree decomposable graph.
00:29:24.104 - 00:30:49.124, Speaker A: And as you may be thinking, there are possible ways to decompose this graph during the first decomposition, but one which is kind of the most immediately visually obvious, is one of our components is going to be this diamond, v one, v two, v three, v four, then v four, v five, v six, v seven and v seven, v eight, v nine and v two. Okay, but alternatively I could have taken one component to be the edge v four, v six, one to be v six, v seven, and the other component to be the rest of the graph. And when we split these components off, by the way, we're going to keep the vertices that they share in each copy. So when we split off v four, v six, it's going to be a little edge over here, v four, v six, but the rest of the graph, the other component is still going to contain v four. And then we're kind of just identifying those vertices to put them back together. Okay, so this is a concrete example of a treaty composable graph. So now from our recursive definition of a tree decomposable graph, we can easily define a decomposition tree.
00:30:49.124 - 00:31:15.752, Speaker A: So let me just show you it first. So this is for that graph that I just showed you, this one right here. And sorry if it's a little small. Let me know if you can't see anything. Maybe I can make it slightly bigger real quick. Maybe that's a little better. So this just shows one decomposition and it shows the first one that I was discussing.
00:31:15.752 - 00:32:07.874, Speaker A: So it breaks it up into this diamond, this diamond and this non convex diamond. And then we can go further, we can take each component, break it up into three tree decomposable graphs. Here we're breaking v one, v two, v three and v four into this triangle and these two edges. And then, you know, you can keep going down. And the leaves of this, the root is going to be the graph, the leaves are going to be the edges of our graph, and then the internal nodes are going to be tree composable graphs whose three children are one decomposition of them. Okay, so that's all this says here. G is the root, e is the set of leaves, and each internal node can be decomposed into its three children.
00:32:07.874 - 00:33:00.414, Speaker A: Okay, now like I said, there are many ways to decompose the graphs and likewise, instead we can kind of reverse it, start from the leaves. So in this case, forget everything you see here except for the leaves. We just have a set of these leaves. Well, just using our definition of tree decomposable, we can identify three leaves, three edges that we can recombine. They just have to pairwise share a distinct vertex. So a very nice property, that tree decomposable graphs that they have is called the church Rosser property. And what this means is that any sequence of recombination steps is going to give us back our original graph.
00:33:00.414 - 00:34:16.774, Speaker A: It doesn't matter if we recombine as shown here, which obviously we can do since we decomposed it this way. But instead, if I'm just given this set of edges, I could recombine v one, v four, v four, v three and v one, v three right here. And that would give me this top triangle. Then I can forget about this and come over here and do another recomposition. So the point is, it doesn't matter what order we do these things in, we're going to get back to our original graph. And then even more useful of a property, since we're dealing with realizations, is that we can perform these recombination steps geometrically, meaning we can perform these and embed them, embed our components that we're recombining in the plane. And the point here, which was also shown, was that if you're given a sufficient set of local orientations for triples of points, which I'll explain in a moment, then any sequence of recombination steps can be performed geometrically to construct the same realization of our graph.
00:34:16.774 - 00:35:50.424, Speaker A: So what I mean here is that take this component, v one, v two, v three, v four, and consider its edges. Now if we want to get back to this realization, and by that I mean just as it's drawn here, when we perform this recombination step, we need to know that v two lies below the line defined by v one, v three. Or in other words, if you start at v one, you go to v three, and then you go to v two, you take a clockwise turn here. Okay? So if we're given this orientation and the orientation for the next step and so on and so forth, then you can perform any sequence of recombinations that just comes from kind of the, you know, graph theoretic property, and you'll get the same realization. Okay? So that shouldn't be too hard to believe just because you're given enough orientations, there's no question about where to place these points, really. Okay, so now what we want to do instead is we want to perform this recombination, but we want to do it with respect to a specific starting edge, which we're going to call the base edge. Okay? So now when we do this, what I mean is say I take v one, v three here and I want to just build this graph up from v one, v three.
00:35:50.424 - 00:36:36.900, Speaker A: So I'm fine with doing this recombination step. I'm fine with doing this recombination step because they both kind of involve v one, v three. But when I look down in the leaves of all these components, I don't really care about them. So I just want you to give me these components because the next step is going to be taking this component which contains v one, v three and then combining them with these three kind of maximal components. So that's all we're describing here. So given a 3d composable graph and an edge, we're going to start with our edge set and we're going to perform all the recombination steps that do not involve f, our edge f that we're given. The resulting subgraphs of g are going to be called our maximal clusters of f.
00:36:36.900 - 00:37:19.260, Speaker A: Okay? And they're unique for f by the church Rosser property because they involve a set of recombinations and it doesn't matter what order we perform them in, we're going to get the same maximal clusters. So as an example here, sorry, this is an example for one dof, but it doesn't really matter. Add the edge v, not v prime not back as an example here. Notice that this component here does all of its recombination steps don't involve f. So just kind of combine them all. Likewise this edge and then this triangle and these edges. And you can look at it for a moment and just kind of convince yourself that each of these components is maximal.
00:37:19.260 - 00:38:22.034, Speaker A: Meaning that to perform any other recombination step we first need to perform a recombination step involving our non edge or our edge f here. The way to see that is really just take any of these components and try to find two other components that share distinct vertices with this and also share a distinct vertex with each other. And you can't do this because t five and t four, for example, don't share vertex so you can't combine them with t six. Okay, so let me know if maximal clusters isn't super clear. But this is the primary kind of construction we're going to be using. We're only going to be interested in the construction of our graph or the construction of a realization of our linkage starting from a base edge or in our case a base non edge. Okay, so now this just kind of formalizes the construction, but let me just explain it to you visually.
00:38:22.034 - 00:39:13.256, Speaker A: So we're going to start with our edge here. And then that's going to be our initial graph which we're going to denote. If our edge is f, it's going going to be gf of zero g sub f of zero, right? So that's what step one here says. Begin with g sub f of zero equals f. Okay, then we're going to perform recombination steps with our previous graph, which in this case is just g sub f of zero and two maximal clusters. So our first recombination step here could be the edge f with the cluster t one and the cluster t two. Then, and we've kind of labeled these vertices such that you can kind of see the order we do it.
00:39:13.256 - 00:40:18.204, Speaker A: So the first one we add is v one with cluster t one and t two. Then from that triangle that we've now created, which is our g sub f of one, we're going to create the next graph by performing another recombination. So in this case t three and t four will be added. And finally t six or t five and t six will be added. So all this says here is step one, start with your edge f and then our graph g, sub f of k, which k is our recombination step, kind of a linear order. So one, two, three, etcetera is going to be obtained from the previous graph via a recombination step involving maximal clusters t sub u sub k, and t sub w, sub k of f such that, and this is just the definition we've seen. The three of these share a pairwise share vertices that are distinct.
00:40:18.204 - 00:41:29.054, Speaker A: And just to help with some notation here, we're going to denote the k three combination step by v sub k, which is the vertex that we're adding. So in this case our first recombination step adds v one with a left arrow. And then here's our base pair is what they're going to be called, u sub k and w sub kick, and they belong to these maximal clusters. So for example, first construction step here is going to be v sub one, left arrow, v naught, v prime, not our base pair for the first construction step is v zero and v prime, not. Similarly, our base pair of maximal clusters are the clusters that our base pair of vertices belong to. So I want to check real quick, is everything clear with everyone? Just because there haven't been any questions, I don't think it's too complicated stuff that what I'm talking about. I just want to make sure everyone's following or if I'm not going too fast or anything.
00:41:29.054 - 00:42:24.364, Speaker A: So let me know if there's any questions. Okay, so all I'm saying here is. Okay, so before we talked about constructing a graph so purely graph theoretic, we're not talking about realizing now, we're saying that we can still do the realization what we talked about before, we can perform a sequence of recombination steps geometrically to realize our graph, and we can do it with respect to a base edge f. But in this case, we're going to assume that some information is given to us. So obviously we need our tree decomposable linkage g delta and we need our base edge f. We also are going to be given realizations of our maximal clusters of f. Now why? Because like we said, we don't care about those.
00:42:24.364 - 00:43:05.024, Speaker A: We don't, we just want to be given what they are. And then I want to perform the recombination steps that involve them. I don't want to build them. So we're going to be given realizations of them and we're going to treat them as kind of globally rigid graphs. Because since we're given realizations and they're treaty composable, I might add, which means they're minimally rigid, that means that we can just kind of treat them as globally rigid. And in particular we can kind of just replace them with edges. So for example, if we're given this cluster, a realization of this cluster t six, if we're given the realization, then there's no question about how this is going to be placed.
00:43:05.024 - 00:43:46.512, Speaker A: Besides solving the recombination step that combines it with three other clusters. It doesn't really matter if you make v three, v prime, not an edge, because the rest of it is just fixed. Okay. And that's going to be important actually. So we're given our linkage and our base nonage, we're given realizations of our maximal clusters. And then remember previously, in order to realize our graph geometrically, we needed to be given a set of orientations. Well, since we've fixed realizations of some of our maximal clusters, we don't need all of the orientations.
00:43:46.512 - 00:44:49.454, Speaker A: We don't need all that information. In particular, all we need are the local orientations for triples of points involved in our recombination steps. So for example, back to this graph, we just need the orientation of v one with respect to v naught, v naught prime, and so on and so forth. We need the orientation of v two, or more interestingly, v three, since it doesn't have the trivial base pair v three with respect to u one and v prime, not. Okay, so, and remember we're performing our construction starting from an edge. So we're going to call this set of orientations a forward orientation because we're kind of, you know, constructing it in a forward direction from an edge to the entire graph. So, so the set of orientations that we need to construct a realization of our linkage from this base edge is going to be called a forward orientation.
00:44:49.454 - 00:45:48.804, Speaker A: Okay, so just a couple observations because now we want to work with one DoF tree decomposable linkages is that everything I said applies when f is a non edge. The only caveat is that when we're realizing our graph, we need to be given a length for f. Right? So, because remember our initial graph is just our edge f. So in this case, if we're dealing with a non edge, just give me a distance between the two vertices of the non edge f. And now everything applies because we can treat it as an edge. So our graph construction, our realization forward orientation, all that works. And then one other interesting observation, which is kind of obvious after you think about it for a moment, is that in this case the base pair of vertices in every recombination step is a non edge.
00:45:48.804 - 00:46:34.924, Speaker A: Okay, so why is that? So you can almost say this for when f is an edge, but it doesn't quite work. So when f is a non edge, obviously our first recombination step is going to be on f, which is a non edge. Okay? And then similarly the rest of this argument works when f is an edge as well. If you have a recombination step that is pasted on an edge. So say our base pair was v two, v naught prime. Then what you're really doing is building a bigger tree decomposable graph because you've got two treaty composable components and then an edge is 3d composable. So that would kind of violate the maximality of these components so it can't be pasted on an edge.
00:46:34.924 - 00:47:43.184, Speaker A: Okay, so we'll use this property a little bit. All right, so just to recap everything, because it's kind of a lot to go through, is that what we've described so far is the recursive structure of one DOF treaty composable graphs and how to construct the graphs and realizations of them starting from a base non edge and what information we need to do that, in particular the forward orientation. Yes. Oh, sorry. So I mentioned before that our maximal clusters are given to us realizations of them. So when we're performing a recombination step in particular, when we're realizing our linkage, we said that the distances, so this is our recombination step. Uv is our base pair and v is the vertex that we're adding.
00:47:43.184 - 00:48:56.364, Speaker A: So we pointed out that the distances which we're going to denote by l l of two vertices will give us the distance. So length, really, I should say the length between u and v and w and v are fixed because we're given realizations of our clusters. So I pointed this out earlier in the last recombination step with t five and t six, the distance v three, v prime not is fixed. Okay, so this may not be the best notation, but I came up with this last minute because I needed to talk about these distances. We're going to call these distances just implied bars, okay, so maybe there's a better name for it. But the point is when you're doing a recombination step and the pair uv isn't an edge, then that distance is fixed and we're going to call that an implied bar. Alright, so finally now we can define what we mean by a generic linkage.
00:48:56.364 - 00:50:24.364, Speaker A: Okay, so we're going to call a linkage generic if the entries of our, if our edge links given by delta are non zero and distinct. Furthermore, if the implied bars which you can get from delta and your realization of your maximal clusters are non zero and distinct, okay, and then, so those aren't too difficult. Then the third one is that at most one triple of points contained in adjacent edges or implied bars are collinear. So let me just show you what I mean by that. So u one, v three and v not prime is such a triple of points because they're contained in an adjacent bar and implied bar, right? So u one, v three and v three, v not prime is an edge and an implied bar that are adjacent because they share the vertex v three, we're only allowing one of these pair of triples to be collinear. So in particular, if we flex this so that u one, v three and v naught prime are collinear, that's fine, so long as no other triple is collinear. That's what we mean by that condition of genericity.
00:50:24.364 - 00:50:39.260, Speaker A: Okay, so that is what we're going to mean by a generic linkage. Okay, so we're almost ready to, sorry, William. Yeah.
00:50:39.452 - 00:50:57.000, Speaker B: What's the intuition of why we allow this? I call that non generic behavior, but this collinearity, but we restrict it only to one situation. Can you flash forward and imagine tell.
00:50:57.032 - 00:51:16.688, Speaker A: Us what that's so yeah, the intuition is that, remember, we're given a. Oh, sorry, there's a chat as well. I don't know if. Doctor Sith. Minimal condition for proofs to go through. Yeah, that's basically it. But the intuition kind of visually here is that remember, we're given a forward orientation.
00:51:16.688 - 00:52:04.934, Speaker A: So in particular, we know that v three is above u one and v zero prime. But as we move, say we're given another realization where v three is on the other side, but they're in the same connected interval. We want a motion path between them. And along this motion path, we're going to need this orientation to change. And at that point, those triplet points are going to be collinear. So we want to allow that so that we can get between them. And in particular, we're going to show that during these motion paths, exactly one triple is going to be collinear during this orientation change, which means that only one orientation is going to change along these motion paths at a time.
00:52:05.094 - 00:52:06.086, Speaker B: At a time.
00:52:06.270 - 00:52:06.630, Speaker A: Yeah.
00:52:06.662 - 00:52:11.750, Speaker B: Yeah, I see. Interesting. Okay, cool. Thanks.
00:52:11.902 - 00:52:29.514, Speaker A: Yeah, so before I go into a few more details, I want to just kind of give an overview of the theorem because it's a lot to process before the theorem. Yeah. And as Doctor Sithram said, it's relatively easy to test. Oh, sorry. I'm not quite sure what you're referencing.
00:52:32.174 - 00:52:32.774, Speaker B: I think she.
00:52:32.814 - 00:53:06.030, Speaker A: No, I mean the generic one. I mean the property. Oh, property, yeah. Okay. So I want to kind of give you the flavor of the theorem that we're working towards because there's just a couple more things to discuss before we state it. But basically what we're going to say here is that we're going to be given a generic linkage and a base non edge. And we're going to say that the Cayley configuration space over this non edge is a set of disjoint closed real intervals or it's empty.
00:53:06.030 - 00:53:52.622, Speaker A: This one's kind of obvious in a way because you're dealing with a one dimensional Kayley configuration space. So you expect to be dealing with intervals. And all we're saying here is that they're disjoint closed real intervals. The next one, which kind of deals with this collinearity is that any interval endpoint of this Kayley configuration space is going to correspond to the length of our non edge. Sorry, let me say this a little bit better. So say we get to an interval endpoint of our Kayley configuration space and we look at the realization corresponding to this endpoint of our linkage. Then there's going to be a collinear pair, triple collinear triple of points.
00:53:52.622 - 00:54:58.126, Speaker A: That's basically what this is saying. We're going to formalize this by defining something called an extreme linkage. And then the other interesting thing we're going to show, which is not too hard and kind of intuitive, is that given a, when you have a fixed orientation, a forward orientation, and you're moving along an interval where this forward orientation doesn't change, then the motions are kind of well defined, meaning that all of the vertices of our realization, their coordinates are going to be continuous functions of the length of our non edge that we're given. So as we move this non edge, then the vertices are going to be continuous functions of it. And this works only when we fix the forward orientation. So nothing weird happens, like flipping of no flipping of vertices, like around things that would cause discontinuities. Okay, so this is the theorem that we're going to prove.
00:54:58.126 - 00:55:46.764, Speaker A: We just need to define a couple things. Okay, so what we're going to define here, which is kind of about that collinear triple that I mentioned, is called an extreme graph. So the k th extreme graph corresponding to the kth graph that we get from k construction steps is obtained by performing the first k minus one recombination steps. And then instead of performing the last one, so for example, t five, t six, we're just going to add the edge between their base pair. So u one, v prime, nought. That's what we get over here. This is the kth extreme graph, or in this case, since there's only three recombination steps, the third extreme graph.
00:55:46.764 - 00:56:27.740, Speaker A: Okay, and the reason we're kind of doing this is because when this triple becomes collinear, you can kind of just treat it as an edge. And so we've got this, this extreme graph. And then we want to remember we are dealing with a linkage. So we have distances assigned to all the other edges of this graph. We want to assign distances to this extreme edge. So all we're going to do is look at these two components here, t five and t six, and just compute the triangle inequality on these two. So remember u one, v three is an edge.
00:56:27.740 - 00:57:01.394, Speaker A: So we have a distance for it. And v prime, nought, v three is an implied bar. So compute the triangle inequality, the two bounds to the interval we get from the triangle inequality. So in particular, the distance on this edge plus the distance on this implied bar will give us our maximum and the distance on this edge. The absolute value of the distance on this edge minus the distance on this implied bar will give us our minimum. Right. So we're going to take those two distances and we're going to create two different extreme linkages.
00:57:01.394 - 00:58:02.564, Speaker A: One is going to be this extreme graph with the maximum distance that we get from the triangle inequality on this extreme edge. And the other one is going to be this extreme graph, or this extreme linkage with the minimum distance assigned to this extreme edge. So the reason we're doing that is because when you get to a point where an orientation changes, you're either at a point where these two are so stretched apart that they reach their maximum distance between them via this triangle inequality, or you're at a point where, if you can go the other way, where instead of becoming stretched apart, they kind of come together, these two, u one and v naught prime. And they're at their minimum distance away. And it's kind of like you can imagine v three kind of rotating out. I mean, it's kind of hard to see in this one because it doesn't look like it can. But if these distances were long enough, they could kind of rotate out this way instead of stretching apart.
00:58:02.564 - 00:58:05.000, Speaker A: Okay. Yeah.
00:58:05.032 - 00:58:34.022, Speaker B: William, I'm a little curious about this because as you say in this example, if you try to rotate that edge, u one, v three to the left, it's going to. It's going to stop rotating before you get to the kind of parallel situation. Right.
00:58:34.078 - 00:58:34.390, Speaker A: Right.
00:58:34.462 - 00:58:49.814, Speaker B: So how should we think of this, this extreme edge with this kind of weird distance? It's not really the distance that it can be the boundaries thinking.
00:58:49.974 - 00:59:21.554, Speaker A: So you're kind of alluding to something we're going to show later. And that is that. So an endpoint is going to correspond to a realization of an extreme linkage where these three are going to be collinear. But not every extreme linkage is going to correspond to an endpoint. So in this particular example, we may not be able to reach the extreme distance because of other parts of the linkage. And that's not going to be an endpoint in our interval.
00:59:24.294 - 00:59:41.114, Speaker B: Okay, that makes sense. So it's not an endpoint in the interval because there were some other kind of decisions that were made earlier that are constraining us. But if we're allowed to shift those decisions, those earlier decisions a little bit, then we could move, move this distance further.
00:59:41.774 - 00:59:53.268, Speaker A: Yes. So, and then, as doctor sithroom points out here, the set of endpoints is a subset of the realizations of extreme linkages. So, yeah, not all of them are going to be useful to us.
00:59:53.316 - 00:59:54.588, Speaker B: Yeah, that makes sense.
00:59:54.636 - 01:00:34.796, Speaker A: Thanks okay, so I hope this part's clear. The intuition is kind of like this collinearity to switch forward orientations behind this definition of an extreme linkage. Okay, so all this is saying is formalizing that. So we're given our base pair u sub k, w, sub k. It adds the vertex in the recombination k. Through recombination step we add the vertex v sub k. And then we're just defining this minimum distance by the triangle inequality and this maximum distance by the triangle inequality.
01:00:34.796 - 01:01:48.494, Speaker A: And our new edge lengths are going to be the edge lengths on our first k recombination steps just as they are with this additional distance on the extreme edge. And from this we get two extreme linkages, the minimum and the maximum. Okay, and finally, before we state the theorem, we have these forward orientations. So we want to formally state what they are and then we want to discuss how we're going to use them in our Kayley configuration space. So first off, given a graph, a local orientation for an ordered triple of vertices, UWV is a value in this set negative 10 or one, and we'll call it x. Now a realization of our graph realizes x realizes this local orientation for this triple if the sign of this determinant has the same sign as x. Again, this is just kind of a very elementary thing about kind of like the, for lack of better term, two dimensional cross product.
01:01:48.494 - 01:02:38.844, Speaker A: You're just stating whether you're taking a, you know, clockwise or counterclockwise turn with respect to these three vertices. Okay, so now an orientation, a forward orientation is going to be a vector of these negative ones, zeros and ones corresponding to our recombination steps. And then we're going to say that the. So we'll denote this forward orientation by sigma. So the sigma oriented Cayley configuration space is the subset of our Cayley configuration space that realizes our forward orientation sigma. So in particular a value for f in our oriented Kayley configuration space. When we look at the realizations that it corresponds to, we're only going to consider the forward orientations.
01:02:38.844 - 01:04:45.024, Speaker A: And maybe I should have mentioned this, when we're given a distance for f, it's kind of clear that there are multiple realizations that we can map to in the cartesian plane, right? So one has v three on this side and one has v three, say, flipped, but for the same value of f. So what we're using these four orientations to do is kind of partition our Kaylee configuration space, or not necessarily partition, but to give it some more structure so notice that our Kaylee configuration space is the union of oriented Kayley configuration spaces. And that just follows from the fact that for a non edge, for a distance for f, you have multiple realizations corresponding to different forward orientations. Okay? So that is the oriented Kayley configuration space. All right, now back to our theorem and just to kind of summarize what this was about, the first thing we're going to show is that our Kley configuration space, or our oriented Kayley configuration space is a set of disjoint closed real intervals. The second thing we're going to show is that any endpoint in our Klee configuration space, or respectively, the oriented one for any distance of f in that space, the corresponding realization is a realization of an extreme linkage. So in particular, three points are going to be collinear and they're going to kind of realize the distance on an extreme edge in an extreme linkage, whether it be the maximum one where you have, you know, the last construction, or a construction step fully stretched out, or the minimum one where the base pair is as close together.
01:04:45.024 - 01:05:50.906, Speaker A: Okay, and then like we said earlier, for any realization of our linkage and any vertex of our graph p of v, which is just the coordinates of the vertex, is a continuous function of the value of f on each closed interval in the oriented Cayley configuration space. And this is because we'll have the same forward orientation in one of these intervals, so things will kind of move nicely. And then consequently, because the coordinates of the vertices are continuous functions of the length of f, so too will be the length of any non edge. So the length of a non edge is going to be a continuous function of the length of f. Okay, so let's prove this. All right, so we're going to prove this by induction on the number of recombination steps. Okay, so given, and we're going to, we're going to just talk about oriented Kayley configuration spaces first.
01:05:50.906 - 01:06:52.696, Speaker A: And the results that apply to general Kaly configuration spaces will follow from this. So consider our oriented Cayley configuration space, and sigma is some given forward orientation, and we're going to proceed by induction on the number of recombination steps from our given knowledge f. Okay, when we have one recombination step, just consider the recombination step. So it adds v one. The base pair of vertices are the vertices of our not edge v naught v prime not. Okay, so the lengths of v naught v one and v prime not v one, which could be edges or implied bars are fixed because we're given realizations for t one and t two respectively. Therefore, we can apply the triangle inequality and we can compute the Kayley configuration space very easily.
01:06:52.696 - 01:07:29.958, Speaker A: The oriented one, it's just going to be this closed real interval given by the triangle inequality. So this distance minus this distance and this distance plus this distance. So one and two hold. So it's a set of disjoint closed real intervals. And in the base case, it's one interval. And any endpoint corresponds to a realization of some extreme linkage. Because an endpoint is going to be when these are collinear, either because they're stretched out or because these two, they're not allowed to overlap, remember? Well, actually, so it's not super obvious immediately to me anyways, why they are not allowed to overlap.
01:07:29.958 - 01:08:36.404, Speaker A: But remember, we're assuming that the edges and implied bars here have distinct nonzero lengths. And because of that, this non edge or these two points of this non edge cannot coincide. So. Yeah, all right, so one and two hold in the base case. Now for three, we want to show that v one is a continuous, the coordinates of v one is a continuous function of the distance between v naught and v prime, not. Okay, so we're going to get this distance for our non edge be a, we're going to let this distance, v prime not be one, be b and v naught v one bc then without loss of generality, we're going to place v zero at the origin. We're going to place v prime, not somewhere on the x axis, at a distance of a, away from v zero.
01:08:36.404 - 01:09:23.892, Speaker A: So it's important to note that v prime naught could be positive x axis or negative x axis. We haven't specified that. Okay, and then we're placing the third point. We're just going to place this above the y axis. Okay? So given a length for a, um, and we know the lengths of cmb, we can solve for the position of v one. It just requires solving this system, this quadratic system here, which we're going to see that it simplifies to one quadratic and one linear equation. And it's just basically solving for this intersection point of these two circles.
01:09:23.892 - 01:10:13.700, Speaker A: Right? So x squared plus, oh, and sorry, the coordinates of v one are going to be x and y. So x squared plus y squared equals c squared, that's just this radius. And then because v naught is not at the origin, we have x minus a squared plus y squared equals b squared, just this radius. Okay, so by some simple algebra, we can just rearrange these equations and do some substitution and we get that x is equal to this quotient times sigma sub one. So the sigma sum one here, remember sigma is our forward orientation. Sigma sub one gives us the local orientation for the first recombination step. And we multiply by sigma sub one here.
01:10:13.700 - 01:10:55.970, Speaker A: Because recall that we don't know where v prime nought is. It's either positive x axis or negative x axis. So this gives us the placement of x based on what we specify for the orientation and then y. The reason why we took y to be positive is because when we're dealing with these square roots, we're just going to take the positive square root. Just makes things a little easier. So we solve for y and we get this expression here. Now we want to show that x and y are continuous functions of the distance on f, which is a here.
01:10:55.970 - 01:12:05.544, Speaker A: So because our linkage is generic, a which is the length of f is going to be non zero. That just like we said before, v not and v prime not can't coincide because of the genericity of our edge links and implied bar links. Okay, so that means that these denominators aren't zero. Yeah, and moreover, since we're given the realizations of our maximal clusters, the coordinates, oh, okay. Yes, so this first sentence here establishes that the coordinates for v one are continuous, is a, coordinates are continuous functions of our non edge. This next sentence says that because our maximal clusters are given realizations of them are given, then the positions of the vertices are kind of fixed relative to where we place v one. So everything in this cluster is fixed once we position v one.
01:12:05.544 - 01:12:41.946, Speaker A: So therefore the coordinates of their vertices, the vertices and the clusters are continuous functions of x and y, which are the coordinates of v one. And because those are continuous functions of the distance of f, we have our result. All vertices in our realization are continuous functions of the distance of f. Okay, so that's the base case. The inductive step follows very easily and similarly. So we're going to assume these three claims hold. When n equals k minus one, we're going to show it for k.
01:12:41.946 - 01:13:38.874, Speaker A: So consider the kth construction step, okay, by the inductive hypothesis, for any vertex in g, sub f of k minus one. So the graph we get by performing k minus one recombination steps and. Hold on, let me see if I have a no, no picture here. Well, okay, we can just treat this picture as our general case. So instead of v naught and v prime not, this is vk or uk and wk. So all this is saying is that by the inductive hypothesis, everything in the graph, not including this last recombination step, all the vertices are continuous functions of the distance on our non edge. And consequently the distance or the length of any non edge is a continuous function of the length of f as well.
01:13:38.874 - 01:14:51.544, Speaker A: That's just inductive hypothesis. Hence we can write the length between the base pair of vertices in our kth construction step as a function gift of the length of our non edge f. All right, so we're going to let g be the function continuous function of lf, that gives us the length of between our base pair vertices. Okay, so just like we did before we by the triangle inequality, because implied bars, because of implied bars being fixed, and, and we know all the distances between uk and bk, wk and bk, we can do this triangle inequality, or we can get this interval from the triangle inequality. Okay, so this is, I mean, this is exactly as we did before we got this triangle inequality. Here we're doing the same thing, except just at a later construction step using the clusters. Okay, so as will kind of pointed out, there could be many different things that happen when we consider this triangle inequality.
01:14:51.544 - 01:16:02.506, Speaker A: So we're going to look at how the minimum and maximum values in this triangle inequality kind of remember the distance between u sub k and w, sub k is given by a continuous function g. And now this new triangle inequality may restrict this function. So all I'm saying is that imagine this without these two clusters and without v one, then the distance between v naught and v prime not is given by some function, or in this case u sub k and w, sub k. And then when we add these two clusters, we may restrict what distances these, what distance this non edge can take. Right, so here's kind of a picture of the rest of the proof, basically. So on the x axis here we have our distance for our non edge f that we're given. On the y axis we have our function g of lf, which gives us the distance between our base pair of vertices for the kth construction step.
01:16:02.506 - 01:16:53.696, Speaker A: So it's kind of this function, right, this curve. Now max and min are these two, are these two interval endpoints given by the triangle inequality. So min is the one on the left, max is the one on the right. Okay, so now we look at how max and min hit our function g on the left. Here you'll notice that max hits g at kind of its maximum, the global maximum of g, and min hits g at the global minimum of g. So it doesn't restrict the values that the distance between u sub k and w sub k can take at all. Right, so in this case, no new interval endpoints are going to be created.
01:16:53.696 - 01:17:57.434, Speaker A: So by the inductive hypothesis, everything still works out because we still have all our same intervals. On the other hand, if max and min intersect g like so, this creates new intervals that f can take. So in particular, when we reach this point, we are restricted by the maximum value of the triangle inequality, meaning we, before we could move u sub k and w sub k very far apart, but now we can't. Um, and it's not until we get to this point here that we once again get a realizable distance for u sub k and w sub k because of this triangle inequality. So this gives us two new intervals, and then the third way it can intersect is just at a single point here. It could be that only the minimum distance is realizable. Um, and that would give us a single point for lf.
01:17:57.434 - 01:19:03.124, Speaker A: Okay, so let me know if that any of that isn't clear. So this just says that the interval endpoints of this triangle inequality slice this function in such a way that applying the inverse function to these points where it gets hit may give us new interval endpoints in our oriented Kayley configuration space. But as we just saw in those pictures, those intervals are kind of, you know, well defined disjoint closed real. So one holds and then two was. Ah yes, so two. Well, what are these endpoints? They are points where either you hit the minimum of this triangle inequality or where you hit the maximum of the triangle inequality. So then that is exactly what we mean when we say the distance for f, then realizes an extreme linkage.
01:19:03.124 - 01:20:09.094, Speaker A: So one and two both hold in this case, okay, and then three, which showed that basically when we add these two new clusters, v, sub k, and all the vertices in the clusters added in the construction step, that adds v, sub k. Their coordinates are all continuous functions of our non edge f. So by a similar argument as we did in the base case, we can show that all these vertices, the coordinates of these vertices, are continuous functions of the base pair u, sub k and w, sub k. And that's following the exact same geometric argument, intersection of two circles, etcetera. So we know that they're continuous functions of our base pair u sub k and w sub k. And now we know that this distance, by the inductive hypothesis is a continuous function of lf we stated it was g here. So now you know, just compose them and you get continuous functions for all the new vertices in terms of the distance of f.
01:20:09.094 - 01:21:04.814, Speaker A: So then by induction the theorem holds for oriented Kayley configuration spaces. Okay, and then finally one and two were just that the Cayley configuration space is a set of disjoint close real intervals and that the endpoints realize extreme linkages. These two both hold between because for general Kaly configuration spaces, because this is just a union of oriented Kayley configuration spaces. So that's kind of an easy final step. Okay, so that proves theorem one. So any question about that, I hope that was clear. Otherwise I can answer questions at the end or go back over any part anybody didn't understand.
01:21:04.814 - 01:22:03.358, Speaker A: Okay, so remember the first result that we're trying to prove here was to give an algorithm to compute the Cayley configuration space. Well, theorem one gives us an immediate algorithm to do that. And here it is, it's called the extreme linkage realization algorithm. So all we're going to do is we're going to initially start with our graph g sub f of zero, which is just our non edge f, and we're going to let the oriented, oh, and we're going to iterate over all oriented Kayley configuration spaces. So for all sigma here, but for a particular one, we're going to start with our nonage f. And then we're going to set our Kayley configuration space to be the whole real line initially. Then at each recombination step we're just going to do what we discussed just previously.
01:22:03.358 - 01:23:21.214, Speaker A: We're going to perform the recombination step and then we're going to update our Kayley configuration space based on how the extreme linkages and the triangle inequalities that we get restricted the distance of f. Right, so we're just going to look at how these triangle inequalities affect the distances that f can take and we're going to just continuously update it for each recombination step. That'll give us our oriented Kayley configuration space. And then if we do this for all forward orientations, that will give us our complete Kayley configuration space because we just take the union of all of those. Okay, so a couple notes about the complexity of this. If our extreme linkages are not quadratically radically solvable, then realizing each one could take time exponential in the number of vertices. Um, because each uh, recombination step is going to be uh, the solution to kind of a more complicated system of equations that takes a very long time to solve.
01:23:21.214 - 01:24:33.454, Speaker A: Okay, um, and then the overall time complexity, uh, could be exponential in the maximum number of, uh, could be exponential in the number of intervals of our Kayley configuration space. Since, as we pointed out, the links of f and extreme linkages may not lead to new endpoints. So we could reach a lot of kind of dead ends. Okay, so I think I say this later, but I'll just say it now. We can do better than this algorithm, which we pointed out in the results, but we're not going to get into that today. But perhaps on Thursday in particular, we can do better for pairs g f that have qrs complexity. Okay, so here's an observation that makes sense just based on kind of our definition of extreme linkages.
01:24:33.454 - 01:25:44.794, Speaker A: So a pair g f has qrs complexity, which, remember, that meant that if you take an interval endpoint in the Kayley configuration space and you look at its corresponding realization of our linkage, then we can solve for the coordinates of each vertex using a treaty composition. So the pair g comma f has qrs complexity if and only if all of our extreme linkages of f are tree decomposable. So that means that when we're performing, and do I have. Let me find a picture. So, for example here, if we perform this construction one step at a time, the first extreme linkage is where instead of adding t one, t two, we just add an edge between v naught and v prime not. So that is tree decomposable. Next, we add these two clusters, and we consider the next extreme linkage.
01:25:44.794 - 01:26:35.920, Speaker A: Instead of adding t three, t four, we add an edge between v naught, v prime not. That gives us this triangle that's tree decomposable. And then finally, instead of adding t five and t six, we add the edge between u one and v prime not. And maybe it's a little hard to visualize, but this is also three decomposable. So if you have this edge, then starting from this edge, you can build this vertex with, you can add t three and t four if you have this edge right here. And then once you have t three and t four, you can create the rest. Okay, so this is an example where all extreme graphs are three decomposable.
01:26:35.920 - 01:27:19.074, Speaker A: So this graph has. Oh, sorry. This graph has qrs complexity. All right, so that's a very useful observation. So instead of defining it via, you know, the endpoint and the realization having to be solved for using a treaty composition, we're just going to say it has qi's complexity if all extreme graphs are treaty composable. Okay, now the next important thing is we have. Okay, so this kind of leads us to this next definition we have forward orientations.
01:27:19.074 - 01:28:13.874, Speaker A: Starting from an on edge, you can construct your graph kind of forward, and the forward orientation gives you the orientations at each recombination step. But we just said that for graphs with qrs complexity, all of their extreme graphs are tree decomposable, which in particular means that we can start given an extreme graph we can start from. Let me just show you here. So top left, our construction adds v one, v two and v three. And this prescribes a certain forward orientation. Now this over here is the extreme graph where instead of adding v three we add the edge v one, v two. Okay, so this has a certain forward orientation.
01:28:13.874 - 01:28:52.454, Speaker A: But then over here, since this is tree decomposable because it has qrs complexity, we can build this graph off of this extreme edge. We can start with v one, v two. Then we can add v zero. Then we can add v zero prime. But notice that when we start from the extreme edge, we need a different set of orientations with respect to the recombination steps starting from the extreme edge. And in this way we're building our graph in the reverse direction. We're starting from the extreme edge and then we're going backwards and building our graph.
01:28:52.454 - 01:29:46.564, Speaker A: So we're going to call the orientation that we have starting from our non edge a forward orientation, for reasons we discussed previously. But then we're going to call the set of orientations we use to build, construct our extreme graph from our extreme edge the reverse orientation. Okay, so this just kind of formalizes that. So the set of orientations tau, which we're going to use to denote reverse orientations corresponding to the construction of an extreme graph from the base edge. The extreme edge is called the reverse orientation. I hope that's clear. And then if we are given both a forward and a reverse orientation, we're going to call that a minimal orientation and we'll see why it's called minimal in a little bit.
01:29:46.564 - 01:30:20.572, Speaker A: Nice properties. If we specify both sigma and tau, we can say very nice things. So it's minimal in that sense. Whereas if we don't then we're going to have very bad things happen. So anyways, the point here minimal orientation is a forward and a reverse orientation given those two. Okay. Oh, and I also wanted to point out here, a and b here showed two different forward orientations.
01:30:20.572 - 01:31:08.346, Speaker A: In particular, v three is on one side of v one, v two, and over here it's on the other side. This c and d show realizations of the extreme linkage and in particular the max extreme linkage. So this extreme edge has the maximum distance, but it's got different reverse orientations. So starting from this edge, we place v zero on the right side of v one and v two, and then v prime, not on the right side. Down here we place v zero on the left and v zero prime on the right. So we have different reverse orientations. And then this shows the same thing, but instead of using the max extreme linkage, it's using the main extreme linkage.
01:31:08.346 - 01:31:49.604, Speaker A: So I won't go into that, but it's the same thing. Okay, so we've defined, we've come up with a new definition for QRS complexity in terms of extreme graphs, and we've defined a reverse orientation. So theorem two, this is what. Okay, so now we're going to prove theorem two. If we have time, hopefully. I think we should be able to get through theorem, too. Yeah, so we're given a generic linkage, we're given our pair gf, and we are given that g f has QRs complexity.
01:31:49.604 - 01:32:44.898, Speaker A: Okay, so given these things, we can say that there exists at most two continuous motion paths between any two realizations. If such a path exists, it can be found in time linear in the number of oriented interval endpoints it contains. So that's a little confusing, that phrasing. But basically, all I'm saying is what we talked about earlier, when you're moving along these motion paths, forward orientations could change. And when we hit an endpoint, we're going to change orientations. When we hit an endpoint in an oriented Kayley configuration space, a orientation is going to change. So we can find this path in time linear in the number of those endpoints that we hit.
01:32:44.898 - 01:34:06.646, Speaker A: So in other words, in the number of orientations that change. Okay, and then the reason we needed to define minimal realizations is because if our two realizations that we're looking at have the same minimal orientation, same forward and reverse orientation, then there exists a unique continuous motion path between them that preserves the minimal orientation and it can be found in constant time. Okay? So that's why minimal orientations are nice, because it restricts us to a single interval, or as we will see, it will restrict us to a single interval in our oriented Cayley configuration space. Okay? So to prove this, we need two lemmas, and we're also going to state a theorem, which we're not going to prove today, but we will hopefully prove tomorrow because it involves a lot of other kind of machinery that we need to talk about. So we're just going to assume this theorem for now, I will try to prove it next time, if we have time, so it won't just be some magical thing that we use. Okay, so here's the theorem. Consider a paired GF with qrs complexity.
01:34:06.646 - 01:34:44.174, Speaker A: If we fix a minimal orientation, then the oriented Cayley configuration space is a single interval. That's all it's saying. So we're restricting our Kayley configuration space to be values of f such that when we look at the corresponding realizations, they all have the same minimal realization type. When we do this, this oriented Kayley configuration space is a single interval. And then, moreover, if you look at the paper, it won't say this, but this is shown in the proof. So I've added it here because we need it. Moreover.
01:34:44.174 - 01:35:24.514, Speaker A: And correct me if I'm wrong, Doctor Sithram, if this isn't exactly true, but I believe it is. Moreover, for any non edge uv, the distance between this pair of vertices is a continuous monotonic function of the distance of f in this interval. So we already knew it was a continuous function from theorem one. Now we're saying that it's monotonic. Okay, so that's going to be very helpful. So theorem three just says minimal orientation allows us to restrict the Kali configuration space to a single interval. And everything behaves even more nicely on this interval.
01:35:24.514 - 01:36:08.598, Speaker A: Okay, so we'll prove this next time. And in doing so, we're going to obtain that better algorithm for computing oriented Kayla configuration spaces that we talked about. The reason that we're not proving is because proving this requires that we kind of go through all the details of this algorithm. And I think there's, I want to get to other things today. Okay? So we're going to assume this is true. Okay, so here's our first lemo. So for a generic linkage such that GF has QRS complexity, there is a continuous motion path between any two points in the same interval of an oriented Kayley configuration space.
01:36:08.598 - 01:36:57.914, Speaker A: And this motion path is contained in that interval. So we have two realizations corresponding to two values of f in the same interval of an oriented Kayley configuration space. And we're just saying that there's a motion between them and it stays within that interval. Okay, next, here's what. So recall that the endpoints of our intervals correspond to realizations of extreme linkages. What we're saying here is that no internal point in an oriented interval can correspond to a realization of an extreme linkage. So nothing can become collinear in internal points in these intervals.
01:36:57.914 - 01:37:49.474, Speaker A: Okay? So the proof of one is very easy. Here's our two points, lf and lf prime in our interval. They're two points in the same oriented interval. Okay, so because they're tree, because we have QRs complexity, all points in this interval correspond to realizations that have ruler and compass constructions, or in particular our tree decomposition. So that means that all the points between lf and lf have these constructions. Okay, and now we just notice that this gives us our continuous motion path. So just at each point perform this construction and you get our continuous motion path between this interval, lf comma lf prime.
01:37:49.474 - 01:38:40.390, Speaker A: Okay, so that proves one. Okay, now for the next part. Remember, we want to show that no internal point of an oriented interval corresponds to an extreme realization of an extreme linkage. So nothing can become collinear inside of these intervals. Okay? So without loss of generality, we're going to let lf be an internal point in our oriented interval. We're going to assume to contra, we're going to kind of do this by contradiction. So LF is an internal point of an interval and we're going to assume that it corresponds to a realization of the max extreme linkage.
01:38:40.390 - 01:39:38.974, Speaker A: So this is the without loss of generality part. We could have chosen the minimum one. The argument is almost identical. So we've got a point in the inside interior of one of these intervals, and it corresponds to a realization of an extreme linkage. This implies that the implied bars of the k three combination step are collinear, because when you realize an extreme linkage, in this case the max one, this means that your base pair of vertices are as far apart as can be, which means that our point v, sub k that we add is collinear with u sub k and w sub k. So we have one pair of collinear bars already in the interior of our interval. And the rest of this argument is just going to show that there's another set of collinear bars.
01:39:38.974 - 01:41:26.774, Speaker A: And that's going to contradict our genericity condition. Okay, so for a sufficiently small epsilon neighborhood around our internal point, l, not the realizations of g corresponding to these points, right? The kind of endpoints of our epsilon neighborhood have the distance between u sub k and w, sub k is less than l, sub e, which, sorry, maybe I didn't define l sub e, but l sub e is the distance between u sub k and w sub k in this extreme linkage. Right? So it's maximum. So since we've reached this maximum point on an internal point of our interval, we can kind of move to the left, move to the right, and we should have distances between u, sub k and w, sub k that are less than this maximum since we have a continuous motion. Right? So by theorem three, this distance here between the space pair is a continuous monotonic function of l if the minimal orientation remains the same. Right? That was what theorem three said. But we know that the minimal, or we, we know that this is not a monotonic function, because to the left of l not l, at l not minus epsilon, we are going, this distance is increasing because once it reaches l not, this is equal.
01:41:26.774 - 01:42:08.194, Speaker A: We've reached our maximum length between u, sub k and w, sub k. And then to the right of l not, it goes back down this distance. So it's not monotonic, which means by the contrapositive that our minimal orientation must change at l not. Okay, now remember, we're inside of an interval of an oriented Cayley configuration space. So that means that our forward orientation is the same. It doesn't change. So that means that the reverse orientation must change since our minimal orientation changed.
01:42:08.194 - 01:43:11.594, Speaker A: Okay, so recall that at this point l not, we have a triple of collinear points where this forward orientation is. It's not going to change. But we know that there's another triple of points where as we pass over this point, l not the reverse orientation must change, and this triple of points has to be collinear then. Okay, so that means that we have one pair, just from the definition of being a realization of an extreme linkage, we have one triple of points that's collinear. And then down here, because the reverse orientation changes, we have another triple of points that's collinear. That contradicts our generic city assumption of g delta, where we only have one triple of collinear points of adjacent collinear points. Okay, so that means that this internal point where it realizes an extreme linkage cannot exist.
01:43:11.594 - 01:44:06.874, Speaker A: Okay, so I think all I'm going to have time for is just this lemma real quick because it's a fast one, and then we'll end there before proving the theorem. Unless people want to see the proof of that, I think they're both kind of short. Okay, so that was lemma one. And just to recap what it says, there's a continuous motion between two points in the same interval, and no internal point can be a realization of an extreme linkage. Okay, limit two. If we have a generic linkage and our pair g f has qrs complexity, then along a continuous motion path, this is kind of what we've said before. Along a continuous motion path, the forward orientation can only change at endpoints of oriented Kayley configuration spaces.
01:44:06.874 - 01:45:00.944, Speaker A: Furthermore, only one entry in the orientation changes in this manner. So you hit an endpoint, your forward orientation is going to change by exactly one entry. Okay, so here's the proof. So let l not be a point along this path where the forward orientation changes. So to ensure continuous motion before and after this point, the orientation at this point must be compatible with the orientation before it and the one after it. Okay, so that just kind of makes sense. So since our linkage is generic, only one pair of adjacent bars may be collinear at any one time.
01:45:00.944 - 01:45:52.554, Speaker A: Hence, only one entry in the orientation may change at l not. Thus, l not is the length of f in a realization of an extreme linkage. And by lemma one, part two, which said that this can't occur at an internal point, we know that it occurs at an endpoint. So therefore that proves the theorem. We've shown that if you're at a point where your orientation changes, by our genericity assumption, only one pair of collinear or pair of adjacent bars can be collinear, and this is a realization of an extreme linkage. And by the previous lemma, this only happens at endpoints of our oriented interval. So that's lemma two.
01:45:52.554 - 01:46:40.044, Speaker A: Yeah, so I think I'm a, well, I've got two minutes, so I don't know whether I should, should I attempt to prove this real quick? The proof is just this, this long, or should I just stop here and wait till next time? You might want to just go ahead so that you can start on a fresh slate tomorrow. Yeah, okay. All right, so we'll prove this real quick. So I'm just restating the theorem here because we proved several other results. So just so you remember what we're proving now. So we have a generic language, we have g. F has qrs complexity, and we want to show that between any two realizations of our linkage, there are at most two continuous motion paths.
01:46:40.044 - 01:47:17.904, Speaker A: We can find it in time, such a path in time, linear and the number of oriented interval endpoints it contains. And if we fix the minimal orientation, then there's actually a unique continuous motion path between them and it preserves the minimal orientation and we can find it in constant time. Okay, so let's prove the first two things. The third one's easy. So the first two things we're looking for at most two motion paths, and we want to find them fast. So here's how we do it. So p and q are two realizations of g delta.
01:47:17.904 - 01:48:10.724, Speaker A: We're going to let p have forward orientation sigma, and we're going to compute the oriented interval containing p. So we know how to compute oriented Kayley configuration spaces. So we find where p is and we locate that interval, okay, by lemma one, part one, it told us that within an interval there's continuous motion, so we can continuously move in this interval. And in particular, we can travel to an endpoint. By lemma five, the next reachable oriented Kayley configuration space, not interval. The next oriented Kayley configuration space that we can reach is uniquely determined by the single orientation entry that changes at the endpoint. So we hit this endpoint and one orientation triple changes.
01:48:10.724 - 01:49:02.954, Speaker A: Our one orientation value changes. This gives us a new forward orientation and a new oriented Kayley configuration space. But this Kayley configuration space is uniquely determined. Okay? Furthermore, by theorem one, we know that inside of this new Cayley configuration space, the intervals are disjoint. So in particular, there's at most one interval whose endpoint is the same endpoint as the original interval we started with. So we can only reach one unique interval in this new Kaly configuration space. So all I've described here is we're starting in an interval, we're reaching an endpoint, we're switching orientations, which moves us to a new unique interval, and now we're going to move in that interval.
01:49:02.954 - 01:49:51.058, Speaker A: So we just repeat this movement until either we find q or we return to p. If we find q, there's a continuous motion. If we return to p, you can't get to q. Okay? And then the fact that there are two possible continuous motions, it's really easy to see. When we start at p, we can either go left or right to two different endpoints, and those will give us our two different motion paths. And then the complexity is clearly as we had hoped, because we're just basically counting the number of these oriented endpoints that we encounter. Okay? And then part three, since we're, since we have a minimal orientation, sorry, right here.
01:49:51.058 - 01:50:47.104, Speaker A: Since we have a fixed minimal orientation, we're in a unique interval of the oriented Kaylee configuration space. And by lemma one, there is a continuous motion between or inside of an interval. So that gives us our continuous motion between two realizations with fixed minimal realization, minimal orientation. Okay, so that proves theorem two. So I'll stop there next time. So I want to start with these two results, which is we're going to characterize graphs with QRS complexity, and then we're going to show that QRS complexity is actually just a, sorry, this shouldn't say generic is just a property of graphs. So if g f has qrs complexity for one non edge, then it has it for all non edges, such that g union f is tree decomposable.
01:50:47.104 - 01:51:05.284, Speaker A: So that's all I have for today. I think we just went, like, three minutes over. So if you have any questions, feel free to ask, but that's everything then. Thanks.
01:51:06.064 - 01:51:08.084, Speaker B: Thank you, William. That was great.
01:51:14.544 - 01:51:56.014, Speaker A: Any questions? Any further questions? Maybe you can show some of the videos next time. More of the videos? Yeah, from the kmos paper. Oh, yes. So I'll talk to you about that, because I think some of the links are broken. I was having trouble finding some videos, but, yeah, I'd like to show some more videos. The KMOS software actually implements the algorithms and techniques in these papers. And in particular, that strand beast.
01:51:56.014 - 01:52:25.414, Speaker A: This one. There's another paper called how the beast really moves. And it details the Kaylee configuration space of the strand beast. Because before, there was only one motion path kind of known. And that was what you see in the video, these things walking. But there are other motion paths which correspond to configurations of these wings or these legs. Different orientations of those.
01:52:25.414 - 01:52:28.794, Speaker A: So, yeah, maybe I can find some more videos of that.

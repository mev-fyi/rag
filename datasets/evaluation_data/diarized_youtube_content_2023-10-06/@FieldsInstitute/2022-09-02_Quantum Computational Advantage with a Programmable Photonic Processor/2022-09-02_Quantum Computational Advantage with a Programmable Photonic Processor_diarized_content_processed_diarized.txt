00:00:00.240 - 00:00:47.602, Speaker A: Well, thanks for the introduction and thanks for the organizers for setting up this really nice conference. It's been like three years since I saw people in 3D, so it's great to finally see that you have depth and you're not only like heads on a screen and. Yeah, so this is work that I did while I was at Sanadu down the street from here with the team that Jonathan leads and also with people at nist. And it's on quantum computational advantage with a programmable photonic quantum processor. Let me tell you a little bit about that. So this is kind of how I want to break the talk. I want to tell you a little bit about what's quantum advantage then? Sort of a no go result that tells you if you try to build this machine that you want to show quantum advantage with, well, that's not going to work.
00:00:47.602 - 00:01:42.736, Speaker A: And I'm going to try to argue why that's going to be the case based on drawing blobs of different colors. Then we will show a scalable architecture that actually we thought it would work. And finally, I also actually get to show you the machine that Jonathan's team and other people at Sanadu built. Okay, so I guess the main motivation for why doing these types of experiments goes to this thing called the extended short story thesis that takes the name of these two folks, Choring and Turing. And this is something I've taken from the paper by Scott Aronson and Alex Arkhipov that you see there, where they say the extended church Turing thesis says that all computational problems that are efficiently solvable by a realistic physical device are efficiently solvable by a classical computer. That's actually not what it says. It says a probabilistic Turing machine.
00:01:42.736 - 00:03:02.970, Speaker A: But since I tend to be confused by this term, I just replace it without loss of generality by just a classical computer. So this is a statement that says there are things in the universe that you can build and then whatever that thing that you build, you can simulate it efficiently with a classical computer. And to some extent, if you are say a computational quantum chemist or a condensed matter person and you have been thinking about these systems with many electrons, you know, that somehow annoys you because you have these problems that exist in the real world where you have electrons going around a lattice or electrons going around a nuclei, and you throw the best that you have and supercomputer and very clever methods and well, you make some advances, but still there are things that you cannot do. And more generally, well, this leads to this natural question which is, are There computations a quantum computation computer can do efficiently that a classical computer cannot. So that's kind of the main question that motivates these experiments. So if we had a universal quantum computer that is fault tolerant and scalable, then we can just run Shor's algorithm. And I will contend that contrary to what Juan Miguel says, this is how you will make money, just by factoring and just finding the secrets of everyone.
00:03:02.970 - 00:04:04.140, Speaker A: But we don't have that yet. So we come up with other architectures for quantum computer that are non universal and that still allows us to disprove or to find these problems that a quantum computer can do efficiently and then a classical computer cannot do efficiently. So I will of course focus on the first one, boson sampling. So let me tell you a little bit more about what this is. This is the statement of the problem, or at least the physics version of the problem, which is given an interferometer which, which is something that you can put on an optical table or you can print out on a chip, as Raj showed us on Monday, that takes M modes, then you can send some sort of non classical light inputs into this interferometer. They do whatever quantum mechanical thing that photons do inside interferometers, they come out and then at the output you put this photon number resolving detector or threshold detectors depending on what you have in your lab. And the task is precisely to sample from the distribution.
00:04:04.140 - 00:04:44.380, Speaker A: So every time you run the experiment you get a collection of random numbers. And then you want to be able to do this efficiently with a classical computer as opposed to what you will do with a quantum computer, which will be precisely to build this optical setup. So let me tell you a little bit more about what these three things mean. So the first one is, I'll remind you a little bit about classical optics and how you building interferometers. So classically there is this thing called beam splitters that basically allow you to split beams. So you send some light and it can be transmitted or it can be reflected. And there is a linear relation between the light that you send in, which is to the left, and the light that comes out, which is to the right.
00:04:44.380 - 00:05:29.896, Speaker A: And this linear relation is specified by these matrix elements T that you see there. So because it is a linear relation, then we can sort of put things inside a matrix. And one particular useful matrix that has been mentioned many times is when you have a 50, 50 beam splitter. So you will have something like what you see there at the bottom, where half the light gets transmitted or half the light gets reflected. If you just use one of the ports. So now the nice thing about this is that now I can change a little bit how it looks, because theories are well known to screw up how these things look. So I will change this by just the circuit diagram that you see on the right, where I still have fields going in the horizontal direction.
00:05:29.896 - 00:06:12.594, Speaker A: And whenever a beam splitter happened, I represent it by this vertical line with two dots at the end. And the nice thing about working in this way of drawing things is that you can now start to do more complicated things like interferometers, which are literally just connections, collections of beam splitters that you put for different modes. So, for example, here we have three modes. Then there is a beam splitter between the first two modes. That's the matrix that you see there, where you see that there is a one on the bottom right corner, which is to say the third mode is doing nothing. Then I can do now this for the second and third mode. And now the top left corner has a one for the same reason that the previous one had a one at the bottom right.
00:06:12.594 - 00:07:06.130, Speaker A: And then I can do this again. And now I have these three matrices. And remember that because there is a linear input output relation, then the composition of these things is going to be just matrix multiplication. So I just multiply that, and that tells me how the electric fields that come on the left will leave on the right. Okay, so one thing that I want you to notice as well is that for light from every mode to be able to go out in every possible mode, the depth of this interferometer, the number of layers that I have to stack up here, is roughly proportional to the width. So here I have three modes, and I have to stack up at least three layers so that every possible bit of light goes out in every possible mode. And then this matrix that I obtained by multiplying all these small matrixes is what I will call T and is the matrix that represents the interferometer that I've built.
00:07:06.130 - 00:08:00.316, Speaker A: Yeah, and as I said, you know, if you want to have interactions between all the modes and the interactions that you can do are just local interactions, then you're going to need something where the depth scales with the width. And this is going to be important later on. All right, so now I told you what an interferometer is. Now let me tell you about how single photons, as opposed to classical light, interact or, or how they behave when they meet in interferometers. So this is perhaps a canonical example of this, which is called Hongo Mandel interference, where you send two single photons that are identical in every degree of freedom, except on the fact that they're coming in different directions and they meet into this interferometer. And so there are these Feynman rules that allow you to calculate, for example, what is the probability that they exit in different ports. And the rule is that you have to consider these two possible events.
00:08:00.316 - 00:08:58.320, Speaker A: The first one is where the two photons get reflected, and the second one is where the two photons get transmitted. And because these two photons are indistinguishable, we have to take the probability amplitudes of the two possible ways to get into this final result, we have to add them up, and then we have to take the modulus square of that. And then similarly, if I want to know what's the probability that the two photons leave on the right, or sorry, on the top or on the bottom, then I have these other two possibilities, right? And now, for example, I remember that I told you about this 50, 50 beam splitter. So I take that matrix there, I plug it in the formula on the right, I get that that number is zero. So this is a very important phenomenon for people that are thinking about photons, because even though they're very hard to make to interact, this gives you some sort of effective interaction where they always live together, they're always bunch. And this is called the Congo model interference. And just by symmetry you can see that the two other alternatives should have a probability of one half.
00:08:58.320 - 00:09:34.766, Speaker A: Okay, so that's how photons behave. We can now maybe think of a more complicated example where now I send three photons and I want to know what's the probability that the three photons come out in different ports. Notice that there are other alternatives, for example, that the three photons exit together, or you have two and one in a subset of the modes, things like that. But I want to focus on this one. So now for this case I have a number of possibilities. So this is the first one, the first two, where basically you can think that each photon goes through straight. Then you have these three where two photons get permuted.
00:09:34.766 - 00:10:06.750, Speaker A: And finally you have two extra more. And you can see that this thing is kind of a degree 3 polynomial in the entries of this interferometer. And actually the sum of these things has a name the the mathematicians gave to some time ago, and it's called the permanent of that three by three matrix. So the permanent that you see there is defined in terms of a sum over the elements of the symmetric group. So this accounts for the different permutations that we have there. And then you have to multiply each. For each of those permutations, you multiply different t's where you take different entries.
00:10:06.750 - 00:11:11.900, Speaker A: And this might be familiar to something that you learn in linear algebra, which is called the determinant, which is almost like the permanent, except that you have to account for this minus sign that comes with the sign of that permutation. And one very important property of the permanent is that unlike the determinant, the permanent of a product is not the product of the permanence. So that's going to be important later, because even though these two functions are defined in terms of sums over the symmetric group, because of this property, determinants can be calculated in polynomial time. I can take a matrix of size 1000 by 1000 and put it on my laptop. I have the answer in microseconds. But if I try to calculate the permanent of a matrix of size 1000 by 1000, I think I tried to estimate this, and it will come out to like many times the age of the universe in the most partial supercomputer that we have. So just because of that property, okay, so this is the case with three particles.
00:11:11.900 - 00:12:17.590, Speaker A: And now I told you how these single photons interact. And then the general case is I'm going to send some number of photons on the left, they do their interference in the interferometer, and then for a certain, I'm going to get some random output. And the probability of that output is given by this object that you see there. That depends on the permanent that I described before of the matrix T that represents the interferometer that I obtained by multiplying all these small matrices that represent the beam splitters. And to give you an example, if I say take a 4 by 4 interferometer where I send three single photons in the first three inputs, and I want to know what's the probability that I get one photon in the first input and two photons in the third input. Then what I do is the inputs tell me which columns of this matrix to take, and the outputs tells me which rows of this matrix to take. And in the case where I have repetitions, or where I have numbers that are greater than one, that means that that particular row has to be repeated.
00:12:17.590 - 00:12:55.282, Speaker A: So I do that. I construct this matrix that you see there, and then I take the permanent that tells me the probability that this event happens. If these were fermions, by the way, then this permanent will be replaced by a determinant. And. And if you plug that matrix there that has two repeated rows, you will find that the probability that these two fermions come together is zero, which is precisely what you want from the Pauli exclusion principle. But somehow when you do this with bosons, you get this other quantity called the permanent that has some built in complexity. Okay, so this is what Scott Aronson and Alex Arkhipov did.
00:12:55.282 - 00:13:42.454, Speaker A: They studied this problem and they showed that on the reasonable complexity theoretic assumptions, performing this task in a classical computer, namely generating this set of random numbers that distribute according to this modulus square of permanence, is very unlikely. Because if you could do that, then you could solve certain sharpie hard problems with a special type of classical algorithm. And computer scientists believe that's very unlikely. And for the physicist, this is like saying you cannot build a perpetual motion machine because you will violate the laws of thermodynamics. But we believe that you cannot violate the laws of thermodynamics, so you cannot build this perpetual motion machine. So, okay, so people set to build these things. The very first demonstrations had three or four photons.
00:13:42.454 - 00:14:39.944, Speaker A: Then, in what is an impressive experiment by people in Germany and China, including Chaoyang, who just talked a moment ago, they get up to 20 photons from a quantum dot source and they interfere them into a 60 mode interferometer. But that's still not going to get you to quantum advantage, because actually some really smart people came up with an algorithm that allows you to simulate this and even 30 photons on a laptop. And despite the claim that this dimension of Hilbert space is the thing that makes things complicated, that has nothing to do with the complication, it's just the fact that that to simulate this boson sampling, you have to calculate something that is like a permanent. So it's just the number of particles that tells you how hard it's going to be. And the reasonable estimates that we have is that you have to reach about 50 single photons going to an interferometer. And despite many efforts, I've heard rumors of people trying to build this with maybe 30 photons. That's still not going to get you to quantum advantage.
00:14:39.944 - 00:15:23.890, Speaker A: So you want to figure out, okay, what can we do? So one way to go about this is there is other ways to prepare non classical states of light. And one of the most well known is to use quantum nonlinear optics. So there is this process called spontaneous parametric down conversion, where you send a pump classical beam, which is the blue one, and then every now and then, one of the blue photons is split into two Photons. And you can think of this as being mediated by this Hamiltonian which, where R is the blue and A and B and the orange and red. And well, it kind of looks like this. So a photon that is blue gets destroyed and you make two photons that just leave. And those two photons are born at the same time.
00:15:23.890 - 00:16:03.394, Speaker A: And moreover, they have a number of interesting properties. In particular, they will allow you to make non classical light. And you can use actually this type of state to get yourself a single photon source. With a caveat that I'm going to tell you about in a moment. And the fact is that when you make these two mode squeeze states that you make with this spontaneous parametric tank conversion, they are strongly correlated in the photon number. So whenever you learn that there are three photons in the red beam, you know that there are exactly three photons in the orange beam. And this was shown in a beautiful experiment by the people from Paderborn and Nist where they created precisely this state.
00:16:03.394 - 00:16:48.746, Speaker A: And then they look at the joint probability distribution of these two modes and they find that except for the fact that there are always losses, they find precisely this very nice correlation that I'm telling you about. So why is this useful? Well, because if you measure a single photon here, you know that you made a single photon there. So this is a heralded single photon source. And so you want to make a state like this with one photon. What you can do is you can make a two mode squeezed state that you can measure one half of it and make sure that you get a one. And then you know that you have prepared a single photon in the other arm, and it turns out that the probability that this succeed is bounded by one quarter. That's the best that you can hope so 25%.
00:16:48.746 - 00:17:32.370, Speaker A: And for this you require first of all to have no loss, which is quite challenging. And you also, very importantly, you need photon number resolving detectors. If you don't have photonumber resolving detectors, that somehow you have to restrict a probability that is in practice much less than one quantity. So with this in mind, you can now kind of do this in parallel. You can make many of these two mode squeezed light sources. You can reroute one half of these photons directly into detectors and the other half you send into an interferometer. And then this actually ends up being just like regular boson sampling, except that you don't know where the photons are coming because sometimes the heralds, they tell you yes, there was a photon, and sometimes they tell you no, there was no photon.
00:17:32.370 - 00:18:05.390, Speaker A: So this is called scattershield boson sampling, or, well, it was dubbed the scattershot boson sampling by Scott Aronson. This is how the people who came up with the idea titled it. So this is a way to go about this. And the takeaway from this is. Oh, sorry. That these parametric sources can be used as single photon sources with the caveat that they're just probabilistic. Now, there is a nice kind of circuit identity which says if you want to make a two mode squeeze state, one way to do it is to take.
00:18:05.390 - 00:18:27.410, Speaker A: Sorry. And there should be a two here. So this is a two mode squeeze state. You can do it by taking two single mode squeeze states and then just mixing them in a 50, 50 beam splitter. And then you can do this many, many times. So you can do pairs of single mode squeeze states like this and this, this and this. You can do 50, 50 beam splitters.
00:18:27.410 - 00:19:22.850, Speaker A: And then that's equivalent to what you have in the right to have in just two mode squeezed light sources. And then you could build this scattershot boson sampling. But this is still problematic because the rates that you're going to get from here are still going to be very small. So you're still not going to be able to get as many photons as you would like to be able to claim quantum advantage. So the clever idea that was proposed by the people from Paderborn was to say, look, to some extent you can understand all of these as being just one big interferometer with a special structure, namely that, for example, the light from the first mode has no chance of exiting in the second mode. It can only exit either in the first mode or in the second half of the modes. Right? Because there is no path, there is no interferometer connecting this rail, the first rail and the second rail.
00:19:22.850 - 00:20:08.010, Speaker A: So they say, why we don't forget about that. And we just think about the problem of having access to single mode squeeze states and mixing them in an interferometer that I call T prime. And that is the problem of Gaussian boson sampling. All good. So this is the main idea. This was proposed by Craig Hamilton and Igor Jecks, who are, or well, at least Craig was based in Prague and Regina, Linda, Sonia and Christine Silverhorn, who are in Paderborn, they said, ok, let's study this problem directly, the problem of sending squeezed light in all the modes into an interferometer. And so the first question that we want to answer is, well, what is the function that describes the probabilities of this event.
00:20:08.010 - 00:20:44.650, Speaker A: And so they set out to do that and they find that is related to this quantity here, called the Hafnian. So let me tell you how to read this equation. So, first of all, there are these squeeze states on the left, and they are parameterized by a certain quantity that tells you how much they are squeezed. Then they go into this interferometer and then you get some collection of photons at the outputs. So the first difference from boson sampling is that these quiz states don't have a defined number of particles. So they can have zero photons or two photons, or four photons, or six photons, and so on and so forth. So now the total number of particles is undefined.
00:20:44.650 - 00:21:47.126, Speaker A: Sometimes you can get 60 photons, sometimes you can get 100, sometimes you get 20. And then the probability that you get a particular pattern of photons, so the probability that you get a specific number of photons in the first mode, in the second mode, all the way to the last mode, is given by this quantity that you see there, called the Hafnian, which is like the older brother of the permanent. And the Hafnian is defined also again in terms of the symmetric group, in this case of the symmetric group of an even number of objects. And importantly, this Hafnian allows you to calculate the permanence. So if you have some magic box that calculate hafnions, you can also use it to calculate permanence. And since permanence are hard to calculate, then we also expect that these hafnions are, at least in worst case instances, as hard to calculate as these permanence. And then the matrix that you put inside this hafnian contains information both about the interferometer and about the amount of squeezing that you send.
00:21:47.126 - 00:22:42.310, Speaker A: So this R parameterizes how much you squeeze the vacuum fluctuations, and this T describes what is the transformation that these modes had on the interferometer. So under reasonable conditions, then Hamilton and his collaborators show that this problem is also hard. Actually, with Jens and Bill Pfefferman and Jens Student and Abhinav and Arthur, we further elaborate on this complexity arguments. And there is also a related work, although takes a different path about also arguing why Gaussian boson sampling is hard. And in the second world, we kind of remove some of the reasonable complexity theoretic assumptions, or we can actually just circumvent them directly. So that's the only thing that I'll say about these arguments of complexity. Okay, so we want to build these things.
00:22:42.310 - 00:23:18.304, Speaker A: We have this problem that is at least more amenable to be built, because you don't need single photon sources, you just need squeezed light. And for squeezed light, the only thing that you need is a nonlinear material and good lasers and very good experimentalists. But there is also an extra caveat with this and is that there is always loss. So far I was always saying this is my interferometer. And there is the idea that the photons that come in must go out, which means that this matrix U is unitary. But of course that's not true. So we always have some loss.
00:23:18.304 - 00:24:19.186, Speaker A: So we're always going to have this factor eta that tells us what fraction of the energy that comes in goes out. And I'll represent this loss by this yellow thunder that you see there. And now if we have a network of interferometers, say for instance here, to mix four modes, then you're going to have a little bit of loss in each of the components. If you're building, well, if you're building an interferometer out of local beam splitters, and of course, if each of those components has a small loss eta when you compound this over many layers, then this is going to start to scale exponentially with the number of modes that you use. If the width is proportional to the depth, and this is the first no go result. We show that for most linear architectures where photon loss increases exponentially with the circuit depth, noisy gbs simulating this setup where you have loss can be done efficiently in a classical computer. And I'll try to argue why that happens.
00:24:19.186 - 00:24:57.940, Speaker A: So let me make some drawings here. So this is like to think of the electromagnetic field as a point in phase space. You have the in phase quadrature, you have the out of phase quadrature. And if you want to add a little bit of quantumness on top of that, you don't think about a point, you think about a blob, because there is noise. And so we have the vacuum that has this form, that is round, and it has the same noise in both quadratures. And we represented by this covariance matrix, which is just the identity saying there is the same amount of noise on both quadratures. Then we have squeezed states where now there is some excess noise in one quadrature and there is some suppressed noise in the other quadrature.
00:24:57.940 - 00:25:53.638, Speaker A: And of course we make sure that we don't violate the uncertainty relation. So these two things have to be inverse proportional. And then when loss happens, what happens is that essentially you take the average of these two situations. So when you apply loss to a squeezed state, literally what you're doing is mixing it with vacuum. So you have that the covariance matrix of a lossy squeeze state is the thing that you see on the right. An important thing to notice is that even after loss happens, there is still a little bit of squeezing. So you see that the red blob is still below the, the blue circle, right? Now, this state that has a little bit of squeezing is, at least by eye, not too different from this state that has no squeezing whatsoever, which we call a squash state that has exactly the vacuum fluctuations in one quadrature and it has some excess noise in the other quadrature.
00:25:53.638 - 00:26:28.152, Speaker A: Turns out that because this state has no squeezing, when we mix these types of states in an interferometer, these we can simulate efficiently. And the reason for this is that these states have something called a positive p function. So they can be written as mixtures of coherent states. And once we know that they're mixtures of coherent states, we can just pick up some coherent states from this mixture, send them into an interferometer. Coherent states just interfere like classical waves. And at the output, when we need to measure, the number of photons of a coherent state is just a Poisson distribution. So that's an easy task to do.
00:26:28.152 - 00:27:11.720, Speaker A: You can do it in cubic time. And now the argument is that this situation where you have pure nice squeeze states with a loss interferometer is equivalent to this situation where you have lossy squeeze state, where there is still a little bit of squeezing. But this situation is actually very hard to distinguish from this situation where there is no squeezing whatsoever. And the only thing that you have is pure excess noise in the vertical quadrature. And so, more quantitatively, for a finite case scenario, we derive this inequality that looks a little bit daunted. But I can explain where we say, okay, maybe your detectors have some dark current rate. If not, you can set it to zero.
00:27:11.720 - 00:27:44.976, Speaker A: You have the total transmission of your interferometer, which scales like eta, of one particular beam splitter, to the power, the number of modes. You have the amount of squeezing that you sent, and you have the number of input squeeze states. And then there is parameter epsilon that tells you how much discordance between your simulation and the actual experiment you're willing to tolerate. So sometimes you say, I want an exact simulation. You put that epsilon to be zero. Sometimes you want a simulation with 1% error. Then you will replace that epsilon by that amount.
00:27:44.976 - 00:28:33.036, Speaker A: And moreover, when you think a little bit more carefully about this inequality, you find that if the loss scales exponentially with the number of modes, then it becomes trivially to satisfy this inequality or to be arbitrarily close to the ideal situation. And so you can do it. So that's the first, that large, deep, programmable circuits are very lossy and this can make them classically simulable. So you want to not be in a situation. So what can you do? Well, one alternative is to go the way that, for example, the USCC group did, where they didn't build the interferometer out of small parts, where you start to have this exponential accumulation of loss. Instead you just print a big interferometer in glass that is extremely ultra loss. But then you sacrifice the ability to program this big interferometer.
00:28:33.036 - 00:29:06.448, Speaker A: It's just whatever was printed that day in your piece of glass. Another alternative, which is what we propose is the following. So maybe the problem is that we should think beyond having local gates. So here we have local gates, so gates that connect nearest neighbors. But we can also have gates like these ones that connect modes that are far away. And here I'm also representing the modes one after the other in one dimension. But it can also be useful to represent them in two dimensions, as you'll see in a second.
00:29:06.448 - 00:29:45.296, Speaker A: And then we can do more of these long range gates and we can get something like what you see on the right. Now you might wonder how you can do this experimentally. And the solution is both simple and elegant. And it's just to use fiber loops. And this is an idea that was proposed by Keith Moats and Jonathan Dowling. And so you can do something like this, where, for example, if you need to mediate a short range interaction between these modes, what you do is you just store one of them in a loop that contains exactly one mode when they meet into this beam splitter that gives you exactly what you want. But Moreover, when the Mode 4 exits, it can meet with Mode 1 and gives you precisely this interaction between two modes that are three time bins apart.
00:29:45.296 - 00:30:11.382, Speaker A: You can get creative and do something like this, where you have three loops that store 1, 4 and 16 modes. Or you can do it with 1, 6 and 36. And then you can look for example at the transmission matrix that describes the experiment. Looks like that is not a complete matrix. The white stuff is actually zero. So not all the modes can talk with all the modes, but most of them can talk with each other. And so this is the solution.
00:30:11.382 - 00:30:37.376, Speaker A: Let me skip this. And so with this idea in mind, the people at Sanadu precisely built this machine. So they built a source of squeezed light that you See here, they took these three different loops of length 1, 6 and 36, and then they send them to photon number resolving detectors. And I'm saying this as it's not a big deal. It's extremely complicated. You need to keep these loops stable. You need the detectors to count the right number of photons.
00:30:37.376 - 00:31:14.140, Speaker A: You need this OPO to produce a squeezed light with a very specific characteristic. But I'm going to gloss over that. Sorry, Jonathan. And so now we have this machine and we have to validate it. We have to say, how do we convince a skeptical referee from a journalist that what we did is exactly what we claim we did? So in this case, what we can start to provide is circumstantial evidence that what happened is what we believe it happened. So the first thing that we can do is to start to compare different adversaries or different hypotheses that will explain this data. So here is one way to compare this.
00:31:14.140 - 00:32:19.012, Speaker A: We will look at the photon number correlations for three different, actually four different adversaries or for different hypotheses, namely, that we send squeeze states, that we send thermal light, that we send these squash states that only have excess noise. And the fourth one is just squeeze states that don't interfere with each other. For example, if you send the squeeze states after each squeeze states have left interferometer, and what we find is that the ground truth, namely squeeze states, are the one that correlates the best with this data. So that's kind of one nice picture. Another thing that we can think about is which of these will explain the total photon number distribution of the data. And for that we see again that the one that explains data best is precisely the one that corresponds to the ground truth. Then we can also ask ourselves, how long will it take us to simulate this problem using the best techniques available, which were developed by Jake Palmer from Anthony Lang's group and coworkers, and also by Bryn Bell and a number of other people from Raj and Ian Walms team in Imperial.
00:32:19.012 - 00:33:05.890, Speaker A: So they came up with this formula here that says it depends on two things. One is this geometric factor, and it's geometric because it's the geometric mean of something, not because there is some geometry. So if you have a sample that has certain number of photons, you calculate this number G, and then you take it to the power, the number of detectors that collected at least one photon. And so we can do this. For our experiment, we have photon number resolving detectors, which means that our G can be greater than 2, because sometimes we can collect 3 or 4 or 5. And we can also compare it to other experiments like the one from USDC, where they only have access to threshold detectors and they cannot see the photon number. And so in that case, G is always two.
00:33:05.890 - 00:34:19.182, Speaker A: And that's why sitting here at the bottom. And then we see that in our case, on average, one of these samples will take about 9,000 years to be generated with this method, which is the best that we know so far. Finally, we can look at this idea of cross entropy, which is to ask, we have this collection of samples from the experiment and we can generate samples from other classical adversaries that we can generate efficiently. And then we calculate the probability of those entropies according to the ground truth. And then we take the logarithm, and then we see that the samples that come on top, in some sense the samples that are most likely to be coming from the ground truth are precisely the samples of the experiment for different adversaries. Particularly important, one of the adversaries that we consider is this greedy adversary, which is an idea that the Google team introduced to spoof this same benchmark for the USDC experiment. And finally, we can also ask, given the samples, we can ask of all these hypotheses, which one explains the data better? So we can take the probability of a sample or a collection of samples given hypothesis A and given hypothesis B.
00:34:19.182 - 00:35:01.556, Speaker A: And I can take the ratio, if that ratio is greater than one, that means the probability according to hypothesis A is more likely. And because this is going to start to blow up really fast, what I take is the logarithm, and this is this Bayesian log average, and we plot it. We are here comparing these different hypotheses against the ground truth. And in all cases, the fact that this number is positive means that the most likely explanation are squeezed states. And with that I'll just show you this quick summary. And also to mention, Javier has a poster about how to apply some of these ideas for threshold experiments and how you can spoof at least the first version of Yushang. And also to say that Jonah and I are looking for a postdoc.
00:35:01.556 - 00:35:06.260, Speaker A: So if you want to come to Montreal, you can talk to me. Actually, since I'm here, thanks.

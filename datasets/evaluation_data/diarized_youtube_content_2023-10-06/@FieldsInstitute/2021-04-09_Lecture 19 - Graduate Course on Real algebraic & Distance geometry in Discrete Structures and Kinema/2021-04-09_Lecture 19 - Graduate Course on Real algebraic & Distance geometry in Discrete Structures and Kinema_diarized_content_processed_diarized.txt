00:00:00.280 - 00:01:07.184, Speaker A: On Tuesday, we covered roughly these first seven items, and these were giving sort of the basic ideas of how to solve polynomial systems of equations by what's called homotopy continuation. And you can solve many different kinds of systems of equations by homotopy continuation. But when your equations are defined by polynomials, then everything works a lot better because you have guarantees on finitely many solutions. You can find start systems, so you can guarantee that you have found all the isolated solutions. And, and this is sort of what we, we talked about the basics last time. So today the plan is to keep going. And I imagine that we'll roughly get through these eight through eleven.
00:01:07.184 - 00:02:29.933, Speaker A: So just to give a preview, monodromy will be a way that a method you can use that takes loops in parameter space. And if you can specify at least one solution, then often you can produce all the solutions by a monodromy action on the points in the fiber above that parameter. So we'll explain that first, we'll talk about over determined systems. So for everything we've done so far, we needed n polynomials in n variables, which is called a square system, and we needed it to be, to have isolated solutions. And that is what homotopy continuation can do very well. So at first glance, this seems quite restrictive. Many objects that we're interested in are specified by less equations than the number of variables, or more equations than the number of variables.
00:02:29.933 - 00:03:40.820, Speaker A: And so it turns out that the way to handle positive dimensional solution sets also involves the method of handling over determined solution sets, which you would expect to have negative dimension or at least zero dimensional. We'll talk about that. Then, once we have that tool, we'll be able to handle the underdetermined systems, those that have more variables than equations, whose complex solution sets are necessarily positive dimensional. And the concept of witness set will lead to the numerical irreducible decomposition, which is the numerical analog of the irreducible decomposition of an algebraic set into its irreducible components. And. Yeah, so that's the plan. Okay, let's get rid of all these red arrows and things.
00:03:40.820 - 00:04:34.308, Speaker A: I don't know why I'm doing this. And we're done. Okay, so let's talk about monitoring. Maybe over here is a good spot. So, if you'll remember, a crucial tool is parameter homotopy. And that's where we see our system of equations in, let's say n variables and n equations to be actually just one in a, in a, in a family of equations, depending on some parameters, right? And so we had our very, our n variables x, our p parameters p. And those get mapped to some, you know, n equations.
00:04:34.308 - 00:05:41.708, Speaker A: So now we have each polynomial f, sub I, depends not only on the n variables, but also on some parameters. We can think of them as a column vector whose entries are polynomials. Okay. And then we had, this is just a review, first of parameter homotopy. So why don't I just write that? Then we had a path, a real valued path, in our space of parameters. And what we'll do is our homotopy, which we need to do, homotopy continuation, will then be defined by sending xt to. What is it? H of x of t.
00:05:41.708 - 00:06:17.444, Speaker A: Q of t, or I guess, really, and we're thinking of a solution path as well, in the space of variables. So this is just sort of reminding you some of the notation we covered on Tuesday. And. Okay, so, you know, at every, at every moment in time, we have a polynomial system of equations. So, Alex. Yes?
00:06:18.384 - 00:06:38.554, Speaker B: For your h, you've got h. Of course, it, obviously the image is h of x and q, but is that also equal to the composition of f with q? Is that how the h and the f and the q are related?
00:06:38.934 - 00:07:02.894, Speaker A: Oh, yeah. Okay, so maybe. Okay, I should have written. Yeah, I need to define this. So this is what, like this. And maybe it's better to leave the t out of here. Yeah.
00:07:02.894 - 00:07:41.384, Speaker A: Yeah. So that means that, you know, we've specified a specific parameter, and so when we substitute that into our family of system of equations, we'll get actually one specific equation for each value of t. Yeah, thank you, Will. Okay. Yeah. And then, so we follow the solution path, and that's what homotopy continuation does. Okay, so now let's look at monodromy.
00:07:41.384 - 00:08:39.604, Speaker A: So monodromy. So let's say we're in our space of parameters, some sort of space, and we pick one particular parameter value, let's say p. P, maybe. Now, at p naught, we have a system of equations, f of x p naught. And so these are, these are n polynomials in n variables. Okay, so we have a very specific system of equations. Now, say we know one solution to f of x e naught.
00:08:39.604 - 00:09:49.394, Speaker A: Call it x naught. Okay, so somewhere over here in the land of our n variables, maybe this has some more coordinate axes, we have one solution, namely x naught. Okay? And so the idea is that sitting above that parameter value, p naught is one of its solutions, x naught, in a different space in the space cn, whereas p naught was one of our parameters in Cp. Now, besides x naught, presumably there are many other I'm drawing them in a line because I want them to. You can visualize them sitting over p naught. But of course, they could be, they could be anywhere in c to the n. Maybe it's better to draw them like that.
00:09:49.394 - 00:10:57.678, Speaker A: So these are the other solutions, the other unknown solutions to the very much more specific system where we've plugged in our specific parameter p naught. Okay, this cartoon may make sense to you. However, if it doesn't, please speak up. Okay, good. So then what happens is that we can take a loop in parameter space, okay? And this will be our, you know, this is our q of t, our path in the space of parameters. And in fact, I mean, it doesn't, in reality, when you're actually coding this, it's not really a loop. Maybe, maybe you can make it a loop by doing some sort of gamma trick.
00:10:57.678 - 00:12:09.494, Speaker A: But here's one very simple thing to do. Just go over to some new parameter, some random new parameter, and then go over to a second random parameter and then go home. Okay? Now this is, this is a loop, loop in parameter space, okay? Now the nice thing is that when we return to our original parameter p naught, if we along this loop followed our solution x zero, it's going to be moving. So maybe at this point corresponds to this parameter value. Our original solution moved as we moved from p naught to some other parameter, let's say p one. And maybe here, this is a solution to f of x. So solves f of x, p one.
00:12:09.494 - 00:13:09.054, Speaker A: Okay. And maybe over here, as we perturb our system to p from p one to p two, we again just path track, solving the differential equation by Euler steps, and then a corrective Newton step. And then we can follow this solution as it continues to evolve. Maybe over here. And finally we go our final stretch of our path, q of t in the space of parameters. And that will take us somewhere. Now, it could take us back home to x zero, but more likely, if we take a big enough loop in parameter space, what's going to happen is we're going to go to some new solution, some solution that we did not know previously.
00:13:09.054 - 00:14:38.088, Speaker A: Okay, and so this is, so this is what's monodromy? So the monodromy group group of this parameterized family of polynomial equations, what does it do? It's a group. Well, it permutes. So in particular, it's a finite group because you have finitely many solutions. Oh, that's to make an e s permutes the finitely many solutions of f of x at p naught okay, so is the monodromic group like a group of these loops or what? Yeah. So, yeah, what is a group? Is it the group of loops? Like, sort of like a fundamental group? Well, no, not really. You need the loops, but the monodromy group is actually the thing that's permuting the solutions up here. Okay.
00:14:38.088 - 00:15:16.194, Speaker A: But, of course, this is just my definition of the two words monodromy group. So there are loops down here, and there's maybe a fundamental group. I mean, of CP. No, not really. But maybe CP subtract the discriminant, would have some sort of fundamental group. But either way, the monodromy group is permuting these solutions. And how do we obtain those permutations in practice? Well, the way we obtain them is we make loops in parameter space and we path track.
00:15:16.194 - 00:15:23.634, Speaker A: Okay, does that. Does that make sense? I'll pause for a moment for questions.
00:15:25.974 - 00:15:37.654, Speaker B: Does every element of the monodromy group arise as a. From one of these paths?
00:15:39.354 - 00:16:26.874, Speaker A: So, yes, yes, you can get every solution. And so you can get from any one solution, you can go to all the others. Now, the problem is, we don't know what paths will actually make a permutation. So in practice, you just, you try a loop, and if nothing happens, if you come back to your original solution, well, you just try a bigger loop, and then you just. And you do it randomly, and you just keep trying these loops, and you hope for the best. So, unfortunately, you know. Okay, so what our original.
00:16:26.874 - 00:16:54.684, Speaker A: When we have a start system and we path track all of its solutions, we are guaranteed to find all the solutions of our target system. That's a really great thing about this method. However, in monodromy, we do not have a similar guarantee. We don't have an algorithm that is guaranteed to output all the solutions in finitely many attempts.
00:16:55.264 - 00:16:58.124, Speaker C: Is there a way to make it trial and error?
00:16:58.944 - 00:17:08.552, Speaker A: Yes. And that's. That's what. That's what we. We do in practice, is like, it's just trial and error, different loops and parameter space, and see what happens until.
00:17:08.608 - 00:17:10.284, Speaker C: You exhaust the situation.
00:17:10.984 - 00:17:56.358, Speaker A: Yeah, yeah, exactly. And so what, maybe one more thing that's worth that I didn't mention, but is extremely important. Okay, so here it is, after one successful loop. Successful loop, we have. And here's the big. The big moment, two solutions. Now, our next loop can follow both, maybe at the end of the second loop.
00:17:56.358 - 00:18:51.828, Speaker A: At the end of the second loop, we have four solutions, etcetera. So, in other words, very quickly, you can start to produce many, many solutions, because at every stage, you've increased the number of known solutions you have. And so at the next loop, maybe we follow x naught again along a different loop, and maybe it goes over here this time. But then we also can follow this one on our second loop, and we see that it goes here. And so now we know x naught, we know our second one that we discovered, and we know these two new ones that we discovered. And then our third loop, we can follow four paths, and maybe we get another four solutions. Now we have eight solutions.
00:18:51.828 - 00:19:05.172, Speaker A: And so each time it could potentially double. Okay, maybe.
00:19:05.228 - 00:19:06.624, Speaker C: It depends on what?
00:19:07.644 - 00:19:08.990, Speaker A: Can you repeat the question?
00:19:09.132 - 00:19:15.814, Speaker C: The maybe it's like, not guaranteed, it's semi shaky.
00:19:16.474 - 00:19:37.334, Speaker A: Well, the maybe two sides to the maybe, right? Yeah, maybe just sort of depends on were we lucky to pick a loop that sort of went through the discriminant in some way that induced a loop up in the solution space or that induced a permutation in the solution space?
00:19:38.634 - 00:19:46.538, Speaker C: So I miss the discriminant. What, what was the going through the discriminant? What, what is this?
00:19:46.666 - 00:21:07.826, Speaker A: Well, okay, so at this point, we're talking about my intuition, which I think is probably mostly correct, that in some way, like, why would a loop produce a permutation? Well, in my imagined mind, it's sort of going around the discriminant of Cp. And discriminant is just sort of a blanket term for a subset where pathological behavior occurs. And so in my mind, there's some, there's some subset of our parameter space that, that, you know, if you loop around it will induce a permutation. But I actually don't know. So this would be something to look up and find out more about, perhaps in one of these, one of these books. But, you know, oftentimes, like, actually calculating a discriminant for some problem is extremely difficult. And so, like, the hopes of understanding it in some way that would allow you to guide your monodromy loops in parameter space is pretty much zero.
00:21:07.826 - 00:21:24.074, Speaker A: Hope is my understanding. Okay, but the, the great thing is that in practice, this just seems to work. You just take different loops and you come back and pretty soon you have all the solutions.
00:21:27.694 - 00:21:29.846, Speaker B: How do you know that you have all the solutions?
00:21:29.990 - 00:21:30.998, Speaker A: Excellent question.
00:21:31.086 - 00:21:33.554, Speaker B: That was stopped producing new ones, but.
00:21:35.614 - 00:22:49.594, Speaker A: So, trace test. So I'm not going to talk much about this, but, you know, see textbooks or papers and I think, yeah, okay, so the trace test is a way to determine whether you have points on an irreducible component. And really I need witness sets to talk about this. So we're going to. Just for now, we'll just say the trace test can be used to check if we found all the solutions. Yeah, I'd have to check on this. Not fully clear to me.
00:22:49.594 - 00:23:39.874, Speaker A: So we're sort of reaching one of the limits of my knowledge here, but we'll come back to it. I do know some things about this and we'll talk about those soon. Okay, so let's. So now we know what monodromy is, and maybe it's a good time to show an example where I use monodromy. And this will connect to flex doctor plans and Kaylee parameters that we've seen previously in this course. Okay, so next is an example. Okay, so very unintelligently, this is a picture of the screen of my computer.
00:23:39.874 - 00:24:00.124, Speaker A: But this is the best way I could quickly write this example down. This is a framework, obviously, and let's say we are given just the. Let's say we don't know any realization.
00:24:00.244 - 00:24:05.132, Speaker D: Alex, Alex, can I, can I interrupt a little bit with the previous. Just go back to the previous slide.
00:24:05.228 - 00:24:05.500, Speaker A: Yes.
00:24:05.532 - 00:24:39.888, Speaker D: For a second. Yeah. So I was wondering why this procedure of having found one solution and then trying to get a permutation of the solution set somehow and this through this monodromy, why would this be less or more difficult than going back to your starting system and picking a different solution and following the homotopy path to find another solution?
00:24:40.056 - 00:26:25.644, Speaker A: This is a good question. This would be a question to motivate. Why would we even use monodromy at all? Yeah, so the idea here is that sometimes the only available start systems are very large, even though you suspect that your system has a reasonable amount of solutions. So I'll just write that here. Like in case a start system is too large, too many paths to track, then often in practice, we find that monodromy is still very efficient and much faster than following all the paths of some start system. And so, again, like with monodromy, at least I'm not aware of, like any sort, because you're just taking random loops in parameter space. So there's not much that you can say about, like how often will it succeed? But the fact is that in practice, systems that are really, really big can be solved very quickly if you have one solution and then just use monodromy.
00:26:26.904 - 00:26:39.184, Speaker D: Could you say that there is another system that has the permuted solutions which you can then consider to be the start start system that you're doing this for?
00:26:39.724 - 00:27:28.078, Speaker A: Yeah. So, I mean, in, in the best case scenario, you would be able to be able to produce an optimal start system. So maybe this is worth writing down, because I don't think I wrote it down last time. An optimal start system for a given problem, for a given polynomial system, contains exactly as many solutions as f. Right. Now, an opt, you know, finding an optimal start system is difficult. Yeah, sometimes you can do it.
00:27:28.078 - 00:27:44.634, Speaker A: But if you're in the case where you do not have an optimal start system and the start systems that you do have are way too large, not, you still have hope. In fact, you have very good hope. Just use monodromy.
00:27:45.174 - 00:28:16.134, Speaker D: Okay, so my question was slightly different. So it was like saying that can one interpretation, this monitor me, path following thing, loop following thing, as having a start system whose solutions are somehow permutation of the original system and doing a homotopy there. Now, what would this other system be? Even the system for which you have the permuted solutions?
00:28:17.074 - 00:28:19.334, Speaker A: Well, I think that would be the original system.
00:28:20.724 - 00:28:29.744, Speaker D: I see. But there's no. So it's just a set. Somehow the solutions don't have a meaning beyond the fact that it's a set.
00:28:30.724 - 00:28:50.560, Speaker A: Yeah, exactly. I would say the solutions are just a set. Now, where they obtain additional structure is when, when you embed them in a family. And so when you embed a specific system in a family of systems, now the solution set has some sequence.
00:28:50.672 - 00:28:51.224, Speaker D: Yeah.
00:28:51.344 - 00:28:54.120, Speaker A: Has additional structure, namely its monodromy group.
00:28:54.232 - 00:28:55.204, Speaker D: Oh, I see.
00:28:56.264 - 00:29:13.564, Speaker A: And that monodromy group is dependent on what family of parameters you've chosen. So if you embed your, your original system in some different family of systems, some different parameter set, you will get a different monodromy group.
00:29:14.284 - 00:29:15.144, Speaker D: Okay.
00:29:16.684 - 00:30:08.342, Speaker A: And so, you know, even if so, again, this, this suggests even more ways to problem solve. Namely, if you choose some parameters and do monodromy, and you, you don't get all of the solutions, but you get a lot of them. Yeah. Just choose a different parameter set. Just embed your family in a different parameter space, and try monitoring there with, and you still can use all the solutions you computed with the other parameter parameterization or parameterized family. And so you can just keep trying new, new embeddings of your system into a family of systems. Each embedding will have a different monodromy group, but any solution you compute using any embedding can be carried over to some other embedding and then start and used as start paths for mono dromy loops.
00:30:08.488 - 00:30:35.814, Speaker D: I'm wondering if this has any connection. I don't know. I don't know enough about the ideal theoretic interpretation of this but does this have any connection to having different generators for the vanishing ideal of this, of this zero, this zero dimensional variety that you have, which is the set of solutions.
00:30:37.174 - 00:30:38.194, Speaker A: Yeah, I see.
00:30:38.614 - 00:31:15.854, Speaker D: Yeah. Whether or not, you know, the, as you said, there's a family of, if you embed this in a family of polynomial systems, which gives you the monodromic group, which you can think of as, I don't know whether it is different families of generators for some of them are like the grobna basis or something, and some which give you an easy way of getting the solutions. And some of them are, some of these generator sets are so horrible that it's not going to be easier to get the solution, that kind of thing. You understand what I'm saying? I don't know.
00:31:16.154 - 00:31:29.682, Speaker A: I think so in order for something like that to be true, you would need a connection between different parameterized families containing yours and the different bases of the ideal.
00:31:29.818 - 00:31:30.534, Speaker D: Yeah.
00:31:31.854 - 00:31:50.070, Speaker A: At first thought they seem independent because the, the different Grosvenor bases of an ideal, you know, has nothing to do with how that ideal embeds in another family with more variables. But, but, yeah, I haven't thought about that. So.
00:31:50.262 - 00:31:52.166, Speaker D: Okay, thanks.
00:31:52.230 - 00:32:28.304, Speaker B: So, Alex, one thing we might try doing is having as a parameter space the something like the metric. So we measure distance using these quadratic formulas, let's say. Or maybe the square of the distance between two points. Yes. But you could imagine changing that quadratic to a different quadratic. Maybe that's much easier. The square of a linear form or something like that.
00:32:28.304 - 00:32:55.702, Speaker B: Right. And then if you could solve the, that simpler problem, imagine it was simpler. I'm not sure if it is. Then you could use monodromy inside the path space to kind of move your solutions back to the more complicated setup.
00:32:55.878 - 00:33:02.326, Speaker A: That's interesting. It sounds like to me what you're describing is more just a parameter homotopy.
00:33:02.430 - 00:33:06.966, Speaker B: Yeah. Actually, now that I'm saying it, it's not like. Yeah, I think that's right.
00:33:07.150 - 00:33:36.494, Speaker A: But I mean, this brings up another point. I mean, parameter homotopy is absolutely the most useful thing. And coming up with a start system, I mean, your suggestion was some kind of change of variables, and then the system appears easy to solve. That is finding a start system. And you can just parameter use a parameter homotopy to move those solutions back. Yeah, which I think makes a lot of sense.
00:33:37.074 - 00:33:38.490, Speaker B: Okay, this is lots of fun.
00:33:38.562 - 00:33:56.684, Speaker C: All right, we're wondering question here that may be too daring. After you found all the solutions, is there a way to look back and find that they all lie on some kind of locus or common property.
00:34:00.344 - 00:34:07.924, Speaker A: Well, I guess they'll lie on the variety that you are interested in.
00:34:08.784 - 00:34:11.188, Speaker D: They'll also are the variety, right?
00:34:11.296 - 00:34:27.224, Speaker A: Yeah, they are the variety. If they're a witness set, then they're inside of the variety. But yeah, I think that's sort of the question of what varieties contain a given variety.
00:34:28.084 - 00:34:42.143, Speaker B: So, yeah, so for that you could try to compute the ideal of polynomials vanishing on your variety. And that would tell you about functions that vanish at all these points.
00:34:42.303 - 00:34:42.647, Speaker D: Yeah.
00:34:42.695 - 00:34:46.803, Speaker C: Is there a quick definition to help me? What is the variety?
00:34:47.863 - 00:34:57.375, Speaker B: The zero set of a bunch of polynomials. So the common, common zeros of a bunch of polynomials, common zeros, that would.
00:34:57.399 - 00:35:04.443, Speaker A: Be just the algebraic set or the algebraic variety associated to that list of polynomials.
00:35:06.114 - 00:35:08.698, Speaker D: Would you not want irreducibility as well?
00:35:08.746 - 00:35:11.994, Speaker A: For a variety, you don't need it.
00:35:12.154 - 00:35:29.558, Speaker B: I mean, it would be typical to think about that, but on a quick. Yeah. First glance, I wouldn't bother too much with thinking too much about the difference between the scheme theoretic structure and the set theoretic structure.
00:35:29.666 - 00:35:29.926, Speaker D: Yeah.
00:35:29.950 - 00:35:33.234, Speaker B: Which is what you're getting at. You're right, yeah.
00:35:35.774 - 00:35:43.794, Speaker A: Yeah. So, okay, this is monitoring, it's really important concept. So more questions are welcome.
00:35:45.734 - 00:35:47.394, Speaker B: Can you show us your example?
00:35:47.774 - 00:36:24.014, Speaker A: Yeah, so I can move to the example and we'll sort of see just at least this is a good example because it connects to what we've seen before in this course. So let's say we want to find realizations. I know, like right here, I've literally drawn a realization. So we've found one. But let's pretend that I didn't find this. Okay, so all we know is the lengths of each of the edges. We just know the length of the edges, and we know the graph structure.
00:36:24.014 - 00:37:14.856, Speaker A: And that's it. Now, one difficulty. So here's the idea. We want to apply monodromy to generate all the realizations, but in order to get monodromy started, we need one realization. Okay, so first let me just say that you could just use a Newton's method and hope that it converges to some solution. And that would be a method that you could try. However, if you, Newton's method would just be to solve a system of equations numerically by an iteration of some random.
00:37:14.856 - 00:37:20.210, Speaker A: You'd start with a random guess and then you'd update using the Newton steps that we covered.
00:37:20.242 - 00:37:24.254, Speaker B: Like I see, pushing yourself back onto the path.
00:37:24.554 - 00:38:02.954, Speaker A: Yeah, exactly. Yeah. So here's the Newton step that we did. So we use this in our path tracking algorithm. But the thing that made it work so well was that we always take the Euler steps. Okay? So for any given solution, there's always some region where Newton's method converges quadratically, but that region may be small. Now, with path tracking and homotopic continuation, we just take our euler steps small enough so that we're always within sort of an epsilon tube of the actual path.
00:38:02.954 - 00:38:44.704, Speaker A: And if we stay within that tube, our Newton steps are going to converge quadratically, and we'll be able to apply Newton's method very quickly to, you know, as a correction step. But here, what I'm talking about is we need one solution. We need one realization of this thing to get started. And so you could just pick some random point in and then just try Newton's method and see if it converges. So you could try that. Now, what I'm going to describe is an alternative. How do we get started? With monodromy, we need one solution, so need one solution.
00:38:44.704 - 00:39:57.516, Speaker A: And actually this method is guaranteed to work. So Newton's method may or may not work. But this method is very quick and is guaranteed to work. So it's actually not too bad. Okay, so the method uses Kaylee parameters. So the idea here, in at least this specific instance, is that if this were a different graph, if this were an easier graph, namely, if it looks like this right here, then what we have is that our graph is just produced by adding triangles one at a time to each other. So let me just recap that if we have a graph that looks like this, where I just add a triangle each time, then what I would do is I would just set up these first two points at specified locations.
00:39:57.516 - 00:40:40.564, Speaker A: I'm assuming that I know the edges or the edge links. Sorry. And so then I would, you know, here's vertex 123-4567 how do I find the location of vertex three? Well, just looking at this triangle gives me a quadratic system. And in fact, this system is one. We've, you know, we've seen this before in the course. One quadratic, one linear. And solving that produces, you know, the coordinates of the third vertex.
00:40:40.564 - 00:41:54.184, Speaker A: And then, okay, maybe I should have labeled these differently. And then once we know the coordinates of three, which we can easily produce them by solving a quadratic. So that means we can even do it using square roots symbolically, if we wanted, then we can produce vertex four, because again, now this triangle here is just one quadratic, one linear equation, and that'll produce the coordinates of vertex four. And so, because at each stage, we sort of are just adding one more triangle. Now we can produce the coordinates of vertex five by solving one quadratic, one linear and we just keep moving. Get vertex six, get vertex seven. And so you can see that if our graph has this very simple structure, then we can very quickly find a realization.
00:41:55.004 - 00:41:58.812, Speaker B: Is that simple structure shell ability or is that something else?
00:41:58.988 - 00:42:01.704, Speaker A: It definitely looks like shell ability. Yeah.
00:42:02.084 - 00:42:05.344, Speaker B: Like a kind of path from one face to the next.
00:42:05.734 - 00:42:14.630, Speaker A: Yeah. But it's, I don't think it's shellability. You could, in other words you could have a non shellable complex that still had this quadratically radical solvable.
00:42:14.742 - 00:42:15.310, Speaker B: That's true.
00:42:15.382 - 00:42:57.490, Speaker A: Okay. Okay. So yeah, this was a review. So now the problem is our graph doesn't have that structure. Okay? So what we do is we remove some of these red edges, we remove the red edges and then we add in the green edges. And now this graph with the black and the green edges has that quadratically radically solvable structure. Okay.
00:42:57.562 - 00:43:11.244, Speaker D: It's a little more than that too. You also have the, I mean just quadratically radically solvable doesn't mean that the realizable values of these green edges is a convex set. We actually even have that.
00:43:11.864 - 00:43:13.088, Speaker A: Yeah. Yeah.
00:43:13.256 - 00:43:30.196, Speaker D: So we have this. This is not just a quadratically radically solvable graph, it's actually what we call a two tree. Maybe that's the, so in other words, the branched cover, the covering map, the image is a convex set right onto.
00:43:30.220 - 00:43:33.268, Speaker A: The space of Kaylee parameters, which are the lengths of the green edges.
00:43:33.316 - 00:43:34.740, Speaker D: Green edges, correct.
00:43:34.932 - 00:44:19.974, Speaker A: Now for this method I'm going to describe. This actually doesn't matter because I'm going to give the green edges complex, random, complex number values. This is going to be the trick we're using. Now we have this, maybe it's called a flex doctor plan where we add each vertex like vertex three is found by looking at adding a triangle to vertices one, two. Vertex four is found by adding a triangle to vertices one and three. And so we proceed, but eventually we find that we need one of these green edges. So right here is the green edge length, which I'll call c 46.
00:44:19.974 - 00:45:25.074, Speaker A: And it's not an edge in our graph, in our original graph, it's an edge in our new easier graph. And so what we'll do is we'll assign that green edge a random complex number value and we'll just proceed with solving these quadratic equations. Of course at the end the coordinates of the vertices will have no meaning to our original problem because our original problem didn't have the distance between four and six as some complex number. Presumably it was some real number, but we won't care because we're just going to use this as a start system. So we'll proceed and at each time we need a green edge. It's not in our original graph. So we're just going to assign it a random complex number and continue solving, producing our meaningless vertex coordinates for all the vertices of our graph.
00:45:25.074 - 00:46:32.974, Speaker A: Okay, at the end of this, at the end of this we have, I guess seven green edges whose values we've given random complex numbers. And so that's this part, choose random complex numbers for each of the green edges. And now here we're just solving those quadratics. Kind of ignore the words I'm using here, but we just solve the quadratics. That's step two, in other words, this step where we produce the new coordinates. Now we set up a parameterized system and here's the, this is where we're setting up our family in some parameterized family that will be convenient for us. So set up a parameterized system of polynomial equations given by the black edges, which we know, and the red edges as parameters.
00:46:32.974 - 00:47:31.524, Speaker A: So the red edges are going to be parameters. They are edges that were in our original graph, but we deleted them because we wanted to produce an easier graph. Okay. And now we have our complex valued solution that we produced by these quadratics with the green edge links being random complex numbers. And we'll just, you know, so that's sort of a garbage solution. It has no meaning, but we will perturb it in the space of parameters given by the red edges and we're going to perturb it from whatever the red edge values were in this complex numbered solution. So the red edges are all complex number value lengths and we just perturb it to the actual lengths.
00:47:31.524 - 00:47:52.804, Speaker A: And so because at the beginning we knew the length for every red edge, we knew this, we knew all those lengths. So we have a list of correct red edge length values. Oh, is this, did my screen freeze?
00:47:59.244 - 00:48:00.244, Speaker B: Seems okay.
00:48:00.364 - 00:48:48.870, Speaker A: Okay. And so we can just move our garbage complex solution over to this solution. And now it's actually a realization that we wanted. It's a realization that solves our original problem. And the key was we made a new family. We could find a start system using the tree decomposable structure or the two tree structure and we just moved it over to the parameter values that made sense for us. Okay.
00:48:48.942 - 00:49:02.086, Speaker D: Yeah. And you're right that for this particular use of it, you didn't need the two tree structure. All you need is a tree decomposable structure because you just want to find those red lengths quickly.
00:49:02.150 - 00:49:24.730, Speaker A: Right, right. Yeah, yeah. And the trick is that you don't to find that start system because it's in this parameterized family. It doesn't matter that the lengths are complex numbers. So we can just make up lengths and it's going to be fine. So maybe I'll.
00:49:24.762 - 00:49:38.774, Speaker B: Now what is the path that you've got? Here it goes. I understand where it starts and where it ends, but you've got this p going from b to c two. That's not the same thing as the path. Right.
00:49:39.124 - 00:49:43.900, Speaker A: So our parameter space in this case is the rijs.
00:49:44.052 - 00:49:49.344, Speaker B: Yeah, there could be a lot of them. Or maybe there's just however many edges we deleted.
00:49:50.124 - 00:49:57.444, Speaker A: Yeah, I see. Okay, so however many red edges will be the c to the, that number.
00:49:57.604 - 00:49:58.344, Speaker B: Yeah.
00:49:58.804 - 00:50:29.034, Speaker A: And we have some, we just compute the red edge lengths which are going to be complex number lengths. And that of course doesn't mean anything. But we also have red angelinks that are real valued and that were given to us in our original problem. And so then we can just do a straight line homotopy if we want, or if we want to be more careful, we can do a two step homotopy between them.
00:50:31.594 - 00:50:40.130, Speaker D: You can probably get away with a lot fewer parameters if all you cared about was to getting a three decomposable system.
00:50:40.282 - 00:50:41.458, Speaker A: Yeah, absolutely.
00:50:41.586 - 00:51:10.554, Speaker D: Yeah. So like if you just look at the bottom part that looks like a star, I don't know, somewhere down there, that part you probably, you need like. So we had just this tri hex, what was called a try hex before. I don't know, the small example, much smaller example. And that you needed like three green edges, three k parameters to get.
00:51:12.494 - 00:51:13.674, Speaker A: Was it this one?
00:51:14.214 - 00:51:27.614, Speaker D: I don't remember. I mean, it's, we probably did it as an example. Never mind. It needs three k parameters to make it a two tree, but it only needs one to make it a three decomposable graph.
00:51:28.394 - 00:51:37.242, Speaker A: Yeah. So given your original graph, if you can just somehow make it simple, then you could apply this process.
00:51:37.378 - 00:51:41.054, Speaker D: Correct. And the fewer parameters, the better for you. Right?
00:51:41.514 - 00:52:08.118, Speaker A: Yeah. Although I find that a parameter homotopy is even in a larger number of variables, it doesn't take any longer. It's the, it's really the start systems that can be really bad. And so in this case we get the start system sort of for free by this quadratic little, a little quadratic system at each step. And so it's not too much of.
00:52:08.126 - 00:52:14.286, Speaker D: A problem, but having, does it help to have fewer parameters in your parameter homotopy?
00:52:14.390 - 00:52:17.044, Speaker A: No, I mean, I think in general. Yeah, it does.
00:52:17.134 - 00:52:30.360, Speaker D: Okay. Yeah, so that's what would happen if you just, you could drop a lot fewer edges if you were allowed to use three d to, to just get a 3d composable graph.
00:52:30.472 - 00:52:31.408, Speaker A: Right, right.
00:52:31.536 - 00:52:39.016, Speaker D: And then the number of, you might get a drastic reduction in the number of parameters in your parameter.
00:52:39.200 - 00:52:42.112, Speaker A: Yeah, that's true. For some graphs. It might be a big, big difference.
00:52:42.208 - 00:52:43.394, Speaker D: Yeah, yeah.
00:52:44.094 - 00:53:08.914, Speaker A: So I guess I'll just kind of show this in action here. I'm solving quadratic equations, I'm just defining the equations that I need. Here is our original framework. This one we didn't know. Right. But then here I find this sort of garbage solution. And so here as a list of numbers, these are the coordinates of the vertices.
00:53:08.914 - 00:54:01.292, Speaker A: All right, so here we see that this vertex really has imaginary components. It is meaningless, but it doesn't matter because this is just going to be a start solution. And so we okay, a lot of this was just me figuring out how to set up the right equations. And then here one path tract. So this was my parameter homotopy. I started from that one start solution, and with the start parameters being the garbage red edge lengths, the complex valued red edge links, and the target parameters being the red edge lengths that were given to us in the original problem, then I get the solution. Now here is where I call monodromy.
00:54:01.292 - 00:54:35.294, Speaker A: Now I solve the original problem with my one solution. And you can see that I actually interrupted it. I stopped it, but after eight minutes, it had produced 6612 solutions. So pretty quickly we got a lot of solutions. And let's just take a look at some of them. Here is a realization that we did not know before that monodromy picked up. And here's another one that we did not know before that monodrom we picked up.
00:54:35.294 - 00:55:01.254, Speaker A: And here's another one. Interestingly, it seems that a lot of the realizations are sort of just crisscrossed on top of each other, but these are all realizations that genuinely satisfy the real number edge length that we wanted. And we didn't need to know a realization to start this process.
00:55:07.234 - 00:55:26.884, Speaker B: In those pictures, you still have the green edges that were kind of added in order to make things kind of easy to solve the original system. Are you tracking those numbers too, or are they just figments of the draw, of the drawing program?
00:55:27.304 - 00:55:33.920, Speaker A: Oh, yeah, good, good question. No, they're just figments. I abandoned them as. As soon as I didn't need them anymore.
00:55:34.032 - 00:55:54.834, Speaker B: Right. Okay, that's cool. Wow, this is, this is super awesome. So you solve a much easier system, then you parameter homotopy to get a solution to your original system, a meaningful solution, and then you use monodromy to produce many solutions to your original system.
00:55:55.174 - 00:55:56.422, Speaker A: Exactly. Yeah.
00:55:56.478 - 00:56:09.354, Speaker D: Great. Yeah. So, Alex, I was a little. I'm not, I wasn't sure when I looked at the alternative solutions that you had, some of those red edges seemed really long.
00:56:10.294 - 00:56:22.144, Speaker A: Oh, okay. So actually, if I had scrolled down a little bit, they also looked along to me. And so I checked them explicitly and they were all correct. So it was just a figment of the drawing.
00:56:23.564 - 00:56:31.944, Speaker D: I mean, the longest one here seems like three times those small triangle edges.
00:56:32.844 - 00:56:35.932, Speaker A: So, yeah, I mean, they're the right length.
00:56:36.068 - 00:56:36.788, Speaker D: Okay.
00:56:36.916 - 00:56:51.528, Speaker A: Right here. So here's, here are the new ones that I showed, and here's the original. And you can see that they all have. I just picked a random red edge length, but they're all.
00:56:51.656 - 00:56:55.044, Speaker D: So maybe your black edges also got very long or something.
00:56:57.864 - 00:57:58.872, Speaker A: The plot size is determined dynamically based on fitting it. Yeah, that's all it was. Well, okay, so I'm sort of out of time, but it's really a shame, because the most fun part of this to me is the witness sets, and we didn't get to talk about that. But luckily, these three items, which I really hoped that I could get to, will be covered at this workshop. And so if you're intrigued, and you want to know, how do I find the irreducible decomposition? Let me just tell you that it's really not hard. You just add some linear equations and you think carefully about randomization, and then you're good to go. And you can start sampling from varieties.
00:57:58.872 - 00:58:09.484, Speaker A: You can decompose a variety and decide what are the degrees of all of its irreducible components and really start doing some interesting stuff.
00:58:13.104 - 00:58:56.364, Speaker D: Great. So next week, there's no lectures because of the second workshop on circle packing. The week after that, which is April 20, Georg is going to be talking on grobna bases and counting solutions and so forth. And then. So, Alex, if you wanted to talk about witnesses, sets and so forth, we, you know, we have one week where there's, we haven't planned anything at the end, so, you know, follow ups on the lectures, we can certainly have them.
00:58:56.904 - 00:59:01.024, Speaker A: Okay, great. And if anybody has any questions, feel free to email me.
00:59:01.184 - 00:59:05.124, Speaker D: Yeah. Any further questions?
00:59:06.344 - 00:59:24.754, Speaker C: Yeah. You say you have to be careful with randomization in the next step of witness. How about in the step that you described already, you did. You picked up things at random, right?
00:59:25.614 - 00:59:44.476, Speaker A: Yeah, that's true. I mean, yeah, sort of throughout. You have to sort of trust in the computer's ability to pick random numbers. And what we find is that in practice, everything matches theory. And so this seems to work decently well. Quite. Quite well.
00:59:44.476 - 00:59:49.528, Speaker A: Yeah. But actually, I was. I was talking about a process that I haven't explained yet.
00:59:49.696 - 00:59:50.604, Speaker C: Okay.
00:59:51.184 - 01:00:34.384, Speaker A: Which has to do with crunching a large number of equations down into a smaller number of equations by taking random linear combinations of the original equations. And there, the. When I said we have to be careful, I just meant we just have to know what dimension we're looking for in order to know how. How far to crunch our original equations down. But that's. I mean, just be careful in the same way that it's hard to decide. Like, if today is Thursday, then how many days is it until next Tuesday? It's like, in other words, subtraction is sometimes difficult for me, so.

00:00:03.200 - 00:00:53.654, Speaker A: So, as for what concerns the references about the things that I've done so far. So, for measure theory, well, any good book on measure theory covers the disintegration theorem and the Kolmogorov theorem that I'm going to discuss today. I think a quick, good introduction, you can find it on Doodle's book, realities and probability. Sometimes the presentation is a bit more probabilistic, in some sense oriented, but even if you don't know, probably that's okay, or should be okay. And for optimal transport, well, there are several. Again, I mean, now, optimal transport is quite a well known topic, and there are several references to it. For what I mean, we really need just very, just the basics of optimal transport.
00:00:53.654 - 00:01:21.594, Speaker A: So, nothing, nothing too complicated. And for that, an introduction to optimal transport theory and application that I brought a while back is more than sufficient. Just the first chapter and half of the second is modern enough. There's another version of this book that I brought with Ambrosio. It's called the user's guide, talking about transport. And it's basically the same content. But of course, besides that is, far as I know, the quickest way, you know, getting into the things that we need.
00:01:21.594 - 00:02:09.404, Speaker A: But, you know, there are many other introductions to ottoman transport. And not only there's the book, baby Lenny, Ottoman Transport, all the new. There is a recent survey by Figali and Glauco. I don't remember the title, but, you know, I think, you know, if you look Figali, Glauco and, you know, on archive, you will find it. There's a book by Sartre Broze, optimal transport for the applied mathematicians, that also covers in, I mean, at least some. I mean, the generality, what we will need, though, I mean, we go quickly to metric spaces and so on, and supported is not very much covered by the book, but still, you know, the basic ingredients of the period are there. And then there is the book by Ambrose Avaray and myself about gradient flows, I guess, on metric spaces, in the case and in the space of probability measures, that also covers many, most of what I've done and will do in utmost.
00:02:09.404 - 00:02:44.150, Speaker A: Okay, with that said, yeah, we can start. So, I had to conclude the proof of this integration theorem. So, let's go. Oh, questions. So, we start from where I interrupted last time. So we had, let me recall just the setting. There was a map morel PI from polyspace X to polyspace Y.
00:02:44.150 - 00:03:43.884, Speaker A: There was here a measure mu. Here we have the measure mu, which is phi, push over mu, and we were disintegrating mu, according to this math PI. So we were looking for a family of Borrell map from y to the probability measures on X. No, weakly Borrell. And such that, such that mu of e was equal to the integral of mu y of e in the mu y for every e, you know, Borrell in X and these guys, this mu I should be concentrated, mu I should be concentrated, you know, concentrate on the primage of Y. Maybe posted the other time, I don't remember. So the other five for mu, almost every y.
00:03:43.884 - 00:04:17.510, Speaker A: Okay. And we actually built a family of maps, a family of measures weekly Borrell. And the definition basically ensures that mu y of e was equal to the density, the radon nicodem density of PI. Push forward chi e mu d. Okay. Phi push forward mu if you want. This is new at the point y, you know, or new almost every one.
00:04:17.510 - 00:04:44.318, Speaker A: Okay. So that, I mean, we gave it and we have been able to prove that there is such a family of maps of measures. And I still need to prove this family of measures. So by definition they do satisfy this identity. And I needed to prove that it is concentrated on the pre major, on the pre major file. That's what it remained to be proven. And this comes from the following identity.
00:04:44.318 - 00:05:55.034, Speaker A: So I guess the claim is, let me see. Yeah, the claim is that, the claim is that for every e, let's say Borel in X and say a Borrell in Y, we have the identity that the new, so the integral over a of nu, y of e in D, mu of Y, this is equal to mu of e, intersection PI minus one of a. Okay, I claim that these identity holes, right? And why is this the case? Well, let's just, you know, work, work with the definition. So this, I mean, if you believe in the formula that we proved last time, this is equal to the integral. Let me write this way of, I guess, chi. Let me write like this. D f d PI, push forward.
00:05:55.034 - 00:07:09.262, Speaker A: So again, I will sort of simplify. And this is equal to, this is equal to the integral where this is equal basically to this phi push forward chi e mu of the set a, right? And this is equal to this, right, by sort of basic, basic definitions. All right, now if you have these, if you have these, what is it that we can conclude? Now pick, now let a variety on a countable set of, on a countable collection of bolt sets such that, you know, such that for every, what is that I want, I wanted this. For every point in the target space, I can find a sequence of set whose intersection is exactly equal to that point. A decreasing sequence of set. So for instance, peak as a, the collection of bolts centered in a denser setting, y with rational, okay, now, and we apply that formula to. For e equal to PI, the primage of a.
00:07:09.262 - 00:08:38.090, Speaker A: So we get that, the integral, let me write this way. So, mu, y of primage of a. D, nu of y. This is equal to, uh, mu, this is equal to nu of b, right? Because there is no intersection of e that e is equal to common as well, right? Well, but given that, given that, now look at this. So given that all these are probability measures, right? So, so this integral is by, by, you know, by mass consideration, this is less or equal than this right hand side. So the fact that there is equality ensures that for almost every y in a, this guy has to be one, right? And now, now basically we are done, right? Because now, now what you do, you do, you pick, yeah. Now you let a vary in this countable set and then you deduce that for new almost every y we have that if y belongs to a for, I mean to an for sum n, then mu y, phi minus y of a n is equal to one, right? And then we are done.
00:08:38.090 - 00:09:14.974, Speaker A: Pick any such y. This measure is concentrated on premage of an. For any n for which y belong, you intersect all of this new mutual, all right? Okay, so it remains uniqueness. The uniqueness statement, remember, was like this. I should have, suppose that I have another weekly border map for which this and these are true. Then let's say mu tilde. I don't know why tilde has the same properties then same properties.
00:09:14.974 - 00:10:06.844, Speaker A: Then the uniqueness is that mu y should be equal to mu tilde y for nu, almost every one that's unique, which is the strongest kind of uniqueness statement that you can opt for out of an integral identity like this, you can always change these measures on exit set. And this is not right. And why is that the case? Well, let me claim that. So let me claim that this is also true for mutilda. We already know that for our new, that statement is true. Let me prove that this is true for mutil and why it is so? Well, I make a slightly different computation. And the computation is that.
00:10:06.844 - 00:10:58.906, Speaker A: So? Let me see. Oh, yes. So, so again I write this as the integral. Well, let me, let me perhaps, let me perhaps, I guess, I guess that the claim is this. So if mu tilde y of each characteristic function, this is equal to mu tilde I of e intersection PI minus zero, right? You know, so if, so, the point is this. If mu tilde y is concentrated on the premise of y, then these formula holds. Okay, why is this decay? So let's have a look to what is written on this formula on the left hand side.
00:10:58.906 - 00:11:38.446, Speaker A: There the measure of some set multiplied by this characteristic function. This characteristic function is either zero or one according to whether, okay, one if y belongs to this set, zero y if y belongs to this set. That is basically, you know, it's not here. But if y belongs to this set, I mean, mu is concentrated on this set. So taking this intersection makes no difference in computing measures. Okay, so if y belongs to a and this also, this is true. But if y is not on a, then this left hand side is zero, right? But also the right hand side is zero because mu and y is concentrated on this set.
00:11:38.446 - 00:13:05.434, Speaker A: And therefore, when we take the intersection, okay, now you integrate and you get this right. Therefore, therefore, you see what we can conclude is that, is that the integral over a of mu y e d nu y is equal to the integral over a of mu tilde y d nu of y because both are equal to this expression where new Tilde and mui that do not appear. But now again, and this is true for any couple of bullet sets on the source and on the target space. But then again, we know that, you know, there is, you know, there is accountable collection. So, you know, we have probability measures on separable space. And then we know that once we restrict, once we look at the value of this probability measure on a certain algebra countable, that generates the, the Boltzigma algebra, if they agree on that algebra, they must agree everywhere, right? So I play with this fact in here to deduce that first of all, so I let a variety on this countable algebra to deduce, to deduce that new y. So for any, so that for any Borrell set e on the source space, I know that this is true for new almost every y.
00:13:05.434 - 00:13:52.234, Speaker A: You agree. Actually, if you want, if you want, this requires even. So fix e. Look at the function of y that gives you mu y of e and u tilde y of e. These two functions integrate to the same real number whenever I integrate on anybody except a. So they must agree almost every, okay, now let me play, let me play with the part. Now let me let e vary on a countable set generating the sigma algebra and the source space, okay? And so you know that this is true for mutual effort and for every m, right? But once you know that two probability measures agree on a certain well chosen countable set of countable collection set, then they must have, okay, end of the.
00:13:52.234 - 00:15:03.526, Speaker A: All right, let me, let me remind, let me remind you. So, on what concerns the existence, the existence of this probability measure, I relied on the following basic lemma of measure theory. Let me insist on this fact, because I'm going to use once again, it now that does the following. Suppose you suppose a is an algebra of set, say of subsets of some, you know, of some base x, just a set. I mean, there's no, no additional step. And, and u from a to, let's say zero, one, just for simplicity, is finitely additive, is a finite relative measure measure. Then you can wonder when, under which conditions this extends to an actual measure on the sigma algebra generated by a.
00:15:03.526 - 00:16:39.412, Speaker A: Well, then mu extends, extends to a measure count of emission on the sigma algebra generated by a, by a, by a, if and only if mu of Cn goes to zero for every choice of, you know, sets Cn inside a c n included, I mean, sort of decreasing choice of sets and such that the intersection in n of all DCN is empty. So I'm asking for continuity from above, okay. In general, you will not see, you see this probability from below without the requirement that the measure is finite. I mean, for simplicity, I'm putting, you know, one, okay, now the proof of this result is totally trivial. Okay, it basically, you start from such a finite dedicated measure. You build the, the outer measure generated by, not by this measure. So you call, you try to cover any arbitrary set with the sets, with the countable collection of sets in the sigma in the algebra.
00:16:39.412 - 00:17:51.152, Speaker A: And then, you know, the info or all the possible coverings of the given of the sum of the measures. And basically this condition is what ensures you that this sets in the algebra are actually measurable and that the measure of these sets coincide with, okay, it's an exercise in measure. Okay, I'm pointing this out because there is another quite simple, I mean, there is a rather direct consequence of that result, which also has for some reason a bad reputation among students, and they want to sometimes convince you that there's no need to be scared of this result. And it's called mogollotte about existence of measures with, given what is sometimes improbability is called conditioning in a finite number of events. But for us, it's just existence of product. So, theory and I will stick to the case of cantablo products. The theorem is valid in much more generality.
00:17:51.152 - 00:19:44.124, Speaker A: So let xn be polished spaces and let me call xi and for every n, let's say, let's call it, I don't know alpha n be a probability measure, not on the x n, but on the product from I equal whatever, 10 whatever to n of these sets. Okay, so for any finite number of this, you have a product measure on the product. And let's, and let's assume that, that, you know, for every, say, n smaller than m, if I take the projection from, I don't know from m, then I do this, push forward Alpha M, I get alpha. Okay, so what is this map? This map is the projection from m product to end product x one. If m is bigger than n. Now this prototype is bigger, and you have a natural, natural projection. Okay? Then there exists a unique probability measure alpha on the infinite product of this xi, such that, uh, you know, the projection from, let's say infinity to n of this half of this alpha is equal to alpha n for everything.
00:19:44.124 - 00:20:29.344, Speaker A: Okay, so, so what, what does this theorem says? So, so the question. So the theorem wonders about the existence of a certain probability measure on an implant product. Okay, then you observe that forgiven for given finitely dimensional marginal system. Now notice that if you have a probability measure alpha and probability measures alpha n, satisfying this constraint, this must be true, right? By some sense post composing projections. So this sort of compatibility must be there. Kolmogorov's theorem tells you that as soon as you have that compatibility, you also have existence and uniqueness of the given measure. Thanks.
00:20:29.344 - 00:20:50.564, Speaker A: Proof. Truth. It seems like the obvious case would be if you have one measure on every extent, and then whenever we. Yes, sure. That's, that's, that's in particular a possibility. Sure, of course, of course. Actually, yes.
00:20:50.564 - 00:21:26.986, Speaker A: And you will see many of those in optimal transportation. So let me, well, okay, let me give you another trivial example, sort of in the opposite direction. Imagine that all the exercises are the same. And imagine that all of these alpha n are concentrated on the diagonal. So for instance, now you fix a probability measure mu on one, and therefore on all of those. And then you can consider the map that sends x to x, comma, comma x in the end. Then you can do the push forward of this measure under this map.
00:21:26.986 - 00:21:44.546, Speaker A: And this gives you a measure concentrated on the diagonal. You know, that's it, the opposite direction. This is extremely concentrated. You made it up extremely diffused. This is extremely concentrated. And of course, in this case, what is the resulting measure? Well, of course, it's the one that sends, of course. Right.
00:21:44.546 - 00:22:30.476, Speaker A: Can be anything, right. Let me comment, perhaps another comment I should make. A countable product of polish spaces is still polished, right? Why? Because you can endow. So what does it mean being polished means that the topology, which in this case, of course, is the product topology, is induced by a complete and separable distance. And then the distance, not the distance that we put on over here, the distance between two sequences, you know, xi, and say, yi, this is, you know, for instance, you know, one distance. And this is something like, what is one over one plus two to the power I? The distance between xi and Yi mean one, something like this. No.
00:22:30.476 - 00:23:06.310, Speaker A: And that's one example in which you see that at the actual distance, I mean, it's totally relevant. I care about the topology now you can put whatever you want. Okay. All right, yeah, good. Thanks for asking for examples, I mean, please do that. Sometimes I might forget proof. Okay, there's one clear set collection of sets for which we know what these measure alpha should be.
00:23:06.310 - 00:24:02.284, Speaker A: Okay. And these are the cylindrical sets. So let you know a, you know, subset of, I don't know, collection of subset of x. Italian is a set of parties, I don't know in English, what is set of substance two to the two to the x. What should I remember? The denotation, a collection of subsets, collection of. And so this is, this is the set made of those guys of the form of those, a subset. Let me write x infinity just to, you know, denote the proto space such that a is equal to PI infinity, n minus one for some an for some n in n and a n Borel in excel.
00:24:02.284 - 00:24:28.810, Speaker A: These are called the cylinders, right? Yeah, I guess, more or less, obviously. Okay, now this clearly form an algebra. Exactly. The complement is there, finite uniform. I mean, as soon as you, as far as you only take finite, you know, number of operations, you do not exit the range of cylinders. Of course, if you take counterbal, you know, countable intersection, that you might be, you know, in trouble. You can be not any more scene.
00:24:28.810 - 00:25:26.954, Speaker A: But that's true. This is an algebra, okay? And it's clear, it's clear that, that, you know, if I define for such an alpha, for such a, if I define alpha a to be equal alpha n of an. Okay, that, that's what I want to do, okay, and the assumption, this assumption Star, ensures that this is what post, it's an exercise. I mean, there's nothing hard. This is what, what do I mean by this word? Post? Well, maybe the same set a can be written in different ways. In this book, for instance, I could add two way. I could take a nice multiply by the whole space x n plus one, and that's another base of a cylinder, okay? But because of that, it doesn't matter which one.
00:25:26.954 - 00:26:55.014, Speaker A: Okay, so this map is well defined. And it's easy to check that it's finitely additive, because for trivial reason, because these are finitely additive. So all I need to prove is that this is true. If I prove that this is true, it's clear then, okay, extends here, the extension is unique, okay, for trivia reason, the extension is unique because once you have the, I mean, okay, because any, any set can be indispensable, you know, you can approximate by these kind of guys, okay, so it's the hard part here is the, is the existence of these, of these measures, not the unions. Okay? Okay. Well, suppose not, okay, suppose that if it's my contradiction, say that for, or, you know, say that mu, sorry, the alpha of cn remains bounded from below by some delta. You know, the ends are like this, this approach.
00:26:55.014 - 00:29:06.204, Speaker A: And let's see, let's see what we can do. And actually we do something, you know, the topology has to come into play as usual, when some limit occurs. And again, I will use once again the tightness of probability measures on poly spaces to help me conclude so, because what do I do? Actually, I cannot assume, I cannot assume, can also assume, I mean, unfortunately, I will explain, wait a second, why I can do this. So that c, so that c n is of the form c n, sorry, PI, what is it? The PI infinity n minus one of some c n prime, you know, for c n prime, Borel, in the product of the first, you know, just so I have this priority decreasing sequence and I, let me assume that it is of this form, I can always reduce to this case, because, because, you know, so c one, c one is, you know, a d prime, instant cylinder, some cylinder over the first product of few guys, let me call the product of the first, you know, these few guys, x one prime, and then c two is another cylinder. So up to adding some other factor, you know, let me call this other factor, x two prime and whatever. So I can always, you know, for simplicity, reduce to this case, okay, just to, don't get crazy with indices, okay? Okay, so let me say that this is the case. And then, and then you give me a silo and I find a compact set, k one inside k one inside this cm prime, such that, let's see, one prime, the first, such that the measure of the difference, so mu one of c one prime minus k one is less than epsilon.
00:29:06.204 - 00:30:27.016, Speaker A: I know that every single probability measure, sorry, alpha one, any probability measure on about, on any probability measure on a polysty space is tight. And therefore I can do this. And now let me consider this setup. Okay, let me consider this set c n bar. This is the cn minus, sorry, intersected the pre image to say n one minus one of k one. Okay, so, so what's the picture here? I have, I have, okay. A lot of products, so it might be harder.
00:30:27.016 - 00:31:12.482, Speaker A: So I have a set, the first cylinder which is like a cylinder over a set c one. And then I have another set which is cylinder over, you know, like of this form, like the product of two guys. And what I'm doing over here, I'm, first of all, I'm sort of almost feeling this base cylinder by the first compact k one prime. This is k one. And then what do I, what do I do? I look at the cylinder built over k one and I, you know, restrict the other series by intersecting with different angles. Okay, what is clear is that, is that these guys now are still decreasing and still the intersection is going to zero to the empty set because these are smaller than zero and one side, you know, I have a decrease in sequence of set. I make the intersection with.
00:31:12.482 - 00:31:32.588, Speaker A: Okay. Morally, the same cylinder, you see, makes sense. Maybe I'm confusing some confusing definition. Oh, perhaps what should perhaps. Let me. Okay, with the same cylinder make sense, please. Superstructomic production with this one.
00:31:32.588 - 00:31:55.118, Speaker A: Yeah, one, I mean. Oh, just one, just one. So this is a first composite on, on the first guy. So I'm just taking, you know, this is the projection from the whole product space to the first coordinate. And I'm taking the cylinder with base a one. Then take this cylinder and intersect with all of this. Okay, so now these new guys are still go to zero and, and just a little bit more.
00:31:55.118 - 00:32:40.522, Speaker A: Right? And, and I should also notice that sort of, how could I put this? So the, well, alpha n of c n prime intersected, you know, basically, okay, I'll tell you informally what I mean. And then, so in principle, you know, the major alpha of these guys in principle, should always be bounded from below by delta. Okay, I don't have a measure alpha. So that's why, that's why I don't. But that's what I have in mind. So what will be now the measure half of this intersection, now that I've removed something? Well, the idea is that this is going to be at least delta minus epsilon. In other words, can be made as more as I want.
00:32:40.522 - 00:33:23.334, Speaker A: Okay, is this clear what I'm saying? So alpha n of c n prime intersection by n one of t one. This is at least delta minus x. Makes sense because what is that? I took out on this. I took out what is basically what was in c one prime minus k one. But this is more. Okay, make sense. And now I iterate this construction.
00:33:23.334 - 00:34:07.724, Speaker A: So, I found the first compass set, k one. Now we look for a second compass set, k two. K two will be a subset of x one, cross x two compact, and with the following and such that, and such that, let me say, and such that you know the measure. So alpha two of c two, prime minus k two is smaller than, let me say, epsilon two. This was epsilon one there. Okay. And then I repeat the construction.
00:34:07.724 - 00:34:34.364, Speaker A: Okay, and etc. Etc. Etc. I find the compact sets, compact sets, kn inside the product of the first n, guys, compact. And such that, and such that alpha n of c n prime minus. This compact set is smaller than epsilon. Some epsilon n is just innervats.
00:34:34.364 - 00:35:29.244, Speaker A: Okay? And these compact sets have the following properties. First of all, if I pick, say, km and I project it onto the n coordinates, imagine that n is smaller than m. Then this is included in km. I started with k one, with the first one. Then I, you know, I build these new cylinders a little bit smaller. But now all of these cylinders and the property, the one, when I project them on the first coordinate, I fold inside k one. Okay, so now this new set, k two, I will actually, I will actually build it inside this intersection.
00:35:29.244 - 00:36:21.872, Speaker A: Make sense, etcetera, etcetera. Okay, then I have this property. And of course, also I want that kn in particular is included. In particular is included in the sets. And in particular, and in particular, the intersection of all the kn's is empty because these are included in. Should I make the intersection of these cylinders built so phi infinity, n minus one, because these cylinders, the cylinder on top of k one, was included into, you know, into cylinder c one, etc. Etc.
00:36:21.872 - 00:37:13.704, Speaker A: Etcetera. Okay, now, and now where's the problem in here? Wait a second. I have to think 1 second. Let me think 1 second. Okay. Right. So first of all, first of all, first of all, I can, okay, first of all, I still need to work a little bit for this contradiction, because I still need to tell you what this epsilon n.
00:37:13.704 - 00:38:41.200, Speaker A: And basically I want this epsilon n to be sure that the sum to be, damn. So small, then the sum over n of the epsilon n, say, is smaller than, say, delta over two. So that even after I took away all these small sets, still the measure of the cylinders is bounded from below. Okay, so now, so basically what I've done using, let me rephrase what I've done using this tightness principle, what I've done is I replaced the initial cylinders, which were cylinders over arbitrary bolt sets, with cylinders, with base compact sets, okay? And, but still, but still the measures are, you know, the measures are, you know, bounded from below by some positive. This restriction thing was not, was not. I did not, okay. And now, and now the problem is in the fact that, and another problem is that the intersection cannot be empty.
00:38:41.200 - 00:39:26.764, Speaker A: And because for compactness, for compactness reasons. So here it is. And here it is. So the claim, the intersection, the intersection is not, is not. If I prove this, I'm done, because I'm contracting this. Okay, makes sense. This measure business, this measure business helped me ensure, let me be clear on this, helped me ensure that at no step I can take the kn to be empty.
00:39:26.764 - 00:40:29.446, Speaker A: You know, if the intersection, if the measure is so small and I'm allowed to throw away that small amount of measure, you know, I'm done. But now this cannot be empty. And why, and why is this the case? But thanks to this property, why. Let me, let me first, okay, let me, let me consider the following sets. Let's consider the projection of all the kn's on the first coordinate, okay? For every n, this is the projection of a compact set in the product of n spaces onto the first coordinate. So this is compact, okay? And in n this decreases, right? But these guys are never empty with their projection on empty set. So there exists, so this intersection is not empty.
00:40:29.446 - 00:41:08.104, Speaker A: So there exists, say a point x one. Okay, let me iterate now. Let me consider instead of these sets. So basically the point in the intersection that we find that we left this guy as first one. Let's look at the second coordinate. And what do I do? I pick, you know, let me say, you don't know k and prime, this is kn intersect. I mean those with the first coordinate minus one, those guys know that means lies those compounds.
00:41:08.104 - 00:41:38.932, Speaker A: Again, these are, these are all non empty. Now, because, because of this and they are compact, I can iterate. Is it clear what I'm doing over here? These are compact. You know, I look at the second coordinate of this, the second coordinates of these form a decreasing sequence of compact sets, each of which is not n and therefore it has a second, you know, there is, there's a point in this intersection, etc. Etc. Etcetera. So I have found one point in intersection of all of this.
00:41:38.932 - 00:42:12.544, Speaker A: And this contradicts the fact that this k anywhere inside with my initial synchronous. Make sense, please. Because these guys, because PI, because of this inclusion and the fact that PI n, you know, minus one. Therefore, kn is included in CN because of this. So CN. So CN is the primage. Cn is the cylinder built over some set.
00:42:12.544 - 00:42:31.948, Speaker A: And, and I'm picking something which is including the subset. And I'm looking at the cylinder bit over it. So it's included in the original scene, but the intersection of all the CN was empty. So, you know, by the really basic, you know, set. Set. Okay. Makes sense that we'll get anything.
00:42:31.948 - 00:42:44.504, Speaker A: Let's see. No. Okay. Right. Okay. Now I have a question. So basically, end of measure theory.
00:42:44.504 - 00:43:41.292, Speaker A: I have a question, and the question is, how many of you are not familiar with the basic concepts in optimal transport, like sea cyclical, monotonicity, sigon, K functions and this sort of stuff? So raise your hand if you are not familiar, if you never heard about this sort of stuff. 12345. Okay, um. So here's what I will do. I will, I will state clearly, I mean, after the hour, we make a small break, but after, after the break, I will make. I will provide you with a list of basic definitions and I will state the fundamental theory of optimal transport, which characterizes optimal plans. But I will not prove it.
00:43:41.292 - 00:44:17.274, Speaker A: I will describe you why that is true, but will not prove it because that requires a couple of hours, which is an important share of the total amount of hours that I do have in the introduction to optimal transport that I pointed you out is on page 20. And so what I invite you to do is go there, read it, and if there are questions, come to me. Okay. We can also organize if you want an extra lecture, you know, not on Monday and Friday. That's where we sit down and we review this material. The reason why. So is that because I don't really, I will not really need that much of the theory, basically.
00:44:17.274 - 00:44:36.412, Speaker A: And. But the little bit that I need would require, I mean, just too much of investment of time. It's really not worth. Okay. And on the other hand, I would perfectly fine if, for the purpose of my course, you know, you take as a black block this sort of basic stuff about. About black boxes. Sorry.
00:44:36.412 - 00:45:19.504, Speaker A: This basic stuff about. Okay, so let's make a five minute breaks. Meanwhile, I've write a few definitions on the board, and then we. Five minutes and not a minute. Five minutes and then we continue it. Hi. I'm a first year.
00:45:19.504 - 00:45:55.434, Speaker A: So you said this course can be taken as a reading course. Like to get credits? Yes. How would you like to evaluate those? Unfortunately, non reflexive Banach spaces do exist, apparently. So we have to choose which side of the story we want to look. And for measures, we really should look at direction on previously defined objects like sets or functions. That's a kind of philosophical point of view, right? But technically speaking, I mean, this is really just. Sure.
00:45:55.434 - 00:46:45.550, Speaker A: All right, so about optimal transport. So let's say. So let's fix for the last of this lecture, let's fix two polish spaces and the map from their product to say zero plus infinity. Whatever continues. Let me exclude plus infinity, just in case. I don't think, I think I can handle. But c, in our mind, is the cost function.
00:46:45.550 - 00:47:45.592, Speaker A: So, if I wanted to transport a point which is x on the third space to a point y in the target space, I pay c of xy. Okay. And then the optimal transform rule is as follows. Take. So fix also selects, say, mu b probability measure on x, new Borrell probability measure on y, and minimize the integral of c x y d alpha xy. Amongst all alphas, probability measures on the product with such that. So PI x push forward, alpha is mu and PI y push forward.
00:47:45.592 - 00:48:04.456, Speaker A: Alpha is the target measure. This is the optimal transport rule. Okay, so what does it mean? So what does it mean? What is this alpha? Just, let's just clarify. So let's think for the first case. Let's say the new and new are deltas. So delta and x delta y. Okay? Then there is only one probability measure that project.
00:48:04.456 - 00:48:37.602, Speaker A: Also, PI x is the projection to the first coordinate and PI y and the second. So, so if both are deltas, then you see that the only chance for a measure to project on this is to be the delta in the product. So you are minimizing among, you know, a guy with one. So that's the minimum, the maximum, whatever. And that is gives you the cost CxY. Okay. More generally, if mu, if mu is Delta X, so if mu is just a delta or mu, just one of the two delta, then there is only one alpha that does the job.
00:48:37.602 - 00:49:13.606, Speaker A: So the only alpha alpha is delta F X product. You can see this, you know, think, you think at how this, this shape. So you're looking for measures on the product pace. So this is x and this is y. You're looking for measures that project into x and y to the given measures. If the starting measure is an x is a delta x. So this measure should be, you know, concentrated on the, you know, the cylinder based in x.
00:49:13.606 - 00:49:37.212, Speaker A: So there is really not any wiggling room to play. The projection of y should be new. And that's, you know, exercise would be the only measure that satisfies the constraint. Okay. Other examples so let's see how to. So I'm trying to give you an idea of how these half as are made. So what are these trans, called? The transport plants in the general case.
00:49:37.212 - 00:50:35.444, Speaker A: General case, you have a certain measure mu here, a certain measure nu here. And these alphas are measured in the product. And you should think it like this. The measure of a small rectangle, say e times alpha. Alpha of such a rectangle measures the amount of mass that mu was given to the set e that is actually going to be sent into the set f. Okay, and how much do I pay for transporting this map from e to f? Well, it's cost. A particular element example is suppose that you have a map t from x to y such that t push forward mu is equal to mu, a transformer.
00:50:35.444 - 00:51:26.594, Speaker A: Then this induces in a natural way a coupling in the following way that alpha equal, you know, identity comma t, push forward mu. This is the transport identity comma t is the map that takes x and return x comma t of x in the product. And by, you know, functionality of the push forward, if you like this sort of terminology. But you know, this sort of chain rule. If you know, the first margin of alpha is mu and the second margin of alpha is t, push all mu, which is nu. Okay? And this, this guy is made like this. So if this is the graph of t, then what you are doing, what you are doing is you taking the measure of mu and you are sending it on the, on the graph of t right now.
00:51:26.594 - 00:52:24.088, Speaker A: In fact, in the original formulation of the optimal transport problem, as given by monsieur, one was minimizing, minimizing among, among transport maps the integral of c x, comma t of x, d mu of x. That gives you the idea that I'm sending any point x to a certain point t of x. How much do I pay in total with this amount of it? Okay, this formulation, either from the mathematical perspective, is not that good, because the set of transport map per se, it has no structure, could be empty, for instance. And there is no operation that you can do on maps that still gives maps basically, and also is extremely non symmetric. What happens if I want to transfer? While this in some sense is way better. So, for example, there is always at least one mu cross mu. The product measure is always a competitor.
00:52:24.088 - 00:53:03.492, Speaker A: So the set where you're minimizing, not at all. One other thing that I want to mention is that. So this pastures from maps t to plants is extremely common in analysis, is what is called the study of young measures. If you are a little bit into the weak convergence of Lp spaces. And perhaps we will also encounter this sort of procedure if I will be able to, when discussing regular random flows of sobel effect of this. That's, you know, the first step of the, is always, it's always this kind of procedure. Why, what is the disproportionate? It linearizes an Olina program.
00:53:03.492 - 00:54:14.790, Speaker A: No, in t. In t, this program is just Ms. You have no constraint, no reasonable constraint, no reasonable structure on the class of maps, t, no good dependence on the cost on t and whatever, while here in alpha, this program is linear and the constraint is convex. You know, the average of alpha of two, alpha is still a good alpha, right? So intuitively, in terms of, you know, if you look at, back at what happens with maps, like saying, well, let's say that I have two maps to transform up from new to new and say, how do I take their average? Well, basically it's like saying, well, let's, let's send half of the mass through t and half of the mass through s. So the average of the plants induced by maps would do something like this. Okay, now I want to minimize something. So, there is one theorem that we all know about existence of minimizer that tells you that if you are minimized a lower semi continuous function over a compact set, then a minimizer exists.
00:54:14.790 - 00:55:12.224, Speaker A: So that's basically almost the only theorem. Well, not really the only, but almost the only theorem we do have about existing numbers. So, let's try to see whether we can apply this theorem in this case. First of all, what it is, what it is the, so, let's study the collection of advisable transport plans. So this coupling, they give it a name. Sometimes I don't know, sometime I don't know if I will keep this notation later on, but admissible transport plans, this is the subset of morel probability measures on the product such that this constraint is true. Okay, and the first remark is that this guy is weakly compound in the weak topology in the border space, it is compact.
00:55:12.224 - 00:56:42.134, Speaker A: Okay, and why this is the case? Well, because, because more generally, more generally, the union, more generally, if don't know, k, x and Ky are weakly compact. Or let me see, like this, are tight collections of probability measures, measures on x and y with obvious choice of notation. Then the collections of alphas in the product such that, you know, PI, x before alpha fits into kx, and the second marginal goes into Ky. This is tight. So tightness in some sense works well under product. So I have a tight family measure on x, a tight family measure on y. And look at all the probability measures on the product whose first marginal is in the first, you know, collection the second margin.
00:56:42.134 - 00:57:18.858, Speaker A: This is tight and the proof is trivial because I have to prove tightness. So I have to find this compact set on which most of these guys are. This guy's almost all concentrated. So you give me epsilon and I find, first I find k one inside x, for which all the measurements that mu of the complement of k one is more than epsilon for every mu in this first pending. Right. And similarly, and also I can find the compact set inside. Yeah.
00:57:18.858 - 00:58:00.734, Speaker A: Such that nu of k two complement is more than epsilon for every new in, you know, Ky. Right. Make sense by that. Okay, now what will be the compact set in the product space that I will pick? Well, let's look at what happens if I take p one cross table. This is compact in the product of compact position. And let me pick alpha of k one times, sorry, of the complement of this for alpha in this set. So I'm taking the product of two sets and I'm taking the complement.
00:58:00.734 - 00:58:54.204, Speaker A: So this is clearly, you know, this is clearly as a set, this is included into the complement of k one cross y union, x times the complement of k. It's just, you know, this guy and the other guy makes sense. So alpha of this is less or equal than alpha of this guy plus alpha of this other guy. But how much is it? Half of this guy, alpha of this guy by definition. Right, this is k one. So this is PI x, push forward alpha of k, the complement of k one, which is smaller than epsilon and the same over there. So tightness is.
00:58:54.204 - 00:59:53.724, Speaker A: So in particular, if I fix, if I just pick x and k y are made by just one probability measure that is certainly tight. And therefore this set, I've just proved that this set is tight. Okay, so to prove that this weak compatible is now just sufficient to prove that it is weakly closed. Right. But why it is weakly closed? Well, the constraint, well, I guess, I guess one way of seeing it is that PI x to forward alpha is equal to mu. If and only if. For every PI continues and bounded on x, we have that the integral of phi x d alpha xy is equal to the integral of phi.
00:59:53.724 - 01:00:48.496, Speaker A: Okay, but then, but then, but then you see that these are closed, weakly closed constraints fix phi, fix one function Phi, and the collection of alphas such that this integral is equal to some given number is closed, weakly closed. Right. So I'm just intersecting over all the phi's and. Okay, so this is proof. So I have a weekly compact and now I have compact. And so I would, now I would love my functional to be weakly lower semi continuous, so that now, you know, the direct method of calculus operation applies. And let's look at this.
01:00:48.496 - 01:02:01.270, Speaker A: So, notice that, so the map, of course, the map that takes alpha and returns the integral, let's say, of psi xy D alpha xy, this is weakly continuous if psi is continuous and bounded on the product. Right now my function, my cost function is not bounded. And I don't want to assume that, because in my mind, in my applications, there will be the distance squared over the given set. So I don't really want to make that assumption. However, however, the map, so what I know is that the map that takes, you know, up and returns the inter of the cost truncated, say the level up. This is, we will continue because the cost function I strong kd was continuous from zero, you know, rounded from below, I'm cutting from above. But then, and, but then, of course, the integral of cost, the alpha is equal to the soup by monoton.
01:02:01.270 - 01:02:52.652, Speaker A: Convergence is equal to the soup over n of the integral, right? For any alpha probability measure which is equal. Therefore, therefore, the map that takes alpha and the term this guy is the soup of the map that takes alpha and trans, these guys, but each of these is a continuous, weakly continuous map. Therefore, the soup of continuous maps is lower semiconductor. Okay, so I have compactness of the, of the set, you know, my set where I want to minimize stuff and the function is lower. So it continues existence of the minimizer string. I pick a minimizer, the direct method of a calculator. What's that is, I pick, I want to find a minimum.
01:02:52.652 - 01:03:28.884, Speaker A: I, a priori, don't know whether the minimum exists or not. So I pick a minimizing sequence. So I pick a sequence alpha n such that the associated cost converges to the infinite that by definition of inf exists for sure. Okay, then I invoke compactness. In this case, we compactness to say that, you know, I can extract a subsequence that we can converge somewhere. This plus the lower semi continuity of the function ensures that the function applied to this limit of the sequence is less or equal than the limit, but therefore it's exactly equal to limit. Okay, so existence of the minimizers is there.
01:03:28.884 - 01:04:13.996, Speaker A: You know, one of the advantages of this formulation is that, you know, existence is trivial. What about uniqueness? Of course, at this level of generality, there cannot be a unique, a constant cost function, for instance, is included. And in fact, in general, I don't think we really care that much during my course about uniqueness, nor about the fact that minimizers are actually induced by a map, which is, on the other hand, a crucial aspect of the theory when you work on a smooth phase. See RD, remainifold and et cetera, et cetera. But I. Okay, perhaps I will touch, but in case much later on. So, so for the moment, what I care the most is the structure of the, of the minimizers.
01:04:13.996 - 01:05:47.404, Speaker A: And, and yet, there are a couple of remarks that I want to actually, let me give a definition. And this, this kind of things work in the high generality of the diagonal that I'm working right now. So let's consider a subset of the product. This guy is called C, cyclically monotone. If for every choice of natural number, let's say positive, and for every choice of xi yi in this set, y goes from, you know, one to n, we have that if I, and actually, and also, and also, and also, and for any choice of permutation, sigma. I don't remember the notation sn, I guess. So the permutation of the set of n indexes, we have that the sum over I of the cost of going from xi to yi is not bigger than the sum over I of the cost of going from xi to y sigma I.
01:05:47.404 - 01:06:25.046, Speaker A: Let me comment about this definition. Say that we have that our transport problem is between sort of combination of direct masses. Say that both Nu and Nu are, you know, one over n sum of direct masses over n points on the source and n points on the target space. Okay? And we have a plan, a way of transporting these masses, and we want to check whether this is optimal or not. I mean, we don't know if we can random one. Okay, what it is that we can do? Say that we know. Say that we know that inside.
01:06:25.046 - 01:07:05.562, Speaker A: So this plan by nature should be concentrated on a finite number of points. Okay, say now that let's pick endpoints in the support of this plan. So this point will be of the form x y. So what we know by the fact that these points belong to the support of this plan is that, is that a little bit of mass is taken from x I and sent to yi. Okay, now let's say that we wonder whether our plan is optimal well before. This condition must for sure be satisfied in this support. Meaning, so I cannot find a finite set of points and a permutation.
01:07:05.562 - 01:08:03.494, Speaker A: So that if, rather than sending the math to x from xi to yi, I rather send from xi to y sigma I, I cannot do something strictly better than what I was doing before in terms of total cost. You see what I mean? At the intuitive level. Okay, if for some sigma I have a strict inequality, well, let me, you know, take out as much as I can from this sort of circle and let's, you know, redistribute it in such a way that I get this input. The fact that I'm picking a permutation here is what would ensure me that after redistributing the mass, I still have the same margin. It's not that I took out some extremely costly jump and not replacing it with anything. Okay, so that is a definition. A couple of other definitions are the following.
01:08:03.494 - 01:08:46.393, Speaker A: A function phi from x possibly, I guess we, I never remember. So here I should pay a little bit of attention. I should be sure that should be minus infinity should be included. Okay, well, anyway, yes, okay, I priorit surplus infinity, but I miss it. So this is secant key. Actually, actually, let me do this. Let me speak about ctrospores.
01:08:46.393 - 01:09:45.786, Speaker A: So a c transform. So the operation of c transforming is something that takes a real value function on x and returns the real value function of y positively plus or minus infinity and vice versa, takes function from y and a function of y. So let me start, let me start from functions on y. So let's say that psi goes from y to say r possibly plus or minus infinity. Then psi c is a function from x with values on r possibly plus minus infinity. And this is defined as the inf over all the y's of c x y minus psi of y. It's a definition, okay? Its relation to optimal transport might be totally unclear at this point, but there is another construction that probably you've already seen that is extremely close to this one.
01:09:45.786 - 01:10:19.510, Speaker A: And it is the definition of legend transform of convex functions. Say that, okay, let we play a little bit with signs. This info could be a soup. And if x and y are rd and the cost is the scalar product, then this is, you know, the soup. Let me recall that f star x is the sup over y of x dot y minus f of y. That's definition of lesion transformer. And this is just the direct generalization of this.
01:10:19.510 - 01:10:51.090, Speaker A: Don't get scared by the super infin because this is just a shortage. Okay? And now of course, of course a similar definition is in place if I start from function phi over x and I use the same kind of trick to define a function, a function of y. Okay, in general, I should pay attention that the two are not really the same thing, because c is defined on two different spaces. And therefore, in particular, can also be non symmetric. So, looking the inf over y is not the same as doing the inf over x. But you know, the. From the adjust perspective, they are sort of the same.
01:10:51.090 - 01:11:18.214, Speaker A: Okay, and now I say. And now I say that the function. So a function is convex and lower semicontinuous if and only. It is the legend transformation that is one of the first theorem in convex analysis that one encounters. But it's clear that the soup of linear stuff is convex. And basically Ambanac, which, okay, in finite dimension is rather easy. Ambana tells you that any convex lower semiconductor function can actually be retained.
01:11:18.214 - 01:12:45.458, Speaker A: And at the definition c concavity and c separate differential. So phi, say, from x to r, is the c concave if PI is equal to sine c for some, and similarly for c concave functions on y, and the c sub differential of phi. This is a subset of the product. And it is the collection of couples xyz such that phi of x plus PI, c of y is equal to Cxy. Okay, end of the definition. Now, with commentary that we can, first of all, despite the differential in the terminology, there is no derivative in here. I'm not, you know, linearizing anything.
01:12:45.458 - 01:13:27.490, Speaker A: I'm just looking at, you know, where a certain equality goes. Also notice, notice that for every x and y, this inequality is always true. Why? Because. Because you see, right? If being an inf, the c transform is an infinite of something. So, the choice of this particular x, where I'm looking, is always admissible in the definition of ic. And you get. And you get the lesser, right? So in some sense, you live in the c sub differential.
01:13:27.490 - 01:14:25.544, Speaker A: If you are, if, you know, effects, is one of those points where the definition of the infinite PI c is actually realized. Make sense? Okay? One other thing is that if you play a little bit with these signs and whatever, to reduce to this, to this situation, then you are in the c sub differential if and only if, you are in the sub differential. In the classical terminology of convex, so y. So a point. Now, you know that when y realizes the max over here, it means that y is in the subdifferential of in the sub differential of x. And much like in convex geometry, in convex analysis, there is this duality between f and f star. Right here we have the analog duality between.
01:14:25.544 - 01:15:10.874, Speaker A: Actually, there is one thing that I should mention, and it is easy, easy, easy. And that's really the same in convection as this for any phi, for any phi from x to r, or whatever, plus minus infinity. If I do the c transform now, I get a function over y. Therefore I can make another time as a transform, and I get a function over x. And therefore I can make another time this transform and get a function of a y. Okay. And in principle, I could go back and forth a number of times, but after I do three times, I go back, I go back to, okay, check it.
01:15:10.874 - 01:15:44.244, Speaker A: It's an exercise of, you know, playing with the definition that is inf to pin. And you see this box. Okay, so in particular, in particular, if phi is c concave, then phi cc is equal to phi. In fact, this is another, because it's phi secon k. Phi is the transform of something. So doing other two times the transform, it's like doing just one. So it's going back to PI.
01:15:44.244 - 01:17:02.074, Speaker A: On the other hand, if phi is five cc, then it is the c transform of PI c, so it is secant. Okay, okay. It's still, of course, totally unclear what all of this has to do with optimal transport. But here is, here is the, another easy observation. And the easy observation is this, is that for any phi, let's say phi sigon k imply, okay, this is not really needed, but I only look at the c sub differential for c concatenate functions imply that PI c is a c sig element. So if you believe the sigma monogenesity had something to do with oxygen transport, also these conditions and why this is the case. Well, let's look at the definition.
01:17:02.074 - 01:17:50.886, Speaker A: And it's going to be trivial because so ccmator means that this happens, right? So, so what should I pick? I should pick a finite collection of xi yi in the c sub differential PI and the permutation, right? And then I should check whether, whether that equal. Behold. And so, let's have a look. So I should do sum over I or cxyi. Okay, but by definition, this means that for every I, no, let's forget about this. For every I, this is equal to phi of xi plus phi c of yi. And then I saw the operation of addition is commutative.
01:17:50.886 - 01:18:36.194, Speaker A: Therefore, this is also equal to the sum over I of phi xi plus phi at y sigma. I just rearranged the second term. Okay, but now, again, for each term in this, in this, in this sum, this is always bounded from both by the cost of transfer of transporting xi into y sigma. Okay. All right. Now, here it comes, the fundamental theorem. Optimal task makes us close this circle of ideas.
01:18:36.194 - 01:19:46.480, Speaker A: So, okay, let me write fully distance. So, xy completes polish c from x cross y to let me say zero plus infinity. I'm putting loads of assumptions that are totally unnecessary, but there are more than sufficient to cover the case that I actually care. Continuous new probability measure on x, new probability measure on Y. And I need to assume something. So there is, as of now, it could be that any time I find a transport plan from new to new, the associated cost is plus infinity. I mean, I have no, you know, finiteness assumption on this.
01:19:46.480 - 01:20:37.872, Speaker A: And I need to, if I want to deduce something about the structure of minimizers, I really need to assume something that, you know, exclude this sort of behavior. So, let me assume that. Let me assume that there exists some function f in l one mu and the function g in l, one mu such that c of x y is less or equal than f of x plus g of y for every x and y. So, but of course here, I mean, there is a, there's a function, not an equivalent class of function. There is a function which is Borrell and integral immune. This is true for everything. Then.
01:20:37.872 - 01:21:07.904, Speaker A: And then the following are equivalent. And let, and let. And let's say alpha be an admissible plan. Okay. Then the following are equivalent. First, alpha is optimal. It minimizes the cost.
01:21:07.904 - 01:22:17.054, Speaker A: Okay. Second property. Ah, I should, okay, should mention one thing. The support of alpha is sequentially monitored. I read the statement and then I comment on you three. There exists phi from x to r, possibly plus minus infinity t concave such that the positive part of phi is in l one mu, and so that the support of alpha is contained in the c sub differential phi. All right.
01:22:17.054 - 01:22:43.934, Speaker A: Okay, I make a few comments. First of all, I never mentioned what the support of a measure is. Perhaps, let me do it. Now, the support of the measure is the, so support. Support of alpha is by definition the intersection of all the c among all c closed. And where alpha of c is equal, one. Okay, probability measures.
01:22:43.934 - 01:23:19.740, Speaker A: Otherwise, you can adapt this to a general measure. This is equal to the complement. Okay, let me say x minus the union of all the u open such that alpha of u is equal to zero. Okay. Now this definition you can do any time on a general topological space. The interesting part about separable spaces is that alpha is concentrated on itself. In general, this intersection is more than countable.
01:23:19.740 - 01:24:13.314, Speaker A: So it could be that a priori, after you intersect it, there are measures with empty support in crazy spaces, not surpassable spaces. But this intersection, you can always reduce the decays of countable or countable intersection. And perhaps you can see more easily out of this if your topological space is accountable basis. Any union of open sets can always be reduced to a union of certain subsets, certain open sets in this base, because every open set is union of suitable collection of set in the basis. So that union is always at most countable. So if you have now accountable collection of open sets with zero measure union is equal to zero measure by counterbalancing, and therefore the measure is concentrated on its support. Okay, okay.
01:24:13.314 - 01:24:50.918, Speaker A: As mentioned. So I will not, I will not prove this theorem, but I will describe the proof and then leave the technical details to you guys. Have a look to this introduction that I brought. It's not that art, okay, it's just long. Let me comment. So this implication, actually, we already know, because any time, you know, a set is. So the full steel differential is, and clearly sigmaton is preserved if you pass two subsets for, by checking thing.
01:24:50.918 - 01:25:37.060, Speaker A: So if this all dissolves. So that's, you know, there's nothing to, okay, and, and let me see if there are other, other implications that are trivial, okay? Not really. So, so let me see, let me see how, how the proof goes and, okay, the implication three to one. So proof, not really, but, you know, sketch of it. Yeah. The implication from three to one is the, I mean, is the easy one. Suppose that you have, that you have Phi satisfying, you know, this condition.
01:25:37.060 - 01:26:58.640, Speaker A: Let me, let me neglect the integrity issues and let me, let me, let me take, you know, alpha prime, any other admissible plan, and let me try to compare the cost of alpha that satisfy this property with the cost of alpha price. Okay, so what it is the integral of c. And this will be, I mean, it's basically the same computation that we done. So alpha is fully concentrated on the C sub differential of phi, right? Therefore, for any x and y that actually, you know, will matter in this integral, we do really have that this is equal to the integral of phi, phi of x plus phi c of y d alpha xy. Okay? And now if you believe in the linearity of integral, which is a tricky statement, of course, if plus infinity is allowed here. But, you know, under this integrity assumption, you can see that this is actually equal to the integral of Phi x D alpha, you know, plus the integral of Phi y or Phi cy a little bit, just, you know, just check that this is true. Okay? So say if the cost is bounded, for instance, this is certainly true.
01:26:58.640 - 01:27:33.364, Speaker A: Okay? Otherwise you have to use a little bit of assumption. But this is equal to the integral of phi D mu, and this is integral to the integral of phi c d nu. Makes sense. So these, all these, again by, you know, now you call into play alpha prime. This is equal to the integral of phi x plus phi, c of y. D. Alpha prime of Xy, right? So, but this, now for any x and y, this, the sum is less or equal than the cost of going from x to y.
01:27:33.364 - 01:28:37.864, Speaker A: So this is less or equal than the inferior of Cxy, the alpha y. Okay? So up to this technicality, this, you know, that's the easy implication, okay? And of course, if you believe now that this theorem is telling you something nontrivial, it means that at least one of the other implications is not triggered, right? And in fact, it is not the case. So, so let me, let me try to illustrate why. Why one implies two. So one implies two is done by contradiction. In fact, in fact, in some sense, okay, okay, let me just say this. So if, if mu and nu are concentrated on, on finite sets, the conclusion is true.
01:28:37.864 - 01:29:36.332, Speaker A: And the conclusion is true, meaning that we cannot, I mean, that's the same argument that we've done before, right? If the alpha was not concentrated on a seasick mountain set, we could rearrange the mass in such a way that to find the new alpha with strictly less cost, and therefore, alpha was not alpha. Okay? Now all we need to do is to pass this kind of idea from the finite to the continued case. And that's, again, why. And that's why the assumption of continuity of c plays a role, basically. If, so, the idea is this. So suppose that alpha, again by contradiction, if alpha is not the support is not, we can find a finite number of sets in the product and the permutation where the strict clinical defense. But then by continuity, technically fails on, okay, this, the single points typically will have zero mass, right? Because measures could be diffused.
01:29:36.332 - 01:30:28.398, Speaker A: But, but, but now we, so by continuing, we can find small neighborhoods, the product neighborhoods of these points where the strict equation still fails with the same permutation. Okay, now these will have positive mass, you know, because, because they are pointing. And now it's just a matter of rearranging things between these points without destroying the mass unconstraint and producing, and producing a new plan which still transports the mass. This is only a technical, okay, but the idea is this. And two implies three is perhaps the most, I guess, the most incredible thing. I mean, I couldn't believe the first time I see this. So two implies three, in fact, rests you upon the following very general fact.
01:30:28.398 - 01:31:21.348, Speaker A: If gamma is a sea sigma monoton, then there exists, in fact, I can build. Not only there exists, there is a formula producing a c concave functions PI. Let's see, with, you know, phi c, sorry, series of relation phi containing them. That's totally crazy. You know, you start with the set. The only thing that you know is that this signaling monotone and you can build an actual Sigoncave function with sysapper differential context. Okay, it's not obvious.
01:31:21.348 - 01:31:48.704, Speaker A: In fact, in fact, in some sense, okay, a priori is not obvious. A posterior. Once you see the formula, there's really no other thing that you can do. Again, try to look at this formula in these lecture notes. But that basically, and that's basically the end is interpretive condition. Then comes into play after the assumptions, after the assumption of the cost. Okay, let me comment, let me give another couple of comments about this statement.
01:31:48.704 - 01:32:20.384, Speaker A: So, there is one factor among others that is particularly non trivial about this. And that again, a priori is a little bit surprising. And a posterior, maybe not that much, but, and the fact is the following, that being optimal depends only on the support, the plan. So this means the following. Pick two measures, mu and u. Find an optimal plan alpha. And now find any, pick any other measure in the product space whose support is concentrated on the support.
01:32:20.384 - 01:33:06.104, Speaker A: Support is included in support of your plan. Typically, this will have different margins, of course, but whatever their margins are, this new plan is still optimal. Okay? Which might be strange at the beginning, but if you think, if you go back, if you go back to the finite dimensional case, perhaps, perhaps you see why this can be true. Because, I mean, in the final, in, sorry, finite direct masses, that's clear. That the sea sequel monotonicity characterizes optimality. It doesn't matter how much mass you give to each of those points. As soon as you give a positive amount of mass, you must be physically monotone, because otherwise you can promote stuff and be strictly better.
01:33:06.104 - 01:34:03.680, Speaker A: Okay? So that's the same kind of principle which is at play here. And one last thing that I should mention before concluding today's lecture, and it is about the dual problem and optimality in the dual problem, as you will see. So we'll see the direct consequence of this statement as I made it. So you have this transport problem, right? You have your mass new, your mass new, the cost, and you want to transport new to new in the most efficient way. I'm a transport company, and they come to you and they tell, look, I'll take care of the transport, okay? You just pay me psi X for any time I pick a unit amount of mass from the point x. And you also pay me psi of Y. Anytime I drop a unit of mass, at the point Y.
01:34:03.680 - 01:34:46.052, Speaker A: Okay, you know, how much is the. So the reason, so first of all, what? It is a reasonable set of prices that I should put if I want to be sure that I could, you know, being some sense, you know, a good, good match for you. Well, certainly in general, I would like phi of x plus psi of Y. This should be bounded from above by CXY. Otherwise my prices are too high and they're not convenient for you. Okay. And of course, the total cost that I heard, the total, you know, the total price that I get once, once I fix this, if you allow me to do the transportation cost, is the interest of finding you plus the interoperability, that's my total revenue.
01:34:46.052 - 01:36:00.672, Speaker A: Okay? And it is obvious, it is obvious that my total revenue is for sure less or equal than what you pay for the cost if you come with me, because this, if alpha is an admissible plan, that this is equal to integral phi x plus psi y, the alpha xy, okay, and by this condition, this is less or equal than the interval of the cost, right? Okay, and then, and then, and so my problem, you have the problem of transporting. My problem is to maximize this subject to this constraint. So that's the dual problem. And what this inequality is telling is that the soup of the dual is always less rigor than the info of the primal pro, okay? And a corollary of that statement is that equality can be achieved. There exists phi and Psi, which actually I can take as the sitters form of phi. And phi is c concave, actually. Also, so that, you know, equality holds here.
01:36:00.672 - 01:36:53.952, Speaker A: I mean, so that, you know, equality, you know, equality holds. So my, the soup of the dual, the max, this becomes a max of dual problem. For dual problem equals the mean of the original problem. Just pick phi this time. Okay, if I have phi and phi c, the trans, the c transform certainly satisfies this constraint. In fact, for any phi, if I pick a psi, the c transform, I get this constraint by definition. But then, but then I have an optimal, no, I have an optimal plan alpha for which, for which equality holds in.
01:36:53.952 - 01:37:41.340, Speaker A: Right, okay, so, just a couple of conceptual remarks. These. So there is, so anytime, so anytime you are minimizing a linear function over a convex set. This is what sometimes is called. Well, I mean, it's a linear optimization problem. And this kind of problems do have always been a dual problem where you minimize or maximizing another function over another convex set. And one feature that the course on this duality is the relation between the constraint and the cost function.
01:37:41.340 - 01:38:20.530, Speaker A: Notice that, notice that in the cost problem. So of course, the data of the problem in both cases are the starting measure, the final measure, and the cost. These are the data. Now, in the original optima transport problem, the unknown is the alpha, and so the constraint. So the constraint is alpha being admissible, right? So the constraint calls him to place the measure and the functional to minimize is this that causes to play the chord. In the dual problem, things happen in the other way around. So the constraint takes into account only the post and the function to maximize.
01:38:20.530 - 01:39:12.088, Speaker A: To maximize takes into account only the measure. Okay, this is a common feature on these, on these duality program. And what it is perhaps one other thing that I want to mention is that, is that. And then I will conclude, by the way things are written over here, it might seem that you start from an optimal plan and you get the c concave functions as that. This is true. Okay, what is actually in fact worth to mention is that the same phi worked with any optimal plan, and vice versa. That any, you know, basically any optimal plan works with any, with any phi which maximizes, which maximizes the dual problem.
01:39:12.088 - 01:39:57.468, Speaker A: Let me point out, let me clarify what I mean by this. Actually, let's have a look at this. So, as soon as phi, psi and alpha are admissible, I do have this inequality. I'm almost done. 30 seconds. We do have this inequality. Now, if alpha is optimal and psi also with psi, Rothman and dual permanent, we have equality value, right? Now take another beta, which is optimal for the cost, for the cost, for the cost, then we do also have that the inter of PI, sub psi in the beta is equal to the inter of the cost function in the beta, because it is equal to the cost function in the alpha, the minimizes, the minimize the same.
01:39:57.468 - 01:40:39.386, Speaker A: But, you know, but this is always less or equivalent cxy. So if I have the integer of this function in the beta is equal to the integer of this function in the beta. It means that I'm concentrated on points where PI x plus psi y is equal to zero. Make sense? Think about this. I'm saying it's reality. I'm saying that if I have another plan which is optimal, the cost of this other plan is the same as the cost of r. But on the other hand, the inter of the cost should be, in principle, should be greater or equal than the integral of PI x plus psi y, because this identity because of this inequality.
01:40:39.386 - 01:41:13.398, Speaker A: But if the integrals are the same, it means that I'm concentrated on points where equality holds, right? Okay. For today, that's all we resume on Friday at same hour, 1030. Okay. Unless there are questions. Okay. If not, goodbye to the person following online. Thank you.
01:41:13.398 - 01:41:38.734, Speaker A: Thank you very much. Very interesting mathematical arguments. Thank you. Thank you. Appreciate the details. Was there a question? I couldn't hear the last sentence. No, I said I appreciate.
01:41:38.734 - 01:41:45.914, Speaker A: Okay, my pleasure. My pleasure. See you on Friday. You're a good teacher.

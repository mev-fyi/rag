00:00:00.080 - 00:00:00.320, Speaker A: So on.
00:00:00.320 - 00:00:28.756, Speaker B: Okay. Good evening everyone. Welcome to our monthly seminar series on quantitative finance here at the Fields Institute. Before introducing our speaker, I'd just like to say thank you to our sponsors, Scotiabank through the center for Financial Industries and Waterfront International, for their continual support of this seminar series in particular. So today it's a great pleasure to introduce Eric Delaj from Hachesee in Morial, and he'll be telling us about toward data driven, what is it exactly? Data driven equal risk pricing.
00:00:28.860 - 00:00:31.144, Speaker A: So Eric, the floor is yours.
00:00:33.684 - 00:01:40.084, Speaker C: Everyone here with me online also? I assume so. So thank you very much, Sebastian, for inviting me to give this seminar. It's a real honor for me to be here. So I'll be presenting some work with my recently graduated student, Saeed Marzban, who's currently a senior consultant at Ernst and Young, and a colleague of mine, Jonathan Lee, who's associate professor at Telfer School of Management. I'd like to thank Canada Research chair program for the support, the financial support, and the girard, also in Ivado. So today I'll be presenting some new methods that we've derived, algorithmic methods based on reinforcement learning, in order to price financial derivatives in the context where we want the two parties involved in the transaction to be somehow sharing the load in terms of the risk that are there being exposed by the derivatives. And we're doing this with the aim in the long run to be deriving option prices and hedging strategies that are purely driven by the data, instead of being driven by stochastic processes, assumptions.
00:01:40.084 - 00:02:24.920, Speaker C: So let's start, and I'll start very simple. And throughout the talk, I'll be talking about this very simple european call options. So I can introduce my notations here. So the payout of this option is the maximum between zero and the value of the asset at maturity minus the strike price. And you see that if we're trading this option, there's two sides to this transaction. There's the buying side, which is worried about perhaps the asset price not going beyond the strike price, and in that case, it's going to have lost the transaction expense. While on the other side, the writer of the option, which is typically a bank, he's exposed to the opposite risk of what if the asset price goes beyond the strike price and then he has to pay out this option.
00:02:24.920 - 00:03:31.416, Speaker C: We assume you all know about this. So traditionally, the way options have been priced is assuming complete market environment. And I know this is a very basic environment to describe, but I want to give the basic principles that are replicating the complete market pricing strategy is based on no arbitrage assumption. And it's exploiting the fact that when the market or the asset process is simple enough and the market is frictionless, well, you can actually replicate the option payout using a portfolio that is edging the risk of the options. So here are very simple equations in the context of two scenarios where we see that the only appropriate price for this option is sigma star s plus zeta star. Okay? So this can be applied in the more multi period setting or in continuous time, as long as we can make this assumption that the market is complete, meaning that for any payout function, we can replicate the payout using a hedging strategy. In reality, it's very rare that the markets are complete the moment you introduce transaction costs.
00:03:31.416 - 00:04:02.614, Speaker C: This hypothesis sales. Here you have just a little augmentation of my example where I add a third scenario and there's no more replicating portfolio anymore. Okay, so this is one problem we encounter in reality. The other problem is that we don't know what is the stochastic process in reality. We don't know even if there's two scenarios, what is the value of the asset in the good scenario or the bad scenario. Okay, so this talk will try to address these two issues. But first, let's go through what are the methods that can be used for pricing option in an incomplete market.
00:04:02.614 - 00:04:43.354, Speaker C: When we survey the literature, we see two big categories of approaches. The first category is trying to draw as many insights from the complete market setting, namely the fact that you can price using a risk neutral martingale measure. And then the question is, what martingale measure should we use, since the process itself doesn't give rise to a unique one that can be used for pricing. So they will use other market data. Or you could use existing options to calibrate your market, your martingale measure. Or you could also look at the physical measure and try to find a martingale measure that is closest to the physical one. So we won't be going into these directions because we're really worried about the hedging problem.
00:04:43.354 - 00:05:34.184, Speaker C: We're thinking that whatever price we sell this option at, we'll have to manage the risk associated with the option. So from that perspective, you have different categories of methods. So some methods are take like the first in the list here takes the point of view of the writer of the option, saying, this writer will not come into doing this transaction unless the price is such that after trading the option, he's able to edge completely the risk out of this option. And this gives rise in some context to expected utility and differential credit pricing. These are prices for which the expected utility of the writer is the same, whether he trades the option or not. There are models that are more based on the arbitrage principle or trying to minimize as much as possible using the hedging strategy.
00:05:36.644 - 00:05:38.524, Speaker A: The error in replication.
00:05:38.684 - 00:06:13.750, Speaker C: These are called epsilon arbitrage models, and I'll be giving you an example in a moment. So, our method will fall into a very recent category of pricing scheme, which is called equal risk pricing. This was introduced in 2017 by Guo and Zoo. So if we look at the epsilon arbitrage model, which is somehow the most closely related to what we're looking at, because it really tries to see the problem from both perspectives, either over cases where the replicating portfolio is above and cases where the replicating portfolio is below the payout function. So you see here that the idea.
00:06:13.782 - 00:06:16.986, Speaker A: Is to find a price for the.
00:06:17.010 - 00:07:09.864, Speaker C: Option that allows me to use a self financing hedging strategy that will bring my value at the maturity as close as possible to the payout function that I'm trying to cover. And what do I mean by as close as possible? In this context, I'll be using one would use the expected square difference between the value of the portfolio at maturity and the payout. Okay, when you solve this problem, you have two products from your computations. First, you'll have a hedging portfolio that allows you to get very close in terms of value to the payout. And second is the price of this portfolio, and you could interpret this price as being the option price. This was extended to a more risk averse setting in Bandy and Bertie mass. 2014, where they now use robust epsilon arbitrage.
00:07:09.864 - 00:08:09.290, Speaker C: So what does this mean, robust? It means that instead of looking at the average square difference, we really worry about the tail of the square difference. So how large can that be? And we want to shrink this as much as possible. So what is the advantage of excellent arbitrage models? The first one is computational tractability enabling with the robust epsilon arbitrage. You can solve this using dynamic programming, or there's tools you can use from the robust optimization literature to address the problem. The resulting price that you get is also converges to the reduces to the no arbitrage price. If the market is complete using that method, and you can think of it as if there exists a portfolio that can match the payout, well, then you can bring this error to zero and you'll recuperate the price in a complete market setting. If you don't have a complete market, you can interpret the minimal expected squared error as being a measurement of how.
00:08:09.322 - 00:08:10.814, Speaker A: Incomplete the market is.
00:08:11.474 - 00:08:18.346, Speaker C: And from this you get also a way of edging. We'll have a look at this in an example here, where I really have.
00:08:18.370 - 00:08:20.010, Speaker A: Just one point of time.
00:08:20.042 - 00:08:49.172, Speaker C: I can compose a portfolio at time zero, and I let the stock evolve until the maturity. And this is very simple setting, but we see things emerge in this incomplete market. The asset value here is assumed to be uniform over an interview, an interval at the end of the horizon. So obviously the market is incomplete. If you apply the epsilon arbitrage model in this setting, using the robust Epsilon arbitrage approach, which looks at the worst case error, you get different prices for.
00:08:49.188 - 00:08:51.564, Speaker A: The strike price depending on the strike price.
00:08:51.604 - 00:09:26.112, Speaker C: And you see that there's a region on the right hand side here where the strike price is at 120, and this orange line is actually going below the dotted line. The dotted line is the subhedging price. This is a price for which, if that option is traded at this price, the buyer has a way of composing a portfolio on this market that produces, with probability one, strictly more revenue than the cost that was incurred by acquiring the option. So this is considered to lead to an arbitrage, because someone could exploit this to make profit at no expense.
00:09:26.248 - 00:09:30.284, Speaker A: Okay, so what we'll be presenting left.
00:09:30.704 - 00:10:26.164, Speaker C: In the next section will be the equal risk price. And I give you already the, you know, I don't want you to be surprised later. I give you already all the results. The equal risk price will remain within the two boundaries of the sub hedging and the super hedging price. What really interests us is not only the fact that we can, it can give rise to arbitrage. It's also the fact that it might expose the writer in particular, but also the buyer to unnecessary risk, or a risk that is very different from one perspective compared to the other in particular. Here's the same example where we compare the worst case loss after the transaction at the Epsilon arbitrage price, and we see with the dotted orange curve, what is the worst case loss for the buyer, and with the dotted line curve, what is the worst case loss for the writer? From this, we really observe that the worst case loss is much worse for the writer than for the buyer.
00:10:26.164 - 00:10:30.164, Speaker C: And this is because somehow the expected.
00:10:30.544 - 00:10:34.724, Speaker A: Error squared error function, it doesn't distinguish.
00:10:35.064 - 00:10:56.234, Speaker C: Who'S manipulating this hedging portfolio. Of course, the writer doesn't really care for how bad the replication is if the replication is giving him more value than the payout he has to pay for. And it's the opposite for the writer. The buyer doesn't care if the replication gives him, gives the writer.
00:10:58.974 - 00:11:00.246, Speaker A: Less, more.
00:11:00.270 - 00:11:23.426, Speaker C: Payout than the option. So the fact that this function is symmetric and that somehow this approach only gives you one hedging strategy is problematic. So, in the rest of this talk, I'll be talking about two different things. So, first, talking about fair pricing. So we'll present this equal risk pricing framework. The work that we've contributed to in this field is to say, what happens.
00:11:23.450 - 00:11:26.002, Speaker A: When we use convex risk measures, and.
00:11:26.018 - 00:11:30.226, Speaker C: We'Ll be computing a price that expose both sides of the transaction to the.
00:11:30.250 - 00:11:31.494, Speaker A: Same amount of risk.
00:11:32.514 - 00:12:56.884, Speaker C: Then I'll give you some assumption that allows me to write dynamic programming equations for this simple european call option. And we will look at the quality of the price and the hedging that we obtain through the approach on a geometric brownian motion that is traded in discrete time, and where we're using, again, this notion of a worst case risk measure, meaning the worst case realization of the liability. In the second part of the talk, I will continue talking about equal risk price, but you can also listen to that talk. Thinking about portfolio management or option hedging, will be thinking about, how do we hedge a payout of an option? If you're managing a portfolio, you just don't have any options. You're just manipulating a portfolio in order to generate wealth. Well, how do we edge an option without having to make an assumption about the stochastic process? Can we use directly historical data and learn from the data, the statistics that are necessary to identify optimal policies for the investments? Okay, and in this context, we'll be extending a very simple and very popular deep reinforcement learning method to the risk averse setting where we're using dynamic expectile risk measures. And I'll give you some preliminary results on how this reinforcement learning method actually works on geometric brownian motion.
00:12:56.884 - 00:13:10.704, Speaker C: So, this is an overview of what's left for today. What's the plan for today? So, the two first section will be aligned with my first objective, and the last section will be about this deep reinforcement learning method.
00:13:11.404 - 00:13:13.020, Speaker A: So, if you're interested in looking at.
00:13:13.052 - 00:13:24.392, Speaker C: More details about this work, the first two sections, I encourage you to look to scan this QR code. It will also appear at the end of the talk, and you'll find a quantitative finance article that describes the everything.
00:13:24.448 - 00:13:25.684, Speaker A: That I'm talking about.
00:13:26.864 - 00:13:43.936, Speaker C: Okay, so let's start with trying to do equal risk pricing first with convex risk measure. So, what's a convex risk measure. I don't want to lose anyone in the audience. So, convex first, historically coherent risk measure were introduced. So this is introduced in 1999. And it tells you that if you're.
00:13:43.960 - 00:13:46.952, Speaker A: Measuring risk of a liability, well, you.
00:13:46.968 - 00:14:00.964, Speaker C: Want to map the liability, a random variable, to a scalar. And this mapping needs to have some nice property. If we don't satisfy these properties, the measurement could be misleading in terms of trying to hedge a risky situation.
00:14:01.624 - 00:14:02.976, Speaker A: So what are these properties?
00:14:03.040 - 00:14:29.134, Speaker C: And really the most important property for what's coming next in my derivation will be the translation invariance. So we can start with that one. That one says that if I have a liability, x and I inject money in this liability, the risk should be reduced by the same amount that I just injected. Okay. Other property which are really important, monotonicity. So if I have two liabilities and one is guaranteed to generate more losses with probability one, it should be riskier. And this is an important one, which.
00:14:29.174 - 00:14:31.994, Speaker A: Is not necessarily satisfied by mean variance approaches.
00:14:32.614 - 00:14:39.222, Speaker C: Sub additivity says that if I have a sum of two liabilities, the risk of the sum should be smaller than.
00:14:39.238 - 00:14:40.390, Speaker A: The sum of the risk.
00:14:40.582 - 00:15:05.140, Speaker C: And finally, positive homogeneity, saying if I scale the liability by lambda, it should be, the risk should be scaled, perhaps proportionally. Okay, normalized risk measure. The normalized risk here just is a special case, or is implied by positive homogeneity. If you replace positive homogeneity by sub additivity, you get, and sub additivity by convexity, you get a convex risk measure. And this was kind of somewhat surprising.
00:15:05.292 - 00:15:08.412, Speaker A: Where we discovered later that there was.
00:15:08.428 - 00:15:23.960, Speaker C: Maybe a more general class of risk measure that was also interesting. So what's convexity? It's the risk of diversification should, diversification should be encouraged, namely, if I do convex combination of two liability, the risk of the result should be smaller than.
00:15:23.992 - 00:15:26.368, Speaker A: The convex combination of the risks.
00:15:26.536 - 00:15:43.100, Speaker C: Okay? So to give examples, convex risk measure. If you've heard of entropic risk measures, this is a measure that falls in that category. If you've done expected utility with an exponential function, this is a convex risk measure. If you've done expected shortfall or c.
00:15:43.132 - 00:15:45.304, Speaker A: VAR, this is a coherent risk measure.
00:15:45.804 - 00:15:58.148, Speaker C: We'll be introducing another coherent risk measure later on, which is called the expectile measure. So I don't just as a heads up to make you interested about what's coming up. So before I can talk about equal.
00:15:58.196 - 00:16:01.124, Speaker A: Risk while we want, put the two.
00:16:01.164 - 00:16:09.866, Speaker C: Parties face to the same risk. So we'll talk about the minimal risk of each parties. If the transaction of the option happens. Well, there's money that goes from the.
00:16:09.890 - 00:16:12.530, Speaker A: Buyer to the rider, and the rider.
00:16:12.602 - 00:16:38.110, Speaker C: Is able to manipulate a hedging strategy, a hedging portfolio, in order to reduce as much as possible the risk of the liability that he's just committed to. So this is the first problem here. On the top, it says the minimal risk for the rider if the transaction is at a price, w zero, is the lowest risk he can achieve by trading in the market.
00:16:38.182 - 00:16:41.954, Speaker A: The asset, starting with a wealth of w zero.
00:16:42.494 - 00:16:46.230, Speaker C: At the end of the horizon, at maturity, he's left with a liability that.
00:16:46.262 - 00:16:48.646, Speaker A: Involves the payout of the option, from.
00:16:48.670 - 00:17:18.294, Speaker C: Which he can deduct how much money he made from the market or how much money he lost from the market. The situation is reversed for the buyer of the option, which starts with a loss. He just paid for this option, so he's losing w zero, but at the end of the horizon, at maturity, he's going to be winning the payout. So this is in terms of liabilities. So the liabilities is negative f and minus the reward, the returns he gets from his investment. Okay, so this gives rise to what I call here these varro w, varro.
00:17:18.334 - 00:17:21.630, Speaker A: B, which are the minimal risk at.
00:17:21.662 - 00:17:32.394, Speaker C: Price w zero for the writer and the buyer. What do we want to do with these two elements? Well, we can now define equal risk. What's the equal risk price? It's the price at which the two.
00:17:32.434 - 00:17:35.706, Speaker A: Parties, if they hedge in the market.
00:17:35.810 - 00:17:58.460, Speaker C: Appropriately, they are exposed to the same level of risk. In practice, we all know that probably the bank is hedging the payout of the option, maybe not the buyer. The buyer is buying this for other reasons. He has other risks that he's trying to cover with his option. But this price still makes sense because the buyer could be edging the option using the market.
00:17:58.532 - 00:18:01.364, Speaker A: So without knowing more about the buyer's.
00:18:01.404 - 00:18:32.870, Speaker C: Situation, this is all that we can discuss about. Like, if I give you this option, you might edge it. You are able to reduce the risk to this level. So why should I reduce my price further than this amount in terms of, from the writer's perspective? So this will be the price that we're talking about, this equal risk price. Okay, so how do we compute this equal risk price? Well, first of all, there's this notion of fair price interval. You might have been exposed to work of Bernard et al. 2013 that introduced concepts of fair price interval.
00:18:32.982 - 00:18:36.830, Speaker A: So this approach is described an interval.
00:18:36.862 - 00:18:45.206, Speaker C: That is within the super hedging and the sub edging price. It's saying, if I fix the writer's risk measure and I fix the buyer's.
00:18:45.230 - 00:18:48.934, Speaker A: Risk measure, well, then there are prices.
00:18:48.974 - 00:19:07.354, Speaker C: For which each of them, or if they edge properly, can bring the risk below zero. Okay, so the fair price interval for the writer will be the largest price at the lowest price, so that he has a way of, after accepting this transaction, edging his risk out of the problem.
00:19:07.934 - 00:19:10.094, Speaker A: The same thing for the buyer.
00:19:10.214 - 00:19:21.248, Speaker C: If he do a transaction at w zero b, he has a way of edging in the market so that at the end of the day, his risk is below zero, meaning that he might as well buy the, there's no loss.
00:19:21.296 - 00:19:25.776, Speaker A: In buying this option. Okay, by translation invariance, and I'm not.
00:19:25.840 - 00:19:39.084, Speaker C: Giving you the details of the proof for sake of time, you can actually demonstrate that the boundaries of this fair price intervals are actually directly related to the minimal risk at the transaction price of zero.
00:19:39.384 - 00:19:40.624, Speaker A: It's going to be the upper bound.
00:19:40.664 - 00:19:47.626, Speaker C: Would be the transaction, the minimal risk at zero for the writer, the lower bound will be the negative of the minimal risk at zero.
00:19:47.690 - 00:19:48.654, Speaker A: For the buyer.
00:19:49.794 - 00:19:53.730, Speaker C: The equal risk in this condition will exist if and only if this fair.
00:19:53.762 - 00:19:55.762, Speaker A: Price interval is bounded, and it will.
00:19:55.778 - 00:20:06.570, Speaker C: Be equal to exactly the middle of this interval. It's a very simple result that if you find the boundaries of this fair price interval, which only requires you to find the hedging strategy for an initial.
00:20:06.602 - 00:20:09.042, Speaker A: Transaction at price zero, you get the.
00:20:09.058 - 00:20:38.216, Speaker C: Two boundary and you get the equal risk price as the middle point. And this also, by extension, leads to a price that will be protected against arbitrage to lie in what's called the no arbitrage interval. So, going back to our illustration, before we see that the fair price interval for any strike level is this triangle, the blue triangle. We saw that we were worried about epsilon arbitrage that was going beyond this.
00:20:38.240 - 00:20:43.164, Speaker A: Fair price, this no arbitrage interval.
00:20:43.864 - 00:21:19.860, Speaker C: And we see that, well, yes, indeed. The equilibrium price, as I've drawn it, is exactly in the middle of the two boundaries. Okay, this is in a worst case risk measure setting. If I'm using a c VAR setting, well, then the region that is blue, the fair price interval region, will be within this triangle. But here we're looking really at the worst that could happen, which is if both parties are worried about worst case, then these things simplify and we can have a nice intuitive illustration. Okay, so how do we compute this? This is the main question. So the approach we will use will assume discrete time trading.
00:21:19.860 - 00:21:52.860, Speaker C: I'm really a discrete time person. I like formulating optimization model dynamic programs and working with these type of tools. So we'll assume we can trade k different time point between the transaction and the maturity, which gives us a feasible set for the self finance hedging strategy, which is denoted by x bar. Note here that in this x bar, the controls are at each point of time. How much asset am I putting in my portfolio? Then you start with the initial transaction.
00:21:52.892 - 00:21:56.580, Speaker A: Price, which is for the writer w.
00:21:56.652 - 00:22:06.454, Speaker C: Zero, and you add to it the revenues you're gaining from owning the asset for a certain amount of time and seeing the evolution of your wealth.
00:22:07.194 - 00:22:09.202, Speaker A: Okay, I'm getting on the way of.
00:22:09.218 - 00:22:56.644, Speaker C: Getting dynamic programming equation. But remember, I only assume here that these risk measures were convex risk measures in particular. To go forward with this work, I will need to make some assumptions that will allow me to write Bellman equations. And for this, I need to make the following assumption. First, that I'm dealing with a convex dynamic risk measure. So, in Rudzinski and Shapiro in 2006, they introduced the notion of conditional risk mapping. So, and this is really useful if you're trying to get measure that is dynamically consistent, meaning that at any point of time as you go along, you can motivate the optimal plan that you have for the future simply by applying the risk measure from that point on.
00:22:57.144 - 00:22:58.784, Speaker A: Okay, so we have a nested structure.
00:22:58.824 - 00:23:52.828, Speaker C: For the risk measure where we're nesting inside each other. Conditional risk mapping. Conditional risk mapping will take a random variable from a certain, will map back a random variable in terms of the condition that was imposed on the conditional risk measure. Okay, this conditional risk mapping will assume, satisfy the same properties as we were imposing on the original risk measure, namely convexity, monotonicity and translation invariance. If you're dealing with the coherent risk measure, also scale invariance. Okay, so what's another hypothesis we have to make? Well, it's possible that I have this nice nested formulation. For example, here I give you an example of c VAR, where I'm taking the c variable of the c VAR, given that the asset has now a value s one of the c VAR of assuming that.
00:23:52.828 - 00:24:30.738, Speaker C: Now given that s one and s two have been observed up to. Finally, this x variable, c VAR of x, given that I've seen almost the whole history of this acid value. So this is the nested structure. But this is not enough to have a dynamic program that has a low dimensional state space, because you might have arbitrary, like here. At this point, I would need to keep the whole history of the asset value process in my state space in order to compute things. So we make a second assumption that the conditional mappings are such that given.
00:24:30.786 - 00:24:33.122, Speaker A: The history up to time k, I.
00:24:33.138 - 00:25:24.580, Speaker C: Can measure the risk of x using a different risk measure. That only depends on the statistic of the history. Okay? And this statistic will be what will replace the whole history in my dynamic program, particularly at the bottom here, we have the typical markovian assumption on a, on a, on a process which allows us to discard the history if we have the right statistic on which we, for which we are markovian. So this being said, I laid the equations here. There's a lot to parse especially, but already maybe only half of it is interesting because the rest is we have two versions of this model. If I start with the writer's model, what do I have? I have at time k, I know everything about the pass or all the statistics that is relevant about the past. So I can simply evaluate the payout.
00:25:24.580 - 00:25:54.964, Speaker C: If I go backward one time step, I'll be measuring as a value function. I need the state in my equation, because I need to keep it in order to evaluate the payout at the end. But in order to predict the dynamics, I only need to keep the statistics and I can impose the risk measure that is conditional on the statistic measuring the risk of the return that are generated by my investment, negative of the return plus the risk to go starting.
00:25:55.004 - 00:25:56.344, Speaker A: From the next time point.
00:25:56.884 - 00:26:17.820, Speaker C: This is the nested structure that allows me to write this this way. The same is happening for the buyer, except that the buyer finishes with the negative payout since it is now a revenue and we are casting things in terms of liabilities. And once we have the solution of these dynamic programming equation, we can simply evaluate the value function at time zero for the initial state of the asset.
00:26:17.852 - 00:26:22.220, Speaker A: Value and the initial statistic, which will.
00:26:22.252 - 00:26:36.964, Speaker C: Identify the upper bound of our fair price interval. The lower bound is the negative of this amount, and if we take the midpoint well, we'll get our equilibrius price. So, solving for the equilibrium price involves solving two dynamic programming problems.
00:26:37.864 - 00:26:39.240, Speaker A: So, let's see this at work.
00:26:39.312 - 00:26:57.614, Speaker C: In terms of a problem, we'll be using a geometric brownian motion in a moment. But before I get there, I'm really from a robust optimization point of view, at this point, I'm looking at the future stock asset value process as being simply a vector. And this vector has to lie in some uncertainty set.
00:26:59.074 - 00:27:00.690, Speaker A: So my risk measure here, I interpret.
00:27:00.722 - 00:27:11.974, Speaker C: It as being a worst case risk measure. It's looking at the support of our distribution, and I'm looking at the worst case realization of my liability for any realization on the support.
00:27:12.954 - 00:27:15.162, Speaker A: Okay, the buyer and the writer could.
00:27:15.178 - 00:27:24.994, Speaker C: Use different uncertainty set. We'll be choosing the same uncertainty set for both. And this gives rise to robust dynamic programming problem that we can solve by.
00:27:25.034 - 00:27:26.614, Speaker A: Discretizing the state space.
00:27:28.714 - 00:27:58.304, Speaker C: So the application here is really the first type of test you would want to do with this type of technique. Namely, I'm dealing with an asset that evolves according to a geometric bond in motion. The drift is 0.07, the volatility 1.13. And I'm looking at a one year maturity. I'll give between 100 and we'll say 225 periods at which we can trade. Meaning that although it's a geometric drawn in motion, the market is incomplete because I cannot edge continuously.
00:27:58.304 - 00:28:29.624, Speaker C: Both writer and buyer is using the same uncertainty set. And the uncertainty set, I usually present the details because it's important to design the uncertainty set the right way. There's a lot of technical aspect there. I pushed this to the paper. If you want to have a look, we can also talk about it later. But just think of it as there's an uncertainty set with a certain parameter that I can scale, which is gamma, and I'm scaling this parameter so that it covers in this experiment, 95% of all the trajectories that the asset can take. Yes.
00:28:29.624 - 00:29:00.184, Speaker C: So what is your risk measure going? Is this. Yes. So, so the question is where the risk measure went. I see this as the risk measure here. Yeah. The fact that what, you could write this as a soup somehow, where you're looking at the support of some, some distribution. But what I care about this distribution is not all the density, but just.
00:29:00.224 - 00:29:01.264, Speaker A: Where does it land?
00:29:01.424 - 00:29:37.068, Speaker C: And there's a bit of a stretch here, because here I'm saying it's the s soup, but then I'll be calibrating my uncertainty set based on a confidence level. So there's a. A leap of faith there that needs to happen in order to interpret what's going on. So if we could, we would do full support, but perhaps full support, you know, distribution can be, have infinite support. So then we need to take something more reasonable. And we can always play with this confidence level to represent how risk averse each parties are. So do they just want to cover 50% of the trajectories, or maybe 99.9%
00:29:37.068 - 00:30:08.754, Speaker C: of the trajectories? So this is what we produce with this approach. The important roles of this table is the equal risk price and the black schole price. So black schole price would be the right price if we were trading in continuous time. Here, we're using it just as a reference, and somehow, as we're discretizing more and more, we should converge to the actual price, should become the right price. Okay, so what we see is that our equal risk price in this setting is always higher than the black schole price.
00:30:09.374 - 00:30:11.510, Speaker A: So this indicates that the hedging strategy.
00:30:11.542 - 00:30:24.354, Speaker C: From the black scholar price somehow exposes the writer to more risk. And our equal risk price is saying, well, you should increase this price, actually, if you want the risk to be well distributed between the two parties.
00:30:25.774 - 00:30:27.202, Speaker A: So this is for a call option.
00:30:27.278 - 00:30:28.898, Speaker C: Or different other type of options.
00:30:28.946 - 00:30:31.610, Speaker A: You might have the opposite effect. Okay.
00:30:31.722 - 00:30:50.746, Speaker C: But you can find out by. By computing the equal risk price. What we saw, which was very encouraging here, is that the two. The fair price interval, which is really just based on this 95% coverage property of an uncertainty set, there is. It still seems that it's converging to the blackshield price. So it's getting closer to the black hole price.
00:30:50.810 - 00:30:51.170, Speaker A: Of course.
00:30:51.202 - 00:31:10.744, Speaker C: Like, we cannot go for larger amounts of 225 than 225. There's more work to be done to make this scalable to perhaps 10,000 trading points. So this is maybe left to verify and validate, but this is very encouraging that we seem to be narrowing down and getting closer in terms of boundaries.
00:31:11.164 - 00:31:11.572, Speaker A: So.
00:31:11.628 - 00:31:19.484, Speaker C: Yeah, and I didn't give too much details, though. Itm. I don't know if it's an acronym you all recognize. So there's an in the money option and add the money option and an.
00:31:19.524 - 00:31:26.296, Speaker A: Out of the money option. Okay, so what else can we say?
00:31:26.360 - 00:32:10.118, Speaker C: Especially, like, what does it mean? What do we gain by being equal risk? By having a price that leads to equal risk? I'll start with the graph on the right. So on the graph on the right, we're giving for different percentile level, the percentile value difference of the. Of the liability obtained by the equal risk price or the black scholar price. So by difference, I mean that we have two parties, the rider and the buyer. And if I run these hedging policy hedging strategy, they'll be exposed to different risk. And I can different liability overall, and I can measure the quantile and compare the two quantiles, the 99% quantile for the rider, the 99% quantile for the buyer.
00:32:10.206 - 00:32:11.822, Speaker A: And I show the difference here.
00:32:11.998 - 00:32:14.424, Speaker C: So when we have low quantiles, black.
00:32:14.464 - 00:32:17.784, Speaker A: Scholar equal risk price seems to be inadequate.
00:32:17.824 - 00:32:37.840, Speaker C: So why is it inadequate? Well, I used this worst case analysis, which was really focusing on equal risk in the large quantiles, not equal risk in the low quantile. As we increase the quantile rank, we see that the differences between the same quantile for both parties become smaller as I increase. And for the black scholar price, it's.
00:32:37.872 - 00:32:39.484, Speaker A: Actually the opposite that appearance.
00:32:40.084 - 00:33:09.350, Speaker C: So given that I'm using a 95% confidence region, it is the high quantile level that are really worrying me. And we see that we do get an edge there. We're able to rebalance the risk for those quantile levels. On the left hand side, we see something about the average percentile value. So if you're just interested in on average, are the two parties exposed to more or less risk? We see that again the same type of behavior, that actual price is much better when the quantile is low, but.
00:33:09.382 - 00:33:13.870, Speaker A: It'S becoming outperformed by the equal risk.
00:33:13.902 - 00:33:25.990, Speaker C: Price for high quantile level. Now, this graph would be also interesting if we looked at other type of risk measure than the worst case risk measure. But already here we see signs that when we care about the worst case losses, then the equal risk pricing is.
00:33:26.022 - 00:33:30.194, Speaker A: Able to balance things more appropriately.
00:33:31.834 - 00:33:34.066, Speaker C: Okay, so the last part of the.
00:33:34.090 - 00:33:38.322, Speaker A: Talk is based on, I'm going back.
00:33:38.338 - 00:34:13.496, Speaker C: To this idea of towards data driven pricing, or data driven hedging. And as we've seen, the option pricing problem for equal risk price was required us to solve two risk averse hedging problems. So we'll do this here using reinforcement learning. So before I introduce the methods, I'll go back and introduce a notation of a markup decision process. And this is especially important because we're not just going to take an off the box, off the shelf algorithm and plug it in. There are no algorithm really, that works for risk averse mdps right now if.
00:34:13.520 - 00:34:15.168, Speaker A: You'Re using dynamic risk measures.
00:34:15.336 - 00:34:53.944, Speaker C: So this is really active research and the methods are being developed, deployed, evaluated. So there's a lot to do in this field. So let's look at the finite horizon MDP. We have a set of state, a set of action, a reward function that depends on state action and the transition that was obtained, and then an operator p that models the dynamics of the system. Okay, our objective is to find a policy that maps the state and the time to an action. And if we just run this policy, we'll obtain a random sum of cumulative reward. This is captured by our tilde here of PI.
00:34:53.944 - 00:35:03.844, Speaker C: So our risk averse MDP will try to find the policy that minimizes the risk of the accumulated reward. So we apply a risk measure on this minus rto.
00:35:04.344 - 00:35:04.776, Speaker A: Okay.
00:35:04.800 - 00:35:19.456, Speaker C: And what we saw before is that the type of risk measure we would like to work with are dynamic risk measures. Right. How is this related to equal risk pricing? Well, we can actually massage our equal risk pricing problem so that it actually.
00:35:19.520 - 00:35:22.084, Speaker A: Fits into the risk average MVP settings.
00:35:22.544 - 00:35:42.512, Speaker C: Namely, remember, we had to solve two hedging strategy problems for the one for the rider, one for the buyer. This will give rise to two risk averse mdps. Each MDP have to do with a state space that keeps track of the asset value and the state of the Markov chain. If I know that the underlying process is Markov, then I would like to.
00:35:42.528 - 00:35:46.136, Speaker A: Keep track of this state and an.
00:35:46.160 - 00:36:06.356, Speaker C: Action that is here model as being how much do I invest in every stock? So just an interval minus one for every asset. Finally, the reward will be for any time t smaller than t, we obtain the return from our investment, and at time capital t, we have to, sorry for the notation here.
00:36:06.380 - 00:36:09.972, Speaker A: This should be s capital t. We.
00:36:09.988 - 00:36:15.044, Speaker C: Obtain the payout of our option if we are the buyer. If we're the writer, well, one minus.
00:36:15.084 - 00:36:21.120, Speaker A: Two will give you the negative payout, or the opposite. The payout will be a liability.
00:36:21.192 - 00:36:35.912, Speaker C: So for the writer it's going to be what's going on? It's all in reward. So now we're casting things in terms of rewards. So the liability becomes negative for the, for the writer and is a positive amount for the buyer because he's getting this payout in his pocket and reward.
00:36:35.968 - 00:36:38.000, Speaker A: Is that okay?
00:36:38.032 - 00:37:34.326, Speaker C: So we have two different risk averse mdps. We know that we want to use dynamic risk measures, and here I won't want to use worst case risk measure. I want to do something more, maybe more easier to understand or easier to adopt than always worrying about worst case scenarios. So I'll be using a special type of risk measure. But what should I use as a dynamic risk measure? Our choice will be specifically aligned with whether there exists or we can think of an algorithm for implementing it. The initial work in risk averse MDP, they somehow, they wanted to tackle too many large class of ProB, too large, too much large class problem as possible. So they looked at general dynamic risk measures that are coherent, and they said, oh look, these dynamic risk measures, we can cast them as robust MDP because we know that there's a worst case expected value representation for conditional risks.
00:37:34.326 - 00:38:13.766, Speaker C: And if we have a robust MDP, then perhaps we can exploit this structure of robust NDP. This first work needed a simulator that would resimulate conditional on a state be able to resimulate the trend, the transition, and even resimulating in a reweighted way might be doing important sampling or something. This was improved by Juan et al. In 2021, where they designed a policy gradient for on policy. Learning on policy means that you will learn as you are acting. And then, since you're learning as you're acting, you don't control really which state you reach, and you have to learn from the state transitions that you're obtaining, you cannot simulate.
00:38:13.910 - 00:38:15.262, Speaker A: The problem there is that there was.
00:38:15.318 - 00:38:56.646, Speaker C: Five different neural networks in this approach. There's a network that controls your policy. What are you, how much do you invest? There's a network that tries to estimate what's the value of what's about to happen, the cost to go. And there's three other networks that are there somehow to model the robust aspects. So there are adversarial networks that are trying to find what are the best reweighting of the reward that will model this dynamic risk measure. So, a very complicated approach in 2000, I think it was in 21 or beginning of 22, we found a very simple modification to deep deterministic policy gradient to handle a very specific class of.
00:38:56.670 - 00:39:01.314, Speaker A: Risk, dynamic expectile risk measures.
00:39:01.664 - 00:39:16.960, Speaker C: This is important because this algorithm has more than 10,000 citations right now. It's a well established algorithm. People have designed improvements on it, and it's being deployed for important problems in reinforcement learning. It addresses the risk neutral setting. How can we make it risk averse?
00:39:16.992 - 00:39:18.644, Speaker A: You'll see it's one line of code.
00:39:20.424 - 00:39:56.054, Speaker C: Finally, and I'm very happy to be presenting this here, I hope this can create new synergies with the research that's being done in the statistics department here. There's this work, local work called chital involving Sebastian, that proposed, extended somehow what we did. But for a general class of dynamic risk measures, what they exploit is the fact that some risk measures are conditionally elicitable. Maybe we can have a discussion about this afterwards. We'll see how somehow it requires to go beyond what we did requires more machinery.
00:39:57.634 - 00:40:00.650, Speaker A: So why use expectal risk measure?
00:40:00.682 - 00:40:23.180, Speaker C: Well, let's backtrack. And remember that expectal risk measure were somehow invented in order to solve the problem of elastability. The same paper that defined elastability of risk measure came up with, hey, look, expectile risk measures are solving this problem. It's the only measure that, that has this property. So what is elicitability? Well, it says that risk measure is elicitable if it is the minimizer of.
00:40:23.212 - 00:40:25.224, Speaker A: An empirical risk problem.
00:40:25.844 - 00:40:33.884, Speaker C: Okay, so here my random variable is x, and I want to find the q that is closest to x. But somehow, with respect to a loss.
00:40:33.924 - 00:40:37.348, Speaker A: Function, okay, if you have a squared.
00:40:37.516 - 00:40:41.636, Speaker C: Loss function, just a square, you recuperate the expected value.
00:40:41.700 - 00:40:44.904, Speaker A: We all know this, or at least you learned today.
00:40:45.624 - 00:41:09.844, Speaker C: Otherwise, you can also use a piecewise linear function and you get the quantile of x. Okay. And the quantile level is parameterized by tau. So why is this important? Well, it's actually part of an instability property to say that if I get data, I'm able to, from the data, identify whether my expectal estimate was right or not, and if it's wrong, I can steer it in the right direction.
00:41:10.184 - 00:41:15.456, Speaker A: Okay, so if I have a bunch of historical data, xi yi later on.
00:41:15.480 - 00:41:30.704, Speaker C: What will this be? This will be, xi will be the state. It will also include the action. But let's just think about the state and y. I would be the realized risk to go, a sample from the risk to go. What do I want to do? I want to measure the conditional risk.
00:41:30.744 - 00:41:33.016, Speaker A: Of y given x, but I don't.
00:41:33.040 - 00:41:45.880, Speaker C: Know what's the conditional distribution? Well, these elicitable risk measures are saying that the, that this risk can be estimated using an estimator. So think about this maybe as a.
00:41:45.912 - 00:41:49.696, Speaker A: Linear function of your state x, and.
00:41:49.720 - 00:41:54.912, Speaker C: You get the right estimator if you minimize, if you train this estimator using.
00:41:54.968 - 00:41:56.244, Speaker A: The write loss function.
00:41:56.744 - 00:42:27.564, Speaker C: So if you use an affine function here of x, and the theta is the parameters of your affine function, and you use the loss function for expected value, while the estimator you get is measuring the expected, the conditional expectation. If you're using the quantile loss function, you're doing quantile regression. We want this because we want to learn from the data what is the risk to go. So we need to estimate it using as a function of the state. Okay. So going forward, we want to, if you want to use a coherent risk.
00:42:27.604 - 00:42:29.700, Speaker A: Measure such as c VAR, well, c.
00:42:29.732 - 00:42:48.370, Speaker C: VAR is not directly elicitable. You'll need to use an expectile risk measure. The expectile risk measure has a special loss function which is piecewise quadratic. If tau is equal to 0.5, you get back your expected value. If tau goes to one, you get the worst case.
00:42:48.482 - 00:42:51.934, Speaker A: So tau allows you to control the risk aversion.
00:42:52.234 - 00:42:53.610, Speaker C: And I see that I maybe have.
00:42:53.642 - 00:42:59.040, Speaker A: Five more minutes or we started late. Yeah.
00:42:59.152 - 00:43:10.204, Speaker C: So I'll try to, maybe I'll be skipped a few slides so we can write. We can then extend this expectile risk measure to the dynamic setting well, we're going to nest them.
00:43:12.664 - 00:43:13.624, Speaker A: At any level.
00:43:13.704 - 00:43:23.044, Speaker C: I would condition on the history of the MDP. And I can measure the conditional risk of a random variable here, vt plus one, which is the risk to go.
00:43:23.364 - 00:43:26.224, Speaker A: Given that I've done this trajectory up to this point.
00:43:28.684 - 00:44:10.230, Speaker C: So this is how we define the expectile, and we can obtain very similar dynamic programming expression as we have obtained before, but in terms of a markup decision process. Remember last time we were looking at the reward was the return I get from my investment, and then v PI was the risk of pursuing my hedging strategy forward. By using interchangeability property, we can actually also derive a q function, which is an operator that allows you to estimate the risk to go. If you start in state st, you apply action at, and from that point on, you apply the best hedging strategy.
00:44:10.262 - 00:44:11.394, Speaker A: That you can think of.
00:44:12.934 - 00:44:16.188, Speaker C: So this can be modeled recursively in.
00:44:16.196 - 00:44:19.024, Speaker A: Terms of the next q star, t plus one function.
00:44:20.924 - 00:44:42.364, Speaker C: Okay, so here's the algorithm. So in its risk neutral setting. So remember, tau equals 0.5. There's already a paper, 2015, it's been applied extensively. It does two things. On one side, it has, you see over here, a neural network parameterized by Theta Q. That depends on the state and the action.
00:44:42.364 - 00:45:01.744, Speaker C: This is what's called the critique. So this one is in charge of estimating what's the risk to go if I start in s and I apply a, and then I do the best I can. The other neural network serves as the policy. The policy here is my edging strategy. It depends on the state, and it's going to be parameterized using ETA PI.
00:45:02.204 - 00:45:03.764, Speaker A: Okay, so there's two things to update.
00:45:03.804 - 00:45:22.464, Speaker C: In this, in this DDPG algorithm. How do I change, how do I improve my critique network, which is trying to give me the best estimate of the risk to go? And how do I improve my policy, which will look at the critique and say, well, for this critique, I should improve by doing this type of action in this type of situation.
00:45:22.964 - 00:45:24.468, Speaker A: So what they do here is they.
00:45:24.556 - 00:46:02.610, Speaker C: I mean, the critique step is pretty, it's just following gradient descent along the policy network. It's not so sophisticated. And what will be really pay attention to is this, is this step for updating the critique network. This was the policy network. So the critique network. And really what you're doing there is, you're taking a step in the direction of the derivative of l, which respect to your current critique, minus what you observed in terms of risk to go sample and then multiply by the gradient of the critique with respect to its parameter. When you have the last function being the quadratic function, this here is the.
00:46:02.642 - 00:46:08.164, Speaker A: TD error and reduced to very simple. I mean, this is the DDPG algorithm.
00:46:09.064 - 00:46:17.152, Speaker C: When we are using dynamic expectile risk measure, we simply have to pull out the square difference from the, from the.
00:46:17.168 - 00:46:21.324, Speaker A: Algorithm and put in our piecewise quadratic equation.
00:46:21.824 - 00:46:53.900, Speaker C: So the gradient, the derivative here will be slightly different. It will adapt to the level of risk aversion that we have, again remembering that it's tau that controls this risk aversion. So let's look at how this plays out in practice. We're again in a very simple setting using geometric brownian motion. Initially, this setting is there to tell us, well, you know this setting, I know how to solve the problem. I can discretize my dynamic program so I can get these orange curves that are the true values at optimality if.
00:46:53.932 - 00:46:57.744, Speaker A: I was able to solve this perfectly.
00:46:58.064 - 00:47:42.044, Speaker C: So in this context, we have two sides here, the writer and the buyer, and we have the risk that is being exposed to when you follow the policy obtained from the reinforcement learning agent, and you see that these curves are very close. It seems like for the buyer here, our network was slightly inaccurate and loses a little bit in terms of risk exposure. For the buyer, we also compared to some work that does that that was concurrent with ours. And I mean, this is really active field of using reinforcement learning for hedging. And the type of work that for which there's the most algorithms in reinforcement learning are situation where you've got a static risk measure. So instead of having this nested structure, you impose maybe a C VAR over.
00:47:42.084 - 00:47:44.012, Speaker A: The whole random variable.
00:47:44.188 - 00:48:03.326, Speaker C: You don't have dynamic programming equation, but you might still get policy gradient method to work. So we see here that we get an exposure to risk in terms of static expectile and at maturity twelve. The two methods pretty much expose to the same level of risk. But the issue with static risk measures.
00:48:03.350 - 00:48:05.750, Speaker A: Is that they're not dynamically consistent, meaning.
00:48:05.782 - 00:48:22.576, Speaker C: That if you find yourself six months later implementing the static risk measure policy, you'll be exposed to more risk than if you were trading the option on that day and finding a new edging strategy for the option. So you see that the dynamic risk measure is able to get better risk.
00:48:22.640 - 00:48:25.376, Speaker A: As time goes along and gives an.
00:48:25.440 - 00:48:37.264, Speaker C: Incentive to deviate from the policy that was actually proposed by a static risk measure. This also tells us that once I solve the problem for dynamic risk measure, I have a policy that works for.
00:48:37.304 - 00:48:39.736, Speaker A: Any maturity, because I could think, okay.
00:48:39.760 - 00:49:00.312, Speaker C: What if I have six month maturity instead of twelve, I'm still in the same state. So I can run this, I can compute this price, and I can compute the hedging portfolio. This also works for the strike price, because usually you also include in the state space the amount of accumulated well. So if your strike price is different, you can adjust the state accordingly and.
00:49:00.328 - 00:49:01.684, Speaker A: Get the policy for that.
00:49:03.584 - 00:49:41.094, Speaker C: So finally, this is the only thing, the approach situation in which we looked at more complicated models, we were working with a correlated geometric brownian motion. It was calibrated using five different stocks. And again we were comparing the same two methods, dynamic risk measure and static risk measure. In this context, it's much more hard to identify whether these reinforcement learning approach have converged to the best they can produce. But given the state of what we could deploy here, we see that the two methods somehow perform more similarly in larger scale problems.
00:49:41.674 - 00:49:43.954, Speaker A: But still, I think these are very.
00:49:43.994 - 00:50:20.600, Speaker C: Interesting methods to try to deploy and experiment with in a context where we don't want to make assumptions about the underlying asset process. So this leads me to my conclusion. So the main takeaway message is twofold. So first, I want you to remember that when you have an incomplete market, it is possible to price in a way that both parties are exposed to the same risk. The technology is emerging, there are mathematical construct for doing that. What we showed was that for convex risk measure, it was not much more difficult than to edge the option itself. We just have to find the edging policy for the two parties.
00:50:20.600 - 00:50:29.684, Speaker C: And we showed that it corrects for some inequalities that are obtained when you use a risk neutral measure or if you use an epsilon arbitrage model.
00:50:30.024 - 00:50:35.412, Speaker A: The second message is that I'm hoping that in five years, about five years.
00:50:35.428 - 00:51:15.044, Speaker C: We'Ll be able to do option edging and portfolio management directly from the data using reinforcement learning. And if we want to be risk averse, which we should be. These methods are in development and I think there's still a lot of work, but there are already some methods that are worth experimenting in different contexts. And anyone that wants to collaborate on this would be more than welcome to contact, get in contact with me in our. Well, the last point here I described already for dynamic risk measures. When you train these methods, it can take a long time, but once they're trained, you can apply them for a different maturity level, different strike price. So they're very versatile in terms of application.
00:51:15.044 - 00:51:25.174, Speaker C: So thank you very much for your attention and I'm happy to answer any questions. Again, the QR codes for the two papers are there. Thank you.

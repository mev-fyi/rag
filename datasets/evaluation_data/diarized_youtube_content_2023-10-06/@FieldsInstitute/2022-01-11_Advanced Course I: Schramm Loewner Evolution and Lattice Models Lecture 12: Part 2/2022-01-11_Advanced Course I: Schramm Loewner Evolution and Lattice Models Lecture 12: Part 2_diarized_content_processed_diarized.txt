00:00:01.280 - 00:01:33.114, Speaker A: Okay, so let us continue our discussion. And we are discussing axiomatic approach to these results. So the idea is to essentially create an approach where instead of proving all these difficult technical estimates for each particular model, you just say, okay, model is good, there is a good absorbable, and then you can do everything. Okay, so let me do setup carefully for this. So we start as usual, we simply connect the domain, and omega would be interior approximation by Jordan domains. So what do I mean by interior approximation? Let me again remind you that it means that not only your omega in a subset of omega, but for every point on the boundary of omega n, you can find the point on the boundary of omega, which is one over n close. So it could mean that this is our domain, and this would be a good interior approximation.
00:01:33.114 - 00:02:22.194, Speaker A: So nothing is close to the points here. But it's okay. Every point here is close to the boundary. So it's an approximation, cross header sense. And of course, the real examples that we have in mind is lightest approximation. So we just select the lightest and select the closest, lightest domain of scale 101, which approximates our domain omega. It would satisfy this, because again, each boundary vertex of this approximation would have an edge which goes outside, and the length of the edge is about one away.
00:02:22.194 - 00:03:40.112, Speaker A: Okay, now another thing that we would fix, of course, there would be two points, prime ends on the boundary, and we'll fix a conformal map which maps omega e b configuration to h zero infinity. So, as usual, to define ljovnar parameterization, all the stuff we need to fix conformal map. And then we will always select the sequence of a and b and the boundary of omega such that the crossed or resistance between them would converge to zero. And well, in general, we would ask this to happen polynomially fast. So let me actually write it down. So we simply select the closest point in crescendo distance to a and b. That would be, again, from interior approximation conditions, that would be about rate of convergence would be about one over n.
00:03:40.112 - 00:04:35.194, Speaker A: But again, we wanted a slightly more general theorem. So we wanted this to just converge polynomial fast. And then another thing that we would select, again, everything is up to constant, so we have up to multiplication by constant. So we have to be careful here. We select sequence finds conformal maps of omega a and b n to h zero infinity such that phi n of n converged to phi of a. Fine of bn, converts to phi of b and phi n in general converts to phi uniformial compounds. Again, because we have this car Seder approximation, such a sequence can be found but again, it will depend on phi.
00:04:35.194 - 00:05:23.340, Speaker A: And this is a lack of canonicity which we would like to preserve. Okay, and then let's continue our setup. Gamma n is a random curve in normal gn from n to b n. Gamma is a random curve from from a to b. Now, we consider corresponding curve, two corresponding curves from zero to infinity, both of them. So even on the level gamma n, remember that gamma n, phi n maps n to zero, b n to infinity. So gamma n bar would be a curve in h from zero to infinity.
00:05:23.340 - 00:06:14.380, Speaker A: And the same with gamma bar. So this would be just a curve from zero to infinity in the upper half plane. And we would AssUMe that these curves. So that's one part of the assumption that these curves gamma, N and gamma, and of course, gamma and bar and gamma, we assume that they are surely l curves. So again, usually in the models that we consider, it would be trivial to observe because the curves that we consider are usually simple. Or in the case of dense phases of fk model, well, they will be self touching curve. So usually not a problem to see here.
00:06:14.380 - 00:06:51.654, Speaker A: And gamma would usually be Sla. So agAin, LEONARD curve. So this is not much restriction, but to state Ethereum, we have to assume this. So there almost surely leopard curves. Now, let this curve be driven by this function w and t. And this curve would be driven by this function wt. So these are driving functions of gamma n and gamma and gtn.
00:06:51.654 - 00:07:27.546, Speaker A: ANd gt would be correspondingly of nur chains. So in particular, you know, the tip is mapped by gnt to wnt. The tip is mapped by gt to wt. So gt of gamma bar of t of gt of phi, of gamma of t would be wt, so exactly as before. And I noticed that I changed the notations from lambda to w. Sorry. For some reason with larissa, we use notation w.
00:07:27.546 - 00:08:30.062, Speaker A: And when I worked many years ago on this proof of convergence without polynomial convergence, we used lambda. Sorry, I kept these notations. Anyways, now let's look at the following domains. So, omega t. This is omega minus the beginning of the curve in l parameterization up to time t. This is the same as pre image of the curve in the upper half plane of the wall, corresponding curve, and the same with omega t. But here I have to be very careful because, well, they are not simple curve.
00:08:30.062 - 00:09:28.922, Speaker A: So here it's unbounded component, right? Because I not saying that they cannot be self touching. And here, this is component of the complement. This here bn here b at the boundary. But again, this may be too much of technicality, so you might think about them as just simple curves. And then this is indeed just complement. Now we would want absorbers. And notice that sometimes we need to introduce auxiliary points.
00:09:28.922 - 00:10:29.672, Speaker A: For example, in card absorbal, which we discussed, we needed two boundary points which had nothing to do with original curve. So we simply needed to introduce these two boundary points and look at the crossing probability. So the observable dependent on these two boundary points. In general, this actually, this crossing probability would not be a good absorbable for us. I will tell you what we'll need to modify. We want an observable which would depend on a few points, some points on the boundary, some points inside, but we definitely want at least one point inside. Okay, so for this we fix two numbers, m and l, and let's discuss this multiverticks.
00:10:29.672 - 00:11:56.136, Speaker A: So, multi vertex or multipoint, it's a collection of points, m points inside the domain and l points on the boundary of the domain. So multi point at which we would define the observable would be this collection of this interior l boundary points and this vmylofen, again with a set of all such collections. So if you think about lightest approximations, we actually don't really look at all points. We only look at vertices where these are the vertices of the lattice which are strictly inside them, and this is the vertices which are on the boundary. Okay, and now we define the image of this point under phi and under phi n. Well, it's clear what it is, because everything is extendable up to the boundary. Remember that in this direction you can actually extend things to the boundary and from domain to the half plane.
00:11:56.136 - 00:12:55.904, Speaker A: And so this is, I wrote that this belong to hm plus l. Well, because we took phi of them. Right. On the other hand, if you take vn phi n, all the boundary points in R. Okay, so phi hat of this collection of points is just, you know, just a point in the collection of points in the upper half plane. Here is the collection of points in the upper half plane, but with the conditions that the last point should be. And this is a remark I already made, that it's all well defined at the boundary points because everything is extendable up to the boundary.
00:12:55.904 - 00:14:00.364, Speaker A: Okay, so now let's continue with our setup. Gamma n of omega Ub be a family of random curves indexed by simply connected omega, a and b. So for every omega, a and b prime ends, you are supposed to produce to me this random curve. So imagine curves where these are curves actually in omega from a n to b n. And let me be careful here. The indices are at the top so again, this sounds like a very abstract setup, but just always think about percolation. For example, you have domain, you can see the lights approximation, you can see the exploration process.
00:14:00.364 - 00:14:47.894, Speaker A: That's your curve from end to bn. And now I want to assume that it satisfies the main mark of property. All the interfaces of the lattice models we consider, they do satisfy this. So the main Markov property is the following. Suppose that I know that my curve up to time t is something. Then the remainder of the curve is the same as the curve in the following domain. You remove the beginning and use just running curve from gamma n of t to b.
00:14:47.894 - 00:15:58.910, Speaker A: Well, so that's, that's the domain mark of property. Now assume that there exists some m l and some stopping time, which depends on multivertex continuously. So I don't want them to abruptly drop. And also there is some s and not again, this is a ciamatic approach, so there will be lots of, you know, technical conditions. But let me try to explain what they really mean. First of all, we have discrete, almost martingale. Absolutely.
00:15:58.910 - 00:17:21.764, Speaker A: So if you look at two times which are less than the stocking time at this multivertex, then conditional expectation of this observable on what happened in the beginning up to time t is the same as this observable at time t. So exactly what we observe for critical percolation and say paraphernionic fermionic absorbers, they all satisfy this condition. But we don't even assume that this is equal to this. We simply say, okay, let them be close to each other, less or equal than n to the minus s. So it's almost martingale absorption. So suppose that you found something like this. Now, I also want limiting absorbable.
00:17:21.764 - 00:18:09.914, Speaker A: And so here, let me explain what's going on. I want to define conformity invariant observable on all domains. But I don't need to define it on all domains. Instead, I need to define it only in the upper half plane. So, since it's a multivariable observable, it would be defined on this atm cross rl and let it be real value. Also consider complex value observable. And let us assume that this satisfies this horrible looking differential equation.
00:18:09.914 - 00:19:32.446, Speaker A: And you would say, okay, so probably this is a very limited theory. It only holds for very narrow class of h of observables. And by the way, here is the only place where we see kappa, because the result would be that something converges to sl kappa. And how here I'm saying, okay, this limiting absorbable should satisfy this horrible differential equation. But it has to do it, because if I want the result which says okay, it converts something is convergent to slicappa, and I have this observable which satisfies this martingale property. Precisely, then it's really easy calculation using that h should satisfy this condition, well, if I want it to be smooth. And here, well, let me not, this was horrible enough.
00:19:32.446 - 00:20:37.780, Speaker A: So let me not write what h is not degenerative condition for h, but it requires that at least one of the points in my observable, so that m is at least one, that one of the points for which I compute my observable in this multi vertexes, at least that it's at side at least one. Okay, so we have discrete observable, which is almost martingale. We have continuous thing which is martingale for sla kappa, how they relate it. And so that's the part which still needs to be proven. Of course, this is very model specific part that they're polynomially close to each other. Well, again, lots of technicalities here that this should not be true for all vertices, it should be true only for certain multi vertexes. So for example, we don't want to deal with boundary effects.
00:20:37.780 - 00:21:35.564, Speaker A: So actually it's enough to consider the situations when all the interior points are far away from the boundary, well, far away. This is called mesoscopic distance. So microscopic is one over n. Macroscopic is just epsilon does depend on n here, depends on n, but decays much slowly than one o n. So this is called mesoscopic. And condition number four, that this family satisfies camp and Smirnov condition. Okay, so after all these technicalities and preparations, what really happens? We have almost martingale absorbable, which is close to continuous absorbable and continuous absorbable waste, a good continuous observance.
00:21:35.564 - 00:22:48.002, Speaker A: So it satisfies this equation. So if you know, for example, that by some previous result that our family of curves converges to slicappa and we have conditions one and three, then condition two will be satisfied automatically, provided of course, that h is most enough, little h. Again, as I explained, this is exactly the condition which guarantees that it's Mersenne absorbable for isolic kappa. So we don't need to specifically check it for every absorption. Okay, the condition for that we have case condition. Okay, and now let me state the main theorem. Suppose that you have family, of course, which satisfies these conditions one to four from some copper less than eight.
00:22:48.002 - 00:24:07.554, Speaker A: So again, we have discrete, almost martingale absorbable, which is close to continuous martingale observable foist oligopoly close, and our family of curves satisfies case condition. Then everything is great. Then the existing coupling of this curve gamma n in omega ab. So this, remember, we had in every domain curve random curve. So we can couple all of them, put them in the same probability space with brownian motion, such that for this SlE kappa in the upper half plane. So you look at this gamma escal kappa in the upper half plane, probability that the supreme, before some stopping time of this gamma n of t minus gamma of t in the upper half plane is bigger than n to the minus u, is less than n to the minus u. So for sum u, there exists some u such that value depends on l.
00:24:07.554 - 00:24:46.254, Speaker A: So this is called procurement distance. So indeed, you can couple them. You can. So this is even stronger than the convergence. So you can put them at the same probability space such that these two curves are close with huge probability. So the probabilities are far away is, and phi is still very small, is less than n to the minus here. Okay, so notice the limitation of this.
00:24:46.254 - 00:25:47.004, Speaker A: I'm only talking about polynomial close in ideal plane, in the model plane, in the half plane. So the curves, the images of the curves are close polynomially close to each other. Unfortunately, to translate it to polynomially close in the domain, we need some extra condition. And this condition is called alpha Helder condition. So again, the problem is that conformal map can really perturb the distances dramatically. So, two curves which were closed in the half plane, suddenly, when you can formally map them, things deteriorate. So alpha here means that we have bound on the derivative that the derivative of the map to omega, he wrote it from D, but can do it from H.
00:25:47.004 - 00:26:40.324, Speaker A: So, but if it's a map from d, then the derivative is, doesn't grow too far, which means that essentially psi has held their extension up to the boundary. Then if omega omega, so omega usually would be alpha hundreds. The lightest domains, the difficulties here. But if you have this, then it's actually, you can see that in the domain, you also have this. So this is sle kappa. In the domain omega from a to b would be close to the curve gamma n polynomial equals. Notice that if you don't care about polynomial rate of convergence, this already implies convergence is a domain, of course.
00:26:40.324 - 00:27:44.084, Speaker A: Okay, so what this theorem tells us that all you need to do now to establish convergence, and not only convergence, polynomial convergence of a lysis interface to Sla kappa is just to do the find one good observable, which converges polynomially fast to its continuous counterpart. And that's all. Well, of course, your curve should satisfy case condition, but everything satisfies case condition, as we discussed. Well, disclaimer, since this is recorded, not everything satisfies case condition, of course. And there are even reasonable models which do not satisfy companies burn off condition. But for the models which I still invoke, well, most of them do, such as. Well.
00:27:44.084 - 00:29:15.634, Speaker A: So before discussing the proof of it, let me just mention an application which I promised to you, a critical percolation hexagonal lattice. And notice that our observable that we had crossing probability, it did not satisfy our not degeneracy condition, simply because it didn't have any, any point inside the domain. So the absorb will depend on two points which were on the boundary. Okay, now we fear we don't only have absorbable, now we have Cardi Smirnov absorbent. So remember, this is, you look at the probability that your point z is separated from bc, you look at the probability that is separated from ac and from ab. And then you take the sum of these probabilities with corresponding taus, with corresponding coefficients, where the coefficients are just roots of unit. And as you know by Smirnov's theorem, this converges to a map of the domain to the triangle.
00:29:15.634 - 00:30:08.172, Speaker A: So this absorbable, now remember, a and b are fixed. So this absorbable, now depends on one point on side d and one point on the boundary circle. And this is a very good observable. So what is the limiting observable? Well, this is exactly this map, h of z and ABc. But again, if you go from a to c, this is just from a to b, this is just h of c. But we can also write it as a four variable observable. So you have z, you have a, b and c on the boundary, and the map is just the map to the triangle, not really real value, it's absorbable.
00:30:08.172 - 00:31:06.446, Speaker A: But you can take real part if you're pedantic. Okay, so again, you can fix a and b to b, your beginning and end, or you can simply consider this as a four variable observable. Okay, so you have four variable observable, you have this thing which converges to this. And again, notice in what sense it converges. So you extend h the observable to your domain by the conformal map. So you take domain, take it in the upper half plane, apply continuous observable, and they should be close polynomial. So we know that this converts to this.
00:31:06.446 - 00:31:37.254, Speaker A: This is actually Smirnov theorem in this case. And, but we need polynomial conversion. Condition four is that case. Condition is satisfied. Condition one and condition two. Again, condition one just means that this is, this satisfies martingale property. And it does.
00:31:37.254 - 00:32:31.774, Speaker A: So we'll talk about it in a moment. But why do we have this condition three? Discrete disclosed to continuous and luckily, well, not so likely. This is exactly what we aim into proof. Eventually there was result about this. This is my joint work with Lincoln chains and Helen Lee. And what is it? This says that if you have a domain and abc are prime ends, and you look at some interior approximation by one over n hexagonal lattice, again for critical percolation. Since we only know convergence for hexagonal light, some variations of it, that's the setup we have to have.
00:32:31.774 - 00:34:15.084, Speaker A: And so, let gamma n be the interface from n to cn on the lattice. And t is the first time that we hit some delta neighborhood. So we go now from a to c and we stop when we hit this delta neighborhood. Then the theorem says that there exists some s which is domain dependent and not which depends only on the domain, such that when you consider the corresponding crossing probability and ht of z, where what ht of z is ht of z would be the map of this exciting domain, omega minus the beginning of the curve to the triangle, which maps of course the steep to one, b to tau, c to tau squared. So where our theorem says that this discrete observable cardism absorbable is polynomial close to ht, and this ht is exactly h of phi t. So h of phi at time t. So this is this closeness.
00:34:15.084 - 00:35:06.600, Speaker A: So this gives us condition three again. So this ht is the composition of map to the upper half plane, and then h v j defined here. Now, condition two, remember this horrible differential equation. So, the one thing we need to check here, and this is unfortunately direct computation, but very easy one, is that this is not degenerate. That's trivial for this particular observable. But of course, nobody would want to compute this to check this pd that we wrote for H. But again, we don't need to do it here.
00:35:06.600 - 00:35:55.408, Speaker A: We know that h n capital h n converges to little h, and we know that Hn is Martingale observable. So the limiting thing is also martingale observable. Aha. For what we already know that interface converge to slowed it last hour. So what do we have? We have that this h, little h, automatically satisfies the pD. And finally, condition one. Well, that's what we need, this martingale property.
00:35:55.408 - 00:36:25.954, Speaker A: But it's proven exactly the same as what we did for crossing probability. Just cik. So the separating path can either touch this exploration or not touched. Let's see what happens in each case. And again, this is. So this is also true. So this is emerging absorbable.
00:36:25.954 - 00:37:05.894, Speaker A: And by our theorem we are done interface. So sorry. Exploration process for critical percolation. Hexagonal lattice converges polynomially fast to SL. Again immediately converts polynomial fast in the image and in the upper half plane and in the domain and converge as well. We know that this theorem only for health domains. It, by the way might happen that it's true in general.
00:37:05.894 - 00:38:04.978, Speaker A: Essentially, one of the things we saw in the proof of the fact that SLV kappa in arbitrary domain as a curve for couples. And exactly the setup here is the fact that Leo revolution doesn't really. Well, SL at least doesn't really like the places where conformal map is not a holder. So so far we were unable to make a proof out of it. But again, I'm just saying that it's possible that the theorem about closeness in the images is true. In general setting at least, I don't see no counterexample. And I suspect that more careful analysis would provide proof.
00:38:04.978 - 00:38:50.654, Speaker A: But anyway, this is just wild speculations. Let us first see whales. Does this framework work? And one of the places where it works actually, while influenced a lot of our work. Well, what we do is very similar to what they did for very particular case of loop raised random work. And this is framework, which is due to. Well, not framework, this result, which is due to Venice, Viklund and Kostro. So they proved polynomial convergence for loop raised random walk, even with this, even with some explicit constants.
00:38:50.654 - 00:39:47.354, Speaker A: So let me remind you what loop raised random walker is. Basically, we run a random walk, and here, while I draw a hexagonal lattice, but they are proximal. So you run your random walk. The moment you hit the thing, which you already visited, you erase the whole loop, and you keep going till you hit the boundary. And now you parameterize it as a radial lumar evolution from this random endpoint to the w naught. And this is a result, as I mentioned, of lower charm and Vernon, that this converges to sla two. But Bernard comes run and fecund proved that it actually converges polynomial fast.
00:39:47.354 - 00:40:33.494, Speaker A: What is observable here? So let us fix this naught and w naught. And the observable would be the following. You look at the random walk, so forget about operation, you just look at the probability that random walk started at z exits omega zero. But you normalize it. You normalize that probability. That random walk started at w naught, exits at e naught. The reason why we need to normalize, of course, imagine that when the light has become smaller and smaller, more boundary points, so both of these probabilities tends to zero, but their ratio doesn't tends to zero.
00:40:33.494 - 00:41:11.386, Speaker A: It actually tends to Poisson kernel. So this is Poisson kernel. Of course, in the upper half plane, this would tend to Poisson kernel, corresponding Poisson kernel in the domain. So this is actually, they will like, they have one variable, absorbable, u not and double, you not affixed. And the absorbable is simply Poisson kernel. And the limiting curve is Sla two. And again, so the result even provides some explicit constant rate of convergence.
00:41:11.386 - 00:42:28.154, Speaker A: Not optimal, of course, but at least it's explicit. Our result is, well, again, it's so nothing is explicit here. Now, let's remember, FKA easing model. So I don't want to spend time on reminding what it is, but for this FKA easing model, as I mentioned, fermionic absorbable. And if you look at the domain, then your observable is simply square root of the derivative of the map from your omega ab to the strip where you map, well, this is minus infinity. So you map a to one end of the strip, b to the other end of the strip, and you take the derivative, and the limiting curve is oscillating. Okay, so this is what is true for fking.
00:42:28.154 - 00:43:30.760, Speaker A: I wanted to talk a little bit about another model, which is called harmonic explorer. So this is another way to create an exploration process. So you define your model using this exploration process, and that's called harmonic explorer. It's an artificially created model, meaning that it was not created by physicists. It was created by Schramm and Scheifeld to study gaussian free field. Well, I hope to at least touch a little bit on gaussian free field later today, but we'll see how fast I'm going. So what is harmonic explorer? Again, we try to draw an interface between blue and yellow hexagons.
00:43:30.760 - 00:44:18.664, Speaker A: And like in harmonic explorer, what we do, we just start exploring. And when we saw the difference would be what happens when you hit an unexplored hexagon. Remember, in exploration process, in percolation, all we do, we just flip a coin. It seems to be the easiest thing to do and the hardest thing to analyze because it creates the most chaos. Here, what you do instead is the following. You look at this point and to call it, you start a random walk from this point until it hits a boundary. So you start random walk on faces until you hit a boundary.
00:44:18.664 - 00:45:09.424, Speaker A: And you color your point, your hexagon rather in the color which was hit. So you start random walk here, it hits here, you color blue, it hits here, you color yellow. Okay, so now you call it, and then if the path encounters yellow, you continue this. If the person counts yellow face down, right is the path encounters blue phase, turn left. So exactly like what we did for percolation, but with the twist that this is not a percolation at all. This is totally different thing, because instead of coin flip, you start an independent random walk and look where it hits the boundary. And this process is actually very easy to analyze.
00:45:09.424 - 00:46:15.544, Speaker A: So this, if it were. No, if this process was known to physicists, this would be the first process for which we would prove the convergence to SLA, because the observable is very simple. So you look at the point, this is the probability that your path will go to the left of the point. This is the same as the probability that random walk from this point would hit a blue face, right? So think about it. You eventually, if you are to the, if your path is to the left of the point, you always hit the blue face. So it says you are to the right. The probability that you hit the blue face is zero to the left, zero to the right, it's fine.
00:46:15.544 - 00:47:23.624, Speaker A: And then it's really easy to see that this probability would not change with every step. You either hit this or hit this, or maybe you hit this point, but this point is blue or yellow, depending of what your random work would do further, after this time. So you hit this point, what would it do afterwards? Okay, so continuous counterpart of this, this is harmonic measure of the arc ab. So in the upper half plane, the map, the curve, the map is rather, well, it's continuous is harmonic measure. And harmonic measure in the upper half plane is one, one over PI principal value of the argument. So this is the probability that you. So, well, sorry, this is harmonic measure of what? Harmonic measure of the right of the positive real line.
00:47:23.624 - 00:48:11.384, Speaker A: Okay, so now this is a discrete harmonic measure. This is a continuous harmonic measure. And there is extensive literature about why they converge, how fast they converge. This was studied a long time ago, how discrete harmonic measures converge to continuous harmonic measures. And so these absorbables do easily converge to each other. That's something that allowed Schum and Scheffel to prove that the limiting curve is SLA four. Indeed.
00:48:11.384 - 00:49:15.134, Speaker A: And again, in terms of convergence to the absorbable, I would say that this is the easiest model, it was essentially created so that the absorbable was known to be to converge to well to continuous counterpart. So again, this is the easiest model to analyze. And of course it satisfies ks property. And so as I mentioned, polynomial rate of convergence of discrete harmonic measure to continuous one is a very classical result. Notice that this is also one variable absorb our variable. It's just a point inside the domain. Kay said this.
00:49:15.134 - 00:50:22.594, Speaker A: Okay, this is all trivial and all this, unfortunately, we needed to strengthen this result. And let me I noticed that I not mentioning my name, not that I forgot it. So, polynomial rate of convergence for harmonic Explorer, that's actually our result with D. Mitchell Kak, whose picture will insert and find version. And again, because we need better results on this convergence of discrete harmonic measure to the continuous one than the ones which were available. And then we can prove it, not just with hexagonal lattice, we can prove it essentially for any good lattice. Let me not discuss what good lattice is.
00:50:22.594 - 00:50:42.894, Speaker A: Okay, so in the next hour I will outline the proof of the framework, and then I will probably have time to mention list gaussian free field, which is very much related to all this and leads to new exciting directions. But let me take a ten minute break for now.

00:00:00.200 - 00:02:12.154, Speaker A: We're trying to figure out how to recombine the, or how to use the doctor plan that we create in order to minimize the algebraic complexity of finding a realization of a geometric constraint system. And we have primarily talked about distance constraint systems. And we gave a combinatorial description of how to optimize the algebraic complexity for a class of parameterizations that we described. Rational parameterizations that allow us to put together at every point in the node in the doctor plan, the solutions of the subsystems, the child subsystems, which are rigid, which correspond to rigid, rigid subsystems, and have zero dimensional solution set how to put them together to create, to solve another system at the parent, and thereby find the solutions to the parent system. So the understanding is that you sort of pick one solution of each subsystem and substitute it into the system corresponding to the parent and solve it. So we went through that process and we defined this idea of an overlap graph, which is a weighted object that's based on, you know, how the child substance systems are put together to create the parent system. And we, after creating the overlap graph, we found a covering set that gave a sort of a minimal spanning tree according to those weights, where the weights represent the number of variables in the final system that we would be solving.
00:02:12.154 - 00:03:02.184, Speaker A: And then also optimize after. Once the spanning tree, the best covering set that gives the optimal spanning tree, is found, then we find the root, decide where to place the root of the spanning tree, which also decides the degree of the system. So that way we minimize the number of variables and the degree of the system that's solved at the given node of the doctor plan, given the solutions for the children. And we gave some examples, three or four examples of systems, platforms, kind of systems that were solved. Stuart platform type of systems. And, you know, using this method. And here's an example of the different solutions we got for one of these platforms.
00:03:02.184 - 00:04:13.684, Speaker A: Okay, so then it was pointed out that there's another issue that comes up when you're trying to solve these systems according in the way that we describe, which involves having some incidence constraints in the final system. So, going back, for example, to the example that we talked about here, you know, if we took the covering set consisting of c one, c two, c three and c four, in this particular case, there are no incidences that are just eventually, you parameterize this system as using its rotation about this axis, and this one using its rotation about this axis, and this one about its rotation about this axis. And so those are your variables. And then eventually all you have is the distance constraints. So there are no incidence constraints involved here. But if you remember the original way that we had unoptimized ways, and it could well be that the optimized way also has that feature. The unoptimized way was to have c one, c two, c three as the covering set.
00:04:13.684 - 00:05:14.392, Speaker A: And then in that case, you would parameterize c three as a quaternion three dimensional three Dof rotation about the point b. And then you would parameterize c two by a three dimensional rotation around the point a after choosing c one as the home cluster. And then you would have one incidence constraint here with c, and then saying that c in this system is the same as c in that one in the solution of this system is the same as the c here. So that would be three equations here, and then you would have the three distance equations in a similar fashion. You could well imagine a situation where the incidence constraint is not just at a point, but in fact at a pair of points. So we will look at a pair of points that are in two different clusters, that are shared by two different clusters. So the example here is one of those.
00:05:14.392 - 00:06:13.372, Speaker A: So this is talking about the three clusters, c one, c two, c three, which share essentially pairs of points. So if you try to use the method that we had, the overlap graph and the covering set and so forth, you would pick c one and c two, let's say, and say that, okay, so we can parameter, and say c one is a home cluster, and then you can param, I mean home subsystem. So again, the picture, just to take a step back, the overall picture is the same. C is the entire thing, and c one, c two, c three are the children we're trying to place having solutions for c one, c two, c three. We're trying to find a solution to the clusters, the overall system c. And here, if we choose c one as the home cluster, you could potentially parameterize c two by rotation about this point. So that's okay.
00:06:13.372 - 00:07:00.386, Speaker A: But then you have these two incidences. So c three, for example, would be then incident upon c two. You could also parameterize c three by rotation across this. But then you have the incidence on this edge between c three and c two. So what we're looking at now is for a moment, let's forget about this overlap graph thing, and we'll put that together. There was another separate paper that put together this overlap graph base optimization here, which has underlying it the matriarch that corresponds to the spanning tree. So that's the usual graphic metroid with this other metroid that comes up in resolving these incidences.
00:07:00.386 - 00:08:06.814, Speaker A: So for the moment, let's just assume that we're looking at the entire system of incidences here between c one, c two, c three. So c one and c two are incidents on this edge, v two, v four, c one, c two are incident on this edge, v four, v three, and so forth. The question is how many of these incidences are independent? So I have to be careful to tell you why this type of independence is actually interesting. So, numerically speaking, when you have the solutions to c one and the solution to c two, and you have a placement of the vertex v three and v four in c one, and you also have a placement of the vertex v three and v four in c two. And let's say this edge actually existed in the graph. You would expect, if these are proper solutions, that the distance between v three and v four in c one and the distance between v three and v four in c two would be exactly the same. But that's never the case because you're doing this numerically.
00:08:06.814 - 00:08:54.024, Speaker A: So you end up with the distance, even though it was asserted as a constraint in c one and this distance was asserted as a constraint in c two. The placement of v three and v four and c one is usually slightly different from the placement of v three and v four and c two. And you would realize that, in fact, if you're going to constrain these two with the same distance between them, you would have maybe three equations saying that the position of v three in c one. By the way, this is three dimensional. Everything that we have seen recently is three dimensional. This continues to be three dimensions. So the position of v three and c one, just three three coordinates, equate them to the position of v three and c two.
00:08:54.024 - 00:10:15.478, Speaker A: But then, because this distance is the same between them, in fact, you can equate with independently only two of the coordinates of v four in c one with the two of the coordinates of v four in c two. So just by looking at the single constraint, you would say, okay, I can only equate two of them and then do the same thing here. And if you think about it, once you have equated these, then after that you only have one that you can equate between these two and one here. And so this is basically showing different ways in which you could try to resolve this, this type of dependence by not, by using an independent system of constraints, I mean, independent system of incidence constraints of this type. But, you know, there are many ways you could try to do it, and all of the ways are somehow local in the sense that I've shown here. I mean, that are local in the sense that I look at each constraint separately. But in fact, these constraints, these incidence constraints form a sort of a global system where dependence could sort of be transmitted across the clusters.
00:10:15.478 - 00:10:31.754, Speaker A: So that's sort of the classical situation where you might expect that there is some type of metroid there. So this is another example. These are all in that, I mean, I put the references somewhere on these slides. You should be able to find them.
00:10:32.614 - 00:10:33.942, Speaker B: Can I ask a question?
00:10:34.078 - 00:10:34.822, Speaker A: Yeah.
00:10:34.998 - 00:10:42.214, Speaker B: Could we go back to that slide that you just had with the four? This one?
00:10:42.254 - 00:10:42.710, Speaker A: Yes.
00:10:42.822 - 00:11:03.166, Speaker B: Thanks. So we're talking about the, the number of independent equations here. But how do you, in what order does one solve them? Right, because we solve the, I was under the impression that we solved each of the child systems first.
00:11:03.350 - 00:11:04.958, Speaker A: Yeah, those are already solved. Yeah.
00:11:05.006 - 00:11:06.622, Speaker B: Then we patch them together.
00:11:06.798 - 00:11:17.248, Speaker A: Exactly. And the question is how do you, I mean, what is the system of incidences you use to patch them together?
00:11:17.416 - 00:11:20.960, Speaker B: I see. So it's really just figuring out rotations and translations.
00:11:21.072 - 00:11:21.544, Speaker A: Exactly.
00:11:21.584 - 00:11:34.336, Speaker B: In order to make the patching. And those rotations and translations have dependence constraints upon them. Okay, now I understand.
00:11:34.440 - 00:11:49.700, Speaker A: Perfect. Yeah. So you know, the rotations and translations are just like what we defined here. I mean these, these, these type of things. Yeah. So I mean in the, so yeah, I've simplified it even further compared to this for the moment. Yeah.
00:11:49.700 - 00:12:06.064, Speaker A: So I mean here, I'm just saying, let's say that c one is, and there's some rotation of c two and rotation and translation of c two and rotation of translation of c three that I need to figure out that satisfies these constraints. Yeah.
00:12:07.174 - 00:12:20.154, Speaker B: Is there an advantage to solving, to patching the constraints in one order rather than another? Does it make sense?
00:12:21.054 - 00:12:25.114, Speaker A: Yes, that's what this previous section was about.
00:12:26.374 - 00:12:28.622, Speaker B: That's that ordering of the overlap.
00:12:28.678 - 00:12:38.062, Speaker A: Exactly right. That overlap graph and the covering spanning tree. And the ordering, partial ordering is given by where you put the root of that spanning tree.
00:12:38.118 - 00:12:39.558, Speaker B: Okay, now I'm following. Okay, good.
00:12:39.606 - 00:13:25.584, Speaker A: Okay, but now for the moment, I'm asking you to forget what I just said because forget the, just immediate previous lecture and just think about these separate, just as in, as though I'm doing it the dumb way without doing that. Okay, so all I'm doing is picking c one as home cluster and figuring out the translations and rotations of c two and translation of rotation of c three and have, have this big one big system to try to solve it. Yeah. And then later we can, we will put the two, there is an underlying matriarch here. There was an underlying metroid that gave you the spanning tree in the previous approach. And then I will try to put those two together. Yeah.
00:13:25.584 - 00:14:20.060, Speaker A: So at least indicate it. I don't know if I'll have time today to go through that. Okay, so here's another example, you know, of various different ways you can do this. The slides are available. You can go have. So this one actually shows a bad one and that these two are good, good choices, independent choices. Okay, so now I just want to recall that what we're looking at is, you know, you're starting out with something that someone promises is an independent, is an independent system, right? So what they gave you was a system of distance constraints that was independent, and then you formed the doctor plan, as we showed in the previous slides, if it is not independent, if it was actually dependent, finding an optimal doctor plan is actually np hard.
00:14:20.060 - 00:15:41.640, Speaker A: But given that it's independent, you actually have a way to find the optimal doctor plan, which means optimal recursive decomposition into maximal rigid subgraphs in polynomial time. So that's the assumption that we still go with, is that the overall system is independent. And therefore we have this complete canonical doctor plan and all of those things that we defined, you know, with that same properties, that every parent is split up into the complete set of its maximal rigid subsystems. And if they are, any pairwise intersection between them is non trivial, then it's sufficient to pick exactly two of them. And if otherwise, all of them are there, if their pairwise intersection is trivial. And we showed that this was a well defined, you can always divide into only one of these two cases, and that the union of the children was the parent. And all this, so all the previous lectures that we, all the previous stuff that we did, we're going to use this property of this canonical doctor plan here as well, and the fact that we're starting out with an independent system.
00:15:41.640 - 00:16:56.996, Speaker A: So given that we have something independent and we have this canonical doctor plan, we can make certain assumptions about degrees of freedom just through counting, right? So counting works because we know it's independent and we know we have these properties. So we can define something called the adjusted degree of freedom, just simply a kind of inclusion exclusion count of the number, you know, the degrees of freedom that you would expect this system, this recombination system to have. So if you have the standard decomposition, which is just what we called canonical decomposition of a constraint in this manner, so into its maximal subgraphs maximal rigid subgraphs. Then the expression for the adjusted DoF uses this inclusion exclusion, which is simple. It says that for every subset you take the subset of the set of children. So C is the parent you can think of. So basically t is a subset of its children.
00:16:56.996 - 00:17:51.484, Speaker A: So when you're looking at every possible subset of that and you're simply taking this degrees of freedom of the intersection minus the degree of freedom of the shared part. Right. So, and then this sort of, you know, becomes, you can simplify it by simply taking six times the number of actual clusters or subsystems or children, if you will, plus five times the number of shared parts between them and three times the number, sorry, shared edges and shared vertices and other portions here. So, sv. I should have gone back to the paper. The paper is. Where is the paper? I should have.
00:17:51.484 - 00:18:50.334, Speaker A: Okay, when I make that, when I send you put the slides, I'll ensure that all the things are defined. I thought they were all different, but apparently not. Okay, so let me quickly go to the paper. Okay, so this is not it. Go back. Ah, shoot. Okay, here, I think this month.
00:18:50.334 - 00:19:59.734, Speaker A: Yeah, there we go. Okay, this should be it. Now this should work. Yeah, I was trying to avoid scrolling through this thing, but I think I forgot to pull out some of the definitions. So that is no good. Okay, I'm in the middle of her. Where is the definition of this defined as above? Okay, here, this was the original one.
00:19:59.734 - 00:20:44.294, Speaker A: Okay, I'm sorry about this. Okay, so here is the definition. Okay, good. So here it is. I have to change. Okay, stop. Share.
00:20:44.294 - 00:20:59.974, Speaker A: And there we go. So here's the definitions that I forgot to bring there. So can you see the screen?
00:21:03.514 - 00:21:04.522, Speaker B: Yeah, it's fine.
00:21:04.658 - 00:21:41.208, Speaker A: Okay. Yes, I'll make it a little bit bigger. Okay, so we have the c, which is the recombination, the system particular node of the doctor plan that you're looking at. And D is a standard collection, which is just because it's a standard decomposition, just a canonical decomposition. So you have rigid subsystems and you can, without loss, assume there are a whole bunch of them, so not just two. So without loss you can assume that their intersection is non trivial. Is trivial, because if they were non trivial, it's really easy.
00:21:41.208 - 00:22:43.894, Speaker A: They share more than in three d, three vertices. And putting them together once you have the solutions of each of them is trivial. So VD and Ed are the sets of objects of C that are shared by more than one child. So you basically have a collection of subsets of the set of objects vertices, where CI contains all the vertices in VD that belong to one cluster. And for each v you have each vertex and each edge, the set sv and segment are those, that are those clusters that contain the vertex or that particular edge. So in other words, if there's a common shared vertex or edge, then there's a bunch of vertices, a bunch of clusters that contain that vertex or that edge. And that's the set sv and se.
00:22:43.894 - 00:23:31.704, Speaker A: The pair cd is the canonical decomposition. So this is simply just defining what we already know, just seen a few times, we can assume that the intersections are trivial. And because if it's non trivial, we don't. It's extremely easy, the recombination system. And then for every triple of points we know that the intersection of the set of clusters that share each one of those points is at most one. Also that follows from the fact that we, that the whole thing is independent. And we also know for every pair, the set of clusters that share that pair is less than or equal to one.
00:23:31.704 - 00:24:41.274, Speaker A: So the intersection between the set of clusters that share one of those edges and the other edge is one. All of these just simply follows from the fact that their common intersection is less than or equal to two. It's a trivial, the standard decomposition case that we're looking at, or canonical decomposition case that we're looking at is you have a cluster c and the pairwise intersections of all of their children are all trivial. Okay, so those are the notations. And from that we can define the number of degrees of freedom, because everything is independent and we know that it's a canonical decomposition. We can define this adjusted degrees of freedom, which is given the cluster c D of its children, and t is any subset of it. You can look at every subset of it of size greater than or equal to one, and you can take the degrees of freedom of the intersection minus the degrees of freedom of.
00:24:41.274 - 00:25:48.414, Speaker A: So, okay, x is, x is defined here. Xt is the set of non shared external constraints relating the objects in these clusters. So for example, we had those additional degrees of, I mean, additional distance constraints or additional incidence constraints which are not shared, which involve objects that are not shared between any pair of clusters. Those are those x t's. So if you subtract those degrees of freedom that are assert that are removed by those constraints, then you basically have this, okay, so none of this is true if you didn't start out with something that was independent. And so that's a big assumption. And we know that it is a big assumption because we know, for example, that finding an optimal doctor plan in the case of dependent systems, we had an example right in the beginning, is np hard, whereas we have a polynomial time algorithm of finding an optimal doctor plan.
00:25:48.414 - 00:26:56.968, Speaker A: Essentially we proved that the canonical doctor plan is optimal and finding the canonical doctor plan is polynomial time. And as a result of which we have a polynomial time algorithm, if the original was original system was independent. So now I want to stop sharing this and go back to the other screen. So this one, okay, so now we know the definitions of all of these things and we can take that original definition of the adjusted degree of freedom, which is just a simple inclusion exclusion, and massage it into this form. It's a little bit easier. So instead of having this thing, which was the original definition, we can actually get a simpler definition, I mean, easier to compute because you don't have all the possible subsets and so on and so forth. This would be like an exponentially sized thing if you did the summations.
00:26:56.968 - 00:27:51.174, Speaker A: But this makes it much simpler. It just sums over the edges in the common that are common, that are shared, the vertices that are shared, the constraints that are between pairs that are not shared, and all of these degrees of freedom. So is this for three dimensions and this is for two dimensions. It's not hard to see that the first, that the first, sorry, the first expression here simply becomes these expressions. So this, odd. So there's this other residual dof or whatever that is of use, which I will simply put here. So you have, you know, given a subset of children, I mean, given the set of all children and any given subset of it.
00:27:51.174 - 00:28:18.744, Speaker A: Sv, remember, is the set of all clusters in d that share a particular vertex. And this is the set of all edges in d that share a particular vertex. And then this particular quantity is defined. This rdof, and this is ed, is the common shared edges. In the 2d case, they don't exist. The trivial intersections are of size one. So you only have this.
00:28:18.744 - 00:29:41.920, Speaker A: Okay, so these are numbers, I mean sort of quantities to keep in mind. So, and another notation to keep in mind before we talk about this metroid, is this triple b cicjl what this is saying is that v in the shared point at which the incidence is asserted, CI and cj are the sharing clusters in d and l less than or equal to l less than three denotes the particular coordinate x, y or z of the point v, which is equated by that incidence constraint. So an incidence constraint is represented by this, the vertex at which the incident is being, incidence is being asserted, v in the set s, v and CI and cj. So in other words, the shared vertex and CI and cj are the particular sharing clusters that I'm referring to. And l is the particular coordinate of that vertex, coordinates of that vertex that are being asserted as being equal. So in the case of 2d systems, you know, l is going to be less than or equal to two. Okay? Now, so we define this well formed set of incidences in three ways.
00:29:41.920 - 00:30:26.480, Speaker A: So first of all, there is no local cycle of incidences. And so in other words, you don't have the situation that for a given single vertex, remember this vertex. Notice that all of these vertices are the same vertex and they're all being shared by this whole bunch of clusters. And we are asserting an equal equality at that vertex between the first two clusters, the second, the second one and the third, and so on and so forth. And then you don't have like the k being IK being equal to I one. Because if you do that, you have a cycle of incidences which numerically will give you problems. Okay? So you don't want that.
00:30:26.480 - 00:31:20.054, Speaker A: So it's a, there is no local cycle. So that's, then we're saying that for any subset of clusters, let IDT denote those incidences, these incidences for which CI and CJ are in this subset t. So for any t, we want to make sure that the number of incidences that we assert is going to be less than or equal to this difference. This what we call the residual dof of DT. So this is a kind of a Maxwell condition. So it's saying that this number of incidences that we assert has to be smaller than or equal to this number that you, that would correspond to an independent set of incidences. And then the total number of incidences should be actually equal to the total number of residual Dof that you expect in an independent system.
00:31:20.054 - 00:32:17.504, Speaker A: Okay, so these are the definitions. This is how we define a well farmed system of incidences. And once you have this, you won't have any of the numerical issues that we talked about. So this is motivated, this definition is motivated by the practical difficulty of solving the system of incidences if you have numerical issues. Now what we show is that having defined it this way, that we now have a, this notion of well formedness turns out to be independence of something in a certain metroid. Okay, so what is that metroid? So we're going to define for a standard decomposition, an undirected graph. So let, here's your standard decomposition set of clusters, the total set of vertices, total set of edges.
00:32:17.504 - 00:33:05.460, Speaker A: And we're defining this, uh, graph where the set of vertices are all the vertices. The set of edges are going to be pe, union, le and I. That just means that you're taking every vertex in the shed in all of them and you're simply taking all pairs that belong in B. So we call these the point seam edges and these were, these are called the line seam edges. So it describes it here. Okay, so essentially what we have is that the set of vertices, sorry, the edges are of two types. The first is called the point seam edges that connect every pair of vertices uv in the set, forming a complete graph.
00:33:05.460 - 00:34:10.931, Speaker A: So in other words, what you have is that if you have a particular vertex appearing in multiple clusters, you're just making, going to make a complete graph that takes all the different copies of them. Notice that here you're simply taking a simple union of all the copies of the vertices that are present. So in other words, if a single vertex is present in more than one cluster, you'll simply have that many copies of it. So this is saying that between the copies of the same vertex I'm putting a complete graph, right? So those are called the points images and then the line seam edges are essentially, if you have a particular edge that belongs in two clusters, then you make two copies of that edge. So how many ever clusters it belongs to, in how many ever elements of d it belongs to, you make that many copies. And so it consists of se copies. Se, remember, is the set of all clusters that share a given vertex edge.
00:34:10.931 - 00:34:37.356, Speaker A: E copies of every edge. And for each edge and each cluster that shares, we create a copy of. Yeah, so we create a copy of that edge. So you copy, you have a copy of all the common vertices, one copy each for each of the clusters and one copy each of the edges, shared edges for each of the clusters that contains it. So that's essentially what we call the scene graph. It should be clear. And here's an example.
00:34:37.356 - 00:35:21.930, Speaker A: Here was our original. So if you have this system, so the original system that we had here, this one here, so you have v three, v four, so this guy shared by three clusters. So it'll have three copies, and with a clock with a click, which is just a triangle here, this guy is shared by two. So it'll have two copies, this will have two copies, this will have two copies, and the two copies here will be connected by an edge because that's the click and here click, click. Plus you'll have, this guy will have two copies of this edge, two copies of this edge and two copies of this edge. And that's exactly what we have drawn here. So essentially you've got the click in the middle because this vertex is shared by three, this is shared by two, shared by two, shared by two.
00:35:21.930 - 00:35:57.134, Speaker A: And then two copies of the shared edge. Two copies of the shared edge. So this is what we call the seam graph. So now you, you know, this would be a seam path, what we call a seam path. And the seam path is not some arbitrary path in the graph. It has to have this pairing. So in other words, whenever an edge corresponding to one of these, what we call the line seam edges, then its partner, one of its partners should also appear in the path and it should be separated by one of the point seam edges.
00:35:57.134 - 00:36:17.654, Speaker A: So it could be that there is no point seam edge like in this case that separates them. I mean that separates two line seam edges. But if you look at two partner line seam edges, they'll be separated by. So that's like a seam path. And this is seem cycle. So these are all allowed paths and cycles. That's why we give them the name seam.
00:36:17.654 - 00:37:23.450, Speaker A: And this would be a scene tree, another same tree. Okay, so, and these would all the same trees complete whatever, spanning trees, I think we don't call it spanning, but it's a connected tree that contains all the vertices and all the vertices of the same graph and has this same path structure, everything in it the same path. So those are called, so those are all defined here. A seam path is defined between a connecting pair of vertices connecting a pair of vertices in the same set of the seam graph gd, we denote a path as a sequence of consecutively incidenced edges. The path assigns each of his edges a direction. Seam path between u and v, the simple path, that is the concatenation of simple path segments. And so u and v are the first and last vertices and the segments are of two types.
00:37:23.450 - 00:38:03.524, Speaker A: Those are the h segments and the g segments. The h segments could be empty and consist only of point seam edges and the g segment. Each g two j plus one is a single edge in the line seam edges and it has a unique partner edge g two l plus one, such that both edges belong to the same, you know, belong to the same set. So in other words though, all of those lines, em edges correspond to the same edge e in the original graph. So then they, they appear. So that's the definition here. So that's how we define these seam graphs.
00:38:03.524 - 00:38:44.384, Speaker A: And then you can talk about spanning subgraphs as induced subgraphs. And they should be line inclusive, which means they include all of the line seam edges in this. And when the context is clear, we simply identify these subgraphs with their set of points images. And then the seam forest is the seam subgraph that does not contain any seam cycles. And seam subgraph is seam connected if it contains a seam path. And remember, we have to keep saying seam everywhere because it's not an ordinary path. It has this condition that you have the partner edges there and so forth.
00:38:44.384 - 00:39:32.240, Speaker A: And seam tree is the same forest that's also connected and then etcetera. So the rest of the definitions are what you would expect. The only weirdness is this idea of the two things. That one is that the scene path has this idea of partner edges being present. And when we say spanning, we mean that all the line seam edges should also be present. Okay, so in this case, we have different, so we have the situation of bad and good choices, of incidences. So you will see here that same cycles corresponding to the bad choice of incidences.
00:39:32.240 - 00:40:04.902, Speaker A: So this was this example. If you look at this example, it's hard to do during a lecture because it requires some staring at it. But you'll see that this is a bad example, doesn't satisfy the well formed ness criterion that, for numerical stability. And these two are good. And now we want to show that these two good ones correspond to actual seam trees and this one does not. Okay, so that's what this is doing. So not this.
00:40:04.902 - 00:40:25.804, Speaker A: This one is doing for that example, it's sort of showing. Here's the seam graph. Look at the same graph here. And isn't it missing something? No, I think that was a different example. Yeah, this was a different example. Okay, so this is a, we'll come to another bigger example later. Okay, so this one has.
00:40:25.804 - 00:40:59.192, Speaker A: Yeah, so this is the same graph. And you'll see that some of these are not good and some of these are good. So basically it says that these two are seen trees that correspond to the well formed choices of incidences. So it follows the exact same picture that we have here. So if you go back to this picture, the top left is the seam graph. We draw the seam graph for it. The top right is, has the seam cycles, which shouldn't be there.
00:40:59.192 - 00:41:26.516, Speaker A: And the bottom two are seam trees, which are good. So essentially you see the bad stuff happening. And this is, this is good stuff. Okay, that requires staring at that example for a little bit. So I leave that for later. So essentially we can ask a question.
00:41:26.660 - 00:41:44.514, Speaker B: Yeah, so when we have the good or the well formed scene path does, you mentioned that that corresponds to good numerical stability properties for the solutions or for the algorithms.
00:41:44.814 - 00:41:45.406, Speaker A: Yeah.
00:41:45.510 - 00:41:46.634, Speaker B: How does that work?
00:41:47.054 - 00:42:20.648, Speaker A: Yeah, that. So if you, that was sort of what I was explaining in the beginning. So if you have, if you have a solution to this cluster, or you have, you know, all the placements of all the vertices and everything in this, in this cluster, and you have the placement of all the vertices in this cluster and so forth, then when you try to find the rotation and translation of c two and c three so that they fit together to satisfy this condition, this incidence here, what you would.
00:42:20.696 - 00:42:24.296, Speaker B: Do is they're just off a little bit.
00:42:24.440 - 00:43:28.564, Speaker A: They're off a little bit. So now when you try to say that, oh, you know, v four is common between c one and c two, and you say, oh, that the three coordinates of v four in c one and the three coordinates of v four and c two are the same, and then you have another three that says the three coordinates of v three and the three coordinates of v three and c two are the same, then what happens is that's over constrained because in fact they are slightly off. Right. So the distance between them here and the distance between them here are different from each other. So that six constraints that you assert there are over constraint inconsistently over constrained. So what you should do is just say, well, I'm going to assume that this distance is the same between them. So in fact, the number of degrees of freedom that I have at my disposal is five.
00:43:28.564 - 00:43:51.552, Speaker A: So that the common thing here is three degrees of freedom that I can assert here and two only two over here, or vice versa. So three over here and two over here, something like that. But it's not just locally for one edge. In fact, all of these interact across all of these. That's what I'm trying to say.
00:43:51.648 - 00:43:55.864, Speaker B: Right. And that's what the seam graph allows you to do.
00:43:55.904 - 00:43:56.208, Speaker A: Exactly.
00:43:56.256 - 00:44:07.750, Speaker B: Keep track of how they interact, to kind of avoid using extra constraints that would now make your system unsolvable.
00:44:07.942 - 00:44:08.630, Speaker A: Exactly.
00:44:08.702 - 00:44:21.674, Speaker B: That's the sense in which the numerical instability is there. It's not like a Newton's method kind of thing, that it's diverging. It's rather that we're imposing an extra constraint that's not satisfied.
00:44:22.054 - 00:44:46.504, Speaker A: Right, okay, and so, and that's exactly what we're saying here. With this condition, we are trying to sort out how many constraints should we be asserting for any subsystem. Yes. So that we can solve it. And that's what this is. And that's how we arrive at this definition of wealth on system.
00:44:46.804 - 00:45:07.840, Speaker B: Okay, so I have one more question which relates to these incidents, theorems that I spoke about yesterday in the seminar, there are sometimes constraints that you don't put into the system explicitly, but they somehow are there. Right?
00:45:07.912 - 00:45:34.522, Speaker A: That's true. We are assuming some genericity, like we are assuming, like, for example, things like three points don't lie on a line, perfect. All that kind of stuff doesn't, doesn't happen. Right. So, yeah, so these are just distance constraint systems. We happen to have already solved portions of them and we're trying to put them together, and when we do that, we are asserting some incidence constraints.
00:45:34.618 - 00:45:39.378, Speaker B: Yeah, I see, I see. These are what I would call expected degrees of freedom.
00:45:39.506 - 00:45:39.890, Speaker A: Yes.
00:45:39.962 - 00:45:49.892, Speaker B: They may turn out to be over estimates lately in special position. If your points were in special position, the degrees of freedom can drop somehow.
00:45:50.028 - 00:46:30.484, Speaker A: That's right. And not only can they drop, I mean, in fact, if even in all ordinary bar and joint rigidity, if I had not previously assumed that the whole thing is independent, in fact, we would have hidden over constraints here too, like in the two banana case or all of that. Right? So there are no dependent constraints. That's what we're assuming right in the beginning. And that's an assumption that we have had now for three or four lectures, because we would not have been able to get this polynomial time algorithm for the canonical doctor plan otherwise, because we have actually shown that in the general case, getting an optimal doctor plan is NPR.
00:46:30.944 - 00:46:31.824, Speaker B: Right. Okay.
00:46:31.864 - 00:46:40.008, Speaker A: Okay. So that's an assumption that we have made throughout in the last several lectures. But even then, there are these intricacies that need to be sorted out.
00:46:40.096 - 00:46:43.808, Speaker B: Yeah, yeah, yeah, understood. Okay.
00:46:43.856 - 00:47:11.336, Speaker A: Okay, so, so here. Okay, so we defined, so here's the main consequence here. Did I show this picture? Yes, I already showed this picture. Okay, so here's the main theorem. So basically, a seam tree in a seam graph can be found using a greedy algorithm because it happens to be a matrix. Okay. Even though it has this weird seam property, it's not quite the graphic metroid.
00:47:11.336 - 00:48:02.838, Speaker A: It's got special, special pads and special notion of connected and special type of tree, but it turns out to be a metroid. And because of that, we can find this entry using a greedy algorithm just like you would a normal tree. And the other thing is that. Where's the corollary? Okay, well, before the corollary, we have an example. So here's the, another sort of slightly more complicated example. And you'll notice here that this cluster has just shares one vertex. So it's sort of off here by itself as a, as a separate, you know, pair of seam, point seam vertices with, you know, point seam edge here, and the rest of it is like this.
00:48:02.838 - 00:49:04.168, Speaker A: So you might have this example to say that, you know, it's not, the maximal connected spanning subgraph may not be a tree. So we may have to have something separate here that's showing that, but it's also showing this interesting seam graph for this system here and the corresponding, so here's a seam graph, and you can find a, this is an example of a seam spanning same subgraph. And so this part of it is the same tree. And then you've got this thing. And so essentially the other theorem that says is that, you know, if we ensure that we take, we get a cm three, then we get the right number of equations that we wanted. So in other words, we define this notion of a well formed system of incidences by saying it's got the right number of equations, it should have the right number of equations. And then we separately defined the seam graph and the same tree for it.
00:49:04.168 - 00:49:37.258, Speaker A: And now we're saying that, in fact, if you use the same tree, then you get what we want. So in other words, the rank of the underlying seam for s metroid turns out to be exactly the number of equations that we want. For each. We get a well formed system of incidences. That's what this is saying. Okay, so yeah, so Corollary says there's a well formed set of incidences for a standard decomposition. Remember, standard is just canonical for a 3d constraint graph.
00:49:37.258 - 00:51:18.420, Speaker A: And then this is saying that because it's, there's an underlying metroid, we can quickly find the same forest or the spanning seam, spanning seam forest or seam tree for each connected component of the same graph in fairly fast. And so we can get this system into a numerically stable form in polynomial time. So essentially that's what this is. This is simply showing the corresponding set of incidences that that particular seam forest that we found, spanning seam forest that we found, would assert, and there's just no way you would, this is just to illustrate that if you eyeballed it and tried to do this, you wouldn't know how to do this. Okay, so, and I have to say that this was an example of a problem that arose really, because we first saw, we first, you know, I write mathematical software, my group writes mathematical software, and we had to scratch our heads for a long time because we'd end up with something that should be solvable, but we wouldn't be able to solve then that we would, because the thing would come back and say, sorry, this distance that you found for c two and this distance that you found for c one. Although both, it's a single edge that's present in both of them are different from each other, so you can't solve the system of the whole thing for C. And then we would eyeball it and try to sort out these dependences in some way, but then they'll turn out to be all wrong.
00:51:18.420 - 00:52:25.434, Speaker A: So then we said, oh, we got to pick this set of incidences that we assert in a very careful way here. And then that came to the formalization of the problem of this well formed system of incidences, and then came to the formalization of this idea of this underlying graph and metroid and so forth. So this is exactly the type of problem that I find really interesting that, you know, I didn't cook it up as a mathematician. You know, I think of myself as both a mathematician and a sort of an applied person, but it actually arose in an applied context, and I had to, you know, sort of find the sort of mathematics underneath it. And it turned out to be very interesting, the last bit, which is, you know, okay, you said we had this other way of optimizing. So you can think of it as the first thing that we talked about was optimizing the algebraic complexity using a combinatorial approach with the spanning subgraphs of this overlap graph. And the second part was just, in fact, maybe I should have done the second part before the first.
00:52:25.434 - 00:53:34.326, Speaker A: The second part was just ensuring that we have some kind of a well formed system that we're solving. So there's an optimization, and there's a well formedness, and both have different metroids underneath. And the question was, how do these metroids interact? So, in other words, if I went ahead and did this optimization, ignoring the well formedness completely. So here, if I did this optimization, ignoring the well formedness, is it possible that I end up with something that's not well formed? Or conversely, if I did the well foundness first, and there are many possible well formed choices, how do I. Then, after that, I have to go and do the optimization among the well formed choices, will this overlap graph approach, will that even work? So, that was the question. So we wrote another paper that sort of said that, in fact, you can do them one after the other, and you don't lose anything. So.
00:53:34.326 - 00:54:18.202, Speaker A: And neither in terms of complexity or in terms of something going wrong. So, unfortunately, I don't have time to do that. But. And next week, Sean is starting, but we have a few grace, you know, we'll tie up some loose ends at the very end or whenever we have a little bit of time in between, and then I can do it then. Any other questions? So the new set of slides are on. I've already put the copy on the piazza site. I will ensure that I, you know, the place where I had forgotten to put the definitions.
00:54:18.202 - 00:54:36.194, Speaker A: I'll add a new slide so that the definitions are there and somewhere here and then update the slides. Okay, let's talk share.
00:54:40.254 - 00:55:04.414, Speaker B: Thanks, Meera. This is really cool stuff. I mean, it's really excellent when you can see the algorithm kind of coming together, you know, bit by bit, and seeing the obstacles in place that you had to solve. It's really, it's really a nice way to learn this materials.
00:55:04.534 - 00:55:12.310, Speaker A: Yeah, yeah, yeah. It's a nice way to learn the material. Yeah, I agree. Okay.
00:55:12.342 - 00:55:23.844, Speaker B: It'd be a little bit more frustrating if you, if on your end, in the sense that you had to go through the learning of it without knowing that there was a solution at the end.
00:55:24.004 - 00:55:59.540, Speaker A: Absolutely. I mean, it doesn't happen often that you have such a nice solution at the end. You know, it's usually messy, some mess, you know. So in this case, I have to say, from start to finish, you know, we started this frontier geometric constraint solver for 3D, which is open source. We started it around 2001 or so. And this paper, as you can tell, came out this, well, fondness paper came out in 2006, and the optimal parameterization paper came out in 2010. Now, they didn't all take that long.
00:55:59.540 - 00:56:17.484, Speaker A: Let's say it took about five years. And there's a student who actually struggled through it. He was writing the software. So who actually saw the whole thing unfold, you know. So I think that was a very good experience. I'll stop recording.

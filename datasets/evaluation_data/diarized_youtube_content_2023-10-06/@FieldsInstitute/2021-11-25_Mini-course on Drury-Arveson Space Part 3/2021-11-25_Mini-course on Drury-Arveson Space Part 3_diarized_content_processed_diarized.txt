00:00:00.120 - 00:00:21.354, Speaker A: We may start. Good morning, good afternoon. Good evening, everybody, and happy thanksgiving to our american friends. Enjoy and also enjoy listening to the talks. We continue with Michael lectures and Rory Alvarson space. Michael, please.
00:00:23.094 - 00:00:53.364, Speaker B: Thanks for the introduction. Thank you all for coming, especially those of you who join on a holiday. So, happy american thanksgiving to everyone. Yeah. So, let me pick up where I left off yesterday, which was. I introduced these pig spaces, which are, roughly speaking, spaces in which pig's theorem is true. And I tried to convince you that there is sort of a reformulation of this pick condition in terms of extending multipliers from subsets to the whole thing.
00:00:53.364 - 00:01:31.974, Speaker B: So the one thing you should pay attention to on this slide here, it's just this bit here. So, at least at level one, the pick condition means that for every multiplier that's defined on a subset, you get an extension to the entire space that has the same multiplier norm. So it's this multiplier extension property. Last time, I think I explained why this is the case. So let me skip this and instead talk about the question of which kernels are complete pick kernels or which spaces are complete pick spaces. Right. I'm using these two things interchangeably.
00:01:31.974 - 00:02:03.350, Speaker B: So I need another little bit of terminology. Namely, a function f of two variables. This bivariate function is positive. If, whenever you take endpoints in your underlying set x and you form this n by n matrix, then you get a positive, semi definite matrix out of it. So, we've seen this in and in other toxins. It's convenient to have this shorthand formulation. Then there is a theorem which is usually called the McCulloch Quiggin theorem.
00:02:03.350 - 00:02:59.064, Speaker B: But as far as I know in this formulation, that I'm stating it here, it's due to Agva and McCarthy, and it characterizes which kernels are complete pig kernels. So, let's assume we have a non vanishing kernel k, and then this theorem says that this k is a complete pick kernel if and only if there exists a point z in your underlying set x. So that this function here, one minus this ratio, is positive in the sense described above. And if it's positive for one z, then it's positive for all z in the underlying set. So, let me comment a little bit on this. So, first of all, how should you read this fraction here that's on the right? Well, I think a convenient way of reading it is to group terms like this. So you should think that of this as essentially being one over the kernel.
00:02:59.064 - 00:03:49.518, Speaker B: But then you rescale, or you multiply by this rank one kernel that I've just circled in, and I'll get back to this interpretation in a minute. Let me also comment on this assumption of non vanishing kernel. So this means that k of xy is non zero for all choices of x and y. In the case of pick kernels, this turns out to be a harmless assumption, because it turns out that if you have a pick kernel that vanishes somewhere, then you can break up your set into individual bits, so that on each bit your kernel doesn't vanish and the function space is corresponding to different bits are orthogonal. So you can always do this decomposition. And it's a little bit. So working with non managing kernels is a little bit like doing complex analysis on connected sets as opposed to general open sets, right? You can write every open set as a union of its connected components.
00:03:49.518 - 00:04:28.764, Speaker B: But oftentimes theorems and complex analysis become cleaner if you just assume connectedness from the beginning. And so it's similar here. So this is essentially like assuming connectedness. So I'm going to make a couple of comments about this theorem as we go forward, but let me point out that there is a very clean and simple proof of necessity of this theorem that was recently obtained by Greg Nees. So if you want to learn about this, I recommend checking out his paper. I think it's a one or two page argument. Now, this becomes even cleaner if you assume, in addition, that your kernel is normalized at a point.
00:04:28.764 - 00:05:16.564, Speaker B: So you assume that there is some point x zero in your domain, so that kx naught is equal to one for every point x. And so again, this is a fairly harmless assumption because you can always renormalize non vanishing kernels. And this doesn't change the multipliers, but also many kernels you encounter in nature already are normalized at the point. So if you think of the drealers and kernel as an example, one over one minus z inner product w, then this is normalized at zero. Because if you choose w to be zero, then you get one. So you can think of this point x zero as essentially playing the role of the origin in this, in this case. And then what you can do is you just take this point z in this McCulloch Quiggin theorem to be the normalization point.
00:05:16.564 - 00:06:11.942, Speaker B: And then you get this very clean characterization that the kernel is a complete pick kernel if and only if one minus one over the kernel is positive, because then this entry that I circled is just equal to one in the normalized case. Okay, so what can you do with this then, well, what you can do, well, one thing you can do with it is you can prove that a whole bunch of things are complete pick spaces. So here are some examples. If you believe this theorem has a black box, then you can show that the dualis in space is a complete pick space. Because if you look at one minus one over the kernel, then this is just z in our product w. And that's sort of the prototypical example of a positive function. Because if you take this, if you form this n by n matrix by plugging in points, then what you get is the matrix of inner products of these points are also known as the Gram matrix.
00:06:11.942 - 00:07:06.310, Speaker B: These Gram matrices are always positive, semi definite, because they have the form a star a. So in particular, you can see that this McCulloch Quiggin theorem contains a pax original theorem as a special case, because this applies when d equals one. We can also prove that a whole bunch of other spaces are complete pick spaces. And so the ones I want to briefly mention are these spaces in the scale that I introduced in the first lecture, namely, for every number a bigger than zero, we had this. Let's just do it on the disk. So there we have this reproducing Colonel Hilbert space on the disk whose kernel was a power of the Sega kernel. And then it follows from this McCulloch Wiggin theorem that this guy is a complete peg space, if and only if your index a is less than or equal to one.
00:07:06.310 - 00:07:49.094, Speaker B: So a equals one corresponds to hardy space. A less than one corresponds to some weighted Dirichlet spaces, so they turn out to be complete pick spaces. But, for instance, the case a equals two corresponds to Bergman space, excuse me, which is then not a complete pick space. And so, let me actually show you this computation, because I think it's remarkably simple. And so here's how it goes. So you take, you look at one minus one over the kernel, which is this function, and then you expand it into a binomial series. So you get these binomial coefficients, h, u, z n, where I'm reminding you a choose n is this expression here.
00:07:49.094 - 00:08:36.414, Speaker B: And it's an easy exercise to show that if you have a function on, sorry. If you have a power series in z w bar, then this defines a positive function in the sense I described earlier. If and only if all these coefficients are positive or non negative real numbers, I should say so, then when you stare at this long enough, then you see what's going on. Because if a is less than or equal to one, then if you look at this coefficient hoose n. The first factor is always non negative, but all the remaining ones are negative, and so there's n minus one of them. So, once you multiply by minus one to the n minus one, then you see that all of them are greater than or equal to zero. So you get the complete peg property from the McCulloch theorem.
00:08:36.414 - 00:09:08.618, Speaker B: And conversely, if a is bigger than one, then, for instance, you can look at the second coefficient. So a choose two. So a choose two is then positive if a is bigger than one. So once you multiply by minus one, it becomes negative. So that fails the complete peg property. So, one reason why I'm showing this is because I think it shows how powerful this theorem is, especially in this formulation with a normalized kernel. Because usually, proving something like a pick theorem is not easy.
00:09:08.618 - 00:09:51.554, Speaker B: But this McCulloch Quiggin theorem, at least in these examples, more or less reduces it to a calculus one homework problem, right? Because you just have to check certain inequalities for the coefficients. You might also remember if, in some sense, if you take the limit as a goes to zero here, then you get the classical unweighted Dirichlet space. And this also is a complete pick space. And the computation, you can prove it using this McCall Quiggin theorem. But the computation is a bit more complicated, so I'm not going to show it. But actually, this predates the McCulloch Quiggin theorem. So, this is a theorem of Agloe from 1988, where it shows directly that the classical Dirichlet space is a complete pick space.
00:09:51.554 - 00:10:46.682, Speaker B: And so Quiggin says in his paper, for instance, that he was influenced by this argument of Agra. So I think this theorem of actor is really what got the whole thing started. So, one takeaway message here is that there are complete pick spaces that people care about independently of this development of this theory. For instance, this Drury Alveson space and the classical Dirichlet space, which, of course, we learned about in Tom Reinsworth's lectures. Okay, so I said, for necessity, in this McCulloch Wiggin theorem, you should consult Greg nees. Let me briefly comment on sufficiency, because it involves another idea, which is of independent interest, and that's of realization formula. So we saw, I think, realization formulas last week in Mike Joy's talk and yesterday in Michael Driszel's talk.
00:10:46.682 - 00:11:29.944, Speaker B: So, yeah, so I guess I'm not the third Michael to talk about this within one week or so, but let me. Let me still mention it briefly so you can do this. What I'm going to tell what I'm going to say whenever the one minus one over k is, oops, sorry, you can do this whenever one minus one over k is positive. But let me just do it in the case of the duriavas in space, because there the formulas become a bit cleaner. And that's the main object of interest for us right now. Anyway, so suppose you have, sorry. Okay, I think this works.
00:11:29.944 - 00:12:12.748, Speaker B: Sorry about that. So if you have a subset y of the ball and a function phi that's defined on y, then two things turn out to be equivalent. So the first one is that phi is a multiplier on y of multiply and om at most one. So this is also the same as saying that this function one minus phi of z, phi of w bar divided by one minus z in our product w is positive in the sense that I described earlier. That's the first point. And the second point is you have what's known as a network realization formula. So there exists a Hilbert space e, and the unitary operator from e direct sum c into e to the d direct sum c.
00:12:12.748 - 00:12:50.054, Speaker B: So that if you partition it as this two by two block operator, then you can write phi as a fractional linear transformation in these entries, this unitary operator u. And so the z of z here is just the row of the zi, so z one through zd. And then maybe you ask, well, why does this inverse make sense? Well, the inverse makes sense because u is a unitary. So this, this one by one. So this one, one piece a is in particular contraction. So once you multiply by z of z, it becomes a strict contraction for every z in the, in the open bar. And so you can, can form this inverse by Neumann series, for instance.
00:12:50.054 - 00:13:37.146, Speaker B: And so this almost looks like a Mobius transformation, right? And in some sense it's a Mobius transformation, but with operator coefficients. And so this is quite remarkable because it gives a, in some sense, fairly simple form of an arbitrary multiplier. And I should say so for the Dualson space. This is due to Baltrand and Binakoff. But in the case of d equals one, this actually goes back to the engineering literature. So in control theory, people care about when this transfer function is an h infinity, because it has to do with the stability of your control system. One thing you can do with this theorem is that you can give a quick proof of the peg property of the dualison space.
00:13:37.146 - 00:14:16.964, Speaker B: Because what you do is you start with pick data, which is defined on your subset y. So think of it as a finite set, if you like, and then you apply this implication one implies two, which says that if you start with this, then you get a realization. Now, the realization holds, by definition, for all z and y. But the basic observation is that right hand side actually makes sense for all z in the ball. And then you just use that formula to extend a phi to the ball. You call this extension capital Phi, and then you apply the reverse, but now with y equals the whole ball. And then the reverse says that the extension is also contractive multiplier.
00:14:16.964 - 00:15:03.914, Speaker B: So, in some sense, once you know this, then the extension sort of stares at you. You just take this formula, which makes sense on the whole ball, and you extend it this way. So where do we use that we have the dualison space or this positivity assumption? Well, the way that this is usually proved is it uses something known as the lurking isometry argument. And to make this lurking isometry argument work, you need certain things to look like inner products. And so the crucial thing turns out that this thing in the bottom here looks like an inner product. If you want to learn more about this lurking isometry argument, there's a recent book by Agla McCarthy and young called operator analysis, where they really explain this lurking isometry argument really nicely. So you can look at that.
00:15:03.914 - 00:15:56.284, Speaker B: Okay, so we know that the Drury Allison space is a complete pick space. And what I'm going to try to convince you of next is that it's not just any old example, that it's actually universal in a certain sense. And so here I'm just restating this, this theorem of McCullough and Quiggin in this version of Agla McCarthy for normalized kernels. So, this is what I, what I just had earlier. And then a key observation you can make is you can apply it to this positive function, one minus one over k, what's known as the Kolmogorov factorization. So, the Kolmogorov factorization says that every positive function essentially looks like a gramion. It looks like B of X in a product B of Y for some map B, that takes your underlying set X into some Hilbert space E, and then you rearrange.
00:15:56.284 - 00:17:02.946, Speaker B: And then what you get is this theorem of Agular McCarthy, which says that if you have a normalized, reproducing kernel hood, so a Hilbert space with a normalized, reproducing kernel, then it's a complete pick space if and only if there is some Hilbert space e, and the map from the underlying set X into e, that, well, it takes it into the open unit bar, and you can write your kernel k as one over one minus b of X, naught product b of Y. So this shows why it's, why it's crucial to have the right formulation of this theorem so that you can actually see this here. And so the fact that b of x maps the open ball just follows from taking x equals y here. And so this is an if and only if, because a function is positive if and only if it has such a common graph factorization. So then you can observe that this essentially looks like the durialisin space kernel came up, right, because the dualison space kernel was one over one minus z in our product w. And so this looks like the Drealers and space kernel composed with b. And I'll explain in a minute what this, what this means for the function spaces.
00:17:02.946 - 00:17:38.787, Speaker B: But you can already see that for the kernels, the Drealers and kernel is in some sense universal, right? You can recover any complete pick kernel in it. By doing this construction here. Now, you can make your life a bit easier, which I want to do. And then you can assume two more things. I'm going to assume that h separates the points of x, which translates to saying that b is an injective map. So you can really think of b as an embedding of x into the unit ball of some Hilbert space. And I also want to assume that the function space is separable, which means that you can take e to be separable as well.
00:17:38.787 - 00:18:26.664, Speaker B: And so e is either c to the d or little l two. Okay, so if e is equal to c to the d, then this is literally the dualison kernel that we have. But if e is little l two, then, okay, we need to extend the definition of the dualisin space. So this is what I want to do next. So I'm going to write b infinity for the open unit ball in little l two, and then you can define the Drury Allison space on the open unit ball to be the reproducing Colonel Hilbert space, whose reproducing kernel is this familiar formula, one over one minus z in product w. And the only observation is that this makes sense on the open bar of little l two as well. So this is sort of a the version of the Treyarson space in infinitely many variables, and many of the things carry over, but you need to be somehow careful.
00:18:26.664 - 00:19:36.746, Speaker B: I mean, there are some things that don't quite work out the same way, and in particular, certain points of view are missing. So as far as I know, there's no good function theoretic description of this reality space on the infinite dimensional bond, either way you can make this definition, and then you can reformulate this relationship on the kernels as a statement about the function spaces. So if the kernel has this representation here, then this just translates to saying that you get an isometry from your complete pick space into the dualison space that maps the reproducing kernel of the complete pick space to the corresponding kernel of the dualison space. And so this is just a reformulation, because if you think this relationship for the kernels here says that if you take the inner product between two kernels on the left, it's the same as taking the inner product between the corresponding kernels on the right. Okay? So in this sense, you can embed every complete pick space into the dualisin space. But it's also useful to take adjoints in the statement. And if you take adjoints, then you get this result.
00:19:36.746 - 00:20:11.256, Speaker B: So if you take the adjoint of v, then you get a composition operator. And so the adjunct of an isometry is a core isometry, so objective partial isometry. And then you get this. So if you have a normalized complete pick space, then you can find some number d, which might be infinity. So this is one caveat. And the map b from x into the ball in d dimensions. So that composition with this map induces a co isometric composition operator from the dualisin space into the complete pick space.
00:20:11.256 - 00:21:08.712, Speaker B: So if this is your point of view, then the thing to say is that every complete picked space is a quotient of the dualis in space, because you have this coefficient. There's also a companion fact for multipliers, which says that this composition by b gives you a complete quotient map on the level of multipliers. And so in particular at level one, this means that if you start with a multiplier on hyper, then you can lift it to a multiplier of the dualisin space, so that composition with b recovers the original multiply. So part a is really just a reformulation of this relationship between kernels, and part B is more or less the complete pick property of the dualisin space. Because if you have a multiplier on the subset, then it corresponds to a, sorry, if you have a multiplier on x, then it corresponds to some multiplier on the image of x under this map b. And then by the complete pick property, you can extend it to a multiplier.
00:21:08.768 - 00:21:09.764, Speaker C: On the whole bar.
00:21:10.384 - 00:22:08.236, Speaker B: So part B is essentially the complete pick property of the drialis in space. So this shows that the durialisin space is a universal complete pick space, at least if you allow d equals infinity here, because every other space is a quotient and every other multiplier algebra, the complete quotient of the multiplier algebra of the derialis in space. Now you can run with this a little further. And so the first thing you can do is you can just do another reformulation, which is instead of taking the whole draya is in space, you just look at the restriction of your functions to the subset, which you can give the quotient normal always. And then in this setting, what you get is that you get a unitary map from this restriction space into the complete pick space. So this is just another way of phrasing what was on the previous slide. The point is, once you take the restriction and the map becomes injective.
00:22:08.236 - 00:22:55.114, Speaker B: And so if it's injective coisometry, then it's unit error. The advantage of this point of view is that you can work a bit harder to show that you don't need to consider arbitrary subsets v. And so here the key definitions. If you have a set s of functions in the duriavasan space, then you can look at the vanishing locus of this set. So this is the set of all points in the ball where all your functions in S vanish. And conversely, if you have a set of points in the ball w, you can look at the collection of all duriavasan space functions that vanish on w. We say that v is a variety, if it's the vanishing set of some collection of functions in the dualisin space.
00:22:55.114 - 00:23:28.494, Speaker B: So these varieties, in the sense are analytic varieties, because these functions are holomorphic. But it's a little more restrictive, because if you think about it, if d is one, then you're talking about zero sets of the hardy space. And so these are precisely Blaske sequences. Well then I guess the whole disk. And whereas, you know, analytic varieties in one variable would just be discrete sets in the disk. So it is more restrictive. By the way, it doesn't make a difference if you take functions in the druid in space or multipliers.
00:23:28.494 - 00:24:06.854, Speaker B: That also follows from the complete pick property that there's no difference there. So the key observation here is that you can do essentially something like the Zyriski closure and algebraic geometry. So what you can do is if you have an arbitrary subset v of the ball, you can look at the set of all functions that vanish on W. And then you look at the set of all points where those functions vanish and then you get a variety which certainly contains w, but it might be bigger. And so this is essentially like the Zersky closure. And the point is that on the Hilbert space level, you don't really see the difference. I guess there's a d missing here, so there should be h.
00:24:06.854 - 00:24:58.094, Speaker B: So the restriction map from the set v onto the set w gives you unitary on the level of Hilbert functions basis, because it's, I mean, these restrictions are always quoisometries. And it has to be injective, because if you have a function that vanishes on w, then it vanishes on v by definition. So it's injective. Okay, so if you put all this together, then you get an improvement of this theorem I had earlier. And as far as I know, this is, this observation is due to Davidson, Ramsey and Charlit. And it says that if you have any normalized complete pick space, then you can find a variety. So not just any old subset, but a variety in some ball, possibly of infinite dimensions, and a map b from x into the variety, so that you get a unitary composition operator.
00:24:58.094 - 00:26:05.198, Speaker B: So up to unitary composition operators, which is really the sort of isomorphism in the category of filled by function spaces. This is every normalized complete pick space looks like the restriction of the dualisin space onto a variety. Now again, there's a companion fact for multipliers. So if you have a unitary on the level of Hilbert function spaces, you get a completely isometric isomorphism on the level of multiplier algebras. And so then you get these algebras m sub v, which you can either think of the multiplier algebra of this a space on the variety v, or you can think of it as taking all multipliers on the dualis in space and restricting them to the subset v. And the reason why there's no difference is again, the complete pick property of the dualis in space, the multipliers and the subset extend to multipliers on the whole thing. Okay, so once you realize this, that, so that there's a one to one correspondence between these varieties and so complete pick spaces in some sense, then there are some obvious questions.
00:26:05.198 - 00:27:09.504, Speaker B: For instance, what's the relationship between the operator algebra structure of this algebra mv and the geometry of the variety v? So in particular, maybe you would like to prove things that say something like that. The arpeggio algebra is isomorphic in a certain sense, if and only if the varieties are geometrically equivalent in a suitable sense. And so if you want to learn more about this, which I hope you do, then you should just stick around after my talk and listen to orchalit, where he exactly is going to talk about this question here. So just wait half an hour, and then you'll have Warex explain this to you. All right, now, what is this all good for? So, now we know that the Dreyavison space is a complete pick space, and we know that it's actually universal. So what can you do with this? So, I thought I'd just select a couple of topics where you can see how this is used. And then I thought about how to make the selection.
00:27:09.504 - 00:27:42.220, Speaker B: And so the criterion I came up with is, I went through the program of the last couple of weeks, and I tried to select topics that somehow relate to previous weeks. So if I left out your favorite topic, I apologize, but that's the, that's the criterion I came up with. Okay, sorry. So, two weeks ago, there was a program about the corona problem. Let me talk about this. So let's now assume D is finite. That's important.
00:27:42.220 - 00:28:19.224, Speaker B: Things get difficult when D is infinity. In this case, let's just assume finite D. Well, then we know that the multiplier algebra is a unital, commutative banner algebra. So Gelfand theory suggests that we should try to understand its maximal ideal space. So, the maximum ideal space, of course, the set of all linear, multiplicative, non zero functionals on the multiplier algebra. And while there are certain maximal deals, or, equivalently, characters which are obvious, namely point evaluations, right. For every point in the ball, you get the character of point evaluation on the ballot.
00:28:19.224 - 00:28:54.546, Speaker B: We learned two weeks ago in Alex Putney's attacks, that Carlson famously proved, if D is one, that the unit disk is dense in the maximum ideal space of h infinity. So if D is one, then this multiply algebra is h infinity. And so this is Carlson's theorem. Now, remarkably, this works in higher variables. And there is. So this is a theorem of Castella soy and wake from about ten years ago, where they prove that the corona theorem remains true in the durialisin space. So the unit ball is dense in the maximal ideal space of the multiplier output of the dualisin space.
00:28:54.546 - 00:29:35.654, Speaker B: So for the dualisin space, corona is no longer a problem. It's a theorem. And as Jing Bo Xia mentioned in his talk yesterday, one reason why this is remarkable is that this is probably the first, and perhaps still the only real corona theorem in several variables. I mean, the corona problem is open for h infinity of the bar, or h infinity of the poly disc. Well, maybe open and either way it is still. So I shouldn't say it's the only one, but I think it's the first corona theorem in several variables. So let me comment on the proof here.
00:29:35.654 - 00:30:37.534, Speaker B: And so the, it essentially consists of two steps. In the first step, you use the complete pick property to reduce this problem about the multiplier algebra to a problem about the durias in space. So this is originally a problem about the multipliers, and it turns out you can reduce it to a problem about the Hilbert space. I'm going to say a bit more about this in a minute, but then this problem about the Hilbert space becomes a bit easier. It's still very hard, but it is something that Costello, soy and Wick can solve. So then they solve the Dryaveson space problem using the function theory description of the Dryabusen space. So, one reason why I'm mentioning this is that this really combines multiple points of view on the duriavas space, right? It combines this reproducing kernel point of view, which is where the complete pick property comes from, and it combines the function theory point of view, which they need to solve the hard analysis problem in the end.
00:30:37.534 - 00:31:24.124, Speaker B: And let me also mention in passing, maybe if you're like me or you have wild dreams, that maybe there's a general corona theorem that works for all complete pick spaces. But this seems somewhat unlikely, because a couple of years ago with Allemand McCarthy Dresda, in a paper we constructed, or we point out that there is a complete pick space of holomorphic functions on the disk for which the corona theorem failed. So the disk is not dense in the maximum ideal space of the multiply algebra. And so, I mean, it's not a space of functions on a disk of radius bigger than one. I mean, okay, that would be one way to do it, but that would be silly. No, it is a space of functions that they really live on a disk of radius one. Yet the disk is not dense in the maximum field space.
00:31:24.124 - 00:32:32.804, Speaker B: So it does look like you need to interface with the function theory of your space in some non trivial way, because it doesn't work in complete generality. Let me also mention that this uses a construction of Hector cellars. So he constructed some kind of weighted shift that answered a question of Alan shields, and turns out you can realize his shift on a complete pick space that gives you this in the end. So what does the complete pick property then do for you in the context of this corona problem? Well, as we also saw in Alex Britney's talks, you can rephrase this density of point evaluations in the maximum ideal space in terms of function theory. And so this is essentially sort of an exercise in Gelfunk theory and the definition of the weak style topology, namely the unit ball, is dense in the maximum ideal space of the multiplier algebra if and only if. Whenever you have n multipliers that are bounded below on the ballot. The ideal they generate in the multiplier algebra is everything.
00:32:32.804 - 00:33:14.366, Speaker B: In other words, you can find these multipliers c one through cn, so that the sum of phi at CI is equal to one. So this is equivalent to this density of the ball. And so this is what you need to solve. So we're given n multipliers that are bounded below, and you want to show that you can solve this bisou equation. Now, what the complete peg property does for you is it translates solvability of this bizzou equation into a Hilbert space problem. And so in the case of the dualison space, this was also proved by Baltrand and Winnikoff. And if you have a complete pick space, and if you take n functions in the complete pick space, then two things are equivalent.
00:33:14.366 - 00:34:07.400, Speaker B: The first one is what you want. The ideal they generate is the whole thing. So you can find these multipliers so that phi is equal to one. And the second thing is that the raw operator from n copies of the dualisin space into one copy of the dualisin space is a subjective map. And so the reason why this is helpful is it translates this problem, the first one about the multiplier algebra, into a problem about the Hilbert space. So this is something that you can try to solve in Hilbert space, right? You have to show, given any function g in the realison space, it has a preimage over here. And so, just to give you a feeling, I mean, the, the obvious implication here is one implies two, because if you have these multipliers CI, then you can look at the column of the cis, and this is a right inverse for the row of the fields, right? So, which gives you subjectivity.
00:34:07.400 - 00:34:42.634, Speaker B: But the, but the non trivial implication is to go from, from two to one. And this is really what the complete pick property does for you. So this is usually proved using either the realization formula or commit handler theorem. And so this reduces the problem, the corona problem for the 3 hours in space, to the following. You're given corona data so n multiplied upon it below. Then you want to show that the multiplication operator is subjective, which, as I said, is still a hard problem. It is a lot of hard harmonic analysis, but it is something that costia so n we can solve.
00:34:42.634 - 00:35:20.514, Speaker B: Let me also mention that this result is often called the turpert's corona theorem. There's actually an interesting history of this theorem, because in h two, there is sort of a precursor by Leach. Leach's paper appeared about 40 years late. The reason is it was first rejected because it wasn't clear what it was good for. But then the preprint was still circulated, and it turned out to be actually quite influential. So after many decades, people went back, and then it actually got published. So this is sometimes what people call it Leach's theorem as well.
00:35:20.514 - 00:36:01.924, Speaker B: Okay, so this is all I'm going to say about. About corona. Let me try to interface with something else that we saw in this focus program, which. So there was one week about interpolation and sampling and about interpolating sequences and sampling sets. So let me try to talk about this. So, as you may recall, in interpolating sequence for h infinity is a sequence zn in the disk for which the evaluation map is subjective. In other words, for every sequence, wn and l infinity, you can find a function in h infinity that takes those values that send zn to wn for each n.
00:36:01.924 - 00:36:43.264, Speaker B: So, as you may know, the way to think about this is to think that these points are spread out in the disk so much that you can choose the values of your function in h infinity to be essentially independently. You can choose these values essentially independently at these points. And so people are interested in interpolating sequences, for instance, because they tell you a lot about the maximum deal space of h infinity. Alex Botni also explained that Collison's study of interpolating sequences was sort of a precursor to his corona construction. So that's another reason why you might be interested in these. So college and characterize them. And there are two conditions that show up.
00:36:43.264 - 00:37:21.740, Speaker B: Namely, you have a weak separation condition and a college measure condition. And so the weak separation condition means that you can find an epsilon, so that any two distinct points are separated by epsilon in the hyperbolic metric or the pseudo hyperbolic metric. And so this thing here is the. This is usually called the pseudo hyperbolic metric between z and and z m. And you want this to be at least epsilon. And then there's a Carlson measure condition, which says that you have a constant, so that this sum here is bounded above by a constant times the normal function squared in the Hardy space. So we've seen Carlisle measures before.
00:37:21.740 - 00:38:08.842, Speaker B: And this says that the discrete measure that assigns to zn this weight here is a Carlson measure for the Hardy space H two. So, very roughly speaking, weak separation prevents the points from bunching up, and the colors and measure condition ensures that they go to infinity fast enough in some very vague sense. So, Collison proved that a sequence is interpolating if and only if it satisfies both, right? If and only if it's weakly separated, and it satisfies the college measure condition. And once you know this, you can give lots of examples. For instance, if you're, if the moduli tend to one exponentially fast, then you have an interpolating sequence. Okay? So you can ask similar things in the Dreyavison space. And in fact, you can ask this in every complete pick space.
00:38:08.842 - 00:39:05.264, Speaker B: So, I'm formulating things for complete pick spaces now, but you can just think of the Dryaveson space, that it doesn't make a difference. And it's also interesting in the case of the Droehaveson space, and non trivial. So, if you have a complete peg space, then there are obvious analogs of all these conditions here. Namely, you can define an interpolating sequence, which is a sequence for which the evaluation map from the multiplier algebra into little l infinity is subjective. So again, for every bounded sequence of complex numbers, you find a multiplier that takes these values. Then there is a version of the weak separation condition, which involves another metric, which is defined in terms of the reproducing kernel. So you can work out, if you take the Zeger kernel here, and it's not completely trivial, the computation, but you can do it, that this essentially works out to be the pseudo hyperbolic metric on the disc.
00:39:05.264 - 00:39:48.884, Speaker B: So if you're thinking of the dreyalis in space, then this works out to be separation in the pseudo hyperbolic metric on the ball. So, this is also pretty concrete geometrical condition. And then again, there's the Carlisle measure condition, which is essentially the same thing, but the weight is now given by the reciprocal of the kernel. So we have a. So the discrete measure that assigns to zn this weight here is a collision measure for the Hilbert space. And so, in 94, Bishop and Maschlin Sandberg proved that Coliseum's theorem holds in the Dirichlet space. So, a sequence is interpolating if and only if it's both weakly separated and it satisfies the colors and measure condition.
00:39:48.884 - 00:40:53.822, Speaker B: And this proof of Marshall and Sandberg actually did use the complete pick property of the Dirichlet space. And as far as I know, this was one of the first big theorems that made non trivial use of the complete pick property in some space. And so there was some more work which sort of brutally cutting out. There was some work by, for instance, for some of these spaces in this scale. But a couple of years ago, four of us, Alamann, McCarthy, Risht and I, showed that this collison interpolation theorem extends to all complete pig spaces, and in particular it extends to the droias in space. So this does give a characterization of interpolating sequences in the case of the droiasm space, to stir weak separation and the colors and measure condition. The proof we had in 2017 used a big hammer, used the solution of the Kadasen singer problem due to Marcus Spearman and Schiff Astalla Kiattessen.
00:40:53.822 - 00:41:22.204, Speaker B: Singer was known to be equivalent to many things, one of which was the Feistinger conjecture. And the Feistinger conjecture in this context says that every coliseum sequence is a finite union of interpolating sequence. So you can imagine that without going into detail. So this would probably help you out in the proof. And this is what we use. There's now an argument which avoids this, which uses what's known as the column row property. And I might say a few words about this at the end, if I have time.
00:41:22.204 - 00:42:21.206, Speaker B: Okay, so that's what I want to say about interpolating sequences. Then there was another week at this workshop, which was about BMO and Hunkel operators and h one and h one BMO duality. So let me try to connect to that as well. So, as you probably know, h one is the space of all holomorphic functions on the disk, where these l one integrals here are finite, or the super, where these l one integrals is finite. And so I think with this audience, no one needs convincing that one should look at h one as well, even if you only care about Hilbert space. So then the question is, what's the replacement of h one for the Druyawesen space or for the Dirichlet space? You can ask either, and you could try to take the function theory definitions and replace the l two norm with an l one norm, but that doesn't quite have the same properties as h one has. So instead, you can do something else.
00:42:21.206 - 00:43:03.330, Speaker B: You can try to mimic this basic fact, namely that a function is in h one if and only if it's a product of two functions in h two. And so this idea was taken up by. This idea is due to Kaufman, Rakbec, and Weiss, who in the seventies proved that if you have a reproducing kernel Hilbert space. Then the weak product of h is. Well, then they define the weak product of h. The first attempt you can do is you can say, well, you take the set of all products or functions in h, but then you think about it for a second and then you realize, well, why should this even be a vector spring, right? It's kind of a miracle that it is a vector space in the case of h two. Okay, fine.
00:43:03.330 - 00:44:02.512, Speaker B: Then you take finite sums of products, but then, well, if you want to do serious functional analysis, then you really want your spaces to be complete. So then you take infinite sums of products, and the convergence assumption that turns out to be natural is this one that's reminiscent of the projective tensors product of two binance spaces. So on, you can define a norm using this on this weak product, because you just take the infoball representations on the right and then this is a banner function space. And so you can try to study that. And this is supposed to be the replacement for h one. Okay, so if this is h one, then where is where the Hunkel operators and where's Bmo? Well, here the Hunkel forms at least. So a Hunkel bilinear form, it has a symbol function in h, and it's a densely defined bilinear form on H, which just takes two functions in h and multiplies them together and takes the inner product with b.
00:44:02.512 - 00:44:59.184, Speaker B: So with a symbol function b. Now, for the product to make sense, let's assume that one of these functions is in the multiplier algebra and under mild conditions, for instance, if you have a normalized complete pick space, then the multiplier algebra is dense. So this is density defined. And so we can look at the space of all symbols that give you bounded bilinear form, because when it's bounded, then it extends to the whole, to the whole of H. And so when you have a bounded bilinear form, then bilinear form one h is the same as an operator from h into its dual, which is the complex conjugate Hilbert space, because the, the linear dual is the complex conjugate space. And so you get an operator hb from h into the complex conjugate space, which is, which really works like a Hunkel operator. So it just represents this, this bilinear form that I mentioned above.
00:44:59.184 - 00:45:45.998, Speaker B: If you know about Henkel operators, this is little Hunkel operator, right? I mean the big and little Hunkel operators. This is a little one. Now, in the case of h two, there's an old theorem of nihari, which you can rephrase as saying that the Hankel, so all the b's that give you bounded bilinear forms on h two is exactly the dual space of h one. And then Pfeffermann showed that this is actually the space BMW, the space of functions of bounded mean oscillation, which are analytic. And so, there is a version of this Nihari theorem here. So, I mean, it's. Kaufman, Ragberg and Weis observed that often you get, if you have weak products, often you get some kind of duality.
00:45:45.998 - 00:46:42.168, Speaker B: But with Hunkel forms, in the case of the Druyavesen space, this is a special case of a theorem of Richter in Sandberg, that the dual space of the weak product of the drealest space is the space of Hankel form. So this is supposed to generalize h one BMoA duality. It turns out this is true in any complete pig space, which satisfies this technical property, called the column rule property. Okay, let me also mention, in my opinion, very remarkable result of Julian Martin, which says that if you have a complete pick space, which again satisfies this technical assumption, then actually the weak product becomes much simpler. Then every function in the weak product factors as a product of two functions in the Hilbert space. So you don't need the sums, and certainly not the infinite sums. And what I really like about this theorem is that this was an open problem in the Dirichlet space, even.
00:46:42.168 - 00:47:12.784, Speaker B: And so they solved the open problem in the Dirichlet space. But the proof uses Nc function theory. So, if you think about it, the Dirichlet space is a space of functions, of a single variable. So what should there be? Non commutative. But what they do is they take the Dirichlet space, they lift everything to the Duriaveson space in infinitely many variables. Then they lift it even further to the NC Hardy space, and then they solve it in the NC Hardy space. And so some things become much more amenable in the NC world, and this seems to be one of them.
00:47:12.784 - 00:48:18.574, Speaker B: So, I think this is really quite amazing that you use non commutative function theory in infinitely many variables to solve a problem about the Dirichlet space in one variable. There was also, I guess, maybe by now you believe that if you have a space of functions, then you should look at the multipliers. So then clearly you should look at the multipliers of the weak product. And so, there's something that I did with Rafael Glotra, where we showed that, again, under the same assumptions, the multipliers of the weak products are the same as the multipliers of the Hilbert space. So this is supposed to remind you of the fact that the multipliers of h one are the same as is h infinity, which is the same as the multipliers of h two. Curiously enough, our proof uses an operator space approach to these weak product spaces, which is different from some things you see in the literature, where there's usually approach using more harmonic analysis. Let me finish up by briefly saying one word about this technical property, this column row property.
00:48:18.574 - 00:48:53.274, Speaker B: And since this is about the Dryaveson space, I can try to motivate it using a basic fact in the joy Alison space. Namely, if we have these coordinate multipliers, then we know that they form a row contraction. But if you stick them into a column, the norm gets much bigger. It turns out to be square root of D. And so there is some asymmetry between norms of rows and norms of columns. And the question is, so it's possible that the norm of the row is bigger, the norm of the column is bigger than the norm of the row. And the question is, can it also go the other way? And so this turned into a definition.
00:48:53.274 - 00:49:41.568, Speaker B: So, space is said to satisfy the column row property with some constant, if the norm of the row for any sequence is at most the constant times the norm of the column. So, in the dualison space, at least in this very particular example, we see that the norm of the row is bounded by the norm of the column. But in general, it's not so clear. And so the reason why people started caring about this is because it kept popping up as an assumption in these theorems. And so the first non trivial result in this direction is, I think, due to Trent, who showed that the Dirichlet space satisfies the column world property. And there were some other results, positive results by Alderman McCarthy, Richter and myself, and by James Pasco, for instance. And this is remarkably something that does fail in non commutative world.
00:49:41.568 - 00:50:13.312, Speaker B: So they are there. Or Gart, jury and Pascal show that the column oh, property fails in the NC Hardy space. But it turns out now you can actually go back and cross it out as an assumption, because last year I showed that every complete pick space satisfies this column property with constant one. So you don't have to worry about it anymore. You can just ignore it in these theorems. Okay, so that's the end of my lecture series. Let me try to give a very quick summary.
00:50:13.312 - 00:50:47.654, Speaker B: So, the Drury Allison space is a space of functions on the open ball that's supposed to generalize classical hardy space. It plays a universal role in two seemingly different subjects. In multivariable operator theory and in the theory of complete pick spaces. We have many different points of view, which, in my opinion, make for a very rich theory. And in particular, this approach, using complete pick spaces gives an approach to some classical functions, spaces like the daily space, that's useful for certain problems. So thanks for sticking around. And that's it.
00:50:48.994 - 00:50:58.734, Speaker A: Thank you indeed, Michael. Let's thank him first for this wonderful series of lectures. Any question or comments for Michael?
00:51:00.034 - 00:51:14.006, Speaker D: Sure. Can I make. I'd like to make a comment about the Tuplitz Corona theorem. You mentioned this paper by Leach, which I hadn't heard of, but you didn't mention the paper by Arvisson.
00:51:14.110 - 00:51:14.870, Speaker B: Yeah.
00:51:15.062 - 00:51:53.466, Speaker D: So Arverson's paper is from 75. So that's, what, 45 years ago or something? And it's his paper on nest algebras, where he proves the distance formula to nests and proves a number of other things. But it's clear that if you look at what he's doing in that paper and you look at the last section, that he was trying to find an operator theoretic proof of the corona theorem, and he doesn't quite succeed, but he proves this, what's become known as the Tuplitz corona theorem in h two.
00:51:53.650 - 00:51:54.414, Speaker B: Yeah.
00:51:54.834 - 00:52:10.984, Speaker D: And it's sort of buried in that paper now because the paper became important for its work on nest algebra. Wasn't so much known for that.
00:52:12.444 - 00:52:26.744, Speaker B: Right? Yeah, yeah. Thanks for that comment. Yeah, I think. I think Leach didn't realize that you could do this, you know, that you could say something about Corona using his approach, because surely, if he had realized this, then he would have pointed out in his paper and it would have been rejected, I guess.
00:52:30.784 - 00:52:36.684, Speaker A: Thank you, Ken. There was a question in the chat. You see it, Michael?
00:52:38.984 - 00:53:13.504, Speaker B: Yeah. So does the existed turbulence corona type theorem for spaces with CNP factors? Yes, there's a version of this, sort of. So this leech theorem is usually stated more generally, and there's a version of this leech there in for space with CMP factors. But you need to replace multipliers from one space into itself with multipliers from one space into the other. So you get multipliers from the complete pick space into the space with the CMP factor. So it's not so clear what it says about corona, really. But there's a version of it, at least.
00:53:13.504 - 00:53:51.964, Speaker B: Okay. And b, is there an example where they multiplier with the weak product, but the h does not satisfy the column row property? I mean, there are plenty of examples where it's not a complete big space. For instance, if you take h to be h two on the ball, so hardy space on the ball, then the weak product is h one, and the multipliers are both h infinity. I'm not sure about examples where you don't have, where you don't have the column row property. I mean, this column row property has really only been, I mean, so far, at least been useful in the context of complete pick spaces. So I'm not sure people have really looked into it in great detail in space that aren't complete pix places.
00:53:54.944 - 00:53:58.244, Speaker A: Thanks, Michael. Further comments or questions?
00:53:58.384 - 00:54:23.144, Speaker C: Yeah, Michael, in your Corona theorem, there's in a lot of spaces, there's like a part two of the Corona theorem, which is an upper bound for the sum of the moduli. And I think the classical Corona theorem, it's like log delta over delta, maybe some power. So is there a version of that?
00:54:25.064 - 00:55:02.324, Speaker B: So in the triplets Corona theorem, let me go back. In the triplets Corona theorem, you get the best possible upper bound you could hope for in some sense. So what was it? Struggling to go back here? The zoom interface is really not all that easy to handle, I must say. Almost. There we are. Yes. So in this triples Corona theorem, you get the best possible upper bound, because you can get the.
00:55:02.324 - 00:55:37.998, Speaker B: So saying that this row is subjective means that there is some kind of right inverse with some bound. And you get that the column norm of these CI is here is exactly that bound. So this is. If you, if you say that. Let me rephrase it. If you say that MvI, MVI, MVI star is greater than or equal to delta times the identity, then you get that the column of these CI's has normal most. I guess if I phrase it well, let me say delta squared, then you get one over Delta.
00:55:37.998 - 00:55:52.752, Speaker B: So this is the best possible you could hope for. But the problem is that this assumption here is not a point wise assumption. It's an assumption about the operators. So in the usual corona theorem, the lower bound you have is a point wise lower bound, not a lower bound on the operators, right?
00:55:52.808 - 00:55:53.352, Speaker C: Yeah.
00:55:53.488 - 00:55:54.096, Speaker B: Okay.
00:55:54.200 - 00:56:07.684, Speaker C: Yeah. Because for the, in, like h two, there's an upper bound thing. You know, the super, the upper bound is. Right. It's like one over log delta over delta power. Yeah. Okay.
00:56:09.044 - 00:56:21.264, Speaker B: But here the assumption is stronger, because if you test this thing on reproducing kernels, then you get the pointwise lower bound. But this is stronger than just asking for a point where it's lower bound, and therefore the conclusion is stronger as well.
00:56:24.804 - 00:56:37.034, Speaker A: Okay, so let's thank Michael again. Michael, are you going to share the slides with the participants?
00:56:37.114 - 00:56:39.994, Speaker B: Yes. I mean, I'm going to upload them in the chat right now, please.

00:00:00.240 - 00:00:43.654, Speaker A: To introduce our first speaker of today, Olimarte, who will talk about who will continue his mini course on Blaschki products and trainer functions. Please. Thanks. So, let me start just recalling what we did during the last ten minutes of yesterday. So, we had a self mapping of the unit disk and a point in the circle. So here is the point in the circle. And then we were considering the composition of this mapping, so that the composition sends this to the right half plane.
00:00:43.654 - 00:01:36.644, Speaker A: So this means that the composition can be written as the herglot's integral of a positive measure. And this positive measure is called the Alexander of Clark measure of the function f at the point alpha. And taking real parts, what you get is that, say the Poisson kernel at the point f of z evaluated at alpha, is equal to the Poisson integral. Let me write it that way. Of mu alpha evaluated at the point z inside the disk. So you have this nice relation from this niggulation, which holds for any point z in the disk and any alpha in the circle. We were making some observations, some remarks, and this was what we did yesterday.
00:01:36.644 - 00:02:23.304, Speaker A: We started to do that. So, the first thing is, as you see, the first statement is that you can recognize if the function is inner in terms of the Alexander of Clark measure. So the function is inner even only if the Alexander of Clark measure is singular with respect to Lebec measure. So it's concentrated on a set of Lebec measure, zero. In that case, when the function is inner, you can say even more, you can say that the measure is concentrated in the pre image of the point alpha. So it's something like that. You have here the unit disk, and you have here the point alpha.
00:02:23.304 - 00:03:17.006, Speaker A: I'm sorry, I should maybe do it here. So you have here the unit disk, and you have here the point alpha. Then you look to the preimage of the point alpha. This is going to be a set of Lebec major zero, a very tiny set, which topologically, could be very complicated, but still a small set. So this is the preimage of f by the point alpha of the point alpha. And this is the place in this tiny set, is the place where the Alexander of Clark major is concentrated. Moreover, these measures are mutually singular because they are concentrated in the joint sets.
00:03:17.006 - 00:04:14.276, Speaker A: So they are concentrated in. So if you have another point, say, beta, here, then the prayer material, of course, will be different, will be maybe this set of points. And here is where mu beta is concentrated. Okay, very good. And you should think on this, Alexandrov Karl measures as measures, which in a certain sense, tell the intensity in which the function f takes the value alpha. So actually, what happens is that, say the biggest is the measure at a given point, the smaller is the derivative of the function at this point. And this can be easily shown in the case of finite Blaschki products.
00:04:14.276 - 00:05:29.784, Speaker A: So if you have a finite Blaschki product, then, well, in that case, the computation is very easy, right? Because if you have a finite blascke product, then this set is just a finite set, a finite collection of points in the circle. Each point alpha has finally many prey images. So the corresponding Alexandrovgaard measures, which is concentrated in this set, has to be just linear combination of point masses. And this is when, just using this formula and a small, an easy computation tells you that the Alexander of Clark Major has this form in the case of finite plasket products, right? Just this linear combination of the Dac masses located at the pre images of the point alpha. Okay, so I'm not going to do this competition, and actually we are not going to use it. But I just wanted to remark that, as I said, mu alpha has to do with the intensity in which the function f takes the value alpha. Okay, so here is our main tool.
00:05:29.784 - 00:05:55.684, Speaker A: This is Alexandrov disintegration theorem. It's very nice, right, because it tells you something like that. Let's see. This is the picture we should have in mind. Here you have the point alpha. Here you have the pre images of the point alpha. And the major mu alpha is concentrated in these pre images.
00:05:55.684 - 00:06:55.904, Speaker A: As I said, if you have a different point beta, well, the prey images will be located in other points. For instance, in the case of a finite blaster product, this would be the places where mu beta is concentrated. And this happens for any point in the circle. So the Alexandria, I'm sorry. The Alexandrov disintegration theorem tells you that when you average all these measures, you return to Lebec measure. So the situation is as follows. You have a collection, a continuous collection, a non countable collection of singular measures, the mu alphas, which are mutually singular and in such a way that when you average them, you return to the back measure.
00:06:55.904 - 00:08:01.856, Speaker A: So this is really, well, quite a family, right? It's, well, a sophisticated family of measures. Okay, so what does this mean that when you, when this is what I have said, that when you average them, you return to Lebec measure. In practical terms, this means that when you integrate, well, an interval function against the beck measure, you can think on that the following way. You first integrate with respect to given Alexander grard measures to respect to a given Alexander graph gras. And the result you integrate with respect to alpha. Okay, so, well, the proof of this has a delicate point, because first we should prove that whenever you have an interval function, this quantity makes sense. So you have to show that whenever you have an interval function, the function g is interval with respect to the Alexandrov measure, at least for almost every alpha.
00:08:01.856 - 00:09:09.944, Speaker A: And this is the case. But let me just skip this technical point and let me just prove it for g, continuous. And, well, when G's continues, the situation is easier, because, as you know, linear combinations of Poisson kernels are uniformly dense in the space of continuous functions. So this means that we can, without logical generality, we can assume that g is a Poisson kernel at a given point in the disk. And in that case, the proof is very easy, because, well, the left hand side, this integral, since g is a Poisson kernel, is, of course, one. And now let's look to the integral of the double integral in the right, this double integral. Well, first, let's compute the interior integral.
00:09:09.944 - 00:10:21.746, Speaker A: So, let's compute that, well, g is just the g is just the Poisson kernel. Well, our definition of Alexander of Clark measures tells that this is just the Poisson kernel at the point f of z evaluated at the point alpha. So what we need to do is just to compute this. As I said, the interior integral is just the Poisson kernel. So you get the Poisson kernel at the point f of z evaluated at the point alpha, and then you need to integrate over alpha. But this is just the integral of the position kernel at a given point point in the disk. So this is also one, right? So this finishes the proof, right? When, in the case when g is continuous.
00:10:21.746 - 00:11:09.828, Speaker A: Because when g is continuous, as I said, you can assume that g is the Poisson kernel. So, in that case, this gives you one and DsoL gives you one. So this is the proof in this particular case. Okay? Okay. So this, as you'll see during this talk, this will be our main, our main, our main tool to study, say, stochastic properties of inner functions. So, the plan today is to present a version of the central limit theorem for iterates of inner functions. Okay? So let me just recall the central limit theorem, the classical central limit theorem for you.
00:11:09.828 - 00:12:58.350, Speaker A: So, if you have a sequence of real, independent, identically distributed random variables with mean zero and, say, variance sigma squared, then the central limit theorem tells that when you perform this average of the random variables, then the average ten in distribution to a gaussian right? So this means that the probability that this set, I mean, this random variable, takes value in a given, say, interval. So k is going to be here. An interval in the line is just, well, the gaussian measure, the gaussian measure of the interval, okay, the gaussian measure of the interval, okay, so this is the, well, the, probably the most classical version of the central limit theorem. And it has, of course, extended in many directions, in many different directions. In particular, there are versions of the central limit theorem which are literal in function theory. So here is a version, the version of the central limit theorem I want to present is a classical result by Sal and Sigmund on Lacunae series. Okay, so a lacunary series is a power series of the following form is a power series where the only monomials which are present are monomials which grow exponentially fast.
00:12:58.350 - 00:14:24.190, Speaker A: Okay, so for instance, you may take nk to be two to the k, right? So this would give you an example of lacunar series. Well, what happens is that the idea, I guess, behind all these results is that if the series is lacunary, then these monomials, because the exponents grow exponentially, these big monomials behave as independent random variables. And it makes a lot of sense, right? Because, for instance, imagine that n sub k is two to the k. Imagine that you are in that situation. So it makes a lot of sense, because even if you have some information on how, I mean, which are the values of z to the two to the k, then, well, the values of z two to the k plus one. Since this grow exponentially, probably not too much information can be captured from z to the two to the k. Okay, so, well, now there is a classical result by Pali.
00:14:24.190 - 00:15:06.304, Speaker A: So this point match convergence is due to Pali. I forgot to mention that it's a classical result by ballet. And tell you the following. This very nice result, which also has some probabilistic flavor. It tells you that whenever you have a lacunary series, then the following conditions are equivalent. Either the series converges at almost every point in the circle, or the series converges at a set of positive measurements, or the coefficients are square summable. These three conditions are equivalent.
00:15:06.304 - 00:15:52.924, Speaker A: So, if you want, in other terms, there is again a decautonomy. It's like a zero one law. If the series converges, if the series of the coefficients, I'm sorry, if the series of the squares of the coefficients converges, absolutely. So if the coefficients are in little l two, then the series converges, the lacklary series converges. At almost every point in the circle. However, if the series diverges of the coefficients of the square of the coefficients diverges, so if the coefficients are not in little or two, then the lacunary series diverges at almost every point in the circle. So you have very good behavior or very bad behavior.
00:15:52.924 - 00:16:44.882, Speaker A: You do not have intermediate behaviors. Okay? So then it's quite natural to ask, well, what happens when the, when the series diverges, when the series of coefficients are not, when the coefficients are not in l two, you would expect to have some result on the distribution of values of the lacunar series. And this is the central limit theorem, which was proved by Salem and Zimon, well, many years ago, in 1947. It says the following. So, assume that you have coefficients which are not enough in middle of two. Okay? So assume that you have coefficients whose squares are not summable, and then you consider these, say this. This plays the role of the variance.
00:16:44.882 - 00:18:24.464, Speaker A: So the partial sum of models of a n squared. And assume that condition. Right? So this condition tells you that in this sigma n square, one individual, a n, is not really important. So sigma n tends to infinity, of course, because this sum tends to infinity, but not due to us, to the growth of a single term in the series. So, if this is the case, then what happens is that these quantities, which, as I said, the partial sums would burge at almost every point, but when you normalize them conveniently, then this tends in distribution to a complex gaussian. Okay? And this means what I have written here, this means that the measure of the set of points where these partial sums lie in a given disk. So k here is going to be a disk, for instance, in the plane, the measure of the points in the circle where this quantity is in a given disk, this tends, when n tends to infinity, course to the complex gaussian, to the complex, to the, what they want to say is to the gaussian measure of the disk.
00:18:24.464 - 00:19:28.654, Speaker A: So this, well, this result, actually, we like a lot. And I guess that also Salim and Zingman like it a lot, because they proved many different variants of this result. They proved similar results for trigonometric lacunari series. They also proved tail versions of this central limit theorem, and they also proved local versions of this central limit theorem. So let me, let me at least, let me at least mention the local version. So, this is the result they proved. But as I said, they proved more, actually, they proved the following even nicer result, I guess that what, that whenever you have a set so fixed, fix a set e in the circle, and instead of looking to the measure of all the points in so, just a measurable set, I'm sorry, of positive measure.
00:19:28.654 - 00:20:17.244, Speaker A: So it could be very complicated. And now you look to, instead of looking to that, you look to the measure, to the normalized measure. So you look to these quantities, the measure of the set of points where this lies in a given disk, and you divide, you normalize it, you divide by the length, by the measure of it. And this thing is still true. So this still holds. So this means that this central limit theorem, even whole, it even holds locally on any set of positive measure. Okay, so, and as I said, they proved many other variants, but I wanted to mention this.
00:20:17.244 - 00:21:24.744, Speaker A: Okay, so our main, our main objective today is to prove a similar result for inner functions. Okay? So let's go to that. Well, when you want to prove limit theorem for inner functions, the first thing I guess that one should ask is, well, how far away we are from the usual assumptions. So, usual assumptions is that our random variables should be independent and identically distributed. In our case, our random variables are not random anymore, but the iterates should take the place of the random variables. So in a sense, we should ask ourselves if the iterates are independent than if they are identically distributed. And here there is a good new and a bad new.
00:21:24.744 - 00:22:07.242, Speaker A: Well, let's start with the bad news. Bad news is that they are not independent. They cannot be independent in any sense, right? Because at the end, the n plus one iterate depends on the nth iterate, right? So it's clearly, they are clearly not independent, and this will be our main obstacle, right? That they are not independent. However, there is also, as I said, the good news. And the good news is that they are identically distributed. And they are identically distributed, because we already show it. We already proved this is Lefner's lemma, right? When you have an inner function fixed in the origin, the back measure is invariant.
00:22:07.242 - 00:22:49.454, Speaker A: So this holds. Right? Let me use this to make a computation. So instead of writing left nerve lemma in this form, I will use it in this form. So what I mean here is that whenever you have an invariant measure, so for instance, Lebec measure, what this formula tells you is that you can, well, you can decompose. I mean, if you want to compute this integral, you can decompose with f. So you can write this identity. So why this is true? Well, it's very easy, right? So.
00:22:49.454 - 00:23:58.404, Speaker A: So, to prove this for any, for any integrable function g, it's enough to prove it for characteristic functions of sets, right? Because such linear combinations are then l one. So without lot of generality, we can assume that g is just the characteristic function, the indicator function of a set e in the circle. But in that case, it's, the result is, is just Lesner's lemma, because this is of course the measure of e. And this is of course decomposed with f, will be just the characteristic function of the pray image. So this is just the measure, the back measure of the pray image. Okay, so this is clearly another, another state, a restatement of Lerner's nema. And this is what we are going to use to compute the variance.
00:23:58.404 - 00:25:12.160, Speaker A: So to compute the variance, we will need to compute first these integrals you have here, right? So let me start computing these integrals, okay? So here, the first step is the fact that we can, as I said, whenever you have something, a function which depends on f, you can forget about f, right? So of course this function depends on f to the n. So we are going to apply this Lefner's lemma. So when we apply it, you arrive to this integral, okay? But this integral is just by Cauchy's theorem. This is just the derivative of the iterate at the origin. And now remember, recall that the origin is a fixed point for our inner function f. So you just apply chain rule and then you arrive to this quantity. Okay? So this is a very easy computation using Lefner's lemma.
00:25:12.160 - 00:26:47.424, Speaker A: And this is what is used here, right. This will be our variance, okay? This will take the place of the variance in the central limit theorem. So the variance is like the l two norm, okay, you don't see here the mean, right? Because the mean is zero, because the function f vanishes at the origin. Then what we do is the most naive thing, which is to compute. I mean, we just write this as the sum of an squared fn squared, and then we have the mixed terms, right, which would be just two times the real part an. And then I would have something like the sum, I guess, fk, something like that. This is what you have, this is what you need to integrate, right? At first sight, it could see as hopeless, but several things help.
00:26:47.424 - 00:27:53.122, Speaker A: The first is that the function is inner, right? So this is one at almost every point, so we can forget about this. And the second is that we already did the computation of the integrals of these parts, right? And this comput, and these integrals were giving us the integrals of these were giving us just f prime of zero at the point k, right? So what you get is this identity here, and then, well, this you need to check, but it's not hard to check that this is comparable to the sum. I mean, you have here two terms, this one and this one. And the idea is that since f is a self mapping of the disk, which is not an automobile fist, this is going to be smaller than one in modulus. So this second term is like an error term. It can be absorbed by the first one. So, for instance, imagine that the function f vanishes at the origin, and also that the derivative vanishes at the origin case.
00:27:53.122 - 00:28:38.674, Speaker A: This second term would disappear. So at the end, what I mean is that the variance is comparable to the l to the l two sum of the coefficients. Okay. Okay, so now we have, using lefe lemma, we have already localized the variance. The variance will be this expression here. Okay, now I can state our result, which is the central limit theorem, which I have in this screen. So here I have recalled the definition of the variance, this large expression here.
00:28:38.674 - 00:29:16.104, Speaker A: And then here is our result. Assume that the function is inner that vanishes at the origin. So the origin is the dendrite wall fixed point in that case, which is not a rotation. And assume that the coefficients are uniformly bounded. So this is, well, we can prove this theorem under weaker assumptions on the coefficients. But for the presentation, I guess this will be enough. Okay, so assume that the coefficients are bounded, and of course, the coefficients are not square summable.
00:29:16.104 - 00:30:56.624, Speaker A: Then what happens is, again, that the partial sums, when conveniently normalized, converge in distribution to a complex standard Gaussian. So again, this means, if you want, this means that the measure of the points psi in the circle were these quantities stay in a given disk. And I given this kick, this would converge when n tends to infinity to one over square root of two PI, the integral over k of e to the minus z squared. I write it here. This would convert to one over square root of two PI, just to the gaussian measure of the, I'm sorry, this would be area measure, right, area measure. Okay, so this is the result I wanted to present today. This is joint work.
00:30:56.624 - 00:31:52.988, Speaker A: This is a recent joint work with auditioning. And there are a few things I wanted to remark. The first thing is that I should say that in this result, no lacunarity assumption is needed. Right. So here we have the whole sequence of iterates. Okay, the second is, well, I will not talk about the second, but we also have versions and which are similar to versions that Zalim and Zingmoon had for lackli series. But there is a version that we do not know how to prove.
00:31:52.988 - 00:33:07.512, Speaker A: So. And what we don't know how to prove is a local version of the result. So here, here is something open, local versions. So this means that if we fix a set in the circle, we do not know how to prove that this would tend to the Gaussian, right? So if, what I mean is that if we fix the set on the circle, so e is fixed, a set of positive measure. Of course, we do not know if this thing holds or not. And as you'll see this, I mean, we don't know, our methods do not apply because at some, at some point, our methods rely on complex variables, arguments. So this kind of argument, typical from complex analysis, that certain integrals manage and, well, and these are, of course, very nice and very beautiful, but they are also very rigid.
00:33:07.512 - 00:35:05.246, Speaker A: So when we have, when we restrict attention to a set of positive measure in the circle, we already do not know how to proceed. So let me skip now that also, I wanted to remark that, well, there is a particular case which is especially interesting, which is when all the ans are one, if all the coefficients are one, what we have here is, well, something like an ergodic mean, right? So when in the case where all coefficients are one, then this variance can be easily computed, right, this is just one. This is just one. And here you have a geometric series, so you can really compute the sigma n. And what you get is that this sigma n squared is n times sigma squared, and sigma squared has this nice, this nice formula, right? So it really depends on the derivative of the function at the origin, right? So you should, it makes also a lot of sense, right? Because if this derivative at the origin is very close to one, this means that f would be very close to VR rotation. And in that case, of course, what you would expect is to have a very small variance, right? Okay, so now the rest of the last 15 minutes of my talk would be devoted to, well, to explain you how the Alexander of Clark measures enter into the game, one least to explain the main parts of the proof. Okay, so here, this was the result.
00:35:05.246 - 00:35:56.044, Speaker A: And now, to prove this central limit theorem, we need two main auxiliary results. And these two main auxiliary results are stated in my next screen. So let me first present them. Well, the main estimates are the following. So I'm going to use this notation. Whenever you have a set of indexes or a set of positive integers, let me write bite size of a to be the part of the sum we will consider, but restricted to the indexes in the set a okay, so the first obsidian result says the following. Assume that you have two sets a and b of positive integers.
00:35:56.044 - 00:37:20.944, Speaker A: So here I have a set a, and here I'll have a set b sets of positive integers. Okay? And assume you have this condition, right, that the set a is at the left from the set b. Then what happens is that, well, this fantastic formula, right? It's a formula which looks like a mistake, right? It says that the integral of the product of the models square is just the product of the integrals. So this is, we understand this as trace of independence, because remember, when you have two independent random variables, then the expected value of the product is the product of expected values. Of course, in our case, these modulus of size of a square, so the modulus of square of these partial sums, these are not independent in any sense. But still it happens that the expected value, so the integral of the product is the product of integrals. This is the first auxiliary result which I will discuss in a minute.
00:37:20.944 - 00:38:21.096, Speaker A: And here is the second. The second is more sophisticated, but it's actually harder also to prove. So the second says the following. Assume that you have, well, first annotation, and let's use this notation f to the power minus n would mean the nth iterates of the function f. And then to taking a complex conjugate, of course, n here is a positive integer, right? Okay, so this second result tells you the following. Assume you have natural numbers which are one. I mean they are, and they are ordered from smaller to bigger, and they are in such a way that the difference between two consecutive ones is bigger than a large number q.
00:38:21.096 - 00:38:56.888, Speaker A: So q will be a large number. And let epsilon j be pluses or minus one. Then this tells you this. Our estimate is that the integral of the product of all these iterates with respect to the back measure is smaller than this quantity. Okay? So we should understand this in the following way. This is, this quantity here is a correlation. Remember that some epsilon j's could be minus one.
00:38:56.888 - 00:39:52.738, Speaker A: So this means that you could have complex conjugates here, okay? And this one, and we're going to apply this when q is much more bigger than k. So when q. So the idea is to apply it when q is a number which is bigger than k. So remember that f was an inner function fixing the origin. So this means that this quantity, this, the derivative at the origin is smaller than one because f was not a rotation. Okay? So this means that you have here an exponential decay. So this second theorem tells that the correlations, the higher order correlations, the higher order correlations decay exponentially.
00:39:52.738 - 00:40:36.374, Speaker A: And this will be also very important in our proof. So, my plan now is to discuss the proof of the first artillery result of this. This proof is very, as you see, it's very easy and it uses Alexander flag measures. The proof of this is also used Alexander Clark measure, but it's much more involved and I'm not going to present it. Okay, so let me concentrate on this. Okay, so here is the statement, and my plan is to present, as I said, the proof. Okay.
00:40:36.374 - 00:41:22.764, Speaker A: Okay. So in order to prove it, we again act in the most naive way. Okay, so remember that site a was just a partial sum. So we need to compute the modulus square. So what we do is we just look to this. We compute the modulus, modulus, square, just expanding all the terms, okay, so what you get is something like that, okay, so you get here the sum of the square of the modulus, and then you have the mixed terms, right, which would give you something. This is something as the real part of this quantity here, two times the real part.
00:41:22.764 - 00:42:16.664, Speaker A: So, we do this for psi a modulus square, and we will do also it for psi B modulus square. Okay, so now we need to integrate the product. So, the product would consist of linear combinations, very complicated linear combinations of products of this part, of this sort, products of guys in here against similar guys. But now in psi B. So what we would get is linear combination of guys in which appearance in psi A. So n and j will be in a, one bigger than the other. And then the same thing for k and l l in b and k and l in b and say l bigger than k.
00:42:16.664 - 00:43:26.864, Speaker A: So in order to show that, what you need to prove is that the integral of this product is the product of the integrals. Once you prove this, then you put things together and you arrive to this identity here. Okay? But as I said, this again looks like an identity which should be understood as a trace of independence between this guy and this guy, because it tells you that the integral of the product is the product of the integrals. And this was already, we already computed that this was f prime of zero to the power j n. Okay, so we need to start with the left hand side and arrive to the right hand side. So here is the argument, and here is where you will see Alexander of Clark Majors. So we start with the left hand side.
00:43:26.864 - 00:44:21.492, Speaker A: And remember, the situation is that n is smaller than j and k is smaller than l. These are how the indexes are located. But now remember that by Lefner's lemma, we know that the integral of g composed with f, it's the same as the integral of g over the circle. So this means that I can replace this nth iterate and here replace j by j minus n, k by k minus n and l. And this is what I have done here. Okay? So we arrive to this quantity here we have used, as I said, lefner's lemma. And now, and here is the crucial point.
00:44:21.492 - 00:45:25.968, Speaker A: Now let's let us consider the Alexander of power measures of j minus m. Remember that by Alexander of this integration theorem, dm of z is the integral of v mu alpha with respect to DMIA alpha. So the Alexander square measures when we average them. You return to the Beck measure, and remember that these Alexandrovcar measures are concentrated in the places where f, where this iterate has the value alpha. So this means that we are concentrating in places where this is equal to alpha. So when you write the double integral coming from this identity, for coming from the Alexander disintegration theorem, this is going to be equal to alpha, right here, this is alpha. And then of course here you would get something like f k minus a of alpha and f l j of alpha.
00:45:25.968 - 00:46:15.464, Speaker A: And you need to integrate that. And here is what helps. What helps is that what we have got is this integral. You see in this part, you see the moment, the first moment of the major mu alpha. These can be very easily computed through the corresponding iterate. Now here is the formula for Alexander measures. From this formula, you can easily compute the moments of this measure in terms of the derivative of fj minus n at the origin.
00:46:15.464 - 00:47:10.684, Speaker A: You just expand this in power series, right? And you arrive to this thing. So this means that this integral, this integral with respect to this integral here, we know how to compute is just alpha bar f prime of zero to the power g minus n. Okay? And this is very nice, because this alpha bar here cancels with this alpha, because alpha is unimodular. So what you get is just this quantity, which is a constant which goes outside the integral. And the only thing which is left is this f k minus j. And this is fl minus j. So you only are left with these two quantities.
00:47:10.684 - 00:48:13.502, Speaker A: And again, this, by Lefner's lemma, this is just integral of fk fl bar with respect to the back measure. So this finishes the proof, right? This is what really what you needed to prove, okay? That the interior of the product, as I said, is the product of integral. This is the first part and this is the second part. Okay? So now, as you see, this is a very, I mean, a complex analysis argument. If, instead of integrating over the whole circle, we would integrate over a subset of the circle, then. Well, the difficulty would be that this moment would be probably hard to compute. Right? Because this, in this, in the definition of Alexander Square, measures were integrated over the whole unit circle.
00:48:13.502 - 00:48:43.148, Speaker A: And this is why this local version of our result is still open. Okay, this is the first identity. And now let me just mention a couple of ideas we need in the proof, the second ident, the second estimate, the second main result, that we just skip. And here is. Let me just mention that here is the main idea. In the proof, the first part is. Consists in splitting.
00:48:43.148 - 00:49:32.792, Speaker A: So the idea is that we will consider this partial sum and we will split it into two parts. One part which is relevant, which are the psyche, and another part which is irrelevant, which is the etax. And the ETA case will be irrelevant because they would have very small l, two norm. And the nice thing is that the ETA case are located between two different Psi case. So this means that indexes in two different psyches are far away, one from each other. And this gives an extra amount of, say, of independence between the PSIK. Once this is done, the proof uses the standard argument to show that something turns to agaussion.
00:49:32.792 - 00:50:13.944, Speaker A: What you need to show is that the Fourier transform of your process, say, tends to. And tends to agaussion. Right. Thanks to this gaussian. And for this, what we do is we just follow, say, standard arguments to show that this Fourier transform looks like something like that. This is going now to be a little bit fast, but I'm running out of time. So this is the.
00:50:13.944 - 00:50:58.114, Speaker A: The main quantity you need to establish. And in this main quantity, what happens is that you see products of cycase. And when you have products of cycase, this is the moment where you will use the first identity. Those are just the products of integrals. And then you will have also the mixed terms. And in the mixed terms, you will use the second identity, that these higher order correlations decay exponentially fast. So, I think my time is over.
00:50:58.114 - 00:51:27.904, Speaker A: So I thank you all for your attention. Thanks a lot. Thank you, Arthur, for wonderful lecture and wonderful course. Thank you. Any questions, comments, suggestions? I don't see anything in the chat. So if there are no questions, let's, again, thank Arthur again for.

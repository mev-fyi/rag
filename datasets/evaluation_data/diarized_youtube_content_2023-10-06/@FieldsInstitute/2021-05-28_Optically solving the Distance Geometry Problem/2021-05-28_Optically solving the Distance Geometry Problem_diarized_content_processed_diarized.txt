00:00:00.240 - 00:01:45.544, Speaker A: In my talk today, I will actually talk more specifically about a work we have been doing for optically solving the distance geometry problem. And in this work we actually collaborate with mathematicians who are also part of the symposium, who gave talks already, Douglas Gonsalves from the Department of mathematics in the Federal University of Santa Catarina as well, and Simon Hengefeld and Antonio Muccerino from the University of Rennes. Just to mention Paolo already gave the number of the archive submission of our manuscript, but it's written here again. So if you have, if you are interested in looking at much more details, then go for it. Well, so probably most of you know better than I do that a distance geometry problem is a problem involving vertices connected by edges, which sounds very abstract for a physicist like me. So why would we be interested in dealing with such a problem? Well, I've seen many talks in this symposium showing very interesting applications that for physicists are nice, for example, on localizing sensors in a network, or like a talk two days ago about molecules confirmation. And yeah, there was also this 3d motion of skeletons.
00:01:45.544 - 00:03:34.604, Speaker A: So interesting applications that can be connected to physics, to experiments in physics, especially in this one here on the molecular conformation, can be the theoretical predictions using distance geometry problems can be confronted with state of the art imaging and diffraction techniques. Another point of interest here is that for for me, is that the hardness of the problem of the distance geometry problem makes it difficult to solve in a traditional computing platform, as we have in our computers nowadays, which are fundamentally based on electric current. So to build new computing platforms that can deal this kind of hard problems, one needs to know the physical processes behind them. In the talk today and the work I present, we are actually interested on a distance geometry problem in dimension one. And although just one dimension of being just a one dimensional problem, it has also very nice applications. For instance, if this dimension is time, one can use solve DGP problems to synchronize clocks in, for instance, a diffuse network of clocks where you have only a few delay measurements, for example, between pairs of clocks. Not all of them are available.
00:03:34.604 - 00:04:40.504, Speaker A: Still, one dimensional problem seems simple, but it's not. It's an NP hard problem. And this means that the complexity of the algorithms needed to solve this problem increases exponentially with the size of the problem. So which kind of platforms are there available instead of traditional computers to solve NP hard problems? I'll show you here two examples to solving a different kind of hard problem. It's not the DGP, it's a subset, some problem, but it's possible to build networks which can search all possible realizations of a problem in parallel. The platforms for building such networks can be, for instance, molecules or light. And the point here is that this parallel computing can reduce the algorithm complexity.
00:04:40.504 - 00:05:53.826, Speaker A: And in my case I'm especially interested in looking on optical ways to address NP hard problems. So a quick outline of my talk is as follows. I'll first define the DGP instance we are dealing with. Then I will introduce you to one type of algorithm used to solve it, and then I will present how we reformulate this algorithm as a matrix by vector multiplication and this operation. This multiplication can be performed with our proposed optical scheme, which I will show you in the last part of my talk. First, let me generally introduce you to the problem we are actually addressing here, which is a subclass of a distance geometry problem. A kind of formal definition of a distance geometry problem can can be shortly summarized in a question that asks whether a graph is realizable or not.
00:05:53.826 - 00:07:00.160, Speaker A: A graph is defined by vertices, by edges connecting these vertices, and by distances. These distances are real valued and positive weights for each of the edges involved in the graph. And recalling that these problems are hard problems right to solve. We are particularly interested here in a subclass of distance geometry problems which are called here paradoxical DGP ones. This is a subclass even after the problems in one dimension. The problems in one dimension. In these problems in one dimension, the vertices and the edges all lie along a line, and the paradoxical instance has additional definitions, additional constraints which are listed here.
00:07:00.160 - 00:08:21.624, Speaker A: So first is that there exists a vertex order in our graph, meaning that we can label each of the vertices with a real number, an integer number. And the edges contained in the graph are the edges connecting the consecutive vertices in the order apart from them. The only edge still in the graph is the one between the first and the last vertices. And why is this word paradoxical here? Why do you use this adjective? Actually, this arises from the fact that the presence of this last distance, the one between the first and the last vertex, this on one hand makes the problem kind of simple, because in the end only two solutions will be possible. But on the other hand, this information, this last distance information, can only be used in the last moment. So up to this moment, the number of solutions or candidate solutions still grows up exponentially. So the problem is still np hard.
00:08:21.624 - 00:09:38.884, Speaker A: A way to find solutions in a distance geometry problem is to use buildup algorithms. In this kind of algorithm, one can take one vertex position at a time and build the next vertex position by using a predefined order and the distance information. With that one can. With this algorithm, one can finally generate a search tree with all multiple candidate realizations. And for our instance here, for our paradoxical DGP one instance, as I said, the number of realizations still keeps exponentially growing until reaching the last vertex in this kind of algorithm, and at most two realizations will be feasible in the end. The feasibility here means that all distances in the problem are satisfied. One example, actually one kind of buildup algorithm is the branch and prune algorithm, the one we will be using.
00:09:38.884 - 00:10:49.444, Speaker A: And for first introducing you to this algorithm, I would use the simplified cartoon here to describe it. So let's say we have four vertices in our instance and a predefined order. So starting from the gray to the purple, then to the yellow, then to the red one, and here in this first line I show you the expected solution of our instance. The branching part of the algorithm consists of starting from the current vertex and building the positions of the next ones up to the last. So starting from the first one, the gray one here, we use the distance to the second one to place the two possible positions of the second vertex. We do that again for placing the next two possible positions of the vertex tree, and so on up to the end. And this here is then the search tree showing all possible realizations of this instance.
00:10:49.444 - 00:11:59.976, Speaker A: In the end, of course, the search tree here we have to kind of project in one dimension because we are dealing with one dimensional problem. Okay, but the branching in the end, the main point is that the branching is used to build the search tree with all possible realizations. Now the pruning part of the algorithm is to use the later distance information to discard all wrong realizations. For example, let's check if this first vertex here is feasible or leads us to a feasible realization. For that, we check if the distance from this vertex to the first vertex corresponds to the actual distance we have in the definition of the graph. If not, we can just prune the whole tree or the whole branch that is connected to this last vertex position, and we do that again, for instance with this vertex and so on. So in the end we can discard all wrong realizations and have only at most these two solutions.
00:11:59.976 - 00:13:33.634, Speaker A: Here on the bottom one corresponds to the expected one and the other one to a symmetric image of it. More formally, the branch and prone algorithm algorithm works as follows. So for a paradoxical DgP one instance, I will write here. So we first initialize the position of the first vertex. We are taking it as the position at zero then we calculate the possible positions for all subsequent vertices by taking the position of the current vertex and summing it to a term that is the product of the distance information, and a constant sk which can take the values minus one or one, depending on whether the new vertex will be positioned to the left or to the right relative to the previous one. So the branching part of the algorithm will consists on computing two new positions for each preceding vertex position. As I showed you in the cartoon, the pruning part will be applied at the last layer, and there the last information distance information the distance between the first and the last vertex will be used to select only two solutions of the tree.
00:13:33.634 - 00:15:25.204, Speaker A: In our way of writing the algorithm here, we are actually uniformizing these two two steps, these branching and pruning parts, by including a virtual vertex, a virtual vertex with label n plus one, where n is the dimension of the problem and for which the distance from this virtual vertex to the last vertex is numerically equal to the distance between the first and the last vertex. With this way of writing the positions of the all the vertices, and so on, it's quite easy to check if the solution is feasible or not. We can just check if the position of the virtual vertex when it's reached in the algorithm coincides with the position of the first one. Now I will present the reformulation of the search algorithm in order, and this reformulation is important to construct our optical computing scheme. So let me first introduce you to the basic idea, recalling that we can compute the position of the vertex by taking the position of the previous vertex plus an additive term here relating distance and the constant sk we can collect. We can represent our candidate realization by collecting all the values skill corresponding to that realization. For instance, here in this vector I collected one realization where the first sk takes the value minus one, the second plus one, the third plus one as well, and so on.
00:15:25.204 - 00:17:17.158, Speaker A: And if we multiply this vector contained by a vector containing all the distances information in the problem, we actually get the position of the last, or not the last, but this virtual vertex, the vertex n plus one, right. So you can see here on the, on the right of this equation that we have the result of applying the first equation from the first to the last vertex, and this gives us the position of the virtual vertex. And then we can finally check the feasibility of the solution so we can collect all the possible. The idea here is that we can collect then all possible realizations at once by simply building a binary matrix that can collect all those s k vectors I showed you in the previous slide. In this matrix there will be thus one row for each possible realization, which means counting with the fictive vertex a total of two n rows and two n as the number of columns. There are n columns corresponding to each of the n vertices. For example, if we have only one vertex in the graph, the matrix, the binary matrix will contain only two elements, and when this minus one and one only, and when these two elements, this matrix is multiplied by the distance vector, which is a simple one element vector.
00:17:17.158 - 00:18:21.894, Speaker A: Here we get the two possible realizations, same for two vertices, the binary matrix will be larger. Now we'll have four rows representing each of the possible realizations and the multiplication with the distances vector will give us four possible realizations. If we look at these binary matrices here, we can note that there are patterns appearing on the first column. For example, there is a pattern whose cell has only the elements minus one and one, and it's repeated two times. On the second column there is a longer pattern and at least up to two vertices. It's repeated only once. So it seems that there's a pattern cell in each of the columns and the jth column we can look at we can see that the pattern length is two to the j.
00:18:21.894 - 00:20:30.614, Speaker A: If we keep doing that, increasing the size of the problem for three vertices and four vertices and so on, we see that still we can build a binary matrix the way I told you. And the realizations matrix vector will have all possible realizations and the binary matrix will still have these patterns appearing and the size of the pattern will be connected with the position of the column in the binary matrix. With that, I hope I could convince you that we can reformulate the algorithm to find in parallel all realizations of a paradoxical DGP instance by this realizations vector here, which is the product of a binary matrix and a distances vector. The distances vector collects all distances in the graph and the binary matrix can be built by taking advantage of that pattern I just showed you, which is summarized in this equation. And then we can use this realizations vector in the end to check very simply the feasibility of the candidate solutions by looking at each of the elements of r and checking if there is a new element equal to zero, remembering that we take the vertex position of the first vertex to be zero. Okay, in this last part of my talk I will show you how we can implement now this operation which is a matrix by vector multiplication using an optical setup. For that I have to show you how we can encode matrices and vectors using a light beam.
00:20:30.614 - 00:22:06.980, Speaker A: We are encoding it here using a transverse property of the light beam. That was shown also by Paolo in previous talk. If we look at the transverse plane of a light beam, we can see that there is a transverse intensity distribution that can be uniform or can have different patterns, like speckle pattern, or like a usual laser pattern, which is a gaussian gaussian distribution, or even more complicated, lager gaussian distribution, and so on. The point is that here is that we want to encode in this transverse intensity profile something that looks like a matrix. And the main advantage of using intensity distributions for this encoding is that we can easily detect it. We can just place a CCD camera here and we can record the intensity of the light beam. The device we use here for encoding this information is the spatial light modulator, which was introduced already by Paolo, and I then tried to go briefly over it again, just to explain a little more in detail how we finally get the encoding we need here.
00:22:06.980 - 00:23:18.202, Speaker A: So the spatial light modulator is, as Paulo said, LCD screen, the same as we have in our computers and so on. And we can easily program this screen to show the image we want. And this image that is displayed in the s and m surface will be used to control the light beam in each pixel of the display. Then there's a liquid crystal cell. And the way this device works is that the incoming light will enter the liquid crystal cell, and the refractive index of this liquid crystal can be controlled by the gray level of it. And the refractive index then can be changed pixel by pixel. And the light coming in then will, inside the pixel, it will propagate at a different speed and have a different wavelength, and then it will be reflected in the back surface of the pixel.
00:23:18.202 - 00:24:25.422, Speaker A: And then when the light leaves the cell, the outgoing wave will not have necessarily the same phase as it had when it came in. And the amount of the dephasing can be determined by this gray level of each pixel, because we can control the refractive index, as I said, therefore, we can spatially modulate the phase of the wave coming, or the light wave coming to the SLM surface. Okay, okay. I explained then how we can spatially modulate the phase, but I said that in the end, we want to spatially modulate the intensity of the light beam. So how we can get from one thing to the other. The point is that the action of the SLN depends on the polarization, as Paul said. So let's say the SLN affects only age polarized light.
00:24:25.422 - 00:24:38.402, Speaker A: Oh, sorry, you don't see my screen correctly, I think. Okay, yeah, you don't see the waves, right. Can someone tell me if you are seeing.
00:24:38.538 - 00:24:39.170, Speaker B: No.
00:24:39.322 - 00:24:41.442, Speaker A: A wave like thing? No. Okay.
00:24:41.538 - 00:24:42.174, Speaker B: No.
00:24:42.714 - 00:25:54.628, Speaker A: Yeah, doesn't matter. The point is, if the SLM is affecting only horizontally polarized light, let's say, then the outgoing wave will be defaced relative to the incoming, the way I show here on the right side. Only if the light is h polarized, so polarized in the horizontal direction. If we send instead of h polarized light, we send vertically polarized light, then there will be no dephasing. So imagine that the red curve here, the outgoing wave will be exactly in phase with the yellow one. Now if we use diagonally polarized light instead, which is a light that has half of its intensity in h polarization and half of its intensity in depolarization, while those two polarizations are in phase, those two components are in phase. Well, now let's take this depolarized light and send to the SLM.
00:25:54.628 - 00:27:02.194, Speaker A: This means that only the horizontal component will be affected and will show this dephasing and the vertical one won't be. So in the end, the net effect is that there will be a dephasing on the outgoing light. There will be a dephasing between the h polarized component and the vertical component, which means that the polarization state of the outgoing light is not diagonal anymore, it's something different. The point then is that if we project the depolarization, ah, okay, this graph appeared here, so that that would be the, the phase, like the phase of the two components of the outgoing field. Okay, so you see that the a h component with this, I forgot the name. Okay, the h component and the v component will be the phase that I just mentioned. And the polarization state is not diagonal anymore, it's something else.
00:27:02.194 - 00:28:35.132, Speaker A: But if we project in the end or filter the deep component, the diagonal component of the outgoing wave, this will be transferred to the intensity of the field of the light beam. And that's how we do it. So here it's a quick overview of the experimental setup for preparing that we propose, right, for preparing the vectors and matrices. Then here you see, we send diagonally polarized light to an SLN and then we use these two elements here to project the polarization, which means in the end that we filter only the diagonal component of the beam coming to these elements and projected to the horizontal direction. But yeah, we don't need to understand the details of these objects, just that we filter the, the diagonal component of the beam coming to it. Okay, so the first 1st, we have uniformly distributed distribution of the intensity and diagonal polarization. And then we send the wave or the light beam to the SLM where we have, and we encode a matrix in this gray level.
00:28:35.132 - 00:29:48.244, Speaker A: So each of the cells in this gray level image will correspond to the matrix elements. And then after interacting with the SLM, we have this spatial modulation of the polarization. So in each of the cells there will be a different polarization state, different from the diagonal one was in the input. After filtering the polarization, then we have this distribution transferred to the spatial modulation of the intensity of the beam. And that's how we encode these matrices and vectors in the spatial distribution of the light. The whole processing of our scheme will be shown here in this slide, and I'll just go slowly, build slowly to them to that. So first we prepare a vector which will correspond to our distances vector.
00:29:48.244 - 00:31:14.332, Speaker A: And here you see that we have those elements, right, the depolarized light coming to an SLM where we have grayscale representing our vector and the filtering of the polarization to transfer to the intensity profile. So you see that the intensity profile will directly correspond to the mask applied to the SLM. The reason why I use these stripes here for encoding the vector will be clear in a moment. Okay, so next we project the vector that had horizontal polarization to diagonal polarization again, so we can implement the next operation, which will be multiplying this vector by a matrix. We do that by sending the light to the next SLM where matrix elements will be encoded. These matrix elements are the binary matrix in our algorithm. The lens here, I haven't told you about that yet, but the lens here, it's placed in a way that we can image very well the light between these two planes, the planes of SLM one and SLM two.
00:31:14.332 - 00:32:28.968, Speaker A: This is important so we can ensure a nice spatial overlap between the two masks. And this is really relevant because the sequence, the fact that we are applying this sequence of two snlms means that the net effect will be a multiplication of the elements of the mask one and the mask two, which in the end means that we are taking each element of the distances vector and multiplying by, by each element of the matrices. Matri, the binary matrix, right. And that's why it's important to have these stripes on the mask representing the vector. So we can have all elements in the first column of the binary matrix multiplied by the first element in the vector and so on. Now there is still one operation that is missing to complete the matrix by vector multiplication. And this is the accumulation of the elements along a line of this matrix.
00:32:28.968 - 00:33:15.444, Speaker A: Right. So for performing this operation. Oh, sorry, it's also missing here. Sorry guys, there it is. Okay, so for performing this operation, we employ here a cylindrical lens, which is a lens that focuses only along one direction. So you see here that we place it in a way that it will be do exactly what we want, which means we'll accumulate, will focus along the direction of a line of this matrix, of the binary matrix. And that's how we perform the accumulation operation of the matrix, by vector multiplication.
00:33:15.444 - 00:34:23.584, Speaker A: And in the end, we detect the signal using a CCD, as I told you in the beginning. And the detected signal has then cells representing each element of their realizations. Vector of the paradoxical DGP, one instance corresponding to the matrix, to the binary matrix, and the distances vector that were programmed in the slMs. Right. To check the feasibility of each of these possible realizations, we check simply the intensity of the pixels. If any of these pixels has the intensity comparable with the reference intensity value corresponding to the position of the first vertex, then fine, we have feasible solutions. If not, if we don't find any pixel with this reference value in the end, then this means that our DGP instance has no feasible solution.
00:34:23.584 - 00:35:44.770, Speaker A: Okay, so to finish, I just wanted to discuss a little bit the performance we expect to achieve in our proposed optical scheme, and a figure of merit for evaluating the quality, let's say, of a processing unit, is the number of Mac operations it can do by per second. So here, by taking into account a usual SLM display size and the refreshing rate, or how fast we can change the face mask in the SLN and so on, we can compute this figure of merit to be 0.1 tops. There are other approaches to do processing with light using a photonic chip, which can reach two tops. But this is for actually for a much smaller matrix than the one we consider here. And it's a different approach. And if we take this very good cpu, it can reach 2.6
00:35:44.770 - 00:37:04.014, Speaker A: tops. Of course, this depends also on the kind of operation you're doing, the precision and so on, but I don't know much details about that there. Of course, we have also to take into account possible limitations of our scheme. One of them was already discussed by Paulo previously. That is, the noise level of the light and the electronic signal and so on, that can introduce noise in this, this final detected image. And that can make a little more difficult to recognize it, recognize if there are feasible solutions or not. Other limitations are of course, technical limitations of the way we are using the way we are encoding the matrices and vectors, which is the SLN limits, right? So the speed at which it works and the resolution, the number of pixels that there are available in the SLN screen, they can limit the performance of our scheme, right.
00:37:04.014 - 00:38:59.032, Speaker A: These two parameters here are actually, they can be improved. I took, as I said, for calculating our tops, I took typical SLN, but they are larger slms with higher resolution, and which can improve by four times this operation speed. And by taking faster slms that can work ten times faster as the one I considered here, we can also improve the number of operations per second. However, there are also very nice, let's say there are advantages in our optical scheme here that I have to mention as well. It's not only limited in one side, but there are also very nice possibilities to speeding up our scheme, as I said before, just by taking larger and faster slms, but also because we can split these matrices and vectors if they are larger than our SLM screen, for instance, and we can compute the realizations vector for each of these parts in parallel by simply splitting the matrix, the whole matrix mask in different slms and doing these operations in parallel. So there's other way to speed up our approach. Another way would be to take an alternative manner to modulate the matrices, the light beam.
00:38:59.032 - 00:40:27.042, Speaker A: Instead of using slms to encode the matrices and vectors, one could use a different and maybe faster, maybe more powerful way to modulate the light beam and still use the same general idea of our approach. But just replacing, let's say, one basic, one unit in our, in the optical setup, I showed that would be the SLN. Another step we can still, I mean, still with these limitations and the possibilities to speed up, we can address NP hard problems with our optical scheme, which is quite nice. And the next steps of our work would be to really simulate how the results would look like in a CCD, as done for a different problem here in this paper. And we can also, we also want to do that in the lab and compare the performance of our scheme in an experimental way and a simulated way. Okay. By the way, this work here that I cite is one of our inspirations to do this reformulation of the problem.
00:40:27.042 - 00:41:56.594, Speaker A: They actually tackle a different heart problem. It's not DGP, it's a traveling salesman problem. It's also an NP hard. And they do a reformulation of the problem using matrices and use an optical scheme completely different to ours using slms, but completely different. Okay, so to sum up, I defined a subclass of DGP problems we want to solve using our optical scheme, the paradoxical DGP one instance, and this problem, we reformulate an algorithm to solve it using a matrix by vector multiplication, and we perform, where we propose to perform the necessary operations by using an optical scheme based on slms and polarization projection. With that, I just want to acknowledge my working group in Floyd, Annapolis, the very nice island that Paulo advertised earlier, and thank our institutions, my university, my home university, and the University of Rennes, from our collaborators and all our funding agencies, and thank you all for your attention.
00:41:58.174 - 00:42:05.234, Speaker B: Thank you very much, Nara, for this nice presentation. Are there any questions from the audience?
00:42:06.884 - 00:42:38.564, Speaker C: Just a comment. You mentioned alternative SLN, and one simple alternative could be, instead of using only SK plus minus one, you can use a sequence of this, like plus minus two, plus minus three, and so on. And this way you increase the space of possibilities.
00:42:40.784 - 00:42:53.044, Speaker A: Okay, you mean like collecting several of these indices together or really taking different values for it?
00:42:54.624 - 00:43:22.034, Speaker C: I'm not sure that I answer you, but by doing what I suggest, you simply use a different and richer phase modulation. And if the phase modulation is having bigger range, you increase the number of possibilities.
00:43:25.514 - 00:43:26.458, Speaker A: Okay?
00:43:26.626 - 00:43:55.604, Speaker C: So that means you will generate new patterns, but repetitive patterns. And the beautiful aspect of your work is the capacity to take simple mathematical thinking and implementing it in experiments. I admire this, it's fascinating, and thank you so much for it.
00:43:55.984 - 00:43:56.952, Speaker A: Okay, thank you.
00:43:57.008 - 00:43:57.764, Speaker C: Amazing.
00:43:59.104 - 00:44:10.844, Speaker A: Thank you. It was a joint effort from all of us, and it was nice to see it coming into shape. Actually.
00:44:13.584 - 00:44:19.944, Speaker C: Your work brings many other new ideas, but that's for a different time.
00:44:20.644 - 00:44:23.024, Speaker A: Okay, thanks.
00:44:24.164 - 00:44:33.384, Speaker B: Other questions, Nara, when we will have the real experiment?
00:44:36.204 - 00:45:01.680, Speaker A: Well, we should do that as soon as possible, right? I mean, we have the whole idea and we know how to build the masks. That's. I mean, building the mask in the lab is quite easy. The point is to know which mask you have to build. Right. To address the problem you want to solve. And that we have now as well.
00:45:01.680 - 00:45:05.084, Speaker A: So we have the recipe. We should do that.
00:45:05.904 - 00:45:19.874, Speaker B: Yeah. Yeah. So if I'll be organizing something, I will consider you for a talk in case, you know, to. In case of the experiment will be ready. Yeah, it would be very interesting to see.
00:45:20.374 - 00:45:24.158, Speaker D: Tony, can I make a comment?
00:45:24.326 - 00:45:25.158, Speaker B: Yes, of course.
00:45:25.246 - 00:46:35.774, Speaker D: I was about to comment on the experiment. So, yes, we are planning to realize the. An experimental version, at least, preliminary one, very soon. And one point that is interesting is for a real world implementation, there are some choices that we should do. So, for instance, one choice is if we use a laser source, or if we use ordinary thermal light, which for a specific application can be interesting as well. But anyway, it seems that we have all that we need in terms of resource to realize our first version of this. I think then we can actually measure the effects of noise and limits in terms of intensity, etcetera.

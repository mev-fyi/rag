00:00:03.480 - 00:02:07.290, Speaker A: Thank you, Samitra. To continue and discuss further about kernels, I need to address an issue about convergence. When we have, say, Hilbert space, I mean it is the same if you are in Banneker space and a collection of families of family of function hs, where our parameter s is not necessarily accountable set. What do you mean by h equal sum hs s in our set s? Understanding the meaning of this is important even if s is countable. It's a type of convergence which is called unconditional convergence. And even before giving the definition to highlight in the countable setting, it's important to understand the meaning and consider these examples. Even for scalars, sum of minus one to the power n over n n from one to infinity.
00:02:07.290 - 00:03:22.744, Speaker A: This is something that we study in analysis calculus or analysis one. And when using methods like Leibniz method, we can show that it is, I mean convergent. And I mean you can obtain an estimation for its value based on the definition I want to give today. And sum n from one to infinity is not the right notation. I should write sum n to n, where n is the natural number minus one to the n over n is not converged. And you may say that, oh, it's true, because it's not absolutely convergent. But it's more than that.
00:03:22.744 - 00:04:20.564, Speaker A: It's more than that. Unconditional convergence is even stronger than absolute convergence. When it's clear for you, I can give you examples of even sequences which are absolutely convergent, but not unconditionally convergent. It's a very important topic in Banach space theory. We saw a version of this when we studied a positive quantities. I mean, hs here was a positive real number, and I gave a meaning to this back to three weeks ago. But now hs is a function in Hilbert space, or even in abstract setting, an element of a Banach space.
00:04:20.564 - 00:06:01.174, Speaker A: Here is the definition, again, a type of epsilon delta definition, which people do not like, but it's the key. And when you get used to this, you see that that's really the key point. And arriving at this definition has not been easy for the mathematician. It took many, many versions until they arrived at this format. So we say that f is equal to the sum of fs in some index space. S. If I use f or hmo, I use hiv, doesn't matter if for every epsilon there is a finite set f zero in s, a finite set of indices such that for any finite set s which is bigger than, sorry, f which is bigger than f zero, f zero is in f is in s.
00:06:01.174 - 00:07:22.034, Speaker A: For any finite set bigger than this f zero. Of course, f zero depends on epsilon. But after that the norm of f minus sum fs is in f. Not that there is no ambiguity about this sum, because it's a finite number of elements in our space is less than epsilon. So for any finite set, for every epsilon there is a finite set f zero, f zero epsilon such that say, after that, if you add any other finite number of elements, the difference is not that big stays less than epsilon. If this is the case, we say that the sum of s is unconditionally equal to f. In the case these quantities are positive.
00:07:22.034 - 00:08:51.064, Speaker A: Somehow we return to the classical setting, because if fs they are positive numbers, belongs to r plus, and sum of fs is finite, the way I define the bound, then we can conclude that the set of s such that f is not equal to zero is countable. We can index them as s one, s two, s three. So on the complement of this fs is identically equal to zero and set of s such that the sum of fs is actually the sum of FSI. The one we know from our studies of series is the same as before. And here the ordering is not important because everything is positive. That's for the positive. But if not positive, we need to be careful.
00:08:51.064 - 00:09:50.244, Speaker A: Many strange things may happen. The best way to treat unconditional convergence is to restrict to this definition. This is just a convergence in terms of maps. Yes, yes, it's a definition. I mean, the way I didn't mention the name net, but if you consider the family of fanatic with the inclusion, it's a net. And this is the same as again, I mean, I mentioned the name of Moore. This is the same as limit of this sum is equal to f, but limit not as a sequence, as a net.
00:09:50.244 - 00:11:09.934, Speaker A: True, if the way I define is equivalent to this sum of fs belongs to a finite state f. Call this, say x, which depends on f x index f is well defined because f is finite. And now if you find the lim over f of xf the way more defined for nets. This is precisely what I defined for or unconditional convergence. It's the same thing with, I mean, I use a different language, but it's the same things. It was the first. Yeah, the first talk today we talked about parcel identities.
00:11:09.934 - 00:12:51.896, Speaker A: So if you are in Hilbert space age with es, s in s, an orthonormal basis, not necessarily a separable space. So s here is not accountable set, but for any h in the space age, Percival identity says that the norm of h squared is equal to absolute value. H inner product with es in this base h squared s in and for this, because everything is positive, we know that despite the fact that the sum could be a huge sum, huge in terms of a number of elements which are in it, and that number is not necessarily countable. But still, in this case we can say a countable number of them is not zero, and we can transform this sum into a regular sum that we have seen before. So there's less than j here. But there is another version that is also called parcel identity. Of this at least two more versions.
00:12:51.896 - 00:13:57.670, Speaker A: The first one is to use the polarization identity and conclude that for every, say, f and g, the inner product of f and g in h is equal to the sum s in s. F inner product with es, g inner product with esr and gain everything in h. It becomes a bit more sensitive here because the numbers here are no longer positive ones. These are complex numbers. So going from here to there, even though straightforward. But care is needed. And now we have to use the definition I mentioned because of not having positive number.
00:13:57.670 - 00:15:22.784, Speaker A: And the third one, which is still even more, way more careful, is to say that for any f or for any age, we can write h as this identity. So note that here we are in R plus, here we are in C, and here we are in h in R plus. We can go back to the standard or previous definition in C, and in particular in H. We need a new definition. The third one in h in particular means that the sum on the right side is unconditionally convergent to h. The meaning of this was was given above. A conclusion of this is the following theorem.
00:15:22.784 - 00:16:59.054, Speaker A: Well, let h be an Rkhs on omega with kernel. Okay. Then the way suppose that es s done and index set s is an orthan normal basis for h, then gives a formula for capital k, capital k at the point xy is given by sum s in s e s at point x, e s at point y bar. And. Well, the convergence is at each point. And we know the meaning of this convergence now. And indeed, when we look at the proof.
00:16:59.054 - 00:18:26.388, Speaker A: The proof is a consequence of this identity in age, which by itself is important. But it's not mentioned as a part of the proof, part of the theorem. I think it's important to include it as a result. That's why I say then this and ky is equal to the sum s in sesy bar es for this. This is a convergence in C, but this is a convergence in h. Both unconditional convergence, the way we defined it and indeed, I proved the second one first and used the second one to obtain the first one. Proof based on the explanation above is very easy for every we saw that for every h in h, indeed h is equal to the sum s in s.
00:18:26.388 - 00:19:50.564, Speaker A: That's the meaning of having an orthanormal basis. We have this since p's is an orthonormal basis, it's a consequence of, I mean, it's hidden in the definition of basis. And even we can say that this is one, one of the partial identities. So now replace h by k one h equal to ky. So ky is equal to sum s in s k y e s e s, which easily seem to be es inner product with ky bar. Yes, and any function in a product with ky is the value of this function at point y. So the sum s is in s.
00:19:50.564 - 00:21:16.224, Speaker A: This function evaluated at point y and there is a bar and the convergence is unconditional convergence. Convergence is in H. We know that when we have convergence in h, it implies point wise convergence. This is one of the easy result that we saw, I mean, before the break in terms of the sequences. But it also works for this setting. So this immediately, I mean, the fact that ky is equal to the sum esy bar es immediately implies that for every x k y at point x is also equal to the coefficient. And this function evaluated at point x and this is, we wanted to prove, that's the end of proof.
00:21:16.224 - 00:22:49.234, Speaker A: And the then it's added in the book that we can use this formula. This is equal to k of x y. We can use this formula to obtain kernel in the examples we saw before, in four examples of sublux spaces, and then some analytic functional spaces, and even in the Perliviner space, in some of them we already know an orthonormal basis. For example in h two it's separable. Instead of es, I write en e n of z equal to zn n bigger than or equal to zero. We know that en zero is an orthonormal basis for h two, even though we found already the kernel, but that another way to do it based on the previous result. So we can conclude that k at point zw instead of x and y, I use x and w, they are a complex number is the sum.
00:22:49.234 - 00:24:03.324, Speaker A: Let me write n in n en at the point z en at point w bar. So the sum n is in n z and w in bar, so z w bar n. Up to here is the sum the way I defined about the unconditional convergence that we saw. But zw bar in absolute value is less than one, and this sum is equal to the sum we had before the traditional one. Just because of this, it's unconditionally and even absolutely convergence. I mentioned both because these are not the same in this context. They coincide.
00:24:03.324 - 00:24:53.218, Speaker A: It's absolutely convergent, is unconditionally convergent. So these two notions coincide. And instead of sum n is in n, I can write some n from zero to infinity which is equal to one over one minus zwar. We saw this and call it cucije code. Just let me modify one thing. And I think here instead of n, I better to write n not because n is usually one to three, not included zero. But when we write n, not zero, is just matter of notation.
00:24:53.218 - 00:26:16.368, Speaker A: So this is a good way to find the kernel for the hardy space. There is an attempt in the book which, I mean, I do not agree with that, but I explain what it says. To find the kernel of the first space we studied, it was this one h function f from zero one to r such that f is absolutely continuous. F prime is in l two and boundary condition called one. We found the kernel by using distribution theory. Sheldon provided a PDF file explaining how to use very neat elementary method to find it. And here is another method which eventually gives a formula.
00:26:16.368 - 00:26:58.784, Speaker A: But I mean, it's a kind of delicate. At the end we'll see why. But the first step is to find an orthonormal basis if we want to use the formula. So what is an orthonormal basis for hook? Remember, the inner product f and g in h is integral from zero to one f prime x g prime x. I mean, we don't need bar here. Everything is real. But in complex setting, you should put a bar there too.
00:26:58.784 - 00:27:46.024, Speaker A: In l two, either l two of t or l two of zero to PI. So some preparation. L two of t or l two of zero to PI. We know the basis it's e to the I n theta n in z. And if you want to consider the real case, these are for the complex case. Uh, by using euler formula e to the I theta is cos theta plus I sine theta. We see that this is constant one.
00:27:46.024 - 00:28:29.762, Speaker A: Then sine n theta and cosine n theta n bigger than or equal to one. I didn't put zero because the normalizing coefficients are different. These are orthogonal, but not normal. If you want to normalize, you have to add some coefficients. I mean, alpha zero. Here alpha, I mean, yeah, alpha and here beta, you can, you can find alpha and beta n such that this is orthon normal. But the important thing here is combination n theta with cosine sine and the coefficient.
00:28:29.762 - 00:29:42.564, Speaker A: If we change the scale which I need here, and consider l two of zero one, then my basis is still the constant remains constant, but sine becomes two PI n theta. Because I mean I replace zero two PI by zero one. It's a change of scale. And cosine n two PI n theta n bigger than one. This is orthogonal. And if you want to normalize again, I mean you put, it's not the same as above, it's different, but still we can call it alpha n beta n to obtain an orthonormal basis. Now if we start with elements in this space, the original one fn, then fn and gn for the inner product, it's integral of fn prime gn prime.
00:29:42.564 - 00:31:04.126, Speaker A: So our f at gn should be such that the prime is equal to this, to have something orthogonal and then normalized to be orthogonal. So I should look for the solution of egret prime equal to one prime equal to sine, two PI n theta and prime equal to cosine two PI n theta to obtain elements in the space, the original space, which are orthogonal together. The solution of this is a constant here. The solution of this one is one over two in well cos two PI and theta with a minus plus another constant here. And with the other one it is y equal to one over two PI n sine two PI n theta plus c. The constants are not necessarily the same. I just wrote c all the time.
00:31:04.126 - 00:31:54.064, Speaker A: And remember, that's the solution of the equation. At the same time, I want to have y one equal to y zero equal to zero. We have some boundary values, so this kills the first opportunity. No constant, the constant should be identically zero. And then we can you find the constant here and the constant such that these are satisfies very easy, just plug in and you see that the solutions are here. I mean I look at the book and copy paste. The first solution is cosine dou p and theta minus one.
00:31:54.064 - 00:32:34.660, Speaker A: That's the function which is orthogonal to the function just sine two p n theta. And if you want to normalize it, the factor is one over root two PI n, and here one over root two PI n. And the authors call this cnt. And this is sn. That's very good. So we obtain n bigger than or equal to one. So these are in space h and they form an orthonormal sequence.
00:32:34.660 - 00:33:25.658, Speaker A: This is now very easy. To prove, because when you take the derivative of this one, you immediately obtain what we had before. And in interval zero one, these are sequences which are orthogonal coefficients in front are adjusted such that the norm is equal to one. So it's normalized too. And why is it complete? I used this technique before. Just start with the assumption f being orthogonal to Cn being orthogonal to sn, and do a little bit of calculation, very straightforward to deduce that f is identically zero. So it's more than being an orthonormal sequence.
00:33:25.658 - 00:34:19.398, Speaker A: Indeed, it's an orthonormal basis. So that's good. Up to here, I obtain an orthonormal basis for my space h. I didn't know when I studied this space, I didn't find this orthonormal basis. But knowing this, now we can say that therefore k at point x and y is equal to the sum. Let me call it en for the time being, en at point x. En at point y bar is not needed because everything is real and the summation is over n.
00:34:19.398 - 00:35:52.074, Speaker A: And we have two types of en here, either Cn or sn. So it's sum in from one to infinity c and x cny plus snx sny. And I note that the convergence is good and I can plug and do the summation. And if you look at the page 20 of the book, I mean, after some calculation there is a typo, which is not important, but after some calculations, they obtain the summation over n cosine two PI n x minus y minus cosine two PI n x minus cosine two PI ny plus one divided by two PI squared n squared. Up to here, there's absolutely no problem. We have series of complex number real numbers. They behave well.
00:35:52.074 - 00:37:03.906, Speaker A: And then I do not see, absolutely do not see how from here we can conclude this is equal to one minus y x if x is less than or equal to y, and y times one minus x if x is bigger than or equal to one. This is the way written on page 20. And as I said, there is no mathematical error in this. Even up to this point, everything is straightforward. Just going from this step to this. This is the part I do not see, of course, backward. It's easy, because if this function is given, I mean, if this is given, this function, if this is given, and they ask, find the Fourier series of this.
00:37:03.906 - 00:37:47.994, Speaker A: Going from here to there is a straightforward, because you have explicit formula for the four year series. But the other way around, I mean, coming from the four year series to the function I do not know how to do it. If you have a remedy shortcut to do this, please, please let me know. Well, I think it finishes our course today. If there is no question, I have a comment to make about next week. Is there any question? You may stop sharing. Symmetra, please.

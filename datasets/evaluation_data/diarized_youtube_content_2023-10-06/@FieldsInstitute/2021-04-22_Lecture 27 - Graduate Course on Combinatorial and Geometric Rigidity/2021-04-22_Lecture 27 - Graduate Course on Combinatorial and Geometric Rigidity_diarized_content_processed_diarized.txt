00:00:00.200 - 00:01:00.342, Speaker A: To be talking about symmetry, forced rigidity and the idea, or just let's look at an example. Oops. All right, so here's a graph, and it is symmetric with respect to the group that's generated by an order for rotation. And so what I mean by that, right, is if you rotate this 90 degrees, it will look the same. Now, it's a graph in the plane. If you just use Lamond's theorem or pulchat Geiringer's theorem, you'll see just from counting edges and stuff that this is flexible. And the flex that you do to this, it just sort of comes from like shearing, shearing, sort of this outer square.
00:01:00.342 - 00:02:53.058, Speaker A: But you'll notice that if you were to do that, apply that flex, you would break the symmetry. So, yeah, we're in the symmetry force setting. So this graph is flexible, but not symmetry force flexible. And last time, Tony talked about gain graphs and quotient graphs and how to represent a symmetric graph with a gain graph. And so just to sort of briefly review, you know, we can express the above graph as a gain graph, you know, and we'll let I a squared, a cubed be the symmetry group. So one gain graph representation would be following, um, where. So, you know, and you all did this yesterday.
00:02:53.058 - 00:03:54.034, Speaker A: So I'll be sort of in brief and informal with this. But, um, this vertex of the gain graph corresponds to this vertex orbit in the symmetric graph itself. And then the other vertex in the gain graph corresponds to the other vertex orbit. The two loop edges correspond to the fact that you have edges that stay within each of the orbits. And the label on them just corresponds to what element of the group you apply in order to get the other vertex of that. And this identity edge corresponds to the edges going between your vertex orbits. So, yeah, I mean, does this all make sense? Are people comfortable more or less, with going between gain graphs and symmetric graphs? If not, let me know.
00:03:54.034 - 00:05:04.254, Speaker A: Okay. All right. So if people are okay with that, then I will continue. And yet, I guess Tony also talked about using gain graphs to represent not just symmetric graphs, but symmetric frameworks. And so I'll just sort of take that for granted that you understand this. So the motivating question for this lecture is going to be the following. You know, for a fixed rotation subgroup of planar euclidean isometries, and I'll call this subgroup s, which s gain graphs are generically symmetry force rigid.
00:05:04.254 - 00:05:48.404, Speaker A: All right, so is the question clear? All right, I will take silence as a yes. Um, so, yeah, in the above one, where the question is, is the gain graph rigid. That was shown that the, you said above that the original graph is also symmetry force. Oh, it's symmetry force flexible. Okay. The above graph is symmetry forced rigid. It's flexible if you, if you don't force symmetry, but it's, it's symmetry, force, rigid.
00:05:48.404 - 00:06:23.770, Speaker A: The gain graph or the original one? Both. Yeah, I guess this is what I mean. So, corresponding to every gain graph, you have a bunch of infinitely many generic symmetric frameworks. And then the question is, are those generic symmetric frameworks? Symmetry force, rigid? Does that make sense? Yeah. Okay. Okay, cool, cool. All right.
00:06:23.770 - 00:08:35.962, Speaker A: And so I'm going to take sort of an algebraic perspective on this, and this is going to be the same kind of perspective I took in the last lecture I gave in this course. And so let's recall. Sorry, sorry. Before I get there, I'm getting a little ahead of myself. So, yeah, just some notation, you know, I'll use, you know, c to the e, r to the e to denote vector spaces whose coordinates are indexed by e, where e is a set, usually the edge set of a graph or the arc set of a gain graph. And then if f from, say, I guess, any field, you know, k to the, say, d to k to the e is a polynomial map. I'm going to let j of f is the matrix whose rows are given by differentiating tia ting the component functions of f.
00:08:35.962 - 00:10:50.526, Speaker A: Right? So, you know, you've seen this 100 times in this rigidity context, where usually f is just going to be the polynomial given by a bunch of pairwise distances between endpoints and d dimensions. And then the Jacobian of that is this rigidity matrix. And then. Yeah, so more specifically. Sorry, one, one last, one last definition. And I'll say m of f is the matriid of linear independence of the rows of j of f. All right? And so, for example, if dij is just equal to, say, xi minus xj squared, where, you know, each xi is just a vector of indeterminants, then as we let ij range from one to nice, then this is a polynomial map from, say, r to the dn to r to the n.
00:10:50.526 - 00:12:45.064, Speaker A: Choose two, and m of this map is the rigidity metroid, the d dimensional rigidity metroid. Okay. All right. And then just to. I know this is, you know, probably all review, but just since I'm going to sort of, kind of generalize this picture a bit, I just want to be a little pedantic about this. Okay, so I'll let die g be the polynomial map from r to the I'm gonna, I'm gonna, we're gonna eventually stick to the plane, so I might as well just do that now. Yeah, I'm just gonna let d to the g be this map that sends a point x one dot dot xn y one dot a dot yn to the vector xi minus xj squared plus yi minus yj squared over all edges ij of g.
00:12:45.064 - 00:14:25.610, Speaker A: Okay? And we know that g is rigid if and only if the rank of the Jacobian of d to the g is equal to the rank of the Jacobian of the, of d to the complete graph. Okay? And then in other words, g or the edge set of gift is a spanning set in the matriid of this map for the complete graph. Okay? So hopefully all this is review. And now I just want to adapt this to the symmetry for setting so that we get some good sort of concrete language and tools for talking about rigidity in the symmetry force setting. Oh yeah. Are there any questions about that? Is all that clear? Okay, so now let's add symmetry to this picture. Um, now all of this of course is more generally works for dimensions other than two.
00:14:25.610 - 00:16:26.982, Speaker A: But I, I'm just going to talk about dimension two for simplicity sake. So, because that's what I want to present a theorem on. So, okay, let s be a subgroup of the planar euclidean isometries and I'm going to let kns be the complete gain graph on n vertices. And what I mean by this is that kn has order of s arcs from I to j, each labeled by distinct element by a distinct element of s. And also we're going to have cardinality of s minus one loops at each vertex for each non identity. And I'll show, so for example, so k two of z two is going to be this gain graph. So this is vertex one, this is vertex two.
00:16:26.982 - 00:17:57.470, Speaker A: I'm going to have two arcs going from one to two and one arc or one loop at each vertex. I'm going to label the arcs between vertices by the distinct elements of the group and then the loops by the non identity elements of the group. Okay, and then one other definition I need for each arc e of kns, define d of e to be the following polynomial. It's going to be the norm, the norm squared of x. And I'm going to use, I'm going to define this notation in a second. X at s of the source of e, y of the source of e minus phi of e applied to x, target of e y, target of e. Oops, I'm sorry, sorry.
00:17:57.470 - 00:20:33.324, Speaker A: That should be phi of e squared, where phi of e is the gain of e. So of e is the source of e, and then ta of e is the target of e. Okay, and then, so, right, since phi of e is the gain of e, e is an edge in a gain graph with gain group s, and s is a group of planar euclidean isometries. You can think of phi of e as just a two by two matrix. So this, hopefully this makes sense. Yeah, are there questions about that? Does de make sense? Okay, so, and then finally, given this, you know, for a gain graph g, I'm going to define d to the g to be the polynomial map from r to the, to n to r to the arc set of g to be the polynomial function where the component corresponding to e is d, sub e. Okay, so I have this polynomial d of e that I can associate to any edge of any gain graph with gain group s.
00:20:33.324 - 00:22:31.692, Speaker A: I'll fix a gain graph g, and then I get this polynomial map just by having for every edge, I just take that function. And so you should think about this as analogous to the map that you would apply to a graph like in the rigidity setting, where every edge corresponds to a pairwise distance between two points. Now it's basically the same, except every edge corresponds to the pairwise distance between one point, the source of your arc, and then another point, which is obtained by applying the gain label of that arc to the target of it. Okay, and so the point of introducing all this is to remind you of this theorem of Schultze and Whiteley, which is that g is generically symmetry force rigid, if and only if the rank of the jacobian of j. Sorry, the rank of the jacobian of d to the g is equal to the rank of the jacobian of d kn of s. Okay? Right. And this is the, you get exactly the familiar situation in the non symmetric setting when you just take your group to be the trivial group.
00:22:31.692 - 00:24:34.154, Speaker A: This just says that a graph is rigid if and only if the rank of the jacobian of this distance map is the same as the rank of the distance map for the complete graph. Okay, so with this in mind, oops, I'll now rephrase the initial motivating question as follows. You know, for a fixed group s of planar, euclidean isometries characterize the algebraic metroid of d kn of s, or equivalently characterize g such that the rank of the jacobian of d to the g is equal to the rank of the jacobian of d to the kn of s. Whoops. All right. So, hopefully the question is clear. I'll get into now how we'll be able to solve this for the case that s is a group of rotations.
00:24:34.154 - 00:26:17.034, Speaker A: And in order to do that, I need the following definition, which I actually introduced the last time I gave a lecture in this course to give you the Lobosch and Yamini theorem. So, let f from two to the e to z be an increasing submodular function. In other words, if a is a subset of b, f of a is less than or equal to f of b. That's the increasing part. And two f of a union b plus f of a intersect, b is less than or equal to f of a plus f of b. Then define m of f to be the matriid where I is independent if and only if for all subsets I prime of I, I is empty, or the cardinality of I prime is less than or equal to f of I. Okay.
00:26:17.034 - 00:27:24.654, Speaker A: And yes, this does define a matroid. This is a theorem of Edmonds. Yeah. And again, I mentioned this in the previous lecture I gave, so this hopefully isn't a surprise. And the main example, which I presented last time I talked in this course, is that if, Richard, it's a function on the edge set of the complete graph, just ordinary graph, not gain graphs, to c is the rank function of kn's graphic matriid. Then the 2d rigidity matriid is m of two, r minus one. And this is essentially that Lovashi mean result.
00:27:24.654 - 00:28:25.944, Speaker A: Okay. And I'm reminding you of this because a very similar thing is going to be true for the symmetry force setting when a rotation group. Okay, so. And I'll. Okay, so, yeah, the punchline of this next whiteboard is basically going to be an analogous thing holds for symmetry, for rigidity, when s is a rotation group. In order to do that, I need to define you now the, the analog of the graphic matroid, but for gain graphs. And this is something that is very important in rigidity theory, for reasons that are way beyond the scope of this course.
00:28:25.944 - 00:30:13.404, Speaker A: But here's the definition. Let s be any group. The gain graphic matroid on kn of s is the metroid on ground set, the arcs of kn of s, wherein a graph arcs are said to be independent. Oops. If the graph has at most one cycle which is not balanced. Yeah. And I guess Tony went over what it means for a cycle and a gain graph to be balanced.
00:30:13.404 - 00:31:15.784, Speaker A: And just to give you an example, or two examples rather, or an example and a non example, let's say sz two. I'll give these gain labels, say 01101. Just doesn't really matter which way I orient this when z two is your group. But let's say I orient this in a cycle. Okay? So on the left here, this graph has exactly one cycle. And as you can see, it's not balanced because as I sort of walk around, as I do a closed loop, the gain I'm going to get is zero times one times one times one, which is one, or I guess, plus. However, this graph on the left, this is not independent.
00:31:15.784 - 00:33:20.154, Speaker A: So it also has one cycle, but that one cycle is balanced. Right? Because if I do that same close walk, the gain I'm going to get is one plus one plus one plus one, which is zero. So this is independent. This is dependent. Okay, and now finally, I can state this theorem. And this was proven independently in one paper by Malistine and Thoran, and then in a separate paper concurrently by Jordan Kas and Itsuki Itz and Tanigawa. And it says that if s is a rotation subgroup of euclidean isometries, then the metroid of d to the complete graph, the complete gain graph for s is equal to m of two, r minus one, where r is the rank function of the gain graphic matriid of kn of s.
00:33:20.154 - 00:33:47.774, Speaker A: All right, so are there any questions about that theorem? Is this d equals two or any d? Yes. D equals two. Yes. D equals two. Thank you. Yeah, euclidean planar. I'll put the word planar in there.
00:33:47.774 - 00:34:58.634, Speaker A: All right. And then, you know, in the remaining 25 minutes, I will sketch a proof. I guess I will prove this modulo one hard thing that I won't prove, but. Yeah, okay. So, yeah, how does the proof of this work? Well, okay, so I'm going to sketch for you a proof that is not what those original papers had done, but this actually appears in a recent paper of mine that sort of extends these techniques to prove something more general. But, yeah, so here's the idea. And the hard part that I'm not going to prove for you is the following.
00:34:58.634 - 00:36:25.474, Speaker A: So this is a theorem of mine, and it says the following. Let f and g be polynomial maps be in the complex setting, or, sorry. Let them be linear. Let f and g be linear functions. Let rf and rg be the rank functions of the algebraic metroids of f and g. Then the metroid of their product, which is a quadratic function, is just this matriid that you get from rf plus rg minus one. So does the theorem statement make sense? Notation is a little overloaded here.
00:36:25.474 - 00:36:52.360, Speaker A: Right. So over here, this is, this m on the left, this is the algebraic matriarch of f and g. This matrix on the right. This function on the right, is a. It's a function that's set valued. And this is the construction of Edmonds that takes a submodular function and constructs a matriid out of it. So this m notation is a little overloaded.
00:36:52.360 - 00:38:02.178, Speaker A: I hope that isn't confusing. Okay, so this is the part I'm not going to prove. Um, the proof, yeah, is in a recent paper of mine, and it uses tropical geometry, which is, of course, way outside of the scope of this particular course. Um, but here's an example application of it, and I consider the following change of variables. We'll say ti is equal to xi plus xj over two, and si is equal to. Sorry, not sorry, sorry. Ti is equal to xi plus yi over two, and si is equal to xi minus yi over two.
00:38:02.178 - 00:39:15.296, Speaker A: Square root of negative one. I don't want to overload I. Okay. And this I'm going to use again later, actually, in the proof of the symmetry force characterization. But if we just do this in the regular rigidity setting, then dij, which, you know, is equal to xi minus xj squared plus yi minus yj squared, just becomes ti minus tj times si minus sj. And then since the algebraic metroid of ti minus tj is equal to the algebraic matriid of si minus sj. Okay.
00:39:15.296 - 00:40:23.664, Speaker A: Where one less than or equal to I less than j less than or equal to n, one less than or equal to I less than equal to j. Sorry. Strictly less than is the graphic matriid of kn m of Dijon. One less than or equal to I less than j less than or equal to n is equal to m of two, r minus one, where r is the rank function of the graphic matriid. Okay, we saw this already. This is Lova Shimini. This is what I presented last time I spoke in this course, and it just follows from this theorem.
00:40:23.664 - 00:41:34.824, Speaker A: Now, we're going to do the same thing for, like, the same exact change of variables, gives you, like, exactly the analogous theorem in the symmetry force case when you're dealing with a rotation group. So, yeah, now let's continue on to the proof of the theorem of the symmetry, of the symmetry force theorem. So again, the same, the same change of variables are going to work. I just have to tell you, like, what the parameterization is that I'm changing variables of. So d of e is just going to be, you know, just by definition, x source of e over y, source of E. Okay, we're taking norms here. Minus phi of e times x, target of E.
00:41:34.824 - 00:42:51.254, Speaker A: Y, target of e squared. Now, since we're dealing with rotation groups, phi of E has a very special form, namely, this is just the following. It's just the matrix cosine of some angle, which I'll call theta of E. E negative sine of theta of E, sine theta of E, cosine theta of E. Again, applied to x, target of e y, target of e squared. Now, if I just write this out, bear with me, this is just kind of a mess. It's s source of e minus cosine phi of e x, target of e plus sine phi of E.
00:42:51.254 - 00:44:38.184, Speaker A: Y, target of e squared, plus y, source of e minus sine phi of E. X, target of E, plus cosine, theta of E. Y, target of e squared. Okay, so that's, that's just matrix multiplication. Then, applying the same change of variables from before gives that d of e is equal to t of the source of e minus. Okay? And here e is overloaded. Now, I just mean the number e e to the I theta of arc, e times the target, times t of the target of e, and then times s source of e minus e to the minus I theta of ey, target of e, not y.
00:44:38.184 - 00:46:50.992, Speaker A: Sorry, that should be s. So, we can now apply the theorem where we set f is the polynomial map t source of e minus e to the I theta e t target of e as e ranges over all arcs of the complete gain graph. And then g is similarly, you know, for the s part. But then this matriarch, the algebraic matriarch for f is equal to the algebraic metroid for gift is the gain graphic matriid on kn of s. And this is just sort of a basic matriarch theory fact. See, say, Oxley. And then this gives that the matriid of dkn of s is equal to the matriid of twice the rank function of this gain graphic matriid minus one.
00:46:50.992 - 00:48:29.494, Speaker A: Yeah. Where, where r is the rank function of the gain graphic matriid on kn of s. So, yeah, that's all I wanted to say for today, and I'm happy to take questions if there are any. So what happens for dihedral groups? Ah, yes. Where does it break? So the problem, okay, so what worked out really nicely in this case, actually, what worked out really nicely in this case is that when you apply this change of variables, the t and the s's sort of like separate into these two, like kind of disjoint linear forms or these two linear forms where, like, the t's and S's never cross. But if now e were orientation reversing the matrix, you would get. Would look like this, except you would just have a positive sign there.
00:48:29.494 - 00:49:01.502, Speaker A: And that messes everything up in the sense now that you would have your t here and your s here, sort of trade places. And so now sometimes you have your t's and s's together. Sometimes they are separate. And this is what messes things up for the dihedral case. You can't just cleanly separate your. Your polynomial that you're taking the Jacobian of into like a product of two linear forms. It's now, I mean, but like something similar can be done.
00:49:01.502 - 00:49:20.854, Speaker A: You. You can maybe think about having like this huge polynomial or this huge, like, thing of linear forms and you're just multiplying together like certain pairs of them. But yeah, you don't get this clean product of just. Yeah, linear polynomials.

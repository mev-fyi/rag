00:00:28.154 - 00:01:19.886, Speaker A: I provide two proofs for trolesky theorem. Both of them are good. I went for the second one because the one which is in book, and I couldn't see what's going on and trying to see what's going on. I mean, I came up with the second proof, which probably even sheds more light on the proof. So let's go with the proof which is provided in the book. Our goal is to show that the matrix pij minus pik pkj divided by pkk is positive. But recall that by assumption, pkk is strictly positive.
00:01:19.886 - 00:02:20.678, Speaker A: So this is equivalent to show that pij pk, we multiply by pkk is bigger than or equal to zero. So it's a matrix whose ij element qij is equal to this one. And this is equivalent to. I mean, our goal is to show that sum over I and j alpha I alpha j, and say, let's put bar on this, q I j bigger than or equal to zero for any alpha in Cn. We need to show this. This is a normal. How do we do that? Our assumption is that p is positive.
00:02:20.678 - 00:03:13.684, Speaker A: So assumption p is positive, which is we want to say that p and x is positive. Or if you wish, we, we can write it this way too. Sum ij from one up to n p I j p I j. I write later, xi bar xj. Pij is positive for every x in C. And we know this. This is our assumption.
00:03:13.684 - 00:04:26.234, Speaker A: So this is our assumption. And the idea in the proof is to choose a good choice, a good candidate for x, such that when we do the simplification, we obtain this one. Even at the very beginning, the components of x are given. And when we plug the component inside, we see that it works. I mean, xi are defined this way. Xi is equal to root of pk alpha I. If I is not equal to k and x k, it's minus one over root pkk, sum j from one up to n j not equal to k pkj.
00:04:26.234 - 00:05:25.336, Speaker A: And the rest is just calculation. It means that we plug xi here, x and x j there, and we simplify. And then after a few lines, we arrive at this. That's the whole story. I try to explain a little bit, but, and that's precisely the point when I said, I mean, why, why this choice where it does come from? And I try to understand this better. And that is why I came up with a second proof, which I show you later. Well, a little bit on the proof px and x, as we saw, is the sum I j from one to n x.
00:05:25.336 - 00:06:04.894, Speaker A: I bar x j p I j. And then we divide it into four groups. One group is just one element. Element, pkk, another one, the one which are above it or below it. Yet another group on the same row. And the rest, do they have any other color here? And the one which are here. That's the way we divide this sum into four sums.
00:06:04.894 - 00:07:14.234, Speaker A: So it's sum I, j from one up to n, I not equal to k, j not equal to k. Xi bar xj pij. This is our big sum. Then class, the another one is sum I from one to n, I not equal to k, same thing. So here I changes from one to n. So this is other one, plus the same thing with Jack. Did I write it correctly? There is one thing which I didn't write correctly, is this one.
00:07:14.234 - 00:08:09.194, Speaker A: Okay, we are on the column k. And then, so now we are on the row k. So x k bar xj, pkj. Here is this column. And finally, just one point plus x. K bar xk, pkk. It's just the green one, just one point.
00:08:09.194 - 00:08:50.690, Speaker A: So that's the way we divide our sum into four sums. Now, we know what is xi and xj in each case. And that is the reason we do this, because the formula for xi is different when I is equal to k. So here we know what to put for x k the same here, the same here and there, and for all other values, xj, xi bar or x j. Here I is not equal to k, j is not equal to k. And we use the other formula, this one. So everything is known.
00:08:50.690 - 00:09:37.044, Speaker A: The rest is just plugging. And when you plug, so I don't do the rest. Some calculation. And at the end, what you obtain is precisely some I and j from one up to n alpha, I bar alpha j q I j bigger than I call this simple calculation. And we obtain a result, q zero. End of the story. So it's quite straightforward proof, except that you don't know where this come from.
00:09:37.044 - 00:10:44.744, Speaker A: Where does this come from? And to do this, I give you another proof before proof remark. If you have a matrix s which is invertible, then matrix a is positive if and only if s star as is positive. Indeed, invertibility is needed here to have both sided. If s is not invertible, just a matrix s, then we have one direction. A positive implies that s star as is positive for any s. This is true. But the matrix I use here is invertible.
00:10:44.744 - 00:11:35.124, Speaker A: So we have both. And it's enough to give the proof for one direction. Because. Because if it is true for one direction, for example, for this one, then we simply multiply by ss minus one, s minus one from, from left and right, and we obtain the same. So, and the proof is very straightforward because s star as acting on x inner product with x is a sx. So it's like a y acting on y. When y is sx is in our space, whatever it is h.
00:11:35.124 - 00:13:07.134, Speaker A: And so if a is positive, then this is positive, and which implies that ss is positive. It's a very simple observation, and this observation is used in the second proof that I present here. We have the matrix p. Here is pkk, which is not zero. Some elements here and now try to multiply by a matrix such that, I mean, call this matrix s one such that if you do p s one, then the element here is zero, kind of linear operation. Of course, the elements on the which one I choose c one. PK.
00:13:07.134 - 00:13:48.328, Speaker A: The I one, sorry, not necessarily on this one. So here is PKK. I want to do some operation such that. Yeah, what I said is true. I want to make this elements here one by one to be equal to zero. But I do it one at the time, not everything in one one shot. So we have elements here.
00:13:48.328 - 00:14:37.924, Speaker A: I want to do an operation such that this element is zero. What is this one that you suggest? If I use the same notation that I use in a course I gave about two years ago. It's called introduction. It's very elementary analysis. The thing we do is that we replace the column one by column one minus the coefficient column k. This is not an identity in the language of mathematics. It's an identity in the language of computer programming.
00:14:37.924 - 00:15:36.034, Speaker A: So the new c one is the old c one minus eta times ck, and Eta is adjusted such that when we do the operation, the result here is equal to zero. And it's easy to see that it has to be c. One minus pk one divided by PKk Ck. That's the operation we need to do. And the matrix we have, we need s one. Is this matrix c 10 minus pk one when we multiply by this. No, it has to be here, sorry.
00:15:36.034 - 00:16:22.934, Speaker A: Minus pk one pkk here. Here is everything. Zero. And on the diagonal equal to one. Everywhere else equal to zero. So when you look at column two, column three up to column n, it's just e two, e three en. So when you multiply s one by p, column two doesn't change, column three doesn't change, and column n doesn't change, but column one changes.
00:16:22.934 - 00:18:00.482, Speaker A: Column one is one which is used here times column one minus this, eta times column k. And Eta is adjusted such that this, when we do the multiplication, the result here is equal to zero. So it's a matrix which is basically the identity matrix, except at one point we replace it by minus pk, one divided by pkk. And the question is that now if I do s one star ps one, what do I obtain? You should immediately see that. Note that when I multiply it from the right, I do operation on the columns of p. So naturally, when I multiply from the left, I do a similar operation, but on the rows of p. So when I do this, the result will be a matrix which is pkk, zero here, zero here, and of course the other elements here, they change.
00:18:00.482 - 00:19:02.964, Speaker A: I mean the elements here and here and here and here are changing because I do column one equal to column one minus a constant times column k and the same for row one, row one would be the same as row one minus another constant rho k. Everything else is remaining the same. True, it's just an operation. S one star times p, p times small is an operation that we do on P. And we do this operation just to obtain a zero here and a zero there. If you ask what are these new elements here, you have seen them before. We have seen them before.
00:19:02.964 - 00:20:20.806, Speaker A: These are precisely this element. But just for row one and column one do the operation, you'll see them. It's pij minus pik, pki divided by Pkk for. For I equal to one gives you the element here, and for j equal to one gives you the element true. And repeat this operation. Now with goal of on this matrix, find s two such that when you choose two star s two, the result is the matrix we had before, but now two zeros. And because of the zero which are we already created, these do not change.
00:20:20.806 - 00:21:18.614, Speaker A: These, that element that we had before, they remain the same. But we have a new set of elements. The one here, the one there and the one there. And they are again given by the same formula that we saw before. And repeat this for for all n minus one elements which are here to make zeros above, below, on the right and on the left side of PKK. And what you obtain at the end, if you repeat this operation and you call s equal to s one, s two, sn one, what you obtain is s star p. Almost the same matrix that we saw above.
00:21:18.614 - 00:22:31.278, Speaker A: It's almost this matrix, the one that we want, almost this one. Why I say almost? Because what we obtain at the end is a matrix that here is not zero pk remains in the previous matrix here is also equal to zero. All elements in this row and in this column are zero. Because of the operation we did, so zero here, and the rest is precisely what we are looking for. The elements here in all four corners are Pij minus Pik, pkj divided by pkk. So it's almost the matrix that we have before. And we know p implies that s star p's is positive.
00:22:31.278 - 00:23:14.412, Speaker A: So this matrix is positive. And if you remove a row and a column of the same order, here is row k and column k, what is remaining is still a positive matrix. So if you completely remove this and remove this, so pkk, you also remove it, you obtain a matrix which is n minus one by n minus one. And. And that matrix is positive, which is equivalent to what we wanted to do before. Because it is true that the previous matrix is n by n. This is n by n.
00:23:14.412 - 00:24:00.942, Speaker A: But everything in the case row and case column is equal to zero. So in practice, it's just n by n minus one by n minus one. So that's a proof that, I mean, I found, I mean, more instructive if you explain properly by, by this proof that we do elementary operation to make some element equal to zero. And what remains is what we saw about that's. I mean, I don't know if. Sheldon, do you agree with that? You are an expert in linear algebra? Yes. That's a very nice proof of the Cholesky theorem.
00:24:00.942 - 00:24:38.398, Speaker A: I like it a lot. Thank you. But I repeat, the only difference is that what remains at the end is PKK. But here it really doesn't matter. So we obtained something which is still a positive matrix. And this leads us to a theorem which is called trolexi factorization theorem. But how did we obtain this matrix? So this is important to recall.
00:24:38.398 - 00:25:10.476, Speaker A: So recall, we started with matrix p, but to obtain the matrix whose case column and case row both are equal to zero, we did this operation. We did p minus one over PKK. It's better to write CK. Still. I used K. My apology, Sheldon. This is my notes.
00:25:10.476 - 00:25:46.660, Speaker A: Ck for the K columns of p and c, K star. This is what we did above to obtain something which is positive. So that's the matrix whose case row and case column are equal to zero. We did this. And p we look at it. I try to change my notation later on. We look at p as.
00:25:46.660 - 00:26:46.100, Speaker A: As columns like this. So if we do p minus one over pkk, ck, ck, star, we obtain a matrix which is still positive. But practically, the new matrix is n minus one. By n minus one. And that's the beginning of Trolesky's factorization theorem. So here is the theorem. Let p be n times n positive matrix positive.
00:26:46.100 - 00:28:13.022, Speaker A: Here. I mean, I mentioned in one of the lectures before. For us, it means bigger than or equal to zero, but it's not something universal. For some authors, positive means strictly bigger than zero. Here, then there exists, there exists a lower triangle matrix l l for lower, such that p is equal to l l star. Of course, the reverse is trivial, because if we know that, if we know that p is equal to ll star, then px l l star x, we can take l to the other side. It's just normal.
00:28:13.022 - 00:29:11.634, Speaker A: Star x is positive, so p is positive. If we have this shape, this form, then p is positive. The reverse order is important. And we do this by induction. If p is one by one matrix, just one element here, p is equivalent to that component being positive. And so we can take root square. So l is root square of p one y.
00:29:11.634 - 00:30:21.866, Speaker A: And we see that ll star, is it ll star? Yeah. L star is just so kind of trivial, but still important. And now assume that the result is true for n minus one. And look at the element p eleven. There are two cases, case one p eleven, equal to zero. Then by the dilemma we had at the very beginning, the first column and the first row, both of them are identically equal to zero p one. J is equal to p I.
00:30:21.866 - 00:31:26.864, Speaker A: One is equal to zero for all I and j. In other words, our matrix p has this form. Everything here is equal to zero, and the remaining is a matrix q, which is n minus one times n minus one. P positive implies that q is positive. The order of q is n minus one. We can use our induction hypothesis for n minus one, the decomposition works. So there is a matrix l one.
00:31:26.864 - 00:32:25.194, Speaker A: N minus one times n minus one, lower triangular, such that q is equal to l one l one star. And now we define l precisely, as we have for p. Here we just, instead of q, we plug l one. So define l by this formula. Instead of writing the formula, I do it at diagram. You understand what I mean? So here, zero, first row, first column, also equal to zero. So these are all zero.
00:32:25.194 - 00:32:59.884, Speaker A: And then I put l one here. And note that l one is lower triangle. So everything here is zero and l one is there. I mean, this zero is also part of l one. This one. But I mean, this way, you immediately see that l is lower triangular. Try angular.
00:32:59.884 - 00:33:48.268, Speaker A: In standard books, sometimes they write, they write it this way, too. Zero, zero l one, which is true very good. But you need to be careful that these zeros are not the same. The first zero here, let me erase the colors to explain. The first zero here is just a scalar. The second zero is this part of the row, and the third one is this vector. So even though we write zero, zero, you need to be careful what they mean.
00:33:48.268 - 00:35:04.467, Speaker A: But still, it works. And there is no danger of writing is this composed matrix. Sometimes they even add some dot lines like this. And then when you do l times l star and l times l star in particular, with this form, it's easy to see what is l times l star, because even though, as I said, zeros are not the same, but there is no danger to write it this way, it will be one star. I mean, all dimensions work perfectly and there is no problem with that. True. Again, to respect the color we had before, if you write this as green, then it becomes like that and the same for the other one.
00:35:04.467 - 00:36:32.532, Speaker A: This becomes like this. But I mean, after the multiplication, everything works well and there is no problem with that. So in this case it works well if the first, if the first element is equal to zero. If not, case two, if p eleven is bigger than zero, then we use the previous theorem of Cholesky. The first, the main observation by pre minus one over p eleven. And then we had column one, column one star is still bigger than or equal to zero. And we end up with the same story again, because now if I already use qp, let me call this matrix r again.
00:36:32.532 - 00:37:40.354, Speaker A: R has the form zero here, zero there, and all elements here are zero. And there is another matrix s here. But s is n minus one by n, s by n minus one. So this is n minus one times n minus one. And you do the same thing, you do the same that we had before with s, and we proceed as before. So by induction, there is l one. It's not the same l one as before, but it's okay, we can write it that way.
00:37:40.354 - 00:38:47.814, Speaker A: N minus one, n minus one, lower triangle such that s is equal to l one, l one star. And now we define l by this formula. From this, you see what is your first column? Note that p one is positive. So instead of p one, we can write root, root square of p eleven squared. So we give one of them to c one, one of them to c one squared. So our first column here would be one over root square of p one, one c one. This is the first column here.
00:38:47.814 - 00:39:55.104, Speaker A: And then here is completely zero. And I put l one tennis test. But again, l one is lower triangle I put l one here and this zero also belongs to l one. But I write it that way. And you see immediately that l is n by n, lower triangular. And just do the multiplication. Ll is equal to pie.
00:39:55.104 - 00:40:31.994, Speaker A: In a sense, this finishes the proof. But there is more in the proof than stated in the theorem. And the more is what we see here. We start with p. We do p minus one over p eleven c one, c one. Then we obtain a matrix which is positive. But a column and a row are equal to zero, so we can do the same.
00:40:31.994 - 00:41:13.852, Speaker A: And for column, for the rest, column two, column three up to the end. And this gives us an algorithm to decompose a positive definite matrix. The algorithm is like this. How to detect if a matrix is positive, definite or not. So a is given. Generally a equal to a is given. The question is indeed two questions.
00:41:13.852 - 00:42:38.452, Speaker A: The question one is that is a bigger than or equal to zero? And question two, if yes, give the decomposition. And here the way the algorithm work. You start with any element in the diagonal. I mean either a eleven or a 22, or a anyone you wish. If a is bigger than or equal to zero, all of these have to be positive. So if by any chance you have a matrix such as a diagonal, you have something which is a complex number, not real or real, but negative, then for sure that matrix is not positive. So you the answer to the question one is no.
00:42:38.452 - 00:44:24.528, Speaker A: So if any of this is bigger, smaller than zero, or the line to c not r, then for sure a is not positive. So that's the first thing to check. Second, assume that all of them are positive. If one of them, say a eleven, is equal to zero, anything on the diagonal is equal to zero. The, the first result tells us that everything on the column of that element and on the row of that element must be zero. So this, we need a first row, a one j to be zero for rj, and first column AI, one to be zero for all I. If any of this is violated, then p is not positive.
00:44:24.528 - 00:45:51.318, Speaker A: If not, p is not positive. Again, if yes, what do we have? We go to we start all over with n n minus one times n minus one matrix. So remember we started with an n by n matrix, n by n. If we ended up here, everything in the first column and first row equal to zero or doesn't matter, the third column and third row, everything zero. We can forget about this and start all over, what with the matrix whose order is less, n minus one, n minus one. But this is where the case. If a one is equal to zero, if not if a eleven is strictly bigger than zero.
00:45:51.318 - 00:47:34.714, Speaker A: Consider matrix p minus a eleven. Column one star, no column one, column one star. We consider this, we know p minus one over a minus one c, one c. One start is positive, and also the first column and the first row are identically equal to zero. So again, we are in this situation, start all over with an n by n minus one times n minus one matrix. It's the matrix. So in brief, briefly speaking, you have a matrix like this.
00:47:34.714 - 00:48:58.068, Speaker A: This is your p. And in the first step, if, even if, instead of p eleven, I write p eleven, the root of p one squared, and done one root to this one and one root to this one, I start with p and then I have p minus, let's call it l one l one star. And this gives me a matrix such that this is zero and this is zero. This is, this is my matrix, p minus l one l one star. And then I do this one more time, and I do it one more time. If still the algorithms doesn't tell me that the matrix is not possible positive, then I continue and I obtain the matrix. Here is p minus l one l one star minus l two.
00:48:58.068 - 00:49:50.052, Speaker A: L two star, such that here and here, everything is zero and the remaining one is n minus two times n minus two. And I continue this up to the end. At the end, what do I obtain if it is successful up to the end? If the algorithm does not stop at the end, I obtain p minus l one l one star minus two. L two star. Ln star equal to zero. It's the matrix which is identically equal to zero. Of course, it is possible that somewhere in the middle the algorithm breaks and says that the matrix you have is not a positive matrix.
00:49:50.052 - 00:50:23.654, Speaker A: So we go back and the one we started with is not positive too. That's a really good and effective and fast algorithm to do two things. You see, at the end, we have, we have obtained two things. Back to the questions. I have two questions. Is it positive if we go up to the end successfully? The answer is yes, if we have equal to zero at the end. And if yes, we have something more.
00:50:23.654 - 00:50:52.070, Speaker A: We have p equal to l one l one star. And what is l one l one is just a column instead of c. I wrote l. Indeed, I should have kept c. So we can, we can write p as a sum I from one. Even we might stop at the, in the middle. It's not necessarily up to the end.
00:50:52.070 - 00:51:40.654, Speaker A: Maybe somewhere in the, in the middle we arrive at zero and allow me to write a star. Then a is a column a I AI. So we have a decomposition like this, too. And this is another form of the Cholesky's algorithm. And even still, we can say even more. I mean, the first column that we have, sometimes this is useful. The first column we have is the first column of p, but the second column is the first column of this matrix, so its first component is equal to zero.
00:51:40.654 - 00:53:06.504, Speaker A: And for the third one, the first two component is equal to zero. So we can write it this way. And indeed, this information were provided before, but in kind of disguised form, because when we say that l is lower triangular and p is equal to l l, you remember I, at the beginning of this, we said that at least there are three or four interpretations for the product of two matrices. One of them is to consider the column of the first one and the rows of the second one. So here we can consider p and the columns of l. There is no danger. Now, if I write l one, l two, l, you understand what I mean? And the rows of l star, and you know, what are the rows of l star are, because it's l one star, l two star, ln star.
00:53:06.504 - 00:54:17.644, Speaker A: And we saw that this multiplication is precisely l one l one star, the first column, the first row, second column, second row, ln ln star. And note that each of these by itself is an n by n matrix, but a very particular one. And as we proceed in l two, because it's lower triangular, in l two we have 10. Here in l three we have 20, and in ln we have n minus 10. This is what I mentioned here, that there are more information inside this decomposition, but it was indeed hidden in the pro, in the theorem of Chulesky two. But with this algorithm, you really see what's going on. And it's a very fast algorithm to detect if something is positive or not.
00:54:17.644 - 00:55:13.484, Speaker A: I started with p eleven, but for a stability reason, this is something that people in numerical analysis, they consider. Instead of working with p eleven, they look at the diagonal and choose the biggest element. And because we divide to that biggest element, it's more stable. So if, for example, an element here is the biggest one, they try to make this column equal to zero and that corresponding rho equal to zero, and then continue the same at each time, they don't go in order. They consider the greatest element on the diagonal, and they divide by that element and go up to the end. Very good. So now you, you have a very effective argument to detect if something is positive or not.
00:55:13.484 - 00:55:25.664, Speaker A: After the break, I'll give another interpretation for Cholesky's algorithm. And then we'll go to shure products. Or, I mean, sometimes they call automat products, too.

00:00:00.120 - 00:00:22.078, Speaker A: Would you please stop? Good morning, good afternoon, or good evening, everybody. Welcome to week nine of this focus program. We are halfway through, and we are going to start with lectures by Ross on operators on function spaces. Bill, please.
00:00:22.246 - 00:01:14.852, Speaker B: Okay, so thanks to the introducer and the organizer of this javad, this is a tremendous amount of work, and he's only halfway through. Also, thanks, everybody, for showing up early or late, wherever you are. So I'm going to make these slides available, but I think I'm going to wait until the end of all the talks where I can make all the slides in the one file. And I'll take out any typos, and I'll take out all the pauses and things like that. And also there'll be a survey paper on this by the field institute. So if you miss anything, it'll be in there. So I was asked to give a series of lectures on operators on function spaces.
00:01:14.852 - 00:01:52.694, Speaker B: So this is a very big topic, and you're going to have to make some choices. So I'm going to apologize in advance if I made the incorrect choice. And your favorite operator isn't on here. So here are the six operators that I'm going to cover. I'm going to cover two per day. And so why did I select these operators? Well, these are operators I know SOmething about. And then I also see these operators as inspiration for a lot of other work and other talks.
00:01:52.694 - 00:02:34.158, Speaker B: And I'm going to take a historical approach to this whole thing. I'm going to try to mention the original papers, and then I'm also going to include proofs. I think this talk is meant for new people in the field, graduate students, postdocs. All right, so lecture one is going to be on the Volterra and the Cesaro operators. So I selected the Volterra operator first because I don't have to work very hard defining the ambient space. It's just l 20 one. And then the operator is also very easy.
00:02:34.158 - 00:03:16.304, Speaker B: It's sort of anti differentiation. So I'll mention some nice references for this one is a book by Joel Shapiro, kind of a recent book. And then I'll also mention some of the original work by volterra. This 96 is 1896. And then sort of a collection of volterra papers on integral operators. So this is sort of the easiest version of the volterra integral operator. I'll mention the big class of them at the end.
00:03:16.304 - 00:04:37.734, Speaker B: All right, so let's first of all prove that the Volterra operator operates on L two. So the first stop is to prove that the volterra operator is bounded and the norm is estimated from above by one over the square root of two. I'll actually compute the norm exactly in a moment, but let's just start slow. So if you were to take the definition of the volterra operator, crash THROUgh with absolute values, and then use the cauchy SCHWARzenegger and follow your nose, you're going to get this point wise estimate for any f in l two. And now if I integrate both sides, you'll see they're one half. And now to compute the norm, I'm going to soup over all unit vectors in l two and then take square roots, and that'll show that vf is in l two, and the norm of the VoLTerra operator is bounded above by one over the square root of two. All right, I'm fully aware there's an improvement to be made here, which I'll do in a moment.
00:04:37.734 - 00:05:08.492, Speaker B: So with all the operators I'm going to be studying here, I'm going to compute the adjoint. It's always important to know what the adjoint is. And the volterra operator, the adjoint is given by this integral. It's a very similar integral. Instead of integrating from zero to x, you're going to integrate from x to one. All right, so the proof is integration by parts. So I teach it in undergraduate college.
00:05:08.492 - 00:06:05.374, Speaker B: So integration by parts is my life. All right, so for f and g in L two, look at vf inner product with g. So this inner thing right here is vf, and then I'm interproducting it with g. If you forgot your integration by parts, u is is this piece, and dv is this piece. Apply the integration by parts formula and things vanish at the boundary and you get f against this integral. So therefore, this piece right Here has to be the adjoint of v applied to g. Now that we have the adjoint formula, an important piece of understanding the Volterra operator is to understand v.
00:06:05.374 - 00:06:54.832, Speaker B: So this is a self adjoint operator, and it's actually compact, and we can pick off its eigenvalues and the corresponding orthonormal basis of eigenvectors. But by the way, these fns are unit vectors in l 20 one. And by using a FourIer cosine series in l 20 one, this is actually an orthonormal basis. And then from this I'll also show you that the norm of the Volterra operator is two over PI. Okay? So let's get busy with the proof of this. All right. So I have a formula for v and for v star.
00:06:54.832 - 00:07:35.334, Speaker B: So the inner integral is v. The outer integral is going to be v star. All right. So to compute eigenvalues, I am going to solve an eigenvalue eigenvector equation. So, looking for the eigenvalues and eigenvectors for v b, differentiate twice the minus sign comes from the fact that x is on the bottom. Then a little bit of thought will show that f of one is zero and f prime of zero is zero. Then you have a second order differential equation and you have some boundary conditions.
00:07:35.334 - 00:08:18.272, Speaker B: This will yield the eigenvalues and eigenvectors. I won't go through the sophomore differential equations course. All right. Now, since the eigenvectors form an orthonormal basis, v v has a matrix representation with respect to this basis, and it's a diagonal operator. And if you look at the formula for the eigenvalues, notice that they go to zero. So if you have a diagonal operator whose entries go to zero, it'll say it's a compact operator. So v v is a compact operator.
00:08:18.272 - 00:08:57.434, Speaker B: So we have the first part. Now for the norm. Notice that v v, I have this nice diagonal operator. And a second fact about diagonal operators is that the norm is equal to the supremum of the diagonal entries here, the absolute values of those. So the norm of v squared used the c star algebra identity for norms of operators. Right. And then you're computing the norm of this diagonal operator, and then take square roots and you're done.
00:08:57.434 - 00:09:53.028, Speaker B: As a consequence of all this v. The Volterra operator is a compact operator, kind of a general observation that integral operators, at least the classical ones, usually define compact operators. All right, for this, we did all the work. Notice that V V is compact. So you can use the polar decomposition to show that V is compact. So we have a lot of information so far about the volterra operator, the spectrum, all the operators I'm going to be looking at, I can talk ABout the spectrum of these operators. First of all, it's just an interesting object to look at.
00:09:53.028 - 00:10:35.654, Speaker B: And then there are all these theorems, the spectral theorem, and things like that. Knowing what the spectrum is Gives you alternate ways of looking at the operator. The spectrum of the volterra operator is just the. .0 and this puts the volterra operator in a class of operators called quasi nilpotent operators. Our approach here is going to be to use the spectral radius formula via the Berlin Gelfand theorem. So in order to do that, I need to know what powers of the operator R.
00:10:35.654 - 00:11:35.904, Speaker B: So if I integrate the formula for the Volterra operator n times, right, and then YOu cAn sort of see I'm integrating X to the n, YOu have to switch the limits of integration. All right? And then look at a similar estimate I got for the norm of the Volterra operator. And you're going to see that the norm of b to the n decays like a factorial one over a factorial. All right? So by the spectral radius formula, the maximum of the modulus of any element in the spectrum is equal to. So this is, the Berlin Gelfand formula is equal to this limit. All right? So then you need to dust off Sterling's formula to get a reasonable estimate on the factorial. But if you do that, you'll show this limit is equal to zero.
00:11:35.904 - 00:12:24.754, Speaker B: All right, so this says that the spectrum of the volterra operator is contained in the singleton zero. Now use the fact that the spectrum of any Bounded operator is non empTy. So the, the spectrum has to be equal to that singleton zero. All right? The numerical range. So the numerical range of v, or any operator, is going to be a top, let's call it the field of values. So you look at vf against f. So the inner product of vf against f, and you look at all those numbers where you sample over every unit vector in L two.
00:12:24.754 - 00:13:06.434, Speaker B: So, the Toplitz Hausdorff theorem says that's going to be a convex set. It doesn't always have to be closed. The numerical range is the closure of it is going to have to contain the spectrum. That's another general fact. Well, in this case, the numerical range turns out to be this sort of, I don't know, sidewards squashed tomato region. So it's the region bounded between these two curves. So here's the upper one, the plus option, and here's the lower one, the minus option.
00:13:06.434 - 00:13:48.804, Speaker B: So it's everything in between, including the two curves. All right, so maybe I won't prove every technical detail it takes to do that, but let me at least put you in the ballpark of where a result like that comes from. All right? So for each theta between zero and two PI, you can see this is going to be the parameter of my curve. Define f theta of x. So, let's look at e to the I theta x. So this is a function on zero one. It's a unit vector in l two.
00:13:48.804 - 00:14:23.704, Speaker B: So it's a point I'm going to use to sample to get my numerical range. And if I look at vf, vf theta against f theta. And I do the integration, I wind up with this function of theta. And now it's just a matter of taking separating that into real and imaginary parts. And that at least gives you the boundary curves. You still have a little work to do to show that nothing else is in the numerical range. But that's generally the correct idea.
00:14:23.704 - 00:15:10.034, Speaker B: The commutant of the Voltaire operator, or any operator. So all the operators I'm going to be studying in these lectures, I'm going to compute the commutant just because it's interesting. So v with a little prime on it is going to denote the commutant. And these are the operators a that commute with v. So certain obvious elements of the commutant or any polynomial in v. So certainly v commutes with itself, as does v squared and v cubed, and the identity operator commutes with v. So any polynomial in v will commute with v.
00:15:10.034 - 00:15:57.354, Speaker B: Alright. And a result of Saracen. This is part of his h infinity interpolation, which kind of his operator value, his operator interpolation theory. It turns out that the commutant is the strong operator topology closure of p of V. So the set of all these polynomials I mentioned a result of Erdos, J. Erdos, not Paul Erdos, who gives a sort of a more direct way of showing this. You don't have to go through the detour of Saracen's operator interpolation paper.
00:15:57.354 - 00:16:48.950, Speaker B: So those of YOu maybe are a little critical of this result. And you may think, wait a minute, the Volterra operator is essentially a convolution operator. It's convolution with the function one. And usually convolution operators commute with each other, and they certainly do. And so why isn't every element in the commutant a convolution? And you can show by certain arguments that that isn't the case. So there are other operators besides convolution operators in the commutant of v. All right, the invariants, subspaces of the voice Volterra operator.
00:16:48.950 - 00:17:48.584, Speaker B: This is what's known as the Gelfon problem for a number between zero and one. Look at this space f, sub a. So it's defined to be the characteristic function on a to one of l two of zero one. This is essentially the functions in l two of zero one, which are zero almost everywhere on zero to a. So this is a closed subspace of l two. You can see that in a number of ways you can sort of use egaross theorem or something like that. Or you can show that the operator of multiplication by this characteristic function will be an orthogonal projection of l two onto the space fa.
00:17:48.584 - 00:18:47.940, Speaker B: All right? So if I take a function in fa, it'll vanish on zero to a almost everywhere. And if I take the Volterra operator, so I integrate from zero to x of that function, and I'll still get a function which vanishes actually everywhere on zero to one, on zero to a. And whatever it does after that is its own business. But fa is actually an invariant subspace for v. All right? And it turns out, Gelfand asked, and a number of people answered, that these are actually all of the invariant subspaces of the Volterra operator. So it was a convolution theorem of agmond that actually prove this. But there are more direct proofs, one by Donahue and others.
00:18:47.940 - 00:19:37.394, Speaker B: They worked in Lp. And I point out a paper of Saracen has a very elegant proof of this theorem using inner functions. A more modern thinking about the Volterra operator is that it belongs to a, a set of operators called complex symmetric operators. So let's define this map j on l 201. I'm cautious not to say operator, because it isn't an operator, it's a map. So it takes a function f. It composes with the function one minus x, and then it takes the conjugate of the whole thing.
00:19:37.394 - 00:20:33.892, Speaker B: All right, so a couple things. Just do the simplest of u substitutions, and you can see that this is an isometric map. Another thing that you can see is that it's additive, but it's conjugate linear. So j of Cf is c bar times j of f. So it's conjugate linear. Another thing you can see is that if you do it twice, you get the identity operator, and then a little bit of integration with The VolTerra operator will show that jvj is equal to v. So v is not a self adjoint operator, but it's sort of, in a way, a self transpose operator.
00:20:33.892 - 00:21:11.240, Speaker B: And I'll make that clear in a moment. So sort of operators for which there's a conjugation, for which this type of property hold. Those are called complex symmetric operators. All right, here's an interesting thing. I teach linear algebra, and matter of fact, I'm teaching it this TERm. So the matrix representation of a linear transformation is kind of of near and dear to my heart. So I'll mention this cool observation of GArcia, proton And putinar.
00:21:11.240 - 00:22:16.954, Speaker B: So let's look at these functions fn a little bit of thought will show this is ACTUALlY an orthonormal basis for l 20 one. And also if you work with, with J, you can actually see that JFN is equal to FN. So this is what's known as a j real basis. So we sort of think of the real numbers as ones that are fixed by complex conjugation. So we think of the FNs or j real bases as they're fixed by this conjugation operator J. All right, now with respect to this basis, these FN's, the matrix representation is this rather cool looking matrix. Now observe here that this is not a self adjoint matrix, but it's a self transposed matrix.
00:22:16.954 - 00:23:06.112, Speaker B: If you look at this entry here, I over two PI and I over two PI. So in other words, if you flip along the main diagonal, you'll actually get the same matrix back. So that's sort of an important feature of complex symmetric operators. And I'll mention here that Saracen also proved that the Volterra operator is unitarily equivalent to a truncated toplets operator. And I think next week is tto week. So that's a neat feature to have. So I'll mention, as we sort of leave Volterra operators, there is the wide class of integral operators.
00:23:06.112 - 00:23:43.530, Speaker B: So the Volterra operator is going to be the integral operator, which is the characteristic function on a triangle. So if I have some reasonable kernel K, these Volterra operators are well studied by Volterra and many others. I'll refer you to a pretty thorough book by Gachberg and Crane on this. And there are other books. So this is sort of standard fare. And look at integral equations. Of these, I'll mention one other Volterra operator, and you're free to generalize this as you please.
00:23:43.530 - 00:24:45.434, Speaker B: So if you're given ANY space of analytic functions, just take the antiderivative of it in the disk. So on the hardy space, or even HP, Alexandria Alleman and Boris Korenblum actually sort of studied these things in various subspaces and things that Donahue studied about these Volterra operators. These go on. Volterra operators are important. And matter of fact, there's going to be a talk later on today about Volterra operators, but I need to make some choices and I'm choosing to move on to the Chizarro operator. So, excuse me. So the CESAro operator, it's an integral operator on h two.
00:24:45.434 - 00:25:30.536, Speaker B: And here's what it is. So H two is a square summable power series on the disk. So for an f in h two and a z inside the disk. Certainly this integran is defined for c in the disk. And now I integrate that from zero to z. This is a perfectly well defined analytic function that vanishes at zero, and then I divide out that zero. So this is not the original version of the Cesaro operator, but I'm going to be using several different ways of talking about it.
00:25:30.536 - 00:26:14.490, Speaker B: I'll mention some early papers of this sort. Ernesto Cesaro in 1890 used the Cesaro, what's known as the Cesaro averages, in his summability theory. And a lot of what I'm going to be talking about with regards to basic properties of the Cesaro operator comes from a 1965 paper by Brown, Hamas and shields. All right, so CF is going to be a nice analytic function on the disk. And so one should know what its power series is. And you can actually just work this out. So one minus c.
00:26:14.490 - 00:26:46.814, Speaker B: Or you could use a, write one over that as a geometric series and just integrate. You can see the integrating z to the power n. You get the one over n plus one. So let's take a close look. So the power series coefficients of cf, these Are, notice these are the average of the first n plus one. Fourier coefficients of f. These are the CESAro averages.
00:26:46.814 - 00:27:35.534, Speaker B: All right. So if we want to prove this is an operator on h two, I need to show that this is a square summable sequence here. Well, luckily, I didn't have to wait too long, because Hardy did this. And so if you have a sequence of non negative numbers and you take their average, square them and add them, you get, this is less than or equal to 16 times this, some of the squares of the B's. Now, there are p versions of this as well. All right. So this ImmedIately gives you that the CEsAro operator is a bounded operator on h two, and the norm is at most four.
00:27:35.534 - 00:28:14.452, Speaker B: Okay. As with the Volterra operator, we're going to actually improve that a lot. All right, so the original way of thinking about the CHizarro operator was by means of the CHizarro matrix. All right, so, all right. Having a little trouble advancing here. All right, so if I have cf, right, so this is the Cesaro operator. So now if you were.
00:28:14.452 - 00:29:03.704, Speaker B: So the monomial basis for h two is one z squared. So if you apply c of one, you get the first column c of Z, you get the second, third and fourth. And notice you have this beautiful patterned matrix. It's called the Cesaro matrix. And notice what happens if you take this matrix and multiply it by a vector in l two. What you're going to get is each slot right of the result is going to be the average of the first k terms. And Cesaro used this to define a way you could add up series that were not summable in the traditional sense.
00:29:03.704 - 00:30:09.976, Speaker B: By the way, if you know about Shor's test, you can actually fashion a proof of the boundedness of the Cesaro operator via the Cesaro matrix. Using Schur's test, you still get a norm at most four. Ok, so let's look at the adjoint of the Cesaro matrix. So in one sense the adjoint is, well, just take the adjoint of the matrix, and if you work backwards from the matrix on the right, you can actually read off the power series of the adjoint. You have. The power series coefficients are these sums from j is equal to n two. And, and if you, a little bit of thought working with power series shows this nice integral formula for the Cesaro operator.
00:30:09.976 - 00:31:08.188, Speaker B: So you can think of the Cesaro operator as an interval operator and its adjoint will also be an integral operator. One of the things you're going to see as we go here is I want to use both the integral definition of the Chizarro operator, and in a moment I actually want to use the matrix definition of the Chizarro operator in use to discussing things that I like to know about it. And here is the first instance of you can use both. So the norm of the Cesaro operator is equal to two. And here's the proof. So if you look at I minus C times I minus C star, just multiply those matrices, you actually get a diagonal operator. And diagonal operators are great because I can compute their norms easily.
00:31:08.188 - 00:32:14.278, Speaker B: It's just going to be the supremum of the modulus of their entries. All right, so the norm squared of I minus c by the c star algebra identity for operators is going to be the norm of this diagonal operator, which is one. All right. So then if to compute the norm of c I n, subtract the identity operator, use the triangle inequality, and both those sumns have norm one. So I get the Cesaro operator is bounded above by two. A little bit of more work, you can get the lower bound by sampling c star on an appropriate set of vectors eigenvalues. So this is going to play a huge role in understanding a very important property of the Cesaro operator.
00:32:14.278 - 00:33:00.064, Speaker B: So here I'm going to be using. In the previous slide, I used a matrix definition of the Cesaro operator to get a property of the Cesaro. But here I'm actually going to be using the integral definition. So let's look at these vectors. So for parameter in the disk, look at this analytic function on the disk. Notice that one minus z, if z is in the disk, this function has no zeros in the disk. So I can take its power via the logarithm.
00:33:00.064 - 00:33:29.410, Speaker B: And let's arrange the branch of the logarithm so that phi of w of zero is equal to one. In other words, one to this power. We'll interpret that as one. All right, so these are nice analytic functions on the disk. And I claim these are actually going to be eigenvalues. So if they're going to be eigenvalues, they had better belong to h two. All right, it's a little bit of a tricky power series computation.
00:33:29.410 - 00:34:32.376, Speaker B: Or you can do it via an integral estimate. You can show that these belong to h two, and then these functions form a total set in h two. And you can actually see this, because if you let w is equal to n over n plus one, where n is a positive integer phi of n over n plus one, it turns out to be one minus z to the nth power, you can show that the linear span of these things certainly contain all the polynomials. And if they contain all the polynomials, then their closure is going to be h two. All right, now use the integral estimate. Use the integral definition of the adjoint of the Cesaro operator, and these functions turn out to be eigenvectors. With these are your eigenvalues.
00:34:32.376 - 00:35:19.326, Speaker B: So the eigenvalues of the Cesaro operator fill a disk that's shifted over with radius one. It's center at one. All right, so now we're in business here, because I can tell a lot about the spectrum of the Chizarro operator. Maybe I won't really prove all this stuff, but the point spectrum of the chizarro operator is actually the empty set. And you can see this. Just take Cf is equal to lambda F. So use the integral definition of the Cesaro operator and kind of follow your nose, and you'll see that there are no f except zero that satisfies C.
00:35:19.326 - 00:36:23.082, Speaker B: Cf is equal to lambda F. We've already seen that the eigenvalues of C, at least a bunch of them, it's going to be this shifted disk. And now it remains to argue that those are the only eigenvalues, by the way, they have multiplicity one. Now use the fact that the relationship between the spectrum of the operator and its adjoint they're just conjugates of each other. So then the spectrum certainly contains this open disk, so therefore it will contain the closure of that. And now it's a matter to diddle that it doesn't contain anything else. All right, so the closure of the numerical range contains the spectrum, and you can argue that the numerical range is actually equal to that open disk.
00:36:23.082 - 00:37:27.162, Speaker B: So we know quite a lot about the spectral theory of the classical Cesaro operator. My opinion, the gem of studying the Cesaro operator on HD two, is this wonderful result that the Cesaro operator is a subnormal operator. And I'd like to go through pieces of this, certainly not dive into every technical detail of the proof, because I think it really shows off the relationship between operator theory and function theory and spaces of analytic functions. So a subnormal operator is the restriction of a normal operator. So a normal operator is one that commutes with its adjoint. So a subnormal operator is a normal operator restricted to one of its invariant subspaces. So that's the short version of it.
00:37:27.162 - 00:38:30.034, Speaker B: The long winded version of it is that an operator s on a Hilbert space, h is subnormal if there's a containing Hilbert space, and a normal operator on the containing Hilbert space, that leaves h invariant, and then the restriction of n to h is equal to s. So people use the language that s a sub normal operator is one that has a normal extension. So, too obvious, at least to me, they're obvious. Subnormal operators are the Hardy and Bergman schiffs. So both these operators are defined on clear subspaces of l two. The first one is l two of the circle, and the second one is l two of the disk. They're both the restriction of multiplication by z to their corresponding space of analytic functions, multiplication by z on any l two space.
00:38:30.034 - 00:39:22.594, Speaker B: We'll talk about that more tomorrow. Is always a normal operator. And so those are kind of the obvious examples of subnormal operators. The dircelet shift is not a subnormal operator because it's not hypo normal, and the classical backward shift on h two is not a subnormal operator either. I mentioned this just to make sure we all understand that subnormal operators are a class of operators and not a universal property of them. So Conway has a wonderful treatise on these things, but there's been significant work that's followed in subnormal operators. Pass Conway's 1991 treatment.
00:39:22.594 - 00:40:00.972, Speaker B: All right, so here's the prize here. It's a result of Tom Creed and David Trutt is that the Cesaro operator is a subnormal operator. Now, think about this a little bit. For the operators that I mentioned before, the shift on the Hardy and Bergman spaces, they sort of have kind of an obvious subnormal, an obvious normal extension. If you think about the Cesaro operator, it's defined on h two in a kind of this weird integral way. So it's not obvious that it has a normal extension. Right.
00:40:00.972 - 00:40:54.076, Speaker B: And even with the proof of this subnormality of the Cesaro operator, it's still not obvious what the normal extension is. All right, so I'd like to give you an outline of this proof, because it makes connections with, I think is a very fascinating operator on a very interesting space of analytic functions. So step one. Okay, I'm having trouble advancing here. Step one is to show that any operator that's unitarily equivalent to a subnormal operator is a subnormal operator. So the hand waving version of the proof of that. So if I have a subnormal operator, that's unitarily equivalent to a mystery operator, right.
00:40:54.076 - 00:41:57.744, Speaker B: The subnormal operator has a normal extension. And it turns out you can extend the definition of the unitary operator so that it'll actually carry the normal extension of the known subnormal operator to a normal extension of the mystery operator. Just write it down as a matrix, and you'll see exactly what I mean. All right, so I just need to show that the Cesaro operator is unitarily equivalent to a subnormal operator. All right, so we're going to do this by looking at the eigenvalues, the eigenvectors and eigenvalues of the adjoint of the Cesaro operator. This is a trick sort of popularized by Berling in his 1949 paper. Okay, so we learned that these phis are actually eigenvectors.
00:41:57.744 - 00:42:53.792, Speaker B: For the adjoint of the Cesaro operator, I choose to write the eigenvalue and eigenvector relationship in this way. So now I want to use this to define a Hilbert space of analytic functions. So, I take one of these eigenvectors, I put a bar on the parameter, and then I take its inner product with a function in h two. All right, I claim that's actually an analytic function. Now, I know it doesn't look like an analytic function immediately, but keep in mind, because there's a bar on the z, but keep in mind the bar is attached to the second slot, and the integration in Hilbert spaces is on the second slot. I teach mathematical physics at Richmond. And I have to put the bar on the first slot sometime for my physics courses.
00:42:53.792 - 00:43:25.484, Speaker B: Anyway, in Hilbert's basis, it's on the second slot. So this is an analytic function on the disk. Now I'm going to make it a Hilbert space by decree. Right? So I'm going to define the norm of one of these capital f's to be the norm of the f and h two. So this is kind of the range norm that Dan Timothy was talking about in his talk. Okay, so you don't do this because it's Tuesday. There's some things to check.
00:43:25.484 - 00:44:22.646, Speaker B: You want to check that if the norm of capital f is zero, the norm of little f is zero, and that follows from the totalness of the eigenvectors. All right, so now I can define a unitary operator from h two to script h, kind of in the obvious way. Well, let's see what we get. So if I take u of I minus c for an h two function evaluated at z, well, here's the definition of u. Then I move the c star to the other side. And now I use the fact that phi is actually an eigenvector. And then I notice that the variable of integration, thankfully, is not z bar.
00:44:22.646 - 00:44:56.704, Speaker B: So it comes outside as a constant. And then I'm looking at z times u. This says a couple things here. First of all, it says that multiplication by z is actually a well defined and bounded operator. That's unitarily equivalent to I minus c. All right, so I'm going to state that as the Cesaro operator is unitarily equivalent to multiplication by one minus z on h. So now you can see.
00:44:56.704 - 00:45:34.766, Speaker B: Well, okay, so I don't understand the Cesaro operator, but I certainly understand multiplication by one minus z. That's very easy to do. Now, the only complication is that the space is h is a little complicated. So here's the magic of the Crete and truth result. So the c to the n, that's an orthonormal basis for h two. So these psi ns are going to be the unitary image of these monomials. So they will also be an orthonormal basis.
00:45:34.766 - 00:46:46.046, Speaker B: And something called the air delay integral formula will actually give you a nice closed formula for these u's. Now, I can multiply each one of those functions by z minus one to the power n, and that's okay. And I get a polynomial. And so you can use this to fashion an argument that h contains the polynomials as a dense set. Okay, so the real gem of this is that you can renorm, at least on the polynomials you can renorm h by an l two integral norm. So for any polynomial p, there's, I can, the l two norm of p is actually equal to the square of the h norm. So as a corollary to this is that the Cesaro operator is unitarily equivalent to multiplication by one minus z on what we're calling p two mu.
00:46:46.046 - 00:47:26.614, Speaker B: So this is the closure of the polynomials in l two. All right, so the multiplication by one minus z on l two of any measure in the plane, that's certainly going to be a normal operator. You can certainly just write down the adjoint as multiplication by one minus z bar. So it's a normal operator. So therefore multiplication by one minus z on p two has a normal extension. So if multiplication by one minus z is subnormal, so is c. A couple little tidbits here.
00:47:26.614 - 00:48:16.610, Speaker B: You can actually describe the commutant of the Cesaro operator. It's the weak operator topology, closure of the polynomials. And by the Crete truth construction is you can identify the commutant with the multiplier algebra of this space script h. And what's sort of interesting here, and important is that this multiplier algebra is all of h infinity. Usually a multiplier algebra on a space of analytic functions is not. It's contained in h infinity, but it's not always equal to h infinity affinity. All right, so we have a lot of understanding with the Crete truth result.
00:48:16.610 - 00:48:51.064, Speaker B: Let me mention here that the ambient space h has sort of properties like the Berkman space, meaning the invariant subspaces are very pathological. They have all these weird properties. So the same is going to be true for the Cesaro operator. And you can be intimidated by that. I know I am. But you can also be inspired by that. So this mew is not a magic mew.
00:48:51.064 - 00:49:29.484, Speaker B: You can actually write down a formula for it. So worth exploring more. And I'll end with some generalizations of the Chizarro operator. These are mentioned in Daniel Guerrella's talk. You can put in the derivative of any analytic function you want, and that integral will certainly be defined and give you an analytic function. You can show this is bounded on h two. And I think the same is for hp, if and only if G is a function of bounded mean oscillation.
00:49:29.484 - 00:50:07.854, Speaker B: And if G is equal to this logarithm that's in BMOA. That's sort of your go to example of an unbounded function in BMOA. Take the derivative of that and you get the Cesaro operator. And now you're free to define this on your favorite HIlbERT space of analytic functions. You can look at whatever properties you like on this. All right, so that's the end of the first lecture. I hope you'll come back for the other two.
00:50:07.854 - 00:50:09.594, Speaker B: So thank you.
00:50:10.614 - 00:50:19.914, Speaker A: Thank you indeed, bilL. Thank you, speaker one, any question or comments for Bill?
00:50:23.314 - 00:50:33.946, Speaker C: I have a question. Yeah, this is maybe overly fussy, but. So, when we talk about the commutant of the Chizaru operator, you said it's the watt closure of the polynomials.
00:50:34.050 - 00:50:34.994, Speaker B: Right? Right.
00:50:35.034 - 00:50:39.826, Speaker C: Which is what you expect, because the commutant will be at least that big, trivially. But then there's nothing else.
00:50:39.930 - 00:50:40.482, Speaker B: Right.
00:50:40.618 - 00:50:46.574, Speaker C: And I think maybe I'm just REmeMBering it wrong, but I think when you stated talked about the commutant to the volterra operator, you said sock closure.
00:50:46.954 - 00:50:47.774, Speaker B: Yes.
00:50:48.174 - 00:50:56.022, Speaker C: Okay, so then that means there's. So that means there's a theorem hidden in there that for the Volterra operator, the sock closure of the polynomials is equal to the Watt closure.
00:50:56.198 - 00:50:57.126, Speaker B: Indeed.
00:50:57.310 - 00:51:02.554, Speaker C: So is that. Is that interesting? I mean. Well, I mean, it's sort of. It sounds interesting, but is there anything to say about that?
00:51:03.654 - 00:51:29.076, Speaker B: Yeah. So off the top of my head. So, Mike, I'm actually working on a book on all of this, and it's an exercise in the. In the book, forgotten how to do it. Okay. Yeah, you sort of caught me at the quick here. So, anyway, that is that I read it.
00:51:29.100 - 00:51:30.700, Speaker C: Right. And it wasn't just a typo or something.
00:51:30.772 - 00:51:32.984, Speaker B: No, no, it's. It's. It's actually correct.
00:51:34.244 - 00:51:35.024, Speaker C: Yeah.
00:51:38.124 - 00:51:41.504, Speaker A: There is a question by Marco in chat.
00:51:43.644 - 00:52:27.164, Speaker B: Do we know the ranges of these operators? The Volterra operator? Certainly. It's the absolutely continuous functions whose derivative is an l two. And there's probably a vanishing condition here. And I think there is information about. Alexandru Alleman had a series of students, I was the opponent on one of their PhD thesis. And I think she did some work on the range of the Chizarro operator, actually. And she had a version of generalizations of the Cesaro operator to certain Bergman spaces.
00:52:27.164 - 00:52:50.024, Speaker B: So there is information about the range of. I don't remember very well, but yeah, we could check. Right. So. Yeah, and then you had some other students that around her time that were looking at ranges of these operators or their resolve that might be.
00:52:56.164 - 00:52:58.624, Speaker A: Any further comments or questions?
00:52:59.044 - 00:53:24.322, Speaker D: This is Sheldon. Beautiful talk, Bill. Just wanted to mention an alternative proof of one of the results you gave, that the spectrum of the Volterra operator is just zero. You use the spectral radius formula, it might be easier to use. You'd already proved that the Volterra operator is compact, and that means that all points of the spectrum, except possibly zero, are eigenvalues.
00:53:24.498 - 00:53:25.002, Speaker B: Right.
00:53:25.098 - 00:53:29.402, Speaker D: Now, just write out the eigenvalue. Eigenvector equation and you get nothing.
00:53:29.458 - 00:53:29.714, Speaker B: Yeah.
00:53:29.754 - 00:53:31.694, Speaker D: Get nothing. Yes. Right.
00:53:33.444 - 00:53:42.788, Speaker B: You can also prove. Yeah, so. Right. Another exercise for the book. All right, so.
00:53:42.876 - 00:53:45.604, Speaker A: Yes. Thank you, Sheldon. Another exercise.
00:53:45.644 - 00:53:50.784, Speaker B: Thank you. Okay, I took that down. Perfect. Thanks.
00:53:56.204 - 00:53:59.784, Speaker A: If no further comment, let's thank Bill again.
00:54:00.364 - 00:54:01.084, Speaker B: Thank you so much.

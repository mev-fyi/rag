00:00:00.480 - 00:00:18.354, Speaker A: Second day of the workshop, and it's my great pleasure to introduce our first speaker today, Bill Ross from University of Richmond, who will continue his mini course on operators on function space. And today he will talk about multiplication and tablets operators. Welcome.
00:00:18.654 - 00:01:31.130, Speaker B: Okay, thank you to Javad. Once again, I don't think we can thank him enough for all the work he's put into this, and thanks to the Fields Institute for managing this whole thing. All right, so today's lecture is going to be, like I said, I've made some choices, perhaps the incorrect ones, of which operators I'm going to cover. So yesterday was Volterra and Cesaro here are going to be multiplication and tuplets operators. So when I cover multiplication operators, I'm going to focus on l two of the circle with standard labate measure. I am fully aware that multiplication operators and everything that I'm going to say generalizes to multiplication operators on l two of some compact house or space with a measure on it. But I don't want to get bogged down in technical details, and I also want to sort of have a natural transition from multiplication to tuplets operators.
00:01:31.130 - 00:02:24.967, Speaker B: So let's get going here. So, though the setup, maybe I didn't make this too clear on the last lecture, but we need to make it a little more formal here. So m is going to be normalized lepic measure on the circle, l two of t is going to be l two with normalized opaque measure, and l infinity is going to be the essentially bounded functions. We have the l two norm and the essential suit norm. And a simple computation using the fact that m is normalized labate measure is c to the n, where n is an integer, is actually an orthonormal basis for l two. That's going to be an important player here. So here's the operator.
00:02:24.967 - 00:03:33.904, Speaker B: So, for a symbol, an essentially bounded symbol, the multiplication operator is an operator from l two to itself, and it's simply multiply the function by phi. Okay, so what I'd like to convince you of is that this is a bounded operator and I can compute its norm. It's the essential suit norm of phi. Okay, so with all these proofs, I'm going to kind of give you outlines of the proof, and then for homework you can complete it. All right, so here's how it goes. So we're going to prove two bounds, and together they'll give us what we want. So for an f and l two, the l two norm of m phi of f square, you write it out as an integral you sacrifice an inequality by pulling out the modulus of phi squared outside the integral, and then you're just left with the norm of f squared.
00:03:33.904 - 00:04:37.104, Speaker B: Okay, so now you soup both sides over unit vectors in l two, and that'll give you an upper bound. All right, for the other inequality to show that they're equal, notice that if I take phi to the two n, and if I think about it for a second here, notice I'm taking the nth power of multiplication by phi applied to the function one. And if you think about it, that's exactly what's going on here. And then I use the fact, a simple operator inequality, I use it n times, right? So I get an inequality here. Then, notice I judiciously chose one, and I have normalized Labake measure. So the l two norm of one is one. Okay? So now I have, this integral is less than or equal to the two n power of the norm of m phi.
00:04:37.104 - 00:05:38.916, Speaker B: All right? So I'm sure we've given this as a homework exercise to our analysis students. This essentially says that the lp norm goes to the essential suit norm as p goes to infinity. So if you apply that here, here with n is equal to two n, you'll get the other direction. Okay, so that's the norm. Now, you may be thinking, have I sort of captured all of the multiplication operators? So maybe you're thinking, well, let's see, he said that if phi is a bounded symbol, you actually get a bounded multiplication operator. Is it possible to have an unbounded symbol and you get a multiplication operator, and the answer is no. Right? So the only functions that are going to multiply l two into itself are going to be the essentially bounded functions.
00:05:38.916 - 00:06:27.624, Speaker B: And the proof is just a jazzed up version of the proof that I just did. Okay, so we're talking about the full slate of M phi's here. All right? The adjoint of M phi, it's actually another m operator. It's M phi bar, the complex conjugate of this symbol. We do this by taking f and g in l two, and you write out the inner product, and the inner product is an integral. All right? So then by sort of sleight of hand, I'm going to take the conjugate of phi twice. And if I do that, I just get feedback and I just rearrange the orders of the terms.
00:06:27.624 - 00:07:29.494, Speaker B: And now I'll look at the term underneath the complex conjugate sign. And that's just what's going to appear in this second slot. All right? So that's going to prove that the adjoint of M phi is M phi bar, all multiplication operators commute with each other. So this means that m phi is a normal operator in a sense that m phi m phi bar is mfibar M phi. Now this is important for the spectral theorem. So if I were to do this in the most general case of multiplication operators on l two of x mu, where x is a complex house or space, then any normal operator is unitarily equivalent to an M phi in that generality. So the fact that this is a normal operator is important.
00:07:29.494 - 00:08:23.272, Speaker B: The spectrum. So the spectrum of M phi, going off the page a little bit, is the essential range of this symbol. Now if phi is actually a continuous function, then the essential range is actually going to be the range. It's going to be the image of the circle. So the essential range just picks out the important parts of the range for general elena infinity function here. So these are the complex numbers for which the measure of the set of for which phi minus lambda is less than epsilon is always positive for every epsilon. So those are the kind of the significant parts of the range.
00:08:23.272 - 00:09:00.320, Speaker B: So that'll be the spectrum. And I'll give you an idea of the proof of that. And then there's the point spectrum of M phi. So these are going to be the complex numbers for which the measure of the set where phi is equal to lambda is a positive number. All right, so again, proofs. I'll give you an idea of how it goes. So the resolvent of M phi is just going to be the multiplication operator with phi minus lambda inverse.
00:09:00.320 - 00:09:46.906, Speaker B: Just think about it. It has to be that. So it all boils down to when this inverse is an l infinity function. And if a little analysis exercise will show that that's going to take place exactly when lambda is in the essential range. All right, so if you were to look at an eigenvalue equation here. So if you look at m phi times the characteristic function for which phi is equal to lambda, that's certainly going to be lambda times the characteristic function. Now we all teach our students that you need to check that your eigenvector, your suppose eigenvector is actually non zero.
00:09:46.906 - 00:10:58.574, Speaker B: And so that characteristic function will be a non zero function when condition b holds. Okay, so that's the spectrum and the point spectrum. Okay, I'm big on the, as you can see, I'm big on the matrix representation of operators. So let's recall that c to the n, or those of you who want to write it, is e to the in theta is an orthonormal basis for l two. All right, so for an essentially bounded function, let's compute the matrix of m phi with respect to this orthonormal basis. So I'm looking at the JK entry of this, and it's going to be a doubly infinite matrix because j and k are integers. All right, so you work out what the inner product is, and then you observe that you have the Fourier coefficients of j minus k.
00:10:58.574 - 00:11:55.662, Speaker B: Well, what you want to extract from that is that these are constant on the diagonals, right? So the entry is going to be the same on each of the diagonals. All right, so we can kind of put that in a matrix form and I can show off that I actually know how to use colors in tech. But anyway, so you get this pattern matrix. So this is what's called a doubly infinite topelets matrix. Okay? Now, so every m phi is a tuplets matrix. You can ask the opposite question. Suppose I were to give you a doubly infinite sequence of complex numbers and form that tuplets matrix.
00:11:55.662 - 00:12:58.470, Speaker B: And you want to know is that a bounded operator on l two? And you can show, it's a bit of a projection argument that this is going to take place if and only if the ans are actually the Fourier coefficients of an essentially bounded function phi. So doubly infinite toplets matrices and m phi operators are the same thing. As long as we're agreeing, we're going to use the standard orthonormal basis for l two. Okay, now an operator I'm particularly fond of is the bilateral shift. I've worked on this in other settings, so I find it interesting. So if the symbol is just the identity function. So I'm looking at multiplication by the independent variable on the circle Mc.
00:12:58.470 - 00:14:02.284, Speaker B: It's called the bilingual lateral shift because if you write an l two function out as its Fourier series, you're going to have powers of C and Mc applied to that is going to just shift all those coefficients up by one. By what we've said before, MC is a unitary operator because we know its adjoin is Mc bar and c bar is going to be one on the circle. So that's a unitary operator. And then the essential range is very easy because you have a continuous function, right? So the essential range is equal to the range and that's a circle. As expected, all unitary operators have spectrum in the circle. All right, the invariants, subspaces are interesting, so subspace. And by the way, throughout the rest of my talks.
00:14:02.284 - 00:14:58.534, Speaker B: Take it down in your notes that a subspace is always closed. So subspace is going to be invariant if Cm is contained in M. So for the invariant subspaces for l two, they come in two types, what's called doubly invariant subspaces. Cm is equal to M and singly invariant subspaces, Cm is a proper subspace of M. Now, the first was described as follows. So they are essentially the functions which vanish on a set. So first of all, a characteristic function times l two is going to be closed because multiplication by a characteristic function will be actually an orthogonal projection.
00:14:58.534 - 00:15:50.174, Speaker B: And m, if you think about it, these are going to be the functions which vanish almost everywhere on the complement of e. And notice if you multiply by c, that doesn't change the zeros of any function from m. So these are the, what's called this doubly invariant subspaces. Or if you want to think about it in a different way, in terms of adjoint, these are the reducing subspaces for multiplication by c. Then there are the single invariant subspaces. And so I might as well just give you the whole thing. Cm is a proper subspace of m if and only if there's a unimodular function on the circle.
00:15:50.174 - 00:16:26.014, Speaker B: By the way, unimodular does not have to be inner, right? There's a lot of non inner unimodular functions such that m is equal to phi h two of the circle. So I'm thinking of h two. Here is the Fourier series in l two with only positively indexed Fourier coefficients. And by the way, if m is contained in h two, that's certainly allowed. Then this function phi is going to be inner. And I get Berling's theorem. And you actually prove this.
00:16:26.014 - 00:17:01.048, Speaker B: It's some work. You actually prove this using what's called a wandering subspace argument. You look at the orthogonal complement of M phi m in m, right? And you show that that's your phi. Okay, the commutant. So this kind of brings you full circle. So it seems like we took a little detour into the bilateral shift. Let's get back to multiplication operators.
00:17:01.048 - 00:18:05.424, Speaker B: So the commutant, so these are all the bounded operators on L two that commute with the bilateral shift. So a theorem by Brown and Helmos describes the commutant. So first of all, a is in the commutant if and only if a is in the commutant of and its adjoint M phi bar. That's actually nothing. You just work it out on a piece of paper. And here's the part here that's significant is that a is M phi for some essentially bounded function. So, a common theme here is, if you have a shift operator, maybe this is not a law or anything like that, but if you have a shift operator multiplication by independent variable, it is usually the case that the commutant is the set of multipliers of the space.
00:18:05.424 - 00:19:00.888, Speaker B: The proof of this is the stone Weierstrass theorem. So, if you commute with the bilateral shift, you're going to commute with all trigonometric polynomials. And then you could actually fashion an argument that a of one is going to be a bounded symbol, and that will be the symbol for MV. By the way, I'll take a little detour here, even though I said I wasn't going to dwell too much on general MZ operators. But by the way. So, the significance of the set a to b for this case, it finals just by algebra. If I have a general MZ operator on l two of, let's say a measure in the plane is actually called Fuglady's theorem.
00:19:00.888 - 00:19:48.472, Speaker B: So if you commute with MZ, you're going to commute with the Mz bar, okay? And then there you use the stone Weierstrass again. Okay? So this theorem can be generalized. Okay, so now we're doing toplets operators, and there's a trigger warning here. So, this is an enormous field, and there are people in the audience, I'm sure, who know a lot more than I do about this and have published important papers on this. I'm going to just cover a few of the basics to give you an idea of what's going on. And I'm going to associate it to MV operators. There are two books on this.
00:19:48.472 - 00:20:49.924, Speaker B: There's a book by Butcher and Grunsky, and then there's a very recent one by Nikolsky, who have a lot of information, of all things, toplets. And if I didn't include your book, I apologize, but I would like to know it's there. All right, so any M phi operator is, I can write this in a matrix form. And by the way, if you're wondering what the partitions are, the partitions are, I'm gonna, it's gonna be l two written as h two perp on the top and h two on the bottom. We'll focus on that some more. And we're gonna be looking at just the, the part at the bottom, right. And that's gonna be, in a way, the compression of a multiplication operator to h two.
00:20:49.924 - 00:21:37.676, Speaker B: All right. Now, the tuplets matrices are important, but you only get so far by looking at just numbers in a box. Right. The field kind of took off when you kind of think about all the l two theory. So we sort of, okay, maybe this is a personal digression here, is we sort of treat all l two theory and Parseval's theorem, and the Riemann Lebake theorem is all things that, you know, every elementary school kid should know. But it's actually pretty powerful stuff and you can actually get a lot with it. So this is going to be the emphasis of what I'm doing here.
00:21:37.676 - 00:22:29.356, Speaker B: So to make this all part of the l two theory, I'm going to think of h two as the Fourier series with only positively indexed coefficients. The Ries projection is going to be important. I'm going to call that p. So it's a bounded operator from l two to itself, and it's going to take a Fourier series and it's just going to chop off the negatively indexed coefficients. You can check that that is actually a orthogonal projection. So it's idempotent and it's self adjoint, and it's going to go from l two to l two, and it's going to have range h two. All right, so now we're going to define a tuplets operator.
00:22:29.356 - 00:23:11.884, Speaker B: So for phi, an essentially bounded function, define the tupelets operator. It's going to go from h two to itself. And so the phi is going to be called the symbol of the topelet's operator. And so here's what it's going to do. It's going to multiply f by a phi, and then it's going to project, all right, let's take a little pause of what this operator is actually doing. So I take an f and h two, and it only has a positively indexed Fourier series. I multiply it by any l infinity function.
00:23:11.884 - 00:24:01.634, Speaker B: So your generic l infinity function is going to have both a positive and a negatively indexed Fourier series. So when you multiply phi times f, you're going to get an l two function, certainly. But it's going to have both positive and negatively indexed Fourier coefficients. So what the p does, it's going to just chop those off. It's going to ignore all the negatively indexed ones and return only the positively indexed Fourier coefficients of phi times f. All right, so just to give you an idea of what's going on, and I think these two particular tuplets operators are important. So let's, what happens when phi is the identity function.
00:24:01.634 - 00:24:34.350, Speaker B: All right, so let's see what happens here. So Tc, the tuplets operated with that symbol. So I take a generic h two function. So it's a one, which is a positively indexed Fourier series. I multiply by C, and then I project. All right, so I multiply by c, and all that does is just increases the power on all the exponents. So c to the n turns to c to the n plus one.
00:24:34.350 - 00:25:29.286, Speaker B: And then notice that Fourier series still has positively indexed coefficients. So the orthogonal projection doesn't do anything. There isn't anything for it to do. So what's actually going on here is that Tc just multiplies f by the independent variable, and that's called the unilateral shift on h two. So it just shifts in a way the positive or the 48 or the power series coefficients of h two all up by one. As you can see, I'm big into matrices. So here's the matrix representation of this with respect to the usual orthonormal basis, c to the n for n positive.
00:25:29.286 - 00:26:14.240, Speaker B: And just think about what this is going to do. So if I take this matrix and I multiply it by an l two column vector, what it's going to do is it's going to shift everything up and put a zero in the first slot. And that's precisely what the unilateral shift does. All right, let's suppose I have C bar. What is Cassie multiplication by the toplets operator with Cassie bar do? It's going to take your typical h two function. So I only have a positively indexed Fourier coefficient. It's going to multiply by C bar, and it's going to project, here's something a little bit different happens.
00:26:14.240 - 00:27:01.980, Speaker B: So I will give you the first few terms of the Fourier series. And so now I multiply by C bar and notice that c is actually a variable on the circle. So I multiply by C bar here, and then I multiply by C bar. So C bar times C is just one. C bar times C squared is going to be just C. All right, so now I have to apply the projection. But the projection leaves all these coefficients alone and ignores the first one.
00:27:01.980 - 00:28:05.520, Speaker B: So notice I've lost the a zero. So this is what's known as the backward shift on h two. All right, so the backward shift, I can write it as a matrix with respect to the orthonormal basis, the monomial basis. So if I take this matrix, multiply it by an l two vector, what it's going to do, it's going to shift everything up one and I just lose the first coefficient. All right, so we know that the norm of m phi is equal to the essential suit norm of phi. It turns out, for a Tauplitz matrix, the same thing is true, but for a different reason. All right, so let me give you an outline of this argument so you can think of t phi is the restriction of m phi.
00:28:05.520 - 00:28:51.270, Speaker B: And then followed by p, the norm of t phi is just going to be the norm of this operator. This is less than or equal to the product of the norms. I'm going to do two steps at once here. First of all, the norm of a projection is equal to one. The norm of the restriction increases when I don't restrict it anymore. All right, and then we just prove that the norm of the multiplication operator is actually the essential sup? Norm. So the norm of the toplitz operator is at most the essential suit norm of phi for the other direction.
00:28:51.270 - 00:29:37.620, Speaker B: Right. The norm of t phi is going to be t phi applied to a unit vector. And then I take the soup of it. So if I don't take the soup and I apply to a particular unit vector, these are the normalized reproducing kernels. So Nina thankfully did those in her talk yesterday. So if I apply these to t phi, right, and then if I work what these things are, I'm going to be getting the Poisson integral. And if I use Fatu's theorem and take non tangential limits, there's a lot of little things I'm not going to really talk about.
00:29:37.620 - 00:30:18.234, Speaker B: But you'll actually get the other direction. So the norm of t phi will be equal to phi. There are other ways you can prove this, but this is the way I know. All right, a topelet's matrix is important here. So for positively. So for two positive numbers, m non negative numbers, m and n, these to the m, these are an orthonormal basis for l two. So let's figure out the matrix for t Phi with REspect to this basis.
00:30:18.234 - 00:30:56.086, Speaker B: So this is going to be the nm entry. It works with exactly as it did for M Phi, except there's a little step in here. All right, so first of all, the tuplets operator, I have to not forget to take the projection. So I take phi times this basis element and then project. All right? And so in a little step here, I am moving the p to the other side, but n is a non negative number. So C to the n is actually an H two. So the projection doesN't DO anything.
00:30:56.086 - 00:32:13.224, Speaker B: And then I'm off to the braces, as I did before. I write it out as an integral, and then realize I'm looking at the n minus n Fourier coefficient of phi. So that indicates that the entries only depend on which diagonal you're on. So with respect to that orthonormal basis, you get a diagonal, you get this, what's called a topelet matrix. You're constant on each of the diagonals. All right? So theorem says that's if you give me a sequence of complex numbers and you form a topelet matrix out of that, you want to know, when does that form a bounded operator on L two? The theorem is going to be, that happens if and only if phi is an essentially bounded function. Okay? And the way you actually get this is sort of a jazzed up version of the what we got for the doubly infinite toplitz matrix for mv.
00:32:13.224 - 00:33:02.088, Speaker B: Moreover, the matrix representation of t phi will actually be t. To me, this is saying the upshot of all this is that Topelet's matrices and topelet's operators are the same thing. You can't get one without the other. By the way, I'm trying to do a little bit of history here. So this result appears in a paper of Hartman and Winter, but sort of a preliminary version of it, I think, for self adjoints operators. I'm pretty sure it's done by topelets. The adjoint of a tuplitz operator is going to be the toplitz operator with the bar as its symbol.
00:33:02.088 - 00:33:38.984, Speaker B: So t phi is t phi bar. All right. And the way you show that is somewhat similar as how we computed the adjoint of m phi is m phi bar. But there are just a little bit of a step here. Okay, so let's do it, because actually, this same kind of trick works for tupelets operators and a lot of other settings as well. All right, so t phi of f against g. I just have to figure out what happens when I move t phi to the other side.
00:33:38.984 - 00:34:19.983, Speaker B: What operator do I get? All right, so the toplitz operator is just pmv. I move the projection to the other side, and then g is in h two, so it doesn't do anything. Then I move the multiplication operator to the other side, and I sacrifice a bar. Then here's the trick. I realize that I can artificially insert a p in there, a Rees projection, because f is in h two. So I can put a p in there of no cost to me. All right? Then I can bring the p to the other side.
00:34:19.983 - 00:35:09.744, Speaker B: And then what you're looking at is just a topelet's operator with t phi bar. Okay? So that's nice to have. All right. The brown Helmos theorem is a great tool that introduces, that combines toplitz operators with the shift and the backward shift. And it reinforces this concept that a topelet's operator and a tuplets matrix are the same thing. So essentially, you can ask, how do toplitz operators distinguish themselves in BH two? And here's the theorem. You're a toplitz operator if and only if you satisfy this operator identity.
00:35:09.744 - 00:35:44.874, Speaker B: The backward shift a. The forward shift has to be a again. All right, so let me give you a little bit of an outline of this proof. All right, so if a is a tuplets operator. All right, then let's see what happens on the basis elements. I'll leave you to kind of bring everything to the other side and work all the little pieces out. And you're going to get the m minus n Fourier coefficient of Phi.
00:35:44.874 - 00:36:19.394, Speaker B: We've already talked about how this is this inner product. All right? So the fact that this operator and this operator act the same on basis elements to prove they're the same. All right? Conversely, if this operator identity holds, keep on applying it. Left multiply by t V bar and right multiply by TC. Right. And you'll get this operator identity. All right.
00:36:19.394 - 00:37:24.334, Speaker B: And now compute these inner products and move everything to the correct place. And what this is saying is that the matrix representation of a only depends on which diagonal you're on. So this means a is a toplitz matrix, which means it has to be a topelet operator. All right, to me, what I get out of the brown helm o theorem is not that a topelet's matrix and a topelet's operator is the same, but this very useful operator idea identity, which appears a lot. Let's talk about compactness for a second, and then we'll get back to the brown helm of operator identity. Complex tuplets operators on h two are not interesting unless you find this zero operator interesting. Okay, so your compact if and only if your zero almost everywhere.
00:37:24.334 - 00:37:58.634, Speaker B: All right, so here's the proof. C to the n that goes weakly to zero in h two. And that's just the Riemann Labegg lemma. That's just saying the Fourier coefficients of an l one function go to zero. Now use the sort of the complete continuity definition of compactness. So this means t phi. If it's compact, it's going to take weakly null sequences to strongly null sequences.
00:37:58.634 - 00:39:18.064, Speaker B: So now you actually just work out what T phi applied to C to the n is, right. Now, if you think about it, T phi has a Fourier coefficients, C to the n is going to shift all of those up by one, and it's going to avoid. Right? So then the negatively indexed one that you've shifted up has avoid the executioner's axe of the projection. So you now have some of the negatively indexed Fourier coefficients appearing, and then use a Parseval's theorem, right, which equates the l two norm. And then what happens is this side goes to zero and this side, again, a use of Parseval's theorem, which creates the sum of the squares of the Fourier coefficients with the l two norm of phi. It's just going to say that the l two norm of phi is zero and then phi is zero. Now, as Sheldon Axler a couple weeks ago and Nina Zorboska yesterday taught us, that compact topolitz operators on the Bergmann space are extremely interesting, even though Tauplitz operators on the Hardy space are not.
00:39:18.064 - 00:40:02.660, Speaker B: Unless zero, you find the zero interesting, the zero operator interesting. Let's talk about analytic tuplets operators. So if you have a h infinity symbol, so that means you're an l infinity, but your Fourier coefficients are all zero for the negative ones. All right? So if you take a phi in h two, you. So, excuse me, an f in h two, and you multiply it by phi, that's still going to have positively indexed Fourier coefficients. All right, so the Ries projection doesn't do anything. So in this case, a tuplets operator is a multiplication operator.
00:40:02.660 - 00:40:51.130, Speaker B: And if you want, you can think of this now in the setting of analytic function. So it's going to take an analytic function in h two, right? And it's going to multiply it by phi. All right, here are some simple facts about the analytic tuplets operators. The point spectrum is the empty set. The spectrum is actually equal to the closure of the range. So this is where you have to stop thinking about phi is just a symbol on the circle. I need to think about it as an analytic function on the disk.
00:40:51.130 - 00:41:32.206, Speaker B: So I take its image and I take the closure, and that's the spectrum. All right? The matrix representation of t phi is just, it's going to be a lower triangular matrix. And if you sort of think about it, what's on top are going to be the a minus n coefficients, and those are all zero. All right, so let's talk about the proofs of a and b. So the proof of the point spectrum is empty. If you try to solve an eigenvector equation, you're essentially going to be looking at. So t phi is just going to be a multiplication operator.
00:41:32.206 - 00:42:20.094, Speaker B: So I'm looking at phi minus lambda. F is equal to zero. But on the disk, everything is analytic, and that's going to say that f is this zero function, so it has no eigenvectors. All right then, to prove that the spectrum of an analytic tupelet's operator is the closure of the image, I wanted to show you a reproducing kernel argument here. If I take a, a Cauchy kernel, I'm going to try to make this an eigenvector. I'm going to show you it's an eigenvector for the adjoint of this analytic, Tupelet's operator. This is going to be an h two function, and I want to know what is its value at z.
00:42:20.094 - 00:42:56.804, Speaker B: It's this function applied to the kernel. I move the Tuleletz operator to the other side. An analytic topic operator is a multiplication operator. Now look what you're doing here. You have phi kz, and if this were the other way around, you'd be evaluating this function at lambda, right? But it's the wrong way. So you have to apply conjugates to make it right. So the end result here is, I notice I have k lambda here and a k lambda here.
00:42:56.804 - 00:43:50.120, Speaker B: So this says that this is an eigenvector, and here are your eigenvalues. All right? So the complex conjugate of all these values are contained in this point spectrum, and that's definitely contained in the spectrum. All right, now use a little operator theory here that the spectrum and the spectrum of the adjoint just differ by a conjugate. All right? So the closure of the spectrum is contained in, the closure of the image is contained in the spectrum. And then a little bit of work saying that's all you can have, right. If you're outside the image, then the resolvent, you can write it as a Tulblitz operator. The commutant of the unilateral shift just turns out to be the h infinity functions.
00:43:50.120 - 00:44:31.152, Speaker B: Or you can think of this as the analytic tuplets operators. And I've given you a little bit of the outline of the proof. If a is in the commutant, a is going to take a polynomial to p times a of one. And you can make an argument that a of f takes f times a of one for any f in h two, let's back to the spectrum here. There's the essential range. Brown and Hamas and then Hartman and Winter have different versions of this. So you're combining them all, and you have a.
00:44:31.152 - 00:45:12.964, Speaker B: We don't know the spectrum all the time. Well, we have results, but a most general result is that the spectrum contains the essential range and is contained in the closed convex hull of the ascension central range. And if you're self adjoint, you actually get the spectrum is an interval. Right. And by the way, the spectrum is always a connected set. All right, let me mention the kernel of a topless operator. So I have a lot of opportunities to get in trouble here because I'm going to leave out a lot of results.
00:45:12.964 - 00:46:28.120, Speaker B: So, kind of an early result of Cockburn says that at least one of the kernel of t phi or t phi bar has to be zero. All right, let me give you an example of this. So, in his talk on model spaces, Stefan Garcia says, if you have an inner function, then the kernel of the adjoint of this analytic tuplets operator is a model space. So that's not the zero kernel, but the kernel of the analytic tuplets operator is going to be these zero one. It turns out that the kernel of a tuplets operator is actually a nearly invariant subspace. So if I have a function, and if so, for any topelet operator, if I have a function in the kernel and it's zero at zero, then let's argue whether the backward shift applied to f is also in the kernel. So let's figure out t of this thing.
00:46:28.120 - 00:47:32.504, Speaker B: So, using the brown Haumos theorem, you get that it's the backward shift applied to this thing, but f is in the kernel, so this will be zero. All right, so it turns out that the kernel of a tulpis operator is a nearly invariant subspace. There's a lot of work on these things, and there's continuing work going on about these. Now, in various different settings, David Hitt actually computed all the nearly invariants subspaces, and they're essentially a model space times an isometric multiplier of the model space back onto the nearly invariant subspace. I don't want to dwell on the details here, but just so you know that the nearly invariant subspaces are known. Now, every kernel of a Toplitz operator takes this form. It's a nearly invariant subspace.
00:47:32.504 - 00:48:26.128, Speaker B: But not every nearly invariant subspace is the kernel of a tuplets operator. And I'll just mention Eric Hayashi and Donald Saracen have results which describe which nearly invariant subspaces are kernels of tuplets operators. Heiyashi, by the way, he's not only known for his great results on kernels of tuplitz operators, but he was also my college calculus teacher way back when. All right, I will end this talk with an inspirational result of Hilbert. So, if I look at this particular toplitz operator, it's a tupelet matrix. So it's a tupelet operator. And if you, you can think about it in a number of ways.
00:48:26.128 - 00:49:26.470, Speaker B: So, first of all, it's the average of the forward shift and the backward shift. It's also the toplitz operator with symbol being cosine theta. Observe a couple things. It's a self adjoint matrix. Also, if you look at the vector 10 zero, this is actually a cyclical vector. So this is a cyclic sofa joint operator. And by the spectral theorem, it's unitarily equivalent to multiplication by x on some l two mu space for some measure on the real line, you can show that the spectrum, spectrum of this toplitz operator is going to be minus one to one and a result of Hilbert.
00:49:26.470 - 00:50:23.334, Speaker B: I'm interpreting it a little bit, is that this matrix is unitarily equivalent to multiplication by x on this l two space of minus one to one. And you have a weight here. And by the way, the diagonalization brings in the wonderful Chebyshev polynomials. So, if you were to write the matrix representation of multiplication by x with respect to the orthonormal basis of Chebyshev polynomials, you will actually get this toplitz matrix T. And by the way, you can also look at cosine and theta. I'm pretty sure that just moves all these halves further and further apart. And there are results of putnam which kind of describe the spectral decomposition of that.
00:50:23.334 - 00:50:34.814, Speaker B: So I've gone 30 seconds over my time, so I apologize. And that's the end of talk number two.
00:50:36.194 - 00:50:51.454, Speaker A: Thank you very much, Bill. Any questions, comments, suggestions? You can shout them out or ask them in chat, as usual.
00:50:52.234 - 00:50:54.794, Speaker B: Is there anything in the chat? I can't see the chat.
00:50:54.834 - 00:50:56.234, Speaker A: No, nothing in the chat.
00:50:56.394 - 00:50:57.214, Speaker B: Okay.
00:50:59.514 - 00:51:06.834, Speaker A: Okay. If there are no questions, let's thank Bill again for wonderful talk, and we'll reconcile.

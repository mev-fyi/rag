00:00:00.160 - 00:00:01.594, Speaker A: Can hear you now. Thanks.
00:00:02.694 - 00:00:04.422, Speaker B: I see somebody nodding.
00:00:04.598 - 00:00:05.910, Speaker A: Perhaps one last question.
00:00:05.982 - 00:00:14.278, Speaker B: So do they see all the blackboards from the online? So what happens is we'll be switching between these blackboard here.
00:00:14.326 - 00:00:16.954, Speaker A: Yes. You guys want to take a look at this?
00:00:18.334 - 00:00:18.910, Speaker B: Okay.
00:00:18.982 - 00:00:19.526, Speaker A: So.
00:00:19.670 - 00:00:26.334, Speaker B: Okay. Okay. But in principle, if I just use these two black ports is better, right?
00:00:26.374 - 00:00:27.158, Speaker A: Exactly. Okay.
00:00:27.206 - 00:00:29.526, Speaker B: Okay. It should be fine. It should be fine. It should be fine.
00:00:29.550 - 00:00:30.082, Speaker A: Okay. Just.
00:00:30.158 - 00:00:30.774, Speaker B: Yeah.
00:00:32.714 - 00:00:34.534, Speaker A: All right. Hey.
00:00:36.354 - 00:01:19.174, Speaker B: Please have a seat. Good morning. I'm Nicola Gigli and yeah, this is the first lecture of my course about the romanian curvature dimensional condition. Informations about this course can be found at the webpage. You know, this course is part of the thematic semester on Mozambique geometry and Lorenzo geometry, which is taking place now at pills. All the information about this course schedule in particular or anything that may occur will be found on that web page. If you need to contact me, please feel free to do this anytime.
00:01:19.174 - 00:01:34.244, Speaker B: I have an email at Fields institute that you also can find on this webpage, but I'm not sure how long it will last, when I will be back in Italy and whatever. If you want. I mean, just a permanent address you can use. You can use this one. So I'm from Sisa, Italy.
00:01:37.104 - 00:01:37.576, Speaker A: Yeah.
00:01:37.640 - 00:01:43.544, Speaker B: Perhaps one of the first small announcements. So next lecture is a schedule next.
00:01:43.584 - 00:01:47.136, Speaker A: Monday, but next Friday there will be no lecture. Okay.
00:01:47.160 - 00:01:57.674, Speaker B: I will be sure to write this down on the website so that even person that are not here can know about this. But, you know, that's all right.
00:02:01.054 - 00:02:01.834, Speaker A: Sorry.
00:02:03.574 - 00:02:11.334, Speaker B: Yeah. Yes, yes. Despite the announcement having been given, you know, only late about this, I'm like, that's good.
00:02:11.454 - 00:02:14.414, Speaker A: All right, what it is.
00:02:14.494 - 00:02:39.918, Speaker B: So what is this series of lectures about? It is about understanding a bit of what it means for a non smooth structure to possess a bound from below on the rich equipment. Okay, so first task is basically understand the definition of the space. I mean, the correct definition of the space.
00:02:39.966 - 00:02:42.406, Speaker A: And this will take at least half.
00:02:42.430 - 00:03:07.988, Speaker B: Of the course, I would say. And then if, you know, if really I'm able to stick enough for the course definition. The other alt is about properties of this basis. Now, where this theory comes from. Well, the starting point is the following here. I mean, if you. If you have been or either line or physically to Sturm's talk a couple of days ago, I'm basically going to repeat something that you already mentioned.
00:03:07.988 - 00:03:11.788, Speaker B: But anyway, for those of you who are not familiar with the theory. So the starting point of the theory.
00:03:11.836 - 00:03:21.728, Speaker A: Is the following result by Sturma and bonus and.
00:03:21.896 - 00:03:40.604, Speaker B: But this is a result, I mean, it's very important that I want to acknowledge that this comes after related results by Otto Villany and even earlier result that goes, I mean, after Cordellera scan.
00:03:43.944 - 00:03:48.408, Speaker A: This is one person, Mekan has a.
00:03:48.416 - 00:03:53.804, Speaker B: Lot of things having to do with displacement interpolation. I mean, this can be traced back to Meccan and.
00:03:57.744 - 00:04:00.584, Speaker A: Sorry, could you please a little larger?
00:04:00.624 - 00:04:03.488, Speaker B: It's really hard to, okay, okay, okay, sorry.
00:04:03.576 - 00:04:04.324, Speaker A: I will.
00:04:06.744 - 00:04:14.632, Speaker B: Yeah. And the theorem tells the following. So let m g it is large.
00:04:14.648 - 00:04:18.684, Speaker A: Enough be remanya.
00:04:25.104 - 00:04:40.454, Speaker B: And I will, I mean, unless otherwise stated, and I don't think I will ever state otherwise, but for me, remaining many of these complete, connected, smooth and without boundary. Okay, so the best demand manifold that we have, then.
00:04:43.514 - 00:04:54.658, Speaker A: The following are equivalent. First condition, the rich curvature of m.
00:04:54.826 - 00:05:05.004, Speaker B: Is uniformly bounded from below by some real number, k. Okay, I will be, I mean, I will be a bit more precise in a second about what this means.
00:05:05.304 - 00:05:11.444, Speaker A: And second, for any couple mu zero.
00:05:12.224 - 00:05:21.204, Speaker B: Mu one of borrell probability measures on m with, let me say, bounded support.
00:05:28.364 - 00:05:34.972, Speaker A: There exists a w two geodesic. And if you have an idea what.
00:05:34.988 - 00:05:40.220, Speaker B: It is, it doesn't matter. I mean, it matters, but I mean, we'll take care of this w two.
00:05:40.252 - 00:05:47.196, Speaker A: Geodesic, let me call it muti interpolating.
00:05:47.260 - 00:06:07.520, Speaker B: So from new zero to mu one such that the relative entropy is k convex along this geodesic. So the Boltzmann Shannon entropy, let me write it, let me write it this way.
00:06:07.672 - 00:06:10.324, Speaker A: Ent vol.
00:06:12.624 - 00:06:15.004, Speaker B: This is less or equal than one minus the.
00:06:16.724 - 00:06:27.548, Speaker A: And volume mu zero three times and volume u one. And then there is a minus k.
00:06:27.596 - 00:06:30.764, Speaker B: Over two t one minus t w.
00:06:30.844 - 00:06:43.764, Speaker A: Two squared u zero new one. Okay, so this is the statement, right? Now let's pause for a second and let's try to understand what this is.
00:06:44.944 - 00:06:49.204, Speaker B: Now, the rich equity. So first of all, rich equivalent, what is rich equal measure?
00:06:50.424 - 00:06:57.872, Speaker A: Okay, if you, okay, is the real number. Yes, if you want.
00:06:57.928 - 00:07:06.984, Speaker B: Let's, let's say that's. So let's envision and the k real number. Then the following two electrical, of course, this is the same k appearing in.
00:07:07.024 - 00:07:08.204, Speaker A: Item one and item.
00:07:10.164 - 00:07:28.148, Speaker B: Now, if you know what the Riemann tensor is, then you can define the Ricci tensor. So the rich tensor is something. So you have a riemannian manifold. At every point it picks two tangent vectors and returns a real number.
00:07:28.276 - 00:07:28.956, Speaker A: Okay.
00:07:29.100 - 00:07:30.836, Speaker B: And it is defined in the following way.
00:07:30.940 - 00:07:35.640, Speaker A: It is just the sun from one.
00:07:35.672 - 00:07:39.304, Speaker B: To n and is the dimension of the manifold of the Riemann tensor of.
00:07:39.344 - 00:07:44.408, Speaker A: V e I w e I, where.
00:07:44.456 - 00:07:50.084, Speaker B: At any point, the eis form an orthonormal basis of the tangent space at that point.
00:07:50.424 - 00:07:53.280, Speaker A: Okay, because of the symmetry.
00:07:53.312 - 00:08:08.374, Speaker B: Now if you know what the Riemann tensor is, perhaps you know that the Riemann tensor is unchanged. If you swap the first two entries with the last two entries, and therefore out of this symmetry, it follows that the Ricci curvature is asymmetric.
00:08:10.714 - 00:08:12.730, Speaker A: Right? All right.
00:08:12.762 - 00:08:27.722, Speaker B: Now if you have a symmetric tensor, it makes sense. I mean, on the space of symmetric tensor, there is a natural ordering, you know, the partial ordering of symmetric tensors. And speaking about rich curvature, greater or equal than k means, I mean, I.
00:08:27.738 - 00:08:30.454, Speaker A: Will write this to mean that.
00:08:32.194 - 00:08:39.530, Speaker B: For every, no vector fields, for every vector field, b vector field, I don't know how to mention it. Vector field.
00:08:39.562 - 00:08:42.978, Speaker A: On m we have that, on m.
00:08:43.146 - 00:09:01.124, Speaker B: We have that the Ricci curvature calculated in the direction vv is greater or equal than k times g of vv. The metric of course is our first symmetric tensor that we have on our.
00:09:01.164 - 00:09:05.812, Speaker A: Manipulate, okay, and now this, so in.
00:09:05.828 - 00:09:12.108, Speaker B: Such as this is, I should write in this way to be, to be more precise, but I will often omit.
00:09:12.156 - 00:09:16.308, Speaker A: This g from the right. Okay, so that makes sense.
00:09:16.436 - 00:09:17.932, Speaker B: Now, if you don't know what Riemann.
00:09:17.948 - 00:09:24.348, Speaker A: Tensor is and therefore what this is about, don't worry.
00:09:24.516 - 00:09:40.580, Speaker B: The important thing that you should know is that the rich tensor is a symmetric two tensor. So that's okay. And it has to do with the geometry of the under eye manifold. And we are going to learn about how bounds on this tensor affects the geometry and the analysis on a manifold in the course of this series of lectures.
00:09:40.652 - 00:09:46.934, Speaker A: Okay, very good. So item one is, you know, define.
00:09:47.554 - 00:09:49.266, Speaker B: Now let's speak about item two.
00:09:49.410 - 00:09:50.894, Speaker A: So what it is this guy.
00:09:51.754 - 00:10:00.706, Speaker B: So the relative entropy functional. For the moment, I will stick to, you know, in this way. So I will think of it as.
00:10:00.730 - 00:10:03.866, Speaker A: A functional, from the space, for the.
00:10:03.890 - 00:10:15.730, Speaker B: Moment, let me take from the space of probability measures, Borel probability measures on m. Let me put a subscript here. We bound that support. You will be clear in a second why something of this for this form.
00:10:15.762 - 00:10:20.734, Speaker A: Is needed to the real numbers, possibly.
00:10:21.114 - 00:10:23.334, Speaker B: The value plus infinity is allowed.
00:10:24.114 - 00:10:27.250, Speaker A: Okay. And this is defined in the following way.
00:10:27.442 - 00:10:39.920, Speaker B: So this takes a probability measure with boundary support, a retard, a real number or plus infinity. And how is this defined? You know, this is the Shannon Boltzmann entropy.
00:10:39.952 - 00:10:43.160, Speaker A: So this is equal to, there are two cases.
00:10:43.352 - 00:11:17.890, Speaker B: Either mu is absolutely continuous with respect to the volume measure, or it is not. Perhaps it has a singular part. Now if it is a singular part, you define the entropy to be plus infinity. If it is absolutely continuous, then it has a density rather than equal density. Say that mu is equal, let's say to rho times volume, where rho is now is an integrable function with non negative, with integral one. And then in this case, the entropy.
00:11:17.922 - 00:11:29.066, Speaker A: Is the integral of rho log rho d mod. Okay, notice that with respect to the.
00:11:29.170 - 00:11:30.970, Speaker B: Conventional common in physics, there is no.
00:11:31.002 - 00:11:34.674, Speaker A: Minus sign over here. So a direct mass.
00:11:35.454 - 00:11:43.874, Speaker B: So the thing with, from the physical perspective as the least entropy, because it's very concentrated in this convention, it has entropy, maximum entropy.
00:11:44.294 - 00:11:47.454, Speaker A: Okay, I guess it's for, just for.
00:11:47.494 - 00:11:53.550, Speaker B: Historical, there is no excuse just for historical reasons how things have been came out in this.
00:11:53.662 - 00:11:54.394, Speaker A: Okay.
00:11:56.294 - 00:12:09.856, Speaker B: Now one comment. In order to give this definition, I should be sure that this guy here is integrable. Now it is because I'm sure that it's integral, because I assume the measure.
00:12:09.880 - 00:12:12.144, Speaker A: Mu two have bounded support, right?
00:12:12.224 - 00:12:28.624, Speaker B: So this integral, this integral, this integral, that in principle is an integral over the whole manifold. In fact, it's an integral over just the support of the manifold of the measure. And this, so because, you know, the function z log z has both positive.
00:12:28.664 - 00:12:30.710, Speaker A: And negative parts, right?
00:12:30.822 - 00:12:51.566, Speaker B: But the contribution of the negative part is for sure finite, because I'm integrating over, over, you know, a set of finite, finite masters. Okay, it's bound, I guess z log z is bounded from below by minus one over here or something, this form, so it's uniformly bounded from below. So they couldn't, so here, something of the form plus infinity, minus infinity does.
00:12:51.590 - 00:12:54.510, Speaker A: Not, okay, so be cautious when for.
00:12:54.542 - 00:12:58.046, Speaker B: Instance, you want to compute the entropy even on the, on RD or even.
00:12:58.070 - 00:12:59.908, Speaker A: On r, it's not that any probability.
00:12:59.956 - 00:13:05.964, Speaker B: Measure as an entity, because in principle you can have a troubles, you know, of this. So just a little bit of care.
00:13:06.044 - 00:13:12.148, Speaker A: Okay? All right, I can relax.
00:13:12.196 - 00:13:38.142, Speaker B: In fact, soon we will relax this bound. So basically what you don't want is that, is that the contribution of the negative part is plus infinity, I mean, or minus infinity according. So you don't want the mass to be too much spread out with respect to how much is spread out, the mass of the reference. Okay, but for the moment, I mean, we will take care of this. But for the moment, this is, you know, perfectly viable.
00:13:38.318 - 00:13:41.954, Speaker A: Okay, so now I've defined the energy.
00:13:43.294 - 00:14:12.154, Speaker B: Now it only remains to define what it is. This w two jurisdict, okay, which I will not actually do. Now it takes time, I will do, but I want to at least, at least a few of the properties of this w two geodesics. So, first of all, the interpolation that is known as displacement interpolation, or Wasserstein interpolation or optimal transport interpolation, it has nothing to do, there's nothing to do with the classical affine interpolation.
00:14:12.314 - 00:14:13.018, Speaker A: Okay?
00:14:13.146 - 00:14:40.124, Speaker B: So. And, okay, I have to say, I'm a bit emotional in saying this in front of Robert Mechan. I mean, this displacement approach is basically the first thing that I've learned about, you know, real research world when I was an undergraduate. This crazy thing about interpolating measures in an absolutely non linear way and looking back at how much history has been created upon this is quite amazing. So it is not. So it is not. Sorry.
00:14:40.124 - 00:14:46.068, Speaker B: End of the personal. Let's go back. So, this is not, uh, one minus.
00:14:46.116 - 00:14:48.884, Speaker A: T. There's nothing to do with this. Okay?
00:14:48.924 - 00:15:15.464, Speaker B: Absolutely nothing to do. Um, perhaps a first intuition about what this is, is if you think in the particular case where mu zero is a delta at some point, and mu one is a delta on a different point, then mu t, a choice, at least a choice of mu t would be, uh, put mu t, the delta at some gamma t with gamma geodesic.
00:15:18.444 - 00:15:24.852, Speaker A: From x to y. Okay, so you have two points, a.
00:15:24.868 - 00:15:53.108, Speaker B: Direct mass, direct mass over there. You look, you know, the geometry of your underlying space. You have a romanian manifold, so you have a Judisc, by the way, for me, is always globally minimizing Judesiq, okay? Not the more common use on, you know, romanian context of local minimize. In metric geometry, these things are basically only globally minimized. And then you just basically follow the Judisc and you put a delta, you.
00:15:53.116 - 00:15:58.156, Speaker A: Know, time t. More generally, I don't.
00:15:58.180 - 00:16:40.428, Speaker B: Want to be precise now, but more generally, if mu zero has a certain distribution of mass, mu one another distribution of mass, what optimal transformation for that is basically to, you know, almost, almost, I mean, under, I mean, in this case, I guess under fairly general conditions, Robert proved that what happens is a kind of a generalization of this construction. So, to mu zero, almost every point, it is associated a target point in such a way that the low of the map coincides with the distribution of the target measure. And then the optimal, the basic interpolation will be, you know, basically following each of these genetics at the same time.
00:16:40.516 - 00:16:46.356, Speaker A: Okay, now, from a, you know, from.
00:16:46.380 - 00:16:47.988, Speaker B: A more rigorous perspective, what you should.
00:16:48.036 - 00:16:50.308, Speaker A: Know, I mean, that should be sufficient.
00:16:50.356 - 00:17:01.844, Speaker B: For today, and actual definitions and theorems will come later on. But what you should know is that, and this is all more generally, if.
00:17:02.544 - 00:17:07.528, Speaker A: Say, x, d, is a, okay, let.
00:17:07.536 - 00:17:13.840, Speaker B: Me, let me, let me, let me perhaps exaggerate with the complete, I mean, complete and separable.
00:17:13.912 - 00:17:16.336, Speaker A: Let me see, you don't really need.
00:17:16.360 - 00:17:20.844, Speaker B: Any of these, but separable. But let me, I will stick this assumption matrix space.
00:17:24.504 - 00:17:25.538, Speaker A: Questions.
00:17:25.736 - 00:17:30.110, Speaker B: I didn't say, but I mean, feel free to ask questions and interrupt at any point.
00:17:30.142 - 00:17:30.754, Speaker A: Yes.
00:17:33.214 - 00:18:08.884, Speaker B: Well, I mean, to define the distance, you don't need other computers. No, separate, yeah, but I mean, you typically, you can replace, I mean, you just want the support of the measures to be separable. I mean, and that's, but I mean, yes, I mean this really nitpicking, you know, and polishing or generating the theory, I mean, everything will happen in the competence of a then. Well, there exists, okay, I mean, that's a big claim, but you know, one can define, and one can define.
00:18:12.384 - 00:18:12.648, Speaker A: You.
00:18:12.656 - 00:18:23.166, Speaker B: Know, a distance on, on the space. Okay, let me, let me first say something which is not really true of.
00:18:23.190 - 00:18:25.478, Speaker A: Borrell probability measures, okay?
00:18:25.566 - 00:18:28.394, Speaker B: And this distance, I will call it w two.
00:18:31.414 - 00:18:32.154, Speaker A: And.
00:18:34.014 - 00:19:12.306, Speaker B: So, a bit of history, w comes from Barste Stein, that actually has nothing to do with international distance. In fact, this distance should be called Cantorovich or Kantorovich Rubristein kind of distance. Luckily, in his first work on optimal transport, Kantorovich used the word w to mention the work needed to make transport from one mass to the other. So, let's pretend that this is work, so we respect, you know, Kantrovich original paper of tremendous impact on the field. So this has w two and this distance, and this distance is the following, properly.
00:19:12.330 - 00:19:14.622, Speaker A: So, well, actually, let me, let me.
00:19:14.638 - 00:19:25.070, Speaker B: Let me put this way, so I should be more precise. What is p two of x? P two of x. This is the space of Borrell probability.
00:19:25.142 - 00:19:29.166, Speaker A: Measures with finite second moment.
00:19:29.230 - 00:19:32.594, Speaker B: So, such that the integral of distance squared.
00:19:34.534 - 00:19:38.326, Speaker A: Mu is finite for some.
00:19:38.430 - 00:19:43.824, Speaker B: So, the finiteness of this integral is independent from the chosen point x bar.
00:19:45.084 - 00:19:47.652, Speaker A: Okay, the value, of course, depends on.
00:19:47.668 - 00:20:12.780, Speaker B: The point, but the fact that this is finite does not. So, this set is a well defined subset of border probability measures, and certainly contains all the measures with bounded support. Because if the support is bounded, if nothing happens outside a certain bounded set, this interval is finite and can be bounded by two, you know, the radius, the diameter of the support, and, and, and what turns out is that the.
00:20:12.812 - 00:20:18.984, Speaker A: Space p two, x w two is.
00:20:22.004 - 00:20:52.044, Speaker B: First of all, it's complete and separable, much like the space x. Yes, absolutely, absolutely, yes. So since x is complete and separable, p two of x is also completely separable. Thanks for clarifying. This, and second, has geodesics. Well, is a geodesic space.
00:20:53.904 - 00:20:55.724, Speaker A: If x.
00:20:59.924 - 00:21:17.356, Speaker B: So if you follow the lectures by Alexandre Licha, Coranto and Petrunin, you should have an idea of what geodesics on a metric space are. If that's not clear to you, let's just pretend that cards of shortest length. Okay, I will be.
00:21:17.380 - 00:21:20.068, Speaker A: Of course I will, you know, prove all of this.
00:21:20.156 - 00:21:34.304, Speaker B: For the moment, I'm satisfied with the heuristic description. And what is it I want to say? And, and by the way, by the way, the original space xt always isometrically embedded in here.
00:21:34.464 - 00:21:40.440, Speaker A: So the map x to delta over x.
00:21:40.552 - 00:21:42.644, Speaker B: Can you read online if I write over here?
00:21:45.784 - 00:21:47.164, Speaker A: I hope so. Okay.
00:21:48.444 - 00:22:00.144, Speaker B: Okay, thanks. Is an isometric meaning that the distance, the w two distance between delta X.
00:22:00.484 - 00:22:03.212, Speaker A: And delta y is always equal to.
00:22:03.228 - 00:22:17.544, Speaker B: The distance between the base points x and y. Okay, you can take this as a, you know, first, little but significant information about the fact that this w two distance is related to the geometry of the underlying space.
00:22:17.704 - 00:22:20.312, Speaker A: At least notice that, for instance, if.
00:22:20.328 - 00:22:29.752, Speaker B: You pick, if you put here total variation distance or procure distance or other distance typically not originating from optimal transport, you will not get this equal.
00:22:29.888 - 00:22:30.496, Speaker A: Okay?
00:22:30.600 - 00:22:53.204, Speaker B: So a little bit of, you know, the geometric significance of the optimal transport theory into matrix geometry is, you know, at least intuitively, due to this kind, this kind, the basic information, okay, now, if you accept this as sort of a truth, okay, as I encourage you to do for the moment, then at least, you know, the statement makes sense.
00:22:55.144 - 00:22:56.072, Speaker A: Right? Because.
00:22:56.128 - 00:23:06.084, Speaker B: So now, a romanian manifold, of course, is a metric space. When you use the, you know, the classical distance by minimizing the actual curves.
00:23:07.184 - 00:23:08.560, Speaker A: These are the basic space.
00:23:08.712 - 00:23:25.800, Speaker B: So it makes sense. So there are w two judicial between measures. In fact, in most cases of interest, it is unique, thanks to McCann's result. But for the moment, I don't really matter about this. And this makes sense. Okay, sorry, I forgot here to say that this should be true.
00:23:25.912 - 00:23:30.360, Speaker A: For every t, maybe it was two years.
00:23:30.472 - 00:23:31.862, Speaker B: For every t between zero and one.
00:23:31.928 - 00:23:37.658, Speaker A: Okay. Okay. Now, I will take.
00:23:37.706 - 00:23:51.618, Speaker B: I will take a little bit of time. I mean, a few lectures will be needed in order to properly introduce with all the details, the this w to distance. For the moment, I'm satisfied. I'm satisfied with this informal description, and I want to look at the structure.
00:23:51.666 - 00:23:53.482, Speaker A: Of this theorem, and I want you.
00:23:53.498 - 00:24:00.954, Speaker B: To compare this theorem to the following well known result. Let me read this.
00:24:20.974 - 00:24:27.334, Speaker A: Let f from rd into r business.
00:24:33.274 - 00:24:34.374, Speaker B: Then the following.
00:24:39.194 - 00:24:43.054, Speaker A: First, the Hessian of s, the Hessian.
00:24:43.954 - 00:24:47.894, Speaker B: Of f is bounded from below uniformly and, say nk.
00:24:50.614 - 00:24:51.574, Speaker A: It'S bounded from below.
00:24:51.614 - 00:24:54.434, Speaker B: By k. Or I should say k times the identity.
00:24:55.414 - 00:25:02.798, Speaker A: The hessian ismatic tensor makes sense whether this is true. And two, for every x and y.
00:25:02.966 - 00:25:12.694, Speaker B: In Rd, we have the convexity inequality, that is to say f. Well, let me write it. F at the t intermediate point between x and y.
00:25:12.734 - 00:25:17.784, Speaker A: So that should be one minus t. X plus ty.
00:25:18.444 - 00:25:20.564, Speaker B: This should be less or equal than.
00:25:20.604 - 00:25:31.172, Speaker A: One minus t plus t. Sorry. F of x plus t times f of y minus.
00:25:31.268 - 00:25:34.188, Speaker B: I guess k over two, t, y.
00:25:34.236 - 00:25:37.212, Speaker A: Minus t. This square.
00:25:37.228 - 00:25:38.224, Speaker B: This will be next.
00:25:39.204 - 00:25:40.064, Speaker A: Okay.
00:25:41.384 - 00:25:56.004, Speaker B: In which sense are these two theorems analog? Well, let's have a look to this. You know, this should be more familiar, right? I guess you know this. Everybody knows now why this is conceptually important, at least for what I want to say in this course.
00:25:57.184 - 00:26:01.484, Speaker A: Well, the first item, one is a differential information.
00:26:02.064 - 00:26:09.152, Speaker B: You need to know how to take derivatives, and you really need the smoothness assumption in order to be sure that you can compute at every point the.
00:26:09.168 - 00:26:12.464, Speaker A: Hash that's really need. Okay.
00:26:12.884 - 00:26:17.984, Speaker B: The second item does not. You don't need any movement for it.
00:26:19.044 - 00:26:25.588, Speaker A: Okay? And in fact, in fact, say, imagine k equals zero.
00:26:25.636 - 00:26:40.254, Speaker B: So, non Esha, non negative and convex inequality. Once you learn about this identity in high school, typically soon after, soon after, you define a convex function as a function satisfying this inequality, not as a smooth function for radiation.
00:26:40.634 - 00:26:41.402, Speaker A: Okay?
00:26:41.538 - 00:26:47.494, Speaker B: And why, you know why we are taught this way? Well, because this is way more robust.
00:26:48.874 - 00:26:49.734, Speaker A: Okay?
00:26:50.114 - 00:27:08.290, Speaker B: It's also, I mean, it's also more general. It's something that makes sense. You know, in higher generality, you don't need even finite dimensionality or anything of this form of this sort. But for instance, let's, I mean, for the purpose of this course, imagine you have, you, you ponder the following question. You have a sequence fn of, say.
00:27:08.362 - 00:27:11.666, Speaker A: Smooth and convex functions, and this sequence.
00:27:11.730 - 00:27:16.130, Speaker B: Converts point wise to a limit function that for some reason, for some reason, you already know it is moving.
00:27:16.202 - 00:27:16.466, Speaker A: Okay.
00:27:16.490 - 00:27:32.670, Speaker B: In general, of course, point wise convergence of a function is not good. But let's say that you already know, for whatever reason, that the limit function is. Can you deduce that the limit function is also convex? Now, if your only information about convexity.
00:27:32.702 - 00:27:35.246, Speaker A: Is this, of course you can prove it.
00:27:35.270 - 00:27:49.414, Speaker B: But this is tricky, because typically, second, you know, you have a point wise conversion that is not sufficient to per se to pass the limiting in a second order inequality. Of course, the posteriorities, but at least in austerity. Why, if you know about this well.
00:27:49.454 - 00:27:52.150, Speaker A: That'S point wise convert.
00:27:52.222 - 00:27:56.034, Speaker B: You write inequality for f time, you pass the link that nothing easier than that.
00:27:57.034 - 00:27:57.894, Speaker A: Okay?
00:27:58.914 - 00:28:01.106, Speaker B: And moreover, moreover, this inequality in some.
00:28:01.130 - 00:28:04.922, Speaker A: Sense captures the key information about being.
00:28:04.978 - 00:28:17.974, Speaker B: Convex or k convex without the need of relying on, you know, other assumptions that may be unnatural in this context. Why is, I mean, why absolute value shouldn't be a convex font? I mean, alone satisfies the converse.
00:28:19.114 - 00:28:19.854, Speaker A: Right?
00:28:20.754 - 00:28:23.994, Speaker B: Okay, then, with this in mind, let's have a look to this theorem.
00:28:26.094 - 00:28:31.234, Speaker A: Let's observe that item one requires movements. You really need a rich equivalent by two tender.
00:28:31.894 - 00:28:34.382, Speaker B: In order to speak about item one.
00:28:34.518 - 00:28:35.750, Speaker A: You need to have a metric tensor.
00:28:35.782 - 00:28:38.846, Speaker B: Take two derivatives, Riemann tensor, trace it and get the rich.
00:28:39.030 - 00:28:39.710, Speaker A: There's no way.
00:28:39.742 - 00:28:41.714, Speaker B: I mean, other than that, there's no way.
00:28:42.454 - 00:28:43.190, Speaker A: Okay, okay.
00:28:43.222 - 00:28:56.364, Speaker B: You can, you know, tweak a little bit the smoothness assumption, maybe you can do with the siwa one geometric tensor or zero one or whatever. But, you know, you need to take derivatives while item two, there are no, no derivatives involved.
00:28:56.484 - 00:28:56.884, Speaker A: Okay?
00:28:56.924 - 00:29:02.276, Speaker B: All you need, all you need is a measure that you use to compute.
00:29:02.300 - 00:29:06.796, Speaker A: The relative entropy, a reference measure, and.
00:29:06.820 - 00:29:20.604, Speaker B: The distance that induces through these abstract machinery that I, not really, given, you know, too many details about, but for the moment, distance on the base space, you have a distance on the vastness space, and therefore, you can speak about w two interpolation.
00:29:21.944 - 00:29:32.524, Speaker A: Okay, so this leads, or I should say, this led Lord Stuttman Villany propose the following definition.
00:29:46.764 - 00:29:48.092, Speaker B: Let me first give a little bit.
00:29:48.108 - 00:29:51.372, Speaker A: Of setup for me and for the.
00:29:51.388 - 00:29:59.544, Speaker B: Entirety of this class. A metric measure space is always, always without exception, such that.
00:30:01.964 - 00:30:02.700, Speaker A: Always such that.
00:30:02.732 - 00:30:07.024, Speaker B: So, as a metric space, it is complete and separable.
00:30:10.124 - 00:30:20.544, Speaker A: As before. And the reference measure should be borel, non negative, non zero.
00:30:21.204 - 00:30:29.652, Speaker B: I don't want to, you know, trivial, trivial spaces. And, and I want bounded sets to.
00:30:29.668 - 00:30:31.516, Speaker A: A finite mass, okay?
00:30:31.620 - 00:30:36.078, Speaker B: So I don't, so radon is not sufficient. I really want, I really want m.
00:30:36.206 - 00:30:41.114, Speaker A: Of, say, b finite for every b.
00:30:41.934 - 00:30:42.754, Speaker B: Bound.
00:30:47.534 - 00:30:50.774, Speaker A: Of course, any remaina manifold with.
00:30:50.814 - 00:30:57.834, Speaker B: Induced volume measure and distance satisfies this very basic. And then the definition.
00:31:01.274 - 00:31:03.490, Speaker A: This is a lot.
00:31:03.602 - 00:31:31.714, Speaker B: This has been given. Let me write, let me write lost tombidani. I mean, there has been two papers that in the one by lot, Villany and the other by sturm, that came out more or less at the same time, based on the same underlying principle, a little bit of technical differences, but the basic point of the ideas is very common. So let me just quickly acknowledge this definition to the three of them.
00:31:33.694 - 00:31:36.594, Speaker A: We say, so let.
00:31:38.334 - 00:31:43.434, Speaker B: K be a real number. Sorry, not a real number. Okay, we say.
00:31:45.734 - 00:31:51.954, Speaker A: That a metric measure of space as above, x dm has.
00:31:53.734 - 00:31:57.886, Speaker B: A rich curvature greater or equal than.
00:31:57.910 - 00:32:04.074, Speaker A: K. Let me put quotation marks. If for every.
00:32:05.974 - 00:32:13.554, Speaker B: Mu zero, mu one, Borel probability measures on x with bounded support. So b's stands for bounded support.
00:32:13.934 - 00:32:21.062, Speaker A: There exists a w two. Okay, that should say.
00:32:21.118 - 00:32:32.074, Speaker B: I should. Let me be more precise. Weband support and finite entropy. I will comment on this in a second.
00:32:32.234 - 00:32:37.234, Speaker A: There exists a w two geodesic connecting.
00:32:37.274 - 00:32:40.538, Speaker B: Them such that basically, what?
00:32:40.706 - 00:32:46.210, Speaker A: Okay, such that the relative entropy, this.
00:32:46.242 - 00:32:58.574, Speaker B: Time with respect to this reference measure that in my mind is the volume measure, is at the, you know, t intermediate point, is bounded from. From above by one minus t. The.
00:32:58.614 - 00:33:04.794, Speaker A: Entropy of the reference measure at the starting point plus t times the entropy.
00:33:06.294 - 00:33:07.914, Speaker B: Of the target measure.
00:33:12.974 - 00:33:13.630, Speaker A: And then the.
00:33:13.662 - 00:33:17.484, Speaker B: Square distance, much like, much like in the romanian case for everything.
00:33:17.654 - 00:33:18.484, Speaker A: Okay.
00:33:25.104 - 00:33:42.924, Speaker B: So a couple of technical. So perhaps, let me just make a couple of technical. So, first of all, this requirement of finite entropy, you. I mean, this is really just for technical reasons, but morally, if the entropy of either one of these is not finite, then these inequalities do nothing. So there's really no point of insisting or insisting.
00:33:43.064 - 00:33:43.916, Speaker A: It has to do with.
00:33:43.980 - 00:34:19.873, Speaker B: I mean, it's important to be that this year, in the non compact spaces, but in compact or proper space, this is an irrelevant information. Now, this, of course, is in quotation mark. I have not defined the rich Denzel, and I'm not claiming that there is a rich denzel. I'm just saying, in some weak sense, that it is bounded from below by k. In some sense, much like one can interpret this inequality as the Hessian is bounded from below by k, even though a priori, I've given no hash on. All right, what I mean.
00:34:22.173 - 00:34:23.429, Speaker A: Okay, I guess.
00:34:23.541 - 00:34:24.701, Speaker B: Nicolas, sorry.
00:34:24.877 - 00:34:26.181, Speaker A: Please. Yes.
00:34:26.317 - 00:34:27.645, Speaker B: I think you want to assume that.
00:34:27.669 - 00:34:31.053, Speaker A: The metric is yet easy. No, I don't want.
00:34:31.093 - 00:34:38.113, Speaker B: Oh, you don't want to assume that. Thanks for this comment. I don't want. I want the existence of these w two judicial.
00:34:39.194 - 00:34:40.890, Speaker A: Okay. I mean, this is really just.
00:34:40.922 - 00:34:48.058, Speaker B: I mean. Okay, so let's be honest. So if the space is proper, then this condition implies that the metric is judicial, right?
00:34:48.106 - 00:34:48.458, Speaker A: Right.
00:34:48.546 - 00:34:54.146, Speaker B: I don't want to insist on that, because a priority that could be crazy in three dimensional spaces that are not.
00:34:54.170 - 00:34:56.914, Speaker A: Judicial, but such that for any two.
00:34:56.954 - 00:35:04.810, Speaker B: Measures, we find that entropy. I still can find w two judicial connecting them. Okay, but they at least length in a metric spaces.
00:35:04.842 - 00:35:06.526, Speaker A: Right? Say that again. Yeah.
00:35:06.630 - 00:35:25.862, Speaker B: Yes. It's always an inner space. Yes, a length space. So, a consequence of this assumption is that, is that at least on this. So these are, I mean, we're going to this some technical condition, but of course, Vitaly knows a lot about matrix geometry, so it should be precise. So, on the support of this measure. And so any couple of points in.
00:35:25.878 - 00:35:28.742, Speaker A: Support of the measure, maybe there is.
00:35:28.758 - 00:35:54.024, Speaker B: No judiciary, but for sure, as a consequence of this assumption, there is a sequence of curves whose length approaches the distance, the distance between. And in that sense, for m cross m, almost every couple of points that exist as you disable. Okay, in some sense, but these, I mean, you can forget about all of this for the moment. Think that this space is compact and judicial and that you will lose. You will lose nothing about.
00:35:54.604 - 00:35:55.464, Speaker A: Okay.
00:35:57.764 - 00:36:16.984, Speaker B: Perhaps, perhaps one last comment, and then we take a break. A consequence of the fact that I insisted on this being with finite entropy is that I see nothing of what happens on open sets to which the reference measure m gives no mass.
00:36:18.364 - 00:36:19.304, Speaker A: Okay?
00:36:20.004 - 00:36:23.788, Speaker B: So from the perspective of metric measure.
00:36:23.836 - 00:36:27.452, Speaker A: Geometry, the measure is part of the.
00:36:27.468 - 00:36:58.674, Speaker B: Data, and this is where the mass is. And you only care about the shape of your space. Where there is some mass, where there is no mass, doesn't matter, basically. So, in some sense, only the support of the measure that I didn't define yet, but only the close set to where the measure is concentrated, really matter in terms of giving the definition of loss to mobile. Now, let's pause for five minutes and we will resume pregnancy.
00:37:19.894 - 00:37:25.856, Speaker A: I guess, by the way, I forgot, is 1140.
00:37:25.920 - 00:37:49.282, Speaker B: Right, the deadline. Okay, okay, five minutes has passed past. Let's come back. Okay, the mic is on. Let's come back to this overview. There is one important thing that you should know. So if you know nothing about Richie Kulbasure, beside it being a symmetric tensor, there is another thing that you should know that from.
00:37:49.368 - 00:37:49.994, Speaker A: Please.
00:37:54.574 - 00:38:31.654, Speaker B: Yes, I will not today, so you have to come to the next lecture. Okay, so this material, this material that I'm going to say today, and for the first two lectures, you can find it in Cedric Villany book ottoman transport, all the new. Okay, the book is very big, so you should select appropriate chapters, but I'm telling you, nothing new with respect to what comes from that book. But I will, you know, we provide more detailed reference later on. So I was saying, one, one.
00:38:33.594 - 00:38:33.906, Speaker A: Thing.
00:38:33.930 - 00:38:52.902, Speaker B: That you should know about Ricci Kurbashul, if you know nothing about it, is, well, first of all, it's a symmetric tensor. And second, geometric and analytic information can extract from a lower reach equivalent bound. Most often, I mean, not always, but most often if it is coupled with an upper dimension bound.
00:38:52.998 - 00:39:00.074, Speaker A: So what matters, what often, not always, but often matters.
00:39:02.374 - 00:39:08.794, Speaker B: In geometric analytic.
00:39:10.914 - 00:39:11.894, Speaker A: Applications.
00:39:17.354 - 00:39:20.374, Speaker B: Is the capping of, you know.
00:39:24.834 - 00:39:25.170, Speaker A: Of.
00:39:25.202 - 00:39:33.294, Speaker B: A lower reach, lower reach bound and an upper dimension bound.
00:39:38.934 - 00:39:42.914, Speaker A: Dynamic. Okay?
00:39:44.134 - 00:39:46.894, Speaker B: So in this statement by Stone Bernice.
00:39:46.934 - 00:39:49.514, Speaker A: There is no upper dimension bound, okay?
00:39:50.374 - 00:40:05.254, Speaker B: But so in some sense, one says, also let me, let me give a definition. So for, for k real number and n real number, not necessarily integer, between one and infinity. One says.
00:40:07.154 - 00:40:13.122, Speaker A: One says that the riemannian.
00:40:13.218 - 00:40:26.414, Speaker B: Manifold mg satisfies the curvature dimensional condition. The, okay, the CDkN condition.
00:40:29.924 - 00:40:32.188, Speaker A: If, you.
00:40:32.196 - 00:40:38.784, Speaker B: Know, the rich equivalent is greater, equal than k and the dimension.
00:40:41.804 - 00:40:42.316, Speaker A: Is less.
00:40:42.340 - 00:40:43.504, Speaker B: Or equal than n.
00:40:48.244 - 00:40:48.964, Speaker A: So in some.
00:40:49.004 - 00:41:06.098, Speaker B: Sense, you can rephrase sturborn's theorem by saying, look, the entropy satisfies this inequality if and only if the manifold satisfies a CdK infinity condition. If you put in upper bound, I plus infinity means no upper bound.
00:41:06.266 - 00:41:09.986, Speaker A: Okay? Now, of course, the first thing one.
00:41:10.050 - 00:41:56.834, Speaker B: Typically thinks about when sees this definition for the first time is why n should be real. I mean, the dimension is integer. So clearly here you could always improve a little bit by taking, you know, the least, the largest interest integer below n. There are reasons for that in some sense, from the analytic perspective, there are situations where the dimension, or the best upper boundary dimension is not an integer number is something else. We will see about this later on. For the moment, I ask you to believe me and what I want to say, another important thing to notice is that there are variants of Sturm boreness theorem that take into account general curve dimensional conditions. So this is the statement basically for CDK infinity, believe me.
00:41:56.834 - 00:42:19.144, Speaker B: You know, there is an analogous statement, or there are actually a plethora of statements depending on many equivalent versions, but where the basic principle is always the same. So you couple you. So a CDKN condition can be encoded in an integrated form in some sense through some sort of convexity like inequality for an entropy like function.
00:42:19.524 - 00:42:21.860, Speaker A: Okay, maybe it's not precisely as simple.
00:42:21.892 - 00:42:39.604, Speaker B: As this in a code, it's something more elaborate. Maybe it's not the integral of rologro, but perhaps integral of some other function of the density or something like that. But, but, you know, the basic idea is the same. Okay, I'm not saying that the finite dimensional variant is a trivial, you know, consequence of the infinite dimensional one, but the basic underlying principle is this.
00:42:39.724 - 00:42:44.416, Speaker A: Okay, so in some sense, this definition.
00:42:44.520 - 00:42:51.040, Speaker B: Is typically, you will find it in the literature as a definition of CDK infinity spaces.
00:42:51.192 - 00:42:52.284, Speaker A: Actually, let me write.
00:42:54.464 - 00:42:58.084, Speaker B: So these are what are called the CD K infinity spaces.
00:42:59.024 - 00:42:59.884, Speaker A: Okay?
00:43:00.304 - 00:43:07.336, Speaker B: But, you know, once you have a finite dimensional analog of this theorem, and I will discuss, you know, sooner or.
00:43:07.360 - 00:43:09.644, Speaker A: Later we discuss what that is, you.
00:43:09.724 - 00:43:23.532, Speaker B: Know, by the analogous, you know, argument. And that's what lost to avid, you can introduce the CDK ten kind of class of matrix measure space that in some sense they have lower reach and upper dimension bound.
00:43:23.588 - 00:43:23.836, Speaker A: Okay?
00:43:23.860 - 00:43:32.424, Speaker B: So CD stands down for curvature, dimension. So the first number is the lower bound on the curvature, and the second number is the upper bound on the dimension.
00:43:34.384 - 00:43:35.124, Speaker A: Now.
00:43:39.744 - 00:43:52.384, Speaker B: From the perspective of application to romanian geometry, in some sense, this class of spaces is not really suitable. And one needs to refine a little.
00:43:52.424 - 00:43:54.404, Speaker A: Bit this class of spaces.
00:43:55.504 - 00:44:46.174, Speaker B: And that is where they are, CD. Because my course is about RCD condition, and this is defined as the class of CDM spaces with an additional requirement. I'm just, you know, so you start hearing a little bit of nomenclature, in some sense, terminology. This is something that I proposed in the 2012. And, and, okay, again, there is a story over here. So, so the path from CD to RCD, which is basically what this course is about. So this course is about first understanding CD and then reaching RCD, and then possibly going back to the romanian world and learning something new about romanian manifold out of this, out of, out of this curvature condition.
00:44:46.174 - 00:45:18.734, Speaker B: So this part. So another, another sort of, you know, sentence that you will hear a lot in my class is about heat flow. And because understanding this guy, this thing and its relation with this corvus dimensional condition, is very much about the heat flow, a topic on which I worked a lot with, first of all, Kuvada and Ota, and then with Ambrose and Savare. In fact, it has been with Ambrose and Savare that the first sort of refinement of this condition, of the CDK and condition appeared, at least in the infra dimensional case.
00:45:20.354 - 00:45:33.134, Speaker A: And so, the plan is for the course, understanding what this is, understanding what this is. So get this.
00:45:35.314 - 00:45:39.738, Speaker B: And then getting back, if time allows, getting back to the marine work.
00:45:39.866 - 00:45:42.130, Speaker A: Okay, one thing that I will not.
00:45:42.162 - 00:45:45.002, Speaker B: Do, and I apologize in advance, but one thing that I will not do.
00:45:45.018 - 00:45:48.046, Speaker A: I will never actually prove this to you, okay?
00:45:48.230 - 00:45:52.326, Speaker B: And that's the reason for this, because to prove this theorem, basically, in some.
00:45:52.350 - 00:45:55.486, Speaker A: Sense, you need to work a lot.
00:45:55.510 - 00:46:12.354, Speaker B: With optimal transport on moot spaces, which is precisely what I don't want to do. I mean, I want to do with optimal transport in not mood spaces. And these sort of, the technologies are different but I promise, I promise that even though you will not have a formal proof, you will get, I promise, a quite clear idea why that leaves the theorem is true. You wanted to say something?
00:46:14.274 - 00:46:19.494, Speaker A: Okay, what else? Please.
00:46:24.474 - 00:46:42.494, Speaker B: Either know a lot about smooth manifolds or develop a lot of machinery. Exactly, exactly, exactly. I want to, you know. Exactly, exactly. That's exactly the point. That's exactly the point. And, you know, even calculus with these, you know, controlled potential dynamism, there is also a bit of geometric measure theory in the smooth case that I don't really want to.
00:46:42.494 - 00:46:51.074, Speaker B: So I apologize. I understand that this is, you know, a little bit incomplete, but I ask you to make this leap of faith and believing in student bonus.
00:46:54.174 - 00:46:56.194, Speaker A: There was one other thing that I want to say.
00:47:06.934 - 00:48:07.572, Speaker B: Okay, so it's proved, right? So we agree that the theorem is true, right? So that's, that's the important thing, right. Okay, very well, very well, very well. So one thing that I wanted to say. So I've mentioned, I have mentioned that, okay, I raised the statement about convex functions, but I mentioned that one of the reasons for which this convex inequality was good was because it allows you to quickly get stability of convexity under weak convergence of functions. And there is an analog of these statement for both CD and RCD conditions. So in some sense, both conditions are stable under weak convergence of metric measure spaces. And the theory really goes back and at least in this rich curvature case, is really very much related to the names of the gromov on one side and the Georgia on the other.
00:48:07.572 - 00:48:50.248, Speaker B: So Gromov is the person that introduced the concept of convergence of matrix spaces, at least in the sense that we are going to discuss during this series of lectures. So the convergence in the so called the measure gravas topology and the George introduced, which is, I mean, this is that sense the best possible convergence or one of the best possible convergence for metric measure structures. And the Georgia introduced the concept of gamma convergence. Gamma convergence is the best possible convergence for lower semicontinuous function and for reasons related to the fact. Okay, I will be very vague, but let me just tell you this. So Ricci curvature is very much related.
00:48:50.296 - 00:48:54.080, Speaker A: To Laplacian and Laplacian as a variational.
00:48:54.152 - 00:49:26.254, Speaker B: Interpretation, a sub differential of a suitable of the divisive planet. And this variation interpretation means that a lot of things that are related to Ricci curve turns out to be, in a natural sense, lower semi continuous functionals. And what happens in this business is that one, when you have convergence of metric measure structures, the relevant lower semicontinuous functionals either gamma converge or satisfy what is called the gamma limit. And this is these two things that we introduce with care, please.
00:49:29.394 - 00:49:29.890, Speaker A: Yeah, yeah.
00:49:29.922 - 00:49:35.954, Speaker B: Three plus one. Yeah, in the chapters. Three plus one out. That's 3.1, actually. So. So I think.
00:49:35.954 - 00:50:05.530, Speaker B: Thanks for this comment. So. So Gromov should be crazy for the idea of. But I mean, I wish. If anybody in the audience either here or online wants to correct me, I'm perfectly fine with it. So the idea of convergence of matrix structures was certainly him. I think it was Fukaya, the first one who actually realized that for convergence, I mean, when Ricci curvature is involved, you know, you should also, in some sense, take care of the convergence of the measure.
00:50:05.642 - 00:50:06.450, Speaker A: Okay.
00:50:06.642 - 00:50:39.574, Speaker B: And then, you know, then after Foucault, Gromo intensity re implemented these ideas in his framework. But I should. Yeah, but I mean, the idea of looking, you know, so there is this green book by Gromov, matrix structures for romanian and romanian space. This is, I think, one of the books with the best possible title ever. So basically, take a romanian manifold, forget about this chart, and look at the metric structure. So that's, that's in some sense, and look at the convergence of it. That's the key point, I would say, that has been introduced by Grohov, and then variance has been.
00:50:39.574 - 00:51:07.382, Speaker B: I mean, metric can be put right in form, or it can be. Well, well, but fair enough, fair enough. But I mean, Gromo's book is extremely clear. What is metric? Oh, I see what you mean. Yeah, yeah. But if there is no tense or, I mean metric. I don't know.
00:51:07.382 - 00:51:12.466, Speaker B: I don't know. That's okay. That's. Maybe everybody has it on feelings about definitions, but.
00:51:12.490 - 00:51:15.746, Speaker A: Okay. Anyway, now, if there are no questions.
00:51:15.770 - 00:51:23.494, Speaker B: I would start with actual math. So top with abstract mumbo jumbo and let's go.
00:51:26.754 - 00:51:27.494, Speaker A: Now.
00:51:30.314 - 00:51:38.370, Speaker B: Working on non smooth structures like an arbitrary metric, measure space can potentially.
00:51:38.402 - 00:51:41.714, Speaker A: Lead, or even not potentially, but actually.
00:51:41.874 - 00:51:53.042, Speaker B: Lead to technical sort of subdivisions and issues. And I don't want this to be an obstacle. Okay, so what I want to do in the today, maybe next time, and.
00:51:53.058 - 00:51:55.306, Speaker A: Maybe for a couple of lectures, lay.
00:51:55.330 - 00:52:21.704, Speaker B: A little bit of ground about a few basic facts, at least about measure theory, on complete and separable spaces, so that you are not cured when you hear something like tightness or Prokorov theorem or disintegration theorem or sort of things of this form. It's nothing too complicated, but it's something that is often scary, especially for students if they've never seen things in this generality. But so.
00:52:24.244 - 00:52:26.572, Speaker A: So for a while I.
00:52:26.588 - 00:52:29.904, Speaker B: Will now do measure theory on polish spaces.
00:52:33.784 - 00:52:35.840, Speaker A: What it is a polish space, a.
00:52:35.872 - 00:52:38.364, Speaker B: Polished space is a topological space.
00:52:39.304 - 00:52:56.724, Speaker A: This topological space, topological space whose topology is induced.
00:52:59.324 - 00:53:11.744, Speaker B: By a complete and separable distance. In fact, okay, let me say paramor.
00:53:13.044 - 00:53:18.956, Speaker A: In fact, to be honest, I will actually work directly with a complete and.
00:53:18.980 - 00:53:38.522, Speaker B: Separable matrix space d x d. But I want to emphasize this point of view, because for a while all these statements are lead topological. And when one does measure theory, I mean, when one speaks on polyspace, it really means that the actual distance is irrelevant. And what only matters is that there exists such a distance, but there is no preferred one.
00:53:38.658 - 00:53:42.974, Speaker A: Okay, very well.
00:53:43.634 - 00:53:50.734, Speaker B: So let me a bit of terminology. So let's say p of x, whatever probability measures.
00:53:53.374 - 00:53:54.422, Speaker A: You know, you have a.
00:53:54.438 - 00:54:00.074, Speaker B: Topological space, so you have open set, so you have Borat sigma algebra, the sigma algebra generated by the sets.
00:54:04.694 - 00:54:14.634, Speaker A: Probability. Um, uh, let me say, I don't know.
00:54:15.454 - 00:54:28.216, Speaker B: Okay, let me start, let me start perhaps starting with the following easy remark. So first of all, if mu is a Borel probability measure, then for every, let me say, let's say b of.
00:54:28.240 - 00:54:30.844, Speaker A: X border sigma algebra.
00:54:37.944 - 00:54:53.032, Speaker B: And the first observation that I want to make, I'm going to improve this soon, but the first observation is that if you have probability measure, then for every Borrell subset you do have that.
00:54:53.088 - 00:55:02.680, Speaker A: Mu of e is equal to the imp of mu of u among the.
00:55:02.712 - 00:55:13.394, Speaker B: U'S that contain e open. And this is equal to the soup among all the circuit continually closed.
00:55:15.574 - 00:55:17.114, Speaker A: Of mu of c.
00:55:18.974 - 00:55:33.834, Speaker B: Okay, this will be, you know, I don't know if today, but either today or Monday will be improved by putting here compact. But for the moment, let me put it closed. Why is this the case? Okay, wash, let me check the class.
00:55:34.174 - 00:55:35.310, Speaker A: So if I want to prove this.
00:55:35.382 - 00:55:55.924, Speaker B: It'S sufficient to prove that the class of Borel sets e, for which this is true, contains the open sets and form a sigma. If I do that sort of by definition of Boresig manager. And so why it contains open sets? Well, if e is open, this is trivially true.
00:55:57.704 - 00:55:58.444, Speaker A: Right?
00:55:59.024 - 00:56:00.568, Speaker B: On the other end, on the other.
00:56:00.616 - 00:56:03.752, Speaker A: End, on the other end, of course.
00:56:03.808 - 00:56:17.114, Speaker B: An open set, you can always write an open set u as the union, okay, over n, union over n of c n where cn is, you know, the set of points in x.
00:56:19.934 - 00:56:20.270, Speaker A: Such.
00:56:20.302 - 00:56:25.982, Speaker B: That the distance between x and the complement of u is greater ego than one.
00:56:25.998 - 00:56:28.714, Speaker A: Over n, you have an open set.
00:56:29.654 - 00:56:30.910, Speaker B: And then you take, you know, the.
00:56:30.942 - 00:56:33.266, Speaker A: Set of points whose distance from the.
00:56:33.290 - 00:56:36.746, Speaker B: Boundary of u is bigger than one over n. And it is clear that.
00:56:36.770 - 00:56:41.922, Speaker A: This old and by monotone, you know.
00:56:41.938 - 00:56:49.214, Speaker B: The monotonicity from below of, you know, measure. So mu of this set is the limit of new OCR.
00:56:49.594 - 00:56:50.490, Speaker A: Okay, so.
00:56:50.562 - 00:56:52.074, Speaker B: So in particular it is this.
00:56:52.234 - 00:56:55.494, Speaker A: Okay, so open set belong to this class.
00:56:56.794 - 00:57:08.434, Speaker B: This collection of Borel sets is clearly stable by passing to the complement, because a little bit of symmetry over here. And so it only remains to prove that it is stable under countable union.
00:57:08.774 - 00:57:10.038, Speaker A: And why it is so.
00:57:10.166 - 00:57:23.046, Speaker B: Well, let's say that. Let's say that you have sets n belonging to, I mean, for which identity is true. Fix epsilon and then find, you know.
00:57:23.110 - 00:57:26.280, Speaker A: Find open sets unit.
00:57:26.382 - 00:57:39.820, Speaker B: Enclose the set cn in this way, in such a way that the measure of en is what is less, is greater or equal than the measure of u. N, I guess, minus epsilon over.
00:57:39.852 - 00:57:42.356, Speaker A: Two to the n and less than.
00:57:42.380 - 00:57:46.364, Speaker B: The measure of cn plus epsilon over.
00:57:46.404 - 00:57:52.696, Speaker A: Two to the n. Okay. And then the union of this n.
00:57:52.760 - 00:58:01.904, Speaker B: You are going to compare this with on one side, the union of the UN. This is open. And it is clear from this condition.
00:58:01.984 - 00:58:07.520, Speaker A: That the measure of u minus e.
00:58:07.632 - 00:58:26.984, Speaker B: Is less than epsilon. And of course, I cannot take as close at the union, the countable union of close set, because that is not closed anymore. But I will take the union from little n to capital n of DCN. So that, so that, I mean, this capital n is so big.
00:58:28.964 - 00:58:29.524, Speaker A: That the.
00:58:29.564 - 00:58:31.104, Speaker B: Measure of.
00:58:33.564 - 00:58:37.212, Speaker A: The whole union up to infinity.
00:58:37.308 - 00:58:45.824, Speaker B: Let me say like this, the union from n plus one to infinity of the cn is less than epsilon.
00:58:46.854 - 00:58:47.502, Speaker A: Okay?
00:58:47.598 - 00:59:09.834, Speaker B: This you can always do by, again, by monotonicity, as capital n goes to plus infinity, these sets, you know, go to zero, meaning the intersection of all. This is the empty set, right? So for any new is a finite measure, no negative. So by monotonicity from above, once you have an upper bound of the measure, you know that epsilon, you can find answers that this is true.
00:59:10.174 - 00:59:10.678, Speaker A: Okay?
00:59:10.726 - 00:59:18.002, Speaker B: And once you've done this, this set is closed. And it is easy to check that, you know, it gives you the corner bound.
00:59:18.058 - 00:59:19.654, Speaker A: Okay, so that's the first.
00:59:20.154 - 00:59:22.734, Speaker B: 2Nd thing I want to mention is that.
00:59:30.874 - 00:59:31.854, Speaker A: Is that.
00:59:34.514 - 00:59:44.534, Speaker B: So for any, so for any new signed measure assigned finite measure, more.
00:59:46.514 - 00:59:47.026, Speaker A: Measure.
00:59:47.050 - 01:00:00.690, Speaker B: On x, we, we can, you know. Well, let me first write the formula and then discuss it. The total variation of mu is the real number.
01:00:00.882 - 01:00:05.214, Speaker A: This is equal to the supremum of.
01:00:05.374 - 01:00:18.446, Speaker B: The integral of f b mu among all the f that are continuous and bounded over x. And with, let me say, infinity norm.
01:00:18.470 - 01:00:19.634, Speaker A: Less regular than one.
01:00:21.494 - 01:00:28.074, Speaker B: Let's agree on the notation. So, CBX is the space of functions that are continuous and bounded over x.
01:00:30.194 - 01:00:32.014, Speaker A: B. Sorry. Yes.
01:00:33.034 - 01:00:34.614, Speaker B: C. Yes.
01:00:35.554 - 01:00:36.454, Speaker A: Cv.
01:00:36.914 - 01:00:56.154, Speaker B: And of course, if x is compact, this coincides with the class of just continuous functions. But for x, possibly non compact, I want to be, you know, sure to be able to integrate with it. And so, Cb is a Banach space for trivial reasons. Under the supernova, okay, we denote the sup norm by, you know, the infinity.
01:00:56.194 - 01:00:58.074, Speaker A: Subscription, which of course is a little.
01:00:58.114 - 01:01:26.380, Speaker B: Bit, you know, I should not do this because there is no measure, there is no infinity measure. But let's agree that this is the supreme, okay, not the essential, supreme with the spread. Okay, now what is the total variation? I assume you are familiar with this, but basically, you know that any signed measure can be written in a unique way. And I speak about the hande composition as difference between, between two positive measures that are singular.
01:01:26.532 - 01:01:30.828, Speaker A: Namely, they are concentrated on these joint subsets, okay?
01:01:30.916 - 01:01:56.358, Speaker B: And the total variation is nothing. But, you know, this number is by definition mu plus of the whole space, plus mu minus of the whole space. So notice that in the terminology that I'm choosing, the negative part is still a positive measure. So, so the measure is the difference between these two things, not the sum. So that's why, that's why there is.
01:01:56.366 - 01:01:57.994, Speaker A: A plus over here, okay?
01:02:00.854 - 01:02:05.894, Speaker B: And this is a, you know, a claim to a lemma, okay, lemma, this.
01:02:05.934 - 01:02:09.194, Speaker A: Identity is true, right?
01:02:09.894 - 01:02:13.754, Speaker B: Now the inequality, this inequality is trivial.
01:02:16.114 - 01:02:16.666, Speaker A: Right?
01:02:16.770 - 01:02:31.674, Speaker B: Why is this trivial? Because what is the intro of fdmu? The integral of fdmu is, by the hand, the composition. This is equal to the integral of f. D mu plus minus, the integral.
01:02:31.794 - 01:02:46.526, Speaker A: Of f in the mu minus, right? But this is bounded by one because f is bounded by one, sorry, not by one.
01:02:46.550 - 01:02:54.382, Speaker B: This is. Sorry. This is bounded by the mass of this measure. So f is bounded by one in absolute value. So this is less or equal, if.
01:02:54.398 - 01:02:56.702, Speaker A: You want, of this guy.
01:02:56.838 - 01:03:15.748, Speaker B: And then you are putting up to the value plus plus this guy, right? Now, this is uniformly bounded by one. I take it out and I get mass of mu plus, mass of mu minus, and. Yes, and I get this inequality, this left hand side is less or equal than the sum of these two guys.
01:03:15.876 - 01:03:17.852, Speaker A: All right, so let's go, let's go.
01:03:17.868 - 01:04:12.730, Speaker B: To the other inequality. So for the other inequality, I used this observation that I made over there. Yes, welcome Cartier's tool. Sure, a lot of interesting stuff. So now let's prove the other inequalities. So what I want to say is that I want to prove now that the total variation is less or equal than the supremum over there. And how do I do this? Well, first of all, I decompose mu as mu plus plus mu minus minus mu minus.
01:04:12.922 - 01:04:13.974, Speaker A: This is mu.
01:04:14.434 - 01:04:43.874, Speaker B: And then, and then I use this remark over here. And I can find a fixed epsilon and then find, find two sets, let's say a positive set and a negative set. These are disjoint. And so, such that mu plus of, you know, x minus, the positive set is smaller than epsilon and mu minus of x minus. The negative set is also smaller than epsilon. See, these are closed. This joint.
01:04:48.094 - 01:04:49.190, Speaker A: I can find this right.
01:04:49.222 - 01:05:18.460, Speaker B: Because mu plus and mu minus are concentrated on to borrell these joint subsets. I apply this relation to these two Borel disjoint subsets and then go, okay, this was for probability measures, but these are finite measures. It doesn't really matter. Well then, now that p and n are closed, let me define the function so fn, let me do. So what do I do?
01:05:18.522 - 01:05:27.624, Speaker A: I do one minus n times the distance from p. And I take the positive part.
01:05:27.664 - 01:05:40.968, Speaker B: When I write over here, I mean that I take the max between this number and zero. Okay, so this function for n is a function that, you know, it is always equal to one on the set.
01:05:41.016 - 01:05:43.176, Speaker A: P. On the set p, the distance.
01:05:43.240 - 01:05:50.086, Speaker B: Is zero, of course, and then it decreases fast to zero, and then it remains zero when you are farther than.
01:05:50.230 - 01:05:52.934, Speaker A: One over m from p. Okay, and.
01:05:53.014 - 01:06:17.734, Speaker B: Ng, analogously with the set n, then I define hn, just the difference between fn and here. What matters is that these functions are uniformly bounded and this function decreases monotonically to the characteristic function of the set.
01:06:17.774 - 01:06:21.262, Speaker A: P. So, chi of a set is.
01:06:21.278 - 01:06:22.566, Speaker B: The function that is one on the.
01:06:22.590 - 01:06:25.110, Speaker A: Set and zero outside, okay?
01:06:25.222 - 01:06:37.794, Speaker B: And because of these, and I guess dominate convergence, for instance, you know that the integral of fnd mu plus goes to mu plus of p.
01:06:39.874 - 01:06:40.614, Speaker A: Right?
01:06:41.594 - 01:06:46.306, Speaker B: And the integral of fnd mu minus.
01:06:46.370 - 01:06:48.534, Speaker A: Goes to zero for the same reason.
01:06:49.954 - 01:07:00.562, Speaker B: Because in both case it goes to measure of this, you know, inter of chi p with respect to the. You combine all of these and you.
01:07:00.578 - 01:07:04.674, Speaker A: Deduce that the integral of of.
01:07:05.774 - 01:07:14.514, Speaker B: Let me go ahead. And you deduce that.
01:07:18.214 - 01:07:19.774, Speaker A: The integral of.
01:07:19.854 - 01:07:30.214, Speaker B: H and d mu, this converges to mu plus of p plus mu minus.
01:07:30.254 - 01:07:33.712, Speaker A: Of n. You just write down, you.
01:07:33.728 - 01:08:01.036, Speaker B: Know, these and the analogous for gn. But this is, you know, because of the assumption, this is at least the total variation of mu minus twice epsilon, right? What you have lost in the two step. But of course, each of these hn is continuous and bounded with norm one because it is the difference of two non negative functions with values between zero and one. So the difference is still between one.
01:08:01.060 - 01:08:02.984, Speaker A: And minus one, right?
01:08:04.004 - 01:08:06.744, Speaker B: Okay, so that, that has also been proven.
01:08:09.244 - 01:08:10.104, Speaker A: All right?
01:08:11.484 - 01:08:20.380, Speaker B: Now, nobody ever uses total variation conversion. So the space of measures or probability measures, signed measures with the total variation.
01:08:20.532 - 01:08:22.060, Speaker A: Distance is a terrible place.
01:08:22.172 - 01:08:34.534, Speaker B: It's not a variable. Uh, innocent, extremely innocent looking maps, I don't know, take, consider, you know, take them out the car that takes t and returns delta t as a probability measure on zero one.
01:08:35.514 - 01:08:36.786, Speaker A: This is non measurable.
01:08:36.930 - 01:08:47.394, Speaker B: If you put, if you put on this space the total variation, the total variation distance, just because the distance between any two direct masses is either zero if they are the same, or two if they're different.
01:08:47.554 - 01:08:50.226, Speaker A: So this map is extremely discontinuous, okay?
01:08:50.250 - 01:09:03.210, Speaker B: So discontinuous that it is not even better, okay? And if you believe in the axiom of choice, not even measurable. Okay, so, so actually one uses typically different topologies on the space of measures.
01:09:03.402 - 01:09:04.134, Speaker A: And.
01:09:14.434 - 01:09:15.954, Speaker B: Let me perhaps.
01:09:17.734 - 01:09:18.398, Speaker A: Well, actually, let.
01:09:18.406 - 01:09:33.614, Speaker B: Me start defining topology. So I'm defining a topology.
01:09:33.774 - 01:09:35.354, Speaker A: So the weak topology.
01:09:42.273 - 01:09:51.893, Speaker B: On, okay, I'll define just on probability measures because I'm a little bit lazy. But the same works for finite signed measures. Px is the coarsest topology.
01:09:59.433 - 01:10:03.753, Speaker A: Topology such.
01:10:03.793 - 01:10:13.274, Speaker B: That for every function f, which is continuous and bounded over x.
01:10:15.614 - 01:10:16.254, Speaker A: The map.
01:10:16.294 - 01:10:19.366, Speaker B: That takes mu and returns the integral.
01:10:19.470 - 01:10:28.274, Speaker A: Of fd mu is continuous. Right?
01:10:30.894 - 01:10:55.606, Speaker B: Clearly there exists a weakest topologist as well. Notice of course, this map is well defined because f has finite mass, the function is bounded. So for sure, you know, this integration is well defined, there is no doubt about that. And I can require this. And if you want, as a consequence of this result, you get that the weak topology is weaker than the total variation, the topology induced by the total.
01:10:55.630 - 01:10:59.810, Speaker A: Variation, meaning that all these functionals are.
01:10:59.842 - 01:11:03.774, Speaker B: Continuous in the total variation distance. Because, because of this rule.
01:11:08.274 - 01:11:15.354, Speaker A: Uh, so a first remark, uh, uh.
01:11:15.434 - 01:11:29.494, Speaker B: By the way, so in literature, this, this time called narrow topology or vague topology, according to, you know, a bit, a little bit on the literature, I will just take two weeks topology, just for simplicity. Well, a couple of remarks.
01:11:29.574 - 01:11:32.238, Speaker A: First of all, why am I using.
01:11:32.326 - 01:12:11.230, Speaker B: Cb x in place of the space of continuous functions with compact support? I mean, that's the question that one can answer. The one could wonder, and the answer is that I'm only assuming that the space is completely separable. I know nothing about compact sets on these spaces. And in particular, it could be that any compact set is actually empty in theory, like, you know, for Banach or reverse spaces of infinite dimension. And if that's the case, any function that is continuous with compact support, it must be automatically identically zero. So you don't really get any, okay, so you really need to enlarge a little bit, the space of function. Okay, now there is a little bit of choice here.
01:12:11.230 - 01:12:27.934, Speaker B: So if you stick with finite measures, this is perhaps the best option. If you want to, if you want to deal with measures that are only finite on bounded sets that perhaps you should impose, you should just work with functions that have also bounded support of thing of this sort. But, you know, for me, I will be satisfied.
01:12:30.354 - 01:12:33.386, Speaker A: No, no, no, bounded, no, no.
01:12:33.450 - 01:12:37.154, Speaker B: Continuous and bounded function. Bounded function. Sorry, sorry.
01:12:37.194 - 01:12:38.810, Speaker A: This is CB. Sorry.
01:12:38.842 - 01:12:43.194, Speaker B: Okay, maybe, maybe I should clarify a bit the terminology.
01:12:43.274 - 01:12:46.452, Speaker A: So, CB, continuous and bounded.
01:12:46.618 - 01:12:50.872, Speaker B: If I want bounded support, you know, I write b's, the bounded support.
01:12:50.968 - 01:12:52.448, Speaker A: Okay, I put it.
01:12:52.456 - 01:13:07.664, Speaker B: Thanks for Robert, I mean, and please, if anything creates, you know, even a little bit of confusion, especially in these first lectures, just feel free to ask, so what is the one? So why are we not using continuous.
01:13:07.704 - 01:13:10.244, Speaker A: Function with compact, can you say that again?
01:13:10.584 - 01:13:20.808, Speaker B: Because it could be that my matrix space is such that any compact subset has empty interior. Imagine l two.
01:13:20.936 - 01:13:24.216, Speaker A: Okay, now if that's the case, any.
01:13:24.280 - 01:13:39.304, Speaker B: Continuous functions with compact support has to be identically zero, right? Because, because if f is, you know, continuous, let's say we compact support, then, then the set where f, say, is.
01:13:39.344 - 01:13:43.992, Speaker A: Different from zero, this is open because.
01:13:44.168 - 01:13:47.280, Speaker B: By continuity and contained in the support.
01:13:47.352 - 01:13:49.884, Speaker A: Of f, which is compact.
01:13:50.904 - 01:14:04.364, Speaker B: So if by any chance the only, you know, all the compact subset of empty interior, this means that this set must be empty. So the function must be identically zero.
01:14:05.544 - 01:14:15.504, Speaker A: Is that clear? Yes, thanks. Okay. Okay.
01:14:17.884 - 01:14:44.520, Speaker B: Remark. So these topologies are the weak topologies. How can I prove this? Well, I need to prove, it is sufficient basically to prove the following fact, that if the interval of fd mu is equal to the integral of fd.
01:14:44.552 - 01:14:51.624, Speaker A: Mu for every f in Cb, then.
01:14:51.704 - 01:14:53.564, Speaker B: Actually mu must be equal to nu.
01:14:56.184 - 01:14:57.032, Speaker A: Do you agree?
01:14:57.168 - 01:15:15.144, Speaker B: Right, because, because if that's the case, it means that as soon as you have two measures that are different, you can find a continuous function for which these two values are different. That continuous function induces a function which is lean, which is continuous on the space of measures.
01:15:15.884 - 01:15:17.916, Speaker A: And you know, the, you know, you.
01:15:17.940 - 01:15:26.504, Speaker B: Take like the midpoint of the value over here, and that separates, that gives you the pre measure of the, of the two half lines will separate the two measures.
01:15:26.584 - 01:15:31.688, Speaker A: Okay, so, and why is this true?
01:15:31.856 - 01:15:38.864, Speaker B: Well, because basically with the same argument that we have been used, I claim that if this is true, then this.
01:15:38.904 - 01:15:42.616, Speaker A: Implies that, first of all, that the.
01:15:42.640 - 01:15:44.244, Speaker B: Measure of any open set.
01:15:46.504 - 01:15:54.204, Speaker A: Mu of mutual. Why?
01:15:54.324 - 01:16:05.716, Speaker B: Well, because the characteristic function of any open set can be written as supremum of continuous and bounded functions. So notice that chi of u is.
01:16:05.740 - 01:16:13.004, Speaker A: Equal to the soup over n of, okay, what I should pick, I should.
01:16:13.044 - 01:16:16.044, Speaker B: Pick, I mean.
01:16:19.184 - 01:16:20.808, Speaker A: Should be one over there.
01:16:20.976 - 01:16:27.084, Speaker B: Okay, should pick n times the distance between, you know, point and the complement.
01:16:27.704 - 01:16:29.364, Speaker A: And truncate it at one.
01:16:34.824 - 01:17:03.790, Speaker B: So if you, so this is the mean, the mean between this number and one. So for any n, this function is continuous. I'm just truncating a continuous function at level one. So this continues for any, clearly, and it clearly converges monotonically to the characteristic function of u. I mean, if you are outside u, this is identically zero. So that doesn't matter if you multiply by n stays zero as soon as you are inside ultra positive, because u is open. And, and therefore, and therefore, you know.
01:17:03.942 - 01:17:07.262, Speaker A: You, you reach one, okay, but, but.
01:17:07.318 - 01:17:14.660, Speaker B: Now you write, so you write this identity. For these functions, you pass the limit monotone convergence theorem, or dominant convergence.
01:17:14.732 - 01:17:16.504, Speaker A: They both work and you delete it.
01:17:17.444 - 01:17:33.252, Speaker B: But once you have the two Borel probability measures coincide on open sets, you automatically have that they coincide, that they coincide on the whole borert sigma. That's a consequence of the dinking PI lambda theorem. Right? So the class, the class of sub.
01:17:33.308 - 01:17:35.740, Speaker A: Borrell subset for which this is true.
01:17:35.852 - 01:17:47.304, Speaker B: Is closed under relative complement countable disjoint union contains the open set and therefore contact with the brain. Okay, general general measure. All right, so, so these are.
01:17:49.124 - 01:17:49.564, Speaker A: Perhaps.
01:17:49.604 - 01:18:10.886, Speaker B: I want to conclude, if I'm able to, I want to prove that this topology is induced by a distance. Now it would be easy to, to prove. So if the space, if X is compact, because perhaps I will, I will leave a lot of exercise during my lectures. I think, especially in speaking to the.
01:18:10.910 - 01:18:13.038, Speaker A: Youngest, it is important that you try.
01:18:13.086 - 01:18:16.302, Speaker B: To do the exercise, not that you saw, you may not stop, but at least you should try.
01:18:16.398 - 01:18:17.154, Speaker A: Okay?
01:18:17.614 - 01:18:41.454, Speaker B: And either if you succeed or if you fail, feel free to contact me either during the lectures or outside the lectures to, you know, speak about what you do. So the exercise is that the space CBX is the separable if and only x is complex.
01:18:46.554 - 01:18:47.374, Speaker A: Okay.
01:18:51.394 - 01:19:11.054, Speaker B: Well, let me give another couple of exercises. So this is, I mean, this is mildly difficult. This is the next, this is, so the space, the collection of direct masses. This of course, is a subset of the space of probability measures.
01:19:12.074 - 01:19:13.734, Speaker A: This is weakly code.
01:19:23.114 - 01:19:27.520, Speaker B: And if you're up to a little bit of a challenge, ESR and abdomen.
01:19:27.552 - 01:19:31.032, Speaker A: Exercise, this is three and it tells you the following.
01:19:31.088 - 01:19:33.484, Speaker B: So fix a direct probability measure.
01:19:35.384 - 01:19:35.768, Speaker A: And.
01:19:35.816 - 01:19:42.648, Speaker B: Consider the collection of measures probability measures again that are absolutely continuous with respect.
01:19:42.696 - 01:19:49.248, Speaker A: To mu is absolutely continuous with respect to nu. This again is a subset of probability.
01:19:49.296 - 01:19:54.144, Speaker B: Measures, and the exercise asks you to prove that this is weakly bored.
01:19:57.364 - 01:19:57.652, Speaker A: That.
01:19:57.668 - 01:20:01.132, Speaker B: Is to say, belongs to the Boret.
01:20:01.148 - 01:20:15.516, Speaker A: Sigma algebra generated by weekly opening.
01:20:15.530 - 01:20:39.888, Speaker B: Erase this definition. Now, if I were in a case where Cb was a parable that according to the exercise above is true, if and only if x is compact, then, then it would be easy to find a distance induced a weak topology. You basically just pick a countable then subset of this space of boundary continuous.
01:20:39.936 - 01:20:49.172, Speaker A: Please. Thank you. Supernor, thank you.
01:20:49.268 - 01:20:56.980, Speaker B: Uh, let me, I'm not with the Binac norm.
01:20:57.132 - 01:21:00.044, Speaker A: Um, what was I saying?
01:21:00.084 - 01:21:49.674, Speaker B: Okay, so yes, if Cb is a parable, then you know as much like you do when you prove that the dual of a Binax space, the unit ball of the dual urbanac space, is materializable as soon as the original Banach space is separable by the same sort of principle, if Cb was always separable, that would be quite easy to prove that the state of measures is also metallicable with the weak topology, the probability measures. In general, this is not the case, but thankfully there is. Cb is a parable in some sense in the following weaker sense, and this is quite useful. So yeah, we'll not write see XD is always complete and subtle by macro space is always better. There exists a collection d inside CD.
01:21:51.134 - 01:21:52.114, Speaker A: Countable.
01:21:55.294 - 01:21:57.114, Speaker B: Such that the following is true.
01:21:57.414 - 01:22:03.764, Speaker A: For any continuous and bounded function we.
01:22:03.804 - 01:22:04.944, Speaker B: Have that.
01:22:08.404 - 01:22:23.060, Speaker A: F is equal to the soup among all the function g in d g less or equal than f of g point wise, and is also equal to the inf or among all.
01:22:23.092 - 01:22:26.652, Speaker B: The functions h in d h greater.
01:22:26.668 - 01:22:30.398, Speaker A: Or equal than f of h. So.
01:22:30.406 - 01:22:45.514, Speaker B: In the point y sense there is a countable collection. And here the key is countable, okay, such that any function continuous and bounded, you know, can be reached from above at any point by, by, by functions in this countable collection.
01:22:45.894 - 01:22:47.994, Speaker A: Right? So let me prove this.
01:23:03.194 - 01:23:20.564, Speaker B: And the proof of as follows. I tell you first of all, who is, I mean, a brother of d prime and pick a d prime, the set of functions of the following form. So first of all, I fixed a.
01:23:20.604 - 01:23:26.476, Speaker A: Sequence dense in x x is a parable.
01:23:26.540 - 01:23:28.316, Speaker B: So I have a countable collection of.
01:23:28.380 - 01:23:30.572, Speaker A: Dense guys, and then I do the following.
01:23:30.628 - 01:23:33.492, Speaker B: I pick functions of the form distance.
01:23:33.548 - 01:23:37.116, Speaker A: Function from one of these guys multiplied.
01:23:37.180 - 01:23:47.936, Speaker B: By a rational number plus another rational number. And then I take, you know, max, mean rational and maximum. So herefore, you know, n is in.
01:23:47.960 - 01:24:14.500, Speaker A: N and a, b, c, and d are rational. This is a countable collection. And I claim that for any f in Cbx and for any point we have, that f of x is equal to the soup among all, let's say.
01:24:14.532 - 01:24:18.104, Speaker B: G prime in d prime, g prime less.
01:24:19.564 - 01:24:20.492, Speaker A: Okay, um.
01:24:20.588 - 01:24:44.054, Speaker B: Okay, let me say, okay, I have to correct the statement. I have to say something, something stronger than that. And this equal to the, of course, I mean, h prime in d prime, h prime h. I mean, this is, they are exactly the same statement. So actually here I can do something, something stronger, I can do something better. I can say that. Let me make a stronger statement.
01:24:44.954 - 01:24:48.494, Speaker A: So f is the, is.
01:24:50.194 - 01:24:54.298, Speaker B: The limit in n of gn and is also.
01:24:54.346 - 01:24:58.290, Speaker A: Equal to the soup in n of.
01:24:58.322 - 01:25:03.614, Speaker B: Gn for some, you know, increasing.
01:25:06.414 - 01:25:06.918, Speaker A: Increase.
01:25:07.006 - 01:25:16.350, Speaker B: In sequence gn inside d. And also f is also equal to the limiting.
01:25:16.422 - 01:25:30.862, Speaker A: N of Hn and equal also to the inf. I apologize for this, for this mistake of hn for some, you know, decreasing.
01:25:31.038 - 01:25:39.774, Speaker B: Or, no, I mean, increasing and decreasing is always in the weak sense, not increased sequence.
01:25:42.994 - 01:25:45.094, Speaker A: Hm. Okay.
01:25:47.434 - 01:25:49.530, Speaker B: Here the limit means the point wise limit.
01:25:49.562 - 01:25:53.570, Speaker A: Right again. Or the, you are taking point wise.
01:25:53.602 - 01:25:55.018, Speaker B: Limit of the function point wise.
01:25:55.066 - 01:26:03.294, Speaker A: Point wise. Point wise. Thanks for asking. And same here. Right.
01:26:05.154 - 01:26:12.922, Speaker B: And the hypothesis you are assuming for x is just complete and separable. Just like, say that again. Sorry. X is complete and separable.
01:26:12.978 - 01:26:13.658, Speaker A: That's it.
01:26:13.786 - 01:26:18.466, Speaker B: That the metric space is always complete and circle. We not write it every time just because.
01:26:18.530 - 01:26:19.494, Speaker A: Okay, okay.
01:26:20.154 - 01:26:22.014, Speaker B: There's no other reason. Okay.
01:26:27.934 - 01:26:33.398, Speaker A: No, it does not. I mean, okay, yeah, choose either.
01:26:33.486 - 01:26:36.006, Speaker B: Okay, let's say d d less than.
01:26:36.030 - 01:26:36.594, Speaker A: C.
01:26:38.614 - 01:27:07.332, Speaker B: So, I mean, but what are these functions? I mean, let me quickly conclude the proof of this factor, and then we postpone the fact that the weak topology is induced by distance. To the next lecture. So these functions are a function, basically the following form. You pick a point in this set xn, you look at distance from this point, and you multiply it by a number that you should think is very big. And let's say if the number is positive, the distance function looks like this. And then you perhaps add some constant. So this is not really zero, is the distance plus something.
01:27:07.332 - 01:27:27.746, Speaker B: And then you truncate above. At some level you also truncate below. But this doesn't really matter because you're let me say you're truncating at a lower level, okay? Now what I'm saying is that with functions of this form, it could matter translating from below, but it won't basically. So what I'm saying is that for any function which is bounded and continuous.
01:27:27.770 - 01:27:29.554, Speaker A: At, for any point, you can find.
01:27:29.594 - 01:27:50.016, Speaker B: The sequence of functions of this form such that you are, you know, you pick a point x, and basically you can reach the value of this, this point x by taking, you know, the limit of functions of rational. Yes, it can also, it can also be, yes, upside down. And in this case, you're looking for the soup kind of thing.
01:27:50.080 - 01:27:56.160, Speaker A: You're looking. Okay. Now, in fact, in fact, it's trivial.
01:27:56.192 - 01:28:08.560, Speaker B: To check that with functions of this form. I mean, if you look at it a bit at the picture, you stare at the picture for 1 minute, it will confess you everything you want to know. So think about that and you can prove this result.
01:28:08.752 - 01:28:09.488, Speaker A: Okay?
01:28:09.616 - 01:28:46.324, Speaker B: But once you have this, the conclusion follows easily, because you just define. So, this collection d prime is countable because they have a countable collection of points. And then the coefficients are rationals. And then you just consider, and then you consider d, basically the collection of, you know, finite, I guess so the g's are what I want to. So, g, one veg.
01:28:48.824 - 01:28:52.744, Speaker A: With Gks, gi's.
01:28:52.864 - 01:28:56.456, Speaker B: In d prime, and also union, the.
01:28:56.480 - 01:29:07.956, Speaker A: Mean of h, one prime, h prime, ki is in the prime.
01:29:08.040 - 01:29:11.744, Speaker B: And of course, k is an arbitrary natural number.
01:29:14.724 - 01:29:15.660, Speaker A: Does it make sense?
01:29:15.732 - 01:29:21.108, Speaker B: So you pick, you have these functions, and you start taking, say, the mean.
01:29:21.156 - 01:29:24.424, Speaker A: Of a finite number of those, and.
01:29:24.764 - 01:29:33.908, Speaker B: The max of a finite number, also of those that you should imagine with the ops, I mean, the other direction. And then it is clear.
01:29:33.956 - 01:29:38.906, Speaker A: Now, being this true, this is equal.
01:29:38.930 - 01:29:44.934, Speaker B: To the soup of a countable collection. The functions in d prime are countable, so those that are less than f are also countable.
01:29:45.994 - 01:29:47.346, Speaker A: And I have the soup.
01:29:47.450 - 01:30:03.364, Speaker B: This soup is actually also equal to the limit of the increasing sequence made by the first function, the max of the first two, the max of the first three, et cetera, et cetera, et cetera. And then you are producing an increasing sequence, or at least not decreasing sequence, that is point wise, converging to f.
01:30:05.424 - 01:30:11.736, Speaker A: Okay. And similarly for the upper bound. Right, okay, so my time is over.
01:30:11.840 - 01:30:20.164, Speaker B: So for today. For today, that's all. I will continue on Monday for the, for the next lecture. Monday, 10th, please. There is a question.
01:30:23.984 - 01:30:24.464, Speaker A: Deeper.
01:30:24.504 - 01:30:35.102, Speaker B: This is deeper. At the moment, I. So, at this level, I have not yet defined d. I'm just defined, you know, another set which is d prime, which is. Which is. Which is this. And I'm claiming that this is true.
01:30:35.238 - 01:30:36.702, Speaker A: And the proof.
01:30:36.798 - 01:30:47.334, Speaker B: I didn't give you the proof. I just draw the picture. But I hope this is, you know, convincing enough using the continuity of f that you can. There was another question, maybe.
01:30:47.374 - 01:30:56.018, Speaker A: No. Ah, okay.
01:30:56.066 - 01:31:00.374, Speaker B: Okay. Okay. Glad. I have no idea what that means, but I'm sure.
01:31:04.834 - 01:31:08.082, Speaker A: Okay, okay. Okay.
01:31:08.178 - 01:31:11.054, Speaker B: About lectures, about when. Okay, okay.
01:31:14.594 - 01:31:16.330, Speaker A: Email address or whatever.
01:31:16.442 - 01:31:17.214, Speaker B: Okay.
01:31:18.554 - 01:31:19.002, Speaker A: Yeah.
01:31:19.058 - 01:31:38.204, Speaker B: I mean, personally, you know, if you. If you want to write me for this, you can and I will. But, you know, lectures will be listed online, so you can do by yourself. But I guess I think that the decision is important if you are a student of University of Toronto that wants to give the exam and get, of course, the credits for that. But I mean, this matters will surely.
01:31:39.144 - 01:31:41.704, Speaker A: Okay, that's it. Thank you.

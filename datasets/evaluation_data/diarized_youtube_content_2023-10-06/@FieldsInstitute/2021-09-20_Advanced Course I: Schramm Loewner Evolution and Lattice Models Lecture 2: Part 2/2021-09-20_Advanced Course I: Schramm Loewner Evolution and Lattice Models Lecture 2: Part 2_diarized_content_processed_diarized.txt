00:00:03.160 - 00:01:01.146, Speaker A: Okay, welcome back everybody. And let me quickly recap the end of the last hour because there was a question about boundary conditions. So what we did, we talked about q state spot model with this exciting probability of configuration. So you have spins from one to q assigned to each vrtx and then your probability configuration adjust this. So you really like to have all of them have the same spin because when the spins are different, that is dependent, beta is some number bigger than zero. And here we want to add boundary conditions. And that was the question about.
00:01:01.146 - 00:02:03.960, Speaker A: So you take any subset of the vertices, anything from the point of view of our later discussion of scaling limits at everything boundary would be the collection of vertices of rescaled square lights, closes to the boundary of the domain. But you take any subset of the set of vertices and you only consider vertices with given values on this boundary. So that's your boundary conditions, given values. Again, that would depend on certain discussions. And then we talked about fortune Castellan clusters. And again, boundary is the same. You select any subset of vertices the same beam, and you only first look at the edges between vertices and b and you fix configuration for them.
00:02:03.960 - 00:02:51.060, Speaker A: You fix openness or closeness only for them. For everything else, it's business as usual. They can be open or closed. So let me remind you that this random cluster model is a model where you assign now weights to each edge and, well, you are saying, sorry, you open a closed edge and then weights of the configuration is this. It's proportional to just the standard floating of non fair coin, p to open, one minus p to close for each edge. But then you weigh it by the number of clusters of 1.6 and again with boundary conditions.
00:02:51.060 - 00:03:51.784, Speaker A: That's what happens then for our coupling. So our coupling, remember is we flip a fair coin, but the way we do it, non firecoin rather, but the way we do it, we only look at edge configurations which are compatible with spin configuration. So originally we start with a collection of spins. So we assign spins and then we only look at configurations which can join things with the same spin. So you are not allowed by this thing to join objects of different, to join vertices of different spin. And what is the boundary condition? It's the same. So for boundary you need to fix spins on the vertices.
00:03:51.784 - 00:05:19.836, Speaker A: And for every edge you just fix what it would be. So for every edge which is strictly inside the boundary, user make it open a clause. So in my semi example here, you would fix, say the value of this edge, you would fix the value of this edge, say maybe this edge you leave open, you leave close, you open this and so here you maybe close this and open this, but you don't touch anything else. So in here you join this, but everything else should be non assigned. And again, for on boundary you only need to consider things, you can only consider things which are compatible to the spin configuration. And now ethereum of Edwards and Sokal is that these two models are essentially the same. More specifically, if you couple them in this called adverse Sokol complex, then probability of having given spin configuration is exactly q state post probability and probability of having edge configurations of k probability.
00:05:19.836 - 00:05:59.488, Speaker A: So actually the right way to do it is you just do Fk model and then at random assign clusters. At random, assign spin spins to every cluster. So two neighboring clusters could have the same spin. It's okay, because you know, you can still leave an edge closed between two clusters, two vertices of the same spin. This condition doesn't prohibit. Okay, so let me prove it. It's actually, I find it a cool proof.
00:05:59.488 - 00:07:25.274, Speaker A: So it's just an easy high school computation. Okay, so let's, let's do it. So let us fix Eta node better. So we sum up probabilities of all compatible lambdas, right? So we, that's precisely what is stated here, right? So we look at it and let's see what happens when we sum up probabilities. So each connected cluster should have the same value assigned. So for each connected classes you have q to the k tilde of Eta number of choices because you, you cannot assign new spins to boundary clusters, right? So if you already have cluster at the boundary, it has at least one point at the boundary which already has a spin. So the spin is already assigned here.
00:07:25.274 - 00:08:16.818, Speaker A: So really the probability. So if you sum up all the things which are compatible with given data, that's it. You would get exactly this, because again, all you can do here, all the different lambdas amount to assigning the same value to each cluster. So for example, at this picture, remember there was this huge cluster in my example. So to this cluster you can assign just one weight and there are few ways to do it. Then to this point you assign one weight. To this point you assign some weight, some, sorry, not weight, sorry, some spin.
00:08:16.818 - 00:09:19.104, Speaker A: So you assign some spin to each cluster and the array there will be exactly q to this k tilde of choices. So this is a trivial computation. The next one is more interesting. So how do we get q ports for configuration of edges, for configuration of vertices? So we fix lambda node and we look at all compatible letters. Now if you have an edge where lambda naught of x is not equal to lambda naught of y. So if you have an edge joining two different spins, then you should close the search. There is no choice.
00:09:19.104 - 00:10:32.104, Speaker A: So again, what are we doing? We look, we start with vertex configuration, and we look at all compatible spin configurations, and we can, well, how many of them would we have? But all other edges can be both open and closed. And let's see, what is the relative fate, then of each such thing? So we sum things up here. Well, first, there is this factor you need to sum to take number of edges for which lambda of x is not equal to lambda five. And this, all of them are closed. So the weight of this is of each of them is one minus p. And then you take the product. Remember that the probability of each configuration, this model, is one minus p to the number for edges of each closed multiplied by p to the number of edges which are open.
00:10:32.104 - 00:12:27.482, Speaker A: And now here, if edge is between two things of the same, of the same spin, what could happen is the you either make it open or you make it closed, right? So you can do both things. And I don't know why I wrote this, p squared plus two, p plus one minus p squared, because this is just p plus one minus p. Because for each edge with joins things of the same spin, you have p in the product. So you have a thing with p here. And the thing with one minus p here, p plus one minus p is one. So eventually that would be the relative weight as compared to other configurations of your particular. Well, of all compatible items, this is just one minus p to the number of open, to the number of closed edges, to the number of, sorry.
00:12:27.482 - 00:13:06.732, Speaker A: To the number of things where lambda of x is not equal to lambda five. And now let's remember that our choice of p was one minus e to the two beta. So one minus p is e to the minus two beta. That's exactly. That's exactly. Would be the Q states. What's weight? Okay, so questions about this again.
00:13:06.732 - 00:14:01.336, Speaker A: It was invented by physicists, but it's physicists, but it's purely probabilistic, purely combinatorial proof, and very easy. Okay, so at this moment you say, okay, so you just introduced two different models. You explained essentially that they're the same, but why would anyone care? Well, with random clusters, you can do another cool thing, which is called duality. And duality is the following. So suppose that you have random cluster configuration. So now forget about ports. You just have a configuration of edges and, well, just configuration of edges.
00:14:01.336 - 00:15:26.924, Speaker A: And the probability of a given configuration is given by this, so you have two parameters, p and q. And now Q doesn't have to be integer, right? So you can just put any q you want here as long as it's positive. And so you have this random configuration. And then I claim that for each random cluster configuration, you also have dual configuration on the dual lattice. So remember, the dual lattice consists of faces of your original lattice, and the edges are exactly orthogonal to the edges of your original lattice and dual edges. And the beautiful thing about square light is that of course dual lattice to square lattice is again a square lattice just shifted by diagonally by square root of two if it's unit lattice. And so what configuration would be Lambda star configuration? Lambda star on the dual lattice would be the dual h is open if and only if the original h is closed.
00:15:26.924 - 00:16:20.244, Speaker A: So I tried to draw the correct representation of this for my first example of configuration on the square lattice. So what we do here, again, we just each edge can be either black or red. And if the edge, so if you originally were closed, then duly you are supposed to be open. Okay, so this is our new configuration on the dual lattice. It's totally deterministic at this moment. Give me the configuration original one. I give you a configuration on dual one.
00:16:20.244 - 00:17:52.363, Speaker A: So the claim now this is the lemma that if you start with configuration with Fk model. So I don't know why I called it fj. So if you start with configuration of Fk model, then the dual configuration would also have Fk model with the same queue but with slightly different p. So this is the formal for the duality of p. So for dual probability, remember you throw this unfair coin, so the dual probability satisfies this condition. P star over one minus p star is equal to one minus p over p times q. Okay, so let me prove this, that another combinatorial statement, let me start with earlier formula, that number of open clusters plus number of clusters minus number of dual clusters as a constant, you can convince yourself that this is exactly the formula.
00:17:52.363 - 00:18:55.624, Speaker A: And now let us try to do the computation. So let us try to see that essentially this probability is the same as dual lesser probability with the p star, with this very specific p star. Sorry, this very specific. And in this computation, again, I will heavily use this Euler formula, this form of Euler formula. And here, just to simplify things, this squiggle would mean that it's proportional with coefficient, which is independent of configuration. Because remember, at the end we divide everything by the partition function. So if we divide all the weights by some constant, it's fine.
00:18:55.624 - 00:20:42.048, Speaker A: Okay, so let's start p to the number of open, one minus p to the number of closed q to the number of clusters that our random cluster probability is proportional to one minus p over p number of closed. Why is it because the total number of open plus closed is constant. So if you divide everything by p to the total number of edges, well, we get exactly the same thing. Right, so that's this proportional. So this is not the number of vertices, this is the number of edges, and it's q to the number of clusters. Okay, so now I want to use earlier formula. So this is proportional to one minus p over p times q to the number of closed clusters, to the number, sorry, of closed closed edges.
00:20:42.048 - 00:21:29.254, Speaker A: Again, remember that open plus clusters minus dual clusters is constant. So minus closed plus clusters minus dual clusters is still constant because open plus closed is constant on the given graph. So that's why this, and this are proportional. And well, again, there is some coefficient of proportionality. And this is already good because this guy is the same as this guy. And we are done. So, because this is p star one p star number of door open, q star number of doll cluster.
00:21:29.254 - 00:22:16.574, Speaker A: So this is p star number of doll open, y minus p star number of doll closed, because again, do open plus doll close. It's some number, it's a constant. And we are done. Okay, any questions here? So again, just an easy derivation, but it again sheds light on what should be the critical value of p and critical number value of beta. So remember, first thing, before talking about scaling limits, we want to see that there is criticality. So there is some sort of critical behavior here. And I will explain in a second what it means.
00:22:16.574 - 00:22:53.150, Speaker A: And for this b, it's totally unclear what it should be. But for p, now I will tell you what it should be. And now it's not even conjecture the same. So there is a very special value of p where p is equal to p star. So this is called p. And well, after you solve this, it's sizing equation. P star over one minus p star is equal to one minus p over p times q, and plug in p star equal to p.
00:22:53.150 - 00:23:36.454, Speaker A: You solve it and you would get this. And now there is a theorem by Bifara and Dominion Kapan, whom we saw before that this self doul is critical on the square lattice. So this is, this means the following. When you are less than self dual, you almost surely have no infinite component. So here you would ask me, wait a second, wait second. You are talking about finite graphs and fine, now you start talking about infinite components. I think it's the following.
00:23:36.454 - 00:24:36.694, Speaker A: You can define limit measure on configurations on the whole z two. So there is a process which I would not describe here, but there is a well defined measure on the spin configurations, or in the case of random cluster model edge configurations on the whole zeto. And when p is less than self dual value, there are almost surely no infinite component in this. So the number of edges is small, and so there is, all the connected components of open edges are finite in the limit. Again, this is a different limit from the one I just described. So this is just the limit on the whole z squared. We don't rescale this squared here.
00:24:36.694 - 00:25:39.454, Speaker A: On the other hand, when you are bigger than solved all, there are infinitely many components. So there is one infinite component. So, just one comment here that I would like to make is, what happens when q is equal to one piece of dual here, well, it's exactly one half. So for percolation. So when you select edges uniformly at random, well, there is no question about existence of infinite configuration, right? You just flip a coin for each edge of the lattice square. And here, this piece of dual is one half. This is a famous serum of Harry Kesten.
00:25:39.454 - 00:26:27.602, Speaker A: Well, he will appear in later slides, so I'm not putting his picture here yet, but. So this is his theory. And it somewhere from the eighties, I don't remember it exactly. So what Vincent and Hugo did were generalized significantly and extent. So it's quite an ingenious proof, but they managed to extract this. Self dual is actually critical for any q state box model. So at least on square lightest, we know the critical beta also.
00:26:27.602 - 00:27:37.194, Speaker A: So you just plug it, plug it in here and get the critical beta. Okay, so that's all good, but what happens is this critical regime, because, well, we eventually want to loop back, sorry for the pun, to sleep. So how do we do it? And for this, sorry about that, we'll need yet another representation, which is called double loop representation or dense loop representation. So this is loops. Now, loops are on medial lattice. So you have your lattice, you had configuration of the lattice, you had configuration of the dual lattice. Now I want a collection of loops which pass through all the vertices of medial lights.
00:27:37.194 - 00:28:34.714, Speaker A: More than that, I want every loop to visit every vertex of the middle lattice twice. And this loops would be loops separating clusters and dual clusters. So here I try to draw this blue loop is the loop separating this black cluster and this red cluster. So you see, it's just one of the loops of the configuration. So the corresponding double loop configuration to what I drew here would be significantly more complicated. So just, well, but it wouldn't be interesting. So it would be just collection of all the, from the, if I would draw it, it would just look like I drew a picture of middle lattice.
00:28:34.714 - 00:30:10.464, Speaker A: And by the way, just a bit of recall that medial lattice was square lattice, surprise, surprise is again square watt just rotated by 45 degrees century squared. So it's just a collection of these loops. And then weight of each such configuration is the following is p over one minus p over square root of q multiplied by the number of open edges in the original configuration, square root of q to the number of loops. It's especially nice for the critical value of the probability, because then this thing just dies and the weight of such configuration is square root of q to the number of loops that you have. Okay, so now, well this is very easy to see, because essentially you just, well you just use this lemma about dollar, because each loop separates one dual and one cluster. So then you just count it. So I didn't want to include yet another computation here.
00:30:10.464 - 00:31:33.954, Speaker A: And now finally, we talk about very important boundary condition for this course, which is called douche and boundary condition. And it's the following. In your original ports configuration, if you still remember what it is, your sine spins, lambda one and two to the different parts of the boundary. So let me be slightly more specific. You take simply connected domain, you take two boundary points, a and b, and all the spins here on this part of the boundary would be one, all the spins here would be two or in. Yes. So, well now in the double loop model, there would be a path from a to b, which is not a loop, because you need to separate spin configurations, different clusters of spins.
00:31:33.954 - 00:32:37.006, Speaker A: So you will need this separating thing. So this is not a loop. And by the way, while I'm saying this, I realize that for this model you do need slightly different things. So let me immediately correct myself. So here this actually, you look at the configurations of the random cluster model and you leave all the edges at the top open and all the edges at the bottom close, which means that all the dual edges are open. Okay, so sorry about this missing. And then again, then what I am saying was correct.
00:32:37.006 - 00:33:31.714, Speaker A: I was saying was correct that you need to separate somehow this dual cluster at the bottom from the cluster at the top. So just for topological reasons, like we had for percolation before this exploration process, you would have some curve which goes from a to b, which is not a loop. But you know, the way I drew this curve is extremely misleading because it tries also to be this dual loop. So it tries to visit every needle vertex twice. Other loops which would be present here would help it to visit every vertex twice. But again, so this is boundary condition. You do have a path from a to b.
00:33:31.714 - 00:34:34.294, Speaker A: And so let's call this path gamma. And there, finally, we return to SlA. If q is between zero and four, including four, but not including zero, then the law of gamma converges to this sle kappa. So here, obviously, this couple is bigger than bigger equals four. Well, it's. Yes, so it's actually bigger than four because we don't include zero. And then there is the theorem of Smirnov again, that for q equal to two, which is, again, easing.
00:34:34.294 - 00:35:30.436, Speaker A: It's correct. So again, the same model, easing model, but we just look at the different way to approach it. Instead of considering interface between spins, we consider this double loop interface. And this double loop interface converges to different SLA. Kappa for kappa is equal to 16 over three. And so just one remark I want to make here. Well, this is really important remark that, remember that for easing this thing, this interface converge to SLS three for this dense state of freezing.
00:35:30.436 - 00:36:24.304, Speaker A: So the same model, but we just looked at the different representation. It converged to 16 divided by three. So there is some sort of duality, and this is not surprising. So essentially, this is true when Kappa is bigger than four. Well, it's also true for kappa equal to four, but it's not that interesting. So for Kappa bigger than four, boundary of a slicappa is essentially a sole 16 Ola kappa. So there is a sort of duality there.
00:36:24.304 - 00:37:54.794, Speaker A: So this is called duplential duality. And this was established rigorously, actually, by Dapenzian and by Jupiter. Okay, so that's. So it's not surprising that here we see the things of two different sls appear from the same model, if you just look at this model slightly differently. So let me try to explain what is absorbable here. So how do you deal with these models? And eventually, this absorbable gave rise to the theorem. So the observable, which works for all q well in the range when q is between zero and four, is very similar to what we had before.
00:37:54.794 - 00:39:04.020, Speaker A: We pick very special value of sigma, and then our paraffinic function would be, well, renormalized. The weight of the model, remember, it's q to the number of loops. But here we add rotation of the curve. And, well, since historically it's not done, we just put, do not put a minus sign here. But instead, we put the winding of the curve from z to b. So remember, in of n model, in our previous iteration of easing model of in self avoidant work, we only considered gamma which would go from a to z. But here the things are totally different.
00:39:04.020 - 00:39:42.670, Speaker A: There are no gammas which go from a to z. All the gammas, they go from a to b. And so we only look at the configuration where there is this special path which goes from a to b and it goes through z. We only consider such configurations and we sum this up and we get this f of z. Or in probabilistic terms, this is expected value of the rotation of the curve from z to b. If the gamma of course goes through z. But, well, it's a moment of this.
00:39:42.670 - 00:40:37.514, Speaker A: So it's e to the I sigma times this, where again, sigma is very specific. And the key lemma for this double loop model is the following. So this already looks like Cache Riemann equation in all its glory. Suppose that v is any vertex and north east southwest are four adjacent edges. So like in this picture, then f of north minus f of south is I times f of east minus f of west. So this exact, this is exactly like cache rim df dx is equal to df divide. So if you think of this as discrete derivatives, that's what you get.
00:40:37.514 - 00:41:18.014, Speaker A: Again, this works for all q in the range. And I will explain in a moment why. And again, it's not enough to prove analyticity of anything, or discrete analyticity of anything, simply because there are not enough equations. But amazingly, in the case of wheezing, there are enough equations. The self has special phases. And again, this is something we will discuss later in the course. So here actually the proof of the, I think is even easier than for orphan model.
00:41:18.014 - 00:42:15.884, Speaker A: So let us consider curves. So this gamma, suppose it enters v on north, exit on east. There are actually, it's easy to convince yourself that each edge would have an orientation here. So if gamma somewhere at one instant went, when it went from a to b, it went down on this north edge, there is no way it would go up. So just standard consideration, this checkerboard coloring. But anyway, so you can enter on north or south, for example, exit on east or west. So let's consider for example the curve which enters on north, exit on east.
00:42:15.884 - 00:43:06.864, Speaker A: And the pairing would be the following. We look at the curve which immediately does it and couple it with the curve which first does this loop and then exit. If you look at the weight of gamma two, probability that gamma two is interface. Then the weight of gamma one is square root of q times w naught because there is an extra loop. Remember the weight of the configuration. The probability of each configuration is square root of q to the number of loops. So x rope, square root of q.
00:43:06.864 - 00:43:58.974, Speaker A: And now you can just see the contributions of everybody. So if I normalize f of contribution of gamma one to be square root of two times w naught, then contribution to f of is, well, you have less rotation. So this is e to the minus I PI over two sigma multiplied by this. Because, you know, you, you already rotated one less going toward b. And, well, the same consideration also tells you all the rotations for gamma two. So you count. Okay, here it's you rotated.
00:43:58.974 - 00:44:54.374, Speaker A: What is it? You rotated negatively, but it means that you have less, rather more rotation going from here to b, then going from here to b, and so on. And so this is your contributions. And then you sum them up and you see this. So exactly, that's how you find the sigma. And again, this is definitely not nearly enough to determine f. So each edge participates into equation, and each equation involves four edges. So on average, you would have half an equation for each edge.
00:44:54.374 - 00:45:44.672, Speaker A: So you cannot even hope to determine fit. But there is a conjunction. And the conjunction is the following. Suppose that omega is a simply connected domain and you have two boundary points, or even boundary prime ends. We will select what they are. And you consider conformal map, which maps omega ab to the strip r cross zero, one minus infinity, infinity. It's not uniquely determined, but it's determined up to a shift, as you will see in the moment.
00:45:44.672 - 00:47:01.604, Speaker A: In a moment, it doesn't matter what the shift is. And let G delta will be delta z squared approximation of omega and a delta B delta b approximations of a and b. Then, for some normalizing constant, which depends on q only, this renormalized delta to the minus sigma f delta of z times c of q converges to the derivative of this map, phi, when delta goes to zero. So we saw something very similar for o five models. So this is this conjecture for this bots models and for random clusters. And then another theorem of smirnovirus, which we will prove later in the course that this is actually holds for easing. So that's the heart of the proof of the convergence, to easily 16 thirds that one q is two and sigma is one half.
00:47:01.604 - 00:47:48.424, Speaker A: Amazingly, there is this convergence. And just to give you an idea, you see, when sigma is equal to one half, not only you know this about f, you also know the phases of f. So actually the phases of f don't change when you look at different curves. So for example, here you. You are purely imaginary. So f and f are purely imaginary. This idea, and this is already great because then it tell, it gives you more equations.
00:47:48.424 - 00:49:03.244, Speaker A: So this is these more equations, which we will again see later in the course. What's that? This is called spin analyticity. So it's, again, it's just Cachy Riemann, but this extra phase condition. So this spin analytic condition, which actually, when we look at it, it would not even look like hash Riemann condition, but trust me, it will work. And this spin analytic thing would give us everything. Okay, so, any questions about random clusters and paraphernic observable here? If not that, in the remaining few moments before the break, let me give you a preview of what will happen next. So, in the next hour, we'll talk about Cardi Smirnov absorber.
00:49:03.244 - 00:49:59.634, Speaker A: So, this is a totally different object. Well, it's connected to previous ones only by the name Smirnov, because, well, he is the one who invented and started using them here. Although again, paraphernalia existed in physics before. And the difference with previous ones was that everything I was talking about in the previous 12 hours was true for fairly wide class of functions of lysis. What I will talk about here, even 20 years later, is still true, essentially only for hexagonal lights. And we are still at loss, at loss of how to generalize it meaningfully. Okay, I will talk more about this after the break.
00:49:59.634 - 00:50:03.334, Speaker A: So let me stop the recording for now.

00:00:03.800 - 00:01:06.324, Speaker A: Thank you, Samitra. Let's continue. We defined the inner product, but still, I mean, I use the word inner product. I have to show some properties. Let's repeat the definition. The definition was, if f has the representation some alpha ikxi and g sum beta j k y j, then my definition was that f inner product with g is sum alpha I beta grkyjxi. The most important step was taken before the break.
00:01:06.324 - 00:02:08.784, Speaker A: It was the fact that this function, this mapping is well defined. That the mapping is linear with respect to the first coil coordinate, and conjugate linear with respect to the second is straightforward. This is very clear. Another property is what is the inner product of f itself? If we do this, we obtain some from I from one to n. Also j from one to n alpha I. This time alpha j, because f is equal to g, k at point x j x I. And I think everybody immediately agrees that this is bigger than or equal to zero.
00:02:08.784 - 00:02:55.094, Speaker A: That's our main assumption. Our main assumption was that k is positive. And that's the meaning of k being positive. So for every f in w, we have f in a product with f is bigger than or equal to zero. In technical terms, this is a Cisco linear mapping on the space. And whenever we have such a mapping, the Cauchy Schwarz inequality form works. This is a very, again, easy exercise in linear algebra.
00:02:55.094 - 00:04:12.674, Speaker A: This means that for every f and g in w, f inner product g squared is majorized by f inner product type f g inner product g. The proof is the same proof that we give for ordinary Cauchy Schwarz inequality, but written in the language of Cisco linear forms. What's good about this inequality, this general form, is that we can tell when f inner product f is precisely equal to zero. So if f inner product with f is equal to zero, then by Cauchy Schwartz, which is, we know it's true. F inner product with g is equal to zero for every g in this space. If f kills itself, it kills everything else, too. So for any g, this is true.
00:04:12.674 - 00:05:01.162, Speaker A: In particular, take g to be little k at point y. We have f in a product with little ky is equal to zero. But we already saw that this is f evaluated at point y for any. Yeah. Therefore, f is identically equal to zero. That's another property. And the last one that we want to have for an inner product.
00:05:01.162 - 00:05:53.674, Speaker A: So it's really an inner product on w. Up to here, w is not necessarily complete. We do the completion. There is a several standard techniques, I mean, even constructive ones, that whenever w is given how you can create a completion. So w is given, you can complete and find h, which is a Hilbert space. If your norm is not a norm, it satisfies. The parallelogram law gives you a Banach space such that w is dense in h.
00:05:53.674 - 00:06:42.234, Speaker A: That's a very standard construction in analysis. The problem here, I mean, we have a couple of problems here. That's good that we get a completion Hilbert space. But first of all, we want to have functions on the set omega. It is true that the element of w are functions on omega, but when you do, the completion doesn't matter. The technique that you use is important, and it really does not. You cannot conclude that the completion age also composed of functions on the set omega.
00:06:42.234 - 00:07:28.642, Speaker A: So that's one problem. The abstract completion may give you something else, even though all of them are unitarily equivalent. But still we cannot judge in advance about the elements of h. And second, I mean, we want to have a reproducing kernel Hill participation. We want to do this completion such that in h the evaluations are continuous. These are not clear at this moment, and we have to cook a little bit more to do it the way we do it. It's a kind of, again, a standard technique in analysis, and I use it today in this proof.
00:07:28.642 - 00:08:36.594, Speaker A: I will use it again and again in several other theorems. Very generally speaking, this means that if you have a set a with a structure, structures could mean a group Hilbert space structure. I mean Banach space structure, topological space, whatever I mean structure in and then a bijection in the sense of set theory, from the set a to the set b. It's just one to one answer jective between elements of a and element of b. Then you can transfer this structure to the space b. Whatever is here, you can move it to. This sounds very elementary and naive, but that's precisely what I'm going to do here and in some proofs later on.
00:08:36.594 - 00:09:25.516, Speaker A: So now I have w, which is enlarged to give me age. So let's imagine like this. This is my age and this is my w. Elements here are functions on omega, but elements in here I have no clue. I construct another set, which, let's call it h hat, such that between h and h hat there is a bijection as sets. Here is a bijection. Elements of h hat are functions on omega, and in particular there is the copy of w here too.
00:09:25.516 - 00:10:40.844, Speaker A: In other words, if I call this copy w hat, w hat is precisely equal to w, but h hat is just a set of function which is in bijection with h and now, I have a structure here which is a Hilbert space structure. And by the phenomenon I explained above, I transferred this structure to this one, and therefore I obtained the completion I wanted. The only difference is that in the theorem, in the statement of theorem, I mentioned h. But here the space I obtain is h hat at the end of it. That's not a big deal. Let's see how we can do this definition given f in h, which is, I mean, Hilbert. Smith define f hat as an element of functions from omega with value in c by the following formula.
00:10:40.844 - 00:11:10.882, Speaker A: So that's the definition. F hat at point x is defined to be the inner product of f and little kx in h. That is well defined. The inner product in h is well defined. So f inner with kh. I call it f hat x. And then I formed f hat of x is a function.
00:11:10.882 - 00:11:39.954, Speaker A: I form the collection h hat. All of these f hats. F is in h. So as you see, f hat h hat. Sorry, is a subspace or a set for this arc naive, you tell me. I have not proven the properties yet. Just a subset of all functions from omega to c.
00:11:39.954 - 00:12:39.684, Speaker A: And I have this mapping. What can I tell about this mapping from h to h hat? I map f to f hat by this formula. Some properties are immediately. For example, it's linear. That's very clear from from the definition, because f is in the first component of the inner product, and with respect to the inner component, the inner product is linear. It transformed here to the linearity of this map that that's immediate. Second one, it's subjective simply because of definition of h hat.
00:12:39.684 - 00:13:24.354, Speaker A: H hat is the collection of all the points in the image. So there's nothing to prove here. It's just by the definition. So it's subjective. What is less clear, and I need to prove that, is that it's injective too. It is true, but I need to prove that. And also, I mentioned here that the copy of w here is itself w hat is equal to w.
00:13:24.354 - 00:14:24.874, Speaker A: In other words, this means that for any f in w, f hat is equal to f. This is not difficult to see, because what is, let f be in w. What is f hat at point x? By definition, this is the inner product of f and kx in h. That's. That's the definition I put here. But now observe that both components, f and k, both are in Wisconsin. Note that f and k x both are in w, and h is an extension of W.
00:14:24.874 - 00:15:07.674, Speaker A: So this is equal to f kx, the inner product in w. We already saw that this inner product is precisely the value f at point x. That's the way our inner product was was defined at the earlier steps of this proof. And this is true for every x in omega. Therefore, f hat is equal to f. In other words, w hat is equal to w. It's the copy that we created here.
00:15:07.674 - 00:16:38.142, Speaker A: And to prove the injectivity, again, we use the properties of w, since f, since this mapping is linear. To prove that it's injective, it's equivalent to show that the kernel is just equal to zero. So assume f is in the kernel of the map, which means that f hat is identically zero, which means that for every x in the space in the set f hat of x is equal to zero. And remember the definition of f hat. This was f inner product with kx in this space h. What was w? Can I say that f inner product with g is equal to zero for energy in w, g was simply linear combination of all these kernel function at points. So if this is true, this one is true too.
00:16:38.142 - 00:17:47.290, Speaker A: Immediately implies that last step. Use the fact that w is dense in h by definition. Again, it's a completion. Use the fact that w bar is equal to h to conclude that for every g in H, indeed f and g is equal to zero. And this means that f is equal to zero. So our map is injective, map is injected. So I succeeded to create a map, this map which is bijective, injective and subjective, from h which has a structure, to h hat, which does not have.
00:17:47.290 - 00:18:57.034, Speaker A: But I can transfer the properties of H to h hat the way I mentioned before. The way I mentioned before, it means that for every f and g in H, we define, that's the transfer. The inner product of f hat and g hat in h hat in the image, is equal to the inner product of f and g in H. Copy paste from the first space to the second one. Why do we do this? Because now on H hat, everything is a function on omega. On h we didn't know. So again, again, now we have h hat a Hilbert space containing w and w bar.
00:18:57.034 - 00:20:05.434, Speaker A: The closure is equal to h head. Remember w hat was equal to w. So instead of, instead of thinking about w here, now I think about w there among a collection of functions to finish, which are not far away from the endpoint of the proof. If I just show that all evaluation are continuous, then we are done. But that's not difficult. So what can we say about point evaluation ex of f hat ex, the evaluation at point x on the space h hat so that's f hat at point x. What was the definition of this? Again, this was the definition of f hat.
00:20:05.434 - 00:20:52.264, Speaker A: It was f inner product of a kx in H. That's the definition I adopted here. Here it is. X was defined as the inner product of f and kx in the space age. So we have it here now copy and paste that we did before. This is equal to the inner product of f hat and kx hat in the copy space. H hat.
00:20:52.264 - 00:21:53.604, Speaker A: Very good. Again, this is a definition definition of another thing. And finally, one more time, recall that w hat is equal to w. So this is equal to f hat inner product with kx in a hat. What does this mean? This means that ex is bounded for any x, and the kernel function at point x reproducing kernel at point x is precisely what we wanted. Little kx. End of proof.
00:21:53.604 - 00:23:07.386, Speaker A: That was a long proof, but many good things come out of this proof. And this will be mostly the other discussion a little bit this week and mostly next week. For example, whenever something positive is given, you can construct a space as described in the proof. But sometimes it is not that clear what is in this space. Example, consider kwz is equal to one minus z w bar z w is in t. We know that. We know that k z, like this, is positive.
00:23:07.386 - 00:24:12.338, Speaker A: We know, but because it's the kernel of the Hardy space. But temporarily forget about this. Suppose that with some techniques, say something from linear algebra or another elegant method, we directly prove that k is bigger than or equal to zero. And then we use more theorem to show that there is a function space for this, which is an Rkhs, which is ken. But can we really extract all the properties of RDs spaces from just having this kernel at hand? Some we may, but not all of them. For example, we know that polynomials are dense in h two. Just by looking at this kernel, can you conclude that polynomials are in h two? I forget about being dense, just polynomials.
00:24:12.338 - 00:25:17.434, Speaker A: I don't say that it is impossible, I just say that it is not that immediate. And there are many other properties like that. To make things more pleasant, let's go back to dobronzhovniak space that I mentioned before the break. If b is a function in h, infinity means bounded function and with norm less than or equal to one, then for k of z w equal to one minus bz w bar one minus z w I. I will show later that this is bigger than or equal to zero. So for the time being accepted that this is a positive kernel. So there is a functional space corresponding to this by Moore's theorem.
00:25:17.434 - 00:26:38.224, Speaker A: So the h is denoted in papers by Hb. Doctor, space with symbol b. What can you say about this space? What are its elements? And the, I mean, given f in hb, how can we calculate the norm of hp? I mean, can equation be simpler than that? The size of the function in this space. And this is the interesting phenomenon that I mentioned at the almost very beginning of this series of lectures, that not all the information are available in a space that we study. In this space, HB, we have the kernel and we can develop go. I mean, there is a rich theory now, if you look at the works of people who work on HP spaces, I mentioned Ball, Joseph Ball, Sarasota, many others. Out of this kernel, they deduce many, many interesting properties.
00:26:38.224 - 00:27:39.844, Speaker A: But still, we do not have a nice formula or available formula for the Norfolk. And for another series of examples, the weighted Dirichlet spaces, we saw the classical one, but there is a weighted version too. We have an explicit formula for the norm. So Dirichlet spaces with a weight, we have a formula for norm in the space this is available. But an explicit formula for the kernel is not known, even though we know that it's a reproducing kernel Filbert space. This is somehow interesting. On one hand, we know the kernel exists, on the other hand, we don't have a formula for that.
00:27:39.844 - 00:28:37.678, Speaker A: And again, to emphasize the importance of this observation, if you can see the sum hb and some d mu for this space, a part is missing. The norm we do not know. And for this space, the other part is missing, that the kernel is not known. And the great master Dan Sarasson showed that some hp spaces coincide with some Dw spaces. In other words, this is equal to this, not for every b or every w. For some b and some w, they coincide. And even this observation was enough to deduce many, many beautiful theorems.
00:28:37.678 - 00:29:46.244, Speaker A: The information which we are missing here, we use hp, and the information missing here we use dw to complete the picture. For example, polynomial approximation was proved precisely by this observation and many more things. Well, this course is not about this specific space, even though in the program there was a week about Hps. And if we compel duration spaces, I mean, if you can explore more, you can go and study those spaces. I mentioned this just to highlight the importance of Moore's theorem here, that starting from this kernel, we can develop a, I mean, good theory about HPS spaces. Many, many properties can be, can be deduced. And after that we will continue further to see if kernel k is given.
00:29:46.244 - 00:31:10.664, Speaker A: What kind of information we can deduce for this phase h and for its elements. What can we say? Some general theorems of this type, which falls in the category of reconstruction problems. Let me, I mean, because we are not far away from the break, let me just mention one of them. But more will be, will be given next week. So here is the, let omega be, I mean, up to here all the time, I wrote omega be a set. But now I add a bit more. Let omega be a topological space structure on it, and k from omega times omega to c be a continuous kernel function.
00:31:10.664 - 00:32:20.478, Speaker A: So two things, kernel function and continuous continuous kernel function. So, being a kernel function, more theorem tells us that there is a space, but can we deduce more? And here is the conclusion then. Every element in h of k is continuous. I forgot to mention this. I think everybody know, can guess what h of k is. Back to, back to Morse theorem here, which finished. So for each k we know there is a, there is a space, and by previous theorem we know that this space is unique.
00:32:20.478 - 00:33:15.210, Speaker A: So the notation is used for h is h of k, the rkh as created by the kernel, which I used here. And every element in this space is continuous. So you see the, the influence of k on the space, just kernel gives us h of k. But continuity, continuity of kernel forces everything in this space to be continuous too. It's one of the many theorem that I said falls in the category of reconstruction problems. Proof. Proof is, I mean, standard proof in the analysis of topological spaces.
00:33:15.210 - 00:35:20.054, Speaker A: How do we show that every f is continuous? We can show, indeed, something interesting as a part of the proof that if two points are close together, so if, naively speaking, like if y is close to y zero in this topological space omega, then k, sub y is close to k, sub y zero. Of course, this is in this space, this is in norm. So how can we prove this and make it more precise? Well, ky close to ky zero, it means that we need to calculate this norm. True. So to calculate this norm, the definition is ky minus k y zero, inner product ky with k y zero in this space hk. And now we have four terms, I mean ky with ky with y zero, and so on. So, minus ky k 10, the other 10.
00:35:20.054 - 00:36:03.802, Speaker A: And finally, plus h, four terms. In the third term, the second coordinate will be k one ky ky ky ky is zero k. Yes. This with, this is y. You meant this one? Yeah, this one. Okay. And now we use the relation between little k and capital k.
00:36:03.802 - 00:37:11.594, Speaker A: This is k capital k y. And here it really doesn't matter if you forget this is kyy zero or y zero y, because both of them are there. If you don't make mistake, you are safe. But if you make a mistake, this is for this one and this for that one. So we have this. This is just by definition of little k. And now to show that this combination is small, I write it this way, I write ky and then minus k y zero minus k y zero y.
00:37:11.594 - 00:38:00.070, Speaker A: Well, I add, for example, this one here. I need two more, uh, one here and one here. Again, a standard technique in analysis, add and subtract, but all the time. Now we have k at one point, minus k at another point. But the two points are very close to each other. Here the point y zero, y zero is close to yy and the same for the other two. And now we can apply the triangle inequality.
00:38:00.070 - 00:39:40.914, Speaker A: I mean, everything is positive, even. We can take the absolute value of both sides and include that ky it was, yeah, minus k y zero. The norm in hk squared is less than or equal to the sum of each of these with absolute value plus ky zero plus k of y zero, y minus k of y. Now use the main assumption, the main assumption. Part two assumptions, one of them, continuity. Continuity as a function of two variables on omega times omega. This means given epsilon, there is v, a neighborhood of y zero, such that even the y and y here are not necessarily the same for any z and w in v k of z, w minus k of y zero, y zero is less than absolute.
00:39:40.914 - 00:40:34.592, Speaker A: That's the meaning of being continuous at point y zero y zero. This is the only thing I need here. And then, hence, for any y in v, the norm of ky minus k, y zero in h of k squared is less than or equal to three epsilon. Done. That's the meaning of what I wrote here. If y is close to y zero in omega, then k of y is close to k of y zero in h. In the language of, I mean, in the general setting, sequences are not good.
00:40:34.592 - 00:42:08.594, Speaker A: You need to take nets. You can say that if y s is in the set I is a net, and with the meaning of y going to y as a net in topology of omega, then k of y again as a net goes to k of y zero in h of k, it's more than, say, a sequence yk goes to y zero. Then the corresponding sequence of kernels converges. More than that, it's for nets, because in general, this space is not matrizable. And now this is enough to that that was the continuity for this kernel function at point y zero. But that is enough to conclude the that every function is continuous, every element of HLk is continuous. To do so, let me just use the, just use the representation.
00:42:08.594 - 00:43:28.572, Speaker A: For every f in this space hk and for every y omega, what is f of y minus f of y zero? That's the inner product of f. The first element is with ky. The second element is with ky zero in a space h of k. And therefore, absolute value of f minus f is less than or equal to the normal f times the norm of the second element. And we just showed that the second element, this goes to zero, or in the language of, I mean, v and epsilon. For every y in v f of y minus f of y zero is less than or equal to epsilon. A constant, or it was three epsilon really doesn't matter.
00:43:28.572 - 00:44:38.244, Speaker A: We can say that it's. To be precise, what I obtained was three epsilon with roots, with squared. So it's less than or equal to h of k. This is really not important as a constant and then a quantity which goes to zero with epsilon. So this means that Zof is continuous at y zero. So I gave this example as a prototype of theorems of this type, saying that if you have a property for k, then you have a similar property for the elements of h, for example, continuity. We will study more of this later on.
00:44:38.244 - 00:44:57.324, Speaker A: So we do another break now, and then I come back to talk a little bit about the first world frames and to see what they do for us in the context of archeologists.

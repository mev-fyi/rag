00:00:06.090 - 00:00:27.942, Speaker A: Welcome to Uncommon Core, where we explore the big ideas in crypto from first principles. This show is hosted by John Chabanot, co founder and general partner of DBA, and me, Hasu strategy lead at Flashbots, and advisor to the lid of Dao. Hey, John, how are you doing? It's been a while.
00:00:28.076 - 00:00:34.358, Speaker B: Good. It has been a very long time since we've done one of these. Well, actually, what has it been? It's been like two, three months.
00:00:34.444 - 00:00:44.780, Speaker A: Yeah, probably. People were already making very angry tweets at us on Twitter. One of the jokes was, like, flying way over your head.
00:00:46.350 - 00:00:50.554, Speaker B: Yeah, I did not pick up on the sarcasm there, but we're finally back now.
00:00:50.752 - 00:00:52.154, Speaker A: How's DBA doing?
00:00:52.272 - 00:01:13.220, Speaker B: Good. Doing well, just like, still, I'm in early stages in the fun for the. Clearly, the stuff that I've been spending time on, just general performance improvements around vms. So a lot of that have been leading to. Clearly, the Solana ecosystem is where we've been spending a lot of time. Those were the first couple investments that we actually made were around there. Just eclipse and Solana were around.
00:01:13.220 - 00:02:32.542, Speaker B: So that's a lot of the stuff that we're looking at right now is just. It started to become kind of increasingly clear by middle part of last year that, okay, the second that we get into some kind of bull market again, it seemed sort of apparently obvious that the current system, just scalability wise, wasn't kind of going to cut it of the system of single constraint Da on Ethereum and a bunch of still very unoptimized evms at the moment of just like, single threaded, not super dealing well in an optimized manner with Stakerith and all these things, that fees are just going to get expensive is the short answer to that. Like, the second that we have somewhat of a bull market and we're already starting to see that where on the traditional roll ups, they're not super cheap to use, you could be paying a dollar to transfer and more than that to do a swap stuff right now. So paying a lot more attention to. Okay, how much juice can you squeeze out of these things, both on the side of like, okay, how much further can you actually push the evm? Are these fundamental problems that you can never fix, or has it just not been a priority versus. Clearly, Solana has had a ton of these improvements over the past couple years, and people are starting to finally care about those again. So been spending a lot of time around there.
00:02:32.596 - 00:02:41.946, Speaker A: Okay. Wow. There's a lot to unpack. So you said eclipse and Solana have been your first two investments. Okay, and how are these differentiated from Ethereum?
00:02:42.138 - 00:03:25.950, Speaker B: Yeah, I mean, like, the simple part of it. I mean, it's just very, the left curve, fast and cheap of like, it's very clear that going into some kind of a bull market with any kind of uptick in demand, the current infrastructure just doesn't support a lot of scale right now. It's very fragmented, it's rather low throughput. And so the reason eclipses architecture just got us excited was, okay, clearly, ethereum l two s are going to be a thing. This is still the most important and biggest ecosystem, where all the developers are, most of the users, the liquidity, all of these things. So how do we bring those kind of innovations that Solana has had over to the Ethereum ecosystem? And that is a lot of what they're doing. And so people are starting to appreciate that tech again, particularly as people need more scale again.
00:03:25.950 - 00:03:29.886, Speaker B: And so that was like the very simple thesis of it's just like putting kind of the best pieces together.
00:03:29.988 - 00:03:33.306, Speaker A: So eclipse is like Solana roll ups on Ethereum?
00:03:33.418 - 00:04:20.590, Speaker B: Yeah, basically they're going to have an l two that is trying to address the scalability bottlenecks that you're starting to see already with existing, just like simple roll ups of. I mean, the first bottleneck is honestly just like using Ethereum. Da. At the moment, I think that there's going to be an increasing trend of using alternative Da solutions, whether that's celestia, eigen, da avail, like all these different ones popping up, that I think that they are going to be commonplace to start to become used more. 4844 is obviously on its own not able to provide these thousands of TPS that alone, Salana alone would heat up more than what 4844 would provide. Clearly going to need to turn to those. And then once you have that extra bandwidth, it's like, okay, now you don't want to be bottlenecked by your single threaded execution either.
00:04:20.590 - 00:04:26.690, Speaker B: And like a low throughput environment. So innovating on the VM, and that's what the SVM is doing.
00:04:26.840 - 00:04:56.460, Speaker A: Okay, so eclipse and soil, they both use the SVM, the solana virtual machine, or c level virtual machine. I think nobody really knows what this acronym stands for, but you're basically acknowledging that throughput in execution isn't really the bottleneck in roll ups. It's actually DA actually posting the data somewhere. To what degree do you think that the SVM for roll ups even makes a lot of sense?
00:04:56.910 - 00:05:44.486, Speaker B: So in the steady state, bandwidth is definitely just the simple constraint of DA. The steady state cost of just a regular transfer on any of these roll ups right now on Ethereum is going to be in the order of something like that, even just for a basic transfer, even if the chain itself is not congested. Innovating in the execution environment helps more, particularly when there's congestion within that virtual machine. And we've seen that at different times where there is something like idiosyncratic, some big thing is going on in arbitram, and now all of a sudden, arbitram fees are like $20. But, oh, it's still super cheap. Over on optimism. And the reason you get that is when even if Ethereum DA is in the bandwidth constraint, now that there's just too much for arbitram to handle.
00:05:44.486 - 00:05:53.182, Speaker B: So you got to be able to kind of handle both of those if you want to hit full scale. So it's kind of addressing both of those kind of together.
00:05:53.316 - 00:05:56.762, Speaker A: So are roll ups parallel execution for Ethereum?
00:05:56.906 - 00:06:53.450, Speaker B: It gets into the. What exactly is Ethereum? Do you consider these extensions of it? The analogy that everyone always gives is like, it's a form of sharding. And a lot of other people will point out how technically it's obviously not really the same thing as sharding. It is different, but in a way, they are a dirty form of sharding is still a reasonably understandable, rough analogy of they kind of are extensions of Ethereum in that manner. But yeah, it's not parallel execution within a single, composable, obviously virtual machine. So that is a lot of what obviously Solana has innovated around is like, okay, having parallel execution within an actual single, composable virtual machine. And a lot of what people are starting to think about more in the EVM, particularly like Monad is the main one, is like, okay, well, while all of these evms to date have been super non performant and generally sickle threaded and all of these bottlenecks, those aren't mostly fundamental.
00:06:53.450 - 00:07:10.310, Speaker B: You can fix a lot of those things in the EVM. So it's trying to kind of push out, like, okay, what is the boundary of what a fully juiced out EVM really can do? And trying to do more optimizations there. So been starting to look more around that lately as well. It's like, what are the fundamental constraints? Like, what can you do at the EVM? What are the bottlenecks there?
00:07:10.460 - 00:07:27.590, Speaker A: Before we dive into some of the technicals, talk to me a bit about kind of the social dynamics of these communities. I heard you went to biggest official Solana conference. I have never been myself. What's the energy over in Solana?
00:07:27.670 - 00:08:07.282, Speaker B: It was great. I mean, breakpoint was probably like the perfect timing possible for a conference where it was like, just as Solana was really starting to kind of take off in the narrative. I feel like if breakpoint was happening now or a month later or something, it would have probably been overrun by a bunch of investors like myself and a bunch of other people. But it was like, just early enough where Solana wasn't the hyped up thing yet, where not all those people that were there. So it ended up being just like a great crowd of. It was a lot of fun of pretty developer heavy, a lot of just builders there. There were some investors as well, certainly, but it was definitely a very different vibe than most Ethereum conferences.
00:08:07.282 - 00:08:29.770, Speaker B: If you go to one of the big ethereum conferences, it was my first time going to breakpoint as well. So it was the great mix of, it was like mostly people who have been around building for the last couple of years who have just gone through all of the shit that has happened in the Solana ecosystem, and, like, finally getting the kind of recognition and excitement again, and people were getting excited about it. So it was definitely a great atmosphere. It was a really very well organized and very fun conference.
00:08:29.930 - 00:08:33.550, Speaker A: Eclipse and Solana. Competitive or complementary?
00:08:34.130 - 00:09:10.714, Speaker B: Because to argue that they're directly competitive, I mean, you mostly need to be holding on to the idea still that there's going to be this kind of one chain to roll them all at the end of the day. And then, sure, yeah, then every chain is competitive. In reality, this just isn't zero sum unless they're just actually going for the exact same design and users. In reality, they're both using the SVM. But then, I mean, the parallels basically stop there. The whole point of eclipse is they're making entirely different architectural trade offs and tapping into a new market, which is Ethereum. So from Solana's perspective, like, look, Ethereum l two s are going to exist and take different trade offs than you.
00:09:10.714 - 00:10:02.246, Speaker B: You obviously prefer those to be SVM rather than EVM. L two s, it's just purely additive to your network effects. Infrastructure reduces developer platform risk, like, all of those things. So more concretely, half of this is architectural differences. So as an l two, Eclipse is prioritizing data availability, sampling improves. And then the other big part of that is kind of this just like, core design difference philosophy between Salana and these l two s, is that just kind of like, what commitment do you need at what time the benefit of these kind of l two architectures is you can get virtually instant confirmations even faster than Salana using either a single sequencer, potentially small sequencer set, because the whole point is they are just fundamentally less trusted. And then you post your data to this other DA layer with a larger validator set with a slight lag, and then you can get those additional guarantees.
00:10:02.246 - 00:10:45.286, Speaker B: And that compares versus Solana, which is trying to give you the gigantic validator set to give you those guarantees right away on its own. And that is just a very fundamentally difficult problem to kind of do that. And a lot of Solana's issues in the past have kind of stemmed from the fact that it's tower BFT consensus and proof of history around that. They are still quite unproven, they're not formally proven, there are aspects of it that are still not fully understood, and you can just simply gut that kind of complexity and risk with a trade off. And so I think it's awesome that both are experimenting with radically different directions. And I do think that we're going to see both of those designs be super successful in the long run for different things. So then that's like half of it, then the other half of bacon.
00:10:45.286 - 00:11:29.078, Speaker B: L two is honestly just like summarizes like a UX thing and like a network effects thing on top of that. For better or worse, blast is a pretty good example of there's a lot of users in liquidity, if you can get the attention of kind of the Ethereum ecosystem. With an l two design like this, Ethereum users get to hold the simple things of a clear mental mapping in their head of this being an extension of Ethereum. There's this canonical eth that I get to use as the gas token. I don't need to figure out, there are these different wrapped versions of eth on this chain. Like which bridge do I use? Or I need to get some new wallet and then get this gas token. It's a lot of complexity that you're putting onto the user, which these kind of l two s kind of really try to abstract away as much as possible.
00:11:29.078 - 00:11:40.794, Speaker B: Using like Frontech was like a simple example of like, I think something like that worked and someone like me had a low barrier to go use this thing because it was like, oh sure, I'll just put a few eth over there. I'm using the wallet.
00:11:40.842 - 00:11:42.880, Speaker A: Yeah. Did you tokenize yourself?
00:11:43.810 - 00:11:46.478, Speaker B: Yeah, I went to go play. I haven't used it.
00:11:46.484 - 00:11:48.880, Speaker A: Thicken your market cap.
00:11:50.130 - 00:11:55.114, Speaker B: I actually don't know because I don't know how many people bought it? I haven't.
00:11:55.162 - 00:11:57.258, Speaker A: How many keys? Outstanding.
00:11:57.434 - 00:11:58.998, Speaker B: Yeah, I doubt that I was that extent.
00:11:59.034 - 00:12:31.454, Speaker A: How many non shares? Yeah. You know, the funny thing about what you said about blast and. Okay, so first observation, people are still building on Ethereum primarily as a distribution strategy. It's like less about the tech, it's all about tapping into that mindshare, like that network effect and saying, you are Ethereum aligned. Right. Second thing is, it's kind of funny because the blast bridge isn't actually any more secure than a centralized bridge to Salana. Right.
00:12:31.454 - 00:12:40.362, Speaker A: So they are not benefiting at all from being a roll up on Ethereum that has like a trustless validating bridge.
00:12:40.426 - 00:12:42.090, Speaker B: Especially when the l two doesn't exist.
00:12:42.170 - 00:13:17.706, Speaker A: Exactly. Let's not talk about that too much, too triggering. I mean, I guess there's like one meta point which you can kind of glean from this, which you can have in Ethereum. There's some apps and some funds that are so successful that they can give a project a critical enough halo, basically, to get away with anything. Pretty much. Right. And in Solana, I wouldn't know what a similar fund as paradigm and a similar project as Blur would be.
00:13:17.706 - 00:14:00.982, Speaker A: So I think if you kind of have already this reputation of being very successful and being very trustworthy, then, yeah, then you can get away with a lot. Whereas in Solana, maybe that kind of entities don't yet exist. So DBA, that's your fund. You're hosting a monthly research club, and you've been doing this for some time. There's different topics every month, and I hear it's like a very technically minded audience. And we are recording this podcast the morning after the last research club. So tell me, what was last night's meeting about?
00:14:01.116 - 00:14:53.446, Speaker B: Yeah, so most of them more technically minded than myself by a lot as well. So I try to pick up what I can. But, yeah, I mean, we do these meetings kind of just like on random, fun topics that we're thinking about every once in a while, get like, a small group together that just talk about these things. So the one last night, we were doing it kind of primarily around some of the stuff that I was talking earlier around, just generally, VM optimizations. What are the bottlenecks in execution for the EVM? How can we improve these things? How does the SVM tackle these things? Similarly, what are the constraints between them? How do we fix these things? So most of the guys who were leading the discussion, we had the Monag guys come in who were awesome at this, who really understand it super, super well. So they were around, had a few of the EF guys, and then also had some others on the Solana side who understand that well. And also, Kevin, who works at Monad, used to be in Solana core.
00:14:53.446 - 00:15:01.214, Speaker B: So it was like the perfect mix of people just to be able to talk about all the different optimizations between the two. It was a really good group.
00:15:01.332 - 00:15:07.262, Speaker A: Okay, so before we dive into SVM versus EVM, what even is a vm? John?
00:15:07.396 - 00:15:51.446, Speaker B: Yeah, I mean, just at a super high level, in the blockchain context, it's the software that the nodes are running to be able to just basically execute code and compute what is the new state of the chain. So they're the ones that are actually running what is the code of the smart contracts deployed on chain and feeding transactions through. What is the new state that I get out of this? And obviously, doing that in very different manners can be far more or less efficient, depending on how you do that. Like simple things like being able to execute code in parallel for different transactions, like stuff like that. It's like the basic example, very simply, it's the software that nodes are running to be able to execute instructions and update the state of the chain.
00:15:51.558 - 00:16:26.674, Speaker A: Yeah, I would add that just as you can have a hardware computer that has a cpu that uses transistors and stuff and gates, and it has short term memory and has long term memory and some way of writing between these, you can have the same thing just made of software. Right. Just the very same component. Right. You have a disk for long term storage, like a disk for short term storage. And basically you have a computer that actually is like the thinking brain of the whole thing. And you can have that made entirely out of just software parts, and that's a vm.
00:16:26.674 - 00:16:48.990, Speaker A: Right. But it can do basically the exact same thing as, like, a hardware computer. So it's a software computer. So between the two most popular vms that we have seen, the ethereum virtual machine, or EVM, and the Solana virtual machine, or SVM, what would you say are the main differentiators between these two?
00:16:49.140 - 00:18:19.718, Speaker B: So I'd say the main thing that certainly that gets the most attention, at the very least, is that the SVM is built to pretty natively support parallel execution. So the basic idea is, and this is true for a bunch of different software, you want to be able to generally try to parallelize workloads as much as you possibly can, because the simple TLDR of just, like, looking at the way that computers are built and where progress is, is that computers have a bunch of different cores that individually can do sequential computation. So you want to be able to try to parallelize across them doing different threads of sequential computation. So the problem is that most of the advances kind of currently in performance, like from year to year, tend to be increasing core count, rather than just making each individual core a lot faster. So if you have a single threaded virtual machine, which is the way that the EVM is implemented today, and you're unable to be able to try to execute transactions in parallel, then that means that all of those extra cores are just kind of sitting there idly and you're not taking advantage of the fact that you're adding more cores every year. It's getting cheaper and cheaper to do that. So the SEM is very much built from the ground up of like, okay, how do we arrange everything in a manner such that we can very easily execute all of the transactions in parallel? And that just helps you with a lot of speed ups and being able to much more efficiently process transactions.
00:18:19.718 - 00:19:00.390, Speaker B: One of the main things that Solana does to kind of enable that is they force up front that all transactions have to be able to specify up front. Like when I send a transaction, okay, here's all of the state, here are all the accounts that my transaction is going to read and write to. So, you know, when you are like a node that you get all these transactions, they have declared up front that this is the state that they're all reading and writing from. So I could see which transactions are non conflicting, and then I could just schedule them accordingly to execute in parallel. The ones that I know are not going to conflict with each other. In Ethereum, you don't have to do that. So when you get a transaction, you don't know what state this is going to touch, you don't know what storage slots it's going to touch.
00:19:00.390 - 00:19:32.066, Speaker B: And so by default, what every client does is you execute everything sequentially, because otherwise you don't know what's going to conflict or not. That's the way that Ethereum works today and every other EVM chain currently works is you just execute everything sequentially because the EVM doesn't enforce anything like these access lists where you have to specify upfront. And adding those would, you can theoretically make those mandatory in the EVM, but it would be a breaking change and then you wouldn't be backwards compatible anymore. And that's kind of the whole point of keeping EVM compatibility, right?
00:19:32.168 - 00:19:48.742, Speaker A: And that's why not only Ethereum, but also all of the other EVM chains are not adding state access lists because that would break compatibility with all existing, the entire existing EVM ecosystem, meaning all of the bytecodes of all of the applications that exist.
00:19:48.806 - 00:19:52.246, Speaker B: Okay, exactly. If you make them mandatory, then yeah, you break compatibility.
00:19:52.358 - 00:20:11.706, Speaker A: So between using state lists and not using state access lists, if we start from zero, is it strictly better? So I'm asking on a strategy perspective, is it like table stakes to do this now, or are there trade offs involved?
00:20:11.818 - 00:20:45.446, Speaker B: So I think the parallel execution is going to become table stakes over time. It's unclear that requiring access lists will become table stakes. I certainly don't have a strong opinion that that would be true. That is very unclear. So for background then, the way that you can parallelize the EVM and other virtual machines is you just do it optimistically. You can use heuristics to kind of see that, okay, these transactions probably do not conflict with each other. I'm going to just optimistically execute all of these transactions in parallel.
00:20:45.446 - 00:21:21.794, Speaker B: And if when I run them, I get an error on one of them that like, oh, this one did conflict with that one, then you rerun it again. So in the best case, and the normal case is most transactions won't overlap with each other, and so you're just going to zip across them and it'll be fine. Most transactions aren't going to conflict. In the worst case, you do try them the first time and then oh wait, everything conflicted, everything was sequential, and then you have to go and execute all of them again. So that is kind of the trade off between the two. Is that in the worst case you don't know. They could just all end up being sequential if designed properly.
00:21:21.794 - 00:22:03.694, Speaker B: I mean, the worst case is actually not that bad because the worst case is you do have to execute all of them again. But the actual computation at that point of just reexecuting them isn't actually the most stressful part on the validator. That is not really the main constraint. Just reexecuting them is actually a relatively simple step that isn't the primary bottleneck. So it's unclear which of them there are trade offs to both of them. The main trade off to declaring upfront with state access list is honestly, it's just annoying for developers. It makes their lives harder to develop applications for this that specify upfront for every transaction.
00:22:03.694 - 00:22:07.474, Speaker B: It's much easier if you just don't have to think about this, and then you just use heuristics, right?
00:22:07.512 - 00:22:13.714, Speaker A: So the developer has to be the one who has to basically manage the state access. And that makes it much more tricky.
00:22:13.762 - 00:22:48.546, Speaker B: Yeah, it puts more work on, say, a Solana developer versus a traditional Ethereum developer, that when they design the application in the first place, that it has to be designed in a manner that you're thinking about this, and so that transactions are formed in this way, so it is more work for them. The other thing that is annoying with state access lists today, and this is to some extent fixable with better resource pricing, but you see this on Salana, is you can just intentionally write lock a bunch of state with a transaction that you're not actually using. So I could just send an mvv transaction and I could just choose to right lock the top 60.
00:22:48.648 - 00:22:49.810, Speaker A: What transaction?
00:22:50.310 - 00:23:19.690, Speaker B: Right lock all different accounts that my transaction isn't touching. So I can send a transaction that says, oh, I'm going to use all of these 50 high volume trading pools. So when the node goes to run that, they see the access list of like, okay, it's touching all of these. So I need to lock all of these and I can't execute those in parallel. That is a problem as of right now, that is just like a pretty trivial thing that is free to do.
00:23:19.760 - 00:23:28.590, Speaker A: Wait, how are they solving this? Does this problem exist right now in the wild? Can I just send transaction after transaction and lock the Solana chain for hours?
00:23:28.660 - 00:23:29.326, Speaker B: Yeah, people do that.
00:23:29.348 - 00:23:30.014, Speaker A: No cost.
00:23:30.132 - 00:23:33.450, Speaker B: Okay, well, you won't lock the chain.
00:23:33.610 - 00:23:36.238, Speaker A: But all of the trading pools, you.
00:23:36.244 - 00:24:33.058, Speaker B: Make it much more inefficient of like, I can just send a single transaction that effectively for free will just write lock a bunch of like I'm not actually using, and people will do that. This is a specific one, which can be most likely addressed to the primary extent just with better resource pricing. Solana has a lot of wonky kind of things with resource pricing, and the simplest thing for them is that as of right now, their transactions are very different than ethereum transactions in the way that they charge. Transactions just have a fixed flat fee per signature. So it doesn't matter how many compute units, compute units are. The solana equivalent to Ethereum gas, basically, whether you use a million cus or like 20,000 cus on a transaction, if it's got one signature, it gets charged the same. So there should be a mechanism by which you're actually being charged more, one for the amount of cus that you're using.
00:24:33.058 - 00:24:50.842, Speaker B: And also if you're locking a bunch of other state, you should have a manner to charge. What is the different state that I'm trying to access as opposed to being able to, for free, just send a gigantic transaction and lock a bunch of state that I'm not actually using, because otherwise it makes it super inefficient if people start doing that.
00:24:50.896 - 00:25:03.814, Speaker A: I still remember when Solana had no fee market. At mean, that was wild. When there was just no fee on any transaction. You could just ddos the network for free, basically.
00:25:03.952 - 00:25:14.530, Speaker B: We talked about their fee market quite a bit last night as well. Like the local fee markets, that is often brought up as one of the benefits of having parallel execution in the way that they do it.
00:25:14.600 - 00:25:33.206, Speaker A: Yeah, I was going to say, I mean, it's interesting, Solana, in theory, was always lagging behind Ethereum in kind of the economic design. But because they have these state access lists, in theory, they can do something that's actually really neat, which is the idea of local fee markets. Tell us what that means.
00:25:33.308 - 00:26:41.626, Speaker B: Yeah, and so that was, a lot of the conversation was in theory versus in practice how it works. And so the basic idea is that for Ethereum or any chain today, you have a global fee market where everyone is just competing in the mem pool and you send a priority fee and everyone's competing with each other. So this makes it easier for if there's one hot piece of state, an NFT mint or whatever, that they will drive up prices for the entire chain if, say, everyone's trying to bid that up, even if the bandwidth of the entire chain isn't saturated and the blocks aren't full. So what Solana does is, and they started to realize this after having some of the liveness failures in the past where they were getting exactly this issue, where it was just like, you're getting a million transactions that are trying to spam some NFT mint, but everything else on the chain is fine. So how do we just price this piece of state higher and leave everyone else alone? So that's what local fee markets do, is trying to say, like, okay, you need to pay a higher priority fee to access this piece of state because this is a hot piece of state. And then all the other pieces of state, everyone could just bid the same priority fees as normal, and they'll go through because they're non conflicting. It's easy to do.
00:26:41.728 - 00:26:51.946, Speaker A: And you couldn't do that easily in ethereum, because at the moment when basically the computation starts, the client doesn't already know what part of state is going to be touched.
00:26:51.978 - 00:27:17.942, Speaker B: Yeah, they wouldn't be able to do it in the same manner. And so theory of it definitely makes a lot of sense. The way that it is currently implemented. And this is a lot of what we were talking around, a bit around it was, the idea definitely makes a lot of sense. The current implementation is rather rudimentary. It's not an actually in protocol, fully fleshed out thing. It's just implemented at the scheduler level.
00:27:17.942 - 00:28:12.010, Speaker B: So at the kind of, the client level is just doing this. And it's also, the problem is it's not actually deterministic and guaranteed to work just because of the way that Solana builds blocks. In particular, Solana is just naturally building blocks continuously, as opposed to waiting a second and then building a block at the end. There's like a continuous block production and propagation. And there's a weird part of it where you're kind of assigning these transactions to different threads somewhat randomly. So increasing your priority fee can increase your chances of actually getting what you want. But if you know that they're going to be executing it across multiple different threads and assigning transactions to different threads, you could certainly end up in a situation where I paid a high priority fee, but someone just randomly got assigned to a different thread, and so they beat me.
00:28:12.010 - 00:28:52.390, Speaker B: And there's a lot of incentives to. So the priority fees can help on the margin, but there is still a very high incentive to still latency race effectively. So it's a very still imperfect solution. And we're talking around some of the ideas of how could you change it, how could you put it in protocol more of like, you could try to have a trailing, like, 1559 mechanism of just for different pieces of state. Like, okay, there was a million transactions that tried to touch this piece of state in the last block. So it changes in the next block and try to implement it differently, which again is an imperfect mechanism because you could just get like a million that shows up the next block for one piece of state and then the next slot. Like no one cares about it anymore.
00:28:52.390 - 00:28:58.810, Speaker B: But it's a balance of if it is still an improvement, if it's still helpful, people are starting to think about that more.
00:28:58.880 - 00:29:15.520, Speaker A: Yeah, and it probably gets easier because I guess calculating the right price for all of these different pieces of state is relatively tricky to do on chain, but something I guess you can do now off chain as well.
00:29:16.770 - 00:29:42.406, Speaker B: It's difficult. And they definitely had a very interesting and unique direction, and they'll keep innovating on it. I remember one of the random things we were talking about last night was someone was talking about how they diligenced Solana before it launched as an investment. They're looking at the white paper and everything. And when they're doing the diligence, their result was like, oh, this is broken in so many different ways without the mempool, and there's like, there's no fees and whatever. It's just going to get spammed. It's going to break and all these things.
00:29:42.406 - 00:29:54.442, Speaker B: And it was like, that was technically right, but it was also clearly the wrong decision of, there's a degree of, you got to ship these things, you see what breaks, and then you iterate from there, and they've done a great job with that.
00:29:54.496 - 00:30:36.534, Speaker A: That's like the eternal struggle. When I saw Solana in the beginning, I thought the exact same things, and I also didn't invest. I didn't invest in any alternate chains, et cetera. So it wasn't like Solana was the exception. But ultimately, you just have to assume that the team can figure it out, right. And it can be successful staying at it for a long time and build a community and go to market and solve some of these challenges, not that they are solved in the beginning. It's like the big challenge, I guess, as an investor, to play this scenario out in, like, five years.
00:30:36.534 - 00:30:48.758, Speaker A: Right? Because you're locked up anyway. Right? It doesn't matter what happens in one year, in two years, in three years. What matters is only, how is this project doing in, like, four to five years? Right?
00:30:48.844 - 00:31:45.534, Speaker B: Yeah, it was. One of the things I was joking about with this last night is other people in Solana will say this. There's almost certainty that there will be some sort of variation of liveness failure if you look at a long enough time horizon for Solana, and the same thing is true for all of these roll ups and other chains. We've seen the same thing with sequencers of multiple of these roll ups, whether it's base or arbitrum, at times where the sequencer's gone down or it's being ddos, and you can't get a transaction through and all these different things, and they need to iterate and fix these things. It's going to happen with early stage tech. If you're basically not bitcoin or Ethereum at this point, you should really be kind of pushing the limits for the most part of how can we actually get this thing more performant and really kind of juice? Yeah, I was, like, joking. It would be very nice if the next time there's a liveness failure for these chains, it's for some ridiculous exogenous reason, and that Solana and the roll ups and multiple of them just kind of go down at the same time.
00:31:45.534 - 00:31:58.274, Speaker B: So it's not like a tribal, like OC Solana went down, or OC, like your sequencer went down. And we could both realize it's early stage, like it's going to happen. At times you need to plan accordingly and try to kind of push the limits sometimes.
00:31:58.472 - 00:32:34.650, Speaker A: Okay, so we get parallel execution in Solana, in the SVM, we have what you call deterministic parallel execution. And then we have some other projects Monard say, and they are doing speculative parallel execution. We learned that these are quite different. One works with access lists and one works with using heuristics for the pipelining of the transactions. So does this solve all our problems? Is this going to make Ethereum or new blockchains magically much more performant?
00:32:34.810 - 00:33:41.310, Speaker B: Short answer, no. Unfortunately, the kind of basic framework to look at it is nodes have a bunch of different resources that they need to use, whether it's like disk space, I o costs of going in and out, like actual raw compute bandwidth, all these different things. And there are multiple bottlenecks kind of along that supply chain. You kind of got to figure out what is the bottleneck and how to address that before kind of moving on to, okay, what is the next bottleneck after that? And particularly for Ethereum, that is kind of what the case is for parallel execution. Particularly looking at Ethereum itself, is you can optimistically execute transactions in parallel for ethereum, but that is not actually the bottleneck of the gas limit is intentionally constrained on Ethereum to limit the state size growth, so you can sequentially execute transactions at a much higher gas limit than Ethereum is doing right now. And you see that on other chains. And what actually is the bottleneck kind of for ethereum in that is state growth.
00:33:41.310 - 00:34:48.258, Speaker B: And so the perfect example of what happens when you push it too far is like you look at what happened with BNB chain, like roughly a year ago ish of they forked geth, which is the primary ethereum execution client didn't make modifications and just said like, okay, let's just juice the gas limit like incredibly high, do hundreds of TPS, and the EVM can do that. The problem was that running it at that speeds without any optimizations at all, just like the state size started to explode. And even with a small validator set and really high hardware requirements, they were able to still kind of keep up with that. The problem was, it just became impossible at a certain point to be able to sync to the chain for a new node. It was just actually just like impossible at that point, even with a supercomputer basically to actually just sync to the chain and catch up. So what they ended up doing was, okay, they reduced the gas limit, they added Aragon as a client, which deals with state differently and realized, okay, there is a fundamental bottleneck here. And so that is a lot of what Monad pushes on is parallel execution tends to grab the headlines.
00:34:48.258 - 00:35:39.130, Speaker B: But if you don't solve the state bottlenecks kind of in Ethereum first, well, then it doesn't really matter, because doing simple math, imagine that, just like making up numbers, imagine that the EVM could do say 1000 tps with parallel execution, and it could only do 100 with sequential execution. Well, if going over that was just going to blow up your state size so far that it's just impossible to use the chain anyway, well, then it doesn't matter that you implement a parallel execution. So you need to implement all these other changes kind of holistically to deal with state in a very different manner. And so that's a lot of what they're doing is they're literally just rewriting a new client from scratch in c plus plus and rust, basically like the fire dancer ish of kind of the EVM world. It's like, okay, how do we need to optimize this thing from the ground up? Because just doing one thing on its own is not actually going to solve many problems.
00:35:39.280 - 00:35:50.906, Speaker A: Yeah, let's say it again for the folks in the back, right, the key bottleneck for scaling your blockchain is actually state growth. Let's unpack that a bit. So what's in the state?
00:35:51.008 - 00:36:33.158, Speaker B: State is actually somewhat hard to describe. It's like, almost like intuitively it is basically a snapshot of all of the current stuff that matters in Ethereum as opposed to the history, which is like everything that has happened. So simple example is like if we transfer one eth, me and you back and forth 100 times, all of those transactions are in the history. The state of the chain at the end of that is just like, you have one eth and I have zero eth, that's the state. So in something like bitcoin, that's really simple. It's literally just like the Utxo set of what address has what coin. That's a very simple state to keep track of in Ethereum and in other chains.
00:36:33.334 - 00:36:38.620, Speaker A: I think it's actually what coin has what address. But yeah, I'm trolling a little bit.
00:36:40.590 - 00:37:28.822, Speaker B: But yes, it's much simpler. And as opposed to Ethereum or any of these other general purpose virtual machines, where it could be like anything, where you have a smart contract that has arbitrary code and data in there, and that is like tracking who has what tokens and who's approved what, and all these different things. So the state is much more complex and it gets a lot bigger. And the primary bottleneck for Ethereum ends up being basically the state size just continues to grow indefinitely. That is kind of like the fundamental resource pricing problem of I do something which changes the state of the chain and updates it in some way. I pay some cost up front. But the problem is that I have increased the state size, and that is just like an eternal burden on the network.
00:37:28.822 - 00:37:48.820, Speaker B: That is just an ever increasing, okay, now every future node that ever executes another transaction, this adds a cost for them. It is now harder for them to compute new states because I have just forever increased the state of the chain. And there's no kind of rolling that back. So that is kind of like the fundamental resource pricing. And so the different approaches to that.
00:37:49.190 - 00:38:05.138, Speaker A: Before we go into that, I do want to build some more intuition for why is this a problem? So why is the state size a problem? Walk me, I guess, through an operation of how the state even comes into play when I make an ethereum transaction.
00:38:05.234 - 00:38:31.118, Speaker B: Yeah. So concretely on the resource side of things, basically history is not as big a problem. You could stick it on a hard drive. Hard drives are cheap. Like, you don't need to access it quickly. The problem with state is that you need to be able to access it relatively quickly as a validator to be able to look things up. Because what happens in a block is that a validator is executing all these transactions and they need to compute the new state at the end of it.
00:38:31.118 - 00:39:12.714, Speaker B: So that requires like, okay, I get a transaction that says update my balance from zero eth to one eth. That validator needs to go look through the Merkel tree, which Merkel tree is the data structure that ethereum stores all of its state in. And they need to go look up like, okay, that's this person's account. Okay, I found it at the bottom of the tree here, and now I need to update this leaf to say this, and now I just update the entire tree. So the problem is that you need to be able to access that in relatively real time throughout the block. And so you can't just stick it on a hard drive, you need relatively quick access to it. So the easiest thing would be, okay, just stick it in RAM and you have instant access, like keep it in memory.
00:39:12.762 - 00:39:16.320, Speaker A: But obviously you can't have 1 Ram, I think. Exactly.
00:39:19.010 - 00:39:34.994, Speaker B: And that is, what if you're super high powered and you're running a relay that's trying to be super optimized? You can do that. You literally just stick the whole state in RAm, and it'll be fast, because now you don't have to reach down into disk to go look things up.
00:39:35.032 - 00:40:04.414, Speaker A: But if you can't have that, then you will be storing most of the stuff actually on disk, and you'll be basically pulling it into ram, looking something up, putting it back, taking something else, et cetera. So, okay, we can already see there's probably like an infinite amount of optimization that you can do just in predicting what state you need. I mean, either the user tells you what kind of state you will need, like in Solana, or you will have to optimistically predict what kind of state you will need. And that's the other system, right?
00:40:04.532 - 00:40:27.098, Speaker B: Yeah, exactly. So for any validator reason, obviously you don't want to require, like, you need a terabyte of Ram. So people put it in. SSD is what you practically need to store state in as an ethereum client. And so the bottleneck ends up becoming concretely like, the disk size of how much data am I keeping? And then the I O costs of reaching down into disk and going back out, that is like a heavy operation.
00:40:27.214 - 00:40:36.918, Speaker A: Okay, so when people say I O, they mean reading from disk into ram, and that's the I. And the o is like, from ram to hard drive. Okay.
00:40:37.004 - 00:41:22.086, Speaker B: Yeah. It's really easy to, if you just have everything in RAM, which is like, in memory, which is just like live, it's very easy to look stuff up in there. It's effectively like instant. It is a more computationally intensive, like, when you're storing something in SSD to reach into it, look up something, and then get it back, that takes more time and resources. And so that ends up becoming kind of the bottleneck is that state size just keeps growing indefinitely, effectively, like the way that it's currently structured. And so the bigger the state size grows, the harder of an operation that becomes continuously of, like, the bigger the state is, the harder it is to go look through it and go find, like, okay, this is this person's balance. The merkel tree just keeps getting bigger, and you're looking deeper in the tree every time.
00:41:22.086 - 00:41:28.850, Speaker B: And it's like, it's harder to find things, the bigger the state is. So it just becomes increasingly problematic as the state size grows.
00:41:29.010 - 00:41:55.406, Speaker A: And obviously, as a species, we're incredibly good at compression. But compression doesn't matter here at all, right? It doesn't help because you constantly have to unpack it in order to use it. All right? Yeah. Okay. Now I want to hear about what does the solution space for this look like? So if parallelization doesn't really help us yet, what's the design space like for removing the current bottleneck of state growth?
00:41:55.518 - 00:42:36.206, Speaker B: Yeah. So the short answer is, there's no silver bullet. There are different trade offs and different optimizations that you can make. So kind of going through the list of things, I would say the primary thing that Ethereum itself is focused on doing is what is called weak statelessness. And so the basic idea of this is that currently, the way that validators work today is, as I was describing, is they keep locally, every validator client keeps locally a copy of the entire state. They keep it in their SSD, and then when they go to execute transactions, they're looking up through the tree and saying, like, okay, this is the state I need to update. I need to update this and so on.
00:42:36.206 - 00:43:34.830, Speaker B: And they execute everything. The proposal for weak statelessness is to change it such that you say, the validators, okay, you don't have to save the state at all anymore. What we'll do is the builder, because now we have these high resource builders that are actually building the blocks, is we just say, like, okay, when the builder sends a block to the proposer, what they'll do is they include what are called witnesses with the block. And that's basically just giving the validator, okay, here are the relevant pieces of state that you need to go look at and update so that the validator doesn't need to go search through, keep an entire local copy of the entire state and go look through everything the builder just sends them with each transaction. Like, hey, here's a transaction to send one Eth from Alice to like, here's the info you need to update the state for Alice and Bob and proves that this is correct. So you're basically shifting the work of saying, like, okay, the validators don't need to do this anymore. And you shift a little more work over to the builders.
00:43:34.830 - 00:44:03.542, Speaker B: So there's a lot of movement in this direction. With Ethereum, it's like the same idea with dank sharding of how they're going to scale. Da. That is kind of like the general philosophy is we're going to offload, try to, as much as possible offload work from the validators and put it over to the builders. So that is the primary idea that Ethereum is pursuing as a solution to this, because they want decentralization of the validators. And it's not as big a deal if we add some resource requirements from the builders. They're already high resourced.
00:44:03.542 - 00:44:56.554, Speaker B: So basically what that ends up requiring for Ethereum is you just need to switch the way that the state is stored currently, I was saying it's stored in a Merkel tree, modified merkel, patricia tree. Specifically, you need to switch that to Merkel trees is kind of the technical change, just because with a Merkel tree, all of those proofs, those witnesses I was describing of what state you need to update with a Merkel tree, those are just like gigantic and super inefficient that it just wouldn't work sending that over the network and being able to download those and everything. So a verkel tree is a different kind of tree format that lays out the data differently, such that it's much more efficient and the witnesses are just actually very small. So it's not actually any meaningful increase in bandwidth or anything like that. So that is the primary solution that Ethereum is kind of pushing towards.
00:44:56.672 - 00:44:59.450, Speaker A: It really reminds me of proposal builder separation.
00:45:01.070 - 00:45:32.166, Speaker B: It leverages and relies entirely on that. Without proposal builder separation, it doesn't work. That is the kind of fundamental truth of this, is that you always need someone to have the state. And the question is, who do you want to give that burden to? Do you want it to be a validator? Do you want it to be a builder? Do you want it to be? Every user has to know their own local state. Do we want just like some other big provider to store all of it has to have it, and someone has to show it. The question is just who do we want to give that work to and who do you kind of prioritize and.
00:45:32.188 - 00:45:37.110, Speaker A: How do you incentivize it? Yeah, which brings us, I guess to the second solution.
00:45:37.530 - 00:47:04.078, Speaker B: Yeah, the next idea, and this doesn't seem to be something that ethereum is prioritizing, but you could start to see other places, start to look at more like roll ups and other chains, is like some notion of state expert or state rent. So trying to more directly, as opposed to statelessness, which kind of just shifts the problem to someone else, state expert and state rent kind of tries to more specifically address what I was describing of just the kind of fundamental resource mispricing that we have of like there is just a cost on the network that is eternally there whenever I increase the state size. So the idea here is that after some period. You would basically just take a certain, the simplest idea is like, let's say that we have an epoch of one year, and after one year what every client does is like, okay, all of the state that is older than one year, we just prune that from the tree, we just cut that, we get rid of it so it doesn't make the data disappear, that it's irretrievable and my money is gone. It just means that, let's say I haven't used my account in two years. That means if I want to use my account again, you need to have a transaction to kind of refresh that state because otherwise they will have pruned the old state. But as long as you have the data to prove that, hey, I did have this count, it's just inactive.
00:47:04.078 - 00:47:10.998, Speaker B: You could just send another transaction that says like, hey, here's my state, please add this back to the tree. And now it's ready to go again.
00:47:11.084 - 00:47:32.006, Speaker A: And so these other retired transactions, other retired parts of state folks, would still be, it wouldn't just be you saving that, it would be everyone, but it wouldn't have to be part of the state. It could just be part of the history. It could be somewhere on some hard drive, but it wouldn't have to be eternally on basic.
00:47:32.038 - 00:48:01.574, Speaker B: Yeah, it goes to a one of n storage requirement of like someone has the data out there to be able to refresh this. You're just not mandating that clients don't need it anymore to be a validator on the network. They don't have to store this anymore. So you're relying on either the simple centralized providers are like that. You assume that RPC providers and block explorers and so on, that they're going to keep this. There are business reasons to keep it. Users could in theory keep it themselves.
00:48:01.574 - 00:48:07.270, Speaker B: And there are more decentralized solutions that can store the whole chain and all of the data.
00:48:07.420 - 00:48:16.406, Speaker A: I mean, I guess people are already storing stuff on hardware, wallets and so on and with custodians. So this would just be one more thing for them to store even on the same device.
00:48:16.518 - 00:48:22.622, Speaker B: Yeah. Generally, like the one event storage requirement isn't seen as kind of a major blocker, something like this.
00:48:22.676 - 00:48:24.122, Speaker A: What about state rent?
00:48:24.266 - 00:49:04.140, Speaker B: Yeah, so the idea there is that basically you can also expire state based on like, okay, we charge them ongoing fee to maintain this account and there's different ways to do it, but you could literally just have like, okay, there's continuously, some amount of your balance is taken out just to keep it in active state. And then if it runs out of balance, then we push it to inactive state. And then same idea. To refresh it, you would need to show proof. And here's a transaction and pay a fee of like hey, please bring this account back. I want to use it again. Again, just charging in some way for the fact that we're keeping this actively around.
00:49:04.140 - 00:49:15.774, Speaker B: Obviously that gets more complicated. There's kind of like ux things to think about with that of charging people continuously and making things more complicated there. Yeah, it's the basic idea.
00:49:15.892 - 00:49:20.862, Speaker A: And could you do this today on Ethereum if you wanted to? Or would it break everything for state.
00:49:20.916 - 00:49:28.962, Speaker B: X ray and state rent? Yeah, they're kind of like breaking changes. Like you would need to make meaningful changes to Ethereum that are probably not realistically going to happen.
00:49:29.016 - 00:50:05.680, Speaker A: Yeah, they are annoyingly there in this camp. So if you make a new blockchain, there's things that you can basically differentiate on with your early users, and then there are things that you can differentiate on with your later users, but it doesn't make sense to differentiate with any of the later stuff. And that definitely includes everything related to state growth. Right. I think that's why we haven't seen in the world any innovation on this, because no chain really, other than Ethereum has run into this limit. Right. I mean, you could say, okay, maybe binance smart chain has, but I mean they have like seven.
00:50:05.680 - 00:50:14.442, Speaker A: And I guess they don't really have a tech team that's really looking for long term solutions.
00:50:14.586 - 00:50:38.758, Speaker B: Yeah, problems like this, and to a somewhat similar extent, like Mev too, is just like a general thing that when you're launching a new chain, this is just not the thing that you're incentivized to figure out. You figure this out when it's a problem, when we have enough activity and have things such like there is Mev, when we have enough activity such that there is state growth, but when you're starting from scratch, you just don't have that problem, really. You think about it later on when it starts to get bigger Mev, you can get it.
00:50:38.764 - 00:51:10.100, Speaker A: Right. State growth, less MEv is changing. Yeah. I mean, nowadays I think people are aware, okay, front running, huge problem for traders, LVR, huge problem for lps. And so there's actually now a lot of incentive to make, quote unquote, like finance chains that are MeV optimized or something like that. But yeah, Statecroft, that one's like a five year plus, even under best conditions, like a five year plus problem. So you end up backloading it.
00:51:10.100 - 00:51:13.550, Speaker A: What about any other approaches?
00:51:13.630 - 00:52:04.546, Speaker B: So the one to at least quickly mention is like, Solana just does this completely differently of, you can just have a fundamentally different model of how you require people to store state. So Solana just doesn't have its validators. Keep a Merkel tree actively that has all the state such that they're always updating the merkle tree every block. They just rip that out basically and only mercalize it very infrequently. So that makes it an easier problem to deal with. There are also other trade offs with that of like, it makes it more difficult to make, like clients improve it in certain ways, but there are just completely different models like that. And then lastly to mention, I mean, is a lot of the stuff that is very client level optimizations that different teams can do.
00:52:04.546 - 00:52:54.370, Speaker B: And this is some of the stuff that gath and Aragon and typical ethereum clients have worked on, and that a lot of what Monad is doing is like, okay, when we just rebuild this thing from scratch, just making a lot of different optimizations, so simple things that you could think of as just like an example that current clients, ethereum clients even do, is just as we mentioned before, it's really expensive operationally to kind of reach down a disk and look up different state. So different clients. What you could try to do is try to be really efficient about, even though you can't fit all of the state in RAM, keep some of the state in RAM. That in particular is the state that is most likely to be used such that if that's the stuff that I'm constantly updating, just keep that in ram and then it's really easy to update it.
00:52:54.440 - 00:52:58.798, Speaker A: I guess as a new chain, you can't keep everything in RAM. The state is actually.
00:52:58.904 - 00:53:00.470, Speaker B: You can. Exactly.
00:53:00.540 - 00:53:01.910, Speaker A: Yeah, but it wouldn't scale.
00:53:02.330 - 00:53:44.260, Speaker B: Yeah. And the problem is, again, okay, but as the state size grows now, disproportionately, you can't keep it in RAM. The SSD is growing, and more and more you're reaching down to disk as opposed to just being able to pull stuff out of RAM. But that is an optimization that makes sense to try to keep what you can in RAM. And then Monad, a lot of what they're doing is, and this is why it'll take the time to do this stuff, is they're just like rewriting the whole client from scratch and putting a completely different database, I think MonadDB, I believe, is what they call it. But just like using a completely different database to store all of the data in the Merkel tree, that is much more optimized for being able to look stuff up in here quickly.
00:53:45.290 - 00:54:36.610, Speaker A: But then, do you know if Monet is also looking to innovate on the state size, state growth size? Because there's a few things that we said and now we are trying to put them together. I guess one is that parallel execution is going to be table stakes. It's one of those fundamental improvements of the virtual machine that you won't get around. Everyone will use it. Second, the real bottleneck of scaling blockchains today is actually the state size and how to manage that. But number three, there's very different things. Kind of a new blockchain has different things, like different inventory of things to differentiate on than a five year old blockchain, than a ten year old blockchain.
00:54:36.610 - 00:55:17.806, Speaker A: And the state growth is kind of a five year problem. Monet is like a zero year old chain. Do you think that for a new chain, the solutions are kind of sufficiently in place, theoretically speaking, to go into the benefits of parallelization now? Maybe also with the expectation that either by the time we get there and we're in a new chain, like there's things we can do, but also maybe the space itself will have matured and by the time there will be new solutions, et cetera.
00:55:17.918 - 00:56:22.840, Speaker B: So parallelizing execution on its own wouldn't really help any chains today, any of the EVM changes. EVM chains, if you look at the gas limit on arbitrum or optimism or ethereum, like any of them, they're not actually bottlenecked right now by execution. It's just like it's state problems, and especially as they go longer. And so it's going to be dealing with that kind of first. And that's why Monad is kind of like doing both of them together is to deal with that. But yeah, I mean, to your point of most of the stuff that I certainly imagine that they're going to be focusing on early on from talking to them, is more of the kind of performance related, client level type things of like, okay, how do we store this in a different database, such as it's super inefficient, super efficient, as opposed to how do we think about properly expiring state to keep that in check? Because that's just not what you need to think about, quite frankly, at least as a priority, as a new chain. That is what you think about kind of after a few years and also just disproportionately what more ethereum researchers are also working on.
00:56:22.840 - 00:56:40.300, Speaker B: Monad doesn't need to lead the charge on how do we implement weak statelessness or something like that. Ethereum is doing that already, so the older chain is more incentivized to work on those things, and they're doing a lot of this other stuff as well, while also still a lot of it overlaps and we'll be looking at it.
00:56:41.710 - 00:57:03.678, Speaker A: In general, you would say that. Okay, so parallelization alone doesn't really help you, but if you bundle it with a bunch of other, basically, like rethinking of the whole client architecture and state management and so on, then you can also generate some immediate benefits as a new chain. And those are basically, is it just like higher TPS, lower latency?
00:57:03.774 - 00:57:05.202, Speaker B: Yeah, okay, exactly.
00:57:05.256 - 00:57:06.098, Speaker A: That makes sense.
00:57:06.264 - 00:57:17.190, Speaker B: But yeah, the parallel execution doesn't help you if you have a super inefficient database that you can't look stuff up quickly to update state anyway and quickly retrieve data. They kind of go hand in hand.
00:57:17.260 - 00:58:08.806, Speaker A: To zoom out a little bit before we close out here. Do you think that all of these approaches to doing it? I think we saw the EVM on the one side, saw Solana on the other side, and then Mona and say in the middle and like some other chains as well that are neither Solana nor EVM, but use move or something else. Are these converging on the same shared endgame? Like is this a temporary fork in the road and then at some point they converge on some mega thing? That's what triple ZK scaling or whatever, recursive to the nth degree. Or are we moving to permanent places of differentiation here?
00:58:08.908 - 00:59:00.098, Speaker B: I mean, there are going to be some things that are fundamental and are not going to change. I would say the majority of it is going to converge more and more and more like certain things that are just not going to change, or like something like we were describing with mandatory access lists. Ethereum and EVM chains are just not going to add that because it would just break compatibility. But are you going to get to roughly the same place where we execute transactions in parallel in a very similar like that seems reasonable on a long enough time horizon. So the exact mechanics of it, some of them are fundamental and you can't change them. In theory, Facebook could become Google tomorrow. They just make all the changes to the company, but they're not going to do that because obvious reasons.
00:59:00.098 - 01:00:00.678, Speaker B: And it's like, it's kind of the same idea here. There are some reasonable limitations to what you can't change because it's just going to break everything. And so those won't be done. But directionally, everyone is kind of moving to the same ideas of like, okay, how do we just deal with a state in a much more efficient manner? How do we try to price this more accurately in the long run? How do we access it more efficiently? And then on top of that, how do we execute transactions in parallel to kind of take advantage of that? It's all the same concepts of basically, just like, validators have resources, nodes have resources, how do we use them as efficiently as possible, solving one bottleneck after another? And most of the ideas are kind of the same, and they're not even just blockchain specific things like taking advantage of multiple cores and having software that can execute stuff in parallel. That is just like a general thing that you try to do in software development. Like, you don't want to have single threaded processes because, like, it's a bottleneck. So it's borrowing a lot of like, those kind of traditional things.
01:00:00.784 - 01:00:30.018, Speaker A: Yeah, I think a lot of design philosophy in engineering is like moving things that don't scale into things that do scale. What's a good example of this? Maybe it's the I O that doesn't scale, but the compute does to the degree that you can parallelize it. And so you replace, try to replace more I o with more compute, because compute is infinitely cheaper to scale, basically, and it's affected by moose law and all of those things. Cool. I think that was a really great overview.
01:00:30.114 - 01:00:31.702, Speaker B: Yeah, I think we hit everything on that.
01:00:31.756 - 01:00:34.230, Speaker A: Thanks, John. Let's do this again soon.
01:00:34.380 - 01:00:35.720, Speaker B: Cool. Thanks everyone.
01:00:36.810 - 01:00:55.930, Speaker A: Thanks for joining us today. As always, nothing we say here is investment or legal advice. The views expressed by the course are their personal views alone. Please see our podcast description for more disclosures. If you enjoyed this episode, please feel free to subscribe and share it on Twitter. Thanks and goodbye.

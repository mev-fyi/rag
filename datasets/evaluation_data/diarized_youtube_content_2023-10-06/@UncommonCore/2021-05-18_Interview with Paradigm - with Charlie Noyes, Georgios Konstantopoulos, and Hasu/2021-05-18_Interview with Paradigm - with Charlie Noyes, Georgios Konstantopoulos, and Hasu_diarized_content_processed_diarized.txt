00:00:01.050 - 00:00:55.630, Speaker A: Welcome to Uncommon Core, where we explore the big ideas in crypto from first principles. This show is hosted by Su Zu, the CEO and Chief Investment Officer of Three Arrows Capital. And Me Hasu, a crypto researcher and writer. Sue, my regular co host, is sitting out today, and I welcome instead on the show charlie Noyes and Georgia Constantopolos of Paradigm, one of the largest investment funds in crypto. We covered a lot of ground in this episode, starting with how Paradigm can so consistently identify and back the category defining protocols and companies in crypto. Next, we talked about Mev and how it can be mitigated, including some actionable advice, how you can avoid getting sandwich attacked today. Then we moved on to Unisop Three, discussing its new features and remaining challenges.
00:00:55.630 - 00:01:27.906, Speaker A: We also discussed Paradigm's thesis for Cosmos and why each blockchain should adopt the IBC protocol. Finally, we had a really interesting and spirited conversation about the value proposition of bitcoin and whether it is still intact at a time where bitcoin dominance in the market is at an all time low. This led us to compare our personal wish lists for bitcoin improvement proposals, which was a lot of fun. Enjoy. Please introduce yourselves. Maybe starting with you, Charlie.
00:01:28.018 - 00:01:39.834, Speaker B: Hi, I'm Charlie. I'm on the investment team here at Paradigm, have been for about the last three years now. Before that, I worked at another crypto focused investment fund called Pantera, and before.
00:01:39.872 - 00:02:00.180, Speaker C: That, I was at MIT everyone, I'm Giorgios. I do research at Paradigm, where I also work very closely with our portfolio companies. Before that, I worked with many crypto companies doing their architecture code reviews. So anything on the technical side. And before that, I did some security.
00:02:01.030 - 00:02:24.730, Speaker A: Paradigm is, I would say, the funding crypto that more than any other fund, has the image of being able to predict the future. For example, you have been early to the AMM space, the lending space, the stablecoin space, and now layer two. And Mev, what is your secret?
00:02:25.070 - 00:03:32.598, Speaker B: So I don't think there's any secret recipe. I do think that Paradigm is unique in affording everyone here the opportunity to go as deep as they want in any rabbit hole that they want to jump down. So I think maybe the best example would be, like, Dan Robinson met Hayden really early on, just as Uniswap was getting the Ethereum Foundation grant in early 2017, late 2018, and basically fell in love with Xyk. And over the last three years, I think Dan basically did everything from helping to formalize the initial protocol spec, do a lot of analysis on it, and there were some opportunities for other folks on the team to collaborate with him on that. Like the fee paper I published with Drunkitra at Gauntlet and Dave White's solution to the fee problem we posed. And then finally culminating in Dan's Uniswap V Three contribution, basically designing that protocol. And I think that was really like the culmination of three years spent down in that rabbit hole, which is pretty incredible.
00:03:32.598 - 00:04:10.990, Speaker B: Elsewhere on the team, I've spent a good amount of time on mev myself and we were able to translate that into Flashbots. Dave White, who we brought on for after he solved that uniswap fee problem recently has been spending a lot of time on perpetual products and funding rate based products published like a pretty fantastic overview, perpetual Futures. That actually clarified for me some of the things I wildly misunderstood about how they worked. Just generally, I guess, you get to spend time down rabbit holes and I think that makes Paradigm pretty unique.
00:04:11.410 - 00:04:17.950, Speaker A: So what are some rabbit holes that you're going down right now that haven't led to any investments?
00:04:19.490 - 00:05:04.320, Speaker B: Well, I guess one really interesting thing that came out recently was Dave White just published basically a new financial product called Everlasting Options based on funding rates and to reroll options rather than needing to exercise them at discrete points in time. I think it was interesting for a couple of reasons. First, a deep rabbit hole that he came out of with potentially an entirely novel financial product and drawing on some of the concepts that we as a firm have spent a lot of time thinking about, like in Maker's case, the funding rate. The interplay between the Dai Stability fee and the Dai Savings rate is an argument that Dan and I have had many times.
00:05:05.170 - 00:05:06.986, Speaker A: It's also one of the first arguments.
00:05:07.018 - 00:05:10.110, Speaker C: That we ever had, like the interest.
00:05:10.180 - 00:05:13.030, Speaker A: Rates contact points with Paradigm.
00:05:13.130 - 00:05:53.180, Speaker B: I forgot. Yeah, you're actually there for that. Yeah, so that was super fun. And then last summer we made an investment in a protocol called Reflexor which has sort of an automated control theory based interest rate component. And I think that was sort of a prepared mind, having spent a lot of time thinking about stability fee in the context of Maker and what could make sense there. And now with Dave's Everlasting Option proposal, perhaps there will be the opportunity to draw on sort of all of these various different concepts in areas that folks on the team have spent time rabbit holing down over the last three years.
00:05:53.630 - 00:06:02.298, Speaker A: And I would say you are probably also one of the most hands on companies. So can you give an example of how you would work with a portfolio company?
00:06:02.484 - 00:06:33.980, Speaker B: We help a lot of portfolio companies with mechanism design. Giorgios helps with writing code. I do not. Sam is like an audit god. So I think we are pretty hands on. It kind of depends on the needs of the project. We have everything in our portfolio from super early stage like kind of far out there very crypto native things to what you might call traditional companies.
00:06:33.980 - 00:06:39.306, Speaker B: And I think we just try to help out however we can.
00:06:39.408 - 00:06:49.194, Speaker C: Yeah, exactly. And this kind of very hands on approach either helps us make sure that the companies that work with us, get the optimal result out of their effort.
00:06:49.322 - 00:06:53.970, Speaker A: Recently you have been working with Optimism. What have you done for them?
00:06:54.040 - 00:07:45.778, Speaker C: Yeah, so in Optimism's case, what happened was that there was lots of organizational complexity due to having working on multiple code repositories. So I undertook like a project where we would combine all of these repositories into a monorepo and automate completely the versioning and deployments of optimism systems. And this kind of lets us minimize errors that occur from manual processes where some developer runs a command locally. And this was an example, for example, which the company was kind of resource constrained at the time. So many things happening, everybody wants to build something on optimism and basically there was nobody available in their team that could do it. And I said, hey, let me do it. I'll work with you for two, three, four weeks, however long needed to get the job done.
00:07:45.864 - 00:07:52.900, Speaker A: Did that produce any generalizable learnings or processes that could be applied to other portfolio companies?
00:07:53.590 - 00:08:08.898, Speaker C: Definitely. So throughout that, the whole automation and kind of organizational aspect of complex code bases like optimisms definitely carries over towards making sure that these mistakes are not repeated in other cases.
00:08:09.074 - 00:08:34.660, Speaker A: So to take a turn here and dive a bit into sort of the future of crypto because I feel like that's sort of what our listeners would most like to hear from you, sort of hear the future from you before it happens. And a big topic that you saw coming years ago, both of you, is mev. Could you maybe give a short intro about what mev is?
00:08:35.030 - 00:09:41.074, Speaker B: Yeah, mev is minor extractable value. It's an idea that there are profitable opportunities to order transactions in specific ways. Or alternatively, I guess you can think of it as that certain orderings of transactions on a blockchain are more profitable for the sequencer than others. And this creates incentives for, I think on Ethereum today, we mostly see arbitrage bots or we have mostly seen arbitrage bots competing in transaction fee auctions to be able to get their transactions in front of things like dex trades, front running. And now we're starting to see miners more directly participate in this. But I think generally you can just think of MEB as the profit opportunity of some transaction ordering. And that miners sequencers validators depending on the context that you're in, whether it's proof of work, proof of stake blockchain, or even in layer two, can access, given their power to order transactions.
00:09:41.074 - 00:09:42.226, Speaker B: Arbitrarily.
00:09:42.418 - 00:10:05.502, Speaker A: Yeah. And as I understand the extraction of this mev, that's something that's very hard to avoid, but the way that it is extracted produces some negative externalities for the respective blockchain. Maybe, George, could you walk us through what those negative externalities are and what options there are sort of to minimize them?
00:10:05.636 - 00:10:59.230, Speaker C: Yeah, of course. So the main negative externality, which is a byproduct of mev, is that when there is many, let's say arbitrage bots that would go after the same arbitrage opportunity, only one of them will be able to take it. And while everything else ends up being a reverted transaction, the implication of that is that the blockchain ends up having lots of junk transactions which don't do anything and that's redundant computation, that's redundant storage. It's not great. So that's the first one. The second one is that due to Mev and again mev creates these priority gas auctions. The bots end up paying exorbitant amount in gas prices for including their transactions and this ends up pushing up the average gas prices of the network.
00:10:59.230 - 00:11:16.006, Speaker C: So in a way this is a negative externality towards the user itself. The previous one was a negative externality to the protocol and then there is the final negative externality of just the peer to peer layer having lots of transactions that don't end up mattering what.
00:11:16.028 - 00:11:19.990, Speaker A: Is sort of the downside of having a flooded peer to peer layer.
00:11:22.730 - 00:11:26.550, Speaker C: Ideally your node just ends up using more bandwidth.
00:11:27.370 - 00:11:28.134, Speaker A: Okay, yeah.
00:11:28.172 - 00:12:29.740, Speaker B: To the debate that has been had in the Bitcoin community in the past around the costs of running a full node and the cost of decentralization within a network. I think there's some argument that P to P layer congestion, it does raise those resource costs and then depending on the form of MEB, it kind of can get more extreme. Like in the past we saw something called back running which was basically like if you have a bunch of transactions with the same gas price the one that ends up getting included directly behind another is functionally random or was at the time based on the default GAF config. So deliar you end up getting people basically like spamming transactions actually on chain. So rather than just competing directly on the transaction fee as you can with like a front running style of mev. So the exact negative externality depends on the context but there are a bunch of interesting ones.
00:12:30.750 - 00:13:01.890, Speaker A: This may be my subjective experience but I feel like it has also become harder to make low fee paying transactions on Ethereum because I feel like those then you broadcast them but it's no longer possible to wait for three days and then they will get executed. I feel like when you send them to the infura node or whatever, it gets booted from the mempool and if your own node doesn't rebroadcast it then it's just never going to get executed. Would you say that's also a negative externality of having just too many transactions flying around relative to the capacity?
00:13:01.970 - 00:13:04.006, Speaker C: It's a UX degradation for sure.
00:13:04.108 - 00:13:34.686, Speaker B: Yeah. And I think it highlights like a lot of the infrastructure just was not really designed with this eventuality in mind. Put another way, we have a high degree of reliance on infuria across the ecosystem and some other folks like them and I don't think it's their fault in any way. But the mev stuff has just kind of exposed a lot of gaps in the architecture, and they get worse at scale.
00:13:34.798 - 00:13:44.850, Speaker A: Yeah. And there's one project that's actually trying to improve this infrastructure and mitigate the negative externalities, and that is Flashbots.
00:13:45.210 - 00:14:50.886, Speaker C: Flashbots is basically a research collective with the mission of democratizing mev and reducing its negative externalities, which we already talked about. Flashbots projects, let's say, are Mev geth, which is a fork or a patch on top of the normal Go Ethereum client implementation, which allows users to submit transactions to a kind of overlay mempool. Not the one where everybody competes for gas prices, but one which is only for mev transactions. What's been happening with Flashbots is that they have gotten miners on board. Right now, they have over 58% of the hash rate onboarded. And this means that traders are able to submit transactions to miners and compete with each other without having to, at the same time, kind of compete with normal nonmev extracting users for inclusion.
00:14:50.998 - 00:14:58.406, Speaker A: How does the auction, sort of the auction mechanism work that's used in the Mev GEF mempool?
00:14:58.518 - 00:15:50.282, Speaker C: It's a sealed bid auction. You bid on a bundle of transactions, and basically your bid is the average gas price multiplied by whatever you consumed. And we allow users to submit bundles of transactions. So it's not just you submitting one transaction. You can submit ten or 20 or 30 transactions. And this has an interesting implication that by being able to submit more than one transaction, you can either do something like account abstraction on Ethereum, where you can send a transaction with a zero gas price from one wallet, but you can have a follow on transaction from another wallet that pays the fee. You can also do sandwich attacks more efficiently, which is a kind of attack that you can do on automated market makers to force traders to get the worst execution price that they can.
00:15:50.336 - 00:16:01.486, Speaker A: Let me interrupt you there for a second. Is that because you can see, like, the trade that you sandwich in the mempool and it's already signed, so you can take it and you can put it in your own bundle? Okay, exactly.
00:16:01.668 - 00:16:10.130, Speaker C: So it's basically like the bot checks the mempool, picks the transaction it wants, creates the sandwich, and serves the sandwich to Flash.
00:16:10.550 - 00:17:01.010, Speaker B: It might be worth saying, I think the Dex sandwiching example is probably the best to build up from simplistic extraction to the maximum that you could possibly do and how it changes in different contexts. So we started with I make a Dex trade, and like Giorgios, an Arbitrage bot gets into a gas auction to get his trade directly in front of mine, in front run me. That's something that you can do without being a miner or without being, like, a Flashbot's bundle. And we've seen that for the last year. Now, ideally, you would be able to get a trade both in front of and behind the Dex transaction, right. Not just in front. However, there's no way to compete for that priority in the native Ethereum Gas auction.
00:17:01.010 - 00:17:32.362, Speaker B: It doesn't work that way. At one point, like I mentioned earlier, the default geth config randomized transactions, basically, that were of the same gas price. So you started to see people competing in auctions on the front and then just spamming transactions on the back to try to do sandwiches without Flashbots. But what Flashbots give you the ability to do is that within the bundle, you can just say, okay, like my first transaction here, trade, and then the back run without needing the auction or the spam.
00:17:32.506 - 00:17:39.518, Speaker A: A crucial part or attribute of the bundle is that it has to be either executed completely or not at all.
00:17:39.604 - 00:17:40.142, Speaker B: Yes.
00:17:40.276 - 00:17:59.362, Speaker A: Could this also be used to let's say it set a very low slippage tolerance on a Dex trade, and then this DexterIt only executes when sort of the trade can actually get filled, because otherwise that's the problem. Right? Why people don't set low slippage tolerance because then their transactions fail too frequently.
00:17:59.426 - 00:17:59.654, Speaker B: Yes.
00:17:59.692 - 00:18:17.462, Speaker C: A transaction on Flashbots, if it does not get picked for a bundle, it remains in the pool of bundles. So, yes, what you said definitely is possible. And I think that most traders, mev traders or not, should just use Flashbots.
00:18:17.606 - 00:18:23.802, Speaker A: So you would have to make the bundle conditional on the trade being executed successfully.
00:18:23.866 - 00:18:28.890, Speaker C: So the fee, you would have to add, like, a smart contract to execute your trade.
00:18:29.050 - 00:18:32.382, Speaker B: I think Archer Dao does this, right? Yeah.
00:18:32.516 - 00:18:36.790, Speaker A: I don't fully understand what they do. It's not the same as flashboards.
00:18:36.810 - 00:18:59.570, Speaker C: I think, in a way, all of these application layer mev Mitigations, they work by introducing a smart contract, which kind of encodes all the rules about when the mev opportunity should be fired. And if that condition does not pass, the transaction never gets mined.
00:18:59.730 - 00:19:15.870, Speaker A: Couldn't you just do it like this? You have one transaction that is like a zero slippage Dex trade, and then the fee is paid in the currency that you buy on the decks. So that's how you have just two transactions, no smart contract needed. Wouldn't that also satisfy the condition?
00:19:17.570 - 00:19:23.546, Speaker C: That is possible, but right now, the profit calculator only uses ETH.
00:19:23.658 - 00:19:26.980, Speaker A: Okay, but when you buy ETH on a Dex, then you can do it this way.
00:19:27.510 - 00:19:28.260, Speaker B: Yes.
00:19:28.710 - 00:19:37.714, Speaker A: Okay, cool. So Dex takers actually, regular Dex traders should also use Flashpots already. Cool. I feel like nobody knows about this.
00:19:37.832 - 00:20:02.060, Speaker C: I think this has to do with the fact that most of the user interfaces right now, they are built around the experience of sending a single transaction. Whereas this experience that you described, the gasless one involves two transactions. So you'll need some sort of service that detects the transaction gets submitted, and then lets you do it. This is like literally some infrastructure that needs to be built on.
00:20:03.310 - 00:20:10.974, Speaker A: I want I trade a lot on DEXes if I want to do this, like, later today? What do I have to do? Is it too difficult right now?
00:20:11.012 - 00:20:12.030, Speaker B: Call Georgia.
00:20:15.330 - 00:20:19.762, Speaker C: If somebody likes this idea and wants to build, yeah, we can talk.
00:20:19.896 - 00:20:20.580, Speaker A: Okay.
00:20:22.470 - 00:21:14.194, Speaker B: To your original question hasu on why is mev inevitable? So one other interesting anecdote with the slippage tolerance stuff that you can set on uniswap trades natively or on Dex trades natively ignoring flashbots. In the last couple of months, we actually started to see arbitragers intentionally causing them to fail and revert. I e saying, well, this person sent a 1% slippage limit and it only cost me like a few dollars to force their trade to fail. And I expect that if I do this, they're then going to come back and set a higher slippage limit and then I'll be able to profit off of it. That's a very interesting situation. It's not an instantaneous profit. I don't know.
00:21:14.194 - 00:22:05.498, Speaker B: I think it speaks to kind of like the nature of MEB. The reason to me that it feels inevitable is that there is sort of an unknown upper bound on how much potential profit is available from doing this. And then there's like, pressure that builds up over time as people get better. Like, the market gets larger and larger, arbitragers get better and better at extracting this, our understanding of mev improves and it becomes clearer what you could do. So, like with the back running example, again, there was like the geth config randomized transactions at the same gas price. This caused people to spam transactions because to raise the probability that they would be able to backrun some given one. Then the config got changed such that this was no longer like, the spam was no longer incentivized.
00:22:05.498 - 00:23:06.466, Speaker B: And very quickly you started to see adoption of alternatives. And over time, I think it's sort of like there is some hopefully stable equilibrium at which the network doesn't just completely degenerate to an unusable state or something ridiculous like infinite time bandits. And then there's sort of like a very naive state in which you assume that people in general aren't going to do this thing or do these kinds of things and are going to be honest. I think that hypothetically, the honesty hypothesis has been basically definitively proven false at this point. We know that people, minors, arbitragers, whatever, are going to want to go do this to some extent. And then I think the question becomes, can we find some stable equilibrium or is it going to degenerate? And there's no real option to stick on the current because we're already sort of trending further and further in that direction.
00:23:06.578 - 00:23:31.502, Speaker A: What you described where someone, especially a frontrunner sandwich attacker who has like very tight grip on a certain trading pair where they then deliberately make a trade fail. Make a second trade fail just in order on the third one to then sandwich. Based on a higher slippage tolerance, I would say that's a multi block sandwich attack.
00:23:31.556 - 00:23:31.822, Speaker B: Right?
00:23:31.876 - 00:24:20.234, Speaker A: And we have seen very little of that so far. What you described. I would say that's maybe one of the first examples. However, when we are moving to proof of stake after the merge, ethereum consensus will change in a very fundamental way, namely who will produce a certain block will be known in advance. So basically you can have I know the next like I'm next to make a block and then it's Georgia's turn and then it's Charlie's turn and if we cooperate, then we basically control the next three blocks and there's no probabilistic thing there at all. The poisson process that we have in place today that makes this harder will be completely gone. So how does this change the nature of mev?
00:24:20.362 - 00:24:21.680, Speaker B: That's a great question.
00:24:22.050 - 00:25:14.282, Speaker C: There's two angles here, right? So firstly there is the angle that because if validators are known ahead of time, there is an incentive to collaborate and try to collude and so on. So I think that's a valid point. If validator ordering is known, that's not great. And so right now I don't think that's supported by Ethereum too. But there is a branch of research that is on secret private election of validators. And so if you were to apply that, you would bypass that limitation. In a similar vein, Tendermint and other chains have like a VRF module which allows them to randomize validator election.
00:25:14.346 - 00:25:47.642, Speaker B: I'll give you an unsatisfying answer. I think we have to hope the same thing that we do currently with Ethereum miners, which is that they're not going to intentionally rework blocks. So far they haven't. But I would say that with respect to known block producer election and a proof of stake world, at least before to Giorgios's point, we implement like a secret election scheme. Hopefully it doesn't happen, or if it does happen, we very quickly have a way to randomize that. That's a great question. I actually haven't heard someone ask that before.
00:25:47.776 - 00:26:13.090, Speaker A: Judges, I have a bit of an operational question since you are very familiar with ERP 1559. So after this sort of many gases transactions won't really be possible anymore that are possible today. Because then every transaction will have to burn some amount of eve. What is sort of the interaction with Flashbots and these kinds of gases transactions?
00:26:14.150 - 00:27:06.642, Speaker C: What you said is correct. So post IP 1559 each transaction will need to burn some ETH from the sender's balance. The short answer, which is more immediate is that there is another EIP called 30 74 which would allow you to authorize another account to pay your fee. So if that EIP were to be adopted in the presence of E 1559, then you would still be able to pay from any other account. And the process for Flashbots would be that the trader would authorize the miner to pay the fee for them. So that's the one part. The other part is that instead of having the current model where each user has to pay ETH from their wallet.
00:27:06.642 - 00:27:32.490, Speaker C: The model could in the future change to the block producer needs to burn some ETH from their wallet and that's it. And then the block producer individually negotiates with its users on how they will cover his costs, his or her costs. But the block producer ends up being like the central party that has to pay them the fee. And that kind of makes the issue with heap 1559 nonexistent.
00:27:32.650 - 00:27:44.560, Speaker A: Yeah, I actually tried a while ago to make a trade with zero gas that had some slippage tolerance. So I tried to pay via worst execution on Unisop but it didn't yet work.
00:27:45.090 - 00:27:50.322, Speaker C: Maybe this would you wanted to get intentionally front run so that they right?
00:27:50.456 - 00:27:57.130, Speaker A: Correct. I didn't have any ETH in that account, so I thought, why not give it a shot?
00:27:57.230 - 00:28:08.654, Speaker C: There is a nice blog post on e three search by Laxman Sangar who explains like this kind of technique that you can bait front runners into putting your transaction on chain.
00:28:08.802 - 00:28:59.770, Speaker A: Yeah, we will link to that in the show post. That's a great call. So we talked about mev and the biggest source of mev is actually the decentralized exchanges on ethereum and especially liquidity being spread across multiple exchanges, which then allows for these arbitrage opportunities between them where bots basically front run the price on one exchange where a trade happened to be in line with the other exchanges. You guys have incubated Uniswap, which is the biggest decentralized exchange by far and not just in terms of adoption. Also you could say sort of they made the deck space and Unisop has a new version coming out now. Georgia, could you describe what's new in Unisop version three?
00:28:59.920 - 00:30:10.634, Speaker C: Unisop v three's biggest feature or other difference from V two is that when you're providing liquidity, you get more capital efficiency. What this means is that instead of providing liquidity to the entire price range as was in unsop V two, unsop v three allows liquidity providers to provide liquidity between a certain range. And they've been calling that concentrated liquidity. And what this implies is that if you have, let's say 1000 a pool, let's say with $1 million worth of liquidity in uniswap V two, you would be able to make some trade of whatever like depending on the XY equals k formula. But in V three if the liquidity is concentrated between, let's say zero point 99 and 1.1, such as would be in the case of a stablecoin pair, perhaps like curve, then you can get the same amount of price impact for some trade but with much much less liquidity. And this directly translates to capital efficiency.
00:30:10.634 - 00:31:06.398, Speaker C: So that's one big feature of uniswap V three. Another feature is the rework on the Oracles which allows you to statelessly get arbitrary slice t WAPs over the last week, I believe, or sorry, whatever 65,000 blocks attributes to so better price oracles using uniswap v three's liquidity and we think that's one of the most understated features of it. And one could say that with uniswap v three, basically you start to approximate something that looks like an order book at times. So basically, instead of having an AMM curve which is very smooth and follows a certain equation, now it is made up of many smaller curves between all the ticks that get covered.
00:31:06.494 - 00:31:18.360, Speaker A: Okay, so when I'm an LP in uniswap and let's say the price of ESA goes up by $500, then how do I ensure that my liquidity is still centered around the market price and I'm not left behind?
00:31:18.970 - 00:32:00.098, Speaker C: So it cannot get done automatically. Right now if you are a liquidity provider and the price moves outside of the ranges that you're providing, you would need to kind of poke your smart, contract your position and reposition it around the new price. As a result, it could be probably expected that yield aggregators or other sorts of outsourced infrastructure would exist and start to kind of do these services for you. So in a way, the v three construction and the fact that positions may need to be more actively managed means that there will be a whole new ecosystem flourishing on top of it.
00:32:00.184 - 00:32:06.290, Speaker A: Do you see any risk that unisoft with three will sort of kill the lazy liquidity providers?
00:32:07.130 - 00:33:25.246, Speaker B: I think it'll become more competitive and there's going to be a gap between the most sort of efficient and competitive liquidity providers and those that don't want to put as much thought into it. I think there already is to some extent like you see people taking leverage positions to be able to provide more liquidity for given capital base and uniswap v two. But obviously v three, like the delta is going to get much bigger. I think that probably there will be, well, hopefully there will be a proliferation of new types of aggregators that basically implement LP strategies for different pools that are more competitive than just sort of like the bog standard Xyk full spectrum default. I think that'll be quite interesting and it'll mean that it's not like, quote unquote normal users are kind of just stuck with one option relative to a bunch of much more competitive market makers. I think it'll be more interesting than that long term. I think it's hard to say though, how the split will work out.
00:33:25.246 - 00:33:58.002, Speaker B: Hopefully it'll still be less hopefully it'll still give more of an opportunity for normal folks to participate than you see on centralized limit order books where back in 2015 I was like market making on GDAX or Coinbase Pro now and I'm certainly no longer doing that. I don't think that any normal person really is and hopefully that will still be possible to an extent on uniswap long term.
00:33:58.066 - 00:34:12.874, Speaker A: So George has mentioned that yield aggregators could sort of provide active IP management strategies for people. What are some other infrastructure projects that you. Would like to see built on top of uniswap or that you think are low hanging fruits.
00:34:12.922 - 00:35:02.558, Speaker C: Right now, generally there should be tooling around managing liquidity, whether that is for following the price or whether that is for adjusting your quotes as the other relative market changes. Right now, the basic smart contract only lets you input a specific range and that will be for one position, but it does not let you, for example, create the full distribution of your quotes that you want to participate in the market with. So that kind of tool would be something that's missing, something that does more extensive simulations on LP returns. Maybe there's work to be done on how LP returns, the optimal LP returns for uniswap change with V Three. And that might build on Charlie and.
00:35:02.644 - 00:35:31.640, Speaker B: Dave's previous work, I think also yield farming stuff. It goes from being one big homogeneous pool to very heterogeneous. And the current uniswap uniswap based liquidity mining programs. I think there's going to be very interesting stuff to be built around that in Uswap. B three.
00:35:32.250 - 00:35:49.450, Speaker A: Yeah, I mean, implementing yield farming on current unisorp, right. What they did when the Uni token launched is very trivial. But now it seems to be much harder to even do the same thing. Right. Is that a solved problem or how to even do yield farming on top of uniswap?
00:35:50.430 - 00:36:49.614, Speaker C: Right now there is no canonical yield farming contract that's in the public, as far as I know. And the main challenge rather is that you need to figure out when a position is in range so that you properly pay it. And recently, I think less than a week ago, there was a PR merged on the Uniswap V Three periphery v Three core repository which changes the logic and enables that. So all the pieces are in place and somebody has to build the canonical uniswap V Three liquidity mining contract. Another thing that would be nice to be implemented is LP shares as collateral in lending protocols like maker or compound. And pricing these is slightly harder than how you would price the normal V Two shares. So there is some work to be done on that end.
00:36:49.732 - 00:37:22.934, Speaker A: Right. That was actually one of my first questions when I saw the white paper for unisop V Three was whether this would make sort of leveraged yield farming obsolete. I feel like when Alpha Mora came out, this sort of saw insane success that I wouldn't have predicted at all. But then I realized after talking to Dan that basically Unisop Three makes leveraged yield farming obsolete anyway because the positions are already implicitly leveraged and way higher.
00:37:22.972 - 00:37:29.734, Speaker C: Exactly than the tighter the range that you're providing liquidity to, the higher your leverage.
00:37:29.862 - 00:38:20.518, Speaker A: Yeah, that's when I actually became bearish on Alphomora instead of on units of V three when I realized that they are both competing in the same thing, which is concentrated liquidity. That's all that leverage yield farming actually gives you is concentrating your liquidity around the current market price so you get more transaction fees and more yield. Yeah, though I take it that Unisor V Three, it does require a lot of transaction overhead. Right? You need to constantly message the Unisor pool where your liquidity is in depending on market conditions. And do you think this is even viable on layer one, or will Unisop V Three only fully come into shape on L2?
00:38:20.704 - 00:38:55.490, Speaker B: Well, I think it's certainly viable because the base case is just as much interaction as you see on Uniswap today. If everyone is just full spectrum Xyk and then in terms of the trade offs to fees, costs of adjustment, frequency and all that stuff, I think it's just a market discovery process. So it will definitely be more efficient, I think. Fair to ask how much more efficient? And probably difficult to say before we get some kind of data in the wild.
00:38:55.650 - 00:39:03.240, Speaker C: For sure, like lower latency and lower fees mean that LPs will be comfortable with adjusting their positions more.
00:39:03.630 - 00:39:19.290, Speaker A: Yeah, I'm mainly trying to understand how big is the on chain footprint of Unisop V Three actually going to be? It feels like there's a lot of incentive for LPs to constantly update their positions, leading to a lot of transactions.
00:39:19.450 - 00:40:34.950, Speaker B: I think that's true. I think it's also true though, of many of the strategies that are implemented by yield farming aggregators today, one of the biggest value propositions is socializing gas costs and minimizing transaction overhead by pooling. I think that'll also be true in Uniswap B Three there will be a higher transaction footprint and it's like a question of how much higher relative to how efficient you want to get. And then on L2, with much lower latency and much lower fees, the markets will be more efficient. And then there's some question of trade offs too, whether you're just there to simply trade or you want to buy the asset to use it in other protocols and then need to move back to the main chain. I don't really view any of those as potential showstopper issues, more so just the kinds of things where we're kind of going to have to see what the market prefers in practice. And perhaps a lot more usage comes from highly composable main chain necessary activity than we might guess today.
00:40:34.950 - 00:40:49.578, Speaker B: Perhaps a lot more of it is just purely trading based and really doesn't care at all for anything other than speed and efficiency. And we'll just prefer L two. We can make guesses, but it's just, I think the kind of thing where it'll be interesting to observe based on.
00:40:49.584 - 00:41:25.698, Speaker A: What you just said. I also realized that we would probably see a lot of bundled liquidity in some sort of smart contract and then executes these active strategies and it sort of puts it or bundles it all into one transaction, though. Have you thought about sort of the front running aspect of providing liquidity to unisop V three, because the miners can obviously put in update their quotes first and foremost. Do you think this will sort of make miners the primary liquidity providers or miners flashboards users?
00:41:25.794 - 00:41:27.240, Speaker C: TBD, I think.
00:41:27.550 - 00:41:31.674, Speaker A: Yeah. Okay. But we can say that it's getting harsher out there.
00:41:31.792 - 00:41:41.882, Speaker B: It's getting harsher out there. And I think the mev dynamics also are so complex that it'll be interesting to see what happens.
00:41:42.016 - 00:42:06.994, Speaker C: But I mean, it's not bad necessarily, right? If the liquidity ends up being very concentrated, yes, you will end up taking a 2% slippage fee, but that might be or whatever your transaction was. But maybe that means that the base fee that you end up paying for every transaction ends up being the minimum acceptable slippage by the market.
00:42:07.192 - 00:42:19.030, Speaker A: Yeah, right. For the APS, I'm concerned that for every trade that pays a fee, the miner can just almost fill it completely and then for a trade that moves in the other direction, they can always pull out the liquidity.
00:42:19.610 - 00:42:20.714, Speaker B: Yeah, I guess.
00:42:20.752 - 00:42:31.994, Speaker A: I mean, for users, maybe this is great. I don't know. I think it's fascinating to speculate about, but I have no special insight and no strong intuition about how any of this is going to play out.
00:42:32.192 - 00:42:45.806, Speaker C: And also, just to say the obvious, all the attacks need to be weighted against all the benefits that you get. And it seems to me that the benefit here is very much worth any additional complexity introduced elsewhere.
00:42:45.918 - 00:43:14.922, Speaker A: Yeah. Also staying with front running for a second. So we talked about one way that Front running is going to be mitigated, and some people already mitigated today on the peer to peer layer via gasless transactions. What are sort of the options that we have to further minimize this problem on one, the application layer, and two, also maybe on the protocol layer in the future. Yeah.
00:43:14.976 - 00:44:08.614, Speaker C: So we can think of the mitigation layers for mev as three layers. Firstly, there is the application layer, which is things that Keeperdao and Archer Dao are doing. Then there's the network layer, something like what Flashwood is doing by introducing new API endpoint for transactions. And then there's also the protocol layer, which is basically introducing randomization in the transaction ordering or kind of splitting the processes of ordering and execution, where approaches here include either threshold threshold cryptography sorry, using a random beacon to kind of randomize your transactions. Others are using a VDF, others are with Threshold signatures. You can get creative at that layer.
00:44:08.742 - 00:44:13.040, Speaker A: Are we going to see any of those in Ethereum? Maybe on layer two.
00:44:13.490 - 00:44:36.078, Speaker C: On layer two, I think that's possible. On layer one, maybe some randomization based on an insecure random number. Maybe the previous block hash or something, maybe is good enough. It won't be a perfect solution, but maybe like having something that half good is better than status quo.
00:44:36.174 - 00:44:36.386, Speaker B: Yeah.
00:44:36.408 - 00:44:52.600, Speaker A: So we address the peer to peer layer IPQ sort of curious what's possible on the application layer. So maybe can you construct the decks in a way, for example, using batched auctions or something like that?
00:44:53.070 - 00:45:43.478, Speaker C: Yeah, exactly. I think the best way to think about it is that when trading on a simple AMM like uniswap, there's only two variables that kind of determine your execution price. It's the reserve one and the reserve of the other. Token, in order to mitigate mev, you need to reduce the overlap between two users transactions. In uniswap, if there's two users, they always touch the same two reserve values because they're always trading on one pair. Whereas if you have, for example, an order book no, again in an order book, in an order book, two users still can go after the same transaction. But in a batch auction, everybody gets the same price independent of the order that they submitted their transaction.
00:45:43.478 - 00:45:46.326, Speaker C: So here is another example of ordering.
00:45:46.358 - 00:46:05.970, Speaker A: And then executing, wrapping up the mev topic and changing gears here a little bit. Paradigm has made many investments in the Ethereum ecosystem. But Ethereum is not the only base layer you support. Especially you, Charlie. You have been a vocal supporter of Cosmos. What is your thesis?
00:46:06.630 - 00:47:26.134, Speaker B: So I think Cosmos is one of the few, maybe the only project that is trying to enable a vibrant application ecosystem with practical interoperability and sort of the other features that have allowed DFI to grow up on Ethereum to enable that kind of ecosystem without sort of providing a new platform style blockchain. So if you think about, like, Ethereum and many of the L two s that are coming out for it and sort of like alternative, quote unquote, smart contract blockchains, essentially all of them try to augment or offer an alternative platform to Ethereum. Cosmos is a bit different. It's not like one blockchain. It's essentially a set of tools, developer tooling and various protocols that enable projects to launch on their own blockchain. And the reasons that you might want to do this are that it gives you more fine grained control over your environment, like both the execution environment and the incentives of the system. And I think that we've seen with Ethereum that certain protocol layer issues like MEB kind of necessitate like an application layer response.
00:47:26.134 - 00:47:48.034, Speaker B: And that's only possible to some extent when you're running on top of a shared platform. Like, no Ethereum application, at least not without great difficulty, can rearchitect the fundamental sort of transaction ordering model of Ethereum and Cosmos gives you the opportunity to do that.
00:47:48.232 - 00:48:02.630, Speaker A: So is that something that you would use Cosmos for? I would love to hear, like one or two examples maybe of applications that lend themselves specifically well to using an application chain on Cosmos instead of building on top of Ethereum.
00:48:03.370 - 00:48:47.550, Speaker B: Yeah. So maybe a few different examples, I think, like the Cosmos hub and a few other Cosmos zones, how they refer to individual blockchains that run on top of the stack that have DEXes like batch trades and enforced batched execution of trades in each block. So this is essentially a transaction ordering constraint that's specific to the application and affects front running. It's a dynamic that you can't accomplish on Ethereum today, at least not without bdfs and a bunch of other very fancy tricks. And I think that would be like an obvious example of something that's enabled by Cosmos.
00:48:47.630 - 00:49:01.174, Speaker A: Right, but you do give up a lot in return, right? So let's say you build a Dex on an application chain on Cosmos. Is there a simple way to explain how it is possible that you might use assets from other application chains on Cosmos? For example, the Cosmos hub.
00:49:01.302 - 00:49:54.780, Speaker B: Yeah. So Cosmos provides the first generalized interoperability protocol that we've seen in crypto, actually called IBC, the Inter Blockchain Communication Protocol. And essentially any blockchain with finality and efficient light client proofs. So most proof of stake blockchains, everything within Cosmos substrate based, Ethereum, et cetera, can all adopt IBC and use it to implement various different modes of interoperability, one of which, and that's actually live today, are cross blockchain asset transfers. So you can kind of think of it as a generalized bridge. If I want to build, for example, a lending market within Cosmos, I can deploy that application to its own blockchain. Perhaps I'm the only validator, perhaps I pay some people to do that for me, whatever.
00:49:54.780 - 00:50:09.034, Speaker B: And any user that wants to send, for example, atoms from the Cosmos Hub or like Luna from Terra's Cosmos zone to my lending market is able to do that without really any sort of by default.
00:50:09.162 - 00:50:20.638, Speaker A: You said it's basically like a generalized bridge. How does this work in comparison to a trusted know one like WBTC, where we all know how it works on Ethereum?
00:50:20.734 - 00:51:07.422, Speaker B: I guess a couple of thoughts on that. The first would be I think it's probably better to think about it just in terms of IBC as a generalized bridge versus Idiosyncratic implementations, whether they be custodial in nature or not. So like WBTC or Salana's bridge to Ethereum or any of the Ethereum L two S bridges to the main chain or to BSc or whatever, are all kind of like Idiosyncratic protocols. They have different trust assumptions. Some of them are more decentralized than others. Some of them are more custodial and centralized. But broadly speaking, they are not generalized or shared.
00:51:07.422 - 00:51:40.194, Speaker B: And this makes it quite difficult to get efficient interoperability across a wide variety of platforms. You frequently have to route through sort of like Hubs, and you end up with multiple versions of the same asset on different platforms depending on sort of the route that you've taken. IBC, in contrast, provides you the ability to, in a generalized fashion, basically make pairwise bridges with minimal trust assumptions.
00:51:40.342 - 00:52:18.950, Speaker A: Cosmos does have a native token, Adam. But it's not necessary to use Adam to create your own application chain using the Cosmos SDK. It's also not necessary to adopt IBC and to communicate with another blockchain in the Cosmos ecosystem. So one thing that I hear a lot is that value proposition of Adam is basically it springs from the Cosmos Hub, which is a special blockchain, a special zone inside the ecosystem. Could you say something about what is basically the thesis for the Cosmos Hub?
00:52:19.030 - 00:53:35.250, Speaker B: So there's nothing inherently special about the Cosmos Hub, and maybe that is what's special about it. Sort of unlike in any other project, the Cosmos Hub is not privileged by the protocol. It's on an equal footing to any other zone. It does happen to sort of have natural centrality or be a natural shelling point for the development of the protocol and for users and developers of other Cosmos SDK chains. So today it's imagined that, or I guess I should say in the short to medium term, the Cosmos Hub plans to provide certain functionality that requires a high degree of trust and credible neutrality. So some examples of these would be bridges to, like, ethereum and bitcoin. And then in the future, it's imagined that the Cosmos Hub will adopt a shared security model in a kneel towards an end state that looks likely broadly similar to like a roll up based ETH two or polka dot's main chain.
00:53:35.250 - 00:53:46.850, Speaker B: The mechanism for it just hasn't been decided yet. They decided to build the rest of the protocol and the interoperability spec first rather than like a main chain first. So it's kind of just a different approach.
00:53:46.930 - 00:53:48.520, Speaker A: What do you mean by shared security?
00:53:48.890 - 00:55:33.320, Speaker B: Shared security, in, well, the literal sense, like many blockchain protocols, I guess many smart contract blockchains start with either a generalized execution environment that anybody can deploy applications to or in the case of something like polkadot sorry. In which case within that environment, they sort of all share the same security. The security of all ethereum applications is uniform across the platform. There are other examples of blockchains like polkadot, which, although it doesn't provide a generalized execution environment or smart contract functionality on its main chain directly, it does provide like, a built in auction mechanism to allow different applications to bid for the rights essentially to share security with that main chain, which in theory has sort of like the most credible, validator set and highest degree of security. Cosmos in contrast to these approaches, rather than starting with a shared platform or an architecture for shared security, started with interoperability and then is going to build towards whatever long term vision makes the most sense with respect to sort of like the network security topology. And so I think of them as just kind of like working towards likely the same end state from sort of opposite sides of the problem.
00:55:33.930 - 00:56:06.050, Speaker A: Okay, so we established that applications can build their own blockchains using the Cosmos SDK, but they're all proof of stake blockchains, right? And so in order to generate security. And finality, they need validators and how are they going to get those? And I think what you suggested is that they can basically buy validators, for example, from the Cosmos Hub, but also maybe from other places.
00:56:06.950 - 00:57:18.394, Speaker B: Yeah, I mean, I think that that's a simplistic and reasonable model for security sharing in the short to medium term that doesn't require sort of deep cryptographic or incentive design work. I think long term there is sort of an open question as to what an ideal shared security layer for all cryptocurrency applications or different ecosystems of applications, potentially different niches depending on their use case looks like. Whether that's a generalized execution environment, whether that's a sharded execution environment, whether that's like a roll up centric e two, whether it's something like Polka Dot with its parrot chain auctions. And I think the Cosmos Hub will likely experiment with multiple different models. One of the first will probably be leasing validator sets without sort of more direct incentive engineering around it.
00:57:18.592 - 00:57:37.150, Speaker A: Would this then mean that? Sort of so I have my app chain I need validators. I go to the Cosmos Hub and they already have their atom staked and I just say, please validate my chain as well. And then that atom becomes exposed to double staking risk, basically, right?
00:57:37.220 - 00:58:41.118, Speaker B: Yeah, it's essentially sharing the slashing risk. I mean, there's multiple different modes you could imagine. One is purely social, which is if a validator on the cosmos hub or a set of validators from the cosmos hub which have significant amounts of money and credibility at stake, come and validate your chain or you pay them to do that and they become malicious like that's going to have social consequences. And I think is honestly not that dissimilar of an assumption to weak subjectivity. But you can take it a step further and you can actually couple their slashing conditions such that if those validators violate or make an invalid state transition on your blockchain, then they get slashed on the Hub too. And you can tie the incentives together directly. And there's like a very broad spectrum of potential protocols in this vein.
00:58:41.118 - 00:58:49.670, Speaker B: I think that probably many of them will make sense in many different contexts and the Cosmos Hub is like an interesting vehicle for their exploration.
00:58:50.090 - 00:59:13.390, Speaker A: Yeah, it's pretty interesting to think about a blockchain where the validators are not paid in and they don't stake the blockchain's native token. So it feels like they may be less incentivized to protect the half of the blockchain if the token that they stake is not exposed to it's not basically a bet on the half of that blockchain.
00:59:13.730 - 00:59:38.070, Speaker B: I'm not sure that I would fully agree with that, but to the extent that is true, it's an incentive security issue that's shared by any shared security layer, whether it be a generalized execution environment or one that's directly leased. I think that's probably more of a general comment about non application specific security layers.
00:59:38.410 - 00:59:49.942, Speaker A: Maybe the bigger point would be that just the idea of application layers, doesn't this force application developers to be protocol developers as well?
00:59:50.076 - 00:59:53.942, Speaker B: Well, I think they're already forced to be protocol developers, I mean, in practice.
00:59:54.086 - 00:59:59.258, Speaker A: And that is because they have to understand all the idiosyncrasies of the blockchain they're building on or why.
00:59:59.344 - 01:00:54.570, Speaker B: Well, they have to understand all the idiosyncrasies of the blockchain that they're building on. Like building on something like Ethereum doesn't obviate mev or sort of prevent your application's exposure to it or other things like the communication layer. Like, we have all the infura stuff. We now have various different private memory pools and this type of thing. So those are all sort of features that have meaningful implications at the application layer and that application developers are probably going to have to contemplate, like, if they choose not to, it's at the detriment of users. So I think they're already kind of forced to be protocol developers, and many of them may want more control over their environment and the ability to fit the protocol to their applications.
01:00:54.730 - 01:01:17.986, Speaker C: I agree with Charlie said, and I think that a very underestimated aspect of the Cosmos ecosystem is the SDK, which allows you to very easily build these chains by using all the kind of community made modules for providing very common features that you will need when building a blockchain instead of having to rebuild them on your own.
01:01:18.088 - 01:02:09.798, Speaker B: Yeah, and I might get in trouble for saying this, but even to the extent that you don't like the Cosmos thesis and you're not interested in building a Cosmos based blockchain, there are still many parts of the protocol that are probably going to be purely additive to everything in crypto. Like, IBC as a generalized communication layer is the interoperability protocol that should be adopted by essentially everything, like every L two, every blockchain. I think when you reframe the conversation that way, you can maybe start with, are certain applications going to want to build their own blockchain or have their own blockchain and design their own protocols? And if your answer to that is like, feasibly yes, then Cosmos is probably your best bet right now.
01:02:09.964 - 01:02:21.102, Speaker C: In the same vein, I think it would be valuable for us to eventually have a solidity contract or an Ethereum pre compile for accepting IBC type messages on Ethereum.
01:02:21.186 - 01:02:24.090, Speaker A: What is the way that you would use IBC on Ethereum right now?
01:02:24.160 - 01:02:42.586, Speaker B: Well, every single L two and every single non Ethereum platform right now has its own bridge. That doesn't need to be the case if you adopt IBC and any protocol with finality can. So those should all most likely be replaced with IBC as like a generalized spec.
01:02:42.708 - 01:02:44.370, Speaker A: Is this viable judges?
01:02:45.030 - 01:03:27.630, Speaker C: I think so. Currently, all the roll up systems, they either don't have an interoperability protocol or plan right now for talking with each other, and they will either have to roll their own bespoke one which will have to follow some kind of message format, or they could try to leverage one of the existing ones. And I think that using IBC would be a good choice. Similarly, I think that interoperating, for example, with the polka dot ecosystem, I think it would be valuable to adopt IBC over the Xcmp protocol that they're currently using.
01:03:27.780 - 01:03:36.514, Speaker A: And is this a case of, there are 20 different standards, this is not sustainable, so here, let me make the 21st standard.
01:03:36.712 - 01:03:56.758, Speaker C: I think that this is not a case of there is 20 standards, and let's make the 21st. This is the first or second interoperability standard. That has always been the expectation, in my opinion, that this should become the one thing for chains to communicate over.
01:03:56.924 - 01:04:02.618, Speaker A: Why is it that all of those ethereum layer twos don't adopt IBC? What is that thinking?
01:04:02.704 - 01:04:05.482, Speaker B: I mean, it's just relatively new because.
01:04:05.536 - 01:04:12.506, Speaker C: There'S so many things to do and so little time, and it's still very little, very new, as Charlie said, as.
01:04:12.528 - 01:04:19.470, Speaker A: A protocol, how difficult is it for an existing layer two to rip out their protocol and replace it with IBC?
01:04:20.130 - 01:04:58.870, Speaker C: I think trivial, because you would implement it as a smart contract. That's the beauty of using smart contracts, that they don't require protocol changes. You just define a new smart contract which implements whatever you want, where for IBC, it is just a message format, more or less, and some validation rules on that message format, and that's about it. And you would then need to maybe adjust your client code on how they would interpret these messages. But I don't think it's a large overhead, assuming that you have clear semantics around the protocol.
01:04:58.950 - 01:05:13.282, Speaker A: If we entertain this idea and say that IBC will be adopted by more blockchains in the future, what is the impact on the Cosmos ecosystem? Does it know? Do the borders disappear or what happens?
01:05:13.416 - 01:06:06.070, Speaker B: I think it's very possible that the borders disappear. I mean, there's some joke that everything is a Cosmos chain. That's not really a joke, because Cosmos doesn't privilege any chain. Like we said with the Hub, it's not special in any way, and neither is Ethereum. If Ethereum or any application developers on top of it decide to support IBC and interoperate in that way, I think, again, philosophically, if Cosmos works, it won't have borders. It will make it possible for the first time to, in a reasonable and practical manner, interoperate between different blockchains without a bunch of idiosyncratic middleware. And I think that's not a question of dissolving Cosmos's borders.
01:06:06.070 - 01:06:08.974, Speaker B: That's a question of dissolving borders between all blockchains.
01:06:09.102 - 01:06:22.674, Speaker A: So Cosmos is like a bet on blockchain globalism? Sure, yeah, I guess it doesn't privilege any blockchains. But what about Bitcoin, for example? I mean, could Bitcoin ever adopt IBC.
01:06:22.722 - 01:07:54.066, Speaker B: Or will it forever be no? Well, Bitcoin could choose to adopt IBC by having a pre compile and choose to sort of process the consensus mechanism or the consensus messages of remote blockchains like Ethereum or the Cosmos hub or whatever. But bitcoin will almost certainly never choose to do this. There's near 0% probability, I would guess, perhaps as unlikely as Bitcoin supporting smart contract functionality generally. And bitcoin is unique in that it does not have finality and it's unable to understand the consensus mechanism messages of remote blockchains, so it is unable to adopt any interoperability protocol. And that's why every bitcoin bridge that you see essentially needs to build is either custodial or it needs to build the crypto economic incentives to secure the interoperability mode on the remote blockchain. So whether this is like in WBTC's case, obviously it's just custodial you have something like keep which uses collateral, you have, I don't know, I guess other forms of interoperability, but notably none of them really involve bitcoin at all. It's all building scaffolding around it because the bitcoin protocol is blind to the world around it.
01:07:54.168 - 01:08:59.530, Speaker A: I would say that sort of the sentiment around Bitcoin, especially with regards to Ethereum is even though a bitcoin is trading at like fifty k or something, is pretty low. And that's because Ether has made some advances to becoming more store of value, like with ERP one five nine and proof of stake could reasonably in a year have lower inflation than bitcoin. And that of course has made a dent with a lot of people who now see it as much more desirable and even to the point where some people expect flipping this cycle. And I don't want you to comment on the price because I know that's not really possible, but I do want you to sort of leverage the fact that you are known to have an extremely long time horizon when it comes to your allocations to crypto. And I just want to hear from you if you think that your thesis for bitcoin is still as intact.
01:08:59.870 - 01:10:13.806, Speaker B: If you think about it in terms of use cases, I think bitcoin's use case as like a maximally censorship resistant store of value or non sovereign asset is intact. Bitcoin has a function and a purpose and I think it fulfills it elegantly. It's quite minimalistic really. With Ethereum, I think that up until relatively recently, like potentially sometime in early 2020, there was some broad question as to whether there were going to be use cases that were meaningful. And then we had sort of the DFI renaissance. And at this point I think that there are quite a lot of products that make fundamental sense and feel like they should exist and have a purpose in the world that are on top of Ethereum and that millions of people are using. And I think with respect to Ether as the Ethereum network's native money, it seems to be gaining adoption in that use case.
01:10:13.806 - 01:10:26.046, Speaker B: And I guess I would think about it less in terms of competition and more so just like. Ether is succeeding. Because ethereum is succeeding. It's not obvious that there's like near term competition, at least to me with bitcoin.
01:10:26.158 - 01:10:45.674, Speaker C: I agree with that. Also, Ethereum's hard forks sometimes may make it hard for people to think about it on longer term horizons. So I think that this kind of difference in the governance layer kind of paints a very clear place for both of these to coexist for a very long time.
01:10:45.792 - 01:11:01.838, Speaker A: Is there anything that would like changed in bitcoin or do you think the way that it is, it can carve its niche and survive alongside these other crypto assets that are more rapidly adapting to sort of the demands of the market?
01:11:02.004 - 01:11:51.054, Speaker C: For me, there's two things. Firstly, I would like a minimal change to the scripting language, which would allow us to build more flexible protocols for off chain scaling and for key management such as vaults. And I think that that may be hard to make the case today, but I think it may become a very popular discussion topic in the future that we may end up needing a finality gadget on top of bitcoin. I don't know how that will look like if that will mean that there is some proof of stake component that ends up being built on bitcoin or something like that. But I think that we will need a finality gadget as the block reward approaches zero.
01:11:51.252 - 01:11:57.170, Speaker A: Okay, cool. I'd love to unpack those. So starting with the vault. So what is a vault? Judge us.
01:11:57.240 - 01:12:41.070, Speaker C: A vault is a system which allows you to maintain custody of your funds even if one of your keys gets stolen. Basically you have a hotkey and a cold key. And if your hotkey gets stolen, you can always use your cold key to claw back your fans and recover them. And today this kind of protocol can be implemented, but it is tricky to do and it kind of has very specific limitations. Whereas by augmenting the scripting language, we could get a more easy to implement and more flexible protocol.
01:12:41.730 - 01:12:45.870, Speaker A: Are vaults only useful to improve sort of custody solutions around bitcoin?
01:12:45.950 - 01:12:46.580, Speaker C: Yes.
01:12:47.270 - 01:12:49.058, Speaker A: There's nothing else they can do.
01:12:49.224 - 01:12:52.926, Speaker C: Vaults are an improved custody solution.
01:12:53.118 - 01:12:57.190, Speaker A: Okay. What is the difference between a vault and a covenant?
01:12:57.930 - 01:13:00.630, Speaker C: Vaults are built using covenants.
01:13:01.210 - 01:13:09.560, Speaker B: What are the hotkeys used for in bitcoin? Like in Ethereum, your hotkey would normally be like a staking key or a voting key or whatever.
01:13:10.410 - 01:13:16.790, Speaker C: I don't think that's something that you want to do a transfer or that's a lightning. Maybe it's a lightning wallet.
01:13:16.870 - 01:13:22.458, Speaker A: I mean, an exchange needs a hot wallet. I mean, because they need to process transactions.
01:13:22.554 - 01:14:06.074, Speaker C: Exactly. So the one change is the vault. That would be nice. And the other is the off chain scaling solutions. Currently it seems that lightning has had trouble with scaling the amount of assets inside of it. And it's not clear if this is about usage or if it's due to the fundamental limitations of payment channels around capital efficiency. Hence I think that modifying the scripting language in a way that would allow introducing some kind of protocol that looks like the very popular roll ups in Ethereum would be a net positive for the system.
01:14:06.192 - 01:14:14.138, Speaker A: Oh, so you could create a version of roll ups in Bitcoin and it requires only sort of minimal changes to the scripting language.
01:14:14.314 - 01:14:19.566, Speaker C: I'm not claiming I can, I'm saying it would be nice if that were the case.
01:14:19.668 - 01:14:44.902, Speaker B: I mean, you could imagine enshrining snark for only proof checking, like a UTXO off chain environment. I think historically Bitcoin developers have said that the cryptography is too new. Yes, but long term that seems like a minimalistic sort of change and seems reasonable, I guess.
01:14:45.036 - 01:15:11.306, Speaker C: Yes, exactly. And Op snark verify or Op Stark Verify Opcode in the future could be something which satisfies this condition. While we're at it, at the topic of the changes, I just had another thing come to mind, which is an EP 1559 like mechanism could be also net positive.
01:15:11.418 - 01:15:22.930, Speaker A: And by that I guess you don't mean to introduce permanent inflation like ERP 1559 has, but rather to spread out the rewards. Maybe, yes.
01:15:23.080 - 01:15:47.146, Speaker C: EP 1559 defines there's various ways you can implement the fee burn, or rather the component where the miner does not get the entire reward of the block and hence Ethereum's implementation chose to burn it. In this implementation we could do something else. We could choose to distribute the block reward over the next 100 miners, for example.
01:15:47.248 - 01:15:49.274, Speaker A: Yeah, I think that would be a good idea.
01:15:49.392 - 01:16:10.558, Speaker C: So in general, these are the three kind of changes that I would it's scripting language related changes, finality Gadget EEP 1559. But just to be very upfront, I think that Bitcoin as is today, it's fine. And I don't think that these are nice to haves. These are not must haves.
01:16:10.734 - 01:16:17.734, Speaker A: Let a man dream. I do want to talk about the finality gadget. So what does it mean?
01:16:17.852 - 01:16:41.022, Speaker C: It would mean that you introduce an additional layer on top of the proof of work consensus that says every, let's say 100, 200, whatever number of blocks that becomes the last block in the system and reorgs cannot be triggered past that number.
01:16:41.156 - 01:16:43.770, Speaker A: Is that just a different word for checkpoint?
01:16:43.930 - 01:17:25.370, Speaker C: No, because a checkpoint is an overloaded term. When people say checkpoints, they seem to think that you start to discard the entire chain history and all that, which is not great. Whereas what we're talking about is just disallowing reorgs past a certain threshold. You could argue that today there is already some kind of implicit social consensus around the max reorg depth, which would be the time after which a coinbase is spendable, which is 100 blocks. But I think it would be nice if this detail could be enshrined in the protocol.
01:17:25.790 - 01:18:38.594, Speaker B: Safety is already a collective hallucination. Yeah, I remember when there was an inflation bug in bitcoin. I think I made, like, a Twitter poll at the time that was along the lines of if there were a certain number of bitcoin that we knew to have been minted through it, like 100 blocks ago, would we be willing to unwind the chain and go back? And I think it's a very tricky question. In the same way that as of right now, to the collective hallucination of six block finality, if there is a 50 block reorg, I don't expect that it would be accepted by the network at a social layer. I just don't think it would happen. And so I think the finality gadget point is like if you're already kind of in that state, and this is already an assumption that you're making implicitly, then if you have some reasonable crypto economic mechanism to try and enshrine it more directly, then seems like a reasonable idea.
01:18:38.792 - 01:18:50.280, Speaker A: Yeah, I agree. And the way that we do this would be just to tell our nodes not to accept reorgs deeper than X blocks. Is that right?
01:18:50.650 - 01:19:09.510, Speaker B: That would be one. I mean, it probably has worse security properties than one in which you make like a twelve month liveness assumption and have something like the Casper FFG or finality gadget with like a proof of stake overlay.
01:19:09.590 - 01:19:13.614, Speaker A: How does it work? Where does the proof of stake come in? What do the stakers do?
01:19:13.732 - 01:19:34.942, Speaker C: There would be a committee of validators elected pseudo randomly weighted by their stake, where the stake would be denominated, let's say, in bitcoin, and these validators would sign on a block hash, which would be considered the checkpoint. The point of noriog.
01:19:35.086 - 01:19:39.998, Speaker B: I don't think the Casper FFG had a pseudo random.
01:19:40.174 - 01:19:40.718, Speaker C: Yeah.
01:19:40.824 - 01:19:43.558, Speaker B: I think it was a signature of all validators. Right.
01:19:43.724 - 01:19:54.170, Speaker C: It doesn't matter. I did not call it Casper FFG, I just said that there needs to be some collective signing via a committee.
01:19:55.470 - 01:20:00.038, Speaker A: How deep would you personally put this point? Is it like 100 blocks deeper?
01:20:00.134 - 01:20:07.834, Speaker C: I don't know. I think this is up for debate. Simulation and other things that are beyond my security clearance.
01:20:07.962 - 01:20:15.010, Speaker A: Would have the interesting side effect that you could allow people to stake their bitcoin even if it's just for a small reward?
01:20:15.350 - 01:20:20.814, Speaker C: Yeah, maybe if that allowed you, for example, to earn transaction fees, turning bitcoin.
01:20:20.862 - 01:20:24.020, Speaker A: Into a productive asset trustlessly, that would be nice.
01:20:24.390 - 01:21:17.414, Speaker B: Yeah. I think someone had thrown out an idea out there for charging transaction fees on the basis of coin days destroyed, which always to me sound like potentially interesting long term. On bitcoin much fewer. You have very few ways to kind of game that system securely, whereas on Ethereum it's very hard to do, for example, charge a percentage transaction fee because there are an infinite number of ways to implement a transaction and avoid the constraints. Right, yeah. Whereas on Bitcoin I think probably feasible within the existing protocol to charge a coinbase destroyed based transaction fee without a secure way to game it.
01:21:17.452 - 01:21:23.430, Speaker A: It's also a beautiful example of why softforks can indeed be evil.
01:21:24.890 - 01:21:25.638, Speaker B: Certainly.
01:21:25.804 - 01:21:43.258, Speaker A: Yeah. I mean, this is a super interesting topic, this whole basically price discrimination. What do you think about that in general, in blockchains? Like, should blockchains price discriminate? Because right now there seems to be a strong consensus that they shouldn't.
01:21:43.354 - 01:21:54.594, Speaker B: I feel like they probably shouldn't in some philosophical sense, but in practice it's completely unsurprising that they do objectivity at.
01:21:54.632 - 01:21:57.102, Speaker C: Scale is hard, like, fundamentally.
01:21:57.246 - 01:22:22.466, Speaker A: So we mentioned the finality gadget. What about something like consensus before a full block has been mined? Like 0.5 block finality? Is there a way to do this to give us a bit, like, lower latency on bitcoin, like a pre consensus thing or whatever?
01:22:22.588 - 01:22:30.246, Speaker C: Like the type of proposal that was done for running the avalanche consensus, for example, on bitcoin cash blocks?
01:22:30.358 - 01:22:35.280, Speaker A: Exactly. I really like that proposal, to be honest. I wish bitcoin cash would have done it at the time.
01:22:35.730 - 01:22:40.698, Speaker C: I'm not well enough informed on that specific proposal to give you a good enough comment.
01:22:40.874 - 01:22:56.770, Speaker B: Yeah. Hypothetically though, you could have a head chain or like a header, like how on e two, there's a finality gadget, I believe, like a certain number of blocks back from the head. And you could do something similar on bitcoin.
01:22:56.850 - 01:23:31.134, Speaker C: I mean, the moment that you introduce an additional consensus, the first problem is getting people to agree that it's okay to introduce an additional layer of consensus participants other than the miners. If you do that, I think that we can go crazy with designing protocols which improve finality or which improve latency or anything like that. I don't think that the hard problem is designing a protocol that would be useful like that. I think that the hard problem is.
01:23:31.332 - 01:23:33.680, Speaker B: Actually getting everyone to agree on it.
01:23:34.690 - 01:23:41.842, Speaker C: That and getting everyone to agree on the fact that there might be an overlay a consensus overlay layer maybe one day.
01:23:41.976 - 01:24:13.440, Speaker A: Okay, two questions as a follow up to this. The first, yesterday, elon musk has sent two tweets that basically criticized the energy usage of bitcoin. And this strikes right at the thing that you just said, which know, should we pay miners or should know get consensus via some other as? Do you see bitcoin ever abandoned proof of work? And if not, do you think this will eventually become a problem?
01:24:14.130 - 01:25:27.910, Speaker B: I think the environmental questions are worthwhile, but in general, I've found that the arguments are not super salient. Like, I think Nick Carter has written a lot on know energy. So maybe the question I would take it less as should bitcoin switch off of proof of work, given the energy consumption on a substantive level and more like, if this is going to be a common criticism of bitcoin, should it just switch off of proof of work to obviate the criticism? I would guess probably not. That's probably not a good enough reason to get folks on board, but I don't know, potentially long term and in concert with the declining block subsidy, I think it's possible to imagine that 2050 bitcoin has adopted a hardened, tested, proven proof of stake consensus system or overlay.
01:25:29.210 - 01:26:32.794, Speaker C: Taking the opposite side on this. I think that the whole approach of firstly using mining heat emissions to do other things inside the cyclical economy, I think that's a very valid thing which we can use. Let's just assume that we cannot get rid of the proof of work because maybe it has to stay because we value objectivity a lot, so we have to figure out what to do with it. I think that only now is the problem getting the dimensions that it quote unquote deserves. And only now are we going to see the proper measures or solutions, creative solutions developed to address or maybe utilize this effort. So, for example, for me at least the use case where if there is excess energy, you use bitcoin as a quote unquote energy battery. Maybe many people would call it not a great idea.
01:26:32.794 - 01:27:08.306, Speaker C: Personally, for me, I think that there is lots of areas where we have a lot of sun, a lot of sun and all that energy just doesn't get used at all. Or for example, when you want to transmit energy from a to b, lots of energy gets lost along that cable. So I'm not posting a or b. I'm just saying that it's worth digging hard at the problem and seeing if it can be inverted in some way. Instead of just saying it's bad, let's give it up, let's move on to the next.
01:27:08.328 - 01:27:12.646, Speaker A: And by inverted, you mean actually turned into a strength of bitcoin, right, in.
01:27:12.668 - 01:27:14.742, Speaker C: Some way or a new use case?
01:27:14.876 - 01:27:24.140, Speaker A: Yeah. And I mean, you do see like credible reports that the energy grid actually can be stabilized in many parts of the world.
01:27:25.150 - 01:27:57.170, Speaker C: So little known fact that I studied electrical engineering and yes, all of this stuff like around the load balancing of the grid when there is more load and then you turn on your bitcoin machines to consume the load or the opposite, or you turn off the machines. This is a very valid use case, okay? Or even just dead simple. You have a bitcoin miner, it emits heat, you use it to warm your greenhouse. The products that will utilize all these forces have not been created.
01:27:57.250 - 01:28:49.730, Speaker A: I had a second question and again so I don't want you to comment on the likelihood of this at all, but if ethereum or another coin was to flip in bitcoin and bitcoin loses its number one spot, do you think? I'm curious to explore what this means for bitcoin in the cultural governance sense. So we talked about how that it's very difficult to change bitcoin today because you just wouldn't get consensus on anything. And people rightly, have adopted this very conservative mindset that the rules are set in stone forever. Do you think that this is something that could change if the bitcoin community was to feel more competition and urgency? Do you think there could be like a quote unquote cultural awakening?
01:28:50.230 - 01:29:09.494, Speaker B: I mean, sure, but we probably should title the episode first, just to state it. Right. I'm sure we're going to get tweeted out for this, but two ethereum dudes talk about and speculate about bitcoin. I wouldn't profess to be very deep in the bitcoin community or have any special insight.
01:29:09.542 - 01:29:11.850, Speaker A: Oh, you see yourself as an ethereum dude?
01:29:12.270 - 01:29:44.790, Speaker B: I don't see myself as an ethereum dude. I just mean I think that there is a defined subset of the crypto community that are very specifically bitcoin people and we're now speculating on their social dynamics, which could be completely wrong. I agree with that. Just for state's disclaimer or whatever. That being said. Sure, yeah. It seems like if bitcoin felt less secure in its use case, then perhaps we're forced to make change or bitcoin feels forced to make changes.
01:29:44.790 - 01:30:31.378, Speaker B: Like, historically, I think probably the closest the issue has come to coming to a head was, like, the block size stuff. And I think that was successfully argued as unnecessary. And bitcoin has obviously been quite successful since then. It still feels secure in its use case. So I don't know, perhaps there's never a problem that sort of moves the bitcoin community set point and it always kind of remains like, we're fine and this is unnecessary. I don't know, perhaps not. And at some point, I don't know, we see bitcoin proof of stake.
01:30:31.378 - 01:30:32.630, Speaker B: I think it'll be cool.
01:30:32.780 - 01:30:58.574, Speaker C: But, yeah, I think that I see myself as somewhere in between because I follow all of the bitcoin kind of protocol developments. Although I don't think that we are people that nothing that we say kind of is about the community. It's more about our independent thinking as engineers, investors, protocol designers and all that. So it's more of an entertainment thought experiment, maybe.
01:30:58.692 - 01:31:03.966, Speaker A: Thank you so much, guys, for coming on the show. I think it was a great discussion. Thank you.
01:31:03.988 - 01:31:04.666, Speaker C: Hashim.
01:31:04.778 - 01:31:05.486, Speaker B: Thank you.
01:31:05.588 - 01:31:05.900, Speaker A: All right.

00:00:06.090 - 00:00:24.590, Speaker A: Welcome to Uncommon Core where we explore the big ideas in crypto from first principles. This show is hosted by John Chabanot, co founder and general partner of DBA and Me Hasu, strategy lead at Flashbots and advisor to the Lido Dao.
00:00:26.810 - 00:00:27.906, Speaker B: Today hasu.
00:00:27.938 - 00:00:36.882, Speaker C: And I sat down with Mike Neuter from the Ethereum Foundation and Chris Hager from Flashbots. We had a great time chatting through PBS, also known as proposal builder separation.
00:00:37.026 - 00:00:38.562, Speaker B: We talked about the history of PBS.
00:00:38.626 - 00:01:03.166, Speaker C: On Ethereum, talking about what it looked like on Proof of Work and how that brought us to where we are today with Mevboost on Ethereum right now. We also looked ahead, looking at the future of PBS, asking each other should we ensuring PBS or not and what would that look like? That included talking about really fun new ideas like PEPC. We also had some fun at the end talking about what should PBS look like on other domains, especially layer two.
00:01:03.188 - 00:01:04.938, Speaker B: S on Ethereum, like other roll ups.
00:01:05.034 - 00:01:07.026, Speaker C: Where we chatted through why we think.
00:01:07.048 - 00:01:10.898, Speaker B: It could actually look very, very different on L two S compared to Ethereum itself.
00:01:10.984 - 00:01:11.986, Speaker D: Hope you enjoy.
00:01:12.168 - 00:01:17.010, Speaker E: What is Proposal builder separation or short as we know it, PBS.
00:01:17.350 - 00:02:17.426, Speaker B: Sure. So the first thing that I'll pick out that we kind of used before it's, the quote from Barnaby is still my favorite kind of one liner description of what it really is. So PBS is first and foremost a design philosophy, recognizing that protocol actors may invoke services from third parties in the course of their consensus duties. So I really like that as just like a kind of high level setting of what it is. Because while we look at it in Ethereum as a very concrete implementation, the reality is it is just kind of a higher level design philosophy of we understand that we're going to have protocol actors that are responsible for certain things. And then there's going to be an economic incentive and for various other reasons, for them to outsource certain actions to other actors that may not be actually in the protocol. So concretely, the way that we're used to thinking about that is in the Ethereum world where we have validators one of which, who will be the active proposer at a given time to propose a block to the rest of the network.
00:02:17.426 - 00:03:35.326, Speaker B: And so the reason that we have concretely proposer builder separation here is that we want that proposer to be relatively unsophisticated and yet be economically competitive such that we can keep the validator set decentralized, so they can outsource the very specialized task to this network of specialized block builders which sit outside the protocol. And those block builders are responsible for building what is the most optimized block that can extract the most value, such that they can pass the majority of value back. Because otherwise what you would have, conversely, is if we don't have this ability for proposers to kind of interact with this out of protocol market in a relatively trust, minimized way, well, then you would simply have a very clear return to Sophistication, where the only way to be a competitive proposer would be okay, well, now you need to be a builder in house. You need to be super sophisticated and know how to optimize everything. So it's trying to get at the fact that you're going to have these different roles and we need to design what is the right way to have an interface between these kind of in protocol and out of protocol roles. And right now the way that that works with mevboost is kind of a strapped on way of doing that. And a lot of the research right now that Mike has been doing over the F is like, how do we kind of maybe bring that a little bit more in house and what should that look like to try to make that interface between the in protocol and out protocol actors even more trustless?
00:03:35.518 - 00:04:30.002, Speaker D: Yeah, and I always like to kind of circle back to Vitalik's Endgame post. The last sentence of his post is basically the future of many iterations of these designs will probably end up in a world where there's centralized production, decentralized verification and strong antisensorship properties. And he kind of talks about how some ecosystems might start more centralized in the block production world and evolve into something that has decentralized verification only. And others could take different trade offs in the initial state, but ultimately we might always end up in that state where we need to firewall off the heavy duty kind of actions that the validators need to take from something that can be run on a local machine has like credible decentralization features. So that's kind of how I like to think about it.
00:04:30.136 - 00:05:04.858, Speaker F: Yeah, you spoke to a lot of things that I'm also thinking. I think in particular, it's also a case of there is either an implicit or an explicit auction and if the auction is implicit, has a lot more negative externalities and incentives to centralization. And PBS recognizes that not all protocol actors may be able to fulfill all the duties in a comparatively performant way and need external support for that to also keep the decentralization of the network stable.
00:05:05.034 - 00:05:05.374, Speaker A: Yeah.
00:05:05.412 - 00:05:55.470, Speaker E: And what I particularly like, and kind of why I picked out this quote is that it really hones in on PBS as philosophy. Right. And I think the PBS, the implementation on Ethereum faces a lot of criticism from different directions, all great arguments and concerns that we will also go into in this episode. But really I think the general idea behind it is one that is extremely sound and I think that all of you laid out here really well. So with this high level overview out of the way, I'd like to go a bit a couple of years back and hear from you PBS, as an idea. Where did it start? What is its history? How do we get from there to where we are today?
00:05:55.620 - 00:07:04.446, Speaker D: I think historically the PBS marketplace was a little more explicit in the Mevgeth world before we had proof of stake merge. So essentially in that scenario, there was a few large mining pools that controlled a huge portion of the hash rate. Mevgeth was the ability like provided the ability for searchers to send bundles to those miners. The searchers were able to send bundles to the miner kind of without worry about the miner stealing them because since there were so few, the miner's reputation was worth more than stealing the contents of that bundle. So in that regard, the interaction between the searchers and the block producers was simpler because there were so many fewer block producers. And then I guess as the merge kind of approached, a lot of people were talking about PBS as a general approach. And I think even we're considering holding off on shipping the merge until we had some in protocol version of PBS that could be accompanying the merge.
00:07:04.446 - 00:07:33.950, Speaker D: Hard fork. I think that was discarded in general because the merge was already a huge lift and adding more complexity to the software and to the spec was kind of just going to slow things down more than necessary. And so yeah, maybe I'll pass it over to Chris here as Flashbot stepped in and implemented Mevboost. And that was like the real first PBS instantiation out of protocol that we saw post merge.
00:07:34.610 - 00:08:43.474, Speaker F: Yeah, I think about one year before the merge, stefan from flashboards posted the OG Math boost specification outlining how proposers could interact with an external blockbuilding network. And then work started in the background in the Dev Connect meeting on Math day in Amsterdam in 22, that was April 22, there was a finalization of all the APIs that were needed and from then on it was clear that everybody is shooting for the merge with PBS, with Mafboost PBS enabled. I think at this point it was fully unclear how permissioned or permissionless this whole thing will be and how this plays out. But it seemed inevitable that some form of this is going to ship. And we worked them through the summer to deliver a permissionless relay on the open source software that also other relay operators can run and had everything ready in time, just in time for the merge that included permissionless builder access.
00:08:43.672 - 00:09:42.070, Speaker D: Yeah, and it might be worth just kind of running through Mevboost as a software for people who aren't familiar. So the idea of Mevboost is there's a third party actor here that facilitates the auction between the proposer and the builder. And the reason for that is the proposer needs to trust that the block that the builder produces is both valid and accurately pays them the amount that the builder promised. And the builders can't simply send those blocks to the proposer for them to verify that themselves because the proposer could just steal the mev from the block and in that way take away all the earning from the builder themselves. So the relay kind of sits in the middle. It facilitates this auction insofar as the builders send a bunch of blocks to the relay and the proposer commits to the highest paying of those blocks before they actually see the block contents. So that's an important feature here.
00:09:42.070 - 00:10:18.210, Speaker D: And that kind of comes up as I think it'll probably come up as we think more broadly about EPBs designs, which is that proposers need to commit without seeing the contents of their block in order to protect the builders from the mev being stolen. So the current status quo, I guess, post merge, there was maybe like three or four relays running immediately and now I think we're up to like eight that facilitate most of the mev boost blocks. A bunch of builders are sending blocks to those relays and about 95% of validators are hooked up to one of those relays and using their connection to that relay to source their block production.
00:10:19.030 - 00:10:22.946, Speaker E: Yeah, I guess I'm really a sucker for proof of work and kind of.
00:10:22.968 - 00:10:23.794, Speaker A: The history of it.
00:10:23.832 - 00:11:10.258, Speaker E: So I would add that in some ways there was even a form of proposal builder separation. Before MEB, GEF existed in the division of labor that existed between a mining pool operator and the workers. Because the way that it works is the mining pool operator would construct the block body and then they would hash the block header once and they would send it to the workers to hash it further. And that hash would then have the golden non so or not. Right. So you find a bunch of things here. You find block construction because there was only one party that had to do like all of the peering and the validation and the block construction and so on, and also had to invest into latency infrastructure, right.
00:11:10.258 - 00:11:36.294, Speaker E: Being like having good propagation to other mining pools and to big exchanges and so on. And then you had the workers who did the actual work on the Encrypted block body. Right. So you also had this idea of the Comet Reveal scheme even back then. So it's funny how far back some of these ideas trace that we established PBS as a design philosophy.
00:11:36.342 - 00:11:36.506, Speaker A: Right?
00:11:36.528 - 00:12:11.826, Speaker E: And I think you already touched on it a little bit, John, when you said we want to protect validators from having kind of to do these duties that are so complicated, so difficult, that it leads to an unevenness in kind of how much money they make or how well they execute these services. So tell us a bit more about what are the benefits of PBS as we try to unpack this idea of let's create a healthy, decentralized market structure.
00:12:12.018 - 00:13:24.942, Speaker B: Yeah, so the high level benefit is kind of what Mike was talking about before, as how in large part decentralization of the validator set is a means to an end primarily and that's to get certain properties out of them and out of the protocol such as censorship, resistance, liveness in extreme scenarios, stuff like that. So to get that we want a decentralized validator set and then to get the decentralized validator set, we want to make sure to offload all the complexity to these other builders to the extent that possible. So that is like the simplest one is just to keep them decentralized. And then the other realization, kind of on top of that is, hey, if we have these more specialized, more sophisticated actors that kind of sit next to the protocol that we can rely on to be economically incentivized, to keep building these blocks, we can kind of lean into that and take advantage of it as long as their power is sufficiently constrained. So the simple things like that is like okay, we can have builders do these more complex tasks going forward. The clearest example of that being for scaling. So something like the Dank charting design where instead of having all of these different subcommittees where you're building all the you effectively will now have one gigantic block with all the data in it.
00:13:24.942 - 00:13:55.138, Speaker B: And that is a relatively more complex task to do for one single person to make this larger block, make all the KZG commitments for it, et cetera. But that helps and produces a more efficient scaling design and keeps the load on the proposers very light. It's just a realization that hey, we're going to have these specialized actors anyway because there's clearly an economic incentive for mev capture reasons for them to exist like they will need to. So we can take advantage of that, lean into it and have them do these other tasks that we can kind of push off to them that someone needs to do in a more efficient manner.
00:13:55.234 - 00:14:17.454, Speaker E: And this is a new idea that you're now introducing, right? Because so far we kind of kept it to mev and kind of just the ordering of transactions. I mean we touched on some things like a mining pool needs latency infrastructure and good peering and stuff like that. But now you're really opening almost like an entirely new much wider design space, right?
00:14:17.572 - 00:15:01.322, Speaker B: Yeah, exactly. And even kind of more extreme scenarios I would say. Or kind of pushing the same idea to different layers. It's the same kind of thing where depends on you ask how viable they are. But like based roll ups as the simple example of when Vitalik had first had a post probably a few years ago on roll ups of what are the different ways that you could do sequencing. Like one of the ideas was something that he called like total anarchy at the time and you basically instead of having a sequencer for the roll up, it would just be know what's the first one that lands on chain basically that's the block for the roll up. And the reason that didn't work is because that would just be an absolute mess.
00:15:01.322 - 00:16:15.246, Speaker B: Like you'd have spam on Chain, like no one would know who's going to win. It would just be a lot of wasted effort, incredibly inefficient, like you wouldn't know anything. The reason that that kind of becomes a more viable design. And this is something that Justin's Post kind of touched on earlier this year called Base Roll Ups is like, hey, we can lean into the fact that we now have these more sophisticated and economically rational actors who have this proposer interface where the builder for the layer one can effectively be the searchers feeding into that can effectively be the sequencers for the roll up and say, hey, I'm not going to include these ten failed attempts to get a roll up block in here. I'm just going to include the Blob that is going to be the most efficient one for this roll up and I'm going to land that one on chain and I'll pass that to the proposer and make sure only that gets in so you can lean into it, realizing that there are going to be these economically incentivized parties who are kind of sitting next to the protocol and have them do this kind of additional work, acknowledging that, hey, they're going to be sitting there anyway, we might as well lean into them and use them for these different things. So that's another simple example. Other things are stuff like for statelessness, having them create proofs to make that a viable design because otherwise you'll need to give the witnesses to the validators for them to be able to be stateless like leaning into them for all these kinds of different tasks.
00:16:15.246 - 00:16:21.400, Speaker B: You realize there's a lot of stuff that we could lean into the builders and have them kind of outsource those kind of complexities to them.
00:16:22.170 - 00:16:48.142, Speaker F: Yeah, complexity can then also increase on the proposal side of PBS, for instance, in PEPC, the protocol enforced proposal commitments which are also a form of PBS where there is more arbitrary commitments a proposer can enter into. So this whole design space provides a lot of more opportunities to build interesting things.
00:16:48.276 - 00:17:40.526, Speaker B: So it doesn't necessarily, I would say, have to increase the complexity on the proposer a lot because even if they are entering into these arbitrary commitments, they don't have to be the ones who fulfill them. And this is something that kind of barnaby touched on a bit in his last FAQ of where he's talking about PEPC boosts and stuff like mean outsourcing a full block is just one thing you can outsource. They can outsource any of these commitments where a proposer can just be opted into like, hey, here are the commitments that I'm opted into specifically. And the builder, as long as they're aware of those, they can build a block that's in recognition of those, and they will send them a block that fulfills those conditions. Because if they don't fulfill those conditions, they know that they're not going to get their block on Chain. It's the same kind of incentive as builders for the full block auction. As long as there is an interface and awareness of the builders know that the commitments that they're opted into, they can kind of build them for them.
00:17:40.526 - 00:17:45.970, Speaker B: So if designed well, I would say it doesn't have to increase complexity for the proposers necessarily.
00:17:46.790 - 00:17:59.910, Speaker E: Builders can also, I would add out of protocol actors can in general do things that in protocol actors can't. So in mev in particular, I think there's two very clear things. They can keep transactions private.
00:18:00.330 - 00:18:01.746, Speaker A: Like a builder can run a sealed.
00:18:01.778 - 00:18:29.274, Speaker E: Bid auction instead of an open bid auction. They can do simulation on the transaction so they can have instead of an all pay auction. And these are some things that well, a validator could do, but it's really difficult and it's not possible really to establish this trust. Right? And so ultimately out of protocol kind of the design space is much bigger and it then leads to a better market structure.
00:18:29.402 - 00:19:12.300, Speaker D: Two other features that just kind of jumped to mind when you were describing that Hazu is cancellations. So like builders can offer bundle cancellations. This is especially important for the centralized exchange arbitragers who need if the centralized exchange price moves against them, they need to be able to cancel a bundle and also instant confirmations. It kind of depends exactly what type of confirmation the searcher is looking for, but they could give some guarantee on the post state route after a bundle conditioned on their block winning the bid. So yeah, there's a lot that builder can do out of the protocol, as you mentioned.
00:19:12.770 - 00:20:16.402, Speaker E: In general, I think we say PBS allows validators to stay simple and affordable. And connecting that back to what you said John, why do we want that? It's because we want to maximize the censorship resistance of the network, right? Because a lot of that in particular in ethereum. So when you talk about layer twos, for example, they all have assumptions built into their own security model that basically says the layer one chain can't be censored for x period of time or something, right? So this is actually kind of the property that we're trying to protect. I've seen another argument discussed and this is really kind of a double edged sword, but it's nonetheless interesting to point out, which is the regulatory argument. So the argument goes roughly like this. So the less discretion validators have over the kind of blocks that they build, the less they have to be regulated as any kind of financial intermediary. And you would really kind of draw the line on the far end.
00:20:16.402 - 00:21:18.886, Speaker E: Like on one side of kind of the extreme spectrum, you would have a validator as money transmitter that basically has to KYC every single person that transacts through them. Right. So it would be like an extremely kind of censored and regulated ethereum. And on the other end you have the validator as an ISP or like a fiber cable, right. What it transports is just data packages and inspecting all of them would be completely infeasible and so it really has no discretion over what passes through its pipes. And so I think a big idea behind keeping proposing simple and affordable is really to also, I think, boost this argument right. That really proposing is it should be kind of have the least amount discretion as possible, but when you get there, you introduce new problems right, that we talk about because we are talking about really also difficult jobs that the builders do.
00:21:18.886 - 00:21:41.820, Speaker E: There tends to be power law outcomes in this market and so all of a sudden it takes a lot fewer things to go wrong to kind of censor that market in turn. Right. And so, yeah, ultimately you're not really solving the problem easily, you're just shifting it in some way.
00:21:42.830 - 00:22:38.394, Speaker D: Yeah. And it's probably worth just calling back to immediately post merge. The issues around OFAC compliance and censorship were largely there because the relays had to commit to censoring those transactions in some way. So even though you allow the burden of the validators to be shifted to the relay, that still opens up like new regulatory surface that might be smaller than the regulatory surface of the entire validator set. So, yeah, definitely a trade. Also, you know, in terms of censorship resistance, I think inclusion lists and their relationship here is also very interesting. And this is something John and I have discussed a lot, which is if you bring back the censorship resistance properties and place them back on the shoulders of the validators, now the validator has to opt into kind of getting these OFAC or these sensor transactions on chain.
00:22:38.394 - 00:22:46.660, Speaker D: So it's kind of like, okay, the responsibility is still somewhere. It's just like who shoulders it at the end of the day.
00:22:47.910 - 00:23:56.866, Speaker B: Yeah. And that's one of the interesting things with these designs where it is hard to say when you're designing inclusion lists or something like that, are you designing for a specific regulatory environment in mind where there actually aren't clear regulations? It's pretty hard to actually do that. But yeah, some of the designs like that, if there is a regulatory burden, it's also probably where I say not legal advice type thing, I don't actually know. But some of the designs like that would seem to put more agency kind of on a particular actor where we're saying one person is enforcing censorship resistance. Like they're explicitly saying you must include this transaction in a block that maybe looks a little more gray as compared to something like and this is one of the reasons that I think that designs like Suave and other types of encrypted bend pools are like they're very often talked about as an mev solution. I think that they're very interesting from the censorship side of things and that is a very underrated property of them, is that they seem to be in the best direction of ensuring these properties for people while also giving everyone plausible deniability. I don't know what's in there of completely removing that agency from anyone throughout.
00:23:56.866 - 00:24:38.566, Speaker B: It's just that I see a bunch of white noise and I run my algorithm over it. Here's what I get at the end of the day and that is what starts to really look like at the end of the day is like I'm an ISP I'm sending data packets around. I don't know what the hell any of them are and you really are a dumb pipe at every point in the supply chain. So that is a very interesting dynamic of them that I think does get underrated at times is that they are very much a censorship tool and making everyone a dumb infrastructure provider as opposed to just being this MVP solution which they are very helpful for short term privacy, for things like making auctions incentive compatible, et cetera. But the censorship side of things is very interesting to me for that reason as well.
00:24:38.748 - 00:25:43.526, Speaker E: Yeah, very well put. I rounded off with one more point and then we can move on. But I think what I in particularly like about PBS is that it's basically acknowledging that a division of labor between different parties will happen no matter what. And I think this becomes very clear when you contrast it to kind of other ordering algorithms for example, or other forms, how blocks can be constructed like time based ordering. Right? Because with PBS you really basically acknowledge that there is a market for ordering these transactions with the goal of maximizing validator revenue. And so that is the most valuable thing for them to do. And if you don't allow validators to kind of compete on that to maximize kind of the revenue that way, then what you will get is you will get other forms basically of extraction that are kind of ultimately much more destructive for the chain.
00:25:43.526 - 00:26:18.150, Speaker E: And so you basically say, well, if there's mev to be extracted, I want it to be an explicit auction. I don't want it to be an implicit auction that's harder to monitor, that leads to spam, that leads to entrenchment of latency advantage players and all of these things centralization. So it's really about saying acknowledging that the market will find a way and designing around that. And I think this is a line of thinking that I think you find in all of Barnabay's articles have any risks.
00:26:18.570 - 00:27:45.134, Speaker D: I was just going to call back to this idea that we mentioned before, which is the regulatory surface kind of changes in terms of centralization and I guess not even from a regulatory perspective, but just the fact that in the current status quo, there's essentially, like, eight to ten relays that are responsible for 95% of Ethereum blocks and eight to ten builders that are responsible for producing those blocks. That has some definite risks in terms of the builders especially are the ones in a position to capitalize most from the PBS market. They can continue to make the most money. The relays are in this weird position where they're kind of a public good, but still the fact that there's so few of them controlling such a huge part of the market is kind of anti the ethos, I guess, generally. And one way this actually manifests, not from an economic perspective, but more from just a fragility perspective, has showed up in a few different issues around relay operators and their relationship with consensus clients. So immediately after the CHAPELLA fork, there was a bug in the relationship with how Prism interacted with mevboost and that resulted in huge network instability. Immediately post the hard fork, it took a few epochs for the chain to finalize.
00:27:45.134 - 00:28:13.862, Speaker D: There was a lot of missed slots, it was full blown like firefighting mode. And that comes from the fact that there's these ten relays and all of the software that is running on the validator machines is kind of decoupled from this mevboost external software. So there is like consensus stability implications around the centralization found in particular in out of protocol PBS systems.
00:28:14.006 - 00:29:02.570, Speaker F: I would add to that there is the overall technical complexity of entry and PBS. The merge is now basically just a year ago and the whole year we've been thinking about moving PBS more in protocol, how to get rid and move beyond the relays as trusted actors. And it's super hard challenges where you may need a lot of additional responsibilities, you may need to increase the consensus protocol complexity, which is already pretty hard to reason about, and it could introduce new nuanced reorg risks or vulnerabilities. And this is just a thing that is very hard, a very hard problem to get right. So I would say there is a lot of overall technical risk on the path to improrotocol PBS.
00:29:04.110 - 00:29:52.970, Speaker E: Yeah, I have a bit more kind of arcane point, but clearly we are seeing that proposal builder separation can exist outside the protocol and that's where it does so far most of the time. And not all of this stuff is actually maintained by Ethereum core developers, I guess. As someone who's working for the Ethereum Foundation, Mike, what do you think this does to kind of the power dynamics in the Ethereum ecosystem? Is it on the one hand, more that we have to change the definition of what it means to be a core developer? Or is it that Ethereum should eventually try to pull everything into the protocol? What do you think it does to the invisible kind of power in the ecosystem?
00:29:53.390 - 00:30:59.050, Speaker D: Yeah, I would say Barnaby has a really nice post on this. We keep calling him out, but he has a post called Seeing like. A protocol and he defines kind of what it could look like to enshrine different things and when to draw the line and say, okay, this is out of protocol versus in protocol. And I think part of EPBs and the work that I've been focusing on is kind of figuring out not only what to enshrine, like what design works for EPBs, whatever, technically speaking, but also on a more meta level, should we actually do the enshrinement? And one of our recent pieces that we wrote with us, four actually, and a few others was kind of talking about the role of PBS and Enshrined PBS in the world in which a relay market exists outside of the protocol still. So we'll probably touch on that later. But I guess in the current meta where mevboost essentially is core protocol software, I think there's a bit of an ownership mismatch. Flashbots.org
00:30:59.050 - 00:31:53.410, Speaker D: wrote this code and it's been working really well for the year that's been running post merge. But I think everyone would agree that the testing and tooling and specification around that code is not at the same level of the core consensus clients. And part of that is because it's sort of a public good, but it's also originally written by Flashbot. So I'm not sure exactly how the ownership should evolve and the politics there. I will say I guess one of my big reasons why I like Enshrine PBS is because it makes that distinction a lot more clear. Like it draws the line in the sand is like this is the in protocol mechanism that we're going to maintain in terms of the consensus spec and the client teams. If you want to go outside of that, you have to rely on out of protocol software that might inherently be more brittle, more risky, et cetera.
00:31:53.410 - 00:31:56.580, Speaker D: Hopefully that answered your question.
00:31:57.270 - 00:32:13.350, Speaker E: Do you think it's more risky for ethereum? That important part of the ethereum stack are maintained by kind of non ethereum foundation teams that may even have a commercial interest? Or do you think it's more risky that it isn't?
00:32:14.250 - 00:33:31.040, Speaker D: Yeah, I think it feels more risky in the current state, and I'll say especially right now, it feels like the equilibrium we're in is not stable. The relays are kind of fighting for their lives in terms of some of them are third party kind of credibly neutral relays that are trying to get funding from grants and other things. Other relays are parts of companies and commercial entities that are trying to either monetize or trying to figure out if this is part of the core business model. And I think even some of the large relay operators now, it's not clear that if we don't find a viable funding mechanism, we'll be around by the end of the year, for example. So I think insofar as we get to a world where there's only like two or three relays, that is much riskier to the protocol than the current status quo, which seems to be the direction we're headed in. So I would say yeah, either enshrining something and clearly delineating between in protocol and out of protocol PBS, or finding a way to ensure that the mevboost ecosystem is more stable into the future and more sustainable, is going to be critical in the coming weeks and months.
00:33:31.970 - 00:34:19.214, Speaker E: If we see in the protocol that there are some incentives for different actors to specialize or even the same actor to specialize in some way that they can make more money or that they can do additional things for the protocol. I feel like we have established PBS almost as kind of the canonical solution to this problem, but this is not the case at all, right? So I kind of want to place it kind of in contrast to some other things that you could also do. So what would you see as the main kind of schools of thought that are in some way competing with PBS on solving that problem?
00:34:19.412 - 00:35:50.794, Speaker B: So in Ethereum, I don't know that there really is a meaningful alternative to PBS like in the specific Ethereum context because the way that the kind of broad directional alternative to PBS is just completely constraining what the proposer is allowed to do effectively. And you specify very concrete rules of like this is what you must follow. So like some of the fair ordering type, quote unquote fair ordering proposals where you're trying to say all the consensus participants enforce upon each other, this is the ordering that you must follow within this block. So to the extent that that happens, there really isn't room to be outsourcing block production at that point because it's supposed to be at least deterministic of like this is exactly the block that you should be outputting out from this. The reality is you're not going to be able to enshrine something that prescriptive in Ethereum generally. And so if you assume that there are going to be decentralized participants within the validator set and they're going to have some amount of agency to propose a different block, the natural result of that is there are going to be different people in the world who have a better block at different times, and there's going to be an economic incentive for them to kind of outsource that production at different times. So I don't really think that there's an alternative to PBS to any meaningful extent, like within Ethereum, given a lot of the design constraints that it gives itself for what it's optimizing for.
00:35:50.832 - 00:35:51.846, Speaker E: And outside of ethereum.
00:35:51.878 - 00:36:58.194, Speaker B: Outside of Ethereum, I think that you can argue that there are credible alternatives and the credible alternatives are very opinionated and very app specific. And so those you can say that you don't need to outsource to this arbitrary market because we know for our application very specifically, this is the transaction ordering that is going to be welfare maximizing for what we want to achieve. And so we can ingrain very specifically this is the transaction ordering that must result potentially difficult to achieve that. But you can incredibly have a mechanism that works pretty well where I don't think it's just even reasonably viable at all to do something like that on ethereum, which is incredibly opinionated, which is incredibly constrained. I think you can make a credible argument for that in certain app specific use cases. But the thing is, even in the app specific use cases, I think that the reality is it is still a spectrum on how much are you constraining what you're doing. And so one of the things that I feel like is sometimes seen as an alternative to PBS is what's called protocol owned building.
00:36:58.194 - 00:37:46.462, Speaker B: So this is something that is more popular in the Cosmos context with the Skip guys we're working on where we have these app specific chains and so they have this notion of protocol owned building which is you have certain consensus rules that enforce certain validity conditions upon the blocks. So we have it as part of our consensus in a chain like Osmosis that after these trades we check if there's an arbitrage. If there is an arbitrage, it is baked into consensus that cyclical arbitrage is automatically closed and the funds are distributed how we agreed upon in consensus. There's no way around that. But the thing is, while that is constraining what you are allowed to build as a block, there are still degrees of freedom within that. So there is still flexibility within that. So you can constrain the search space with something like protocol I'm building.
00:37:46.462 - 00:38:53.058, Speaker B: But depending on how much you constrain the search space, if there are still degrees of freedom, which there very well may very well be, you can still outsource block production, so you can have protocol and building where you have certain validity conditions that are enforced, but the validator can still outsource to some other builder to build according to those rules. And that's kind of what I was getting back to before when I was mentioning PEPC briefly with Chris is that you don't necessarily have to. Just because you have more constraints on the proposer, that doesn't necessarily mean that there is no more freedom left or that they have to do it themselves. PEPC is a similar idea of pepsi is a way for proposers to constrain the allowable space of what kind of block it can propose in much the same way that protocol on building does. The difference is more that protocol on building takes the very kind of Cosmos approach know tap specific and we can reasonably know for our given application this is the right way to constrain the search space of allowable blocks. That is relatively welfare optimizing. So like every validator has to go by that commitment.
00:38:53.058 - 00:39:50.650, Speaker B: Whereas PEPC is kind of the ethereum variation of that, where we can't say that because ethereum is very general purpose, it is optimizing for very different guarantees. And so you have to allow proposers to be able to locally make those constraints and those commitments which are very analogous to what protocol and building wants to do, but in a very generic context of constraining. What is the block that I'm going to output? Kind of at the end of the day, a lot of things are viewed as alternatives to PBS. And I think that is kind of one of the things that I try to hammer up more is PBS isn't just supposed to refer to this is the concrete implementation that we see on Ethereum today. It is just like the acknowledgment of there is probably going to be a separation between different actors and there is a spectrum of what that separation is and how much we constrain what those different actors can do. And I think that we're starting to see that increasingly across different ecosystems. PBS really is a spectrum of what kind of constraints are you putting on different people and what is the interaction between them.
00:39:50.800 - 00:40:55.530, Speaker D: Yeah, another thing that came to mind here is that especially in the Ethereum context, the ordering of a set of transactions could be worth different to different actors. Right. Like a certain block might be worth a lot to a builder only because they can close the second leg of the ARB on a centralized exchange, whereas that block itself might be worth a lot less to a validator that produced it locally because they don't have the liquidity on the centralized exchange. So there seems to be like yeah, with such a general purpose design, it doesn't seem that viable to just say, okay, this has to be the most valuable block according to everyone's view. So this block becomes canonical, like by that definition. And additionally, just the idea of coming to consensus over the set of transactions that can construct that can be eligible to be in a block is a very difficult thing, too, because everyone's in the P to P network, they have a different view of the world. And, yeah, I think that's one of the design challenges that Ethereum faces.
00:40:55.530 - 00:40:56.014, Speaker D: Yeah.
00:40:56.052 - 00:41:53.700, Speaker E: And I mean, the more you try to constrain, the more you push the auction to happen outside of the protocol. Right, because when you on the one hand say, I'm going to constrain the validator in some way, like on what block they can build, then all of a sudden now two things can happen. One is the validator becomes really focused on the things that they still can control. For example, where do I run my machine and who is allowed to run it in their machine next to my machine. Right. Or second, you really push it kind of to I mean, this is like the most likely thing. But the second thing is really you kind of push extraction away from the validator, even super unlikely, but to the searcher market, that then happens in a way, that's kind of highly latency optimized that has very strong kind of winner tech all dynamics in mev and then ultimately in a lot of other things as well.
00:41:53.700 - 00:43:25.898, Speaker E: I want to also point the spotlight at one more thing that I think is picking up a little more. When I read Twitter, it seems like the same people always, but a few people are talking about it, which is the idea that why do we have to make validators like small at all? I mean, ultimately isn't the goal of Ethereum to be useful to people? So shouldn't we start from the idea of what properties should a blockchain have to be the optimal, let's say, base layer for decentralized finance? And so what is the biggest problem in decentralized finance? Well, it's probably all of liquidity because it's very difficult to be a competitive market maker on Ethereum because you're bleeding so much money to arbitrage, right? And so I think this has kind of been people are kind of honing in on that as the problem. And so they're asking, well, how can we reduce mev for IPS but also for traders? And I think one thing you see is, well, what if we just lowered the block time a lot? For example, fewer blocks means there's less potential to reorder transactions, there's less mev, market makers can update their bits faster, all of these things, right? What's kind of your view on this idea of, well, let's sacrifice some decentralization invalidators to make Ethereum more useful?
00:43:26.074 - 00:44:34.094, Speaker B: As far as the people on Twitter who are saying that, I mean, I'm often one of the people on Twitter who are saying that to some extent and that's a little bit of what I've poked at lately. I just think it's important to kind of delineate between what is Ethereum's place on that spectrum versus what are the other chains place on that spectrum? Because, yeah, there are plenty of more opinionated optimizations that Ethereum could make to make it better for traders, better for users, better in these different very concrete ways. But you are inherently favoring a certain class of users by doing that over other certain guarantees and that is inherently going to be a trade off with a lot of those changes and just broad brushstrokes. Generally. The way that I view it is that is not Ethereum's primary user is some low latency trader. Quite frankly, very often other chains, things like rollups will optimize more for what is directly the user, the trader, what is their UX, what is their latency like all of those things that matter a lot. I view that less as Ethereum's primary customer, where roll ups are building for those users.
00:44:34.094 - 00:44:59.814, Speaker B: In large part, Ethereum is building for roll ups and other types of longer term, slower use cases that need really strong guarantees at the end of the day. Which is why I think it's a very practical decision for a lot of the reasons for Ethereum to have a permissionless validator set. And this is some of the stuff that I've touched on. There are trade offs to a permissionless validator set, particularly in the short term of that means that your validators are not going to be able to enforce.
00:44:59.862 - 00:45:01.206, Speaker C: Any kind of mev protection.
00:45:01.238 - 00:45:13.594, Speaker B: It's harder for them to enforce censorship, resistance potentially you need to add other mechanisms like inclusion lists. But things like mev, you basically end up pushing it to these out of protocol builders. So now, because a validator on Ethereum.
00:45:13.642 - 00:45:15.198, Speaker C: Probably will, if I send it out.
00:45:15.204 - 00:45:56.510, Speaker B: To the public mempool, I will get front run, I will get sandwiched. What do we do? We push that private mempool, we push it to a builder as opposed to a chain that has a more opinionated validator sets and can have a handful of validators that we trust and we say, hey, don't front run the users because if you front run them, we're going to kick you out of here. And that actually makes sense as a trade off for other chains. I just don't think that makes sense as a trade off for Ethereum because it is trying to provide a fundamentally different set of guarantees. If you are looking as a user to use a low latency chain where you can send your things to the public mempool and you're not going to get front run and you want to pay low fees, you shouldn't use Ethereum. And I'm just like fine to say that you should go use a roll up. That's kind of the whole point.
00:45:56.510 - 00:46:30.060, Speaker B: Ethereum is just like optimizing for a very different set of trade offs so that roll ups can optimize for the exact opposite other end of trade offs where they can be more guarded and opinionated in their designs. Where Ethereum is very trying to be very unappinionated and very robust and very broad in its design goals and kind of pushing those intricacies over to different layers of the stack. So generally my response was like those trade offs do make sense, they just don't necessarily make sense for Ethereum. And different protocols should have different spots on that trade off spectrum depending on who is their user. What are the guarantees that they're trying to provide.
00:46:31.070 - 00:47:01.300, Speaker E: Changing gears here a little bit. PBS is a design philosophy, but it also has an implementation on Ethereum today that's called mev boost. And you are one of the main people working on this mev boost ecosystem for a long time, Chris. So can you describe for us kind of what is the current state of the mev boost ecosystem and then we will transition that a little bit into how it's going to evolve in the future.
00:47:02.870 - 00:48:16.490, Speaker F: The current state of the mev boost ecosystem? Yeah, this whole topic here, from the software itself to the relay ecosystem to the builder ecosystem to the protocol, I think the MAV Boost protocol is the one thing that stayed relatively unchanged so far, with the only change right now being the void for four upgrade where we introduced the Blobs. And they also need to go all the way through the builder network, through the relays to the proposers. And there's a lot of heavy lifting to do here that is all in progress. On the relay side, I think we've reached a somewhat unstable equilibrium with the ten relays that are providing services. Of course, there's the downside of proposers that the more relays they add, they inherit the security guarantees of the weakest link. So even though they might be maybe looking good on paper to spin up as many relates as possible in practice, for proposers, it often would mean war. Security guarantees relists are too powerful, trusted actors run by private businesses, this is not great for the whole trust.
00:48:16.490 - 00:49:04.630, Speaker F: And a rogue relay can cause a lot of harm to proposers to builders, to the blockchain stability itself. This is something that we are very strongly looking to mitigate on. The path to enshrinement the builder ecosystem is constantly changing with about like four to five builders producing the majority of the blocks. I think the top two builders, they have been relatively stable recently. Grealishcan IO is a good website to track it. There is Rsync Builder and Beaver build and now it is also Titan that are dominating the market with I would say like almost 70% of the blocks. Then there is flashboards and Bill 69 with 10% about each, and then a steep drop off to 2% for other builders.
00:49:04.630 - 00:49:41.842, Speaker F: So I would say it's like somewhat almost centralized set of players here. It's probably not too easy to ramp up. There's a lot of things these high market share builders do to gain it. But yeah, we will see how that shapes up software wise. Overall, I think Meth boost is relatively stable now. Really, operation is the more demanding task for operators mostly right now. It provides a lot of duress protection, validity checks, payment checks.
00:49:41.842 - 00:50:41.046, Speaker F: It has a lot of things to do that requires a lot of compute. It's not quite easy to run it, but possible. Then there is the performance and latency optimizations that the ultrasound team and Mike in particular has implemented over the past couple of months. That also really boosted the inclusion rate of this. So, optimistic relaying in particular, which means that the guarantees are changed in a certain way that the builder blocks, they are not validated anymore before they reach a proposal and the proposer might sign blindly to it. And the optimistic relay is basically guarantee a reimbursement in case of a fault. So, this is an interesting development that's currently run by the ultrasound relay and I think some other relay, I'm not sure if Blockthrough is also running optimistic mode on some builders that also has a lot of additional operational overhead.
00:50:41.046 - 00:50:51.594, Speaker F: Flashbots is not doing optimistically relaying. Yeah, and I think overall our focus is moving beyond relays, the sooner the better.
00:50:51.792 - 00:52:09.634, Speaker D: Yeah, I was just going to say part of the optimistic kind of roadmap and the idea of making some evolution in the relays is to try and make them actually cheaper to run. So what optimistic relaying does is it tries to simplify the task of being a relay operator because the blocks don't have to be simulated kind of in the same few hundred milliseconds right before the end of the slot. So by spreading out the simulation over the subsequent slot the actual overhead of running a relay could go down quite significantly. And this is part of kind of this path to hopefully more sustainable and more economic relays. And as Chris mentioned, the trade off here is additional overhead from the relay operation perspective because builders have to be collateralized with the relay and if there's ever any failure then that's kind of on the relay to reimburse the proposer for that issue. But yeah, the kind of long tail goal here is to get to a point where we can explore and kind of forerun some of the features that would be present in an enshrined PBS mechanism through the existing relay market that we have today. So that's kind of the high level goal of optimistic relaying generally.
00:52:09.762 - 00:52:23.114, Speaker E: Yeah, let's stick with that for a bit here. So EPBs, Enshrined PBS, what is it, what is really the central problem that it's trying to solve or that needs.
00:52:23.152 - 00:52:24.998, Speaker A: To be solved to have Epps?
00:52:25.174 - 00:52:40.670, Speaker D: Yeah, I think the high level problem is just trying to eliminate the need for the relay market. Ideally we want some way to facilitate the auction between the proposer and the builder without needing a trusted third party.
00:52:41.330 - 00:52:44.100, Speaker E: And why is it difficult to do that?
00:52:45.270 - 00:53:36.110, Speaker D: Yeah, it's difficult because the relays provide some services that the protocol actually we can try to provide them in the protocol but they're slightly different in the way they actually manifest themselves. So in our recent EPBs relays post EPBs post I think we described PBS as kind of a two part mechanism. It has a commit reveal scheme which is to enforce that the proposer commits to a bid before seeing the actual block and then it has an unconditional payment mechanism. The relays enforce the unconditional payment mechanism through basically checking the contents of the block because the relays have the block in the clear they can see. Okay, the balance before and after the block is executed increases for the proposer.
00:53:36.950 - 00:53:42.500, Speaker E: What do all of these things tell us about what's the minimum viable EPBs going to look like?
00:53:43.350 - 00:54:35.010, Speaker D: Yeah, so the minimum viable EPBs would be a commit reveal scheme to allow the proposers to commit to a builder block and then an unconditional payment mechanism. So the unconditional payment mechanism is important because we no longer have the relay to verify that the payment goes from the builder to the proposer. So the kind of easiest version of this is what we've proposed called top of block payments. And the requirement here is that the builder submits along with their bid a valid transaction that pays the proposer the amount that is associated with the bid. So this along with just enforcing that the proposer kind of at the protocol level can sign onto a block header without seeing the block contents is the minimal EPBs instantiation that we're considering.
00:54:35.450 - 00:54:43.014, Speaker E: So I assume that would require then changes to how blocks work basically in Ethereum like the format of them.
00:54:43.212 - 00:55:43.500, Speaker D: Yeah. So the important enforcement mechanism here is that if a proposer commits to a block and the builder has a chance basically to reveal their payload and that payload can make it on chain. So the kind of trade off in the design space here is how do we ensure that once the proposer reveals their payload, that payload becomes part of the canonical chain. There's a couple of different ways to do this. You can give the builder block fork choice weight explicitly, which is kind of the original line of thought that Vitalik's two slot PBS and the rest of the designs went with. The most recent design we have is called the Payload Timeliness Committee where there's a committee that specifically attests to the availability of the payload from the builder without actually giving explicit fork choice weight to the builder block. So yeah, it does change the consensus rules but the idea would be that most of the structure of the block remains the same.
00:55:43.500 - 00:55:48.730, Speaker D: You have to enforce that if the builder reveals their payload it becomes canonical.
00:55:49.310 - 00:55:53.498, Speaker F: And if it doesn't reveal the payload that the payment is still executed.
00:55:53.594 - 00:55:54.560, Speaker D: Right, exactly.
00:55:55.090 - 00:56:38.826, Speaker E: Okay, so EPBs is one way that PBS is going to evolve, as we have heard. Another angle is all of the rollups are looking to decentralize their sequencer in some way. So we'll talk about what that means exactly, because different people can have wildly different opinions but one of the things that they are kind of looking at is PBS. But really it's part of a much broader design spectrum than you have on the layer one. So John, can you kind of walk us through to what degree do we need at all some form of PBS on layer two and how are these different teams thinking about it?
00:56:39.008 - 00:57:28.038, Speaker B: Yeah, so I would say broadly they have a lot more flexibility in their designs is the very TLDR of it, where Ethereum kind of as I was mentioned before, has this very strict set of constraints where it's like we want to be very generalized, unappinionated, super, permissionless, all of those conditions. It makes it much harder to optimize for. And the reality is roll ups are going to have a lot more degrees of flexibility there. So they don't need to have necessarily a gigantic permissionless set of sequencers. They can have potentially one or a handful or some permission set of them. And that just like it makes it much easier to design the process. Like that interface between the proposers who is kind of like the sequencer more or less here, and some kind of out of protocol builder.
00:57:28.038 - 00:57:49.618, Speaker B: So it makes it much easier if you kind of know who all the parties are and they're able to have some sort of trust interaction between them for proper execution and fulfilling their commitments. So that makes it a lot easier. And the other part of it is also they can be way more opinionated than Ethereum is going to be. So roll ups can play around with things like threshold encryption with some variations of first come, first serve, with a.
00:57:49.624 - 00:57:51.726, Speaker C: Batch auction like Shin's proposal.
00:57:51.918 - 00:57:56.018, Speaker B: There are going to be a lot of these different variations that are going to be more opinionated and people are.
00:57:56.024 - 00:57:56.754, Speaker C: Going to try different things.
00:57:56.792 - 00:58:13.046, Speaker B: It's going to be like basically the better analogy for them in large part is Cosmos compared to Ethereum roll ups are the Cosmos app chains of the Ethereum vision. Realistically they are not Ethereum itself. That is the whole point of kind of what I was going back to before of ethereum makes a certain set.
00:58:13.068 - 00:58:14.678, Speaker C: Of tradeoffs that are very difficult to.
00:58:14.684 - 00:58:28.974, Speaker B: Deal with, so that roll ups in large part do not have. To deal with those and they can optimize for another kind of end of the trade off us. In large part, though some form of PBS is likely going to rise be necessary in them.
00:58:29.092 - 00:58:29.486, Speaker A: What that?
00:58:29.508 - 00:58:31.854, Speaker B: Looks like Will. Look very different, but for those same.
00:58:31.892 - 00:58:33.886, Speaker C: Reasons before, even when you constrain the.
00:58:33.908 - 00:58:48.374, Speaker B: Search base of, you do certain things like protocol I'm building or you constrain certain ordering rules. There still are going to potentially be degrees of freedom that you want to outsource to a competitive market such that you are getting the best block that the Sequencers are going to put in there. At the end of the day that.
00:58:48.412 - 00:58:58.566, Speaker E: Makes sense and another topic that we have touched already on in this call is PEPC. So what is PEPC and how does.
00:58:58.588 - 00:59:00.390, Speaker A: It relate to PVs?
00:59:00.830 - 01:00:03.854, Speaker D: Cool yeah so PEPC is a proposal from Barnabay. It stands for Protocol enforced Proposer commitments and the idea here is that it kind of generalizes PBS insofar as expanding the set of commitments that a proposer can make that are enforced at the block validity level. So the idea is in this new design proposers can sign up for different block validity conditions that are applied to their block. And this is kind of often compared to the type of commitments that could be made through Eigen layer. But I think the important distinction is that Eigen layer commitments are only enforceable kind of at the execution layer meaning they're only enforceable by slashing the stake of the validator kind of after the fact if they don't fulfill the commitments that they made. PEPC is kind of a stronger commitment or in. My mind kind of closer to the medal of Ethereum in that the commitments are actually part of the fork choice rule and part of the state transition function.
01:00:03.854 - 01:01:31.042, Speaker D: So if a proposer commits to something and their block doesn't satisfy that constraint then it's not even able to be part of the blockchain because of the commitments that they made. So I like to think about the difference between EPBs and PEPC as the difference between homogeneous and heterogeneous commitments that the proposer can make. So in EPBs we're saying we're going to specifically enshrine a single version of the mechanism that the proposer and builders participate in so that could be a full block auction. So the proposers can commit to a specific block hash the builder has to reveal a payload that corresponds to that block hash. It could also be more general like the proposer commits that they sell their block production rights for the entire slot to the builder so instead of specifying the block that the builder has to produce, they say whatever the builder wants they can make as long as it's signed by a specific builder pubkey for example. Yeah in general the space of commitments is just the single commitment that the proposer can make in Enshrined, PBS, PEPC is different in that different proposers can make different commitments from slot to slot. So the slot n proposer could say I only want to sell the first 1 million gas of my block, I'm selling it to this builder.
01:01:31.042 - 01:01:47.882, Speaker D: The bundle that comes there has to be signed by that builder for example. But the next proposer, the slot n plus one proposer could commit to selling their entire block to a different builder and that heterogeneity of the commitments is, I think, the important distinction between EPBs and PEPC.
01:01:48.026 - 01:02:17.186, Speaker E: Could you say that PBS is a kind of very specific commitment protocol in the sense it allows builders to commit to validators and validators to commit to builders in a way that lets them exchange blocks for money without leaking the information. And then PEPC is a kind of highly generalized commitment protocol where both parties can make I mean, especially validators can make more elaborate commitments to the builders.
01:02:17.378 - 01:03:00.098, Speaker D: Yeah, absolutely. I don't see PEPC and EPBs as like mutually exclusive in any way. I see PEPC as kind of the superset of EPBs. And Barnaby actually mentioned this in his recent said, you know, the way to do PEPC might be to start with limiting the set of commitments that a proposer can make. And that commitment set might just be a single commitment, which is, I agree to sell my entire block to this builder, and the roadmap could evolve to kind of open up the space of commitments that the proposers makes. And, yeah, that would be probably the direction we go if we decide PEPC is the right roadmap.
01:03:00.194 - 01:03:04.710, Speaker F: And is there idea still to express these commitments as smart contracts?
01:03:05.130 - 01:03:29.150, Speaker D: I think yeah the implementation details are still very much kind of being ironed out. And yeah, there's people thinking specifically about PEPC Boost like what that could look like in the boost ecosystem. And yeah, I think the research stage of PEPC is still in the very early days in the same way that most of the EPBs implementations are too.
01:03:29.300 - 01:04:17.642, Speaker E: So imagine that PEPC is live. I know that runs counter to what you just said, it's like the early research, but imagine it's live and there's only two possible commitments that can be made. So let's say it's full blocks and I don't know, it's slot auction or it's like auctioning off your block in advance, whatever. Right. Something else. So how do I now learn what commitments should I make? Is it basically like I can imagine there's a form of map boost or some kind of block market but instead of only showing me what's the highest bid, it also shows me what kind of commitments I have to make and then how do I kind of decide between those things? Am I just continuously just picking whatever the highest bid is the same way that it does today with pretty much no discretion?
01:04:17.786 - 01:05:15.886, Speaker D: Yeah. So I guess in PEPC Boost, like if we did this out of protocol, maybe it's easiest to start there. The proposer would broadcast their commitments and the relay would as part of the block validity checks that the relay does, they would make sure that the builder block that's produced satisfies those conditions. In PEPC in protocol, I think the question becomes a little more complicated because in order to enforce it at the fork choice rule you really need that commitment to be encoded in the block data somehow. So basically, the slot n commitments need to be available for the slot n a testing committee because part of their fork choice rule is going to ensure that those commitments are satisfied by a valid block that's produced at. Slot N. So the probable mechanism that fits in here is before their slot, the proposer at slot N needs to publicize the commitments that they're willing to make for their slot.
01:05:15.886 - 01:05:24.878, Speaker D: And in the slot N minus one block those commitments are included and encoded in some way that is enforceable by the next round of attestations.
01:05:25.054 - 01:05:29.846, Speaker E: Amazing. I think that upright. Does anyone have any points that they want to make?
01:05:29.948 - 01:07:09.942, Speaker B: It's kind of a broad thing. I guess you can kind of just like as a high level way to think of these kind of proposal commitments and the constraints you're putting it is kind of the other side of the coin of when everyone talks about the new buzword of intents. It's just like from the opposite end where this whole notion of expressing an intent versus a typical transaction is like the general idea is you're being very prescriptive in a typical transaction based model, where you're saying, here's the execution trace of, like, this is exactly the path of this transaction and this is what will happen versus this notion of intents. Whatever it means is you are generally giving some certain broader set of constraints on like, hey, I don't want to be so prescriptive of, like, this is the exact execution path that you're taking, but, hey, here are the constraints that I'm happy with. As long as anything within this kind of realm is the result of whatever you do, I'm happy with that at the end of the day and then let someone else go figure out the optimal way to do that. And very similarly on this proposer commitments thing, it is kind of the other side of the coin of that where you are saying what is the right balance of what are the constraints that we impose on builders in this scenario from the proposer side of things, as opposed to just having a very prescriptive mechanism, which is like, I will sign a commitment and you will give me a full block, and this is it, as opposed to, like, hey, what if we could say you give me this full block, but I'm going to give you these constraints of, like, it's a block, but it has to meet. It has to have this certain type of transaction ordering in it, and I want this Oracle transaction at the top of the block and then the rest of it, you do whatever is the most welfare maximizing thing, like whatever you get the most value out of.
01:07:09.942 - 01:07:37.022, Speaker B: So it's kind of like both of them have that similar trade off of what is the right way to express these types of constraints in a way that is practical. Because also, when you have absolutely no constraints, it starts to become a potentially intractable problem that is just too difficult to be useful. And when you're too constrained, you're possibly destroying value because you were enshrining something that is very concrete and there's like a broader kind of search space here that you want to kind of work around.
01:07:37.156 - 01:08:08.534, Speaker E: Let me ask you a philosophical question. So if in PEPC, a proposer can first make a commitment, then a builder has to honor it. And in Swath, a validator can request a block that has certain properties. So they are also basically enforcing a commitment, and they cannot see the contents of the block, so they have no discretion over withdrawing whatever commitment they made. Is it the same? Is it different?
01:08:08.652 - 01:08:21.180, Speaker B: It's a similar idea from kind of two different perspectives, I would say. It's like broadly what you're doing there. It's like both of them are imposing some constraint, whether it's the user side of what they're telling Swab of, like, hey, here are the constraints that I want.
01:08:22.030 - 01:08:24.174, Speaker E: Like, I didn't even mean it from the user side.
01:08:24.212 - 01:08:24.366, Speaker A: Right.
01:08:24.388 - 01:08:29.726, Speaker E: It's really the validator that can say, give me the value of a block that has, like, property X, for example.
01:08:29.828 - 01:09:03.706, Speaker B: Yeah, and I'm saying basically swab is the black box that matches kind of both ends of those. Because what you're saying is, yes, the validator can tell Swab like, hey, give me a block that satisfies these conditions. And then on the other side of them, the user is sending things into Swab saying like, hey, here are my transactions, just do something with them that satisfies my kind of constraints. And then Swab is that thing kind of in the middle that takes like, okay, here are the validators constraints, here are the constraints that all the users that they gave me, and now I can match those together. What is the optimal outcome of this? Send it along to the proposer and now they can kick it out.
01:09:03.808 - 01:09:14.800, Speaker E: What do we learn from all of this? Okay, one thing, I guess commitments are very powerful. Anything else? Any takeaways from you guys on this episode before we wrap up?
01:09:16.050 - 01:10:22.690, Speaker B: The biggest high level thing for me is just honestly kind of goes back to the thing that we said in the first place is a lot of the criticism around PBS is just very misguided in that it's really a criticism of a specific mechanism that Ethereum has in place and is looking at. It is not really a criticism of the idea that, hey, there's naturally going to be a division of labor for certain kinds of specialization. And even when you make opinionated protocol owned building type stuff, that doesn't mean that it's impossible to have any kind of division of labor. So it's just realizing that there is always going to be this kind of separation of roles to some extent. And you just need to understand in the context of your own protocol what is the right place on that trade off spectrum of does it just look like a very simple, very dumb, like, hey, I sign a commitment, you give me a full block and that's it? Or is it a very opinionated kind of interaction where there's some kind of outsource, but you're giving a lot of constraints and a lot of enforcement over that? It's a different trade off spectrum and different protocols should have a different spot on that. It's not like PBS is good or PBS is bad. It's just like different kind of versions of it make sense in different places.
01:10:23.190 - 01:10:24.226, Speaker D: Well said.
01:10:24.408 - 01:10:56.702, Speaker F: Overall, I think what is clear is that entraining PBS is hard. It's a challenge. I think we have been making really good progress as a community towards that. And I think it makes sense to start like we did with Mafboost, with a out of protocol way to experiment and then iterating towards enshrining it and yeah, I think I'm very excited to see where it's going next and working on it with all of you guys.
01:10:56.836 - 01:11:01.130, Speaker E: Okay, fantastic. So thank you guys so much for the discussion.
01:11:01.290 - 01:11:02.126, Speaker D: Thanks for having us on.
01:11:02.148 - 01:11:02.778, Speaker F: Thanks guys.
01:11:02.884 - 01:11:03.154, Speaker A: Thanks.
01:11:03.192 - 01:11:04.500, Speaker F: It was nice being here.
01:11:06.470 - 01:11:08.850, Speaker A: Hey, John, what did you think about this episode?
01:11:10.150 - 01:11:13.230, Speaker C: Well, it took us like five tries.
01:11:13.310 - 01:11:18.910, Speaker B: Or something like that over the past month, but it was worth it. It was a lot of fun doing this one.
01:11:19.080 - 01:11:30.406, Speaker C: So I guess for a background for the listeners, we first tried to do this episode, I think like over a month ago. We did it in Vienna where the.
01:11:30.428 - 01:11:32.399, Speaker B: Four of us and then Tomas and.
01:11:32.399 - 01:11:37.766, Speaker C: Tony had spent a week together right after EthCC, which was a ton of fun jamming on all the PBS tamas.
01:11:37.798 - 01:11:40.970, Speaker A: From flashboards and Tony watched that are from the Ether Foundation.
01:11:41.310 - 01:11:42.538, Speaker B: Spent like a week jamming on the.
01:11:42.544 - 01:11:49.034, Speaker C: PBS stuff and then we tried to record it at the end of the week and just absolute awful audio quality on the laptop.
01:11:49.082 - 01:11:52.174, Speaker B: Took a few tries to do it, finally recorded it a couple of weeks.
01:11:52.212 - 01:12:02.578, Speaker C: Ago and now we're finally doing the recap currently in the middle of SPC for me. So finally getting to put it together. But it was a lot of fun doing this one.
01:12:02.744 - 01:12:09.270, Speaker A: Yeah, it's been a long way coming. I'm really glad to put this out. What was for you the highlight of the episode?
01:12:10.730 - 01:12:16.870, Speaker C: The highlight for me, I'd probably say talking about PEPC.
01:12:19.210 - 01:12:22.346, Speaker B: It's at least the most fun thing for me at the moment because I.
01:12:22.368 - 01:12:31.498, Speaker C: Feel like it's the most probably under talked about thing recently compared to what will be talked about upcoming at least a little bit of like it's an.
01:12:31.504 - 01:12:33.366, Speaker B: Idea that feels like it's been kicking.
01:12:33.398 - 01:12:39.374, Speaker C: Around for a while. That Barnaby had brought up last year, and that kind of went away after.
01:12:39.412 - 01:12:40.334, Speaker B: That for a few months.
01:12:40.372 - 01:13:42.174, Speaker C: It was kind of this fun thought experiment thing and then especially in the last few months or so seems to be just kind of coming back much more meaningfully. I also am probably biased, like front of my mind because I just came from listening to Barnaby give a presentation on PEPC like two or 3 hours ago. So it's kind of front of mind for me. But it is very interesting because there's clearly a lot of thought being given on what should really PBS look like to the extent that it's enshrined in the protocol and there's a very wide design space on the types of commitments that it kind of makes sense to potentially have. And potentially even in the shorter term of out of protocol versions of that stuff like PEPC Boost. And in particular, you had just sent me the link right before this of Mevboost Plus and Mevboost plus plus, which is like the idea for mylayer which touches on a lot of the same ideas and the tougher part with those kinds of constructions. So for brief context we'll link it in the show notes.
01:13:42.174 - 01:14:54.346, Speaker C: But for the listeners like Mevboost Plus and Mevboost Plus Plus, they're like ideas from Eigen Layer, which are basically partial blocks auctions where you can allow the proposer to opt into restaking commitments, where they can say, like, hey, I agree that I'm going to sell the top half of this block. I'm going to agree to this, and then I'll get the block body, and then after that, I can add in whatever I want at the bottom of the block. And there's various reasons why partial block auctions might be interesting, but the initial cited reason of why this came up actually a year ago now almost to the date I remember it first came up at SPC last year was like particularly as a censorship tool of similar to the idea of inclusion list. It's a way for proposers to give them back agency of like okay, even if the builder is know, I only have to sell the top of the block, that's what has the value in it anyway. And then I can stick something in the bottom of the block. The tougher part of doing kind of this stuff in much more putting the control in the proposer's hands as opposed to having the protocol enforce proposed equipments is the fact that the proposer can still deviate from this. So these ones that are secure by restaking are very challenged in the fact that the proposer can deviate from this.
01:14:54.346 - 01:15:27.378, Speaker C: So let's say that they agree to do the top of the block but they can make more than they'll be slashed by deviating from that, then they're incentivized to do so. And the simplest example of that is even if you have say a sandwich trade in there that it might be for a small amount of profit. But as we've seen with the low carb crusader unbundling, that can be a very profitable thing to unbundle. So it might be worth it if they ever got sent a bundle through mevboost. Plus to be like, hey, I'm going to unbundle this and then just get slashed my 32 E or whatever.
01:15:27.544 - 01:15:53.980, Speaker A: It's like the max effect of balance change could really help with that. Which is really the idea of combining many validators into one, right? So a single validator wouldn't just have 32 eve staked to it, but it could have hundreds or thousands of eve really. And in that case there would be much more value available for slashing. So it's interesting, right? Max effective balance. They want it for very different reasons but it could also help here.
01:15:54.350 - 01:16:05.358, Speaker B: So it is possible to even do that without max effective balance. That is like a clearer way to do it. But it is possible if someone just opts in to the they could just opt in for their restaking commitment of.
01:16:05.364 - 01:16:06.846, Speaker C: Just like, hey, I tie all of.
01:16:06.868 - 01:16:09.106, Speaker B: These together so when they tie in.
01:16:09.128 - 01:16:14.226, Speaker C: The first place, they just tie in like, okay, if I screw up with this proposer, all of these say ten.
01:16:14.248 - 01:16:15.246, Speaker B: Proposes are all linked.
01:16:15.278 - 01:16:16.466, Speaker C: Like you could slash all of them too.
01:16:16.488 - 01:16:19.538, Speaker A: Yeah, like a shared, shared identity layer on top or something.
01:16:19.624 - 01:16:38.026, Speaker C: The problem with doing that kind of thing is obviously that becomes super centralizing of like okay, well now you need a million dollars to make a commitment and now the small guy can't do that anymore. So that's the kind of trade off. The nice way to solve it is you have it be protocol, enforce these types of commitments. Now it's no longer a hey, I.
01:16:38.048 - 01:16:40.826, Speaker B: Lose my 32 ETH if I deviate from this thing it's if I try.
01:16:40.848 - 01:16:53.806, Speaker C: To deviate from this thing the entire testing committee will just reject the block as invalid. So seeing that design space get played out a little bit more is very interesting to see and it's clearly getting more thought in the last couple of months which has been a lot of fun.
01:16:53.988 - 01:17:03.938, Speaker A: So it's top of mind for a bunch of people but do you think it will be big in terms of impact? Do you think it will be implemented? Do you think it will be heavily used?
01:17:04.104 - 01:17:42.718, Speaker C: I still have mixed thoughts on this. I definitely think some forms of it will happen. I think that there is going to be certainly enough incentives to do something like PEPC boost whether it makes its way to be in protocol. I am very mixed on that. I don't have as high a confidence. It feels very likely that someone will do something like a PEPC Boost out of protocol. There are various commitments that you can enforce them at a different layer where you basically just rely as opposed to the mevboost plus type thing where you're relying on the proposers to do this.
01:17:42.718 - 01:18:33.966, Speaker C: You can just basically hand that off to a relay where you trust the relay to enforce the commitments. So something like that definitely makes sense and I think that there are variations of this which could be interesting which people are probably going to be worth experimenting with. Does it get to the point where it makes it into the protocol? For Ethereum, that's where I have a lot of questions. It's much harder to tell. They are very fundamentally useful things that these commitments can make which is why you will definitely see these types of things happen on a lot of other chains that are very opinionated like we talked about with the protocol and building type stuff. Those are specific implementations of PEPC in a sense where PEPC is the very general sense of that. So it's difficult for me to say on Ethereum that if something like that would ever make its way into the protocol it's also incredibly early stages of what would like.
01:18:33.966 - 01:19:01.274, Speaker C: There is no concrete implementation of what something like PEPC would look like. It's just like the very fun thing at the moment to at least think about of it's a very broad generalization of PBS which is super interesting because it does seem like there's a lot of consideration right now of what, if at all, should EPBs look like and that rethinking it from first principles. And that kind of leads you to, okay, what is the most general idea possible that we could put on top of a potential EPBs? And it's something like PEPC, which is cool.
01:19:01.392 - 01:19:01.674, Speaker E: Yeah.
01:19:01.712 - 01:19:55.820, Speaker A: Whether we do it or not, I think it's good to basically explore the entire design space and think almost as the most extreme option that can be built like the most generalized. And then it may be the case that we land somewhere that's totally different from that. Right, but I think this is something totally tangent, but this is something that I think I learned over the two years that I'm doing strategy work at Flashbots and Lido as well, which is don't stop at, like, there's a human bias. If you generated one good option to just stop and do it, and you really have to force yourself actively to keep asking, and what else? And what else? And what else? And it's so difficult, but it's so important. And I think for protocol design even more. And so I think I can really see that at work here.
01:19:56.510 - 01:20:23.250, Speaker C: And I think they've done a good job of that with EPBs in particular, where it kind of felt like a year, year and a half ago or whatever, it felt like, oh, like this two slot PBS design, this is what we're definitely going to do in the short term. I was like, yeah, this seems like it works and you could implement it. And I like that there's been a lot more just fundamental consideration certainly throughout the course of this year of, okay, just like from first principles, why do we really want this thing?
01:20:23.400 - 01:20:24.418, Speaker B: What in the first place, are the.
01:20:24.424 - 01:20:55.626, Speaker C: Properties that we need out of it? Do we even need to enshrine something to get those properties? And are there better ways, like more general ways to do it? And a lot of that exploration, I think is really valuable and is producing a lot of very interesting stuff that probably gets implemented to some extent. But even if some of it doesn't get implemented on ethereum, it's very valuable research that's going to be incredibly useful for a lot of L two S who are going to be thinking about the same ideas as they go through this and who are going to be even more likely to experiment. Like, sure, we'll go use this thing. This sounds really valuable.
01:20:55.818 - 01:21:41.654, Speaker A: Yeah, I mean, for me, fundamentally, if I now see a proposal that is just an implementation that doesn't start with, okay, here's a description of the problem that we are trying to solve. Here are all of the constraints. Oh, and here's like five different things that would be possible and here are the trade offs and for reasons XYZ, we would suggest to use that one. But it deserves more research. That's the kind of, I think, clarity of thinking that you need in the future to make any changes to ethereum or really to any kind of open protocol. And if I don't see that, I'm almost, like, by default, I'm against. But I think we're increasingly kind of moving towards that, and it's very good to see.
01:21:41.792 - 01:21:42.480, Speaker C: Yeah.
01:21:43.570 - 01:22:01.774, Speaker A: So one thing that I really liked and that kind of came out in the episode, I think, really well, is that PBS is not an implementation kind of building on that previous point. Right. PBS really is a design philosophy that is in itself extremely broad.
01:22:01.822 - 01:22:02.082, Speaker E: Right.
01:22:02.136 - 01:23:30.590, Speaker A: All it really says is there are incentives for division of labor in the protocol, or, like, framing it differently for protocol actors to outsource part of their duties to external actors who might be more specialized. And then those are explicitly not in the protocol. But what the protocol can do is provide as expressive and as trustless as possible interface as it can to make it so that this outsourcing really becomes as easy, like, as fair and as egalitarian as possible. Because if it doesn't, then what you see is some protocol actors might be better at outsourcing than others. And this is kind of what we saw initially with MEB in kind of pre proposal builder separation days, right. Where there wasn't such a trustless interface and, like, a way for validators or mining pools to really discover, okay, so who are the searchers I should be working with? And now the builders and so on. Just, like, zooming out, basically, and looking at this entire thing as a design philosophy that's really strongly rooted in kind of fairness and decentralization of the protocol that was, for me, I would say, the highlight.
01:23:31.010 - 01:23:33.810, Speaker C: Yeah, I like that.
01:23:33.880 - 01:23:34.210, Speaker F: Yeah.
01:23:34.280 - 01:23:44.798, Speaker C: And it's definitely been really interesting to see. I've noticed this more over the past several months, particularly as PEPC has gotten a bit more attention.
01:23:44.974 - 01:23:47.666, Speaker B: Is it's a bit what we talked.
01:23:47.688 - 01:24:23.760, Speaker C: About in the episode of where a lot of these ideas that are almost thought about as opposites of each other, of the ethereum PBS, and then there's, like, the Cosmos Protocol I'm building or the more opinionated things, you start to realize when you start to do, the more soul searching of, like, okay, fundamentally, what are these things? And you look at things like PEPC, and you realize how many parallels actually across those different systems there are, and, hey, they actually work really well together. It's not like this one or this. They very much do fit together in these different ways, and they look very different in different ecosystems when you have different goals. But yeah, watching how the pieces actually fit together now and it's like you just approach it from different ends has been very cool.
01:24:24.130 - 01:24:24.542, Speaker A: Yeah.
01:24:24.596 - 01:24:25.646, Speaker E: I have to give you a shout.
01:24:25.678 - 01:24:42.230, Speaker A: Out, I think, especially for that with your efforts around proof of governance, which is really I think what you're doing very effectively is just removing politics and ideology from what should really be kind of a technical subject matter.
01:24:42.300 - 01:24:42.920, Speaker E: Right.
01:24:44.170 - 01:25:01.654, Speaker A: Just because it's Ethereum, the Ethereum ecosystem and Ethereum on layer one has PBS doesn't mean that the exact same implementation should also work for or should also be the right one for layer twos, which have totally different kind of needs and goals and constraints.
01:25:01.702 - 01:25:02.154, Speaker E: Right.
01:25:02.272 - 01:25:40.858, Speaker A: So it's really about taking the politics out of it and approaching it from first principles and really seeing, well, these are all part of the same kind of design. Family and different implementations work best under different conditions, and they are all fair game. It doesn't matter where they were invented. If something was invented in Cosmos or whether it was invented by the Ethereum Foundation or was invented by Flashpots, we are here to kind of build the best crypto ecosystem that we can. This is something that I see very heavily in your research.
01:25:41.024 - 01:25:42.442, Speaker C: Yeah. Appreciate it.
01:25:42.576 - 01:25:57.206, Speaker A: One thing that you pointed out to me that we didn't talk about much in the episode was the question whether to enshrine proposal builder separation or not in Ethereum. How do you think about yeah, yeah, it was weird.
01:25:57.238 - 01:25:58.446, Speaker B: I felt bad that we didn't cover this.
01:25:58.468 - 01:26:00.366, Speaker C: I feel like it was the most obvious thing for us to cover.
01:26:00.388 - 01:26:01.614, Speaker B: And it was also, like, right after.
01:26:01.652 - 01:26:04.974, Speaker C: Mike wrote the post, too, on a lot of this stuff.
01:26:05.092 - 01:26:05.374, Speaker D: Yeah.
01:26:05.412 - 01:26:33.414, Speaker C: So, I mean, like, this is a lot of the interesting kind of like it's really the core question for PBS, but also so many other things tangential to the protocol right now, like PBS, restaking, PEPC, a lot of them kind of touch different areas where it's like, what is that boundary of the protocol? Again, she'll go look at a bunch of Barnabay's writings and presentations on this, of seeing a protocol and what the boundaries are is grace.
01:26:33.542 - 01:26:39.100, Speaker A: We should just call the episode The Ghost of Barnaby pretty much like the Ghost of Christmas Past or something.
01:26:39.470 - 01:26:48.346, Speaker C: We're quoting him for half of it. But yeah, that is a lot of what it is, is what is fundamentally kind of the protocol's boundary, what is its role, what should be in protocol.
01:26:48.378 - 01:26:49.390, Speaker A: What should be out?
01:26:49.540 - 01:27:36.746, Speaker C: And that is like, the fundamental question that a lot of the researchers at the effort are doing on PBS right now is that question. And it's been interesting. There's definitely been, I feel like, a bit of a change. And this was a lot of what we spoke about at Vienna, particularly after ECC. So a lot of the reason to do enshrine PBS EPBs for a long time was thought of as, okay, we'll do EPBs and then the relays go away. That's kind of the reason to do it. And there's starting to be more, I would say, realization lately is that, okay, even if we do EPBs, relays probably stick around or something very much like them in a reduced role, I would say, from where they are today, where they're significantly less systemically important and less relied upon.
01:27:36.746 - 01:28:51.686, Speaker C: And they provide less of an advantage, but where there is probably still an incentive to use some sort of out of protocol solutions that are probably more optimal than using the Enshrined PBS protocol. So some of the simple examples are even if we do this Enshrined PBS, where there is this canonical P to P pool where this is where the bids are and this is where you're supposed to listen to what are some advantages that some sort of out of protocol actor like a relay could still potentially provide you. So a couple of the simple ones that seem to be pretty important are one of the really simple ones is just flexible payments of, like, the way that you would do the payments in this kind of epps world. Would be like the main idea is probably to do something called tob Top of block payments, where I would be able to, as a builder, send you a bid that even if I don't give you the block body, you could take the payment. So that works well in most cases. There are certain times where you would want more flexible payments of, let's say this is like a gigantic mev block where I'm going to get 1000 ETH in the block or whatever and I'm only going to be able to give you the bid for that 1000 ETH after the execution payload. So I can't send you the 1000 ETH in the top of block payment because I actually don't have it yet.
01:28:51.686 - 01:28:58.470, Speaker C: The only way I can send it to you is you need a check at the end of the block like, hey, I made the money and I can actually send it to you.
01:28:58.540 - 01:28:59.810, Speaker B: So that's a service that really the.
01:28:59.820 - 01:29:06.922, Speaker A: Relay is fronting the money but only atomically for the relay. It's trustless. Right? But that is something that the protocol cannot do.
01:29:06.976 - 01:29:53.466, Speaker C: Yeah, they're effectively guaranteeing to the proposer like, hey, don't worry, the builder is good for this the block, they definitely capture it, we're going to pay it to at the end. And so that is one scenario where it is still potentially useful to have some sort of third party who's mediating this fair exchange between the proposer and the builders. That may be more of like an edge case. One I'd say the more pointed ones are specifically, like through the bidding process of cancellations is one where a lot of these in particular, like the Sex Decks arbitrager builders, they will be continuously updating their bids throughout the sought. And there are times where they will potentially want to cancel their bids at certain times because prices moved off chain and I need to lower my bid. Actually. And so you can't cancel if you broadcast something to a P to P like public mempool, there's no way to do that.
01:29:53.466 - 01:30:51.174, Speaker C: But a relay can do that. We just have a limitation that like, hey, as a proposer you can only call, get header once, so they'll call it at the end of the slot and I cancel before then. Could also do private auctions which is potentially helpful for some builders who don't want to reveal everything. And then the last thing is just like simple latency of relays are probably going to be like some latency optimization services. Probably going to be able to get a faster connection between if they're absolutely optimized between the builder and the proposer as opposed to sending it just to the main P to PMEM pool. So it's very possible that you would be able to get your bid slightly later towards the end if you're using the relay as opposed to the P to P mempool. So it gives you these on the margin optimizations and that becomes like the fundamental question of is this even the relay that we think of it as it is today? I was going to ask you exactly and it's like is it the relay or is it not? It almost is a different role.
01:30:51.174 - 01:31:39.082, Speaker C: It is just almost like a latency optimizer, whatever you want to call it. It's not a fundamental role that it's needed anymore to just mediate the fair exchange between the proposers and the builders. And that is the interesting difference is today basically if the relays go down today, the whole PBS thing doesn't work really. There is no interface between the builders and the proposers in this world. If the relays go down, okay, maybe the latency at the end of the slot is slightly suboptimal, and there are times where you can't cancel bids. They're optimizations, but it's not like PBS doesn't fundamentally work well, and it's like, okay, you got to build a box locally now, so it's a very large delta and they're sort of like an optimization service at that point, as opposed to this is like a fundamental role in the middle of this thing and it doesn't work without them. So it is a very different kind of point there.
01:31:39.216 - 01:31:55.950, Speaker A: So do you envision that if we build this form of EPBs that basically makes the bits trustless, would those trustless or quote unquote in protocol bits be used even for services where the quote unquote relay would be used as well?
01:31:56.020 - 01:31:57.298, Speaker E: Can they be used together or would.
01:31:57.304 - 01:31:59.074, Speaker A: It be either or in your mind?
01:31:59.192 - 01:32:01.714, Speaker B: Yeah, the relay could still just send.
01:32:01.752 - 01:32:06.280, Speaker C: Along those trustless type payments so they could work together in that form.
01:32:07.690 - 01:32:09.046, Speaker B: It would certainly make sense for them.
01:32:09.068 - 01:32:16.966, Speaker C: To support the protocol approved type payment in addition to the flexible payments like kind of where they're needed because the.
01:32:16.988 - 01:32:20.146, Speaker A: In protocol payment doesn't have any downsides.
01:32:20.178 - 01:32:20.470, Speaker E: Right.
01:32:20.540 - 01:32:29.580, Speaker A: It's using the P to P layer where the kind of disadvantage comes from and so you can use the centralized relay rails but with the in protocol trustless payment.
01:32:31.390 - 01:32:36.046, Speaker C: It'S also potentially actually better. I should probably point out one, in.
01:32:36.068 - 01:32:43.406, Speaker B: Trustlessness of like you really don't have to trust them. And two potentially latency optimization of like if you can avoid having to do.
01:32:43.428 - 01:32:46.430, Speaker C: The flexible bottom of the block payment, that is better.
01:32:46.500 - 01:32:47.438, Speaker B: Because if I get to send the.
01:32:47.444 - 01:32:54.146, Speaker C: Top of the block payment, then the relay doesn't even have to check anything. They don't need to waste time simulating anything. If the relay has to simulate the.
01:32:54.168 - 01:32:55.282, Speaker B: Block and then check at the bottom.
01:32:55.336 - 01:32:59.794, Speaker C: Like, hey, this is there, then that does take additional latency.
01:32:59.922 - 01:33:54.598, Speaker A: Yeah, I mean, something that I really regretted after releasing this post or kind of contributing it is even calling it a relay because as you say, it has pretty much nothing to do anymore with the relay that we have. And so to say that quote unquote relays will stick around after EPBs is not accurate because you're just like kind of moving the goalposts simply because it's not a relay anymore. And so I think I'm landing on the more optimistic side, I would say on this whole debate that we should do this. I think it's a good idea. And even if some form of out of protocol infrastructure may still be used, the structural importance of this infrastructure will be very low. Right? Yeah, I think it's a good idea. Good idea.
01:33:54.764 - 01:33:57.494, Speaker B: Yeah, it definitely does seem to be.
01:33:57.612 - 01:34:28.370, Speaker C: Quite additive to put it in there. And yeah, to your point, I probably do agree. I probably could honestly call them something else because that is the unclear. They're not a systemic roll it anymore. It is just like this kind of additional service where it's unclear what exactly is the delta and it's effectively reducing the cost of altruism is the way to put it, massively. Where the delta today is, your options are build a block locally or do the full PBS. So there's just a gigantic delta between the two of them where the difference.
01:34:28.440 - 01:34:30.402, Speaker B: In this world would be okay, use.
01:34:30.456 - 01:35:01.434, Speaker C: The PBS enshrined canonical and you use this latency optimized relay thing, maybe you earn like 1% more. It's unclear what exactly is the number on that. It may be such a small margin that for most people it's honestly just not even worth doing it at that point of like it's such a small optimization, I don't really care. It doesn't even justify the cost and the additional risk of running out of particle software of maintaining this thing. It's just like forget it, the other thing works. 99% is good. I don't care about the last like five milliseconds at the end of this thing.
01:35:01.434 - 01:35:12.110, Speaker C: And that exact delta does matter and it's unclear exactly what it is, but yeah, it is a very fundamentally different role as opposed to this is the central point that is holding up the whole PBS auction.
01:35:12.690 - 01:36:05.540, Speaker A: Yeah, I agree. One more thing that I want to touch on is kind of I mean, I was kind of giving Mike a bit of a hard time asking him about different governance entities in Ethereum and like their power distribution, who maintains what what this means for the decentralization of the overall ecosystem. And yeah, Kudos, you gave a good answer. I still want to talk about this a bit more with Mean right now. It's pretty much the case, I think that the Ethereum Foundation is working on EPBs with the help of various other researchers. I think Flashbots is contributing, as are various other parties. Meanwhile, Flashbots is primarily maintaining mev boost and that's where you more have the Ethereum foundation and support primarily supporting kind of with research.
01:36:05.540 - 01:37:06.882, Speaker A: Folks like Tony, for example, have know, do some great monitoring and data analysis and increasingly also like academia is starting to contribute to so. What would you think about the idea of so? On the one hand, you could kind of enshrine it. And I think Mike especially was kind of hinting at that idea, right? So you could resolve this power. It's not a struggle in any sense, this separation. You could address it by just saying specifically, okay, PBS is now part of the protocol. And so the protocol devs basically also have to work on it and make sure that it stays up to date and it stays optimal. But the alternative may be to basically create more sustainability and maybe governance around PBS, but outside the protocol.
01:37:06.882 - 01:37:10.600, Speaker A: So between these two options, what do you think?
01:37:11.610 - 01:37:55.380, Speaker C: Yeah, I mean, part of it's a time horizon question. I don't think that you need to rush to enshrine something because of this. You definitely want to take your time on it. In an ideal world, yeah, you solve these problems and you enshrine stuff and you don't have to rely on different companies with different interests to be funding this stuff and developing it, et cetera. It is the fundamental recurring trend with ethereum of even execution charge to roll ups is somewhat of the same trend honestly of you start to realize like hey, maybe this actually works really well if we let the free market. Just take this thing and kind of keep innovating it over time. It particularly becomes like that.
01:37:55.380 - 01:38:39.778, Speaker C: Depending on your view of how much does this thing need to keep being updated over time? That becomes a big part of it, quite frankly. If you start to have more confidence of like, okay, this is a mechanism which is very simple, it is very forward compatible, it's not very opinionated. This is something which works and it can last the next ten years, 20 years, whatever, then you feel pretty good about like, okay, we could just enshrine this thing. It's really simple. Like it works. You don't need to leave people to keep innovating, keep changing this thing over time in the way that roll ups or something else, they're going to keep changing. So part of it changes based on that view, I would say, is like how confident are you that this thing is actually static and can stay there for a long time.
01:38:39.778 - 01:39:24.266, Speaker C: At that point you want to enshrine it and you want to put it in the protocol if possible. Because just leaving it out to different companies, people have different interests and that leads to potentially worse outcomes over time. So it is suboptimal, I would say in the short to medium term at least, I definitely think it makes sense, like you don't need to rush to do these things. The main pressing result of that though is okay, we do need to figure out funding for a lot of the tangible stuff, particularly for relay funding. That is the main question out of this. PBS Gildon similar ideas is that this is part of the benefit of EPBs in my mind is it gets rid of the relay funding issues. At that point you should not get any funding.
01:39:24.266 - 01:40:18.098, Speaker C: Like you are a latency optimization service, you're not fundamental to the protocol. But the big question today is that we're not there and the relays are pretty fundamental to holding up the PBS process, at least for the untrusted participants. So in the absence of relays you would have today like the top 90% or whatever number of validators and top 90% of builders, they're fine, they could trust each other. Lido and Beaver build like hey, we know each other, we could trust each other, is fine. But the relays are fundamental to upholding the hey, that last 5%, 10%, whatever that number is of like they would not be trusted to receive something from a builder. So they are fundamental for that and as of right now, they're not a business that's able to monetize that. So the question is how do we try to fund these? Hopefully we have a upvs at some point in the next couple of years, whatever it is.
01:40:18.098 - 01:40:28.626, Speaker C: But for today, people have to run these relays. It costs some money and it may not be profitable for them to do so. So figuring out that is one of the main directives of something like this.
01:40:28.808 - 01:41:20.594, Speaker A: Yeah, I would agree. I mean, I think how static you can make it, how close you think you are to something that can be static. I think for me that is a key determinant to whether you want to pull it into the protocol. I think before that point it really makes sense to address kind of the relay sustainability issues. Why are we talking about this? I mean, it's because relays basically have a hard time monetizing in a market driven way because they basically become too like if some relays charge fees they become too easy to bypass and you really create an incentive just for a builder basically to run their own relay or for a pool to run their own relay. And at that point they can do it cheaper and better and faster basically. So it's like the current market structure really doesn't support monetization through fees.
01:41:20.594 - 01:42:04.500, Speaker A: And to me this suggests that what we need is kind of an entity, like an independent entity that can support relays to grant funding. And in my view, this could also solve some of the other issues. It could make the governance of mev boost more open. It could support development work and yeah, possibly even govern not just Mev boost, but kind of more the umbrella idea of PBS that we have been talking about and kind of, for example, help layer twos figure out what they should be doing with regards to this.
01:42:05.430 - 01:42:23.498, Speaker C: Yeah, certainly on the base layer, depending on where the EPBs road kind of goes. I mean, I definitely see that being valuable. I've mentioned this before, I don't see this needing to play a role for layer twos at all in my mind. So I'm curious to hear your thoughts on that.
01:42:23.584 - 01:42:59.334, Speaker A: Yeah, why not? I give you my case. The case is not it's not at all about sustainability. Right. I'm not saying that entities should fund the research for layer two. So they would be crazy. I think the layer twos can pay for it and I think it's like especially they could contribute to something like that as the grants actually like the grantees, if you will. I mean, more in the sense that there isn't a whole lot of expertise right now in building this.
01:42:59.334 - 01:43:03.446, Speaker A: Right, so you basically want to bring parties together. You want to bring the parties who.
01:43:03.468 - 01:43:04.646, Speaker E: Need it and who can fund it.
01:43:04.668 - 01:43:20.940, Speaker A: With the parties, who actually can build it and who understand deeply what goes into making kind of an efficient and robust kind of implementation of this. And yeah, that's my thinking behind it. What about you?
01:43:21.790 - 01:43:32.990, Speaker C: So what exactly would the L two S involvement in this really be then? I mean, they would be funding it, if anything, not like being a recipient of it. I don't see why you need another.
01:43:33.060 - 01:43:53.560, Speaker A: Oh, sorry, I mean, I maybe used the wrong word. Yeah, no, they would be funding it and they would outsource the building of their form of PBS possibly to the same parties who do it on layer one or like kind of this body. Do you think they want to own the building and maintenance of this?
01:43:54.650 - 01:44:46.534, Speaker C: Yes, one, I'm influenced by the fact that I think that they are very different problems in many ways, layer ones versus layer twos. And I think that different roll ups also have probably makes sense for them to have very different opinionated designs at PBS. Like it can look very different from one roll up to another. So part of it is that part of that is also I think that is something that fundamentally they do kind of want control over. For some of them it is a pretty important selling point of what they're going for. Like Arbitrarim being kind of the simplest example of a lot of their research around first come, first serve and how that's evolved over time. That is a pretty important thing to them of this is what they're saying to users of like, hey, these are the types of guarantees we care about a lot.
01:44:46.534 - 01:45:08.910, Speaker C: So I don't see them wanting to outsource, like, oh, hey, this other entity, please tell us how to do PBS. So I don't think they want to outsource that necessarily. I think that they like having different teams, like having opinionated and different stances on some of these things. So I don't know that they really need to outsource it.
01:45:09.060 - 01:45:10.506, Speaker B: I think that they have the resources.
01:45:10.538 - 01:45:28.710, Speaker C: Internally to do it, certainly. And this is where the governance and the ownership of what this type of committee is matters a lot that you obviously do not want it to be that we are outsourcing this to some committee that has some other agenda behind it that is not aligned with what we're doing.
01:45:28.780 - 01:46:11.934, Speaker A: Yeah, no, I mean, I completely agree, right. I mean, basically whatever PBS is developed for layer two has to adhere to their policies. I think it would be an unsustainable situation, though, if every layer two had its own implementation of this because it basically becomes like a security nightmare. I mean, you see all of the things that can go wrong on layer one already. And so I think standardization across at least a few shelling points. Maybe you have like two to three different flavors and they kind of have their own kind of customization options or different policies are enforced by governance.
01:46:11.982 - 01:46:12.194, Speaker C: Right.
01:46:12.232 - 01:46:31.366, Speaker A: Like proof of governance style. You do have PBS, but the policy comes from governance and governance monitors the builders and whitelists them. I think something like that is probably a good middle way because if you really have a unique implementation for everyone, I don't know that it's very trustworthy, to be honest.
01:46:31.548 - 01:46:33.354, Speaker B: Yeah, I think what you described there.
01:46:33.392 - 01:46:56.322, Speaker C: Is kind of where I more likely envision it happening, is there are going to be standards within the different verticals of like you start to see this already with optimism. Talking about the super chain and the law of chains, where each chain within that super chain can have meaningful flexibility to we can have different sequencer designs across them. Like maybe you do use the shared sequencer, maybe you don't different flexibility within.
01:46:56.376 - 01:46:58.014, Speaker B: That, but that there are certain approved.
01:46:58.062 - 01:47:59.782, Speaker C: Standards of like, hey, you have to abide by this if you want to be part of this ecosystem. And certain opinionated decisions around something like PBS or allowable sequencer designs is something that you could certainly see falling within there where, hey, within this optimism, superchain, here are the things that are acceptable and these are approved governance stamped of like, this works, we approve of this. This works really well. Similarly for the optimism sorry, for the Arbitrum kind of stack and the polygons and the Starknets and so on within each of those verticals. I would imagine that core team is doing a lot of research of like, hey, here are the approved things that we think work really well. It makes it very easy if you want to spin up a new chain within that ecosystem, because I agree, if literally every single chain out there has to do this, it's insane, it's impossible. My guess is there are a few basic standards that may look different from one ecosystem to the next, where for the Arbitrum one, for example, they are still pursuing some variation of first come, first serve, whether it's like time boost or whatever.
01:47:59.782 - 01:48:14.330, Speaker C: And that is going to look very different versus if you slap something like mevboost on another roll up ecosystem. So I think there will be different standards across different ecosystems that may be useful in different places.
01:48:14.910 - 01:48:15.660, Speaker A: Yeah.
01:48:16.110 - 01:48:18.278, Speaker E: It's also very important to have standards.
01:48:18.294 - 01:49:06.010, Speaker A: On the builder side for Swerve, right. Because if you're designing this, then you want basically you want to make it as easy as possible for builders to join, and you want them to have the same, basically interface that they have to other roll ups, especially in cross domain world. Right. Because a lot of your value basically comes from getting access to the same or making it easy for the same block builders to build your chain. That may also know Ethereum, optimism, polygon uptrum, whatever. And so I think really there's a huge incentive for standardization of these interfaces. And that kind of almost gets us to the vision for Swarf and why you want a shared mempool, why you want a shared block building layer.
01:49:07.710 - 01:49:51.478, Speaker C: And in particular on that, as you start to think of, okay, particularly in this future, say that there are many roll ups and they each have some variation of PBS or something that looks similar to it. Who are the builders across these ecosystems? I think you'd probably agree that we're already in a pretty far from optimal state of what the builder market on Ethereum looks like, where you have two or three entities that build the vast majority of blocks. What is that going to start to look like when we start to talk about like, okay, now we have a bunch of different roll ups and what's the builder market on roll up number 42 going to look like? It's probably not going to be like, oh, it's 1000 different people who are perfectly competitive with each other. I would be rather surprised if that's.
01:49:51.494 - 01:49:52.538, Speaker B: What it looks like.
01:49:52.704 - 01:50:16.530, Speaker C: And you start to realize, okay, there's a lot of effort being put into Ethereum today and already it's quite imperfect. Where does that equilibrium end up? And just assuming that, oh, there's going to be a bunch of competitive builders for all of these million different chains seems like highly unrealistic. And you probably need a more holistic solution of like, okay, how do we decentralize this role and constrain the power more meaningfully?
01:50:17.190 - 01:51:18.840, Speaker A: So on the point of censorship, resistance, John, we are seeing a lot of proposals around giving basically proposers more agency whether it's through inclusion lists or mevboost plus or PEPC and also in mev boost itself. Now there's minBit, I believe, which is a feature that basically lets you build a block locally unless the value of the block that you can get from the builder market exceeds a certain value and that value you can configure. So you can basically say, let me build the top 70% through Mafboost and like the bottom 30% locally. And this is like all ways of giving more agency to the proposer. I think we fully get the idea of why you would want this. I mean, of course you want to make the protocol more censorship resistance, et cetera. But then do you think that there's also a market demand from validators to actually use this?
01:51:21.450 - 01:52:37.760, Speaker C: A big part of my worry is that there's a market demand to not have it in place, that it's very much the opposite. So much of the discussion, particularly early on, with ideas like inclusion lists and medboos plus proposer suffixes, was this trade off between wanting to give back proposers agency and trying to kind of keep them dumb of like, hey, we want to have statelessness. We want to be compatible with these things where they don't have to enforce these things. I think at this point I pretty confidently feel that the bigger trade off is realistically just on a potentially practical, legal and regulatory side of things. I don't think that most people want to have the agency thrown on them like, hey, you are the person who enforces censorship resistance of all these things and it's difficult for anything like ethereum to ever design itself around trying to guess at the current estimation of what regulations in a given jurisdiction are. You don't want to be designing based on, oh, I as a validator think that maybe this is okay legally to do. The practical reality is like so much of crypto regulations, it's incredibly unclear what the guidance is.
01:52:37.760 - 01:53:26.942, Speaker C: But it is a very practical, simple point of like it is very possible that a lot of validators are going to be uncomfortable saying, hey, I'm going to enforce that. I'm going to put all of these OFAC transactions in there. There are a reason that relays and builders are understandably personally uncomfortable doing that. And you would imagine that a lot of large validators are going to have similar stances of if it is unclear regulation wise what we are supposed to be doing, there may be hesitation to exercise those rights even if they were given those rights. That is a meaningful kind of fear of mine of there is an assumption that if we give proposers the tool to enforce censorship resistance that they will use them. And a lot of the other concerns around it was like, oh, they have to be altruistic to use something like an inclusion list. Like they don't make money by doing it.
01:53:26.942 - 01:54:30.718, Speaker C: I don't really think that's a concern. It's very negligible those kind of incentives. It is entirely are people going to feel legally comfortable doing this when there isn't really upside to them? So that is a meaningful question in my mind and that is why I've continued to increasingly be interested in the more privacy side of things of various forms of encrypted mempools where it is the much more encompassing solution of providing the censorship resistance while also giving absolutely everyone plausible deniability effectively throughout that entire supply chain. Whereas the more inclusionless and bev boost plus side of things is we are going to put it squarely on one person's back and say like hey, this is up to you. Please enforce censorship resistance and that works fine if you assume that everyone is willing to do that. It's hard to assume that when you have a permissionless protocol and a lot of large entities who are probably going to end up in those shoes. But removing anyone's agency to do anything at all and you have to let everything through kind of seems to be the better long term solution of how to provide a lot of these guarantees.
01:54:30.718 - 01:54:48.698, Speaker C: So it was something that we touched on a bit in the episode of while things like Swab and Threshold encrypted mempools and different variations are very often presented and they're like hey, this is an mev tool. They really are a censorship tool just as much and those do go very much hand in hand. There's a reason they go hand in hand and it is very useful in.
01:54:48.704 - 01:54:50.118, Speaker D: These kind of situations.
01:54:50.294 - 01:55:38.306, Speaker A: Yeah, I completely agree. I fall on the more bearish camp about any kind of proposer agency tools. I think that there is a design constraint in all of this and this is that proposers don't want agency and so a solution that requires them to exert agency in my book is not going to solve the problem. I think what you need is you need a solution that's compliant with proposers not having agency, not wanting agency. And to me the idea of kind of an encrypted mempool, an encrypted computing environment where blocks can be built still where you can have your kind of efficient block building on top of private data to me that is the only solution that I can see to this problem. And yeah, very bullish that it certainly.
01:55:38.348 - 01:56:29.346, Speaker C: Seems the most all encompassing solution to me. The question that I still have and why I probably still lean somewhat positive on them is like something like inclusion lists. Is it detrimental in any way to add it in there or is it purely additive? So let's say you added something like inclusion list and in the bad case, let's say most validators are like hey, I am not legally comfortable doing this but a good portion of them use it. Is that worth implementing? It probably is in my mind and that's like an open question or maybe. They just don't even want that tool available to them in the first place for the reasons described. Nothing is a cure all on these short to medium term solutions, but it does seem to be a valuable tool still, nonetheless. And that's kind of where I am still of like it does help on the margin.
01:56:29.346 - 01:56:34.538, Speaker C: There are certainly going to be some amount of Validators who will use this who are comfortable doing so.
01:56:34.704 - 01:56:35.402, Speaker E: I will agree.
01:56:35.456 - 01:56:40.342, Speaker C: And where is it worth it? What is the tipping point of where it's worth it? Is like, that's what's kind of tougher.
01:56:40.406 - 01:56:45.726, Speaker A: I will agree. I mean, the solution to censorship is probably a patchwork of different options that.
01:56:45.748 - 01:56:47.246, Speaker E: All work together that are used by.
01:56:47.268 - 01:57:35.498, Speaker A: Different parties based on kind of their risk preferences. And I mean, I don't think inclusion lists hurt in any way. I don't think they will be used heavily. But you can argue the same thing for something like minBit in Map Boost, right? There's also a fair amount of it's, not a big amount, but it's like a sufficient amount of the network who use this, right? And then you can say maybe for a system like Ethereum that's okay to kind of give the properties that it does. At any point, a sufficient number of Validators should mine your transaction. It doesn't need to be the case that all of them have to mine it all the time. And I think if you're really trying to target kind of the latter option, it's probably unfeasible.
01:57:35.498 - 01:57:59.990, Speaker A: You're probably going to run your head against the wall and yeah, I think it's like pragmatism, I guess, over ideology. It's like a good final word to wrap it up, which is like, I think this is really the whole idea around PBS, that PBS really is like the win of pragmatism and realism about market forces over ideology.
01:58:00.330 - 01:58:02.678, Speaker C: Yeah, I will strongly agree on that. I love that.
01:58:02.684 - 01:58:04.866, Speaker A: As a final note, John, it's been a pleasure.
01:58:04.978 - 01:58:09.318, Speaker C: Likewise. Took the long road to get this done after five or six tries in.
01:58:09.324 - 01:58:13.414, Speaker B: A month or so, but apologies to the audience. We'll hopefully be quicker on the next.
01:58:13.452 - 01:58:15.974, Speaker C: Episode, but it's a lot of fun.
01:58:16.092 - 01:58:17.398, Speaker E: Thanks for joining us today.
01:58:17.484 - 01:58:21.162, Speaker A: As always, nothing we say here is invest or legal advice.
01:58:21.226 - 01:58:23.006, Speaker E: The views expressed by the course are.
01:58:23.028 - 01:58:31.374, Speaker A: Their personal views alone. Please see our podcast description for more disclosures. If you enjoyed this episode, please feel.
01:58:31.412 - 01:58:33.962, Speaker E: Free to subscribe and share it on Twitter.
01:58:34.106 - 01:58:35.130, Speaker A: Thanks and goodbye.

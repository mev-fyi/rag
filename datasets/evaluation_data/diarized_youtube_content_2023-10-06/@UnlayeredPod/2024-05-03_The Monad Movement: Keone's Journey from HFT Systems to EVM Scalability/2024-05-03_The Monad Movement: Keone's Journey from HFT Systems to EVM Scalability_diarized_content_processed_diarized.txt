00:00:14.160 - 00:00:40.570, Speaker A: Welcome to Unlayered, the podcast where we explore next generation blockchains. I'm your host, Saul, alongside my co host here, Dave. And today we're joined by Keon, founder and CEO of Monad Labs. And prior to Monad, Keyon led a high frequency trading team at jump trading for eight years, focusing on system design, machine learning, quant trading and low level systems engineering. Kian, we're excited to have you here today. How are you doing?
00:00:40.642 - 00:00:42.826, Speaker B: Hey, doing well. Super happy to be here.
00:00:42.930 - 00:00:57.960, Speaker A: Awesome, awesome. I guess I want to start a bit high level. I think it goes without saying there's certainly no shortage of layer one blockchains out there in the world. Would love to hear from you. What is Monad's vision and what makes it unique? From a technical perspective?
00:00:58.072 - 00:01:35.044, Speaker B: The thing that makes Monad unique is we're focusing on EVM execution. And very specifically, we're introducing pipelining to the EVM execution stack. Pipelining is the practice of identifying work that can be done in parallel and utilizing all of the system's resources efficiently by staging work and running things in parallel. And Monad introduces pipelining to a couple of different areas in order to ultimately help blockchain scale much more efficiently than they do right now. Gotcha.
00:01:35.084 - 00:01:56.412, Speaker A: Gotcha. I think that's kind of a common theme we're seeing with these next generation blockchains, an emphasis on the ability to parallelize execution and increase throughput and scalability, I guess, from a high level, why do it? While also maintaining that EVM equivalency? What was the design decision there?
00:01:56.548 - 00:02:29.392, Speaker B: It's really driven by the fact that there is a lot of work that's already gone into building libraries in solidity, applications in solidity. And then I think people don't really think about the research aspect as much. A lot of the applied cryptography research is all being done in the context of EVM as well. So it's really a common standard that is really powerful. And we felt that it was just really important to try to make the underlying system that processes EVM transactions more performant.
00:02:29.528 - 00:02:47.596, Speaker C: What are your thoughts around this idea of EVM is great because you can drop applications basically on these brand new chains, because at some level, is it not that you're just sort of creating maybe a poor replica on a brand new chain? What do you see as the big advantages there of being able to deploy the same code on a new chain now?
00:02:47.620 - 00:03:46.090, Speaker B: Like, there needs to be some separation between the application layer and the blockchain layer. And we've kind of defined the interface already in the form of this EVM bytecode. Yeah, it's just really important to support high performance EVM. I guess another aspect of your question that you might be asking is like, is it from a l one perspective, is it better to support a common standard, knowing that all of the people that are building on the blockchain could very easily port over to another environment? And our view is that we can't think about that. That shouldn't be part of the calculus. If anything, it really should be the other way around. Application builders just build their application and go wherever they find the right set of characteristics in terms of performance and community and other integrations, other apps they can integrate with, I think probably reducing.
00:03:46.122 - 00:04:02.496, Speaker C: That barrier to exit one ecosystem and move to another. Yeah, I can definitely see massive benefits from that. I think the obvious question, which I'm sure you get asked a lot, is why not build an l two on ethereum? So it'd be great if we could get into that subject.
00:04:02.640 - 00:05:11.668, Speaker B: Yeah, I am actually really excited about rollups as well. I think that it's another good scaling effort that at the end of the day, what we're trying to do, what we're all trying to do, is just fight against the forces of centralization and advance the efforts of decentralized apps and make it easier to build scalable. Decentralized apps and rollups are one approach to tackling that, and parallel execution is another approach to tackling that. And I think at the end of the day, we're going to need both kinds of things in order to deliver the right, you know, all the right tools for developers to build decentralized apps. For Monad in particular, our team is just really focused on absolute performance, scalability and decentralization. We felt that the best way to do that is having a system of nodes that are all fully replicas of each other, that are communicating through consensus. This notion of shared global state across a large number of nodes being held in place by consensus is really powerful.
00:05:11.668 - 00:05:42.064, Speaker B: We wanted to push the limits there, and then we also wanted to push the limits in terms of just the amount of computation being done. And I guess one very specific thing is that rollups inherit the cost of data availability, and roll ups that are based on ethereum inherit a fairly high cost, just because data availability on Ethereum is quite expensive. So from a cost perspective, it made sense to build an independent layer one. And then from a performance perspective, it also made the most sense.
00:05:46.804 - 00:06:08.252, Speaker A: Can you actually expand a bit, kind of, on that point you're making, which is to say, what was the story and motivation behind Monad? You obviously were in crypto before starting this company, but what kind of pain points or things did you see with the EVM that you thought this particular approach would be the optimal solution versus things like Solana or other ecosystems?
00:06:08.428 - 00:06:52.284, Speaker B: So I started working on high performance systems right after college, joined a company called Getgo, which is a high frequency trading firm. They don't exist anymore. Through a series of mergers and acquisitions, is now Virtu, another big HFT firm. But I was at gecko for two years, at jump trading for eight years, mostly on the high frequency trading side. And that was just a really good experience for building things at scale, because our trading system that we built from scratch was sending on the order of 10 million orders a day, trading on the order of tens of billions of notional. The tradfi space is just. The numbers are orders of magnitude larger than in DeFi right now.
00:06:52.284 - 00:08:08.310, Speaker B: So just having that experience and then building the sort of competitive standards of single digit microseconds from tick to trade, those were really motivators for having a background that gave me and my co founder, James, or CTO, a ton of confidence that we would be able to contribute to the problem of just building really high performance blockchains. So, started at jump in 2014. Fast forward to mid 2021. Our team actually joined the crypto division of Jump trading and just started to actually mostly work on Solana DeFi and work on helping support some companies that jump had invested in, and just more generally learning about the space and trying to contribute. And while we were working on that, we just realized that there was a big gap between the Solana ecosystem and the ethereum ecosystem. And Solana is amazing technology that really did a lot of things extremely well in terms of performance and ability to push all this data around the world. Turbine is a really cool technology.
00:08:08.310 - 00:08:30.144, Speaker B: So really excited about a lot of things that are going on in Solana. But we also realized that the majority of DeFi users are using EVM applications. So that was when, mid 2021. That process of working on Solana DeFi and working a little bit on Ethereum DeFi caused us to realize that there was a huge need for much more performant EVM.
00:08:30.254 - 00:08:50.724, Speaker A: I think one of the key challenges with Solana specifically is the lack of TVL and DeFi, and how difficult it is to bridge capital over and bring inflows in, especially in a bear market. How does Monad fit into that? I guess problem set, because it's not an l. Two necessarily does it not have the same challenges in terms of bringing capital over?
00:08:50.844 - 00:09:55.850, Speaker B: Yeah, I think that growing anything from scratch is challenging. I think that getting new capital into the crypto space is challenging right now, given 5% cost of capital for holding dollars and, yeah, just given the fact that majority of non crypto natives are just, they've been subjected to two years of negative headlines and headlines about hacks and just a lot of bad news, a lot of. Some bad behavior from people like Do Kwan or others. I think that it's definitely challenging to get new non crypto natives to start using decentralized apps right now. But that's really the crux of what all of us are. All of our mission is to ultimately provide services for normal people, not just for the one to 2 million very crypto native people out there.
00:09:55.962 - 00:10:25.120, Speaker C: You mentioned earlier that being able to parallelize transactions is probably the big breakthrough, or one of the big breakthroughs, which has allowed Solana to scale well and is presumably helping you guys to get to, I think you've been quoted as saying, 10,000 tps. I suppose my first question on it is, why do you think? Because, am I right in thinking that currently none of the l two s even are looking at parallelizing transactions? Is that correct? And why do you think that is the case?
00:10:25.232 - 00:11:14.050, Speaker B: Yeah, I think it's the case because it's a pretty significant effort. And right now, most L two teams are more focused on other very pressing problems that need to get solved on their side, like decentralizing the sequencer or removing the whitelist on submitting fraud proofs, or having a, you know, very scalable fraud proof system that isn't subject to a denial of service attack. Things like the arbitrum's bold that they announced, I think, about two weeks ago. There's still a lot of, like, roll up related problems that need to get solved. And there's just, I mean, doing anything requires a lot of focus. It requires discipline to. Yeah, just to solve engineering problems.
00:11:14.050 - 00:11:46.740, Speaker B: And for us, our focus is very much on parallelization more generally, pipelining of different aspects of the ethereum system and the transaction lifecycle. And I think for roll up teams, they're solving very roll up related problems, but they're not incompatible per se in a roll up system right now, generally, single node systems, getting that single node to be more performant would be beneficial for, for them. So the work that we're doing at Monad potentially could be integrated into a roll up someday.
00:11:46.892 - 00:12:01.236, Speaker C: And are you able to paralyze transactions in a similar way to Solana, where upfront, the developers basically have to specify what these transactions are going to be, which piece of state they're going to be changing. Is it working in a similar way?
00:12:01.420 - 00:12:42.500, Speaker B: Yeah, that's a great question. It's not similar to Solana in that sense. So there is no pre specification of dependencies. Rather, the dependencies are just inferred through optimistic parallelization, where just to expand on the concept a little bit. So transactions are linear. In Monad, that is, a block has a list of transactions, and the true end state is always just the result of executing those transactions serially, then we have a bunch of executors that are running transactions in parallel, and an executor takes a transaction and produces a result. A result is basically two things.
00:12:42.500 - 00:13:42.882, Speaker B: It's a list of inputs and a list of outputs. And the inputs are basically the addresses and slots and values that were assumed at the time of execution, that were read from state at the time of execution. And then the outputs are basically anything that changed, like any of the address slot value tuples that changed as a result of execution. Yeah, so they're basically the executors produce results for transactions, but then the results get committed back in the original order that the transactions were specified in. So if there's a bunch of results that got produced in parallel, and then one of the results, say transaction five, changes in input that was used in transaction six, then when we're committing results, we commit transaction five's result, but then we realize that transaction six has now had an input change. So then we go reschedule it and re execute it.
00:13:43.058 - 00:13:52.298, Speaker A: Can you expound on that and tie it back to why it's called optimistic parallelization, versus what other blockchains like how they approach it?
00:13:52.466 - 00:14:52.600, Speaker B: Optimistic parallel execution means that we're optimistically assuming that transactions will not compete and running them in parallel. And then if it turns out to be a conflict, like if it turns out that one of the inputs to one of the transactions has changed as a result of an earlier transaction that was being run at the same time, then we just go reschedule the work. I think one thing to emphasize as well is that generally the bottleneck is IO. The bottleneck is not. Most of this work is not cpu bound, it's IO boundaries. So when you re execute, typically, although there is more computation that needs to be done, the inputs are already cached like they're already values that we don't have to go back to disk. Generally, unless there's a different execution path that results from some of the state changes, which could happen in certain cases, but generally is not the case.
00:14:52.600 - 00:14:58.566, Speaker B: So having that state in cache already means that re executing is quite cheap.
00:14:58.760 - 00:15:17.634, Speaker A: It kind of reminds me of, I believe, like suis approach with narwhal and Bull Shark, I believe there's also some optimistic component to how they achieve parallelization. I know they do the Dag thing too. Have you studied that ecosystem, and are there similarities there, or is it still kind of a different approach you're talking about?
00:15:17.794 - 00:16:08.504, Speaker B: Yeah, I think they're definitely similarities. I think it's kind of similar to Aptos block STM concept of optimistic parallel execution. It's not as similar to the DAg thing, which I think involves consensus as well. This is strictly an execution related optimization. But maybe just to talk a little bit more about the design of Monad overall, one of the other big changes that we have made is we move execution to be after consensus. This concept that we have called asynchronous execution or deferred execution. So the idea is basically that nodes communicate, they come to consensus on an official ordering of transactions, but they don't actually execute the transactions at that point in time.
00:16:08.504 - 00:17:08.134, Speaker B: And the benefit of that is that because execution is not a prerequisite to consensus, that means that there's a much larger execution budget that you can have for each block. So we have 1 second blocks in that 1 second. The job of the nodes is to communicate with each other and come to agreement about the official ordering of transactions. At that point in time, the state is fully defined, like everything is fully deterministic. When the nodes go to execute that list of transactions, they're all going to get the same result and still be in sync, because prior to that they also have the same state, and then they're applying the same list of work. I think that's just a little bit different from most other blockchains where the execution happens as a prerequisite to consensus. And in most other blockchains, that property means that the execution budget is actually a small fraction of the block time, because most of the block time is going to be spent on communicating with nodes on potentially opposite sides of the world.
00:17:08.134 - 00:17:18.917, Speaker B: This change of moving execution to be post consensus really opens up the execution budget and gives us a lot more time each second to spend on execution.
00:17:19.005 - 00:17:33.477, Speaker C: I'd love to understand your view on hardware, because obviously on the Ethereum side, they're very keen that everyone can validate basically from a home computer on Solana, the requirements are beefier. So just wondering where Monad sits on.
00:17:33.485 - 00:19:02.868, Speaker B: That spectrum, yeah, we think that it's really important for normal everyday people to be able to run a node on their computer that really contributes to the decentralization of the network. So we've really been working with the assumption that, yeah, we cannot rely on really beefy hardware specs. I think the one in particular that is the easiest way to boost performance and also the most expensive is basically requiring a lot of ram. And the reason that RAM is important is because, as I was mentioning earlier, the biggest bottleneck is really disk I o. So if you have a lot of ram, then more of your state could be cached in memory, and then that means you're hitting the SSD much less frequently with Monad. One of the big breakthroughs, I guess you would say, is the custom state backend that we've been building called Tri DB, which is a custom state backend for storing data in a Merkle tree, leveraging asynchronous I o to really more efficiently read and write stuff from disk. So having that backend instead of using sort of higher level key value store like LevelDB used by Ethereum, or RocksDB used by Solana, really allows us to get the most out of the disk.
00:19:02.868 - 00:19:10.744, Speaker B: And it's just a really custom solution for a very specific problem that is very core to transaction execution.
00:19:19.364 - 00:19:50.194, Speaker C: Would you say that you are against or indifferent to Solana's flaws philosophy of having beefier hardware? And I ask that because I think today or yesterday the latest upgrade is reducing the memory requirements from hardware. Obviously, hardware improves every year, and I think it's going to improve. At the minute, it's improving more than new people are coming into crypto, basically. So do you not think that there is a point in the next few years, really, where even the Solana requirements can be done at home?
00:19:50.354 - 00:20:29.888, Speaker B: I mean, it's hard to. Hard to say. I think it's great that Solana core developers are trying to reduce the hardware requirements. I think that a lot of times, like, you know, you're making trade offs to expediently solve a problem. And sometimes a way to do that is just throwing more ram at the problem. Similar to how like if you have a bandwidth problem, then an easy way is just to restrict the number of validators or to have all the validators be geographically close to each other, which is, I think, what we've seen with some other recent blockchain launches. All the validators are in Europe, they're all in Germany.
00:20:29.888 - 00:21:23.444, Speaker B: That makes it a lot easier to cut your block time. I think that there's trade offs that can be made to expediently ship a solution. And sometimes that's a reasonable thing to do in the early days of a project, because we are also trying to address a very urgent need, which is solving problems for application developers and allowing decentralized apps to thrive. So I understand that. And then over time, the shortcuts can ultimately get paid off, the tech deck could get paid off, and the requirements can get reduced over time. I think it's a reasonable approach. I guess the only thing that I really that I disagree with is sort of the citation of Moore's law, or like the, you know, the comment about, like, how well hardware gets cheaper.
00:21:23.444 - 00:22:01.776, Speaker B: So it's okay to, you know, sort of base the scaling efforts or like, to make an argument about scaling that's specifically related to, like, how hardware gets cheaper. Because I think that we should always be doing as much as we can to make the usage of hardware more efficient through software, through architectural improvements. But it seems like that's happening already. Ethereum also, I think the Geth team also announced pretty recently that they reduced the size of their state storage quite a bit. So, yeah, I mean, everyone is trying to push the limits of what's possible, and it's exciting to see that, and we're doing that as well.
00:22:01.880 - 00:22:18.346, Speaker A: I would be curious to get your thoughts on, given your background and high frequency trading at one of the biggest firms in the world that does that is the current state of MEV in crypto, and what your thoughts are on it and how you engineered the Monad protocol with that in mind.
00:22:18.490 - 00:23:22.374, Speaker B: The thing that's a little bit confusing about MEv is that people look at the numbers that are associated with MEV, like the magnitude of value extraction from transaction reordering, and they see a big number and they're like, oh my gosh, we should engineer. There's just so many MEv resistant dexs or products that are just very oriented around reducing meV. But fundamentally, MEV is really just. I think it's much more clear to just think about it as user loss. So basically, when you show up as a user to swap from ETH to Pepe, maybe that's a bad example, because I think there's some weird transfer tax going on there. But swapping from ETH to some other token, the expectation right now is that you're just going to pay pretty high slippage, like 1% or 2% or even more. People talk about setting the slippage tolerance to 10% just so their transaction goes through.
00:23:22.374 - 00:23:57.884, Speaker B: That's just in traditional finance standards. That's insane. That's an insane amount of slippage to be willing to tolerate. And the reason for that very high tolerance that's needed is because liquidity is very thin on chain. And in particular, liquidity that is provided automatically is not provided very efficiently. A lot of the value is not, a lot of the capital is not very close to the current fair value. It's spread across a curve, even with univ three with ranges.
00:23:57.884 - 00:24:52.654, Speaker B: Most of that liquidity is not right at the range, which is right where the current price is. It's spread out still. So I think ultimately the magnitude of MEV, like the magnitude of user loss, is really coming from really inefficient liquidity. I think the way to solve it is by making it so that it is possible for liquidity providers to make markets very close to fair value and to compete with each other on price, like to undercut each other repeatedly, to cut the spread down to something that is much more reasonable. And the way to do that is through a fully on chain limit order book. But then the reason why fully on chain limit order books don't exist in the EVM space is because it would be super expensive to update those orders all the time. If you pay $10 every time you as the market maker want to adjust your quotes a little bit, then you're going to end up spending a crazy amount of money quite quickly.
00:24:52.654 - 00:25:04.274, Speaker B: Then that really is resulting from high gas fees. At the end of the day, I see a lot of the user loss as really coming from inefficient blockchains with high gas fees.
00:25:04.434 - 00:25:29.530, Speaker A: You alluded to one of the solutions there that's been talked about in other ecosystems like Solana. How do you see this vision playing out for Monad specifically? For instance, you mentioned that block times are 1 second, so would there be some sort of an oracle? I know pith was a thing that came out of jump, I believe, to kind of support that use case. Like what kind of pieces needs to happen for an on chain limit order book to be a real thing?
00:25:29.682 - 00:26:30.458, Speaker B: Right? On chain limit order book is fairly freestanding, at least for spot markets, for derivatives markets. I think it would require an oracle, because if you allow leverage, then you need the oracle pricing to protect the protocol from users going underwater on their levered positions. But for spot positions alone, there isn't a need for an oracle per se. But with that said, we are really excited about high fidelity oracles that are pushing prices quite frequently to the chain, because that can also result in a lot of capital efficiency in terms of allowing the derivatives to protocols to allow more leverage, or allowing the lending protocols to allow more leverage because the pricing is more precise. So there's less of a danger, like there's less fudge factor that has to get associated with a particular oracle price, which ultimately is the reason why lending protocols need to have lower capital, like LTV ratios.
00:26:30.606 - 00:26:58.494, Speaker C: Even putting that aside, price discovery obviously right now happens on binance. That's where the majority of trading still happens. And even if we can produce these limit order books on chain, as Sal said, I think your block times are about 1 second on Sloaner, they're about 400 milliseconds, but you're competing with binance with latency of about ten milliseconds, I think. So can we ever have price discovery on chain? Can we ever get the majority of liquidity on chain? How do you see that shaping out?
00:26:58.884 - 00:28:33.838, Speaker B: I think we can. I think at the end of the day, pricing is a function of expectation, or basically how tight the prices are, is a function of how much it costs for market makers to update their orders, like how much wiggle room they need to have on their order. Because if there is basically zero cost to update, then they, they can quote super precisely. But if there is a small cost associated, like a 10th of a cent or a third of a cent or so, then they're just going to update their quotes to be a little bit wider, but still quite tight. And I think that the width of the market is ultimately one of the big drivers of volume, because when the spread is super wide, then it's just not going to be that many people that are crossing, and most of them are going to go to wherever the cheapest venue is. So I think I see the sort of like economics of market making as being one of the factors that will ultimately determine where volume, the extent to which volumes could migrate to deXs. But I think Dexs have a lot of other compelling attributes, like the non custodial nature, the fact that you retain control of your assets, or you can withdraw your assets very quickly without having to rely on a centralized party to authorize you to transfer your assets back, as well as composability, like the fact that other apps can be built on top of the Dex, and then atomically swap through the DeX as a subroutine within a larger execution, a larger transaction that's being happening.
00:28:33.838 - 00:28:46.442, Speaker B: I think that those properties are things that allow DExs to offer a better experience than centralized exchanges, but we just have to get the liquidity and the economics of market making.
00:28:46.638 - 00:29:21.384, Speaker A: So how do you see that dynamic playing out? Because I've heard opinions on both sides where sexes will continue to dominate crypto volumes and derivatives volumes related to crypto in the next ten years or so. But then obviously there's a lot of people that are very bullish, defi and even amms, even though they're not super capital efficient for the users. Do you see both playing an important role for institutional adoption and retail adoption in the next ten years? Or are we kind of in the early innings of a cambrian explosion of new Dex primitives, like on chain limit order books and things like that?
00:29:21.544 - 00:30:20.104, Speaker B: Yeah, I mean, it's very much a consumer product. So I think to answer that question, you just have to think about previous stories about challengers upending incumbents, like Robinhood upending e trade, Charles Schwab, and all these other brokerages by undercutting from a fee perspective, as well as having a really great trading interface that became a little bit mimic and had all the Wall street bets people, like, showing off their. Their Robin Hood screenshots. It's like, yeah, building a consumer product is really hard. I can't claim to be an expert on it by any means, but there are other really talented builders in the space that do have previous experience building consumer products. I think that from adoption perspective right now, they're just sort of like certain obvious things that are preventing adoption from happening that are basically the opposite of sort of viral. You know, like when you build an app, you want it to go viral.
00:30:20.104 - 00:31:21.574, Speaker B: You're trying to figure out, like, how to get that viral effect to happen. And when you look at, like, I don't know, it's kind of like a silly Twitter story, but like, Nikita Byer, this entrepreneur who built the gas app and had this really, like, smart strategy of launching it. So just to summarize really quickly, it's an app that allows you to gas up your friends to basically give compliments that are semi anonymous. I'm kind of. I haven't used. I'm not a high schooler, so this is just my interpretation of how it works. But basically, the way that his team caused this app to go viral is they had a really smart strategy of, like, only launching it, like, one school at a time and then, like, stuff related to, like, using Instagram to get a bunch of high schoolers all that, like, went to the same high school to get excited about the app before it showed up, and then they would drop it and then it would go crazy, and then there'd be a huge amount of demand for it.
00:31:21.574 - 00:32:03.218, Speaker B: So anyway, this is a long winded way of saying that getting your app to go viral is like a very important thing. And in crypto, it feels like we have the opposite of that, where there's all of these random challenges that actually make it super hard for your friend who heard about the app from you to actually use it. And those impediments are a couple of things. One, the actual on ramp, like actually getting crypto value into your wallet. Second of all, the actual user interface of using a wallet, which is a very foreign experience for most people, having to sign transactions for everything. Number three, lack of mobile support in general for most apps. Like most apps are not mobile.
00:32:03.218 - 00:32:26.494, Speaker B: And then number four, the high cost of interacting with those apps, basically high gas fee is antiviral medication for your app. It will cause your app to not go viral because people don't want to spend $10 anytime they interact with it. All this has to get solved in order to make it possible for people to build viral, decentralized apps. But I think once that happens, it's very possible.
00:32:31.764 - 00:32:50.544, Speaker A: I was perusing the website and I noticed there's grants programs, a lot of initiatives supporting various use cases in crypto among deFi, social and things like that. I guess what gets you most excited looking to the future with that in mind, and what are you guys on the grant side really focused on these days?
00:32:51.364 - 00:33:54.808, Speaker B: I guess I'm excited about a couple of things. One is that I think that crypto really has the potential to be the settlement rails for all finance. Right now. All of the current users of Defi are basically just the early test users that are dog fooding around products. I'm really excited about getting retail grade or institutional grade financial applications in the form of payments, decentralized exchanges, money markets, lending protocols, aka banks, things like that. I'm also really excited about the idea of decentralized identity. And I think with crypto, Twitter, we've seen just how much fun it is just to have an anon account or a semi non account and just have your identity not be your LinkedIn account and your resume, but rather like the communities you're part of nfts you collect achievements that you've made.
00:33:54.808 - 00:34:22.386, Speaker B: I think that the space of on chain achievements like stack overflow badges that all get pushed to the blockchain, or like, you know, you're in a. You're in your discord and then you like hit a new level. Like having like, those things be reflected on chain and having those be part of your identity, like part of your wall of badges. I know it sounds a little cheesy. Like, it sounds like the. The. I forget, it's like the guy in, is it office space? Like he has the.
00:34:22.386 - 00:35:01.990, Speaker B: All of the. Maybe it's not office space. It's probably wrong, but it's like the guy who has like 100 little, like, where's your flair? Like you didn't wear your flare today. Yeah, I know it sounds a little cheesy. Like, you know, people are have they're flared up with their accounts, like they have all their, like, discord achievements and so on. But I do legitimately think that there is like, having a place where all of your achievements go that are part of your on identity and the people even being able to have multiple identities, I think that's kind of cool. And I think that decentralized apps really enable that.
00:35:02.102 - 00:35:52.654, Speaker C: Obviously at Monad, you're aiming to be a highly performant chain. I think you've quoted 10,000 tpS. You've also made some references to what you think TPS will be across Ethereum post 4844, which I think was more in the 750 range. How do you see the future of crypto going in terms of the TPS that's going to be required across all these things? Because obviously you're coming from this high frequency trading background. You just talked through these various examples. Maybe AI could start making its way onto blockchains sooner rather than later. Do you think that it is going to be a sort of very high TPS in the next 510 years? Or do you think that Ethereum will be able to swallow up most of the activity?
00:35:52.994 - 00:36:29.726, Speaker B: Right. I think that all it requires is one app that goes viral. If you have one app that has a million daily active users and, say, 100 transactions per day per user, then that's 100 million transactions per day, which translates to about 1000 TPS. That's all you need is one app that does that. And that's the scale of successful iPhone apps is like five hundred K, a million Daus. So we really just need one app that would saturate all of the block space that's available right now.
00:36:29.870 - 00:37:09.978, Speaker C: We had Carl Simone on the show a couple of weeks ago, and actually we did ask him about Monad, and he said he really liked you guys. He thought the project's super exciting. He had a couple of reservations, which I was wondering if you wanted to push back on. So he said one thing is that maybe you're like, five years too late. Crypto is very path dependent and Ethereum is sort of now going in this other direction. Ethereum is now about amms, it's now about very low hardware, whereas you're talking about fully on chain limit order books and slightly higher hardware. So I think his other point was that you're maybe diverging away from the Ethernet eth narrative.
00:37:09.978 - 00:37:18.106, Speaker C: So I suppose how would you respond to those? And how do you feel it will be onboarding the Ethereum community to Monad?
00:37:18.210 - 00:38:00.744, Speaker B: Yeah, I definitely don't feel that anyone is too late right now. At the end of the day, it's still, we have, like I said, maybe a million or 2 million crypto users right now. So that's still a very small fraction. You know, even like when Facebook like surpassed MySpace, that was MySpace probably still had like 50 billion users or something like that. So it's still pretty early in terms of the adoption curve. And then I think beyond that it's really just technology. So everyone is working to make the technology a lot better, a lot more performant, more scalable, more decentralized, or a good combination of those, a good set of characteristics.
00:38:00.744 - 00:38:49.702, Speaker B: And it just doesn't feel like the space is super mature from a technology perspective. There's still a lot of movement in terms of Ethereum executing on the roadmap that the Ethereum community has set out. For example, like you mentioned, EIP 4844, that is still a much smaller initiative within the broader initiative of dank sharding. EIP 4844, proto Dank sharding, introducing blob space to support more roll up throughput. But the actual spec is still pretty, pretty limited. Trying to remember exactly. I think it's four to eight blobs per block, and then a blob is up to 250.
00:38:49.702 - 00:39:35.722, Speaker B: Might be getting these numbers wrong, but it's like a megabyte per block, but a block is only every 12 seconds. It's about like 100 kb/second which is not that many transactions right now on a roll up. So that's still a very small part of a broader effort of dank sharding. But then dank sharding requires a lot of other technology changes. So I definitely don't feel that the space is super mature in terms of technological progress. And then also I would add that the roadmap changes every now and then as well. Like a couple of years ago, the focus was really on sharding within Ethereum, and that's kind of officially been set aside as not the focus.
00:39:35.722 - 00:40:13.670, Speaker B: Now the focus is really on roll up scalability and offering data availability as a service. Ethereum is a data availability layer for rollups. The plan can continue to evolve, basically, as we see new technologies come to market and deliver on the promises that they've made with us, we're delivering on our promises that we've made, and I think that after people see what's possible, they'll get very excited and it'll continue to evolve. The roadmap.
00:40:13.842 - 00:40:29.718, Speaker C: Could you imagine a day in the future where Monad became an l two of Ethereum? Obviously that's not what you're thinking right now, but if Ethereum maybe inherited some of the technical advances that you're putting out to the community, could that be a possible endgame, do you think?
00:40:29.806 - 00:41:42.474, Speaker B: I think anything is possible. I think that our classification of l two s will become more and more fuzzy over time. Is it an l two of Ethereum? If, like Ethereum is not being used for data availability, for example, there's basically just state routes that are getting posted to Ethereum, but then there's a separate thing that is actually serving as data availability. That's what the sello announcement pretty recently was, using a separate service as data availability, but then pushing the state routes back to Ethereum. Does that count as an l two? So I think the lines will be more and more blurred over time about what really is an l two, and it'll really just be like a spectrum of security in terms of the security of the enshrined bridge. There's also this notion of sovereign roll ups that I guess has been getting some momentum recently. To me, those don't sound like l two s in the way that, you know, I was described what an l two was back in the day, like a year ago, but some people might start to refer to those as l two.
00:41:42.474 - 00:42:21.818, Speaker B: So I think that's one thing is like, the definitions are going to be very unclear, but it's definitely possible that Monad could push the data to a separate data availability layer and then inherit some security properties from that. But it really depends on the cost of the data availability layer. It really depends on whether that's economically feasible, whether that'll impose an undue burden on users of Monad right now, who would be benefiting from very low transaction fees. If that inflates the transaction fee too much, then it might not make sense for this iteration of monad.
00:42:21.986 - 00:43:13.520, Speaker A: This actually reminds me just really quickly from a user experience perspective, back in the bull run, quite similar to avalanche in that you use the same wallet, but it's definitely a completely different chain, different set of technology, different consensus mechanism, all that good stuff. And then the bridging experience was pretty good from what I remember, to use those apps and those ecosystems and then kind of bring it back to eth as needed. But kind of my question and it just reminds me of that whole thesis that avalanche bet on and some other ecosystems are betting on, which is kind of like this multiple app chains that can communicate with each other, whether it's subnets or super nets or whatever. I think optimism is also doing this too. Do you have a view on that approach for scalability versus obviously monads taking a different approach and whether it's. You think it's feasible long term?
00:43:13.632 - 00:44:09.314, Speaker B: Yeah, I'm excited about there being potentially multiple monads in the future as well. I think of a subnet or Supernet as really just another instance of the blockchain that's using the same technology and using some sort of special bridge that makes it easy to move between those different environments. There's some technical details varying from supernets versus subnets versus what have you. But at the end of the day, that's really just horizontal scaling, which is making multiple copies of the environment that exist in parallel and that maybe have specialized set of apps on them. And I think that'll happen with Monad as well. When we get to the point as an ecosystem of having so much demand for transaction throughput that it saturates one monad, then there would be multiple monads. But it's really about density of that network.
00:44:09.314 - 00:44:37.694, Speaker B: Is that one unit of blockchain like that one network, is it delivering 10,000 transactions per second, or is it delivering 100 transactions per second? Because if in order to get to 10,000 you need 100 copies of 100, that's just like a worse experience than having one unit that could get to 10,000 by itself. But I think that horizontal scaling is totally reasonable as well. And I think that that'll be part of the roadmap at a later point in time.
00:44:37.824 - 00:44:58.474, Speaker C: Now, while I'm sure that there's loads of ETH admirers of Monad, I think also on the slana side there's a lot of admirers because you're following a similar thesis really around how to scale blockchains, but adding the EVM compatibility. Do you have any plans to try and integrate not only with the ETH side, but also on the Solana side.
00:44:58.634 - 00:45:40.392, Speaker B: In the longer term plans? Potentially there's things that could be done making WaSm the base layer and then having an EVM emulation on top of that as the sort of like the way to support EVM. We thought about that, but didn't go in that route just because I think it would have added a lot of technical complexities. Having a WASm base layer would then make it a lot easier to support other runtimes, like the Solana runtime. But it's really not part of the focus right now. I think with any effort, like, you have to be super focused on the shorter term, and I would say at this point we're not focused on that at all.
00:45:40.568 - 00:46:02.544, Speaker A: Another quick technical question that I forgot to bring up earlier. So Monad has single slot finality 1 second block times. Can you just help our listeners understand? Because I think time to finality is a thing that's turned around a lot on crypto Twitter to compare and contrast blockchains. What does that mean and how does that benefit the user ultimately?
00:46:02.664 - 00:47:08.414, Speaker B: Right, so single slot finality means that we are using a consensus mechanism that once the network reaches super majority, that is two thirds of stake weight agreeing on a particular block, it's very unlikely that that block will end up getting reverted. That could only happen if a super majority then equivocated aka signed another block with that same slot height, which would then be a slashing condition. That's like the extreme case that I think is pretty well understood to be not something that would happen. So once two thirds of the stakewait has signed a block, that block is enshrined, and anyone building the next block knows that they should be building on top of that block. Tendermint is a consensus mechanism that has this property. Hot stuff is a consensus mechanism that has this property. DM BFT is a consensus mechanism that has this property.
00:47:08.414 - 00:48:06.648, Speaker B: So Monad's consensus mechanism is a derivative of hot stuff that has this property as well. And I guess I would just add also that although it sounds like a distinguishing feature, we don't necessarily think of it as such. We think that single slot finality is probably the default for most blockchains at this point. It's just that I guess notably, both Ethereum and Solana don't have that property because there are other things that they're trying to optimize for. With Ethereum, Ethereum is trying to prioritize liveness, which means that they have the separate finality gadget mechanism that finalizes blocks after two epochs, like twelve to 19 minutes. But there's this much more frequent block production mechanism that's happening every 12 seconds. So even if finalization is not happening, like if there were a bug like, I think a little while ago there was a bug that was preventing finality from happening on Ethereum.
00:48:06.648 - 00:49:00.542, Speaker B: The block producers were still able to keep producing blocks. So I'm so sorry, it's kind of a long winded way of addressing your question, but I guess I would just really briefly say that single slot finality is just the property of having. Having it be the case that once the network has achieved a supermajority on a block, then that block cannot be reverted. But the trade off is that if your network doesn't get to two thirds of the network voting on a block, then the network will get stuck. So it's really just a decision about what to prioritize. Generally, blockchains that have a single slot finality property are prioritizing safety over liveness.
00:49:00.718 - 00:49:45.552, Speaker C: I just want to steer, as we're coming towards the end of this, your go to market strategy, because you're almost victims of your potential success in that previous. Blockchains have been able to benefit from starting with very low valuations. They've been able to enrich their early supporters, and then they build up this sort of fanatic fan base. Unfortunately, the big blockchains which are launching these days are tending to start a billion plus market cap. So that naturally is going to put these new blockchains at a slight disadvantage. How are you thinking about this go to market strategy? When are you planning on launching and have you got any incentives or strategies in place to try and build up that early community?
00:49:45.728 - 00:51:02.568, Speaker B: Well, I would say, first of all, that I'm really grateful for our community of supporters who are really excited about Monad and Monad's mission and are excited about it. In this pre test net phase, there's nothing to touch, there's nothing to use yet, and yet there are a lot of people that are super excited. So just in general, in crypto, we're extremely blessed to, in this day and age, where the attention economy is where attention is incredibly valuable. The fact that there's a community of people that are really passionate about the mission of decentralized apps and this new paradigm for how apps are built and how users use them, I think that's really amazing. So we're all blessed, of course, in terms of the timing and differences of launching in a certain market condition versus another, there are pros and cons to any kind of situation. But I think I would. The thing that jumps out at me most is just that in general, we're incredibly blessed to have so many people that are excited about what we're all doing in the crypto space that, you know, have it as, like, their hobby or their passion.
00:51:02.568 - 00:51:47.290, Speaker B: It's like, it's like being a fan of a sport, like, like, sports fandom is such a, it's something that brings people together. Like, it's something that builds community, but it's like, super cool that there's this fandom about technology, because in a normal startup, like, you wouldn't have that. You know, your normal tech startup would have, like, 100 followers on Twitter. And like, even really big tech startups, they post announcements on Twitter and no one cares. So I think that, yeah, that's the main thing that comes to mind when you ask that question. I guess I would also say with anything, the go to market is about demonstrating value. Like demonstrating that we're doing something that's fundamentally different from other projects.
00:51:47.290 - 00:52:15.912, Speaker B: And for teams that think that that has merit, for teams that believe that much cheaper, much more plentiful transactions that are in an environment that's fully evm compatible to the extent to which they believe that, that's ultimately going to help bring a lot more people into the space and utilize the apps that they're building. Yeah, that's the reason why they would choose to build on Monad. So I think community is incredibly important.
00:52:16.048 - 00:52:17.964, Speaker C: Plus, I like the memes that you put out.
00:52:18.304 - 00:52:32.528, Speaker B: Honestly, almost everything is just community driven people who are really creative and really funny. And a lot of the memes that we put out on the Monad Twitter are just made by community members. Actually, probably all of them at this point.
00:52:32.616 - 00:52:48.260, Speaker A: One final question that I wanted to bring up is, what is your vision for how blockchains interface with privacy? How do you see that playing out? Or do you think it's much more of a far fetched long term thing that isn't worth focusing on right now?
00:52:48.432 - 00:53:37.900, Speaker B: I tend to, yeah, I think about everything from a common sense perspective. So I feel like the common sense perspective is obviously, privacy is really important. Like, obviously, you wouldn't want someone who interacts with your wallet like you do a, you know, you buy like, a sofa from them, and then you send them money, and then they like, look and see what your address is, and they see, like, oh, he went and bought coffee, like, last week at blah, and then he, like, you know, was shopping at the adult bookstore the week before. Like, it's, you know, it's just common sense that people wouldn't want that. So I think that privacy is definitely a major hurdle to adoption. And also, yeah, I think it's super important. I would say that I'm not the expert on the technologies that you're mentioning.
00:53:37.900 - 00:54:13.282, Speaker B: I think it's great that other people in the, in the space are innovating and focusing there. And I think the existence of common standards, like, honestly, like EVM as a standard, means that work that's being done in that space probably will be able to interface with Monad pretty easily. But, you know, it's not my area of expertise, but I am definitely. I think it's quite important, and I'm excited about people who are working on it. Everyone has to have their specialty. For our team, we're just high performance specialists. We know how to build really fast systems.
00:54:13.282 - 00:54:27.450, Speaker B: So that's why we're focusing on really improving EVM execution. But there are other teams that are probably much more knowledgeable about zero knowledge or other cryptography technologies that could make a really work on this really important problem.
00:54:27.602 - 00:54:40.266, Speaker A: Yeah, that would make sense. You guys are the speed experts, it seems. Well, Kian, thank you so much for joining us today and taking us on this journey of what Monad is, what the vision is, how it works, and all that good stuff. It's been an awesome conversation.
00:54:40.370 - 00:54:42.954, Speaker B: Thanks. I really, really enjoyed it. Thanks for having me.

00:00:00.440 - 00:00:33.856, Speaker A: Rust has a huge problem. It's extremely fast when executing code, but it can take eons to compile that code. This is a major pain point for developers and makes Rust the butt of many jokes. Fortunately, the Rust team has taken these concerns seriously and is on the verge of releasing the biggest improvement to the compiler to date. Rust's compiler is actually pretty great. It's renowned for its helpful error messages, which clearly tell you what went wrong, where it went wrong, and how to possibly fix it. If that's not enough, you can also add flags like explain or verbose to get more detailed information.
00:00:33.856 - 00:01:13.206, Speaker A: Developers love that. What developers don't love is long compile times. You see, to maintain Rust's very high safety and performance guarantees, the Rust compiler performs rigorous checks on your code, which slow down compilation. This is especially true for release builds, which include the highest level of optimization. When people complain about slow builds, they're almost always talking about the final release build, which is meant for production. Still, there are other scenarios, like web development with hot module replacement, where slow compile times, even for small programs, can be difficult or annoying to deal with. Slow builds eat up your personal time, and can cost you money if they're part of your CI CD pipeline.
00:01:13.206 - 00:01:53.690, Speaker A: Thankfully, the Rust team is aware of this issue and even has a dedicated working group to solve this problem. Over the last eight years, the compiler performance working group has been able to cut compile times by a factor of three by tackling some of the low hanging fruit, like adding incremental compilation and parallelizing the compiler's backend. However, many fear that the steady decrease in compile times would soon start to plateau as they racked up these easy wins. But turns out there's still room for major improvements, especially on the front end. Rust's compiler is split into two parts. The backend is responsible for cogeneration and relies on LLVM. The front end handles parsing as well as type checking and borrow checking.
00:01:53.690 - 00:02:38.544, Speaker A: As a result of a new experimental feature, the front end of the compiler is finally taking advantage of one of rusts superpowers, fearless concurrency. By parallelizing the frontend using rayon, compile times have been cut drastically on some codebases. This feature was tested on, compile times were cut in half. So how can you take advantage of this new feature in your own code? For now, this feature is only available in the nightly compiler, and you have to opt in by using a flag. The recommendation is to use eight threads, because that's been shown to give good results. Know that these results can vary significantly as some code is better suited for parallelization than others. On my M one MacBook Pro, I was able to build the Tokyo codebase without this feature enabled in about 10 seconds.
00:02:38.544 - 00:03:10.654, Speaker A: With the feature enabled, the build time decreased to about 8 seconds. Again, the results will vary depending on the code base and the hardware and operating system you use. Also, spawning so many threads, unsurprisingly means memory use increases. So make sure to benchmark your own code and see what it does for you. Overall, this is great news for rust developers. Faster compile times mean improved developer productivity, faster iteration cycles, and faster, cheaper CI CD builds. So be on the lookout for this major update to hit stable rust later this year.
00:03:10.654 - 00:03:23.180, Speaker A: In the meantime, test it out using the nightly compiler and provide feedback to the rust team. Before you go, make sure to get your free rust cheat sheet@letsgetrusty.com. cheatsheet hope youve enjoyed the video and remember to stay rusty.

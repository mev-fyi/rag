00:00:00.240 - 00:00:46.620, Speaker A: In this video, I'm going to be explaining the async await model in rust, which is extremely important to understand, especially if you're doing anything with servers. So with that said, let's jump in. In this example, we have two functions, the main function and a function I created called my function. Let's go ahead and make my function async by adding the async keyword before fn. We'll also add a print line statement in rust. Asyncawait is special syntax which allows us to write functions, closures, and blocks that can pause execution and yield control back to the runtime, allowing other code to make progress and then pick back up from where they left off. Typically, those pauses are to wait for I o.
00:00:46.620 - 00:01:30.308, Speaker A: One advantage of the async await syntax is that it allows us to write asynchronous code, which looks like synchronous code. The async away syntax in rust is similar to the async away syntax in JavaScript or C hash, with a few key differences. So let's dive into the details. This async keyword is actually syntax sugar for the following code. Async functions are simply functions which return something that implements the trait. Future output is an associated type which represents the return type of the function. In this case, this function is now returning anything, so output is set to a unit type.
00:01:30.308 - 00:02:09.206, Speaker A: Let's see what a simplified version of the future trait looks like. A future is a simple state machine which could be pulled to check if it's ready to return a value. The pull method returns an enum with two variants. Either the future is ready with a value, or the future is pending because it's not done executing. The pull method also accepts a callback function called wake. If calling the pull method returns pending, then the future will continue making progress until it's ready to get pulled again. When it's ready to get pulled again, the future will call the wake callback to notify its executor.
00:02:09.206 - 00:03:03.840, Speaker A: If you're familiar with JavaScript, futures are similar to promises, except in rust. Futures are lazy, meaning that they wont do anything unless driven to completion by being pulled. This is what allows futures to be a zero cost abstraction. Futures could be driven to completion by either awaiting the future or giving it to an executor. Lets see an example of how we would await a future. First, well add another async function called readfromdatabase which returns a string. Imagine that readfromdatabase performs some asynchronous I o by querying a database and eventually returning a result.
00:03:03.840 - 00:03:45.532, Speaker A: Let's call readfromdatabase inside my function. Here we're calling readfromdatabase twice, saving the result and printing it out. We're also adding await to each call. If I remove the await keyword, then readfromdatabase will return a future adding await to an async function. Call will attempt to run the future to completion. This is what allows us to write async code, which looks synchronous. The await keyword also pauses execution of the current future, yielding control back to the runtime.
00:03:45.532 - 00:04:23.278, Speaker A: To understand how this works, let's imagine the process of calling myfunction. Myfunction returns a future which is a state machine with three states. Imagine it being an enum with three variants. When my function is first polled, all the code in state one will execute synchronously, which is everything up till the first await point. The future will return the pending variant because it's waiting for readfromdatabase to finish. In this case, readfromdatabase returns instantly. But you can imagine that a real database query will take some time.
00:04:23.278 - 00:05:10.620, Speaker A: Once readfromdatabase returns a result, myfunction will notify its executor that it's ready to make more progress by calling the wake callback. The executor will then pull my function again, and all the code in state two will execute synchronously, which is everything up till the second await point. And again my function will return pending because it's waiting for a database query. Once the second call to readfromdatabase returns, the wake callback will be called again. The executor will be notified that my function is ready to make more progress, and it will pull my function again. On the third pole, all the code in state three will execute, which is the rest of the code. This time my function will return the ready variant because we're at the end of the function.
00:05:10.620 - 00:06:05.916, Speaker A: Now that we understand how a future is executed, let's try to call myfunction from maintain. If we try to call myfunction like a regular function, we'll get a warning which states that futures do nothing unless you await or poll them. So let's try to await myfunction. We get an error stating that the await keyword is only allowed inside async functions or blocks. So let's try to make main async. This time we get another error stating that the main function is not allowed to be async. So how do we fix this problem? Throughout the video I've been using words such as executor and runtime, but I haven't explained what those words mean.
00:06:05.916 - 00:06:53.346, Speaker A: Futures can be driven to completion in two ways, either calling await on the future or manually pulling the future until it's complete. Using await works on futures inside other futures, in other words, an async function inside another async function. However, for the topmost futures, we need some code which will manually pull them to completion. That code is called a runtime or an executor. A runtime is responsible for polling the top level futures and running them till completion. It's also responsible for running multiple futures in parallel languages such as JavaScript and C hash have an async runtime built in. However, one difference with rust is that the standard library does not provide an async runtime.
00:06:53.346 - 00:07:39.410, Speaker A: So in order to run our async code, we need to use a community built async runtime, and the most popular one is called Tokyo. Let's open up cargo toml and add Tokyo as a dependency. Well also enable the full feature to make all of Tokyo's capabilities available to us. Then we'll go back to main and annotate the main function with Tokyo Main. This is an attribute macro that allows our main function to be async, and specifies that our async code will be executed by the tokyo runtime. Let's go ahead and run our program. As we can see, our print statements were executed in order.
00:07:39.410 - 00:08:31.656, Speaker A: Earlier I mentioned that futures are lazy, meaning that they won't do anything until pulled to completion. This means that we could save the return value of myfunction, which is going to be a future, and then call away on it later on. Let's save the return value of myfunction in a variable called fdeheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheh. Then we'll add a print line statement, and finally a weight f. Let's run our program again. This time the print line statement let's get rusty online. Four in main was printed out before executing the printline statements inside the future as I've mentioned before, one benefit of futures being lazy is that they are a zero cost abstraction.
00:08:31.656 - 00:09:03.162, Speaker A: This means you won't incur a runtime cost unless you actually use the futures. Another benefit of futures being lazy is that they're easy to cancel. In order to cancel a particular future, all you have to do is stop pulling the future. So far, we're not taking advantage of our async code, and that's because everything is running serially. To make our async code run concurrently. We can use Tokyo tasks. A task is a lightweight, non blocking unit of execution.
00:09:03.162 - 00:09:40.600, Speaker A: A task is a green thread similar to a go. Routine. Tasks allow top level futures to be executed concurrently. In main, let's spawn two Tokyo tasks which will both execute my function. First well create an empty vector to store our task handles. Then well create a for loop with two iterations to spawn a new task. We can call the spawn function on the Tokyo module.
00:09:40.600 - 00:10:20.320, Speaker A: Tokyo Spawn takes a future as an argument and returns a join handle. Notice that this API is very similar to the API for spawning a thread. This is on purpose. Tokyo tries to make it easy to switch from using threads to using tasks. We're passing in an async block to spawn. As of this video, async closures are still unstable. We can use the move keyword with async blocks just like we could with closures, so that the async blocks take ownership of the variables in their environment.
00:10:20.320 - 00:11:17.232, Speaker A: In this case, we want to take ownership of the variable I and pass it into myfunction. Lets update myfunction to accept an integer, then well update the print statements to print out I. This will let us know which task is executing the println statements in my function. Then at the end of main well loop through our task handles and await them. Handle returns a result type which could be an error if the task panics. In this case, were just going to call unwrap. Before running our example, lets first simulate asynchronous IO by using the Tokyo sleep function.
00:11:17.232 - 00:12:05.520, Speaker A: First well import sleep from Tokyo. Well also need to import duration from the standard library. Then well call sleep and read from database. The sleep function in Tokyo is similar to the thread sleep function, except that it will stop the current future from executing for a given duration instead of an entire thread. With that, let's go ahead and run our program. The results you get might be slightly different, but as you can see, our tasks were executed concurrently. By default, Tokyo uses a thread pool to execute tasks.
00:12:05.520 - 00:12:51.370, Speaker A: This allows tasks to be executed in parallel. We could, however, force Tokyo to execute on one thread by changing the flavor to current thread. This will cause threads to be executed concurrently. Using time slicing instead of threads let's go ahead and run our program again. As we can see, the tasks are still executed concurrently. Note that like threads, in order to communicate between tasks, we would either need to use message passing through a channel or shared state through a mutex. Unlike threads, however, async code uses cooperative scheduling instead of preemptive scheduling.
00:12:51.370 - 00:13:22.444, Speaker A: If you have two threads. The operating system can switch between the two threads at any given time. But when you're dealing with async code, we as developers tell the runtime when a block of async code is ready to yield so that other async code can run. For example, let's look at my function. There are two points where we yield execution by calling await line 22 and line 24. This gives developers more control. However, it also puts more responsibility on developers.
00:13:22.444 - 00:13:47.400, Speaker A: Specifically, we as developers need to make sure we're writing efficient async await code. For example, we don't want to put cpu intensive operations inside an async function. That's it for this video. If you enjoyed it, make sure to leave a comment down below and give this video a like subscribe to the channel and get your free rust cheat sheet by heading over to letsgetrusty.com cheat sheet. I'll catch you in the next one.

00:00:00.440 - 00:00:31.054, Speaker A: All right, everyone, so on Empire, you obviously know that we talk a lot about the institutions coming into crypto, and that is why we are super excited to share that we are hosting the digital asset summit. We've hosted this since 2019. It's coming up in London, March 18 to 20th. Don't miss your chance to get ahead of the curve. You can get 20% off with code Empire 20. We'll see you in London. This episode is brought to you by Toku, the first comprehensive global solution for both token compensation and tax compliance.
00:00:31.054 - 00:01:02.274, Speaker A: Toku makes implementing global token compensation and incentive awards simple. With Toku, you get unmatched legal and tax support to both grant and administer your global team's tokens across the entire token lifecycle. Make your token grants easy today with Token. All right, everyone, welcome back to Empire. Very excited to be joined by Kevin, co founder of Avalanche, and Patrick O'Grady, VP of engineering at Avalanche. So, gents, welcome to the show.
00:01:02.774 - 00:01:03.766, Speaker B: Thank you for having us.
00:01:03.830 - 00:01:40.396, Speaker A: Yeah, thanks for having us. I was joking to some of the guys before this that hadn't spent too much time in Avalanche world in the last couple of months. And this podcast forced me to go deep and I will say I'm impressed by everything that's going on. There's a couple interesting acps hyper SDK, some cool plans, like future plans for consensus fee, isolation, firewood, um, warp messaging, a lot of cool stuff. I don't think we can have that conversation though, until we kind of just remind folks, like, what in the world you guys are doing. So, Kevin, I think I'll pick on you for this. Almost a too high level of a question, but, like, there's this big landscape of blockchains today.
00:01:40.396 - 00:01:47.384, Speaker A: L1 s, l two s. Why does avalanche exist? Like, where do you guys fit into this whole landscape?
00:01:48.684 - 00:02:56.354, Speaker B: Yeah. So at the end of the day, it comes down to a simple thesis that I think the market still has to play out from adoption perspective, but I think it will become, at least internally, on the engineering side, we hold this opinion. I think lots of other people actually ultimately would hold this opinion as well, even externally. And I think it will materialize in the next three to five years. But the future of blockchain, ultimately, blockchain infrastructure is extremely fast, highly optimized chains and a lot of them. The simple reason for why a lot of them is because there's just far too much potential data that could be produced by users. I mean, just back of the napkin calculation, if you were to have, let's say, I think Goon had tweeted this recently as well, just back of a napkin, if you were to have 4 billion users, and each one of those users on average produces about 100 megabytes of data per year, not even more, which is a trivial amount of data, but just back of the napkin.
00:02:56.354 - 00:04:08.740, Speaker B: And this is not actually hard to imagine, especially if you're considering NFT applications, gaming skins, all kinds of defi applications on chain 100 megabytes is nothing. But still, supposing back of the napkin, we're still talking about a amount of data that is greater than the entirety of the Facebook data lake right now per year. It's just infeasible, completely infeasible under any infra, under anything that we currently have right now, where we can possibly envision to have everything on a single chain. So the simple thesis is, okay, there is just all this data that's going to be generated from gaming to music NFTs and regular JPeg NFTs and social fi coming. There is real world tokenization of things and all the applications built on top as stacks. How do we manage all this data? Well, the simple answer is we shove as much hardcore engineering to make each chain as fast as possible under even gigabytes or terabytes of load. And yet at a certain point, everything will break.
00:04:08.740 - 00:05:14.378, Speaker B: So we distribute it horizontally. When you distribute things horizontally into their own environments, where each environment has isolation for storage, has isolation for execution, meaning its own potential virtual machine isolation for security as well, you still need a way to make things interoperate so seamlessly that at the end of the day, if you make a transaction on chain a and it has to get routed to chain b and chain C for liquidity, the end user will feel like this just happened on the same chain. There will be no visibility to the user, to the end user of what just happened. So imagine, for example, you have on chain a, you have a token that you want to swap. Token X, you want to swap from token y, you have an aggregator application. It notices that there is actually a better pricing on chains b and C. It will automatically route your asset x directly into chains b and C.
00:05:14.378 - 00:05:59.770, Speaker B: It will swap there, and then we'll reroute them back in a single transaction lasting less than 1 second. It's the gold standard, but it will make basically, you know, this global, I mean, this, this universe of many super fast blockchains look like there is actually just one single chain. It's the, it's the ultimate instantiation of sharding, even though I hate using that word, because this is not what sharding is, but it's the ultimate nirvana instantiation of sharding, basically. So I think this will become so obvious in five years, maybe a little bit longer. But let's suppose five years, it becomes so obvious. And avalanche has built all this infrastructure precisely to go towards that direction. So I think that's a very high level overview.
00:05:59.882 - 00:06:12.786, Speaker A: Okay, so go one level deeper. We've got the P chain, we've got the C chain, the P chain, the X chain, and then all these subnets. So maybe walk us through how you guys have actually set this whole thing up.
00:06:12.890 - 00:06:43.314, Speaker B: Yeah. So, Patrick, I will let you dive as deep as you want on this, but very quick high level on this. Just for a little bit of clarity. There is a bunch of, for historical reasons, there is some name nomenclature that has still stuck around that is probably not very accurate. And it gets confusing. But XPC chain and all the other chains that are currently are, whether on mainnet or on testnet, they're just chains. And at the end of the day, none of them are special.
00:06:43.314 - 00:07:11.904, Speaker B: The only one that's special is the P chain. And I'll just give you a bit of a architectural overview. XMP and C chain, totally not special. They're really just subnets themselves. There just happen to be subnets that everybody else also replicates right now. So they're global subnets. They're basically replicated across every single validator on the avalanche network, whether you're running maybe singling out like the Gonzilla subnet or whatever.
00:07:11.904 - 00:07:49.922, Speaker B: You know, other subnets don't have to run the Godzilla network, but they have to run the XP and C chain currently. But the current ACP is to remove that completely and only ultimately, everybody would have to run the P chain. And P chain really just is a metadata chain. It's a platform chain. That's what it stands for. And it's the basic, most minimal requirement necessary for us to be able to run AWM, which is the interoperability infrastructure that we have. It effectively says that if you want to interoperate all these, these chains seamlessly, we need to know at any given point what the latest set of stakers is.
00:07:49.922 - 00:08:16.010, Speaker B: That's precisely what the P chain would give you. It would also give you some ability for simple payments and transfers and so on. And of course, staking. But the most important thing is to respond to the question, okay, I'm Subnet X. I want to interoperate with Subnet Y, which are or what are the current set of stakers for Subnet. Yeah. And I need to know this because this is the only way that I can do a trustless transaction between the two.
00:08:16.010 - 00:09:00.426, Speaker B: Trustless being defined here as nothing more than the set of validators for any particular chain, like no reliance on any third parties. So that's really the architecture here. They're all just horizontal, completely flat, all separate set of validators, some interlapping, some not. And the only one that's super special is the P chain. And that one is because we need all this metadata right now. The C chain is also replicated, and that's more of just like, you need smart contract, permissionless, evm based, so you can use the C chain, but there is this ACP right now to not require the C chain to be replicated across the network and make it more niche. But that's basically the architecture here.
00:09:00.490 - 00:09:39.312, Speaker A: We'll get into that ACP in a little bit because I read that is really interesting. Patrick, maybe I'd throw this to you. When I think of what you guys are trying to build, the word that comes to mind is app chains. And I think when a lot of folks think about app chains, it was originally, it was actually Polkadot, which I think a lot of people have forgotten about now, and Cosmos. And what's happened is a lot of actually app chains have been built not in Cosmos land, but on roll ups, actually. And I'd be curious how you think about how subnets, like, compare subnets, maybe, to Cosmos and to building an app channel and roll up. Yeah.
00:09:39.328 - 00:10:25.774, Speaker C: The first thing I'll say there is, I think app chains has been a term used for a while. I prefer, I think that the industry should move towards more like using the term optimized chain, I think, for that term because I think it is a better description of really, like, what the actual qualitative experience of using them is for many of them now. Like, it's not typically like a toy, but like, some, you know, specific set of trade offs that's optimized for a use case. So apptrain sounds like kind of like a toy a bit to me. But I think on that front, that's the question we always get asked, right, is, you know, you got subnets. Right? But there's already l, two s, there's already zones, there's already parachains. There's already, you know, to use to bring back sharding, like Kevin mentioned shards, I guess, and other ecosystems.
00:10:25.774 - 00:11:22.602, Speaker C: And I would say, like, for people that aren't familiar with avalanche, it's much closer and probably closest to the cosmos world, which is it's optimized from the get go for sovereign security. So like, sovereign sovereignty all the way through. So there is no, like an l two, an attempt to try and share security from like a single base chain or origin chain where data somehow needs to be incorporated or even in some cases included in that chain. The difference being primarily that, you know, as Kevin mentioned, with having really fast but a lot of chains, the first question that comes up is like, well, great, you've now made the problem worse, right? Because you have a bunch of chain instead of like one. Like, we can't even get people to use one chain safely or easily. Like, now we got like a ton of them. So the first thing that comes up, right, is, well, how could you connect them? Or like, how could you make it feel seamless? And so the big difference there between avalanche and cosmos is cosmos.
00:11:22.602 - 00:12:09.490, Speaker C: There is no, like, mothership in some sense where like some of the registry and information is held. So cosmos zones, you know, constantly keep each other up to date with like the channel state to actually send messages across each other. And not to say it's good or bad. Like, if you're not sending a lot of messages, it's great, right? Because you have a very low fixed cost. You really only send like channel synchronization information whenever a new message needs to be processed or there's some timeout, but I'm not going to get into that. Avalanche, on the other hand, says, you know, we're willing to accept a fixed cost, aka sinking the p chain, but then have a very low variable cost. So on avalanche between any two subnets, there is no, like, it's just as expensive to send a message from Subnet A to Subnet B as it is to send a message from Subnet A to Subnet C.
00:12:09.490 - 00:13:00.628, Speaker C: But that's not quite the case in cosmos where you have a smaller set of channels because there's this overhead of maintaining channel synchronization information. Now, all that being said is to say, if you have a lot of chains, it should, you should be able to communicate with them. But I think in terms of the L two world, it really depends on your view on how security comes to be and what is required for a community to succeed. So in a world where you have no interest in creating some sort of community source security budget, an L two is a great choice for you. I won't debate that. You just want to spin up something and use e security, rely on fraud proofs or some sort of ZK mechanism to secure the chain. I totally understand that.
00:13:00.628 - 00:14:08.930, Speaker C: But there are sets of communities that have very different security standards. Maybe like let's say some of the partners that have started to use Avalanche for their subnets, like a JP Morgan. They understand that ETH is willing to provide security for NL two, but they have a couple thousand people working on infrastructure like in their own company or tens of thousands of would much prefer to provide their own security. Similarly, with a new community or ecosystem, the incentive to provide security can be quite a powerful flywheel to like get ecosystems and communities off the ground, right? If you only have your native unit of account and that's only within your community, there's clear incentive amongst everyone there where maybe it maybe is more expensive to get started, but there's a different type of flywheel than using the assets or security of a different ecosystem where you're maybe getting off the ground faster, but have to answer questions on a long term sustainability basis of how you actually, if you want to incorporate some sort of token what the utility of that is over time. Not going to get into that any deeper. I'm not a lawyer. I don't want to be a lawyer, but I think there's interesting conversations to be had there.
00:14:08.930 - 00:14:38.744, Speaker C: But my main takeaway is there's quite a spread of different options. I think time will tell in terms of what actually ends up being the most meaningful. But the two theories that I think avalanche is oriented most around is transactions fill the space that's allocated to them and within that people want to communicate between these different communities. That's our architecture in a nutshell, is based around those two core ideas.
00:14:38.904 - 00:15:09.992, Speaker B: Just to say one more thing that's very, very important. It's all about optimizing speed and efficiency between these chains. Roll ups have this problem. Well, besides, you know, the centralized sequencer, I'm not even going to get into that stuff. Putting that aside, the one thing that's really, really important, that's almost fatal at this point. You cannot do the 1 second transaction cross roll up right now. You will never be able to do that under any circumstances.
00:15:09.992 - 00:15:50.620, Speaker B: You just don't have the settlement speed that you would have from something like the avalanche network because the trust assumptions are a little bit different. That poses new challenges for the roll up operators that are really, really hard to overcome. And then on the cosmos side, the app chain thesis was probably right the way that Cosmos designed it earlier on. And I think it will in fact play out precisely at a high level in the next five years. I have actually no doubts of that. It was just that the implementation was done incorrectly. So the vision was there, but implementation was wrong.
00:15:50.620 - 00:16:25.110, Speaker B: IBC is extremely heavy, for example. It's deeply, deeply heavy. I mean, you have to carry so much information that it becomes like almost, it becomes so hard to use and so cumbersome. And just the performance of the system is significantly, I mean, outdated at this point. I don't. That's the best word I can use. And then furthermore, interoperability, I mean, the SDK, while Cosmos has a really fantastic SDK, I still think it's deeply outdated at this point from like a vm perspective and so on.
00:16:25.110 - 00:16:32.518, Speaker B: So the vision I have no doubt is going to be correct. The implementation was maybe, maybe one of.
00:16:32.526 - 00:16:55.988, Speaker A: You guys could actually expand on the economics of subnets as they relate to fixed costs and variable costs with this spectrum of, like there's cosmos, there's avalanche, and there's roll ups. Can you walk me through like the three, those three as they relate to like, some have low fix, some have high fix, some. Some. The variable scales quickly. Some the variable is minimized. Like, how do you guys see that? What is what, what does that look like?
00:16:56.156 - 00:17:46.264, Speaker C: Yeah, so I think this is another one of the bigger trade offs between like zone subnets and l two s, which is like when you're using the l two, your ability to scale there is based on how much data you end up replicating because the security comes from elsewhere. So if you want to pose a fraud proof or prove that that data was actually correct, you somehow need to store pay to store that somewhere. So inherently that data is variable cost. I think people are currently using ETH for that. Obviously the arbitrum and optimism side of it where they're putting it on chain and dank sharding and everything that's coming there should lower the cost of that. Other people are trying to do an entirely different da thing, like some of the eigen da stuff where it should be a factor lower but share some of the security properties. Not exactly as an l two, but like pretty close to it for good enough for most people.
00:17:46.264 - 00:18:44.534, Speaker C: The difference with subnets is like the subnet itself solely replicates the data. So there is no external fee rent charged by avalanche, the platform. So for people that are getting started right now, all you need is one validator to create a subnet. So right now, as we talked about ACP 13, we can go into that deeper later, but requires you to be a validator, which requires 2000 minimum of ox. But then once you have a subnet and like some set of validators there, there is no additional variable cost charged to avalanche. So in the sense, and I think the very fair critique is, well, isn't that kind of high for like a new project getting started? Yeah, and that's what the whole idea behind ACP 13 is, is to try and lower that threshold to make it more competitive with other projects that are trying to introduce this sort of like create your own blockchain scaling, you know, property.
00:18:45.394 - 00:19:09.358, Speaker A: Yes, fully understand that's a role you could say roll ups on ETH are actually low fixed to start, but high variable. They skip this, the cost scale very quickly. Obviously someone like maybe a Celestia is trying to solve this, but that's the case right now. Avalanche actually has inverse economics to roll ups where they're actually maybe high at the beginning, but the variable is decreased. Is that fair to say?
00:19:09.486 - 00:19:49.046, Speaker C: Yeah, it just has to do with where the security is sourced. If the security is external, naturally there has to be some exchange of value to compensate someone external for supporting your effort. And again, instinctively they're probably not going to do that for however much you want to do. If you want to shove like 100 megabits per second in, they're probably not going to charge the same amount as 1 mbps. So naturally there has to be some sort of scaling there. Now on avalanche with subnets there is a variable cost to the infrastructure provider. If you are processing more data you need better hardware.
00:19:49.046 - 00:19:59.166, Speaker C: But from a charge to the network itself, it's entirely controlled by the subnet. On how it wants to do that. That's the nuance.
00:19:59.230 - 00:20:26.934, Speaker B: Yeah, said maybe slightly with a few different examples. A roll up operator would have to fully pay for the hardware costs. The users would pay for the fee costs when settling everything. So they're the one carrying the actual, you know, transactional cost. But hardware cost is fully shared by the roll of operator. It can get very big. So you have to run a lot of machinery there.
00:20:26.934 - 00:21:01.804, Speaker B: Different for a subnet. You run the subnet. If the subnet has value associated with it and the rewards that are paid in the native token are valuable, there's going to be an economy of people running this chain immediately. In the same way that there's an economy of people running Ethan bitcoin and you know, everything else, there's a value to running it because you're accumulating the rewards. That's basically what it is on the subnet side. So I would probably say it's after the ACP. If it's passed, it's low cost to start at low cost to maintain as well versus anything else.
00:21:01.804 - 00:21:29.604, Speaker B: So that's at least, hopefully if the ACP passes. If it doesn't pass, then right now it's probably a little bit high upfront cost and then lower afterwards. But you can easily imagine in a situation where you run a subnet and it has its native staking token, the Yano token, and then all of a sudden everybody started validating it. You don't need to run a single piece of infrastructure yourself. It's fully permissionless. Other people run it for you and it just takes off.
00:21:32.584 - 00:21:37.536, Speaker A: I think one of the things that folks maybe didn't like who wanted to run their own subnets was that you.
00:21:37.560 - 00:21:40.708, Speaker C: Had to, I think, also become a.
00:21:40.716 - 00:22:00.784, Speaker A: Validator on the C chain. I'm going to completely botch this, but I think you have to become a validator on the C chain. Kevin, I think you wrote this piece, path to 1000 subnets, and I think you guys are thinking about relaxing the required. I'm mixing up acps, I'm sure, already, but starting to relax requirements to actually validate the main chain. What's the decision making behind this?
00:22:01.124 - 00:22:13.224, Speaker C: Yeah, so the path to 10,000 subnets was a piece I wrote kind of originally a blog post, and then turned it into ACP. But that feedback is exactly the feedback that prompted it.
00:22:13.264 - 00:22:13.632, Speaker A: Right?
00:22:13.728 - 00:23:10.026, Speaker C: People want to have their own network, their own sovereign chain. And there was a lot of confusion, first of all, like why I have to validate the seachin. That dramatically increases the amount of hardware I have to allocate to the primary network. But also from like, a regulatory perspective, some of the people that were launching subnets could not or were not able to actually validate a permissionless smart contracts chain. So these are the people, like, more of the publicly listed regulated companies that are like, okay, I get the premise of a subnet, but I don't understand how I can validate this thing and continue to actually operate the way I'm supposed to as well as great, I want super subnet scale, but that seems to be conflicting with the need to validate these other chains that I don't need really to run my subnet. And so that was the culmination of a ton of community feedback on the way that people felt the avalanche network should evolve. And in a nutshell, idea.
00:23:10.026 - 00:23:54.326, Speaker C: And then I'll turn it over to you, Kevin, to elaborate on any aspect of it is really the only thing that's needed from a ability to run a subnet or operate a subnet is, as Kevin mentioned earlier, this knowledge of the staking sets. So like, what is your staking set? As well as what is the staking set of other people to verify? Warp messages. And all of that, because of the original design, is contained on the P chain. So really all you need to stake is like verify or synchronizes the P chain. You can't fully validate it because you can't. There are like transitions of transactions between the X, C and P. And if you don't verify stuff on the c and x chain, you can't properly fully verify the P chain.
00:23:54.326 - 00:24:27.410, Speaker C: So you still have to trust the consensus of the primary network to sync the P chain. But the idea is it will dramatically lower the actual cost to run a subnet from an infrastructure perspective. Then from there, because you're not a validator, you don't have to put the 2000 evox up front. And that ACP goes into some ideas of different ways that subnets could work with the primary network, such that there's still this deep connection between the two, even though subnet validators are not primary network validators. Got you.
00:24:27.442 - 00:24:44.494, Speaker A: So you're basically introducing this new type of stake, or I think you called them subnet only validators, where you can validate, express Subnet and participate in all the new things like Avalanche, warp messaging, awm, but you don't have to sync back to the primary network, is that right?
00:24:45.154 - 00:25:28.660, Speaker C: That's correct, yeah, you don't have to validate it. You're basically saying, I don't want staking rewards from the primary network, I don't want to run the X and the C chain. I just want the benefits that the P chain offers, which is securing my stake and letting me basically operate warp messaging. And in return I will use this new staker type. So not mandatory. You could still do both if you wanted to, but we expect many folks to do this. But the outline from there goes into how things could even be better with pay as you go staking, which basically sets a market for how people join and become subnet participants based on the capacity of the primary network.
00:25:28.660 - 00:25:58.988, Speaker C: And then Avox augmented security, which is, well, now there's this disconnect between avalanche, the primary network, and what it can offer subnets. And so the idea with that is that people can use avalanche to bolster the security of a subnet. In the first, probably well elaborated intent to have some way to share or provide help with security as a network is small. We can go into that later if you want to, but there's a few different before going into that I mean, yeah, before.
00:25:59.076 - 00:26:24.454, Speaker A: So actually something Kevin said made me think about, so I actually didn't. This is gonna be a really show. Show how left Bell curve. I am here on avalanche, but I didn't even realize the P and x chain were just like these global subnets. But it makes me think about what the end vision for subnets are. And I think there's probably two worlds here. And I'd love to hear maybe, Kevin, your vision for this one world is there's millions or tens of millions or hundreds of thousands of subnets.
00:26:24.454 - 00:26:43.474, Speaker A: Eventually. Another version is you basically have these big global subnets that are. Maybe there's the gaming subnet or the DeFi subnet or the NFT subnet. Which one of those versions is more correct with your vision of the future?
00:26:45.294 - 00:28:13.506, Speaker B: Right? Maybe differently said is whether or not there's going to be only a couple of big subnets or a lot of, like, smaller subnets is not the question to ask. It's more of like, regardless of what happens, how can we minimize as much as possible overhead of launching new blockchains that interoperate basically, you know, as, as minimally as possible, like, reduce those requirements minimally as possible. And it comes down to basically this ACP that Patrick is talking about, which is get rid of the seaching, get rid of all these, or reduce the amount of stake for validation. And at that point, just let the market decide what it wants to do. But if we get to a position where we are having billions of users, and if we're getting into a position where these users are producing data that is comparable in the dozens of megabytes or even hundreds of megabytes per year, there's just no way a single chain can ever handle this full stop. So there's no doubt in my mind that the only proper architecture for the next five years or so is multiple of these. And so the question is, what is the absolute bare minimum required architecturally to make all this stuff work as easily as possible? And that's effectively what is being designed here with AWM, with the new acps that are coming in, the only bare minimum here is the p chain.
00:28:13.506 - 00:28:28.734, Speaker B: Everything else is optional. And optimizing the living crap out of these chains in terms of performance, in terms of cross chain interoperability, in terms of flexibility for developers, and just let people go wild with all this tooling.
00:28:31.114 - 00:28:53.264, Speaker A: We can switch gears a little bit and talk trade offs. There's no, there's no perfect blockchain. Uh, everyone's got a trade off, right? You could, uh, you could have higher performance, but you're probably trading off some flexibility of smart contracts, right? You could increase throughput, but you're gonna probably raise the requirements for hardware as we've seen other, other folks make that decision. What is the trade off that you guys have decided to make?
00:28:53.804 - 00:28:56.188, Speaker B: How dare you say a trade off? There's no trade offs.
00:28:56.276 - 00:28:56.892, Speaker C: No trade offs.
00:28:56.908 - 00:28:58.224, Speaker A: You guys have solved the trial.
00:28:58.644 - 00:29:28.596, Speaker B: No, no. Look, we'll be very straightforward with everything you can increase the blockchain. I mean, the hardware size, you know, probably there's gonna be ACP. Increase the blockchain, the hardware size as well for, for avalanche. At the end of the day, just very quick, back of the napkin. The data that I'm selling you at that particular volume, you can't have it even under the most hardcore block hardware out there. You do need to replicate things or you do need to separate things horizontally across multiple blockchains.
00:29:28.596 - 00:30:11.434, Speaker B: Fault isolated. Performance isolated. So, you know, what are the trade offs for avalanche? I mean, the trade off is fundamental in the building of a distributed system. I don't think there is necessarily a trade off of avalanche versus other blockchains. It's more of just like, is there a trade off to using a blockchain at all versus not using one? And you're just using a database. If you want to use a blockchain and you want to replicate things and you want things to be distributed and you want other people to replicate this data and make it persistent for a very long time, you're going to fundamentally have an immediate trade off in performance, in scaling and so on. That just running on a data lake on AWS will not give you that.
00:30:11.434 - 00:30:51.350, Speaker B: But then again, that's fundamentally what it comes down to from a trade off between avalanche versus the other ones. I'm just totally being honest right now. Let's think through it algorithmically. Probably the fastest one right now in terms of time to finality. There is some trade offs in terms of latency that we're working through and optimizing one of the fastest, if not the fastest in terms of time to finality in terms of storage and hardware requirements. You can increase this as much as you want. It's just really a question of will the community accept this insanely high hardware requirement? Maybe they do.
00:30:51.350 - 00:31:59.786, Speaker B: That's great. So that's not really a trade off in terms of database stuff and all that hyper optimizing the living crap out of those as well. And in terms of the interoperability protocol, almost certainly between IBC, CCIP and AWM probably by far the most efficient across all of these in terms of maybe the trade offs might come in the form of, oh, I don't want to necessarily bootstrap my own security, I want to rely on ETH security. But then again, why is ETH secure? It's really ultimately comes down to private key management. So maybe that's the trade off between a subnet versus an L two, but I'm not exactly sure that's necessarily a good one. So the question to be asking here is, if I'm a gaming developer and I'm building secondary market for my gaming skins, do I do it with a blockchain or do I not do it with a blockchain at all? That's the really the trade off question. But then, otherwise, if you're.
00:31:59.786 - 00:32:18.034, Speaker B: If you've already been sold on the benefits of tokenizing everything and making them available on an open network of blockchains, then I don't think you have any trade offs here with other blockchains versus avalanche, at least now that I can see if that are obvious to me, at least. So that's the TLDR I see three.
00:32:18.114 - 00:32:38.978, Speaker C: If you want to talk about those. I think. I think the three, like, first one is like, I think the benefit of like that we get for messaging comes with having this p chain, right? Like, so some people would argue that they don't want to have like this kind of registry train. Like a cosmos world, right? So they only have point to point connections.
00:32:39.066 - 00:32:39.338, Speaker A: Agree.
00:32:39.386 - 00:33:06.020, Speaker C: So there's like something. Something that, you know, it's, again, a preference choice. The other one is, I think, the security topology. So none of avalanche is like, virtual machine designs are meant to be provable on the primary network at this point. You could certainly go down that direction if you wanted to. But it's a very different goal than maybe some of the other groups that are trying to balance dev. And then the last one is flexibility, kind of an extension.
00:33:06.020 - 00:34:05.824, Speaker C: There is like we are trying to achieve, like this multi vm world on Avalanche, where you may spin up a wide collection of different things. And inherently, when you have that, communicating between, like, really flexible vms can be challenging, right? So some of the L two designs, for example, like, I think there's the super chain packed or manifesto that optimism is pushing is like to have a single, like, kind of base. Same thing with Zksync. They want to have everyone have the same core ZK module. And what that allows is like easier integration between the seat, like the different chains that are being sequenced and so we have felt that the more important aspect there is to like, really optimize how broad you can go in the crypto design space and accept maybe more flexibility at the cost of maybe having some of the interoperability between those virtual machines be a little bit more difficult to manage. So I think from a technical perspective at least, those are three clear trade offs that I think we've made.
00:34:07.284 - 00:34:43.246, Speaker A: All right, everyone, so we talk a lot about the institutions coming into crypto on empire. Santi and I are both headed out to London March 18 to 20th for blockworks 8th ever digital asset Summit. Das this is an institutional buttoned up conference that we've hosted since 2019. I like to joke that it is probably the last remaining kind of suit and tie event in crypto. People are still wearing suit and tie. It's pretty funny, but you'll actually hear from a lot of the largest institutions in the world coming from standard Charter FIS, JPMorgan framework folks coming out. Wintermute Vanek Goldman Sachs there are a couple big themes of this conference.
00:34:43.246 - 00:35:08.414, Speaker A: One, bitcoin catalysts, the halving and the spot ETF. Two, a view from the buy side. Three, Rwas tokenization and stablecoins. Four, global regulatory frameworks five, institutional infrastructure, including banking and payments and six, the macro case for crypto. If you have anything to do with the institutional side of crypto, you have to be there. Santi and I got your back. We've, we hooked, got you up with a 20% off code.
00:35:08.414 - 00:35:54.370, Speaker A: It is empire 20. There is a little competition running internally at blockworks to see who can drive the most number of tickets. So help Santi and I out register with our code and you get 20% off. That is empire 20. This episode is brought to you by Toku, the first comprehensive global solution for token compensation and tax compliance. If you say yes to any of the following four questions, Toku is a no brainer solution for you. Number one, are you planning to launch a token? Number two, is your token already live? Number three, are you currently granting your employees or contractors vesting token awards? And number four, are you trying to figure out how to take care of taxable token events for your team? If yes, you have to get in touch with the Toku team.
00:35:54.370 - 00:36:33.960, Speaker A: Toku to high level makes implementing global token compensation and incentive awards simple. You get unmatched legal and tax support to both grant and administer your global team's tokens. Toku navigates this across the entire token lifecycle, from easy to use Token grant award templates, through tracking vesting to managing tax withholdings. Toku makes it simple for leading companies in the space, including protocol Labs, DyBX Foundation, Mina Foundation, Hedera Gnosis, Safe, Gitcoin, and many more. Reach out to Toku. That is toku.com empire, Toku.com
00:36:33.960 - 00:37:07.376, Speaker A: empire. Click the link in the description or dm me on Twitter and I'll get you connected to the team. What do you guys think about when you see these new as like the industry has branded them next gen chains like the, you know, whether it's a monad or a Sui or Apdos, they've made some they're very interested in interested in like I guess Max throughput is what I'd call it. What are the mistakes that you guys have probably gone through and made that they maybe don't realize that they're going to have to make or that they might fall into soon?
00:37:07.520 - 00:37:13.336, Speaker B: Oh, let me, let me get into this more real quick. So, so the Kevin just like cracked.
00:37:13.360 - 00:37:14.744, Speaker A: His fingers, stretched his back.
00:37:14.824 - 00:38:06.360, Speaker B: No, I'm not, I'm not going to talk negatively at all, because they're all actually doing, doing lots of great stuff. Parallelizing the EVM is good work, although there is arguments on whether or not the EVM is sustainable long term. Honestly, in 510 years timeframe, are there maybe better virtual machines? Arguably, yes. So maybe that's a different conversation. But at least for the EVM, parallelizing it is a good endeavor. The thing is, we actually have an enormous amount of data on where a lot of the bottlenecks are like real world data, from networking to execution to block propagation and then storage and memory and so on. The parallel execution is not even remotely a bottleneck.
00:38:06.360 - 00:38:47.944, Speaker B: It is a bottleneck when you have an empty state. So if I launch a new blockchain and there is no state and the database is empty, then I start bombarding you with transactions. Indeed, you could run into the problem where parallelization is actually really nice. As you start scaling up the amount of storage that has been used up by the chain, you will very fast like so quickly find that it's not even room. Like it doesn't even come in the same zip code as the overhead of actually just writing and not reading, but predominantly writing the data to disk and then managing it easily. So it's still a huge problem. It is a completely unsolved problem, even algorithmically, let alone implementation wise.
00:38:47.944 - 00:39:07.268, Speaker B: How to actually manage active state long term. The one answer that is obvious is to separate it logically between multiple different kinds of applications. That's exactly what subnets are doing it's a form of sharding. But I want, I do not want to use that word. So do not confuse that with, you.
00:39:07.276 - 00:39:08.704, Speaker A: Guys really hate that word, huh?
00:39:09.524 - 00:39:56.584, Speaker B: It's just not, it's not the right word. But, but yeah, so, you know, it's just not the bottleneck right now. It's ultimately, it all comes down to at some point, it will grow. Like, the state will grow very big. How do we manage that? So that's a problem that Solana will run into very soon. ETH probably will not run into that problem anytime soon purely because they have parameterized their blockchain to currently not have storage as the bottleneck, but to actually have the consensus be a bottleneck, meaning that, like, they literally just tuned it all the way down to whatever the TPS is at max capacity. And that's because they're just trying to throttle and avoid going into like, the state blow up issue too fast.
00:39:56.584 - 00:40:12.964, Speaker B: But if you don't have that otherwise, you know, if you remove the artificial bottleneck that has been implemented in Ethereum, then ultimately over a long enough period of time, storage always becomes the bottleneck. So all these other things being optimized.
00:40:13.044 - 00:40:13.548, Speaker C: Great.
00:40:13.676 - 00:40:20.268, Speaker B: And we can probably use a lot of this research directly into avalanche, frankly, but it's just not the bottleneck right now.
00:40:20.356 - 00:40:45.924, Speaker A: Yeah, we can get into some of the things that you guys are working on going into 2024. There's hyper SDK, there's some fee isolation stuff. I saw goon had this post about Avalanche go, which seemed pretty interesting, though a little over my head, technically. There's firewood. There's warp messaging. Where do you guys want, what's like, the most interesting in your mind?
00:40:47.744 - 00:40:52.004, Speaker B: A lot of it is really interesting. Patrick, what are you thinking? Where do we want to start here?
00:40:52.384 - 00:41:50.272, Speaker C: So I think it makes sense to start with the stuff that is closest to use, I think for the average person in the avalanche community. And I think that probably starts with Warp. For those that aren't familiar with it, we keep saying warp, warp, warp, warp. Right? Like it's this cross subnet messaging protocol. It actually has been out since last year, actually, like winter of 2022. But the issue is that we like adopting it to work well with the EVM has taken time. And so finally, after what has been about a year of development, we have a protocol adaptation of warp that is part of the EVM and then wrapped in something called Teleporter, which is like a smart contract interface that will let people take assets from the primary network like Avalanche or any ERC 20 and bring it into a subnet using this warp protocol.
00:41:50.272 - 00:42:37.880, Speaker C: And so people have heard about warp, but they actually haven't used it yet. So what this will allow people to do is easily bring assets between the two without having to rely on a, you know, a third party bridge operator. So from like a what can I soon use on avalanche that will totally change how everything works. Like that is going to be a big one for folks. And then from there, you know, once we have like a credible path to actually having these things communicate with each other, a lot of the work just goes into performance. So like, you know, no one's happy with like ten or 100 tps on the c chain or on any of the subnets. And so like, how can we entirely change how that's done? And then, which is obviously quite an engineering feat as a lot of other teams have also seen.
00:42:37.880 - 00:42:41.472, Speaker C: And then the other one being, yeah, I'll pause there.
00:42:41.528 - 00:42:59.474, Speaker A: Yeah, I just have some questions on warp message. So like what sets awm and teleporter apart from? Someone asked us on Twitter and I thought it was a good question. Apart from the likes of IBC and Axelar, when it comes to trust minimized bridging and liquidity access.
00:43:01.014 - 00:43:29.542, Speaker C: Yeah. So first off, kind of describe a bit about warp and so the mechanism of what it is. And so as we mentioned before, there's this p chain, this registry chain. Validators on any subnet will register a special key, a BLS key. In this case, not important. And what will happen is when they message with each other, the validators in a particular subnet will stein that message. And then once you have so many of those signatures, you can aggregate them into a multi signature.
00:43:29.542 - 00:44:11.148, Speaker C: This is similar to like what ETH two does with validator attestations. And you can take that multi signature and bring that to a destination subnet and it can verify it. Now, the key there is in that verification step on the destination subnet is where a lot of these things differ. So on avalanche, the verification works as the subnet says. Hey, who are the validators on the subnet that's messaging me? I'll go ask the p chain. The P chain tells me what the stake weight was and their keys. And I can see that the message that they send me, was that valid from my parameterization of is it a subnet I want to listen to messages from? And is there like a substantial amount of stake that has signed it? That's avalanche.
00:44:11.148 - 00:45:15.750, Speaker C: The difference with Cosmos is an IBC generic messaging format. Theirs is pretty geared towards like Cosmos SDK interoperability, but it doesn't need to be. And the way they do it is they're constantly synchronizing the signers between two zones. And so that when you verify a message on a Cosmos zone, you're looking at like that chain's channel and record of the validators and then looking to say, okay, is this message valid? So they have like a local record on their zone, but they're not like asking some external chain, in a sense, like they have records from that external chain that they internalize. Axelr is just a multi signature similar to Thor chain, which is that they have some set of validators that produce like typically some sort of threshold signature, where as long as that threshold signature exists, all you're doing on chain is checking the cryptographic validity of it. But you're not like looking externally to say like, oh, someone out of stake signed it or something. Now, they all have different properties, as I've mentioned, but that's the big difference between the three.
00:45:15.750 - 00:45:42.624, Speaker C: And again, is there a perfect solution? Well, it depends on your preferences, right. The cryptographic solution Axelar has is super generic, right? You don't need to be within avalanche or anything like that. You just have a signature that I can verify on bitcoin or I can verify on Ethereum. Ethereum, as long as it can verify, the signature doesn't care where it came from. So that would be one example of something that's interesting trade off. Like warp works really well within avalanche, but not out of avalanche.
00:45:43.084 - 00:45:56.224, Speaker A: So, okay, so Warp solves the need for cross chain communication between subnets. Will you guys, will you guys launch like, native solutions to communicate from avalanche and from subnets to other chains?
00:45:56.804 - 00:46:34.534, Speaker C: So this is one that will be possible in the future. But what it requires is synchronizing, like the stake that's on the P chain with other chains. Because the validity of warp relies on checking signatures against that staking set. What would have to happen is the p chain would somehow have to produce some sort of signature that could then be imported by ETH or imported by something else. But there's inherent limits on some of the chains capability to do that. We couldn't import that data into bitcoin, for example. Warp is probably never going to be compatible with bitcoin.
00:46:34.534 - 00:47:26.884, Speaker C: So similarly, ETH, at least on the execution layer, doesn't support quick verification of BLS signatures. So it'd probably be really expensive actually to integrate it within Ethereum. The idea I think we've gone for so far is like, sure, that like, as I mentioned, there's this like broad spectrum of different cryptography could be used for this. We really wanted to pick the one that we felt like was best within Avalanche and make sure that that was really, really good and optimal for that. And then in terms of external bridging, discuss that once we felt like within Avalanche there was a great bridging story which hasn't been the case yet because teleporter and some of the EVM adaptation to warp hasn't really rolled out yet. But I think following that, if we really see great adoption of that, I think there'll certainly be a push to understand how you could bring that technology out of Avalanche. But to me, that's really like running before you walk, in a sense.
00:47:26.884 - 00:47:27.906, Speaker C: Yeah.
00:47:27.970 - 00:47:29.494, Speaker A: When does this go live, Patrick?
00:47:30.794 - 00:48:01.574, Speaker C: So we have actually a demo website you can go visit called omywarp.com. I don't go with the name. It's hilarious where you can go move assets between different subnets. But we're targeting, it's up for ACP review right now. But the hope would be that at least on Fuji, which is our testnet, that it would be activated by the end of the year so people could actually play around with it. So very soon is the answer to that. And then if Fuji goes well as a testnet, then Mainnet could be a few weeks later if the community decides to go with that.
00:48:02.034 - 00:48:24.000, Speaker A: Nice. Okay, so that, okay, so warp solves subnet to Subnet communication. What about Hyper SDK? My understanding of Hyper SDK is it's basically like the first of many future frameworks that will help make it easier and faster to basically launch your own blockchain on a subnet, I think. Or launch your own subnet.
00:48:24.032 - 00:48:27.764, Speaker C: Do you need it? Do you need a job? That's a better description I've probably been giving people.
00:48:28.184 - 00:48:28.964, Speaker B: Yeah.
00:48:29.504 - 00:48:57.324, Speaker C: Like, so the hyper SDK. Yeah, I mean, long story short, you want to create your own blockchain. And you, like most people these days that you mentioned these like, next gen chains that are targeting high throughput. You know, you want high throughput, but you want it to be your own chain. You want to use your own token or whatever. And the most common subnet, if not the only subnet people have deployed on avalanche so far is EVM based. And there are just certain decisions made there that are not competitive with something that's like this super high throughput.
00:48:57.324 - 00:49:22.628, Speaker C: And so at that point, what do we tell people? Either, like, avalanche isn't the one for you, or like, we don't believe high throughput is possible or whatever, right? Which is none of those are true. And so it's just clear that there needs to be some sort of avalanche oriented and avalanche optimized framework for building chains. And that's the hyper SDK. So that's what I spend most of my time on is getting that to a place where we think it's really competitive with other of these.
00:49:22.716 - 00:49:33.196, Speaker A: So if your Dax or a game or something like that, instead of focusing on like all the complexities of basically doing this, you can get 500 lines of code, set up your own. Set up your own blockchain.
00:49:33.260 - 00:50:18.686, Speaker C: Yeah, so the idea that we also. Yeah, exactly. So the idea that we also are trying to really drive home is, and we've learned this now that we have like three chains on the, on the main network or the primary network we call it, is the maintenance of like having like, of these virtual machines is massive. And you can talk to anybody about like just look at the version spread of people that have like zones or parachains or whatever. Like there are some people that like, once it's up, like don't fix it if it ain't broke sort of situation. Right? Like, and so the HypersDK wants to give you a lot out of the box, but make it easy to, you know, keep up to date with changes and so only exposes things that it feels like you really need to manage. And that's the whole point of the multi framework, which is to say HypersDK is an opinionated way to do this.
00:50:18.686 - 00:50:44.624, Speaker C: On avalanche. Is it the only way? No, like we have seen other people building on top of subnets, like movement, for example, where they have like a move dialect as part of the framework for launching a chain. And like some people just want that, they just want to use move, right, but like it makes move and aptos derivative specific ways to scale. And the hyper SDK takes a very different approach, so. But the idea is to give people a framework for scaling.
00:50:45.484 - 00:51:28.556, Speaker B: To me it's like, it's not just the complexity of maintaining and building your own stuff. Like for example, building your own roll up and you know, whatever happens in the future and maintaining it and so on. It's also just, you also need like to update with the latest in optimizations and everything, which can be a nightmare. It's really, it's not something that most people will even want to do. Instead you just kind of borrow what the best engine is out there, let the development cycle make it faster and faster over time, and otherwise just focus on building your own thing. It's the equivalent of, you know, if you have a web, if you're building a web website, some web app. But instead of just worrying about building the web app, you also worry about building your own web browser.
00:51:28.556 - 00:51:38.684, Speaker B: It's impossible. It's just not something that anybody would ever want to be in a position of. The web browser is Avalanche. You worry on the web app, which is what everybody else would want to worry about.
00:51:40.584 - 00:51:52.044, Speaker A: Zooming out from the technicals for a second. Kevin, I have a question for you about just applications and working with other founders in Avalanche. What's been the hardest part about getting people to build on avalanche that you maybe didn't expect?
00:51:53.344 - 00:52:31.034, Speaker B: I actually probably not the best person to ask this. I don't deal a lot with this kind of stuff. Most of these days are just technical things. I think frankly, a lot of the, you know, a lot of difficulty right now is just on these last few things that are still left in order for the full avalanche framework to be done. We still don't have, for example, c chain based tokens available as native tokens for other subnets, which is something that is an important one. There's a couple of things for AWM that are still not done. ACP 13 has not been pushed yet.
00:52:31.034 - 00:53:08.618, Speaker B: So this vision that I mentioned at the very beginning of the podcast is something that is probably going to materialize within about a year. But it's still not there yet. And it's a big pain point. But otherwise there is also a lot of noise around what others are building and you have to differentiate yourself. But I think that's kind of ultimately pretty easy. I think once the next set of performance tests come in and we show that like you can get 250 millisecond on the sea chain type of thing with avalanche and blow the second best competitor out the water as well. I think it will just speak for itself.
00:53:08.618 - 00:53:11.894, Speaker B: So, yeah, it's just a lot of hardcore engineering work.
00:53:14.554 - 00:53:23.364, Speaker A: Good infra is usually informed by good applications like what if? What? Yeah, how's that impacted, like the avalanche vision?
00:53:24.864 - 00:53:58.574, Speaker B: Really good question. So the very biggest, the very first thing is, you know, I want to run an application or whatever and I want to be making sure that like nobody else is competing with me. I just don't want this to be on an open permissionless chain in the same way that, for example, the seachain is. That informs a lot of institutional applications as well. This does not mean they're necessarily permissioned. They just don't want the seachain style permissionlessness. They want more control over things.
00:53:58.574 - 00:54:32.196, Speaker B: It does not mean that it's closed either. It's fully open. You can work with it, you can play with it, but that's a huge one. And so that's precisely actually the one solution that subnets provide that nobody else provides. There is a lot of, of course, feedback around fees and fee isolation being a very important one. Solana does actually not do fee isolation, despite them saying do fee isolation. They just divide things between four cores, but they're not actually dividing any smart contracts on their own little environment.
00:54:32.196 - 00:55:02.204, Speaker B: That's something that we're working on that's very important. With hyperdimensional fees. We're designing SDKs with hyper SDK to literally allow you to provide or to specify fees per operation code. So like writes, for example, much more expensive than reads. So very fine tuning, and that's feedback that we've gotten. So the ability to manage in environments better, the ability to specify fees more dynamically and more precisely. Speed always comes down to speed at the end of the day.
00:55:02.204 - 00:55:25.088, Speaker B: So hyper optimize on being the number one in terms of speed, time to finality the number one in terms of overall TPS. Although TPS is largely a function of hardware as well. But I don't see a reason why Avalanche can just also boost its hardware requirements up. But yeah, that's just a hardware thing.
00:55:25.216 - 00:56:14.924, Speaker C: First off, I think the community's been great. Anytime you have a whole new community or a new project, there's definitely some people that are, you know, the pioneers, right, exploring, exploring it for the first time. And I think like DFK and Cravata, for example, were two that really explored subnets for the first time and made them a lot better for, you know, everybody. I think my main takeaway from this has been a lot of people are targeting a very specific niche of the crypto design space, which is massive and largely untouched because I think a lot of people are just familiar with that. They're like, you know, bundled sequencing or bundled replication, sequencing, execution. Like, you know, very specific paradigms for like, running code on chain. And I think, like, the feedback we've gotten from builders and I think Solana and some of these other ecosystems would eco.
00:56:14.924 - 00:57:24.794, Speaker C: The same sentiment is some of the builders coming in are like, we have no idea what you're talking about, and could literally care less how everyone else has done it up to this point. Like, the things that we care about are this, you know, I want to be on a blockchain because it provides sovereignty to the people in the community that I'm with and I can do things that I couldn't do by having this, like, shared state and shared computer. And when you look at, like, the design of infrastructure from that higher level perspective, it really makes you question, like, some of the core ideas that, you know, bitcoin brought on the table, but, like, may no longer be important to some of the builders, especially if you can launch your own chain or launch your own community where you can really play around with some of the trade offs there, as you mentioned earlier. So I think that's the thing that at least excites me most about the space is, like, a lot of the community, people aren't saying, like, I just want to do the same thing as everybody else. Like, give me another one. Right? Like, it's a lot of, you know, you're telling me all these things are constraints, but, like, you're basing it off of this assumption that, you know, I really want to mirror what a lot of other people are doing. And frankly, this is what my application is, especially large enterprises.
00:57:24.794 - 00:57:43.714, Speaker C: And I know you're saying that this is how it's always been done, but, like, that's just not good enough or just not something I'm interested in. Like, I'm willing to do this instead if that means that I can have my shiny, like, higher throughput or, you know, more flexible computing surface. And so, yeah, it's been great to engage with a lot of really great, great engineers in the space.
00:57:45.174 - 00:58:09.114, Speaker A: It feels like avalanche is when I'm switching gears here, avalanche is winning the institutional game. And I think part of that is due to, I mean, you guys have a really good team, like Morgan and John, and obviously all the way to the top. Like, you know, John, John two Johns over there and Morgan obviously are doing a great job. But what about on the technical side? Why do you guys think that folks, like, whether it's a KKR or JP Morgan, like, why are people choosing avalanche?
00:58:10.494 - 00:58:38.918, Speaker B: It just goes back right to what Patrick said that, you know, if a KKR and so on comes, you know, with their developer team and, you know, where can I develop? And then somebody says, well, you should develop on Ethereum because of this. They're just going to blink, blink. They'd be like, what are you talking about? Like, I'm going to need much more customizability on all this kind of stuff. I don't care about what the narratives are. I want customizability. I want ability to manage these things a lot more, you know, more, a lot more fine tuned way subnets provide you basically. Exactly that.
00:58:38.918 - 00:58:59.672, Speaker B: That's what effectively comes down to. You can do basically almost any of the applications that are possible or that are, that come along with the institutional side with anything but subnets. So, I mean, I don't know if Cosmos could do that as well. I don't know if it's mature enough at this point, but yeah, that's what it comes down to, I said, in.
00:58:59.688 - 00:59:54.154, Speaker C: Like, roundtables with some of the technical contributors from like, some of the larger, like, enterprises and institutions, right. They obviously want to understand the technology they're playing with, and they bring up conversations about, like, you know, what are the different options here? And when it comes down to it, like, whether or not the crypto community wants to accept it or not, like, some of their needs are very different than what I think we hope their needs are. So, like, from the outside looking in, it's like, oh, they're adopting crypto and, like, really leaning in because they want to be more decentralized. That's actually very much for them. Not a consideration or even something that they're looking to do. They're very interested in the way that it allows them to better communicate and interoperate with partners and other people even within their own company. You have massive lines of businesses and many of these multinationals that really operate as separate companies.
00:59:54.154 - 01:00:36.264, Speaker C: They want to find better ways to interact or offer more value to their customers. But they often feel like their customers aren't asking, hey, can we put, you know, bank, large bank a like, and just tear down all the walls? And, like, that's not their intent. And so I think a lot of Avalanche's architecture imposes, like, very little belief or constraint on, like, what you're doing. Like, if you really want to run it with like, a subnet with ten nodes in your own data center, but then you have interoperability with other subnets. You can do that. You can even run it privately, right? Where, like, other people can't even connect to your subnet. They don't even know what virtual machine you're running.
01:00:36.264 - 01:01:22.048, Speaker C: That's all possible. And for a lot of these enterprises, they're interested in moving on chain, but at a speed they're comfortable with. And they're interested in this public private trade off, which subnets, again, let you do via this warp thing where there is no proving on the warp message, for example, of the state of another chain or something like that. So they don't actually have to communicate that state externally because they very much may not want to, but they can still issue messages externally. And if you trust that subnet with what they're doing, that's totally fine. So all I'm saying is I think the needs of some of these enterprises and financial institutions don't map to our expectation of what they are. Maybe someday they will, but right now they don't.
01:01:22.048 - 01:01:37.074, Speaker C: And so they see value in the technology. And avalanche, I think because of its flexibility, allows you to use the technology in the way that they want to. Whether that's the way everyone wants to, probably not. But in some cases for enterprises, they just want very different things.
01:01:38.254 - 01:01:58.998, Speaker B: Yeah, this is super key. And maybe it'll be clear in a couple of years, but maybe it seems controversial right now, but you gotta, you just have to design for things that are as unopened as possible. And that's effectively what avalanche is trying to optimize.
01:01:59.086 - 01:02:01.158, Speaker C: That was the word I was looking for. Unopinionated.
01:02:01.206 - 01:02:18.038, Speaker B: Yeah. It does not try to opinionate on, no, no, no, JP Morgan, you should do it on l two because it. Listen, it shares the security of the theory. What? No, like, they know what they need. They know what they want. They want to, you know, tokenize. They want to be a part of the network.
01:02:18.038 - 01:03:02.900, Speaker B: They want to provide liquidity for the secondary markets, whatever, but they want to do it on their own terms. So if you're building a blockchain network, you got to do it in a very unopened way. You just got to make technology that is extremely fast, best in class SDKs that are extremely unopinionated but very powerful and just let you spin up things and then otherwise, you know, do not get in the way. You know, I think Avalanche becomes this Os which doesn't just, just does not get in the way in any way. Like this blockchain Os, basically where you just deploy things, you run things and then just kind of spin up and work. And otherwise developers get their full flexibility and they don't need to worry about future optimizations. They just kind of come for free by just being part of the network and then otherwise focus on their restrictions and their applications.
01:03:02.900 - 01:03:06.340, Speaker B: That's really like why this design is so compelling, ultimately.
01:03:06.372 - 01:03:51.394, Speaker A: Yeah. How does everything that we've talked about in the last hour impact the value accrual of Avax? Like for one, something that comes to mind is we're talking about removing the necessity to validate back to the c chain. So right now I think the way that it works is more subnets that you have means more Avax is locked because every validator needs to stake to validate this ties down supply. And I think I read that all fees on the primary network get burned, or at least some of them. If this new ACP gets put in place. This would actually probably hurt the value accrual to Avax, but it actually makes it more attractive to developers, which I'm assuming is a conversation you guys had internally. How do you think about this?
01:03:51.904 - 01:04:00.360, Speaker B: But Patrick, I'll let you add, but I'll just give it my quick opinion because I think this is one is a very subjective one and everybody has their own different opinion. Unlike, you know, engineering, which is just.
01:04:00.432 - 01:04:04.944, Speaker A: Making the fish as much about the narrative as it is about the technical.
01:04:05.064 - 01:04:34.282, Speaker B: Yeah, it's very subjective. So to me at least I actually sounds maybe controversial, but I don't necessarily think at all about that. I just want to build infrastructure that just feels like. Like basically you don't even have to worry ever about blockchain scaling. It just kind of works. And yes you do as you remove things because you don't want to get in the way for developers. You do remove requirements for a box.
01:04:34.282 - 01:05:07.352, Speaker B: I don't necessarily think we're just trying to build technology here that will scale up so easily for the future. I don't think any of these other things are necessarily, to me at least worth like concerning yourself with. There's still use cases for a vox that are obviously important. It is a central hub for the P chain. It is essential hub for the c chain. It's essential hub probably for a lot of. When I say hub, I mean like the token itself is a central liquidity provider for a lot of different applications.
01:05:07.352 - 01:05:27.596, Speaker B: But so will USDC. So will USDT potentially. I just think that if you are an engineer and you're thinking about value accrual, it's probably almost certainly a recipe to design a system that will hurt developers and will hurt usage down the line. I think as engineers it's probably our number one priority.
01:05:27.700 - 01:05:28.164, Speaker C: Priority.
01:05:28.204 - 01:05:50.494, Speaker B: Just optimize the blockchains, make them really fast, don't get in the way, build things that are just incredibly easy to adopt and then let the things afterwards kind of play out. So to me, I don't care about that kind of stuff. Sounds very controversial, but I honestly don't. I care just about building really fast blockchains. Patrick, I don't know what you think about that.
01:05:52.274 - 01:06:55.598, Speaker C: Yeah, I mean, again, this is my opinion, I think on this one, but avalanche is subnets. Like, I don't think the intent with avalanche from the community or anyone is to have like one chain or like one monolithic chain. And avalanche, I think grows in adoption the more powerful subnets can be. Now people may say like, oh, you know, the staking ratio could go down if you don't have to stake to launch a subnet. I look at it very differently, which is to say that the primary network for many people is the jumping in point to avalanche from externally as well as like the point of provenance or liquidity hub that everyone shares. Now that liquidity hub and point of provenance is only interesting and only interesting to secure if there are really novel and cool use cases actually interacting with it. Why would you bridge anything to avalanche if it's the same thing that you could just get elsewhere? It has never really made sense to me that that's the primary motivation.
01:06:55.598 - 01:07:50.382, Speaker C: And so what I think provides a lot of interest and adoption to the primary network is this really expressive world around it that is subnets. And so I think in the path to 10,000 subnets or that article I wrote, I talked about that last item, which is the augmented security, which is also saying, great, there's been this historical relationship with subnets and the primary network. Is it the best one? I don't know. People have a lot of different opinions, but it still makes sense to have some deep relationship between the two if we can. And that's where this approach comes in. Which is to say, if you're a new subnet, like a new permissionless subnet, and I don't know, maybe it's Patrick Coin, probably going to be a small network at first, but if I have a lot of value on it, hopefully I can drive the security budget of that network. We're designing again for these sovereign ecosystems where you're not borrowing security from the primary network.
01:07:50.382 - 01:08:59.594, Speaker C: So what can you do? Well, one option instead is to almost flip the story, which is to say instead of subnet validators actually doing something with security, you can have anyone in the community augment the security of a particular validator and say, hey, I'm going to pledge security, in this case avalanche tokens, to the subnet validator. And if they like, equivocate or have some issue some of that, my avalanche will be slashed or taken away. But in the case that they don't, I'm actually rewarded with the subnet staking token as the reward rather than avalanche. In this world you have this really nice relationship between subnets and the primary network that seemed to be really like a productive relationship that you couldn't get on your own, which is to say I want to be a subnet that can hold substantial value, but I can't do that if my security budget isn't high enough. And hey, I'm on the primary network, maybe I'm staking, maybe I'm not. But I want to use avalanche differently on the primary network. While I can support the growth of subnets, which then increases the value of the liquidity hub that is the c chain.
01:08:59.594 - 01:09:19.322, Speaker C: So I think that my takeaway here is to say the 2000 of ox that's locked to become a subnet validator. There's probably a better way to use that that has the similar properties of Lockheed. And if people are interested in that, that really makes subnets better. And I think that's probably the way I look at it.
01:09:19.418 - 01:09:52.432, Speaker A: Yeah. If I had to push you guys on the Avax. Avax, I still don't know how to pronounce it like value accrual question. If you look at, I think a lot of people compare Avalanche and Solana and look at those two and they're kind of deciding between those and which one to make a trade on. Obviously, none of this is financial advice, but you're seeing something like Solana run up from ten or $15 to 60, and I think Avax has run up from ten to 20. How do you think about that internally? Or how should other people be thinking about that?
01:09:52.432 - 01:09:52.714, Speaker C: About?
01:09:56.014 - 01:10:35.270, Speaker B: I personally don't, honestly at all. It sounds very boring of an answer, but I really don't. I think nobody can talk about any of these kinds of token prices, like predict them in any way. They're kind of silly. So I don't concern myself with that kind of stuff personally. At the end of the day, you know, I just want to build technology that does not get in the way. And I would any day of the week take a blockchain that is extremely popular and technology that we've built being extremely popular over anything else, whether or not it has any value accrual.
01:10:35.270 - 01:10:39.806, Speaker B: So that's my very boring answer. Patrick, you can add yours.
01:10:39.830 - 01:10:43.662, Speaker A: I'm a feeling, Patrick, I'm not going.
01:10:43.678 - 01:11:39.506, Speaker C: To comment too deeply on it. I mean, I think that's. Yeah, I've been in crypto for quite some time, and I think I'd go mad a few times over if I tried to like, explain all of that. I mean, the way I look at it is we're trying, I think everyone in the space is just trying to get people on chain, you know, I think that's a great cause. I think there's a lot of benefits to society from that. You know, what comes from the value accrual of those mechanisms, I think is just a reflection more so of, you know, when you're coming on chain, where's the interesting stuff happening? That's pretty much it. And I think Solana, because of their feed topology, I think makes them very nuanced in the space right now relative to a lot of the EVM chains, because a lot of the narrative there is we want decentralized blockchains, in their terminology of decentralized in terms of the average compute cost or resources that any validator has to use.
01:11:39.506 - 01:12:13.858, Speaker C: And then as a result, we're constrained to some sort of throughput. And there's someone now that is pitching a very different story, which is like, let's have many more resources and just do it differently. And it turns out people are interested in that. And so to me it's more reflection generally. Speaking of, I'll just talk about popularity, not value of anything. And to say like, there are many areas of interest in this crypto design space, and over the last ten years we've really stuck to one. And I love the explosion of looking at different parts of it.
01:12:13.858 - 01:12:33.298, Speaker C: And people just seem to get really excited when we've discovered a new part of the crypto design space. I do too. It's cool. I didn't know you could do that on chain. People freaked out about friendtech when you realized you could connect social to some of the social trading. People get euphoric when they're like, wow, that's something you could never do before. Same thing with flash loans.
01:12:33.298 - 01:12:59.472, Speaker C: And so I think when it gets down to the layer, one layer of wow, this is a totally different trade off. And it lets me do things faster or cheaper, or interact in different ways. It just gets people excited. And so I think with teleporter and some of the subnet stuff coming, I think that will tap into different areas of the crypto design space as well. And I think that developers will find that interesting. That's probably all, I guess, as we.
01:12:59.618 - 01:13:08.864, Speaker A: Wrap this up, Kevin and Patrick, anything that you guys think is really important to think about avalabs and avalanche going into 2024 that we didn't hit on.
01:13:12.404 - 01:14:21.880, Speaker B: I mean, I think again, the most, we're in a very exciting time, I will say in blockchain engineering, I think the narrative that which was wrong, completely wrong, or narrative slash assumption, whatever, that, you know, blockchains, you know, that are very high performant, are centralized, is completely wrong. We're moving away from that thankfully, Solana is on a lot of that narrative counter attack in a lot of ways. That's good. So that means now that there is a really exciting new kind of like wave of hyper optimization, while keeping everything actually very decentralized, which was always possible and always the case. So I think over the next year, I'm personally just so incredibly excited about like actually getting to fruition all the stuff on the engineering side, you know, whatever happens with the crypto markets, honestly, you know, you'd go mad to think about any of these things. It does not matter. I'm excited about just the applications and the engineering.
01:14:21.880 - 01:14:45.604, Speaker B: I'm excited about social fi, I'm excited about everything that's coming on the institutional side. I'm excited about gaming. I'm excited about all these different applications. I'm excited to see these things play out in really interesting new ways we've never seen before. That's not a comment on necessarily avalanche, it's just more of a comment in general on the crypto space. Really exciting to see. Let's see what happens there.
01:14:45.604 - 01:15:18.294, Speaker B: Obviously, I've always had the same thesis that when you allow the programming of value in the same way that you allow the programming of information, the sharing of information, like the Internet did, that thesis has still to play out at incredibly large scale. But when it does, it's going to be really exciting. I think we are at the edge of some really interesting applications at mass. And so I'm really excited about that. Honestly, really, really excited about adoption. So, I don't know, Patrick, if you want to add anything.
01:15:19.554 - 01:15:55.354, Speaker C: Yeah, I mean I'll say that a number of people have asked particularly about the hyper SDK, like what makes it so different and special when we're talking about scaling chains. And so I've been working on a long form piece about more of that because that's very fair question is like, you know, you have all these other like high throughput chains, like what are you guys doing special that makes it even that stand out in this really competitive space better. So just working on that. We didn't talk much about that, but that's, I'd say more on the super, more of the technical side. And so once I share that, maybe we'll chat again. But yeah, I think that's been our.
01:15:57.454 - 01:16:34.364, Speaker B: The one thing that I would like to the space to view as like more of an apples to apples comparison is which one is the fastest to confirmation per core of hardware or like per, I don't know, gigabyte of hardware or whatever it is like, per the same kind of hardware, which one, which implementation will actually be the fastest? I want to get to number. I would love to see avalanche get to number one, and I'm really, really excited about that. It's going to be a really exciting time because I think we're just seeing now that, like, you know, it's time for some serious optimizations in the, in these blockchains. Yeah.
01:16:34.744 - 01:16:38.376, Speaker A: Kevin, Patrick, thank you, guys. Great conversation. Really appreciate it. Thank you.
01:16:38.480 - 01:16:39.112, Speaker C: Really appreciate it.
01:16:39.128 - 01:16:39.496, Speaker B: Thank you.
01:16:39.560 - 01:16:42.208, Speaker C: Thanks for having us, everyone.
01:16:42.296 - 01:17:05.160, Speaker A: Thank you so much for watching today's episode. Really hope you enjoyed it. We wanted to take a second to just remind you about our upcoming digital assets summit in London, March 18 to 20th. Santi and I got your back. Seats are limited, and we hooked you up with a 20% off discount code. It is Empire 20. If you heard it or earlier in the podcast, there's a little competition running at blockworks to see who can drive the most number of tickets.
01:17:05.160 - 01:17:10.704, Speaker A: So when you register for the digital asset summit, make sure you use our code. Empire 20. See you in London.

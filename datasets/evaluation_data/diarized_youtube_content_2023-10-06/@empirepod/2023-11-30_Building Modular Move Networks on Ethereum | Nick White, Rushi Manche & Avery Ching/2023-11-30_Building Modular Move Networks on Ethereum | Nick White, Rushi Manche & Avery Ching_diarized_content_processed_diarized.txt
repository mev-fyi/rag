00:00:33.364 - 00:01:06.744, Speaker A: Welcome, everyone. We have a fascinating and one of our first live stream pods here, and we're joined by Avery Rushy and Nick from Aptos movement and Celestia. And I think if you've been still in crypto, haven't pivoted to AI or haven't left, I think you've heard the word modular before by now. Hope you have. And so this can be a fascinating discussion, because there's a lot of intersection happening between these ecosystems. And so, welcome, everyone. Why don't we get started with quick intros? Avery?
00:01:07.404 - 00:01:20.732, Speaker B: Hi, folks. I'm Avery Chang. I was at Meta for ten years before starting up co founding Optos Labs with Moshe, and before that, I have a PhD in high performance computing. I'm the CTO, currently at Optos labs. Great to meet you.
00:01:20.748 - 00:01:24.480, Speaker A: All right, Rushi.
00:01:24.672 - 00:01:37.084, Speaker C: I'm Rushi, co founder of Movement Labs. Background is engineering, system based and database security at United Health Group, and then got into early theorem engineering and Appdisk engineering. And here are my movement.
00:01:39.064 - 00:01:57.904, Speaker D: I'm Nick. I'm the COO at Celestia Labs, and we're building the first modular data availability layer. And essentially, you can think of Celestia as this new type of layer, one that is built specifically to scale l two s and roll ups, and enable more flexibility for developers.
00:02:00.084 - 00:02:12.704, Speaker A: That's great. Well, welcome, everyone. Again, I'm curious if any one of you guys can just broadly, simplistically explain what modular blockchains do, what they uniquely enable, what the problem is that you guys are solving?
00:02:13.684 - 00:03:03.578, Speaker D: Yeah, I can take that. So, modular blockchains are contrasted with monolithic blockchains, and most existing l one s since the birth of blockchains with bitcoin and ethereum have been designed in a monolithic architecture where essentially the same set of nodes do all the tasks that a blockchain needs to do to provide the infrastructure to run applications. Those tasks are consensus, um, data availability and. And execution. And when you combine all those things into one monolithic stack, it kind of limits. It kind of imposes some limitations on scalability as well as flexibility. So the modular blockchain thesis is that you can actually decompose these functions into separate protocols that can then be stacked on top of each other and recombined.
00:03:03.578 - 00:03:24.034, Speaker D: And when you do that, you can get better scalability, you can get better flexibility, because each one of those layers can be, you know, specialized to perform that function really, really effectively. And so, you know, there's different layers of the stack. You know, celestia being sort of like a consensus and data availability layer. But then you have things like movement who are building execution layers that run on top of things like Celestia.
00:03:25.134 - 00:03:35.030, Speaker A: Yeah, excellent. So ruchi, maybe that's a good segue into talking about like, what movement actually is and how you're working with like Aptos and Celestial. Yeah.
00:03:35.062 - 00:04:24.094, Speaker C: So movement is the building the first ethereum L2 powered by the move virtual machine that leverages celestia for data availability. I think in the past, we've been using EVM for the past few years and most developers in ecosystem can be like, this is horrible, I'm getting hacked for $4 billion every year. And now we're seeing with the modular thesis and what modularity means to me is the ability to truly build whatever, choose whatever execution layer you want to use, choose whatever da you want to use. It's use case specific blockchains. So whether you're building a blockchain for gaming and you need paralyzed throughput, low gas fees, or you're building a DeFi specific one, and it's smart contract security so cyber swap attack doesn't happen again. The curb attack doesn't happen again. And I think we're focused more on smart contract security scalability coming to Ethereum with low gas fees powered by Celestia.
00:04:25.274 - 00:05:02.116, Speaker A: Got it. I guess you're using the move language, which obviously you guys at Aptos have taken. What was, I guess the initial team of Facebook then spun out and then you guys took that. And can you just explain the novelty of Aptos and movement as a programming language relative to solidity? Because for context, I would say the lion's share of developers still are working with solidity and exist in the ethereum ecosystem. Um, but you guys obviously came out and uh, with move. And um, so anyways, if you could explain that.
00:05:02.140 - 00:06:05.526, Speaker B: But yeah, thanks for, thanks for that segue. Um, back in 2018 when, when meta started looking at what it would mean to build out a scalable payments network that could support, uh, for, for, you know, billions of people around the world, we had to kind of, you know, we were definitely inspired by what Ethereum had done, whether it's done in the space in terms of what was possible. But we realized that technology would not scale to the use cases that we wanted to design for. And so that meant a new blockchain architecture, which was DM, a new programming language, which was move. And the idea behind move was how do we kind of get from ideation to production as quickly and safely as possible? And being very inspired by rust around, pushing a lot of the bugs from the runtime into compile time earlier in the programming stack, and then thinking about what are the primitives necessary to make sure money movement is as safe as possible so it can be dropped on the floor, can be actually meant to have thin air. All those things as built in ways that programmers can't hurt themselves. So just a safer way to get smart contract language development into the hands of programmers.
00:06:05.526 - 00:06:49.962, Speaker B: Now, I think it's worth noting that many, very few smart contracts are working at a time we were writing for very specific use cases. So things like travel rule governance were some of the earlier primitives that we worked on it in the early days. Now, fast forwarding a little bit. You know, at Aptos, we wanted to definitely take this forward to a massive degree. And so a whole bunch of the team has come with us to make that happen. And Aptos has taken on a massive pivot, kind of from its original vision in terms of how do we take on, especially parallelism, from programmers to extract it automatically. So with block STM technology, I think, which is being used by many other protocols in the space, and being inspired by that, we kind of call that implicit parallelism.
00:06:49.962 - 00:07:37.834, Speaker B: So when a program starts to design their contract, whenever there's parallelism possible, it'll be extracted automatically from the program without having to impose any necessary boundaries on them. Also, when you think about programs, they naturally touch different pieces of shared data, and being allowed that shared data to be kind of in the same program, as opposed to being split across programs to extract parallelism, which is what happens with another. A lot of other program paradigms, produces a lot of challenges. And so I think that's some of the core things that we have really been taking forward in the language. Also, formal specification and verification is really important to us. So the move prover code has been an amazing asset for making sure programs are safe running in the move space. The entire framework at Aptos is actually formally verified, which is really, really incredible as a particular tool.
00:07:37.834 - 00:08:00.874, Speaker B: And so there are other move variants out there, just again, being very transparent. There's the original kind of DM move that was there. There's a sue movement. And I think Aptos is the most fully featured superset of these different moves out there, and the most supported and the easiest for integration into different platforms. And I think that's kind of why we're excited about movement being one of the many different kind of providers that are taking move into different ecosystems going forward into the future.
00:08:01.814 - 00:08:46.542, Speaker A: Yeah. And so maybe if you can, rush or avery, if you want to take this, but unpack like from a developer experience, how is it, um, if you're trying to convince someone that perhaps is coming new to crypto, wants to build an application, how would you frame it to them? It's, here's why you should build on, on move, here's why you should utilize movement. And how would you kind of frame it and pitch it to them? Because the natural, perhaps inclination still may be I want to build where, where the users are and the liquidity is today, which in my opinion is sort of like we're all beta testers and it's not really going to like, we need to think about at scale, like where are most users going to exist and build towards that. But that's just my bias. So if you guys could just comment on that.
00:08:46.718 - 00:09:27.016, Speaker C: I think an analogy I use is move is to Rust as react is to JavaScript, and that it's a very specialized version of programming. Rust has been around for years. It's a standard now in multiple industries I believe Microsoft is now using for AI biotech. It's huge. It's clear that Rust is like a very hot programming language that's very powerful. And what Avery and a few other great guys really did and girls is made move the programming like Russ made move the blockchain programming language powered by rust based provers, rust based mechanisms, and the way we kind of approach it is like Avery and appdraus doing a phenomenal job innovating the move language. Some of the best engineering work I've ever witnessed.
00:09:27.016 - 00:10:00.428, Speaker C: We're approaching it as like a very web3 focused angle. We acknowledge that in the short to mid terminal, solidity is still going to have a mind share. It's going to be difficult to get EVM adoption away, especially when liquidity lives on the EVM. All developers know solidity in a bear market. If you're going to develop it and say, hey, learn this new language is probably going to be a very tough battle to win. Which is why we explore this idea of a transpiler, which allows any EVM code to launch things. Code curve contracts, Aave contracts, Uniswap contracts, continuously deploy SDK, it'll transpile down and move bytecode and launch the VM itself.
00:10:00.428 - 00:10:33.234, Speaker C: So we kind of hedge our bets in the short term where we're saying, okay, we believe in move as thesis. We believe the future of programming is move. But in the short term, we acknowledge that Sludi has a lion's share of developers. So we allow seamless deployments to Ethereum, JSON RPC, Metamask compatibility, hardhat compatibility, that all comes out of the box. And any sluddy code can now run the great Aptos DMVM or movie and live on Ethereum. So you get the liquidity of Ethereum, you get the benefits of EVM tooling and development while still harnessing the benefits of aptos and move.
00:10:33.694 - 00:11:32.054, Speaker A: So this is really, this bridge is. So if you're, these are, if you're a project that has already built an Aptos, or perhaps sui, some other, you allow it just to seamlessly, like deploy and run an EVM instance on movement and like attract all the users. And the liquidity that may exist is the end goal to ultimately just like bring it all back to something like Aptos, where once people realize that, it's just better. I'm curious how you think about like, because the analogy, once you see it, like, you don't unsee it. And so once you start interacting like in a move base, like for the user, it's like, well, you don't have a reentrancy attack, and so DeFi becomes a safer environment. And so how do you think about that user flow? Perhaps in the next one, three, five years of the state of aptos and movement relative to Ethereum and the growth of liquidity users.
00:11:33.874 - 00:12:17.974, Speaker B: I can take this one. I think the goal would be that it's a technology argument. You brought up a lot of advantages. What EVM has today, definitely users, developers. But what we've seen and observed from people building on move with Aptos is that people who start running this code, just it, they don't want to go back. And we've seen flagship projects from the EVM world come over to Aptos using move and being really, really excited about that, whether it's sushiswap or it's a live life here and many others actually coming in haven't announced yet, but are being moving over, no pun intended, in the coming months. And as people start to see again the idea from ideation to production as safely as possible, these range attacks are not possible.
00:12:17.974 - 00:12:55.454, Speaker B: You have the additional safeness of formal verification in the place. And also you have this very rich way to get parallelism, both optimistically as well as pessimistically coming in the future. And then seeing the way that we evolve the language, the compiler and the VM, we have a very long roadmap of taking it to the next level. I think that is going to be the reason why people start to use these different networks that compatible. So whether it's going to be movement chains or what's happening. Celestia, we want move to be the interface into how all the smart contract programming happens in the future.
00:12:56.034 - 00:13:22.354, Speaker A: Nick, I want to go to you and Rush as well, commenting on how important was it to this data availability unbundling for you guys, where you can now use Celestia. From a cost perspective, what does it mean to be able to utilize Celestia versus do da and consensus in house? And I'm curious if you could put a finer point on the benefits of using something like Celestia.
00:13:23.654 - 00:14:17.894, Speaker D: Yeah, I'll start off, and then I'd love for rushi to jump into. So there's a lot of advantages to building on a modular stack and a modular foundation like Celestia. One of the key things, if we go back to modularity, is decoupling execution from consensus and data availability. What that means is when you launch a normal monolithic chain, it comes with the execution environment already defined in it. You as a developer, when you're building on that l one, are stuck with that execution environment. It could be EVM, it could be Solana VM, or it could be moved. Celestia's thesis, or the modular thesis, and captured in the phrase that Ruchi said earlier, is build whatever, which is that we want to remove constraints from developers and enable people to choose whatever things best suit their use case.
00:14:17.894 - 00:15:09.492, Speaker D: And we firmly believe that there is no one stack to rule them all monolithic architectures tend to breed. So maximalism, because you have to say that, like, well, you have to justify that you're the best. You're better than everyone else. And in the modular world, it's like, well, there isn't actually a best stack. And instead it's like, well, what are you trying to build? And then from there, work backwards and say, like, okay, well, in that case, EVM might be the best for you, or maybe it's Cosmos SDK, or maybe it's move. And so, first and foremost, I think that's one of the benefits of building on something like Celestia, is that it removes any lock in, I guess, into our particular ecosystem or stack. And so one of the things that we're really excited about is supporting all these different execution environments, and we like all of them.
00:15:09.492 - 00:15:52.684, Speaker D: It's like a pluralistic view, right? So recently there's also, Eclipse is launching a Solana virtual machine roll up on top of Celestia. And now with movement like, it's another offering that can be built on Celestia long term. The way we see things playing out is that it will be as easy for developers to deploy a new execution layer, a new blockchain as it is right now to deploy a smart contract. In the long term, it will be this really easy out of the box experience to just spin up a move VM chain and be off to the races, building whatever applications you want. And that's like the future that we want to get to. But Rushi, why don't you add your perspective?
00:15:53.064 - 00:16:44.746, Speaker C: Yeah, I think Avery touched on this earlier, but one of the benefits of move is apparel runtime, in that you have local fee markets. I've been using arbitrum for a while now, and every time that GMX goes crazy, the gas fees go through the roof. So I think one of the benefits of next gen vms, whether it's Solana VM, movevm fuel guys are doing a great job with sway, is really allowing gas fees to be controlled and minimized. So when we look at architecturally, building on Ethereum, sure, Ethereum is great settlement layer. You have a lot of liquidity, it's great for mind share and just generally good for Defi. But if your gas fees are going to be through the roof, it creates a really poor user experience. So when we're looking at different DA layers and studying the modularity thesis, what struck out to me is, look, if I'm going to be bringing this next gen VM to Ethereum, it can't use Ethereum's main da as its da layer until pro dang sharding, which is years out.
00:16:44.746 - 00:17:28.504, Speaker C: It needs a different solution. So that's why the Celestia research, the Celestia integration made a lot of sense, because now we can essentially bring an Ethereum scaling solution, bring a better next gen VM to Ethereum settlement, and not have to worry about Da being a bottleneck. Instead, it can be a fraction of the cost, basically mimic some of the cheapest, if not the cheapest, roll up on Ethereum. So that enables a lot of use cases for Defi where you kind of abstract away any gas spikes, but also on the consumer gaming angle, right? We work with a lot of gaming clients that can't afford $10 per transaction, where you're minting millions of nfts, killing a thousand zombies. That would probably run the player like out of all their money, especially if it's like a 14 year old kid. So having alternative DL airs like Celestia make a lot of sense to us.
00:17:28.844 - 00:18:35.242, Speaker A: Yeah. For me, the big aha moment. And I think a lot of the market is kind of coming, there's realization is there are incredible benefits to this next gen kind of movement, like building an aptos like parallel execution and dynamic fee markets just make a lot of sense when you start thinking about all the different use cases that are now uniquely powered by that. And I think, you know, I want to get into discussion around modular integrated, however you want to use it versus, sorry, modular versus integrated slash monolithic. And like particularly in the context of like why do you still like, what do you think is the benefit to monolithic blockchains today? Because one could argue, well, there's all the incredible benefit with modular and modularity makes a lot of sense. Like the software, like you know, pre bubble crash 99 and then software as a service, like I kind of liken it to that. Like there's this huge unbundling.
00:18:35.242 - 00:18:59.854, Speaker A: And in technology movements, the unbundling like creates a lot of new possibilities. But I think we're seeing that with blockchains, execution environments. And so I'm curious like how you guys think about that debate of modular versus monolithic and if there's merits to still looking at a monolithic integrated blockchain saying yeah, I want to build there, versus the modular approach.
00:19:00.634 - 00:19:47.020, Speaker B: Yeah, I'd be happy to take this one. First of all, definitely respect the work that those in the modular space like Nick are doing. I think it's an interesting design exploration for me. A couple of things I think two examples I'll pick on. One is I think the Linux kernel is a great example of a monolithic kernel where Linus Torvald had a very strong opinion that monolithic kernel would actually allow them to move faster and be more performant. And I think it's done extremely well in terms of achieving those goals and being deployed to pretty much all major clusters and cloud centers today compared to modular kernels or microkernels. And I think another example was even from our early days within meta when we started to build out the Libra blockchain.
00:19:47.020 - 00:20:36.044, Speaker B: We actually tried to build it as a microservices architecture to some degree all connected through GRPC. We quickly realized that this wasn't a good approach due to it was super inefficient in theory. These things all sound great. I can deploy this component here, this component here. We end up rewriting the whole thing instead more internally APIs, the whole system got much more efficient, much faster to develop. I think it comes down to a thesis around if you believe strongly you have the right path forward, you have the right interfaces, the language is the way that it should be the way that the system interfaces with it is built really well for it. Or if you feel like there's a lot of use cases that are not going to be covered by these particular components, then sure, adding all the optionality makes sense.
00:20:36.044 - 00:21:09.324, Speaker B: It doesn't mean you can't be more modular in the future. When it comes to APIs and interfaces, you can always add those in as you discover the right points for those. But today we haven't had any concerns where people are like, well, you know, we love move for this, but we really wish we had EVM for that. Or we love the way the blockchain works today, but we wish the consensus protocol was slightly different. So far we have, you know, every use case that we've seen being thrown in Aptos has worked really, really well. And so there's just no need to kind of explore the alternatives right at this second. That could change, of course, in the future.
00:21:09.324 - 00:21:39.552, Speaker B: And the other thing, I would just point a point. A point on modularity is Aptos is a modular stack. We're designed as several phases. We have data dissemination, we have ordering, we have parallel execution, parallel rights, and then proof verification after that. You have the modularity as a design choice. And we can actually take a lot of benefits from upgrading individual components of that and testing individual components. But one of the downsides if you start to also get too modular in certain services, for example, that testing becomes very complex.
00:21:39.552 - 00:22:07.154, Speaker B: Like suppose you want to test interaction of chain a with chain b, and chain a is changing this thing and chain b is changing that thing. If you want to test holistically, it gets very challenging, like the number of combinations explodes exponentially. And that's something we just, again, that we don't think that right now we haven't seen use cases for that. Our developers are really happy with what we offer them and building that full stack is just simpler and performant for us and optimizing for it currently today.
00:22:07.454 - 00:22:52.786, Speaker A: Yeah, we don't have someone from Solana here, but perhaps I may take that. I'll try to, I'll attempt to do that. But the argument would be, look, Solana just makes a very clear trade off that they're just going to accept higher hardware costs and requirements and try to optimize the bandwidth. Because when I think of blockchains, you have the hardware costs, you have bandwidth and storage. And those are, in my mind the three biggest categories that Ethereum guys say, well, our hardware costs are not 3000, they're 200, and anyone can run a node and that's great. When you actually look at the data, they're actually the same. When you look at the Nakamoto coefficients, Solana actually has way higher than Solana.
00:22:52.786 - 00:23:41.494, Speaker A: So in practice, like, these things also manifest themselves in different ways. But someone might Solana say, well, why not just come and build in Solana? Like, why do I have to go to Aptos? Or why do I have to use, like, a modular design when you still need to run? Like, you still depend on full nodes, and running a full node has a real meaningful cost. And if you just accept that, then we can just focus on solving, like, hardware costs can come down over time, or solving on bandwidth or optimizing these things. But I'm just kind of curious, like, taking the camp of you could build on Solana. What would you say to a builder? There's a lot of excitement, of course, now in Solana for a variety of reasons, but what is that trade off between aptos or movement?
00:23:41.794 - 00:24:05.322, Speaker B: Yeah, I'm happy to answer that question about Solana. I think Solana is definitely one of the first in the space around high performance blockchains. Obviously, we're in the same field. We've taken different design trade offs. We think our design is much more scalable from a throughput perspective. And there's different goals around latency. I think they talk a lot about the block times, but finality time is actually quite different than block time.
00:24:05.322 - 00:24:41.328, Speaker B: And so finale time in Aptos is generally about a second or so. And that's kind of where all validators agree on the execution of the transaction from a byzantine fault tolerance perspective, two thirds. So I think from a throughput and a latency perspective, you can try a lab test. You can see the numbers we put out. We put out verifiable numbers, even in a benchmark in March for anyone can rerun the same experiment we ran and get the same numbers of. I think our experiment showed about 20,000 transactions per second in a mainland like setup. End to end results for that.
00:24:41.328 - 00:25:06.124, Speaker B: And we also have new numbers that will be coming out fairly soon that will even blow those numbers away. And so again, our goal is to keep pushing on the spectrum of parallelism, latency and other aspects. And, yes, so if we're trying, we're not trying to support all the use cases out there. It's really about high throughput, low latency, highly safe and available use cases and kind of enterprise grade technology that you can trust to build on billions of people.
00:25:06.824 - 00:25:25.194, Speaker A: Yeah, Nick or rushy. I'm curious, when you think about the projects that have been become interested in working with Celestia and also using move as a programming language. What kind of use cases and projects have you been getting the most amount of interest from?
00:25:27.014 - 00:25:38.078, Speaker D: Yeah, well, there's a lot to talk about in the monolithic versus modular debate, which maybe we can revisit, but in terms of we can keep going, I.
00:25:38.086 - 00:25:43.514, Speaker A: Think it's probably the most important discussion that we can have in crypto today, realistically.
00:25:44.054 - 00:27:29.228, Speaker D: Yeah, well, I think. I mean, okay, so, first of all, it's clear, I think, from everyone, that we're entering into a multi chain world, right? Like, even if each of those chains is monolithic, we're entering a world where there's going to be lots and lots of different experimentation of execution environments, and a lot of different chains kind of living side by side with their own ecosystems. And I think when you, like, start to play that out further, the modular approach makes more and more sense in the sense that you can still share security by having this common consensus and data availability layer, while still experimenting with all these different chains and execution environments. All the optimizations that are happening in the move world or the Solano virtual machine world, that speed things up and make them faster, et cetera, are absolutely, really crucial, but they're only really scaling the execution aspect and not so much specifically, the other major bottleneck to scaling blockchains, which is data availability. I think that's one of the key differences, I would say. Another thing that's really important, at least in the modular space that I think it gets lost in this debate, is the emphasis on verifiability, too. Increasing the throughput of your chain simply by requiring higher bandwidth and higher execution, cpu or whatever computational resources in the node, is not really scaling the blockchain, because you're increasing the cost to run a node and making it less and less accessible for, for the average person.
00:27:29.228 - 00:28:26.370, Speaker D: So, the only solutions that I think actually scale blockchains is a combination of data availability, sampling and roll ups. And what they allow you to do is they allow someone to verify a chain very efficiently with low resources. So even as the amount of data in the block grows, you don't have to do more work to verify that the chain, even as the number of transactions that are processed, grows, you don't have to do more work to verify that execution. And so what that means is we can preserve the core value proposition of blockchains, which is end users can verify the chain and audit it, and uphold the rules of the chain, and not have to delegate trust to validators. Or other people running full nodes on their behalf. And so I think that's a really core thing that like, and I think that we need to like keep that very central because it's the core value proposition of blockchains. And I think the modular stack kind of stands for that.
00:28:26.370 - 00:28:54.884, Speaker D: Obviously, a monolithic chain can implement data availability sampling and can implement these proof systems that are like rollups. But then when you enter in that world, it kind of modularity makes more and more sense because data availability makes sense to pool resources because you get all these benefits of scale. And rollups naturally lend themselves to these, like just, oh, spin up your own chain. So like, to me, all role, all roads kind of lead to modularity one way or another.
00:28:55.864 - 00:29:11.844, Speaker A: Can you go a little bit deeper into the specialization? And like, by specialization you have all these advantages, like what, what is uniquely enabled when you kind of outsource it to Celestia, when you outsource da in consensus to Celestia. Like, how does this actually, like scale and.
00:29:12.904 - 00:30:14.148, Speaker D: Yeah, so, so Celestia is the first l one that was designed for people to just only run l two s. And so you could, for example, run a roll up on Solana or Ethereum or all these things, but it ends up being very hacky because those l one s were never actually designed specifically for that use case. Right? So, like, even the way that rollups run on ethereum today is by using call data, which is, I don't think it was like ever planned that like, oh, people are going to want to run these roll ups and then therefore we'll design this call data interface as a way that's optimal for that versus Celestia was designed from the ground up for this use case. So there's a bunch of things. First is that we scale specifically data availability via data availability sampling, which means that we can scale the block size with the number of sampling nodes in the network. And so no other blockchain has this property where you can increase the throughput without increasing the node requirements. It's just you just need more people participating.
00:30:14.148 - 00:30:30.612, Speaker D: And I think that's a huge unlock and that enables us, for example, to have these extremely low fees for l two s and why you would launch. For example, movement is launching using celestia rather than ethereum da, for example. In addition to that there, just to.
00:30:30.628 - 00:30:32.252, Speaker A: Put it in perspective, that's a order.
00:30:32.308 - 00:30:37.724, Speaker D: Magnitude save probably multiple orders of magnitude. Multiple compared to ECA.
00:30:37.884 - 00:30:53.504, Speaker A: Yeah, but like, even compared to a nor, like if you're a normal l two launching on the op stack, whatever, and you're not using Celestia. And if you use Celestia like that, cost save translates into one to, like, one or a couple orders of magnitude.
00:30:54.164 - 00:31:56.746, Speaker D: I would, I think we're still working on exact numbers, and we'll have that more concretely when some of the first roll ups launch on Celestia, but I think it'll be multiple orders of magnitude. And so because the main cost driver for rollups, especially optimistic roll ups, is not the settlement costs, but the DA costs. And so when you can offload the DA costs to celestia, it can dramatically reduces the end user costs. But anyway, just back on the specialization point, some other things that Celestia were designed for is like, it's overhead minimized, meaning that, so when you're running a roll up on top of, let's say, ethereum or any other l one, you have to verify what's actually happening on the l one, too. So you kind of have to, you have to run like a full node of that l one. And if there's a lot of execution and state and things to track on that l one, then that adds overhead to every single roll up that's running on top. So Celestia is designed in a way where it has basically no execution, has a minimal, minimal amount of execution, and minimal, minimal amount of state.
00:31:56.746 - 00:32:33.534, Speaker D: And so verifying celestia is as light as possible. So all the roll ups that are built on top don't inherit all this baggage and overhead that you would, for example, if you're running on Ethereum or other monolithic l one s. And then also there's things about, it's designed specifically to post data to it. So the interface for posting data is very clean. And the way you pay for that is all optimized for that use case. And that's just something that a monolithic l one can't do or could, but has to completely start from scratch.
00:32:34.754 - 00:33:28.564, Speaker A: Yeah. Can we comment on around this throughput? And I'm not a TPS maximalist, but if we just compare TPS as a figure of all these different use cases that can be enabled if you're going to visa, well, they care about TPS, I guess, of course, other components, but one could argue, like, and I'm referencing some figures here, but like, Solana, for instance, with firedancer has, I would say, like, probably the highest DP's, and then you go down from there, like with Celestia. Like, what are the improvements? I guess I'm curious, like movement. Like, where does apdo stand in term in that spectrum relative to Ethereum, relative to Solana. And where does, like, a movement, VM with Celestia stand in that spectrum? And I'm not saying TPS is the most important thing, but I do think it's important to just, like, call it out, I guess.
00:33:28.604 - 00:33:34.068, Speaker B: Yeah, I think. I think, by the way, TPS is a metric that has to go away at some point. I just want to be very clear. Like, it's a really poor way to.
00:33:34.116 - 00:33:37.988, Speaker A: Like, that's Avery's fine way of saying it was a very stupid question, but anyway.
00:33:38.036 - 00:34:03.436, Speaker B: No, no, no. I think, by the way, it's a very fair question. Everyone asks us all the time, what is the transaction throughput of your system? The issue with TPS is that it really depends on the transaction types that are being issued. That's why databases have TBC benchmarks. So you can actually test out a suite of different types of operations and understand for this type of workload, this is the performance you're gonna get for this type of workflow. This is the performance you're gonna get in our world. Unfortunately, there just isn't standards out there.
00:34:03.436 - 00:34:31.463, Speaker B: We've done our best to try to put out some standards again. We put out repeatable benchmarks. We'd love others to do the same in this space. So, you know, we have a medium post that describes, like, here's our exact setup for how we ran our experiment. Here's the exact types of transactions we've run. We have coming again very, very soon improvement upon that, where we describe different types of workloads that we think are important for different kind of crypto use cases. And we'd love others to go ahead and participate and share, you know, what they think is important.
00:34:31.463 - 00:35:11.604, Speaker B: And also, ideally, adopt some of those benchmarks that we put out there so we can have apples to apples to apples comparison, instead of apples to oranges to bananas to pears, to whatever jackfruit that's out there. And so I think fire dancer is probably an interesting product. It is something, though, that is still designed within the current solana parameters. It's just a faster implementation of it today. I don't know we've actually seen any verifiable numbers from what Solana can do in an actual controlled maintenance type environment. And so I think these are not apples apps numbers that we compare. And the only numbers that we know of that kind of show benchmarks from the space are the ones that we put out there.
00:35:11.604 - 00:35:29.864, Speaker B: So, again, as of now, we think that we've shown the fastest numbers in transaction throughput, they are verifiable, they're repeatable. You can run them on the same GCP hardware. You actually get better numbers today. We haven't shared those yet. We will show those in the coming weeks, but you'll get the same kind of results that we have at this particular time. And I think they're the only ones that are verified for now.
00:35:30.424 - 00:36:10.114, Speaker A: Yeah, I guess the better way to reframe the question for all of you guys is when you think about scalability, what is exciting now is that there are many different use cases that have been tried in the past, didn't work. We're in a different environment now because with celestial we're a different environment because of aptos, and then with the movement VM. And so I am curious, when you think about scalability, something that, to your point Avery, is heavily discussed. It can mean a whole variety of things. It may be the most important thing for certain, but it just depends on the use case. And again, there's trade offs and whatnot. So it's a very nuanced discussion and I don't think we have enough time to do it.
00:36:10.114 - 00:36:38.034, Speaker A: But I do think the more exciting thing, maybe transitioning a bit into the discussion is like rushy as you guys have set up to do this kind of connectivity between Ethereum. And I'm curious, like what type of use cases do you envision, what type of projects do you envision building and utilizing kind of this bridge for lack of a better term, or just environment that kind of gets the best of both worlds?
00:36:38.454 - 00:37:30.994, Speaker C: I think what gets lost in the infrastructure discussion and the whole module versus model discussion is what do the builders actually think? So me and my co founder were just Dapp builders as a Dex builder in Aptos. My co founder build the first yield to aggregate in Aptos. So we're really looking at it from like how can we build better financial products for our customers? It really mattered to us what the TPS was because if we got five tps we were throwing a party. It didn't really matter much on like what latency was at that point because we were just trying to figure out like how do we get ten users on our app? I think one kind of led us to the modularity thesis is that we could permissionlessly innovate, if that makes sense. For example, when we were building yield aggregator, there's only three assets that we had at the time on Testnet. It was like apt native token and two live native tokens. And that was on Testnet so we're trying to get customers to use our app.
00:37:30.994 - 00:38:09.432, Speaker C: It was like, do you guys really want to play around with three tokens that not that many people know about, or do you want to use native ETH on your protocol? Do you want to use BDCB, which is powered by the snowmaking sensors that we leverage? Do you want to use EVM assets which are usually more speculated upon? So we're taking like a Defi app to Mainnet. Think about DyDx perps lending. It's usually the EVM assets that are usually speculated upon that drive demand to your protocol. So that was the bottleneck that we face as builders in the space, which is often forgotten in these discussions. And I really haven't seen it come up like, cool, latency is cool, cool. The fees are cool. But most of that's, in theory.
00:38:09.432 - 00:38:48.034, Speaker C: What we're looking at infrastructure today is I want to build the Dex in the next six months if I'm going to monothe chains right now, especially ones that are starting up on the come up. Usually these assets aren't speculated upon heavily, and it takes time for development to occur. It takes time for stable coins to come, it takes time for bridging to happen. Whereas when we went to a modular chain on top of Ethereum with celestia, we built a hyperlink bridge in a month. Now we have full connectivity with the rest of modular ecosystem with other EVM chains, and we have to wait for a third party like layer zero to warmhole to prioritize us. Instead, we could do it ourselves. That ties in IBC.
00:38:48.034 - 00:39:17.224, Speaker C: We were able to fully bring IBC to move, which is pretty exciting. And also assets. When we have defi apps that build on top of a chain, now you have app dots and suite assets, which are move assets. We can also have native EVM assets. So native ETH in your protocol, BDCB in your protocol, Lido in your protocol, native Ethereum assets, which can actually drive adoption for these moot protocols and make my life as a builder a lot easier. But I'm sure Nick has more thoughts on modularity in that sense.
00:39:18.804 - 00:40:15.802, Speaker D: Well, I think you hit the nail on the head in terms of permissionless innovation. That's a big part of the modular thesis is this idea of just set the developers and the builders free and give them as many options as they could want and then let them build whatever, essentially. And I think I'm glad to hear that. That's one of the things that it does end up mattering to builders like Ruchi and I think just on the throughput conversation earlier, I totally agree. I think transaction per second is a bad metric for all the reasons that Avery mentioned and at least for us. And what I think will eventually become the standard, at least for the base layer data availability stack, is just simply data availability throughput as a metric. And that is universal because you don't have these things about what transactions are there.
00:40:15.802 - 00:40:54.994, Speaker D: It's just how many bytes can you publish and make available on this l one? I think that's something that it's great. It's another benefit of this modular paradigm is that it really clarifies. It's like, okay, we know what the objective of this protocol is. What are some of the things we need to maximize? One of them is just data availability throughput now with the constraint of. It must be actually easy to verify and all those other things that I mentioned earlier. But I think that, to me, is a very clear standard. I think will emerge is like, how much? What's the data throughput of your chain?
00:40:55.534 - 00:41:24.800, Speaker C: Another builder thing that, if we can go, is why drew me to move is the concept of velocity of production. I think I was an EVM builder before that. And for me to build a slurry Dapp as like Dex or yield dagger, it took me months, and I've spent another few months auditing the code and then pay 100 grand to an auditorium who out of the code. And then it still will probably get hacked. Right? So that was a whole headache for me. And my stomach cross move. And the work that Avery's done, it's like, okay, so, like, 90% of the hacker attacks that was spending, like, countless hours at 03:00 a.m.,
00:41:24.800 - 00:41:49.592, Speaker C: like, are kind of taking care of me. I don't have to pay this auditor 100 grand to not do that great of a job and still get hacked. So we focus on velocity production. If you're a random developer, think of Mark Zuckerberg in his college dorm. You should be able to ship mainnet code as quickly as possible, not worrying about security instead of worrying about actual functionality. Build the best social fi app. Don't worry about that 108th line of code that you glossed over.
00:41:49.592 - 00:42:04.324, Speaker C: That can lose your protocol 3 million and lose all your credibility. That's the biggest issue in development. As a young and aspiring, being infrastructure application developer is too difficult to build the killer app or making the killer app easier with mood.
00:42:05.564 - 00:42:27.104, Speaker B: Yeah, I couldn't agree more with that. And don't get me wrong, I really love the fact that, like, movement and celestial are partnering together, make this happen. I know Nick, you're putting your, hedge your bets on all these different, you know, ways of languages, whether it's Solana, VM or EVM. But you know, I think hopefully the right stack will emerge over time and maybe, maybe there'll be less focus on the ones that are not as interesting to your developers as that plays out.
00:42:27.564 - 00:42:51.612, Speaker A: Yeah, I'm curious, like just looking ahead, like the synergies between the teams and also just how do you think about all this is fairly new. How do you envision the next. I don't want to call it the next cycle, but just like the next two, three years in terms of just developer interest, activity, type of applications, with all this kind of new possibilities out.
00:42:51.628 - 00:42:53.444, Speaker D: There, I'll go quickly.
00:42:53.484 - 00:43:19.794, Speaker C: I think the EVM burns. I think every developer is sick of the EVM. There's literally a major hacker attack every year, every month it's the same reentry bug over and over and over again. It's like getting punched by the same kid over and over again and you're not doing anything about it. So hopefully in the next two or three years we see more adoption, the blue chip defi protocols actually on move, some other networks, just anything that has the EVM, and I'm happy.
00:43:22.014 - 00:44:18.756, Speaker B: I completely agree with that. I think the technology space is going to evolve rapidly. Like I said, we were doing 20,000 transactions in a verified environment that we run in March. That number is going to increase significantly in the coming weeks as we put those numbers out, and in next year those numbers will increase even further. And so as we see the technology start to grow to really rival those of traditional databases or other systems that are used for money movement, it's going to be a pretty massive technology advantage to move more into the blockchain space. And we're taking a very opinionated approach that our version of move is going to be the right test version of move is going to be the one that drives this innovation forward with new compiler coming out, with new VM technology coming out, with folks like Ruchi and others helping us to derive this from a developer standpoint going forward, as well as the system being co designed with it, like hardware, software design is something really important. We think about full optimization across the stack.
00:44:18.756 - 00:45:01.494, Speaker B: And as Nick pointed out, these metrics around whether it's going to be data movement or, I like to think about resource usage. I worked in distributed scheduling for a long time across 100,000 machines. How do we measure the real like performance, usage and benefit from these different infrastructures will become very, very clear and massive, massive adoption in the coming years, because these big enterprises and other large applications will be very confident to put their use cases on top of blockchain, because it's truly scalable, it's truly reliable, it's easy to build on. And the user pain points around how the user experience of onboarding is going to be much, much simpler when you have things like account abstraction built directly into things like Aptos move as well as, I'm sure, movement what they were doing as well.
00:45:03.314 - 00:45:40.734, Speaker D: Yeah, I agree that the EVM is not the be all and end all. I think a lot of people over index on that. I think it just had the first mover advantage. But there's just, you know, part of the modular thesis again, is experimentation. And especially experimentation at the execution layer has been held back by the fact that to try out a new execution environment, you had to launch a whole new l one. Now, when we remove that barrier, we're going to accelerate the velocity of innovation at the execution layer, and that even includes new flavors of the EVM. We have teams like Manta Pacific who have built an EVM that has ZK op codes inside of it.
00:45:40.734 - 00:46:23.670, Speaker D: I'm really excited for that. Just unleashing a whole new, uh, wave of innovation at the execution layer itself. And I think in the future, what I see is, um, just, you know, right now, l two beat has something like 30 roll ups or l two s listed on it. I think in 2024 into 2025, we're going to have thousands, maybe tens of thousands of roll ups. Eventually, it's just going to be like smart contracts. It'll be the same thing as we had kind of in the wave when Ethereum first shipped. Of all these people, just like deploying new apps, I think we're going to see something similar, and it's going to also have this explosion of all these different combinations of different components, modular components that you can mix and match and achieve different trade offs.
00:46:23.670 - 00:46:44.012, Speaker D: And so I'm just excited for experimentation, because wherever there's experimentation, there's innovation, and there's going to be a net new applications and use cases that haven't existed before, so the whole space can move forward. I'm just stoked to see what comes out of it. I can't predict what will be the breakout use cases, but I'm sure that we'll find some.
00:46:44.148 - 00:47:22.084, Speaker A: Yeah, I don't think anyone envisioned Uber when the smartphone came out, but as a general point of just curiosity for me is in this decoupling unbundling between execution settlement and da consensus. And kind of like this Rubik's cube analogy. Where are we in the state of integration when you do that? Um, you know, you, you talk about IBC, like, connecting all these different chains, but, like, can one of you guys just simplistically comment on, like, how these, like, when you do this unbundling, are you losing some sort of communication or performance by doing this on bundling? Um, or not. And I'm just curious.
00:47:23.424 - 00:48:23.420, Speaker D: I think I'd be the first to say that, like, it's going to, you know, integrated chains have an advantage in the sense of, if you've already defined how all the pieces fit together and you've tested them, et cetera, like what Avery is saying, it's going to work out of the box. And I think one of the near term challenges for the modular space is going to be defining those interfaces in a way that makes it actually more pluggable and then also making it easy to test all these things. I will be the first to say that I think there will be challenges to it. There's a lot. The good thing on the flip side is that there's all these different teams that are incentivized to make this work. And so there's just a huge amount of really talented people tackling these problems. And you have teams like rollup as a service projects who are sort of like system integrators, who are like, okay, here are all the components, and we're going to plug them all together into this stack and sort of sell that as an end product to people who want to deploy a chain.
00:48:23.420 - 00:49:09.156, Speaker D: And so, like, you have, you have people from across the modular ecosystem that are actively really working on this. I think we're going to still struggle for a while to have better bridging. I think that's just not solved. That problem exists everywhere, not just on the modular space, but any cross chain thing is still not quite as smooth as I think it could be. And that does diminish the value proposition of everyone launching their own chain, because then you are, until bridging becomes machine seamless, it will be a little bit more fragmented component. But I operate under the assumption that, or the belief that in the long term future, cross chain composability will be really seamless. And so eventually we'll get there.
00:49:09.156 - 00:49:30.154, Speaker D: But for the near term, I could see an advantage to sort of like shared execution layers, like Solana or Aptos, or even like arbitrum, for example, as a roll up example, where, you know, it makes sense for people to build there because, like, you do get this seamless composability, that might still be a challenge for like, cross l two stuff.
00:49:31.614 - 00:49:33.630, Speaker A: Yeah, go ahead, Rishi.
00:49:33.702 - 00:50:04.258, Speaker C: I think it's largely use case dependent at the currency. Like, if you're trying to build a venmo for crypto is, I would argue it's best in Solana Aptos. So we just makes the most sense. It's easiest to do out of the box. I think if you're trying to unlock different use cases that weren't possible in monolithic chains, like I touched on, like, innovative defi apps that can use assets from different chains, like IBC enablement, stuff like that. That's where modular chains have an edge because you can kind of customize it. You don't need to wait for a third party to add dependencies, add features.
00:50:04.258 - 00:50:17.908, Speaker C: You can kind of innovate by yourself. If you're just looking to use blockchain in the background, build payments app, build a gaming app, and get to market as quickly as possible. In the current state, I would say that monothic chains will win. So I think it's monolithic and modular in the current environment, not.
00:50:17.956 - 00:50:23.384, Speaker A: Or would you, Avery? Nick, would you agree?
00:50:25.204 - 00:50:54.388, Speaker B: I think they're just a different exploration spaces. Like I said, I respect the fact that people are exploring different ideas, and I think you can probably innovate faster in a monolithic chain. Sorry, a modular chain. As Rushi suggested, our goal is always to support the 99% of use cases in Aptos, and there might be 1% we don't hit, but we haven't seen it yet. But we would love to wait until. What I've learned as a developer for a long time, though, is it's really, really hard to build APIs before, you know, the use cases, and you almost always get it wrong. And that's the problem.
00:50:54.388 - 00:51:27.594, Speaker B: And Nick alluded to this earlier. Right. It's tough because you don't know what you want until you have a use case that you're driving it, and then, you know, like, exactly what you need in those APIs to push forward on. So, you know, we're always open to adding APIs at the right layers and allowing people to plug in and play different things, but we kind of wait for those use cases to emerge first rather than being a little bit more proactive about it. That way it allows us to focus on our core stack, support those pretty much most of the use, if not all the use cases out there. We've seen and built in a simpler and easier to test and more performant from the get go.
00:51:27.894 - 00:51:48.154, Speaker A: Yeah. If you were to predict what is the killer use case that's going to emerge? Obviously in the last cycle, a lot of it was just innovations in Defi and Defi summer and yield farming, which was fun until it wasn't. What do you think is the next catalyst? And like the first type of application that just gets mass adoption?
00:51:51.494 - 00:51:54.014, Speaker B: This is a hard one. You want to go ahead, Nick, you can go first.
00:51:54.174 - 00:52:35.684, Speaker D: I, you know, I don't, I don't have, I feel like, you know, it's one of those things where it's very hard to predict because. And if you could, maybe you would go out and like build that. Right? Like, so I don't, I don't have a good answer. I think that some things that I think are kind of exciting are things like on chain gaming. I feel like gaming is something that naturally has this like virality and mass market appeal. And if you bake in the right kind of like economics or incentives, it could really like take off. And I think also things like social fi applications similarly have this baked in kind of like mass market and if you crack the incentive code could spread virally.
00:52:35.684 - 00:52:53.524, Speaker D: So I think about those things. I think stablecoins are something that already have really strong product market fit. And so there could be something around payments or just leveraging stable coins that could also really take off. And those are just some ideas off the top of my head.
00:52:55.504 - 00:52:55.888, Speaker A: But I.
00:52:55.896 - 00:53:19.634, Speaker D: Think universally I'll just say that all those, in order to reach mass, mass adoption or like these breakout use cases, you need to have the underlying infrastructure ready to absorb all that demand. And so that's why it's so important that like teams like Aptos or like Celestia, et cetera, are like trying to build this like underlying capacity to like. So when if we do hit that hyper growth as an industry, we don't just scale fail and like go back.
00:53:19.674 - 00:53:22.934, Speaker A: We're not in dialogue. We're broadband. We need to get broadband.
00:53:23.314 - 00:54:21.694, Speaker B: Yes, that's right. I think those are all great use cases that Nick laid out. The one I think that is hopefully coming a little bit sooner than or later and maybe it's more of a hope than a reality is really about how blockchain can provide much more accountability and responsibility to AI innovation going forward. And so we've been working very closely with Microsoft on a couple of different initiatives in this space to understand like, you know, how does, how does identity play into the picture? How do we get responsible AI where, you know, if you're using, if people are using your data for training, you're either, like, giving your explicit permission for it, you're getting compensated for it, or, you know, other, you know, or you're just not giving that permission at all, right? And so those kind of things are very interesting also, like, verification of content of AI, right? So if someone post a video of rushi dancing on a tree, like rush, you can say, like, you know, this is, this was really me, or this was, like, someone faking that content. This is not me.
00:54:22.274 - 00:54:24.546, Speaker A: Private keys are proof of humanity, I guess.
00:54:24.650 - 00:54:44.774, Speaker B: Yeah, yeah. Proof of humanity is a really important thing that blockchain can do as a, you know, auditability with private keys and user signing to show that kind of, you know, attestation of whatever content is being put out there in market. So that's an area that we're pushing very hard with a couple of partners on, and we really want to see that change happen in the world sooner rather than later.
00:54:45.644 - 00:54:48.384, Speaker A: Rusev, what's going to be the killer app and move VM?
00:54:49.724 - 00:55:33.994, Speaker C: I think payments outside of infrastructure is just like, where the obvious use cases, sending money from, like, Thailand to, like, Ethiopia and under like a second without using, like, Western Union, without having to pay PayPal, like, 30% and having, like, centralized authorities. We're still waiting for the Venmo crypto to come out. But I think that that's what gets me personally excited. Whether it's on Aptos, whether it's on roll up, it doesn't really matter. Getting the average user to use USCC in the backend, not mention blockchain once, is what kind of keeps me going, how it's accomplished, I don't know. I don't know what chain it's on, don't know what the wallet's on, but the team that does that and gets people actually using blockchain for payments and USDC everywhere in the backend wins.
00:55:34.974 - 00:56:34.672, Speaker A: That's fair. Maybe as a parting question, um, I'd like to get, um, two components. But the first question really is, whenever there's an unbundling, decoupling there, over time there, there tends to go back to bundling. Like, you see these unbundling and bundling waves and technology cycles. Um, as you think about, we're, I think, now entering a phase of mass experimentation, right? Because you all of a sudden can decouple them. And we're going to try all the different flavors, SVM, movie, and all the different components. Do you see a time where we ossify into one standard of the stack that is the most optimal, or do we, or do we never get there? Will we define one, two or three very nicely stacks? Or it will just be, there's going to be so many different verticals and use cases that we never define a standard in this modular movement.
00:56:34.672 - 00:56:37.324, Speaker A: And you just continue to iterate and innovate.
00:56:38.824 - 00:57:22.774, Speaker D: That's a good question. The way that I see it is not so much in the rebundling, the way I frame it, but consolidation, definitely. I think you have this exploration divergence and then there's clear winners that emerge and they become network effects around certain execution environments and what have you. So I do expect that to happen. And there might be sort of like a power law distribution of like here's like the most common execution environment that everyone uses and then it kind of goes down and there's like a long tail. But I think there will always be a long tail and we should enable that long tail for sure. And one way, like I often use a sort of analogy.
00:57:22.774 - 00:58:16.254, Speaker D: The way I think about modular blockchains is very similar to like cloud infrastructure. And that a roll up is a virtual machine that you deploy on a data center, but instead of a data center it's a data network like Celestia. The cool thing is if you think about how the virtual machine world has evolved, you have all these. Linux is obviously the most common operating system, but there's all these different distributions that have different trade offs, etcetera. And so there's this really long tail of different Linux distributions that people use. And so I think you could see a similar thing kind of emerging with execution layers in modular watchings where they follow one common standard, but then there's customizations and different sort of like they branch out into this family of different things.
00:58:17.734 - 00:58:54.614, Speaker C: The best analogy is like there's a billion websites, right? But there's one Google, there's one Amazon. It's the website that has the best underlying infrastructure, the best partnerships, the best distribution that win. Similarly with like blockchains, whether it's a layer one, L2, layer three, layer 500, it's going to be the blockchain that can get the most partnerships, get the most users, and then whatever underlying infrastructure that allows them to accomplish that job, the best wins. So whether it's ethereum, whether it's any other settlement layer, whether DA layers, execution layers, it's gonna be a billion blockchain, sure, but there's gonna be three ones that actually get users.
00:58:55.634 - 00:59:31.514, Speaker B: Yeah, I think we use the same analogy here at Aptos like, thinking about blockchains is very similar to cloud. There's several major cloud providers. It drops off after number four or five pretty rapidly, and that's the expectation we have. And we think that we're building out the right execution environment, the right consensus protocol, the right fully integrated stack that is going to support a huge chunk, if not all the use cases out there. But again, very respectful of others that are trying different approaches in the space. And ultimately, though, I think we all agree that we'll see consolidation to a small number of technology stacks in the future that ultimately serve the most user use cases, as Ruchi mentioned.
00:59:31.854 - 00:59:56.768, Speaker A: Absolutely. Well, I'm all for experimentation, and I think maximalism doesn't serve you well. And I think we're in this incredible renaissance of let's trial the different variations and see what sticks. And ultimately, we're so early, we have, like, we're all, you know, it's a. It's a speck of dust and we. We haven't even reached any sort of mainstream adoption. So I think this is a uniquely in that, like, it's a requirement to get there.
00:59:56.768 - 01:00:07.084, Speaker A: So great work from. From all you guys. Really exciting, I guess. Any parting thoughts? Things that you're excited about? You're building challenges or, you know, stuff that you want to call out before I wrap it up.
01:00:08.554 - 01:00:37.138, Speaker D: I like what you said, that we're so early. I agree. I think we're so early on so many different dimensions, and one being just the actual infrastructure. When I first got into crypto in 2017, I thought, wow, I'm so late. It feels like everything is already done. Here we are six years later. I actually now feel like we're still extremely early, and there's so much more innovation and experimentation to be done.
01:00:37.138 - 01:00:59.374, Speaker D: And we're also early from an adoption standpoint. Like, very few people actually use blockchains today. There's very little value that are sort of transacted on blockchains today compared to, like, you know, the actual, like, scale of the global economy. And so I think, yeah, we're just a speck of dust. So I'm excited for hopefully in the next six to ten years, like, we'll actually get there.
01:01:00.814 - 01:01:30.514, Speaker C: Yeah, I think for me, it's like, on Twitter, I see, like, ethereum, rewan, or EvM rewind. And the question I asked is, like, what did you win? Like, you got the ten users, you got, like, four people knowing about you. Is that what your definition win is? So I think people are finally recognizing, like, network effects, especially in crypto, very small and all it takes is, like, one Kickstart team, one killer use case, one app that gets more than ten users to really take away the network effects, and then EVM and Ethereum is not winning anymore.
01:01:32.014 - 01:01:50.590, Speaker B: I completely agree with those points. I love the fact that we're early. I love the fact that also, the adoption is not there yet. I wanted that to change, obviously, over time. But I think the one thing I want us to leave us with is that the infrastructure is going to get ready really fast. It's not going to take a long time. It's actually pretty much here that people can build reliably.
01:01:50.590 - 01:02:14.064, Speaker B: People have the UX experiences, you know, if it's not here yet. Exactly. It's coming really, really soon. And our team is hyper focused on providing at least one clear path of making sure that there's a great fully integrated stack, a great user experience, you know, low fees, and something that hopefully folks like Celestia and movement, you know, leveraging other networks, we love that, and we're going to push that future as quickly as we can.
01:02:15.484 - 01:02:36.360, Speaker A: That's great. Well, guys, amazing work. Well, obviously, link to your total handles and projects. Um, so, really exciting. Uh, I I guess we. We ought to probably do a checkup in six months, because to your point, Avery, like, if you weren't paying attention and you left the bear market, you know, back, like, you'll be shocked at the state of infrastructure and how that is so quickly, uh, evolving. So, great work, guys.
01:02:36.360 - 01:02:39.644, Speaker A: I really appreciate you coming on and sharing your thoughts. Uh, I really enjoyed it.
01:02:40.304 - 01:02:44.704, Speaker D: Thank you, Sandra. Nice chatting with you, Avery and Rushy. Bye.

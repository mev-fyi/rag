00:00:00.280 - 00:00:13.526, Speaker A: Why do we have kind of sequencers in general? It's like, because users prefer faster block times and they want those soft commitments. And you say, okay, well, why would we decentralize that? Well, because we still want to remain decentralized.
00:00:13.670 - 00:00:33.622, Speaker B: This episode of Empire is brought to you by quick node. Quicknode is an end to end blockchain development platform that makes building web3 apps super easy. No matter what you want to build, you can effortlessly develop any application by leveraging their elastic APIs. Go to quicknode.com comma, use code Empire. You'll get a free month on their feature backed build plan. That's right.
00:00:33.622 - 00:00:58.914, Speaker B: Go to quicknode.com comma. You'll get a free month to start playing around. You'll hear more about Quicknode later in the show. This episode is brought to you by Quenta, the premier derivatives platform on optimism that offers deep liquidity, low fees, and up to 50 x leverage across 24 different assets. You'll hear more about Quenta later in the show. All right, everyone, welcome back to another episode of Empire.
00:00:58.914 - 00:01:06.818, Speaker B: You got Santin me today, and then we've got Ben, CEO of espresso. And then we have Josh, CEO of Astria. Ben and Josh, welcome to Empire goes.
00:01:06.866 - 00:01:08.322, Speaker C: Thank you. It's great to be here.
00:01:08.338 - 00:01:16.570, Speaker B: Thanks for having us, man. You guys are doing the blockworks rounds these days. I think two blockworks pods in two weeks. How you doing? How are you feeling about it?
00:01:16.722 - 00:01:17.890, Speaker C: It's pretty great.
00:01:18.082 - 00:01:20.062, Speaker B: It was great to be on heroic research. Good.
00:01:20.118 - 00:01:45.390, Speaker D: We wanted to warm you guys up because obviously Empire is the best podcast, not, you know, of the blockworks family, but, you know. So anyways, it's great to have you guys on. Heard a lot of really good things about what you guys are doing. For all of our listeners, one of the more important topics that we've been talking about recently is scalability. And in that context, sort of the l one l two. We've had the arbitrum guys, come on. We've had starcore guys, come on.
00:01:45.390 - 00:02:17.484, Speaker D: And I think a lot of the conversation, even the multi coin guys reference of why the l one l two dynamic would not work as well is because of this sequencer. And the idea of decentralizing the sequencer has come over has come up a number of times. So I think this episode would love to touch on that, as well as what you guys are building. Why is that so important? So maybe we can start with intro guys, Josh and Ben, maybe you guys can just give us a little bit of background on how you got started.
00:02:18.944 - 00:03:03.490, Speaker A: I'm Josh, CEO, co founder at Astria. Prior to Astria, I was at Celestia, and my work there was on how do we deploy roll ups more generally on Celestia, taking a slightly distinct model from the existing l two s on Ethereum and that existing known paradigm, with optimism and arbitrum being the primary examples at the time. Prior to that, worked at Edge and node, who runs the graph for a little bit. And then before that, I spent maybe too many years at Google, mostly within the cloud. So, yeah, that's kind of like my long history there. Kind of broadly, what I focused on in my two and a half or so years. And crypto is generally around research and scalability more broadly.
00:03:03.490 - 00:03:10.014, Speaker A: And I still see shared sequencers, decentralized sequencers, as just kind of a continued extension of that general research.
00:03:12.794 - 00:03:27.854, Speaker C: And I'm Ben. My introduction to the industry was initially through academic research. I was doing my PhD at Stanford in applied cryptography, and then ended up working pretty much from 2015.
00:03:29.674 - 00:03:30.122, Speaker D: Through the.
00:03:30.138 - 00:04:27.704, Speaker C: Current day on applications of cryptography to blockchains. And I ended up focusing a lot on questions around not only alternative ways of doing consensus in permissionless networks, alternatives to proof of work, proof of stake, proof of space, et cetera, but also how to use cryptographic tools to scale the performance of blockchains. And so I worked in the early days with Filecoin, with Chia, I worked on problems related to randomness, beacons that ended up being incorporated into the design of present day Ethereum. And my journey to espresso systems was really just a long term passion for how do we scale these blockchains, but without compromising on what they're supposed to do and what their core principles are around decentralization. Decentralization and fault tolerance.
00:04:28.764 - 00:04:45.330, Speaker B: Ben, can I pick on you? Just almost at the risk of starting too basic here, can you just give us a definition of sequencers and what they look like today? And maybe there's a second part of that question, which is like, just validators, like, what they are and really like, what is the sequencer?
00:04:45.522 - 00:05:48.586, Speaker C: Yes. So a sequencer is a term that has arisen from this now more modular description of blockchains and what they do. Right. So the original concept of a blockchain is you have a distributed virtual machine, and it has to order transactions to a state machine and execute them. As soon as we started shifting to outsourcing some of these roles to L2, namely proving and execution, which is the core of how rollups actually achieve scalability or remove computational bottlenecks in blockchains, then we still have all these roles that we need to take care of. If you have a roll up that's proving the result of executing some sequence of transactions, how do those transactions get ordered? Do they get ordered by the l one and just not executed? Or is there an external system that is handling that ordering? Similar to how now we've separated out data availability into data availability layers. All of these are required for consensus.
00:05:48.586 - 00:06:12.404, Speaker C: You need to make the data available. You need to make sure that the available data is ordered. That's what a sequencer does, whether it's a single computer or a decentralized consensus protocol. And then you need to execute these transactions that are available in the order that they've been ordered in order to derive the resulting state of the machine and convince all the other clients connecting to the system of that current state.
00:06:14.064 - 00:06:22.644, Speaker B: And, Josh, maybe, can you just frame this conversation for us a little bit more? What is the state of how sequencers work on rollups today?
00:06:23.544 - 00:07:18.784, Speaker A: Yeah, so rollups today generally conflate. What I think Ben and I would agree is actually two components of, you know, sequencing. It'll be like sequencing and like, like validating to some degree, right. And that there is sequencing, which is just ordering the blocks, right, and defining for a given, like, fork of chain, like, what is the canonical ordering of, you know, this block? And then how do we append the block onto that, right. How do we get this kind of chain? And then there is also generating the state route. So this is the execution part, right, of applying a given state machine transition function over an ordered set of blocks on top of the previous state route at the end of the previous block. We view sequencing as purely just the act of taking a set of transactions in a mempool, or however you're choosing to gather these kind of unordered transactions, and then producing this ordered block, and then attesting to that ordering.
00:07:18.784 - 00:08:01.630, Speaker A: That's an important component of that. In the existing state, you have these centralized attesters run by arbitram or optimism, that say, hey, here is the order of the block, and then they will batch that, make a transaction, and then submit that to the call data on the contract they have on the ethereum as their l one. But they will also do a second step, which is attesting to a given state route and actual state of the state machine for the l two. I guess the key distinction, I think, of the shared sequencing is that we separate that sequencing into just the ordering step, whereas right now they're doing both the ordering and the validation and attestation of that given stateroom.
00:08:01.822 - 00:08:30.974, Speaker B: Okay, so today we have basically three layers. You have the DA layer, the data availability layer, you have the ordering, and then you have the execution layer. Today, is it fair to say that sequencing and then determining the state and execution are kind of like they're kind of all, they're kind of all happening in one layer, but in the future those will be like almost owned by different folks who specialize in that thing. It's kind of a fluffy way to describe that.
00:08:31.474 - 00:09:17.000, Speaker C: No, that's a good high level description. I may just add to that that. So today most layer one blockchains do all three of those things, right? Like Ethereum does all three of those things. And also most roll ups that are running on top of Ethereum. Maybe they're using Ethereum for data availability, but then they're taking ownership of and actually centralizing both the sequencing and then the execution and proving. So I do expect to see that these rules will become more modular, that at least the decentralization. So it's not clear that proving needs to be decentralized, because once you've determined the ordering of transactions in the state machine, then anyone can submit a proof.
00:09:17.000 - 00:09:50.184, Speaker C: It's not really like a permission role, it's just you have a correct proof or not, or the same for fraud proofs, but the determination of who gets to be included and in what order. That shouldn't be centralized if you want to retain the original properties of blockchains. And so the reason why it became centralized is mostly for performance reasons and that it was too expensive or not good for the user experience to use Ethereum as an l one for both availability and ordering.
00:09:51.244 - 00:10:28.004, Speaker D: And maybe to this as a follow up to that. How complicated? Like if you're the arbitrum team or the optimism team, not to pick on one or the other, but just why is it a fair characterization that they've punted this, maybe hoping that someone like you would come in and fix it? Or is it more like a technical problem that they would hope that the user experience would be vastly, you know, better that at some point you figure it out like this sort of progressive decentralization that a lot of teams take in crypto, right?
00:10:28.584 - 00:11:25.374, Speaker C: Yeah, I think almost, I can't think of a project that I'm aware of that doesn't have decentralization somewhere on the roadmap. It's hard to say as a selling point of a scalability solution that, hey, we've solved the scalability problem by centralizing the process of ordering your data. Now it's losing one of the core principles, it's losing the credible neutrality of the system, it's losing the anti monopolistic behavior of the system. So among others, and I think rollups just see this as like an iterative process. Right? It's already hard to build a ZKVM or an optimistic vm, and so they started with centralized sequencers because it's simpler, you can get a product off the ground. But I think either teams are planning on building their own decentralization solutions for that sequencing step, or they are hoping for other people to solve that problem and, and then they can just plug in.
00:11:26.274 - 00:11:48.894, Speaker D: From a user perspective, what's the worst that can happen in today's environment where it's centralized? What are the biggest risks? And maybe there is some nuance between, as I understand, between arbitrum and optimism. One has fraud proofs, the other one is not both by and large, or centralized sequencers. But I'm curious if you could go into like what's the worst that can happen in the current state of these l two s?
00:11:49.354 - 00:12:13.634, Speaker C: Boy, I mean, that's a. And I'll let Josh jump in here too. I don't mean to hog the mic, but that's like a really deep question, because you could ask that question about blockchains overall. The question is, what's so bad about a centralized system and what are the advantages of blockchains? So we could probably spend a whole podcast series talking about that. And I think that it's not like, there isn't like an obvious answer to that. I think that it's very nuanced. Right.
00:12:13.634 - 00:13:13.974, Speaker C: And you can look at the evolution of how applications have been built on blockchains and how the decentralization may or may not have led to that. But some of the things that I like to emphasize about a centralized system versus a decentralized system are, one, credible neutrality, two, I think that from an economic perspective, one of the most incredible things about blockchains are that they achieve services with network effects but without monopolization. One of the reasons why Internet services are so monopolized is because there are very strong network effects around Internet services. It's hard to compete with Facebook, it's hard to compete with, with even the existing banking system. Right. It's difficult to get users to switch to a new system because all the state is in one place, all the other users are there, all the liquidity is there. In the same vein, it's hard for another blockchain to compete with Ethereum, right, because it has all the liquidity, all the users, all the applications.
00:13:13.974 - 00:14:13.434, Speaker C: What's amazing about Ethereum is that because of the decentralization of its validator set, and specifically the set of nodes that get to determine what ends up getting included and how it's priced and how it's ordered, et cetera, is decentralized in a way that quasi fosters competition among the different nodes. Decentralization leads to more short sighted, myopic behavior of participants, rather than engaging in long term strategies to price out users who aren't willing to pay enough. If a blockchain were centralized, then you might see pricing that involves keeping it so that only one party can transact who's willing to pay a million dollars. The revenue maximizing price might be above what the market clearing price is, where supply meets demand. And so the problem with scalability is like, how do we increase the supply side, but we don't want to lose the decentralization? Because if you increase the supply, but you lose the decentralization, it doesn't matter. You now have a monopolistic system that will just determine sort of a monopolistic strategy of how, how to allocate resources.
00:14:14.494 - 00:14:31.294, Speaker B: Josh, would you add to that? I mean, it sounds like, Ben, if I had to almost repeat that back, it's like the risks of having a centralized sequencer are censorship, like risk of reordering, risk that it maybe goes down, and then that last thing that you were saying is broadly categorized as malicious behavior, basically.
00:14:31.414 - 00:14:35.942, Speaker C: Well, monopolistic. I wouldn't go so far as, say, malicious is from an economic perspective.
00:14:36.038 - 00:14:37.690, Speaker B: Right, exactly.
00:14:37.822 - 00:15:18.592, Speaker D: And, Josh, feel free to go and answer this, but are users funds ever at risk in the sense that, you know, someone can? Because I think at some point security becomes important. Where is there a backdoor? Can people rug you are, your funds are at risk? A lot of times we've talked to teams and they say the worst that can happen is there's a delay, but you will always get your funds back because they can't. There's not like a, an ability for the particular team that's behind the project to kind of rug you and take your assets. There might be a delay, but by and large. So I want to make it clear for our listeners if there's that risk today in the way these l two.
00:15:18.608 - 00:15:20.296, Speaker B: S are operating, I think one key.
00:15:20.320 - 00:16:02.880, Speaker A: Thing is the only party that is allowed to append a new block to the chain is the centralized party and centralized sequencer. That's the fundamental structure of it. That doesn't mean that optimism or arbitrum has access to your private key and can sign a message that moves your funds from your account to an. They could just like, hard fork the chain, right? And just like zero out your funds, right? If they just say, hey, we're gonna like zero out this address, we're on the hard fork the chain. That is pretty obviously detectable in that. Like, you would then go connect to like, the RPC and be like, oh, look, my money's gone. And like, whether your ability to, like, prove that, right, fraud proofs are this kind of verifiable mechanism to actually, like, prove that, like, an invalid state transition, like, occurred.
00:16:02.880 - 00:16:58.800, Speaker A: So there's various kind of things like that I don't want to dive too much into. Kind of the social question of like, could they hard fork the chain in like, an undetectable manner? If we assume that is kind of out of the scope, then no, they can't steal your funds. From a censorship perspective, they do have what's called the escape hatch or whatever you want to term it. But this forced withdrawal transaction to the l one by way of submitting a transaction directly through the l one smart contract, and then that inherits the censorship properties of Ethereum cell one, which are very, very, like, good, right? Like, it's unlikely that you're going to be censored. Good. Within ethereum, I think the more kind of concerning things right now is like, okay, you know, in like a congested gas time or whatever, right? If you're censored by the sequencer, like, the quality of your service degrades. If for whatever reason the sequencer says, I don't like you and I'm not going to submit your transactions in batches, you're going to have to go through the l one, you know, then you have to suffer whatever is, like, the l one cost to some degree.
00:16:58.800 - 00:18:15.922, Speaker A: There's a question of like, you know, the cost savings of submitting like a transaction to the l one versus, like, through the l two. What is the benefit of using the l two if you kind of are forced to fall back to that, right? So it's like, you know, should be assumed to be like, like a failure mode, right? It's a more acceptable failure mode than like, your funds are locked forever, you know, to like the MeV discussion, right? Which has been like, obviously, you know, you're very happening lately, right? Like, you know, there's this question of like, either optimism and arbitrum by way of like, sequencing are like extracting all of the MEV or none of the mev, but like they're the only party that is kind of allowed to extract this MEV, whereas all the other MEV is like this first come, first serve, right, which is essentially just like this probabilistic spamming of trying to get your transaction in. But it's, again, to the detectability of these faults, I think is one of the big questions of could you detect if optimism was front running every transaction or whatever? Probably. But again, one of these difficulties of blockchains inherently is how do you know if optimism controls this pool of addresses or whatever that happens to have transaction testing that happen to be front running, et cetera. So there's things like that. I think to Deben's point, it's this credible neutrality. It's just hard to verify whether or not it actually is being neutral.
00:18:15.922 - 00:18:33.554, Speaker A: But I do think it's important to note that in existing optimism arbitrum designs, and I'm assuming for the ZK evms as well, your funds can get out. You have that escape hash mechanism, and it's not like the centralized sequencer is capable of signing a transaction with your private key.
00:18:35.014 - 00:19:48.934, Speaker C: Yeah, I think, though when it comes to talking about security, it's easy to oversimplify. I think that in some ways, even just comparing centralized systems and decentralized systems, it's an apples to oranges comparison. There isn't one is not clearly more secure than the other. We really need to unpack that. And in particular here, when we talk about rollups, if we just talk about, okay, let's say you bridge over assets from ETH, you deposit ETH into the roll up, then can those be stolen? Right? No. If there are mechanisms for always, like if there's an escape hatch, if there's a way of withdrawing, if Ethereum is always verifying the state of the roll up and ethereum, there's a commitment on an Ethereum smart contract to the definition of that virtual machine, then no, from that very narrow perspective, these funds can't be stolen. On the other hand, if you look at the virtual machine as being defined by the company that's running the virtual machine, and they can change the way it works and they can update the smart contract, and you look at the security of assets that are not just bridging from Ethereum to the roll up, but the security of transactions and the finality of transactions within the roll up itself, then the question becomes more complicated.
00:19:48.934 - 00:20:15.778, Speaker C: Yes, proofs are being verified by Ethereum, maybe every few hours, but if the roll up is giving you soft confirmations as a centralized sequencer and you're trusting those for finality, and then you go and send some goods to someone, then you are at risk of that being reversed. Right. So I think it's like a pretty nuanced question. So there isn't just like a really easy, straightforward answer to it, because I.
00:20:15.786 - 00:20:48.406, Speaker B: Have a question just actually, okay, so there's like three roles of a blockchain, right? This is, I'm gonna, I'm still almost struggling to grasp one thing. So like three roles of a blockchain, you have guaranteeing the availability of the data, the data availability layer. Then you have achieving consensus on transaction ordering, and then you have executing the transactions. Why does an l two or rollup even need a sequencer? Why can't you just use an l one for both the first two buckets for ordering the data and the availability of data?
00:20:48.540 - 00:21:08.946, Speaker C: You can, you can absolutely do that. I think that's one of the, like the points. Um, and this is something that I like. It's a great, it's great that you're asking this question because I don't think it's like, it's, I don't think it's obvious to the, to the whole, to the whole industry. Like you can absolutely use the l one. You can use Ethereum for making the data available, available, available. Ordering it, not executing it.
00:21:08.946 - 00:22:35.748, Speaker C: And then, and then just what is the job of a roll up? It's to report what the state execution result is and then either just post that and put a bond to it and wait for someone else to challenge it through a fraud proof, or to just prove straight away, using snarks, that it is correct. And so what roleups really do are just separating ordering from execution. That's literally all they do. The question then becomes, well, is Ethereum as a layer one, is that ideal for the making data available and ordering it right? Or is there room for improvement? And so the other thing is that there are fundamental design trade offs of both the a layers and consensus protocols for ordering. You can be dynamically available, but then have long latency, or you can have optimistic responsiveness and the potential to give faster confirmations, but then not be dynamically available. And that's why my perspective today is, well, you can get the same validator set to essentially run more than one ordering service so that users can choose which one to use. And that's like the approach we're taking at Espresso, which is use Eigen layer to get the Ethereum validators to run an optimistically responsive protocol so that users just have more options.
00:22:35.748 - 00:23:12.524, Speaker C: But they can totally use Ethereum as well. Presuming that Ethereum improves its, I mean, once bank sharding comes onto the scene and improves its way of handling data availability in a more scalable way, which is like Ethereum today is not really set up to do, then it will become a good service for data ordering and availability. And some of the work that other projects in the L2 system are doing in the modular blockchain ecosystem like Celestia, like us, is just to build systems that are optimized for the availability and ordering roles, with an eye towards the fact that they don't have to do other things like execution, and that that's outsourced to a different process.
00:23:13.064 - 00:23:39.184, Speaker B: Okay, so I get all of that then. I guess the second part of that question is like, why would an l two want to use an external sequencer here, right? Like if you have a centralized sequencer, it's this honey pot for Mev and Ben. All the things that you mentioned, censorship, resistance and monopolistic behavior, those are all things that are really good for the user or that you're trying to help the user with. But if you're the l two.
00:23:42.924 - 00:23:43.188, Speaker C: I.
00:23:43.196 - 00:23:51.524, Speaker B: Don'T really get the incentive to use an external sequencer. So maybe I could hear both of your guys take on this because I know you're both. Obviously those are the two big core things that you're working on.
00:23:51.644 - 00:24:59.568, Speaker C: Yeah, really good question. I'll go quickly and then bump it to you, Josh. First of all, to make, to accrue value, a roll up needs users. So doing things that are better for users does lead to more, especially in a competitive environment where there's many different roll ups out there and users get to choose which one to use. I think it is important for rollups to consider what's good for users. What do users want? The conception that by moving sequencing to another system, whether it's like ethereum, l one, or another system in the modular stack like Celestia or espresso or Astria, etcetera, for handling availability of data and ordering, it doesn't mean that value won't be shared back to the roll up. In fact, there's a strong incentive for the communities to align a system like Celestia or extra or espresso have, and their stakeholders have, have a strong incentive to retain rollups as users.
00:24:59.568 - 00:25:39.184, Speaker C: Roll ups can easily move away if they're not getting their fair share of the value and so it becomes an economic allocation problem, which has its own challenges, not just in the blockchain space, but it's like if you have all the phone companies using a common infrastructure, then how do you price things, right? How do you allocate revenue as well? And that's a solvable problem as and if overall the system is increasing, is better for users and it's more interoperable, and thus creates more economic value overall, then there's a larger pie to share. Josh, I'll bump it over to you.
00:25:39.804 - 00:26:45.886, Speaker A: I think I agree with those points. I think going back to the previous question of why would one like, why would you not just use ETH L1 for your sequencing? And fundamentally, it's a user demand question, optimism and arbitrage original design, where you will post the transactions to the l one. The l one will then just provide availability for them, and you'll have this off chain process that gives the state route and attests to the validity of these transactions and has a challenge mechanism. But fundamentally, users prefer faster block times. One of the reasons I see decentralized as a worthy thing is, is this general idea that maybe it's somewhat cynical, but users, I believe, will trend towards something that provides a higher quality user experience in a visual manner to them. What I mean by that is they will feel that it takes 2 seconds for a transaction to go through, then 20 seconds for a transaction to go through, and they will prefer the two second one. What they won't visually see is the trade off they are making that resulted in one being 2 seconds versus one being 20 seconds.
00:26:45.886 - 00:27:44.278, Speaker A: You know, it's one of these general, difficult things of cryptography and security kind of things in general is you become aware of them when they fail catastrophically. And prior to that, everyone just assumes everything is going smoothly, and then is it too late once the system fails catastrophically, to say, well, you already accepted some trade offs you weren't aware you were accepting. So that's what I see is like, why do we have kind of sequencers in general? It's like because users prefer faster block times and they want those soft commitments. And you say, okay, well, why would we decentralize that? Well, because we still want to remain decentralized, to Ben's point. Right. And the modular thesis generally is the idea that you can do one role, or a smaller set of all of the roles of a blockchain in a more optimized manner by just doing that. Right? And so we can say, well, this thing is providing sequencing, and it's providing decentralization guarantees not necessarily as strong as Ethereum.
00:27:44.278 - 00:28:40.714, Speaker A: It might not have that size, the validator said. It might not have that economic weight, but it's giving you this soft commitment that is stronger or more credibly neutral than what you get from a centralized provider. So it's still an improvement, but it's also still giving you the user experience that the users want. And what this is fundamentally providing is an alternative to a user using a centralized system. The job fundamentally is providing users with a good enough experience without requiring them to sacrifice the decentralization principles to get that better user experience. Because if the only option available to them for this high quality user experience that is ten times better or whatever significant enough for them to move from wherever they are is centralized, then some percentage of users will do so. So I think it's important to provide them an option that is still decentralized while providing that good user experience.
00:28:41.614 - 00:29:05.546, Speaker B: So I've heard this concern that rollups running on shared sequencers won't see the same value accrual as rollups running on their own sequencer. But I think both of your pushback would be like consumers and users will end up preferring l two s or rollups that end up decentralizing their sequencer, and therefore they actually will accrue more value because users will flow there. Is that correct?
00:29:05.710 - 00:29:06.694, Speaker C: That is true.
00:29:07.594 - 00:29:51.554, Speaker A: I think that's like maybe an optimistic take. I take a pretty cynical perspective in that generally, I assume users just quite frankly don't give a damn about decentralization, at least some batch of users. My view is to growing the pie question we have x tens of thousands or millions or whatever. Tens of millions crypto users. I don't know where that comes into daily active, monthly active, whatever. But if we want to grow the pie, my assumption is that each new user is somewhat less ideologically aligned with the ethos of crypto than the existing batch of users. And so as we move from the people using bitcoin in 2011, we have generally gotten on average less motivated by the decentralized principles of it.
00:29:51.554 - 00:30:50.676, Speaker A: And so it is somewhat on us as creators of technology to reinforce those primitives and provide good user experiences to users who quite frankly don't necessarily care about it being decentralized. I'm not convinced that decentralization on its own is like a selling point to users. I think you kind of have to do like an active marketing campaign to go say, look, we believe it is unacceptable for these roll ups to be a point of centralization. We think it is normalizing points of centralization as an acceptable kind of thing within these overall decentralized systems. And it kind of trains users who are just not going to have the time, the energy to think about these things as thoroughly to say, oh, that's actually fine, because, look, they've been doing it for two years. If they do it for five years, then this is the status quo, this is the normal thing. So I really do think it's partially a marketing campaign, a pr thing, to say, no, this is an unacceptable status quo and we need to change it.
00:30:50.676 - 00:30:58.464, Speaker A: But you need to do that in such a way that doesn't make the users make these horrible trade offs in user experience. And that's really our job here.
00:30:59.294 - 00:31:02.434, Speaker D: Would you say the regulation is the main catalyst here?
00:31:03.734 - 00:31:41.894, Speaker A: I think from an exogenous state, yeah, I think internally we should be pushing it as a community. We should say we should be decentralized for the sake of being decentralization. I think exogenously, if one of the founders or whatever of arbitrage or optimism shows up on tv in handcuffs and goes to jail when we have a whole thing, then, yeah, I think everyone's going to decentralize their sequencers really, really quickly. Right. But ideally we can just kind of altruistically move towards saying, hey, these are the ideals of the industry, and we can meet them without needing to be directly threatened by the external kind of governing agencies.
00:31:44.354 - 00:32:32.162, Speaker C: I don't fully, I just, I don't fully agree with that perspective. Like, I respect that perspective, but I don't think that users don't care about decentralization or that decentralization is solely for the purpose of regulatory arbitrage. The thing that I would push back on is that users like and care about the effects that come from decentralization, even if they don't say they care about, have an opinion about decentralization or not itself. Users like the fact that all apps on Ethereum are composable with all other apps, and that comes from the fact that Ethereum is a decentralized system. They're all sharing the same system. They're all interoperable. Right? Imagine a centralized, you're not going to have a centralized sequencer that all the roll ups use.
00:32:32.162 - 00:33:13.960, Speaker C: So if decentralization is like a precursor to more interoperability as well, between the roll ups and users care about that, they care about shared liquidity, they care about the fact that if you have cash on one system, you're not going to be isolated for all of the roll ups. Right. You don't have to just buy in to the zksync ecosystem and then not be able to pay for anything on other systems. And so decentralization as a precursor to more bridging between roll ups, you know, more interoperability, and then users also care about the unique services that can be provided to them by block builders. Proposer builder separation does not work with a centralized sequencer. There's no incentive for a centralized sequencer to work with the block builder. Right.
00:33:13.960 - 00:33:45.484, Speaker C: It's a consequence of the myopic behavior of miners in a decentralized system, or validators in a decentralized system that makes them engage in, rather than, rather than engaging in longer term strategies, they engage in shorter term strategies to build the most valuable block they can. And that might be provided by a service like flashbots and flashbuds guarantees users that their transactions don't fail. Right. A centralized sequencer would like to charge users for failed transactions because they can make more money that way. So to be fair, though, that would.
00:33:45.524 - 00:34:21.924, Speaker D: Compromise the user experience, right. There comes a time where if you're interacting in arbitrum, and look, both of them have centralized sequencers, but if they start getting too greedy, then at some point you're going to realize that some users, not all, and they'll migrate over to your other l two flavor of choice. So it's a quasi competitive market. I do agree with you that it is still very fragmented. And, you know, once you acquire a user in Arbitrum, then they can probably get away with some slack from MEV perspective, until it becomes a critical issue and they migrate over to optimism.
00:34:22.584 - 00:34:57.124, Speaker C: Totally. Totally. I think it is a very interesting question is, like, is competition among blockchains enough to achieve the decent? Like, maybe decentralization isn't necessary. If blockchains were all perfectly competitive with each other, and Solana was a perfect substitute for Ethereum, and there would be competitive pressure on miners not to, like, you know, front run users. But I think that that comes back to sort of the core issue, which is that Internet services are prone naturally to centralization due to network effects. And so you do have to decentralize the operation of the Internet service if you want to have long term resilience to these things.
00:34:58.624 - 00:35:30.046, Speaker B: All right, quick break from the show. There is this kind of overused cliche saying in crypto, but it's true. Bear markets are rebuilding, and everyone tells you that, and everyone knows it's. What people don't know is that if you're building apps in crypto and building apps in web3 without using quick node you are building on hard mode. So Quicknode is this amazing blockchain development platform. It reduces costs, streamlines the time to market for your app, and it offers consistent performance at scale. For folks that have built apps, you will know that there are a couple key points here.
00:35:30.046 - 00:36:18.094, Speaker B: One Quicknode offers unlimited endpoints across 18 different chains and 35 different networks. They have response times that are two and a half times faster than any of their competitors, 99.99% uptime and a dedicated 24/7 customer support team. If you've been listening to Empire for a while, you might know that I am no gigabrain developer, but I do know a lot of devs and a lot of great product teams at other places. So when I see Coinbase and Twitter and Adobe and OpenSea and doing analytics, all leveraging and trusting quick node to power their business, that's when we get excited and that's when we want to partner with them. They're the best solution for any leading crypto and web3 company that is seeking an end to end blockchain development platform right out of the box. So my message to you, get off hard mode.
00:36:18.094 - 00:36:36.756, Speaker B: Let quick node handle the blockchain infrastructure. Let quick node handle the security. Let quick node handle the performance. While you focus on building beautiful products for your users, visit quicknode.com. Super easy. You can use code Empire. You'll get a free month on their build plan, so don't forget to use code Empire.
00:36:36.756 - 00:37:16.152, Speaker B: Santi and I got to get credit for this one so they know that we sent you and you will get a first month free. Hope you guys enjoy it. This episode is brought to you by Quenta trade smarter with Quentyn. Quenta is the premier derivatives trading platform on optimism that features deep liquidity, low fees, and up to 50 x leverage across 24 different assets, all powered by synthetix. If you want to trade crypto, forex, or commodities on chain, Quinta is the platform for you. It's built for both the casual degen and advanced traders. It offers stop losses, limit orders, cross margining, and a whole bunch of other advanced order types.
00:37:16.152 - 00:37:35.072, Speaker B: And unlike most of today's web3 products, Quenta has a super easy to use interface, including a position dashboard, charts, and a leaderboard. For a seamless experience, go to Quenta IO. That's Quenta IO right now. Tell them we sent you. Tell them Santi sent you. Tell me sent you. Tell them empire sent you.
00:37:35.072 - 00:37:38.324, Speaker B: Quenta IO. Hope you guys enjoy.
00:37:40.104 - 00:38:18.094, Speaker D: Yeah, so maybe a transition a little bit into the state of your development. And, I mean, there's a lot there that you mentioned, and I want to unpack that in terms of the user experience changing once you decentralize the sequencer, maybe start by saying, okay, where are you guys in this process to make this happen? And as a beta, how does a user experience get impacted? I mean, obviously there's a lot of assumptions there that you have to make. Is it slower? Is it more expensive? Maybe we can start with you, Josh.
00:38:19.194 - 00:39:02.270, Speaker A: Yeah, so just kind of giving like a state of, kind of like our development internally, we don't have anything kind of like publicly available. Our code is public, but we don't have like a public testnet or anything. We have like an internal, you know, developer network. You know, we're working on from like how a user kind of submits a transaction in our testnet. You know, we've structured things such that, you know, it's like roughly similar, like they submit a transaction to like an RPC endpoint of like an Ethereum node that gets included in the shared sequencer, and then the Ethereum node, you know, that, quite frankly, has to be customized. Right. To work with this shared sequencer can pay attention to the shared sequencer and kind of, you know, reads when like a block is included, and then it can check and say, okay, hey, my transaction that I submitted to the shared sequencer was included.
00:39:02.270 - 00:39:40.588, Speaker A: And that runs at the block time of the shared sequencer. Yeah. And on our local devnet, that's like whatever, like half a second or whatever, right. If we run node, one node, right, that's presumably somewhere in the order of like one to 3 seconds or something. It depends on your consensus algorithm and how quickly you want to run that. And yada dada trade offs on mev timing, but roughly that user experience is somewhat similar. I think fundamentally the trade offs might be almost larger, like the developer sense, and I mean the developer of like the roll up itself, in that once you decentralize, you fundamentally have a higher coordination overhead to continue development of something.
00:39:40.588 - 00:40:05.814, Speaker A: If optimism wants to change something on optimism, they can update that. If they have to hotfix a patch or whatever, they're. We have one sequencing node that defines the canonical chain. We just have to go fix that. Same as any other centralized service. You can roll out a hotfix in order of minutes. Whereas if you look at something like, say, the dragonberry exploit on cosmos that affected, you know, the general Cosmos SDK and all of the chains impacted there, right.
00:40:05.814 - 00:40:35.094, Speaker A: It was relatively large coordination effort, kind of behind the scenes to say, okay, we have to get a bunch of people to all update their stuff and otherwise all the chains halt. But we don't want any of them to leak this thing. So there's various things like that. But an end user experience is, you know, it can be structurally similar. I think it will be different than a first come, first serve thing. And there's a lot of points we could go into on, on mev block building PBS, how transaction submission works, order flow auctions. But generally it's pretty similar from an end user flow.
00:40:36.394 - 00:41:01.096, Speaker D: Ben, before I go to you, just curious, who are these sequencers? Like, who are you going out to? Are these like the same folks that are like behind Lido that have doing validation? Are these enterprises or your typical kind of single, you know, sophisticated dev out there? Like, I'm curious, from who the. These entities?
00:41:01.160 - 00:41:01.336, Speaker C: Yeah.
00:41:01.360 - 00:41:04.792, Speaker B: These like industrialized validators or these individuals? Like what?
00:41:04.888 - 00:41:09.644, Speaker C: Yeah, is that question for me or for Josh or both?
00:41:10.784 - 00:41:15.160, Speaker D: Ben, maybe you can go and then transition into talking a little bit about suppose, right?
00:41:15.192 - 00:41:54.234, Speaker C: I mean, building a decentralized sequencing layer is akin to building a decentralized l one. And so we, I mean, we don't have a validator set yet. We're still building. But that's one of the reasons why we're extraordinarily excited about working with Eigen layer, because I think it's brilliant that you already have, you know, 30,000 validators on Ethereum. How many of those are actually distinct? Maybe 10,000 or less. But the point is there's already, if we take, if we start from the premise that there's a decentralized validation set of Ethereum, Ethereum. And that's ultimately what we're trying to scale, right? Or take any other blockchain.
00:41:54.234 - 00:42:41.684, Speaker C: Let's focus on Ethereum for now. Then there's the protocol you want the system to run on, but then there's also the physical set, right? And two different protocols can share the same physical set. So you can get Ethereum validators to. And in fact, it makes complete sense for Ethereum validators to take apart operating the protocols that the L2 of Ethereum is running on. Otherwise, you may even have economic misalignment between the l one and the l two. And so Eigen layer, or restaking more generally, is, I think, a really clever way of subsidizing their entry into the system. So if they already have ETH stake, they don't have to invest into a new token or capital in order to participate in a new service.
00:42:41.684 - 00:43:00.144, Speaker C: And I think it's a brilliant bootstrapping mechanism for acquiring a decentralized physical set to run your new protocol that now offers a different set of properties from Ethereum, not due to a change in the set of physical nodes that it's running on, but due to a change in how the protocol is operating and what it's optimizing for.
00:43:02.764 - 00:43:08.904, Speaker B: Ben, do you want to give a, I know we skipped over your overview on what you're working on if you want to do that.
00:43:10.764 - 00:43:42.144, Speaker C: Oh yeah. So. Well, Josh and I are both working on decentralized sequencing as sort of a layer that can be used by roll ups, whether sovereign roll ups or existing major l two rollups. And our approach is the following. As we discussed at the beginning, you can always use the l one for ordering and availability. You can use Ethereum for that. And Ethereum is working on improving its functionality as a data availability and ordering layer.
00:43:42.144 - 00:44:22.754, Speaker C: But Ethereum is sort of wedded to a certain set of principles around the trade offs it makes in the consensus design space. One of those is dynamic, extreme dynamic availability, so that if only 10% of the nodes are online, the system is still alive. That sacrifices on liveness. So that's why it has extremely long, like minutes long latency. Right. The twelve second block time is just for one block, but you have to wait for multiple blocks to really get confirmation. And so if you take the perspective that, well, part of the reason why users or rollups have moved to centralized sequencing is that users really want that.
00:44:22.754 - 00:45:04.994, Speaker C: They want the experience that you get from a centralized server, which is the opposite of dynamic availability. If the one server goes down, then the whole system goes down. On the other hand, the one server has extremely low latency and can give you fast confirmations. Then let's try to build a consensus protocol that is still centralized and in fact can scale to the same physical set of nodes that Ethereum is running on, but that optimizes for the features of a centralized sequencer, that optimistic responsiveness, for example. Right, and get the Ethereum validator set to run that as an alternative. And then you may have roll ups that choose one or the other based on what they think their users want. Right.
00:45:04.994 - 00:45:22.866, Speaker C: You could run on Ethereum's base layer for your sequencing and availability, or you could run the protocol that we're designing called hotshot, which offers the alternative, which is optimistic responsiveness. But you need all the hotshot nodes. The system only makes progress when 75% are online.
00:45:23.010 - 00:45:59.482, Speaker B: Hmm. Guys, we're 40 minutes in here. I want to almost zoom back out for anyone who's completely lost. Now, Josh, you spend four or five years at Google. Can you guys try to make some analogies to almost like web two land and like, how? To me what I hear is basically everyone's trying to do everything in house right now and you see a world where there's specialization and this is almost like paying, I don't know, Amazon for AWS or something and everyone used to run their own data centers. And eventually we'll live in a world where like there's like AWS and Azure or something. Probably a broken analogy, but I'm sure there's an analogy to be made there.
00:45:59.482 - 00:46:03.894, Speaker B: Have you guys thought about these analogies? What are they? And then maybe where do they break down?
00:46:04.794 - 00:46:47.442, Speaker A: Yeah, so we've used one that I've used in terms of decentralization as a service, and that's because I've worked on AWS, GCP, whatever, infrastructure as a service, platforms as a service, software as a service. And it generally fits into that category of like you're going and buying something off the shelf. I think the analogy is like somewhat apt in that the idea is we want to make it very easy to tie into an existing service. If you're a roll up and you say what we really want to avoid is the roll ups, you say, okay, I'm going to start, I'm going to make a roll up. I'm going to be centralized. We're going to put decentralization on our roadmap. We'll get to that when we burn down every other priority in a very rapidly evolving ecosystem where they're always bumping things above the decentralization.
00:46:47.442 - 00:47:34.604, Speaker A: We can say, you can go say we want to be decentralized, great, we can go get decentralization off the shelf. There are obviously trade offs. There are costs to that, but we offer that as an off the shelf service. And the hope is that we see, in my view, expansion of innovation by way of that problem being solved. One of the benefits, I think, of a lot of the cloud services, which obviously had trade offs, they're centralizing things. You're paying the margins of Amazon or Google or whatever, and we get to competitive questions there. But fundamentally you can say, I can go make a service that focuses on all my effort on a smaller portion of the stack while being able to get a high quality experience equivalent to larger players because everyone is sharing similar things.
00:47:34.604 - 00:47:44.984, Speaker A: You can have similar uptime to what a Fortune 500 company service has without having to staff 50 infrastructure engineers to do that.
00:47:46.204 - 00:47:47.684, Speaker B: Pat, have you thought about these analogies.
00:47:47.764 - 00:49:19.496, Speaker C: Yes, yes, absolutely. I think that the AWS analogy works to some extent in the sense that if you're a company and you want to run a scalable database system, transactional database system, or analytical database system, whatever, you can use AWS, and then you don't have to build out your own distributed system. That works here too, as an analogy, because if you're a roll up company and you don't want to have to build your own consensus protocol that decentralizes your sequencer, then you can use what I'm building or what Josh is building. But I think the analogy kind of stops there, and there's, I think, a much bigger picture here, which goes back to the whole story of blockchains from the very beginning and how we've. I've been in the industry for a very long time, and kind of a lot of the questions we're asking here, sort of we were asking as well when everyone was just developing their own l one. And then there was a question of, why build an app? Why not build your own blockchain for your app, rather than just build an app on another blockchain like Ethereum? And that's where this analogy with AWS completely breaks down, because people don't use AWS in order to talk to other services that are running on AWS. When people stopped just building competitive l one s and realized, oh, wow, I can build a much more successful product by building an application on Ethereum that now plugs into all the other applications that are running on this shared vm.
00:49:19.496 - 00:50:13.340, Speaker C: And Boom, we had defi boom, we had nfts, we had all this explosion of activity that took us away from just the ICO boom of minting your own token and doing, to some degree, people minted tokens on Ethereum. But we moved away from just everyone building a competitive blockchain to people working with the same blockchain and taking advantage of this shared state, which is really one of the reasons why blockchains have brought so much more economic value to our society. It's the same exact thing here. If every roll up runs on its own isolated system and they're not talking to each other, it's just like l one's in the early days, competing with each other, and everyone's just going to build their own custom blockchain for their own custom app. I want to put music on a blockchain, so I build my own blockchain. I don't build an app on Ethereum. That changed.
00:50:13.340 - 00:50:27.664, Speaker C: And so that's exactly what we're seeing now, I think that there's incredible economic value that can come from sharing infrastructure, from sharing state and sharing. The sequencing layer is one step towards that. It's not the complete step, but it does greatly facilitate that.
00:50:28.284 - 00:50:40.456, Speaker B: What are the economic implications of all of this? Josh, you've mentioned MeV a couple of times. How does Astria and Espresso would love to get both of your takes plan on addressing this? Yeah.
00:50:40.480 - 00:51:13.346, Speaker A: So I guess it's like a deep question that I don't know how much time we have, right. But obviously any MeV discussion can take however much time you have to fill. But generally the implications, I guess we talked about the centralized sequencers where right now we're just trusting that you are not being front run by optimism or arbitrum, using whatever sock puppet account they may or may not have in front of your transactions. We're going to be kind of like, like optimistic here, right. And assume they're not doing so within this kind of like credibly neutral system. Right. You know, even if you have ten, you know, nodes in like a sequence or network or whatever, that's rotating.
00:51:13.346 - 00:51:50.714, Speaker A: Right. Any one of these is, you know, now competing with the other to some degree, depending on how you weighed it, we'll assume it's like proof of stake or whatever, right. And so it's in their benefits to like be economically like most profitable, right. You know, you have this competition like intra network now, and so each validator, sequencer, whatever within the network wants to be like the best in return, the most profit for, whether you're getting kind of like a staking or like a delegation, stuff like that, right. And what that leads to, right. Is kind of like MeV as this way to capture more rewards, because fundamentally there is value in transaction ordering. The job of a sequencer is to order transactions.
00:51:50.714 - 00:52:57.494, Speaker A: It is economically in the best interest of whoever gets that role for this slot to extract that value, whether they hold that themselves or whether they return that to their delegates or whatever. But it's kind of in their interest to kind of capture that value. How that plays out, I think it's like a larger question, right? Whether it's, you know, you have many roll ups and each roll up is making an argument for, hey, we are contributing this much economic value to the chain. Any MeV that gets extracted should be returned to like the roll up. There's questions over whether it should, just in my mind at least, whether it should be turned to users, whether there is, it's desirable for kind of as Ben points out, this kind of network of people within this shared network that have more interoperability. Do we want to be encouraging kind of really strong boundaries between the different roll ups to say, well, this roll up gets this slice of the pie and this roll up gets this slice of the pie versus you are users of a singular network and then roll ups are one kind of like sub state machine within this larger network. I think that's an open question we're going to kind of investigate like have to kind of evaluate here.
00:53:01.434 - 00:53:58.728, Speaker C: Yeah, I think that we can start with asking, okay, well, what if every single roll up we're just running on the same sequencing layer, but, but we didn't have interoperability or cross roll up transactions? I don't think it's actually the shared sequencing layer that complicates it. It's the existence of cross roll up activity. So let's, let's start with a world in which everyone is just running their roll up using the sequencing layer, as they would use a data availability layer. Then they're paying infrastructure costs for using the sequencing layer. But whether it's even though, if the sequencing layer is actually determining the ordering, it's easy to see. Okay, transactions for roll up a are isolated from roll up b. So any, any value that's extracted through bids that users are making on ordering preferences, which is just what MEV is, it's a form of fee accrual.
00:53:58.728 - 00:54:46.254, Speaker C: It's accruing for combinatorial preferences and not just simple demand for gas, then that value could be given entirely to the roll up, and the roll up can decide how to allocate that among its stakeholders, approvers, et cetera. That is an economic contract between the sequencing layer and each roll up. Where it gets complicated is when roll ups start to take advantage of the fact that they're now running over an infrastructure that makes cross domain activity so much easier. Right, but that's a thing that users want, so it's an inevitability. And shared sequencing just makes it easier for that to happen. Even if you didn't have shared sequencing but you had bridging, this would become a challenge. Now you have bridges handling transactions that should only be executed on one or the other.
00:54:46.254 - 00:55:11.914, Speaker C: The user would not be transacting if it weren't able to transact on both simultaneously. So how do you now divide the fee that it's paying between the two parties? And that becomes trickier to figure out in terms of economic allocation. It's a fascinating economic research question that I'd love to engage everyone on, but I think that this is totally solvable.
00:55:14.014 - 00:55:33.754, Speaker B: Nick White had this tweet, I think it was yesterday or earlier this week. He said the shared sequencer paradox. He said, option a, extract Mev, but be less attractive for roll ups to use. That's option a. Option b, don't extract Mev, but lose value capture. So what do you do? What do you think about that question?
00:55:34.754 - 00:56:19.940, Speaker A: Or there's probably, yeah, my view. It's like to Ben's point about the combinatorial kind of complications of this. There's a question of, can you calculate this in real time? How do you calculate the counterfactual? I think one of the big questions is you say you have two roll ups. There's only one roll up being present. There is only the Mav on that roll up, with only the other roll up present. The same thing. How much of the kind of like MEV that is extractable is created by the existence of both? Which of them is contributing which portion of that? How do you calculate that? That, I think is the really messy economic question to the fundamental idea of like, what percent of all the MEV would be extracted across like a shared sequencer.
00:56:19.940 - 00:57:22.550, Speaker A: I think that runs into kind of ideological questions of like, you know, the arbitrum versus like, flashbot divide. Right. Do you fundamentally view an auction mechanism for ordering as an illegitimate kind of moral position? I do not, but that is a moral position some people have taken. But if you don't, then I do generally think you relatively rapidly accelerate towards all of the MEV is extracted and the barrier there is really these things like MeV share order flow, auction things like MeV Wallet by James Prestwich of like, just give the user more tools to specify their preferences upfront such that they are not just kind of sending these transactions that have enormous slippage limits so that they are getting front run or sandwich or wherever to have that MV extracted. And they're kind of negotiation can happen in that market where you say, well, hey, I'm going to submit a transaction with really, really low slippage. And you say, all right, well, it might take a while for your transaction to be included, but then you will only suffer that slippage. Right.
00:57:22.550 - 00:57:53.084, Speaker A: And the user can choose kind of their preferences in that. So I guess, you know, coming back to kind of, you know, Nick White's point, I generally think that the shared sequencer themselves, you know, once they instate, if they instate, you know, some PBS style market place, whether it's, you know, an in protocol PBS or an extra protocol, PBS, we'll probably extract like the bulk of the MEV available. That is like profitable for builders, searchers, whatever, to like find and extract. How the revenue gets shared after the fact is probably the larger, stickier question.
00:57:55.224 - 00:57:56.408, Speaker B: And you agree with that?
00:57:56.536 - 00:58:28.120, Speaker C: Yeah, especially the last thing that Josh said. I don't think that there's really a paradox here. I think it's more nuance than that, and it's exactly what Josh said. I think we can expect sequencing layers similar to any other decentralized system like Ethereum, to take profit from users who are paying for their combinatorial preferences. That is essentially what MeV is. And then the question is, how do they allocate that among the roll ups that have decided to use them and essentially feed them?
00:58:28.272 - 00:58:33.324, Speaker B: Are rollups with different block times still composable if they have a shared sequencer?
00:58:34.464 - 00:59:01.190, Speaker A: So I think that's actually an important point to note. And Ben would love to understand if you have a different perspective, because that changes my view quite a bit. But our view is that like the shared sequencer defines the block time of like the roll ups that use the shared sequencer. Like the shared sequencer has a block time. And if you use the shared sequencer, your block time is that because they're making these like, you know, mega blocks or meta blocks or whatever you want to call them. Right. Then your roll up is extracting its subset of stuff from that block.
00:59:01.190 - 00:59:04.714, Speaker A: Right? That's like my view, Ben, if you have a different point.
00:59:05.334 - 00:59:50.534, Speaker C: No, I have exactly the same view. However, I think that, like we can look at the block time of the sequencing layer is just the block time of the sequencing layer, right. You can build an application on top of it that introduces a different kind of latency to some degree. And let's say that, for example, you have a builder for a given roll up that wants to take longer to build a block. It could buy up the, you know, the slots to process for a certain amount of time. And this is just a straw man. I think there's a lot of caveats to this particular thing, but it's maybe an easier thing to understand just as a strawman.
00:59:50.534 - 01:00:42.514, Speaker C: Imagine there's a builder that, you know, you auction off the right to process the next ten blocks for. For a given. For a given, you know, for a given roll up that's being sequenced by the sequencer, then now that that builder is going to take ten block periods in order to build a super block, and now you have a longer block time for that roll up. So that's just a simple way of illustrating how you can always build things on top of the system that gives you some kind of guarantees that put other restrictions because you're trying to do something at the application level. You can even do this at the application level. An application and a smart contract on Ethereum could effectively have a longer block time. What does it even mean for block time? I think it makes more sense to talk about the latency of some kind of action that's happening within the application itself.
01:00:42.514 - 01:01:13.184, Speaker C: We could have like a voting protocol where we all submit votes for a day and we're using Ethereum. Well, the application that is running this election now has a latency of a day. You don't get the, you don't get the results until a day later, but it could still run on a base data and availability and ordering layer that even has instant finality in my mind.
01:01:15.004 - 01:01:43.338, Speaker B: It's cool space, guys. It's funny, it's still so early that you guys are still doing podcasts together. That's how you know it's a small space. You're trying to push this, clearly push this narrative of shared sequencers together, but eventually what will end up happening is you grow the pie to be large enough, and then you guys are obviously competing against each other and you have live products in the market. What is your working model of that timeline? When do Ben and Josh become less friendly?
01:01:43.506 - 01:02:33.944, Speaker C: Spicy questions here. I said this on the last podcast, but I've, you know, I've been in the industry a while, and I think that one of the great things about this industry is that a lot of builders in this space do tend to have a positive sum attitude. And I think that these are the early days for the technology. It's the early days in particular for like the l two scalability of these layer one blockchains. So I think even if ostensibly it's services that are running out there become competitors, they still cooperate on a shared mission of convincing the rest of the world that this is a good idea. They still cooperate on research questions. And so it's like a friendly competition in some sense.
01:02:33.944 - 01:02:50.594, Speaker C: And that's been my experience for the entire time I've been in this industry. I've worked with a lot of different projects, and of course there are some projects that have sharper elbows, and I don't like that as much. And I think it really detracts from the community feeling that we have in this space.
01:02:52.574 - 01:02:54.994, Speaker B: Josh, what's your working timeline on this?
01:02:55.614 - 01:03:54.740, Speaker A: Yeah, I think we're targeting intra year but that's a long timeframe to give in any kind of engineering estimate. The general thing is, anything over a week is highly skeptical because a lot of things can happen in a two week period, much less like a six month period, but sooner rather than later. I think going back to one of the really early questions of is there a technical blocker to the existing centralized sequencers doing that? Not really. To what Ben said a lot, this looks very similar to standing up a new l one network. You go get a bunch of validators, in Ben's case, the Eigen layer guys, and you stand up a new network and you make sure they coordinate and you run the network and you produce blocks for the network. It's not a truly novel problem. The kind of specificity of what that network is doing is novel, but actually setting up a network is not something that hasn't been done before.
01:03:54.740 - 01:04:42.840, Speaker A: How many tenement chains launch in a given year? Quite a few. So in that we're targeting intra year to the competition point. I know I haven't spent that long in this industry, two and a half years or so, but even coming from big tech, and I was biased, I spent a lot of time in open source there. I do think it is this competitive environment. I go to conferences where it would be IBM and Google and AWS and Azure all presenting at the conference, one after the other, and we're all building roughly the same thing, just whatever competitive plugin we had on whatever open source project or whatever. But it's generally, having these competing pressures against each other is beneficial for the industry as a whole. What we want is to push forward the functionality of crypto and decentralized networks generally.
01:04:42.840 - 01:05:04.094, Speaker A: And so if one of us is more competitive than the other, then that is a forcing function on the other to say, hey, look, you got to get your stuff together, you got to do a better job to compete in the market. And that forces progress throughout the whole industry. And I think that's a beneficial thing. And it doesn't need to be everyone being at each other's throats to do that, except the fact, fact that, that you are working in like a competitive environment and compete.
01:05:04.674 - 01:05:31.316, Speaker B: Yeah, last question here. Ben or Josh, I don't remember actually who mentioned this in our Xerox research podcast, but one of you mentioned something about restaking, or you said, look, restaking, super exciting, but also has the chance to. Something will get blown up because of restaking in the next cycle. I actually don't remember who that was who said that, but can you just expand on, like, maybe more details there on why you think that.
01:05:31.340 - 01:05:32.784, Speaker C: Because I think it was.
01:05:34.244 - 01:05:53.756, Speaker A: That was me, maybe someone obviously. And like, you know, I'm not like, you know, hyper bearish on, like, restaking. I think it's like, generally good. And this is like, somewhat of like a hyperbolic take, right. But like, fundamentally right. Like, restaking is like, rehypothecation of risk. Right? You're saying, like, we have some amount of, like, economic stake here and we're going to do multiple things on it, and there are now multiple things that could happen that are a failure mode.
01:05:53.756 - 01:06:40.636, Speaker A: Right. You know, whether they're, you know, it's the question of, like, is it a fraud proof or is it a fault proof, right? And there's like, the ideological question of, like, okay, did they mess up or were they actively malicious in that? Right. To some degree that's like, irrelevant, but it's like something can go wrong and that can slash an amount of stake rate. How many layers of things will we restake with the same amount of kind of economic weight to what point of, like, you know, over some long time frame one of those things will go wrong. And just generally, my view, again, being a relatively cynical person, is that, like, you will stretch a system to the limits until you find the failure mode, and then you will kind of have this pendulum back and forth. And so I think we will do a lot of good things with restaking. We'll enable a lot of new kind of development with strong economic guarantees.
01:06:40.636 - 01:07:17.670, Speaker A: But, like, maybe someone's going to mess up and then we're going to say, okay, well, maybe we went a little bit too far. Maybe we should adjust the parameters on this. This is similar to other kind of economic markets, right? You change the interest rate such and such. You have some strong economic engagement because, hey, look, we managed to do a lot more with a given amount of capital, and then you have a collapse of some kind and you say, okay, well, we're going to adjust what the kind of deposit ratios are required to be. That's my rough thesis on what I think will happen with restaking. But I also think to some degree, the inevitability of a decentralized network is that no one's allowed to say, we're not doing this. Right.
01:07:17.670 - 01:07:28.594, Speaker A: Like, you can implement it. You can put the contract on chain. People will use it if it's desirable. Right. And then, you know, we'll just kind of deal with it as like, an ecosystem to see, like, what are kind of the push and the pull on it.
01:07:30.414 - 01:08:26.280, Speaker C: Yeah, I don't agree with that, but I respect that perspective. I think it's actually pretty, pretty fundamentally different from being over leveraged in other economic scenarios. Restaking is subsidizing participation of participants who have already locked up capital for something, and it's giving them the right to participate in something else. I think that we're sort of conflating a lot of different things here. So what is the first of all? I think the main thing is that, is this a personal risk that's being taken on by an individual validator who is now participating in multiple protocols, or is there a systemic risk? Is there a contagion that can spread from multiple validators experiencing, I don't know, errors for different protocols and somehow being slashed when they shouldn't be? There's also the fact that slashing is not supposed to be used for things that could happen by accident. I'm not going to say never. Right.
01:08:26.280 - 01:08:52.402, Speaker C: But that's why we don't slash for liveness. Slashing fundamentally should not be used for liveness. Anyone who's talking about doing that, I think that is on its own, extraordinarily risky. Slashing is used for safety. It's used for preventing nodes who knowingly deviate from the protocol and double sign messages. And could that happen accidentally? I mean, a node could be corrupted because it could be compromised or hacked, but that's actually something that we do want to slash for. Right.
01:08:52.402 - 01:09:15.752, Speaker C: Because that's a form of corruption. That's not accidental. It's hard to accidentally sign two messages if there's not a corruption. So. And even if it is, a case like that, even still may be something that we want to slash for, because it includes increases the incentive for nodes to ensure that that is not something that can happen. Now, are these independent, uncorrelated faults across the different systems? I don't think so either. Right.
01:09:15.752 - 01:09:46.044, Speaker C: I think that if you're, if you're. I don't think that there's an independent probability p that you may, like, accidentally sign two messages for one of the protocols you're participating in. There's. There's correlation between the measures that you're taking in order to prevent that accident from happening across different systems. Now. But finally, I would say that this is a local risk, it's not a systemic risk. So if a party ends up getting slashed because something accidental happened and they lose their economic state, it gets redistributed.
01:09:46.044 - 01:09:48.944, Speaker C: That doesn't fundamentally change the security properties of the system.
01:09:50.284 - 01:10:05.474, Speaker B: Josh, Ben, great chat, guys. I think this is a good place to stop. Got you guys to disagree on something. Tried to make it spicy at the end. So of I the really appreciate this day. It feels early for the shared sequencer space. I feel like you two are both leading the charge.
01:10:05.474 - 01:10:06.834, Speaker B: So I appreciate you guys coming on.
01:10:06.954 - 01:10:09.454, Speaker C: Thank you so much. It was really a pleasure and thanks.
01:10:09.794 - 01:10:21.014, Speaker D: If we were to do a part two, when do you guys think would be appropriate in terms of your development cycle and your timeline over the next, you know, one to two years.
01:10:22.994 - 01:10:23.282, Speaker C: What.
01:10:23.298 - 01:10:40.304, Speaker A: Are we, what do in April now? I think we'd see a lot of things around when it's, when it's like ecclesiastes, like July, like somewhere in circa around like ECC might be like a timeline when we definitely have like guaranteed like significant progress. And I think that's long enough time where we'd see kind of where things are like dynamically different than they are now.
01:10:42.204 - 01:11:02.806, Speaker D: In an optimistic case, maybe we'll leave the listeners like chomping at the bit. An optimistic case, and it's hard when you use optimist optimistic in this context. But anyways, no bias. When do you think that we'll see decentralized sequencers? If you were to plant your flag and say we're going to have them by twelve months time or two years time?
01:11:02.950 - 01:11:05.674, Speaker C: No, I mean we'll definitely have them within a year.
01:11:06.334 - 01:11:32.884, Speaker A: Yeah, certainly within a year. I think more than twelve months is getting pretty pessimistic. Again, it's not that challenging of a technical problem. There's not wildly unsolved problems. It's more of a prioritization. And I think the burn down of kind of other priorities, whether it's through espresso or Asteri as kind of shared sequencers or through roll up projects, kind of independent decentralization efforts? I think we'll certainly see this within twelve months.
01:11:33.264 - 01:11:59.700, Speaker C: Nice. I mean, I don't want to, I don't want to oversimplify. I do think that building any of these systems are really hard. I think decentralized systems are hard in general. So I don't think, I would never say that this is easy. I would never say that anything that we're building is easy here. But I do think that according to our timeline and Josh timeline, we will have decentralization of sequencers within a year.
01:11:59.700 - 01:12:29.264, Speaker C: I think it may take time for the system to fully mature in terms of the after effects of that. Are we going to have a robust, are we going to solve mechanism design for the space within a year? Are we going to have fully operational bridges across all roll ups that are running on shared decentralized sequencers are going to have, you know, proposer builder separation perfectly solved. I don't know that that will happen within a year, but it will certainly the first steps will happen.
01:12:29.684 - 01:12:40.316, Speaker D: That's awesome, guys. Well, we'll certainly have to have you guys then within a year or before that. So I really appreciate the time. It's a, it's a very important topic. So, you know, great having you guys on.
01:12:40.460 - 01:12:40.844, Speaker C: Awesome.
01:12:40.884 - 01:12:41.308, Speaker A: Thanks for having me.
01:12:41.316 - 01:12:42.984, Speaker C: Thanks so much. This is really fun.

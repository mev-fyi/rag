00:00:00.440 - 00:00:15.645, Speaker A: We are hitting our limit in terms of what can be publicly scraped to create these models. And because of that, there's a lot of talk around where crypto could come into play to incentivize the collection of different data sources.
00:00:16.265 - 00:00:25.165, Speaker B: More funding does not necessarily make it easier to find product market fit. But there's a big caveat here, which is many things in AI are closer to hardware than they are to software.
00:00:25.795 - 00:00:52.591, Speaker C: Hey everyone. We all know blockchain is changing the world, but who's actually driving it? I'm excited to invite you to the sixth edition of Meridian, a Web3 conference hosted by the Stellar Development foundation in London from October 15th through 17th. Get early bird tickets at meridian.stellar.org with code blockworkspod. Special thanks to Stellar for sponsoring us. Now let's get into today's episode. Hey everyone.
00:00:52.591 - 00:01:30.381, Speaker C: The Polygon Community Grants Program was launched with 1 billion tokens, all for Polygon builders. Really excited to share that on today's episode of Empire. Season one of the Polygon Community Grants Program is now live. It features 35 million in Matic to support the next generation of Polygon projects. Join the aggregated future today by applying at Poly Polygon Technology Grants. Big thanks to Polygon for sponsoring Empire. What's up everyone? Before we jump into today's episode, I'm excited to share Empire's first ever security partner.
00:01:30.381 - 00:01:56.365, Speaker C: Harpy is the best tool to prevent your wallet from theft in real time. Harpy is not just a security solution, they are a peace of mind solution. But don't just take our word for it. Harpy is the only wallet security solution that protected 100% of its users from attacks like the Ledger one in Q4, which was an awesome chain signature attack. To learn more about Harpy, click the link in the show notes or visit Harpy IO Empire.
00:01:58.945 - 00:02:15.905, Speaker D: Hey everybody. Welcome back to Empire. I'm really excited to do this sequel to the first AI crypto pod that we did back in December. Casey, you were on it with Daniel from Modulus. People should go listen to that. It was very well received. The space has moved quite a bit.
00:02:15.905 - 00:02:35.135, Speaker D: The attention in AI seems like it's all time high. So I'm really excited to host. Mo, welcome. I think you're the co founder of Exo Labs doing some really interesting things. I'll pass it on to you for an intro and then Casey, for people not familiar living under a rock, you could also give an intro.
00:02:36.435 - 00:02:41.055, Speaker B: Yeah, thanks so much for having me. I guess Daniel was too busy this time, so I.
00:02:42.115 - 00:02:43.095, Speaker D: Not at all.
00:02:43.805 - 00:03:09.815, Speaker B: My name is Mohammed. I work on a company called Exo. Essentially you can use edge devices like phones and laptops, run AI models locally and privately on there. I guess the two things I know about AI I learned mostly during my studies at Oxford. I did a PhD in AI and robotics at the Oxford Robotics Institute and I've done a few things in Web3 over the years and now I'm working full time on exo. Like Cynthia said, great to be here.
00:03:10.515 - 00:03:24.043, Speaker D: I should say full disclosure, I am an investor in Exo Labs and I'm also an investor in Casey's fund Topologies. So if I'll try to remove my bias from this episode, I mostly will be in the background because these two folks are going to have a great conversation.
00:03:24.099 - 00:03:44.735, Speaker A: But full disclosure, I can give a quick bio too. So my name is Casey. I'm the founding GP of Topology, which is an early stage frontier tech firm. We do not just crypto, but crypto is one of our focus areas. And prior to starting Topology I was an engineer at Google for a long time and then most recently was an investment partner at Paradigm.
00:03:45.795 - 00:04:31.805, Speaker D: Amazing. I think I'd like to start this conversation with just a high level framework. I think it's people come to crypto and they expect grandiose innovations and they may be too impatient or may not be paying close attention to what's happening at the ground level and they miss perhaps really profound but maybe subtle innovations and, or also they expect many innovations and particularly overnight. And I think there's some interesting stuff happening at this intersection of crypto and AI. You guys are probably the closest to it. So I'd like to start the conversation, just maybe starting off like what you're seeing, what's really exciting and, and then we go from there.
00:04:32.105 - 00:05:03.149, Speaker A: What we're seeing is changing. I'll start there. So when we did this podcast back in December, we were seeing a lot of foundation model companies and that was probably the most popular pitch I got was we're going to create a foundation model for crypto. And crypto is an incredible playground that's like contained, that we can train data on. And that was a very, very common thing and that has died down. And what has come up is more like agents, applications and infrastructure. And I think that's only been fortified by the fact that LLMs are being commoditized across Web2 as well.
00:05:03.149 - 00:06:00.501, Speaker A: And so the pitch around foundation models is just getting weaker and weaker by the day. But to Santiago's point, I will say that I deeply agree that there's probably 10 to 15 topics right now that are popular that I have seen maybe more than five pitches in each and I would be excited if just three things worked. I will say right now very little is working. I think the thing that is working the most is from a technical lens there are some breakthroughs in local compute. So like what EXO is doing, there's some breakthroughs potentially in distributed training in inference. But then from a product standpoint, the thing that probably has the most product market fed is just distributed either computer inference, where basically you can get cheaper compute by hooking into a crowdsourced network instead of just using centralized players. And like a very concrete example of this is that you can go to brev.dev
00:06:00.501 - 00:06:45.375, Speaker A: which was recently acquired by Nvidia, it's a just regular web 2 company AI company and you can just rent Akash servers for a fraction of the cost of what you would rent them on aws. And again like we, we don't, we haven't really pressure tested totally over a long period of time how long this price arbitrage will last. AWS could easily come in and maybe say screw it, we want it, we want to eat their lunch. So I don't want to say this is a differentiator that's forever lasting. It could be more ephemeral than we hope. But that's just like a very, I think, concrete example of where we're seeing some sense of product market fit. And then before we go on from this topic, I just want to say one thing which is that at topology we're basically taking a very engineering centric approach to this entire category or entire space.
00:06:45.375 - 00:06:51.811, Speaker A: And we're looking for a technical investor. And so if you're listening to this and you're interested, DM me, I was.
00:06:51.843 - 00:07:02.099, Speaker D: Going to plug the chill. Well, Casey, you mentioned local training. So Mo, I think this would be a great opportunity to explain kind of what EXO is doing and a lot of the innovation that's happening there.
00:07:02.267 - 00:07:37.935, Speaker B: Yeah, just before I go there, just to comment on what you were both saying about a lot of hype and a lot of the stuff that Ray promised and not much work yet today, like in February, before I started working on EXO directly, when I was looking what to work on, I just wrote this report. I just tried to see what's happening in the space, all the different problems that people are working on. And I think we called the AIX crypto primer was this very long report and I had a few takeaways from that takeaway. One is I'm never writing reports again. This is the worst thing ever. It's just so time consuming to write a good report. Good report.
00:07:38.395 - 00:07:42.055, Speaker D: Did you actually write it yourself? You had an AI?
00:07:43.355 - 00:08:29.291, Speaker B: Most of it, most of the substance. The first few sections were all written and iterated on like crazy. It was a very brutal month to just write the report. But the second thing is a lot of the stuff didn't quite make sense to me and I couldn't wrap my head around it because I couldn't often pinpoint what is the problem being solved here. What problem is this thing addressing. I would see a project, I'm like, oh, this looks very cool and I'm just trying to understand what is it actually solving, which is quite non trivial to me to just be able to say and I think that's a general challenge in the space in general is you have a lot of stuff that is tech first. We have this thing that exists and it's cool and let's try to apply it with this AI context in mind.
00:08:29.291 - 00:09:11.970, Speaker B: But it's not like oh, here's a real problem that we're just trying to address. And the report basically starts by making this high level distinction about when you think about these two spaces like AI and Web three, I try to use AI crypto less and say more AI Web three. It makes me feel less that it's a casino, it's more like just technology. And it's really like if you think about intersection, it's like either using something in AI, some AI tool to solve a problem in Web3, for example, you could say a problem in Web3 is DeFi hacks. Stuff gets hacked all the time and that's a problem in Web3. People in Web3 understand it and I'm going to go take tools from AI, like I don't know, reinforcement learning, whatever. I'm going to build a product that makes it less likely for stuff to get hacked.
00:09:11.970 - 00:09:41.961, Speaker B: For example, like an auditing tool that is like AI powered and that's type one. So I'm using something in AI to solve the Web three problem. And the second thing is like I'm using something in web3 like token incentives or maybe cryptography or something like that to solve an AI problem. Let's say I don't actually have a specific example in mind, but let's say data labeling is a problem that's hard in this setting and we need more data to train this model. Label data and I'm going to use incentives to get people to label that data, whether that makes sense. Or not. I'm not sure this is an AI problem.
00:09:41.961 - 00:10:19.229, Speaker B: So for someone to solve that problem, you need to understand, you know, the AI aspect of it and kind of like you need to go talk to AI practitioners to understand how that part works. So what we doing in exo, it just starts with the premise of, like, you want to run a workload, for example, you have a model that you want to run yourself because you care about privacy. Let's say you're a law firm or bio company or a business or anyone who cares about privacy. You want to run something and you care about privacy. So what do you do? Just run on premise? Just like, run it in your own hardware. And your own hardware in this case means a gpu. But what if you don't have a gpu? Well, we can just allow you to do it on edge devices.
00:10:19.229 - 00:10:21.973, Speaker B: So that's kind of like just the TLDR of what we do.
00:10:22.109 - 00:10:46.185, Speaker D: Yeah. Casey, I'm curious what you think of that as you think from an investing lens. How much of what is talked at this crypto AI intersection Is crypto enhancing what is possible with AI or AI enhancing just crypto applications and use cases or just something completely new that is like, possible at both this intersection of crypto and AI?
00:10:46.645 - 00:11:22.603, Speaker A: Yeah, yeah. So I used to use that mental framework. A lot of AI meets crypto, crypto meets AI and then net new. I've actually walked back from that mental model a little bit because I think the lines are starting to get more blurred. But I agree with you, that is one popular mental model. And to answer Santiago's question, we see a lot of crypto helping AI in venture scale problems because a lot of the AI helping crypto are so profitable. And I'll give you an example of like an AI trading bot where they don't really need venture money.
00:11:22.603 - 00:11:47.339, Speaker A: And even if they did need venture money, it's more of a lifestyle business. And I don't. I'm not interested in the funding those businesses because they're just, they're. They're profitable from day one. And so that's like more of like, AI ubiquitously helping crypto and like a lot of DEFI projects, which I think are great businesses, but again, I don't think they're venture scale. And so the things that we venture firms are getting a lot of is more of the latter. And then to Santiago's point, there are.
00:11:47.339 - 00:12:35.973, Speaker A: There is kind of this, like, new category of like, the what is uniquely enabled by both, and that's starting to take form. But there's there's not much product market fit there. But that's why maybe this is a good segue into the map. When I was thinking more of like 30,000 square foot views, how to really index the space and make sure I have a pulse on it, what I ended up deciding was that I wanted to build some software that enabled the community to manage it themselves. And so we have this. If you go to like Topology VC DAI Dash Map, it is a crowdsourced market map where you actually give submissions of what category specific projects live in. And then I have an agent that actually goes through and opens the Twitter link and sees how many people in my network follow them.
00:12:35.973 - 00:13:09.545, Speaker A: And if it's over a threshold, then it sends it to me on Slack and then I can decide if we add it to the map. Actually somebody else decides if it gets added to the map on a weekly basis. But the point is that like most market maps are really static and biased and they don't scale with time. And the purpose of this map is that it actually will update continuously forever. And it hopefully gives like an overview of not what I think the categories are, but actually what people think the categories are. And if it would be helpful, I'm happy to take like a minute or two and walk through what those categories are today.
00:13:10.245 - 00:13:13.413, Speaker D: So we have the map pulled up. So Kasey, continue.
00:13:13.589 - 00:13:32.445, Speaker A: Okay, great. Yeah. So starting at the bottom of the stack, the first thing we have is compute. And these are just raw processors and servers that you have access to. And then within compute there's a handful of categories. This is where I put edge. So what Mohammed is working on also just like aggregated GPUs at scale, which is something we've already talked about.
00:13:32.445 - 00:14:22.013, Speaker A: And then on top of that we have inference networks which is kind of a subset of compute, but it's really focused on just inference, not training at all. And we have some image specific inference networks already in crypto. We also have LLM specific inference networks like Cusco, uh, and then on top of that category I have coordination layers. This is really a catch all for things that there's just so many categories that this is more of just layers between things that don't fit within one category. So things like, let's see, what would be a good example, like near. Near is doing a lot in AI and I think of it as a maybe a general orchestration layer or coordination layer. On top of that we have privacy, which I did not actually want this to be its own category, but because this is crowdsourced and I Listened to the people.
00:14:22.013 - 00:15:01.715, Speaker A: It's its own category now because this will come out later. But I'm pretty, I have pretty strong views on privacy, I'll say. And then there's agents, which is a really big, promising, exciting category. So just using agentic workflows with non deterministic models like LLMs and then on top of that we finally have some applications. So this is where it's like consumer and business B2B use cases next to that, which really maybe should be below but like are the actual model creation and fine tuning. So building the base models as well as doing the fine tuning on top. So people like Noose or Pond are living within this category.
00:15:01.715 - 00:15:49.801, Speaker A: And then there's I guess the most, the biggest category we see, and I put it at the top just because of the raw number of companies we're seeing is data. And the idea here is that we are hitting our limit in terms of what can be publicly scraped to create these models. And because of that there's a lot of talk around where crypto could come into play to incentivize the collection of different data sources. And this is just a known thing you can Google around in the fact that we really are hitting the ceiling. And so there's kind of two options from here. It's either people start coordinating to create more data or there's like there's usually synthetic data, which is I guess another option. And then the third option is we're creating more data moving forward that's used.
00:15:49.801 - 00:16:18.165, Speaker A: But as it goes right now we are just like tapping out. And so crypto introduces a totally new option for how to deal with and I guess like both interact and generate this data. So that's the, that's the map as it is today. And then like I said, if you want to add to it, you basically just hit add new projects and then you can choose a category or say a new category. And then once we hit a quorum with enough requests for a new category, it gets created.
00:16:19.425 - 00:16:28.245, Speaker D: Mo, what are your thoughts when you look at this? Obviously you're there at the very bottom in Edge Computer, but what's your overall reaction or thoughts when you look at the map?
00:16:29.665 - 00:16:41.365, Speaker B: Yeah, I was actually curious why Casey, why don't you think privacy should be a category? And if not, what is the space for things like Xama or fhe? Where does that fit in the stack?
00:16:41.825 - 00:17:09.163, Speaker A: Yeah, I just think that privacy is a feature, not a category and I feel that it should be embedded in each of these. So I think there's for example Million is compute and I think it's privacy centric computer. And so I think that it's just a secondary or ternary classification in the taxonomy that I would prefer. But again, I mean people are so obviously it's so part of the ethos of this space and people want that to be a differentiating factor. So my hands are tied.
00:17:09.339 - 00:17:54.505, Speaker B: Yeah. Because I find privacy really tricky one to think about in general because. Well, first of all, retail caring about privacy is a bit of a meme. Like very few retail users in the world actually care about privacy and we've seen this like and like web2 social media in particular. But like for example businesses care about privacy a lot and I was just always curious like I guess like if, let's say I'm a business and I care about privacy, like I'm a bio company or whatever or what are my options? It's either like on premise or cloud plus something on it. So let's say fhe. And when I, when I personally like try to think if I'm a business, what is the trade off here? Like I guess if I'm a law firm doing stuff on premise means I have to now buy and maintain hardware and that's quite a hard thing.
00:17:54.505 - 00:18:13.925, Speaker B: But if I'm doing FHE, I'm paying like I don't know, 25,000x overhead or if I want proper privacy. So I wonder what you think that space looks like and for who it makes sense to just do stuff on premise versus use some of these protocols that are maybe doing something with MPC or FHE and these kind of technologies.
00:18:14.485 - 00:18:18.301, Speaker A: Yeah, the problem is the trade off between price and trust.
00:18:18.493 - 00:18:18.885, Speaker B: Yeah.
00:18:18.925 - 00:19:10.205, Speaker A: Over and over again I just hear that from businesses like any, any of my portfolio companies that have B2B customers, I like to talk to them and they'll just tell me that, you know, we're willing to try it, but we don't really know this company, we don't really want to trust it. And then the more they say they're decentralized, the less they're interested. Because what business wants to work with a decentralized protocol like that that just introduces a huge more laundry list of concerns. And there are like cases where that makes sense. But I think that that's why Edge Compute is going to make. There's a consumer case which we can talk about but for the business case, it's so obvious, it's so strong for them to be able to be doing these computations locally on their own machines that they trust and they don't have the price arbitrage or the price delta. So it's a win win because they don't have to trust anybody and they get the, the price benefits.
00:19:10.785 - 00:19:21.553, Speaker B: Yeah, I guess what the reason I'm asking this, like obviously I work on edge compute and one of the things I believe is like, oh, with exo, these businesses who want to care about privacy, they can run stuff on premise without having to buy or maintain hardware.
00:19:21.649 - 00:19:21.881, Speaker A: Yeah.
00:19:21.913 - 00:19:29.845, Speaker B: But like I always think about the risks. Like, am I mid curving or does, I don't know, a huge data center in the cloud fhe in 5 years make much more sense?
00:19:31.105 - 00:19:58.139, Speaker A: Yeah, I mean I don't think anybody like, so I personally have stayed away, stayed away from investing in homomorphic encryption for now just because my smartest research friends say we're not there yet. And I think, you know, in the game of venture, timing is really important. You just, you don't need to just be right. You need to be right on the right time horizon. And that's a totally different algorithm. And so like, do I think it's eventually gonna work? Wouldn't have bet against it. Do I think that's like where the best capital could be deployed today? Fuck no.
00:19:58.139 - 00:20:17.543, Speaker A: Like, no. But. So I don't, I don't have an answer to a question, but I think like today I'll say like it's, that's not really what businesses are using out of everyone I've. And they still are looking for a solution. And I just want to comment on something you said, which is that like businesses really care about privacy. I don't really know if businesses care about privacy. I think they care about regulation and following the rules.
00:20:17.543 - 00:20:34.473, Speaker A: And I think that there's a lot of, let's see, like downstream pressure from a lot of regulatory bodies and that's good for them to follow certain protocols. And so that's kind of why it's like they're not actually concerned about the privacy, they're concerned about checking the checkboxes most of the time, I feel.
00:20:34.639 - 00:20:53.149, Speaker B: Yeah. From our chats, like we've seen, for example, like law firms, it just, well, legally I'm supposed to not reveal data. So I just, you know, regulations. So that's why I care about privacy. The only people who seem to care a lot about like privacy are in the more competitive settings. Like, for example, if you're a hedge fund, you're not allowed to use ChatGPT because like you just like there's a chance you leak something to these clouds.
00:20:53.197 - 00:20:53.597, Speaker A: Right.
00:20:53.701 - 00:21:15.473, Speaker B: And the same for like Bio companies, if you're using like a bio model to synthesize a drug, the output is like your ip. So like if that gets leaked, it's really dangerous. So there are a few cases where they actually care about it because of competitive market reasons. And in the other case it's just regulations. But I guess that is very real demand. If someone has to comply with the regulations. That as a business is very attractive to go after.
00:21:15.569 - 00:21:29.693, Speaker A: Yeah, well, I'll turn it back. I would love to know from your perspective. So, yeah, I mean I'm very familiar with that X is doing from a product standpoint, but from a usage standpoint and a customer standpoint, what are you seeing as the greatest demands for this right now?
00:21:29.829 - 00:21:36.613, Speaker B: I can tell you after, when we're off the air. You haven't announced it before yet. I can tell you this after.
00:21:36.709 - 00:21:39.665, Speaker D: Oh, you can share the alpha in the pot, you know, no problem.
00:21:41.405 - 00:21:42.341, Speaker B: For now.
00:21:42.533 - 00:21:43.125, Speaker D: Okay.
00:21:43.205 - 00:21:44.705, Speaker A: Okay, I'll DM you later.
00:21:45.005 - 00:22:32.933, Speaker D: Well, I mean, candidly Mo, when I, when I evaluated EXO initially it was like, this is really cool being able to, you know, run a model on the edge, like with your, any device, you know, hook up an iPad, your MacBook, idle machines, whatever. Really cool. I have asked you time and time again and during the process, like, what does the actual product look like? How big of an opportunity this is? Or is it just more for hobbyists? So without, without going into product announcements or whatnot. But like, I'm curious someone like you can build so many different things and you can get pulled in so many different directions, which is very common in this space. How do you think about killer vertical use cases that you're going after? And if you can comment on that, that'd be great.
00:22:33.069 - 00:23:04.059, Speaker B: Yeah. So at a high level, essentially what we do at EXO is we allow you to use these edge devices to run useful models. So essentially it goes down to a trade off of local versus cloud in some capacity. If why run stuff on your own device if you can just go in AWS and host it there? And there are some cases where that becomes relevant. So like case one is what we just discussed, which is privacy. If I'm a business and I have to comply with privacy, or I'm a competitive business like a hedge fund or a buyer company, I need to be private. So on premise makes sense.
00:23:04.059 - 00:23:39.445, Speaker B: It's very economic way to comply with my privacy requirements. And then in that case, like the reason you might want to use EXO is you don't have to buy or maintain hardware. So Instead of going to buy and maintain GPUs, which is a very hard thing to do unless you're super technical, just buy these free GPUs that run AI models on them and maintain that and rack up servers, you can just use the existing devices you have. So let's say in the context of a hypothetical law firm, you have 50 laptops in the firm, you can just download an app and there you go, you have an AI cluster, you can use AI models on premise, fully private. So that's one clear on that point.
00:23:39.485 - 00:23:46.209, Speaker D: What the law firm say is that going to compromise my performance in other applications. How do we think about load balancing, all that kind of stuff?
00:23:46.397 - 00:23:49.729, Speaker B: These are all things we can solve in the backend and right now there's.
00:23:49.777 - 00:23:52.921, Speaker D: Fairly abstracted from them. It's just like download the app and then it just kind of works down.
00:23:52.953 - 00:24:25.417, Speaker B: The app, Open it, use LLM and then literally the only thing you would notice is with the current version of EXO that we have internally, is if there are more people doing work, let's say playing games, and the M1 chips in the laptop is really busy, like rendering graphics, it'll be a little bit slower, but if people are available, like two, three of your colleagues are available, it'll be a lot faster. So essentially I have stuff on my own device, laptop, and then the late spare compute of my colleagues who are in the same organization is being used to speed up my inference and run these large models. That's just one use case to think about here.
00:24:25.521 - 00:24:28.045, Speaker D: From a performance standpoint, it's parity.
00:24:30.705 - 00:24:53.321, Speaker B: I guess it depends what you compare it against. You can get really high performance, like more tokens per second. It would just be less efficient, so you're paying more. It's like when you. There's things called like tensor parallelism. When I try to like parallelize certain things, I can speed up the inference to some extent, but that comes at the cost of efficiency. I do more redundant compute.
00:24:53.321 - 00:25:13.701, Speaker B: So it depends what you compare against. If you think about compare this against the gpu, the math is very different. Depending whether you have the gpu, you have to buy it. If you have to buy the gpu, then the trade off is like electricity cost versus buying a gpu. But if I have a gpu, the trade off is very different. So then you have to look into like memory and stuff like that. So it comes down to unit economics at the end of the day.
00:25:13.701 - 00:25:34.945, Speaker B: But pretty much everything. Well, to some extent most things are possible. So you can run large models very fast. Locally if you have enough compute. So that's one way to think about it. One other way to think about why you might want to do stuff on edge is cost. Let's say you just don't give a shit about privacy at all.
00:25:34.945 - 00:26:15.877, Speaker B: I just care about optimizing cost. And you have spare compute available, you might be able to use that spare compute versus spending more money on more GPUs. And yeah, cost is one of those things that's kind of interesting. I don't quite know how to think about it in the long term because I think we're going to be in a transient phase where people are going to invest a lot of infrastructure and GPUs and so on, but it might probably plateau. But still to this day, I think OpenAI is going to lose like $4 billion this year because just they subsidize the inference costs and so on. So that's the other thing where you might think about the trade off between edge and cloud. When you think about whether to do stuff local or in the cloud, it just depends what kind of use case you're in.
00:26:15.877 - 00:26:44.709, Speaker B: Again, something might be privacy. Some things might be more about cost, something more about latency. And you have the more ideological stuff about, for example, owning your AI model. If you can just have your AI model just locally on your device, they're private to you and you have access to them. That is one way to think about democratizing access to AI. And that kind of comes into layers. You have these incredible open source models that someone like meta creates these llama models and they release them and that's great for the space.
00:26:44.709 - 00:27:34.897, Speaker B: But once the model is released, like llama 405B, 400 billion parameters and fine tuned version of that model are comparative and in some cases better than ChatGPT in performance. So these are really good models, freely available. But how do you run it? Like you can't run llama 4, obviously too big. And that's where for example, EXO comes in, just allows you to have access and use these models and have them available and not have to rely on AWS or someone else to just give you access to these models, democratize the access to it. So if you have your phone on your laptop and maybe your family now, you guys can have your own Llama at home and you just own it, it's just your model. So these are different ways in which you can think about where this tech could be useful. What we are doing from a business standpoint as a company, I can tell you after the call but that's just like the higher level overview over time.
00:27:34.921 - 00:27:43.325, Speaker D: Do you see this more? Kasey, you kind of alluded to this earlier but like more consumer focused or equally you know, focused on like enterprise and you know, B2B.
00:27:44.105 - 00:28:34.753, Speaker A: Well one thing just quickly mo the I love this spectrum of latency sensitivity and how it unlocks different technologies. I think it's spot on and I could draw it and share my screen or I could do it in this space. But basically it's like if your latency sensitivity is super, super high, the most promising technology is doing it as local as possible. And yeah, cursor is a great example that every dev is using. Notion I think is another great example. Then if it's like middle of the road latency sensitivity you're probably going to go with closed source OpenAI chat or Claude Sonnet, you know, normal models that are closed source and then if you're really late and insensitive. So things like with my DI map it only needs to run once a week.
00:28:34.753 - 00:28:55.601, Speaker A: I really don't care when it runs, definitely not don't care in like 20 minutes, 10 minutes. And so I could use geographically distributed compute and drive down my cost and that's like on the other end of the spectrum. And I think that spectrum is probably not spoken about enough when it comes to consumers making decisions of what technologies to be using.
00:28:55.713 - 00:29:18.869, Speaker B: And I think these things are going to become a lot more obvious like stuff like latency matters once there are more apps because you only have to think about this once it's an app like Cursor, Notion and so on. When we still think about just base infra these things are not quite obvious but it makes a huge difference to the user experience in many cases. Gaming is a great example where a little bit of latency is really annoying. When you're playing a game and you notice it.
00:29:19.057 - 00:29:52.415, Speaker A: Yeah, it's like this, it's like if you're, you have like low latency, you're doing something like Exome medium, you're working with OpenAI and then over here it's like a distributed like Akash Cusco hyperbolic, all of that. But I think that of course there's other, there's other things that you need to consider with this like privacy and other requirements. But I do think that is spot on. As these consumer applications come to market and we're actually forced to make these trade offs in real time, we'll see these materialize in ossify. But then Santiago, Your question about B2B and consumer is it Just, well, I.
00:29:52.415 - 00:30:26.705, Speaker D: Mean maybe more of a general question. Both of you talk to businesses, you also talk to portfolio companies or other people in the space. There's a lot that I want to unpack there. One, how much interest there is from just general businesses and people to use open, decentralized protocols. And also you know how much of the AI community that has been dismissive or just not paying attention to crypto is actually inclined or interested in using some of the tech that is being built by crypto people.
00:30:28.565 - 00:30:41.097, Speaker A: I think high. I think high. But I think that actually consumer AI is severely underrated. I think that the non deterministic. Oh, go ahead.
00:30:41.241 - 00:30:43.377, Speaker D: Well, how would you define consumer AI? I guess.
00:30:43.441 - 00:31:15.627, Speaker A: Yeah, just not enterprise use cases. You're not dealing with another business on the other end. And the reason is because basically I think AI forget Jenny, just AI in general has always had a. If you break up AI into what's production grade and what's research. A lot of it is research. And this is just like throughout my own career I've noticed this is that just a lot of the AI that we think is ready for production, it's not yet and it's just, it's a highly technical field. And that's like, that's true across a lot of technical fields.
00:31:15.627 - 00:32:06.227, Speaker A: And so what happens is you think something's production grade, you try to sell it and then you realize there's the non deterministic nature or there's all these, you know, false positives and it's not, it's not, it's not ready. And so we're seeing this now with Jenny. I. This similar thing where I see a lot of like this is one of the biggest mistakes I see investors making is that they're pouring money into research labs thinking that they're going to be commercialized, but they're never, they're not going to be commercialized because that technology actually isn't ready for production at all. And so the path to monetization is a lot hairier than people realize. And so to that end consumer use cases that are being, that are willing to deal with maybe false positives or the non deterministic nature is actually feature, not a bug like that stuff is really, really interesting and ready for businesses today. And I see a lot of people obviously focus on B2B because I think vertical B2B AI is also really interesting.
00:32:06.227 - 00:32:11.775, Speaker A: But I just think if we're going to talk about underrated, overrated consumer AI underrated.
00:32:13.555 - 00:32:56.433, Speaker C: Hey everyone, Jason here. Just wanted to take a quick break to Talk about something exciting in the world of blockchain. The Stellar Development foundation is hosting their 6th annual Meridian Conference this October 15th through 17th in London. It's a three day event where the brightest minds in web3 come together to discuss everything from tokenization to defi. If you're a developer, builder, policymaker or business leader looking to make an impact in transforming global systems through blockchain, this is your chance to join the conversation. You'll get to network with the forward thinkers who are defining the future of this space. Head over to meridian.stellar.org
00:32:56.433 - 00:33:24.787, Speaker C: and use the code blockworkspod for early bird pricing. Now let's get back to today's episode. This episode is brought to you by Polygon. Polygon Labs is developing the next generation of open source zero knowledge tech to aggregate crypto liquidity and user bases, empowering developers to grow in a unified web of interoperable chains. With the AG layer, that was a big mouthful. So I'm going to tell you what it means. In my in my words.
00:33:24.787 - 00:33:46.807, Speaker C: There's all these things popping up, L2s and L3s and it's chaos, right? If you are building something, you no longer have to worry about bootstrapping liquidity. You can basically just build in the AG layer to tap into the liquidity of the Ag layer and the users of the Ag layer. You get the users, you get the liquidity. It's the AG layer. It's hot. It's by Polygon Labs. They've got the Polygon Community Grants program.
00:33:46.807 - 00:34:09.515, Speaker C: It was launched with 1 billion tokens just for Polygon builders. Season one. It's live right now. It features 35 million in Matic to support the next generation of Polygon Builders. Join the aggregated future today by applying at Polygon Dot Technology Forward Slash Grants. That's Polygon Technology Forward slash Grants. If you talk to anyone, let them know Blockwork sent you.
00:34:09.515 - 00:34:48.280, Speaker C: For a lot of Empire listeners, your crypto is not just another number on a screen. It's part of your future. I know Santi and myself feel that way. Our security sponsor of this episode, Harpy, takes this responsibility seriously and is the only wallet security tool that shields users from both on chain threats and sneaky off chain signature attacks. If you've ever been in that situation where you're moving quickly, you approve something on chain, you realize that the address might be a dubious address or you're really hoping that you could take that back. Harpy has you covered. Harpy can redirect your assets to your self custody vault, ensuring they Remain completely under your control, safe and sound.
00:34:48.280 - 00:35:23.385, Speaker C: With Harpy's always on monitoring, you're not just detecting threats, you're actively blocking and recovering compromised assets from malicious transactions before they can even confirm. On chain Harpy is the only wallet security solution that protected 100% of its users from attacks like the Ledger one in Q4, which was an off chain signature attack. So if you're serious about protecting your crypto investments, it's time to make the switch. Secure your wallet for free at Harpy IO Empire. That's Harpy H A R P I E I O Empire. If you want it to be even easier, just click the link in the show notes.
00:35:24.765 - 00:35:52.287, Speaker D: Well, I pull this map again and I'm curious if we overlay this. Like there's like there's been a lot of money that's been being poured in AI and also in crypto AI startups. You know, some of these have raised tens if not hundreds of millions collectively maybe. Well, I'd like both of you to maybe talk about areas that are overhyped and underestimated in this map.
00:35:52.471 - 00:35:54.195, Speaker A: Okay, Mo, you want to kick us off?
00:35:57.535 - 00:36:00.911, Speaker B: Yeah, I'm going to try and be.
00:36:00.943 - 00:36:06.915, Speaker D: Very without pissing off 99% of the people in the space. No hard feelings.
00:36:08.035 - 00:36:51.545, Speaker B: So I will say a few general ones. So in the bottom right corner you have like Refrabic Compute and there's zkml. I think ZKML is really interesting thing where a lot of the chat about it is scaling ZKML and making it more efficient and using the overhead. I think ZKML will scale, but I think one thing that's like over hyped is like the software aspect of it. One thing that's like under hype is the hardware aspect. I think the biggest reasons for speed up will come from hardware acceleration companies like Inanyama or Fabric Cryptography and so on. I think those will be a little bit more important for actually scaling these things up than the software companies.
00:36:51.545 - 00:37:24.701, Speaker B: And the reason I believe that I can go on a whole spiel is this thing called the Bitter lesson in AI from the famous Block Club by Richard Sutton. And we can go into that. But most breakthroughs in AI over time came from just scale. And hardware is hardware optimized to some extent for these cryptographic operations. I think is going to be a bigger driver in the software aspect. I think it's going to be specialized hardware, generic software, more general purpose software, not, for example, ZK and Prover and stuff like that. I think it's going to be A bit more general and hardware is going to scale it up.
00:37:24.701 - 00:37:44.021, Speaker B: So I think hardware is a bit underrated and it's not underrated in terms of funding. These companies have raised a lot of capital I believe Fabric announced around recently. But they're underrated in terms of just talking about them. They don't come up as often. When you think about zkml, the other thing I guess maybe make a pause.
00:37:44.053 - 00:38:07.405, Speaker D: There when you think about Casey, to your point around being too early on some of this stuff and being indistinguishable from being wrong. Hardware takes time. Most people tend to underestimate that. How do you think about the time that it will take for these hardware to be available and ready, production ready? Are we talking a year? 5 years? 10 years?
00:38:08.065 - 00:38:39.639, Speaker B: I have no idea how long the hardware would take. I guess in AI there's a lot of new hardware. Specific companies like for example chips for Transformers and those have done quite well in fairly short cycles. So there's a chance this goes well. I think in the long run the hardware companies are going to contribute more. I'm not sure if that means you should invest in it now. And this is generally there's a very interesting category in just crypto in general of this stuff doesn't make sense, but I would invest in it.
00:38:39.639 - 00:39:07.957, Speaker B: This stuff is going to pump. So investing is a good idea, but doesn't quite make sense and stuff that might make sense of the long run, but it's probably not a good investment. I'm not an investor, I'm not a professional investor, so I don't think about these things often. Just what I think from a technical standpoint, what is underrated? I think hardware acceleration for Verify Compute is underrated compared to software. I will say though, a lot of stuff around verifiable compute, zkml. I'm not sure why we need it. A lot of the use cases are a bit shaking in my head.
00:39:07.957 - 00:39:14.685, Speaker B: But it is going to scale eventually and I think hardware is going to play a bigger role. So that's one thing I would say is overrated. Underrated.
00:39:14.845 - 00:39:20.465, Speaker D: Notice that Moe's being very conservative. Just talking about underrated. Not overrated, over hyped stuff.
00:39:21.135 - 00:39:22.167, Speaker B: Yeah, political.
00:39:22.311 - 00:39:27.875, Speaker D: Very politically correct. You're lucky I'm not a harder podcaster here.
00:39:30.815 - 00:39:32.075, Speaker A: I can chime in.
00:39:32.775 - 00:39:33.911, Speaker D: Casey's gonna go for the hammers.
00:39:33.943 - 00:39:35.071, Speaker A: He's gonna go, no, no, no.
00:39:35.143 - 00:39:36.555, Speaker D: Well, the shit's alright.
00:39:37.295 - 00:40:09.809, Speaker A: I already gave my over hyped, which I think is privacy generally. I'm really not that interested in that as A primary value proposition. And I think that, okay, let me think what's underrated? I think specific things in agents are underrated. Like I think, I genuinely believe agents are going to use crypto infrastructure for payments in stable coins. I just think that's what's going to happen. And it's, I like to say that I'm not a psychic, I'm an investor. And I think a lot of investors try to be psychics and it messes up the returns.
00:40:09.809 - 00:40:45.615, Speaker A: And so you know, you always need to be open minded to where the puck is headed and be nimble enough to be there. And so I don't say that as like I have a crystal ball, but I just think from like first principles it makes a ton of sense. And so I think that infrastructure is underrated. And then I think what's overrated in agents is this like general development framework stuff, which is like we're creating a new L1 to build to be the home of agents. I have seen so many of those pitches. I just don't think the value proposition is concrete enough. And I think you run into a common pitfall of crypto or Web3, which is like the devs will come mentality.
00:40:45.615 - 00:41:25.165, Speaker A: And then what else do I think? I think maybe one more thing that's underrated on the data side is that because I already mentioned that we're hitting this wall in terms of like the amount of data that we can publicly scrape and that there's things like Fine web, which is, I think it's like 14 trillion tokens, which is like the cap of where we're at. Maybe it's 15. I think protocols like Vana, which like Discloser I am an investor in. But I really do think that this idea of coordinating people to pull more information and now leverage that in a way that's financialized for new models to use is like, is underrated.
00:41:26.265 - 00:42:04.567, Speaker D: To me that feels like the huge unlock that crypto, crypto is always better at coordination and getting people to do stuff. And so if you overlay that with the data problem, like again like in investment banking and finance, it's like you're only as good as your, the inputs, the model's only as good as the inputs. Like that, that's something that you know is true in finance, is true in AI. And so if you want to really do like fine tuning specialized data, if you're a law firm, if you're, you take a generalized model, you need either synthetic data or like, like reinforced with human learning. You, you need to like, if you overlay like a coordination layer. With crypto, it can be really powerful. You can do it at like, it's like deepen.
00:42:04.591 - 00:42:04.727, Speaker B: Right.
00:42:04.751 - 00:42:16.475, Speaker D: It's like you can do it like far more capital efficiently. And that's the area that I'm most excited about. But yeah, I'm sort of a lizard brain.
00:42:16.935 - 00:42:54.681, Speaker A: I know, I agree with you. I can mention two, they're not on the map. But two other things that I think are underrated or underappreciated or talked about is that AI is generally commoditizing software development. And it's really hard for me to say that given my background, but I'm coming to accept it. And it really is going to be a class change of it's been the rise of the nerds in Silicon Valley for so long and having a technical degree was your, you know, Willy Wonka golden ticket situation. And that's just not going to be the case in 10, not even 10, five years. And so with that there's a lot of downstream effects of how venture will change, how innovation will change.
00:42:54.681 - 00:43:51.685, Speaker A: How. Yeah, like class structure in terms of whose talent, where do talent webs move and what's valuable than talent webs. And so that is like, I just think not explored enough when it comes to crypto. And then to Mo's point, which is semi related, which is that some of these businesses that are AI meets crypto because they're profitable so quickly and because crypto is so overloaded with capital because of these multibillion dollar funds, there's actually a new category I think that could become real, which are like micro loans or micro investments for these nearly profitable businesses where because now software development is so cheap, people around the world can make these businesses and maybe they need like $1,000 or $10,000 to get to a point where they don't need additional venture. And these larger funds obviously aren't positioned to do that because it wouldn't impact their P L. It wouldn't, it wouldn't make sense for them incentive wise.
00:43:52.815 - 00:44:06.999, Speaker D: Yeah. Any how do you think. I mean, I guess this map is. The real estate is not to scale in terms of the amount of money that's been poured in. It's just sort of like random, right?
00:44:07.047 - 00:44:09.275, Speaker A: Yeah, well, yeah.
00:44:10.535 - 00:44:44.125, Speaker D: Okay. How do you think about the evolution of this map going forward? Perhaps what are, what are some of the areas that you think perhaps new categories that might emerge or if you were to like do a kind of morphing over time map in terms of actual attraction, actual usage, however you want to Define that. I don't. I care less about capital, more so actual usage like number of users or adoption. How would you, you know, how would you think that this map evolves over time?
00:44:45.495 - 00:45:32.537, Speaker A: Okay, two new categories. So one's on here, one isn't even on here yet because we need one more for the quorum to threshold to be hit. But it's robotics data because there's this huge thing right now with Humanoids and now people are thinking crypto could be the missing incentive as Santiago talked about already for getting the robotics data. And so there's a lot of companies going after that all of a sudden it's like overnight too. And I think the, what I'll say is I know from a traction standpoint the Lois that they've been able to secure and it's pretty impressive. Again, not sure how it scales but I will say at least from an LOI and POC standpoint I'm intrigued. And then the other thing is world models, which are, if people aren't familiar with that term, are basically more generalized models that know about our world and can do variety of things from bioinformatics to chemistry all over.
00:45:32.537 - 00:46:10.865, Speaker A: And Eric Schmidt famously started a company in this category also like a very well known Stanford professor, Fei Fei Lee started a company in this category and that I'm starting to see companies go after as well. So those are like two new categories. And then to quickly answer like how I expect the usage or product market fit to evolve with this. I do think some applications are going to start to have PMF durability. I'm not sure but I think something in consumer will obviously take off or maybe that's not obvious but to me I think it is. And then I think the agentic is also going to start working. So agents probably in 2025 are going to start to work in a way that we can actually use them on day to day basis.
00:46:12.165 - 00:46:34.093, Speaker D: As their normal example would be like you want an agent to do certain tasks that you want to like, you know, and it would use stablecoins because obviously you can't kyc, you can't use bank account but it would naturally can use a stablecoin to pay certain vendors to, you know, build your website and pay and do everything in the background and you kind of need the crypto rails for that.
00:46:34.229 - 00:47:06.569, Speaker A: Yeah, exactly. I think it's more likely to be an actual ecosystem like Amazon. Like I think Amazon is actually going to launch an agent in 2025 and it's going to be really good because they have the contained, they know their software and so they can create guardrails for it not to go off the deep end. And so I think we're going to start to see major organizations launch like their versions of agentic flows and work maybe with maybe with crypto companies to do some like payment integration. Possible. Possible not, but I just think it could, it could make sense and. But I'm curious if Mo, I.
00:47:06.569 - 00:47:06.881, Speaker A: Yeah.
00:47:06.913 - 00:47:32.777, Speaker D: Do you disagree Mo, before I go to you on this point of guard rails, I mean, obviously we had Dan from modulus and verifiability being a big important aspect, how do you think about the traction that you may or may not get from these decentralized protocols because of this particular issue? Like, maybe it's just a trust issue. It may or may not be true, but it's like, you know what, there's just too much. There's no one to call and there's no like red button to stop.
00:47:32.841 - 00:47:33.777, Speaker A: Yeah, exactly.
00:47:33.921 - 00:47:52.555, Speaker D: People pause of like, if this shit goes haywire, I'd rather be using like OpenAI that I can call Sam and just. It may or may not be true. It's more of a matter of perception that can hold back the space of it. I mean, do you think that's real and actually a credible like threat to crypto AI, like getting any sense of adoption?
00:47:53.535 - 00:48:27.607, Speaker A: I think that's a broad stroke, but yeah, in general, do I think it's real that people trust OpenAI more than they want to admit? Yes. Yeah, I do. I think you want to say you don't trust it, but I think the, you know, there were a small set of people in this community and I think most people do trust OpenAI and I think they're moving in that direction to, to get to garner more trust. I also think people trust Apple. I think those are the. And I think Apple is really well positioned to actually break into this category. But, but I still think that there's a lot of, there's a lot of things that we don't know how the story ends yet, especially with AI regulation.
00:48:27.607 - 00:48:48.901, Speaker A: And I think that there's just like a few things that could happen over the next few years that bring decentralized AI more to the forefront. And I think there's still certain categories where even if you trust OpenAI, decentralized AI still makes sense. So I don't think, I guess I want to say it's like, I think there's nuance to that answer and I think the devil's is the devil is probably in the details.
00:48:48.933 - 00:49:52.825, Speaker B: There one thing that is definitely like going to change hopefully soon is like, you know, a lot of people right now build like picks and shovels, like really like low level infra and for some reason in general like crypto space loves to fund infra versus just like apps. And a lot of this low level infra I think will be just commodities very quickly. And because like if I'm like a successful app developer and I'm looking at like which GPU marketplace to run stuff on, it's probably at some point going to be like a very like hard calculation. Maybe I care about privacy, so I'll go for that. But if I don't, probably just cost like whatever is cheapest and I'd be commoditized very quickly. So I think that's something that right now like there's so many projects like doing GPU marketplaces and probably this will like get commoditized and then like, you know, the distinction will be all more on the app layer with like the useful stuff there. Well, I guess people have been saying this in like general crypto for a while, but still like infra is still a very popular thing.
00:49:52.825 - 00:50:31.525, Speaker B: The other thing that's like very interesting to think about I guess is a lot of things like get accelerated or decelerated a little bit based on funding. I think it's a little bit of a fallacy in general. Like more funding does not necessarily make it for you easier to find product market fit. But there's a big caveat here, which is many things in AI are closer to hardware than they are to software. Like many AI companies are very capital intensive. If you think about, I don't know, the foundational model companies, you can't just be two kids in a dorm room to build Mistral, you need all the compute. So it's a little bit more like you need this upfront capital investment and all that stuff that you don't necessarily have in a computer software company.
00:50:31.525 - 00:51:17.237, Speaker B: But again, the foundational model is probably going to get very good. Microsoft program is going to keep funding a few of these open source ones and then a lot of value will accrue to the app layer. So a few things. There is one thing I think about a lot is when you step back first over time, most progress in AI history came from scaling up. There's this famous blog post that I really like to quote called the Bitter Lesson. And basically throughout history, specialized models that were handcrafted don't perform as well, just like people who leverage scale. I have a personal experience with this where in the start of my PhD in Oxford, we had a talk and OpenAI was mentioned at the time.
00:51:17.237 - 00:51:49.119, Speaker B: At the time we still had GPT2, so it's still trash. And I remember the lecture was talking about OpenAI and how they're just doing this like, next world prediction, very simple structure, just trying to scale it up to build these good models. And he called OpenAI retarded. And he said that we should look into how kids learn how humans learn language and encode all this stuff into language models, models. But the thing that worked well was just like, you know, it's fairly simple models, somewhat simple, and I'd like handcrafted for like English language, whatever. It's like fairly general. I would just scale them up like crazy.
00:51:49.119 - 00:52:25.347, Speaker B: Just like more data, more compute, just bigger, better. And this is like a common trend. And the reason it's called the Bitter Lesson is like, as a scientist, it's not very satisfying to just think, oh, scale is just going to beat my intellect of how to cleverly construct the models. But this happens over and over again, like in speech recognition. Yet all these people tried to craft models for speech recognition, but, like hit the Markov models were the best thing, just like a statistical model. Back in the 90s you had all these chess researchers who built chess computers based on like, you know, how humans play chess. But then like IBM came along with a fairly brute force thing and like beat everyone out.
00:52:25.347 - 00:52:26.571, Speaker B: And I think wasn't there a very.
00:52:26.603 - 00:52:37.155, Speaker D: Hallmark moment where like, the model did a move that most chess like savants were like, this doesn't make any sense. And that's how it actually beat Kasparov. I think.
00:52:37.455 - 00:52:40.951, Speaker B: I don't quite remember, but I think a lot of this stuff happened also, like later on with the game of.
00:52:40.983 - 00:52:52.367, Speaker D: Go, a lot of these like, as well. Yeah, where the model just created a totally new movement and experts are like, this doesn't make any sense. And then they're like, holy shit. No, it actually does. And that's how you beat the human.
00:52:52.551 - 00:53:28.811, Speaker B: And yeah, that's just in general that most progress just came from like scaling, scaling up these models. And actually in the case of chess, at the time when the best chess AI beat Kasparov, loads of the researchers said, oh, this is just brute force and this is not going to win the long run. This is how humans do it. But machines are not humans and they're very different in nature. So they can afford to just scale up and plug these GPUs together. So I think one general thing is you go through these Cycles where we discover some specific artists architecture. We scale it up and it gets like passes everything else.
00:53:28.811 - 00:54:00.235, Speaker B: And then we somewhat some point we plateau and then a new architecture come along that allows us to scale better. So things that allow you to scale are historically a good bet to make. That's how just the space is going to progress, just by scaling things up over time. As you think about how stuff evolved, I think soon someone will come up with a new architecture that isn't a transformer. Some new model, some different thing. And then a lot of funding would have to move and go to that, scale that up very quickly. One thing I'm very curious about is this model called an X lstm.
00:54:00.235 - 00:54:39.975, Speaker B: Things like a transformer. It's a different architecture and if someone just scales it up like crazy and makes a really big version, is that going to do much better? Because these models perform much better on a smaller scale. And what that means is some investment become quite tricky. So let's say I want to invest in etched, this hardware company that's like optimized for transformers. If you believe transformers are the future, this architecture and scaling is just better and we need to keep scaling for a long time, then that's a pretty good bet to make because we can just do a lot more with transformers. But if a new architecture comes along, then you've specialized in transformers and now it's not very useful for this other setting. So that's another thing that I think is interesting.
00:54:39.975 - 00:55:11.605, Speaker B: Around the hardware layer and allowed influence the whole stack, depending on what the model looks like, the whole stack changes. One big change that happened over time is previously you had to train every model from scratch. But then foundational models came along. A foundational model is this big thing that you train once and then you train small things on it and you need a lot less data to do it. So that will change a lot how the data layer looks like, for example. The other thing is if synthetic data somehow becomes useful with skeptical synthetic data in general. But historically it has worked in multiple instances.
00:55:11.605 - 00:55:34.179, Speaker B: I remember when I was taking deep learning class in college, you had this thing to classify dogs and cats or cat or not a cat. And then the researcher was like, oh yeah, we're going to augment this data. We're going to take this exact same cat picture and for example crop it and then we'll take this cat picture and give it a different shade of color. And then you have more fake data and that helps the model do better. I always was a bit confused.
00:55:34.227 - 00:55:36.283, Speaker D: For listeners that's Synthetic data, right?
00:55:36.379 - 00:56:15.831, Speaker B: Yeah, somewhat synthetic, but now synthetic just literally mean, like just, you know, AI generated, if that works. There's like an interesting thing called model collapse where if you train these models based on synthetic data from feature models. So like, I guess the idea here is a lot of people now use ChatGPT and Claude. So a lot of the content on the Internet that's going to be used for the future version of them is generated by like GPT and claude. So if you have a lot of synthetic data and use it to train a new model, what happens? And that paper just shows these models degrade over time and become gibberish if you keep training on data. But maybe someone solves that. So here's some of the things that I think are interesting in the general space going forward.
00:56:15.831 - 00:56:56.795, Speaker B: One thing to note is for most stuff we talked about, these are AI problems. These are things to think about them productively. You have to understand machine learning at some depth. So for a lot of this stuff, progress in decentralized AI, you would need also a lot of AI talent, machine learning talent to come and look at these things. And that's, I guess why have people like Casey who have traditional machine learning experience is very important because these are like crypto problems and like defi hacks. This is like, you know, very deep technical machine learning problems. And we're trying to like, let's say, for example, to scale up compute, leverage all these like later computers.
00:56:56.795 - 00:57:23.675, Speaker B: That's cool. But that's not the hard bit. The hard bit is like actually on the machine learning side. And yeah, the other way around I think is a lot more interesting. Like leveraging AI in crypto is like security and like trading bots and all that stuff. That's like there you need the defi expertise to defi hacks and for that you don't need crazy AI talent. But for the other aspect, like Web3 helping AI, you need like, well, a deep understanding of machine learning.
00:57:24.365 - 00:57:49.795, Speaker D: You go to an AI conference, you go talk to your colleagues in Oxford or Google Casey, and you tell them, hey, what are the biggest problems, bottlenecks that you're facing today? And they list out top 10. You survey 100 people. Are any of those bottlenecks or problems, constraints that they have today can be unlocked by crypto?
00:57:52.975 - 00:57:58.231, Speaker A: Do you want me to ask researchers, like, if I put hypothetically or in conversation?
00:57:58.263 - 00:58:05.367, Speaker D: Yeah, like you go talk engineers and they're like, do they see value? I guess is the question in things.
00:58:05.391 - 00:58:43.527, Speaker A: That are unlocked by crypto, the large, the, the only thing That I really feel would be like consensus is that people want AI to stay open. They really believe that they really want AI to be democratized and accessible. And that is something that Web3 and Web2 are aligned on. And I think the Web2 world sees crypto or decentralization as one contender technology to keep that future protected. Other than that, no. But that is like a big thing. And then there's all these technical things like reducing hallucinations, scaling as.
00:58:43.527 - 00:59:12.685, Speaker A: As Mo talked about alternatives to transform our models that are getting, there's a few that are getting really popular. There's like a lot of technical problems that we're still overcoming. And things like mixture of experts are really popular right now. But in terms of just like large vision and ethical standpoint, it's how do we keep this technology accelerating and democratized and free and open and Maybe, maybe the Web3 community could help there. Mo, do you agree with that? You're on mute.
00:59:14.745 - 00:59:48.547, Speaker B: It's the third time. There's definitely a lot of chat about these things like safety, alignment and so on. There was this really interesting quote I'm paraphrasing here that I think George Hoss tweeted. He said something along the lines of like when llama 400b came out he said an aligned model or Grok. Like when grok came out he said an aligned model is a model that does what he tells to do and is not give you a moral lecture based on the values that people created. When you go to ChatGPT and try to ask certain things, just give you a lecture about political views or whatever. And he said an aligned model is a model that does what he failed to do.
00:59:48.547 - 01:00:32.561, Speaker B: And these are a lot of interesting discussions about what does it mean for a model to be quote unquote aligned. What does alignment actually mean? What does safety actually mean? Should you open source stuff? Should you not open source and so on. One other interesting discussion is around how stuff, how these foundational models and all these tools impact things like job markets. So there's this interesting thing about oh, now with Claude and let's say with Claude, like people that aren't very technical can now like for example create a game and all this stuff. So like, oh, this enables a lot of people to come into AI. This does not necessarily help everyone because these AI tools like amplify the best people to like a disproportionate degree. Like normal people can now come in and use cloud to play the game.
01:00:32.561 - 01:01:14.925, Speaker B: But the really best Devs are maybe 100x better with a really good setup that's very enhanced. And you could argue then that the best thing to do in that setting is to open these models to everyone. Because you don't want the most powerful tools that make very small people like 1000x better, only available to a very small subset of people because that puts them so far ahead. So democratizing AI and access to it and is something that's talked about a lot. And I think this kind of stuff around tools like Cursor and Claude is really interesting because it does make like a normal dev, like a lot better, maybe like 2, 3x or whatever. But I think the really best devs like are steroids once they have access to these AI tools. So it actually like creates more inequality in a sense.
01:01:14.925 - 01:01:17.177, Speaker B: I haven't, I don't have. Yeah, sorry.
01:01:17.281 - 01:01:39.545, Speaker A: That will. Okay, so I completely agree. This is another nuance, which is that when I said software, software development is going to be commoditized, actually today all it's doing is making good engineers, great engineers. It's not making no engineers engineers because you still need to understand how it all works. And so it's like the. Everybody says, oh, it's the worst time to be an engineer. It's the best time to be an engineer because you move faster.
01:01:39.545 - 01:01:45.325, Speaker A: But that will change like in two years. I think it will help people go from zero to one.
01:01:45.945 - 01:02:28.999, Speaker B: Yeah. And that's why it's quite important for these things to be open. So as many people as possible come in and try to go up. One other interesting trend in general is around video models and it's something particularly around my work at X I'm very excited about because these video language models are so much bigger and the stuff you send in over the Internet are not streaming text, you're streaming video now. And that is the kind of stuff where a lot of things around edge become really interesting to me. One is streaming video is really hard because there's so much data. Like if it was possible to stream video you probably would have Netflix trying to like stream stuff to like airlines or something, like on a plane stuff is pre downloaded because like sending data over a bad wifi is like terrible.
01:02:28.999 - 01:03:17.755, Speaker B: And like these like video language models could become like really powerful in the future and it's quite important for them to be local. And one interesting thing that I learned about recently is like moving data around is extremely expensive. So you have a lot of like climate considerations there. I don't remember the numbers at the top of my head, but I think it was something like in 2023, the cost of moving data around across the world, data transmission was more than energy consumption of Spain, which reminded me of a lot of these stats around Bitcoin. I remember you say, oh, bitcoin network has more energy than Ireland. So I remember I compared energy transmission, data transmission, cost in energy and the bitcoin network and it was more, I think it was almost like 2x or something. Moving data around is a very expensive thing and that's one of the things I'm excited about.
01:03:17.755 - 01:03:51.321, Speaker B: Edge computing, doing stuff where the data is is also a very important thing from an energy standpoint. And I think these video models are going to become really useful in the future. And for that streaming is really hard anyway. Streaming video over Internet is really hard. And also the environmental considerations there are massive. And yeah, that's another thing that is interesting. And I've seen Some people in Web2AI talk about the climate considerations of developing these large models, but it's not very popular discourse yet.
01:03:51.321 - 01:03:53.725, Speaker B: But I'm interested in that.
01:03:55.745 - 01:04:22.645, Speaker D: Yeah, I guess. I mean this has been a fascinating discussion. I think we can keep going on and on and on. We should definitely do a follow up because I would suspect that this map is going to continue to grow and evolve and it's just such a good central point to anchor the discussion around. I want to maybe end with something that I've thought a lot about, which is decentralizing force of technology. It's incredibly powerful and abundant at the same time. It is also very centralizing and unequal.
01:04:22.645 - 01:04:37.315, Speaker D: Has been how do you think AI? Do you think AI, I guess exponentiates that or it does not. And does crypto play a role in the outcome?
01:04:43.495 - 01:05:21.115, Speaker A: I think that AI is yes, a naturally centralizing force, as most technologies are. And I do think that crypto is going to play a role or I wouldn't be here. I think that it's very promising what the fundamental principles of crypto are and how it can play into the vision of AI. But I think we just need to be very careful in how we construct the future because I think there's also a lot of negative that crypto can bring to AI, to be honest, if we move too fast and loose.
01:05:24.205 - 01:06:13.209, Speaker B: Yeah, I think it's good that this is near the end because I'm going to say some stuff that might be better to cut out. I think, yes, I do agree AI is naturally a centralizing force and there is some role of decentralization that could happen and help with that. But I definitely like Casey's point Just now, I think it's very important how this works. The ethos of decentralizing stuff is really good. And this actually just brought it in AI, I assume back in 2013, 2014, when people work on the first version of Ethereum and so on, the ethos of crypto is fairly admirable. But then quickly what happens is a lot of malicious stuff happens in the space, a lot of scams and grifts and so on, which you think is damaged progress to some extent. And they take resources away from good projects.
01:06:13.209 - 01:06:56.645, Speaker B: And there are all types of dynamics that are very hard to reason about. Like, you know, maybe like one interesting thing is, like, you know, with a lot of projects, you're using something from Web3 to help solve an AI problem. But to assess something as an AI problem or not, you need to understand that space. And if you're like, let's say, a crypto investor, there's a bit of a fog of war because you don't spend your days, like, looking into machine learning. So, like, whether this makes sense or not is not immediately obvious. So I guess you just go with the narratives. And if there's like, overfunding and a lot of, you know, people need to deploy their funds and ownership targets, you might have like, a lot of capital B deployed in, like, stuff that just, like, nonsense, which, like, distracts resources from, like, the stuff that actually makes sense, which is like, not just AI crypto, but just like a general thing in the space of like.
01:06:56.645 - 01:07:42.159, Speaker B: And yeah, and yeah, these kind of things, like the deceleration, the decel and like the grifts and stuff like that can definitely be damaging if we move too quickly. And there's the other type of moving too quickly, which is like, poorly designed systems can also be very dangerous. I'm not sure if you've seen this, but something scared me last week was this guy wrote a Twitter thread about. He used Claude to create a nuclear fusion at home, which is great, just open size and all that stuff. But it's also a little bit terrifying that someone in a dorm room with no hardware experience made a nuclear fusion. And he had like, you know, like the metal thing and the protein shaker that was part of the fusion. I was like, wait, and that.
01:07:42.159 - 01:07:51.503, Speaker B: That is like, these kind of can be quite dangerous, you know, like, you don't want to put like, nukes in everyone's hand. So there is an argument around safety. I'm just not sure what best.
01:07:51.639 - 01:08:15.171, Speaker D: The difference between nuclear fusion and then an actual nuke is quite large. But I Take your point. Yeah. Also the counter argument of that is most nuclear accidents have been human error. And so if the AI can correct that, assuming it doesn't want to destroy humanity, then you know, it's a good thing because you would avoid Fukushima and all the other like three mile and all the other nuclear accidents actually, which have been human error.
01:08:15.283 - 01:08:24.427, Speaker B: And the other argument you can make is like, you know, a big reason why many people leaked nuclear stuff in the Cold War to Russia was like, you know, if two people have nukes, no one's going to use it.
01:08:24.531 - 01:08:26.819, Speaker D: Deterrence. Mutually assured deterrent.
01:08:26.987 - 01:08:57.645, Speaker B: Exactly. So like the best way could just be like, you know, the opens with everything. George has like, you know, alignment, just like it should do what you thought to do. It should be open, it should be accessible to everyone. But yeah, so that's just like a comment in general about how the ideas here I think are good, but it doesn't mean we should just go ahead and everything and stuff like that. And there's real challenges like the fog of war if you're saying I'm going to use incentives or cryptography or something like that to go solve this NL problem. The people assessing this, if they don't know enough.
01:08:57.645 - 01:09:38.201, Speaker B: Machine learning is very hard to do and there's no easy way out of this. And again, as an investor you want to under invest is very dangerous because you might miss early projects and so on. So there's a lot of nuances that could fuel what we've seen in normal crypto. The negative sentiment of crypto is the public sentiment is very negative because of all the scams and grifts that happen over the years. If you go to sf, you mentioned crypto, a lot of people have really turned off immediately and dependent has swung the other direction too hard. Crypto is really cool and that was really not cool. I think on a podcast recently, Tarun from the Gauntlet was saying that he was talking to some people and he didn't want to say that he works in crypto.
01:09:38.201 - 01:09:48.153, Speaker B: He just said, I work in cybersecurity. He's just like not a cool thing at all. And that could happen again in AI crypto in particular by just funding all these things.
01:09:48.249 - 01:10:36.805, Speaker D: I think that line will blur over time. We make this distinction, crypto and non crypto, that goes away. I think for me, my central point around AI and how it fits is I actually think that if there's a shot that we have to making it more equal and not as centralizing is with crypto so that it's AI with crypto properties attached to it that kind of acts as a counter force to the natural gravitational pull to centralization. And I think it begins and ends with why I think crypto is so powerful. It's just a better coordination layer to whatever it is that you're doing, whether it's finance, whether it's deepen or in AI, it's just a better coordinate. It's a kind of novel system to coordinate. And I think it's really interesting for some of these use cases like data labeling.
01:10:36.805 - 01:11:17.537, Speaker D: I mean, I've always felt like there are data gatekeepers and that has facilitated centralization. You think about Google, Meta, Amazon, as more data gets created and gets created on chain and it's open and you can coordinate and incentivize people more cost efficiently. It you're never going to win with ideology. I think you win with practical like ROI kind of stuff. And I think crypto can be really good at that. I don't think there's any problem with that. I think ideology is great, but if it's not backed by real tangible, higher, more efficient roi, better at parity, we're never going to win.
01:11:17.537 - 01:11:54.659, Speaker D: But actually now, when you have really opinionated models from centralized companies, if you're a developer, then maybe you would want to use an open model, you know, because you have to. You can't really use a model that's really opinionated and tells you not to eat red meat or something like that. It's kind of bizarre. Anyways, really fascinating discussion both of you. I know you're incredibly busy, so thank you for coming on. We've linked, we've talked about a lot of different things, blog posts and this website with a map. Casey, people can contribute.
01:11:54.659 - 01:12:01.855, Speaker D: We'll link those in the show notes. But I guess any parting thoughts as we, you know, look to close the pod?
01:12:02.475 - 01:12:45.845, Speaker A: My one parting thought is that there is a dynamic in crypto where investors have made the most money on infrastructure, to Mohammed's point, and specifically L1s. And so a lot of builders are pushed to build in that category because it's where the money lies and where historical returns lie. My push for the space is just to not fall into the fallacy that the future will be replicated by historical performance and just do the thing that you think is most technically interesting and makes the most sense from first principles instead of doing any copy pasta. Because I know it can be tempting, but it's just, it's not actually what's going to lead the entire space to the place that we want it to be.
01:12:48.565 - 01:13:12.661, Speaker B: Yeah. I guess my parting thought, which is how I think about this in general, is just try to solve a useful problem and if it happens to you, like crypto, use crypto. If it happens, the blockchain, use the blockchain. But just try to solve a problem. And I guess even if hypothetically you raise from some crypto investors, but you end up being a very valuable AI company. I don't think anyone's going to mind if you accidentally become OpenAI or something. So just try to solve a useful problem.
01:13:12.661 - 01:13:31.585, Speaker B: And this is very hard, or at least very rare to see. Like when you ask someone, what is the problem solve? What is this? What problem is this solving? For some reason, like it's not clear to the people working on it, which is like a bit dangerous. So I don't get too caught up in like AI and crypto and like all these different things. Just solve a problem and then like, I love that.
01:13:31.965 - 01:13:34.869, Speaker A: Yeah, parting. Parting joint words. Solve problems.
01:13:34.997 - 01:13:49.405, Speaker D: Yeah. Go to an AI conference and ask people what their bottle makes and problems are to that initiative. A prior question. And then I think maybe in that list of problems you'll find something that can be unlocked with crypto or if not, just solve the problem.
01:13:49.985 - 01:13:52.425, Speaker B: Or maybe there's a problem in crypto that would.
01:13:52.465 - 01:13:52.921, Speaker D: Correct.
01:13:53.033 - 01:14:04.725, Speaker B: Maybe you should build that problem with pump fund discoverability. Build pump AI, like recommendation engine for pump fund or something. Maybe that would be very useful. I'm just saying stuff here. Don't actually build this.
01:14:05.705 - 01:14:07.605, Speaker D: Someone's going to go and build it for sure.
01:14:08.845 - 01:14:11.385, Speaker B: If you do build up, if you do build it, reach out to me.
01:14:13.165 - 01:14:28.865, Speaker D: There you go. Amazing. Well, Casey, Mo, thanks so much for coming on. I mean, I really enjoyed this discussion. It was great learning for me and I'm sure our audience will appreciate it as well. So, yeah, thanks so much for coming on. And we'll have to do part three soon.
01:14:29.325 - 01:14:31.837, Speaker A: Sounds good. Thank you, Santiago.
01:14:31.981 - 01:14:32.665, Speaker D: Thanks.
01:14:32.965 - 01:14:59.425, Speaker C: Hey, everyone. Big thanks for watching today's episode. Wanted to just quickly remind you about the stellar Development Foundation's 6th Annual Meridian Conference this October, 15th through 17th in London. This is an incredible opportunity to network with the forward thinkers who are defining the future of this space. Head over to meridian.stellar.org and use the code blockworkspod for early bird pricing.

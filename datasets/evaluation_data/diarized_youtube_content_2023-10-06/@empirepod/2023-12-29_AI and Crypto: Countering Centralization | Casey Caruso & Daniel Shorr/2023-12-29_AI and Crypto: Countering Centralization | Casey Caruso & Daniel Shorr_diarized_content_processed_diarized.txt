00:00:00.160 - 00:00:46.174, Speaker A: So AI is one of the most transformative technologies we've ever made, ever. And I've known that for a long time, since I've been a kid. It's an inherently centralizing technology, and the reason it is, if it's not clear, is because you are more efficient. When you have GPU's, connected, co located, you can do more from a fundamental hardware level. And so this has this huge ripple effect of basically centralizing the entire thing. As a believer of decentralized technology, I've always felt that one of the biggest threats we have, honestly, not to sound super philosophical, but humanity faces right now, is centralizing AI to a point that the innovation doesn't compound.
00:00:46.634 - 00:01:09.334, Speaker B: All right, everyone, so on empire, you obviously know that we talk a lot about the institutions coming into crypto, and that is why we are super excited to share that we are hosting the digital asset at summit. We posted this since 2019. It's coming up in London, March 18 to 20th. Don't miss your chance to get ahead of the curve. You can get 20% off with code Empire 20. We'll see you in London.
00:01:11.794 - 00:01:42.994, Speaker C: So welcome, everyone. I'm really excited to host both Casey and Daniel, which I've known for a bit. The idea was to have a podcast that would cover all things AI and then why it's relevant to crypto, of course. We've all started to see companies that have been trying to leverage some of the key innovations happening in crypto and figured this would be a great time to have both Casey and Daniel, who are in my mind, people that I've learned a lot from in the space. And so, Casey, Daniel, welcome. I'll let you both introduce yourselves.
00:01:43.654 - 00:01:57.764, Speaker A: Thank you. Yeah, happy to give a quick intro here. So my name is Casey. I was previously an investment partner at Paradigm, and before that was an engineer at Google and studied computer engineering undergrad, and then have my master's in AI.
00:02:00.064 - 00:02:27.994, Speaker D: Thanks for having me. Santiago. Casey, always a pleasure. I'm Daniel. I'm one of the co founders of a company called Modulus. We sit at the intersection between AI and crypto, so this should be really fun to be able to dive into this. And before Modulus, I just wrapped up school at Stanford, also studying cs like everybody else now, but actually with a specific focus with my co founder in AI, so definitely right at the intersection.
00:02:28.894 - 00:03:05.996, Speaker C: Great. So I'd like to spend perhaps the first segment of the pod, really just giving a more 101, 102 kind of foundational knowledge of AI, because I feel like most people don't appreciate the key unlocks and innovation that has happened to lead us to where we are today, where everyone's talking about AI, that it's a hottest thing, that it's going to be hugely transformational, and I certainly believe it. But I think that appreciating why and key innovations that have led us here would be a fantastic setup to then give everyone a good understanding. So I'll leave you two, really, to have that discussion. So maybe we can get started with that.
00:03:06.140 - 00:04:12.562, Speaker A: So I feel that a lot has changed over the last few years, and I can just do a quick history from my perspective empirically, of where AI has been and where we are today. When I was in school, a lot of what we were doing was not ML, it was really data science, and we were doing a lot of statistical models. And this whole concept of an autonomous or, like a model that would be able to make decisions was a little bit Sci-Fi still. And then I would say, like, around 2017, when I was at Google, we started to see the power of what now is called a foundation model. And you can think of that as just a big machine learning model that takes a lot of data and is trained on that data. And so something that I think is really underappreciated is that the Internet has basically been this trojan horse as a way to get us digital data. And our models were historically capped because we didn't have all this information that we could feed as examples.
00:04:12.562 - 00:05:11.630, Speaker A: And so, yeah, I like to think of that meme of the Trojan horse, and the horse is the Internet, and inside the horse is the data. And then on the other side of the wall is machine learning, like modern day machine learning. And so kind of like just going back to 2017, we start to see that. We start to see, oh, wow. When we pair transformer based nets with a lot of data with really powerful hardware, we get interesting models, and then we kept them at the big tech giants. So behind the closed walls of googles and meta, all of those companies had these very powerful models, but they didn't really open source them at the time. And so what's super interesting about now, and one of the reasons I'm expanding my own mandate to invest in AI, is we really are at this pinnacle of this revolution where powerful foundation models, pre trained neural nets, are accessible to everyone by, you know, either running them locally or hitting an API.
00:05:11.630 - 00:05:33.374, Speaker A: And so it's a very interesting, we'll look back on this time and say, this is very interesting time in all of history. I mean, neural nets have been around since the sixties. But never in this capacity and never to this accuracy. And it's just, it's very interesting to be here today, because I truly do believe this is the beginning of a totally different transformative age.
00:05:34.074 - 00:05:47.810, Speaker C: Maybe, Daniel, or you, Casey, could talk about it. So it sounds like it was a combination of more data, but also hardware becoming cheaper that would allow you to run these models at scale in a cost effective manner.
00:05:47.962 - 00:06:07.174, Speaker A: And the algorithms got a lot better. Like reinforcement got a lot better, transformer based nets got a lot better, the architectures got better. But then I would, I mean, I'm curious, Daniel, your perspective. From my perspective, it's like those three things, it's better data mainly through the Internet, better models and algorithms, and then also this acceleration of hardware, which we're so, so lucky to have now.
00:06:07.554 - 00:07:10.868, Speaker D: Yeah, I mean, absolutely agreed. I guess maybe of those three, all of which are really, really important, I would say the one that is particularly, or has particularly been relevant for the past couple years, at least from my perspective, has actually been the compute costs or the hardware aspects. Cause in some of sense, I mean, you mentioned this, Casey, but the ideas behind machine learning, these kinds of autonomous models have been around since the fifties and sixties. And a lot of these algorithms that we are now putting into production, those ideas have also been floating around for 2030 years. I think Alexnet was like 2012, 2013, around that period. And the question for me anyways, is always kind of what changed between then and now in particular, that enable these kinds of massive models to suddenly become much more effective at the tasks that we always wanted them to do. And I would make an argument around GPU's and lowering the cost of that silica per unit compute and all those fund metrics.
00:07:10.868 - 00:07:56.194, Speaker D: But I think that's a really important part of the story, which has enabled us to bring these algorithmic improvements to our models and then actually digest that data that the Internet has provided. Because I think around the same time, 2017, which is when I started college, we have started, at least in the academic side of things, moving into computer vision and being able to give these models these multimodal expressions. And that's entirely enabled by the fact that compute was super cheap. Nvidia had a deal with my class, so we could just bring up more GPU's and spin up bigger models. And these kinds of seemingly trivial improvements to accessibility, I would say, is a huge part of what's responsible for, like, what AI is today.
00:07:57.854 - 00:08:50.224, Speaker A: Also, just on this point, since you called out CV, I think for listeners that people are less familiar with ML are probably wondering, like, what is working today and what is not working today? And just to concretely answer that question, I think that two things that are working are basically CV computer vision and NLP language models. And so we don't call them that anymore. Those are more like, antiquated terms. We call them vision models and language models, but those are the predecessor terms, and it's a little bit different. And there's nuance in all of this, but just to do this in a broad stroke, and so just to say that out loud, like, I do think that might be helpful if these two categories have really risen the ranks of where we're seeing the biggest gains. And the reason is because of everything Daniel said, both in hardware and with the GPU's, and we have the most data on that. We have the most data of, like, text and images.
00:08:51.204 - 00:09:21.550, Speaker C: So perhaps if you were to talk to a researcher, perhaps five or even ten years ago, you may not even go that far and say that he just stopped there. Like, what would he have told you about the progression of AI in that state versus today? If someone in academia just stopped? Like, was it three years ago? It just felt even. Maybe two years ago, like, how would he have described. He or she would have described AI? Because I feel like that would have been quite different.
00:09:21.742 - 00:09:38.674, Speaker D: Casey, I guess two or three years ago, I don't even think transformers. It wasn't taught to me in class. We didn't really talk about it very much. It wasn't like, the de facto winner of NLP kind of language model discussion at all.
00:09:40.814 - 00:10:05.114, Speaker A: Yeah, I think at Google. Yeah, maybe a little different because it was so inbred there. A little more so. But I. Yeah, I think the entire architecture was different. I think we were doing a lot of, like, lstms were still a thing back, or. Yeah, long term, short term memory was a lot of things back then, but the entire ecosystem was so dependent on different architectures that are.
00:10:05.114 - 00:10:30.098, Speaker A: We've made so much progress in consensus of how to move forward. I think that's the biggest difference, is, like, three years ago, I feel like there were different camps of, oh, this is the right way. Oh, we think this is the right way. And I think now we've really created these stepping stones where we're all sitting here saying, okay, this is the state of art today. Let's all work towards this. And then, you know, we're still seeing, of course, progression and innovation. But I feel personally like there's a lot more consensus.
00:10:30.098 - 00:10:31.978, Speaker A: I don't know if you disagree with that Daniel?
00:10:32.106 - 00:10:49.738, Speaker D: No, no, agreed. I think, yeah, it was very. It was much more tribal back even just a couple years ago. Right. Because it was not entirely obvious which techniques would be. Would have these, like, emergent properties that just show up when you get to certain compute thresholds. Obviously, transformers, diffusion models.
00:10:49.738 - 00:11:21.484, Speaker D: Like, all of these have been totally been paradigm shifting. But, yeah, it's just very hard to predict when these architectures will emerge suddenly as. Okay. Yeah, like, this way of laying out your algorithm seems to make the models really efficient at logic or really efficient at digesting images. So I think even back then, a couple years ago, I would have been much more pessimistic about the progress in the field, but clearly it's just gone significantly better.
00:11:22.024 - 00:11:34.220, Speaker C: Yeah, I think. Well, if I remember, there's like Google Brain and there was a couple of initiatives, obviously, like there was IBM that like, deep, I believe, like, it was like the chess algorithm.
00:11:34.372 - 00:11:34.972, Speaker A: Watson.
00:11:35.028 - 00:12:16.092, Speaker C: Yeah, yeah, Watson. And then they applied that to, like, medical stuff. So it's like, been percolating. I guess it wouldn't be a podcast about AI. We didn't talk about, like, chat GPT, and how that has been very accessible for people to start understanding how they could leverage AI in their workflow, in their daily day interactions. What made, like, OpenAI just rise to become this, what is probably synonymous when most people, I think if we were to survey like 100 people, like, what is AI to you? They're like, oh, yeah, like OpenAI, like the guy Sam, like chat GPT. But of course, it's like, there's so much more behind that.
00:12:16.092 - 00:12:27.184, Speaker C: But I'm curious, like, how, like some background around that. Like, were they pioneering particular thing, like, what made them what they are today, from your perspective?
00:12:30.214 - 00:13:07.290, Speaker A: Well, they are the grandfather of the modern day language model. So, like, let's just start there. They are the first company to really offer a language model that's accessible and offers a step function utility to the degree that they do. And Daniel, I'm sure you were playing with GPT-3 as well, you know, before it really hit mainstream, but it was good, it was okay. But fine tuning was a pain in the butt. And for people that are less familiar with fine tuning, just a process to basically specialize a model. And it was just a really big pain as a developer.
00:13:07.290 - 00:14:10.844, Speaker A: I remember doing that, I think, in 2021 and just being a little bit disappointed with the output. And then when GPT 3.5 came out, I mean, I think every developer remembers the day that they, like, tried 3.5 for the first time. It's just like, oh my gosh, this works. And the fine tuning, like, it's just everything was better to a degree of like, you know, in venture, we think a lot about set functions, like where is the bar where the switching costs become clear? And so, Santiago, to ask your answer, your question to me, it was like when they basically released, I think it was like DaVinci, I forget like exactly the specs of it, but there was like a model that they released that was just superior and superseded everything else in the market. And then they really use that to crystallize their market leadership by basically making it as easy as possible to use, offering up a UI and interface that anyone could access without needing any developer knowledge.
00:14:10.844 - 00:14:14.414, Speaker A: And so from my perspective, that's kind of the progression.
00:14:14.994 - 00:15:26.824, Speaker D: Yeah, I mean, I think this is a weird thing to say now, but like, AI companies didn't really exist a few years ago. As in like, what does it even mean to have an AI company maybe outside of scale AI around like the data component, it's mostly just products and services that were enhanced with these really hyper specialized models, right? There was no such thing as kind of AI as a product, so to speak. I think it came to or OpenAI's kind of big quote, unquote product level innovation here is to offer that language model in this really accessible form factor and have the model be performant enough where it's starting to get that almost like general intelligence vibe to it, where like my mother could hop on, chat, OpenAI, whatever, and actually engage with this product and have like a really, you know, productive experience that's just like never existed before, right? Previously, it's like, oh, I have this model which helps me understand risk better in my portfolio, or I have a model which can help me pick out faces in a crowd. You know, they're all part of like a bigger product pipeline, but with TAGPD, that is the product.
00:15:27.484 - 00:15:49.784, Speaker C: So maybe pulling on that thread a bit more, just going back to the kind of the more foundational stuff. So the requirements are good, high quality data and the ability to ingest that in a cost efficient manner. How would you describe a language model to your mom, to your dad, to someone that is totally not technical?
00:15:52.644 - 00:16:06.594, Speaker A: I would say that a language model predicts the next word or character by taking examples and using that to predict.
00:16:08.334 - 00:16:09.434, Speaker C: So for instance.
00:16:11.374 - 00:16:17.622, Speaker D: That is literally what it's doing, for what it's worth, like mechanistically. And it's just crazy that it works that well.
00:16:17.758 - 00:16:44.332, Speaker C: Yeah, that to me was quite eye opening. It's like it's predicting the next word, but not, but somehow the entirety of the text, like, just is very coherent and it's very accurate. To me, that was one of the more mind blowing discoveries around how this actually works, because I would have thought, I mean, I think there is some relevance, but when I heard that, I was like, really, how is this even possible? It's just reliable.
00:16:44.468 - 00:16:53.732, Speaker D: What you pointed out, Santiago, around, like, how does it kind of keep. That context had been like the big roadblock to, I would say, the adoption of transformers for a long time.
00:16:53.788 - 00:16:53.980, Speaker C: Right?
00:16:54.012 - 00:17:27.154, Speaker D: Like, oh, this idea around attention, this idea around keeping it in memory and navigating context. So halfway through a sentence, it kind of doesn't just go on a different tangent. If you look at GPT-2, GPT, even three, this is the kind of performance issues that you see. And really it was the continued investment in that architecture to figure out exactly how do we get these modules correct or more performant anyways, that suddenly it's like, oh, my goodness. It's like generating entire conversations with me fully tracking everything.
00:17:27.494 - 00:17:29.262, Speaker A: Yeah, yeah.
00:17:29.358 - 00:18:05.244, Speaker C: And maybe a question in terms of, like, I'm gonna probably say something that may not be correct, but, like, when it's, when the, when the algorithm is thinking about, okay, probabilistically, it looks at all the data that it has at its disposal to say in this particular word, the next word, to predict the next word. It sort of says, in the context of everything that I have, I have in the model and the training is probably this word that is most apt or relevant. And so then it does that very quickly to compose the answer when you're.
00:18:05.324 - 00:18:07.144, Speaker D: Doing a prompt for chat GPT.
00:18:09.364 - 00:18:43.324, Speaker C: Can we talk about the quality of these models, for instance, different languages or the bias in them, or when you're trying to apply them for specific verticals and use cases, are we at a point where they are as relevant as general prompts, or are we still in that phase of. There's an opportunity to get way more sophisticated at, like, specializing these models to be more specific for risk or for bio or whatever.
00:18:43.954 - 00:19:09.722, Speaker D: It absolutely makes sense. It just also covers a lot of ground. So it just depends on which thread you want to, I guess, pick at. I think specialization is as good a place as any. Yeah, I mean, these models are like, I think one of the more surprising things to me, anyways, is the kind of zero shot. Like, just like the untuned performance of these models are already very, very impressive. Right? I mean, x instead of y.
00:19:09.778 - 00:19:10.264, Speaker A: Right?
00:19:10.394 - 00:19:57.484, Speaker D: Like, literally just going to any of the GPT prompts that you might have in mind and just inputting it directly for a response. So you can always tune that conversation by getting more specific based on the response you're getting from the model to give it more information. But imagine not doing that, just a single query, and then getting really accurate results. You ask a question about something medical or something legal, and it finds that piece of information or that relevant context. That is, again, a very surprising feature. The thought for a long time was that these models would have to go through really, really intense fine tuning to be able to even get to that level of performance. And it looks like, actually, these hygienist models are already very good even without that fine tuning.
00:19:57.484 - 00:20:12.774, Speaker D: But now you layer on the fine tuning and that performance, that specificity goes to a level that, again, you know, three or four years ago, I would have totally been just flabbergasted by Casey. I don't know if that's been your experience.
00:20:13.434 - 00:21:02.048, Speaker A: Yeah, yeah. So I agree. There's a lot in that question. And so I just want to run through a list. So the different languages, like, this is my question, I think I like to have, you know, anybody can assess is, like, when you're thinking, would an LLM be good at this? You just think, is there a lot of data of this on the Internet? And so, of course, it's really good at every language because there's so much information in every language. And so, yes, that to answer that question, then I feel the question about how good are these models at a base level? And the kind of, where are we going next with this specialization? I think of 2023, or I think we'll look back on 2023 and say this was the year of base models, just like l one s. You'll be like, this was the year that we made, like, Ethereum and Solana.
00:21:02.048 - 00:21:45.954, Speaker A: And then it's going to be, all right, well, what are going to be the l two s on this, and what are going to be the apps on this? And again, a crude analogy, but bear with me. The way we're going to get there is fine tuning. And I just, again, want to redefine this because I am kind of a little bit hesitant of, we're both just hyper technical. So just think about fine tuning as you put in some extra data and you want it to maybe put guardrails on it. That's one way to think about it, to behave in a certain way, and you want it to prioritize certain information. And so to Santiago's point of these, like, bio being a fascinating now specialized use case for ML. We're absolutely going to see that in 2024.
00:21:45.954 - 00:22:24.204, Speaker A: I mean, we're going to see so many different protein models come out in things with like neurotech models, biotech models, all of these different specializations. And we're already seeing this. Like, I think her V AI, I'm not an investor. No, no incentive to say this, but I think that's a really fantastic example of a model that's reaching product market fit, that is using law as its domain and taking a base model and then training on top of it. And I think they're actually, I don't know too much about them, and they're probably going down the direction of maybe building their own foundation model. But the point is that you can take these kind of modular building blocks, very akin to crypto, and start composing them in a way to build more specific specialized llms.
00:22:24.624 - 00:23:28.684, Speaker C: Yeah, on that point, because I do want to transition the discussion at some point into how are these things being productized and where you see that opportunity. And then of course, talk about the relevance for crypto. Do you agree or disagree around bias in the data problems and challenges that we may face, or is your thinking. No, these models are sophisticated enough that they learn by themselves, they improve by themselves to that kind of true intelligence where the model will just. So, for instance, for law or bio, like, if you're trying to do protein unfolding, there's just stuff that you could have never looked back on because you are trying to cut new ground into discovering a protein that literally we don't know that exists, but maybe it can do a certain relationship. But of course, pharma, Pfizer or whatever Moderna might have, like data that they're not open sourcing that they have for themselves that they're not going to share with anyone. And so they might keep that all to themselves.
00:23:28.684 - 00:23:43.524, Speaker C: Would you say that like, that type of model that has been trained with proprietary data will always be better than a model that is generalized? Like, I'm curious if you have a view there.
00:23:44.704 - 00:24:03.012, Speaker A: I think the bias is there because it's in the data. So it's. Yes, we have to overcome that. And that's why, you know, chat GBT is not just GBT, the base model. There's a lot of steps post GBT to take that corpus of information. Do rlhf on it. Sorry.
00:24:03.012 - 00:24:53.592, Speaker A: Do like bring humans in the loop to help them modulate the output. And so, yes, there is bias to answer that concretely. And then the next question of like will a proprietary dataset over always outperform a public dataset? I think always is a really tough word. I try to stay away from absolutes, first of all. Second of all, I think that, yeah, we're seeing a lot of companies that have these data sets come forward, and this will come out when we talk about the value or kind of the intersection of crypto AI. But there's kind of this elephant in the room right now. I feel, in that data is this one of the most important resources in the world, and yet nobody is monetizing it in a way that the feels, like, robust.
00:24:53.592 - 00:25:24.644, Speaker A: It's like this thing that you keep and you harvest. And our entire Internet of social Internet has been built on this premise of use our products for free, but we'll secretly mine your data, and then we'll advertise to. It's just a very opaque, nebulous kind of market structure that we work within right now. And so I hope that answers Santiago. But it's like, yes, there is this kind of belief right now that this private data can be more valuable, and we're seeing that come true for time and time again as companies go into AI.
00:25:25.664 - 00:26:13.754, Speaker C: And maybe, Daniel, if you can answer the third part of the question was, in terms of discovery, when you're using antiquated historical data, how does that overlay into, like, how sophisticated is the machine when you talk about true intelligence, to making breakthroughs like discovering new proteins or, for law, while you're looking at all the precedent that exists out there. But of course, new precedent gets set every day, or, you know, every so many years in the Supreme Court. I'm curious, like, in terms of the discovery piece, how much of AI today is just reminding ourselves of what historically has been done with that context of data versus totally new stuff, totally new relationships that we have never conceived as humans before?
00:26:14.414 - 00:27:13.486, Speaker D: Yeah, I think one of the first things that Ryan and I did, Ryan being my co founder, when GPT four became accessible, was we asked it to solve one of the millennium problems, or, you know, try to give us the proof to Cantor is like, you know, one of the proof based questions that we would get in our math classes, right. Just to see if it could string together enough logic to either fill in things that we've already solved and therefore should be somewhere in its data bank, although maybe not frequently, or something that we've never solved before. Right. Just try to figure out, is predicting the next token, the next most likely word in a sentence enough mechanistic sophistication that it can actually solve these problems that we thought that we could never solve. And the short answer is, it gives a really good try. No, unfortunately, we didn't solve one of the millennial problems that day. If we did, that would make headlines, I guess.
00:27:13.590 - 00:27:13.902, Speaker C: So.
00:27:13.958 - 00:27:53.824, Speaker D: There's two. I'm of two opinions here. One is pattern recognition to the level or the sophistication of these language models has never been accessible or has never been this accessible before. So certainly, I would say there's a whole class of problems. Maybe they're not quite discovery or they're borderline on what you classify as a discovery that will be unlocked because more people can, you know, go at those problems with these new tools. But there are still, I think, problems out there that are absolutely novel, right. That requires a kind of ingenuity that we've never exhibited before or have done so very infrequently.
00:27:53.824 - 00:28:40.864, Speaker D: And so those kinds of architectural features is very hard for the model to inherit or to pull out that kind of, like, semantic information, you know, is it just requires, I think, a really high degree, again, of sophistication. With all of that said, I don't know what GVD five looks like. Gemini looks great. I'm sure the next version is already being developed. It's quite possible that, although so mind boggling to me anyways, that a deep understanding of language itself turns out to be this incredible tool to just solve a ton of problems. I think that would be, like, the strange, unexpected discovery of this entry. So, yeah, not a very satisfying answer.
00:28:40.864 - 00:28:58.634, Speaker D: There's some tension here, even for me. But I do think that I wouldn't be surprised at all if tomorrow it turns out I'm totally wrong and we're solving new math problems or unlocking protein folding, or whatever it is, with just more sophisticated models.
00:28:59.334 - 00:29:01.902, Speaker A: Yeah. Can I say one more thing on this?
00:29:01.958 - 00:29:02.630, Speaker C: Of course, yeah.
00:29:02.702 - 00:29:59.960, Speaker A: Is that I feel something that you're hitting on is basically asking, is like, look, how smart are these models, actually? And I do think another way to juxtapose the past to the present is in the past, we used ML to predict things. So, like, probably the most well used or most used application of ML is recommendation algorithms, I think, because we use them every single day. And basically, what you're doing in a recommendation algorithm is predicting what you'll buy or what you'll see or what you'll stay on, and that's. Yeah, basically one form or one expression of ML. Now, what's interesting about 2023 is it's no longer. Yes, it's still predicting in the technology part of it, but the actual use of it is not prediction, it's creation. And that juxtaposition is really, really interesting because you're not using it as a developer to protect what somebody's going to click on.
00:29:59.960 - 00:30:36.962, Speaker A: You're using it as an end user to create code, to create images, and to create writing. And for me, I think those are three of the most popular use cases right now. To Santiago's point of, can it really do things that we can't do or we can't predict? And I agree with Daniel, it's a complex answer, but I just want to call that out, because that, to me, is one of the most inspiring things about where we are today, is it's not. It's kind of broken free of that, and it is in kind of this, like, creativity, innovation space. And that's just really remarkable, actually, if you just think about it from first principles.
00:30:37.138 - 00:31:21.002, Speaker C: Yeah, I think that's a great segue into the productization of AI, then eventually going into crypto, but as an engineer, as an artist, architect, whatever, where are you seeing the most amount of usage and efficiency gains that you talk about, Casey? It's like, hey, if you're a developer, you all of a sudden can use AI as a companion tool to just superpower your skillset. And human plus AI is just remarkable. Or just purely AI is just better than human. But I'm curious, like, where are you seeing these use cases pop up, and what are you mostly interested in?
00:31:21.178 - 00:32:20.534, Speaker D: Sure, I mean, I can start very granular, which is, you know, if you walk into the modulus office today in a different weWork, you would see that everybody has on their monitor pulled up some version of a language model, either copilot chat, GPT, whatever, right? Like, we no longer developed alone, which is kind of odd, right? Like, oh, there's this bug that shows up even with these. Like, in our case, you know, cryptography, which is very math heavy, very logic heavy. You know, these areas that you wouldn't expect language models to be a huge resource in, we still use them because they're this incredible accessible, you know, first instinct to check against. Do you have any ideas? I'm seeing this error, or how would you solve this problem? And so it's lowering the bar just across the board for all of us on the team to being more productive and being more creative and kind of solving problems faster. So that's one very specific, but just, like, immediately, like, happening example of where lms are already enhancing our workflow.
00:32:22.034 - 00:33:18.610, Speaker A: Yeah, I don't know. If this is common knowledge, but I think software development is one of the most disrupted industries by AI. And I only say this because I was an engineer at Google and I think I can, it's like, I think I have the ability to, but we're not quite there yet, but we're almost at a point where AI can replace like an l two Google engineer. And so, I mean, that's insane when you think about the repercussions of that and just think about like how that will change innovation, speed of innovation. And even, moreover, when I'm diligent founders, I will basically not, I don't like hard and fast rules, but I will take a very hard look if they're not using AI to augment their software development process. Because the way I like to think about it is like, if anyone's played Mario Kart, you know how when you get that star and you're like a super. Yeah, that's what it is.
00:33:18.610 - 00:33:53.000, Speaker A: Like right now, if you are a developer with AI, using AI and a lot of people, it's interesting, not a developer, you're like, oh gosh, the developers, they're really at risk now. They're just going to be automated away. That's actually not true right now. I think that's one of the, maybe that's one of my contrarian views, is that software engineers are more powerful today than they've ever been. And it's going to be like that for a while where like, even though now we have that, you know, level two engineer being replaced, we're actually just so much better at our jobs. And so we can build what used to take months in weeks. And so I double down what Daniel.
00:33:53.032 - 00:34:05.384, Speaker C: Said instead of, instead of needing ten engineers as a startup like Modulus, you can, you can have one or two very good engineers leveraging copilot and just becoming like just hugely efficient.
00:34:05.544 - 00:34:05.976, Speaker A: Yes.
00:34:06.040 - 00:34:45.500, Speaker D: With that said, everyone in Modulus, don't worry, you're fine, we need you. But definitely, I guess the economic argument had always been, look, there is this massive demand for developers just across the board, which our education system, our work training programs are not able to meet that demand, not even close. Right? But here comes a tool which ten x is every specific developer, whatever their role is within the. And I think it will broaden to just beyond developers who even executives or folks in marketing and all that, it will look a little different. But concretely, today it's already happening for software engineers.
00:34:45.572 - 00:35:12.204, Speaker C: As an example, we can now finally, after 30 minutes, I know most people come to empire to discuss crypto. So maybe we can start talking about crypto and how AI is relevant. And of course, Daniel. And full disclosure, both Casey and I are investors in Daniel's company, Modulus. So you hear us really excited about what he's building. Well, there's obviously bias. But anyways, none of this is any advice.
00:35:12.204 - 00:35:25.870, Speaker C: So, Daniel, maybe you can kick us off in terms of give us the story behind your thinking around. Okay. I want to do something in crypto, and I want to apply AI to it. Yeah, for sure.
00:35:25.902 - 00:36:05.628, Speaker D: I mean, this is going to sound increasingly ridiculous. It may be the most dated thing that will be said in this podcast, and that is that about a year ago, when we first started modulus, there was zero AI activity in the sphere of crypto. And I think that's just going to get more and more ridiculous again. But it's true. And part of that is because I think it's really important to acknowledge this, there is a lot of personality tension between these two technologies. Just like architecturally, what they mean for the world, how they like to be, they're quite different. And the other part is, quite frankly, the crypto industry is a younger one.
00:36:05.628 - 00:37:00.368, Speaker D: And never mind the fact that AI is just now really coming on the scene in a big way. But there wasn't a lot of AI competency when it came to crypto, as you look across the sector. So when we showed up, and as a reminder, at that point, all we knew were the kind of AI training we had received at school, as well as all the crypto kind of white papers and papers we were reading in our free time. We thought, hey, we see this interesting technical inflection in the context of zero knowledge. Proofs don't have to get into that right now, but TLDR, this seems like the perfect bridge or the perfect tool to bring this emerging discipline around AI to augment and enhance the crypto world. We were always hearing about UX issues and kind of like, it's a high friction, and it seemed like AI features everything it represented, from recommendations all the way up to llms, was the perfect antidote. So that was the origin story, basically, the inception of Modulus.
00:37:00.368 - 00:37:11.364, Speaker D: Very simple. Just how do we bring these two technologies together so that we could enhance crypto, but still honor those two personalities and what they're really, really good at?
00:37:11.404 - 00:37:11.724, Speaker C: Right.
00:37:11.804 - 00:37:18.544, Speaker D: And our solution to that is ZK, but there are others, and happy to dive into any of that where it's relevant.
00:37:20.644 - 00:37:53.566, Speaker C: Well, I guess maybe, Casey, from your perspective, because I always tell people that you've been as far as I can remember, you were thinking and researching and studying AI before it was cool, before it hit the hype cycle. And McKinsey, once McKinsey starts writing about it, it's sort of game over in my mind. And so, like, from your standpoint, you've been a crypto investor for years, and in your position, like, how do you think about that? And how did Modulus become. Why did it become interesting to you?
00:37:53.750 - 00:37:54.206, Speaker A: Yeah.
00:37:54.270 - 00:37:56.902, Speaker C: And others. But we can start there, of course.
00:37:56.958 - 00:38:00.634, Speaker A: So 30,000 square foot view.
00:38:02.374 - 00:38:04.100, Speaker C: Very thing to say.
00:38:04.262 - 00:38:41.124, Speaker A: Yeah, here we go. No, but seriously, so AI is one of the most transformative technologies we've ever made, ever. And I've known that for a long time, since I've been a kid. And it's an inherently centralizing technology. And the reason it is, if it's not clear, is because you are more efficient. When you have GPU's connected, co located, you can do more from a fundamental hardware level. And so this has this huge ripple effect of basically centralizing the entire thing.
00:38:41.124 - 00:39:58.288, Speaker A: And as a believer of decentralized technology, I've always felt that one of the biggest threats we have, honestly, not to sound super philosophical, but humanity faces right now, is centralizing AI to a point that the innovation doesn't compound. And so that was the scariest thing when I was at Google, is like, holy cow, we have all of this to ourselves kind of situation. And the reason it's so important to bring these two spheres together, to Daniel's point, is you have decentralization, which is a naturally decentralizing tech. You have AI, and that might be the best mechanism or the best method to keeping AI open and accessible. That is one of my biggest goals of what I'm trying to accomplish. And so when Danielle and I originally connected, I mean, Modulus has come so far so fast, but I remember you guys were one of the first ones to put, like, a small neural net on chain, I think, and I had played with it. And, you know, whatever you came up from Stanford to visit, and just the interests are kind of this meeting of minds thinking, okay, these technologies need to play nicely.
00:39:58.288 - 00:40:17.084, Speaker A: And yes, I know AI people maybe don't love crypto people, but we need to start bridging these worlds, because it's going to be one of the most important things to do in our lifetime. And so I can dive into kind of like, how I view the market, but just that's like the substrate to how we've gotten to where we are today or how I feel.
00:40:17.884 - 00:41:09.022, Speaker C: Yeah, let's do that. I mean, I think the important thing that I heard there was inherently technology is centralizing force. Crypto is sort of pulling that back and trying to resist that natural gravitational tendency for things to centralize. You can be idealistic, which I think everyone in crypto to some extent fails because you then don't become pragmatic around. Yeah, we can talk all day about how nice it would be for technology not to cluster, not to, you know, become centralized. But the reality is, economically or not, that this just may not even we can hope for that, but can it actually work? So maybe this could be a good time to unpack a lot of what you said, Casey and Daniel, around, you know, specifically, like, what is it about zero knowledge proofs that make it relevant, make it actually powerful enough to apply that in others?
00:41:09.078 - 00:41:18.170, Speaker A: Yeah, yeah. I mean, Daniel, let's start with just like on chain verifiability and what that unlocks. And maybe, yeah, if you want to. That's like one very, very exciting use.
00:41:18.202 - 00:41:23.274, Speaker C: Case of this section, proof of humanity or whatever, you know, with your keys. I don't know.
00:41:23.354 - 00:41:24.282, Speaker A: Sure, sure.
00:41:24.458 - 00:42:39.276, Speaker D: I mean, I think just stepping back for a moment, one way to think about Ethereum, or, you know, take your blockchain network of choice. But Ethereum, for the sake of this argument, one way to view it, look at what it is, is this incredibly, incredibly robust public record table, right? Where you can just log whether transactions or state or whatever, where everybody can check and take a look and go, okay, yeah, yeah. I can come to a relatively high confidence belief that what's on this record is accurate. And so this, the capacity for this network to be this great common ground to the world's appetite for high integrity things is a big part of what we try to celebrate at modulus. I don't know if now is too early to take a peek beneath the hood at what zero knowledge cryptography is and why we think it's the right tool for this. But just to give a super, super succinct, I guess, framework for thinking about things, zero knowledge proofs for us is a capacity to make a count of things. And the blockchain network, Ethereum, is just where we log the accounting.
00:42:39.276 - 00:43:03.766, Speaker D: Basically, all of this is happening in a really trust minimized way. And we think it's an excellent tool to do exactly what Casey mentioned earlier, which is to counteract some of the centralizing influences and tendencies, the nature of something like artificial intelligence. But Casey, maybe you have a different take on public verifiability that we can also work into the framework?
00:43:03.910 - 00:43:54.504, Speaker A: Well, I think something maybe just recent that happened, which is pretty interesting, is I don't know who's read Biden's AI executive order, but it's worth reading if you haven't. I also have a summary if that's helpful. But one of the most potent or salient things that I took away from that was the government sees the need for Providence moving forward. And I think verifiability is one of the methods that may achieve that. And I think there's a huge set of challenges with it. But I think it's one of the things where I think if you're playing the pro case of this, is it's not a problem looking for a solution. It has already, by the government and by the general public, been identified as one of the biggest problems with deepfakes, just like model accuracy, model credibility.
00:43:54.504 - 00:44:42.168, Speaker A: And so having a system that's accepted to verify them makes total sense moving forward. And I think it's really, really dangerous to predict what's going to happen in AI next. This is like one of my more interesting, or something that I've been chewing on recently, is just that AI has basically been the reverse of what we expected. So, like, in the beginning of AI, we really thought, or at least like my cohort thought, like reinforcement learning of robots was going to be one of the biggest killer acts. We had this kind of revolution with like, gossip dynamics and that whole era. And what ended up happening was robots still are extremely hard to control. And what we, one of the first killer use cases of AI is human empathy and relatability and accountability.
00:44:42.168 - 00:45:04.064, Speaker A: And those are the things that we thought was going to happen last. And so we're having this like total paradoxical thing with AI, where the things we thought would be easy or hard, the things that we thought were hard would be easy. And so I say this as like a caveat of let's have the conversation. And I'm happy to tell you what I think is interesting. I also think it's really dangerous to be prescriptive with such new technology, new in the capabilities.
00:45:08.284 - 00:45:40.852, Speaker C: Yeah. And so the verifiability, the provenance of that. I mean, of course the simple lizard brain of mind thinks, okay, blockchains are data rich. To your point, Daniel, the applicability of blockchain is such that anyone can verify. This is what makes blockchains blockchains. If anyone can go in and verify the state and the transition per block, then that makes it really powerful because it keeps the system in check. It's open, it's accessible, transparent.
00:45:40.852 - 00:46:26.860, Speaker C: Not only that, but over time, if you think about blockchains, they will produce an inordinate amount of data that it could be used for training and other things. And the data is sort of pristine, like you have these guarantees that it hasn't been tampered with. Of course, now most of it has been transactions sending bitcoin from one address to the other, but it doesn't stop there. I think you can embed a lot of data into these blocks that can make it useful. So back to maybe zero knowledge proofs, or how you're actually thinking about modulus as a product. What is the product? What exactly are you selling or building? I guess.
00:46:27.012 - 00:47:04.292, Speaker D: Yeah. One thing that I think is packaged within the nature of what machine learning models are in production, and we call it these centralizing influences, is also the fact that they're like black boxed models for the most part. They're very opaque. It's very hard to predict a specific set of behaviors. It's very hard to point out fraud when this happens, or any type of manipulation, whether intentional or not, never mind bias and all the rest. These are all active challenges when it comes to machine learning. And so when you think about applying AI models in production, in the real world, those risks just comes bundled in.
00:47:04.292 - 00:48:05.138, Speaker D: Now, it might not matter so much if it's the model trying to pick out a nice outfit for the day, or having a conversation with you about the weather or anything like that, but our belief anyways is that it will really matter when the stakes are high, be it financial, legal, medical, some of the contexts that we mentioned before. One very clear beachhead for these kind of high integrity environments is blockchain based applications. So if you're running a dex, you're trying to balance some pools, anything of that nature here is exactly where that attack vector will be really present. So, to answer your question, Santiago, what is a product we're working on? Well, we're using zero knowledge cryptography to basically prove that an AI model executed the way that it was supposed to. There was no manipulation, there was no tampering. Even if it's a black box model, so to speak, it sits in that box and nobody prodded it to act in a very bizarre manner or in a tampered way. And we make that result something that is both verified on the blockchain.
00:48:05.138 - 00:48:44.384, Speaker D: So from now until forever, anybody can verify that that specific AI result acted correctly in accordance to the pre agreement, and secondly, making that result native to the blockchain, basically something that can be digested by any DAP or composed with, you know, with all those properties that we really appreciate about operating on chain. So we call this idea zero knowledge machine learning, or ZKML. And, you know, it's early innings, but we think it's one of the most, will be one of the most powerful kind of, you know, building blocks to not just blockchain services in the future, but how AI is used, just society wide.
00:48:45.684 - 00:49:17.242, Speaker A: I think that was so well said. And I think one. One thing to just put it one step further is once you have this, which gets me really excited, is that it unlocks the rest of the crypto ecosystem. So if you can verify, then there's all these services like Defi, for example, that you can plug into, but you can't really do that if you can't verify it. I mean, you could, but it's like, it's a total unlock, and so it's valuable for the output, and then it's also valuable for what is on the other side of that verifiability.
00:49:17.418 - 00:49:34.334, Speaker D: Exactly. I mean, you know, the naive way of. Naive mathematically not to make light of anybody's execution, but the simple way, quote unquote, to do this is to just write your AI models on the blockchain. But if you're familiar with gas fees and congestion and block space.
00:49:36.074 - 00:50:07.700, Speaker B: All right, everyone, so we talk a lot about the institutions coming into crypto on empire. Santi and I are both headed out to London March 18 to 20th for blockworks, 8th ever digital asset summit. Das. This is an institutional buttoned up conference that we've hosted since 2019. I like to joke that it is probably the last remaining kind of suit and tie event in crypto. People are still wearing suit and tie. It's pretty funny, but you'll actually hear from a lot of the largest institutions in the world coming from standard, Charter FIS, JPMorgan, framework, folks coming out.
00:50:07.700 - 00:50:26.428, Speaker B: Wintermute, Vanek, Goldman Sachs. There are a couple big themes of this conference. One, bitcoin catalysts, the halving and the spot ETF. Two, a view from the buy side. Three, Rwas tokenization and stable coins. Four, global regulatory frameworks. Five, institutional infrastructure, including banking and payments.
00:50:26.428 - 00:50:48.166, Speaker B: And six, the macro case for crypto. If you have anything to do with the institutional side of crypto, you have to be there. Santi and I got your back. We hooked you up with a 20% off code. It is Empire 20. There is a little competition running internally at blockworks to see who can drive the most number of tickets. So help Santi and I out register with our code and you get 20% off.
00:50:48.166 - 00:50:49.714, Speaker B: That is empire 20.
00:50:51.374 - 00:51:03.420, Speaker C: I was going to ask you just that. You know, we can. As far as I can remember, zero knowledge first had been this sexy holy grail. But we always bump into, how is it cost efficient? Can we do this at scale?
00:51:03.612 - 00:51:26.244, Speaker D: Exactly. Yeah. And actually Casey mentioned this when we first met. We had just put a tiny, tiny, tiny neural network on chain using zero knowledge proofs. So the model is running on a server like anywhere else. But we proved that the model execution was correct and we put the proof in the result on chain. But even with this scaling technology, we were limited to very small models.
00:51:26.244 - 00:52:02.564, Speaker D: We had spent a lot of this conversation talk about llms, and we think there's a lot of applications llms to, especially high integrity results of llms to the blockchain network. But the big question is, how do we unlock access to these massive models, these highly performant, super expressive models, with this zero knowledge kind of, you know, framework or zero knowledge path? So that's what we work on full time, basically just trying to figure out what is the right way to make that unlock happen and open up access to these really exciting developments in the AI world for the on chain audience, especially Casey.
00:52:02.604 - 00:53:08.132, Speaker C: I mean, a lot of what you and I talk about, we've known each other for years and invested in crypto together. And I think you have a uncanny eye for bullshit as well, because in crypto, no, I'm saying this with crypto is one of those spaces that is so generalized and so exciting, maybe like AI, where it is easy to attract certain type of builders that, you know, there's a lot of fluff and there's a lot of bullshit out there. And look, anyone listening to this might have come with a certain degree of skepticism around. Here we go. Crypto is that industry that anything that is hot crypto people are going to take and just reformat, repurpose and try to extract money, but not actually build real products. Yeah, that's just the criticism. If you were to ask most people that are outside of crypto, that's what they would say, how real is this? Like, are we going to see this in production? Is the opportunity there? And when I say opportunity, it's not the ability to make money, because we have cardanos of the world that have not shipped and have valued in stuff that I.
00:53:08.132 - 00:53:20.980, Speaker C: Anyways, how real is this? And how, like, when you think about the opportunity versus investing in other areas of crypto that are perhaps also exciting, how do you see this as an investor?
00:53:21.132 - 00:53:43.852, Speaker A: Yeah, so my answer would change depending on what angle I take, if it's like the AI first or the crypto first. And I'll say for every one Daniel I meet, there are 99 people who are just trying to exactly do what you said, which is take crypto and attach AI to it and capitalize on it. And so, like I said, I think.
00:53:43.868 - 00:53:46.504, Speaker C: You and I have seen collectively, like, hundreds of decks.
00:53:47.484 - 00:54:15.860, Speaker A: Yeah. So I see one more decentralized GPU deck. Oh, my God. Let me just say that Daniel is like a very needle in a haystack situation, and we live to work with people like Daniel who are really here for the right reasons and want to see the change in the world that we want to see. How real is it? Let me just. This is my dependency chart. In my mind, AI must stay open.
00:54:15.860 - 00:54:49.030, Speaker A: It must. We have to do that as a society. Crypto in blockchain, decentralization, web3, all of those are very good contenders to help us achieve that. And so how real is it today? There isn't too, too much, I mean, and I'll walk you through, let me walk you through, like, the six things I'm looking at right now. But we're very, very much at the beginning of what this intersection could look like. And, you know, you're going to be too early, too early, too early, and then you're going to be too late. And I think that transition is going to happen really quickly.
00:54:49.030 - 00:55:17.364, Speaker A: And that's why I'm spending time here is because it is one of the most interesting, asymmetric, I think, opportunities we have in crypto. And I think it's a really good contending technology for AI. And the principles of web3 are going to be leveraged. It's just cardinal to make sure this technology reaches its full potential. Potential. Does that answer it in a way that's satisfying? Santiago?
00:55:17.904 - 00:56:13.416, Speaker C: Well, it could be satisfying to me. Is it satisfying to the world? Yes, I think what you just said is very, I believe it. The two things that you said that stuck for me were crypto is probably the best contender that we have to keep this technology open and to resist that tendency to go and centralized. Of course, you could do that the other way, which is by enforcement through some sort of act, but that hinders innovation locally but not globally. That could, you know, you could stop GPU's from being sent to China, but still, technology always finds a way. And the second one was, I think, you know, crypto is open source and continues to like the innovations that we've seen in crypto, like in AI have felt really slow for ten years and then very fast. And that is just inherently, I think, the state of technology, and I agree with you, I'm spending time on it, even though I'm not as sophisticated.
00:56:13.416 - 00:56:21.004, Speaker C: And so I lean on people like you to help me understand this space and weed through a lot of the crap that's out there.
00:56:21.904 - 00:57:54.434, Speaker D: Well, I can personally attest to, I think, both of you being extremely high quality operators, by my impression, so. And with that, you know, set aside, I do want to make an argument here as well, though, that I think the end state here results in, like, a product with a capital P that is just also better, like, period, end of sentence, right? And if you don't mind me spending like, a minute or two on this, like, mental framework. You know, we spend a lot of time in the world of cryptography, and it's worth thinking about what is it that cryptography is doing for us in the context of ZKML, but also just like zero knowledge in general? And actually, I think it makes sense to visit, just like, what AI models are, even for me anyways. At the extreme, what an AI model ultimately is meant to become is the capacity to scale human decision making, just like forever, for free. Basically, wherever you want a human to be making a decision, you can bring in a model and have that happen for you, but with even higher performance, which is weird to say about a human being, but nonetheless, this is very exciting, of course, but it's also a little bit problematic, like this idea, because let's say that Casey Santiago, we walk into a court of law, and there's a judge giving us a sentence. The three of us committed some terrible, terrible crime, except we didn't. And we want to make sure that the judge is making a fair decision.
00:57:54.434 - 00:58:26.050, Speaker D: The way we would do that today is we will look at the record of this judge. We look at all the decisions that they have made before. We look at their credentials, where did they go to school? What law school? We look at their habits, any scandals, whatever, because human beings have this incredible quality of being really discreet. Here is a person. There's this web of infrastructure and trust that we can use to evaluate a person based on their past behavior. Compute suffers no such luxury. Compute just floats out in the ether.
00:58:26.050 - 00:59:32.284, Speaker D: It's model v one. It's model v one one. We change a couple parameters, we tune some inputs, and the output can be radically different. All that to say that, for me, anyways, one of the big opportunities here where the convergence of crypto and AI literally makes the output better is where we have models that are now accountable, right? That we can look back on the history of that model, we can test it for robustness, for bias. We can look at all the llms, which is consulting this lawyer, all its past recommendations, and make sure that it is fair and it's not hallucinating case studies and whatever. And so I think taking away all the kind of aspirational ideals we have around decentralization, taking away kind of where we're concerned with the progress of technology and how it's going to interact with society, just looking at this product now, an AI model, which is now much more accountable thanks to the work that we're doing in the crypto world. I think for me anyways, it's like, okay, this is a future that I actually think is better.
00:59:32.284 - 00:59:40.094, Speaker D: And so that's a big part of why I think this stuff is worth engaging with and work worth working towards. Yeah.
00:59:40.514 - 01:00:46.562, Speaker C: On the verifiability piece, I totally agree with you. Like if you can have a high degree of certainty that the model did exactly what you wanted to, and you can trace provenance of what resources it consumed to get to that output, then it becomes highly relevant, particularly for the example that you described around, you know, you're sentencing someone, there's inherent bias. You know, there's maybe an AI model can help us compare the decision of a human to the one of an AI that may be less biased and then know contest that outcome. I'm again going back to the challenge of crypto has always been scale and doing these things effectively. My understanding is you've been focusing and tinkering on the ethereum blockchain. Now there are competing l one s that are more performant or claim to be more performant more. I'm curious, in that decision, we don't have to spend a ton of time on it, but I'm curious if you have a view on where we may see these applications actually work at scale and be your actual product with profitable unit economics, if you will.
01:00:46.698 - 01:01:21.528, Speaker D: Yeah, that's a really good question. I mean, I think concretely we spend basically all of our time reducing costs, increasing performance. We want the ZK desk to be as little as possible so that we can bring more performant models to these services. I will say almost all the partners we work with today are on Ethereum. The reason is actually even less about the performance of the underlying chain and more about the culture, the culture of Ethereum today. Although I'm sure this is true as well. On many of the other networks is that of security matters, integrity matters.
01:01:21.528 - 01:01:53.180, Speaker D: We want to make sure that we have a stack of smart contracts that compose the foundation of our service. Actually, we don't breach that security that's provided by that. By suddenly referencing an AI model that is centralized or closed source, we actually want to bring the ZK in. So we maintain that security, this is something that really, really, really matters to the Ethereum clientele or the ethereum audience. And so we found a lot of cultural alignment there. That is not to say that that is the extent of our work. One of our other partners is Worldcoin.
01:01:53.180 - 01:02:25.194, Speaker D: In the context of that collaboration, the proofs aren't even settling on chain. We're actually just trying to convince the worldcoin servers that when people attest to their IR's scans or attest to their identity, they're not doing that with a manipulated IR's or a manipulated identity. So early innings were really just at the beginning. But my expectation is if we can do a good job here by showing that high security, high integrity AI matters and improves dapps across the board, we'll see that pop up in Ethereum and Solana and all the other ecosystems.
01:02:28.354 - 01:03:15.454, Speaker C: Casey, I would love to get your map of how you think about all the different, you've seen many decks, some of which are, as you said, centralized compute networks and something like, how are you thinking about the evolution and the opportunity set in crypto? What's your time horizon? Who are the customers here? Are they crypto native companies like world Coin or may this be a beachhead into actually pulling in less crypto native people? And maybe them not even thinking or thinking that it's crypto, but just being very focused on, oh, verifiability is something that I can really wrap my head around and I like, don't tell me if it's crypto, just sell me the product.
01:03:15.794 - 01:04:02.854, Speaker A: Yeah. So I do think that was spot on in that. One of the more exciting things to your question earlier of why spend time on this category? This might be the most successful category to bring non crypto people into crypto. And the reason is because if you look at what are the killer apps of crypto today, in my opinion, like, the top two are beyond, all ones are NFTs and DeFi, and both of them are inherently crypto native. You know, they weren't from the real world. They were built on chain. And this could be the first subsector to, you know, be prominent in a bull run where it's not crypto native, it's actually coordinating things that are outside of our native world.
01:04:02.854 - 01:04:59.420, Speaker A: And that is so exciting. But yeah, let me tell you. So I keep a list of the categories of Dex, IC and kind of the sectors that people are going after, and here's what I'm seeing the most of, and I'll try to keep this brief, and I can provide commentary on kind of the pro and con case of each of these. But the first thing, as I alluded to, was decentralized networks of GPU's. The case here is could we build basically a crowdsourced Uber Airbnb for GPU's? And from a technical standpoint, it's, it's hard because of what we said, when you get so many compounding effects by GPU's being co located, but there's definitely a case that certain use cases that can handle certain latency and just take more time to train, that could work. So that's actually quite interesting. And then the next thing I see, a lot of which I love is local and peer to peer inference.
01:04:59.420 - 01:05:55.134, Speaker A: So if people aren't familiar with inference, inference is basically when you get a result from the model. So you do the pre training and then you run inference, which you can either hit an endpoint or just anything that gives you back the result. What we're seeing with some centralized companies like Olama, which allows you to run lama two mister l other open source llms locally, that's becoming a huge trend, is that people say, you know what, I don't want to send my data through this hugging phase or replicate endpoint, or, you know, I don't want to have to rely on wifi to hit this model. There's so many reasons that they're like, you know what, I just want to run this locally. I just want to run this on device. And that trend of edge computing is not only just happening, but it makes you think, well, what's the next step of edge computing? Well, it might be peer to peer inference, and that's something that a decentralized network would be phenomenal at. And so that, that's super, super cool.
01:05:55.134 - 01:06:53.458, Speaker A: And then the next category I see a lot of is just crypto incentivized behavior. So think about crypto incentivized AI apps, where basically we use crypto to incentivize or bootstrap a network, crypto incentivize RLHF, mlops, all of that kind of category, which I put, I can do subsectors, but it's basically just taking what, you know, one thing we're really good at is promoting certain behaviors and taking that property and mapping it to AI. Then we already talked about verifiability. And then the two final things I see a lot of that I'm excited about are, I would call it self owned models and data, and to the point of data being this really lucrative yet unregulated asset. How do we use crypto and blockchain to be able to give power back to the people who actually create the data? And it's not about power. It's about. It's not so much more than that, but basically, oh, yeah, no, no, you.
01:06:53.466 - 01:07:01.682, Speaker C: Go, no, it's more like agency, like understanding who's using your data and opting in or opting out and actually getting some modernization out of it.
01:07:01.778 - 01:07:18.124, Speaker A: Exactly. And you can imagine a world where just like metamask today, we take our metamask from crypto app to crypto app to crypto app. You could do the same with your data and models. You could use it on Facebook. You could use it on, you know, whatever the next, like, stability. AI is whatever it is. And, like, it would be this point portable thing that you take with you.
01:07:18.124 - 01:07:57.054, Speaker A: And so that, to me, kind of makes sense if you squint. There's also a lot of problems there. And the last category I see a lot of is, like, agentic use cases where basically for people unfamiliar with agents, they're kind of like autonomous ML models that can make decisions, and they, in a lot of forms, are always on. They operate in the background in a lot of ways. And so you can think of how it might make sense for AI agents to use crypto natively as their payment because they can't really KyC. And that might be part of the agent infrastructure that becomes fortified in 2024.
01:07:57.794 - 01:08:59.378, Speaker C: Yeah. The thing that for me was very exciting was this idea of proof of humanity. You control your keys, and you can attest to, you know, hey, I'm human in some way, shape or form, and I think you can do that with cryptographic keys, if you will. Like, somehow, I guess, the, going back to all these examples, while I agree with them, but what would, you know, we can, like, what would derail the case for these? Like, what are the cons? Are they just purely performance costs? Like, if you're a corporation, you might wish and hope that you have more agency or it's more decentralized. But at the end of the day, like, if a centralized provider is just more cost efficient and performant, I think humans time and time again make these trade offs. Everyone uses social media whether they understand that their data is going to be monetized, you know, it's a free product. So ultimately that wins.
01:08:59.378 - 01:09:10.646, Speaker C: For better or for worse, this is an option. But in terms of market size, do you see this actually competing against the centralized solution?
01:09:10.830 - 01:09:32.448, Speaker A: Yeah, but we need more information. We need to see right now a lot of the crypto providers that I talked to for the decentralized compute for the use case you're bringing up, they're subsidizing costs and that's not sustainable. You need to economically beat the centralized providers or you need to provide another value function which enables the switch. And so I completely agree with what you're saying.
01:09:32.616 - 01:09:58.921, Speaker C: Let's talk about decentralized compute numbers because it is a hot topic. You have IO and you have Akash and you have, I've seen like ten Dex in the last two weeks. The hot TLDR is, it is extremely hard to get access to, like GPU's. It is, it is a hot commodity right now. You cannot find it. And so if you're a startup, you just raised a bunch of venture money. You want to give it to Nvidia, but it's going to take time.
01:09:58.921 - 01:10:41.874, Speaker C: You can have this as Airbnb, unlock this idle inventory or Filecoin, like distributed file storage systems is, let's rent it out and use all this unutilized. And crypto is really good at coordination. So you can all of a sudden, even if it's not co located, you can get the similar performance. And there's a whole subset of people in the market right now that don't even have access to GPU's and are going to now have access to GPU's and they want to pay for that. And so you're just creating a new market opportunity. How real is it? Like, how viable is that? Is it just a short term bottleneck you're fixing or is this actually an enduring product over the next couple of years?
01:10:42.334 - 01:10:55.018, Speaker A: I think it's less real than people think. I'm going to be bold. I think that there's a lot of centralized providers out there, like vast AI that I can hop on and get a GPU. And yeah, maybe H 100s are rented.
01:10:55.066 - 01:10:58.930, Speaker D: Out, but you may not need the h 100.
01:10:58.962 - 01:11:09.594, Speaker C: Is this Nvidia like Ferrari? Right. No one can get access to. Right. But it's the, if you want the Ferrari for this stuff, it's the h 100, right?
01:11:09.714 - 01:11:46.986, Speaker A: Yeah, yeah, a 100. But, yeah. So those are hard to find right now, but there is a lot of like GPU marketplaces there's a lot of centralized providers too that are doing this. And so you can get on like banana dot de V or like runpod or, I mean, I could list a million of them. And yes, then you have the Akashas and the I o dot nets and the renders and all of them and like bitten through, I think, in the future. But the thing that needs to be proven is that you would rather go with a decentralized provider than a centralized marketplace. And there are some early signals of that.
01:11:46.986 - 01:12:17.144, Speaker A: There are actually some interesting case studies of technology companies that I won't dox on the podcast, but they're actively choosing to go with decentralized providers for a variety of reasons. But we need to see that sustained and crystallized because that's the most interesting thing I've heard over the last month. Getting on the phone with these tech companies that are based in the valley. They're just regular AI companies, and they're saying, yeah, I'm going to go with this decentralized GPU provider and I'm going to end my contract with, you know, my other burst provider. And here are the reasons why. I mean, that's like, that's what I'm.
01:12:17.144 - 01:12:37.684, Speaker C: Saying isn't the biggest reason I've heard consistently across these companies is like, it is very localized. So if you want to have access to a GPU that's in Europe, you have to have a different service contract. And just the time component becomes faster from a decentralized standpoint because you sort of transcend local.
01:12:38.404 - 01:13:02.744, Speaker A: Yeah, I mean, you don't have a YC, you don't have to do anything. Like, it takes me 2 seconds to spin up a GPU on Akash. So there was like zero friction in that. And then the other thing is, just for people that are scared about the future of AI regulation, this is like more of an ethos thing. But if a CEO is scared about where the US is going with AI reg, they are like much more apt to go and invest in a decentralized architecture because they just want to be safe.
01:13:03.784 - 01:13:29.644, Speaker C: Mm hmm. Dan, you've been quiet in the background, but I mean, I know you may not, but I want to get your perspective, like as a builder where you see beyond what you're doing, other opportunities, maybe other founders you've interacted with of real. Maybe the real more interesting question is, if you had to pivot today into something else, crypto AI, what would you be doing?
01:13:30.964 - 01:14:16.390, Speaker D: Yeah, maybe just because we're on the topic of decentralized compute networks and so forth. I would say the challenge actually is not so dissimilar from ours in the sense that there's a science challenge here, which is that I think Casey is totally right here in that fundamentally, I guess this is my sense of things in general anyways. Ultimately, it's just about a better product. Anyways. If I'm running a startup and I need a GPU cluster to train my models on, I'm going to choose a provider which is cheaper, more robust, maybe not as geographically constrained, and so forth. If that happens to be a decentralized network, I don't really care what's on the back of the box. The front of the box is good enough for me.
01:14:16.390 - 01:14:30.294, Speaker D: Let me sign this contract and just get rid of this problem insofar as there's another player in the space, for example, called Jensen, which is trying to do this decentralized GPU training network.
01:14:30.634 - 01:14:32.610, Speaker C: They're more focused on training, not infrastructure.
01:14:32.642 - 01:15:12.334, Speaker D: Yes, they're focused on training, specifically of training large models. And in that case, although the cryptography is complex, it's a very linear challenge. If they can get the cryptography to a low enough cost standpoint or low enough unit economics so low that it's better than the centralized provider. I just raised a billion dollars to build some cool LLM or foundation model. Why wouldn't I choose this decentralized network? It's 20% to 30% cheaper than going to Amazon or Google or whatever. All that to say that I think that the funny thing is, ultimately the best product wins over a long enough time horizon. And that's what we are about.
01:15:12.334 - 01:16:02.430, Speaker D: It's just that the cryptography or the crypto aspects of a lot of these decentralized networks of are so early, they're still in their infancy, that we need to oftentimes juice these incentive systems to try and get people to migrate to our networks. But to Casey's earlier point, that's not sustainable and it obfuscates product market fit, which is very, very dangerous. You get addicted to the drip. To answer your question, Santiago, if I had to pivot and work on something else today, I don't know what I would be doing. I'm absolutely obsessed with our problem statement, but it would also most likely be at the intersection of AI and crypto, just because it's such fertile ground for so much. And I think being focused on the science, those kinds of unlocks are meaningful and moves the whole industry forward.
01:16:02.542 - 01:16:49.908, Speaker C: Yeah, I want to emphasize something you said, which is incentives, and it's something that is obviously more people are critical about these days, but I don't think there's anything wrong if you use incentives the right way, as a pull mechanism. And once people, because a lot of times these networks become more efficient, but you need to kickstart them and you solve that friction to get people in the network. And then once that's the case, any platform you need to solve for supply and demand. So if you can do that with incentives, Uber was giving away free rides and then subsidize. This is the way networks get off the ground to resist the inertia of switching and stuff. So there's nothing wrong with crypto incentives. I feel like somehow that has become taboo, and I think people really missed the point.
01:16:49.908 - 01:17:37.828, Speaker C: That is the most powerful thing that we have is coordination in a more efficient manner. Casey, I want to perhaps go back to something you said, which is a lot of times, as particularly you said about AI, is things will look like they're slow, and then all of a sudden you believe that there was going to be a very fast unlock and development around these things. And I wanted to ask both of you, this question is like, as you think about the next two, three years in crypto or just in general, where might we see those huge unlocks, whether it's specific to modulus or other things, how does that impact crypto overall and specifically like crypto AI market?
01:17:37.996 - 01:18:12.160, Speaker A: Yeah, I think the biggest thing we're seeing in AI is, or what we'll see is the productionization. So right now, a lot of it. So it's cool. And everyone's having these aha moments this year of chat, UBT and, you know, this first agent, but they're not really production level ready. And that's maybe an under appreciated fact. And so I think we're going to see a lot more robustness around us bringing these into enterprises. And so this is like a total, in my opinion, a retail driven phenomenon right now.
01:18:12.160 - 01:18:50.700, Speaker A: Like AI, of course, there's a lot of enterprise applications, but in terms of like what people are talking about and excited about, that's retail. And so what needs to happen, and like, not to get too nerdy here, but what's so different about, or what's so different about AI is that the whole thing is non deterministic, meaning that you can't say what the output is going to be. It's a bayesian situation. And when you juxtapose that with traditional programming, those are rules, these are logic, these are pure functions. You know what's going to come out. And so from a programming standpoint. The whole thing, in my opinion, kind of needs to change.
01:18:50.700 - 01:19:38.644, Speaker A: And this will loop back in that the reason things are toys is because we don't know fully how to handle the non deterministic nature. We're figuring this out on the fly. Like, the amount of things I have break on a daily basis because I think I have this agent running for me and it just runs into this edge case, and then I don't know how to handle it. And so once we figure out how to put the guardrails up in a way that we can really trust these systems and say, look, if it does hallucinate, it knows what to do, and, you know, you can really, really trust this. That is going to unlock the next level of use cases, I think. And, like, that's just the answer to your question, and then how crypto will play into it. I mean, again, I think it's dangerous to predict here, but it's just like, I think that needs to happen before we can even have that conversation.
01:19:38.644 - 01:19:49.332, Speaker A: To me, that's like, the necessary next thing for us to advance. Daniel, I'm so curious what you think about this because. Yeah. I haven't said this out loud too many times.
01:19:49.428 - 01:20:00.540, Speaker D: No, no, it's interesting. Yeah. It's definitely one of those, like, underappreciated features of just AI in production, which is a non determinism. It's a challenge when it comes to zapproving as well.
01:20:00.572 - 01:20:00.860, Speaker C: Right.
01:20:00.932 - 01:20:10.614, Speaker D: Just explaining that. Right. Like, smart contracts, the way they're composed is like they're super rigid. That's the whole point. Right. Like, super predictable. You know exactly what's going on.
01:20:10.614 - 01:20:25.698, Speaker D: And, you know, in our world, we're entirely obsessed right now with how do we enhance daps with AI. Right. And so trying to bring that degree of uncertainty into a regime. Right. Some. Some say, like, these two should never mix because of this. Right.
01:20:25.698 - 01:20:42.600, Speaker D: But try to do this in a way that's responsible, high integrity, and again, you know, respects the ethos and the personality of both disciplines is really, really tricky. But I guess to answer Santiago's question in terms of what I'm looking forward to in the short term, it's exactly that.
01:20:42.672 - 01:20:43.304, Speaker C: Convergence.
01:20:43.384 - 01:21:16.094, Speaker D: I think 2024, we're going to see a ton more Dapps with AI features natively. Just part of that service stack, whether it's recommendations, whether it's risk modeling. We just started working with a company called Upshot on appraising NFT values. Yeah, yeah. And automating these kinds of markets or a project called ion on digesting. Like the risk profile, trying to predict slashing with AI models and then, you know, issuing table coin based on that sophisticated AI output. Basically an insurance company on chain, right.
01:21:16.094 - 01:21:38.832, Speaker D: These kinds of products and services are literally impossible without AI, without the ZK attestation that the AI model is high integrity when with manipulation, and of course, impossible without the rest of the crypto ecosystem to support the inputs and outputs to that service. So 2024 is going to be a very weird year. In a good way and maybe sometimes.
01:21:38.848 - 01:21:39.544, Speaker C: In a bad way.
01:21:39.624 - 01:21:40.644, Speaker D: We'll find out.
01:21:41.944 - 01:23:00.146, Speaker C: I see you thinking, Casey, I want to interject here for a minute. In terms of, I'm very focused on security coming from a DeFi background, I think that any industry has been handicapped insofar it hasn't figured out security and insurance was instrumental to as far as back as you can think about any technological revolution required more sophisticated risk management. Like, think about explorers, think about you had to have insurance markets to really. And crypto struggles that even though smart contracts are highly predictable, there are bugs, there are edge cases where human may not see it, but crypto is a very adversarial environment, and these exploits get exploited and things break and they're not fun. And so, like, I invested in a company called Test Machine, and they're very much focused on ingesting all the data, like that is happening at Defi and all the hacks that have happened and being predictive and being not only reactive, but the hope is that over time, you actually become preventative. And can, you know, if the exploit is happening across a variety of blocks, which is where most exploits happen, then you can at least contain the damage that is being done. And I think this ties into what you were saying, Casey, is this guardrail.
01:23:00.146 - 01:23:27.386, Speaker C: Like, if you're, if you're going to make recommendations around the health score of a particular loan on Aave, you want to make sure that the AI is not corrupted or it just goes crazy on you and like, you know, I don't know if that's even possible. I'm not technical enough to understand, like, how you would just have the high degree of certainty that the AI is actually going to be working for you, not against you. If that's a thing, that is a thing.
01:23:27.450 - 01:23:31.974, Speaker A: And Daniel's company will solve this for us in the end. In the end.
01:23:32.554 - 01:23:37.374, Speaker D: That's the goal. That's the goal, yeah, because the verification.
01:23:37.474 - 01:23:55.038, Speaker C: Pieces, like I have a hundred not, but like super high degree of certainty that this particular model will prevent liquidation for me, that will fix my health score. Will fix my loan to the point where I will not be liquidated on chain.
01:23:55.206 - 01:24:21.186, Speaker D: I mean, you can also add, and by the way, this is very, very common with, with AI models in production. You literally add guide rails to it. You say, hey, look, if the model produces, for example, a number below this threshold, just ignore it. Let's just keep to this threshold. And these kinds of post processing features we also bring into the ZK circuit. It's part of the commitment we make to the smart contract. And by the way, this is the kind of AI output you're going to be seeing.
01:24:21.186 - 01:24:30.174, Speaker D: And when it's not this kind of AI output, we're not going to accept it. That is the base unit of promise that the ZK proof makes to the program that's on chain.
01:24:30.354 - 01:24:57.712, Speaker A: Yeah. Also just on this point. So, Santiago. Yes. I think this is going to be a topic for, well, here on out until we really reach more confidence around security of models. But I'm going to give a call out to my friend Josh Payne, who was texting me a few days ago and was, like, looking into LLM insurance. And I don't think I've ever heard this before until ham, but this is going to become a thing, I think, where you basically have an insurance policy policy around how your llms behave.
01:24:57.712 - 01:25:12.056, Speaker A: That's one possible, I don't want to say it's definite, but it's possible that that's where the industry goes with security because it's such a big risk and because we're dealing with non determinism for now, you might end up creating an entire new market around that.
01:25:12.240 - 01:25:46.468, Speaker C: So if a company has a chatbot, then you're like a travel agent, and you make a certain recommendation, and all of a sudden it creates a whole problem. You get sued because it wasn't a human behind that, then you might have insurance towards that. And so that increases the willingness for our customers to adopt AI as a product and have certain guarantees that if things go haywire in this early beta phase, then at least you're covered. Yeah, I would be really interested in that, actually. I just love insurance. I think it's one of those things that, especially in crypto.
01:25:46.636 - 01:25:50.444, Speaker A: Yeah, we can talk offline. I like it. An interesting vertical.
01:25:50.944 - 01:26:08.968, Speaker C: Yeah. Yeah. I've been trying to convince insurance companies to insure against crypto risk. It's just still not there, even though I think the opportunity is great. This has been a fascinating discussion. We've been at it for a while. Any last topics that you want to cover that we haven't covered.
01:26:08.968 - 01:26:24.024, Speaker C: I mean, we could probably make a second segment of just going very deep into the different types of kind of verticals that we're seeing. But, yeah, I'm curious if there's anything else that is worth talking about in this pod, at least for now.
01:26:24.404 - 01:26:46.324, Speaker A: I'm actually just curious just to put it back on you, Santiago. Like, you're putting all the spotlight on us, but you also are extremely bright, have been in this industry forever, and I just would love to hear, from your perspective, what's keeping you up at night or what's most motivating to you in this intersection. And you alluded to a little bit of it, but I would just. Yeah, I'd love to hear more.
01:26:48.704 - 01:27:45.712, Speaker C: Yeah, I've just been perhaps, well, a lot of things keep me up at night, but as it relates to AI, I'm very excited. I mean, I'm wearing this sweater, which is effective accelerationism. This is the only thing I got for Christmas. This is the only thing I wanted. My parents asked me, so I was like, yeah, I want this because for me, I just don't think that we should stop this. I think it's incredibly exciting technology, and I do think that there are, like, governments, for better or for worse, I don't think have a bad intention, but crypto at least has always been for me, like that fourth stool, like, if you think about three stools of Montesquieu, of government, like judicial executive, and what's the other one? Legislative. I think crypto is that third, like, that fourth stool that really allows civic participation and oversight and like, to keep democracies in check because you have an alternative, because there's always, that transcends local, man made rules and limitations.
01:27:45.712 - 01:29:08.624, Speaker C: When you have a decentralized network that supersedes that, it's not to say that it blows up the traditional structures, but at least it keeps the system in check, whether it's just having more flexibility to go and rent out a GPU in Japan. If you're in the US, like, that's just, like, abundant. That just creates more efficiency, removes friction from the system. So I'm constantly on the lookout of, like, how can we implement AI, which is delivering a lot of efficiency gains if you're a developer, if you're an artist or whatever? And how can we embed that in crypto, which sort of like a tale of two cities? It's like, crypto is like opening up many different, like, possibilities, but it has always been handicapped by scalability issues and cost, and there's friction there as well, so can AI help us, like transcend? That is something that I'm focused on, but, yeah. Like, again, to what I liked about modules, like, the verifiability piece, I think is going to be incredibly important, like having certainties of like, provenance and where the data is coming from. So I'm more excited about that than just like the next decentralized, like, you know, compute network to like, you know, rent stuff out. It feels more enduring to figure out, like, the hard problem is what modulus type companies trying to fix, and I'm more excited about meeting those people and figuring that out, even though it may take more years.
01:29:08.624 - 01:29:13.424, Speaker C: But I think that's where the real opportunity will be in my mind.
01:29:15.164 - 01:29:29.844, Speaker D: I'm very invested in that being the future, of course, obviously. But I guess since we're on a topic, I'm curious, Casey, what keeps you up at night? I hope it's not agi, but maybe it is.
01:29:31.224 - 01:30:06.546, Speaker A: It's closing the technology. It's actually pretty similar to what Santiago is saying. It's just the, it's like, we have one life, we're here. Let's see what crazy shit we can do and in general have. I think that I personally believe in morality, and I want to do good in this world, and so I feel that this is one of the biggest hurdles we face right now. And so I'm, I am quite scared about regulation. I think there's good intentions and regulation, but I think after reading the AI executive order, I'm nervous.
01:30:06.690 - 01:30:07.434, Speaker D: Scary.
01:30:07.594 - 01:30:15.700, Speaker A: Yeah, I'm definitely nervous. And so that's, I also, I want to give a little bit of homework, if that's okay, Santiago, or not. Homework.
01:30:15.852 - 01:30:17.428, Speaker C: We always give homework in this pod.
01:30:17.476 - 01:30:47.020, Speaker A: Yeah, we do. Okay. So I feel that if I'm a really big believer, there's, I think there's like two ways to learn. Generally, people can read or people can do, and I'm a big doer or builder, and that's how I learn. It's just like playing with things. And so I think if, if anyone listening hasn't done this, there's a few tools in AI, and I'll just do this off the top of my head that if you haven't used, just go take the ten minutes to do it. So everybody's probably done chat bt and yeah, if you haven't, yes.
01:30:47.020 - 01:31:17.964, Speaker A: First up, go to mid journey or go to discord. Get onto mid journey and generate an image. Then go to eleven labs and clone your voice in less than a minute. Okay. Next, go to perplexity and instead of going to Google and ask anything that would require knowledge that isn't within GPT four. And maybe then if you're still interested, you could email me and I have more tools for you to use. But just, even just those four.
01:31:17.964 - 01:31:32.652, Speaker A: Yeah. And that will just like, make everything we're saying more tactical. I think some people are abstract learners, but I think a lot more people are more tactical learners. And so I just want to give those as like, starting off, jumping off points to go into the world.
01:31:32.788 - 01:31:33.924, Speaker D: It's a great idea.
01:31:34.084 - 01:32:15.644, Speaker C: I mean, jet GPT is like, I think from a number of users and go to market standpoint, it's been the startup that has gathered the most amount of, like, active users ever or close to being just how many people downloaded this thing are using it on the daily becomes. Some people have gone as far as saying it will replace Google as your primary search, as your primary way to, you know, find and acquire knowledge, which is. I could see that version happening. Um, I wanted to end this, uh, in maybe a rapid fire, but, uh, I'm debating maybe we should do that, uh, rapid fire. Like a whole set of questions.
01:32:15.764 - 01:32:18.780, Speaker D: Sorry, have the debate or do the rapid fire?
01:32:18.972 - 01:32:58.274, Speaker C: Uh, well, maybe. Maybe not a rapid fire, because that might be challenging. I may be curious in finding something that you guys don't agree with as far as AI and maybe crypto. AI. Yeah, yeah. Between you guys, is there something that in your conversations you have not agreed with? Or maybe not just you, it could be with someone else, maybe within your team, Daniel or Casey, with your network of people that are at this intersection? Maybe you. Because, Casey, I think you sit at an interesting vantage point around, you know, core, like, hardcore AI that don't care about crypto.
01:32:58.274 - 01:33:21.902, Speaker C: And you also know crypto, like, crazy people like me, that you're at that intersection. Like, what are the things that are the most contentious beyond, like, will AI destroy us or not? Because I don't want to get into that discussion. I think no one really knows. But I am curious, as it relates to crypto and AI, what are the things that Casey disagree with, with people the most?
01:33:22.078 - 01:33:29.954, Speaker D: What's your opinion on model marketplaces? Got it.
01:33:32.214 - 01:33:32.998, Speaker C: That looks best.
01:33:33.086 - 01:33:38.674, Speaker A: Daniel? I actually think we're going to be on the same, but it's a little bit. But they don't work today.
01:33:38.814 - 01:33:40.450, Speaker D: You don't. Yeah. Okay.
01:33:40.562 - 01:34:02.034, Speaker A: And no one's talking about it. And it breaks my brain that no one's talking about it. And, like, people think they work, but they really, really don't. And the reason they don't work is because, or at least I'll tell you my thesis. I'm curious. Your thesis? So I'm not going to call any company out, but basically, like, go try to work with the model, the incentivized model. I don't even know what you would call them.
01:34:02.034 - 01:34:44.568, Speaker A: Basically like marketplaces, where you're incentivized to improve the model. And the problem is that they even perform less than open source models, which should be the floor for them. First of all, it should be the floor, and then you should build off of that with token incentives, but they perform worse. And the reason I think I'm coming to is there's two options, and I don't actually know. So maybe, you know, the first is that no one's actually hosting the best open source models. I think that's less likely. What I think is more likely is the incentives or like the reward structure is perverted in a way that it's basically rewarding people to hit benchmarks instead of actual output.
01:34:44.568 - 01:35:03.040, Speaker A: So basically, like someone's getting rewarded for hitting a certain number, and that is not a good proxy for output quality. So what we're seeing is models win, that shouldn't win. So I'm curious. Yeah. And I have actually a potential solution that I haven't told anyone yet, but I would be curious, curious to discuss with you.
01:35:03.192 - 01:35:53.122, Speaker D: Yeah, I'm very curious. I think, unfortunately, to Santiago's premise, I think we're pretty aligned here. I think it's very easy to think of models as these commodities that they're like uniform surface area, just little balls, and you swap them around until you find the best one. But oftentimes, at least in production, these models, the good ones anyways, are tuned very, very carefully. They're super, super specialized, and they basically break the moment you give them anything that they're not supposed to anticipate. This is very different than llms, which are like the first generalist that can take in all kinds of different inputs and kind of still make sense. And so in the context of model marketplaces, the fact that there's all these asymmetries and inconsistencies to their surface area makes them not very composable or very tradable or.
01:35:53.122 - 01:36:08.916, Speaker D: Yeah, exactly. You just like over fit to the index or over fit to the benchmarks, and then turns out the open source model does better anyways. So, yeah, it turns out to be a very high friction marketplace. It doesn't work very well. I'm very curious how you'd solve it, though.
01:36:09.060 - 01:36:12.944, Speaker A: Okay, so this might be out of bounds for this conversation.
01:36:13.564 - 01:36:15.944, Speaker C: That's all good. Okay, I'm listening.
01:36:16.364 - 01:36:47.004, Speaker A: I think that so obviously, vlms vision language models are kind of this combination of, you know, vision and language model working in a better way. They're not mainstream yet, but I think they're going to come out in the next, like two quarters. And I think basically you would use that as like a gan structure to decide instead of using benchmarks at all, because I think benchmarks are too gamifiable. And so you take out the numbers entirely, you put like a few vlms that are fighting against each other, and then I think that would work.
01:36:47.104 - 01:36:59.424, Speaker D: I love that the solution to non performing AI modeling is more AI models. I think that's absolutely correct. Yeah. If there was a solution, it would probably feel something like that.
01:37:00.044 - 01:37:00.852, Speaker A: We'll see.
01:37:00.988 - 01:37:02.052, Speaker D: Yeah, we'll see.
01:37:02.228 - 01:37:09.260, Speaker A: I do think this is an answer, because I do think we're contrarian in thinking this. We are aligned. People would argue with us.
01:37:09.372 - 01:37:11.944, Speaker D: Yes. Most people love this idea.
01:37:12.744 - 01:37:33.704, Speaker C: Like, like. And so I understand it is, and I'm relating it to crypto because a lot of it is through, like, incentivizing people to do stuff. So you're saying there is a whole set of companies that are incentivizing people to improve the model and they're setting. It's a problem that you're identifying is it's the benchmarks that are easily gamifiable. And you see this all the time in crypto too, by the way.
01:37:33.784 - 01:37:34.496, Speaker D: Yeah.
01:37:34.680 - 01:38:09.558, Speaker C: And that doesn't. It is sub performant to just a pure open source model. Yes. Yeah. I think this is a good place as any to end it. I want to just impart something. To me, one of the more interesting things I've heard in this discussion was something you said, casey, which is, in this journey of AI, the things that researchers thought would be easy have turned out to be the hardest, and the things that researchers thought would be hard to solve have become far easier.
01:38:09.686 - 01:38:10.014, Speaker A: Yes.
01:38:10.054 - 01:38:13.954, Speaker C: And to me that's just mind boggling because it is very humbling.
01:38:14.494 - 01:38:14.942, Speaker A: Yes.
01:38:14.998 - 01:38:37.074, Speaker C: I think this journey of AI has been very humbling to understand what intelligence is and is not. And, yeah, it's just like. It's pretty crazy. I don't. It's just one of those we've talked about at length about how little we understand how the brain works, and this is why it's just a fascinating discussion to have. And so, yeah, I really like that.
01:38:37.194 - 01:38:41.058, Speaker D: Well, that's the appeal of good technology, I think.
01:38:41.106 - 01:38:41.434, Speaker A: Right.
01:38:41.514 - 01:39:02.600, Speaker D: You just be repeatedly humbled in recognizing how little of the world we actually have appropriately modeled. But I think it's Santiago, you said the only way through is just continuing to invest in this stuff and solve the hard problems. A la your sweatshirt. Yeah.
01:39:02.712 - 01:39:50.964, Speaker C: I think it's one of those areas where I feel underexposed. I've been looking at funds because I'm not going to do it myself, but I also lean on Casey a ton to find these opportunities and really parse through what is bullshit and what is not. To be fair, a lot of stuff that I thought was bullshit and crypto ended up being not bullshit and a lot of things that I thought were very real. That's just the nature of, I think, cambrian explosion of interest in things. But we'll see. Casey and Daniel, it's fantastic to host you. I hope I didn't interject too much to disrupt the flow of conversation, but we'll love to have you on to maybe get an update on Modulus and also Casey and all that stuff that you're seeing from where you sit, which I think is hugely fascinating.
01:39:51.884 - 01:39:53.300, Speaker A: Thank you for having us.
01:39:53.452 - 01:39:55.424, Speaker D: Thank you so much. Pleasure.
01:39:55.804 - 01:40:01.092, Speaker C: We'll call this empire crypto AI part one. There may be ten parts, so holiday.
01:40:01.148 - 01:40:02.544, Speaker A: Edition as a wrong.
01:40:02.844 - 01:40:04.236, Speaker C: The holiday edition.
01:40:04.380 - 01:40:04.684, Speaker D: Yes.
01:40:04.724 - 01:40:10.664, Speaker C: I like that. All right, everyone, thanks so much for listening. And Casey and Daniel, thanks so much for coming on. I really enjoyed this conversation.
01:40:11.084 - 01:40:12.452, Speaker D: Thank you. Thank you.
01:40:12.628 - 01:40:13.784, Speaker A: Bye, Santiago.
01:40:14.484 - 01:40:15.044, Speaker C: Hey, everyone.
01:40:15.124 - 01:40:38.020, Speaker B: Thank you so much for watching today's episode. Really hope you enjoyed it. We wanted to take a second to just remind you about our upcoming digital asset summit in London, March 18 to 20th. Santi and I got your back. Seats are limited, and we hooked you up with a 20% off discount code. It is Empire 20. If you heard it earlier in the podcast, there's a little competition running at blockworks to see who can drive the most number of tickets.
01:40:38.020 - 01:40:42.956, Speaker B: So when you register for the digital asset summit, make sure you use our code. Empire 20.
01:40:43.020 - 01:40:49.044, Speaker C: See you in the next London video.

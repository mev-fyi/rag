00:00:00.360 - 00:00:15.737, Speaker A: And I just think most people still aren't ready for the fact that we probably get AGI within the decade. If you had enough of a supply side using this thing, you'd literally have an API key to the entire Internet. Right. Just being scraped for you at all times and fed into a model there.
00:00:15.761 - 00:00:38.735, Speaker B: Does hit a point like the wealth inequality gap can only get so wide before you have just civil unrest. Right. I think you just need to be willing to be like wrong and be. I think if you like being willing to be wrong in public is such a powerful trait to have. Like most people just cannot fathom being wrong in public.
00:00:39.075 - 00:01:36.513, Speaker A: Nothing set on the hive mind is a recommendation to buy or sell securities or tokens. This podcast is strictly for informational purposes only and any views expressed by anyone on the show are solely our own opinions, not financial advice. Hi everyone and welcome to another episode of the Hive Mind podcast. The goal of the podcast is to provide an inside look into what we like to call the Delphi Hive Mind, bringing together some of our brightest minds from each of the divisions to share insights, alpha and shitposts. Today with us, we have the regular crew, Ceteris, Duncan and Jan. Jan has just returned from the all in Summit, so we're very curious to hear about how that was. I've only watched like the Elon talk, which I thought was pretty dope, but I, yeah, I'd love to hear about what it was like Peter Thiel and.
00:01:36.513 - 00:01:37.857, Speaker A: And all of that.
00:01:38.041 - 00:02:31.565, Speaker C: Yeah, no, it's a really strong collection of speakers. I'd say it's the, the best collection of speakers in a conference I've ever been to. Just because the kind of like the pedigree. So yeah, you had Elon, J.D. vance, Sergey Brin, Peter Thiel, Travis Kanick, Megan Kelly, Mark Benioff and then, then you know, you see that was from the founder side. And you also had like a senator from Arizona, Kristen Kirsten Sinema, who's kind of a Democrat who went independent. You had two kind of foremost experts on geopolitics, John Mersheimer and Jeff Sacks, who were professors, wrote a bunch of stuff and one was kind of the advisor to Yeltsin and someone else, and I forget who else, but no really interesting perspectives on kind of geopolitics.
00:02:31.565 - 00:02:58.115, Speaker C: You had the leading founders in the VTOL space, just like vertical takeoff and landing. So in terms of flight, basically planes that have propellers attached to them. So the kind of, you know, helicopters, but they have their winged helicopters so that you can get kind of the benefits of vertical takeoff and landing, but much better travel speed and energy efficiency.
00:02:58.655 - 00:03:13.269, Speaker A: And did you get to like sit with the, like, I know there's the dinners and the parties and stuff. Did you like dress up for all the parties and then did you get to like. Of course hang out with, did you get to hang out with like all these, the speakers at different points?
00:03:13.317 - 00:03:51.265, Speaker C: No. So, so I, I think there were some areas they did really well and then some others they, they left their. There's room for improvement. So the last year they basically did a high and inexpensive tier and a cheap tier, but the distinction was pretty underwhelming from what I gathered. Chatting with people this time they just did one expensive tier. I think they might have invited slightly too many people. It wasn't, it wasn't stuffed by any means, but I think, you know, for the price tag you kind of assumed a certain level of intimacy and you didn't necessarily get that.
00:03:51.265 - 00:04:25.961, Speaker C: I think, you know, they themselves were around, but not really too much. And so that just led to them getting completely mobbed when they were around, which made it kind of difficult to have some organic convos. Whereas I think if they were more available, people that were going to mob would get their fix and then everyone else can kind of chat with them more casually. But. And then the event itself was cool. It happened to be during this blistering heat wave in la. So that kind of added an interesting dimension, but wasn't too big of a deal.
00:04:25.961 - 00:04:34.295, Speaker C: It was half indoors, half outdoors over the course of three days. But yeah, no, the speakers really, really interesting.
00:04:34.635 - 00:04:39.615, Speaker A: What was your favorite talk out of curiosity or like your favorite speaker?
00:04:39.955 - 00:05:22.185, Speaker C: Yeah, so I guess it depends on what topic. So I think one of the cooler ones from a builder side was this guy, Jake Lucerarian. Basically Gecko Robotics was combining. So like AI was naturally a big theme, but there was also a big kind of robotics tilt as well. And so what he's basically building is a way for you to use drones and robots to track wear and tear on major infrastructure all around the world. So from bridges to power plants to all of this stuff, right now it's done very manually in a very analog way. And there's no way to good way to kind of monitor and actually track this stuff.
00:05:22.185 - 00:05:42.039, Speaker C: And so there's a lot like the amount of money that gets spent on maintenance. For example, the military is like 400 billion a year. That's just pure maintenance. And then there's pockets everywhere. So I thought that was a really cool zero to one project that was great. To see. And they brought a lot of these robots in and they were showing them, which is awesome.
00:05:42.127 - 00:06:04.035, Speaker A: Yeah, there's a lot of people working on military tech and autonomous drones. I've seen a few crypto founders actually pivot to that. Like a few really smart crypto founders that I spoke to recently. I won't name names in case people think they're still working on the project they're supposed to be working on. But yeah, they're, they're kind of pivoting to that. Yeah, it's pretty cool.
00:06:04.695 - 00:06:36.141, Speaker C: Yeah, no, the, the, the, it made a lot of sense and, and I think that the cost savings and, and, and prevention because also for bridges it's, you know, collapsing. So there's a lot of lives to be saved and a lot of safety improvements on that front. Because right now it's, it's. They. He showed us how they're basically tracked now. And it's kind of a guy hanging off a cable basically tapping this metal and listening to different sounds and trying to identify, you know, issues with the integrity that way. I thought Peter Thiel was really good.
00:06:36.141 - 00:07:13.965, Speaker C: Megyn Kelly was, was really funny. Marc Benioff was really funny. But yeah, broadly it was, it was great conference and yeah, I mean it was good to, to see the besties as well, but no, yeah, really enjoyed it. It was, I think it was a nice change of pace to go to a non crypto conference. I don't remember the last time I've done that, so that was always fun. Crypto came up a couple times more so from speakers, I think, you know, J.D. vance actually brought it up a couple times.
00:07:13.965 - 00:07:23.913, Speaker C: I'm trying to remember who else brought it up, but it, it, you know, it came up, but it wasn't really a primary topic, it seemed. Yeah.
00:07:23.969 - 00:07:29.445, Speaker A: How was it being the crypto guy at these, at these like, dinner tables and stuff?
00:07:30.225 - 00:08:03.321, Speaker C: It was fine. I wasn't really super loud about it. I kind of wanted to more so just be a sponge rather than be the focal point. So it certainly came up. But I think, you know, it takes a certain amount of existing interest in crypto for the conversation to be lengthy versus kind of just like, oh, what do you do? And then you talk about it and then there's, you know, some interest. But there weren't really, you know, these like hour long convos on crypto and what's happening. I think it's just kind of a function of.
00:08:03.321 - 00:08:06.893, Speaker C: Yeah, the interest in the space from people outside it right now.
00:08:07.029 - 00:08:15.045, Speaker D: Was there a lot of us talk on the election, obviously, like J.D. vance there and then, isn't Megan Kelly's like, pretty. Pretty conservative? Right? Or.
00:08:15.165 - 00:08:37.035, Speaker C: Yeah, no, there was definitely talk about the election. Just, you know, it varied. Some people were looking to chat about it more, others less. So it was definitely a topic. And then the John Mearsheimer and Jeff Sachs convo, the two professors, was somewhat about the election, but it was. It was really cool. Is just talking about they.
00:08:37.035 - 00:08:37.819, Speaker C: They had.
00:08:37.987 - 00:08:38.443, Speaker A: They've.
00:08:38.499 - 00:09:28.675, Speaker C: They've known each other for a while and. And they're both like, you know, preeminent or prominent minds in that. In that space, and they had varying views. Just basically, how can the US Coexist with China being a world superpower? And, and. And kind of what is the trajectory for, you know, how the US foreign policy kind of operates and what the motivations are and what the implications are for kind of other players in the space? Can you have two global powers coexist, or does the US always need to maintain itself as the, like, you know, the foremost superpower and thus creating conflicts to kind of ensure that that stays as is and basically just kind of deciphering the motivations of US Foreign policy.
00:09:29.335 - 00:09:44.223, Speaker A: Nice. Yeah, I studied Miriam at uni. He's like a realist guy. Just thinks everyone's out for themselves, basically. Yeah. Should be fun. Was there a lot of people chatting about AI? I actually was trying to.
00:09:44.223 - 00:09:48.755, Speaker A: I know Elon had some cool stuff on AI.
00:09:49.095 - 00:10:00.959, Speaker C: Yeah. So they kind of talked about, you know, aside from the. Sergey Brin was talking about AI for a while. That was most of his talk.
00:10:01.127 - 00:10:21.301, Speaker A: Yeah, I saw that he's like, back in the office now and stuff. It's pretty cool. Like, it sounds like he was sort of just retired, kitesurfing for like, 10 years. I guess it's pretty tiring. Just like, you know, like, raping people for ads and printing money. You can just get tired of that after a while. But it sounds like AI is, like, rekindled his.
00:10:21.301 - 00:10:43.361, Speaker A: His kind of flame. Like. Yeah, pretty cool. Because obviously they were. They launched the Transformers paper. Like, I did a pod with Ilya yesterday. He was saying that they basically had, like, pretty much chatbots running internally, like, pretty early on, and just never productized it because it just didn't seem like a big enough revenue opportunity for them.
00:10:43.361 - 00:11:29.545, Speaker A: And it also sort of cannibalized the core search business, which makes sense. But yeah, I wanted to chat a little bit about AI on this because, I don't know, I think it's like the most important thing happening in investment and in the World, like in markets and in the world and we haven't really talked about it on the pod. So I mean maybe I can set it up and then I'd love to get you guys thoughts on it. So for me I think been it's as excited I've been about a tech trend since kind of the bitcoin white paper been going down the rabbit hole and really my like my red pill moment. Red pill, black pill. I almost forget what color pill is the one that gets you down the rabbit hole.
00:11:31.285 - 00:11:36.105, Speaker B: Well, red pill, black pill is like red pill. Yeah, like.
00:11:37.885 - 00:11:39.821, Speaker C: Blue pill. It was red and blue pill.
00:11:39.893 - 00:11:43.541, Speaker B: It's red and blue and then white and black are like different. We won't get into.
00:11:43.573 - 00:12:27.511, Speaker A: Okay, well red pill. I got red pilled by the Ash Brenner situational awareness paper. Like and then yeah, that's kind of what really tilted me over the edge. And I just think most people still aren't ready for the fact that we probably get AGI within the decade. Like just based on the relationship between effective compute and the capabilities of AI and how much money is being plowed into compute. Like there's people talking about, you know, Sequoia did that paper on the revenue hole and stuff. But I don't think that even if there is a revenue hole, I don't think people are going to stop spending just because all the big tech companies see it as existential to their businesses, which it probably is.
00:12:27.511 - 00:13:04.083, Speaker A: So they're going to keep plowing money into this. You know, Nvidia is on track. Like Nvidia revenue is probably like the best proxy for AI spending. They're on track for like over 100 billion this year, which is more than 2x last year. There's like 83 billion invested in AI startups since the beginning of 2023. And so I just think like spending on compute is going to increase, spending on talent is going to increase and you end up like I think the current AI sort of already pretty close to an artificial general intelligence. Like we just sort of passed the Turing test and no one, no one really cares.
00:13:04.083 - 00:13:59.519, Speaker A: Like you know, and once you add agenda capabilities to it, like ability to use the Internet to make payments, to join chats, to join group calls, to get larger context windows on your company and stuff. I just think it like kind of changes everything. And then there's obviously like super intelligence on top and the more AI researchers I talk to, like they're all pretty bullish on super intelligence, like which is the idea that once you get AGI it can automate the job of an AI researcher. So you end up with self improving AIs. Like AI is improving AIs. And you go from basically what there's like maybe 1500 researchers at the top labs right now. You could go to like 100 million researchers that are like super powered, working 24 hours a day with, you know, with like the ability to run experiments, like keep millions of lines of code in their head as context and stuff like this.
00:13:59.519 - 00:14:39.721, Speaker A: And then that's when stuff could get pretty crazy. And yeah, most of the AI researchers I talk to say that AI is already super useful for research. And there was that paper that came out yesterday that kind of corroborated this. And so then you have that and then you stack like robots on top, like humanoid robots, you know, which Tesla's working on and figure and a bunch of others. And I feel like you get to a world where the, the cost of labor just collapses to like asymptotes to, to just near zero. Right? The cost of inference, basically, like the cost of cognitive labor goes to like the cost of inference, which is just like power. And, and the cost of physical labor will just like asymptote to raw materials.
00:14:39.721 - 00:14:41.313, Speaker A: To the, to the cost of raw materials.
00:14:41.409 - 00:14:58.797, Speaker B: Just on that point, I think in Pondering's report, I think he was saying it's like 50,000x of like a human brain. The amount of energy that you can, like AI minds, you can kind of run the type of energy that empowers one human brain today. So just like. Yeah, anyways, go on.
00:14:58.901 - 00:14:59.453, Speaker D: Wait, what?
00:14:59.509 - 00:15:00.133, Speaker A: Yeah, it's crazy.
00:15:00.189 - 00:15:02.237, Speaker D: 50,000. Say that again.
00:15:02.341 - 00:15:22.695, Speaker B: The amount of kilowatt, whatever energy measurement he was using to power one human brain, you can power like 50,000 AI agents in, you know, some years from now. And so think about that. These things don't get tired, they don't need coffee, they don't need food, they don't sleep. Right. It's like.
00:15:22.775 - 00:15:41.351, Speaker A: Yeah. And it's kind of like it's weird what happens to the world. In some ways it's sort of like Marx's nightmare. Like I feel like labor just gets destroyed. Like there kind of is no labor. And obviously that's what people say about every technological revolution. But I do think this time is, is different.
00:15:41.351 - 00:16:35.115, Speaker A: Like you, you basically have to compete with an AI that, with a cost of inference, right? Like, you know, whatever job you're doing, accounting, legal, whatever, that's like your new competitor. I see the impact is like roughly the same as you take like billions of highly skilled, 24 hour a day working immigrants into a random country, right? Like, what happens to that, to that country? It's like you'd see it's very bullish for capital, right? Like, I think costs go way down. It's like highly deflationary. I think the cost of everything will just go way down. But I feel like labor, there is this weird transition where labor just gets like, if you don't own capital and you're just selling your time for money, you kind of just get screwed. And I don't know. What do you guys think? I'm sure you guys thought about this.
00:16:35.155 - 00:17:23.515, Speaker B: I agree with that. I think that's also why there's such a rush to invest in AI stuff. Because everyone is scared that you need capital. This will be the defense, I think. Then you get into these other topics, like ubi. It seems like AI is just going to keep making the wealth inequality gap even worse. And so there does hit a point like the wealth inequality gap can only get so wide before you have just civil unrest, right? And so I think like a lot of these policies that governments and like politicians are introducing these days, you're going to see them more and more.
00:17:23.515 - 00:17:42.984, Speaker B: And if one country has a wealth tax, sure, you can just move. But if every country has a wealth tax, you don't really have that arb anymore. So I don't know, like I really. It is, I don't know, like, what are people going to be doing?
00:17:43.104 - 00:17:55.495, Speaker C: Well, there's no world where every country has a wealth tax because the. As more countries have it, it becomes really attractive to not have it because all the rich and talented people will come to you. So there is game theory there to.
00:17:56.115 - 00:18:40.271, Speaker A: I've also been thinking about, like what jobs, what jobs remain. And I basically think like there's one class of jobs which always remain, which are the ones where you value just like humanness over efficiency, right? Like, no matter how efficient and cheap an AI is, you still want a human. Like, you still might want an artisan piece, like a desk made by a human or an art piece made by a human. Like for social workers and psychologists, you'll probably still want to speak to an actual human and not an AI sports and stuff. You're still going to want to watch humans play them rather than, rather than robots and AIs. Although there's a jiu jitsu robot now, which I'm pretty scary to fight, to be honest. And then the second class is just, I think like coordinators.
00:18:40.271 - 00:18:58.653, Speaker A: Like what AIs don't have is like my Friend puts it like, taste. Like they can't make like subjective decisions because they, they like fundamentally aren't subjects. Right? They're. They're not. Like there's some decisions that are made for humans behalf. Like, I think capital allocation is. Is one of these where like should.
00:18:58.653 - 00:19:37.515, Speaker A: Should Zuck invest in or should Facebook or Meta invest in like AI or. Or VR? Like how can an AI make that decision? We're just not going to like trust it with it. Right? Like, it might produce a report that helps in assessing it, but it's not going to make the decision itself. I think like capital allocation and then just like coordinator roles that are going to, you know, keep the goals in mind, like to. And then coordinate a bunch of AIs to get some job done. I think that job also remains like people who are just really good at leveraging and coordinating AIs, but everything else, like all the actual specific technical jobs, you know, are kind of screwed, I think.
00:19:37.635 - 00:20:14.825, Speaker B: I think, yeah, definitely. Like creative type jobs, leadership type jobs, decision making type jobs probably. Okay. But yeah, so basically AI right now I forget if it was one of Rinko's reports or one of Pondering's reports, but it's not good at like arithmetic and it's not good at reasoning, but it's good at everything else. Right. And so the arithmetic one seems like solvable, but I'm not an expert on that.
00:20:15.205 - 00:20:17.269, Speaker A: Yeah, it's already pretty good at arithmetic. I think that's.
00:20:17.357 - 00:20:24.685, Speaker B: No, no, it gets. No, no, no. It's. It's bad at it because it's like not good at doing math. It's like one of the.
00:20:24.725 - 00:20:30.397, Speaker A: I think the latest Claude is pretty good. Are you sure that applies to like the latest models? Because I thought that was like.
00:20:30.421 - 00:20:32.805, Speaker B: I don't know, this is like too much.
00:20:32.845 - 00:20:39.229, Speaker D: I feel like that's solvable. If you like give them a calculator versus the LLM trying to do.
00:20:39.357 - 00:21:00.075, Speaker B: No, because the way LLMs work is like, it'll. It'll just uses a bunch of like basically searches and then just kind of like starts randomizing different words in front based on frequency of how these like, words kind of fit together through all the data sets they have. And doing math is a bit different than that. It's not like constructing sentences.
00:21:00.775 - 00:21:25.795, Speaker D: So how quickly do you, Jose, do you think that jobs will start to be replaced? Like, because right now I feel like. When was it? December of last year. So almost a year ago we kind of got like the chat GPT. Like, holy shit, this is real moment, right? And Then from there, like, so it's been close to a year. How long do you think it takes for more?
00:21:26.215 - 00:22:10.247, Speaker A: I think we're already seeing a bunch of examples of it. Like the customer service company, I forget the name now they're just like laid off or like was it Klarna laid off? Their entire like customer service team just automated it with AI. Like that's a pretty clear one. There's been like there was that tweet the other day about the company that replaced all its SaaS services with AI. I think you're kind of seeing it in big tech where they had like pretty big layoffs, but like the return on invested capital has stayed pretty much the same or improved. And I think that's just going to keep, keep happening. I think we could have like just structurally higher unemployment going forward, you know, just basically deflation going forward.
00:22:10.247 - 00:22:21.111, Speaker A: But obviously I'm aware that people said this about every single other tech revolution, you know, and somehow like we almost find things for humans to do. It just. Yeah, it does seem different to me.
00:22:21.223 - 00:22:49.025, Speaker C: Well, so the question, right, it's because, yeah, you have the industrial revolution, people no longer working in factories or doing something else. And is it something where the next generation is going to be well equipped for new jobs or will the immediately replaced population be able to, you know, find a value add place for themselves in society where they can generate a wage?
00:22:49.525 - 00:23:24.231, Speaker D: Yeah, I feel like it's like a velocity thing, like how quickly it changes. That's like where the deflationary shit gets scary. It's like so Chad, GPT came out. I just looked at, it's not a year ago, two years ago. So let's say this really ramps up in the next three, four years. Then like a bunch of people lose their job, then there's massive deflation, deficits like get even worse and then kind of that's where like the economy could really get screwed. But I feel like over time people will find new jobs and it'll just be different things and more like creative or human like things.
00:23:24.231 - 00:23:24.995, Speaker D: But.
00:23:26.895 - 00:23:41.135, Speaker C: I don't think people are naturally that creative. I think there are some people that are very creative, but I don't think this, this notion that people who are laid off are now just going to be able to go do creative things like that. I just don't see that.
00:23:41.215 - 00:23:43.919, Speaker D: Yeah, well, what's AI bad at or won't be able to do?
00:23:43.967 - 00:24:16.995, Speaker C: Because I mean if you think about who gets laid off, it's going to be, it's a combination of those who are, are Underperforming and those who aren't really capable of enhancing their performance with AI. Right. Because that, that's kind of going to be who, who, who is a 10x employee. It changes from what you can do directly versus how good you are at leveraging these tools to make yourself more productive. And so you know, like, so those that get laid off, like I don't know, I'm, I don't, I'm not as optimistic on them being able to go do something.
00:24:17.075 - 00:24:21.473, Speaker A: There's just a lot of people, there's a lot of humans. That's the worry.
00:24:21.529 - 00:24:23.369, Speaker D: Right, so what are you gonna ubi.
00:24:23.537 - 00:24:31.593, Speaker C: Ubi but like UBI there and they're not gonna go do creative things. I think they're just gonna go play video games or like, I think you.
00:24:31.609 - 00:24:59.449, Speaker A: Need to try and try and like reskill people though. Like have some UBI where they have to go and like learn how to use AI. Learn. Because it's just gonna be a tough century for a lot of people if you're not going to like learn to use AI. But even then like you don't need, I don't know, I think the main thing I can't do is have judgment. Like we won't trust it to make important judgments for the foreseeable future. Like judgment, taste, intuition, whatever you want to call it.
00:24:59.449 - 00:25:26.383, Speaker A: Everything from product to investment to these things like AI is going to be inputs, they're going to be part of the process, but there's going to be a human like coordinating them and making the final call I think on most things. But those humans are like, that's the top like echelon of each job that you want that has the high judgment. Right. And then there's a bunch of like just, just sort of like AIs under them that can replace most of the hard work that's being done. And those people, I, yeah, I struggled.
00:25:26.399 - 00:26:04.513, Speaker C: To see what, what, how you did you see Sam's that the results of that study that came out on UBI too where it just kind of what you'd expect, you know. Basically they did this two year analysis where they gave some people, I forget the exact numbers but it was like $1,000 extra. People that were earning between 30 and 40k, they gave some of them $1,000 post tax a month and then others like 50 bucks or something. And those that got the thousand ended up having much lower salaries after a couple more years than those that had the 50. And then you know, you kind of.
00:26:04.569 - 00:26:08.593, Speaker A: Their happiness reverted to baseline after reverted.
00:26:08.609 - 00:26:35.465, Speaker C: To Baseline and their economics were kind of what you'd expect. Where initially there was some additional money in their bank account, but then it all kind of went towards, you know, discretionary spend and they were no better off. But yeah, like they mentioned, unhappier. But I think the biggest takeaway was the motivation was killed. Right. Like those that got less money ended up working harder in their jobs and had a higher salary than those that got the initial bump up front.
00:26:37.025 - 00:26:39.245, Speaker D: Where was that study from? Or when.
00:26:41.745 - 00:26:46.137, Speaker C: Yeah, if you Google it, it'll come up. It was like the biggest UBI study.
00:26:46.321 - 00:26:47.017, Speaker D: Cool.
00:26:47.161 - 00:27:18.783, Speaker A: Yeah. I wonder if we want to move to how you're thinking about investing, how people think about investing in AI. Because the way I'm thinking about it is there's sort of two possible worlds in my mind. And one of them, open source AI keeps up with closed source. And like we have models that are within at least like a generation. Like open source models are at least within one generation of like the best closed source models. And then we have a world where that doesn't happen.
00:27:18.783 - 00:27:35.789, Speaker A: And closed source models just race ahead and you have these like vertically integrated big tech companies that literally just own the entire stack and have like a level of, like a level of domination over just. Just because. Because everyone's going to be using these things. Right.
00:27:35.837 - 00:28:09.575, Speaker B: I think, you know what, I think a counterpoint to like, that is just the natural incentive that crypto is so good at, that if you're like a cracked founder, you can actually like launch some project with a token and sure, you can create something and then go sell it to like metagoogle, make a bunch of money and then chill, but you actually still have more upside. I think if you create some protocol that ends up doing well. I think that's the one thing is that the incentives are still there in crypto.
00:28:11.395 - 00:28:53.685, Speaker A: If you don't have open source models, if the closed source models are just so much better, it's just hard to create a compelling product because no one's going to have the money to train these models. The next generation of models are going to cost like 50 bill. You know, like that's what I think. Zuckerberg said he's investing in the next generation of Llama and that's going to keep going up. Like people are projecting this hits like 1 trillion, right by 2030 or whatever the people are going to be spending on compute. And you're going to have to build data centers next to power plants, you know, like with the advanced cooling systems, like it's Going to be incredibly centralizing force. Unless of course, the unlikely hero Zuckerberg continues to open source Llama.
00:28:53.685 - 00:29:30.305, Speaker A: I think that's like a very different world. But yeah, if not, I just feel like, yeah, big tech, because they're all either themselves or through partnerships, vertically integrated. Right. Other than the chip layer. But all of them are working on chips. Like Google has their tpu, Amazon has Trainium, Microsoft has their own thing. And then, you know, chips, they own the data centers with their cloud businesses, they own the model layer either through like part of owning part of OpenAI or Amazon owns part of Claude, or Google has their own with Gemini and then they own like the application layer and then all of them have proprietary data as well to train this stuff on.
00:29:30.645 - 00:29:35.385, Speaker D: So how are you investing in it or thinking about like what layer to invest in?
00:29:36.485 - 00:29:55.185, Speaker A: Yeah, I mean, I bought, I've been buying some big tech just for the dystopian world. I can be one of the capitalists that at least benefits from, from the dystopia. Although I do think the government kind of steps in in that world and like breaks these things up. Like, I just don't see how like.
00:29:55.305 - 00:30:17.761, Speaker D: These like entities become like more powerful than governments. I feel like in those worlds they already are starting to become like, with like lobbying and influence. Like, so maybe they have broken up, but it's going to be weird because they're going to become like more powerful than the government itself, especially these global corporations.
00:30:17.793 - 00:30:26.849, Speaker A: Especially with superintelligence. With superintelligence, it's just hard to even predict what happens. Yeah, that's a black hole for me.
00:30:26.937 - 00:30:48.025, Speaker D: Well, the energy one's interesting because it's going to use such an insane amount of energy. Right. So investing around that, I think there's like Amazon bought like some nuclear plant to like power one of their data centers. I think like nuclear could make a comeback maybe if like you need like an insane amount of energy as they're saying.
00:30:49.325 - 00:31:22.079, Speaker A: Yeah, yeah. I just don't know how to kind of think about investing in energy. Yeah, I did big tech and then I do think like in the open source world, which I think is right now the base case, because Zuck's made a pretty big public commitment to open source. There's a lot of startup opportunities and I think you actually end up with like millions of models because, like people, it's like with anything else, there's a cost, performance trade off. Right. Like the AGI, the big AGI models will be the best for everything. But for most use cases, you just want A slither of that.
00:31:22.079 - 00:31:55.491, Speaker A: Right. Whether it's image recognition or booking flights or writing essays or whatever, there's going to be specialized models for those that are much smaller and much cheaper and you're going to want to pay for the maximum. You're going to want to like get the cheapest like for a given performance, the cheapest that you can get it. Right. And so that's like I think a millions of models world with like aggregation layers and like some verticalized models and stuff like that. And I think there's a lot of startup opportunities there and also crypto AI opportunities too. So I think that's interesting.
00:31:55.491 - 00:32:03.387, Speaker A: I mean you could definitely go like energy and commodities and stuff like that. I just don't know how to invest in that stuff really. What have you guys been doing or have you not?
00:32:03.451 - 00:32:29.095, Speaker B: I don't have any, do I? Let me think. No, I don't have any AI crypto bags because it's just hard for me to like wrap. Actually that's not true. I have some stuff, private stuff, but like liquid personally, directly. It's just like hard for me to wrap my head around the valuations. I don't know.
00:32:30.995 - 00:32:38.219, Speaker C: Yeah, it seems like the easiest or the safest bet has been Nvidia for sure and will kind of continue to be. So.
00:32:38.387 - 00:33:02.725, Speaker A: Yeah, it's just like hardware is so tough to build a moat around, especially when everyone else is looking at your margin as their opportunity. Right. You can literally cut costs by 50% by using your own chips. Right. Like just Nvidia's margin seems like some of these, some of these other companies are going to get this stuff to work. But I agree that's been the play so far.
00:33:02.845 - 00:33:30.095, Speaker B: I did see people are trying to get cute like half a year to a year ago about picking intel over Nvidia and then intel just totally shit the bat and it's still top dog. So yeah, for me it's an area. I own Nvidia through the index funds. Yeah, I don't have direct AI stuff. I'm like personally buying.
00:33:30.555 - 00:34:25.065, Speaker D: Yeah, I feel like the nuclear energy likes uranium. Yeah. Camco just seems like a lot of hedge like hedging your bets for a lot of this stuff like green energy. Like this is how if you want just like more abundant energy that's like things are going to scale and you've kind of had this like artificial like suppression of nuclear energy being adopted because of like I don't know, maybe the governments just don't want like anyone to be able to make a nuke because I think it's like pretty easy to like reverse engineer the like reactor tech into a nuclear bomb. So I think that has been a, like, that could have been a reason or people are just kind of scared of it. But definitely nuclear energy seems like a good hedge.
00:34:25.445 - 00:35:28.685, Speaker A: The other investment opportunities I think are kind of cool are the secondaries on like the Xais of this world. And like chat even, even OpenAI like XAI OpenAI Perplexity because I mean Perplexity I think is a pretty interesting one because they're sort of like just building an answer engine on top of all the existing models. So if you pay for Pro, you can literally choose whichever model you want to use. You can add like your context there. So like I'm a vc, I want like science backed stuff, whatever it is your context and it just gives you the best answer. And then they have their own model that has like references and sources for everything, which is super useful. And I think something like that because I'm already using this like way more than Google, right? Like I don't know about how, I'm curious like about you guys, how much you use like the chatbots versus Google, but I'm using them way more than Google and like that in itself is like what, what's, what's Google's search revenue? It's like over 200 billion a year, right?
00:35:29.185 - 00:35:42.235, Speaker B: Yeah, I've been bad to migrate. To be totally honest. I still use search engine a lot. I don't know why. I did get, I did get AI to like plan me a seven day trip though, which was kind of cool.
00:35:44.095 - 00:35:45.071, Speaker C: That's pretty dope.
00:35:45.143 - 00:36:06.361, Speaker B: And so now I have like ideas of that. I just need to use it more. I need to get in the habit of using it more because I know it'll make me a lot better at everything I do for whatever reason. It's hard to break like old habits as you get older I guess. But yeah, I still haven't totally worked it into the flow.
00:36:06.553 - 00:36:31.953, Speaker C: I use a decent amount for questions. I don't like any. Most stuff I Google, I would just look this up aside the random stuff that I know is very specific to a certain site, I'll Google because I want to land on that site. But when I'm asking a question I would just use the app. I haven't used it for planning or these really extensive tasks though. It's been more just a lot of.
00:36:31.969 - 00:37:03.225, Speaker A: Q and A. I use it for everything. And like if you just take the time of search, which I think like this Thing clearly goes after search. It's like a. Yeah, I think it's like a 200 billion a year revenue business for Google. And so I don't know, I just feel like these things, like I think Xai raised at 24 billion or something like that, which is basically betting on Elon and AI. And then I think some of these other secondaries are pretty interesting just given the fact that.
00:37:03.225 - 00:37:08.985, Speaker A: Yeah, I don't know, I think most people are bullish, but they still kind of aren't bullish enough.
00:37:09.565 - 00:37:19.509, Speaker C: On AI, he was saying, Elon was actually saying that he thinks humanoids are going to be a bigger, the biggest opportunity in the history of humanity. More so than AI.
00:37:19.597 - 00:37:25.865, Speaker D: I feel like he's kind of talking his book, checking his batteries for sure. Yeah. Doesn't Tesla have the humanoid?
00:37:26.215 - 00:37:27.951, Speaker C: Yeah, but they're the only ones.
00:37:28.023 - 00:37:32.663, Speaker D: But you put like AI in that, right? And then it's like, damn.
00:37:32.719 - 00:37:47.047, Speaker A: Well, he said he can get, he thinks within three cycles, which he estimated at like six years, three production cycles, he can get humanoid robots to cost less than a small car. So like 20 grand for your personal humanoid robot slave slash friend.
00:37:47.231 - 00:37:49.927, Speaker D: Like, and what it'll like do the dishes for you.
00:37:50.111 - 00:37:52.055, Speaker B: All I'm saying is like, you don't want to be an early adopter.
00:37:52.095 - 00:37:53.475, Speaker A: Whatever you want, Duncan.
00:37:54.255 - 00:37:57.145, Speaker B: That thing's definitely commercial, murdering you in your sleep.
00:37:58.165 - 00:38:00.265, Speaker C: It's governed by the three laws.
00:38:02.565 - 00:38:22.105, Speaker A: I mean, I think robots will be huge, but it's just so much harder to ship hardware. Not just the figuring it out, the regulations, the edge cases. Whereas software just happens. AGI and super intelligence. I feel like there's almost no regulatory or just hard real world blockers to getting it done.
00:38:23.205 - 00:38:28.813, Speaker C: Where you place them. Like humanoids that exist in factories and in the background will be much.
00:38:28.869 - 00:38:31.237, Speaker A: Those already exist. Yeah, I mean, I guess not humanoid.
00:38:31.261 - 00:38:39.501, Speaker C: Not to the scale that they're describing versus things that are walking around down the street. That that's, that's far away.
00:38:39.693 - 00:38:43.485, Speaker D: It's like do all your menial tasks, like clean up your house.
00:38:43.525 - 00:38:58.727, Speaker A: Yeah, yeah. Elon put it really well in the talk as well. He was like productivity is just average productivity per person times the population. Right. So it could just go to. With humanoids and AGI, I feel like.
00:38:58.751 - 00:39:29.641, Speaker D: It can just go up forever. Yeah, I feel like it just will become a resource constraint like energy or something at that point. That's where I think you start to get constrained. Right. Because you see all those graphs of the countries where it's like the whatever GDP or productivity or wealth is just directly correlated with energy. And yeah, the more energy you have, the more wealthy the country is or the economy is. So that's where it kind of leads back to energy being interesting and kind of like a.
00:39:29.641 - 00:39:33.337, Speaker D: Yeah, I think energy is an encompassing play of everything.
00:39:33.441 - 00:39:33.801, Speaker A: Right.
00:39:33.873 - 00:39:36.505, Speaker D: But you have to take a pretty long term view on that.
00:39:36.665 - 00:40:08.933, Speaker A: Yeah. There's a really good report by Epoch AI. It's called like Can AI scaling continue through 2030? And they do some pretty in depth research on all the different constraints. So energy chip production capacity, data scarcity and the latency wall. And they basically conclude that energy is the biggest blocker, although it doesn't really block anything till 2030. But that's going to be the biggest limiting factor which maybe does go to there being some interesting opportunities and investment on the energy side.
00:40:08.989 - 00:40:21.125, Speaker D: But I feel like it's already blocking stuff. It's already an insane amount of energy and like isn't it water is a big component of it as well. I read that cooling.
00:40:21.245 - 00:40:23.345, Speaker A: Yeah, yeah.
00:40:24.165 - 00:40:47.031, Speaker D: That's kind of interesting. Goes back to the two most basic things in life. Water and. Water and energy become the scariest things. But yeah, if you were to think like productivity just like 10x's from here the constraints would probably be on like the commodity physical level, energy level like in the real world rather than, you know, something else.
00:40:47.143 - 00:40:52.487, Speaker A: Yeah. Energy becomes the unit of account, I guess the store value, whatever.
00:40:52.631 - 00:40:54.671, Speaker D: I feel like that's. That's good for bitcoin.
00:40:54.783 - 00:41:04.469, Speaker A: Yeah. I mean crypto AI is interesting too. I do think a lot of people think it's vaporware. I don't think it's vaporware, although there's definitely a lot of vaporware in it.
00:41:04.597 - 00:41:07.749, Speaker D: What do you think that's crypto again?
00:41:07.797 - 00:41:11.069, Speaker B: Right. Most of crypto is the open source.
00:41:11.117 - 00:41:14.389, Speaker C: Nature of anybody being able to do anything. You're naturally going to get a lot of crap.
00:41:14.437 - 00:41:14.997, Speaker A: Yeah.
00:41:15.141 - 00:41:33.557, Speaker B: I don't think you're saying anything. This is the thing it's always easy to. And this is coming from someone who. Yeah. Is called crypto AI Vapor a lot. It's always easy to just say that something new is vapor because you're going to be right on like 90 plus percent of what you're saying. Right.
00:41:33.701 - 00:41:34.005, Speaker A: Yeah.
00:41:34.045 - 00:42:04.143, Speaker B: So you're always going to have things go to go back to and be like see, I was right. But you're also just gonna miss the real like breakthroughs. Right. To do like foundational things. So yeah, I think you just need to be willing to be like wrong and be. I think if you like, being willing to be wrong in public is such a powerful trait to have. Like, most people just cannot fathom being wrong in public and saying something where they.
00:42:04.143 - 00:42:17.719, Speaker B: There's so many things I've said where I look back in two years, I was like, wow, that was so dumb. But like, I think that that's the only way that you really are going to stay at like the forefront of stuff, you know?
00:42:17.847 - 00:42:57.175, Speaker A: Yeah, I agree. Yeah. The most interesting bits I think of crypto AI that if I had to pick is, I mean, I think censorship, resistance just makes sense. Like if artificial intelligence becomes the most important, intelligence becomes like the most important resource, then there's going to be demand for intelligence that sits outside the system, just as there's demand for like money that sits outside the system. But that's very abstract, right. I think the biggest kind of real thing that's interesting is this idea of crypto is the open permissionless API for AI agents. You know, like, you don't have to kyc.
00:42:57.175 - 00:43:29.245, Speaker A: You don't have to have a credit card, you don't need a birth certificate, you don't need approval from any third party. And AI can just like deploy code and transfer value without intervention from any human. Right. It lets these, you can have these sci fi use cases of like AI companies permissionlessly raising money and deploying services and stuff like this. So I think that's pretty cool. And then I think crypto is just really good at bootstrapping supply sides for networks. And I think the data one in particular is kind of interesting.
00:43:29.245 - 00:43:59.779, Speaker A: So OI models have been trained on the entire Internet now and so they're moving to multimodal data. So like video data and all this kind of thing. And I do, and obviously OpenAI is making deals with like New York Times and Reddit to have an API key. So they have fresh data all the time and they can, they can, they can train on that. And I do think there's going to be interesting ways that crypto can coordinate networks to like give you proprietary data. Like hivemapper, I think is an interesting example. Right.
00:43:59.779 - 00:44:34.329, Speaker A: They've mapped I think like a quarter of the world now. Like, it seems like having that live dash cam data all the time is going to be pretty valuable to something. And the same way like there's a lot of people that have valuable data, but they don't. Maybe they're not big enough to like coordinate a deal with OpenAI or whoever. Seems like data marketplaces could, could come into their own too here. But I do think like data collection and like the data layer is one of the most interesting of the crypto AI stack. Like, and where, where you could have most value.
00:44:34.329 - 00:44:57.445, Speaker A: Like I think Grass is a portfolio company of ours, is super cool. Just like uses your spare bandwidth to scrape the Internet. Right. So instead of these companies having to do their own scraping, you could just, if you had enough of a supply side using this thing, you'd literally have an API key to the entire Internet. Right. Just being scraped for you at all times and fed into a model. I think that's pretty, pretty sick.
00:44:57.445 - 00:45:09.241, Speaker A: Yeah. And then there's like the decentralized training and stuff, but those are just harder. It just seems, seems far away. Some of, some of these other ones.
00:45:09.433 - 00:45:17.045, Speaker D: What, like what are the. Other than Grass? What are the other current crypto projects that are doing interesting things that you think?
00:45:19.585 - 00:46:09.495, Speaker A: I mean, I think Nalys is one of the smartest teams in the space. They're doing a bunch of stuff like across the stack they had a pretty competitive open source model called Hermes. And then they just came up with this way to minimize latency so you can do decentralized training, like distributed training, which. Yeah, distributed training is kind of like the holy grail, but because, I mean the benefit is that you could theoretically, and this has always been a theoretical benefit, like tap into the lowest marginal cost of compute anywhere in the world. Right. Whether it's someone's MacBook or something like this. And the, the drawbacks are just that, you know, these big tech companies are spending like billions of dollars designing data centers to be like fully optimized and there's huge latency issues to training and stuff.
00:46:09.495 - 00:46:16.623, Speaker A: So it just seems like it's not going to happen anytime soon to me. But I'm not, I'm definitely not an expert.
00:46:16.719 - 00:46:17.855, Speaker C: Like I could be wrong.
00:46:17.975 - 00:46:38.353, Speaker A: And also like the people that have, the people that have the money have no incentive to like make this happen. Really? Yeah. So that one's interesting. I think Sentient is pretty interesting. I think there's a lot of cool stuff happening. It's just like very early. Yeah, it's just super early.
00:46:38.353 - 00:46:47.257, Speaker A: You guys looked at anything in crypto AI I know, Etc. Been the most bullish historically.
00:46:47.401 - 00:48:05.375, Speaker B: I've read these reports, fonderings reports, which are amazing. And by the way, by the way, we're doing like a crypto AI month in, starting like mid October. These reports, the first one is like unlocked and free right now, but we're going to do like a bunch of stuff around, you know, like infrastructure, middleware, application Layer, so and like, so definitely be on the lookout for that coming up. But I've read all these reports three times each and they're just like packed with info. But I still find it like, it just seems like Mo, you really have to take a leap of faith on the amount of like money, I guess, of all these projects we'll end up making because evaluations are like very much priced in like a lot in the future. But I mean, hey, man, when I do, I have that chart thing that I do where I go see like how coins have performed like by each sector and stuff, and the AI ones continue to actually be like less shitty than everything else. You know, it's like they're not, they're not terrible.
00:48:05.375 - 00:48:10.155, Speaker B: Which is saying a lot, I think, in this market environment. Yeah.
00:48:10.195 - 00:48:12.883, Speaker D: Is there anything about crypto we want to. We haven't like.
00:48:13.019 - 00:48:18.939, Speaker B: I know it looks like. It looks like BTC is about to go under 04. To be honest. It's at 4 024.
00:48:19.067 - 00:48:20.851, Speaker D: Is that an all time low?
00:48:21.003 - 00:48:24.643, Speaker B: No, but it's like it hasn't been under this since like April of 21.
00:48:24.739 - 00:48:25.395, Speaker D: Oh, okay.
00:48:25.435 - 00:48:25.635, Speaker B: Well.
00:48:25.675 - 00:48:27.355, Speaker D: All time low for this cycle.
00:48:27.475 - 00:48:32.815, Speaker B: Oh yeah. All time low for the cycle. I don't know.
00:48:33.195 - 00:48:37.375, Speaker A: God, that thing you want to talk about on roll ups, the post you made on roll up.
00:48:37.675 - 00:49:43.055, Speaker B: Yeah, it's kind of just starting to think, like, obviously, yeah, I've been like bullish Alana over the past year and a part of that thesis was just like, I thought they'd get a lot more like financial activity, a lot more like fundamental revenue and all this stuff. But I actually, I do start to wonder like in the long run, is that even going to be the right way to like value L1 tokens? And I really don't know. I think there's like a lot of good points on a lot of sides. But if you believe that, and I don't know if I necessarily believe this, but if you believe that like apps will be able to capture all like the priority fees and MEV that they cause on like a shared layer, then in that case there's not actually a lot of like fee revenue that ends up going to like the L1 token. And then you kind of do need to value these things as reserve assets or money, whatever you call them. And then in the ETH roll up roadmap where ETH is used. Right.
00:49:43.055 - 00:50:01.847, Speaker B: This is the whole thing. It's like ETH is used on all these roll ups and that makes it money. It is plausible that that ends up working out. Right. I think the hardest thing though is that everybody says ETH is money and podcasters say eat this money. Vitalik says ETH is money. Drake says ETH is money.
00:50:01.847 - 00:50:42.027, Speaker B: It doesn't matter what any one person thinks if like eat this money or not. Right. It's like is the world going to adopt eat this money? And that's still very unclear to me at this point. And so yeah, I don't know. I think the argument that like all apps will be able to capture all their MEV in the long run is not necessarily true. I think there's like a lot of positive like synergies if you're an application and you launch on a shared state where if you now trying to try to capture that mev. Well, for instance Uniswap, if Uniswap goes and makes a chain all their revenue.
00:50:42.027 - 00:51:10.525, Speaker B: Yeah, Uniswap Pump people are saying that pump could be is a good example of something that could be an app chain. I do not agree with that at all. It pump benefits because it has access to all these users and liquidity right there. And so if pump is like, oh, we want to now start capturing our own mev, we're going to do an app chain or we're going to do app specific sequencing. I don't know if that's as easy as people make it out to be. And they can do that with actually maintaining the same level of adoption.
00:51:11.185 - 00:51:37.337, Speaker A: Well, the trade off is ux, right. Like if people just had to use Phantom and it was really easy to move their assets to this new pump chain. Like people don't really give a fuck that they're interacting with Solana. I don't think that's always been my why I'm bullish like rollaps and app chains. Much to my detriment so far. Yeah, I just think that. And that's like the E thesis, right.
00:51:37.337 - 00:51:51.865, Speaker A: Once you get really down to it, L1s have no value other than this like proof verification and money. Right. And then if that's the case, then you have to accept roll ups and build towards that.
00:51:52.025 - 00:52:15.175, Speaker C: The whole thing of people not caring, but it's only until they hit some level of escape velocity of liquidity and users right. Where it's like, okay, there's enough users for this app to operate in the same way it would have on the L1. And so then in that sense, sure, people don't care, but you kind of have a cold star problem.
00:52:16.075 - 00:52:16.387, Speaker D: Yeah.
00:52:16.411 - 00:52:22.215, Speaker B: I mean Pump uses soul in all its pools. Right? Right. Like how the fuck are you going to do that on an app chain?
00:52:22.795 - 00:52:34.963, Speaker A: We just use Bridged Soul, right? Yeah, but if everyone trades on hyperliquid, no one gives a fuck. Everyone's on hyperliquid. It's like closed source code. There's validators run by the team, there's.
00:52:35.099 - 00:53:07.379, Speaker C: People who want to trade on leverage and are in jurisdictions where they can't easily do that. There's a big reason for them to move over here. It's a lot of these native assets that are purely interesting because there's enough other people who are going to speculate on this long tail of trash. Whereas if you just want to trade on leverage, then you'll have a few market makers that can make the experience great and then it doesn't really matter.
00:53:07.547 - 00:53:10.535, Speaker D: Hyper Liquid is really crushing it though.
00:53:12.155 - 00:53:13.147, Speaker B: Do you think?
00:53:13.291 - 00:53:23.109, Speaker D: Yeah, I know, but it's just pretty crazy. I feel like that could be a good. Yeah, well, I'm just looking at this volume chart. Oh God.
00:53:23.157 - 00:53:26.189, Speaker B: But you think this is going to stay after tg? This is what I was trying to say.
00:53:26.237 - 00:53:50.831, Speaker D: Yeah. Because they had a month. Here, I'll show it. I'll send. I need to pull up a chart. But basically they paused their point season for May and volume barely dropped. So if you go look at hyperliquid throughout May, like season one points ended, they had like a month of no points and then season two started and their volume like dropped a bit.
00:53:50.831 - 00:54:46.209, Speaker D: But like it was still pretty significant. I think they've kind of reached and they've moved a lot of distributing points from like perp trading to their spot trading, they've just kind of reached escape velocity. I feel like on the perp side of things where they have like a few hundred million in OI of btc, few hundred million in oiv. So like anyone who wants to get a position on like any single entity, unless like you're some massive trading firm like you can reasonably get a position on. It's like exactly like a centralized exchange in terms of like feel and speed and features. The fees are like only three and a half bips for makers or sorry for takers and. Yeah, and they have like a pretty good selection of long tail.
00:54:46.297 - 00:54:56.569, Speaker A: It's a centralized exchange in its trust assumptions too though. Like at least right now, no, I.
00:54:56.577 - 00:55:20.155, Speaker D: Think that you can still can withdraw to the L1, but er, to the arbitrum or the L1, but yeah, I think that they're trying to make it like its own app chain. Right. Like paralyzed DVM L1 and they've already had like if they can do that and migrate all this liquidity over. Yeah that would be pretty impressive.
00:55:20.195 - 00:55:30.131, Speaker A: The nodes are closed source. MERT had a good post today about hyperliquid kind of repeating things that everyone knows but it's just like way easier.
00:55:30.203 - 00:55:44.969, Speaker D: To to go from like that to like decentralized and like start decentralized and actually get traction. Like they're just killing. They have like over 50% of the per deck volume now and it's by far one I've used and I've used.
00:55:45.017 - 00:55:53.365, Speaker A: Like basically all of them and like fully self funded. Yeah no revenue either other than liquidating you sometimes.
00:55:56.035 - 00:55:58.735, Speaker C: Vaults are big too big product.
00:56:00.155 - 00:56:08.971, Speaker A: Speaking of starting centralized and making a lot of money. What about Robit is that we're having a little Robit season to be on.
00:56:09.123 - 00:56:12.215, Speaker D: Anthony started chilling it on Twitter the other day.
00:56:12.715 - 00:57:12.505, Speaker C: Sellers are exhausted. Yeah, no, I mean it's continued burning burned another like 20 something percent of supply since all time high. Just patiently waiting. Yeah then we'll see if that the front assured sponsorship on Southampton Premier League team starts paying off too. But it's funny, it's like those things, it's hard to. You'd hope there's some immediate benefit but I think it's mostly like brand and recognition because then once you start seeing that you start consciously looking around you're like wow, there's a lot of gambling sponsors on all of these platforms or at least like Stake and kind of the prominent ones. But yeah, now still burning much supply and it's the most deflationary token in crypto and the only one of the few without a lot of or any VC unlocks or founder unlocks or anything like that.
00:57:14.045 - 00:57:50.965, Speaker B: Yeah, I guess. Lastly Billy, we should wrap this up soon. We got like break pointed token next week so you'll probably see and I'd imagine that like Seoul will be pretty volatile going to that. I think the only talks people care about are like the three Fire Dancer talks as like in respect to Soul Soul price. Those are on the 20th and 21st Singapore time. So yeah, we'll see. Normally conferences are bearish but like last Breakpoint Salana ripped through that and like kept ripping after.
00:57:50.965 - 00:57:54.537, Speaker B: So yeah, we'll see.
00:57:54.601 - 00:57:56.585, Speaker D: What was the price last break point?
00:57:56.705 - 00:58:21.735, Speaker B: It was like going into it it was like 1720 bucks and then it was like 45 at the end and then it was like over 100 by the end of the year and Breakpoint was in like October, November. So bullish. Great point. This year is going to be a lot different. Breakpoint. Last year there was honestly, like, no vcs. A lot I even think about, like, Delphi.
00:58:21.735 - 00:58:43.015, Speaker B: It was like, me, Rinko and Golding. There's three of us. And this year we got, like, massive crew, so. And I think a lot of, you know, people are like that. So it'll definitely be different from last year's, but yeah.
00:58:43.595 - 00:58:59.655, Speaker A: Yeah, maybe. Last thing, we're doing a. We just announced we're going to do a crypto AI accelerator with. With near. So that's pretty exciting. Recorded a pod with him, with him yesterday. That was pretty good.
00:58:59.655 - 00:59:54.935, Speaker A: That guy's super smart. Obviously, been. He's actually been like, in AI since he was 10 years old, basically, and was a co author of the original Transformers paper. So that's going out. And then we also released our Delphi Labs sort of crypto AI thesis, which the idea is like, it's not really philosophical, although I think we all know there are strong philosophical reasons for why crypto AI sort of is good for the world, or at least not having on the actual substance of like, what is it about crypto that enables you to make better AI products, or one that you can make without it and kind of go through the stack, what we can do. So, yeah, if you're a crypto AI builder, please apply. All the links are going to be on my Twitter and see you all at.
00:59:57.875 - 01:00:00.255, Speaker B: All right. I think that wraps it up, right?
01:00:00.955 - 01:00:01.811, Speaker A: Yeah.
01:00:02.003 - 01:00:10.051, Speaker D: All right, guys, hopefully the crypto market's more interesting next week or in two weeks. Get some more life.
01:00:10.123 - 01:00:10.275, Speaker C: Yeah.

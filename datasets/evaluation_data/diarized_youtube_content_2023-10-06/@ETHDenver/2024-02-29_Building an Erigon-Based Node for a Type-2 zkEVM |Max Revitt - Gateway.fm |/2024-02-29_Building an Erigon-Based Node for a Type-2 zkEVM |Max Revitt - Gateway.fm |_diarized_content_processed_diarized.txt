00:00:22.590 - 00:00:23.140, Speaker A: You.
00:00:25.110 - 00:00:38.850, Speaker B: Hello everyone. For our next talk, it's building on Aragon based node for type two ZKe EVM. And speaking with us today, who traveled 20 hours to get here is Max Revit. He's a developer. All right, go ahead.
00:00:38.920 - 00:01:20.610, Speaker A: Hey, thanks for the intro, man. So welcome. Yeah, this afternoon I want to explain to you how we modified the Ethereum implementation Aragon on to build the client for Polygon CDK L two. So in the presentation I'm going to cover the following topics. So who are Gateway FM? Like who are we, who's the company? I'm going to go into what is a roll up? You've probably heard that a few times today. And what is CDk? I'm going to cover Gateways product presto, just in brief. And then I'm going to go into why did we choose Aragon to do this implementation? And then we're going to go through the main two parts of the system that we've built and that we're building.
00:01:20.610 - 00:01:59.470, Speaker A: So the bit that we've built already is the synchronizer. So we're going to cover the EVM changes we've made. We're going to cover the sparse Merkel tree, we're going to cover the dynamic fork enablement. We're going to look at the l one and data stream sync, so where the node gets this info from, and then the bit that's work in progress, which is the sequencer. So we're going to cover virtual counters, the witness executor, verification, data stream generation, and then our load testing tool, which is the TX replayer. So who's Gateway? Gateway FM is team professionals in the crypto space. We build web3 infrastructure and tooling.
00:01:59.470 - 00:02:38.710, Speaker A: We have expertise in blockchain, Fintech, Infosec, other industries. And that lets us lend our experience to other people to sort of really help the businesses in the space. So I'm Max Revit, I'm on the R D team. I'm a developer. My team is a group of people who've been on the Aragon team previously. So we have a good experience with this node software and we've been building solutions in the space for quite a while now. So Gateway worked with some industry leaders and some names that you will recognize, Polygon, Wirex, et cetera, trusted by these partners.
00:02:38.710 - 00:02:59.060, Speaker A: So presto. So Presto is Gateway's flagship product. This is rollups as a service. So four clicks to your own roll up. So private ZK rollups with all of the tooling. So once you've deployed that, you get KYc block explorers, et cetera. So kind of turnkey solution for a roll up.
00:02:59.060 - 00:03:43.870, Speaker A: We run these roll ups for other people, as well as building the technology that underpins them. So that gives us a unique perspective and we understand the requirements for a user friendly and performant client and how to use this client with our presto users. So having that r and d department also means that we produce a better product in Presto. So what is a roll up? A roll up is a layer two scaling solution. It will reduce costs and increase throughput by processing transactions away from the main blockchain. So when it comes to Zk rollups, there are a few types, and they each come with their own trade offs. So a type one is essentially ethereum compatible.
00:03:43.870 - 00:04:20.358, Speaker A: It's basically running the l one. The issue here, and the trade off is that proofs can take a long time to generate. So realistically that might not be the option that you want. Type two has minor changes, so state tree modifications change, gas costs, some small EVM changes. This comes with the benefit and the trade off that you get quicker proofs, but you may encounter some incompatibilities when trying to run your smart contracts. We then move to the type three, and again, the trade off towards performance is most heavily skewed here. So it's mostly ethereum compatible.
00:04:20.358 - 00:04:48.914, Speaker A: You've got fast proofs, but you get more incompatibilities. So for example, most of them, there'd be no pre compiles. So CDK is a type two roll up. And throughout this CDK was Hermes polygon Zke Evm. So it's useful to know the terminology and the history. So CDK is the name we'll be using. So the question is, why did we choose to use Aragon as the node to do this? So Aragon benefits from a low footprint on disk.
00:04:48.914 - 00:05:36.926, Speaker A: Anyone familiar with the node in the Ethereum L one space will know that it's an all in one solution. So RPC, transaction pool, EVM, et cetera, they're all there in one repo to be run. It has a stage wise sync, so instead of going block by block, the node will sync in stages. So we can optimize some operations for the batch. So for example, in this case, we can verify multiple blocks in a single state route calculation. Aragon uses MDBX, so this has some advantages over things like bolt and level DB, in that it's simultaneous read whilst you're writing the Db, which means we can split the parts of the system up, and it's super fast. So as I said, you can run components of Aragon separately.
00:05:36.926 - 00:06:28.680, Speaker A: A good example there being that you can separate the RPC out and it can still talk to the database whilst it's been written and the sync is happening in the background. So it's very capable as an archival node and it's an ideal candidate in fact for syncing the layer two. So the first part of the solution that we've provided, and this is the synchronizer, this is a node that will consume and sync the blockchain and it will allow you to then stand up an RPC. So it syncs from both the l one and a data stream which is produced by the sequencer. So the sequencer will produce the data stream which contains transactions, batches and other data. And then we use l one sequences and verification. So the l one verification will contain a state route which we can use to then check and make sure that the chain is okay.
00:06:28.680 - 00:07:09.634, Speaker A: So we made some adjustments to the stage sync as well. So we replaced the headers and body stage with a stage which actually retrieves data from this stream and pipes that into the Aragon DB MDBX. And we have a new stage which is for creating the SMT. So we replace the aragon into hashes stage and this allows us to generate a sparse Merkel tree which will give us the state routes. So that differs a little bit from Ethereum mainnet with the Merkel tree where possible, we have tried to maintain upstream compatibility. So obviously this is a fork of eragon. We want to be able to take changes from the upstream as and when they come.
00:07:09.634 - 00:08:00.962, Speaker A: So we've kind of added underscore Zkevm to the file names and tried to, where possible, separate out the code. We've written as much as we can, so that when it comes to the actual code files that are already in Aragon and in the upstream, we've made small incisions there. So hopefully when we rebase on the upstream that's going to be a lot more easy because we're just going to see like a function name change or something like that. And it'll be fairly clear that, okay, this is the Zkevm version and we'll know which to take. So also we've added a new RPC namespace. So with this being an l two, there is a ZkevM namespace, and that allows you to get stuff by batch and do some operations like that around the batches. So since we're running a type two roll up, we had to make changes to the EVM as discussed with the types of roll up.
00:08:00.962 - 00:08:45.410, Speaker A: So this is an EVM that's based on the Berlin hard fork. We made various changes to opcode, so Xcode hash returns the hash of contract bytecode from the state tree. Difficulties returning zero static call doesn't override return data if the execution is reverted. We also have a new type of error for disabled smart contracts, so that makes it bathe a bit like an error reverted. With each fork we've changed the pre compiles to match the CDK requirements. We also replaced self restruct with send all, so this prevents funds from being lost in the l two. This isn't necessarily EVM changes, but there's a couple of things that we have to write into contract storage as we do the execution.
00:08:45.410 - 00:09:41.890, Speaker A: So global exit routes are placed in the global exit route manager contract storage, and then the transaction number and state route reach placed into the system contract at that point as well. So the sparse Merkel tree this replaces the Merkel tree from the Ethereum implementation. And the benefit of sparse Merkel tree, which is a 20 minutes presentation on its own, maybe longer, is that we can do efficient non inclusion proofs. So we took an algorithm that existed from the JavaScript implementation of the node and we made some performance increases. So as I said, we have the stage sync. That means that we can do a batchwise operation on this tree, and we added some efficiencies there so that we don't multiply hash nodes, and so we got a huge performance benefit there. We use the Aragon history so that we can incrementally update and unwind this sparse merkel tree.
00:09:41.890 - 00:10:27.810, Speaker A: And luckily we retained DB compatibility with the JS implementation, which was a huge debugging win for us, because we've got a lot of state and we're trying to compare and see why our state routes have differed. So that's been a huge help. As we've done the project, we've also added dynamic fork enablement. So normally in upstream eragon you would need to know a block height or a timestamp of which a fork would be enabled ahead of time. Here we can code for it and say that it's Fork IDX, and when that fork id is actually enabled by the chain, we'll consume that, and that will set that feature set live. So this synchronizer is currently in Alpha and we'll be doing the beta soon. This brings me on to the sequencer.
00:10:27.810 - 00:11:13.386, Speaker A: So this is a work in progress, and this is a separate mode of operation for Aragon, where the node will build blocks and batches, which will be sent to the l one, so it acts as the centralized sequencer. Now this is obviously replacing an existing sequencer which has a different EVM implementation. So we have virtual counters which mimic the requirements of the CDK hardware, and they prevent us basically from overwhelming the prover. And the way we've done this is we wrap the Aragon jump table, and so different counts are assigned to different things. More expensive operations will have a higher impact here. And so we're aiming to limit work done by transactions and limit the batch data size. So because proofs are expensive, we want to maximize each batch.
00:11:13.386 - 00:12:22.578, Speaker A: So as we go through, we're working with these counters, and if we hit a counter overflow, we will simply revert back to the previous transaction and then build an optimized batch size. We've implemented the witness, so the witness is a description of changes to states. So it's like a partial sparse merkel tree, and we can send that to the prover and we can send that to the existing executor, in fact, for reasons we'll see later. And that allows you to sort of have a stateless reconstruction and we can use this to verify the existing sequencer implementation, which we're going to see next. So this is where we run Aragon in the sequencer mode. And obviously once we build a batch, we need to know that our EVM has had the same outcome as the existing executor's EVM. So we have to keep compatible with the upstream run due to performance reasons, we use a pool of executors asynchronously and this is where the statelessness comes in with the witness.
00:12:22.578 - 00:12:51.040, Speaker A: So we can verify multiple of those at once. Now on the happy path. That's great. When there's an issue, we go into like a limbo mode that we're calling it. And so we have to sort of revert the batch to find the failing TX where there's this incompatibility and we'll remove that transaction from the pool and then we'll move forward again. So that's how we're dealing with the differences that we may perceive there. And obviously that will be logged and hopefully the issues will be raised and we can then resolve that.
00:12:51.040 - 00:13:35.760, Speaker A: The sequencer does data stream generation. So at the moment, the synchronizer node we talked of is consuming the stream from the polygon implementation of the sequencer. At this point we will start generating that stream for these synchronizer nodes and exposing it. So pieces of the stream are being verified by the executor in that verification step as well. Obviously, whilst doing this, one of the outcomes that we want is a performance node performance sequencer. So we built a TX replayer, which allows us basically to push transactions into the sequencer and replay them safe from Mainnet. And that's kind of like a good real world test.
00:13:35.760 - 00:14:27.980, Speaker A: So, to summarize what I've talked about, roll ups are a layer one scaling solution. The roll up type indicates that compatibility and performance trade off. CDK sits at the type two, so we do get a performance benefit, but we don't introduce massive incompatibilities. Most smart contracts hopefully will work there with minimal tweaking. The reason for the project? The existing polygon CDK ecosystem is being augmented by this eragon based node. I think it's going to be slightly more ergonomic for infrastructure to run this node, and hopefully we can squeeze a little bit more performance out there as well. We've talked about the Presto ecosystem, so obviously that's gateways, roll ups as a service.
00:14:27.980 - 00:15:01.720, Speaker A: And we deploy things like this solution to allow you to have four clicks to your own private ZK roll up, which obviously is super cool. And they're kind of like turnkey solution. We talked about the synchronizer, which is an alpha. The beta is coming soon, and so that's for running basically your RPC nodes. And we also talked about the sequencer, which is the work in progress, where we're building blocks, batches and submitting them to the l one. So I'd like to thank you for listening. If there are any questions, we'll be at the Polygon booth for a bit.
00:15:01.720 - 00:15:10.660, Speaker A: We talked through quite a lot of deep concepts there in brief, so I'd be happy to go into a little bit more detail if anyone wants that. So yeah, thanks very much.

00:00:00.170 - 00:00:42.548, Speaker A: You all right, well, let's get started. Let's get right going. Perhaps just to start, we have many different projects and teams. We've got some of the major kind of l two s here on this panel. Do you want to first say your name and then the project that you work for? Just so we give the audience a little bit of background on who's up here today.
00:00:42.714 - 00:00:54.120, Speaker B: Hi everyone, I'm Stephen, I am from offchain Labs. We contribute to the arbitrum technology stack as well as Prism, which is the leading consensus client for Ethereum. But here today, I think to talk about Arbitrum.
00:00:54.860 - 00:01:03.210, Speaker C: Hi, I am Ellie, co founder CEO at Starkware and we support the Starknet L2.
00:01:04.940 - 00:01:13.420, Speaker D: Hi, my name is Arun, I work at Mantle. We are an op stack based roll up that uses off chain data ability using Eigen layer da.
00:01:14.480 - 00:01:27.280, Speaker E: Hi everyone. I'm Hai Chen from Scroll. So I'm the co founder of the scroll. And inside the scroll I lead the engineering team. And the scroll is ZK Rob, EVM equivalent. ZK rob for ACM.
00:01:28.420 - 00:02:11.808, Speaker A: Amazing. I'm so excited to chat with you guys. Thank you for being here. Let's get started by talking about 4844, about the Denkoon upgrade that is really designed for l two s. It's one of the first in protocol changes where Ethereum is really hammering home the vision that Ethereum wants to scale through l two s and not on the l one. One of the main kind of questions around EIP 4844 is exactly how much of a benefit is it going to be to l two s? There's a lot of back and forth with Ethereum core developers about how many blobs to introduce. They finally landed on three blobs per block with a maximum of six.
00:02:11.808 - 00:02:27.990, Speaker A: But I'm curious to know from you guys, how prepared are you for this upgrade? How much of an impact do you think it really is going to have on L2 adoption? Hai Chen, do you want to go first?
00:02:28.360 - 00:03:22.180, Speaker E: Yeah, sure. So I think 44 four is still like a very important upgrade that's coming to the exam. It's very important for the L2 because you can save on the data availability by just using the blobs that can be expired after about two weeks. But I think people may initially over being overly optimistic about how much reduction of the 44 four data boss it can reduce. I think from the current testnet it sees it's about the three to four x reduction compared to the core data in the saving a cost which people initially think like it's maybe ten x. But I think overall it's still quite important because as L2, the majority cost of the L2 transaction is still coming from for the data availability. So like 80 90% of the data is coming contributing from being making the data available.
00:03:22.180 - 00:03:34.444, Speaker E: So using the 44 for data bops can still reduce a lot of on the L2 transaction cost and then we are working on to supporting the 44 four very soon.
00:03:34.642 - 00:03:38.620, Speaker A: Got you anything to add Arin?
00:03:40.240 - 00:04:48.690, Speaker D: No, I think that's pretty accurate. Like Hayton mentioned, 4844 is foundational in the sense that it paves the way for full dank sharding, at which point the on chain ethereum based datability will increase by order magnitude. But the actual increase right now is going to be fairly mild, at least initially while they're bootstrapped to the network like agent mentioned, three to six data blobs, which equates to about a max about 750 data per block, which would equate to around 100 to 300 extra tps across all roll ups based on some reasonable assumptions about the number of bytes per transaction, based on transaction complexity and in terms of how this actually affects something like mantle, which does off chain DA, I would argue it opens up optionality for sure. But since in almost all cases the cost of posting data to an off chain DA solution like eigenda is going to be orders magnitude lower than anything with on chain call database datability or data flight disability, it's unlikely we change our methodologies that much based on it.
00:04:49.620 - 00:05:07.864, Speaker A: That's fair just to pick up on that. Sure, data availability costs are going down on Ethereum through EIP 4844, but mantle is still going to be using other data availability solutions because they are still cheaper than what's going to be available on Ethereum. Is that correct?
00:05:08.062 - 00:05:12.120, Speaker D: Yeah, for sure. It'll be dramatically cheaper, at least for the near term.
00:05:12.460 - 00:05:50.836, Speaker A: Gotcha. Ellie, I know Starkware was one of the first to be ready for this upgrade. Can you talk a little bit about picking up on that point of you are using Ethereum for data availability and being very conscientious about making sure we're ready to utilize the full benefits of 4844 as soon as it goes live? But why not also experiment and see kind of the perhaps more performant or less costly da layers out there like Celestia and other l ones?
00:05:51.018 - 00:06:54.024, Speaker C: Oh yeah, we don't object to using them. We will be using data availability layers as well. So yeah, no objection there to that. We'll also have volition at some point you want to really integrate things and maintain proper security and proper interface with all of the infrastructure. And the thing that our developer ecosystem wanted first to have is the blobs of EAP 48 four, because they basically get Ethereum security just turned on with no change. Once we bring in things like data availability or volition, it means that they would need to change parts of the code like to opt into using those things, and it would be slightly more work for them. But it really depends on what kind of cost reduction we'll see with 48 44.
00:06:54.024 - 00:07:00.764, Speaker C: If it's as significant as promised, then we'll be happy with that for a while.
00:07:00.962 - 00:07:58.140, Speaker A: That's the thing. I think a lot is up in the air about how much the cost reduction is going to be, especially if we see more activity on l two s. And one of the things that I want to highlight about the analysis that has gone into how EIP 4844 is going to impact l two s is from off chain labs. I believe one of your colleagues, Steven, had written a blog post explaining that EIP 4844 will likely be more economical for the larger roll ups and for smaller roll ups, they'll have to rely on secondary blob markets to basically auction off different parts of the blob because they're not going to use the full 120 gate kilobytes. Can you talk a little bit more about those secondary blob markets and who those markets are going to be run by? A little bit more about the third order consequences of EIP 4844 on l two s?
00:07:58.290 - 00:08:33.992, Speaker B: Yeah, absolutely. So, yeah, that's one of the nice things internally. So as I mentioned, we build arbitrum technology, but our team was very instrumental in building the layer one side of this. The PrISM team in building 4844 support directly into Ethereum clients. So we sort of get to see both sides of that, and it helps us with our understanding of the ecosystem. And yeah, I think the thing that you're alluding to is this idea of if you can fill up a blob, you'll get a much better economics than if you have a partial blob, and sending partial blobs will not be great. So there's this hypothesized idea that people will somehow coordinate to share and come together.
00:08:33.992 - 00:09:13.588, Speaker B: I don't know exactly how that will play out and what that will look like, but what I can tell you is for the arbitram public chains, they do will expect it to be just fine and be able to fill up those blobs so they'll be able to benefit really particularly arbitram one, which is the one that sends its data to Ethereum, they'll benefit from 4844. I haven't done the exact analysis. I know there's a lot of great people doing it. My approach is basically, it's like it's coming in a few weeks, we're going to see what it is. But arbitram technology will be ready. There's a dow proposal already live, making sure that the chains are ready to adopt this as soon as it's ready. And so it will go live basically on day one.
00:09:13.588 - 00:09:44.780, Speaker B: And I think it's going to be very important. One thing that I think is going to come interesting from this is I think it's going to highlight a lot of the differences in l two fees and L2 fees today. As we mentioned, the l one fees are dwarfing everything else. So no one's really paying attention to that little bit on top. So some L2s are charging this much, some are charging this much on top, and I think when you squash the bottom that you zoom in and that becomes important. And there's a very important conversation on sustainability. Arbitrum is not the cheapest of L2, but it's sustainably priced.
00:09:44.780 - 00:09:47.420, Speaker B: I think that's going to open up a very interesting conversation.
00:09:47.500 - 00:10:34.784, Speaker A: I agree. How much of the fee savings will be sent back to the end user of the l two? And to what extent is it actually desirable that you make transactions on l two s subscent cost, especially if that encourages more spam or makes it more unsustainable for the roll up to operate? That is a very interesting question. Any thoughts on that? Before I move on to one of the other questions that I had, though, from the other panelists on the topic of once the fees for data availability are significantly low, to what extent do you give back all those savings to the end user versus the sustainability of the road up?
00:10:34.822 - 00:10:56.810, Speaker E: Yeah, I think for us, initially when we design the scroll, we have multidimensional fee structure. We have like layer one fees and also the execution fee that we separate. So once we're using the 44 data boss, then that automatically will translate that. The layer one data fee will reduce a lot, and then that will be like, I think, saving a lot of cost directly. That user can benefit from that.
00:10:57.660 - 00:11:40.436, Speaker A: Yeah. So show of hands here. How many people have participated or had team members of your team go to something called the roll calls that have started recently? In the last couple months, they're spearheaded by the Ethereum foundation to improve the standardization and kind of interoperability between roll ups. Show of hands who's gone to these roll calls have sent members of their team to the roll calls. Okay, first question to you then Ellie, because this is really about bad mean. Part of it is really about also encouraging. Come.
00:11:40.436 - 00:12:10.960, Speaker A: I know one of the reasons, one of the things about Starknet is that it's not as aligned, aligned. And this meeting is all about how do we ensure that the protocols and the changes that are happening on the l one align with the l two S and the l two S align with the l one. Tell us a little bit about that decision to be not as aligned to Ethereum. And is that a conscious decision not to participate in the roll calls?
00:12:11.620 - 00:12:57.792, Speaker C: So we build different, we build for the long term. We build what we think is the best technology that we can provide. We invented Stark, Cairo, Starknet Stone. By the way, let me take this opportunity to tell you if you have time at 425 at the coral stage, we're going to have a very interesting announcement about proving technology breakthroughs. So please, if you have time, go attend it. Anyways, the story of Starknet is that first of all, we built the first l two scaling solution, which was the Starkx system. And when we started at it, everyone was saying, first, ethereum doesn't really have a scaling problem.
00:12:57.792 - 00:13:39.720, Speaker C: And two, certainly validity technology is not going to be useful for that. Three, definitely it's not going to be Starks. Now, it ended up being that pretty much all of the leading l two s using validity roll ups have converged onto Starks and it is actually considered the end game and we're very proud of it. Cairo and the Starknet Stack are the next generation smart contract language. I think you'll see a lot of convergence on that as well. We have this tendency of saying things that at first people think that we're like crazy or don't make sense, but over time people realize they actually do make sense. So we've been termed unaligned.
00:13:39.720 - 00:13:58.204, Speaker C: I don't think we are unaligned, we just build a bit different and we think of ourselves as trying to do the right thing with our technology. All of this to say, I still apologize for not joining the roll calls. We'll try to make sure that someone attends them because we do very much support Ethereum and we want standardization among.
00:13:58.252 - 00:14:39.752, Speaker A: L two s, of course on the topic though, of maintaining EVM equivalents and conforming to kind of like the standard set by the layer one, which is for example only using a certain pre compile address format, that this was one of the topics of the roll call to reserve a set of pre compile addresses just for l two s to use. Is this a very important initiative that EVM equivalents and maintaining alignment with l one in the future? Is that something that say, steven, that you foresee kind of being like a top priority for arbitram?
00:14:39.896 - 00:15:18.956, Speaker B: Yeah, I think coordination like that, particularly if you are building an EVM chain. If you're not, then you don't need to worry about some of these things. But you do want to have that coordination, because if you use some pre compiled address and it means something else in a different ecosystem, and then Ethereum introduces a new pre compile, now it's just going to cause chaos. So that level of coordination, I think, is important when it comes to the general EVM equivalents or not. I think we take at offchain labs a very middle position, which know, and that's what we call EVM plus. We're building something called arbitrum stylus, which says EVM equivalents, and arbitrum isn't going anywhere. If you want to build a solidity, it's going to have the best support, equivalent support as best as you can.
00:15:18.956 - 00:15:50.784, Speaker B: But we also don't view that as the sailing. We view that as the floor. That's baseline support, which we think is important because so many developers and so much code today written in that language. But then we say, can we do more? Can we appeal to developers writing in other languages? And that's what stylus does. So it adds support on top of the VM for developers that want to write in Rust and C and C Plus plus, and allows them to do that synchronously and also get a ten x benefit. But it's not only the developer, it's also their code. So if you're a gaming studio that spent the last five years writing a gaming edge in a C Plus plus, you can now directly call that on chain.
00:15:50.784 - 00:16:27.484, Speaker B: So our approach is EVM is very, very important because it has so much adoption in our ecosystem today. But if you zoom out, they're estimated to be about few tens of thousands of solidity developers, about 3 million rust developers, about 12 million C and C Plus plus developers. And we say, can we cater to those people, too? And that, to us, seems like a big win. Of course, we should keep EVM equivalents and not do anything with that. So this is all extra and additional, but for those who want it, can we give them a path directly onto the arbitrary chain so they can work together with solidity? You can actually have a single app that's written in solidity and rust. For those that want to opt in and use that, we think that's important. There are some that think this is like, sacrilegious.
00:16:27.484 - 00:16:51.236, Speaker B: Like, EVM is like, you cannot deviate from it. And I respond to them and say Ethereum itself tried to do ewasm, which was very similar a few years ago. Not only like, I don't think anyone in the world today, if they were starting from a friend, including Vitalik, would say, let's create the EVM from a fresh slate. If we could do the same way today, everyone has changes you'd make. That's the way software works. You're locked into some of your decisions based on legacy requirements. But there's nothing religious about the EVM.
00:16:51.236 - 00:16:58.380, Speaker B: There's a very important reason to keep it, and we think it's important for the adoption, but we're also happy to expand it without hurting it. And I think that's sort of the middle line approach we take.
00:16:58.450 - 00:17:46.030, Speaker A: But that's also kind of like the beauty of roll ups that I think a lot of core developers want to see. They want to see the most experimental, the most flexible type of EVM. They want to see code changes that they can't get passed on the l one because of how you can't really move fast and break things on l one. They want to push the more experimental things to l two s. But I think there's also some pushback from l two teams of being viewed as the testing grounds for just layer one changes. I mean, Arun, what do you think about the narrative that l two s should be kind of like the test nets of Ethereum, and then eventually the ones that the projects or like, the protocol changes that really work out, then we do that on the l one.
00:17:48.640 - 00:18:36.376, Speaker D: I think I can argue from two sides there. The first is that if you're creating an l two and you're creating an l two, that's fully EVM equivalent you're going to have at this point, I think, a much harder time getting adoption for it than if you were to try and experiment just because this is going to be the year. I think people are going to launch 1000 different roll ups. And if every single roll up is just an EV equivalent roll up, what's the differentiator that gets you to be the roll up people use? Maybe you could be the Kazakhstan roll up or something, or organize nation states or ethnicity or religion or things like that. But I think a much more interesting approach would be to kind of organize based on some kind of technical advantage or change in architecture or things like that. And to that point, there is nothing that's going to stop. Ethereum can't stop these roll ups from doing this.
00:18:36.376 - 00:19:27.610, Speaker D: At best they could standardize and say, okay, well make sure you don't use any random prefix for your pre compiles, otherwise any kind of cross roll up client that we want to implement is going to have a nightmare trying to deal with all this different stuff. So I think that is a better approach. These roll ups will experiment and then Ethereum can eventually choose to do this to implement the things which the rollups seem to succeed at after kind of picking the winners. And I think we're seeing a level of standardization kind of occur not just with the roll call, but also in terms of the more structured rip development proposals of which the first was to implement this pre compiled that used to be called EIP 77212 which adds a decreased gas cost for AES victor verification to allow for ERC four three seven wallet to have cheaper verification costs on the chain itself.
00:19:28.060 - 00:20:06.872, Speaker A: I mean high Chen, anything you would add to this because scroll of all the roll ups is not to use two awful comparisons, but scroll is probably like the most Ethereum aligned because it's trying to be like a type zero, like a Zke EVM that completely can take the entire EVM and just be able to replicate it fully in its exact state. This is a long term vision for the Ethereum protocol roadmap to one day even have that enshrined in the protocol. So I feel like what are your thoughts that l two s are kind of the testing grounds for what Ethereum will eventually want to be.
00:20:07.006 - 00:21:41.696, Speaker E: Yeah, personally I think I support more experiments on the L2 so that I can try out more features and then in order to making those experiment the new pre compiles be more usable. Is that all of the L2s robs which are EVM compatible adopt the same standard and same protocol so that all of the developing toolings that can be all used across different L2s as that would be benefit the developers and also reduce the confusions to the developers. When you need to be very careful, turn on certain flags when you develop on different chain. That's like a nightmare for developers I would say. But when they come back to the ECM on the layer ones, I think I'll argue for the layer one to behold this golden standard that being very stable, not like they're moving too fast on the changes because otherwise if you like, they're making lots of the drastic changes to the EVM itself, like pushing all of the L2 that are trying to be EVM compatible to be catching up on a lot of things, and then some things like sample certain pre compiled it could be, or some changes to the EVM will not be very ZK friendly. We're adding even more costs for the ZK EVM to catch up to implement those things and adding actual overheads for that. So I would say what Ethereum, like a layer one should be really thinking about how to maybe serve all the L2 row ups better to reduce the cost, like the 44 for data bulbs and in the future for the full dank sharding.
00:21:41.696 - 00:21:48.090, Speaker E: And then can driving this row up centric roadmap to keep growing the L2 space.
00:21:48.940 - 00:22:42.676, Speaker A: That would be nice. But I do believe that Ethereum core developers are really gunning for some pretty major changes to the EVM. Not that it'll happen in the near future, but like Ethereum object format account abstraction, we are definitely probably going to get bls pre compiles in the next upgrade. It seems as though the confidence that in l two s is waning a little bit as of late. There was a tweet a couple of weeks ago by Vitalik that said he was three times less confident in this idea that we can just push all the complexity to l two s because l two s are not as proven as the l one. So making l one more simplified as a DA is not something that he's as confident about doing as he was prior. Does that shock you, Ellie?
00:22:42.788 - 00:22:43.256, Speaker C: Does it?
00:22:43.278 - 00:22:43.608, Speaker B: What?
00:22:43.694 - 00:23:05.728, Speaker A: Does that kind of surprise you? Like that sentiment? That confidence in l two s to be able to inherit the complexity and the risks of what ethereum might otherwise not be able to do because l two s could fail. Because l two s could have a major bug that causes a bunch of people to lose money, et cetera. Does that surprise you?
00:23:05.894 - 00:23:50.252, Speaker C: No. In fact, I think that it's inevitable that some l two s will experience catastrophic bugs and failures. And part of the reason is, I mean, we have to acknowledge that some of the l two s do not have their core security turned on. So the thing I'm most worried about is that some l two s just do not have security turned on and it's heading towards a huge catastrophe. If not on the major l two, then some of the roll ups that are going to be based on it. There will be a mount gox like event on some of these l two s that have no security turned on. And do your own research on whether your l two has a security and where you entrust your funds.
00:23:50.252 - 00:24:16.090, Speaker C: Now, having said that, the teams that are serious about security, and some of them sit here, I'm not worried about that. I'm not worried about that. Look, things could have bugs, ethereum experienced bugs. Serious teams have a way to overcome bugs. And if the technology you're using does not have security turned on, you do not want to put funds on it. Do your own research.
00:24:16.620 - 00:24:50.704, Speaker A: Let's talk a little bit about more about security and how we define security on roll ups. I'm under the impression that many roll ups don't have working fraud proofs or really validity proofs or really have all dependent on a centralized entity to produce blocks on the l two s. These are major kind of shortcomings of most L2s. Does that keep you up at night, Steven? Like the lack of security and the idea that a mount Gox level event could happen on ethereum because of the lack of security?
00:24:50.902 - 00:25:51.684, Speaker B: Well, if I were building a platform that had those limitations, they would keep me up at night. And that's why explicitly like an arbitram, security is always first. I agree with the things that Aldi said, and I know that we agree on a lot of those points, that security being really primary and the most important concern, and that's why we've done things the way we've done things and made sure that security proofs have been live in this ecosystem from day one. I do think to your point about Vitalik's tweet and to Ellie's point, every l two l two s is not like one thing, particularly now there's this explosion of L2s, and everyone has its own considerations, and it goes together. Those teams that take security seriously will also be very slow to do any upgrade that is security conscious and won't be experimenting. So you want to make sure you're in a secure environment today, and one where you have serious developers that are making sure to continue to secure that it gets much, much harder in the world, where now we're encouraging others to use this technology to build their own roll ups and make their own decisions. You have to do your research not only on the core stack, but also on those that are implementing it.
00:25:51.684 - 00:26:14.156, Speaker B: And I think it's important, though, to make sure the core stack having security is the baseline important thing. And then you also have to understand who's operating it. And are you ultimately secure there? So doesn't keep me up personally for the users of arbitrum, but as an industry, I do agree that and one that cares deeply about Ethereum. I think it is something that is very scary and I'm personally concerned about and hope that we can solve soon.
00:26:14.258 - 00:26:30.290, Speaker A: Gotcha. Gotcha. Maybe as a final question, because we now have to wrap up our panel, but for all our panelists, what is kind of like the one major objective or milestone that you'd like to see your roll up kind of achieve this year? Let's start with scroll first.
00:26:33.620 - 00:27:07.884, Speaker E: For the scroll. So one milestone is like, I think the next will be bringing using the 44 four to continue reduce the cost on the scroll. And then the second thing is we are working on to bring the more security features. As Stephen said, we take the security first approaches. So we're trying to build a multi prover approach that we are bringing one more SGX prover that's going to test alongside with the ZK proof. And then after that we are working on towards the decentralization. I think there will be important things for the L2.
00:27:07.884 - 00:27:13.520, Speaker E: I think we are starting from the prover to be having a decentralized and then moving up to the sequencer.
00:27:14.100 - 00:27:17.552, Speaker A: That's a lot to look forward to this year. Mantle, go ahead.
00:27:17.606 - 00:27:19.088, Speaker E: Probably not only this year, but I.
00:27:19.094 - 00:27:41.690, Speaker D: Guess, yeah, I think building a roll up is hard. There's many different objectives. So I could speak myself personally. I would love to see more standardization around fork choice rule when dealing with off chain da. Mainly how does the roll up decide whether data is maybe made available to the l one and what state we should consider canonical and kind of like how the sector resolved at the l one level, because there's a lot of ambiguity right now.
00:27:42.700 - 00:27:58.670, Speaker C: I'll say performance and costs are going to be dramatically improved in starknet. I would love to say more about what we're expecting this year, but I'm not going to spill the beans. Do go 425 to coral stage and you'll hear what I mean.
00:27:59.280 - 00:28:25.956, Speaker B: I would say two things are one developer experience, which ultimately leads to better user experience. So arbitrary stylus I mentioned. I'm hopeful that hits mainets of many arbitrage chains this year, and I'm pretty optimistic about that. And the second one is also continuing on the security and decentralization points. So Vitalik has this sort of three point rubric where arbitrum is leading a general purpose platform today. As a layer one. As a one.
00:28:25.956 - 00:28:42.104, Speaker B: It doesn't sound too exciting. You say we're number one, but most are in zero. So it's pretty exciting, but I'd like to see that go from one to two and also see things like arbitrary bold deploy to Mainnet, which opens up validation for everyone. Security, again, is critical, and I'm happy with where we are, but there's still ways to go.
00:28:42.302 - 00:28:46.748, Speaker A: Thank you, guys. Thank you so much to the panelists, and thank you, everyone, for listening.
00:28:46.844 - 00:28:47.650, Speaker B: Thank you.
00:28:52.740 - 00:28:59.470, Speaker A: Whatever. Anyway, okay, sorry. Thank you so much. Thank you. Thank you so.

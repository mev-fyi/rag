00:00:00.330 - 00:00:03.742, Speaker A: Testing, testing. Hey, everybody. All right.
00:00:03.796 - 00:00:04.014, Speaker B: Yeah.
00:00:04.052 - 00:00:25.970, Speaker A: Let's kick this off. This is going to be a death match panel. ZK rollups versus optimistic rollups. We're going to have some fun with this. And the panel doesn't end until we declare a winner, so we'll have to figure out how we do that. But let me kick off by introducing our panelists. So to my right, we have the wonderful and one and only Zach Williamson from the aztec protocol.
00:00:25.970 - 00:00:47.340, Speaker A: Give it up for Zach. Woo. Next to Zach is Angela Liu from Matter Labs. Give it up for Angela. Next up, we have Ed Felton from Arbitrum. What's up, Ed? And finally, we have our resident musician, Ben Jones from optimism. I heard rumors that we may have a musical performance in store.
00:00:47.340 - 00:00:59.982, Speaker A: All right, I'm Lane, and let's kick off. So let's do intros. Zach, do you want to kick us off? Give us a 62nd intro about yourself and what you're working on.
00:01:00.116 - 00:01:01.822, Speaker C: Hey, there. I'm Zach. I'm the.
00:01:01.876 - 00:01:10.210, Speaker A: Sorry. I'm going to say this, and I'm going to say it again and again because it's so annoying. Lollipop. Like, hold the mic right in front of your mouth or they can't hear you.
00:01:10.280 - 00:01:10.802, Speaker C: Hello?
00:01:10.936 - 00:01:12.100, Speaker A: Good. That's perfect.
00:01:13.830 - 00:01:26.070, Speaker C: Hey, everyone, I'm Zach. I'm the CEO and co founder of ASec. We are a privacy preserving layer two, using ZK Snox for private transactions and for scaling. Yeah, that's our gig.
00:01:27.050 - 00:01:34.650, Speaker D: Hello, everyone. I'm Angela. I do product at Matter Labs, and we're building DK sync, the first EVM compatible DK rollup.
00:01:35.070 - 00:01:44.960, Speaker E: Hi, everybody. I'm Ed. I'm CEO and co founder at Arbitrum. I'm chief scientist and co founder. Excuse me. I just promoted myself.
00:01:45.970 - 00:01:47.374, Speaker A: You heard it here first.
00:01:47.492 - 00:01:52.480, Speaker E: Yes, and we're building the arbitram optimistic roll up system.
00:01:53.110 - 00:02:01.170, Speaker B: What's up, y'all? Oh, I am Ben, aka weird eth Yankovich, founder and chief musician of optimism.
00:02:01.750 - 00:02:19.830, Speaker A: All right, thank you for those intros. So let's start with a kind of lightning round. I want to breeze through some basic material, not assume a ton of prior knowledge, and then we can kind of get into some meteor questions. We'll kick it off here, if that's cool. What is a roll up, and why does it matter? And how does it fit into the Ethereum roadmap?
00:02:20.250 - 00:02:48.580, Speaker C: Yeah, a roll up is a way of scaling Ethereum or other blockchains in general. The idea is that you take a very large number of transactions and you compress them down into a single Ethereum transaction and doing so make it very, very cheap. Obviously, then the problem is, how do you make sure if you've compressed that transaction down, you've lost a bunch of data? How do you make sure that the transactions are secure, no one's cheated, et cetera. And that's where optimistic ZK techniques come in.
00:02:49.270 - 00:02:54.462, Speaker A: Anyone want to add anything to the basic what's a roll up and kind of why it matters and how it fits into Ethereum?
00:02:54.606 - 00:03:05.474, Speaker E: Sure. The key thing that roll ups are doing is they're allowing correct execution of transactions while minimizing the l one gas footprint of those transactions.
00:03:05.602 - 00:03:05.846, Speaker A: Right.
00:03:05.868 - 00:03:12.250, Speaker E: By using a lot less l one gas to do the same transactions, we allow higher scale and lower fees.
00:03:12.750 - 00:03:25.838, Speaker A: Awesome. Yeah, that's really helpful. Thank you. So if you rewind a couple of years, we weren't sure it was going to be roll ups, right. We were very excited about things like plasma and state channels. Still excited about those things, but more excited about rollups. Right.
00:03:25.838 - 00:03:35.654, Speaker A: So what is it about rollups that have caused them to kind of win and emerge as the primary technology we're using to scale Ethereum? Do you want to jump in, Ben?
00:03:35.722 - 00:04:09.882, Speaker B: Yeah, I mean, I think the answer is pretty straightforward. It's that it's the way to get Ethereum style applications in Ethereum style environments in a way that you expect. So before optimism, I was with a group called plasma group. Then that was what became optimism. And plasma got you more scale. But when things started not becoming available, you had problems with applications like uniswap. So the censorship resistance, the unstoppability, the idea that you can always know the state of a roll up because all of the data of the chain is available is ultimately what made this the thing.
00:04:09.882 - 00:04:21.040, Speaker B: So it's actually not the case that plasma and state channels are gone, but it's the case that the uses that we're seeing on Ethereum today need things like roll ups to consistently behave in the way they expect.
00:04:21.970 - 00:04:24.000, Speaker A: Sweet. Anyone else want to add anything?
00:04:24.370 - 00:04:33.458, Speaker C: Yeah, I'll add a little bit. This is kind of ZK roll up specific, but ZK roll ups are kind of cheat codes for blockchains, the way I think of it, because, by the.
00:04:33.464 - 00:04:37.766, Speaker A: Way, we still haven't introduced what ZK roll ups and optimistic roll ups, so feel free to just start. What's a Zk roll up?
00:04:37.788 - 00:05:21.422, Speaker C: So a ZK roll up is one where you construct something called a zero knowledge proof, which proves the correctness of a giant batch of transactions. The idea is you can slap a tiny amount of data on chain and go like this represents 1000 transactions and all their state updates. And here is a tiny little zero knowledge proof that proves it's correct. Basically, you take all of the work that Ethereum nodes have to do to process transactions one by one, blah, blah, blah, and you delegate it to a single third party that has a lot of computational power available to them. They construct a zero knowledge proof of correctness. And then all the blockchain needs to verify is that proof. So it removes all the gas costs of executing transactions on Ethereum.
00:05:21.422 - 00:05:45.580, Speaker C: But you inherit Ethereum's consensus because of the xeonnoledge proof. It's still the Ethereum nodes, Ethereum smart contracts that act as the validators for your network and so you don't get weaker security assumptions, you don't have additional trust assumptions other than some cryptographic ones. And yeah, so it allows Ethereum to scale without additional trust or weak security.
00:05:47.070 - 00:05:50.630, Speaker A: Cool. Do you want to introduce optimistic rollups?
00:05:50.710 - 00:06:28.630, Speaker E: Sure. The key idea in optimistic roll ups is, again, to move execution and storage off chain. The way that you ensure that transactions are settled back to Ethereum trustlessly is by using a protocol where any party can make a claim about what correct outcome is. Other parties can disagree if there's a disagreement. There is an efficient protocol for resolving the disagreement, figuring out who is right on the merits. So the basic philosophy here is to drive down to a minimum the cost of executing transactions and the cost of doing fraud proofs.
00:06:30.250 - 00:06:42.060, Speaker A: Sweet. So I think it'd be interesting because we have two of you working on optimistic rollups, two of you working on ZK roll ups. Maybe we'll continue down with you guys. What are the key differences between optimism and arbitram feel to jump in?
00:06:44.130 - 00:06:49.358, Speaker B: Whoa, we're trying to stay together. You said there was that to be a winner on ZK versus Oru man.
00:06:49.524 - 00:06:59.090, Speaker A: We'll get there. It's a death match. So we're going to have, what is it called? It's a bracket, right? So two of you compete and one of you wins, and then two of you compete, and then we'll go head to head, final round.
00:06:59.510 - 00:07:22.330, Speaker B: Okay. I mean, to us it's a few things. One, we have the best truly EVM equivalent developer experience on the market today. We have an extremely strong foundation being built out that will give the optimal cost that is possible on roll ups, fundamentally. And we are incredibly focused on scaling Ethereum, both at the level of the technology and at the level of the values.
00:07:23.150 - 00:07:54.290, Speaker E: Okay, I would say all the same things. I think we have that much in common. Right. It's about the developer experience. It's about building the community, scaling Ethereum out in a way that feels familiar to. And so, you know, we're really proud of our community. We're proud of the integrations that we really, you know, I think Ben would say, and I say too, it's about building a community and working within the framework of Ethereum.
00:07:55.910 - 00:07:59.206, Speaker A: Here, here. Community. Yeah. So, yeah, let's move into the ZK side.
00:07:59.228 - 00:08:00.006, Speaker C: Go ahead.
00:08:00.188 - 00:08:49.720, Speaker D: So I actually think we were actually talking about this right before, how Aztec is focusing mainly on privacy and we are focused on building a scalable, not so much focused on privacy, but on scalability. That's fundamentally very different sectors. And there is a paradox when it comes to privacy and transparency. And you sort of have ZK sync for transparency and then you do all your private actions. On Aztec and ZK roll ups are actually much more positive, some in a multi chain world, because we can communicate very quickly and that will allow both protocols and users to have both privacy and scalable, transparent protocols together.
00:08:50.490 - 00:08:54.230, Speaker C: Yeah, sorry, we might have done a bit of coordination before the panel.
00:08:54.730 - 00:08:55.974, Speaker E: We did not.
00:08:56.172 - 00:09:21.550, Speaker C: But yeah, I just echo that. Like the SX gig is privacy. We want to effectively go beyond what ethereum delivers and ensure that we use this new technology neurons proofs to hide user identities so that all your onchain activity doesn't reveal information about your financial lives. And that explodes the potential applications that can use web3. And in my opinion, is fundamentally required to make blockchain mainstream.
00:09:21.890 - 00:09:38.882, Speaker A: So I'd like that we're talking about privacy as well. Privacy is really important. So zero knowledge proofs can be used for scalability and privacy. Right. Would you mind taking a moment to explain the difference? Kind of. Are we talking about the proofs that you guys use? Can they achieve both or do you need kind of like different circuits to do these two different things?
00:09:38.936 - 00:09:41.858, Speaker C: Yeah, you need different. It's the same analytic technology, but applied.
00:09:41.874 - 00:09:42.806, Speaker A: In a very different way.
00:09:42.908 - 00:10:33.378, Speaker C: So the way you can get scalability is you take a very large number of transactions and effectively you compress them and then you construct the zero lodge proof, which basically says, if I were to uncompress these transactions and then process them one by one, then I would get the expected outputs. You can get privacy from that, but it's kind of harder and not trickier. Instead, what you do is instead of compressing your data, you encrypt it and you basically construction all those proofs of scope. If I were to decrypt my data and then execute a transaction and then re encrypt it. Then I would get the outputs expected. The difference is if you want private transactions, then you've got to construct like the user sending the transaction must construct a zero knowledge proof of its correctness. Otherwise you leak secrets.
00:10:33.378 - 00:11:07.170, Speaker C: And if you want to use ZK proof to scaling, then users send their transactions to some third party coordinator, and the coordinator constructs a massive zero knowledge proof that proves the correctness of all the transactions. And if you want both, then the user's got to construct a zero knowledge proof of their transaction and then send that to a coordinator. And the coordinator constructs a zero knowledge proof that verifies a large number of individual user zeros. Proofs, which is nuts, but yeah, that's what we do, but it comes with trade offs.
00:11:07.750 - 00:11:25.800, Speaker A: Excellent description. Thank you. To put things in perspective, what sort of scale are we looking at here in terms of. I don't know, you could describe it however you want to. Transactions per second or multiplier on top of ethereum base layer. Where are we at today and what is the goal in terms of what we're targeting in terms of transactions per second? Jump in anybody if you want.
00:11:29.100 - 00:12:07.830, Speaker B: Okay, I give this feel a lot, but I will say that TPS is probably the most misused term in crypto, period. Take that from someone who has a lot of incentive to say we've got a lot of TPS. Right? So it's extremely dependent on what those transactions are doing and what the property of those transactions are. In general, with roll ups, the data must become available. But it's not even the case for ZK versus optimistic that that's the same data. And in some cases it may actually be better for ZK and in others it may be better for optimistic. So it's tricky to answer that question in many ways.
00:12:07.830 - 00:12:30.670, Speaker B: I think ultimately what it comes down to is basically just looking at the behavior of some particular set of transactions and modeling that out. Right. And when we look at that, we see something like ten to 500 x. Right. And just within the EVM, that set of transactions, you have that much variance. So I hope it's not a cop out, but that's kind of where we're at.
00:12:32.720 - 00:13:00.680, Speaker E: Yeah. So we also try to avoid doing Hollywood accounting about TPS. We tend to think in terms of how many ethereums of capacity our chain has and how we can drive that number up. Yeah. So you're talking depending on what generation of the technology you're talking about, depending on how many of the things in the pipeline you're looking at, how far in the future that number is going to grow over time, and it's going to grow pretty rapidly.
00:13:02.220 - 00:13:09.630, Speaker D: I will say that we are all very far away from our limits and we can handle more.
00:13:11.760 - 00:13:13.640, Speaker C: 1 million TPS.
00:13:13.800 - 00:13:41.524, Speaker A: Thank you. That is the right answer. That's the answer I was looking for. All right, do you want to add more? Okay. 2 million TPS, 3 million TPS. Why have 1 million tps when you could have 1 billion tpS? Okay, so with the introductory stuff out of the way, let's move into some slightly deeper questions. We all like decentralization, it's kind of why we're here.
00:13:41.524 - 00:13:53.704, Speaker A: However, the reality of a lot of kind of roll up technology today is that things like the sequencers, which you mentioned earlier, are actually quite centralized. So how do we move towards decentralizing the layer two? Anyone? Jump in? Feel free.
00:13:53.822 - 00:14:09.752, Speaker E: Sure. Here's how we think about this. Our protocol was designed from day one to support full decentralization, but as we've been rolling it out, we're rolling it out in a careful and responsible way, and that means we have some centralized training wheels.
00:14:09.896 - 00:14:10.252, Speaker A: Right.
00:14:10.306 - 00:14:40.070, Speaker E: And over time we're taking those off. And we have labeled our deployment as main net beta, and we promise to keep that beta moniker on until it's fully decentralized. So we have a roadmap for that. We're talking to our community about that. But we believed and believed that the most responsible way to decentralization was to do it somewhat progressively, but to have the plan and the protocol for it built in from day one.
00:14:43.080 - 00:15:23.792, Speaker C: Yeah, I can add some stuff too. Yeah, like arbitrage. We've got the training bills onto. I think we all do, really. I don't think anyone here would claim that our protocols are thoroughly decentralized yet, and that's a function of the fact that we are building out the tech, focusing on deploying it, getting user feedback on how it works. And the idea is we're going to decentralize later, but later is coming up like a freight train and we need to prepare for decentralization pretty damn soon. And I think it is going to introduce some unique challenges that other layer ones don't necessarily have, particularly on the DK side, because you have problems with xerox proof construction is really expensive.
00:15:23.792 - 00:16:31.320, Speaker C: So not many entities are going to be performing this role. And you have a problem of infrastructure centralization where if they're all using the same cloud service provider, then say, well, hey, if this is a genuinely permissionless, decentralized network that you can't control. Some people are going to do politically awkward things on it and this could violate the terms and services of cloud service providers. These incentives don't really align. And so I think one of the key goals for the ZK part of the industry is to work on how do we decentralize provers so we're not reliant on web two infrastructure because that's quite a dangerous road to go down. We do have a plan for this effectively kind of taking these very very expensive knowledge proofs and then splitting them up into like 1000 little subcomponents that can be handled by small approvers. But it's not going to be quick to develop and implement because, well, because we're treading you ground here where you're kind of adding this very complicated role, this proof constructor into like a decentralized network and you need to hit scaling and throughput targets.
00:16:31.320 - 00:16:44.370, Speaker C: Yeah, I guess I would say I wouldn't be surprised if it's a while before everything is genuinely fully decentralized. As know, governments cannot turn the tap off even if they tried. But we're getting there.
00:16:45.540 - 00:18:07.130, Speaker B: Okay, if TPS is the most overused or misused word in crypto, I don't know if number two is decentralization, but it is up there, right? And there's a lot of different aspects, just like aspects of transactions per second, there's a lot of aspects of decentralization. So yes, everyone on the stage has training wheels, upgrade keys, blah, blah, blah. I think another interesting thing to look to is even when that roadmap is fulfilled, what are the other components of centralization, right? And what's fascinating is that when we talk about scalability, when we talk about pumping a lot of transactions, in sum through a system that opens more opportunity for centralization in some ways at an incentive level, right? Look at what happened to bitcoin mining, right? At first you could have done it on your laptop, then you needed a gaming rig, then you needed an ASic that was a little usb stick, now you need a warehouse and under the table handshake with a power plant, whatever. So I think the same thing. We're at the early stages of seeing in layer twos and in scalability. And honestly I think it's too early to say in some aspects, right? There's elements in the ZK world where the long term aspects of proving and that cost will play a factor. On the roll up side there's the elements of block production and whether we want to parallelize things and how we're going to go about doing that.
00:18:07.130 - 00:18:12.970, Speaker B: So I don't know, it's just a ramble. But be wary of decentralization as a term too.
00:18:14.940 - 00:18:18.316, Speaker E: Let me just urge you, if you're really interested in this issue, come and.
00:18:18.338 - 00:18:19.336, Speaker A: Talk to hold the mic closer.
00:18:19.368 - 00:18:20.104, Speaker E: Out of band.
00:18:20.232 - 00:18:21.688, Speaker A: Hold the mic a little bit closer.
00:18:21.784 - 00:18:22.428, Speaker C: Oh yeah.
00:18:22.514 - 00:18:41.510, Speaker E: Let me just urge you, for those who are really interested in the nuts and bolts of this issue, come and talk to all the teams and ask about the details about what their plan is for decentralization. Will I be able to run a node in a year and all those sorts of questions, right? And just dig into it, because as Ben said, it is a complicated issue.
00:18:42.360 - 00:19:15.228, Speaker A: Great advice. Any final thoughts on decentralization? Oh no, we're good. We'll move on to another topic. So one of the wonderful things about Ethereum, l one as a base layer is composability of applications, right? The fact that you can build applications on top of other applications, permissionlessly combine things, do very creative things, touch a bunch of underlying smart contracts in a single transaction. And one of the challenges of l two, of course, is that to some extent it breaks composability. Things become more asynchronous. I'm wondering how you guys all approach composability.
00:19:15.228 - 00:19:17.330, Speaker A: What your thoughts are on this. Jump in anybody?
00:19:22.690 - 00:20:17.906, Speaker C: Yes, I think. Why has Ethereum become so popular? Why has it become like the dominant blockchain where so much liquidity is pooled and it's composability. Composability. Composability. You can build a smart contract that connects to other smart contracts in a permissionless way and build up a modular framework of defi apps and all sorts of insane kind of creativity that you just can't get in a system that does not have this ability to just use other people's protocols as building blocks? And one of the problems with layer twos, maybe I shouldn't say this, but one of the problems with layer twos is you break composability. Because if you migrate a protocol to a layer two, then that might work for the protocol that you're talking about. But then all of the other protocols on layer one that depend on a chain of smart contracts, right? They can't easily migrate, import their sec to layer two.
00:20:17.906 - 00:20:56.730, Speaker C: And so you have this enormous stack of dependent applications where migrating anything except the entire sum of them all will break them. And that sucks. And this is where I'm going to shill ZK rollops. And one of the core strengths of ZK rollops is instant finality. Because on chain you're verifying a zero proof of correctness. You don't need to wait for a large interval of time for a fraud proof to go through before you can withdraw. And that means that what you can do is you can have your layer two talk directly to layer one in an atomic fashion.
00:20:56.730 - 00:21:28.070, Speaker C: From layer two you can emit transactions saying talk to layer one, talk to uniswap, do a trade. That trade gets executed at the next roll up block and the proceeds get kicked back into the layer two. And that can happen atomically. And so this is one of the ways that we're tackling composability. We're trying to leave as much of the d five protocols of the amms, et cetera, on layer one and using d five, pooling basically batching user aggregations together on our layer two to make the costs cheaper. But we keep liquidity on layer one and it doesn't break composability.
00:21:29.530 - 00:22:19.250, Speaker E: So I think the most important thing about composability considerations between l two and l one or across different l two s is that you can have a form of composability. But in all of these cases it's a different kind of composability than you can have with Ethereum. Because Zk provers run asynchronously from the l one ethereum chain, optimistic validators run asynchronously from the underlying l one chain. And so you can have composability, but it's asynchronous composability, and that is a different model. Right. So in the ethereum community, in the Ethereum community you have a whole set of practices and programming methods that have developed around using synchronous composability. And I think the same thing is going to happen around asynchronous composability.
00:22:19.250 - 00:22:33.322, Speaker E: Just like the difference between local programming in sort of web two versus programming across a network where things are inherently asynchronous. Right. And that's the environment you're going to be in. And I think we are all in the same boat as far as that goes.
00:22:33.376 - 00:22:36.318, Speaker C: I disagree. Sorry, but I do.
00:22:36.484 - 00:22:41.470, Speaker E: Your prover runs synchronously with the l one miners. Yes or no?
00:22:41.540 - 00:23:02.280, Speaker C: There is a difference between ten minute asynchronousity and seven day asynchronously. And we have to be just acknowledge that with a full transaction throughput the azure network, you can produce a block every 10 minutes with great attraction. There's no reason why we can't paralyze that down and get it down to say 5 minutes or even 2 minutes.
00:23:03.610 - 00:23:04.882, Speaker E: But it is asynchronous.
00:23:04.946 - 00:23:40.530, Speaker C: Yes, but you're talking about a very, very small time delay. Yes, that means that some highly latency sensitive applications won't work. But then again, if you're going to call that asynchronous, then the Ethereum blockchain is asynchronous because you got to wait 10 seconds for a block to be produced before you send a transaction. So I don't think the term asynchronous here is particularly useful. What we need to consider is the time taken between your transaction being constructed and achieving finality on layer one. And the fact that ZK rolls can make it extremely small means that we can interact in a composable manner with layer one smart contracts in a way that optimistic rollups simply cannot.
00:23:43.030 - 00:24:29.274, Speaker B: Okay, I kind of have a hot take here, which is almost that I disagree with both in some sense. I agree with parts of what both of you are saying, and I disagree. One of the most fascinating things to me, as the roll up centric ethereum roadmap has sort of emerged, has been a loss of a narrative that was present in ETH two, phase two which stated that we are not going to lose cross shard composability. And yes, it is going to be cheaper in these systems to send asynchronous calls, and people are going to desire that. And clearly, I definitely agree those programming paradigms will emerge. But I also think that it's the case that synchronous composability will have an economic value in these systems. And we see that in things like mev and block production.
00:24:29.274 - 00:25:11.870, Speaker B: And a lot of what we're spending our time doing now is now that we've built the EVM rollup, we need to shard the EVM roll up. I will show the talk that I just gave yesterday, which talks a little bit about this. I would also show the Vitalik endgame post, which talks a lot about this. And fundamentally what I think we will all need to do is develop asymmetries between block production and block verification, because large synchronous block verification will have fundamental economic advantages that come from the synchronous kind of composability. So I definitely agree asynchronous is going to be cheaper. We'll have it, we'll have a lot of paradigms. But I also think that there's going to be economic value there that we can't.
00:25:13.730 - 00:25:28.180, Speaker A: Here, here. We're almost out of time. I would like to give Angela a final word. Any final thoughts on any of the topics we talked about or anything else? Any of the topics, anything you want to talk about? We have 2 minutes.
00:25:30.870 - 00:26:27.138, Speaker D: I want to talk a little bit about the amount of scalability that we will all be able to achieve. And I think that something that is not said is that fundamentally. Well, actually, maybe I should start with the. I should start with this because it's more simpler. The fact that ZK roll ups are able to separate transaction validity and data availability, and that allows us to create, to sort of really quickly bypass the most expensive resource on Ethereum right now, which is call data and get sidechain like fees immediately. And from using the exact same architecture that we use for ZK rollup, everything is the same. You just publish data availability on a spectrum of data availability solutions.
00:26:27.138 - 00:27:04.530, Speaker D: You can either keep it yourself, you can rely on proof of stake networks to keep it. You can rely on data availability focused chains such as Celestia. There are very cool designs where you can actually create one system across a spectrum of data availability. And I think that's really powerful to combine sidechain users finally in the same system and as the whales, and we can all be put on the same platform and participate in the same system. I think that's really important for fairness.
00:27:05.990 - 00:27:15.670, Speaker A: Very good point. Thank you. Modular blockchains are really interesting. I've been super into this recently. We have two more minutes. I guess so, actually, any other final thoughts? We can kind of. Do you have any final thoughts?
00:27:16.010 - 00:27:17.720, Speaker C: Let the optimistic folks speak.
00:27:20.010 - 00:27:20.758, Speaker A: Anything?
00:27:20.924 - 00:27:28.646, Speaker C: I'm sorry? No, just saying because. Is there anything you folks want to add? I feel it'll be a bit unfair if I followed Angela.
00:27:28.838 - 00:28:13.400, Speaker E: Sure. I mean, I think at the end of the day, all of us are pushing to scale Ethereum. We're going to find out over time which technology configuration can drive up scalability, drive down cost most effectively over time. And these questions interact with questions of how Ethereum will evolve. What is the underlying cost structure going to be? Our thinking has always been aimed sort of at the long run, and trying to get to the point where we believe the long run, lowest cost, highest scalability will live. Some folks up here probably disagree with that, but that's been our north star in thinking about our architecture over time.
00:28:14.430 - 00:28:16.330, Speaker A: Cool. Ben, do you have any final thoughts?
00:28:18.190 - 00:28:52.920, Speaker B: Yeah, I think my final thoughts would be that I agree with what Ed is saying, is that we're all pushing scalability forward. And I think that one of the most narrow sighted things or short sighted things that we can do today is think about these systems as homogeneous. So actually, I do think there are some ways, like the composability thing, where we don't think of them as homogeneous enough where we want to go. But I think fundamentally the demand and what blockchain applications are going to be doing and what they need from scalability as a result will be different. So I think we're at time.
00:28:54.010 - 00:28:57.414, Speaker A: All right, did you want to jump in with anything before we end?
00:28:57.612 - 00:29:24.720, Speaker C: Just something very briefly. I think we're all kind of on the same. It's fun to debate, but we're all on the same, really have the same goals here, same team scale. Ethereum effectively break the blockchain trilemma at the layer two level and make sure that users can enjoy cheap transactions without compromising on security. And we all have very, very different ideas on how to achieve that. And time will tell what works or if any of us are right.
00:29:25.330 - 00:29:34.426, Speaker A: Amazing. Totally agree. So we'll see you guys back here next year for a new update of where roll ups are at that point in time, and I'm sure there'll be way more progress to report. Thank you very much to the panel.
00:29:34.458 - 00:29:35.198, Speaker B: Thanks, guys.
00:29:35.364 - 00:29:35.900, Speaker E: Thanks, everybody.

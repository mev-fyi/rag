00:00:00.330 - 00:00:21.918, Speaker A: Hello everyone. Well, I'm Eduardo, his sector. We are not Jordy. Jordi is over there. We switched to our talk, but mainly the topic is the same. We are going to talk about how the ape 44 is going to affect roll ups. And as most of you know, this is going to be the end game for cost, transaction cost.
00:00:21.918 - 00:00:58.800, Speaker A: So we are going to give kind of an overview what that means for secret roll ups. I'm going to make a kind of a summary and put some numbers in the table. And later on ector is going to explain how this affect to our roll up. So let's start by talking about some key points about the four. A four, four. The first thing to know is that right now, currently Sigarolo are using call data to publish transaction data or state divs. And now we are going to switch to a new paradigm in which we are going to start to using blobs for publishing this data.
00:00:58.800 - 00:01:43.882, Speaker A: So each blob it has available 128 data. We are going to have six blobs per block. And one important thing especially for node operators is that the blob is going to be only available during 18 days. Mainly this is to not blow up the hard drive space of validators. And that means that probably we are going to see how archival blocks provider start to happening. Because if you want to have this data after this time, you need to ask to this provider for the data. An important thing to mention also is that we are going to move from 17 gas per byte to three gas.
00:01:43.882 - 00:02:23.820, Speaker A: And mainly this is the main benefit of this. And another important thing to mention is the fee market. The fee that you are going to pay using blobs is different to the fee that is computed on the execution layer. Here we have schema, basic schema, how this look like we still have regular finite transactions as you can see here. But now we are going to have a new type of transactions, the data transaction that contains a blob. And these blobs can be verified on chain due to the commitment. Ector is going to provide more information about that.
00:02:23.820 - 00:02:55.598, Speaker A: So yeah, the first thing to know when we talk about data cost of transaction is the prover. Usually people believe that the proverb is about a neck antennas of cost. But I've been talking about this since last year. Proverb is not the bottleneck anymore. You can repeat with me, prover is not the bottleneck. As you can see, the cost of a transaction is quite negligible. And this is some numbers of our current proverb.
00:02:55.598 - 00:03:33.930, Speaker A: It takes two minutes to make a proof of a batch. A batch is more or less 500 transactions and we are going to add a lot of improvements on our proven system like backups and other things. That probably is a topic for another talk, not for today. But that is the key point that the proverb doesn't represent the most part of the cost of a transaction. So what are the costs of a transaction then? So we have four costs here. We have data availability, we have sequencing, we have prover and we have aggregation. Data availability is paid for every byte posted on chain.
00:03:33.930 - 00:04:21.390, Speaker A: Sequencing is when you publish the transaction on l one and you need to pay this constant l one transaction, but it's shared among all the batches that you are submitting to the network. Then the proverb cost is constant hardware cost and is for each proof computed. And finally we have the aggregation that is also constant, like the sequencing and shading among all the sequences aggregated. Don't get confused by this scale we will see later on. But it's just kind of glimpse that the data availability is the most important part on these costs. So this is our current numbers. Before going to the 44 four we are paying 16 gigs byte call data.
00:04:21.390 - 00:05:13.210, Speaker A: And well as, as we previously mentioned, we are going to use 128 kb for sequencing dispatches. Internally in the CKBM we have the CK counters mainly. This is what limit us to group transactions. And the thing is, with backups in the coming months we are going to remove these counters, but at the end it's just a way to make groups of transactions that are being able to be proven. Taking a look to this number, as you can see for instance 350 e transfer is around thirty nine k bytes per batch. Well you can see here that depending on the type of transaction, we need to submit more or less data on chain. And finally, you can see more or less how many transactions we can include in just one blob.
00:05:13.210 - 00:05:58.202, Speaker A: So for instance, we can submit the data for 1127 transactions in the case of eight transfers, or around 350 in the case of uniswaps. It's important to mention that obviously, well the price of eth for these estimations is well some time ago. But obviously the price of ether has an impact on the price of the transaction on l two. So let's put real numbers here, right? This is what we are paying currently. Currently we are paying the 95% of the cost of submitting transaction to l one because of the data availability. If you take a look, sequencing is just a 4%. The proverb is enabled and also the aggregation.
00:05:58.202 - 00:06:52.590, Speaker A: So this PI represents more or less where are the costs and why this is important. The thing is, with the 44 four and this ethereum roll up centric romap that we started in 2020, we are decreasing this around three, seven times less. And that is why this is the end game for transactions, cons for roll ups. So, for instance, well, it's hard to see, but I would try to explain it. This is an script of the blob scan, I will say, in which you can take a look to the blobs that are happening. This is, for instance, something in Sepolia, and here even it's hard to see. But mainly we have grown five blobs.
00:06:52.590 - 00:07:24.614, Speaker A: One is not in the screen. And the first thing that you can see here is the free market price. The thing is, if you include three blobs in a block, that means that the price is going to be constant. If we include more than that, the gas price is going to increase. And if it's less than three, the gas price is going to decrease. Now, it's hard to know what is going to be the price. That depends on how many roll ups are using blobs.
00:07:24.614 - 00:07:53.780, Speaker A: But with Petrotagar beginning, the price is going to be really low. Another important thing to see here is that if you take a look to the blob as call data gas, that is this thing, you can see that it's seven times less than if you use call data. And that is why it's so important, this for roll ups. And now Hector is going to give you more details about how this affects our system.
00:07:55.050 - 00:08:36.462, Speaker B: Hello. Okay, let's start with the funny part. So, to be slightly more specific, I like to see the atata plop as a vector of field elements, each of which are over the BLS scalar field order. And the vision I like more is seeing. These elements are being evaluations of a given polynomial under some sets of prefined values. In this particular case is a set of rules of unity. But also it's important to notice that from rel one, we are not going to be able to access any elements in this vector.
00:08:36.462 - 00:08:55.458, Speaker B: But the only thing we are going to be able to retrieve from any smart contract is through a new opcode, which is called blob hash. And it will basically give you the sha 256 of the commitment of the polynomial that represents this vector.
00:08:55.634 - 00:08:56.118, Speaker C: Okay.
00:08:56.204 - 00:09:29.490, Speaker B: And only with this information, we need to be able to prove, or to be, to prove, that what we are proving off chain in l two is the same, that what you can retrieve in L1. Okay, so the main issue here is that in l one, you are forced to play with what you have. In particular, you are forced to play with the KCC commitment over the BLS. But in L two, we do whatever we want. We do whatever fits better for us.
00:09:29.560 - 00:09:29.794, Speaker C: Okay?
00:09:29.832 - 00:09:42.886, Speaker B: And in particular, we are not using the KCC commitment, but we are using our proven system. So in some sense, we have to fix the inconsistency between what you have in l one versus what we do in L two.
00:09:43.068 - 00:09:43.606, Speaker C: Okay?
00:09:43.708 - 00:09:52.330, Speaker B: And we will see that thanks to a new precompile that will be introduced in this aip, we will be able to fix this inconsistency.
00:09:55.070 - 00:09:55.578, Speaker C: Okay.
00:09:55.664 - 00:10:11.070, Speaker B: And well, in particular, the trick is well known to fix this inconsistency, which is called proof of equivalence protocol. And basically the idea is to prove that what you have committed on chain is the same as what you commit off chain in l two.
00:10:11.220 - 00:10:11.534, Speaker C: Okay?
00:10:11.572 - 00:10:49.030, Speaker B: So basically approver sends to a verifier the two commitments for sure. This protocol will be non interactive at the end. I think it's more intuitive seeing this interactive. Then the verifier will send unpredictable and random point. And then the proverb, what it has to do is to prove that the valuation of the polynomial of both committed polynomials under this point are the same in both cases. Okay, that's why he's sending back the valuation and both proofs. Okay, I'm trying to be slightly more precise in how we are going to work with the Gip.
00:10:49.030 - 00:11:24.262, Speaker B: So basically the idea is that first we are going to compute off chain everything that we need for proving the correctness of the KCC commitment. So basically we are going to be computing the random point as the linear poseidon or the information inside the blob. This is all off chain. And then we are going to compute the proof and the evaluation. And this is the information that we send on chain, at least in the first part of this data flow. And basically the smart contract, what we do in the first instance, when we sequence all the batches, is checking that this information is correct.
00:11:24.396 - 00:11:24.694, Speaker C: Okay?
00:11:24.732 - 00:12:20.540, Speaker B: So it's like a fish guarantee that what is on chain is what we like to prove in the next step. Okay, and in the next step is where we draw all the warlocked in the l two. Okay? So it's more or less the same. But basically we are going to use our approving system to prove that z. So the random point is well computed, meaning that is the linear positum of the information inside the blob. And not only this, but also that evaluation of the polynomial that represents the blob is precisely what we have verified in step one. Okay, so basically, if in the next step, when we prove that the batches are correct, we are able to verify this proof, that will mean that not only that the evaluation is correct, but also that it concise with what we thought in the previous step.
00:12:20.540 - 00:12:57.170, Speaker B: Okay, let's see now the proving architecture. Okay, so this is more or less the summary of the architecture that we have from the proving perspective. Notice that, well, basically what we do is we prove the correctness of one batch of transactions. But not only one, but using aggregation, we're able to verify, just by sending one transaction, just by sending one proof on chain, that all the transactions inside all the batches are correct. And we basically aggregate all the proofs in what we call the aggregation stage.
00:12:57.330 - 00:12:57.654, Speaker C: Okay?
00:12:57.692 - 00:13:25.150, Speaker B: And this is what we have right now. But now with the AP 44, we will need to include the proof of the block, which is the proof of the coordinates of the valuation. And in particular, what we are going to change from the previous architecture is we are going to cut off after computing all the aggregations of all the proofs of all the batches. And in this point, we are going to introduce the proof of the blob.
00:13:25.730 - 00:13:26.574, Speaker C: Okay.
00:13:26.772 - 00:13:54.450, Speaker B: We are going to introduce the proof of the blob, which is the proof of the coordinates of the polynomial evaluation. And we are going to aggregate this proof with the output of the previous aggregation. Okay, this is what we call our inner block proverb. And then not only we are not going to stay that, but we are going to also aggregate the proof from one blob of a set of batches to proofs of other blobs of other set of batches.
00:13:54.610 - 00:13:54.934, Speaker C: Okay?
00:13:54.972 - 00:14:03.610, Speaker B: So at the end, we are just going to send up one transaction to l one, proving the correctness of many blobs that points to many batches.
00:14:07.710 - 00:14:08.170, Speaker C: Okay.
00:14:08.240 - 00:14:26.690, Speaker B: And, well, just going a little bit inside the details. These are going to be the public inputs that we are going to add to the inner blob proverb. Okay, there are more of them, but just to mention a few. Relevance. We have the blob estate root and the newest state root. Blob estate root. Sorry.
00:14:26.690 - 00:14:38.926, Speaker B: And we also have the accumulated input hash, which is important because here, well, the accumulated input hash, basically it's like what relates one blob to another one, like in a blockchain.
00:14:38.958 - 00:14:39.118, Speaker C: Okay.
00:14:39.144 - 00:15:10.510, Speaker B: We are going to relate the previous blob with the next one. And in particular here, we are going to be able to decide if we would like to go for the AIP four or not. Because, for example, let's say we have a period where the blob cost is much expensive than the call data price. So here we will be able to decide if we are going to keep putting things inside the blob, or we prefer to, for a short period, come back to the call data solution.
00:15:12.930 - 00:15:13.438, Speaker C: Okay?
00:15:13.524 - 00:15:31.122, Speaker B: And in the near blob, we have all the public input related to the blob itself. But then here in the order blob part, we have public input not only related to the blob, but also to the set of patches that you are approving.
00:15:31.266 - 00:15:31.814, Speaker C: Okay?
00:15:31.932 - 00:15:47.610, Speaker B: Here, for example, you can see that we again have the block accumulated in push highs, but we also have the state route, the new one and the old one. It's basically the state changes that you encounter when you process all the transactions inside the blob.
00:15:50.610 - 00:15:51.070, Speaker C: Okay?
00:15:51.140 - 00:16:28.582, Speaker B: And, well, in order to prove all this stuff, our solution was to create a processor that is able to interpret all the, let's say, stage changes that are done due to the transactions inside the batch, okay? So basically we have like a gigabrain, which is what we call our GKVM processor, which is elbow. Well, we design it in a distributed manner, meaning that we are not encoding all the logic inside the same processor, but we are distributing them among different comprocessors.
00:16:28.646 - 00:16:28.922, Speaker C: Okay?
00:16:28.976 - 00:17:32.238, Speaker B: For example, we have a part that deal with arithmetic operations. We have another part which deals with binary operations. For example, let's say that what is able to do and what is not able to this main processor is thanks to the ROM part of this processor, okay? This was the old processor. But remember that I tell before that the blob proof is in some sense independent to the batch proof. So we needed to create a new processor, which in principle, it can be thought as a subset or as a subset of the original processor. So, for example, in the left side, we had some specific machines or a specific coprocessor to deal with padding operations and clip operations. And here in the new processor, which will be much shorter than the original one, we will have just a subset of the coprocessors that we had in the original one.
00:17:32.324 - 00:17:32.622, Speaker C: Okay?
00:17:32.676 - 00:18:06.790, Speaker B: In particular, the arithmetic state machines will all I need to deal with much less equations than the original one. Well, and finally, just to give you a glimpse of how we are doing these things, this is like the bunch of the computations that are encoded in the ROM of the new processor, okay? And in particular, as I have explained before, the main objective, at least for now, of this new processor is proving the evaluation of a polynomial.
00:18:07.290 - 00:18:07.714, Speaker C: Okay.
00:18:07.772 - 00:18:30.270, Speaker B: And here in the upper right side we have the formula for computing this evaluation. And here we have the assembly code that is performing basically this evaluation. As you can see, it's evaluation of a polynomial of degree 4096, which is the size of the blob.
00:18:34.710 - 00:19:02.854, Speaker A: Yeah. Finally, I would like to explain a little our roadmap. This is not a commitment, it's just our intentions. Just to make that clear. Well, as you can see, right now we are onboarding cdks on the new aggregation layer. We can talk about that in the booth we have promoting that a lot. We are working on the ape four four currently, and also in parallel we are working on the rigong RPC.
00:19:02.854 - 00:19:40.982, Speaker A: That is going to happen very soon. And also we are going to check our infrastructure to add Igong as a new sequence of our network, with the idea to increase the tps of the CKBN, but also of the cdks. We are also working in p two and backups variable degree composite polynomial. That are the thing that I mentioned before in regard of improving proverb performance. And we are developing the aggregation layer b two, aggregation layer b three. And especially, also important and interesting for this talk is data compression. We have showed how easily we can decrease the cost of transactions by a factor of three or seven or something like that.
00:19:40.982 - 00:19:59.860, Speaker A: But we are also going to add data compression to the data that we are submitting to the blobs, and with that we can achieve bigger factor compression and cheapest transactions. So yeah, mainly this. Thank you for coming and if you have any question, you can find out. Thank you. Thank.

00:00:07.760 - 00:00:47.105, Speaker A: Hey everyone, I'm Neil and I'm the founder of Eclipse. And what we're building with Eclipse is It's an Ethereum layer 2. And the goal is that we're making the most performant L2. So while other L2s are trying to be the most EVM compatible or focusing on ZK proving the entire chain, right now our focus is just maximizing throughput, minimizing latency. And the way that we're doing that is we forced Solana the Layer one blockchain, which is a highly performant Layer one. We added in fraud proofs, we're adding in data availability, sampling and other verifiability features, and we're turning Solana into an Ethereum Layer two instead. So that's what Eclipse is building.
00:00:47.105 - 00:01:12.755, Speaker A: And this talk is all about parallel VM L2s. And we're not the only one. There's fuel, there's Mega Eth is coming up. Some of y'all might have heard about that. And this introduces new advantages to the Ethereum L2 landscape, but also new challenges. So just to rephrase what parallel execution is, parallel execution theoretically could be applied to any vm. Even the EVM could be parallelized.
00:01:12.755 - 00:01:56.197, Speaker A: And there's folks like Monad and Mega Eth that are working on that. And the way that you would do that in practice is you'd optimistically execute rather than knowing the reads and writes upfront like for other VMs. The difference is that VMs like the Solana VM are built from the ground up for the purpose of parallelism. So that means that in the wire format itself, it mentions which accounts are being accessed, and that means that the scheduler can more effectively optimize the execution of transactions to leverage the parallelism. So that's one advantage. Another optimization Solana makes is that it doesn't update the global Merkle tree after every transaction. So this and many other reasons are why Solana's virtual machine is essentially optimized for parallel execution.
00:01:56.197 - 00:02:44.421, Speaker A: And like I was mentioning, there's other folks that are working on similar problem spaces. And one thing that parallel execution enables is new types of fee markets. So here I'm just going to define local fee markets briefly. And it's that for each account or each resource that's being accessed, you might price that differently rather than using some global FEES, such as EIP 1559. So EIP 1559 has some target resource utilization, which is essentially the block size limit, and they'll adjust how much each transaction costs in order to meet that target resource utilization. Solana, on the other hand, it's very rare that transactions actually hit the block limit. But in the case that there is a massive NFT mint or something, they want to make sure that those transactions don't congest the entire chain.
00:02:44.421 - 00:03:37.345, Speaker A: And this means that other transactions like defi swaps or maybe games that are running on chain can still pass through freely and they won't be impacted by those high transaction fees. And the way that that works in practice is they essentially price each smart contract separately. And that's how it works, ideally. Instead they have this approximation where they basically make the assumption that the Solana executor has four cores and then they prevent any specific transaction from using more than 25% of a block. So they're basically assuming that let's say there's a big NFT mint, then that would eat up one of those four cores, and the other three cores will continue to process transactions freely. And that means that if a transaction bids maybe a penny or a fraction of a penny, then they don't have to compete with those NFT mint transactions that are fully occupying some other core. So that's a high level on how Solana's local fee mechanism works as it exists right now.
00:03:37.345 - 00:04:11.475, Speaker A: It's not built into consensus. Instead it's just a feature of how the scheduler is implemented. There are a couple of quirks in how that's implemented, and we'll get into that later, but that's essentially what Solana is building toward. So there's other advantages. This is not really something about parallel runtimes, but the reason why I mention it here is that parallel runtimes often hit this bottleneck very quickly before execution becomes a bottleneck. And this is the issue of stake growth, which is frequently cited in the Ethereum community. And stake growth is it's solved in the Solana virtual machine in kind of an unusual way.
00:04:11.475 - 00:04:57.167, Speaker A: And that one, the Merkle tree is not globalized, is not Merkleized after every transaction. So that's one advantage. And the second is just the way that things are accessed. So because everything's specified upfront, so the reads and writes are specified in the wire format, you can fetch all that information upfront, and therefore you don't have to repeatedly make these disk accesses throughout the execution of a program. So in general this is more efficient than, for example, the Ethereum. For the evm, you have these dynamic memory accesses that are frequently accessing new parts of state, and then that's going to substantially bottleneck execution because you have to make disk accesses. And if you look at the classic memory hierarchy, SRAM is 10 times more efficient than DRAM, than DDRAM and hard drive accesses.
00:04:57.167 - 00:05:52.617, Speaker A: So you really want to minimize any accesses that go all the way to ram, or even worse, all the way to disk space. So overall, this is all to say that parallel runtimes can get cheaper fees for users. And the way that L1s typically enable that is similar methodology, they reduce those binding constraints, such as the number of cores that are being used. Let's say there's four cores being used and a transaction tries to request a fifth core, then obviously you'd have to charge a premium and that transaction is now competing with all those other transactions. So in general, it's binding constraints that cause price to go up. So my point here is that because these beefier paralyzed runtimes just have higher resource requirements, that means that the costs in general are lower. And then the other advantage the layer one blockchains have is that they can inflate the token, which obviously is a L2 we can't do, given that at launch we won't even have a token, we're just using ETH for gas.
00:05:52.617 - 00:06:32.377, Speaker A: But theoretically that's another way that you can make transactions cheaper too. So this is all to say that parallelized L2s, given their beefier hardware requirements, can offer lower fees that are sometimes even competitive with the highly performant L1s that exist. So here I just want to give a brief comparison between parallel runtimes and single threaded runtimes. And I'm just using the EVM as an example. Of course, like I mentioned, you could parallelize the evm, but I'm just looking at existing runtimes like Arbitrum, Optimism and so forth. And on most axes the parallel runtime is superior. Except hardware requirements obviously imply higher costs for running that hardware.
00:06:32.377 - 00:07:02.157, Speaker A: So that's a downside. Of course, that cost is amortized across all transactions and all users. State growth Typically parallelized runtimes like Fuel Move SVM have optimized state growth in ways that single threaded EVMs have not. Yet there's safety advantages. Move is probably the most popular example. With their type system, the SVM has some restrictions on reentrancy. Any kind of re entrancy has to be self re entrancy, meaning that if it's not possible to have a smart contract that.
00:07:02.157 - 00:07:33.445, Speaker A: Let's say if smart contract A that invokes B that then invokes A again, the runtime will prohibit that from being executed. Whereas smart contract A can invoke smart contract A. Again, that is allowed. So that's just one minor reentrancy protection. There's other types of safety protections. And then for proving this is an SVM specific thing because it's register based, a lot of existing ZK VM literature typically is based on register based VMs. So this is one reason why the SVM is slightly simpler to prove.
00:07:33.445 - 00:08:04.595, Speaker A: The biggest downside is that there's just a ton of spam. And this is making it's partly an issue with the implementation of the fee market. And that's what we're going to be talking about for the rest of this presentation. But the obvious downside of lower fees is that the griefing cost is much lower. Anyone can just start spamming your chain if there's some incentive to do so. They might be airdrop farming, they might be trying to claim an NFT mint. And at which point you'd figure that there's some optimal bidding mechanism, like an auction mechanism that can remove the incentive to spam.
00:08:04.595 - 00:08:37.445, Speaker A: But in practice, a lot of these parallel runtimes have not implemented something like that. So this is just reemphasizing that core issue that this is probably the biggest issue that Solana has grappled with. And this is what caused 7, 8 outages in 2022, or maybe it was 2023. But this is basically that there's a few factors involved which I'll get into here. One is that it's a low cost like I was talking about. The second is quirks on how the scheduler is implemented. So one factor there is just straight up network jitter.
00:08:37.445 - 00:09:06.135, Speaker A: The Solana blocks are constructed first in, first out. So as they're received, the leader starts including those transactions in a block. But that's not great because it means that if you submit two transactions, one after another, if transaction B arrives before transaction A, then it will actually be included first. So it's not a property of the fee market. If you look at like Arbitrum, for example, they have fairly short block times. But that's not an issue because blocks are constructed at the end of the block time. I think it's like one second block times or something.
00:09:06.135 - 00:09:48.701, Speaker A: Whereas Solana blocks are constructed continuously, so that first in, first out structure means that network jitter can actually impact the ordering of transactions. And that lead that incentivizes you to submit as many transactions as possible so that you're most likely to get at the front of the pack. And then there's also like jitter within the scheduler itself. So even when two transactions are received, it's not, it's not guaranteed what core each transaction will be assigned to. So let's say you have like a NFT mint transaction and a defi swap. Those might be assigned to the same core, at which point they're competing with each other in terms of fees or they might be assigned to different cores. And it's, it's deterministic, but it's not predictable for the average user.
00:09:48.701 - 00:10:33.403, Speaker A: And as a result folks end up bidding very high amounts and might still not get included. And then this last point is just, this is an issue with just free markets in general. But when resources are mispriced, such as the price to lock an account, then that can lead to griefing attacks. And we've seen that in practice on Solana. These are just a bunch of other competing goals. And a lot of this comes from like Elaine Chee, Tim Rothgarden, and I'll just talk about a few of these just because no need to get into all of them. But desicc or dominant strategy incentive compatibility is probably the most important one, which is that if someone bids $5 to get their transaction included, then they should be willing to pay up to $5, no less and no more.
00:10:33.403 - 00:11:15.995, Speaker A: And that's a useful property because it means that we can quickly audit and easily audit whether a transaction fee mechanism is roughly operating correctly. And there's immediate consequences of that. That means that if someone bids X dollars, you can't always charge them X dollars because then that's an incentive for them to under bid. And that's essentially what first price auctions do, which is why first price auctions have all these game theoretic issues with them. Another one is MMIC or Myopic Miner incentive compatibility. So this is about whether the block producer is incentivized. If, if the block producer is acting economically rationally, are they incentivized to follow the rules of the transaction fee mechanism? That's essentially what MMIC is optimizing for.
00:11:15.995 - 00:12:00.935, Speaker A: Again, a lot of these parallel runtimes have not achieved the MMIC property. And then the last one is welfare maximization. And in Ethereum world that's very well defined. It's just maximize the utility of the transactions minus some well defined measure of cost. For parallel runtimes like Eclipse there are these subtle. I'd argue that the objective function is fundamentally more complicated because there's this informal notion that we also want to support uneconomical use cases even if there's a defi, like if there's some meme coin where people are willing to pay a lot to trade that, we still want to make sure that games or uneconomical applications can still flow through. Because if you don't have that property, then you lose a lot of the benefits that the parallel runtime is seeking to achieve to begin with.
00:12:00.935 - 00:12:57.699, Speaker A: So I'm going to skip this slide just because it goes into just the way that Solana vs Ethereum price things as they exist. Right now, Solana has some base fee which does not account for the amount of gas or compute units which are used. Ethereum's base fee mechanism does dynamically change, but it's a global base fee and that is useful in extreme cases. For example, if there were many non overlapping transactions that fill the Solana block or an SVM block, then we might consider raising the global fee. But in general we don't want to raise the global fee. We want to keep the global fee really low and just raise the local fee for those applications that are getting a lot of activity. So I'm going to go into a few different ways that we can leverage the fact that parallel run times have separated accounts and separate resources to enable new types of fee markets and therefore cheaper fees.
00:12:57.699 - 00:13:44.835, Speaker A: And this first one is multidimensional blockchain fee markets. And this is based on a paper from Tarun, Chitra and Alex over at Bain, a few other guys, and they're basically observing that if you look at most fee markets, they have some notion of gas, which is an approximation of many resources. GAS is accounting for computes, it's accounting for memory, block size, many other things, and they're trying to average that out into some fungible unit. Whereas if you had a full optimization solver available to you, then you might actually break those resources out. So you might break out cores and have some target resource utilization for the number of cores that are being used. You might have some target resource utilization for memory for how many accounts are being used at once. Just every resource could be broken out theoretically.
00:13:44.835 - 00:14:44.595, Speaker A: And what they do in this paper is they formulate the problem just as you'd expect it. So they say let's maximize the utility that each user is willing to is getting out of their transaction, executing which is an unknown, and subtract some measure of cost where that measure of cost accounts for how far each resource utilizations like how far each resource is being utilized in reality compared to the target measure. So they have this objective function they converted to the lagrange dual problem, they solved that. And it turns out that even with some unknowns in the primal problem, you can still get the optimal solution. So this is implemented in practice with avalanche, penumbra, a few other folks, and what could be interesting is applying this to accounts or individual accounts. Of course that leads to a very complex optimization problem and maybe we'd have to have an approximation of the exact solution for the resulting optimization problem. This is another one that's being proposed for the svm.
00:14:44.595 - 00:15:24.471, Speaker A: And what they're basically doing here is for each individual account they're applying some notion, some local EIP 1559. So they're saying if an account is being used very frequently, we're going to increase the cost to access that account. And if it's not used so frequently, then we'll decrease it up until some, up until some minimum fee. So this is better than the existing local fee market implementation, just because now it's enforced by consensus. So that's one. Plus the downside is that it does seem to lack, it doesn't observe the differences between resources like compute, memory, things like that. And it's also relatively complicated to keep track of all these moving averages.
00:15:24.471 - 00:16:21.931, Speaker A: Of course, there's pretty efficient ways to calculate a simple moving average. But think if you're calculating this across millions of accounts and you have to do this on every single validator, this is a runtime that's optimizing for performance first and foremost. So anything that can impact, like let's say, its target goal of thousands of transactions per second, then that's probably undesirable. So they impose some limit on how many accounts would actually be tracked in practice and where this exponential moving average would be applied. So this is the kinds of stuff that we're thinking about at Eclipse for our fee markets, we want to balance the concerns of making sure it's economically optimal in the sense of welfare maximizing. But we also want to make sure that we're supporting these quote unquote uneconomical use cases like gaming NFT mints, things that typically might cost an exorbitant amount on EVM chains, just because those are often not the most important transactions. But this is one of the informal design goals of parallel runtimes.
00:16:21.931 - 00:17:00.693, Speaker A: So I think there's a lot of stuff we can take from the existing Ethereum fee market literature and apply it to the svm. If you look at how Solana has traditionally been approaching it, I think the conversations are sometimes disorienting for the Ethereum community and vice versa. When Ethereum mechanism design literature is shown to the Solana community, it can be disorienting for them too. So I think that Eclipse is a good opportunity to bridge those two gaps and leverage the best parts of the Ethereum fee market literature and apply it to the svm. Cool. So I'll give those three minutes back unless there are any questions the audience. But yeah, thanks.
00:17:00.693 - 00:17:01.245, Speaker A: Thanks for your time.

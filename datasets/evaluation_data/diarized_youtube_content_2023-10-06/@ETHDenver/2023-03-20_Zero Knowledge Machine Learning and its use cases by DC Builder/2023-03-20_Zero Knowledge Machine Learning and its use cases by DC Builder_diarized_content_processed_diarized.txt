00:00:00.330 - 00:00:53.070, Speaker A: Models would give us useful sort of outcomes. Zero knowledge cryptography essentially gives us two main properties. One is the verifiability of execution, which stem from the cryptographic properties of completeness and soundness. And the second part is essentially hiding parts of the computation that you're performing without sacrificing this sort of verifiability. When we're talking about ZKML, we're usually talking about proof of inference. We're creating a proof that a model has been evaluated on some input and that it indeed created some output, and we can verify this entire process cryptographically. We can see sort of like a simple schema over here, where this is sort of like the inference step, where you have some input, you feed it into some model, and out, you have an output, and you're able to sort of create a zero knowledge proof of this entire process.
00:00:53.070 - 00:02:10.726, Speaker A: Why do we create only zero knowledge proofs of, let's say, inference and not training? So, training in and of itself is already extremely computationally intensive because you need to run it on colocated data centers and essentially, let's say, like AWS or Google Cloud or these huge distributed computers that are working and training for months on end. It's millions of dollars that's spent on hardware and electricity and maintaining all this infrastructure just to train a model. And zero knowledge cryptography. If you're proving a computation inside of zero knowledge, it creates a lot of computational overhead in the order of, like, let's say, 100 to 1000 x, right? So it's about 100 x as computationally more expensive to create a zero knowledge proof than perform the computation itself. So if you want to do zero knowledge training, prepare to be training a model for, let's say, decades, in order to actually create a proof for that training. So that's why we are sort of talking about proof of inference, because when the model is already trained, it's just running a few linear combinations and a few, like, matrix multiplications, and you'd be able to create a proof within that a lot more easily than with training. So here I'm going to talk a little bit about different primitives and how you can combine them to sort of give zero knowledge machine learning.
00:02:10.726 - 00:02:51.298, Speaker A: So to sort of create a good intuition for what we're trying to do. So on the left side, we see privacy and computational integrity. If you combine these properties, you get what you would call zero knowledge cryptography if you combine privacy and heuristic optimization. So heuristic optimization, essentially what you can think of it as is sort of like an algorithm that's able to give you a good enough approximation to a good problem that you're trying to solve in the context of ML. To give a good example, you can, for example, have a model that classifies an image as a dog or a cat, and this model has some accuracy on some data that you test it with. It can have like 99%, 99.1, whatever.
00:02:51.298 - 00:03:34.142, Speaker A: So this is sort of like a heuristic. And if you're trying to sort of optimize this problem, that's what you'd call, like, heuristic optimization. So this heuristic optimization thing, you can think of it just like ML, pretty much. And if you want to, for example, have private ML, you could use something like fully homomorphic encryption. Fully homomorphic encryption is a type of cryptography that allows you to encrypt an input, perform some operations on some encrypted input, then you have an output that's encrypted, and then when you decrypt the output, it will have that operation performed on top of it. So you're able to have data privacy. If you combine ML with computational integrity, you get validity ML, right.
00:03:34.142 - 00:04:18.670, Speaker A: So you only get this proof that some computation happened correctly, but you're not hiding any of the computational steps. And if you combine it all, if you get privacy and heuristic optimization and computational integrity, it's sort of like what we would call zero knowledge machine learning. Also, one note that I'd like to point out is that the difference between privacy in terms of ZK and the privacy in terms of fully homomorphic encryption is different, because fully homomorphic encryption allows you to have private data, whereas if you're doing zero knowledge ML, the data is not private. It will always be available to the prover. But the prover will be able to perform some computations and prove that those computations happened without revealing the computation. But it will always have access to that private information. So that's like an important step to note.
00:04:18.670 - 00:05:00.630, Speaker A: Yeah, so this is just repeating a little bit of what I said before. You have more standardized definitions of what they mean. And I'll also talk a little bit about the difference between zero knowledge and validity proofs. In our space, many people are sort of conflating the two concepts, right? So, for example, when people talk about zero knowledge roll ups, they're not really talking about zero knowledge roll ups. They're talking about validity roll ups, like creating proofs that some state transition happened correctly. But you're not hiding parts of that state transition, like think starknet scroll, or any other ZK roll up. If you're actually hiding set computation, think like aztec, where you're having some private transfers where you don't see balances, or think zcash.
00:05:00.630 - 00:05:47.450, Speaker A: That's actually zero knowledge cryptography, not validity. Where validity, you're essentially doing a zero knowledge proof without hiding any computation. Right? So when you're talking about validity, ML is just not hiding any computation, but actually proving that it happened. So I'm going to talk a little bit about the current state of the art of what we are able to do with zero knowledge machine learning in terms of the technology and how far it is along. So zero knowledge machine learning is at its infancy. It's just like currently, zero knowledge proving systems have become mature enough that people have started exploring, sort of creating proofs of more computationally intensive operations, such as machine learning models, right? So it's in a very early R and D phase Research. There's a bunch of papers that have come out in the past few years.
00:05:47.450 - 00:06:24.066, Speaker A: There's a few tools that have come out like more easier, like ZK proving systems and better APIs for these. So you're able to create actually like proofs of more complex operations. And so here I'll mention my friends from Modulus Labs. We're sitting in the front row. They recently released a paper called the cost of intelligence, where they tried to benchmark different proving systems against different sized models. And so here I'll give you an example from their paper of what you can actually do. Nowadays, you're able to prove a model of about 18 million parameters in size in about 50 seconds, running on a powerful machine on nlbs.
00:06:24.066 - 00:07:08.210, Speaker A: By powerful, I mean 64 cores and 192 gigs of ram. So it's a really huge machine. And for this specific one, they used the planky two proving system built by the Polygon zero team. So now I'll show you sort of like a graph of comparing all these different proving systems for the ones that are interested in the list. There's Gemini graph 16, halo two, blonky two, Winterfell and approver, that was custom built by a paper within a paper called ZKCNN. And on the X axis you can see the number of parameters, and on the y axis you can see how long it took to create a proof, given a proving system for that specific model. So the one that's on the lowest, that's like orange, dark orange, is the one with spunky two that I just mentioned earlier.
00:07:08.210 - 00:07:38.090, Speaker A: The very last dot on the right, on the bottom right. So I'll talk a little bit about the tooling and the state of the art, like what you can actually use today. So this tool, the first one that I mentioned is Ezekiel. So by the way, these names are just the slug that you have on GitHub. Just like if you go to GitHub.com slash Zcondo Ezekiel, that's like the actual tool, so you can use it. So Ezekiel is a tool that allows you to create proofs of onnx computational graphs.
00:07:38.090 - 00:08:36.090, Speaker A: Onnx is this like standardized format that you can use to export machine learning models from different frameworks. So if you're an ML engineer, let's say you use Pytorch or keras or Tensorflow, you're able to take a model that you have within your framework, export it to NNX, and then feed it into Ezekiel and create a proof that that actually happened correctly. Ezekiel is using fork from Halo Two's proving system that was created by the privacy scaling Explorations group by the Ethereum foundation, and they're working on an easy to use API for developers, so that if you're an ML engineer, you can easily prove these computations. Another tool is Circumlibml, who is built by Dr. Kathy. So she built sort of this library that allows you to sort of create a model with different layers using the Circom domain specific language, which was originally built by the island three team. So if you want to build a simple model, you can use circom for it, you can use that one.
00:08:36.090 - 00:09:20.186, Speaker A: And if you have a keras model, you can use keras, the circum, which is just a transpiler that allows you to convert any keras model to a circum representation and then create a proof of it. Another good mention is tachikoma from the linear A team. I just use the ZKML handle because that's the one that they have on GitHub. But the team is called linear A, and it's essentially similar to Ezekiel, where they're trying to create a proof of inference of some model in a standardized way. Of course, it's early days, more people are looking into ZKML, more people are trying to explore with its primitive, what they're able to do with it. And so more teams are building out different tools, and I'm sure in the next coming months and years, the state of the art will improve severely. And so now I'll talk about his use cases.
00:09:20.186 - 00:10:07.694, Speaker A: The reason why I put the use cases in the end is because people usually work it backwards. I try to sort of work from the primitives that you have, and then trying to combine these primitives to sort of think of useful use cases. And I also try to give some useful context about its current constraints so that you can sort of think of what you can actually do, what you cannot do, to sort of give you some limitations of what is possible today. So here I'll mention a few of them. The use cases that only use validity proofs, where you do not hide any part of the computation, is, let's say, machine learning. Service providers like machine learning as a service. If you want to use a model, but you don't have it locally on your train, on your physical device, you can just, let's say, delegate it to OpenAI to run these models for you.
00:10:07.694 - 00:11:03.418, Speaker A: And essentially you as a user do not have any guarantee that they're actually running the correct model. Right? Let's say that the newest model is GPT four and you want to use GPT four, but instead they give you GPT-3 because it's easier to operate and you're not able to tell a difference. So in a possible future, when you're able to create proofs of these large language models, for example, you'd be able essentially to query an API, and the API would have to give you a proof that they actually run the model that you want, and they would not be able to lie to you about the model they're running on the API, since it's a block box and you're not able to see what they're actually running on their devices. Another one is verifiable on chain classifiers or regressors. So this is so that you're essentially able to verify the result of machine learning algorithm on chain without having to perform the computation on chain. Right. Like to perform a computation inside of a distributed system like let's say Ethereum is extremely expensive.
00:11:03.418 - 00:11:51.482, Speaker A: And so essentially what you'd be able to do is run it locally, create a proof locally, and then you'd be able to put it on chain. A few use cases of this could be, for example, creating a proof that, let's say that you want to predict the cost of housing somewhere. So you have some inputs which is like square meters, where it is in the area, how many bathrooms, all these sorts of things. And you'd be able to prove to a new input that this is the actual result to a smart contract. And then the smart contract could execute some logic based on the result of this machine learning model. Another one is anomaly detection or fraud prevention. So there's many models that are sort of built to sort of detect anomalies or things that are not supposed to happen or even like, fraudulent transactions, right? So you can train a model that runs on some off chain activity.
00:11:51.482 - 00:12:39.802, Speaker A: And if this model finds an anomaly or a fraud transaction and enlabels it, you can, for example, have a governance protocol that sort of determines that we can stop a protocol if we find some fraud. Right? And this is established as like, a zero knowledge proof of some fraud. And the actual protocol will be able to stop if and only if you provided a proof that some model that people have agreed upon has indeed found some vulnerability. So you'd be able to automatically stop protocols if somebody finds an anomaly. Another one, in terms of more like zero knowledge, we're actually hiding computation. It's, for example, like decentralized Kaggle. So for context, Kaggle is a platform where you can do sort of competitions for trying to source the most efficient model for a given task.
00:12:39.802 - 00:13:23.438, Speaker A: So let's say you want to build a CAD doc classifier, and you want to have the highest accuracy. You can submit a Kaggle competition, and different people will compete to get sort of this price that a person set up for a competition. And if you win, then you get the price. However, this relies on a trusted party, which in this case is Kaggle. So the person running the competition gives money to Kaggle, and then the person running or applying for this competition submits the model to Kaggle. And once all of those parties agree, then Kaggle just distributes the money to the person that won the competition, and it gives the model to the person that created the competition. So instead, you'd be able to make it decentralized in a way where a person would be able to create a zero knowledge proof of how accurate their model was without revealing what their model actually is.
00:13:23.438 - 00:14:19.438, Speaker A: And then they would be able to automatically claim the reward based on submitting this proof to the party that created the competition. Another one that's useful is, for example, running inference on private or sensitive data. And you'd be able to essentially prove that, let's say that a classifier that's trying to find whether a patient has cancer or not, you'd be able to prove with some accuracy that you ran some model on this sort of sensitive data, and you'd be able to hide sort of this execution trace, and you'd be able to prove to either the patient or let's say, some insurance company or to the actual medical expert that they run some model and they actually classified the result in some way. So me personally, I work at Worldcoin, we're building a privacy preserving proof of personhood protocol. I'll show you in a little bit later after the presentation if you want. I have the sort of like orb device that we have. It's an iris scanner, essentially, and the way that we create a unique identifier is running a machine learning model.
00:14:19.438 - 00:15:14.974, Speaker A: Right. However, if we ever think of updating the machine learning model, then the people would have to go again to a hardware device and essentially get onboarded again. However, if you use zero knowledge machine learning, you'd be able to create a proof on their device, on their phone that they indeed created this sort of identifier correctly without having to sort of go to this physical device again. Also, we'd be able to make this sort of device trustless in a way where you'd be able to prove sort of all of the fraud or civil attacks that you're trying to perform, whether it's like tampering with its firmware or tampering with its sensors. You'd be able to essentially prove that the device is running the correct algorithms on it and that it's actually checked for every single thing in order so you cannot attack the system. So these are one of the few use cases that are most prominent, in my opinion. There's of course, many more.
00:15:14.974 - 00:15:58.958, Speaker A: Many people are thinking about what they could use these technologies for. And as there is better hardware, there is more optimized proving systems, and in general, the state of the art evolves. I'm sure that many more use cases will be available. So where to learn more? Where can you find more about zero knowledge machine learning? So here I have three QR codes. One is the zero knowledge machine learning community. It's essentially a telegram group where I created a group for me and my friends originally that were interested in zero knowledge machine learning. And we've started talking about the topic, right? Whether it's about the state of the art in terms of papers and the scientific side of it, or whether about implementation some cryptography things, or just in general hang out and talk about cool, interesting things that we're trying to build.
00:15:58.958 - 00:16:44.560, Speaker A: The middle one is called awesome ZKML, which is a resource aggregator that I put it together essentially, that has a list of all the common resources, the scientific papers that talk about ZKML, the code bases that mention ZKML or trying to do ZKML related things, companies that are building in the area and so on and so forth. And the third one is sort of like a pitch to a zero knowledge hackathon. That we're organizing in Lisbon. It's called Zkhack Lisbon. It's an in person hackathon that starts on the 31 March, ends on the 2 April, and essentially a hackathon for any builders that are interested in zero knowledge cryptography. And there'll be many people building with ZKML primitives as well. So whether you want to build with Ezekiel or any of the other tools that I mentioned, or you have, like, a cool idea, we'd love to have you there.
00:16:44.560 - 00:17:05.810, Speaker A: Cool. So that was my talk. I'm ready for any questions that you want to ask me. If you do not manage to ask me a question, feel free to send me a DM on telegram at DC, build three r or on Twitter, or just pull me aside once I finish my talk. So thank you for listening. Um.

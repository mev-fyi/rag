00:00:00.490 - 00:00:29.542, Speaker A: Thank you. So yeah, I'm going to explain what this word salad means. Firstly, firstly, I'll say that the word almost is used a little bit sarcastically in that you still needs to be a, be able to use a leap proof assistant to do this. So it's actually, you know, it requires quite a bit of knowledge. But you'll see once it's running that at least there aren't too many lines of code required to verify this. So anyway, we'll, we'll see how that goes. But yeah, so the Zergen mlir is.
00:00:29.542 - 00:01:07.582, Speaker A: So Nezmin has been collaborating with RiSC zero to try and formalize, to formally verify their implementation. And we'll talk about this a bit in a second. But essentially they have this language called the Zergen mliR, which is some intermediate representation for different large circuits. And we've developed some tooling to formally verify that. But we'll get into a bit more detail. So first I'll give a little bit of background of the general ZK background. So firstly, I imagine most people in the crowd will be familiar, but essentially a zero knowledge protocol is a two party protocol that has a prover and a verifier.
00:01:07.582 - 00:02:03.038, Speaker A: And the goal of the protocol is to prove that. It's for the prover to convince the verifier that it knows the answer to some shared problem without necessarily revealing what that problem is. Sorry, what the solution is. Even so, one traditional way of expressing this problem, which the proof and the verifier share, is what we call a ZK circuit. So a ZK circuit is just a system of multivariate polynomial equations over some finite field, right? As we mentioned, these can be used for expressing all sorts of things, including, as we said, with risk zeros. It's a ZKBM that executes risk five programs, I should say. But it can be used to express all sorts of domain specific problems like hash function, et cetera.
00:02:03.038 - 00:03:05.974, Speaker A: And then there are things like Cairo risk zero PI squared that can use it for all sorts of rather general, to express all sorts of general purpose computations and expressing the execution of general purpose programs, achieving complete programs, right? And so, as I mentioned earlier, the Zergen MliR is this DSL for expressing these zk circuits. And there are a bunch of others, halo two circum, et cetera. And actually, at the same time as I'm giving this talk right now, we also have a halo two extractor, which Ilya, my colleague is talking about in the other room, but unfortunately they clashed. It's a little bit unfortunate but here I'm going to talk a little bit about, as I said, our form verification tool that we've developed for the Zergen Mlir. So you can't really see that very well. I'm going to start off by showing you a little bit of an example of the Zergen Mlir, but we'll do a relatively quick flyover. So you can see.
00:03:05.974 - 00:03:06.950, Speaker A: Thank you. Yes.
00:03:07.020 - 00:03:07.734, Speaker B: Oh no.
00:03:07.852 - 00:04:17.962, Speaker A: Yes, that's better, that's better. You can see this is a fairly simple piece of code. Well, it might look like quite a lot actually, but this is a snippet of Zergen Mlir, so. Oh yeah, by the way, MLIR stands for is an LVM construct that stands for the multi level intermediate representation. And it's what you call it, it's parameterizable intermediate representation that can be used to, essentially tailored to express the semantics of a bunch of different things, including, it turns out, zk circuits, right? So here's this simple snippet of the function is called is zero. It does exactly what you'd think. It takes some input and it gives you an output that tells you whether the input was zero or not, right? So it outputs a one if the input, if the input was zero, and it outputs a zero, otherwise all other inputs, right? So the first thing I'll tell you about the semantics of this language is that it has three types, right? So the first thing is we have what we call a felt, a field element, right? So that's just some element from this finite field that we use in our system of multivariate polynomial equations.
00:04:17.962 - 00:04:53.926, Speaker A: We also have buffers. Buffers are essentially arrays of fixed, of statically known length that contain these field elements, right? And they often act as we have input and output buffers, which are essentially the values that the input values and output values of your circuit, right? And so essentially we receive both of these as inputs and we constrain these values inside of this code. And the third type that we have is actually a constraint, which is essentially a system of polynomial equations on the input and output values.
00:04:53.958 - 00:04:54.154, Speaker B: Right.
00:04:54.192 - 00:05:09.534, Speaker A: Fairly straightforward for the moment. So, yeah, okay, we've got a bunch of things. The first command just assigns, you can see a bunch of assignments, right. And essentially after each command, I've written what the state update that corresponds to the line before is.
00:05:09.572 - 00:05:09.774, Speaker B: Right.
00:05:09.812 - 00:05:43.322, Speaker A: So the first one is really straightforward. We assign the constant one which is in the field, right, to the variable called percent zero. True is actually the constraint true. So it's satisfied by any single assignment of the inputs and the outputs. We then have these get commands which essentially fetch elements from a buffer. So the first command fetches the zero th element of the input buffer, which we're going to call in. The second command fetches also the zero th element of the output buffer, which we're going to call out also.
00:05:43.322 - 00:05:59.806, Speaker A: Well, in a second, I'll explain you. Yes, I forgot to mention. So you can see the fixed lengths and type, right? So arg zero in the arguments of this function has in the buffer, you can see that it's of length one and arc one, which is the output buffer is of length two.
00:05:59.908 - 00:06:00.560, Speaker B: Right.
00:06:01.650 - 00:07:05.638, Speaker A: As I said. Well, given what I told you, the semantics of is zero is, why do we have two outputs? Well, we'll get there in a second, right? Okay, so we got these get commands, and then I'll just quickly go through the semantics of the next two commands and we'll just skip to the end. So the next two commands are constructors that allow us to construct from one constraint to more constraints, right? So essentially what it does is it takes a constraint and a value, and it constructs a constraint that is equivalent to the original value. So you can see this on the line underneath. So we say p and that little wedge symbol for those who aren't logicians, means and v, the second value inputted, is equal to zero, right? So p, as we know, is true here because that's percent one in the argument, right? And the second argument that we have is percent two, which we know is in. And so essentially this constraint boils down to saying in is equal to zero, right? So we're building up, keep in mind that we're not asserting that this is true. We're just constructing a constraint, right? And the constraint that we return at the end with this return eleven is actually the constraint that will.
00:07:05.638 - 00:07:08.226, Speaker A: This is actually the constructed circuit essentially.
00:07:08.338 - 00:07:08.854, Speaker B: Right?
00:07:08.972 - 00:07:38.062, Speaker A: Okay, so you know what Andy? Qd means? And cond is a conditional conjunction which takes a constraint, a value, and another constraint. And essentially it gives you, as we can see here in the line underneath that the constraint is true. And if the value given is not equal to zero, I don't know if you can see the not equal to zero. This implies that the second constraint must hold, essentially, right? And so here the arguments we have are percent one, which is true.
00:07:38.116 - 00:07:38.286, Speaker B: Right?
00:07:38.308 - 00:08:09.350, Speaker A: So that's kind of boring. The value that we have is our output value, and the constraint that we have is a constraint we just constructed right before, which is in is equal to zero. So all of this says that, well, if out is not equal to zero. We know that in is equal to zero. And we can see we're starting to build up the semantics of the circuit that we actually want, because we know certainly that if the output value is not zero, in this case, we'll want it to be one. But we'll check that later. We certainly want the input to be zero.
00:08:09.420 - 00:08:10.774, Speaker B: Right. Makes sense. Perfect.
00:08:10.892 - 00:08:22.442, Speaker A: Okay, so now there are a couple of other commands you haven't seen. The only commands, actually, you haven't seen here are sub and mull, and they do exactly what you think they do, multiplication and subtraction inside of the finite field.
00:08:22.496 - 00:08:22.810, Speaker B: Right?
00:08:22.880 - 00:08:47.442, Speaker A: But let's skip all the way to the end, and we return this constraint, eleven, which you can see is this construction here, and let's reason about it a tiny bit. If the input is equal to zero, we say, yeah, we're going to need a tiny bit of information about the theory of finite fields here, which is every element inside of a finite field has what we call a multiplicative inverse apart from zero.
00:08:47.576 - 00:08:47.922, Speaker B: Right?
00:08:47.976 - 00:09:31.934, Speaker A: So every element has another element of the field that you can multiply it by to get the number one essentially right. And so if in is zero, we know that, well, in times out two here is certainly equal to zero, and minus one is not equal to zero. And so the consequence of this implication is false. And so consequently, the antecedent, so one minus out one is not equal to zero must also be false. And so then we know out one is equal to one. Right, similarly, on the other. And then, similarly, if in is, what do you call it? If in is not equal to zero, on the left hand side, we know that, well, the antecedent of the amplification is also false.
00:09:31.934 - 00:09:38.594, Speaker A: And so, once again, out one must not not be equal to zero. Out one is equal to zero. And that's how we build these constraints here.
00:09:38.632 - 00:09:38.882, Speaker B: Right.
00:09:38.936 - 00:10:10.270, Speaker A: But reasoning about this by hand is pretty tough, and so we want to try and automate this as much as possible. And so I'm going to show you in a second a methodology for doing this. So, to construct this tool, we've used a proof assistant that is called Lean four. And I'm going to tell you a tiny bit about that very quickly now, actually, how am I doing time wise for here? Just to judge? You have ten minutes. I've got ten minutes. Okay, I'm going to skip part of my demo in that case. So I was meant to give a quick demo of how to use lean here.
00:10:10.270 - 00:10:48.022, Speaker A: But we're not going to do that, actually, because it's going to take too much time. But yeah, I'll tell you a little bit about lean four. It's what we call an interactive, well, firstly, it's a programming language, but it's also what we call an interactive theorem proverb. An interactive theorem proverb is just a programming language that has such an expressive type system that I can express statements in higher logic, in higher order logic into its type system, essentially, right, at a very high level. And this means that essentially I'm able to express arbitrary theorems about things that I want to verify in types, and then I'm actually able to prove these things in the language.
00:10:48.086 - 00:10:48.746, Speaker B: Right.
00:10:48.928 - 00:11:32.710, Speaker A: And so all of this is done via what we call a dependent type theory. And I'll just skip over this really quickly. So, to give you an idea, because a lot of you that will just sound like magic to you, how is all of this done? But to give you a high level idea? Well, I'm imagining most people in this audience are familiar with programming languages. So you'll be familiar with in programming languages having this dichotomy between terms and types, right? So you have your terms, your statements in your language, which you can compose in various ways as this arrow represents to build larger, more complex programs, right. You can nest statements. Oh, hey tunished, sorry, I didn't see you there. So you can nest statements in if branches in while loops, et cetera.
00:11:32.790 - 00:11:33.514, Speaker B: Right.
00:11:33.712 - 00:12:08.614, Speaker A: And that's fairly typical. Some languages will also allow types to refer to themselves. You can have type constructors, like some languages will have vectors, which are parameterized by other types. And you can construct a vector of InTs or Charles or whatever you want, right. Some languages also allow terms that depend on types. So you can have, and we call this polymorphism, right, where, okay, you have some term in your programming language which, depending on the type of the thing passed to it, it might take different kinds of numbers, like a float or an int. The notion of additional multiplication will be different, right.
00:12:08.614 - 00:12:45.778, Speaker A: And so the semantics of the program will depend on the type of the thing passed in. And then finally, and this is where the magic happens, independent type theory, you also allow the types to refer to terms. So in your types, you can actually refer to the functions you defined in your programming, et cetera. And this allows you to essentially express within your types theorems about your programming language and about the semantics. Right, okay. And in particular, so lean is pretty interesting in that it's a very modern proof assistant, right? I think it's learned a lot from its ancestors, so to speak. It has a very powerful notation engine.
00:12:45.778 - 00:13:01.318, Speaker A: So the parser of lean is basically arbitrarily reprogrammable. And I think that's pretty cool, because essentially all of my mathematician friends, I can get theorems to be basically expressed in exactly the notation a mathematician would use on paper.
00:13:01.404 - 00:13:01.702, Speaker B: Right.
00:13:01.756 - 00:13:19.434, Speaker A: So I can just show this to them, and they might not understand the proof, but they immediately know what it means. Right, okay. And the other thing is that there's a huge corpus of formalized mathematics in lean, which we call math label, in particular field theory, which we've been talking about quite a lot.
00:13:19.472 - 00:13:19.818, Speaker B: Right.
00:13:19.904 - 00:14:00.890, Speaker A: So that's great. Okay, perfect. So in practice, actually, when trying to automatically generate specifications for programs written in the Zurich and Mir. Sorry, my mouth is super dry. Apologies, guys. We noticed a bunch of problems with trying to automatically generate specifications for them, which was that actually, when actually considering their semantics, it would quickly be the case that the state updates that we were modeling via these state transformers became out of control. They were so big that essentially the leans type checker would experience a buffer overflow, which was not great.
00:14:00.960 - 00:14:01.482, Speaker B: Right?
00:14:01.616 - 00:14:16.314, Speaker A: And so we had to apply a bunch of optimizations to actually simplify the code while preserving the semantics in a way that would allow us to actually be able to construct these terms and construct these specs.
00:14:16.362 - 00:14:16.814, Speaker B: Right.
00:14:16.932 - 00:14:29.282, Speaker A: So the first thing that we did is we chunked the code, we cut it up into smaller parts. We then computed state transformers for each one of them, and then obviously composed these to actually get a specification for the whole piece of code.
00:14:29.336 - 00:14:29.554, Speaker B: Right?
00:14:29.592 - 00:14:37.618, Speaker A: So if you basically get the spec for the first chunk here, the second, and the third, and then compose these, you get spec for the whole set.
00:14:37.704 - 00:14:38.398, Speaker B: Right.
00:14:38.584 - 00:14:54.502, Speaker A: The second thing that we did is that we found that actually a huge amount of the intermediate representation of the state when we were trying to compute these state transformers in lean was actually, was taken out by a lot of variables that were actually not used anymore.
00:14:54.566 - 00:14:54.842, Speaker B: Right.
00:14:54.896 - 00:15:09.998, Speaker A: So a lot of variables in this program, at some point in time, they're never going to be used again. They just disappear. But they still had to be dragged along in the state. Right, but you can forget them without actually modifying the final value, which is returned here.
00:15:10.084 - 00:15:10.670, Speaker B: Right.
00:15:10.820 - 00:15:23.262, Speaker A: So we then added the option of inserting these drops, which basically told the language model that, hey, this variable is not going to be used anymore.
00:15:23.326 - 00:15:23.506, Speaker B: Right.
00:15:23.528 - 00:15:36.834, Speaker A: And you can just throw it away. And we automatically generated a proof at the same time, using these shuffling lemmers, that actually this program is semantically equivalent to the original program before the chunking and the drops were inserted.
00:15:36.882 - 00:15:37.046, Speaker B: Right.
00:15:37.068 - 00:15:44.314, Speaker A: And that proof is completely automatically generated. We say that the evaluation of this program. Thank you so much. Sorry. Four minutes.
00:15:44.352 - 00:15:45.180, Speaker B: Okay, perfect.
00:15:47.950 - 00:15:52.042, Speaker A: The evaluation of this program is equivalent to the original.
00:15:52.186 - 00:15:52.880, Speaker B: Right.
00:15:53.730 - 00:16:21.670, Speaker A: After applying these optimizations, we found that actually we were able to verify some fairly large programs in the Zergen MLIR, including some programs that were about 300 lines of code, which is fairly good, I thought, at least. So obviously there's still some scaling required to get it to be practical. But, yeah, we'll see how that goes. We're still working with them. Okay, perfect. So I've got four minutes. I think, actually, I'm going to have to skip the demo, basically.
00:16:21.670 - 00:17:33.278, Speaker A: But I'm going to tell you a little bit at a high level about how this actually works in practice, generating these specs, which is essentially, I talked a little bit about, well, we model the programs with these state transformers, right? So how do we actually automatically generate these state transformers? So one way would be to, hey, write a program that automatically tries to go through these lines of code and sequence all of these state transformers. But actually that turned out to be pretty tough. What we did in practice was actually we formalized the Zergen MLI on lean. We gave it a formal semantics, right? And then what we did is we wrote what we call a VC, a verification condition generator, which all that it does is it just writes a proof of a simplification of the Zergen MLIR. So it takes a program, it traverses it, go through it line by line, unfolds the semantics of each line, apply some simplification tactics that exist in lean already, and that automatically just generates a simplified specification for this. So what we do is we generate this proof that just unfolds and simplifies within lean. We chuck it at lean, we ask it, hey, what's the type of this thing?
00:17:33.364 - 00:17:33.854, Speaker B: Right?
00:17:33.972 - 00:18:05.490, Speaker A: And it throws us back a type which actually happens to be a specification. It's a state transformer that, a simplified state transformer that actually describes, what do you call it, which describes the semantics of the program that was given to us, right. Very straightforwardly. Okay, so I think I've got like, what, two minutes left about that? Okay, so what I'm going to do very quickly is put this microphone down and actually just show you guys the spec that was generated here. We'll go, and then we'll go on to the last slide.
00:18:05.570 - 00:18:05.910, Speaker B: Perfect.
00:18:05.980 - 00:18:11.194, Speaker A: 1 second. I will allow it. Thank you. You'll allow two minutes over.
00:18:11.232 - 00:18:11.866, Speaker B: Okay.
00:18:12.048 - 00:18:30.510, Speaker A: You're generous. You're generous. And of course, since I already had another demo. I need to pull this one up, because if only the first one was up, it will take only a second, though. You're timing me, are you? No. Where is it? There we go.
00:18:30.580 - 00:18:31.502, Speaker B: Okay, perfect.
00:18:31.636 - 00:18:41.410, Speaker A: You did a few more minutes. It's fine, by the way, thanks. Okay, there we go. Is this for the constraints? Yes, it is.
00:18:41.480 - 00:18:42.100, Speaker B: Perfect.
00:18:51.440 - 00:19:01.730, Speaker A: Okay, perfect. Let me see. If I do this, it should appear here and. Ooh, that's a bit messy on using this size.
00:19:02.340 - 00:19:03.200, Speaker B: Yeah. Okay.
00:19:03.270 - 00:19:19.792, Speaker A: It's a bit better, hopefully. Perfect. So this is actually a specification. It's still not. Let me make it a bit smaller. Control K and then Z. Now it can be seen, right? And this is actually a specification for the circuit that you saw earlier.
00:19:19.792 - 00:19:23.992, Speaker A: There is zero circuit. This is a specification which is automatically generated for it.
00:19:24.046 - 00:19:24.552, Speaker B: Right.
00:19:24.686 - 00:19:57.300, Speaker A: And in fact, you'll see in lean, well, I'll show you very quickly in lean afterwards that it's actually been formally verified. And so this is an auto generated specification which says, okay, so data zero is the output value. And we say, hey, if it's zero, sorry, if it's not zero, then the input must have been zero. And the other one says, well, if one minus data zero is not zero, because the true branch is not kind of not interesting. If it's not zero, then. So, I e, data zero is one, essentially, right? Wait, if it's not zero? No. So data zero is zero.
00:19:57.300 - 00:20:06.704, Speaker A: Sorry. Then we know that this must be true, essentially, which is saying that, hey, the product of in zero and data one is equal to one, essentially.
00:20:06.752 - 00:20:06.964, Speaker B: Right.
00:20:07.002 - 00:20:12.964, Speaker A: And so that must mean that essentially in zero, as we said from our background and field theory, is nonzero, essentially.
00:20:13.092 - 00:20:13.624, Speaker B: Right?
00:20:13.742 - 00:20:36.912, Speaker A: And so this was automatically generated. And from this we're able to very, very, all of this up to now is automatically generated. The extractions, the optimizations, this specification, and it's in fact proved in lean. So if we look very quickly at, we check our goals, hopefully if we go right here at the end, we'll see that we have no goals. So that means that lean is happy that this is actually a proof of the statement. So we've formally verified it end to end.
00:20:36.966 - 00:20:37.890, Speaker B: Okay, perfect.
00:20:38.660 - 00:20:54.084, Speaker A: And then actually from this, we can very straightforwardly prove the more human readable spec that we had. Perfect. Okay, let me go back very quickly now to the last slide, which is somewhere. No, there we go.
00:20:54.122 - 00:20:54.468, Speaker B: Perfect.
00:20:54.554 - 00:21:29.872, Speaker A: Last slide. So, yeah, I wanted to talk very quickly about some modules, some limitations, and some future work we need to do. So the first thing, the easy ones, is that it actually doesn't support all of the operations in the Zerg and Mlir. There were some slightly spicier ones that we didn't quite get to, but we're working on that. And then obviously modularity, we need to be able to split up these proofs and split up the circuits into subsurcucuits and reason about them individually to make it easier for humans to do this. Oh, I realize I haven't been holding the microphone. Anyways, hopefully that can be heard.
00:21:29.872 - 00:21:53.670, Speaker A: Okay, it'll be fine. And then obviously the performance. I wasn't able to run the demo, but it took a solid, like three or four minutes to do a fairly simple circuit. But we're still working on improving the performance. And finally, the ongoing work here is that we actually want to prove that the constraints of used by risk zero are actually equivalent to the risk five spec. So yeah, we'll see how that goes. Thanks so much, guys.

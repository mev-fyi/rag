00:00:00.490 - 00:00:40.140, Speaker A: So in order to break the ICE, allow me to take the liberty to be the first speaker for today's agenda. I will be representing Nethermind research today, and I will be telling you guys about a research project we delivered for Lido. So let me. There we go. This is titled White Labeling Resistance for Lido, systemization of knowledge research and system design. I am Jorge Arse, blockchain and cryptography researcher at Nevermind. So let me start by introducing what this is all about, some of the important terms for you to understand what we did with this research.
00:00:40.140 - 00:02:09.430, Speaker A: Okay guys, so our research team has been collaborating with Lido Finance. You might know them, the largest liquid staking provider on Ethereum up to date, like over a year ago. And throughout all this time, we have been very conscious about the fact being able to help lido transition towards a permissionless model, or at least allow operators to be onboarded in a permissionless manner on site, the permissioned operators that Lido currently runs via the whitelist model. And so what we want to do to support this goal is to design a mechanism for decentralized maintenance of Lido's operator set. What we're looking at is, although there are permissionless solutions in the liquid staking space to onboard node operators, I think one of the biggest examples is rocket pool, and it relies on abundant model and Lido is currently transitioning to adding something similar on top of its infrastructure. However, we are interested in researching other ways in which the capital efficiency that Lido has that is currently very high can also be maintained, and we can bring down those bonding requirements a little bit. We have been looking at ideas that encompass reputation systems for node operators, identity systems, and even civil resistance and white labeling resistance.
00:02:09.430 - 00:02:44.314, Speaker A: So we have been doing this in multiple phases. Phase one was systemization of knowledge in the fields of decentralized identity and verifiable credentials. This was completed late last year and phase two was on white labeling resistance. Let me get into what white labeling means in a second. This was completed in August. So here you can find, or you can see a QR code of the research we did for the phase one of our research project. We looked at over like 100 different papers in the fields of identity and credentials.
00:02:44.314 - 00:03:25.694, Speaker A: We selected 70 of them. We created a database ranking them by quality, by relevance to the problem we wanted to solve. And the idea from all of this was to provide a recommendation of which kind of protocols in the field of decentralized identity and verifiable credentials, a protocol that is trying to build in a permissionless and decentralized manner could use. And so if this is a field that interests you, I would highly recommend to check that out. I'm going to have another QR link in the next slide which actually points to both the phase one and the phase two. So this is the deliverable for white Acelin resistance. And I promise I'm going to get into explaining all these concepts in a second.
00:03:25.694 - 00:04:20.342, Speaker A: Just wanted to get the links out of the way before we start talking about. That's. I saw some cameras off. Just give me a second here. Okay, so now let's go back to, I gave you this initial description of the problem of helping Lido onboard operators in a permissionless manner. And there's this concept of white labeling that is a little bit of like jargon that is closely related to the field of staking and node operators. What does that mean and why is it a problem? So we're going to understand white labeling as what happens when you have a node operator in a staking protocol that delegates the operation of their nodes to a third party without the liquid staking protocol, in this case lido having any knowledge of that.
00:04:20.342 - 00:05:01.922, Speaker A: So to explain why this is a problem, you could have people, you could have a multitude of node operators which you think are different entities, but they're just delegating their nodes to a single party behind the scenes who controls everything. And you're not aware of that. The problems that this could introduce are plenty. It could be to disproportionate control over the protocol staked by a single entity. It could weaken resistance to correlated flashing. It could introduce single points of failure because you're centralizing the stake into a single entity without knowing. And we note that it's easier to deal with this in the current way that Lido works, which is just a whitelist model.
00:05:01.922 - 00:06:03.030, Speaker A: But as we move towards a permissionless model, it's going to be harder and harder to do. So now here we see a screenshot from Lido's decentralization scorecard showing this goal of operators running their own nodes. That is, there being no white labeling. And this is something important for the Lido protocol, and I think it's important for the decentralization of Ethereum as a whole, knowing that the node operators who claim to be node operators are actually running their own infra, or taking the steps to take care of their own infra. And this is currently good, the way Lite currently works with the 37 node operators that they use. But as we onboard new people, without having this sort of checklist, it could not be so good or it could be compromised. So let me give you a brief overview of the sort of idea, the mechanism that we're trying to design to prevent this delegation of node operators behind the scenes.
00:06:03.030 - 00:07:13.920, Speaker A: We wanted to research the design of a decentralized dispute resolution mechanism for Lido that would penalize misbehaving operators. So what this would do is it would focus on white labeling for this space, but you could use it for a lot more things. You could use it for punishing civil attacks. You could use it for any sorts of irregularities in the node operator set. And so some keywords here are decentralized dispute resolution mechanism, right? Like the decentralized part is what makes it harder, because usually to resolve disputes, you defer to a central authority. So how can you make this decentralized, and what kind of building blocks you would be looking to use that or to create that? So the structure of the research project would be, we started by doing a systemization of knowledge on arbitrage protocols. This is an umbrella term that we're using to refer to any kind of protocols that can be used to look at a given piece of evidence or like some set of information, evidence data, and come to a resolution as to the meaning of that data.
00:07:13.920 - 00:08:48.326, Speaker A: So here we have stuff like, we looked at stuff like prediction markets, decentralized oracles, decentralized justice. The idea was to select the most suitable protocol that could be used for decentralized dispute resolution among what currently exists in the market. And from there, assuming we find a good piece to get started, we move into a very interesting part of the research, which is sort of like the game theory or the mechanism design, like what kind of architecture and economic incentives you need to put in place so that the different parties that participate of this decentralized resolution mechanism, if they're acting rationally, are going to behave in a virtuous way, are going to preserve the integrity of the validator set. And the parties of interest here include the node operators, the accusers, that is, the third parties that come in with evidence, and the jurors who are the parties who arbitrate over the dispute. I will elaborate on those parties in a minute. And then another important thing we looked at. The research is, okay, that's all well and good, assuming you can find an appropriate building block for decentralized speed resolution, assuming you can generate the correct economic incentives for mechanism, that is sound game theoretically, but what is the evidence exactly like? What are we looking for to identify by labeling? How does it look like either on the, how does it look like either on the networking layer of ethereum or otherwise, in the sense of the flow of capital.
00:08:48.326 - 00:09:45.230, Speaker A: How does it look like for someone to be doing white labeling? What kinds of evidence can we find of this delegation of nodes actions? So we'll look into that as well. Okay, so our research had these five objectives or tasks very much related to what we were describing before. And let me share with you some of the results, some of what we've learned, and what is interesting. Okay, starting with actually the second task after the research, but the first one that I was telling you about in detail, SoK and arbitrary protocols. We looked at a bunch of papers and implementations of those, I think roughly 35, if I recall correctly. And remember, I told you about three categories we had the idea of seeing, studying the feasibility of prediction markets, oracles, and decentralized justice for this task. So very briefly, let's go over them one by one.
00:09:45.230 - 00:10:59.270, Speaker A: Prediction markets, you may have heard of them, essentially any kind of protocol where people can bet on binary outcomes of future events. Intuitively, given that the prices of binary options in prediction markets tell you the mean belief of the traders as to whether something is true or false, we wanted to assess whether using a prediction market, you could sort of like use this as a way to determine whether a given piece of evidence points to someone being guilty or innocent about a given action, like white labeling or so. But we found a flaw in the usage of prediction markets, and that is that in fact, most prediction markets rely at the end of the day on a centralized resolution mechanism in order to resolve the prediction market and tell you which body should be paid and which body shouldn't, despite the ODs being either in favor or against the winning party. Right. Some prediction markets look into decentralizing this, and they use stuff like oracles. Precisely, or protocols of the other types that we're going to describe in order to provide that resolution. But in and out of themselves, they are not a resolution mechanism, which is a problem.
00:10:59.270 - 00:11:55.990, Speaker A: So we were led to look into something else. Moving on to oracles, which we understand as any mechanism for bringing off chain data on chain, and use different kinds of economic incentives to remain decentralized. Examples include Chainlink, Nest, even Yuma, that can be included in this list. But we found something with oracles, which is that many of them are not suited to deal with subjective interpretations of data. They are well suited to report on a given value of something that happens off chain, for example, but to provide a sort of ruling as to the meaning of a piece of evidence, their architecture is not necessarily designed for that. So we need something like a more subjective type of oracle, if this is what you're trying to do. And that leads us to the next type of arbitrary protocols we analyze.
00:11:55.990 - 00:12:35.220, Speaker A: So that would be this kind of subjective oracles also go by the name of decentralized justice protocols. And these are protocols that use blockchain technology to decentralize infirmary resolution by crowdsourcing the adjudication of disputes to a worldwide pool of juror arbitrators. So that's sort of like a definition, but you can subjectively think of them as. Sorry. Intuitively think of them as subjective oracles or generalized oracles that look at things that happened off chain, provide an interpretation, and put that interpretation on chain. And this interpretation could be guilty, innocent, or this did happen. This didn't happen.
00:12:35.220 - 00:13:27.990, Speaker A: And the interesting part about these protocols is how they leverage jurors who are financially incentivized to rule truthfully via something, usually something that is known as a shelling point mechanism. And the gist of it is, you put a bunch of people in separate rooms, you do not allow them to communicate with each other, and you ask them for their version of the events or of something that happened that they were witnesses to. And you reward those who answer in the majority, and you punish those who answer in the minority. And so what arises as a sort of natural equilibrium point here is for people to tell the truth. They cannot communicate with each other, and they should say what the majority should say. This is what the meaning of a shelling point is. Kind of like a natural equilibrium point that arises in the lack of communication.
00:13:27.990 - 00:14:19.314, Speaker A: Okay, I think we'll have some time for questions, one or two questions at the end, in case you guys are interested. So from all of this, decentralized justice protocols came out on top of our task. We had a comparative review of these protocols, and we liked what the Claros protocol was doing. It was the most mature in the space. So we identified some useful ideas that we could take from that, and we also analyzed some critiques of decentralized justice from blockchain and law experts. Now, as for the mechanism, let us go back to how you could use this. Or you could design some kind of game theoretical approach to making all the parties behave as intended.
00:14:19.314 - 00:15:09.302, Speaker A: You have three different parties. You have the lido operators who are posting a bond that is subject to being lost if they are found guilty of any of these misconducts in this case, like by labeling or civil, being civil or so on and so forth. You have accusers. So these are any kind of external parties who submit a case with evidence to the dispute resolution mechanism know that these parties must also submit a bond, because if they don't, then they can just spam the mechanism with accusations without being liable to loosen anything. So that's something you want to be careful against. And finally, you have jurors who are appointed by the mechanism to arbitrate a dispute using the shelling point mechanism we discussed before. And they should be knowledgeable enough to understand what the significance of the evidence they're given.
00:15:09.302 - 00:16:30.890, Speaker A: And they have to split a reward taken from the loose inside. So that's sort of like a picture or an architecture diagram of what's going on. You have the validator set, evidence providers obtain insights from that validator set, provide though the red flags or the evidence to a decentralized justice protocol that's integrated with lido contracts in order to obtain a resolution. And there's a juror set that is leveraged in order to obtain those resolutions. Now, there was an interesting thing that we did in order to find out how to make all these pieces work together harmoniously, intuitively, what the way this goes is if there is a gain to be made from white labeling, that is, from delegating your notes to another party, and sort of like just collecting the middleman fees. So how much do you expect to gain from that as a function of time? Second, there is a probability that you will be caught. And this probability, we modeled it as increasing over time, because the longer you are doing something, the more likely you are to be caught in principle, especially like in this case, where there are more possibilities of instances of evidence arising or coming up to the surface.
00:16:30.890 - 00:17:31.886, Speaker A: So taking into account this probability distribution of being caught, so what's the expected return that you have from doing white labeling once the game ends? That is, once you're finally caught. So that will give you a number. And the last question would be how much of a penalty you need to apply to white labeling, so that in expectation, that is, on average, you will have people losing money, not winning money, by the time they are caught. Like what big penalty you need to apply at the time of detection so that people will not want to do this. Now, this penalty cannot be too large because this would decrease the capital efficiency of the mechanism. So we want to make it as optimal as possible. And when we're doing this, there's a simulation tool in the deliverable, which we provide, because all of these questions or all these calculations that I just referred to depend on a variety of conditions.
00:17:31.886 - 00:18:09.706, Speaker A: They depend on the efficiency of the courts, like how likely it is for the court to actually give you a truthful or a fair resolution. We cannot assume perfect courts. It also depends on the price of ease. It depends on a variety of market and technology tech conditions. So we provided a simulation tool in the deliverable that I linked before that allows you to tweak with these parameters and obtain different results. And here's a graph of what we obtained for the market conditions as they were in like August, September or so. There's an initial.
00:18:09.706 - 00:19:09.042, Speaker A: So what this is showing us is what is the minimum accusers reward? What is the minimum payout you have to give to accusers in order to make sure that the parties will behave, if they are rational, they will behave in a way that is beneficial for the integrity of the validator set. And what you see is, okay, we need this sort of like initial constant amount of payout, because otherwise parties are not, the accusers are not incentivized to look at very small cases. It's not worth their while. And so we need to be careful with that. But from there, as the number of validator increases, number of validators increases, the payout grows linearly and is reasonably capital efficient. Because for example, to adequately collateralize against say 100 validators doing white labeling, the node operator would need to post an additional collateral of something like five ether. So that's like 0.5
00:19:09.042 - 00:20:17.154, Speaker A: e per validator to adequately collateralize against the risk of white labeling. And if you think about it, that's a very, very small sum, given that for node operators to protect against latching risks, it is very common to hear of like four ETH per validator or something like that. So this is encouraging in regards of being able to find a way to make the capital efficiency of the mechanism adequate, that is not requiring crazy amount of bond to make sure that they behave correctly. And also like, you could include this zero point 55 e per validator as part of the bond that they are already posting for the slashing conditions. I'm almost out of time. I think I'm just going to have to finish by saying, as for the heuristics to identify white labels, we reviewed the literature and known ecosystem insights on how you can do that, and we found two main ways of identifying white labeling. One would be using machine learning approaches on the blocks that are produced by the validators, or even on the performance metrics of the validators.
00:20:17.154 - 00:21:11.540, Speaker A: So there was an article by rated, which was called solo stakers, the backbone of Ethereum, in which they used a similar idea to identify solo stakers, and they were able to cluster validators into their operator sets using unsupervised machine learning. The idea here would be to use a similar approach to cluster validators that posed to be being run by different people and show that they are actually part of the same entity. And there were also some networking layer analysis that we looked at that allows us to correlate validators as actually connected to the same beacon node, hence shown that they are being run by the same person. So it's an interesting rabbit hole of research that that you can look at as to how to gain more insights into the structure of the validator set. I'm going to wrap it up here for future research directions. We want to look at civil resistance and reputation and how this interacts with the rest of the mechanism. Thank you very much.

00:00:00.330 - 00:00:57.070, Speaker A: Thank, so thank you. So today I will talk about VIP 48, 44, economics and how roll ups may react to the new market that rises after introducing the proposal. So this is a joint work together with David Krappis, who is a researcher at Ethereum foundation, and Edward Felton, who is co founder and chief scientist at Offchain Labs, where I'm myself, researcher. Okay, so a bit of motivation. We heard a lot about roll up, so I'll be quick. We know that they are there to scale the Ethereum because Ethereum needs scaling. But on its own, Ethereum can help roll ups by allocating more data availability or more resources from the validator side.
00:00:57.070 - 00:01:31.020, Speaker A: And this EIP serves that reason. A very short introduction to roll ups. So the transactions are sent by users to a sequencer. There is one designated sequencer that orders transactions for the execution. So sequencer receives the transactions and then passes it to the execution stage to validators or parties that execute the transactions in some order. So there was some discussion what order we want to take. But for now, think that it's simple.
00:01:31.020 - 00:02:16.200, Speaker A: First come, first serve order. So at some point when there are enough transactions collected from the sequencer, or there is another designated party, sometimes called page bolster. But in case of arbitrum, let's say it's sequencer, post a batch to the Ethereum mainet. So this is how things stand at the moment. And then in case of optimistic roll ups, validators coordinate to update the state of the roll up to the Ethereum. And there is some fraud proof mechanics deployed. But depending on the roll up technology, there are different ways of updating the state.
00:02:16.200 - 00:03:05.650, Speaker A: So how does new proposal help roll ups? We know that a big part of roll up costs. So transaction fees, I would say in case of arbitram, it's like 70% are call data costs. So the cost that bet poster incurs posting them on the Ethereum mainet. And if allocating new resources lowers this cost, that will lower the transaction fees on the roll up. And ideally the lowering coefficient can be 70% or three times. And this way roll ups, of course reach more users because transactions just become three times cheaper. And through roll ups, Ethereum also reaches more users.
00:03:05.650 - 00:04:00.650, Speaker A: And that's the goal too. So now how the proposal works, it creates a parallel market, let's call it data market or blob market. Originally it was proposed that target would be two blobs per block and four would be maximum number of blocks accepted in the block. And currently it stands at three blobs per block and six maximum so this is very similar to the dynamic fee update rule EIP 1559. So you also recognize that maximum is two times the target in case of gas market. Also we have maximum 30 million gas versus 15 million gas target. And also there is a matching increase in price.
00:04:00.650 - 00:04:57.082, Speaker A: If maximum number of blocks is achieved, the price goes up one, eight or 12.5%. And if it's an empty block or zero blobs, in the context of new EIP, the price decreases by one, eight or 12.5%. Okay, so now what do roll ups do? They get a stream of transactions. And as I said, once there are enough transactions, the page bolster takes them usually compresses. That's how it saves on the data posting costs. And in case of optimistic rollups, page poster just post compressed raw data transactions. But in case of CK roll ups, it's some combination of compressed raw data and state tips.
00:04:57.082 - 00:05:50.960, Speaker A: It was already discussed during tenon also. Well, of course there are different size rollups. Some roll ups have high transaction arrival rate for throughput and some have low. And the decision problem, we look at it, how often should the roll ups post? And depending what is the price of blobs and what is the price of the glass on the regular main net. So to make problem interesting, we introduce delay cost. Of course, if there is no delay cost, maybe we never post. So we post because transaction senders, users want some kind of l one finality for their transactions and they care about how quickly it is posted on L one, because it also is some proxy measure of security.
00:05:50.960 - 00:06:32.172, Speaker A: So we model the delay with a linear cost function. And in this case, aggregate delay for roll ups is quadratic in time. So there are a few parameters in the model. We have of course transaction arrival rate. So proxy measure for the size of a prolapse, there is block price that we will later assume that it's determined in the equilibrium and it's fixed. For each block there is some fixed metadata data posting cost. It's not actually fixed, it depends on the gas price on the main market.
00:06:32.172 - 00:07:18.136, Speaker A: But for the analysis we assume it's fixed. And then there is regular market gas market. And for the model also we assume that it's fixed the price, or at least the hope is that it is stable, the price of the gas. And that's what ERP 1559 promises, that it finds the equilibrium price quickly. And there is again one more parameter for the metadata data of the regular market transaction or batch posting. Okay, so total cost of a roll up, or you can translate it to a transaction by dividing total cost of a roll up by the number of transactions, it's a sum of two costs. It's posting cost.
00:07:18.136 - 00:07:54.150, Speaker A: So that's the cost that is observed. We see how much fetch poster pays and each roll up transaction incurs and needs to pay. And there is some aggregate delay cost that we also try to minimize. But this is not observed, but we know that it exists. And roll ups try to minimize that too. Okay, so now what are the differences between these two markets? Main difference is that blob price is fixed. So no matter how much data you put in the blob, you pay the same price.
00:07:54.150 - 00:08:49.272, Speaker A: While in case of using the regular market, the price that you pay or the cost you pay is proportional to how much data you put in the batch. Other than that, there are no differences between these two markets. There's one thing we can notice very quickly, is that if the price or cost per buy is higher, in case of blob, you will never post blob and you will always go in the regular market. But there is still a trade off. Because if you wait long enough to fill up the block, it can be that you are incurring very high delay cost. And that depends on the roll up size or the roll up transaction arrival rate. So if roll up is large enough, maybe it doesn't care because it fills up blocks very quickly.
00:08:49.272 - 00:09:30.052, Speaker A: But if roll up is small or medium sized, then it cares about delay costs because it takes a long time to fill up the blob. In either case, roll up can optimize the posting time for blob and posting time for batch. Because in case of batch, it is very easy. You just solve the first order condition. You write down the total cost function and find the time when to close. And the same you can do with blows. But it can be that you reach the maximum size.
00:09:30.052 - 00:10:25.072, Speaker A: And we assume that in case of batches, there is no maximum size. Of course, in reality, there is some maximum size that you cannot cost more than that in case of batches as well. Okay, so now let's assume that roll up knows when is the optimal time to post a blob and when is the optimal time to post a batch. Now, it compares these two solutions and figures out actually what should be the price of a blob. So that blog posting is more favorable for the roll up. And if it's not favorable, then it switches to regular market class market. Okay, so here, one assumption is that roll up can switch between these two markets.
00:10:25.072 - 00:11:22.452, Speaker A: So, data availability and tip, or the block market offers and gas market. And we know that in case of optimistic roll up or in case of arbitrarion, that is doable. And I believe that for zk it can also be done. So it is fine to use one data availability option one time and next round use another availability option then. Observation we already made was that per byte cost in the block market is lower than per byte cost of a transaction in the regular gas market. So, to obtain further results, we assume continuous time. So assume the transaction arrival rate is the same and they arrive continuously.
00:11:22.452 - 00:12:08.728, Speaker A: And also equilibrium price for the globes. But as I said, the dynamic fee mechanism promises that it. And actually there are some empirical studies that the gas cost in the regular market reaches equilibrium price. And we hope that in case of blobs also it will reach equilibrium price quickly and it will be steady for some time period at least. Also, we assume that roll ups are myopic in the sense that they only care about their costs and benefits in this round. So they are not forward looking. And they don't, for example, try to kick out their competitors out of the market.
00:12:08.728 - 00:12:42.064, Speaker A: So they don't apply any aggressive strategies or some sophisticated strategies. So they just care about optimization in this round. They are not strategic in some sense. So, with these assumptions, we obtain first proposition that there exists some threshold. So that if the transaction arrival rate of a roll up is lower than this threshold, then it will switch to using L one gas market. And this is kind of intuitive. If you are small enough, you take too long to fill up the blob space completely.
00:12:42.064 - 00:13:23.424, Speaker A: Then you will switch to much more flexible L one gas market. But you will pay more per byte, but you will save on the delay costs. Next, we look at the problem of merging or joint block posting. And we make few assumptions. The first assumption is that roll ups can actually share the blog. And this is not a trivial assumption, it needs some engineering work. So they are able to extract their own information from the posted blob, and not extract the information of the other roll up.
00:13:23.424 - 00:14:17.216, Speaker A: Also, we assume that in the equilibrium state, we are both posting the blobs. And this is important, because if one roll up is posting blobs, and another roll up is small enough to post on the regular market, and that one joins, then the blob price goes actually up. And it might not be beneficial for the large roll up. But if both of them are posting blobs, and they join into posting blobs together, then the blob price actually goes down. And both of them benefit from that. So that's our proposition that both of them, both of the roll ups, independent of what are their transaction rates, improve their costs if they join the block posting. Okay, so, so far so good.
00:14:17.216 - 00:14:55.944, Speaker A: Both of them are improving. But now, interesting thing starts. How should they share the costs of posting? Because that's the part of cost that is observable. So this is a bit controversial. So one very quick idea is to share the cost proportionally. So if one roll up fills up 70% of the blog and another fills up 30%, so maybe they just share 70 30. And it turns out that this is actually neither here nor realistic.
00:14:55.944 - 00:15:44.344, Speaker A: Because note that small roll up saves a lot of delay time at the expense of large roll up. It only provides 30% of the data, and it already posts as if the blob was full of its own data. So per byte cost is as if it was its own data. But of course it's not, because 70% of the data came from the large roll up. So large roll up has some bargaining power. So like large roll up says, I provided you very low delay time, so maybe you compensate on the blog posting costs. And instead of going with some definitions of what is fair allocation of costs, we went with an axiomatic approach.
00:15:44.344 - 00:16:32.600, Speaker A: So let's list the properties that the cost sharing rule should satisfy, and then find the cost sharing rule. Okay, so there is this very old and very famous niche bargaining solution that exists in the economic literature that takes this axiomatic approach, lists properties, very reasonable properties. When you see them, you're like, okay, these are very reasonable, nothing against them, but that already gives exact cost sharing rule. So we have this disagreement point. So that's where bargaining comes in. If they don't join, we know what are their transaction fees for each prologue. And we know what happens if they join post DevOps.
00:16:32.600 - 00:17:05.892, Speaker A: So only thing we need to decide is how they split the cost. And the proposition says that actually the bargain solution splits in favor of a large roll up. So large roll up always pays less than proportional large roll up, provided 70% of the lob, it always pays less than 70%. But on the other hand, it always pays more than half. So it's not very dramatic. It always pays more than half. That's good enough.
00:17:05.892 - 00:17:50.704, Speaker A: And also in this solution, we have that small roll up always improves more in relative terms. So a large roll up improves some percentage, let's say 10%. Small roll up improves more than 10%. But usually, I think in case of 70 versus 30, and this is the only parameter we actually care how, how much each roll up provides improvement of the small roll up is like 25%, while large roll up is like 10%. So small roll up improves more. Okay, so very quick discussion on the topic. We showed that roll ups can improve by merging their blog posting.
00:17:50.704 - 00:18:32.748, Speaker A: And this can be generalized to more roll ups and to other data availability options. And call splitting depends only on the relative sizes of roll ups. And also roll ups that themselves don't make it to blog posting. Because they are small enough, they may team up with other roll ups and join the blog posting. It will increase the blob price. That is correct, but it can be that they still make it in the equilibrium and now they prefer to post blobs and lower their transaction fees. So there was a lot of simplification.
00:18:32.748 - 00:19:13.552, Speaker A: And in the future work we want to look at different extensions. One is compression rate. So far we didn't assume compression rates. And this is important because this actually favors the large roll up, doesn't favor the small roll up, because small roll up is not gathering enough data to have good compression. But actually roll ups, as we know, save a lot on the compression as well. Also, we assume that the price is found in the equilibrium quickly. But what happens if it doesn't, and how roll ups react to that.
00:19:13.552 - 00:20:09.772, Speaker A: And another one is to relax the myopic assumption and assume that now roll ups are more strategic and they can post more aggressively. What happens then? It can be that larger roll ups can post small blobs and they push out small roll ups out of the market because of that. So they drive up the price of blob. And so we also want to look into how the dynamics of the market will develop. If, for example, EIP provides. EIP provides more and more resources for data availability. If execution moves to the roll ups, for example, then it can be that EIP provides more blobs per block and lowers the gas consumption on the other resources.
00:20:09.772 - 00:20:38.310, Speaker A: Then it's interesting to see how it evolves. For example, what kind of new users are we onboarding? And that will of course depend on the distribution of user types. And user types are like, how much do they care about security? How much do they care about speed and peace? So I think I'm out of time. Thank you. If you have any questions, either now or I'll be here for some time. Thank you.

00:00:09.770 - 00:00:45.222, Speaker A: Welcome to the Infinite Jungle, the podcast about the evolution of Ethereum. I'm your host Christine Kim, VP of research at Galaxy. I am recording from a new place. I'm actually in Florida right now, recording remotely. We've got a great episode for you today. We're going to be talking about the final preparations for the main net Denkun upgrade, and we're also going to be featuring an interview with Ethereum protocol developer and researcher Terrence Sao. Very excited to share that interview.
00:00:45.222 - 00:01:38.780, Speaker A: It was one of the three interviews that I did directly from ETH Denver. It's a crypto conference that happened over the past weekend. So before we begin and start the show, here's a quick disclaimer. I need to remind you to please refer to the disclaimer linked in the podcast show notes and note that none of the information in this podcast constitutes investment advice, an offer, recommendation, or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities the Ethereum main net Denkoon upgrade is happening in a few days. It's happening on Wednesday, March 13. It's coming up, and developers on their latest developer call talked about the final preparations that need to happen for the upgrade. Developers themselves have done most of the work already.
00:01:38.780 - 00:02:50.370, Speaker A: The bulk of their work is really preparing the upgrade, making sure that it's tested and releasing the software for everyone who is running Ethereum nodes to use and upgrade to. So you would think that Ethereum developers are kind of taking a backseat, not really doing much other than encouraging people to upgrade their nodes, but surprisingly major consensus layer client teams including Prism, Techu, Lighthouse have all been releasing new software just right up until really the last minute. I mean, we're in the final couple days before the upgrade, and the client teams shared on the latest dev call that they're still putting out releases. Now, these releases are recommended. They have minor optimizations and changes for node operators to use if they want. But really the most important, you have to upgrade to this version or else you're going to be as an Ethereum node, disconnected from the network. Those mandatory releases have gone out two weeks, two or so weeks prior.
00:02:50.370 - 00:04:07.450, Speaker A: So as an Ethereum node operator, if you're not up to date with the absolute latest versions that are still coming out from client teams, you're in the green. These are just recommended client releases. But still, I was surprised to hear from the latest dev call that developers are still putting out releases for the Denkun upgrade this close to the actual main net launch. And one of the things that I wanted to talk about on the first half of the show is exactly what users need to do, because it's more complex than people realize. When I say that Ethereum nodes need to upgrade, I'm primarily talking about the computers that are connecting to Ethereum. Ethereum is a software, and in order for you to connect to the network, you need to be running a node, an Ethereum node. And before Ethereum upgraded to a proof of stake blockchain, before, what was it, September 2022, the users, the people who wanted to connect to Ethereum, be it to help secure the network as a minor, produce blocks, or get raw data from the blockchain, query it, et cetera.
00:04:07.450 - 00:05:13.726, Speaker A: Whatever you wanted to do by connecting to the network, you primarily had to just use one software, like a geth client. This is what we call execution layer clients. You had one node and you just had to upgrade it before the set time that the upgrade was supposed to activate. So that's what it was like before Ethereum upgraded to proof of stake in September 2022, you had that software, the execution layer software, and you basically upgraded it to the version that would be compatible with whatever upgrade was about to happen on Ethereum. But then after the proof of stake upgrade went live, called the merge, people now had three pieces of software that they needed to use and make sure was properly upgraded and is working smoothly. It's not just the execution layer, it's not just the node that you have to connect to the Ethereum blockchain. You now have an additional network.
00:05:13.726 - 00:06:21.266, Speaker A: It's called the consensus layer, aka the beacon chain. And so for people, primarily the people operating nodes, or people who are financially incentivized to do so, the validators that earn rewards from attesting to blocks, from proposing blocks. These validators are operating the execution layer node, the consensus layer node, and they're also operating a software to earn additional rewards in the form of MEV maximal extractable value. This is called Mev Boost. It basically allows a validator to connect to multiple different relays, which are these marketplaces where they can receive blocks containing this additional reward MeV. So in preparation for Denkoon, what developers are asking people to do, asking node operators, particularly validator node operators, to do is upgrade their consensus layer node, their execution layer node and their MEV boost software. And I recently learned from the last def call that you can add another layer of complexity to this by running two different consensus layer clients for your consensus layer node.
00:06:21.266 - 00:07:28.250, Speaker A: These are called mixed validators. You can basically use your consensus layer client. You can use two different consensus layer clients for just the consensus layer node. It's called like your validator client and your beacon node. And the functionality of the beacon node is that you use a particular software to query the beacon chain, the consensus layer, where all the validator activities happen, and then you can use a different client for your validator client, which is basically the software that allows you to fulfill validator responsibilities. So complexity upon complexity. And I think one of the things that definitely would encourage more at home validators, people who can connect to the Ethereum blockchain, help validate the Ethereum blockchain with as little kind of technical know how as possible, and increase the number of people that are running these validators, is definitely creating ways to simplify running a node, like running an Ethereum node.
00:07:28.250 - 00:08:49.042, Speaker A: And for this effort, there's quite a lot of initiatives like light client development, which would try and allow people to run nodes on very lightweight types of machines, like instead of a very bulky computer, allow people to operate these nodes very easily on even like a handheld device. But these are all initiatives that will take years to develop. And I think in the meanwhile, the complexity of being able to, because of the frequency of how often these upgrades happen, the complexity of managing all pieces of software in preparation for an upgrade is definitely one of the reasons why we see so many people kind of wanting to participate in staking pools and basically seed away the responsibility of managing all this software, because it's a lot, it's more than it was definitely a few years ago to this point. I think there's one other kind of related topic that I want to talk about. We talked a little bit about what developers are doing in preparation. They're continuing to release minor optimizations to their releases for the Dankoon upgrade. What users have to do, they've got to upgrade all three of those pieces of software.
00:08:49.042 - 00:10:15.170, Speaker A: And that's definitely a higher complexity than it was a couple of years ago, but the Ethereum protocol in general, if you think about the amount of testing that goes into the network, into these upgrades, that has also significantly increased. Not only are you testing these different kinds of software, and mind you, the consensus layer and the execution layer is definitely software that all of the developer client teams of Ethereum, some of which are funded by the Ethereum foundation, but funded by many different people in the Ethereum ecosystem. The MeV boost software is actually maintained and tested by the flashbots team. So lots of different people kind of pitching in to make sure that all these pieces of software are working, but not only these pieces of software. There's several different APIs that are needed to facilitate communication between these nodes. Communication between the execution layer and the consensus layer facilitate additional help for validator node operators that are trying to manage the cryptographic keys required to fulfill their validator responsibilities. And these are all APIs and pieces of software that was discussed on yesterday's dev call for quite a while for being under specified in certain areas.
00:10:15.170 - 00:11:17.814, Speaker A: And when under specification happens, when there's areas of Ethereum's code that's under specified, you have different implementations across clients. So you have a specification that says here's how you build, or how an Ethereum node should be working, or here's how the communication between the execution layer and the consensus layer client should happen. And when those specifications are under specified, then you get differences between clients. And some of those differences can make the testing process to make sure that all of the clients are working properly more difficult. And it can also lead to certain confusion in people who are running multiple clients. So one of the main topics that was discussed was the fact that the API endpoint for block value through the Beacon API, which is the API that allows you to query the beacon chain, is under specified. It could result in differing block values being reported depending on the client software you use.
00:11:17.814 - 00:12:38.046, Speaker A: So even if the block itself has the same value across all clients, because of the specifications, that because of the way that the specifications are implemented across different clients, you could get a different block value returned to you when you call on that endpoint. And by block value, I mean how valuable is the block, what is the issuance rewards, what are the fees that the tips that you get from the block and the MEV contained in the block? And that's the value of the block. And there's slightly different ways to calculate this. And so there was a bit of back and forth between developers on how important is it that these values have to be identical across different clients. But it definitely is an ongoing topic of discussion where developers want to ensure that there is as much specificity as possible. And if there's specificity, then you can have these clients, the testing for all the Ethereum clients and these pieces of software to be a lot easier, and also with the idea of mix validators to be able to interchangeably use different clients. So there's quite a bit of detail that goes into maintaining the Ethereum protocol and the Ethereum code base.
00:12:38.046 - 00:13:51.346, Speaker A: And I think this is very natural, because over time Ethereum has done more upgrades, it's gotten much larger as an ecosystem. It's included a lot more features over time through every single upgrade. And so this really kind of boils up to this question of as Ethereum becomes more complex, should the frequency of the upgrades that happen on Ethereum decrease, and should we start to see Ethereum as a protocol become more ossified? And this is a very large topic that is definitely not new. Ethereum developers have discussed this for quite a bit and are thinking about this, but one of the reasons I bring this up, because it's very relevant to the next upgrade that's going to happen after Denkun. Obviously for node operators and for developers that are just focused on Denkoon, which is happening in a couple days, that is the first priority. But after Denkoon, developers have discussed rushing Electra. I use the term rushing in a very light way, because of course developers would never suggest an upgrade or push through an upgrade that isn't ready, completely ready, with high confidence to the network.
00:13:51.346 - 00:15:22.862, Speaker A: But there is talk about reducing the scope of the electra upgrade so that it can go out as soon as possible, so that it can go out before the end of the year. And I wonder if this kind of pressure to keep upgrading, keep putting out these code changes will one day cause quite a bit of vulnerability, of risks to the network, because there's many different moving pieces, and these code changes are taking a lot more testing effort than they used to, because now they touch so many different pieces of software. And so I definitely think that the frequency of upgrades on Ethereum should slow over time. But that is not the reality that I think Ethereum developers are living in. There's so many different objectives, many of which we've talked about on this show already. We've talked about Maxib, we've talked about inclusionless. There are real improvements that do need to be made to the Ethereum protocol, some of which may not feasibly happen in a short timeline because of how bulky of a protocol now Ethereum is, and how difficult I think it will be to continue upgrading Ethereum in a very fast and timely manner.
00:15:22.862 - 00:16:21.714, Speaker A: And to put things into perspective, Dencoon is Ethereum's 16th hard fork, 16th backwards incompatible upgrade. And for the consensus layer, the beacon chain, which launched back in December 2020, Denkun is the fourth backwards incompatible upgrade. And Denkun and Ethereum, the consensus layer, has never been upgraded twice in one year. So I think it's quite ambitious of developers to aim for the electra upgrade to happen this year. And I wonder if more practically speaking, the electra upgrade, if developers should target the electra upgrade to happen not this year, but next. So this is a topic that I actually discussed with Ethereum developers. So prism developers on stage at E Denver.
00:16:21.714 - 00:16:31.850, Speaker A: So I want to share this clip of the conversation we had about this very topic, about the increasing complexity of Ethereum and the frequency of upgrades. So check out the clip.
00:16:32.590 - 00:16:58.030, Speaker B: Okay, so one final big question. Unfortunately, we're not going to get time to talk about Electra like I thought, but we'll have another panel for that, another time. Big question about the future roadmap of Ethereum. So the merge was supposed to be the last phase of development. And now with Proto Dank sharding. I don't know if you guys know this, but Protodank sharding is proto. It is like one stepping stone to full dank sharding.
00:16:58.030 - 00:17:36.718, Speaker B: So there's more upgrades that need to happen to even get the full vision of what we're talking about to reduce fees for l two s. And aside from that, there's just a ton of other development items. Vertical maxi, the inclusion list enshrined PBS. It seems like a never ending list of upgrades that need to happen on Ethereum. And I'm wondering if this worries you. I'm wondering if you guys think that this constant pattern of more upgrades is actually a major centralization risk for Ethereum. The fact that Ethereum can upgrade so easily, so quickly.
00:17:36.718 - 00:18:03.880, Speaker B: Node operators don't ever kind of hard fork away from Ethereum and the release that the client teams are putting out, this seems like a norm and a vision for Ethereum that's not going to be changing anytime soon. How concerned are you guys about the increasing complexity that comes with all these upgrades, the increasing centralization and resources that comes with having to upgrade like twice every year.
00:18:05.530 - 00:18:34.830, Speaker C: My short answer is, software is never finished, and Ethereum core protocol, for example, will be continually making. Even if you said it's feature complete and we're not adding more features, there's still maintenance stuff to do. And this year in Electra, like the prism team's point of view on scoping it is let's pay some of this tech debt down and kind of simplify things, and then we'll go back to the more complex ideas in the following fork. Terrence, what do you think?
00:18:34.900 - 00:18:56.386, Speaker D: I'm not concerned at all. I mean, Ethereum works as of today, right? If everyone goes away, Ethereum will keep working. We have great client diversity. We set up a really good foundation right now. We just keep adding futures on top that we wouldn't have, right? And I think we have accomplished what we wanted to accomplish, which was the merge, and now we have some sort of data sharding.
00:18:56.418 - 00:18:56.566, Speaker E: Right.
00:18:56.588 - 00:19:03.290, Speaker D: And we can just keep building on top. But yes, there's a lot to do, but I don't feel like we're pressured to do this tomorrow.
00:19:03.870 - 00:19:08.570, Speaker B: And so you guys aren't worried that one of these upgrades is going to break Ethereum?
00:19:10.270 - 00:19:30.370, Speaker D: Go ahead. No, because there's client diversity. That's the only reason I don't worry about it. There's enough people at different geographic location, there's different software stack and stuff like that. If one of the bug goes down, unless it's a really crazy spec bug that's open source, which everyone can view, then most of the clients will still survive.
00:19:30.950 - 00:19:41.960, Speaker C: Yeah, same answer for me. It would have to be something fundamentally wrong with the specification. Not really. In particular client because of the client diversity model, the multi client model.
00:19:42.490 - 00:19:44.230, Speaker A: Right. Well, thank you guys.
00:19:44.300 - 00:19:59.450, Speaker B: Thank you guys so much for chatting with me about the Dankoon upgrade. I hope this was helpful for people in the audience, too. If you're a node operator, please update your nodes before March 13. And yeah, thanks for listening.
00:19:59.970 - 00:20:21.810, Speaker A: All right, we are going to move now to talking to Terrence Sao. He and I chatted at ETH Denver further after this panel about a variety of different objectives for the Ethereum protocol, primarily inclusionless and enshrined proposer builder separation. So this is that interview.
00:20:22.630 - 00:20:43.462, Speaker B: Welcome back to the show. I am here with my dear, dear friend Terrence Sao, Ethereum protocol researcher and developer at offchain Labs. He builds the prism client and prism is one of the most, it is the most popular consensus layer client that validator node operators are running. Terrence, it's an honor to have you on the show.
00:20:43.516 - 00:20:49.082, Speaker D: Thanks for having me. And it's a team effort and I didn't do much. It's mostly my team behind it. And yeah, thanks for having me.
00:20:49.136 - 00:20:52.890, Speaker B: This is a little creepy, but I listen to your voice like every Thursday.
00:20:54.110 - 00:20:59.582, Speaker D: It's also at 06:00 a.m. So my voice doesn't sound that nice when I wake up at 06:00 a.m. But yeah, it's very early for me.
00:20:59.636 - 00:21:09.460, Speaker B: I feel like you are one of the most public figures, though, for definitely, like the prison client. I feel like you do a lot of speaking and you do relay a lot of information.
00:21:11.750 - 00:21:17.234, Speaker D: It's one of those things that's been the space that's low enough that you kind of just dive into it.
00:21:17.352 - 00:21:51.786, Speaker B: Yeah, well, I want to talk more on this episode about the research that you're doing as an Ethereum protocol researcher. And one of the main things that I've noticed you've been spending a lot of time on is the design for inclusion lists. And I've talked on this show before about why I don't think inclusion lists are a good idea. But for our listeners, can you give a brief recap of what inclusion lists are and the main design for it that people are now gravitating towards? Like, this is the main design that this is how inclusion lists are going to be implemented.
00:21:51.818 - 00:21:58.802, Speaker D: Yeah. So let's start from the beginning, right? So what get us here at the first place.
00:21:58.936 - 00:21:59.378, Speaker E: Right?
00:21:59.464 - 00:22:10.674, Speaker D: So if you look at how blocks are proposed on the main net today, 90% of the blocks are proposed through MeV boost, relayer and builder, that path.
00:22:10.722 - 00:22:11.320, Speaker E: Right?
00:22:12.970 - 00:22:34.830, Speaker D: Okay. So now we have to kind of assume, by definition, that if your block are proposed by relayer and the builder, you're not using default client software, because how you propose a block that's outside of my code, like my team's code, whoever wakes up at the ACD's code, right? So that's a lot of control.
00:22:34.900 - 00:22:35.230, Speaker E: Right?
00:22:35.300 - 00:22:39.390, Speaker D: So that's kind of the fundamental of the problem to date.
00:22:39.460 - 00:22:39.886, Speaker E: Right.
00:22:39.988 - 00:23:14.150, Speaker D: Now you look at, okay, why would someone do this as a validator, as a solo staker, or as lido operator, right? You do it because there's more profit there, right? So typically when you say you solo stake, people still solo stake with MPV boost, right? You outsource your blog proposal to someone else. There's probably like 1% of them solo stake in a way. They don't use MVV boost, they just use default, whatever, get, never mind wherever they pack their transactions.
00:23:14.230 - 00:23:14.666, Speaker E: Right.
00:23:14.768 - 00:23:28.362, Speaker D: So now what's the problem? The problem is that four out of the five builders are censoring today. The relays are also. Some of the relays are censoring. So there's multiple layers of censorship.
00:23:28.426 - 00:23:28.750, Speaker E: Right.
00:23:28.820 - 00:23:43.726, Speaker D: And as a validator, I have to choose between profitability or I have to choose between running some sort of altruistic. I use my local block, but then I don't have that profitability.
00:23:43.838 - 00:23:44.258, Speaker E: Right.
00:23:44.344 - 00:24:11.290, Speaker D: So this is kind of the fundamental problem that we're trying to solve here. It's just that as a validator, I shouldn't have to make that choice. Right. Today I can still use the MeV boost block. I want to, but I can still include my own transactions. And that is essentially what inclusion this is, is that to allow your validator to have a say to include your own transactions and still use the builder's block.
00:24:11.950 - 00:25:00.394, Speaker B: One question about the origin story, though, because we're going way back about why, and if we're going to go back, we should be clear about why. Is it not that validators are proposing their own box? Let's just say there were no relays, there was no MEV booth, there were no builders. Then validators become extremely specialized in packaging the MEV into their block. And validators such as the ones that are able to specialize and are able to compete, they're probably the ones that have a lot of resources. They're professional, they're companies, they're regulated, and they directly censor the block. Without MeV booths, it's the validators that centralize and the validators that censor. And so we have MeV booths to take away that power from.
00:25:00.394 - 00:25:11.662, Speaker B: Validators, give it to builders and relayers, and now we have inclusionless, which is trying to give it back to the validator. And I'm confused because I thought that was the whole point, was that validators themselves.
00:25:11.796 - 00:25:17.166, Speaker D: So let's go back to the beginning. Right. So the problem that you're describing is that validator can also censor the block.
00:25:17.198 - 00:25:17.490, Speaker E: Right.
00:25:17.560 - 00:25:18.414, Speaker D: Versus the builder.
00:25:18.462 - 00:25:18.722, Speaker E: Right?
00:25:18.776 - 00:25:46.566, Speaker D: But our argument is that validator censoring problem, the validator sensor problem is much less severe than the builder related sensor problem. Today. I actually wouldn't mind validator censoring at all, but I will mind very deeply if the builders are relayer censoring. I presume most of the validators, maybe not most, but there's a healthy amount of validators that would not censor. But today we are seeing censor block because they are using the builder and the relayer.
00:25:46.678 - 00:26:10.210, Speaker B: But based on what data, Lido is the largest staking provider and Lido is primarily operating the node. Operators of Lido are mainly professional staking operators like figment and I should name a few others. What is the data or what makes you think that? Validators. There's a high number of validators that would not send.
00:26:10.280 - 00:26:36.294, Speaker D: Because if you look at Lido's case, right today, as the lido operator, you don't have a choice between solo states. We can build your block solely or using the builder. You always have to use the builder, right? So you just essentially trust whatever builder gives you and then you sign it and you propose it, right? But if today I am a validator, idle validator, I don't have to use the builder, then I actually have a choice to basically pull in what I want to propose.
00:26:36.342 - 00:26:36.940, Speaker E: Right.
00:26:37.310 - 00:26:44.446, Speaker D: And at that point, I can choose to censor or I can choose not to censor, but having the option is very important. But today we don't have the option at all.
00:26:44.468 - 00:26:45.040, Speaker E: Right.
00:26:45.810 - 00:26:48.542, Speaker B: Okay. Let's talk a little bit about the design.
00:26:48.676 - 00:26:49.262, Speaker D: Sure.
00:26:49.396 - 00:27:20.630, Speaker B: What is the main design for inclusionless that we're going with that you think developers are going to do for the electra upgrade? Because I'm under the impression that there are some developers, aka Marius, but he has tweeted that I think a better solution would be to make inclusion list, kind of like an optional, not an in protocol thing. Is that really the design that more developers are banding towards, or what's the design for? I can.
00:27:20.780 - 00:27:23.702, Speaker D: I can compare the two designs here.
00:27:23.756 - 00:27:23.938, Speaker E: Right?
00:27:23.964 - 00:27:45.154, Speaker D: So Mario's design is essentially forcing inclusion. This applied to the builder of your same slot. So, meaning that here I'm a proposer, I'm proposing a slot n. I wish these transactions to my builder at slot N, and then I wish the builder will include it for my own block. Does that make sense?
00:27:45.192 - 00:27:46.834, Speaker B: So far it's a wish list.
00:27:46.952 - 00:27:50.606, Speaker D: I mean, it's kind of like, or don't give me the block.
00:27:50.638 - 00:27:51.218, Speaker E: Right.
00:27:51.384 - 00:28:02.694, Speaker D: So here are the transactions I must include in this slot. If not, then I will not accept your. Yeah, basically this is my wish list.
00:28:02.732 - 00:28:03.270, Speaker E: Right.
00:28:03.420 - 00:28:05.574, Speaker D: So this is Mario's design. Right.
00:28:05.772 - 00:28:07.670, Speaker B: And this requires no protocol changes.
00:28:07.820 - 00:28:22.766, Speaker D: Yes. You still need client code changes. It doesn't require a hard fork, but you kind of require everyone to activate the software at the same time. But it's not backwards. But it is backwards compatible in a way. Right, okay. But now the fundamental question is just that.
00:28:22.766 - 00:28:51.810, Speaker D: Okay, well, as the validator, why would I want to do this at first place, right? Because now I give builders my wish list, and then if today I am a rational validator, I want to use as many builders as possible, right? But once I give my builders my wish list, then I'm probably going to lose some builders, right? Because the builders won't say, no, I cannot use your transaction, I cannot build your block anymore because these are the transactions I must include.
00:28:51.890 - 00:28:52.520, Speaker E: Right?
00:28:53.450 - 00:29:22.026, Speaker D: This is Mario's design. It's nice. It's not very forceful, right? Because now builder can choose like you can choose. So our design is essentially saying, well, instead of giving the builder of the current slot my wish list, I give validator the next slot my wish list. Meaning I'm basically enforcing a constraint on the validator of the next slot. So this is a lot more forceful.
00:29:22.058 - 00:29:22.254, Speaker E: Right?
00:29:22.292 - 00:29:45.926, Speaker D: Because I think of. Because the validator in the next slot all of a sudden cannot use certain builders because of my wish list, right? So this is a very more force portion string, right? But in a way it is a little bit more incentive compatible because now I will not lose my profit because when I propose my wish list, it doesn't affect me, it essentially affect the next person.
00:29:46.028 - 00:29:46.534, Speaker E: Right?
00:29:46.652 - 00:29:51.974, Speaker B: So instead of forcing the inclusion of transactions directly with the builder of your.
00:29:52.012 - 00:29:53.610, Speaker D: Slot, you push it to the next person.
00:29:53.680 - 00:30:19.566, Speaker B: You push it to the next person. And now builders though, can they still have the optionality of being like, actually, I don't want to build this block because of regulatory reasons, et cetera. So in terms of the validator, including that, including the inclusion list, whether it goes to the next validator or the current validator, do you think builder behavior would kind of change because builders in either design can still reject the block?
00:30:19.598 - 00:30:19.842, Speaker A: Right?
00:30:19.896 - 00:30:20.514, Speaker E: Exactly right.
00:30:20.552 - 00:30:30.914, Speaker D: So now the problem becomes the nest validators problem because now the nest validator's problem because there are certain builders they cannot use anymore.
00:30:30.962 - 00:30:31.366, Speaker E: Right?
00:30:31.468 - 00:31:00.560, Speaker D: But then you can think of what if today the two validators are the same entities, two slots in a row, right? Then you're kind of back to the original problem, what Mario is describing, because you have two validators, there are seven entities in a row. Then they may do a very nice inclusion this for the first one, such that the second validator, which is himself, doesn't get constrained. Right, but then it's still better than before. I mean, proposing two slots in a row happen, but doesn't happen all the time.
00:31:01.170 - 00:31:18.130, Speaker B: This is fascinating. I didn't know that the design for these two proposals was about giving the inclusion list to the next validator versus the builder of your slot directly. What is, in your view, the more likely version that will be in Electra.
00:31:18.210 - 00:31:48.458, Speaker D: I think the most likely version is the one that pushes to the next slot validator, unless there is a much implementation simplicity. But when I compare those two designs, I see, yes, the first design, which we talked about first doesn't require a hard fork, but it's still a lot of software changes. The second design requires a hard fork, but it's still software changes. The software changes. It is almost the same, but it just requires a hard fork.
00:31:48.474 - 00:31:48.846, Speaker E: That's it.
00:31:48.868 - 00:31:56.482, Speaker D: So given that if the software changes are the same between the two design, I would rather have the more forceful one.
00:31:56.616 - 00:31:59.090, Speaker B: And I suppose since a hard fork is going to happen anyway.
00:31:59.160 - 00:31:59.538, Speaker D: Exactly.
00:31:59.624 - 00:32:47.810, Speaker B: With or without the inclusion list included, I guess it does make sense that this, in terms of the repercussions of this and the actual impact that it's going to have on censoring activity. Have you talked to builders, have you talked to professional staking providers about how they are going to react to forced inclusion of transactions? In terms of do you think that there are going to be staking operations that shut down? Do you think there are going to be builder operations that shut down? I mean, these are changes that could potentially impact an entire industry. Built on top of Ethereum. Are developers planning on just building it and then releasing it and then seeing what happens? Or tell me about the outreach that you guys have done and what's the feedback been?
00:32:47.880 - 00:33:14.694, Speaker D: Right, so this is the same with EPBs as well, right? It's like designed such that will have cascading effect through the ecosystem. This is why we want feedback. If you have been paying attention to the EIP and still very early, we have been talking about this for only two to three weeks. But if you're paying attention to the EIP, which have been circling around, we would love any feedback for now. We haven't gotten any feedback from anyone besides the developers trying to analyze all the edge cases.
00:33:14.822 - 00:33:24.442, Speaker B: Okay. But this seems like a very important stepping stone to whether or not inclusion lists would go into the upgrade.
00:33:24.506 - 00:33:30.094, Speaker D: Yes, community feedback is important. Design complexity is important. Yes, those are important.
00:33:30.292 - 00:33:59.714, Speaker B: On the topic of censorship and inclusionless is definitely a code change that addresses censorship. There must be a few other code changes that we're researching, that developers are researching and thinking about to make Ethereum a more resilient, censorship resistant blockchain. One of the ones that you mentioned right now is EPBS enshrined proposer builder separation. Can you give us a little bit of an overview of that one and the current design for EPBS?
00:33:59.762 - 00:34:11.990, Speaker D: So EPBS is also very interesting. I feel like EPBS has gotten more hype over the last few weeks because we have gotten some invalid blocks on the mainnet because of the builder, and now people are picking up the urgencies.
00:34:12.070 - 00:34:12.410, Speaker E: Right.
00:34:12.480 - 00:34:26.830, Speaker D: And EPBS has something that me and my team have been looking at over the last year. So the fundamental problem today we want to solve is that the relayer is trusted between the builder and the proposer. The relay is this trust entity.
00:34:26.910 - 00:34:27.298, Speaker E: Right.
00:34:27.384 - 00:34:39.702, Speaker D: And then, I'm not saying the relay is a bad thing, but then the relay is trusted. But anything that's trusted is not good. We want a trustless protocol, and that's what we have been working towards the last four years.
00:34:39.756 - 00:34:40.166, Speaker E: Right.
00:34:40.268 - 00:34:46.454, Speaker B: When you say trusted, you mean that the validator relies on the relay to get their blocks, yes.
00:34:46.492 - 00:34:57.658, Speaker D: And then the builder relies on the relayer to now dig their information as well. Right. Basically just to do the right thing. But then most of the relayer, they run on private source code.
00:34:57.744 - 00:34:58.090, Speaker E: Right.
00:34:58.160 - 00:35:17.394, Speaker D: And another thing is relay is also very expensive too, right. We don't have a good funding model for relayer as of today, right. They spend tons of money and a lot of relayers have been doing things such as taking profit from the builder and then the validator. They take a profit, but without even announcing it. And that's also kind of bad as well.
00:35:17.432 - 00:35:17.778, Speaker E: Right.
00:35:17.864 - 00:35:28.674, Speaker D: A lot of realists are also openly delaying proposals, requests such that the bid is more profitable, playing some timing games. Yes, exactly.
00:35:28.792 - 00:35:29.026, Speaker E: Right.
00:35:29.048 - 00:35:34.102, Speaker D: But that's something that we don't know. No one knows because this is like a black box that no one knows what's happening inside.
00:35:34.156 - 00:35:34.422, Speaker E: Right.
00:35:34.476 - 00:36:00.314, Speaker D: So therefore this is what I mean by trusted. Right. And then another thing is that if today I am a builder, right, if I want to basically work with a validator directly, I have to go to the relayer, right? But then the relayer may have their VIP list of the builders that they are favoring to, right. So as an up and coming builder, that it kind of sucks, right. To have to go through the relayers, like finding how to get to the validator or to the proposer.
00:36:00.362 - 00:36:00.622, Speaker E: Right?
00:36:00.676 - 00:36:11.774, Speaker D: So the way what EPBs means, at least in my mind, is that to get rid of the relayer and open this direct communication between the builder and then the proposer such that it's trusted.
00:36:11.822 - 00:36:12.420, Speaker E: Right?
00:36:13.590 - 00:36:38.042, Speaker D: So how it works today is that the proposal will request the builder for the bid, the builder signs the bid, and then the testers votes for what's the head of the chain. And then if everything goes smoothly, the builder will review the payload. And then you have some other testers that votes for the reveal of the payload, right? And this is kind of the simple model of how it works, but there are a lot of design complexities that goes with it, right?
00:36:38.176 - 00:36:40.506, Speaker B: The builder reveals the payload to the.
00:36:40.528 - 00:36:55.502, Speaker D: Validator or just to the network as a whole, to every person. But there's a lot of design complexity which we don't have to go through in this one. This is still a very, I would say, slightly early design proposal.
00:36:55.646 - 00:37:36.800, Speaker B: One of the pushbacks that I've heard about EPBs and the design complexity is that even with EPBs, there is a high chance that relays will continue to exist and will continue to provide advantages for builders as opposed to going directly to the protocol. Because maybe if you go to the protocol. You can't do timing games. Maybe your block, it's more higher latency. Maybe if you go through the protocol directly, then you have to stake a certain amount and you can't put up that capital if it's true that relays are going to exist anyways, even with EPBs, why even do EPBs in the first place?
00:37:38.930 - 00:38:21.758, Speaker D: So let's just go back to beginning. What is relayer good for? Relayer is good for offering rich feature that we cannot offer, right? Such as big cancellation, such as you can delay some response to generate more profit, right? Yes, 100% agree that relayer will exist after EPBs, but what is important is that the builder becomes a relayer, right? So you can think of in the future the builder itself is a relayer. But instead of validator requesting the relayer to get the bid to do all the information, validator just goes straight to the builder. The builder is a relayer. So you can think of you have MeV boost today, right? You basically put your relayer endpoints. Now you just put the builder's endpoint, you can find any builders you want.
00:38:21.924 - 00:38:39.230, Speaker B: Okay, so you envisioning vertical integration, builder and relay being like a combined entity, a combined actor, and validators. Sure, relays will exist, but those relays will be connected directly to a builder that would be proposing the blog.
00:38:39.310 - 00:38:54.360, Speaker D: I mean, they don't have to offer older features, like they can offer certain features, but it would be very common that builder just open his RPC port such that anyone can request anything. And by definition, that is the relayer today.
00:38:54.970 - 00:39:43.270, Speaker B: That's fascinating. Another major kind of concern around the design complexities of EPBs that I've been hearing about is privacy. So this idea that the relay protects the proprietary information that a builder has, if you have a really juicy MeV strategy, and when you reveal that bid, you're not revealing it directly to the validator in case that they're able to front run you. What is kind of the privacy aspect of what the current EPBS design supports? Is it using trusted hardware like SGX? Is it using zk proofs? To what extent is specific privacy technology a core part of EPBs? Is it not at all.
00:39:43.340 - 00:40:18.818, Speaker D: So privacy is actually better under the EPBS model, because if you really look at it, right today, the relayer is this black box. As a builder, I send my payload to the relayer, and then I trust the relayer to not to dig my information to the other builders or to itself, right? So relayer can learn a lot about my information. So I have to trust the relayer for my privacy concern in the EPBS model. Like I said earlier, that if the builder just becomes a relayer, then the proposal goes to the builder, then the builder can actually determine whether to reveal the payload or not.
00:40:18.904 - 00:40:19.250, Speaker E: Right.
00:40:19.320 - 00:40:32.278, Speaker D: So the builder holds its data by itself, no one knows anything about it. At the end, you would decide whether to reveal its data or not. The privacy is actually way better in.
00:40:32.284 - 00:40:56.102, Speaker B: The EpPs model because you're not having to trust relay. Okay. All right. And what are some of the other major, would you say, like design questions around EpPs? We talked a little bit about the privacy, we talked a little bit about relays are still going to exist. What are some of the other kind of major concerns, or I guess outstanding questions related to Epps design?
00:40:56.256 - 00:41:13.650, Speaker D: I will not say the technical one just because it's kind of technical, but I will say more like the fun one, right? I think the most fun one is that can we fit everything within 12 seconds slot time? That's something that everyone can understand in the podcast that today ethereum slot time is twelve second.
00:41:13.720 - 00:41:14.098, Speaker E: Right.
00:41:14.184 - 00:41:24.470, Speaker D: But then if you increase it to 16 2nd, which will solve a lot of design concern because of slots longer now, but there is downstream effect that will break.
00:41:24.540 - 00:41:24.870, Speaker E: Right.
00:41:24.940 - 00:41:32.282, Speaker D: We don't know if any smart contract, there's this hard coded assumption that I have to use the twelve second slot time. We don't know that. We don't know what's going to happen.
00:41:32.336 - 00:41:32.554, Speaker E: Right.
00:41:32.592 - 00:41:40.938, Speaker D: So that's to us, that having to use a longer slot time is kind of a non starter to begin with. I think that's one of the fun one.
00:41:41.024 - 00:41:41.662, Speaker B: A big one.
00:41:41.716 - 00:41:42.030, Speaker A: Yeah.
00:41:42.100 - 00:42:14.806, Speaker B: And also because it also shows how design constraints, from the way that the Ethereum protocol is now, certain complexities constrict what Ethereum can actually feasibly do for a future upgrade. So the extent to which you could achieve EPBs vertical, all of these things, you have a ton of technical debt and an existing smart contract ecosystem that you have to make sure is continuously compatible. Even though sometimes I feel like certain upgrades, if it only impacts like maybe one or two smart contracts, developers are.
00:42:14.828 - 00:42:17.142, Speaker D: Like, that's fine, it's hard to make changes.
00:42:17.276 - 00:43:16.470, Speaker B: Yeah, these are pretty big concerns. One of the other questions that I have around EPBS is every time I hear about this conversation, it is kind of tightly coupled with another concurrent conversation research question that's happening around this idea of execution tickets, this idea that you have validators who are attesting to the validity of blocks and transactions and they're also, at certain points of time, very infrequently also proposing blocks themselves. So you can either, as a validator, you can attest, but you can also be chosen to propose. What if we split up the responsibilities such that block proposers you? Getting to propose a block is something that you have to buy into, go into a market for, and if you don't, then you just attest. Can you explain why? Is this something that needs to happen for Epps to work? Is it something that would make Epps easier? How do these two concepts and research topics relate?
00:43:16.550 - 00:43:43.266, Speaker D: Epps in our design is fully compatible with attitude tickets. I think I will start with that. I think we can go back to the beginning of why attitude ticket made sense, right? It made sense because of two things. The first thing is timing game. The second thing is if we want to burn Mev. So that's the two things that probably makes the most sense to do as children take you. So I will start with timing game.
00:43:43.266 - 00:44:06.218, Speaker D: So what is the problem today? The problem today is that the proposal has 4 seconds to get the block out. So they will try to squeeze out as many juice as possible to the four second mark, right. Because that will make a more profitable block. But today, a block consists of two parts. Consists of consensus data and execution data, basically.
00:44:06.384 - 00:44:06.714, Speaker E: Right.
00:44:06.752 - 00:44:10.250, Speaker D: So the block always consists so it's bundled together.
00:44:10.400 - 00:44:12.742, Speaker B: The execution data is like smart contract.
00:44:12.806 - 00:44:14.638, Speaker D: User transaction defi stuff.
00:44:14.724 - 00:44:17.162, Speaker B: Consensus data is like the attestation.
00:44:17.226 - 00:44:19.034, Speaker D: Yeah. Votes, deposit slashing.
00:44:19.082 - 00:44:19.294, Speaker E: Right.
00:44:19.332 - 00:44:20.782, Speaker B: And blob data soon.
00:44:20.836 - 00:44:21.790, Speaker D: Blob data, sure.
00:44:21.860 - 00:44:22.366, Speaker E: Fair. Yeah.
00:44:22.388 - 00:44:23.706, Speaker D: So they consist of two parts.
00:44:23.738 - 00:44:23.994, Speaker B: Okay.
00:44:24.052 - 00:44:30.194, Speaker D: And that's not ideal, because first we have to ask ourselves, why are we doing this?
00:44:30.232 - 00:44:30.578, Speaker E: Right.
00:44:30.664 - 00:44:41.794, Speaker D: They should be separating in a way such that if the attitude data is missed or bad, the consensus data can still be there. It doesn't have to be missed on chain.
00:44:41.842 - 00:44:42.054, Speaker E: Right.
00:44:42.092 - 00:44:44.390, Speaker D: So there is this interdependency in the middle.
00:44:44.460 - 00:44:44.886, Speaker E: Right.
00:44:44.988 - 00:44:59.574, Speaker D: So what attitude TK does is essentially, why don't we separate out consensus and execution? We allow two type of proposal. One proposed attitude, sorry, one proposed consensus block. One proposed execution block.
00:44:59.622 - 00:44:59.930, Speaker E: Right?
00:45:00.000 - 00:45:03.754, Speaker B: Oh, so the execution tickets are about proposing different parts of the block.
00:45:03.802 - 00:45:04.400, Speaker D: Exactly.
00:45:04.850 - 00:45:05.646, Speaker A: Okay.
00:45:05.828 - 00:45:29.394, Speaker D: Yeah, exactly. Right. So because of that, right, there's probably not much timing game incentive for the consensus stuff anymore. Because if I'm proposing consensus block, I don't need to play timing game, right? I don't care. And if I'm proposing execution ticket, I presume there will be a very selective validator that will do that. They're very good at what they're doing. So they will just keep doing what they're good at doing.
00:45:29.394 - 00:45:34.326, Speaker D: I don't know if they will play timing game or they will do something else. Right, but we kind of don't care about that.
00:45:34.348 - 00:45:34.918, Speaker E: Right.
00:45:35.084 - 00:45:42.502, Speaker D: What we care is the proposal that propose a consensus block. So we kind of file war from that.
00:45:42.556 - 00:45:42.834, Speaker E: Right.
00:45:42.892 - 00:46:10.450, Speaker D: And the second thing is that, okay, well, now, since now you have two blocks, now you have the consensus block, now you have the execution block. For the execution block, you know exactly what amount it gets on chain, just like what the value is. So now you have this MeV Oracle, which you can decide what to do with it. Right. Because now the value is on chain. You can burn it, you can do something else with it. So that's kind of what addition ticket is.
00:46:10.600 - 00:46:37.062, Speaker B: So execution tickets and EPbs, the way that both of those are connected is. Well, I mean, I guess the reason why we have execution tickets is to basically be able to burn MeV data if we want. That's one of the main reasons. But also be able to have this ability to kind of continue to decentralize MeV, continue to make validators less specialized.
00:46:37.126 - 00:46:38.074, Speaker D: Yeah, exactly.
00:46:38.272 - 00:46:47.006, Speaker B: Okay, fascinating. And EPBs, in terms of the design that you guys have, it can go with inclusion or it can go with execution tickets, but it doesn't have to.
00:46:47.028 - 00:46:53.074, Speaker D: It doesn't have to, yeah, but it's fully compatible with execution ticket. It's just kind of like a complementary piece. We can add it on top of.
00:46:53.112 - 00:47:57.922, Speaker B: It, broadly speaking, because now we're getting kind of close to the end of our show together. I want to talk about the broad goals of what Ethereum core developers, how they view MeV in the Ethereum stack, in the Ethereum protocol. Obviously, there's a lot of value. More decisions about how you think about MEV, as should it be something that can be completely eliminated. I think most developers are under the impression that MEV can't be fully mitigated. We can only try and make it as non centralizing as possible. Are there other kind of values around MEV or viewpoints around MEV that you think is guiding the broad design of inclusion lists, ETs, execution tickets? Because MEV Burn is like, we didn't get into this on this topic, but Mev Burn is a very, that's a very value driven way to address mev.
00:47:57.922 - 00:48:05.042, Speaker B: And I'm wondering, do you and other core developers have broad thoughts around how MeV should be handled?
00:48:05.106 - 00:48:58.380, Speaker D: I think MeV wasn't a hot topic like four years ago, even two years ago. If it was, then maybe the design will slightly change, differ. I think one of my takeaway, my learning is just that having consensus and execution, which consists of majority MeV together, is kind of messy. If I had to redesign the whole thing, I would probably just separate out consensus and execution, kind of like what execution ticket is doing today. We can have a really good solid consensus layer, and then we can have this very solid, trustless execution interaction with the consensus layer, basically. And why are we doing that? It's because of MeV, right? There will be specialized actors. They're really good at what they're doing, and which solo staker cannot do that? So it's important to fire wool from the two.
00:48:58.830 - 00:49:37.330, Speaker B: Do you think that it's inevitable that there will always be a certain level of centralization then, because the specialization that is created by MeV is something that cannot be stopped, like cannot be addressed. So there will always be a level of centralization that exists because of the specialization required for MeV. And does that mean that. I guess the point is, is that centralization going to always live with builders? Is the centralization of the builder market just kind of inevitable? Is that what you would say?
00:49:37.400 - 00:49:37.634, Speaker E: Yeah.
00:49:37.672 - 00:49:43.378, Speaker D: So I would defer to Vitali's post from two years ago. They were saying centralized building, decentralized verification.
00:49:43.474 - 00:49:43.734, Speaker E: Right.
00:49:43.772 - 00:50:25.090, Speaker D: I do believe that's probably the end game. Even in the far future. If you look at food and charting, right, to propose like one block, you would need a lot of bandwidth. And that type of bandwidth is not someone with a solo staker at home with 100 megabyte can handle, right? So proposing a block will go away in five to ten years, and that's the outcome. And that's okay, because if you want scalable data, that's probably the way to go. But we want decentralized blockchain, right? So you need some decentralized verification part, and you want some sort of inclusion such that anyone can force inclusion, but then majority of the block or the contents will probably be centralized.
00:50:25.830 - 00:51:09.934, Speaker B: You know what this really reminds me of? Okay, this is the last thing I'm going to say, and then we're going to wrap up that episode. I think that monolithic blockchains like Solana and modular blockchains like Ethereum are eventually going to end up in the same place. Like the design of having very high compute, like specialized, centralized block builders, but maybe also light client versions or very light validators that help contribute to the decentralization of the ecosystem to some extent. It really makes me think Endgame is a mixture of the two of centralized block producers, but maybe like decentralized attesters.
00:51:09.982 - 00:51:27.560, Speaker D: We can think of like two spatulants, right? And we're just trying to meet in the middle. But in Ethereum's case, it's probably harder to move because of we have a lot more TBL, we have a lot more teams. The decision making is more like, it's more like rough governance based, right?
00:51:28.010 - 00:51:44.080, Speaker B: Yeah, I mean, the governance part is very hard. But thank you so much for being on the show, Terrence. And thank you so much for the work that you do in Ethereum governance. It's always just such a pleasure to chat with you and to hear more about the research and the work that you're doing.
00:51:44.450 - 00:52:00.860, Speaker A: Thanks so much for listening to another episode of Infinite Jungle. I hope you enjoyed the episode. If you did, please be sure to, like, subscribe. Make sure that you are getting notified for when new episodes drop. I will talk to you guys again next week.

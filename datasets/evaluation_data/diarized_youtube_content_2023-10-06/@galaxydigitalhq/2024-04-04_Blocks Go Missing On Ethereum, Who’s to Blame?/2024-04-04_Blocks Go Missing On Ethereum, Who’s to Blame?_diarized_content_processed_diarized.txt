00:00:10.320 - 00:00:52.074, Speaker A: Welcome to the infinite Jungle, the podcast about the evolution of Ethereum. I'm your host, Christine Kim, VP of research at Galaxy. On the show today, we're going to be talking with Verdi Coltman, the head of ecosystem and partnership at Espresso Systems. They are a shared sequencer network, so we'll be getting into what kind of products they're building for rollups and what a shared sequencer network is. We'll also be chatting about what developers talked about in the latest Ethereum developer call, which was the mainnet missing blocks incident. So we're going to talk about what happened, what we know, what we don't know, and what to look out for next. But before we begin, here's a quick disclaimer.
00:00:52.734 - 00:01:09.514, Speaker B: I need to remind you to please refer to the disclaimer linked in the podcast show notes and and note that none of the information in this podcast constitutes investment advice, an offer, recommendation, or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities.
00:01:10.014 - 00:02:13.684, Speaker A: So there was a pretty major incident that happened on the Ethereum network this past week. I shouldn't say major because most users and applications on Ethereum probably didn't even know what was going on. But I would say the Ethereum network is pretty spoiled because it functions normally with such high uptime and such high performance numbers. So all of the security providers of Ethereum are usually actively participating in the network, fulfilling the responsibilities that they need to fulfill to the point where the participation rate for validators, validators are the security providers of Ethereum. That participation rate is usually above 95%. Consistently, all the time, blocks are produced on Ethereum every 12 seconds. And most of the time, the health of Ethereum is very, very high or very healthy, I should say.
00:02:13.684 - 00:03:13.020, Speaker A: So when I say that it was a major incident. It was a major incident in the eyes of Ethereum core developers, because really, any type of small irregularity catches the attention of ethereum core developers. So the incident that we're going to be talking about and what developers had talked about in the latest Ethereum dev call was around the incident of missing blocks. Now, what are missing blocks, and how does this happen? Well, we know that transactions on Ethereum, when they're submitted by a user, are packaged into blocks. When blocks are produced, you build blocks on top of previous blocks, and this is what creates the canonical ledger of transactions that is Ethereum. And blocks are produced, like I said, every 12 seconds. But there is moments where a validator doesn't propose a block on time.
00:03:13.020 - 00:03:58.214, Speaker A: It misses its twelve second window, which is also called a slot, to propose a block. And so that slot passes and there's no block that had been proposed. The network moves on, and any transactions that should have been, you know, processed within that 12 seconds window just gets processed in the next slot. And every 30 minutes, there's about two to 4% of blocks do go missed or slots do go missed, and no block is proposed. And this could be for a variety of reasons. Again, you know, the validator could have proposed the block late and didn't get, wasn't able to propose it on time. It could be that the validator that was selected to propose the block was offline.
00:03:58.214 - 00:04:47.774, Speaker A: At that time, they had an intern and couldn't get access to the network. So these missing blocks do happen. But again, it doesn't really impact the user experience, because if your transaction doesn't get included in a certain block, it'll probably get included in the next few. And it also depends on what fee you've attached to your transaction, of course, which also determines how much priority your transaction gets for inclusion in the very next block. We saw this past week a pretty high spike in the percentage of blocks going missing. In a 30 minutes window. We saw the percentage of blocks going missing spike up from between two to 4% to over 14, 15%.
00:04:47.774 - 00:05:54.534, Speaker A: And this is data that I'll actually link into the show notes that you can see on a public dune data dashboard created by this really phenomenon data scientist data always. But you can see that the percentage of missed blocks in a certain time interval just really spike. And so that happened on Wednesday, March 27, and developers obviously noticed this immediately and tried to investigate what exactly was going on with the network. And one of the other important elements of this story and what happened is, right as the number of missing blocks was spiking, there was also a very high traffic of blob transactions. We've talked about blobs before on this show, but as a little bit of a reminder of what blobs are, they're a new transaction type on Ethereum that has been activated by the Denkun upgrade. Before Denkun, blobs didn't exist. And these blobs are these very data heavy transactions.
00:05:54.534 - 00:07:25.366, Speaker A: They allow additional block space, kind of reserved block space for any user that wants to commit large chunks of data to Ethereum. So rather than create a token or create a different kind of decentralized finance application, these spaces of this new block space that's now called blob space is motivated primarily for rollups and rollups. They are this L2 scaling solution on Ethereum, where you have users and they're sending transactions to the roll up, and the rollup is able to batch these transactions, compress it, and create a proof of all these transactions that had happened, and submit that down to Ethereum and be able to give the security of what's actually going on on the roll up side with the full backing of the security of the Ethereum network. That's what rollups do. And rollups are relying on Ethereum for this space of data to be able to commit data back down to Ethereum. And normally for Ethereum to do that on Ethereum, it's quite expensive. You're competing with everybody else that's trying to use Ethereum, not just for data availability, but also to create tokens to do all the other things that we normally love to do on Ethereum, send transactions around, et cetera.
00:07:25.366 - 00:08:24.350, Speaker A: And so now you have blobs. And blobs offer this very cost effective way for rollups to commit data down to Ethereum. And when Denkun first launched, there were rollups that were starting to experiment with blobs, send a blob transaction and be able to offer lower fees for their users, because now it's not as expensive to commit data to Ethereum, because now they're using blobs instead of the call data space and regular ethereum transactions. So it was going pretty well for the early days after the Denkun activation. But it was also quite clear that the amount of blob space that was available was being underutilized. So rollups are able to not just roll ups, but any user, really. You're able to attach a maximum of six blobs per Ethereum block.
00:08:24.350 - 00:09:22.130, Speaker A: And these blobs have each about 128 space available to be filled up with. And we were seeing that below, three blobs per block were being processed. And the way that the fees for blobs work is that if there's a block that contains more than three blobs, then the fee for those blobs goes up. So the target amount of blobs that you want in a block is three, but there's a maximum of six that can be attached. And we weren't really seeing the fees for blobs increase because the space was being underutilized. And so blob fees were extremely cheap, virtually costless. This was kind of the main takeaway from right after the Denkun upgrade, that now it was virtually costless for rollups to commit data back down to Ethereum.
00:09:22.130 - 00:11:06.294, Speaker A: For rollups to use Ethereum as a data availability layer. So it was a little bit of a I was saying in a prior episode how much of a success the Denkun upgrade was because it's cheaper now. It costs roll ups virtually nothing. But lo and behold, on Wednesday, right when we're seeing the rate of missing blocks go up, we saw an influx of users just take up blob space, the virtually costless blob space, by putting in data that is not batched transaction data from rollups, but just putting in large chunks of data, for example, a large JPEG, like an image of a duck, and start using that space to mint new tokens. And why are people doing this? Well, people are using that blob space because it's actually cheaper to use that space than it is to do all of that activity, like minting a non fungible token, an NFT, or minting a new ERC 20 token, a new fungible token through blob transactions than it is using regular Ethereum transactions, because blobs were virtually costless and rollups were underutilizing the blob space. So the kind of activity that we were seeing with blobs on with blob transactions on Wednesday, people were calling them inscriptions. This is a term that you might have heard in the bitcoin ecosystem, which refers to people minting new non fungible and fungible tokens on bitcoin using the witness data space of bitcoin blocks.
00:11:06.294 - 00:11:59.634, Speaker A: And right on Wednesday, there was actually a tool created on Ethereum called blobscriptions. Blobscriptions IO. We can link to that website in our show notes as well, but it just allows users to easily inscribe different types of data into Blobspace. And we saw a ton of people inscribing fungible and non fungible tokens into blobs. And this caused the blob fee to rise dramatically, exponentially, to the point where blobs were no longer costless. I think the last time that I checked, in order to send a blob transaction, it costs above somewhere around 15 to 16 USD dollars, when just a couple of days ago, before this past week, again, blobs were costless. You can see how quickly the dynamics of blobs have changed.
00:11:59.634 - 00:13:17.702, Speaker A: And as the inscription activity on Ethereum was spiking, we saw the number of missing of blocks, the rate of missing blocks on Ethereum increase. So going back to the developer call and the way that developers were thinking about what was happening, one of the developers Terence Sao, a prism developer, had explained that he had noticed that there was some kind of irregularities happening on Ethereum due to blobs ever since the activation of Denkun. But the seriousness of what was really happening, certainly it got worse. The missing blocks issue got worse, right, as blob activity was increasing. And he said from his investigations, it didn't look like an issue with ethereum client software or really with the software around builders, which are these third party actors that are building blocks. Building blocks on behalf of proposers, on behalf of validators. And these builders, they are able to make these blocks a lot more valuable because they can package it with MeV, which is kind of another, more technical term that I feel like we've talked about in this show.
00:13:17.702 - 00:14:01.916, Speaker A: But again, just as a little bit of background, MeV is additional rewards that a validator slasher builder can make off of reordering transactions in a way that can create a lot more value. So a lot of it depends on market strategies. You can front run, back run sandwich transactions. You can leave certain transactions out, keep certain transactions in. So anyways, builders are these specialized actors that do that and create very valuable blocks that validators can then propose. So Terrence was saying, and we've had Terrence on the show before, but he was saying that investigating what was going on, it didn't look like an issue with validators. It didn't.
00:14:01.916 - 00:15:07.916, Speaker A: Validators and client software, it didn't look like an issue with builders, but it did potentially look like an issue with relays. Relays are the actors that sit in the middle between builders and validators to help process the block, to communicate the block from a builder to a validator and ensure that both parties get their cut of the rewards for the block and don't leak any proprietary information about how that block was built. And so the investigation is still ongoing. Developers Terrence had said, you know, it looks to be an issue with the relay, but the relay that he had mentioned was the cause of the issue, the Bloxroute relay. The CEO of Bloxroute, Uri Klarman, had said, you know, let's hold our horses. We're gonna be coming out with a full postmortem of what is really going on, because it doesn't look, in his view, like an issue with the relay, per se. But again, there's still lots of details.
00:15:07.940 - 00:15:08.852, Speaker B: That are still to come.
00:15:08.908 - 00:16:14.864, Speaker A: So we'll definitely follow up on what happens in the next episode of infinite Jungle, because at the time of recording, I think there's still quite a few unknowns, but two things I will say in terms of the takeaways. The first is that clearly there are new issues. A degradation, it's a slight degradation, but a noticeable degradation in network health because of the Dengkun upgrade that's starting to appear. You know, Terrence had said, you know, it doesn't look like the issue is with client software, but I will note that several major Ethereum client teams have put out releases in the last couple of days just to fix minor issues and bugs around blob processing. So the Prism team, the Tecu team, the lighthouse team have all issued new releases ever since the Denkun upgrade went live to fix minor issues. And so it's quite clear that I think blobs are causing certain degradations in network health. So until we have more information, I think that's something users should be aware of.
00:16:14.864 - 00:17:22.830, Speaker A: And then the second thing, and the last thing that I think is an important takeaway from all this, is that the way that the fee dynamics work for blobs, it dictates who is utilizing that space. Because Blob space was underutilized, you had these users that were just kind of minting random images and text to Blob space. But we're already starting to see the inscription activity kind of pull back because Blob fees have risen so dramatically, and you see the share of blob space used up by rollups that are actually giving perhaps a more valuable service to the network, such as scaling and servicing hundreds of users, if not thousands of users, take up a lot more blob space. So I think over time, as the fee dynamics in the markets for blob space evolves, I think we are going to see the dominant people using Blob space be roll ups, as opposed to these random people that are using Blob space for other reasons, unless, I guess, those inscriptions become extremely valuable and start.
00:17:22.862 - 00:17:26.614, Speaker B: To trade on decentralized exchanges and other.
00:17:26.654 - 00:18:30.620, Speaker A: Avenues for a lot higher money. I think you're starting to see the dynamics of how fees really dictate value and the value of transactions. And so, as funny as it was to kind of see blobscriptions really take off, I think the fee market dynamics will ensure that the blob space is utilized by people who can pay for it. And I think rollups are kind of the strongest leader, the strongest player in the blob fee market because of how much value and adoption they've already accrued and are like to continue to accrue in the future. So that's another kind of important takeaway, I think, around the blobscription dynamics and activity that has been happening. So yeah, a little bit of a long kind of explanation of that main net missing block incident that happened that developers had talked about in the latest dev call and that you might have been hearing about on Twitter and other social media platforms. Next week, hopefully we'll have another.
00:18:30.620 - 00:18:45.294, Speaker A: We'll have more information to share on the show about what really was the cause of those missing blocks. But now we're going to be switching on over to the second half of our show where we're going to talk with Verity about shared sequencing.
00:18:46.474 - 00:18:54.234, Speaker B: Welcome back to the show, you guys. I am here with Verity Coltman, the head of ecosystem and partnerships at Espresso Systems.
00:18:54.274 - 00:18:56.354, Speaker A: Thank you so much for being on the show, Verity.
00:18:56.514 - 00:18:59.334, Speaker C: Hi Christine, thanks so much for having me. I'm pleased to be here.
00:18:59.984 - 00:19:17.488, Speaker B: It's been a pretty big week for Espresso. Can you maybe as a very broad starter, explain to us a little bit about shared sequencing, what it is that espresso does, and then the latest announcement that had come up around Espresso's raise?
00:19:17.656 - 00:20:02.144, Speaker C: Yeah, absolutely. So at Espresso Systems we're very pleased to announce our series b fundraise, which came out last week. So we've had incredible messages of support and a lot of really great inbounds, which is making my life busy in the best way possible. We are building a marketplace for roll ups to sell their sequencing rights, and we can get into a bit more about what that means. And in addition to that, we also offer a consensus protocol called hotshot. It's based off hot stuff, and that offers roll ups a finality gadget so that you could actually get pre confirmations from our consensus in a matter of seconds while you wait for Ethereum L1 finality, which can take up to 15 minutes.
00:20:03.124 - 00:20:44.616, Speaker B: So it sounds like quite a lot of products geared towards rollups and what rollups do. This makes a ton of sense because Ethereum is now basically seeding all of its execution layer, all of its ability to kind of execute transactions, wanting all of that execution activity to happen on L2s, on separate protocols. Let's tackle the first one together first, and then maybe we can go into the consensus stuff if we have time later on in the show, because I think sequencing is a huge topic. And I was just talking about in the first half of the show about validators stating the ability to build blocks.
00:20:44.680 - 00:20:46.204, Speaker A: To third party builders.
00:20:46.584 - 00:20:55.516, Speaker B: Is sequencing a similar activity in that roll ups when they build blocks for the user transactions that they have happening on their network.
00:20:55.660 - 00:20:57.604, Speaker A: Are they ceding the ability to build.
00:20:57.684 - 00:21:13.544, Speaker B: Blocks to a more specialized party, like a builder? Is that what sequencing is? And if so, does it require similar amounts of computational resources and kind of specialization as what we see in the builder market on Ethereum today?
00:21:14.004 - 00:21:54.060, Speaker C: Yeah, this is a great question. So you alluded to Ethereum's roll up centric roadmap, where we're seeing a lot of execution move from Ethereum, which is quite expensive and can be congested over into rollups, which are more cost effective. Yeah. So in the Espresso sequencer world, there are two key roles. There's the proposer, which is eligible to propose blocks for a roll up, and then that could also be someone who wins the right to a block and is a builder, so they're able to execute on the roll ups behalf. A roll up could also choose to actually do that themselves. So we want to provide maximum optionality.
00:21:54.060 - 00:22:27.724, Speaker C: But yeah, I would expect that we'll see proposers play a very similar role to block builders and that they can execute. But we also have a component of our consensus, where basically Ethereum validators can come to consensus on the outcome of an auction, and those participants don't need to have hefty hardware requirements. We can go into a little bit more about how we're looking at like computation for our network, but effectively there's kind of two key roles there, and so they have different requirements.
00:22:28.744 - 00:23:24.920, Speaker B: And what are the benefits to using Espresso's shared sequencer network but wanting to sequence the blocks yourself? Because if you, if you on Ethereum, if you see the ability to build your own block, you give it to a builder that could potentially build more valuable blocks. So you get to earn more from that block, get more rewards in MEV with shared sequencing on Espresso, if you don't give your block for a specialized kind of proposer to be able to build, maybe you don't get as much Mev rewards and maybe that's what you want. But then why would you use espresso in the first place? Why wouldn't you just kind of sequence the block yourself and then put it on straight down to give it straight.
00:23:24.952 - 00:23:26.768, Speaker A: Over through a blob to Ethereum?
00:23:26.896 - 00:24:27.682, Speaker C: I think why you would still consider joining us is so that there is the ability for a proposer to propose across multiple roll ups. That does lead to a better user experience where customers are trying to transact across chain that is not able to be achieved with like current roll up architecture. So I do think that's like something that is compelling enough to consider. The other reason that you might want to use us is as a finality gadget. So many roll ups today will wait for a transaction to be confirmed on the Ethereum l one before it's counted as finality. But basically you could look at us and our hotshot consensus and say, actually, I saw it was finalized in a couple of seconds because hotshot finalizes after two consecutive blocks and count that as a pre confirmation that the transaction will go through. It's very hard for those transactions to revert after Hotshot has agreed on the sequence of them, and so you get some stronger kind of safety guarantees if you're transacting across chains.
00:24:27.682 - 00:25:04.244, Speaker C: Maybe you're a liquidity provider. You could look at hotshot and say, I'm happy, like fronting capital on the destination chain, because I know Hotshot has said that this transaction is going through, and so it just allows things to be a bit cheaper and faster in the long run. That's really what we're aiming for. We did a demo of this actually with across during ETH Denver, where we had two arbitrum roll ups sequenced by Espresso and across basically looked at hotshot as a way to confirm that the transactions were safe and finalized, and we were able to get the bridging completed across the two roll ups in about 10 seconds.
00:25:04.744 - 00:25:19.346, Speaker B: Wow, that's, yeah, 2 seconds faster than Ethereum block times on Ethereum, 10 seconds versus twelve, and also probably much faster than, I don't know what the block times are on arbitrum pretty fast.
00:25:19.450 - 00:25:36.134, Speaker C: I think it just depends on which roll up is deciding when finality occurs on their chain. So arbitrum often prefers to wait for a finalized block, whereas other roll ups may look at blocks closer to the top of the chain on Ethereum, if that makes sense.
00:25:36.514 - 00:25:37.386, Speaker A: Yeah, yeah.
00:25:37.450 - 00:25:44.882, Speaker B: I mean, definitely different kind of thresholds for when you want to consider a block finalized on Ethereum. Is it just it's processed or you.
00:25:44.898 - 00:25:47.850, Speaker A: Wait after two epochs? And I think you make a great.
00:25:47.882 - 00:26:13.468, Speaker B: Point that even if you don't kind of benefit from the shared sequencer side of what's happening on espresso, you can still benefit from the consensus part of espresso in that even if you are the one building your own block and sequencing that block and ordering all the transactions, you could benefit from faster finality by using espresso and to confirm.
00:26:13.596 - 00:26:15.724, Speaker A: So the other part of what espresso.
00:26:15.764 - 00:26:43.374, Speaker B: Does in services for rollups through its network. Is that consensus part the hotshot consensus? Is hotshot consensus also something that rollups can just kind of implement themselves in protocol? Or is hotshot consensus in some way very dependent on the espresso implementation through the espresso network versus that consensus being implemented in the consensus of a roll up?
00:26:43.794 - 00:27:21.774, Speaker C: Yeah, it's a great question. I would say generally you hear espresso talk about sequencing, but we also offer data availability through our consensus. And so roll up teams could choose to use both aspects or just one. We do have a couple of teams that are opting for just one. In that case, you're basically taking the outputs from the sequencer about transaction ordering and doing with it what you will. So some roll up teams may say, we want to use espresso da, which we call tiramisu, in addition to posting to Ethereum. And that gives a different set of benefits and guarantees.
00:27:21.774 - 00:27:46.426, Speaker C: We definitely want to offer something that's competitively priced and very fast and a nice benefit of using the sequencer. But in a modular world, developers have so many different choices that they may choose to use many different solutions. So yeah, they can use us for both the sequencing, the fast finality gadget aspect, as well as data availability. So they could take any one of those components and incorporate it into their stack.
00:27:46.610 - 00:28:12.194, Speaker B: Okay, so for now, maybe just espresso uses hotshot and maybe TBD on its implementation or application for, you know, use on other chains. Maybe we can talk a little bit about the cross chain features and functionalities that you are mentioning as another benefit to using espresso.
00:28:14.054 - 00:28:15.294, Speaker A: Because there will be.
00:28:15.374 - 00:28:29.582, Speaker B: Multiple roll ups relying on espresso for the building of blocks and finality. Are there benefits to using espresso to.
00:28:29.638 - 00:28:32.842, Speaker A: Create interoperability between these roll ups?
00:28:33.038 - 00:28:50.546, Speaker B: When it comes to one of the kind of biggest pushbacks to roll up adoption is the fact that if I have to bridge assets from Ethereum to this roll up, and then I want to move those assets to roll up b, then do I have to go back to Ethereum and then withdraw, put it back on Ethereum and then bridge.
00:28:50.570 - 00:28:52.114, Speaker A: It over to that roll up again.
00:28:52.194 - 00:28:56.266, Speaker B: And it creates user experience challenges. When you're moving from roll up to.
00:28:56.290 - 00:28:58.202, Speaker A: Rollup, can you tell me a little.
00:28:58.258 - 00:29:09.048, Speaker B: Bit about the, you know, enhanced interoperability between, between roll up environments that might occur because of what espresso does?
00:29:09.216 - 00:29:54.802, Speaker C: Yeah, absolutely. So a proposal who would win an auction in our marketplace would basically have the rights to propose future blocks for that roll up. So it means that they can actually know, like when their slot is coming up and what roll ups they won the auction for. So they can actually plan on saying, I know at this point in time I will have the ability to propose blocks for roll up a and roll up b. And so I know that I can actually make commitments to users about executing those transactions together at the same time, which is really useful for things like cross chain swaps. To be able to do that, they need to be able to rely on some sort of output that says these transactions can be included. And that's like what they get from us.
00:29:54.802 - 00:30:57.878, Speaker C: We offer this inclusion guarantee, and what a proposal does is they offer the execution guarantee. So you do actually need those two things, things to come together for a roll up to see interoperability benefits. So that's like the main way that we enable that to happen. Basically, that allows promises of atomic execution. A proposer could give an economic bond to say like, yes, I commit to you user that I will only execute a transaction on roll up a and roll up b if I include them at the same time. And so that actually provides like a new level of composability that we haven't seen before. I think what's also really interesting is that with hotshot and us using Ethereum restaking, l, one, validators will actually be able to play a role in our consensus, and so they can start to get exposure to proposing blocks across the roll up at the same time that they are validating on the ethereum.
00:30:57.878 - 00:31:01.052, Speaker C: L1, yes, I do want to.
00:31:01.108 - 00:31:35.572, Speaker B: Talk a little bit about the roadmap around restaking and definitely, but just to dive a little bit deeper on what you were mentioning around interoperability and those cross atomic swaps. So on rollup a, you can really only express an intent around what you want to happen with your transaction or your account on that roll up. So I want to move a certain amount of money on optimism. On arbitrum, for example, you can really only express your intent and your optionality of what you want to happen on arbitrum.
00:31:35.708 - 00:31:38.836, Speaker A: But from the kind of examples that.
00:31:38.940 - 00:31:40.652, Speaker B: You were showing, there seems to be.
00:31:40.668 - 00:31:41.972, Speaker A: A way to be able to express.
00:31:42.068 - 00:31:56.496, Speaker B: Like, I want this to happen on this roll up. If this happens on another roll up, where are users? Where would users kind of express those intents? I'm under the impression that there are.
00:31:56.640 - 00:31:59.784, Speaker A: Quite a bit of similar shared sequencer.
00:31:59.824 - 00:32:02.564, Speaker B: Networks like suave that flashbots is building.
00:32:03.184 - 00:32:09.200, Speaker A: To allow for people to express cross multi chain kind of intents of what.
00:32:09.232 - 00:32:29.092, Speaker B: They want to see happen on multiple. Like, if I wanted to bridge an asset from this roll up to another roll up that requires kind of like this more universal view of what's going on. Talk a little bit more about where do those intents really just get expressed and through what mechanisms via espresso.
00:32:29.268 - 00:33:16.564, Speaker C: It's a great question. I mean, we are diving pretty deep into the infrastructure side of Ethereum and rollups, and quite frankly, many users may not even know that this whole world exists. And I think that that's completely fine from a user standpoint. They may be able to express this in a wallet UI like metamask, for example. We're working with that team basically to understand how could we potentially leverage snaps as a way to look into this and make it a very seamless way to say, I want these two transactions to execute at the same time. The other angle that we could look at is a bridging UI, like what we did with across. So they have a way for users to express certain preferences, slippage and things like that, because they are an intents based bridge.
00:33:16.564 - 00:33:44.374, Speaker C: So they're the two angles that we think this will be a way for users to communicate their preferences. A user interacting with the roll up shouldn't really change too much. They shouldn't see too much difference, but they would have this extra kind of functionality to say, I want these two transactions to happen at the same time. And basically that is communicated through the sequencer to the proposer and execute it on the backend.
00:33:45.754 - 00:33:46.814, Speaker B: Gotcha.
00:33:47.434 - 00:33:51.266, Speaker A: Let's talk a little bit about the sequencer and the proposer, because it seems.
00:33:51.290 - 00:33:52.786, Speaker B: Like a lot depends on them, on.
00:33:52.810 - 00:33:55.658, Speaker A: Their ability to be able to order.
00:33:55.706 - 00:33:57.874, Speaker B: Transactions on multiple chains, to be able.
00:33:57.914 - 00:34:06.194, Speaker A: To have that flexibility. Can you talk a little bit about what does the sequencer and the proposer.
00:34:06.234 - 00:34:15.174, Speaker B: Set look like now? What are some of the computational requirements to be part of the espresso sequencer and proposer set?
00:34:16.594 - 00:34:17.970, Speaker A: How are you guys doing in terms.
00:34:18.002 - 00:34:21.774, Speaker B: Of the types of the profiles of.
00:34:22.394 - 00:34:24.946, Speaker A: The actors that are going to be.
00:34:25.050 - 00:34:32.482, Speaker B: Fulfilling these requests and executing this kind of cross chain activity, cross chain behaviors?
00:34:32.658 - 00:35:08.994, Speaker C: Yeah, absolutely. What have we been talking about now is very much like the end game of what we're building. So some of this is still work in progress, but, yeah, basically the winner of the auction would be the sequencer or the proposer. We would use either of those terms interchangeably. And then there's also a network of nodes that are participating in hotshot consensus, but they're not doing any kind of execution. They're kind of voting on the outcome of the auction, making sure that data is available. So that's like the delineation of the two roles that we have in terms of the specifications and like hardware requirements that we've communicated to date.
00:35:08.994 - 00:36:03.314, Speaker C: This is in a world where we just have one set of nodes running the network which will be accurate for cappuccino Testnet, which is coming out in the middle of April. And then we actually add the two roles in our release after that, which we're calling decaf. So some of this is still very much work in progress. But yeah, what we've communicated so far for this network of nodes that would run today where there's just one role being played, is 16 to 32gb of ram. Two to four cause cpu's for storage nodes that are holding the data availability component of our network, they're holding that data for a set period of time. We've set about 20gb minimum storage with the ability to scale up to three terabytes. And for non storage nodes you're looking at like 100 megabytes or so, sorry, 100 bytes or so to just kind of make sure data is available.
00:36:03.314 - 00:37:01.756, Speaker C: But not all nodes need to hold that data because we do use a form of erasure coding rather than needing to disperse it across the entire network. So that's what the hardware requirements look at a very high level. We've talked about how proposers are able to offer pre confirmations through hotshot, so that's definitely a big consideration. I think the important thing to highlight here is that we aren't doing any kind of proof verification in our network that would be basically sent to the proposal if they're executing or wrapping to the roll up node to complete. But we will post a proof of the outcome of the auction and post that to the sequencer contract, which is going to be on the Ethereum l one, so people can kind of verify the outputs of the auction and make sure that everything looks good. So in terms of the profile of players that we're working with, we're working very closely with roll ups. That includes l two s, l three s.
00:37:01.756 - 00:37:42.824, Speaker C: We're mainly focused on Ethereum today, but we do also support many vms and other ecosystems. We're working with several Cosmos projects as well. We work with rollup as a service providers as well as SDKs. So Altlair and Caldera are currently hosting our existing testnet, which is an arbitrum roll up that is being run with the espresso sequencer that's live for the next week or so. We'll probably reset it once we get to Capitol Testnet, which is our next one coming up in the middle of April. And then we're also adding a new set of operators. So currently espresso is running the nodes with block Daemon, our first operator partner on our current testnet.
00:37:42.824 - 00:38:30.608, Speaker C: They're geographically distributed, but it's about 15 or so nodes being run between the two of us. We will expand that operator set to 100 nodes, about eight to ten professional operators for Cappuccino. We'll also add support for arbitrum fraud proof so that we're fully production ready to go on that stack. And we will also add a couple of enhancements around how we do erasure coding to make that more efficient. So they're the big kind of changes that are coming, I would say they're also the key players that we're working with right now. You'll start to see us bring in more block builders and add these two distinct roles in the network with our subsequent release Decaf. Decaf is going to come out in the summer and it will be a production version of our product.
00:38:30.608 - 00:38:47.124, Speaker C: It'll be fixed stake, a fixed set of operators, and whitelisted roll ups. So it will be an ability for us to fully test out everything, see how things are working, and still complete any necessary kind of bug bashing or upgrades before we go to main net.
00:38:48.344 - 00:39:52.844, Speaker B: Okay, lots of information there, lots of milestones to reach. So it sounds like the kind of the heavy computational requirements are intentionally very separated from trying to keep the computational requirements of what it takes to be a node operator. Apart from the proof verification that might have to happen with the proposer, the roll up, if they are the ones that are going to be proposers, like we talked about in the beginning of the call. And right now it seems like the first couple testnets are just focused on the operators. The node operators and subsequent testnets like in the summer are going to bring on now the proposers. You got 15, I think you said 15 to 20 node operators now. But in the next upcoming testnet in April, going to expand that set in terms of the node operator set and next steps around node operators.
00:39:52.844 - 00:40:03.804, Speaker B: Tell me a little bit about the road to Mainnet and when we might be able to see the node operator set for espresso go live.
00:40:04.144 - 00:40:36.500, Speaker C: Yeah, absolutely. So we will make an announcement for who our operators will be for our cappuccino testnet coming up in the next week or so. So stay tuned. That will be our first set. With each release, we want to be gradually adding more operators and communicating more clearly about how we plan to decentralize over time. Decaf will be our opportunity to run a production version of the product with real rollups and operators securing the network. And if everything looks good, we would go to mainnet shortly after that.
00:40:36.500 - 00:40:55.114, Speaker C: In terms of how we tie in eigenlayer with our decaf release, I would say we're probably going to run them in parallel and make sure that everything is looking good before we combine them. Definitely an active area that we're hashing out plans on right now, so should have more to share in the next month or so.
00:40:55.534 - 00:41:28.774, Speaker B: Gotcha. Well, thank you so much, Verity, for the very comprehensive overview of, you know, what espresso is doing and where it's heading. It sounds like there's still quite a few big announcements still to come from the team, so we'll definitely continue to track and keep an eye on this. I think those were all of the questions that I had for you for this show, but any other last thoughts or things you wanted to say about Espresso before we end the show?
00:41:29.194 - 00:41:51.808, Speaker C: Yeah. If people want to learn more, please check out our website, espressosyst.com. We have a list of our ecosystem, the stacks. We support, the partners and contributors that we've added. If you are interested, please get in touch with me. My DM's are open on Twitter. I'm ezebel, it's the same handle as telegram and I'm also on webcaster as Verity.
00:41:51.808 - 00:42:11.694, Speaker C: So yeah, thanks so much for having me. I hope that it was a worthwhile discussion. It obviously gets pretty technical pretty quickly, but that's what I love about this space, is that things are just constantly evolving. So happy to answer any kind of follow up questions and get feedback from the community on what resonated totally well.
00:42:11.734 - 00:42:23.994, Speaker B: Yeah. Thank you so much, Verity, and thank you everyone who listened to this week's show of infinite jungle. We are going to be back again next week. If you like the show, please do like and subscribe.
00:42:24.334 - 00:42:27.554, Speaker A: Be sure to engage with the show because it really does help a lot.
00:42:27.954 - 00:42:34.234, Speaker B: And we will talk to you guys again next week on a new episode of infinite Jungle. See you guys later.

00:00:10.120 - 00:00:57.472, Speaker A: Welcome to the Infinite Jungle. On today's show we're going to be talking about all core developers consensus call number 138. It was a surprisingly long call. If you take a look at the call summary, which is linked in the show notes, you'll notice that the summary is much longer than it is usually. The call went on for the full full hour and a half, and developers talked quite a bit about some major changes that are going to be needed to the upgrade, the Petra upgrade. They didn't make any decisions, surprise, surprise, about whether or not to move forward with any of these changes, but they did introduce a few new ones on the call that I think are worth digging into. So before we get started with the show, as always, here is a quick show disclaimer.
00:00:57.472 - 00:01:52.576, Speaker A: I need to remind you to please refer to the disclaimer linked in the podcast show notes and note that none of the information in this podcast constitutes investment advice, an offer, recommendation, or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities. I'll begin with a quick summary of what happened on the call, and then we'll get into some of the takeaways from the call and what you can expect or what should you be looking out for in the next upcoming all core developers call. So first part of the call, and probably the first most important thing to take away from the call, is that Petrodevnet one is officially live. We've been waiting weeks. I've been talking about this for many Infinite Jungle episodes now, but yes, indeed, picture Devnet one is live. Unfortunately, Pectra Devnet one is unstable. It has some major issues.
00:01:52.576 - 00:03:19.184, Speaker A: Many of the clients are not able to produce blocks synced to the chain. So lots of debugging is happening for the client implementations. And it appears as though the transactions, some of the transactions that have been sent over that Devnet, particularly EIP 7702 transactions, these are the transactions that are designed to give greater flexibility and functionality to externally owned accounts, to user controlled accounts. These new types of transactions, which developers are trying to activate through Pectra, has caused the Pectra Devnet one to split into multiple forks into three different chains. So, as was talked about on the latest call, developers are trying to figure out what needs to change about EIP 7702 specifications, or what needs to change about the implementation of EIP 7702 in in Ethereum clients in Ethereum execution layer clients particularly. So yeah, that's the first, I guess, biggest update from the call. Pixar Devnet one is live, the other major kind of update is that there's a couple of changes that developers have shared need to be made to consensus layer specifications and the engine API.
00:03:19.184 - 00:04:45.172, Speaker A: The engine API is basically the software that helps the execution layer and the consensus layer of Ethereum communicate with one another. And because of certain eips that are going to be activated in Pectra, developers have realized there needs to be additional corresponding changes to the way that consensus layer clients function and the way that execution layer clients function. So the first one on the consensus layer side, this was a proposal that was shared by the Prism developer POTUS Otis, proposed a change to the structure of the execution payload contained within the beacon block body and a corresponding change to the engine API. So there are blocks that are produced via the beacon chain, the consensus layer of Ethereum, and within those blocks there is the execution block, the block containing user transactions. All of the updated changes or updated activities of smart contracts on Ethereum, that's the execution payload. Those are the blocks that generally were created via the normal Ethereum blockchain, which is the execution layer. I say normal because that's the part of Ethereum that has, I guess, always existed.
00:04:45.172 - 00:06:14.212, Speaker A: It's the blockchain of Ethereum that was launched in 2015 was proof of work mined up until the merge date. Once Ethereum transitioned into a proof of stake blockchain, those execution layer blocks, those execution payloads were now being enveloped, were now being encapsulated, so to speak, by the beacon chain block. And so you had a little bit of a merge between the two networks. You had the consensus layer of Ethereum continuing to produce beacon chain blocks. Through proof of stake consensus and the merging of the beacon chain with the existing Ethereum blockchain, you are able to take those execution payloads and incorporate them into the body of the beacon chain block and thereby merge the two networks, validate this block within a block together. And so when consensus layer clients make new beacon chain blocks, the way that it works currently is that the consensus layer clients don't store or they don't keep the execution payload. It's not necessary for consensus layer clients to store that data.
00:06:14.212 - 00:08:43.300, Speaker A: It's not necessary for them to evaluate that data, analyze it, and then move on to progress to a new block on the beacon chain. However, what POTUS was talking about on the latest call was that due to certain eips that will be activated in pectra consensus layer, clients will actually need to store parts of the execution payload within the beacon block body in order to correctly transition the beacon chain to correctly execute a state transition a state transition just means progressing the blockchain, moving the blockchain forward in accordance with all of the consensus layer rules of the network. And so in order to make that process more efficient, because one of the things that another developer noted on the call was that currently, if the consensus layer clients are trying to store different parts of the block, they may need to make additional requests to the execution layer client to get the execution payload again, or maybe perhaps multiple times. This, he said, would create quite a bit of degradation in the performance of consensus layer clients. This was said by Lighthouse developer Mark Mackey, noting that a change does need to be made to the way that state transitions are conducted by consensus layer clients in a, you know, once pectra activates. And so one of the proposals that POTUS had shared on the call was that, why don't we envelope all of the data that consensus layer clients need from the execution payload into something called a quote unquote binded execution payload envelope, organize it there so that consensus layer clients can easily, easily have all that data in one place to store, and thereby be able to execute a state transition easily and more efficiently. And this was something that POTUS proposed, and along with it, it creates kind of a change in the structure of the beacon block and of course to the execution payload.
00:08:43.300 - 00:10:12.454, Speaker A: And so there's a corresponding change that also needs to go with this proposal to the engine API. So when the execution layer wants to reconstruct the execution payload block, they need the engine API to have a call that can source all of the data in that envelope in the quote unquote binded execution payload envelope for the execution layer client to get that data, find that data, and be able to construct the block again. So a lot of technical terms, but in summary, this is a proposal to ensure that consensus layer clients don't see a major degradation in their performance, in their ability to keep the beacon chain going, producing a block every, I believe, 12 seconds. Is it 12 seconds? I think the block times are 12 seconds. Keep the beacon chain continuing to progress without creating too much work for consensus layer clients. And on the execution layer client side, there was another proposal shared by Geth developer Liteclient, who proposed a change to the engine API. And this was so that block conversion by execution layer clients would be easier due to EIP 7685.
00:10:12.454 - 00:11:29.586, Speaker A: EIP 7685 is a way to make execution layer requests generalized. There's quite a number of different requests that the execution layer will now be able to ask of the consensus layer through the Pectra upgrade. This creates a lot more functionality for smart contracts on the execution layer, primarily staking pools, perhaps decentralized finance applications when they need to request or trigger actions. On the consensus layer side that primarily interact with validators and validator responsibilities, let's say withdrawals or exits, these requests can obviously be coded into Ethereum as a one off, as a one off change. But EIP 7685, which was also proposed by light client, makes these types of requests. It creates a generalized format for them. And while when it was proposed, developers were all very supportive of the change, all supportive of the inclusion of this EIP into the pectra upgrade, light client noted that it would basically change the way that execution layer clients are able to interpret blocks.
00:11:29.586 - 00:13:18.320, Speaker A: There's a bunch of kind of minor details, I would say, or I should say perhaps more technical details about how execution layer clients interpreted the null and the empty fields in a block to determine what version of the block it is. And the block versioning is also tied to the fork schedule. So the way that I believe one of the developers had put it on the call was the execution layer client is able to identify if this is a block post the Bellatrix upgrade, like is this a Bellatrix block? Is this a dankoon block? Another type of block, depending on what upgrade has just activated on Ethereum based on these null and these empty fields. But because of EIP 7685, execution layer clients will no longer be able to interpret blocks in this way, and hence the proposal by lightclient was to put all of the generalized requests into a single type in the engine API that the execution layer can then pass over to the consensus layer for interpretation. So instead of the execution layer doing all of the interpreting, which they're not going to be able to do accurately, given that the utility of the null and the empty fields within a block no longer work in the same way as before Pectra as before the activation of EIP 7685. The proposal is for this list to be created and able to be passed through to the consensus layer, and that requires a change to the engine API API. There was a little bit of pushback, I think, from other developers on the call.
00:13:18.320 - 00:15:17.242, Speaker A: There was a nimbus developer, Dustin, who was explaining how just the idea of interpreting block versions via null and empty fields is not something that is a, it's a, it's a failure of the protocol, it's a part of the protocol that should be fixed in general. But as light client was pointing out, this is, that would require much deeper changes to the protocol, and it's a lot simpler to simply pass along the requests for the consensus layer to interpret rather than having to change to make more invasive changes to the way that execution layer clients interpret blocks and to the way that execution layer clients do block conversions on Ethereum. Hard for me, I will admit to follow along with all of these technical discussions, but I did appreciate every time developers on the call were summarizing what they were saying, re explaining things, it almost felt like they were talking specifically to me as I was listening to the call. So that was another kind of major change to, that was another change proposed to the Enjin API. And together I think it really highlights how these eips that were accepted into pectra developers haven't yet sufficiently scoped out comprehensively exactly all of the ways in which client behaviors are going to have to change and the ripple effects that this is going to have on the rest of the ethereum code base. And it's now that they're finding oh, we're not going to be able, El clients are not going to be able to rely on null and empty fields anymore to be able to determine what version of this block is. We're going to need to make these changes to Enjin API.
00:15:17.242 - 00:16:33.210, Speaker A: Oh, you know, the state transition function of ethereum for the beacon chain. We're not going to be, we're going to need to access certain information in the execution payload which consensus layer clients are programmed right now just to drop. And hence we're going to need to change perhaps the structure of the beacon block body, et cetera, et cetera. So those were the types of conversations, a big part of the call that happened this week, and another, I would say major part of the call that happened this week was in relation to peer Das. Peer Das is yet another major change coming to Ethereum, primarily to the way that data is gossiped on the network, the way that nodes, the way that Ethereum nodes communicate with one another, share and share and distribute data between nodes. And this is primarily to enhance the capability of Ethereum to be a data availability network data availability layer for rollups. The goal of peer DAS is to greatly increase the number of blobs that are able to be processed by the network at any given time.
00:16:33.210 - 00:17:53.730, Speaker A: Right now, because of the Denkun activation, the number of blobs that, the introduction of just blob transactions as a whole has been quite pivotal to signaling and to showing that Ethereum developers are really serious about this roll up centric roadmap. But it's also highlighted that the number of blobs that the network can currently handle is not enough. We've seen major spikes in the cost of blob transactions on Ethereum already, and so there's definitely a bit of pressure that developers are feeling to try and lower the cost of blobs, and peer Das is one of those upgrades. Peer Das has a separate Devnet, a separate test network that developers are moving along with. Peer dust. Devnet one went live, I think, a couple weeks before Pectra Devnet one, but developers are still continuing to stabilize implementations on peer Das Devnet one, fix bugs and yeah, just continue to work on their implementations for peer Das. One of the really kind of interesting parts of the call related to Peer Das was a recommendation, a proposal by Ethereum foundation researcher Alex Stokes, who was also the chair of this week's AC DC call.
00:17:53.730 - 00:19:09.930, Speaker A: He recommended removing a part of peer Das. The way that he explained it was that peer DAs achieves three functions. It distributes blobs, distributes data throughout the network, a large quantity of data of arbitrary data that is submitted by rollups. The peer Das upgrade also creates the functionality of sampling all that data. So there's the distribution of the data and then there's the sampling of that data. Because the idea of pure das is that nodes will not have to see all of the blob data that is trafficked throughout the network. These nodes will just have to sample certain parts of the data from other peers in the network, in the peer to peer network, and then be able to compute and evaluate the samples that this node has received and have extremely high probability to know that the full data was submitted by the roll up.
00:19:09.930 - 00:20:52.756, Speaker A: I know this sounds a little bit hard, I guess, to understand, but there is some probability. There is some mathematics behind this where as long as you sample a certain amount of times in a given set of data, you can be assured that the full amount of data was there. There's actually a good if you're interested in learning more about this actually on data availability, sampling and the process behind it, I'm going to link in the show notes my report on blockchain modularity for anyone who's interested. But so that's the second function of peer Das, to be able to sample the data, evaluate it, and then be able to make a conclusion about was the full data actually submitted to the chain or not by rollup, and then finally reconstruction. If there was an issue in the sampling process, or an issue in the data distribution process where, say, a data, parts of the data was lost or it wasn't actually there reconstruction is the way in which nodes correct that error or go back and tries to reconstruct the actual blob and the blob data. So there are those three parts of peer das and due to the increasing complexity of pectra concerns that say the efforts to implement peer Das is going to take longer than expected, Stokes recommended, I'm using his last name, Alex, his first name recommended taking out sampling. He had said sampling is probably the area where it's going to be the most complex to implement.
00:20:52.756 - 00:22:04.688, Speaker A: Why don't we implement peer Das in a phased way? First implement focus on implementing the distribution and the reconstruction functionalities of peer Das and perhaps sampling in a future upgrade. This was interesting, an interesting idea to me. I had quite a bit of questions coming out of that call. But developers also, I think it was a new idea for them because there wasn't a ton of discussion on it, even though something like that I think would have major ramifications on the testing schedule of peer Das and also about the impact of peer Das once it is activated, I don't think that developers will actually be able to increase the count as much if they remove sampling than if they left it in. So developers noted that there wasn't a ton of representatives of different developers from client teams that are focused on peer Das on the latest dev call. So they recommended continuing the discussion on next steps for peer Das. Really talking about this new proposal to remove sampling on a future call.
00:22:04.688 - 00:23:00.704, Speaker A: And there is a dedicated breakout call for peer Das implementers that's going to be happening on Tuesday, August 6. I'll also link in the show notes the ways to tune into that call live, although for people that are based out of the east coast of the US, like I am in New York, the call actually happens at 06:00 a.m. so I don't know if tuning in live is really the best thing, but it will be recorded, can definitely tune in to at least take a look at the recording. But this is a new idea that hopefully we'll get to hear more about in future calls. And then finally last two things on the call that I just want to highlight. There wasn't decisions made off of it. Just like the idea around Peer Das, the idea around these changes to the engine API, these were all ideas, new ideas presented.
00:23:00.704 - 00:23:53.698, Speaker A: A lot of them I think are going to, I do think that developers are going to move forward with them. But for now there wasn't any concrete decisions on actions to take in light of these proposals just yet. And two other ones that were shared on the call. The first one is actually a pretty old one. We've talked on this show before about SSC changes, the EIp there's two new EIPs that have been refined and scoped down over the last couple months by Nimbus developer Etang Kisling. He has been working, of course, on ways to update the serialization method of Ethereum, at least on the execution layer side. From RLP to SSC, SSC is faster, has a lot of other more benefits for Ethereum data processing.
00:23:53.698 - 00:25:24.696, Speaker A: It'll bring a lot more cohesion to the execution layer and the consensus layer so that they both have the same serialization formats. And of course the full conversion to SSE cannot happen in pectra because pectra is already extremely large. But kissling has been pushing and reminding developers for the last couple weeks that he has two eips, EIP 7688 and 7495, that would introduce these forward compatible structures that smart contract developers could rely on and could start utilizing sooner rather than later before the full SSE conversion. So he's been pushing to get this into Pectra as a way to address some of the ways in which data structures and data formats will be changing via the Pectra upgrade and make sure that those changes are forward compatible and will not create more work for developers later when they want to do the full SSE conversion. And he shared that, you know, he's been talking to different smart contract developers like Rocketpool about these eips and has heard from them that they're very supportive of having this change in Pektra, having these two code changes in Pectra. There were client teams on the call that expressed their support for these SSC eips. Tecu and Lodestar were representatives from these client teams.
00:25:24.696 - 00:26:21.460, Speaker A: Tecu and Lodestar shared that they do want to see this in Pectra. But of course there was concerns from other developers such as Stokes, such as Alex, who were sharing again that the upgrade is so big already, developers need to be really cautious about adding in even more to the upgrade. And in conclusion, developers did talk about it and they're still discussing it. There hasn't been a decision made on SSE, on these SSe ips. No surprise there, really. I think that it's been months since developers started talking about this, and really the takeaway was that more thought is needed on this decision. But I think developers are just a little bit confused on where to draw the line on how to go about making a yes or no decision on more eips in Pectra, because it's clear that all of the eips that are being proposed in Pectra are good.
00:26:21.460 - 00:28:04.542, Speaker A: They would have benefit for smart contract developers, they would have benefit for the protocol, and it is something that developers probably want to do eventually. But I think it's unclear how developers decide what to do now in Petra, given that there is no cohesion or no really consensus around what the headlining upgrade what the point of Pektra is is the point of Pectra to get peer Das implemented on Mainnet? I don't think so. I think there are some developers that are very excited about peer Das, but the recent proposal to even simplify peer Das does suggest that there are other code changes that developers want to implement on Mainnet in a timely manner, and they don't want peer Das to slow down those changes. It's not really about implementing peer Das to the full, it's about getting, I guess, some version of peer Das out there in a timeline where peer Das wouldn't delay the rest of the upgrade. Well so then what are the other code changes? Some of the code changes are things like Max EB Eofemenous, we've got EIP 7702, but these are all, these are all code changes that I would say some developers are more excited about than others. It's not the headlining feature of Pektra that all developers are really prioritizing and agree that this is the reason why the upgrade is happening and the highest priority item in the upgrade. So lo and behold, I think there, there's, yeah, no decision yet on SSC.
00:28:04.542 - 00:29:34.956, Speaker A: And then finally lighthouse developer Daplion shared a change to a small a minor change to the consensus layer specifications, specifically to the beacon blocks by Range RPC. He shared that there is this vulnerability for clients in the event of an extended chain split. There thankfully hasn't been any major network disruptions causing the state of Ethereum to fork and split. But in the case that there was an extended chain split, the current the way that the RPC currently works, it would make it very hard for clients to sink to the canonical chain to resync to the canonical change. It would open up these clients to DoS attacks that Daplion was sharing. Nothing that he said was all that urgent, given that there hasnt been an extended chain split and the likelihood of seeing the Ethereum network split in pretty drastic ways is not super high. But however, he did emphasize that this relatively simple change to the RPC could ensure that in such an event in such a worst case scenario event, clients can still get onto the same page as other clients, other nodes on the network and resync safely.
00:29:34.956 - 00:30:13.950, Speaker A: So that was another proposal. Daplion, of course, said that because it's easy, it can go into Pectra, maybe. But he added that it's not all that important, it's not all that time sensitive. So even if it doesn't get into Pectra, I think it's okay. So yes, that was the summary of the call. Honestly, I thought I was going to do the summary of the call in like ten minutes in the first ten minutes of the show, but look at me, already 30 minutes in and bogged down with all the technical details of some of these proposals. So very quickly I just want to summarize some of the high level takeaways from the call that I think are really important.
00:30:13.950 - 00:31:41.200, Speaker A: And number one, of course, is again, peer toss this idea of taking sampling out of of peer Das. I'm not sure exactly how this is going to impact the impactfulness of that upgrade. Will this mean that developers are not able to increase the blob count as much? Well, it definitely will mean that they're not going to be able to increase the blob count by as much as if the full peer Das upgrade was implemented. But I'm curious to know how much how drastic is the efficacy of peer Dash? How drastic is that drop in efficacy for peer Das if sampling is removed? Another one is if sampling is removed from peer. To ask does that really change materially change the complexity of this upgrade? Given pectra as a whole, does taking out sampling, will it actually make the implementation of pectra as a whole on Mainnet faster? It will mean that peer Das devnets need to change specifications for peer Das will have to change moving forward. And I just don't know if the complexity of removing sampling, if that benefit outweighs the benefit of having the implementation done in full. Anyways, I was under the impression that developers were actually really close to being ready to implement pure Das on Mainnet.
00:31:41.200 - 00:32:28.744, Speaker A: So this idea to remove sampling is a bit of a surprise to me. I think we'll learn a lot more on the Peerdaas breakout call on August 6. I'm definitely going to be tuning in, probably not at 06:00 a.m. but I'm definitely going to be listening in on it to learn a little bit more. And yeah, and I think the other kind of takeaway that I was alluding to earlier into this episode is this idea that developers continue to be very indecisive on where to draw the line to say, look, we're not going to be accepting any more eips into this upgrade. It's clear that all of the pending code changes, like SSC and a few others are good. There's enough support from it, from client teams, from app teams.
00:32:28.744 - 00:33:41.720, Speaker A: But what is really the criteria that will make developers say, no, this is not an upgrade, this is not a code change that can be added into pectra. And I think it's because there's this lack of understanding around lack of confidence around the timeline for the next upgrade after Pectra. Because if you think about it, so many of these co changes, they're all good and they all should happen on Ethereum eventually. And developers, I think in general, before this upgrade, before Pektra, had high confidence that they had time, they had time to implement code changes on Ethereum. But the way that developers are packing in so much into Pektra, it gives off the impression that petrol will be one of the last upgrades on Ethereum. I know that sounds very dramatic, but I think it's this kind of urgency around getting in an eIp into pectra, into the next immediate upgrade on Ethereum. That kind of sense of urgency is exasperated by the fact that developers have already committed to the next upgrade after Pektra.
00:33:41.720 - 00:35:13.534, Speaker A: Being focused on Virkel and Verkle is a pretty major overhaul to the data structure of Ethereum. I think that it's still, it's an experimental research phase and it could be quite a bit, you know, years perhaps, before Verkle is actually ready for Mainnet on Ethereum. And it will take a lot of testing, a lot of resources from client teams to really make sure that it's ready for Mainnet. And because of knowing that, you know, Verkle is coming up, this urgency from developers to try and get in as many code changes as possible into Pectra now is, I think that's what's really causing a lot of this indecision, a lot of this difficulty around separating out and spacing out some of the upgrades in Pectra. For example, you could imagine a version of Pektra where all of the small code changes that are ready for implementation today, for example, I believe SSE is more or less ready. Say, what are some of the other ones? Anyways, smaller upgrades on Pectra that are ready could be implemented over the next year. And then as the full research and as the full specifications for peer das become ready, doing, say, a bigger upgrade that requires that is clearly not ready in full, but that does require more time get implemented after those smaller eips in Petra go live.
00:35:13.534 - 00:36:43.166, Speaker A: So peer to us after, say, after Pektra. I don't know, maybe there were some stragglers that didn't get into either two implementing those on the third upgrade and then as VRKL gets ready, implementing vertical in the next 6th or 7th upgrade on Ethereum. I know that extends Ethereum's upgrade timeline by years and makes Ethereum a constantly upgrading and evolving blockchain, but it seems to me as though before Pektra that was more the mindset and the mentality of Ethereum developers. But for some reason, be it, say, the precommitment to Verkle, or even just the fact that governance on Ethereum is becoming a lot harder since the merge, developers have this sense of urgency that it has to happen in the next immediate upgrade or it's not going to happen. And that's, I think, a little bit of an interesting shift to make note of and to know that there is the possibility that developers are thinking Ethereum may only have a couple upgrades left in it to feasibly roll out to mainnet over the next couple years. And beyond that, we might see beyond that. It might be just a phase of code ossification that I've been vying for for many years now that I've been championing, saying that it's really important for ossification.
00:36:43.166 - 00:37:52.240, Speaker A: But I think the actual ramifications and the reality of what that means is that developers are a lot more ambitious with the next immediate upgrade that they have on their plate now, because they really don't think that there's many more left to go or many more left in Ethereum. That being said, hard decisions still have to be made. There were many decisions that were punted again on this week's call. This continued lack of certainty around the petroscope is making. I believe it's one of the factors that's making devnets unstable with developers taking eips in taking eips out of scoping out new specifications changes. Of course this is all very natural in the early stages of testing a major upgrade for Ethereum, but I think it's exasperated by the fact that we're not sure which eips, certain eips like EIP 772, the specifications for it really aren't finalized. There is this possibility that peer das will change in pretty major ways over the next couple months.
00:37:52.240 - 00:38:50.560, Speaker A: So there seems to be a moving target that's making making it harder for the ecosystem app developers to really understand what exactly is going to change with Pectra and making it harder, I think even for testing on Devnets as the scope of the upgrade continues to change. So very finally, I know this has been a very long episode, but very finally what to expect from the next call. I think very important to watch out for Devnet two. What is going to be included in Devnet two is the big question. Another big question is will developers pack in more to Pectra, be it the SSE eips or the I believe one? On the agenda for next week's call is EIP 7212. It's a signature scheme that rollups have implemented and I think it'll say a lot about how committed developers are. Ethereum protocol developers are to the roll up centric roadmap based on their decision to include or not include the CIP.
00:38:50.560 - 00:39:36.050, Speaker A: And then, of course an update on history expiry, which, let's face it, is probably not going to be ready for Pectra. And there are, yeah, yeah, I don't think there will be very, you know, important or material updates to the four four history expiry initiative, but that is also a part of the next Ethereum dev goal to watch out for and to make note of. So thank you very much for listening to this episode of the infinite Jungle. I hope that you learned something new about Ethereum and Petra development. Thank you again for tuning in. I am signing off from the concrete jungle that is New York in your explorations of the infinite jungle that is Ethereum. Stay safe out there.

00:00:10.010 - 00:00:57.050, Speaker A: Welcome to the Infinite Jungle, the podcast about the evolution of Ethereum. I'm your host Christine Kim, VP of research at Galaxy. And on today's show, what you can expect are two main big discussion topics. The first is finally we've got a date for the Denkun upgrade on Ethereum Mainet. We're going to talk about how developers got to that date, why they chose March 13 as the official main net launch date, and then we're going to talk a little bit about what the upgrade entails, how that upgrade is going to change Ethereum, what kind of impacts we're going to see on Ethereum once the upgrade goes live. The guest that we're going to have on today's show is Flashbot's data scientist, Danning. We're going to be talking about MeV data and her work utilizing different parts of on chain data and working with different data providers.
00:00:57.050 - 00:02:12.214, Speaker A: But before we begin a quick disclaimer, I need to remind you to please refer to the disclaimer linked in the podcast show notes and note that none of the information in this podcast constitutes investment advice, an offer, recommendation, or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities. Yesterday, developers have finally set a main net activation date for the Dencun upgrade. They decided that it would be happening on March 13. The reason why they set it, basically roughly five weeks from yesterday, is because they want to give client teams enough time to prepare their final client releases, the final versions of software that Ethereum node operators will run. There was a bit of pressure, a little bit of a push from certain developers on the call yesterday. And by the call I mean all core developer consensus call number one two seven, these ACD calls that Ethereum developers have every Thursday. On yesterday's call, developers had discussed briefly having these client releases ready one week, basically within one week instead of two.
00:02:12.214 - 00:03:21.600, Speaker A: But there are certain client teams that had chimed in saying, no, we need two weeks. Let's try and really make sure that the final polishes, the final cleanup work that needs to be done, gets done in the right way. So I personally was a bit relieved to hear that, that developers would be taking their time with the final mainnet releases, especially given how complex this upgrade is. And then again, there was a little bit of discussion about okay, well then, how long does node operators need, how long does the entire network need to take these final client releases and then upgrade the software? So for node operators, for people operating validators on Ethereum, they're all going to need to upgrade their software and developers had initially kind of discussed maybe we should just make it two weeks. But I think in the end reason kind of won out and developers went with three. So three weeks for node operators to be able to upgrade their software, two weeks for clients teams to really put out all their final releases. That's five weeks from when we're recording this show, roughly five weeks from when we're recording this show.
00:03:21.600 - 00:04:27.170, Speaker A: And that's how developers landed on March 13 as the denkun main net activation date. Finally, we can put to bed some speculation around when this upgrade is going to happen. I've got to say before every single upgrade, timing when this upgrade is going to happen is by far the most heavily speculated upon part of the upgrade, like when it's actually going to happen. And even when we talk about the next upgrade after Denkun, which has officially been kind of dubbed its combined name Petra, even as developers are talking about Pektra, they're talking about when it should be. When will pector actually go live on main net and near the beginning of planning an upgrade. These estimations are 90% wrong because as you actually start developing the upgrade and testing the upgrade, the timeline usually does get extended. So developers will get into it in a bit on this show about the discussions around Pektra and when it's going to happen.
00:04:27.170 - 00:06:01.290, Speaker A: But all this to say, I think many people can breathe just a sigh of relief of not having to wonder and wait and estimate again. I know personally, and if you've been following along on this show, a March 13 activation date should not come as a surprise because we talked about this last show last week about how it seemed very likely that developers would pick a date for mainnet activation in March. 3 things that I just want to highlight about the Denkun upgrade that's going to be going live. The first of course is the biggest code change going into Denkun is EIP 4844 and it's really designed to reduce the cost of roll ups, reduce the cost of these layered scaling solutions built on top of Ethereum. And one of the things that I think will be really important to watch is how ready are l two s for mainnet activation for Denkoon? Tim Bico on ACDC one two seven, the latest dev call basically said I reached out to the top ten roll up teams and many of them said that they were going to be ready early to mid March. Now I think those estimations may be a bit optimistic, basically being able to upgrade roll up software to integrate with the Denku and upgrade takes time. I believe that many L two teams, L2 roll up teams are already testing their infrastructure on the sepolia testnets, on the guerreli testnets.
00:06:01.290 - 00:07:32.110, Speaker A: But there may also be a period of social governance that needs to happen on these roll ups to really enact the upgrade as well. So even while testing and the roll up team might be ready to go mid March, there might be a governance process added to the end there to really make sure that the upgrade on these roll ups happen to seamlessly integrate and actually utilize the additional block space that's created for roll ups through EIP 4844. So some things to really watch for is what are the fees for blob transactions? What are the fees for what roll ups are paying to commit their data down to Ethereum? Because right now roll ups are paying basically what users are paying users that are sending transactions directly on Ethereum, roll ups that are trying to commit data down to Ethereum. We're all in the same mem pool. We're all in the same market for block space. But now through EIP 4844, you're going to have dedicated block space that's exclusively for roll ups. And the question is that fee market for that very customized block space, how expensive will that block space become? How utilized will that block space be? Are we going to see blob block space be completely filled up with roll of transactions? Or in the beginning, will it be fairly underutilized? So these are questions and kind of like important things to be watching out for.
00:07:32.110 - 00:08:56.498, Speaker A: As the Denkun upgrade goes live, we're going to see a ton of data on just how much does this upgrade impact roll up fees. So for the end user on rollups, how cheap is it going to become for them to send a transaction on, say, optimism or arbitram after the Denkun upgrade, are we going to see a significant decline in those fees? From the perspective of end users, I'm sure that roll up operators, the sequencers themselves, that are committing down to Ethereum, they'll notice perhaps like a significant drop in how much it costs to commit user transactions down to Ethereum to finalize those transactions. But I do wonder how much those cost savings will be passed back to the end user. So things to be watching out for, these are metrics and kind of interesting points of data that I'll be carefully watching, especially as the Denkoon upgrade goes live. And it's not all about roll ups only. There are some other kind of important eips that are going into Denkun, the second one that I'll mention is for validators. Specifically, the maximum number of validators that can enter into Ethereum will be capped and set at eight validators per epoch.
00:08:56.498 - 00:10:21.074, Speaker A: This is to ensure that the validator set size doesn't grow too large for the network to be able to handle, and this is really a band aid solution. Developers are going to have to figure out a different way to ensure that the validator set size of Ethereum doesn't become too unmanageable in the long run. The setting of the cap and just making sure that no more than eight validators per epoch can actually enter into Ethereum at a time, instead of like say nine or ten or eleven and so on and so forth. That's kind of another interesting change to the protocol that I think people should be aware about, especially if there's a spike in people in demand for staking and people wanting to earn yield, wanting to earn staking rewards on Ethereum. That cap is something to note in projections of how long it might take, and may change a little bit the staking dynamics on Ethereum, but maybe not so much as the long term solution that developers are thinking about for Prague or Pektra, which is the combined name anyways with Max Eb. Now that I think about it, look at me, I'm just like, I'm literally thinking about like seven things at the same time and trying to formulate them into sentences. But let me get back on track.
00:10:21.074 - 00:11:32.598, Speaker A: Say just as a brief note too, for the third part of Dencoon that I think people should be aware about. For smart contract developers, there are actually some interesting new features and tools that will hopefully make smart contract coding on Ethereum a little bit of a better experience. There's the implementation of code changes like transient storage and mcOpy. I won't get into these into too much detail, but just note that this upgrade, though it is focused on roll ups, there are other code changes in it that will be impacting validators and impacting smart contract developers. So it's a pretty major upgrade and one worth watching when it goes live on Ethereum on March 13 to see how it impacts the ecosystem, how it impacts all these stakeholders on Ethereum that are building very cool things and potentially the future of what we might call the Internet one day. So that's Denkun. And even though I talked a lot about it, honestly, developers are already kind of moved on from Denkun.
00:11:32.598 - 00:12:20.962, Speaker A: There is still testing going into the upgrade, but the majority of what developers discussed on the latest dev call was the next upgrade Pektra. And again, as I explained during the last episode, Pektra is a combined name for Prague and Electra. It's a portmanteau of the execution layer upgrade, which is dubbed Prague after the naming schema for execution layer upgrades are major cities, and then Electra, which is the name for the consensus layer upgrade that's happening. And the naming convention for that is kind of major stars and constellations. So that's how we get Petra. And sometimes on this show I'll call the upgrade Prague, I'll call the upgrade Electra, and sometimes I'll call them Pekra. But just know that I'm referring to generally the next major upgrade after Dankoon.
00:12:20.962 - 00:13:38.626, Speaker A: And because yesterday was an all core developer consensus call, developers primarily referred to the name of the upgrade by its consensus layer name Electra. And one of the code changes that was not discussed initially, I think for the upgrade, or at least it wasn't discussed heavily for the upgrade, is enshrined PBS EPBS and that was a really big topic on this week's call. The reason why it was a big topic was because there was a fairly significant incident that happened on main net on February the 6th. One of the MEV relays, the blocks route max profit relay, were delivered, but those blocks failed to be included in the canonical chain of Ethereum because those blocks were invalid. They were faulty blocks, and the relay had a bug in it in that the relay was supposed to basically stop receiving blocks from a particular block builder. If a block builder is building a block that is invalid and they submit it to the relay, the relay should be able to check that and say, oh, I got two, three consecutive invalid blocks from you. Like I'm not going to receive any more blocks from you, sir Builder that kind of process didn't happen.
00:13:38.626 - 00:15:17.220, Speaker A: So what ended up happening was the relay just kind of sent through these invalid blocks to validators and it led to nine missed blocks on Ethereum. And while it didn't cause major disruptions to the network, like delays in finalization and major kind of disruptions to the user experience, it did raise a lot of alarm bells from developers who were watching this and who know that there's an upgrade potentially coming that could remove the need for trusted relays, remove the need for validators to just blindly kind of accept blocks from relays and submit them to the network. And that's really what enshrined PBS is. Enshrined proposer builder separation is trying to remove the need for a trusted relay and there's this quote that I just want to mention from the call yesterday that I thought was an important quote to the conversation. Danny Ryan, basically, at the end of discussion of like, okay, do we want PBS for, do we want to prioritize it for the electra upgrade? Do we not? Is there even design for EPBs that we all agree upon and that's ready for implementation? And Danny Ryan, who chairs these calls, said, quote, when I see this topic, aka EPBs, opened up, there's a lot of questions as to what we are even optimizing. What is the right end goal of this? It seems there's a lot of varying opinions on that. The decision to include this first becomes the decision to figure out what is the design.
00:15:17.220 - 00:17:24.620, Speaker A: And the reason why I really like this quote is because every time we talk about MeV, which is the additional profit that validators can make from building a block through reordering transactions, through kind of playing around with the content, seeing what the content of the transaction is, and reordering them in a particular way to extract more value. When we talk about MeV, there's a lot of questions as to what type of MeV is good and what type of MEV is bad, and how should a network grow so that MEV is mitigated? Like, can MeV even be completely removed from a system? There's these kind of broader questions around the ethics, around the way that people view MeV and the way that MeV may or may not be able to be utilized to actually help the user experience, especially with different decentralized finance apps on chain. So now I'm getting into a little bit of a ramble. But this quote, I thought it highlighted just basically the fact that while you might be able to agree that we do need to remove the need for trusted relays, there's a whole can of worms around. Not just relays, not just that one part of how MEV is extracted on Ethereum, but a bunch of questions then on the related technologies, the related components of how MEV extracted. It's not just relays that are part of that big supply chain of MEV, right? One of the developers, Terrence SaO, from the PrisM team mentioned, look, the builder API, the software that we rely on for third party block builders to submit these blocks containing MEVs to validators, that piece of software as well, needs work. There are significant misaligned incentives there that we need to talk about.
00:17:24.620 - 00:19:16.078, Speaker A: And another prism developer by the name POTUS was talking about how, look, there's also the concern around many of these relays and many of these parts of the MEV supply chain being closed source, built with closed source technology that we as open source developers on Ethereum just don't know, can't really look into how they work or really investigate further what they're doing, whether or not they're engaging in censoring behavior and all sorts of kind of misaligned incentives with the Ethereum protocol. So all that to say, I feel like I've gone way over my time with this call. But all that to say, enshrined PBS was a big topic, and it will continue to be a big topic on further calls. Ethereum developers are going to have a breakout session to talk about this, to talk about Enshrine PBS and its design implementation details in more detail. But one thing that I think developers are really trying to hone in on and really get to the bottom of is what is the collective kind of approach and attitude towards how we want Ethereum in the long term to handle MEV, how Ethereum as a protocol should really view MEV, and what is the right end goal that we're trying to target here? Is it really to kind of get rid of MEV completely? How should the gains of MeV be distributed or across different Ethereum stakeholders? And to that, it just bleeds into so many other discussions, it touches so many other parts of technology. On Ethereum, the builder API, we're talking about potentially different upgrades like Mev Burn and so on and so forth. So I think it's going to open up a whole can of worms, and we'll continue to get into it and discuss it on the show as we move forward.
00:19:16.078 - 00:20:11.514, Speaker A: But with that, let's move on to the second part of our show where I get to talk with basically a subject matter expert and ecosystem participant that works on Ethereum. And today I'm so excited to be welcoming danning from flashmots onto the show. She just launched a new podcast, actually, about crypto data and some of the quirks around working with Onchain data with two of her colleagues. So we're going to learn a little bit more about her passions around on chain data and a little bit more about her work at Flashbots, which know a major organization that's researching Mev as well. So we'll continue the discussion with her. Let's go ahead and bring her on the show. Hey guys, welcome back to the show here with Danning, a data scientist at Flashbots.
00:20:11.514 - 00:20:51.386, Speaker A: I'm so happy that you're here, Danning, because I have so many questions about crypto data, MeV data. We were just talking, I was just listening yesterday on the dev call about. There's just a lot of conversations already about how do we improve the MeV supply chain, how do we get data on MEV. Lots of numbers flying around of what, 90% of blocks potentially being censored, builders only being like ten builders and relays only being like five relays. So there's a lot of things coming around. And as you can see, my mind is in many places right now. But thank you so much for joining the show.
00:20:51.386 - 00:20:59.946, Speaker A: Thank you so much for being here. I'm very excited to dive into these topics with you. But yeah, thanks for invite.
00:20:59.978 - 00:21:04.080, Speaker B: A pleasure to be here. Happy to talk about mevian data, for sure.
00:21:04.550 - 00:21:19.814, Speaker A: Yeah. Well, I mean, I guess, first of all, I also want to say again that congrats on the launch of your podcast as well. The indexed pod. I know you hosted and then you hosted with two other colleagues, is that right? Who are your hosts again?
00:21:20.012 - 00:21:39.770, Speaker B: Yeah, I'm hosting with two other friends who are also data scientists from all different teams, Hidobi from Dragonfly and Boxer from Dune. So it's more like how to say, web3 data nerds, friends chatting about stuff and kind of like joke about the chart crime we see on Twitter all the time, et cetera.
00:21:40.350 - 00:22:01.806, Speaker A: I love that hildavi is a big name. I feel like for anyone who works on Dune or uses Dune, they all know Hildavi because they all use his dashboards. Do you find that there's also a lot of copying going on? Because I know sometimes that's a topic of contention of people using other people's data and not giving credit, et cetera, et cetera.
00:22:01.998 - 00:22:44.640, Speaker B: Yeah, I think it happened probably maybe more earlier in the, how to say, when community started, when people started forking queries on doom. But I think Dune has been doing a good job about basically being able to bring the visibility of the originator. And I think recently more, we've been seeing it more like when web3 people have been talking about this data for forever, but now how to say mainstream media starting to copying the number and posting about it and without crediting. So I think a lot of the web3 people have the awareness of crediting and we love to credit each other. We will bring that more, I guess, to the mainstream as well.
00:22:45.090 - 00:23:53.414, Speaker A: Yeah, it really does flow also from the fact that so much of what we build is open source and it's not just the data, but it's also even the software that people, there's a lot of drama. I feel like even in the L two ecosystem too, of like, oh, you're using my VM, or you're using my proving algorithm, et cetera, et cetera. But yeah, to that, I guess just going a little bit deeper into your work as a data scientist at flashbots, when you're working with on chain data, and when you're working with data that you could potentially be using from other data providers, like Dune and whatnot, or maybe using your own proprietary stuff, what are some kind of common misconceptions or mistakes that you think that people often make when they first start using or start getting into kind of crypto data, especially if they're using like a data provider, or if they're trying to get into it on their own. From your experience, what has it kind of been like working with onchain data? And how different is it, would you say, from kind of the prior if you had.
00:23:53.612 - 00:24:25.322, Speaker B: Yeah, I feel like data provider isn't a big problem, because actually across all data providers, they're providing the same copy of data, which is the charm of blockchain, because we're all analyzing on universal database. Basically. I think it's more of a few problem. For example, first is if, when people just come to web3, there is this context switching of what is a user. So the way we define user in web3 is so different. Everything is anonymous and it's hard to track. And you don't really know if multiple addresses control by one entity.
00:24:25.322 - 00:25:19.326, Speaker B: So people may report like, oh, there is this many dau, but what is you here? It's maybe more like a daw, like daily active wallets or something. And also when you report it be like, oh, there's a hype of new users coming in, but you can't really say that's organically growth of users of a protocol. But more it's possible a lot of yield farming incentive things happening in crypto, because it's basically sort of like a DDos or spam with low cost, especially in a lot of l two. So the way you read into data would be also tricky. But I think it takes time. But people over time would gain this knowledge about how to differentiate between all these. There are some misconcept of people may jump and be like, oh, comparing these metrics across chain, particularly a lot of time, people show Solana by comparing say, ethereum.
00:25:19.326 - 00:25:51.466, Speaker B: Now Solana has more number of transactions or contract calls or like logs, just meaning more activity. But what really even is smart contract concepts in Solana, it's quite different. It's not really smart contract, but more like programs there, so you can't really compare it. A lot of time you say, oh, different chain. This chain has a lot more validators than the other one. But the security or consensus protocol might be totally different. And how to say, the entry barrier or the cost to round validator might be different.
00:25:51.466 - 00:26:17.742, Speaker B: There might be staking pool, et cetera. So something like, for example, people say, oh, the transaction is going up, but it may not mean there's new apps coming. It might be just inscription going on. People are hyping about speculation. The Dex trading volume is really high, but it doesn't really mean there's this many retail trading. Maybe a lot of them are actually MEB bots. So I think go deeper.
00:26:17.742 - 00:26:22.440, Speaker B: Beyond the surface is also a theme we will have to develop over time.
00:26:23.690 - 00:28:08.546, Speaker A: And specifically with the data that you work in, because you were mentioning kind of like when you compare data between Salana and Ethereum or other l one chains and Ethereum, that data that you're looking at, fees, for example, volumes, they might have different meanings. And then even when you look just at Ethereum, the definition of what a daily active user, it could differ from provider to provider, and could just mean that it's not actually one user, it's not multiple users, it's one user controlling multiple wallets. When it comes to data on MEV specifically, one of the things that developers were talking about yesterday is how so much of the products that we rely on for MEV is actually closed source. So like, for example, the incident that happened this past week where the max profit blocks route relay had gone down, developers were kind of saying, we don't know what the fix was, we don't know exactly what went wrong. And then with the increase in the number of kind of private mem pools that are kind of popping up so that people might be able to send their transactions in a more faster way or directly to a builder without going through the public mem pool. I'm just curious to know, is a lot of the data that you're trying to get hard to get, is it very difficult to kind of figure out data from a builder or data from a relay because of the fact that these software, it's not necessarily running through like a public open permissionless blockchain like Ethereum?
00:28:08.738 - 00:29:07.574, Speaker B: Yeah, I think naturally it's a lot of how to say hustle to get all these data analyzed about MeV, how to say settlement or supply chain nuance, just because it's off chain. First of all, and so you can't really just go to Juno or any data provider to query on chain copy or query a so. But luckily, I think it was a good intuition that when the Flashbots team launched Mapboost, we also launched a standard data API, which is relay API. So all the relay, when they round Mapboost, they will post all the received bids from builders, and also they will post what's the winning bid, and basically deliver the payload towards validator. So we have some level of data to analyze there. And that's why you see a lot of community dashboard from, for example, Tony from EF about Pix and for example, payload de. They have really great data dashboard to show within each slot.
00:29:07.574 - 00:29:42.866, Speaker B: What's the bid look like coming from different builder over the slot time. But I would say there's still a lot of barrier to get deeper into the data. Like, for example, we know the bits, we know the winning bit, but we don't really know what are all the block that's submitted by each builder. So really are able to do that. But it's like a giant pack of data. So I doubt any relay is caching that and sharing it to the community today. And there's another also kind of like, how to say, sensitive aspect of, say, flash rods.
00:29:42.866 - 00:30:19.918, Speaker B: We were actually talking about this. We're trying to understand what's the transaction latency today, like going through the private chain. And that was easy in public Memphis case. So you just query a node and you can check when do you get that transaction? When node gives you the timestamp. But now it's like it could exist in any of the builders private mempool. And the only way either builder will share all their transaction batch with you, which is impossible because they would want to keep it private for bidding a higher value block. Or you can maybe estimate it when it comes to the relay.
00:30:19.918 - 00:30:52.550, Speaker B: But then that means we will need to enable the caching of block content in relay side. But then that's kind of tricky because flashbots is analyzing flashbots relay data. But we are also running a builder and relay, so that can be an unfair edge of competition. So we couldn't do that. So we're trying to find a way to potentially take a route. But yeah, so TLDR, I would say, like private mempool definitely makes things harder to track. One is latency aspect.
00:30:52.550 - 00:31:50.878, Speaker B: You don't really know when builder received the transaction, hard to know relay would receive the transaction. Another thing is like, you don't even know if a transaction will be exclusive or not. Like defining exclusive, it means it was only in one person or one builder's pool, or otherwise you can only say it's a private flow, probably. So there's no way to even track if it's exclusive unless everyone posts what did they see? So yeah, there are some other rents I have, sorry. For example, there's this behavior of multiplexing of user because people want to send their transaction to land as fast as possible, so they might send to multiple builders. And in this case, for a RPC provider like us, like flashpots has RPC trying to land a user transaction, it may, how to say, disturb our metrics by many aspects. Like for example, we may see a very high revert rate because users sending to us, they're also sending to others, and it landed with others already.
00:31:50.878 - 00:32:23.814, Speaker B: Then we will see, okay, nouns is too low with this user transaction, okay, revert. And it will be like a much higher simulation fault. How do they failure rate? It may also overestimate our lending rate, because when we find this user transaction, we always keep checking if it's on chain already. If it's already on chain, then we drop it. But then it could be on chain, but not because landed by us. Because the way when we report landing, it's like oh, on chain divided by all the transaction receive. So it might overreporting a transaction landed by other builder.
00:32:23.814 - 00:32:43.040, Speaker B: And overall, it's also hard to identify if any builder has misbehave. Because what if a user transaction was front run or sandwiched through private mempool, but then which builder leaked the information? Maybe to some searcher. Then if it went through multiple builders mempool, it will be much harder to track.
00:32:44.390 - 00:33:54.550, Speaker A: Fascinating. So because users, in order to get their transactions included in a block faster, if they send it to multiple builders, it becomes definitely more difficult to track whether or not that transaction got even front run or sandwiched and by who. And it's fascinating to also hear how we even define what a private order flow is. Is it if that transaction only goes to one builder, or is it if the transaction just circumvents the public mem pool? Maybe it goes to multiple builders or is seen by many people, but it just doesn't go to the mempool. And defining that, yeah, that must be a real challenge. It's great to hear though that there's these other sites like Mevboost, Pix, Tony and all these other people kind of working on MEV data and illuminating what is happening with MEV, because before the merge, I feel like Flashbots was really the only organization that was building these tools and sharing information about how much MEV is being earned. But it seems now that there's more people, aside from flashbots, looking at this data, trying to build on this data.
00:33:54.550 - 00:33:56.040, Speaker A: Would you agree with that?
00:33:56.490 - 00:34:09.420, Speaker B: Yeah, definitely. I think it's also just the growth of MEV supply chain, or itself as like a subdomain of the industry. There's a lot more teams also working on MEV relevant products.
00:34:11.950 - 00:35:26.760, Speaker A: And some of that data you had mentioned is like proprietary data. It's like data that builders have, so that they can be more competitive than other builders. They don't want to leak all of their strategies. And so there's this kind of tension between, we want to be as transparent as possible, to be able to track what the heck is happening in the dark forest that we called MeV. But also there's like this trust breakdown that can happen. Do you think that to some extent, there's parts of MEV that will just forever be unknowable to ethereum developers, to flashbots? To what extent do you think that we can build tools to really be able to understand what's going on on the MEV side? Like for example, should we know what exactly went wrong with the blocks throughout relay? Or does that kind of create competitive disadvantages for that relay in comparison to others? If parts of their stack and parts of what they do were released to the public, or was able to be more easily identifiable by data scientists like you?
00:35:27.290 - 00:36:29.130, Speaker B: Yeah, I think the incident case is probably always good to be analyzed and to be shared. And so other relays, or basically the design of all these mechanism can be improved or avoiding any of the issues. Overall, I think there might be some MEV that's hard to know by most of the other parties. For example, like CFI DeFi arbitrage, like cross domain MEV would be how to say a thing that can be very sophisticated knowledge towards traders. For example, you will need to know how to model the gain and profits across binance price book versus on chain. And it definitely requires a very how to say as much as possible coverage towards all the amm. So then you need to index as many pool as possible, and so to know as better as possible of all the MEV accounted.
00:36:29.130 - 00:37:00.580, Speaker B: I think it might be even harder for l two MEV to be quantified based on all these new features of shared sequencer, or it doesn't have a mempool. So it's still, how to say, a problem that we're trying to tackle with some new initiatives in the coming year, but overall, yeah, I think there's a lot of endeavor to index MEV already, so I think it's a pretty good shared taxonomy today.
00:37:01.190 - 00:37:52.290, Speaker A: Yeah, I think it's one of the most important initiatives, I feel like when it comes to figuring out how to deal with MEV and how to build products in a way that actually solves the MEV problem, so to speak. If you don't have data and if you don't know what's going on, it's very hard to really make tools and products that are going to actually change the game. And one of the products that I have been hearing so much about, danning, especially from Flashpods, is this product called Suave. I'd love to hear a little bit of an update on what that is, how it's going, to what extent it's going to change data collection on MEV, to what extent it's going to change the MEV supply chain. Right now. I think that's another kind of big topic that people are thinking about this year, and I'd love to get your thoughts.
00:37:52.950 - 00:39:18.698, Speaker B: Yeah, so disclaimer that I'm not a researcher working on swap. We have a whole R D team and research engineers that's building swap right now. But I can talk about my understanding and our internal jamming about how all the use cases about swab. So my understanding of swab is like first of all, it's a hard problem, and so they're trying to build something really ideal, which is supposedly a generalized auction mechanism or like a platform where any type of order with auction problems can come here and be provided with permissionless platform. So it provides how to say confidential compute and storage. So, meaning if you share your order, you can basically keep some of the private part information in SGX or enclive, but then you can also configure it to be programmable, to be shared with others, to be, how to say, work on for example, very concrete use case could be like building a block. So if builders all come here and they can share their order flow to an entity that's protected, say like SGX or whatever, and not know, any party has more privileged info on it, and they will provide there how to say merging algorithm, potentially as an application or like a swap, how to say like a smart contract on swap chain.
00:39:18.698 - 00:39:54.940, Speaker B: And then all those can be run and it might be able to build a much more competitive block with all these shared order flow, shared infra, shared subsidy maybe. And in this case you might be able to build like a collaborative block building case. And this might be a big statement, but my imagination is that this may help smaller builders to compete with bigger builder. It may mitigate the centralization problem in PBS. So I don't know, but it could be a direction, right? Another case could be like, go ahead.
00:39:56.190 - 00:40:15.490, Speaker A: Basically, when a builder shares kind of what it wants included in a block, who does the aggregation? Like who kind of puts them together and makes them competitive? Is that the smart contract, it automatically kind of makes a more profitable block? Or is there someone who's like running the SGX, running the kind of hardware?
00:40:16.150 - 00:41:26.742, Speaker B: My understanding is that things will be verified on chain. So like builder, if you're willing to submit your merging algorithm into a smart contract on chain, then it's guaranteed that you're not misbehaving, you're not censoring anything, you are not like trying to replace transactions. Meanwhile you are sharing your merging algorithm infra to build the block, potentially with more inputs from others. And potentially you can build a higher block and then so the value can be distributed also based on contribution, et cetera. But this is just like one wild case we're jamming about. Another example could be like right now, today we know there's a silver model in Dex trading platform like Cowswap, Uniswap X and one inch fusion. But today I think the ideal design for those solver model is that all the solver when they submit the routing results, how to say to the platform, it should be a permissionless process, that there is something that's deciding which routing is the best.
00:41:26.742 - 00:41:55.378, Speaker B: But today it lives in a centralized backend of cowswap or uniswap X. They will decide oh, this server has the best price and they will submit or the server will submit. But imagine if that auction process can be living in swap as like a smart contract. Then you will be able to remove the trust assumption to Coswap or uniswap X as a platform. So that will be potentially be able to realizing the permissionless design.
00:41:55.464 - 00:42:06.150, Speaker A: Actually swab sounds like a general purpose blockchain where people can build smart contracts, but specifically for builders, like smart contracts for builders.
00:42:06.570 - 00:42:09.320, Speaker B: Yeah, I think that's a great way to summarize. Yeah.
00:42:11.370 - 00:42:18.070, Speaker A: How soon do you think builders will be able to build their own smart contracts? Start using the swap chain?
00:42:18.410 - 00:42:44.350, Speaker B: Yeah. So right now we're still working with developers and teams to talk about all these use cases and trying to deploy it in testnet. I think our team would want to do some more hackathon and events around east London time. We actually announced it in Twitter. We're going to have a event called amoeb markets, so keep posted and check it out at London.
00:42:44.850 - 00:43:42.786, Speaker A: Love that. And I've got to make a quick shout out. I mean, this probably isn't your team on flashbots, but every time I listen to the all core developer calls and they're talking about enshrined PBS, they're talking about Mev Boost, talking about the builder API, there's no one from flashbots there talking about these products and tools that Flashbots made. Like, the developers are talking about it as if it was like these tools were dropped from heaven and they just now have to deal with it. But I'm like, remember that time when we were going through the merge and there was a representative from flashbots on every single week talking about these tools, the organization, the people who've built this with understanding and ideas in mind of how Mev should be handled. I think are there, they exist. They're working on new products and tools that might change the game.
00:43:42.786 - 00:43:49.154, Speaker A: I'd love to see some more flashbots folks on the call. I got to say, yeah, totally.
00:43:49.202 - 00:44:32.050, Speaker B: I think it's kind of intentional and maybe kind of like in brand with flashbots. They're trying to establish with us that it's a collective rather than a company or organization. So I think it's also intentional that we don't have a Twitter account and people would go to discord or more like where the ecosystem or community lives, some telegram group chats to discuss about things. And yeah, amoeboost itself is an open source software, so it's great to see. Actually, the ecosystem is designing around it and developing it further. Not saying it's 100% great. I mean, there is a lot of problems today with me boost, so yeah, we'll see how it can evolve.
00:44:32.550 - 00:45:40.520, Speaker A: Yeah, it's crazy how this whole builder relay ecosystem has evolved just from MeV boost. Like from the merge onwards, the changes that have happened to the MeV ecosystem on Ethereum are wild, and I'm sure there's more changes still to come. So thank you so much for being on the pod, for talking with me a little bit about your work, working with on chain data. MeV data, really fascinating stuff. And thank you for the update. We're going to have to have you back on when we have more developments around what Flashbust is working on, suave and other data, you know, we'll be able to talk even about some of the tools that you guys are building around order flow data too, maybe as kind of a final and more fun question, not that this conversation, but maybe an Ethereum culture question that I've been asking most of my guests is what is your Ethereum conference of choice? What Ethereum conference do you most enjoy going to and why?
00:45:41.610 - 00:46:20.920, Speaker B: Yeah, I would say Devcon is the top choice because it's a bigger stage with all the developers who are very technical and people, or how to say the product team is coming to release a big launch. And so, you know, most of the exciting stories from here and I would say Devconnect. I really loved it last year. It's also very Ethereum centric and it's like a lot of infra people and Ethereum foundation people come out, talk about next stage of the design or Eips. So definitely love those as well. I go to East Denver all the time. I think it's totally different vibe there.
00:46:20.920 - 00:46:50.800, Speaker B: It's kind of like spread it out in the city and a lot of the people you meet could be like, oh yeah, I just heard about Ethereum. I love this NFT. I'm a designer and I launched a collection. I think it's great in its way as well. It's like maybe a lot more noisy but also very grassroots, I would say like all the people who curious and love about it can apply to have a talk, et cetera. So yeah, I think those are the top ones I would go to for sure.
00:46:51.170 - 00:47:08.422, Speaker A: Nice. Yeah. And for East Denver, it's free too. So if you're listening and you're in the States and you're wanting to go to an Ethereum conference, I do also recommend East Denver. Are you going this year? At the end of this month? Amazing.
00:47:08.556 - 00:47:19.800, Speaker B: I will be there. Yeah. And I will want to talk to all the Meb people. I think the team isn't planning any events to host, but we'll love to meet.
00:47:20.490 - 00:47:59.800, Speaker A: Yeah, yeah. So if you want to meet Danigan in person, she's going to be at East Denver this month and I'll give another shout out for your podcast, indexed podcast. If you want to hear more about crypto data insights, be sure to check out Danning's pod. Thank you so much everyone for listening again to Infinite jungle for following along with the show, and I love to see all of everyone's comments and feedbacks on what we talk about. So keep it up on Twitter and whatnot. Be sure to like subscribe, do the things that get you interacting with the show. Those really help a lot.
00:47:59.800 - 00:48:08.690, Speaker A: That's it for today. That's it for this episode. And I'll talk to you guys again next week. Thanks, guys. Bye.

00:00:10.080 - 00:01:16.269, Speaker A: Welcome to the Infinite Jungle. On today's episode I am going to be talking about the main takeaways from all core developers. Consensus call number 141 there weren't very many major updates about the Petra upgrade for Ethereum, but there was an interesting discussion on the impact of peer DAs on at home stakers on people that are running validators on resource constrained devices low grade hardware. In other words, that's a lot of synonyms. But we're going to get into that discussion because I think it's quite important to the future of Ethereum and the people that we expect to be validating the network and operating the network in the future. So before we get started with the show, as always, here is a quick show disclaimer. I need to remind you to please refer to the disclaimer linked in the podcast Show Notes and note that none of the information in this podcast constitutes investment advice, an offer recommendation or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities.
00:01:16.269 - 00:02:13.453, Speaker A: It's good to be back on the show. I had a wonderful week off and one of the things that I really appreciated about my time away is that during my time away there was no major catastrophes or or major developments, I would say, in the protocol development space for Ethereum. That's always one of the things I worry about when I go on vacation is if anything related to Petro or Ethereum protocol development is going to happen while I'm away. But I was happy to find that when I came back everything was chugging along pretty smoothly. So during the latest all core developer call, developers gave updates on their progress with Petra. The biggest takeaway is that everything's chugging along pretty and because it's a large upgrade, it's got a lot of different code changes in it. It means that this process for implementation and testing is going to be a long, drawn out process.
00:02:13.453 - 00:03:55.233, Speaker A: So let's get into some of the Devnet updates and some of the quick conversations that were had on the call related to different parts of the upgrade, but truly these aren't all that important. The first one was that debugging efforts on Petra Devnet 2 are now nearing complet. There was one final bug related to the Prism client that has since been resolved, so developers are looking ahead to launching Petra DevNet 3. The one thing about Petra DevNet 3 that developers were talking about in terms of its timing and in terms of when to go ahead with it, there are some outstanding issues related to EIP 7702 this is the EIP related to making user controlled accounts more flexible, more programmable and so some of these issues are going to be talked about on the next all core developers Call this week's call, the latest call I should say was primarily related to code changes on the consensus layer side and on updates to the consensus layer client. EIP 7702 primarily impacts the execution layer clients. So on the next call which is focused on execution layer client development, developer is going to talk about this, talk about EIP 7702, how those implementations are going, and then probably discuss the rest readiness of execution layer clients for Petro DevNet 3 To be clear, not all of the clients for Ethereum need to be ready for the devnet to go live. It's not like all consensus layer clients and all execution layer clients all need to be ready for the next devnet, but a handful of them need to be.
00:03:55.233 - 00:04:57.113, Speaker A: So at least one or two execution layer consensus layer client pairs should be ready and the rest can be added later. So TBD on when the next devnet will go live. For Pectra, there was a slew of different updates related to picture specifications that were shared on the call. This is very natural and I just want to highlight a few of them to really hammer home the type of conversations that you're going to hear a lot on these calls. I hope some of my listeners took me up on the advice I gave last week before I went on the one week hiatus, which is that you should try listening in on these all core developer calls yourself every once in a while. Because most most of these discussions are related to these edge cases or unexpected kind of problems or issues with implementing different parts of Petra, different parts of the upgrade. So the first as an example is EIP 7251.
00:04:57.113 - 00:05:55.729, Speaker A: Developers said let's increase the maximum effective balance of validators from 32 ETH to 2048 and this has the effect of allowing validators to be much larger in size. Now you don't have say like 100 validators that each have an effective balance of 32 ETH. Now you can have just one validator with 3200 ETH staked and 3200 ETH being that validator earning rewards on 3200 ETH rather than just 32 ETH. And the other part of EIP 7251 is to enable existing validators with an effective balance of 32 ETH to consolidate their staked ETH and become larger validators and not have to Run these individual instances of validators just consolidated all into one instance. Hopefully make the overhead of managing all these validators a bit easier for large stakers. So that's the purpose of the upgrade. It sounds all nice and dandy.
00:05:55.729 - 00:07:21.121, Speaker A: You're like, okay, this is kind of what we're hoping to do. But in the process of doing this, as developers are implementing EIP 7251, they're noticing other parts of the code base that they didn't expect needed to change or that they didn't expect that they would run into issues with. For example, in the process of changing the effective balance, you also have to update the calculations for the way that the protocol calculates the rewards for validators and calculates penalties for validators. A lot of the different calculations and parts of the protocols are based on the number of active validators that are on Ethereum. All of the validators have more or less an identical effective balance of 32 ETH. But once you increase the effective balance of 2488, now certain calculations are going to have to be based on the amalgamated the total balance of Ethereum staked by these validators. It's not going to be based on the number of validators, because protocol is going to have to evaluate differently the rewards and the penalties for a variety of validators with a larger effective balance differently from if there's a group of validators with a smaller effective balance.
00:07:21.121 - 00:08:48.900, Speaker A: The penalties are and the rewards are going to have to be higher depending on the effective balance of a validator, not necessarily on just the number of validators that are live on the network and operating. So in relation to this, as I had kind of mentioned on some of these prior, on a prior episode, is that there was an edge case that was identified by developers during the way that penalties are calculated, especially because on Ethereum validator, penalties increase if there are correlated slashing events. So if there are events where validators are, there's multiple validators seen to be misbehaving or breaking the rules of the network. The penalty that's automatically laid by the network on these validators is larger than, say, if it was only one validator that was seen to be misbehaving. But again, since EIP 7251 changes the effective balance of validators, this kind of calculation needs to be updated so that the calculation is based on the effective balance of stake, not necessarily the number of validators that are seen to be misbehaving on the network. And so the fix for making sure that the calculations for core correlated slashing penalties to make sure that it's correctly calculated. That fix was talked about on the latest call.
00:08:48.900 - 00:09:46.481, Speaker A: It's been talked about on a few calls. But on this call, developers kind of agreed more or less to move forward with a certain design for that fix. And developers just shared that it's in the final call for final stages of feedback. So if there really is anything that developers think should or shouldn't be done about that calculation and the way that it'll be updated, they need to speak up because it's about to be merged into the official consensus layer specifications for Pectra. This is the go to document for client teams that are building out the Pectra upgrade and the change to the correlated slashing penalties are about to be finalized. So on this call I was talked about, and on this call I was reiterated that time's up, you had your couple of weeks. All client teams and developers had their couple of weeks to be able to give feedback and review the change.
00:09:46.481 - 00:10:56.097, Speaker A: The change is about to be merged into consensus layer specifications, which means now client teams are going to implement it and it's going to be tested on upcoming devnets. So that's one example of an idea for a code change that developers are working through, they're implementing, and they're identifying different bugs for another one is valid withdrawals and consolidation requests. A couple of code changes in PETRA allow for smart contracts on the execution layer side. For example, major staking pools like Lido, Rocket Pool, other smart contract applications to directly be able to initiate validator consolidations and validator withdrawal requests. Currently on Ethereum, it's not possible for these smart contracts to trigger these kinds of requests. There does need to be manual intervention on the consensus layer side. And this kind of introducing this kind of feature, introducing this kind of flexibility definitely enhances the trustless properties of using staking pools that are built with smart contracts.
00:10:56.097 - 00:12:01.425, Speaker A: You're able to, via smart contract code initiate certain activities that you don't require human intervention for. So it will allow more trustless designs for staking pools. And it's an interesting couple of code changes to be able to enhance the functionality of staking pools. So again, it's a good idea. Developers agreed that it would be included into petra, but in the process of implementing this, they've noticed that there needs to be a way for the execution layer to pass along all of the withdrawal requests and the consolidation requests from the execution layer to the consensus layer in such a way that minimizes overhead so that the execution layer is not doing unnecessary work that the consensus layer perhaps is better equipped to do the serialization. The data serialization formats of the execution layer and the consensus layer are slightly different. These are two different code bases that were developed at different times.
00:12:01.425 - 00:12:54.897, Speaker A: So they have their own strengths and their own weaknesses. And so one of the discussions on the latest call was around how to communicate best communicate these kinds of requests from the execution layer to the consensus layer. And for this there was a new proposal that was shared by Felix Lange. I hope I'm saying his last name right, I probably am not. He's a geth developer and he shared a new solution for doing this. He explained that this will of course need some buy in from execution layer client teams and then he's going to bring it up on the next all core developer call. So another kind of example of of what is primarily talked about on these calls and how developers are slowly but surely working their way through the vast number of code changes that have been included into Petra.
00:12:54.897 - 00:13:41.285, Speaker A: So one last example on this point. EIP6110 this is a co change that developers have agreed to include into Petra as a bit of a fix up or a bit of a cleanup since the merge. So the merge was the upgrade on Ethereum that transitioned Ethereum to a proof of stake blockchain. Woohoo. You know the big milestone that a lot of people didn't think Ethereum would ever reach Ethereum did reach Ethereum is a proof of stake blockchain now. And what EAP6110 does is it reduces a bit of overhead between the way that the execution layer and the consensus layer function. Right now when you want to spin up a new validator, you have these deposits that you need.
00:13:41.285 - 00:14:35.183, Speaker A: You need to have a minimum of 32 eth. You deposit that into the deposit contract on the execution layer side and then there's a round of voting that happens on the consensus layer side to reaffirm or confirm that these deposits were made. And the validator is created on the consensus layer, is activated on the consensus layer of Ethereum. EIP 6110 simplifies things so that the the responsibility of tracking these deposits, of voting and verifying these deposits all happen on the execution layer. It removes the need for additional voting on the consensus layer side when it comes to validator deposits. And so in this process it'll make validator deposits. The waiting period that occurs from when you deposit your eth to when the validator goes live, it reduces the kind of wait period there.
00:14:35.183 - 00:15:54.525, Speaker A: So it's It's a bit of a user experience improvement for stakers as well. EIP6110 Again, a good cleanup code change, a good cleanup fix Developers talked about the need if EIP 6110 is going to be activated, there is now a need to have a deposit queue on the execution layer side. There was no kind of rate limiting feature or functionality, there is no rate limiting feature right now. But with Petra and with the activation VIP 6110 there is a need to ensure that the execution layer side doesn't suddenly get overloaded with too many deposit requests and prevent any type of front running attacks where deposits, new deposits that are created don't incorrectly move through. Basically that there's no front running attacks on withdrawals on people that are depositing their eth and withdrawing it in a very quick fashion. Any new deposit required can only happen after existing deposit requests are fully processed. So creating this also ensures that there's less bugs and less errors when it comes to the way that execution layer clients are caching and storing keeping track of all these deposit requests.
00:15:54.525 - 00:17:56.801, Speaker A: So the addition of a queue is something that of course wasn't talked about in the beginning of EIP 6110, but in the process of implementation and in the process of testing developers are noticing, ah, this is a feature that we're going to need if we want to be able to implement EIP 6110 effectively, we should get this going again. Developers were very enthusiastic about getting this deposit requests queue in the changes to EIP 6110 and the changes in the consensus layer specifications that need to happen to have this queue will be again finalized soon in the final stages of review before being merged into merged into the official consensus layer specifications. So those are a few examples of a few examples of what needs to happen of unexpected kind of tests and unexpected kind of edge cases that developers are coming across things that they need or are realizing would be nice to haves in order to implement Pectra in an effective and efficient and safe way. And that was really the bulk of the call. There was quite a few discussions around things like this, but related to other EIPs, other parts of the Ethereum code base that are going to be changing through Petra near to, I would say like the other half of the call or near to the end of the call, developers started to talk about development related to peer DAs. Peer DAs is the main code change that will improve Ethereum data availability, the scalability of Ethereum's data availability in other words, the ability for Ethereum to be able to support different rollups. The main kind of update around Peerdesk DevNet 2 was related to was related to the launch of the next Devnet.
00:17:56.801 - 00:18:53.255, Speaker A: I should say the main update around Peer Desk was related to the Devnets Peerdesk Devnet 2 has apparently not gone live yet. Developers are focused on testing out client implementations of PeerDesk locally. So in private testnets where it's just that one client, the client is not interacting with other types of consensus layer clients. It's TBD on when peer7.2 will be live. But one of the things that I kind of noticed on the call was that developers are in agreement that the next peer DAS Devnet should be rebased on top of the Pectra upgrade, as opposed to the Deneb upgrade. This was a conversation where developers were talking about how if the peer DAS upgrade is rebased on top of Pectra too early, it will be hard to isolate bugs that are from Pectra eips or from peer DAS code changes.
00:18:53.255 - 00:19:47.601, Speaker A: So up until now peerdes has been being worked on and tested in its own siloed way, where really the only kind of code changes that are being implemented on Ethereum. A test version of Ethereum, of course, is Peerdas. It's not interacting with any of the other Pectra EIPs. But I believe starting from Petra Devnet 2 we're going to see the merging and developers are going to try and see how the Pectra implementation fares alongside the Pectra EIPS. The two will still be tested on different DevNet, different test nets moving forward and of course at some point those two workflows are going to have to come together as well. But for now developers are going to keep the DevNet separate. So that was really the main update as it relates to peer DAS developments.
00:19:47.601 - 00:20:46.583, Speaker A: The last topic on the call that I really want to highlight on this episode is related to the discussion that developers had around peer DAS Proof Computation. So peer to ask will greatly increase the ability of Ethereum to be able to process blob transactions, process transactions with a large amount of arbitrary data attached to them. And this data of course is ideally going to be used by rollups that are compressing and batching user transactions from their own protocols down to Ethereum. And to be able to have to be able to utilize the decentralization of Ethereum, the security of the Ethereum network. Oops, sorry Plant. To be able to utilize the decentralization of Ethereum and its vast network of nodes, the security of Ethereum, all of that eth staked by validators. You'll be able to commit the data down to Ethereum.
00:20:46.583 - 00:22:02.159, Speaker A: And right now the costs to do that have decreased since the Deneb upgrade, since the introduction of blobs. But with peer das, there is the potential that developers will be able to greatly expand the scalability of Ethereum as a data availability layer. But to do this, there are certain changes that need to happen to Ethereum's networking layer and there is the activity of proof generations. Already these clients are generating proofs around blobs. But the proofs that will need to be generated and computed by consensus layer clients post peer das is going to be quite difficult for resource constrained devices to be able to handle. So one of the concerns that was raised on the call was that it could take up to one additional second for certain nodes, for certain validators to be able to operate, to be able to create blocks and produce blocks on Ethereum because of of the additional computational load from generating these proofs in peer DAs. I know one second doesn't sound like a lot for us, it doesn't.
00:22:02.159 - 00:23:15.691, Speaker A: But the number of blocks, Ethereum's block time is 12 seconds long and 1 second is a large chunk of time in that 12 second bracket. And the faster that you can be in building your blocks, the more competitive and profitable you can be as a validator. So one second matters. Honestly, it comes down to even milliseconds of time when it comes to the competitiveness of validators. So the concern is that people that are operating validators, not as a professional or business entity, people that are running their validators at home with pretty cheap hardware, pretty cheap devices that aren't super performant, you could start to see these kinds of actors on the network lose out and not be able to perform to the level as other more performant validators that are running on better hardware. And you could start to see them fail to produce blocks in enough time within that 12 second window, just not have enough time to be able to produce a block and earn block rewards. That's the concern that was raised.
00:23:15.691 - 00:25:07.065, Speaker A: And there were three different solutions that were talked about on the call. The first was to do absolutely nothing to kind of expect that these stakers that realize, oh man, I'm not able to compute the proofs for blobs, I'm going to have to create blocks without any kind of blob transactions or just kind of upgrade my hardware in order to stay competitive in the network, to be able to perform all the responsibilities that I need to perform. The first is to do nothing and to just expect that homestakers will either upgrade their hardware or not participate in the network to the same extent as other validators as other stakers. The second one was to try and utilize the execution layer client in some way to help with the proof computation. Right now all the proof computation is happening on the consensus layer through the consensus layer client, but for the execution layer client in some way to help pre prepare blob and in that way make the proof of computation a bit lighter and not too heavy on resource constrained devices. And the third potential option was to adjust the consensus layer client so that the proof generation and the preparation for blobs for which the consensus layer clients will be generating proofs for so that the that kind of activity can happen in advance and that kind of activity to some extent can be done in parallel by the consensus layer client as they're building out the full block to somehow start computing the proofs earlier. So there were three different solutions and developers talked about all three quite a bit.
00:25:07.065 - 00:25:42.025, Speaker A: Ultimately, developers landed on moving forward with the third option. The first option of course would mean that that at home stakers really take a hit. And already there's not a lot of at home stakers on Ethereum today. So to be able to lose more validators that are being run independently by individuals rather than businesses is not something that developers want to sacrifice. They want to ensure that Ethereum is maximally decentralized. So that was a no go for the first. The second one related to utilizing the execution layer.
00:25:42.025 - 00:27:11.581, Speaker A: Developers reiterated that anytime they want to make a change to the data availability capacity of Ethereum, it would be nice if they didn't have to upgrade both the execution layer and the consensus layer. The kind of isolation in this kind of responsibility is ideal to keep on the consensus layer, to make future changes to data availability for Ethereum a lot more easier to manage and to be able to activate independently from the execution layer. So you could imagine a future where there's just a consensus layer upgrade and that is enough to enhance Ethereum's data availability capabilities. So developers ultimately said let's go with the third option. And they also mentioned the longer term vision, which is that while it's clear that even with the third option there is going to be an increase in the computational requirements for operating an Ethereum node, when Ethereum first launched, the benchmark for low grade hardware was Raspberry PIs. I don't know if listeners who are on the show know what a Raspberry PI is, but it's this extremely, extremely small, small computer that fits in the size of your hand. And it was largely cited by developers that, oh, you know, you can run a consensus layer client, you can run an Ethereum node and be a validator on Ethereum by operating on a Raspberry PI.
00:27:11.581 - 00:27:47.915, Speaker A: That is no longer feasible really today because the computational requirements have gone up. There's far more messages being passed around on the networking layer of Ethereum. There's more than 1 million validators now on Ethereum. So you're going to need a little bit more performant hardware than a Raspberry PI to be a validator. But that's also okay because over time the cost of hardware goes down. This is what many people cite as Moore's Law and also why one of the main thesis or rationales for why validators on Solana are so performant. The idea is that hardware costs decline over time.
00:27:47.915 - 00:29:06.285, Speaker A: So nowadays you can get a lot more performant hardware for about the same cost that you were spending to operate your Raspberry PI or buy the Raspberry PI. And the idea is that one of the ideas that developers were talking about above and beyond just the third option, which is that which should help of course, lower the computational resources required to generate these proofs. One of the things that the Ethereum foundation researcher Dankrad Fais was talking about was to eventually be able to create decentralized block builders, decentralize the activity of block building on Ethereum such that validators that are being operated on very low grade hardware, they don't even need to generate a. They can rely on more performant nodes, super nodes as he calls them, to generate those proofs. And they can take the proofs from the blobs, package it into the block and be able to avoid having to do those computations at all. But this will require a lot more research and this requires a lot more experimentation and testing and thinking. Which is why developers, in the meantime, in preparation for at least the Pectra upgrade, are going to continue to hammer out this third option.
00:29:06.285 - 00:30:37.999, Speaker A: One of the things that I wanted to talk about a little bit more related to this conversation is around the future viability of home stakers on Ethereum. It's clear that Ethereum upgrades a lot and the requirements, the minimum requirements for operating an Ethereum validator are changing, are in flux. Will get more computationally intensive to be able to operate an Ethereum validator, and hopefully it does so as the costs of hardware go down so that it continues to be very accessible for anyone to be able to run a validator. But there's also this idea that as Ethereum tries to scale and as Ethereum tries to evolve into being a performant data availability layer, that perhaps the amount of conviction that developers have about making sure that home stakers are the top priority, that that kind of conviction may change. I mean the very first option that was shared on the call related to this issue, this open question around proof computation, was to do simply nothing at all. Of course developers didn't choose that option, but it was an option. And I think over you're going to start to see the viability of home stakers continue to be not very viable.
00:30:37.999 - 00:31:27.591, Speaker A: Even today with liquid staking solutions, home stakers are missing out on a lot. You are locking up your 32 ETH. You don't get to have a liquid token representation for it, which many other stakers do. You are operating your own machinery, which requires quite a bit of technical skills, not only because Ethereum upgrades so much, but there's so many pieces of software that you have to be running the execution layer client, the condensed layer client, the engine API. There's a variety of clients to choose from, all of which have their own strengths and benefits and different requirements when it comes to being able to operate them proficiently. And you don't get the benefit of scaling, of being able to run multiple validators on one machine. You don't have the economies of scale.
00:31:27.591 - 00:32:29.781, Speaker A: The one thing that at home Stinkers do have in terms of as a positive is the fact that they are they can trust in their own machines. They're not trusting in a third party entity to be able to run their own hardware or software. But in the future many people are likely to choose the easier route, the cheaper route and the route that requires less headache, the less, I guess intervention. So in the future I think we're going to see less and less home stakers, especially as Ethereum continues to prioritize scaling and prioritize bulking up the capacity of Ethereum to be able to process more blob transactions. This is something that I will be talking about with two guests that my listeners of the show are very familiar with already. You can expect tomorrow's Infinite Jungle episode. It's going to be featuring Nixo and Yorek again.
00:32:29.781 - 00:34:07.383, Speaker A: We're going to be talking about this very topic as well. But as a little bit of a precursor, I did want to impress and did want to highlight one of the big concerns or one of the big questions that everybody should be asking related to the inclusion of peer, Das and Petra is how peer impacts the viability of home staking and the future of what home staking should look like. It's clear that there will be a role for super nodes, nodes that light nodes or weaker nodes can rely on for proofs and rely on for, say, the full history of Ethereum or the full state. But what really is the profitability and the financial incentive for users to continue to run smaller nodes, to continue to run nodes at home, rather than just relying on a large staking pool or a large business? You could imagine a world where the public good, the idea that I'm helping with the decentralization of Ethereum, I'm contributing to the censorship resistance of Ethereum. That kind of rationale and that kind of motivation is not enough to really sustain a sizable number of solostakers on Ethereum. You could imagine a future where that comes to be the case. Kind of like in the early days of the Internet, everyone thought, oh, we're all going to run our own servers and have our own hardware, but really, at the end of the day, we all rely on a handful of major service providers.
00:34:07.383 - 00:34:41.674, Speaker A: So food for thought to chew on. Thank you everyone very much for tuning in again to the Infinite Jungle again. It feels great to be back. I hope that you learned something new about Ethereum, and if you did, please consider also sharing the episode with a friend who may also want to join you in your journey of learning a little bit more about Ethereum each week. Until next time, fellow Ethereum Ethereum explorers, Stay safe out there in your explorations of the Infinite jungle that is Ethereum.

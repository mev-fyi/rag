00:00:10.440 - 00:01:09.595, Speaker A: Welcome back to the Infinite Jungle. On today's episode I have with me co founder and CEO of Monad Labs, Keone Han. We are going to be talking about the technology behind Monad and its timeline for mainnet. As a quick note for a conversation, Monad Galaxy is an investor in Monad Labs. We also, as per usual, have a quick show disclaimer to share. Before we get started with our conversation, I need to remind you to please refer to the disclaimer linked in the podcast Show Notes and note that none of the information in this podcast constitutes investment advice, an offer recommendation or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities. So Keoni, there are many different approaches to to scaling layer 1 blockchains, and with Ethereum being the very first general purpose blockchain, there's been many competitors when it comes to what could be improved.
00:01:09.595 - 00:01:25.871, Speaker A: Tell me from kind of the groundwork, why are optimizations to the EVM really the differentiating quality that you wanted to have when you were launching and thinking about starting Monad, this alternative Layer one?
00:01:25.983 - 00:02:01.715, Speaker B: Absolutely. EVM is a really powerful standard. It's the common, really the prevalent standard in web 3. Over 95% of all capital on chain all TVL is in EVM apps. And there's this really powerful network effect of builders that are building for the evm, existing libraries, existing applications. Almost all of the applied cryptography research is being done in the context of the evm. So it's really important to push the standard forward and make it more powerful and more performant.
00:02:01.715 - 00:02:18.251, Speaker B: And that's really the entire mission of Monad is to build a much more performant pipeline for EVM execution in the form of a completely new layer 1 blockchain with optimizations across the but there's.
00:02:18.323 - 00:03:09.857, Speaker A: So many bottlenecks and difficulties when it comes to the evm. It was the first of its kind when it launched in 2015. So one of the difficulties that I've heard about the EVM is that it has a very limited stack access to memory and some of the other difficulties around the EVM that I've been hearing on the ACD calls quite a bit around the conversation with EOF is all of these difficulties related to how the EVM organizes data and code and understands these. So it's not just about the performance, I guess, of the VM that apparently needs quite a few optimizations and changes. How is Monad approaching these issues and thinking about how it might not just be the scalability of the EVM that's really the issue here, the way that.
00:03:09.881 - 00:04:33.945, Speaker B: I think of Ethereum or Ethereum compatible blockchains is they're enabling shared global state, where we have hundreds, thousands, tens of thousands of nodes fully globally distributed that all are completely in sync with each other and are keeping all of the same account balances and all of the same smart contract states. So that you could, a developer could build an application, upload it to one node, it gets propagated to all the other nodes, and then anyone can interact with that application, for example, depositing or borrowing from aave. And when they make an action, then it gets reflected on all these nodes globally. So that really means we need, we just need support for this full replication aspect, which is what consensus does. And then within each node we need perform an execution of transactions which generally involves reading state from disk because every smart contract has residual state that's associated with that smart contract. For example. And to continue the example of aave, there would be, you know, all of the balances of all of the depositors into aave, like a map from each depositor to each balance that's been deposited per token.
00:04:33.945 - 00:05:31.925, Speaker B: And so there's like a whole lot of data. All that state is just, it needs to exist in every single node and it needs to be very accessible. So at the end of the day, the problem of optimizing the EVM is really, it boils down to a couple of sub problems. One is making state really making state access really efficient while still preserving the same sort of storage pattern, like the way that the storage is organized. So specifically in the evm, storage is organized according to slots. The slots are just literally numerically numbered. So the first variable in a smart contract gets assigned to slot zero, the second one gets assigned to slot one, and so on, with some minor tweaks to that description related to packing multiple variables in the same slot if they're small enough, or some things related to how dictionaries and lists and so on are stored.
00:05:31.925 - 00:06:29.551, Speaker B: But at the end of the day, that's just the storage pattern. And it's really important to just build new architecture that builds around that and optimizes around that. And so some of the specific things that our team is working on are a custom database for storing all of that Ethereum style state most efficiently, specifically to be compatible with the fact that all of the state needs to live inside of a merkle tree, needs to generate a merkle root that is a commitment to all of that state, and allows other systems that interface with the blockchain to safely interact with the blockchain relying on that Merkle route. There's other optimizations as well that I can get into. But the point is that at the end of the day, the EVM spec is what it is and it is quite powerful. I don't think there's anything fundamentally wrong with it and we're just building around that and making it more efficient.
00:06:29.703 - 00:07:11.071, Speaker A: And in your research, deep diving into the EVM and working around it, you haven't thought that, oh, this vm. There's changes about this VM that would, if developers had really thought about it and kind of had the hindsight is 20 20. There are different kinds of VM out there that have kind of said that they're better than the evm. What are your thoughts? I mean, have you thought really about certain improvements to the EVM that might mean that you lose compatibility with certain tools that exist with the EVM now, but actually make the EVM from a UX standpoint, from smart contract developing standpoint, a lot better to use?
00:07:11.263 - 00:08:12.171, Speaker B: That's a good question again. So I have two answers to that. One is the high level answer and one is the lower level one. On a high level. It's a question that doesn't, I guess to some extent doesn't even cross our mind because at the end of the day there's so much mindshare around the EVM that it's extremely important and worthwhile just to make it better and to embrace and extend, maybe add new features, but still be backward compatible. So that's the high level, dumb strategic response to the question. I think at a lower level, yeah, maybe if we could go back in time to the genesis of Ethereum, maybe it would have made sense to use a different bytecode standard that is more standardized and that has more front end languages that can compile down to it.
00:08:12.171 - 00:09:29.437, Speaker B: So just to double click on that a tiny bit, the way that, you know, compilers, the way the programming languages work is generally that there is a high level language, AKA a front end language like Rust or C or yeah, some other language like that, and then the compiler converts that generally into an intermediate representation and then converts it into machine code and then the machine code is what the CPU actually interacts with. Whereas in EVM what happens is your high level language is a new language called Solidity. And I guess originally there wasn't even Solidity. So people were literally just writing like raw individual instructions. And then at some point someone came up with a front end language for EVM called Solidity and then built the when you build a language, you build a compiler for it, but it wasn't using the standard tool chains, wasn't using llvm. Anyway, the point is like, in hindsight, perhaps it would have made sense to have like shoehorned everything into more of the common standard, but at the same time, the common standard was evolving at that time. And then also at the end of the day, the EVM also has to be sandboxed.
00:09:29.437 - 00:10:06.719, Speaker B: So, you know, we need to be basically, when executing EVM code, we need to be keeping track of gas expenditures the whole time. It has to be sandboxed. Like the bytecode can't be allowed to like go and read files off your machine or send, you know, messages across the Internet or things like that. So at the end of the day it is a sandbox. And in any sandbox environment, you're going to restrict the overall set of things that can be done. So there's always going to be some amount of restrictions. And I think at the end of the day, the bytecode is actually a totally reasonable standard.
00:10:06.907 - 00:11:09.727, Speaker A: Now, I imagine that with Ethereum pivoting to this role of centric roadmap and the explosion of different L2s, there's going to be a ton more innovation on the execution layer side with different kinds of VMs that could be compatible in terms of the proofs are sent to Ethereum. But developers have all this variety when it comes to the programming languages they can use, the different VMs they could use. There's been some projects around the SVM coming over to ethereum as an L2, things like that. So I do want to talk a little bit about how you see Monad competing with all the different L2s. But one thing I wanted to also talk about a little bit before we get into that is what you were talking about with Merkle trees. So you know that Ethereum is going to switch over to Virkal to a different tree tri state. And as I had mentioned, there are going to be some major overhauls to the way that the structure of the.
00:11:09.727 - 00:11:44.699, Speaker A: Or how the evm, I guess, operates with EOF coming up in the Fusaka upgrade. So Ethereum is going to make updates to the EVM to the way that state is stored. Are you concerned at all that all these changes to Ethereum will kind of have to make your work? Like building around the evm, you're building around a code base that's constantly changing and going to change in major ways? Is that, does that represent a bit of resource cost in terms of what you guys are thinking about?
00:11:44.787 - 00:13:03.585, Speaker B: Yeah, we're super excited about the continued evolution of the evm. No issues there at all, I think in terms of the changes that are coming in EOF or just the gradual changes, introduction, new opcodes, introduction of new pre compiles, that's not a major issue to Monad. And I think one particular way to think about Monad, in contrast to for example ZKEVMs, is that with ZKEVMs, like a new opcode gets introduced that might be really hard to actually replicate with a circuit. But with Monad, because everything is being done in more like normal space rather than ZK space, it's not nearly as big of a lift. So just want to kind of explain that a little bit because sometimes people are wondering about the compatibility and how hard is it to be fully compatible and that's actually not the most challenging part of the overall effort. I should also back up a little bit just for one second and try to explain the major different innovations in Monad, because I think that might be helpful to answering your broader question. So just really quickly, four major improvements and more generally just general optimization.
00:13:03.585 - 00:14:02.227, Speaker B: From the perspective of building low level, high performance systems. The four major optimizations are number one, monadDB, which is this custom state database. Number two, optimistic parallel execution, which allows many transactions to be executed in parallel but then committed in the original order of the transactions while checking for conflicts. The third optimization is asynchronous execution, which is decoupling consensus and execution from each other, massively raising the budget for execution in the process. And then lastly, number four, Monad bft, which is a high performance BFT consensus mechanism that allows hundreds to thousands of nodes to be fully in sync with each other while being fully geographically distributed. So those are all different improvements at different layers of the stack. And I think our broader view is that these improvements need to be proven out.
00:14:02.227 - 00:15:13.985, Speaker B: They need to be done in a production environment where there's actual stuff at stake and many users that are actually using the network for real applications. And that will help ultimately guide the roadmap of other blockchains as well as Monad Labs. We want to be contributors to the Ethereum research community and to contribute these improvements back to Ethereum. So that's sort of the broad mission statement and what we're doing and why we're doing it. To your point specifically about some of the research directions in Ethereum, specifically verkle trees, I think that it takes a long time to research any possible improvements. And yeah, the only way in engineering to Prove what is the best approach is to build out the alternatives and actually see them in production and see the impact that they have. I think that while there's a direction of Ethereum research is going down.
00:15:13.985 - 00:16:27.183, Speaker B: Okay, if we move to vertical trees and what will that give us? Like that gives us potentially like stateless clients where those nodes don't have any state at all and then they just receive like really big blocks that have updates to various pieces of state along with the Verkal proofs. That's like one vision of how to improve Ethereum that has an effect on the overall throughput. But I'm not even sure that that many other. Like, even if Ethereum adopts it, I'm not sure that a whole lot of other rollups are going to adopt Verkal proofs as well. Like, it's just not that clear to me. And more generally, we think that the approach that our team is pioneering in monaddb making the state much more efficient to access and thus enabling State to grow to a much bigger extent without affecting the performance as much of lookups, that that's actually an alternative proposal that might actually be better for Ethereum, but the only way to do it is to build it out, improve it and then submit it as a suggestion for how to go about scaling Ethereum.
00:16:27.279 - 00:17:10.484, Speaker A: That's fascinating because I do agree that right now there is quite a few questions of whether or not worker really is the way to achieve statelessness. And just to confirm what you were saying earlier about Monad's those four points of how Monad is differentiating compared to say like ZKEVMs, ZKEVMs in order to maintain compatibility and continue to operate, they do need to upgrade every single time Ethereum has an upgrade that changes the evm. And for Monad, just to confirm when Ethereum upgrades say like 2 virkal or 2 eof, it doesn't necessarily mean that Monad also needs to upgrade at the same time or it does.
00:17:10.564 - 00:17:50.495, Speaker B: Oh yeah, I think that. Well, I have two comments. So one is that in terms of compatibility, our team very much intends to follow Ethereum compatibility because that's really important to developers at the end of the day. So introduction of tload or T Store or introduction of EOF or like these different things that are changing, our team will continue to follow Ethereum's direction and make those improvements as well. There's no doubt about that. That's really important for supporting developers. But then the second point was around comparing.
00:17:50.495 - 00:18:37.067, Speaker B: I guess this is coming from the specific question that People often give me of is Monad really fully EVM compatible? Because I heard that that's really hard to be EVM compatible. And the reason why I think a lot of people think that it's hard to be EVM compatible is because a lot of the ZKEVMs have trouble being fully EVM compatible because certain opcodes are really hard to emulate in circuits, right? You know, like there's this sort of a parallel world going on that. But that's not true in Monad. Like in Monad, the, you know, there's a big case switch statement in in the code base which is like if I have this opcode, then I do. If I have the add opcode, I do this. If I have the multiply opcode, I do this. If I have the jump opcode, I do this.
00:18:37.067 - 00:18:42.163, Speaker B: That's still a very simple. It's also a case switch statement in our code base.
00:18:42.339 - 00:20:39.945, Speaker A: So on the topic of ZKs, because we had Stephen Lee from the Risk Zero team on the Infinite Jungle on a prior episode, his team is not building a zkevm, but rather there's a Risk zero ZK vm. One of the notes that he had said was that even with all of the scales scaling optimizations of what Monad is doing, even with all of these improvements to the L1, four major applications that will require not just like a couple hundred gas, but millions upon millions of gas in terms of computational transactions even it'll still be expensive to run those applications on monad. I say specifically Monad, but he was saying just generally it'll still be expensive on these blockchains on these L2s, even to run these applications run decentralized applications such as DEPin applications, applications that require a lot of computational effort, and that in these cases actually having those computations happen off chain computed with a ZKVM is what application developers will eventually shift to. So I'm curious to know your thoughts on how other scaling solutions like ZKVM you think will actually be used in conjunction with the scaling improvements on Monad. Do you think that the scaling improvements on Monad are enough to support all types of decentralized applications, or do you foresee users and applications actually relying on additional scaling enhancements once the monad improvements, those four are maxed out? Like, do you foresee further ones needed to really scale blockchains for consumer I don't know for like the global million billions of users out there?
00:20:40.245 - 00:21:23.756, Speaker B: Yeah, I think I have two answers to that question as well. So the first one Is just to give some context, Ethereum is supporting about a million transactions per day. Where when I say transaction I mean something that costs about 100,000 gas. A Uniswap V2 swap for example, costs about 100,000 gas. So a million of those per day and that's with a gas limit of 1.25 million gas per second. Now right now, other roll ups are somewhere in the or maybe like almost 5 to 10x Ethereum right now.
00:21:23.756 - 00:22:12.091, Speaker B: So they're supporting about 5 to 10 million transactions per day. That's for a given roll up. When we look at it, for example, base, I think base is probably the most active right Now. It's about 100 TPS, 10 million transactions per day. With Monad, these different improvements, the four improvements that I mentioned stacked together get Monad to a billion transactions per day or 10,000 tps. It's like 1000x the current throughput of Ethereum or right now 100x the throughput of base. So there's a significant improvement that this technology is bringing and that supports new applications that cannot exist right now.
00:22:12.091 - 00:22:55.984, Speaker B: For example, an app that has a million DAUs 10 transactions per user per day, that's not crazy, would be 10 million transactions. And that one Apple loan would saturate base right now. And that one Apple loan would be 10x throughput of Ethereum right now. So these are significant improvements that we think will materially change just the calculus for developers when they're thinking about the kind of scale of app that they're building or the kind of scale of frequent commitments back to the blockchain that is within the application. So that's just my first high level comment to what you were mentioning about this comment about like is scaling the L1 enough? Yes.
00:22:56.053 - 00:22:57.363, Speaker A: Is scaling the L1?
00:22:57.432 - 00:23:42.825, Speaker B: Is scaling the L1 enough? I mean it's a big improvement. So with further improvements expected down the line as further technologies land. So I think it is significant. But I guess my second comment about the question is that I think that there are multiple pillars to the Ethereum scaling approach or there should be multiple pillars. And certainly fractal scaling through roll ups is definitely a very important one. I just think that fundamental architectural improvements to the L1 are a completely orthogonal pillar that is also really helpful. I think that it's cool to see the growth of projects like Succinct.
00:23:42.825 - 00:24:16.119, Speaker B: So basically allowing arbitrary ZK proving of arbitrary rust code. I think that's very cool. That's one of the puzzle pieces. And so I just imagine have a really performant L1 that can process a lot of execution. And then this performant link between the L1 and rollups enabled through some sort of proving system. And then performant individual, like partitioned L2S is. That's like.
00:24:16.119 - 00:24:19.743, Speaker B: Clearly those are all important pieces of that overall story.
00:24:19.879 - 00:24:33.435, Speaker A: Yeah. So many different building blocks, I could say and I guess different approaches to scaling then, many of which might converge and be able to be used in tandem. But very early stages for. I would say all of them.
00:24:33.515 - 00:25:02.785, Speaker B: Yeah. And I would say that rather than. Well, they'll converge in the sense that they will all be useful together. Sometimes when people say converge they mean they'll all end up doing the same thing. And I'm pretty sure that won't be the case. They'll be specialized in terms of the technologies we're building or specialized for delivering performance, state access or performant consensus. Asynchronous execution is another thing I feel very strongly about.
00:25:02.785 - 00:25:34.725, Speaker B: So just to preview that really Fast, Ethereum has 12 second blocks. The rough time budget for execution is about 100 milliseconds per block. So that's 1% of the block time. And that's like a significant dilation factor. That is coming from the fact that consensus and execution are interleaved. In Ethereum and in most blockchains, consensus takes up most of the time. That makes sense because across the world communication is slow.
00:25:34.725 - 00:26:30.503, Speaker B: But it really constrains the overall throughput of the system because now we're only allowed to use a very small. Or in Ethereum, we're only allowed to use a small percentage of the full block time to execute. Asynchronous execution changes that. Asynchronous execution is like taking the limitless pill that in the movie takes you from using 10% of your brain to 100% of your brain. It is the idea of moving execution out of that hot path of consensus into a separate swim lane, slightly lagging consensus that allows the full block time to be used for execution. I think that's a very big unlock, actually. In the Ethereum research community we've seen this idea which we proposed a year and a half ago or so, starting to get a little bit more traction, which is quite cool to see when.
00:26:30.519 - 00:27:21.065, Speaker A: It comes to these ideas like asynchronous execution and some of the other ones. When you were mentioning those four pillars. Monad is not the only one working on this orthogonal pillar of parallelizable EVM execution and these various EVM optimizations. We've seen a rise of many competitors like Mega Eth Sei Neon, could you talk about some of these ideas in relation to how Monad is differentiated from these other approaches? Because some of these approaches are very similar. Everybody's researching the same ways in which to try and get better throughput, more scale. As you start to look into perhaps the code bases of these other competitors, how do you see Monad continuing to outperform?
00:27:22.245 - 00:28:28.589, Speaker B: Yeah, well, first of all, the most important thing is the ultimate effect, like the ultimate technology, the ultimate result of doing this research and then seeing it propagate. So that, yeah, I think that's the most important thing. Our team will soon share our code base and share findings and we think that that will, you know, we hope to see that ultimately propagate into Ethereum and into the Ethereum ecosystem. To talk specifically about what parallel execution is and how it works, I want to kind of explain high level and then also because I think that will inform, you know, some of the aspects that are differentiated. So Monad does optimistic parallel execution. The way to think about it is many transactions are run in parallel optimistically. And by the way, this is totally different from like the optimistic part of optimistic roll ups.
00:28:28.589 - 00:29:27.229, Speaker B: Sometimes people get confused about that and I have to differentiate. So optimistic parallel execution, it's optimistic in the sense that it means many transactions are starting from the same starting point. So they're all just assuming that the current state of the world is the state of the world that will persist when the transaction's actual turn is. So that's the first step is run many transactions in parallel and generate a bunch of pending results, which each pending result includes sort of like some note taking to keep track of which inputs were read in in the course of that execution and which outputs were mutated in the course of that execution. And that's done at a slot by slot level. So an input is account slot tuple and an output is account slot value tuple. So basically like for each transaction that we ran in parallel, what was read in, what was mutated and then that's like sort of stored as a pending result.
00:29:27.229 - 00:30:39.303, Speaker B: So that's step one and then step two is just stepping through those pending results in the original order of the transactions and making sure the inputs are still valid, that none of the inputs have since been mutated by a previous transaction that was run in parallel that mutated one of whose outputs is now one of this transaction's inputs, stepping through those and then just committing them in the original order of the transactions. And if there's any transaction, if there's any pending Result whose input has been mutated, then that transaction needs to be re executed. So that's just the simple description of what optimistic parallel execution is. Now, I guess I want to point out one or two things. So the first thing is that optimistic parallel execution allows multiple cores on the CPU to be used at the same time and more generally like multithreading. So that can start doing work on a lot of things in parallel. But at the end of the day, the biggest bottleneck for execution is state access because it's the S load and S store opcodes that invoke going back to the SSD and reading some piece of data off of disk.
00:30:39.303 - 00:31:42.415, Speaker B: So at the end of the day, the nice thing about parallel execution is that it's surfacing a bunch of state dependencies in parallel, like identifying, okay, I need this piece of data. This other transaction saying like, I need this piece of data. The third transaction is saying I need this piece of data and surfacing all those in parallel. But then at the end of the day, you also need an underlying database, like an underlying store of that data that can respond to those parallel requests very efficiently. So that's where the monadb, which is this custom database, comes in, because it's a lot more efficient at responding to those parallel requests through the fact that the data is stored natively on disk. The Merkle tree structure is stored natively on disk as opposed to in another database that creates a lot of indirection. There's also Support for asynchronous IO in MonoDB, which TLDR means you can initiate many requests to many pieces of state on disk in parallel, and they can be responded to very quickly.
00:31:42.415 - 00:31:53.335, Speaker B: Anyway, the point is like parallel execution on its own is not the silver bullet. It's the combination of doing the execution in parallel, but then having this perform a database.
00:31:53.955 - 00:32:49.915, Speaker A: I mean, okay, I do, I hear you that the tech is really what will be the differentiator. And making sure that in comparison to these other protocols that are marketed as these very high throughput EVM chains, you know, having these innovations, these tech innovations will be very critical. Another kind of critical part of this I think will be definitely timeline and speed. I think the first market having those network effects, being able to bring in users is also a huge part of it. In the last couple minutes of the show, I wanted to talk a little bit about the timeline for Monad too. I know how Monad is very close to being able to go live on mainnet. I was hearing conversation about sometime next year.
00:32:49.915 - 00:33:08.635, Speaker A: Any kind of specific development milestones that you're looking ahead to between now and the end of the year. What are your thoughts so far on seeing this vision for Monad? Go live with and illustrate with the tech. All of this tech going live.
00:33:08.755 - 00:33:55.439, Speaker B: Yeah, we're super excited about launching the mainnet early next year. At the end of the day, that's just really important to unblocking a lot of developers and allowing, as I said, all these improvements. These technology improvements need to be demonstrated in real life with something real at stake. And the only way to do that is just to get it out and to be supporting many developers that are building for the evm. In terms of the current work that's being done, I just want to emphasize that there's a lot of new things, like the client is completely built from scratch. It's not a fork of any existing code base. It's like a completely new database.
00:33:55.439 - 00:34:25.139, Speaker B: It's built from scratch. It's a completely new VM implementation, It's completely new consensus mechanisms. So our team is trying to be very, very sure that we're just doing a ton of load testing and a ton of, yeah, just honestly robustness testing to ensure that the system is live all the time. There's no liveness halts. That's basically the current work being done right now.
00:34:25.227 - 00:35:32.555, Speaker A: Gotcha. And when you're looking ahead to this pretty major milestone that's going to be had, there's quite a few other protocols and projects that look ahead to a mainnet launch. And once the mainnet goes live, as you can tell from, say, activity and engagement, a lot of engagement kind of plummets off a cliff. Because that is really the reason why many users were participating, say on testnets or really for that mainnet launch. And when the token for that protocol, let's say, really goes live, how is your team thinking about. About user retention post mainnet launch? How are your team thinking about community engagement post that kind of pivotal milestone? Because it is a known kind of issue in the crypto industry of how do we keep that flywheel of incentives going so that users stay engaged and stay active on a particular project.
00:35:32.715 - 00:36:28.585, Speaker B: Right. Yeah. I think it's about building real technology that is actually novel and useful and solves useful problems. I totally hear where you're coming from in terms of the history of some recent launches. And I think at the end of the day, that just implies that the technology that was being brought in that new mainnet was maybe not actually that different or that useful. Monad's a technology project at the End of the day, we're bringing these completely new architectural improvements to life and enabling a scale that has not been seen before at all. And then especially not been seen before in the evm that enables, we think, completely new applications and that ultimately delivers more value to the world.
00:36:28.585 - 00:37:23.535, Speaker B: But yeah, at the end of the day, the apps have to be self sustaining. Like the apps actually have to deliver real value to normal everyday users, not just for pure speculation. And it takes time for any app to achieve that. So mainnet is just the start of the journey at the end of the day. But I think also, you know, if projects are really leaning into incentivization ahead of mainnet and sort of trying to motivate people to utilize the environment purely for speculative reasons, then as you said, after that reason goes away, then the activity will drop. So from my perspective, it means not doing that, not creating artificial incentives that will then disappear.
00:37:24.555 - 00:38:34.315, Speaker A: Yeah, I think the app layer of Monad will be a really key indicator and like you said, reason for real user activity and user retention. And that's where one of the things I'm definitely going to be watching out for, especially in the few months after Monad launches, the kinds of apps that are being developed and launching there. I realized in our conversation we didn't actually get to the conversation around Alt L1s versus L2s really, but we're going to have to have you back to really dive into that topic. But one last question on that, because just in case one of the reasons that had been quoted for why Monad is an alternative L1 rather than L2 is because there currently exists a lack of a robust way to decentralize L2s, decentralize the sequencer. And I gotta agree with you, I gotta agree with your team that it is very difficult. There isn't really like a clear roadmap to decentralizing L2s, I don't really see a huge incentive for decentralization of sequencers. Yada yada.
00:38:34.315 - 00:39:09.075, Speaker A: What is the roadmap for the decentralization of Monad? I'm curious to know, kind of to the extent that that is a very big priority for the Monad team. When you look at kind of the difficulties even Ethereum is having when it comes to its solar staking community and the decentralization of Ethereum, the censorship resistance of Ethereum. How is Monad thinking about the roadmap for decentralization and progressively, you know, fending off forces of centralization? Because with decentralized technologies this is a major problem.
00:39:09.735 - 00:40:00.659, Speaker B: Yeah, I mean Technology enables decentralization. Like the whole premise of crypto is that new technology that was brought into place in 2009 or in 2015, or I guess if you even rewind before that, like some of the early, like pre Bitcoin ideas like those enabled a level of decentralization that did not exist before. So I really think that the North Star is decentralization and the technology. The whole point of why we're building technology is to enable higher and higher degrees of decentralization. So yeah, I think that's core to our mission. To be more specific about, I guess because you're asking, does it matter to us? Yes, it does. It's the core.
00:40:00.659 - 00:41:11.265, Speaker B: But then in practice, what does that look like? It's hundreds of nodes participating in consensus on day one of monad mainnet with full geographic decentralization. None of this business of all the nodes being in the same geography, which I see a lot as a way of putting a finger on the scale, fully geographically decentralized, hundreds of nodes participating in consensus, support for full nodes, so that anyone can run a node cheaply and have full access to the full state. Oh, and one other thing I forgot to mention is decentralization also means commodity hardware. Like, it should be cheap to run a node. It should not be thousands of dollars a year, thousands of dollars a year to run a node, because then it has an impact on who could actually run a node. Like, for me, it's important that, for example, one use case of crypto is enabling payments and having decentralized money where anyone can accept payments in crypto. So if you're a small business owner, you want to be able to accept crypto payments.
00:41:11.265 - 00:41:41.071, Speaker B: You should be able to run a full node so that when someone walks into your store and wants to pay you, you can actually see that payment go through on your node and verify that it did indeed go through before you let the person walk out the door with a packet of Skittles or a Tesla or whatever kind of store you have. So it's very important. Anyone should be able to run a node, full node, cheaply. Like, if it costs tens of thousands of dollars a year to run that node, then the shop owner is obviously not going to do it.
00:41:41.143 - 00:41:45.275, Speaker A: And just to confirm with monad, you can run a monad node on your phone.
00:41:46.155 - 00:41:50.435, Speaker B: Probably not on your phone, but certainly on a Costco MacBook. That's our target.
00:41:50.555 - 00:42:11.095, Speaker A: It is good to hear that there's going to be geographical decentralization when it comes to monad nodes, but I can imagine that that's all under the purview of Monad Labs. It'll all be in a different country, run by as organized by a central authority.
00:42:12.075 - 00:42:24.201, Speaker B: No, that's the. But it's a permissionless network, so anyone can acquire stake and then run nodes based on that stake, or, excuse me, participating consensus based on that stake.
00:42:24.313 - 00:42:43.563, Speaker A: Got you. So based on kind of the geographical diversity of say the test nets or the permissionless, kind of the ways in which you've seen participation in these prior test beds, kind of projecting, in terms of the participation on mainnet, you're foreseeing like a geographical diversity of.
00:42:43.619 - 00:43:04.855, Speaker B: Oh, I guess what I was trying to say is that the technology makes it possible to actually do that because there's a lot of blockchains where the technology literally does not enable high performance while being geographically decentralized. Right. So if the technology doesn't enable that, then there's a constraint that all the nodes need to be in Europe.
00:43:05.275 - 00:43:05.755, Speaker A: Right.
00:43:05.835 - 00:43:55.535, Speaker B: And we might not as everyday people be that aware of that. But that's what's going on behind the scenes. If you try to run a node outside of that region, then it'll fall out of consensus because the software can't keep up. That goes back to my point about why technology enables decentralization. If the technology is not sufficiently powerful, then in practice the system converges on something very centralized because it falls over if it is run with parameters that correspond to decentralization. At the end of the day, Monad is a technology project to enable a high performance network that is decentralized. And that means the geographic decentralization.
00:43:55.535 - 00:44:33.351, Speaker B: That means reasonable hardware requirements, like as I mentioned, Costco MacBook, like 32 gigs of RAM, 2 terabyte SSD, 100 megabits up down bandwidth, reasonable hardware requirements. I think if, you know, if we don't have those, if the requirements were much higher, then it would be a lot easier to get high performance. But the point is to get high performance while also complying with these constraints that we're imposing on that we want to see in the network so that, so that actual decentralization is enabled.
00:44:33.383 - 00:45:00.345, Speaker A: Thank you to all of our listeners who were tuning in and listening to this episode of the Infinite Jungle. We hope that you learned something new about Ethereum, especially the EVM and the way that it works. We hope that you'll join in again for another episode of the Infinite Jungle. Keone and I are signing off from the concrete jungle that is New York City in your explorations of the Infinite Jungle that is Ethereum Stay safe out there.

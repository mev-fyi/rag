00:00:10.440 - 00:00:41.040, Speaker A: Welcome back to the infinite Jungle. On today's show I'm speaking with Shawn Anderson, software engineer at Sigma prime, about the Pectra upgrade. But before we begin with the show, here is a quick show disclaimer. I need to remind you to please refer to the disclaimer linked in the podcast show notes and note that none of the information in this podcast constitutes investment advice, an offer, recommendation, or solicitation by Galaxy Digital or any of its affiliates to buy or sell any securities. Hi Sean, how's it going?
00:00:41.500 - 00:00:43.920, Speaker B: Hi, Christine. It's going good. How's it going with you?
00:00:44.420 - 00:00:56.070, Speaker A: Not bad. I just came back from ECC, so I'm a little bit still jet lagged and getting back into the swing of things. But I have so many questions to ask you about Pectra. So I really thank you for the time.
00:00:56.370 - 00:00:58.650, Speaker B: Yeah, of course. I'm jealous I couldn't make death.
00:00:58.690 - 00:01:09.298, Speaker A: You see, this year it was one to remember. I'm sorry that you missed it, but I hear the next one is going to be in Cannes, so that's kind of cool.
00:01:09.434 - 00:01:11.670, Speaker B: Yeah, I'll have time for that one, I think.
00:01:12.050 - 00:01:39.770, Speaker A: Nice. Yeah, you gotta plan these things in advance. I thought so. I do really want to talk to you about Pectra, but I thought for a listener's sake, maybe we could talk a little bit about your background working for Sigma prime. Of course, but primarily working on the lighthouse client, which is a pretty major consensus layer client on Ethereum. Can you talk a little bit first about your background getting into the space? Into the crypto space, I mean. And then starting work on Ethereum protocol development?
00:01:40.710 - 00:02:34.508, Speaker B: Yeah, sure. So let's see. I started working with Sigma prime four years ago in 2020. It happened around, I guess, COVID lockdown time, because prior to that I was working at a consulting firm where I was writing software for investment banks. And once lockdown happened, I had more time working from home for a bit of schedule flexibility. And I had been following the f two research and the spec for a while and I started looking into specific client implementations and I found the Sigma prime one, which is Lighthouse, which is written in rust. And I decided I wanted to contribute a bit.
00:02:34.508 - 00:03:09.400, Speaker B: So I started contributing my free time for like four or five months. And eventually they reached out and they offered me a job full time. And I was like, let's do it. So, yeah, that's how I got involved. Sigma prime, they're an australian security company. And so when I reached out, they were super welcoming. They were willing to mentor me because I had never worked in rust before, and they're a bunch of smart, kind australians, and it's been a pleasure to work with them so far.
00:03:09.860 - 00:03:41.580, Speaker A: That's pretty cool. And in terms of the technical skills that you have learned on the job, in terms of the technical skills that you use to build the lighthouse client now, compared to the technical skills that you use for writing software for investment banks, would you say that this job is a lot harder in terms of your growth as a programmer? How does it compare working, doing software engineering and being a programmer for, say, more traditional finance versus crypto?
00:03:42.800 - 00:05:03.154, Speaker B: Yes, been pretty drastically different. I would say the biggest difference, like technologically, is that everything in a bank pretty much has to be pre approved. And at least the products I was working on, it was always way behind what I guess the bleeding edge technology stuff is. Whereas with Lighthouse I've spent a lot of time just researching what dependencies we should use, vetting them myself, seeing what's performant, what's secure, whereas at my old job we had an internal repository of dependencies and that's what you had to use. I really enjoyed that, I guess staying on the bleeding edge of the technology and even sometimes we're helping push the boundaries of what's in the rust ecosystem, which I think is really cool, as opposed to being 612 a couple years behind a bank. So that's been really fun. Something that is, interestingly, I guess, kind of similar has been the decision making process on some level.
00:05:03.154 - 00:05:30.230, Speaker B: Wherever in a big massive company like a bank, you have a lot of decision by committee, a lot of people that need to be involved. And Ethereum is weirdly like that with the decentralized decision making, the only difference is it's fully open ended where anyone can really give input, whereas the bank gets closed ended on some level. But sometimes it feels as, I guess, broad because just random people pop up and have input.
00:05:31.020 - 00:06:24.010, Speaker A: Okay, that's a perfect segue into the discussions, because this time the governance discussions I feel like for Petra have broken so many norms. In the Ethereum governance process, usually there is a set of code changes that developers agree we're going to include into a hard fork. This time there was a set of code changes that developers agreed to be in the hard fork, and then several more that started to be input into the hard fork at a later point after those code changes were already finalized. And even now there's a ton of conversation about still more code changes that may or may not get into the upgrade. What is your view on how the Pectra upgrade governance has been like, are you concerned at all about some of the norms that are being kind of newly created in this governance process? And if so, which ones?
00:06:24.050 - 00:07:00.230, Speaker B: I. Yeah, I mean, I have always been pretty interested by the Ethereum, Ethereum governance generally. Like, even before I was working at Sigma Prime, I would watch the YouTube live streams of calls. It always came across to me as, like, odd actually being involved has been. I found it really fun and Petra specifically has been. I mean, I guess chaotic is a way to describe it. Overall, though, I don't have any particular concern about the decision making process.
00:07:00.230 - 00:07:40.830, Speaker B: I kind of view it as there's just a bunch of different people who want different things, but they all want to make Ethereum better. So it's kind of like the same goal with different perspectives on how to achieve that goal, and everyone's just got like, different priorities. And I personally haven't felt like there's been people who are, I guess, disingenuous on that front. So I don't have concerns in that regard. And the process could have been smoother, I guess. But I don't mind the drama. It keeps me entertained, I guess.
00:07:41.330 - 00:08:16.410, Speaker A: Yeah, the calls are a lot more entertaining now. Yeah, calls are good. A little bit of a side question, but do you ever get nervous speaking on the ACD calls, knowing that it's like live streamed and knowing that somebody like me is going to be like, quoting you and, you know, it's a pretty high profile technology that you work on, but that's always something I'm curious about. When I'm like, listening to these calls, I was like, I wonder to what extent developers I don't know, feel comfortable or don't sharing their thoughts honestly, like, genuine, win a genuine way, like, on these, on these platforms.
00:08:17.110 - 00:09:29.836, Speaker B: Yeah, I definitely found the calls very intimidating at first because like, I was a spectator and I felt like I was coming in as a foreigner, but now I'm more comfortable participating on the calls and I have the perspective that it's like, I would find it really refreshing for people who don't normally come to join and maybe have a presentation on topic or whatever. New voices from my perspective are really nice to hear. I do feel like there is some truth to maybe people having reservations about speaking their mind. It seems like people might be more comfortable communicating in the chat as opposed to speaking verbally. And it seems kind of natural to me. I think that's probably just people being afraid of, like, I don't want to look stupid because the subject matter is really hard and it's hard to be across everything at once and people are across things to different degrees. So I definitely get it to that extent sometimes.
00:09:29.836 - 00:09:36.210, Speaker B: I'm definitely staying quiet when I'm like I'm not totally sure about this specific topic. So.
00:09:36.630 - 00:10:13.922, Speaker A: Yeah, no, that's fair. I do. I agree with you. I think Tim, also the chair of the ACDE calls, had talked a little bit about how it's not the forum for everybody, especially certain people who don't want, who feel nervous about maybe more public speaking type communication. But I will say I think the cadence of the ACD calls and that like process is a really great way to ensure that decisions get made and that, you know, developers, as Ethereum grows, it doesn't constantly like not make decisions. It's like a nice little forcing mechanism sometimes. Completely agree.
00:10:13.922 - 00:11:27.550, Speaker A: So on the topic of priorities, though, I agree with you that probably everybody does want to make Ethereum better, but there's clearly just so much, so many different angles in which people think priorities should land. And for the Lighthouse team you guys did basically say your opinion is that one of the highest priorities should be peer dash should be scaling Ethereum for roll ups and peer Das. Now it looks like it is going to be very prioritized for Petra. That almost seems like it's the headlining feature for Petra, which is surprising because in the beginning of Petra discussions I thought it was going to be Max E B. I thought that was going to be the headlining upgrade and that's still going into pectra. But it almost seems like peer Das now is the major code change going in. Are you concerned at all about like the complexity of the fork? Do you think that there are certain priorities like peer desk that should just be, you know, prioritized and some of the other code changes just left for another time for activation, like pushed back into a different hard fork? What are your thoughts around too many trying to like prioritize too many things all at once?
00:11:28.890 - 00:12:48.640, Speaker B: Yeah. So I generally have the perspective that having more changes in per fork is better just because I view it as each hard fork has a certain amount of overhead just in trying to scope the fork, obviously that takes time and then communicating to everyone that these changes are going to happen, like to the ecosystem. So any changes impacting the ecosystem, people have to make changes for on top of that, getting all the infrastructure updated, like all the nodes updated. And we also have just testnet cycles where we have launch a Devnet, make spec changes, launch another Devnet, whatever, and iterate in that way and then get to the public test nets there's built in time, that sort of just process and overhead, that's like per fork. So from my perspective, like bigger forks is kind of better. I think other people, like, I understand this perspective too. Other people would suggest that like the more changes you put in a fork, the more the testing complexity, like it grows exponentially.
00:12:48.640 - 00:13:49.892, Speaker B: In this fork, for example, we're adding like a few different operations, like execution layer triggered withdrawals, for example. And so we're going to have to test combinations of these operations and understand concern with that. As far as overall complexity in this fork specifically, I think without peer Des it's like reasonably complex, but not overwhelmingly from a client perspective. I think that testing overhead is already relatively high, though adding pure desks, it's like a different dimension of testing that's pretty difficult to test, which is like network level testing. And there is a lot of engineering work that also goes with peer desk. So then it becomes like a big fork. This doesn't necessarily scare me though.
00:13:49.892 - 00:14:44.726, Speaker B: It kind of excites me. So I support peer Das inclusion. But realistically, peer desk is like there's still spec changes coming through that seem relatively big and it still seems like there's a fair amount of engineering and testing to do. So it is still like a bit on its own as far as like readiness compared to other execution layer changes. The rest of, sorry, other consensus layer changes, the rest of the consensus layer changes for us are fairly well productionized at this point and like we're working on merging them in, whereas peer desk is still a bit more experimental in development, maybe. Overall, I tend towards big forks and I'd like to see peer desk inclusion in Petra. Realistically it is a bit behind.
00:14:44.726 - 00:14:59.450, Speaker B: So it kind of matters about how this lines up with the execution layer timeline. Right. If execution layer is like ready tomorrow, then realistically no peer dust. They're already in six months, maybe peer dust.
00:14:59.790 - 00:15:21.290, Speaker A: You think that there's a future where Pectra could go live without peer Das, do you think politically, governance process wise? It sounded like, you know, certain client teams were very adamant that peer Das has to be in Pektra. But just to confirm. So you, you think there is a future where if the other code changes are ready and peer Das isn't, they will go live first?
00:15:22.350 - 00:15:34.970, Speaker B: I think if the, I guess timelines diverge relatively drastically. Yeah, I think that's possible. Personally would definitely like to have peer Desktra.
00:15:35.430 - 00:16:32.170, Speaker A: So technically speaking, I always hear this a lot, that peer Das is complex on the networking level and it can be worked on in a different isolated way than the other pectra eips. Can you explain why that is a little bit more understand that peer Das doesn't technically require a hard fork, but I would just like a little bit more color and detail, I guess, about why networking changes are very different and the kind of work that's needed for that kind of change versus the other core pectra eips. I've always heard this a lot before, but what does that even mean a networking change entail? Like, are those not part of like the official specs or are they, but just like in a different way?
00:16:33.070 - 00:17:53.400, Speaker B: Yeah, it's kind of like they are in that the specs define like, oh, like get the data from your peer and check it in this way. And we're just sort of changing the mechanism for how the data is propagated. So I think people divide it between networking and consensus and that there is a consensus mechanism where it's like, okay, assuming I have all the messages, this is the result I should get from my node. This is what my node should say the head of the chain is. And then networking is like, okay, how are the messages distributed? So with peer desk specifically, you're essentially checking like, does this data exist? Is this data that I can get for my peers? And prior to peer desk, it's essentially like, you know, the data exists because like it's sent to everyone. So it's like a big portion of the consensus client is just receiving attestations. So like hundreds of thousands of votes from other nodes about what the head of the chain should be.
00:17:53.400 - 00:18:30.310, Speaker B: Then like processing them and receiving blocks. Processing blocks and figuring out what's the head that is all impacted by like MaxcB and by our change to the attestation structure in this fork. And those are impactful in, I guess this whole message and block processing portion and then peer dash just entirely separately is like, okay, how do we spread around these pieces of the block?
00:18:30.610 - 00:19:59.788, Speaker A: I never really fully understood exactly how these code changes were delineated and why pure Das was considered a networking change. But yeah, I think that makes sense. And it was also brought up, this was a topic of conversation in terms of testing efforts and complexity when developers were talking about the Deneb upgrade and blob propagation as well. Is the networking load on Ethereum today like changes to the networking load on Ethereum? Do you think that peer Das should be coupled with a very definitive change to very definitive change to the amount of blobs that are moved around on the network? I think there's a little bit of disagreement between developers of whether or not peer dash should definitely be coupled alongside a change to the blob gas limit. And from a technical perspective, I'm wondering if you do think it's actually safer to just isolate peer Das as a networking change first, see how things go, and then move on to changing maybe a little bit more of the consensus part if we're talking about network versus consensus. But there's also other arguments saying, well, if you're going to do the networking change, you have to make those consensus changes anyways. I don't know.
00:19:59.788 - 00:20:06.840, Speaker A: From a technical perspective, do you think it's a big difference or deal the way that it's executed and implemented?
00:20:07.620 - 00:21:06.850, Speaker B: Yeah. Yeah. So the debate over blob count is like, that is the one ingredient that impacts the consensus layer and that it's like one of these inputs into how we process blocks. So that's the relevance where that's what, that's what would make pure Das into like, oh, like you have to have it as a hard fork. But essentially I think we're at the point where like even if there is a consensus change or not related to peer Das, we'll probably want to treat peer Das as essentially a hard fork because it's got the same sort of dynamic where we want all the nodes to update at the same time. We need like that same degree of coordination, I guess. And then as far as my opinion on whether we should increase the blob count as we release peer Das, I think that we should, to a degree that we think is reasonable.
00:21:06.850 - 00:22:00.920, Speaker B: There's, I guess, desire to have a lower blob count with peer Das and thinking that that's like, I guess the safer option, more conservative option. And I think that is true, but I think less is always going to be more conservative. So it's kind of like if we're increasing the network capacity to some degree with peer Des, I think that the majority of the risk is in peer Das itself and not necessarily this like blob count number. So I think we should just do like a sort of best guess. Like let's increase it to what we think is reasonable and that increases the risk, I guess, to some extent. But the risks are so high with just like even a constant blob count, then I don't, I don't think it moves the needle in my point of view.
00:22:02.380 - 00:22:09.412, Speaker A: There is the saying, you know, the straw that breaks the camel's back, though. That's true. That's true.
00:22:09.436 - 00:22:12.740, Speaker B: We may, we may have already blown past that straw, though.
00:22:12.900 - 00:22:24.390, Speaker A: That's fair. Okay, well, if it's a three, a target of three per block, and a maximum of six blobs per block, what is the reasonable increase? Do you have a number in mind? Is it going to be 64?
00:22:25.690 - 00:22:34.550, Speaker B: I personally do not have a number. Okay. I'm not sure I'm ready to give one out either without, without crunching them for a bit, I guess.
00:22:35.010 - 00:22:56.830, Speaker A: What about a timeline for pectra? Based on what's all going in and the progress that you have now, in my opinion, I think there's zero chance that it happens in 2024. But do you have any, you know, more inklings of when it could happen in 2025? Are we talking like mid year 2025? End of year 2025?
00:22:56.990 - 00:23:10.570, Speaker B: So my hope would be like early 2025 with peer to us. That'd be amazing. But we'll see. I don't know, maybe that drags on to mid 2025. I still think that'd be great.
00:23:11.030 - 00:23:16.770, Speaker A: I see, I see. Yes. That still seems ambitious in my mind. I know you've been very.
00:23:18.490 - 00:23:23.270, Speaker B: I tend towards, like, ambitious timelines, I guess. So take, take it with a grain of salt.
00:23:23.610 - 00:24:15.870, Speaker A: No, it's fair. You and, like, literally every other protocol developer. And the optimism I hear from you is quite a lot. I mean, especially when you were like, you know, I think we should include more rather than less, you know, with the amount of time it takes to even do these forks. Okay, so you obviously, you know, spent a lot of time talking about these consensus layer changes, working on these consensus layer changes. How much visibility do you have on the execution layer side of the upgrade? Have you been, you know, listening in on the ACDE calls following along with the governance process happening on the execution layer side? Because that, of course, is going to impact the consensus layer to some degree. Do you have any thoughts or opinions about how about the code changes that are going to be going into the Prague side of the upgrade? Any, any ones that you kind of wish wouldn't be in Prague?
00:24:16.610 - 00:25:10.760, Speaker B: Um, so I try to stay across the execution layer sets of changes, um, mostly because I find it interesting and their calls are especially spicy. Um, but I'm not as, like, when I hear about these changes, I can't, like, think in my head, like, oh, like, that's x amount complicated. So I'm not across it to, like, that degree, although that would be, like, valuable for me to understand because it's like our timelines are obviously, like, interlinked to some extent. Like, their scoping impacts ours and ours impacts theirs. Do I have opinions on what not to include? No, I don't think so. So I missed the most recent execution layer call because I think it was on the fourth of, but I think EOF is included. Right.
00:25:10.760 - 00:25:23.528, Speaker B: That was the last spicy change. Okay, nice. To me that sounds really interesting. It sounds like a lot of incremental improvements for the EVM, so I found that exciting.
00:25:23.704 - 00:25:44.520, Speaker A: Yeah, EOF was definitely the latest, the latest one to really get included. But I still think the switch from EIP 3074 to EIP 7702 on the execution layer side, that was a little bit of a sudden last minute change that I think the El developers are still trying to work out and finalize.
00:25:45.140 - 00:26:23.840, Speaker B: That was also very interesting. I thought that some people viewed this as like, oh, like this is a failure of eth governance or whatever because of how rapid it is. But I think that people tend to just really quickly, I guess, come to consensus on ideas that are good. And this seems like a strict improvement over the prior design as far as I can tell, my untrained eyes, but, and I feel like that's a good thing. It's like people recognize good ideas and like move them forward quickly. Like that's a good thing in my point of view.
00:26:24.820 - 00:27:13.264, Speaker A: Do you think that the governance process between the EL and the CL should be more merged? Do you think there would be more benefit if more execution layer developers join the consensus layer calls and participated, and more consensus layer devs joined the execution layer calls and participated? I think there's because the protocol of Ethereum itself is becoming so much more complex over time. Some people just have very niche understandings of different areas of the code, like the EVM versus, I don't know, the beacon chain or networking versus the consensus that could create problems. If there's like third order consequences of certain code changes that you don't expect it'll impact this part, but you just don't have an expertise in it. To what extent do you think, are there any thoughts around how you think the governance process should improve?
00:27:13.392 - 00:28:00.980, Speaker B: Yeah, I think it's definitely good to have exposure to both layers. So yeah, it would be good for client teams to try to join both calls, at least follow along as much as they can. There is on some level like a limit to how much you can, I guess, have that level of expertise in. So like for me it's like I can't, I can't, I don't have time to dive into all the execution layer eips as well, even though that would, that would help. But overall, like when, when there are interactions between the CL and El. To me, so far, it has seemed like people do end up getting a good understanding of, of the dynamics on both sides. So I haven't really seen a lapse there, I guess.
00:28:01.640 - 00:28:57.220, Speaker A: Yeah, the governance processes in terms of, like before the merge, when everything was all happening on one chain, to post merge, when there's the execution and the consensus layer, I don't actually think that it's changed too much. I mean, there are definitely double the amount of calls because before the merge it was bi weekly, but now we do it every week, I actually think. Yeah, I agree that, you know, there's still that kind of communication. I also wanted to ask you a little bit about the future of kind of client development. So I had James Prestwich on the show before. He's not a protocol dev, but he does, like, research on Ethereum. And one of the things that he was talking about was how having multiple clients on Ethereum is very unsustainable and very expensive and also a little bit unnecessary.
00:28:57.220 - 00:29:34.630, Speaker A: And I've also been hearing lately a lot more talk about how the Ethereum foundation does really want to become. I mean, they've been saying this for a while, but, like, minimize their role in the ecosystem. But the truth of the matter is that the Ethereum foundation does still support so many clients. Curious to know your thoughts on, like, the, the sustainability of the number of clients that Ethereum has and whether or not you think that we would still have this many clients if the Ethereum foundation wasn't supporting as many of them as they do.
00:29:35.850 - 00:30:05.980, Speaker B: Yeah, I definitely get that. It's like, so I personally have found it massively beneficial to have multiple clients. It's like we're always testing our implementations against multiple clients. So, like, in the development process, it's like, invaluable. There's definitely, like a number, though, where you have, like, enough clients. I would say I don't know what that number is, but I think it's definitely greater than one. I think greater than two.
00:30:05.980 - 00:31:14.930, Speaker B: So, yeah, I think the benefits are there of having multiple clients. And then as far as, like, sustainability. Yeah, I definitely understand that. It's like, it's expensive to hire this many engineers, have them maintain the code, and on some level, like, yeah, I see how it can't go on infinitely from just like a bunch of EF support. But there's initiatives like the protocol guild, which is sort of supposed to, I mean, maybe like, long term supplant the role of the Ethereum foundation, where they're essentially like collecting donations and distributing to client teams. So like that to me could end up being a long term sustainable thing. But it is like blurry as far as like how many clients? How much is too much? What is a sustainable like level? I guess so.
00:31:14.930 - 00:31:16.250, Speaker B: We'll see.
00:31:16.590 - 00:31:22.370, Speaker A: Is there too much right now? Do you think that the five and six that we have right now are too much?
00:31:23.590 - 00:31:25.570, Speaker B: I think right now it's just perfect.
00:31:27.110 - 00:31:31.290, Speaker A: It's the optimism from you, Sean, again, talking the possibility.
00:31:32.130 - 00:31:34.950, Speaker B: What am I supposed to say? Like, oh yeah, dump this tea.
00:31:35.250 - 00:32:24.444, Speaker A: Yeah, that's what I was expecting. That's exactly what I was expecting, but that's okay. Well, you mentioned the protocol guild and I agree that's a nice community funded little and okay, I shouldn't say little, you know, it's a good effort. All right, it's a good effort. But any initiatives that you're hearing about from within Sigma Prime, I think Sigma prime is kind of a very unique company because they're a security firm. Maybe they do some other stuff, but they support client development and I think it's a unique model in terms of sustainably funding something. Whereas other client teams, the smaller ones, are very much grant driven or they're owned by kind of like a larger, like a L2, like a larger kind of crypto native building an application or a service on chain.
00:32:24.444 - 00:32:43.550, Speaker A: Whereas. Yeah, whereas I feel like Sigma prime isn't trying to really build like an app on Ethereum or really build their own roll up, they're doing something else. Yeah. Any thoughts on kind of the business model that Sigma prime has to be able to host? Lighthouse?
00:32:44.530 - 00:33:50.960, Speaker B: Yeah, no, I think that's a really good point. I think Sigma prime has gotten value from having Lighthouse as a project in terms of like its brand and its like I guess position in the space. Like if Lighthouse is a good client, insecure, then that speaks positively towards the company as being a good security firm. So there is value there and I think thats probably why there have been some other new clients too that have joined on some level. It's not purely a money stink for companies, I don't think. I view it similarly to how maybe in the very long term there's a company that can have its own client that it's developing and it makes money via consulting services on people who run this client or something like that. So yeah, I think there's a path to sustainability somewhere.
00:33:51.300 - 00:33:54.400, Speaker A: Yeah, Reth is a good example of that.
00:33:54.900 - 00:34:01.360, Speaker B: Yeah. They have maybe benefits with paradigm portfolio companies for example.
00:34:01.700 - 00:34:26.850, Speaker A: Right. They're definitely our synergies all right, cool. Well, thank you, Sean. Thank you, Sean. For all of the insights on Pectra and how client development works. It's really cool to hear more from the developer like, yeah, from the developer point of view, how this is all going down. And I really hope that we can talk again as Petra gets farther along and finally moves past Devnet one.
00:34:26.850 - 00:34:38.598, Speaker A: My goodness, it's taken a little bit longer than I expected for Devnet one, to be quite honest. But, you know, we're getting there. So maybe on like Devnet five or something we can check back in.
00:34:38.654 - 00:34:41.988, Speaker B: Yeah, perfect. That sounds great. Thank you for having me.
00:34:42.044 - 00:34:57.740, Speaker A: Well, thank you, everyone else. For everyone who is listening to the show as well. We will be back again with another episode next week. But until then, fellow ethereum explorers who are exploring the infinite jungle, stay safe out there.

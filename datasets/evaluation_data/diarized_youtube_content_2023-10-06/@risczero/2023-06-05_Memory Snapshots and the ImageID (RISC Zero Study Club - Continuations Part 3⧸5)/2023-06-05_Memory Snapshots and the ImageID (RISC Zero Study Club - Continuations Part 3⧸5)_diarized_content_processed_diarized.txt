00:00:00.090 - 00:01:01.114, Speaker A: So let's look at the memory snapshot. So what we did is we kind of looked at the idea of how do we verify that one segment is related to another? It kind of comes down to this whole notion of this image id. What we want to be able to do is say that segment one, segment two expects to start with the same image id. I'll go back to this one. So if we say that a and b are both image ids, what we want to do is prove that when segment two starts, we expect the starting image id to be whatever the result of segment one was, and it's going to produce a new image id, in which case we want to make sure that we're always going from a to b to b to c to c to d, d to e. And so what is the image id? It's basically the root hash of a Merkel tree. And that merkel tree is made up of all of the hashes of pages in memory.
00:01:01.114 - 00:01:57.010, Speaker A: So what we did is we kind of looked at, we kind of borrowed some operating system technology where they have this concept of a page, which is essentially, if you take all your memory and split it up into chunks, call it a page 1 size that we're currently using, then what we do is we can do a hash of that page that becomes an entry in the page table. The leaf nodes in the Merkel tree are all sort of the hash entries for all of the pages in memory. Now there's this funny thing that happens eventually. There's kind of this overlap where we build this Merkel tree. It's not a binary merkel tree. The arity is pretty large. It's like however many entries, however many hashes that you can fit into a single page.
00:01:57.010 - 00:02:54.900, Speaker A: That's the arity of this merkle tree. So there's this kind of overlap that happens if you imagine the page table starts with all just the user memory, but eventually the beginning of the page table itself is actually inside the page table also. So eventually, at the very end of this page table, you end up having sort of a root page, which is sort of the summary of all the other previous pages. And the final hash. If we take that final root page and we hash it, we finally get this image id. And that basically tells us that it's basically an efficient way to represent the verification of an entire memory image, which is currently it's about 192 megabytes. But yeah, that's basically what an image id is.
00:02:54.900 - 00:03:03.240, Speaker A: So I guess I'll stop there for a second and see if there's questions, or I can try to explain that a little better.
00:03:10.000 - 00:03:13.676, Speaker B: I'm curious if you can necessarily do.
00:03:13.698 - 00:03:15.516, Speaker C: This segmenting on all programs, or if.
00:03:15.538 - 00:03:19.756, Speaker B: This is just programs where you could.
00:03:19.778 - 00:03:24.320, Speaker C: Parallelize it, and later instructions aren't dependent on earlier instructions.
00:03:25.540 - 00:04:06.140, Speaker A: So yeah, there's a concept of instruction level parallelism. There's different kinds of parallelism. In our case, we only support like a single thread of execution. There's only like a single context, a single core you can kind of think of that the circuit implements. And so we don't yet have the ability to run multiple cores or multiple threads of execution at the same time. And so really what we're looking at is parallelism for the proving, not necessarily parallelism for the execution. So the execution is all serial.
00:04:06.140 - 00:04:40.808, Speaker A: There's sort of this dependency. Now your compiler may decide to reorder instructions or do whatever it thinks is best in order to achieve better serial performance. And currently we don't have any sort of vectorized instructions, so we don't even get instruction level parallelism either. That would require sort of vectorized instructions to be supported, which we don't yet do. Maybe that's something we'll do in the future. But it's pretty complex. It would cause the constraints to go up quite a bit for the proving system.
00:04:40.808 - 00:05:05.410, Speaker A: So we picked risk five because it's pretty challenging to kind of get all the constraints to run feasibly. Right. So if we pick a more complex instruction set, the constraints go up quite a bit. I don't know, does that answer your question?
00:05:06.020 - 00:05:09.536, Speaker B: Yeah, let me check. So it's not that you couldn't do.
00:05:09.558 - 00:05:11.280, Speaker C: This on Fibonacci, for example.
00:05:11.350 - 00:05:13.776, Speaker B: It's that you do all of the.
00:05:13.798 - 00:05:18.828, Speaker C: Segments and then your verification of them is what you do in parallel.
00:05:18.924 - 00:05:23.604, Speaker B: And you get some scale bonus from this.
00:05:23.802 - 00:06:21.272, Speaker A: Yeah, so the proving is the part that is the most expensive, and that's the part that we can parallelize. So the idea is that running you can take any program you want as long as it's a risk five program. We can execute that entire program with however many cycles it takes. It may take millions and millions of cycles, billions of cycles. In fact, we can go through and run all of those cycles and record all of the memory transactions that are going to occur across that entire execution. So that's kind of the serial part, but that part we can run pretty fast because we aren't doing any proving, we're just purely emulating the actual risk five architecture. We could even run the execution on a real piece of hardware if we wanted to, provided that we had the sort of introspection, we could watch all of the memory transactions going by.
00:06:21.272 - 00:06:58.772, Speaker A: But it is possible in theory to basically run the execution phase in real hardware. So it goes really fast. But then doing the proving, we can basically split transparently. We can just basically decide where the splits need to go and inject some overhead. There's like page ins and page outs. There's basically whenever a piece of memory is accessed, we need to do this page in operation, which is basically go and on demand. When a piece of memory is accessed, go and hash the page that that piece of memory comes from.
00:06:58.772 - 00:07:51.196, Speaker A: And then we're going to do this sort of tree of that. It's kind of like an inclusion proof where we hash up the tree through the merkel tree and verify that the image id is the one that the user has selected. So this is kind of on the read side and then on the right side, when we go to write out the final page, there's also this page out kind of overhead. So for every segment there's like extra cycles that we inject in order to perform this memory verification. But other than that, like the user doesn't really need to see sort of where the splits are happening, it just happens automatically. And so yeah, any program should be capable of doing that. And the parallelism you get is from the most expensive part, which is the proving, constructing a proof for a given segment.
00:07:51.196 - 00:07:53.040, Speaker A: That's the part we can parallelize.
00:07:53.700 - 00:07:57.070, Speaker B: Thank you, that's very helpful. All.

00:00:00.090 - 00:00:33.158, Speaker A: I'm part of the Zath team, and actually we are currently three people in that. So it's me and my amazing colleagues, Tim and Rami. And Zath is our ZK block prover for Ethereum. And in this talk, we are going to look at what exactly this means, how it works, and maybe what we are going to do in the future with it. And of course, like everything in risk zero, this is open source. So feel free to look at the GitHub under the following repo. Yeah, support us.
00:00:33.158 - 00:01:35.498, Speaker A: Write prs, or just look at the code, whatever you want, or run it, of course, all open to you, I guess, since we're in the risk zero study club and there have been previous sessions, whatever, you guys are all reasonably familiar with what a ZK proof or a ZK VM is. But so as a little warm up and so that everyone is on the same page, I have one slide for that, as a little introduction. So let's say Alice has a program that she wants to run. So she obviously has some input to it. And then the program eventually produces some output, right? And now she wants to convince Bob that actually she run the program and that the output is indeed the correct output that the program gets. And then, of course, she can give Bob the input, the program and the output. And then Bob then can also just rerun everything and check whether everything is correct, or ZK is an alternative for that.
00:01:35.498 - 00:02:22.746, Speaker A: So you essentially create a proof, and this proof then cryptographically essentially links the execution of this program and the output together. And then Bob only has to check this proof and has the cryptographic guarantee that the program was indeed run, resulting in that output. And this has two huge benefits. The first one, as you can see here, Bob doesn't need the input for that. So you have the privacy concerns there. The input stays basically hidden. And the second one, which is maybe more relevant in the crypto or blockchain context, is Bob doesn't even have to run the program.
00:02:22.746 - 00:03:01.270, Speaker A: Quite frankly, he can't do it because he doesn't know the input. He just needs to validate the proof. And usually validating the proof is easier or faster than the actual program. So those are the two benefits. And usually writing zero knowledge proofs are very hard and involve a lot of math. Yeah, that's why was the topic of quite a few study club sessions before. And ZK virtual machines, zkvms and especially RisC zero wants to make this much easier.
00:03:01.270 - 00:04:04.502, Speaker A: And the risk zero virtual machine is just a standard processor. So anything virtualized processor and anything that gets run, any program that gets run on this processor also generates this nice proof that we talked about earlier. And as a developer or as a user, you don't have to worry about this. You just have to create a program that runs on this processor. And since this is standard, we can essentially use a whole lot of compilers or whatever is out there. And for various reasons, our preferred language is rust and has the most support. So essentially that means you can use any rust program, you can write any rust program, use any rust crate that you want and just compile it and run it on this risk zero ZKVM, and then you get this nice zero knowledge proof with the same guarantees.
00:04:04.502 - 00:04:47.510, Speaker A: So what exactly are the restrictions? And why is it not what any exactly means? This is exactly what we're going to see also in the context of this presentation. Okay, so I said zest is our ZK block prover for Ethereum. So we have now established what ZK proofs are. So let's take a quick look into what Ethereum actually is. Again, this is a whole new topic and very detailed. So just a very quick overview here. Essentially, Ethereum is a state machine.
00:04:47.510 - 00:06:14.500, Speaker A: State transition is induced by a so called block, which is a bundle of transactions, and in contrast to more classical blockchains, where the state is just account plus balance, so that you can basically transfer funds around. Ethereum went one step further, or actually the ultimate step further, and also introduced basically like randomly accessible memory to every account, which means that you can run essentially any program as part of this state transition, modify the state of account in any arbitrary way. And those programs are then called smart contracts. And since Ethereum is not only that, but it's also decentralized, you have to make sure that the state transitions or the outcome is consistent with all nodes in the network. So for that, each block basically has a cryptographic reference to its parent, which gives you basically a guarantee that the history cannot be altered. But that alone is obviously not sufficient. If you only reference your parent, you could still have a tree or whatever with many, many leaves, and it would be not clear what the actual valid output or the valid current state would be.
00:06:14.500 - 00:07:23.306, Speaker A: So you have to come to consensus among those network nodes what it is, and decide basically what of those parallel chains or leaves or whatever is the valid one. But at least for this talk, we're not interested in this at all. We can basically forget this or use it as a black box. I just wanted to mention it, that that is obviously a very important part of any blockchain essentially. And now, what can you zkify in Ethereum? The first thing you can do is basically you create a proof for everything. So for each one of you who has tried to run an Ethereum node before, you'll notice that when you spin it up, you essentially have to sync it. And that essentially means you have to replay all the transitions of the history of Ethereum to make sure that all the state transitions are correct, and that also the final state is indeed the desired one.
00:07:23.306 - 00:08:06.518, Speaker A: And also in the meantime, you have to make sure that those consensus decisions are correct. And so you also have to take in this data that was used for the consensus mechanism into account. And that takes a long time. So of course it would be very nice if you could essentially download just the final state from essentially any untrusted source and then just get one proof that gives you the guarantee. Yeah, someone else basically applied everything, applied consensus, applied all state transitions, and that is valid. And that then goes into the direction of what maybe a light client would do. So that would be one option, or you could say maybe another use case would be you don't care about this consensus part.
00:08:06.518 - 00:09:09.974, Speaker A: You kind of assume that you are the latest block and the latest state, but you want to have certain guarantees about the parent blocks, maybe very deep in the history of Ethereum. And there again, it would be nice to have proofs that the blocks are correct, that the state transitions were correct, without you needing to replay everything. And the third one, maybe one step smaller, is what Zat actually does, is basically only look at a single block execution that looks very minor to all the previous things we had. But thanks to those nice recursive properties that z cave proofs have, this is actually the most important building block. And yeah, if you have this, you can recursively build up the other parts. So this is probably the most relevant part. And this exactly is what Zeth tries to do.
00:09:09.974 - 00:10:25.154, Speaker A: So we take a closer look at this, what do I mean with block execution, and actually conveniently with the merge. So when Ethereum switched to proof of stake, Ethereum itself had this distinction between execution client and consensus client consensus doing the consensus work, and execution doing the block execution. So what does an execution client do? It listens basically to new transactions broadcast to the network. And then at certain points when it's triggered, it tries to build a new block. And for that it essentially takes a subset of those transactions as an input, and also other information, like a timestamp, or maybe some other minor or block producer information. It takes that as an input, then the actual heavy lifting is happening, the state transition, which means essentially all the transactions that were selected need to be executed. And Ethereum comes with its own runtime for that.
00:10:25.154 - 00:11:28.570, Speaker A: So that is standardized and nice and well defined. And this is the so called EVM, so Ethereum virtual machine. So you have to execute everything in this virtual machine. This includes transfers of coins, of tokens, but also basically any smart contract that you want to execute. And then once this is done, you have basically the state transitioned. The state is now in the final how it's supposed to be after this. And then you can actually output the block, and the block contains the input transactions, or at least references to them, but also a commitment to the state so that other nodes in the network can easier validate that the state transitions that you did are the same, and that there are no deviations in the state, which would be terrible if the nodes in the network would not converge.
00:11:28.570 - 00:12:11.362, Speaker A: Yeah, and that is more or less exactly what we now want to do with Zath, but only like in a ZK manner, which means we have this input that is basically that we need this. This is something that is a requirement that is not proven, that needs to come in. And of course the block produced will depend on this input. And then Zeth produces this new block plus the proof. And then everyone can essentially just check. Yeah. Is the proof correct? And does it match with the block cache, whatever produced? And then we know that all these execution of these transactions were executed correctly.
00:12:11.362 - 00:13:20.300, Speaker A: And not only is this an important building block to other bigger use cases, but by itself this is already pretty relevant, because, for example, execution of transactions is very costly. And in a network with 100,000 nodes, essentially every node has to run the same computations to make sure that the outcome is indeed the same. So this is rather wasteful. And having a proof here that the execution was correct is very beneficial. Okay, and like on the previous slide, I said that with RisC zero, you can run essentially any rust program, any rust crate in the zero knowledge context on the ZKVM. So perfect. Then we take a rath, which is one very nice rust based node implementation, and we just run it inside our vm, and then we're done.
00:13:20.300 - 00:14:13.226, Speaker A: But unfortunately, this will not work. Actually, the compilation will fail already. And why is that the case? The first, most obvious one is the network layer. So every ethereum node has some peer to peer components to get transactions or blocks over the network. Stuff like this, and like networking is not really well defined in the context of a provable execution. You just have one party, so what are the other parties doing? And also you get some timing components into it, and it's not even deterministic, so that doesn't work. This component is something that cannot be emulated in a provable context, and the other one is the database.
00:14:13.226 - 00:15:02.606, Speaker A: So essentially it's highly optimized, but essentially you need the previous state somehow in an accessible format to basically apply the new transactions and stuff like this. And in any ethereum node this is stored in a DB. And this also doesn't really work in a ZK context. Even if you say okay, you emulate the database and the hard disk somehow in memory or whatever, you still need to make sure the data that is supposed to be in this database needs to be trusted or it's useless in a verifiable context. So because of those two reasons, it doesn't work as is. But there are very good solutions for that. So I'm not worried about the network stuff.
00:15:02.606 - 00:16:14.402, Speaker A: You can mock this or whatever, or essentially cut it out and just inject the transactions directly, but probably the database or where the state is coming from is a bit more interesting. And the first option is, okay, since we cannot basically take any external state, any external untrusted input, we basically have to sync from scratch inside our ZKVM. And since for this context we only want to validate one block, this still means we would have to basically replay all the transactions of the entire Ethereum history to come just to the previous state. And that is a lot. That is not feasible. So the second smarter option is, okay, we don't care about the history, we just basically care about the state right before the block is created or applied. So we just basically copy this over from a node that is synced, that has the full state everything.
00:16:14.402 - 00:16:57.714, Speaker A: So that is easy to do, it needs to be verified because essentially this is untrusted. But this is also very easy to do because as I mentioned earlier, basically every block has a commitment to the state. So I would just need to make sure that the state somehow matches the commitment I anyways have in my parent block. Then I would be sure. Yeah, this is indeed the whole state matching this parent, but unfortunately it would still be huge. So we are still talking about hundreds of millions of accounts that the current Ethereum state had. So even that is very big.
00:16:57.714 - 00:17:46.450, Speaker A: So the final idea is we don't need the entire state, I mean only for one block. Only a certain accounts are even touched or even read or whatever. We don't need all the other accounts, right? So we basically want to extract the substate only the part of the state that is relevant. We have to basically extract this and also verify this. This is a bit trickier to do, but it's still possible. And then the advantage, the final goal we achieved here is that that can be very small. So we are then only talking about a few hundred accounts, which is absolutely manageable.
00:17:46.450 - 00:18:42.398, Speaker A: And while doing this, we essentially see we don't need a full ethereum node. A bit simplified, and I guess the ref developers would kill me for that analogy. But essentially the ref is essentially just the EVM, plus a database layer and some networking layer. If we basically say, okay, we don't care about the network layer, that is annoying anyways, and the database layer needs to be remodeled anyways. So what remains is the EVM. So essentially we don't even need the full node implementation, which comes with a lot of baggage. We can focus on the EVM implementation and just for reference.
00:18:42.398 - 00:19:32.930, Speaker A: So we basically then use the EVM implementation that is also used in ref. It is called REVM or Revan. So that gets used 100% in ref and 100% in zath. And that then is much more handleable and reduces code complexity and everything than the actual node. Okay, and with that in mind, this is basically how a zath run would work. So you still need some wrath or some other ethereum node in the background, because you need the state from a sunked node or an archive node. You need that, but that doesn't need to be verified or trusted.
00:19:32.930 - 00:19:40.658, Speaker A: So you can use basically any node you want for that. And then we execute the virtual machine.
00:19:40.834 - 00:19:53.530, Speaker B: Let me interrupt you for a second. There is a question in the chat that I want to bring to the surface that maybe you did just answer, but Austin asked, can't the program take in a state proof or is that still outside of size criteria?
00:19:54.510 - 00:20:43.706, Speaker A: Yeah, that is essentially more or less what we are exactly doing. So the proof that this substate is correct, and you need that because the state is not part of the input that we want to have. This needs to be linked with the parent and how exactly that works. This is then going to be like the topic of the next slide covers the question. Yeah, exactly. So you run the EVM once, and you only run this so that you're able to basically log or trace which accounts, which memory cells are actually accessed. Right.
00:20:43.706 - 00:21:17.682, Speaker A: So this still runs on your regular host. Whatever you use that is not on the ZKVM. And you basically then log. Okay, the execution of this block, access the following accounts, the following memory slots, whatever. And then using that information, you prepare the actual condensed input for the ZKVM. Then you run the ZKVM. On the ZKVM you have to add a verification step, which we're going to talk about next, because you must not trust the state input.
00:21:17.682 - 00:22:05.686, Speaker A: And then you essentially run the EVM twice, they'll be exactly the same output, and then you have the block in the end, and then you have your proof of block creation. Okay, so now we have to talk about how we can prove that, for example, an account is in a state. And for that we have to take a closer look at how a state is stored or handled. In Ethereum. And in Ethereum everything is a key value storage. So you don't have a list of all the accounts. They're always like a key assigned to a value.
00:22:05.686 - 00:23:10.914, Speaker A: And they use a special, very special form for this, which is called like Merkel Patricia trees. If you're familiar with how Merkel tree works, this is more or less exactly the same. It has some very fancy performance optimizations to keep the size small and whatever, which make it much more difficult to actually program or handle. But essentially, from the mathematical point of view, it is exactly the same. One difference being that an ethereum node can have up to eight children, and not only two in a standard binary Merkel tree. And in order to have this key value thing working, what is it, a so called prefix tree? Or try. So for example, the value of the key fape would be so you to find basically the value belong to this key, you basically have to walk down the tree.
00:23:10.914 - 00:24:17.360, Speaker A: You start with an f, then here's ab. So this is basically the subtree you have to look at, and then the e, and then you have reached basically the leaf where the data is then stored. And why is this done this complicated way? And not just like a blob storage or whatever. So the first obvious advantage is that you can just take basically the hash of this route, and then you have the commitment of the entire database, because this depends on all the children and recursively their children and so forth. So just the hash of the root is enough to give you a cryptographically secure commitment to the entire state of the database. So that is one thing, but the other one is also, you can use this to create an inclusion proof. So let's say we want to essentially prove, for example, that fape has a certain value.
00:24:17.360 - 00:25:07.354, Speaker A: So in ethereum, what is the account value? Just in case you're curious, this is the balance, the nons, the bytecode. So actually the computer code and the storage, which is essentially the RAM, you can think of the RAM of that account, and then you can create basically just a miracle proof up to the root. You need to basically follow the path up to the root. And for all the siblings, you just need to include the hash. And then you can use this, you have basically this data, so you can reconstruct this node, then you can hash it. You have here the data already there. So you can reconstruct this node, and then you can just need to check whether that matches the expected route, the expected commitment.
00:25:07.354 - 00:26:00.590, Speaker A: And if it does, you have an inclusion proof of that account, and you can do the same thing to do, non inclusion proofs and everything. Okay, so that is essentially everything what we need. So for Zeth, we basically extract all the accounts, only the needed accounts, right? Then we have those accounts. We could then verify those proofs in the ZKVM and then have the guarantee that the state is indeed correct. But there is one very important optimization that you can easily see here. We're not only checking inclusion of one account, but typically, let's say hundred accounts, and then there is a certain redundancy. So let's say the other account we want to check is ff here.
00:26:00.590 - 00:27:13.080, Speaker A: For example, in both proofs, if you just create them independently from each other, you'd have this hash in here. And for example, if you remember, for this proof of the first of the FApe account here, you had the hash of this one, but you don't need the hash of this one. You actually have the actual real data, so you can compute the hash yourself, so you don't need the hash. And here, why would you need the hash twice? It is more than sufficient to include the hash only once. And an important optimization that we did here is we create this, what we call like a sparse or a partial patricia tree that really is a tree, but only consists of those leaves of those accounts that are relevant for us and everything else. Huge percentage of the tree is pruned by the hashes. And then you can apply the same thing, you get the same guarantees of inclusion and non inclusion, but it is a much more compact representation, as you don't have those duplicates in there.
00:27:13.080 - 00:28:13.130, Speaker A: And with that you can then essentially have the proof. Okay, so now we can actually handle the input. But one important thing that I guess we overlooked so far is there are also state updates happening. So let's say this is the whole state landscape or whatever. And now a new account is created, namely this FCDE account and of course this can happen as part of the execution of the EVM. And then we must add this new node and for that we must know its parents. And it doesn't work if we don't know the parent.
00:28:13.130 - 00:29:54.234, Speaker A: So we have to make sure that this part didn't get pruned even though it was not needed. We didn't need any of those nodes here, but we still have to make sure that this is not replaced by basically pruned but there to the fullest, so that we can then finally attach any changes that might come up. So how do we actually do that? So the diagram here gets a teeny bit more complicated. So we first execute the virtual machine once to basically detect the hot the used accounts. And this is based, let's say we now run this for block n, right? So we are interested in the state of n minus one, because that is the state we are building on. So we have to ask basically a ref node, not only the state at that particular n minus one, but also give us the proofs for all the relevant accounts, right? And then this local execution, as I said, it basically logs all the accounts that are read from, but now it also records the accounts that are written, because those are the ones we have to make sure that those state updates can be processed correctly. How exactly can you make sure that the parent is there? And basically the trick here is it is exactly the same.
00:29:54.234 - 00:30:58.954, Speaker A: If you ask for an inclusion proof in the next, and then in the state after all the transactions have been applied, if you ask for an inclusion proof of this guy, you get the entire path up to the root. So that is exactly what you need to make sure that if this guy is attached, all the parents are there. So it is actually rather simple. Once this execution is done, you basically query all the inclusion proofs for the red accounts. You form a union in some sense, getting rid of those duplicates, getting this nice sparse merkel tree. Then you query the inclusion proofs for the newly created accounts. You get another path and then you basically union them all up into one final tree that you can then use essentially for both for your state proofs.
00:30:58.954 - 00:31:47.870, Speaker A: But also the state updates will work just out of the box without any modifications. Then here in Zeth or in the ZKVM. Yeah, so that is probably the most complicated part in this presentation. So are there any questions concerning this or the Patricia trees in general? Apparently not. So we can also talk about if you have something you can also ask me.
00:31:49.040 - 00:32:15.350, Speaker B: There is a question that appeared in the chat and I would invite people to unmute rather than using the chat, because generally the presenters will have a harder time seeing it and also the video recording won't have them. But I'll read the question that appeared in the chat a moment ago. Oh wait, did it disappear? Am I crazy? There was a chat that question that I am not seeing, but there's one that says why leaf and root values have the same f.
00:32:19.240 - 00:33:00.656, Speaker A: Yeah, I think that was answered in the suba. Maybe I can quickly say about this. So this is what is called a try or a prefix tree. So the value of this leaf is not f is actually ff, because you always have to follow the path from the root to it. This is basically a compression mechanism that you have to store the least amount of data in each node. So you basically use the information from its parents. So this guy is FF actually, and then this guy is not e, but it's actually fape because you basically have to always walk from the root up to the leaf.
00:33:00.656 - 00:33:14.090, Speaker A: And even nodes can have more than one point. That's another one of those compression or optimization mechanisms that are added in Merkel Patricia tries compared to standard Merkel trees, for example.
00:33:17.260 - 00:33:46.450, Speaker C: Yeah, I had one question around maybe like an example. So let's say there was a block that just had like a single transaction, and that transaction was just like an ETH transfer from account a to account b. If we run through the diagram at the bottom, how would that look? Maybe you can take it from here.
00:33:46.900 - 00:34:18.028, Speaker A: Yeah, that's actually a very good question. So just one transfer is definitely the easiest example. So you would run this and then you detect, basically, okay, while executing this transaction. This is a valid transaction. Yeah, the signature is valid, whatever. So it reads from account a, it also reads from account b. And what it then does, it modifies account a and account b.
00:34:18.028 - 00:34:56.410, Speaker A: So it basically subtracts the transfer balance from a and it subtracts it to b. So we have two accounts that are read from. Those are basically, they are relevant. In what state were they before the transaction was applied? So basically in the previous block. So basically this is basically what you'd query here. So you need account a and you need account b, and that's the only thing you need. So you also need inclusion proofs for those two guys, but the rest of the state you don't care about.
00:34:56.410 - 00:36:17.812, Speaker A: And then you also modify those accounts. So you have to make sure that you can modify them even in your condensed, in your sparse try. And the good thing is, if you only modify existing accounts, then this automatically works because you have them already as leaves in your try and there would be nothing needed here. But if we say, for example, you create a new smart contract or something like this, then this account would not be in the account in the try so far, because it doesn't exist at that state there, right? So that is then where we basically have to rely on a full node that had applied this creation. It is then in the new state, and then we can query this new state of this new node. Basically, how does the state try look after this new guy has been applied. And then you know, okay, this comes actually at this position in the try.
00:36:17.812 - 00:36:51.580, Speaker A: And then you have to make sure that also all the parents are in there. So in that example you still have to only get like one inclusion proof for maybe the creating account and then one inclusion proof for the final created account. And then you merge them, you blend them over one another to have the final as condensed as possible. Reduced state try that is then used for our ZKVM.
00:36:54.020 - 00:36:56.640, Speaker C: Thanks, that was really useful.
00:37:01.050 - 00:37:31.502, Speaker A: Okay, then I'll continue. If there are questions, feel free to ask them. We can even go back if you realize something. No issues. Okay, so now that was a bit theoretical. So let's go a bit more into the practical stuff. What actually happens if you compile and run Zath yourself? So here we run Zath for actually this block, the 130 block.
00:37:31.502 - 00:38:11.582, Speaker A: So it essentially queries the block information from this block, which means basically, which transactions did it have. Also other information like the timestamp, extra data, like minor data or whatever it needs to query them. This is input, you cannot know them in before. And then it executes. That is the first execution. It then executes all those transactions. Then, as I said, you basically trace what are the relevant parts of the state, what are the relevant accounts for those.
00:38:11.582 - 00:38:32.046, Speaker A: You then gather the inclusion proofs, right. You might save this in a cache. So that's a bit faster than just querying a random node. And then you're essentially done. This is the first one done. And here you can see some numbers. So the state try, the partial state try consists only of like two and a half thousand nodes.
00:38:32.046 - 00:39:10.222, Speaker A: And we talked about like the full state has hundreds of millions of accounts. So you see what crazy reduction that is. Apart from that, you also have the partial storage tries. We don't need to worry about this. It's exactly the same thing because Ethereum also like basically the memory, the storage of each account is again a try. And you have to do exactly the same thing in that level as well, with the same idea. So you end up with a total of 5000 nodes there, which is a huge compression, but still you don't use any security of this.
00:39:10.222 - 00:39:52.970, Speaker A: Everything, all the data can be proven. So yeah, it is just a compression of what is really needed for that block. And then you have basically the input together. Then at least in the current configuration of zeth, we run this again on the host just as a debugging measure so that we can actually say, yeah, if you run this, you don't get any exceptions. Or you can really check that all the entire block is created the same way. Now from this input data as it's supposed to. That's a bit easier to check and to debug on the host than it is on the ZKVM.
00:39:52.970 - 00:40:45.578, Speaker A: But that's just a configuration, you don't actually need this. And then eventually you would run this as a proof. And then you see the actual input that needs to be transferred to the ZKVM is only everything that you need. All the transactions, all history that all the states, all the proofs is only five megabyte. And if you know how many gigabytes the Ethereum state itself is, otherwise, this is a huge improvement. Yeah, so this is how a run would look in practice. So what is Zath actually doing? So we say it generates a proof of that this block is valid with respect to its input.
00:40:45.578 - 00:41:40.990, Speaker A: And essentially that is depending on the definition, what other projects or other people have called like ZK EVM. So an evm that runs in a ZK verifiable manner. But it is important to note that we are 100% talking standard Ethereum here. As I said, we essentially use exactly the same EVM that is used by full nodes. So we get the same compatibility we get, all the opcodes are obviously working, we use the same gas cost, pre compiled are working. We have the same stack depth like real ethereum. So this is the perfect compatibility that is the real deal.
00:41:40.990 - 00:42:27.534, Speaker A: Or Vitalik and some posts talked about the different kinds of ZK evms. So this would be a type one. Or we called it as actually as a type zero, more as a joke. So it's a type one ZK VM. And how can this be achieved? One way is because I like to think of it as a top down design. Some other project they said they went out and say they actually want to do a ZKe EVM. So they started from that and tried to make all these operations of an evm into some ZK circuits or whatever.
00:42:27.534 - 00:43:40.754, Speaker A: While RISC Zero went actually the entire other way. So we essentially started with our risk zero ZKVM, which is a general purpose ZKVM, nothing ethereum specific there whatsoever. We can rely on all those smart people that did really good compilers or whatever that helped to create good and efficient code for the compatible platform. And we can rely on all the smart developers out there doing like open source rust crates, like the wrath or RevM crates, so we can use them as is, and then basically build upon all of this together. And this is why we get this compatibility with a very small amount of code, or special purpose code, let's put it that way. And then some limitations I want to give you guys here. Currently we're only supporting post merge block.
00:43:40.754 - 00:44:20.562, Speaker A: This is just for clean code reasons. I'd say it would be very easy to extend this, but if you focus only on proof of stake, you don't have to do proof of work, validation or difficulty adjustment. It just makes the code a bit cleaner. And for our prototyping that was something compromised that we're willing to take, but it would be easy to extend no consensus proof. So that's something that I always try to mention, right? The input needs to come from somewhere and it is not. So the transactions, they need to come from somewhere and they're not validated. So essentially they could be faulty or whatever.
00:44:20.562 - 00:45:34.826, Speaker A: So to really get the full deal, you really need to have the consensus proof somehow joined or integrated with this. And also currently no recursive block proofs, you just prove one block with recursive techniques. It would be also rather straightforward to extend this, to join multiple proofs and whatever, but currently, as is, if you run it, you prove just a single block. Okay, and now let's talk a bit about the performance. So we did a lot of optimizations, like the partial state tree being the most important one, but it still is a very complex program. So what can you do, and what happened there to optimize this? And the first point is exactly the same as you see in traditional software development. You write your program in, I don't know, python or go or whatever, but certain very high performance algorithms that are executed over and over again.
00:45:34.826 - 00:46:12.374, Speaker A: For those, it might make sense to look at them more closely and rewrite them in assembly, let's say. So that is then closer to your machine and essentially runs faster, but is harder to maintain. And the equivalent in the ZK world is exactly that. You basically develop specialized circuits for exactly those things. And we are currently using specialized circuits for ECDSA. So that is the signature scheme used in Ethereum, that helps a lot. We also have a special circuit for ShA, which is admittedly not so relevant for Ethereum, since it uses a different hash function.
00:46:12.374 - 00:46:54.290, Speaker A: But still there's a Sha pre compile which benefits from this. So it does have some benefits. And then again, you can do some ZKVM specific optimizations, look at what takes the most time and try to avoid this. For example, it makes a lot of sense to cache hashes you've once computed and avoiding to recompute them. And there's also going to be like talk by, I guess Victor in a few weeks, who talks about the performance of ZKVM a bit more. And all of this comes together. And definitely the most relevant one is continuations.
00:46:54.290 - 00:47:37.810, Speaker A: Also some time ago we had a presentation about this year in the study club, and essentially means it allows us to break huge proofs. And one block is definitely a huge proof into much smaller segments. And those can then attacked by my machines with less memory. And you can paralyze this, and then you just need to join them all together, like recursively, so that you still end up with a single proof. And this actually sounds fairly complicated. And it also is not quite easy. And this is why risk Zero has bonsai available, which basically does this for you as a service.
00:47:37.810 - 00:48:25.198, Speaker A: So you don't have to worry about this. You just upload actually the code and your input, and then Bonsai does the rest for you. If you're interested in this, you can use this link to essentially sign up for it and try it out yourself. And just to give you some example, one block is maybe around 3 billion cycles. This gets cut down into maybe around 3000 segments. And then if you have like 64 gpus available to attack those in parallel, which is something that bonsai typically does, then you end up with a proof in 50 minutes. If you take a bit closer here you see the execution.
00:48:25.198 - 00:48:53.306, Speaker A: This is basically splitting everything up into segments. Takes ten minutes. The first, that is the most difficult one, basically proving each segment takes, I think it's like 35 minutes. Then you have to recursively, basically always join two segments. So one pair, and then you have layers up and up and up, right until you end up with a single one. And so totally, it's about 50 minutes proofs. But that, as I said, bonsai does this automatically for you.
00:48:53.306 - 00:49:39.180, Speaker A: You get one single proof back that has the guarantees that everything, the entire program was correct. Yeah. So that about the current state. And then a bit, let's talk a bit about the future. So initially we developed Zath as some kind of proof of concept to see what the ZKVM is capable of and how performant it is. And that is also one use case. We're definitely going to use it as a benchmark to see if we do like future updates or whatever, that we don't break anything or that we get actual performance improvements going.
00:49:39.180 - 00:50:44.590, Speaker A: There are also some low hanging fruits you could do to significantly improve the performance of zath itself. One thing is, again, this is the beauty, because we can use basically standard rust compiler and standard rust crate any optimizations that we get upstream. So for example, RevM is still under heavy development. They have many great ideas how to improve this. So any new versions coming out there we can essentially just use with invest and profit from the same performance benefit. And then creating more custom circuits would be another one. Two examples would be the 256 bit arithmetics that is heavily used, which is also something that we've done in the past, or something specific for the Ethereum hash function, which would definitely be, which would definitely be the biggest improvement.
00:50:44.590 - 00:51:32.618, Speaker A: And then also use that as a building block to create more complex proof of the entire blockchain, or of layer twos, such as optimism, for example. And I actually have a slide for that particular point. I mean, what exactly optimism is and what roll ups are, is a topic. It's a whole nother topic. So I can only touch it very briefly here. So I try to give you, I don't know, a few sentence introduction to it. So what is a roll up? You can think of a roll up of basically a side chain.
00:51:32.618 - 00:52:24.640, Speaker A: So you start up a completely new chain with its own consensus and its own rules. And you just have bridges enabled that basically make it possible to transfer funds from Ethereum, from the layer one to, let's say the optimism chain, layer two. And this idea is as old as blockchain itself. And it really helps as a scalability solution, because obviously everything that happens on the second chain doesn't need to happen on the first chain. So you have more capacity in total, but it has a huge drawback. And that is you also don't profit from the security of the main chain. Your side chain needs to have its own set of validators, set of miners, whatever, and this decreases the security.
00:52:24.640 - 00:53:13.326, Speaker A: And so what would be ideal? If you can have a side chain that still has the same guarantees as the main chain. And this is exactly what roll ups try to accomplish by essentially compressing and then rolling up. That's where the name is coming from. All data, everything that is happening on the side chain, also onto main Ethereum. And then you can essentially use only the main chain to basically reconstruct any state. And you can do so called like fault proofs, which make it possible to detect fraudulent transactions. But that is the key only from l one data.
00:53:13.326 - 00:54:10.350, Speaker A: And this is where this basically security transitiveness comes from, very briefly. And optimism is one key example for this. And the name is coming from like, it is an optimistic roll up. So there are two alternatives. Like, you can do it optimistically or in a ZK fashion, and without going into any more details, optimism is an optimistic roll up. But they have plans, like in the midterm, to go towards zero knowledge roll up, which has certain advantages. So they opened this RFP, which is supposed to explore how their stack could be zkeified.
00:54:10.350 - 00:55:04.260, Speaker A: And Risc Zero was one of the projects that was selected as a winner in this RFP. And so we're going to provide, essentially, you can look up the exact specifications there, some proof of concept, how the entire P stack could be zkified. And Zath is obviously going to be a major building block in there. So, what needs to be done in order to have this working for the entire op stack? You need to extend Zath to handle op blocks that is actually done already. That is rather easy, because fortunately, optimism blocks are very similar to Ethereum blocks, only some fee changes. So that is already done. Then you need to derive op blocks from l one data in a verifiable way.
00:55:04.260 - 00:55:58.882, Speaker A: That is something we are currently working on. And then basically, as a final building block, you essentially need to not only do this for one block, but need a single proof, having many, many, maybe thousands, or I don't know what exactly op blocks into one block, so that you have just less proofs, so that you don't need a proof for every op block coming out every 2 seconds. But you would only do that every so and so often. But with the recursion capabilities that we have in the Rishero ZKVM or that are coming, this is then also something that should be not too complicated to add on top. Yeah, so that's all I got. Yeah. So we can certainly go into some questions.
00:55:58.882 - 00:56:00.180, Speaker A: If there are.
00:56:03.190 - 00:56:16.550, Speaker B: There was a question that Austin asked in the chat about, if you look at the cycle counts for a typical block, is it like mostly ketchup or what are the kind of major contributors to cycle count?
00:56:16.700 - 00:56:49.570, Speaker A: Yeah, it's a very good question. So, ketchup is about 50%, 50% of the cycles that are wasted or that are done are catch up. And this exactly because we have no optimization for catch up. So this is not very ZK friendly. So that was to be expected. And then the verification is very easy apart from the catcher computations. And then it depends.
00:56:49.570 - 00:57:53.654, Speaker A: We saw one block that was very intensive in like 256 bit arithmetic, that they did some snark verification inside the ZK block. So there was a lot of this arithmetic, but that was only very specific for that block. So I'd say in general, if you take an average over several blocks, it is definitely the hash, the catch our cat. And that is definitely a topic that needs to be researched further. Could you maybe write any ZK bombs or whatever, find some smart contract that is maybe rather easy to execute an ethereum, but that is really the most expensive one to verify. And that would for example have a lot of those 256 bit computations and whatever. So we have to see how expensive that would really be.
00:57:53.654 - 00:58:24.470, Speaker A: But those are like special cases. This is not like the average Ethereum block. Do we have more questions?
00:58:25.580 - 00:58:58.480, Speaker C: I guess I was going to ask a question about the proof generation time and how that relates to say a light client using this technology. So right now it sounds like 3 billion cycles is like 50 minutes. If a light client wanted to use this technology, you'd imagine they would need that proof generation time to be pretty low, right? Am I understanding that correctly?
00:58:59.700 - 00:59:51.010, Speaker A: Yes. So it kind of depends on your use case. Also, you can of course always throw more gpus at it and we can even do that now and get the times down. But still we are in order of minutes and not seconds for certain use case, if you really want to create a proof for every block, you'd need to talk about like one or 2 seconds or whatever. So that is still quite far away. But something that is important to keep in mind, only one party needs to create these proofs because those are just the creation times, right? To verify the proof, that is order of milliseconds. So that is not an issue even today.
00:59:51.010 - 01:00:37.840, Speaker A: And the tricks you can then do, and you would do that. For example, if you want to have like a ZK roll up, you're not interested to have this proof there. For every block you can maybe join 1000 blocks and then use them. And then either those whole batches, valid or not, and you can then basically mix and match how willing you are to accept latency towards throughput and stuff like that. But yeah, it is correct. Of course, the faster the better. And for certain intuitive use cases where you want to prove a block, you would need to get this down to order of seconds.
01:00:37.840 - 01:00:56.496, Speaker A: Cool.
01:00:56.678 - 01:01:32.700, Speaker B: Well, thank you so much for this presentation. It seems like we have reached the end of the questions. Any last questions before we wrap things up? Awesome. Well, I will try to get the recording up online, hopefully by the end of the day, and we'll share on discord when it's up. Wolfgang, this was awesome. I appreciate this a lot. I think having this as a thing to reference in the future is going to be super useful for people who are trying to make sense of this.
01:01:32.700 - 01:01:57.120, Speaker B: And yeah, as we mentioned at the beginning of the talk, we have sessions coming up on. Stephen will be discussing some use cases for ZK in the blockchain space next week. And then the following week, Victor will be diving into some tips and tricks for making your ZKVM programs run faster. So making your cycle counts become lower. Is the details there.

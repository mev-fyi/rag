00:00:00.570 - 00:01:13.634, Speaker A: So generally, our goal is to support as wide a range of use cases as possible. And so our goal is in many ways to try to make programming zero knowledge systems as easy as possible for ordinary programmers. And we also intend to, like we have the Shaw 256 accelerator, add accelerators for other common cryptographic operations that would be too slow to run using the risk five processor directly. Although technically you could technically run anything on the risk five processor, obviously you get huge wins from putting direct support in a circuit for those accelerations. We intend, longer term, to support a generic mechanism for allowing additional circuits to be added and associated with custom instructions within the risk five ISA, because the risk five ISA has innate support for sort of custom instruction extensions. And to that extent, we are interested in supporting as wide a range of things as is possible. Certainly some things are easier, will be easier, or more difficult based on the finite fields that our proof systems ends up using, and so on.
00:01:13.634 - 00:02:16.742, Speaker A: But that said, as much as we can within reason, and hopefully we'll be getting community contributions from this as well. I should also mention, I don't know if we explicitly said it yet, but that all of this does currently already exist and is running. You can actually run these proofs right now, we fully support the RISC five ISA and pass all the conformance tests by the RISC five group. So what we're talking about here is not a thing we're building, it's a thing that we have built by and large. So I'm going to talk a little bit in detail about sort of how we actually implement effectively the actual RISC five circuit, including particularly how we deal with ram, and how we emulate ram within the proof system, as well as a little bit about sort of the structure of our proof system. Our asthma is more or less similar to air, but with some slight differences. So I'm going to cover a little bit of that as well.
00:02:16.742 - 00:03:24.234, Speaker A: So I'm going to make the assumption, sort of, that most everyone is probably familiar at a high level, how starks work. So feel free to ask any questions. So the first thing I wanted to talk about is how we represent the program that the user passes us the elf, and the loading of that within the proof system, as well as sort of the overall structure from a time perspective, to how the processor itself works. So the notion here is that we divide. The starks are naturally sort of divided into cycles, and there's a repetitive sort of arithmetic circuit that relates each cycle to the previous cycle within the execution of a given program in our system. There's sort of this process by which initially there's a special initialization cycle that sort of resets the state. Then there's what we call the program load phase, wherein we're effectively loading the program data for the particular elf into our emulated memory.
00:03:24.234 - 00:04:09.114, Speaker A: And then we sort of do a reset which jumps the program counter to the beginning of the execution. And then basically the actual processor takes three cycles to execute each instruction, which is basically composed of instruction to code, and then a compute load phase and then a register update write to memory phase. What's notable is that effectively we always have at most one memory transaction for each logical cycle, which is important to the way that we actually implement the memory system. That's right. Compile it down to risk five. Exactly. That's right.
00:04:09.114 - 00:04:46.246, Speaker A: Exactly. Yeah. I think one of the great things about this is that by using this sort of mechanism, we then look like a normal computer to people, and people can reuse existing software. We're reusing a huge amount of the existing tool chain in terms of compilers and language support. And I'll also get into a little bit about the way in which we do the interactions between the system running inside the proof system and the outside world, because that's obviously an important how you talk to the oracle and so on.
00:04:46.268 - 00:05:04.270, Speaker B: I should have mentioned this also, Jeremy, you can mention that on our website, not in GitHub, there's like a full write up of how the battleship example works, which sort of is like, if you want to go home and read more about this, this will sort of reinforce your reading of that particular explainer.
00:05:06.290 - 00:06:14.526, Speaker A: All right, so one of the things that's notable is that in your stark, there's typically a set of columns which represent sort of like a hardware register, if you will, over time, every given cycle, that each of those columns has a value. We actually divide the set of columns that we use into three distinct groups of columns, and each group of columns actually is put into a separate Merkel tree. So the first set of columns are actually what we call the code columns, and those columns represent public data that is known to both the prover and the verifier. And this is actually where we encode both the control sort of flags that say, okay, well, this is the initialization cycle. These are the load cycles. These are the sort of three cycle structure of the execution, as well as where we put the actual elf data that's to be loaded. And so by doing that, we're basically able to put all of our sort of control logic into that set of columns.
00:06:14.526 - 00:06:53.154, Speaker A: And that's part of the Merkel tree that is checked in the proof system, similar to the main data Merkel tree, but because they have different Merkel roots. As a result, we end up having to prove two Merkel paths instead of one when we're doing the verification. But what that allows us is it allows us to fit a huge amount of constant data in and make the proof system be able to make use of all of that, which is important, so that otherwise we'd have to say, for example, prove that our code hashes to some value, which would be much more expensive. Right. So that's kind of a good trick. There maybe a related question on the chat. Yes.
00:06:53.154 - 00:07:46.034, Speaker A: Do you also implement control and status registers? So interestingly, the RISC five. Oh, the control status registers within the risk five architecture. Yeah. So currently we don't, although we are going to add support for the, because we only operate in user mode effectively, and the normal mechanisms by which one calls into the system modes, we actually just implement, as that's what induces the termination of the program. That's like affecting the halt instruction. In our next version of the circuit. We do intend to support the CSR registers, including the standard sort of timer registers, as well as we don't intend to support the full the system mode, but we also do intend to use the normal system call mechanism to do our interactions with the external world.
00:07:46.034 - 00:08:40.820, Speaker A: Currently we use this memory mapping trick to do our external world follow up question on this. Is the program by default a public input? Yes. So the program is by default a public input. Now, technically the only thing you need to do the verification is the Merkel root of the control set of columns. So in theory, one could, for example, pad your program with a bunch of extra random bytes and then generate the appropriate Merkel route. But certainly the prover needs to know the program, and the verifier needs to know the hash of the program's sort of control traces in order to do verification. So you could technically verify a program that you don't know what the program is.
00:08:40.820 - 00:08:43.698, Speaker A: None of our use cases do. We make use of that back.
00:08:43.784 - 00:09:11.200, Speaker B: All right, although I will add just briefly that you can imagine use cases where some, say governmental or otherwise trusted body audits a bit of code and attests to some bit of code having certain properties, and says this code that has this hash has these properties. And then people could run it, prove that the results come from this bit of code without necessarily ever revealing the code. But that's like, I don't know, future use case.
00:09:13.250 - 00:09:52.890, Speaker A: So then the next set of sort of columns represent the sort of standard columns you'd have in any sort of a stark. And they hold the state of the risk five during execution, and they also hold the information necessary to do the memory transactions, as well as the memory verification, which I'll get to in a bit. And then we basically have the effectively accumulation set of columns, which basically hold products for the Planck permutation verification mechanism. So we use basically a Planck style way to prove a permutation, which is used as part of the memory consistency evaluation.
00:09:55.070 - 00:10:00.438, Speaker C: Anything in the risk five instruction set that's not supported in the control side?
00:10:00.544 - 00:10:24.942, Speaker A: No. Well, so currently we fully passed the risk five compliance test for the r 32, vm or IM. Yes, thank you. Aside from the. For the user space set of instructions, we fully support them all. Some of them are no ops. Like, for example, the memory fence doesn't do anything.
00:10:24.942 - 00:10:56.218, Speaker A: Right. But it does. Yeah, but yeah. Generally you can literally compile down random C code. You can actually even use floating point, because we actually support a very basic version of Picolib C. I can write a bunch of floating point code and it'll get converted into soft float and put into the system. We actually are seriously considering in the next version of the circuit, adding the proper floating point extensions.
00:10:56.218 - 00:11:39.450, Speaker A: Because with Flukup now, I think that the actual FP unit, while an annoyingly complex engineering task in terms of the total size expansion for the circuit, isn't super huge. And one of the nice things is because the circuit definition itself is part of the verifier and the prover, we can actually have different versions of the circuit. So we could, for example, have optional floating point support. So if you want to use a lot of floating point, you pay for a bigger circuit, but then your floating point is much cheaper. If you don't have much floating point, you can use the smaller circuit that doesn't have the FP support as part of the reason, largely rISC five as the architecture was sort of just sort of lucky. It's just a very nice modern architecture. It's modular.
00:11:39.450 - 00:11:55.786, Speaker A: It's really built for having the minimal set be implementable on a tiny amount of digital logic, which means that it's also implementable in a tiny amount of arithmetic circuits. It's not like the most perfect architecture for ZK, but it's actually pretty reasonable.
00:11:55.898 - 00:12:08.434, Speaker B: I actually have a question now, Jimmy. What's the size of the risk five circuit relative to, say, shaw accelerator? If you don't care about recursion on blockchain how much smaller does that circuit get?
00:12:08.632 - 00:12:28.010, Speaker A: I think that I don't have an exact number because I haven't actually measured that. But my guess off the top of my head is that the risk five circuit is probably about 60% of the circuit. Wow. Okay. The shy accelerator does take, actually, a fair amount of constraints, because it's not trivial. Yeah, that's a very good point. We should really make that optional.
00:12:28.010 - 00:12:56.802, Speaker A: Genius. All right. I don't know why that never occurred to me. All right, so I wanted to talk now in detail about sort of the mechanism that we're using to do the memory validation. So, as we mentioned earlier, we're effectively doing at most one memory transaction per execution cycle. And honestly, if we don't have a specific memory transaction, we just do a read of memory address zero or whatever as a default. So there's always one memory transaction per cycle.
00:12:56.802 - 00:13:28.126, Speaker A: So there are two sets of columns. They're both in the data section. One of them is the sort of memory operations, and those occur in program order. And so there's a sort of cycle of which logical cycle this is, and that just moves forward monotonically. And there's a constraint that that always moves forward monotonically. And then there's basically the address, the data, and a write read write flag, which, of course have constraints that are hooked into the rest of the circuit, basically.
00:13:28.308 - 00:13:31.438, Speaker B: Just real quick, Jamie, if you do.
00:13:31.444 - 00:13:32.942, Speaker A: This, you can like, oh, yeah, there you go.
00:13:32.996 - 00:13:35.146, Speaker B: Do a pointer thing that everybody will see. And hopefully.
00:13:35.258 - 00:14:21.114, Speaker A: There we go. Yeah, so this is the cycle. This is the normal ordered. So this all happens in cycle order. And so what we're saying here is, okay, at time zero, I'm going to do a write to address three of the value 17. And then at time one, I'm going to do a write at the address seven of the value three. Then, of course, later, I'm going to read from address three, and I'm going to read back 17, or at least I should, assuming memory is valid, right? So what happens is, during the initial program execution, we generate these columns, and we just model memory externally, right? Then what we do is after execution, we do a sort of all of the values in here into this sort of verifiers, this sort of second copy of the memory transactions.
00:14:21.114 - 00:14:53.338, Speaker A: But these are, instead of being sorted by cycle, are sorted by address first and cycle second in lexographic sort order. What that means is that all of the memory transactions that occur on the same address are all now located next to each other, and all of them are in proper cycle order, at which point, basically, it's possible to quickly verify the validity of the memory transactions. Oh, wait, you know what? This should actually be a one, shouldn't it? Yes. Oh, shoot. I guess I can't edit this document while I'm doing this. Sorry. This is a one.
00:14:53.338 - 00:15:19.940, Speaker A: This is a one right here. Yes. What you'll see is we write 17, then we read it twice, and then here we write two different values and read it. And interestingly, the requirements for the verified verifier are basically written here. They're actually fairly simple. If the addresses are the same, then we have to verify that the cycle is moving forward. And if it's not a write, we have to make sure that it matches whatever the previous value was.
00:15:19.940 - 00:16:23.878, Speaker A: And then also that otherwise, if they're switching between addresses, the only thing we care about is the addresses are going up. You will note, by the way, that this allows an initial read prior to a write to return any value whatsoever, which we actually take advantage of. Basically, reads of values never written are in fact undefined, and we use that actually as a way to interact with the external world. So basically, in addition to, besides the set of constraints that represent the verification of the resorted versions of the address, we also have to prove, of course, that these two different tables are in fact permutations of each other, which we do using the sort of plonc permutation argument, where we basically commit to the entire state of the data trace Merkel tree. And we use that and the Pyatshmere sort of mechanism to then pick a set of ways of. I won't go through the Planck argument in detail. I'm sure people have read the paper.
00:16:23.878 - 00:17:10.786, Speaker A: If not, it's a great paper. At any rate, there is a question on the chat. How do you efficiently check the inequality? If we don't efficiently check the inequality, what we do is we subtract and then we bit decompose the. So if we want to prove that a is greater than b or greater than equal, say we take a, we subtract b, and then we bit decompose it and prove that it is a 20 bit number. And so since our field is like 31 od bits, if they're the wrong way, then it's not a 20 bit number. And so it failed to constraint check. Now, we're going to replace that with pluckup, which will allow us to very rapidly do that with a much smaller number of columns and a much smaller number of constraints.
00:17:10.786 - 00:18:04.130, Speaker A: But right now, we actually spend like 20 columns for the bit decomposition of the subtractant, and we actually reuse the. So, interestingly, we use the same set of columns for these two different cases because they're never simultaneously true. Right. So there is a fair amount of. Given that we already are using plonk for memory verification, you would think that the idea of pluckup would have been self evident to us when we were writing this the first time, but it was not, unfortunately. So we're building a new version of the circuit for that next slide here. So I want to talk a little bit about how we do the interaction between the actual ZKVM, which we call the guest, in sort of standard virtual machine kind of terms, and the sort of prover, which is the host, from sort of a normal term.
00:18:04.130 - 00:18:26.058, Speaker A: So let's say we want to have the guest send something to the host. Well, the guest just writes to an address that is a particular, well known address, and the host is like, oh, yeah, I see you right there. Right. Because obviously, it's just running an emulation. The host can see the whole world. So trivial. On the other hand, if we want to get something from the host to the guest, then the guest reads.
00:18:26.058 - 00:19:31.026, Speaker A: There's a region of memory that we set aside for host to guest communications, and the guest keeps track of a pointer, and it keeps bumping that pointer and reading the next address. And as it reads those addresses, since those addresses have never been written to before, they're uninitialized, any value is allowed to be returned. And so, right when that address is read, at that moment, the host will decide what it would like the guest to read and places that in there. We use this to basically generate what is effectively a sort of a private two way stream, which we actually. Currently, we have sort of our own sort of read and write calls, but we're actually going to move that to actually inside of Lib C, so that they'll actually be like real things that look like file descriptors that you can read and write to, to talk to the host of the guest and things like that. And then we're going to also implement a number of other sort of systems on top of that. I probably won't go into detail that, but if anyone's interested in how we can build something that looks like a file system inside of a zero knowledge proof system, we do actually have a plan for that.
00:19:31.026 - 00:19:57.210, Speaker A: Even so, I don't think. Do I talk about. No, I didn't get the slide. Yeah, this is Booth. I think that's it. The only other thing I wanted to mention is it's not explicitly written here, but I think it's one interesting note on the model is that the other sort of interaction between the proof system and the outside world is this thing we call the journal. So basically, there's another region of memory that the guest writes to.
00:19:57.210 - 00:20:46.954, Speaker A: And at the termination of the guest from the normal execution, we go into the Sha accelerator circuit, where we shaw up that region, and that ends up coming onto the output of the proof. So effectively, basically, if you want to talk privately to the host, you can read and write to these sort of logical streams. And then there's also this other region that you can write things you want to be publicly known, and then those get basically emitted, and those become part of the public record. So when you provide a proof, you're basically showing what is the journal? What did this thing write to the journal? What is the code that this thing is running? And then a bunch of sort of opaque cryptographic goo that basically allows you to verify the correctness of that. Cool.
00:20:46.992 - 00:20:53.018, Speaker B: Are there more questions right now? Otherwise, Tim is going to talk about formal verification, actually.
00:20:53.104 - 00:21:16.834, Speaker C: So one thing that's not given is normally when you write for a zero knowledge proverb, you don't do computations, you provide witnesses that things were done correctly. So you're writing a verify. For example, if you see code, like in your battleship game, maybe there's battleship games, not the greatest example, but imagine you're sorting algorithms. You would never implement the sorting algorithm.
00:21:16.882 - 00:21:18.150, Speaker A: Inside of the circuit.
00:21:18.490 - 00:21:19.560, Speaker C: Sort outside.
00:21:20.890 - 00:22:09.494, Speaker A: Yes. The way we do that is that if you wanted to, for example, we're actually just talking about trying to get a compiler to fit inside of the knowledge system. And one of the examples that comes up is, well, register allocation is very expensive and complicated, but verifying register allocation is actually a lot cheaper. Right? So you can use this sort of non determinism mechanism in any of these things. And the way that that works in terms of how we implement that within the ZKVM, is that inside the guest code, inside the ZKVM, the ZKVM will write to the host saying, hey, I would like you to solve this problem. And at that point, by the way, the host can just read in any location and in memory to see whatever it needs to see. And then the host will write back the result, which the guest will read, and then the guest will verify whatever it is.
00:22:09.494 - 00:22:47.326, Speaker A: Right? So we're still in the process of building sort of a set of wrappers. Like, for example, we've been considering in rust, having a macro mechanism where you can say, you basically decorate that this method is meant to run on the host and then sort of kind of do all of the back and forth between the host and the guest so that you can basically say, okay, well, this is what I want to run and this is how I want to verify the thing I ran. Right. And so you can basically do these sort of blocks where you're like, allow you to do that acceleration kind of technique.
00:22:47.358 - 00:22:54.546, Speaker B: I guess you could then implement parts of the c plus plus standard library too, if you wanted to, and have various sorting algorithms or whatever.
00:22:54.568 - 00:23:10.598, Speaker A: Yes, exactly. You could do yesterday, sort. And then you say, okay, here I want to call sort the actual host, or the guest is, sorry, host is going to do the sorting. The guest is then going to place that back into your memory and then you're going to do a quick walk through it to verify, although I guess.
00:23:10.684 - 00:23:16.858, Speaker B: Sorry. Yes, but we just use file descriptors. Eventually you write all of your list you want sorted to a file and.
00:23:16.864 - 00:23:36.834, Speaker A: Then you do that. Yeah, absolutely. So there's all kinds of ways to, there's all kinds of ways to do that. Our fundamental listers is figuring out how to get as many of these metaphors to be as easy for developers to use. Right. Currently we don't really do a lot of these. Like the battleship game, for example.
00:23:36.834 - 00:24:20.858, Speaker A: The way it works is that you read in where the user wants to place their ships, and then we just verify that that placement of ships doesn't have any ships overlapping. It has all the ships, none of them go off the edge of the board. And if any of those things are the case, there's sort of an abort that we define. An illegal instruction will make it impossible to produce a proof, because if you execute an illegal instruction, the circuit will fail. And so then it's impossible. So what we basically do is we basically say, oh, well, if you have a bad board state, then abort, otherwise terminate normally. And then basically you have a proof now that the user has committed to where to place their ships.
00:24:20.858 - 00:24:33.460, Speaker A: And then we basically, as we write to the journal, the hash of that ship placement plus hidden secret so that you can't do hash inversion on it. And I guess Bob's your uncle. Right.
00:24:35.290 - 00:24:49.670, Speaker C: The other question I had. Sorry. So I think I asked you on the way here, so why choose the risk architecture? For example, risk has all these registers which you couldn't care less about.
00:24:49.740 - 00:24:51.386, Speaker A: You don't need registers here. True.
00:24:51.488 - 00:24:53.100, Speaker C: Why not rip that all out?
00:24:54.590 - 00:25:32.242, Speaker A: Yeah. So the question is, why pick an existing ISA as opposed to basically building a ZK specific new ISA. And honestly, the answer to that is some back of the envelope shows we probably only are losing like two or three x performance by using something that already exists. And now all of our tool chain is already done. So it's primarily a time to market thing and an ease of understanding for existing programmers. Like right this second, I now have a huge library of rust code that already compiles and works in this system. Right? No one needs to port any code, no one needs to build a new compiler backend.
00:25:32.242 - 00:26:22.294, Speaker A: All that's done. Now, at some point maybe it would make sense for us to build an LLVM backend that supports a new architecture that is specifically optimized for zero knowledge proof systems and then implement that architecture and implement the LLVM lowerings. But there's a lot more engineering to do for that. And at the end of the day, what's cool is that if we are using something that's a normal architecture like RISC five, and people thus program in normal languages like Rust and C Plus plus, if we do end up switching to another architecture, most of that code should port across effectively. To be honest, I do think the total cost of using risk five is actually not particularly huge, and it's a big accelerant in terms of time to market.
00:26:22.412 - 00:26:25.826, Speaker B: Yeah. You can also mention the existing battery of tests.
00:26:25.858 - 00:26:27.174, Speaker A: Oh yeah, that's another huge thing, right?
00:26:27.212 - 00:26:31.670, Speaker B: The tool chain and the extension mechanisms and all these things are well supported throughout the tool chain.
00:26:31.750 - 00:26:32.282, Speaker A: Yes.
00:26:32.416 - 00:26:34.682, Speaker B: And actually there's quite a large accelerator market.
00:26:34.736 - 00:26:39.706, Speaker A: There's a formal description of what it means to be risk five. So we can actually formally verify that.
00:26:39.728 - 00:26:41.574, Speaker B: Our ISA, which is a perfect segue.
00:26:41.622 - 00:27:22.150, Speaker A: To three more questions on the chat. Sure. The first one, can you share any tricks you use to implement SHA 256? Oh yes, we need to do a write up on. Yes, I've heard this question enough that I do think we should do a write up. The short version is that if you look at the state of shot 256, there's sort of a set of registers that there's eight of them, and most of them are sort of like shifting back every cycle. And then two new elements are created. If you unroll that in time so that you place effectively two elements, you make two new elements every time, and then you read back some number of cycles.
00:27:22.150 - 00:28:12.082, Speaker A: So the one thing about Starks is they have this repetitive structure, but most of the time people only go back one cycle in starks, but you can go back as many cycles as you want. And so if you unroll the Shaw 256 in time, you actually only need to produce, regenerate two new registers. It doesn't take very many columns, and then we basically bit decompose them. So we basically take 96 columns, which gives us the two new registers, a and D plus. Also there's this w register, which is related to itself. Basically, you basically take those 96 bits and then we can fit everything into rank three constraints and you take 60 cycles or something, or 68 cycles to do a full shot or not. One round, one compression.
00:28:12.082 - 00:29:02.854, Speaker A: One full compression. The second question on the chat is, how do you compare to tiny brand? So largely, the idea of use of von Neumann architecture, using sort of zero knowledge proof systems that Tinyram does, is very similar. The primary differences are that we are implementing an existing ISA as opposed to some new ISA, and then also the way in which the permutation validation was done on that was a beneath network or banesh network. How do you say that? Whereas in this case we're using the Planck. So the Planck mechanism for verifying the permutation is massively more efficient in terms of prover time as well as verification complexity. But at the heart, the conceptual notion of verifying ram via permutation is similar. And there's the last question on the chat.
00:29:02.854 - 00:29:40.534, Speaker A: Is there any limitation on the recursion call depth? No, it's just emulating a normal risk five processor. We only have two megs of ram, so your stack can only get so big. And of course also the finite field for the ffts, there's a maximum number of cycles you can run within a single instantiation before you. But effectively we're not doing any tricks with control structures or anything. It's literally just random machine code. Like you can do indirect jumps, you can actually do self modifying code if you wanted to. Now, we actually.
00:29:40.534 - 00:30:14.190, Speaker A: Yeah, it's read from ram, right? So you read the elf into ram, and then if it's in ram, you can modify it. Now, technically, we actually have two different regions of memory, one which is write once, which is what we use for the program codes, so that we actually will seg fault if you try to write to your own program code, because we think that the chances that someone wants to correctly use self modifying code versus someone's being hacked by self modifying code would probably err on the side of making it not writable. But in theory, one could in fact generate code in the data segment and then jump into it, and it would actually work the whole nine yards. It's like a real von Neumann machine.
00:30:14.350 - 00:30:16.558, Speaker C: What was the biggest number of cycles.
00:30:16.574 - 00:31:12.050, Speaker A: That you can handle? In civil proof, our finite field is 15 times two to the 27 plus one. And we do a forex expansion. So that means we have two to the 25, so what, 32 million cycles, and there's three cycles per instruction. So about 10 million instructions is the maximum you can do in our current proof system. Now, I think the next version of the circuit we're going to switch to using the so called Goldilocks field, although that was also used for a previous field. But in this case, it represents the field two to the 64 minus two to the 32 plus one, at which point we could do larger proofs. I think you mentioned something like shar accelerator.
00:31:12.050 - 00:31:50.014, Speaker A: No, what I mean by that is, it is a component of the arithmetic circuit that sits next to the arithmetic circuit that represents the stepping of the RiSC five. When you do a shot 256, there's basically some weird dance you can do where you sort of execute certain instructions and poke certain memories. That basically induces the machine to verify a shy inside the circuit. But none of our stuff involves any hardware acceleration. In real hardware, it's all the imaginary, sort of. Right.
00:31:50.132 - 00:32:13.058, Speaker B: It's like you're making just like any standard microcontroller like microprocessor these days has like who knows how many functional units actually on the die. This is basically a mechanism to make new functional units on your arithmetic die and then call them like you would in your standard gigantic intel chip.
00:32:13.154 - 00:32:31.770, Speaker A: And notably right now, all of our stuff runs on cpu multithreaded. In terms of the open source implementations, we do have non open source implementations that are GPU accelerated that make the proof system significantly faster using gpu acceleration. But otherwise, everything else we've got is open source Apache two license.
00:32:31.930 - 00:32:33.806, Speaker C: 10 million cycles was for GPU or.
00:32:33.828 - 00:32:42.080, Speaker A: For 1 million cycles per second was for. That was for GPU. Yeah, it's about 30,000.
00:32:43.330 - 00:32:57.126, Speaker B: Yes, the number of cycles is constant. It's 10 million. Because of the finite field, the speed of the emulated circuit is 10 gpu, or 30 running time.
00:32:57.148 - 00:32:59.030, Speaker C: So if I do have a program that runs.
00:33:01.770 - 00:33:11.260, Speaker A: Like on the order of 20 seconds, I guess, was that right? No, well, it depends upon. Yeah, it's about right. Yeah.
00:33:11.870 - 00:33:19.274, Speaker B: The faster slow. Make sure Tim has time to.
00:33:19.392 - 00:33:57.650, Speaker A: Let's do it. One more question from the chat. Doesn't the planck argument depend on being defined over a very large field, much larger than the degree of polynomial? Correct. And what we do is for the Planck arguments, so we use a small field for most of the circuit. But then when we do the deep alley component of the stark proof, as well as for, as well as for the fry, we use an extension, a field extension in our case, because we're using a fridge bit field, we use an extension field extension before, and we're basically targeting about 100 bits of security in our current implementation speed.

00:00:00.170 - 00:00:05.360, Speaker A: Still talk. We always start doing going immediately, and everyone's like, what is happening?
00:00:10.530 - 00:00:15.166, Speaker B: Okay, whatever. I'm going to start. So you guys ready?
00:00:15.348 - 00:00:16.080, Speaker A: Sure.
00:00:16.770 - 00:00:17.566, Speaker B: Okay.
00:00:17.748 - 00:00:18.720, Speaker C: Of course.
00:00:19.890 - 00:00:57.134, Speaker B: Everyone, welcome to the third episode of the Research Hour series hosted by Uniswap Labs. I'm Shin, researcher at Uniswap Labs and co host of today's conversation. With me here is Austin, my colleague at Labs and co host for the space as well. Uniswap is the largest marketplace for on chain digital assets. The tools we create are built on the Uniswap protocol, which is governed by an independent and decentralized community of Uni token holders. And today is the largest decentralized trading protocol to date. The protocol has served over $1.5
00:00:57.134 - 00:01:49.310, Speaker B: trillion of transactions across multiple blockchains and never been hacked, making Uniswap one of the most trusted names in DFI. Uniswap Labs is focused on building technology that enables users to swap tokens by NFTs, provide liquidity, and self custody their assets with confidence. The opinions expressed during today's conversation will be ours personally and not that of the labs. Our guest today is Jason Milianis. Jason is a second year PhD student in the computer science department at Columbia University. Jason's research focuses on game theory, especially in conjunction with machine learning and decentralized finance. Jason has written six papers on AMMS and two others on NFT auctions, with potentially many more to come in the past few months.
00:01:49.310 - 00:01:55.700, Speaker B: Jason has been a research fellow at Uniswap Labs and was a great pleasure to work with. Jason, welcome.
00:01:56.550 - 00:02:04.098, Speaker C: Thanks, Sinan, for having me. It's a pleasure to be here. And pleasure to have worked with you also. Cool.
00:02:04.184 - 00:02:09.110, Speaker B: First question why are AMMS and NFTs interesting to a game theorist?
00:02:10.970 - 00:03:29.386, Speaker C: That is an excellent question. So I think that in general, the crypto space is very exciting. It's full of interesting and completely novel research problems that really, once we dig deep into them, they can lead to fundamental contributions in significant domains of both computer science and economics, one of which is game theory that you mentioned. So if you ask me then why game theory, then what I can tell you is that essentially, game theory can offer what we are largely missing in the crypto space. And we've already started kind of incorporating through research, and in particular, we can account for incentive compatibility issues. So this allows us to both analyze and shine light on often ill thought aspects of various designs as they play out with strategic participants, and they can help us prepare in advance for such issues. So the interesting thing for me as a game theorist within this space is basically that you have novel problems that kind of illustrate the problem of incentive misalignment that is central to the study of game theory.
00:03:29.386 - 00:04:40.630, Speaker C: And this basically dates all the way back to the first selfish mining paper by a Yal and Sirre. Essentially, no one expected that 51% is actually not the attack threshold for Bitcoin, but that it is even lower. And the thing that came up there is the common theme in the whole Game Theory. So that is that essentially when you have self interested participants that only optimize for themselves and they don't care about the social welfare, let's say, so the total welfare of the protocol, then essentially the incentives that they have can lead them to behave differently and potentially unexpectedly or even maliciously, you could say under some notion of behavior that you might have in mind. So you can use Game Theory, and in particular the mathematical tools and theoretical analysis to basically properly align the behavior of these participants. And so this is what has been most interesting for me in the space and the new problems that this space also contributes to game Theory fundamentally.
00:04:42.090 - 00:04:50.746, Speaker B: Got it. Jason, are you on any particular speaker? Because I think there is some noise that both Austin and I can hear.
00:04:50.928 - 00:04:57.100, Speaker A: Yeah, you should be able to go to the settings under, make sure it's the right mic. Sometimes guests have issues with the mic.
00:04:58.830 - 00:05:06.400, Speaker C: Let me check that out real quick. Can you hear me better now?
00:05:07.010 - 00:05:09.598, Speaker A: Yeah, now it's okay.
00:05:09.764 - 00:05:11.840, Speaker C: Okay, sounds good.
00:05:14.290 - 00:05:30.600, Speaker A: All right, perfect. Now we'll sort of go to the next one. So we had CMAC on for the first episode. He gave us sort of a wonderful overview of lever. So as another author on the paper, how would you describe it from a different angle than him?
00:05:32.170 - 00:06:53.070, Speaker C: So I think we kind of have a common understanding in that regime. So actually, maybe to recap a little bit for parts of our audience that may not be familiar with lever, that's basically a sense of losses for liquidity providers, automate, market makers. Essentially, when you're thinking about providing liquidity in a market, you have to think about both the upside and the downside. So the upside is clearly the fees that you're receiving, but the downside is basically more challenging to think about. And so in our paper with Siamak and team, we said, okay, what else could you do apart from providing liquidity so that we can figure out your theoretical loss that you'd have by providing liquidity in this market? And now a common metric to kind of measure that is permanent loss, which basically focuses on a binary choice. So you either LP or you hold a position fixed. And so what we are saying with our paper is that there are so many things that one could do that why should my alternative essentially only be to hold the position fixed? So if, for example, I'm a smart guy, let's say I might decide to do all sorts of crazy things in my strategy.
00:06:53.070 - 00:08:11.530, Speaker C: So what's the common factor of all these things? All these things essentially involve what's called the market risk. So does the price go up or does it go down? So the idea is that in order for your comparison of providing liquidity to some other strategy, to be kind of fair, it should be done in the way that you can do your crazy thing on the side, but essentially providing liquid should be separate from this smart strategy you're implementing. And so in other words, to evaluate providing liquid on its own, I have to remove all market risk. And it turns out in our paper that there is a unique way to do that and this gives rise to our metric in that paper lever. And now there's many interpretations to lever and I don't think we could finish today if we recount them. But the critical one essentially for this kind of work is that lever kind of measures the maximum adverse flow or otherwise known as toxic flow that you as a liquidity provider might be getting through the AMM. So in this way I would say that lever is essentially showing how advanced your counterparty in your trade in the AMM could be in the worst case.
00:08:11.530 - 00:08:43.650, Speaker C: So the higher the lever, the more sophisticated counterparties you're going to encounter. And now there is something that we should pay attention to here and that is that this does not mean that if you have higher lever then you are strictly worse off just by definition because you might also be getting more of the positive upside that we said before the fees. But in general, my view with lever is that essentially it accounts for your worst case order flow toxicity that you're getting in your AMM.
00:08:45.750 - 00:09:12.830, Speaker A: Yeah, so we sort of thought of an orthogonal metric to that, which is Flare, which is a paper that sort of came out at the beginning of this week on Monday and we framed it as sort of a metric that is orthogonal to lever but is still sort of helpful in understanding LP returns. Essentially you're telling us what is flair and how is it sort of related to lever for the audience.
00:09:13.890 - 00:10:10.394, Speaker C: Yeah, sure, of course. So we're in the business of making names here. Sounds like it and I know it sounds like a mouthful, so let's slowly decompose it into its components. So basically the acronym Flare stands for Fee Liquidity Adjusted Instantaneous Returns. And so the key idea with our work is that basically you need a way to really not account for all the fees that you're getting in the pool, but only for this portion that was actively used or received. By a liquidity provider or by the confluence of liquidity providers, let's say, in the pool, as well as these liquidity providers efficiency in using their capital to capture this portion of fee. And so this metric that we came up with is essentially complementary to lever.
00:10:10.394 - 00:11:22.006, Speaker C: And in some way it's orthogonal to this because lever can be used to essentially evaluate the counterparty, the trader that you're essentially getting. So primarily concentrating on the information and balance that you're getting between that of the liquidity providers and that of the traders. But it doesn't sort of give you a way to account for the competition of liquidity providers within the same pool. So for a simple example for that, you should think that essentially some liquidity provider who's constantly adjusting their position within the pool might be able to capture the fees that the traders are giving to the pool much easier than one who is essentially being static through the entire pool. And so essentially, these active sort of liquidity management strategies, they're not captured well by just your adversary. You need to look within the pool to account for them. And so flair does that.
00:11:22.006 - 00:11:36.620, Speaker C: So Flair sort of measures the return on capital that you can have on the fees, looking into the microstructure of each pool. So that would be my take, if you want, with this.
00:11:37.310 - 00:11:52.960, Speaker A: Yeah, it's a good take. We sort of think it's very valuable as well. Could you reset your mic again really fast as well? I don't know why it's sort of having issues today. Maybe it's like a noise canceling issue or echo cancellation issue.
00:11:55.330 - 00:11:55.994, Speaker C: Is it okay?
00:11:56.052 - 00:12:04.900, Speaker A: No, I'll let Shintai in the next one. Yeah, now it's good. I'll let Shintai maybe just sit a little closer. That might be good. And I'll let Shintai in.
00:12:05.850 - 00:12:13.750, Speaker B: Yeah. Okay. Quick question. Who should care about flare?
00:12:15.530 - 00:13:30.110, Speaker C: So that's actually a good question. I think the overarching goal with our work is essentially to be very useful to practitioners who actually want to evaluate LP returns and maybe also design better markets to essentially capture fees or essentially increase competition in the pool. So for practitioners, I think what would be interesting in this sort of work is essentially to help explain aspects of the LPE returns that you're seeing. For example, actively providing liquidity, or as it's called, JIT, so just in time, liquidity provisioning. And as well, essentially, you can use this tool to help you design better markets, so basically see how you can make everyone more competitive within the same pool. I think these are the most interesting aspects, and I think it's a metric that practitioners will find extremely useful.
00:13:31.490 - 00:14:00.730, Speaker B: If you look at the formula for flare for a single position at one point in time, it looks like it's just the fee it receives divided by the amount of money it's in the pool. So is flare just fee? Is it different? How is it different? And what's our research contribution here to the literature?
00:14:01.710 - 00:15:03.582, Speaker C: Yeah, I think that's an excellent question to have. By the way, can you hear me with the mic? Is it all right? Yeah. Okay. So basically the idea is that there are various flavors of flare, let's say, within the pool. And flare is essentially capturing the efficiency that your capital can capture fees with. And so these various flavors of flare, one of which you mentioned, are not only designed to kind of account for your capital efficiency, but they're also designed for a variety of other things. So, for example, to measure any number of LP positions over an arbitrary period of time, including a single point in time, this is where the instantaneous comes from.
00:15:03.582 - 00:16:03.870, Speaker C: And so essentially you can use this metric not only to account for the return on capital of various LPs, but to also attribute the historical performance within pools to specific LPs. And also for new positions. You can also use it to back test some LP strategy that you might think would be good to have or even optimize new liquidity development in general. So in this sense, it's kind of like we're building a portfolio optimization story over here and I think that's one of the contributions of our work. So to recap, I don't think it's just fee. It has a variety of other uses and I think it's going to be very interesting, especially from the optimization side for new strategies.
00:16:05.490 - 00:16:16.470, Speaker A: Yes, I guess on that lines and a question from the audience, it's also sort of the same. It's very similar to what we wanted to ask. What does flare not take into account, essentially?
00:16:18.970 - 00:16:58.180, Speaker C: So essentially, I think if I had to think of one thing that essentially flare does not take into account, that would be liquidity mining incentives. So that's basically incentives for you to provide liquidity in pools in a way that you're getting token rewards besides just fees. Now, it's not easy to capture these because they can have an arbitrary form, but I do believe that there is a way that you can account for this. But we mostly leave that for future work. So that's something that I think flair does not take into account.
00:16:58.630 - 00:17:12.520, Speaker A: It's sort of the researcher special. Is it's out of the scope of this paper? You sort of throw the good things at the wall and you're like this is a nice metric, or leave the slightly other things that are less problematic for future paper.
00:17:13.370 - 00:17:15.798, Speaker C: You can't work for future work, as we say.
00:17:15.884 - 00:17:36.654, Speaker A: Exactly, right. You can't work yourself out of a job. Right. Can't answer all the questions at once. I guess on a different topic. Right. I think a lot of people in a lot of industry practitioners think of Uniswap V Three as somewhat similar to a central limit order book or somewhere in the middle between an AMM and a central limit order book.
00:17:36.654 - 00:17:50.130, Speaker A: You have this wonderful paper with Tim, I think, CMAC, about exchange complexity, talking about how expressive AMMS can be, sort of what is the conclusion from the comparison? What do you have to add to that literature?
00:17:51.510 - 00:19:21.786, Speaker C: Yeah, so the basic idea is that concentrated liquidity AMMS are kind of similar to limit order books in the sense that they allow LPs to be able to express very a wide variety of types of positions that they can have. So the idea with this paper is that essentially there is various types of markets that we see and the question is fundamentally how should we think about this from a theoretical perspective? How do we compare them? Before our work, we didn't have a unifying framework to compare them. And what we did is we essentially came up with a theoretical framework that allows us to reason about all sorts of generic exchange mechanisms between two assets from the perspective of LPs. So this includes both limit order books and Cfmms, as well as many other types of exchange designs, including Uniswap V three, which essentially concentrate liquidity AML. The general idea is that liquidity providers have some generic preferences in the form of essentially asset demand curves that they ideally would want to submit this to the exchange they participate in. The problem is though, that an exchange mechanism must restrict the liquidity providers for efficiency reasons. So it can only allow some combinations of demand curves.
00:19:21.786 - 00:20:11.578, Speaker C: It cannot allow you to be fully expressive as you'd like. So in this paper, what we do is that we define a notion of exchange complexity. That's essentially the minimum size that you can use to essentially generate all the demand functions that are allowable by an exchange. And for a CfMM this would be a single because you have a single liquidity parameter for a CfMM, you can imagine that essentially the complexity of a CfMM would intuitively be B one. Now, a limit order book essentially you can imagine that it has many ticks. We can prove that the complexity of a limit order book would be essentially the number of the ticks that you can express. And this is similar to Unison.
00:20:11.578 - 00:20:57.920, Speaker C: P three. And so circling back to the topic over there, the idea is that how many ticks you have essentially on a concentrated liquidity AMM, this affects your expressivity, this affects your approximation as a liquidity provider. And the more ticks you have, the better it is, but also the higher description complexity you need for your exchange. So what we do with this work is essentially to quantify in a very theoretical way this optimal tradeoff between exchange complexity on the one hand and approximation error for preferences of liquidity providers on the other hand.
00:20:59.410 - 00:21:15.490, Speaker B: Jason, you might want to reset again. I realize it just gets better every time you reset it and then it is good for five minutes and then it degrades once more. So I think you just have to repeat every five minutes. Unfortunately.
00:21:19.270 - 00:21:20.146, Speaker A: Can'T win.
00:21:20.248 - 00:21:20.686, Speaker C: Makes sense.
00:21:20.728 - 00:21:23.590, Speaker A: The funds of live podcasting.
00:21:25.610 - 00:21:29.498, Speaker B: Let me know when you're ready to.
00:21:29.504 - 00:21:32.010, Speaker C: Give something with the live podcasting.
00:21:34.670 - 00:22:23.980, Speaker B: Okay, one more question on your exchange complexity paper, my interpretation is you're kind of solving like a Min Max problem, right, where you say which exchange structure can serve the most demanding and unreasonable customer who have this weird demand curve for his asset? And if my interpretation is correct, then should people be using this as a guideline for mechanism design? Right? Because shouldn't exchanges be designed to solve the median or the mode customers problem instead of the most annoying person in the world's problem. Why should we care about this ming Max problem here?
00:22:25.390 - 00:23:44.922, Speaker C: So I'd like to first of all, I think your interpretation is right. Like this is what we do in the paper. So there are two arguments essentially for this. The first one is that basically you want to serve even the most demanding LP because if you don't do so, then because we have free competition and we're in a free market, they'll find some other marketplace to go to. And so essentially you lose them from a customer. And by keeping losing LPs, eventually there might be a point where some other type of market becomes more competitive, some other type of market design. Let's say that's I think the one perspective for why you might want to optimize for the most demanding LP you might get another aspect is that recognizing this thing you said for the median or the mode customer let's say it's essentially that you might want to adopt a robustness approach where essentially you're kind of robust to slight changes to the liquidity provider.
00:23:44.922 - 00:25:00.054, Speaker C: And now this is known in the computer science literature as something like smoothed analysis or smoothed complexity, where essentially you're getting this worst case LP and you're trying to smooth them with some notion of adding some notion of noise and then it kind of becomes almost like a smooth adversary. So essentially something that you can optimize easier for. The reason why you don't want to straight up optimize for the average or the median LP is that you usually don't know the distribution of the LPs that you're getting. So you're not actually sure what it means to optimize for someone that's median. Like this median is going to be different under lots of distributions of liquidity provider preferences, let's say. So you really don't want to optimize with respect to the median because you don't really know the distribution that you're getting. So this is why I believe the smooth analysis approach is something that it's interesting for future work, as we said.
00:25:00.054 - 00:25:10.030, Speaker C: And I do think that this is kind of a compromise between the two things that you discussed, the minimax interpretation.
00:25:12.390 - 00:25:29.030, Speaker B: And in general more than this question that you just answered. Who should be the audience of your research? Who should be reading and using it? Apart from the should, who do you think will actually read and use it in practice?
00:25:30.250 - 00:26:52.430, Speaker C: Yeah, I like how you phrase these two questions differently. They can be sort of as different in some cases. So I think that my work is, first of all, very interesting to fellow researchers because as researchers in academia, we really want to understand the space and provide analogues to more traditionally known objects, for example, in game theory like auctions and their incentive alignment issues. So first of all, understanding what kind of analogs exist between the crypto space objects and the traditional objects is something that it's very interesting for us to really fundamentally reduce the complexity and the confusion of these problems. And then again, I think that my work is also predominantly interesting to market designers. So as we are essentially inching closer to a more comprehensive understanding of the virus trade offs that in general market design is subject to, this is broadly what my research is about. If you further this line of research, then this would give us ideas on how to design both effective and efficient markets with all of the possible constraints that we have in mind.
00:26:52.430 - 00:27:57.122, Speaker C: And so that's why I believe it's very much an active and fruitful research topic. And also, finally, I would say that practitioners should be very interesting in my kind of work, I'd say. And I think there's two ways that practice is being affected by the kind of theoretical work that I really enjoy working on. So first of all, it kind of helps practitioners explain what you see in general that might be going on. So a good example with that is, for example, these NFT auctions where you see that the gas goes wild every time that there is a hugely popular NFT drop. And initially you might not understand why that is, why that's a fundamental problem. And game theory actually helps you uncover that it is really due to the misalignment of incentives that your auctioning mechanism actually gives to the NFTs.
00:27:57.122 - 00:28:48.920, Speaker C: So this explanation aspect is one very important aspect that I see moving forward, and something that game theory is really good at explaining it. And the second aspect is that of the market designer hat that I said previously. So basically it can help you as a practitioner use these theoretical tools and metrics to essentially try to find the optimal market that you can do whatever that means in each scenario. Whether that's an auction mechanism, whether that's an exchange mechanism, it really depends very much on your setting. But you can try to find the optimal market and actually implement that in practice. So I think that there's many ways that practice can be affected by my work, and I think that practitioners better look out for it.
00:28:52.570 - 00:29:02.220, Speaker A: Yeah. So I guess we'll go into the fun questions now. So you think if somebody won a Nobel Prize for some work in crypto, what do you think they would win it for?
00:29:05.870 - 00:30:37.270, Speaker C: Well, that's a really loaded question, really tough question to actually answer, because the difficult factor in that is that you don't know what one day will be considered as having stood the test of time, right? So you don't know exante what's going to be important in the future. But if I had to take a wild guess and maybe have some speculation over there, the generic theme of problems that are interesting to this category of prices, let's say it's essentially some general contribution or a general characterization of all markets or something that you can do in all markets. And look at Myerson's theory for example. It allows you to characterize all types of options that you can possibly implement. So if we could come up with something like that in crypto, for example, some ability that's given in the crypto space that allows you to expand the design space of what you can traditionally do in game theory along with a complete characterization of everything that you can do with this, then I think this is very likely to be considered as having stood the test of time in the future and consequently winning a very important prize.
00:30:42.190 - 00:31:04.690, Speaker B: Would you say that John Nash got something wrong here or failed to speak to some potential limitations of his result? Or are people applying it way too liberally in their application of the Nash equilibrium?
00:31:06.230 - 00:32:08.038, Speaker C: Yeah, I think that's a very loaded question as you phrase it. And I wouldn't go as far to say that he did something wrong. Let's say his work has been very influential for decades now and it definitely stood the test of time, hence the Nobel Prize. So the notion of the Nas Equilibrium that NASA is famous for, if our audience is not familiar with it, it has essentially certain issues in the modern environment. So basically nowadays we're mostly interested in something that's called repeated games, or otherwise known as game dynamics, where essentially what you do is that you don't just play a game one time. The participants don't just engage in playing a game one time. You get the chance to essentially revise your playing strategy based on what you see from the other participants and whatever information you glean from the game.
00:32:08.038 - 00:33:32.654, Speaker C: And then after you play and you revise your strategy, then you play again and this happens forever or for a very long time frame. Let's say for example, the stock market is such kind of a game can be viewed in a generic way. The difficulty with the Nas equilibrium is that really in some sense it does not capture everything that you can do in these repeated games. And in particular, in a result with my advisor Crisis Papa Dimitrio and collaborators from Singapore and Oxford, we essentially showed that it's fundamentally impossible for the Nas equilibrium to capture the long term behavior of players in such repeated games. And so essentially the question that springs to mind is that maybe the notion of a Nas equilibrium is fundamentally incomplete due to this aspect. And I think that in future work it's going to be very interesting to see what other kind of notions we can give that are more suited to this modern environment. But essentially I don't think anyone has a good way of thinking about this for now.
00:33:32.654 - 00:33:53.750, Speaker C: So for now, I think that still the notion of Nas equilibrium remains dominant. But I do think that there is a gap there that we need to address. And I think that this is potentially work that will stand the test of time if we can manage to actually give such a notion.
00:33:58.550 - 00:34:29.280, Speaker B: Great. So now, last question for Jason. And then we'll be taking some time to take questions from the audience. If you would like to ask any of us a question, please type it now as we ask last question to Jason. And then once we're finished, we can just read from the yeah, Jason, what's next for you? What are you excited about? And where can people find you and your results online if they want to follow your.
00:34:32.210 - 00:35:54.220, Speaker C: So, basically, I have a website online that's Jasonmilly GitHub IO. So there I have my contact info, my email, my Twitter thread is a good way to reach me also, although I prefer the email format much more, I would say maybe I'm kind of old fashioned in that regime and I don't follow traditional crypto space norms. Another way that I don't follow traditional crypto space norms is that I don't really use Telegram that often, and it's kind of a pet peeve of mine. Like, if someone messages me on Telegram, I'm always a little bit annoyed by that, I should say. So, yeah, these are just some of the ways that one can reach me. And essentially what's next for me is basically thinking about more fundamental game theory problem as they arise in DeFi and more generally in the whole blockchain space. Because, as I said in the beginning, what's interesting for me in this space is that we're given essentially new capabilities that we didn't have before, but we also have new problems.
00:35:54.220 - 00:36:18.740, Speaker C: So specifically incentive alignment problems that we need to solve. And so bridging these two things is essentially what I like to think about, and I think that I like to think about that from all of the possible settings that one can think of. So I think that's essentially what interests me in this space and what excites me here.
00:36:21.750 - 00:36:43.926, Speaker A: All right, perfect. So there's two questions we see from the audience. So one is probably more related to me or Shin, which is about a variable relationship between tick spacing and pool. The the background on the variable on tick spacings and pool fees is that the pool fee is sort of or.
00:36:43.948 - 00:36:51.754, Speaker B: The tick wait, Austin, would you mind reading the question first so then people watching the show can then know, yeah, whatever.
00:36:51.872 - 00:37:45.370, Speaker A: So, yes, the question is, do you think having a variable relationship between tick spacing and pool fees would benefit of I'm not sure. I guess so the tick spacing was chosen to minimize gas costs for backgrounds, essentially. So it's possible that tick spacings could benefit LPs by allowing them to be more expressive with their limit orders. But at the same time, there's always this trade off of gas efficiency. You don't want to change tick spacings too often, especially on trades that are noise trades, because every single time you change tick spacings, it costs money. In gas. So it would be interesting to explore that.
00:37:45.370 - 00:37:58.926, Speaker A: But currently in V three they're sort of set. So it'd be good to explore if that would be beneficial in the future or just sort of allowing users to customize and, I don't know, figure it out.
00:37:58.948 - 00:37:59.134, Speaker C: Right.
00:37:59.172 - 00:38:19.510, Speaker A: Like if they want to do it, they can. And if it works, then it works. And we should. A lot of people do that in the future. And this next one is probably for Jason, which is noting the orthogonality of lever and flair. Could you imagine an example case where both can in slash should be considered or compared?
00:38:21.130 - 00:39:22.198, Speaker C: Yes. So I think that's kind of the overarching goal with our work. Like we have essentially a quadrant interpretation where you plot on the one axis the lever and on the other axis the flare. And essentially the goal with that is that flare basically separates pools by additionally considering the competitiveness of LPs. So an example case, as I mentioned before, is a pool where you, for example, are a passive LP and you see other people trying to constantly JIT or essentially offer a request for code what's known RFQ. In these cases, the vast majority of the fees is going to go to these very active LPs, if you might, that do extremely active liquidity management. And you as a passive LP, you're not going to get almost any of the fee.
00:39:22.198 - 00:40:10.060, Speaker C: So basically lever, which accounts for your order flow toxicity. So for the trader that you're seeing on the other side, as well as the characteristics of the assets of the pool, would not allow you to distinguish between one pool where you see this kind of situation. So a very passive LP and a very active one that gets all the fees, and another situation where everyone is basically passive, so everyone kind of obtains the same proportion of fees. These two situations you can't differentiate by just using the notion of lever you have to additionally account for the competitiveness of LPs and this is exactly what flair is built to allow you to do.
00:40:12.510 - 00:40:49.030, Speaker B: So let me just phrase it slightly differently. I think the two metrics being orthogonal is intended and it's also intended for people to use them in a combined way. So that we're basically adding one additional dimension that you can compare different positions, different LPs and different pools. And hopefully we're measuring something that lever was not designed to measure to give you more insights into the dynamics on AMM.
00:40:51.610 - 00:42:09.150, Speaker C: Yeah, exactly. Through this plot of both lever and flare for a bunch of pools. If you plot a bunch of pools, then you actually get something that's similar to a pareto frontier of pools. So these pools that you should actually try to LP at versus those that you shouldn't and that are essentially very competitive. And now there is one comment that I'd like to make for that maybe if we have time, do you think we have some additional time? Yes. Essentially, I think, the more overarching idea with the whole market design questions and that flair is eventually in the future going to lead to is that whenever you have arbitrage in a market somewhere, someone is always going to try, if you see, of course, free and frictionless perfect competition to take advantage of free arbiters that they see in the market. So in the end, I think that perhaps many years from now, who knows, all pools might end up being kind of mid in their flare.
00:42:09.150 - 00:43:01.780, Speaker C: But that's the goal of market design. Like, the goal of market design is essentially to make it easier to reduce or to the extent that it's possible, eliminate market inefficiencies. And I think Siamak said this excellently in your podcast three weeks ago, in that the only end goal, if you want, of a market is to facilitate the transfer of goods from people with low intrinsic value for this good to those with high. And so this is because this increases the social welfare of the whole system. So that's kind of the broader idea and more overarching perspective with these goals, these metrics, everything that essentially can help you as a liquidity provider decide in a better way where to put your capital to use.
00:43:04.230 - 00:43:29.290, Speaker B: Great. Given that there's no more questions, I'm going to close this episode slightly earlier. If you would like to follow us on Twitter, I'm at Shin two underscores one, and Austin is at Austin Adams ten Jason. You can find him on Jason underscore of underscore CS. Is that the correct Twitter handle?
00:43:29.870 - 00:43:31.738, Speaker C: Jason of CS? That's correct.
00:43:31.824 - 00:43:47.842, Speaker B: Jason of CS. And the recording will be available on YouTube. We're working on bringing it to other platforms. And with that, we will see you guys in two weeks in another episode of Research Hours at Labs. I see you, everyone.
00:43:47.896 - 00:43:48.560, Speaker C: Pleasure to be here.

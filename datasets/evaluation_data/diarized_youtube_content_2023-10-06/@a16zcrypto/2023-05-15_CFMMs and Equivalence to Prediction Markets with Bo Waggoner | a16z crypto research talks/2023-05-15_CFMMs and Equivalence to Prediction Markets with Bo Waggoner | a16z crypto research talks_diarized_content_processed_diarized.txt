00:00:06.480 - 00:00:09.844, Speaker A: You. So welcome everyone.
00:00:09.882 - 00:00:27.984, Speaker B: It's been a while, but a 16 z crypto research seminar is back for today. Very happy to introduce Bo Wagner, professor at University of Colorado, telling us about his new work, Haunt Off the Press, about AMMS and prediction markets and the connections between them. So, Bo, all yours.
00:00:28.112 - 00:00:49.056, Speaker A: Great, thanks. Great. So this is about paper. Draft that's up on archives with Rob and Manisha. Okay. So luckily, I think just about everyone's very familiar with the general setup of automated market makers. So we have a single market maker and every trader is going to interact with that market maker, not with each other.
00:00:49.056 - 00:01:34.290, Speaker A: So sequentially over time, not included in this picture because I won't talk about it today, are some other participants in the market making ecosystem. So liquidity providers, which are people that provide funds to the market maker that it can use for trades. It's very interesting to think about that interaction, but I'm not worrying about it today. And then also any other market that's happening that might have other prices that are different than this one. That's also very interesting, but also something I'm going to skip today. So I'm just thinking about this very small closed system and rules for this market maker just sort of on their own. Okay, so again, I think I can skim through motivation pretty quickly.
00:01:34.290 - 00:02:46.310, Speaker A: These automated market makers have been useful on blockchains recently and also they've been historically useful for designing prediction markets, including prediction markets that you might run on blockchains. So it's good to think about how to design them. And what I want to talk about today are reductions and the equivalences between prediction markets as they've been designed and thought about for, I guess, 20 years, and constant function market makers which have been used much more recently in blockchain. And one thing I'm very interested about my co authors and I are interested in is designing for what you might call functionality of the market, meaning like facilitating trade. That's like the point of running a CfMM versus the point of a prediction market, which is to get information. So how do criteria differ when you have those two different goals or they seem to be the same to us, so we'll talk about it. So first I'm going to recall constant function market makers and actually give you a result we have about sort of axiomatic characterization of those.
00:02:46.310 - 00:03:34.256, Speaker A: There are others in the literature, but I'll tell you why ours is interesting. Then I want to spend a bit of time recalling prediction markets and the theory of design of automated prediction markets and tell you what I think are the kind of most important things to know about that theory. Just as a kind of crash course quick tutorial and then finally get to main results, which are equivalents of the prediction market world and CfMM world in some sense equivalents and tell you what that means. Okay. CfMM. Okay. So before I talk about constant function market makers, let me try to make this as general as a model as we could come up with for an automated market maker.
00:03:34.256 - 00:04:07.824, Speaker A: So there's some set of N assets. We assume they all have non negative value. We'll talk a bit about why that assumption, why I want to highlight it, and you want to facilitate trade among those assets. So what's a trade? Let's just say a trade is a vector in R to the N, and it's the net increase of the market maker's position. So a positive number means the market maker gains some of that asset and a negative number in position I means the market maker is transferring on net to the trader on the sign of this.
00:04:07.862 - 00:04:10.400, Speaker C: Sorry, I keep seeing it half the time being.
00:04:10.550 - 00:05:03.520, Speaker A: Yeah. My understanding is that in Cfmms, this is the more common convention, whereas in predicted markets, the negative is the more common. So we're trying to talk to CSMM people we appreciate. So in general, you would expect a trade to have some positive and some negative components because they're giving some things to the market maker in return for some other things. So what you might call a pricing rule, or there are different terms for it, but the rule that defines the market maker is some function from the history of trades so far to the set of trades that it's willing to accept today for this round. Yeah. So that's kind of what we think of as the most general way to define an automated market maker.
00:05:03.520 - 00:05:36.620, Speaker A: So each round, a trader arrives, they see the set of valid traits, or they know it because they know the definition of the market makers. They pick one of those traits, they communicate it, the trade happens between them and the market maker. And we repeat okay, some notation. The market maker has some initial reserves, Q zero, presumably all positive. So some amount of each asset that they're starting with. And so their current reserves is the Q zero plus the sum of all the trades.
00:05:37.360 - 00:05:50.732, Speaker D: Let me just maybe this is not the right time for this question, but here your pricing rule is very general, like any history to a set of trades which are allowed. I could imagine more restrictive sets. Like, I can imagine pricing rules that depend only on the current reserves.
00:05:50.796 - 00:05:51.410, Speaker A: Right.
00:05:52.500 - 00:05:57.140, Speaker D: Is the additional generality useful? Like, are there interesting designs which are path dependent?
00:05:57.880 - 00:06:10.676, Speaker A: Yeah. So we're going to nail down Cfmms very soon. So we're going to say from this general design, some axioms give you Cfmms. And so we're not going to end up using the generality.
00:06:10.788 - 00:06:11.352, Speaker D: Okay.
00:06:11.486 - 00:06:54.950, Speaker A: But then we'll be able to say, hey, anything in this space that satisfies the axioms actually has to be CfMM. So that's the point. For us, path independence is a great one because we'll only talk about vanilla sort of models that satisfy path dependence. I'll explain that, but it's actually the most important to weaken in practical terms because of things like charging transaction fees for people who know this. That makes sense. Yeah. So it's nice to keep in mind the generality to know the space of things you could do for sure.
00:06:54.950 - 00:07:20.270, Speaker A: Thanks. Okay. Yeah. From this hopefully very general design space, you could ask, you could do anything. What should you do? And by the way, this axiomatic thing is kind of following like a common exercise in the prediction markets literature. Like write down axioms, characterize your market as the only thing you could possibly want to do. So that's what we're going to do here.
00:07:20.270 - 00:07:53.412, Speaker A: Okay. So what is a CfMM constant function market maker? So if you have this function phi, which we'd like to call the potential function, you accept a trade if phi of your reserves afterward is equal to phi of your reserves before. So Q is your current reserves, R is the trade. And you'll call that trade acceptable. It's in your set of things. You'll accept if and only if this equation is satisfied.
00:07:53.556 - 00:07:55.370, Speaker B: Why do you like to call it a potential function?
00:07:57.180 - 00:08:03.252, Speaker A: I guess that came out of our thinking of prediction markets, but I can't remember why.
00:08:03.406 - 00:08:09.356, Speaker B: Where we to me, it suggests you're going to be using some argument, which you're probably not.
00:08:09.458 - 00:08:26.944, Speaker A: Yeah, it's not going to change. Yeah. It's not really going to change over time. But I think we're kind of thinking of different liquidity, so the different values of it is different liquidity levels. And that's probably why it sparks this in Mi. Yeah. So I've seen you use the term bonding function, I think, in papers that.
00:08:26.982 - 00:08:30.790, Speaker B: Seems that's like Cmax paper invariant function.
00:08:32.760 - 00:09:06.952, Speaker A: Invariant seems like yeah. It's not going to change over the course of a single market. So that might have been misleading. Okay. Yeah. A primary example is the constant product market maker, which was used in uniswap, which basically keeps the product of the quantities at a constant. So two assets, it's the square root of how many apples you have, times how many arches you have, as probably everyone knows.
00:09:06.952 - 00:09:47.390, Speaker A: Many people know. Okay. And so this is the picture that everyone draws for Cfmms. So your reserves a point in the space is your reserves number of apples, comma number of oranges, and the red curve is the set of reserves that the CfMM considers valid. So the way Cfmms in particular work, there's a set of valid reserves and a trade is valid if it moves you from one valid reserve to a different valid reserve. Okay. And let me just state this result that I alluded to.
00:09:47.390 - 00:10:25.530, Speaker A: So if an automated market satisfies a certain set of four Axioms, then it's a CfMM in particular for a concave increasing function phi. Right. And so this would be, by the way, the red curve would be the set, for example, of Q, such that phi of Q equals four or whatever the constant is. Okay. So next I'll just walk through the axioms and explain them briefly, verbally, but then try to skim through pretty fast because I think the rest of our results are more interesting.
00:10:26.460 - 00:10:31.720, Speaker B: Definitely. These are like precisely the Cfmms one might think about anyways.
00:10:32.060 - 00:11:11.370, Speaker A: Yeah. So a lot of what I'm going to say today is the Cfmms you're already thinking about anyways, seem to be the right ones to think about. And maybe just kind of reassuring ourselves that out of this large design space, the area we're currently exploring is kind of inevitable. And we don't seem to be missing anything because, yeah, actually, this is what people do. Concave increasing functions. Some of this is just by convention and it's not necessarily like increasing, concave increasing versus convex decreasing. You could do those and they would give you the same set of things.
00:11:14.060 - 00:11:16.804, Speaker D: Sorry, I guess the concavity gives you a computational benefit.
00:11:16.852 - 00:11:17.496, Speaker A: Right.
00:11:17.678 - 00:11:21.752, Speaker D: Concave and increasing. You do the convex optimization type stuff.
00:11:21.806 - 00:11:27.390, Speaker A: Right. Yeah. But there's good market reasons as well. Okay. Yeah. Which we'll talk about.
00:11:28.080 - 00:11:31.084, Speaker B: You basically want incentives for arbitrariors, for example.
00:11:31.202 - 00:11:31.870, Speaker A: Right.
00:11:32.400 - 00:11:33.964, Speaker B: That's one property you could write down.
00:11:34.002 - 00:11:34.300, Speaker A: Yeah.
00:11:34.370 - 00:11:37.016, Speaker B: I think tends to force you to these kinds of properties.
00:11:37.128 - 00:12:03.210, Speaker A: Yeah, we'll have a different name for it. Okay. I was going to ask about the increasing it seems that to be pedantic, we would say it's equivalent to an increasing right. Because one level curve doesn't specify any restrictions on the actual function of two variables. Right. So you could do any warping to those levels curves and not have it be increasing but still maintain the AMM structure. Correct.
00:12:03.210 - 00:12:57.690, Speaker A: Probably correct. I don't know about any possible working, but you could definitely yeah. So an important point that I should make more clear is we're going to say a market that satisfies things can be implemented as a CfMM with a concave increasing function and as you're pointing out, it could also be implemented as a CfMM with some other function as well. Thank you. And they'd be equivalent. Yeah, thanks for that point. Okay, so path independence we've mentioned, so what that means is that a sequence of trades that leads to the same reserves as another sequence of trades should have the same set of valid trades offered at that point in time.
00:12:57.690 - 00:13:39.830, Speaker A: Okay. There are different ways to phrase path independence, but that's one of them. So one way to phrase it, a very strong way to phrase it, is you should only depend on the current reserves, not on the history. This also axiom comes up a lot in the prediction markets literature. One thing people are concerned about there is do you have an incentive to, instead of just coming and make the trade that you want to make, to break it up? And first you make a trade and then you make a different trade and all of those add up to the trade you wanted to make, but somehow you made money along the way. You'd like to say there's no incentive to do that. Just come and squish that entire path into one trade and you get the same thing.
00:13:39.830 - 00:14:32.170, Speaker A: I'm only going to define these axioms out loud because, again, other things we want to get to, but I hope that is clear. So, path independence is very much giving us this CfMM. It's a big part of why you get the CfMM structure, which is there's a set of valid reserves and a valid trade is just the move to a valid reserve. Okay. So no dominated Trades says that, for example, if I offer to trade one orange for one apple, I'm not going to also offer to trade one orange for half an apple because the trader would always pick the second one. They'd always say, okay, I'll just give you half an apple and I'll get an orange. So it's basically removing redundant offers from the set.
00:14:32.170 - 00:14:36.904, Speaker A: So it's kind of for convenience to nail down.
00:14:36.942 - 00:14:41.000, Speaker D: You could have a sublevel set of this phi instead of just level set.
00:14:41.150 - 00:15:15.830, Speaker A: Yeah. So what you could picture here is if I shade in the upper right side of this, those would be all the reserves that result from a dominated trade. From the trade, no one would ever trade with you. Yeah. So it's like you move to this lower blue point, but then the market maker gets an extra one unit of each thing for free. You move out into its upper right space. So, yeah, at least for mathematical convenience, this is an easy condition to add that just removes these redundant things, but it's not a super big deal.
00:15:15.830 - 00:15:54.624, Speaker A: Okay. Liquidation is very important. The way we interpret this is you should be allowing people to sell you anything they want to sell. So if they want to get rid of things, you should offer some price for those things. Let me make that a little bit more formal. So for any non negative vector, which is the set of items the trader wants to sell to you, there should be some other non negative vector that you're willing to trade them in return. The things that you're using to buy actually stronger than that.
00:15:54.624 - 00:15:56.076, Speaker A: They should also just be the negative.
00:15:56.108 - 00:15:56.892, Speaker D: Of the same vector.
00:15:56.956 - 00:16:07.590, Speaker A: Yeah, stronger than that. So the trader should also be able to specify which assets they want and even in which proportions, and you'll tell them how much of that you're going to give.
00:16:08.840 - 00:16:17.336, Speaker D: So just to keep it simple, if I had two assets for whatever quantity of one asset someone wants to sell me, I'm willing to offer him some non zero quantity of the other.
00:16:17.518 - 00:16:17.912, Speaker A: Okay.
00:16:17.966 - 00:16:23.096, Speaker D: So this would rule out things like uniswap V three, where you could run out of one of the okay.
00:16:23.278 - 00:16:34.060, Speaker A: Yeah. A better or more complicated example is if I have N assets, if someone says, all right, I have five of asset one, three of asset four, and so on.
00:16:34.210 - 00:16:36.252, Speaker D: And I want price in asset 27.
00:16:36.306 - 00:17:04.640, Speaker A: I want asset 27 only. We should be able to give them a non negative price in asset 27. Or if they say, I want asset 27 and asset 20 in proportion three to two, we should be able to give them a non negative price up in that proportion. It might be scaled very far down. We're only offering epsilon and three halves epsilon, but it should be something this is the release.
00:17:04.720 - 00:17:05.172, Speaker E: Oh, sorry.
00:17:05.226 - 00:17:10.296, Speaker A: Go ahead. Well, it's kind of what it means to be a market maker, I guess, is what our thinking was.
00:17:10.478 - 00:17:11.272, Speaker C: Go ahead.
00:17:11.406 - 00:17:39.250, Speaker E: This might be a sort of a strange question, and I guess you're probably going to show us, as you sort of explain the characterization, but how much does it really is this is sort of like an edge condition? Or is it basically continuous at zero in this liquidation ability? That amount of exchange can sort of trend arbitrarily close to zero? Or does it need to be sort of a truly strictly positive quantity, if that makes any sense?
00:17:40.440 - 00:17:57.130, Speaker A: I think we will allow you to offer zero for things in this think and Roth and Manisha could jump in if I'm misremembering, but I think here we will actually allow you to pay zero for stuff to say.
00:17:59.180 - 00:18:12.270, Speaker F: There's a funny contradiction that you get where if I offer you something non zero and the price that you give me is zero, then that trade is actually dominated by giving you zero and getting zero.
00:18:12.960 - 00:18:14.450, Speaker E: Right, I see.
00:18:15.300 - 00:18:35.584, Speaker F: I think you are basically correct that it's an edge case and there are prediction markets like the Sqcp or whatever it is, that the prices do hit zero or one for Eritrebrew Securities, I think it's not a big deal, but it did make the math nicer.
00:18:35.712 - 00:18:42.650, Speaker E: Yeah, exactly. It seems like that's just an edge condition that seems totally clean under that interpretation. Thanks.
00:18:43.740 - 00:18:44.152, Speaker A: Awesome.
00:18:44.206 - 00:19:17.970, Speaker C: I have one more question for that, if I could ask. So, for this, if you have many dimensions, so let's say more than three assets, is this kind of somehow stronger than specifying the exchange rate that you want? Because you then specify the exchange rates of all assets that you want, whereas the scalar that you're offering essentially to the trader is just a scalar. Right. So is it the case that I might go into a dominated trade in this sense?
00:19:20.040 - 00:19:27.460, Speaker A: Are you asking about a liquidation where you can only say one asset that you want in exchange for your bundle?
00:19:28.120 - 00:20:03.330, Speaker C: So in a liquidation, when my CFM has more than three assets, then essentially specifying the CF. So me specifying a specific bundle of assets that they want and the proportion of exchange rates they want for all assets means that the CFM can only give me a scaled version of that specific vector that they specified. Right. That's by the assumption. And so then does this mean that I might be led into doing a dominated trade in this specific case?
00:20:08.180 - 00:20:37.870, Speaker A: I guess, if you ask. No, I don't think so. So for example, if you offered one apple and said, pay me an apple, the market would have to give you one apple back. It would have to be a net zero trade. So I don't think this will ever be conflicting with no dominated trades. I may not have fully understood, but yeah, okay, thanks. That's the best answer I think I can give.
00:20:37.870 - 00:21:35.388, Speaker A: So demand responsiveness is an axiom that we've more or less borrowed from prediction markets and it means the price should go up as you demand more stuff. So if you bought four apples for seven oranges and then you come back and buy four apples, you should be paying eight oranges, you shouldn't be paying seven or fewer. And that's really what's giving us concept. And if you look at this curve so a gradient or a tangent line is kind of the exchange rate at any point that you're at and you can see as you move in one direction, the gradient moves in that direction. So as a market maker, if I have fewer apples, more oranges, apples become more expensive, oranges become less expensive.
00:21:35.484 - 00:21:37.996, Speaker C: Does continuity of some form and existence.
00:21:38.028 - 00:22:08.570, Speaker A: Of marginal prices arise from yeah, it does. So concave functions are continuous in the interior of their domain, which here is pretty much more or less the whole space. So continuity arises in a way that's not super obvious. I think demand responsiveness is important there and liquidation is very important because it says liquidation kind of says there is a price for every size yeah, which gives you a function.
00:22:09.820 - 00:22:12.360, Speaker C: What about the derivatives, the marginal prices?
00:22:13.200 - 00:22:16.830, Speaker A: Yeah, not necessarily. And then we're going to talk about that in prediction market.
00:22:20.080 - 00:22:25.016, Speaker B: And so if you drop any of the four, none of these are redundant, I assume you've showed.
00:22:25.128 - 00:22:58.730, Speaker A: Yeah, right. So if you drop demand response in this, you should be able to get a CfMM that might not be concave. If you drop path independence, then you can do something totally different at one step than a previous step. Dropping no dominated trades might not change that much, really, because again, it just says you have to either stay on the line or move up into the right. Although with path independence, that might cause problems because you don't want to move that down. So yeah, actually I'm not sure it was.
00:23:00.540 - 00:23:14.780, Speaker B: Kind of it might be nice to just be specific about which axioms force you to have a CfMM which is forcing Increasingness, which is forcing concavity. So those drivers are clear.
00:23:14.930 - 00:23:57.736, Speaker A: Yeah, we can do a little bit of that in the paper, particularly for CfMM, but it's hard to nail down exactly what a CfMM characterizes because it's actually such a really any the output of any algorithm has to stay constant. Any algorithm of Q is actually just a really weird space. So, yeah, we have only a little bit toward what you're saying. Oh, yes. Important. So the proposition I just quoted for you is kind of fixing one level set of phi. If you want to extend in multiple level sets, the result can extend.
00:23:57.736 - 00:24:45.884, Speaker A: But we can only show, and we think it's only true that phi would be necessarily quasi concave. That's a technical version of concave that I think I'll just skip defining. But I want to mention it might not necessarily be true that it's concave. As far as we can tell, it might be possible to satisfy all of these axioms at each level set, but the level sets don't stitch together into a concave function, level sets of only a little quasi concave function. And that's something that we're clarifying for the next version, the distinction between one level set and stitching together, but not super important for the talk. Yeah. So I want to go to prediction markets next.
00:24:45.884 - 00:25:33.230, Speaker A: Now that I've introduced Cfmms, there are other papers talking about axioms and Cfmms, and the authors of those papers won't find a lot surprising here. I think our axioms are a bit different technically. What's different is starting with that general automated market making framework and deriving Cfmms as a consequence of axioms. Most of these will look these papers will look more at, if I have a CfMM, what further axioms do I want to satisfy? Not super important, but I just wanted to mention okay. Prediction markets. So I love prediction markets and I want to spend some time telling you about them, which is, again, missing literature, not new stuff yet. And then we'll get there.
00:25:33.230 - 00:26:14.470, Speaker A: Okay, so we're looking at prediction markets for just a probability distribution over an event. So there's an event now with N outcomes. And it's going to be nice that N is the same as the previous N assets. So there are N things that could happen. For example, N competitors in a race, one of them will win. So what you do is you create securities where security I pays a dollar if competitor I wins the race, and it pays zero otherwise. So your value for that security is presumably the probability that you think competitor I is going to win.
00:26:14.470 - 00:26:39.250, Speaker A: And the market valuation for all the securities should form a probability distribution over the outcomes. So we're going to run an automated market. It's the same general framework that I mentioned earlier with N plus one assets, where the last asset is cash or let's say US. Dollars. So I'm describing how prediction markets are set up.
00:26:40.740 - 00:26:46.690, Speaker D: Do they have the last asset or do they just because you can trade all N, right, I guess you call the grand bundle, right?
00:26:47.060 - 00:26:49.590, Speaker A: Yeah. So we're going to use that trick. Okay.
00:26:50.440 - 00:26:52.448, Speaker D: But usually define it with a cash asset.
00:26:52.544 - 00:27:26.130, Speaker A: Yeah. And it does make some difference. So usually it's defined with cash is very important because you charge for these securities in terms of cash. So you really need this the way people talk about it needs this numerator, which is what is the price of security? I the price is in terms of US. Dollars. Whereas with the tension with Cfmms is that there is no numerator necessarily, there's no special asset. But yeah, we're going to use the trick you mentioned that's like, going to be the key point.
00:27:26.130 - 00:28:16.752, Speaker A: Okay. And so you just want to design this automated market to elicit the market's belief. So you want to get these prices to reflect what the market believes about the probabilities of these outcomes and a priority that seems like a different design goal than just facilitating trade among these assets. But it's interesting that we're going to end up with something that looks like it was designed to facilitate trade among these assets. Okay. So prediction markets are based on turned out to be convex cost functions. And of course, when we learned about Cfmms, we saw these concave CfMM functions and we knew about these convex cost functions and we just felt they couldn't be complete.
00:28:16.752 - 00:28:55.400, Speaker A: There had to be a technical connection, not just an analogy. So that's what we were looking for. The way it works is I'll accept any proposed trades from the trader and charge them in terms of the N assets. So this could be a positive or negative vector. I'm going to charge them according to this function, C. So Q is my current reserves of just the N assets, the N securities, and I'm going to charge them the difference between C of Q plus R after they've traded and C of Q, my reserves before they traded.
00:28:56.380 - 00:29:04.088, Speaker B: You have a question for both in that particular prediction market, should I think of these functions defined on the non negative orthan or all of RN?
00:29:04.184 - 00:29:37.892, Speaker A: Yeah, that's a good question. So for CSMM, non negative orthened peer all of RN? Cool. I won't exactly hit that point, but it will come back up too. Yeah. So in prediction markets, selling short is built in. And so I can hold a negative amount of the assets and the trader can sell short or buy assets. The market can hold negative numbers of the assets.
00:29:37.892 - 00:30:25.496, Speaker A: So C needs to be defined everywhere. Okay. And when C is convex and satisfies, a condition called ones invariant, this is equivalent to something you may have heard of, which is a proper scoring, rule based, market prediction market. Okay, I need to define some stuff. So ones invariant means that if you add any multiple of the ones vector, all ones one one, then the function goes up by that same multiple additively. Excuse me. So, for example, if I add four units of one one one as my vector, R, C goes up by four plus four.
00:30:25.496 - 00:30:30.168, Speaker A: If I add seven units of the vector one one one, C goes up by plus seven.
00:30:30.334 - 00:30:32.056, Speaker D: Like a no arbitrage.
00:30:32.248 - 00:31:06.224, Speaker A: Yeah. So the reason is that this bundle, one of every asset, its valuation is exactly one dollars, because one of those N assets will pay off one, the rest will pay off zero. So its valuation is always a dollar. So if I offer to trade it, I should always be paying exactly one dollars for it. Yeah. Okay, so I'm not going to define proper scoring rules, but I will mention them a few times. So they're just functions that take in a prediction and produce a score such that they're truthful.
00:31:06.224 - 00:31:35.952, Speaker A: People want to predict truthfully. So Hansen created prediction markets with these elicitation functions, proper scoring rules. So he basically said each person comes in and they predict truthfully to a proper scoring rule and they get paid the difference in their score between their prediction and the next person. What's kind of amazing is there's a one to one correspondence between Hanson's proper scoring rule, prediction markets and these cost.
00:31:36.006 - 00:31:42.108, Speaker B: Function markets, the difference between their prediction and the previous prediction, not the next prediction.
00:31:42.204 - 00:32:35.490, Speaker A: Yeah, that was a mistake. So in the scoring rule market, there's a previous prediction that someone made, you make the next one, you pay your score minus their score, and the connection is via convex duality, which I'm going to show a picture of, but I'm not going to explain technically. So people who seen it will know. But yeah, it's very not obvious, I think, that this is true, but it is. The other point about this is you can use that fact to prove that these cost function markets characterize truthful, path independent prediction markets. So path independence pretty much means the set of the trading function. The scoring rule is the same at every time set.
00:32:35.490 - 00:33:20.320, Speaker A: And so when you add that into the requirement that the prediction market should be truthful, this is all that's left. You take a convex ones invariant cost function, it actually should satisfy a couple of other things we'll talk about. And you use it in this way and that's the only thing you can do that's truthful and patent variant, and we're going to conceptually leverage that. So if you want to do elicitation, in some sense, you have to do this. That's my claim. Okay, so I want to do some drawings, not just words. So this is a picture of how people like to draw cost functions.
00:33:20.320 - 00:34:00.236, Speaker A: So here I'm isolating one security out of the N possible ones, and the horizontal access is how much I've sold of that security. Reserves is actually to the left. More reserves is to the left because I've sold less of it. This is where the convention difference comes in. So if we zoom in, if my current reserves were Q, and then I sell a little bit to move to Q prime, the amount that the trader has to pay is this vertical purple bit here, because we move from Q to. Q prime. So they have to pay C of Q prime minus C of Q.
00:34:00.236 - 00:34:52.590, Speaker A: So they have to pay this little vertical. You can see that the tangent lines are giving the instantaneous price of buying one more unit of this asset. So it's an approximation to how much you have to pay. Okay, so now I want to show a couple of pictures that illustrate in prediction markets how market making properties, like properties of how the market works, follow from convex function and properties. And in doing that, I'm going to again assert this connection to a scoring rule. So for every scoring rule which I'm drawing is a convex function on the left, this generates the scoring rule. Its conjugate is the convex function that gives you the cost function.
00:34:52.590 - 00:35:43.950, Speaker A: And so you can design a market by designing either one of these two complex functions. Okay, the key connection is that the slope in the scoring rule is going to give you the point on the axis of the cost function and the point is going to give you the slope. So in this example, at P is one half. This is a probability between zero and one. The slope of the scoring rule is zero. At Q equals zero, the slope, which is the price, is one half. So and this is the same kind of drawing that I just gave, but showing you what happens in the scoring world.
00:35:43.950 - 00:36:29.522, Speaker A: So the price moved from zero five to 00:51 when I made that trade and Q moved from zero to 0.2 or whatever. Okay, so now that we know this, we can think about how design will influence properties of the market. If you miss a little bit of the next couple of slides, it's not a big deal. We'll come back to CfMM after that. One has to do with the okay, so we're not at existence of prices yet. So what happens if this convex function has a kink in it? So really what this means is it's not differentiable at this point.
00:36:29.522 - 00:36:50.982, Speaker A: There are multiple tangent lines, there's no one derivative. Well, in the conjugate, a kink in the first function corresponds to a flat section in the conjugate. What's a flat section mean? What's happening in the market? There's a flat section in the cost.
00:36:51.116 - 00:36:53.018, Speaker D: Price isn't increasing as you trade more.
00:36:53.104 - 00:37:28.440, Speaker A: The price is not responding to quantity. Yeah, so if you buy from here to here, your price is given by the slope and the price is just not responding. It's not the worst thing in the world, but it's also not what we really expect. We expect to be at least some response. You would want to be approaching flat if you have lots of liquidity, meaning that prices aren't going to change much as you sell lots, buy or sell lots of lots, but you probably don't want to be exactly flat. So it's probably nice if your scoring roll function is differentiable. Now, let's do the opposite property.
00:37:28.440 - 00:37:46.860, Speaker A: So if your scoring roll has a flat section that's not strictly convex, for some region, it has the opposite effect. There's a kink in the cost function and the kink means.
00:37:49.710 - 00:37:50.810, Speaker D: Price jumps.
00:37:51.870 - 00:38:20.470, Speaker A: Yeah. So sort of here, there's no instantaneous price, there's multiple, sort of. But one way to think about it is the price is jumping. So as I'm approaching it from the left and buying more and more, the price is going to a half. And then all of a sudden, to buy the next amount, I sort of need a cash quantity because the price is now suddenly 0.6. So again, something you probably don't want. So you probably want your scoring will be strictly convex.
00:38:20.470 - 00:39:05.700, Speaker A: Strictly convex, differentiable. They're nice things anyway, but they're not just mathematical convenience, they're having impact on the market, the structure of the market. Another thing I want to mention is the slope. So as we go left in the scoring rule picture, this is the negative of the entropy function, which is the LMSR market, if you've heard of it. This slope is actually going to infinity or negative infinity as P goes to zero. So in the cost function world, as the price or the slope in the cost function world goes to zero, the quantity goes to negative infinity. That's a good thing.
00:39:05.700 - 00:39:51.998, Speaker A: On the right side, as the amount sold goes positive infinity, the slope is going to one and that's also a good thing. So the most you should ever pay for this asset is one. And as the amount sold goes to infinity, the price is going to go to one because people keep demanding it. Let me zoom back out to show. Yeah, so this slope is going to one. So you can control this slope by controlling the domain of the scoring rule. And Roth mentioned earlier, if you use something called the Breyer score, which uses a quadratic, these slopes actually don't go to minus infinity and infinity, they actually go to whatever, one or two at the boundaries.
00:39:51.998 - 00:40:32.030, Speaker A: And that means that this market is going to actually reach a price of zero or one. And after that, the price will stay at one or it'll stay at zero. So depending on if you want that behavior, maybe you should choose a function that's a pseudo barrier which has slopes going to minus infinity. Infinity. Okay, one more liquidity. So liquidity is I think of it as how fast does the price change as you sell more and more? That's one interpretation anyway. In the scoring world, it's very easy to add liquidity.
00:40:32.030 - 00:41:27.380, Speaker A: You just multiply this function by, say, 100, and now basically a purchase at the same amount of money is going to change the price much less. But what that does in the cost function world is a little non obvious and it's called the perspective transform. So it turns into 100 times C of Q over 100. A way to see that something funny has to happen here. If you just multiply the cos function by 100, the slope would be like 100 instead of one. So it's clear that you can't just scale up the cost function by 100 and expect it to work because now you have prices of 100 and it turns out this perspective transform is the right thing. This convex analysis just tells you the dual of 100 times G is this thing.
00:41:27.380 - 00:41:59.820, Speaker A: Okay? So we're going to come back to that at the end if I'm not already out of time. Okay, doing good. So that's the end of market design and convex analysis. After this I'll talk about our actual results connecting the two. Okay? Yes. Again, the results are what you're doing now is the right thing to be doing. So I'm not trying to set you up for a big surprise, but let's see.
00:41:59.820 - 00:43:20.740, Speaker A: Okay, so the first kind of equivalent is there are reductions between the space of cost functions with a convex and ones invariant function C and Cfmms with concave and increasing potential function five, such that the automated markets that the first one implements and the second one implements are the same. When I say they're the same, this needs explanation because they're in different settings. So what do I mean? That they're the same? And in particular with prediction markets, I assume that there is this numerator cash and that's how you price things and assets. Prediction markets only work for well, I've defined them for Arrow degree securities, these indicator function securities. So I'm saying that you can use that to price any assets at all. That's a little bit OD, but I'm going to explain this by just showing you the forward direction of the proof and that'll explain the sense in which a prediction market can be turned into a CfMM and then I'll mention the reverse direction.
00:43:22.040 - 00:43:41.640, Speaker E: Do you have a verbal interpretation of this? Is this basically saying these markets made by these market makers are in effect organizing a process of predicting the eventual value of all the different individuals assets in them or something? Is that the right intuition?
00:43:42.060 - 00:43:58.430, Speaker A: Yeah. So the way I think about the elicitation intuition is if you're in CfMM world, imagine that everyone has a valuation for the securities in their head and imagine that I'm trying to elicit an aggregate market.
00:44:01.460 - 00:44:06.000, Speaker E: That everyone is trying to jointly discover the aggregate market valuation.
00:44:06.500 - 00:44:07.250, Speaker A: Yeah.
00:44:08.740 - 00:44:17.584, Speaker E: And this is like a prediction problem in the sense that they're all trying to realize what the settled market valuation will be at the end of some time period.
00:44:17.632 - 00:44:28.884, Speaker A: In some sense, yeah. And then of course, the big difference is that in a prediction market, at the end you find out that just one of these assets has value and the rest are worthless.
00:44:29.012 - 00:44:29.592, Speaker E: Right.
00:44:29.726 - 00:44:41.164, Speaker A: In the CfMM you never sort of find out, although maybe an event happens and you realize that this asset is worthless now. So it's maybe not that different, but.
00:44:41.202 - 00:44:50.252, Speaker E: Yeah, I've always thought of the zero one thing at the end of the prediction market as basically just being sort of being less interesting.
00:44:50.306 - 00:44:50.440, Speaker A: Right.
00:44:50.450 - 00:45:14.200, Speaker E: Like a prediction market doesn't actually require that there be a day at which the information is actually finally realized. It just means that in the limit at infinity, this thing converges to the probability that the thing actually would happen. And so in that interpretation, it feels to me like this is actually very close and that the price here is sort of the market realized probability of sort of yeah.
00:45:14.270 - 00:45:31.600, Speaker A: Agreed. Agreed. Yes. And what this is saying is that the rules for how to adapt those prices are the same between these. The things that have been come up with some semi independently are really using the same rule.
00:45:31.780 - 00:45:39.024, Speaker E: This is really extremely intuitive and very cool. I could feel it changing the way I think about Cfmms in my head. This is super cool.
00:45:39.062 - 00:45:50.816, Speaker A: Thanks. Awesome. Yeah. I think elicitation is how we should think about everything. So that's what I want to push. But maybe tomorrow after you think about it, you'll change your mind. So we'll see.
00:45:50.998 - 00:46:03.690, Speaker E: Well, the question is what's the probability that we're going to be thinking about them all in terms of elicitation in the limit ten years from now? We should all take bets on that and update our bets based on this talk anyhow sorry, go ahead.
00:46:04.060 - 00:46:24.060, Speaker A: Yeah, good. So I think that's all I need to say before I show you what do. So let's do that. Actually, Samak already mentioned the key trick. So remember, they're in a prediction market. I'm going to start with a prediction market. There's these N securities and then cash.
00:46:24.060 - 00:47:15.420, Speaker A: So there's N plus one assets. But it's an overdetermined system because this bundle of one of each of the securities is always equal in value to one unit of cash. And everyone agrees in that no matter what they think money is worth, no matter what they think the probabilities are, they agree. So it's overdetermined. So we will call the cashless prediction market, the one where you follow the rules of the prediction market, but you never use cash. And anytime you're going to use cash, you just use units of the all ones vector of securities, what we call the grand bundle. So for any R that the trader wants to purchase, which can include positive or negative components and it's only an R to the N, it's a bundle of the securities.
00:47:15.420 - 00:48:10.156, Speaker A: We'll say if you say R, the trade that you're going to actually make is R minus alpha times the one spectre, the grand bundle, where alpha is the cost you would have paid in cash. So again, just this trick of just simulate the prediction market, but every time you would have said cash, just give people one of every security. Okay? In fact, this is already a Cfnum and pieces of this you can find pieces of this in like Chen and Penak 2007, which was a constant utility market makers. Of course, Cfmms didn't quite exist. If they did, they might have made the full connection already. This is already a CfMM. I'm still kind of surprised.
00:48:10.156 - 00:48:52.350, Speaker A: But if you just look at ones invariants, you get it, you prove it. So let me say a little bit more what I mean. So the allowable trades are of the form R minus alpha ones. So I'm going to look at my position as a market maker after that. Legal trade ones invariance says that C of stuff minus alpha ones is equal to C of stuff minus alpha. In this case, alpha is C of stuff minus C of Q. And so I just end up with C of Q.
00:48:53.840 - 00:49:12.710, Speaker D: So in your earlier slide, you pointed out there's a connection with risk models, financial risk. There there's something very close where you have a set of acceptable portfolios and the risk of a portfolio is how much cash do I put in to push it? So where does that line up here?
00:49:13.240 - 00:49:22.820, Speaker A: Yeah, I don't know that the technical meat is the same and financial risk measures are usually one variant because of this.
00:49:22.890 - 00:49:23.220, Speaker D: Right.
00:49:23.290 - 00:49:28.408, Speaker A: And so we're using actually next I'm going to use it even more constructions that they use.
00:49:28.494 - 00:49:31.416, Speaker D: The technical meat is the same, but maybe the modeling is not the same.
00:49:31.438 - 00:49:48.210, Speaker A: Is that what you're yeah, I don't know if this idea of cashlessness comes up there like this idea of moving to a world where cash is replaced by the grand bundle. I don't know that that ever I mean, it's possible. It's not that weird an idea. So it might come up there.
00:49:48.820 - 00:50:09.524, Speaker D: I think in that literature, your input is like, okay, so your input would be there's end scenarios and maybe they have probabilities or whatever, and your input is how much money do I gain or lose in each scenario? Right. And because they're exhaustive and mutually exclusive, if you gain exactly a dollar in every scenario, that's got to be worth a dollar today, right?
00:50:09.562 - 00:50:10.150, Speaker A: Exactly.
00:50:10.680 - 00:50:12.404, Speaker D: But maybe they don't explicitly say that.
00:50:12.442 - 00:51:02.052, Speaker A: Okay. I mean, that's definitely why they use ones in variance. And they definitely say what he yeah, and Ross knows more about this than me, but I don't know if there's anything more to say about why the claim that we're proving with this one line is related to what they're doing. But yeah, the next one's a bit more so that's the sense in which so it's a CfMM with a convex potential function. But if you want to get concave increasing, you can just negate the function and negate the inside. You'll end up with a CfMM with a concave potential function. Does that make sense, sir? So if you use C as a potential function, you could also use minus C as a potential function.
00:51:02.052 - 00:51:09.320, Speaker A: It would give you the same level size, the same shape and it's conveyed.
00:51:10.300 - 00:51:24.444, Speaker D: Okay, let me ask another question. I sort of feel like having read through your paper earlier and looking at the early literature, the equivalent cost function to, let's say, a constant product market is something with square roots and stuff, right?
00:51:24.482 - 00:51:24.684, Speaker A: Yeah.
00:51:24.722 - 00:51:31.170, Speaker D: So if you do that, you're not going to get phi is not going to be a product or a geometric mean or whatever, right.
00:51:35.380 - 00:51:40.160, Speaker A: You should be able to produce uniswap in this way starting from the correct.
00:51:40.310 - 00:51:41.892, Speaker D: Cost, the correct cost function.
00:51:41.946 - 00:51:46.868, Speaker A: Okay. We've only done it backwards, but it must work.
00:51:46.954 - 00:51:53.976, Speaker D: I could be wrong about that. If I think about phi, there's many different phi's that capture the same market.
00:51:54.078 - 00:51:55.096, Speaker A: Yeah, right.
00:51:55.278 - 00:52:05.420, Speaker D: Does C have that degree of flexibility also? There must be if you go back and forth. Right. Are there many different C's which would give you the same prices for all trades?
00:52:06.400 - 00:52:22.960, Speaker A: I'm not sure. So one important difference is phi has many level sets that behave differently and C is only equivalent to one of those level sets. Okay. And we're going to talk about more about that later. Okay. Other than that though, I think that's.
00:52:26.420 - 00:53:03.784, Speaker C: I think I have also one question here. So I guess the equivalent that you're saying, the C and the equivalence of the prediction market will have some dependence on which level curve of the CFM we're referring to. And then if we have that, then the phi that's produced by this rule that you have in the last line here, this will also depend on K. Right. And so then if I want to take the level set curves of that, I would need to use exactly the same K to obtain the reverse side of the equivalence.
00:53:03.832 - 00:53:04.188, Speaker A: Right.
00:53:04.274 - 00:53:14.080, Speaker C: Is there some intuition to why this should be the case and why I should not be able to take other level set curves for the same scoring?
00:53:14.660 - 00:53:26.244, Speaker A: I think so, and I think I'm going to show you some pictures that give some insight into that. So can I ask you to ask me again after a few more pictures? Of course.
00:53:26.282 - 00:53:26.964, Speaker C: Thank you.
00:53:27.082 - 00:54:41.790, Speaker A: All right, let me just quickly say this other direction and then there's really just one more main result that I want to state before the end. The other direction is given a phi from a CfMM, it's concave and increasing. And given a particular level set that you're on, or Q zero initial reserves, we can create a cost function using this kind of weird looking construction that the picture illustrates, but is really not that important to the talk that comes from risk measures. And this is a convex ones invariant function and the set of trades is equivalent up to cashlessness. So anything that the original CfMM is offering as a valid trade, the cost function is going to offer that as a valid trade plus any sort of conversions of one's vectors to cash. Okay, let me try to speed through a couple comments and show that picture and then we can kind of have any extra time for Q A. Okay, so should you use this to turn prediction markets into Cfmms? No, because of a picture I'm going to show there's a problem and we're going to fix the problem.
00:54:41.790 - 00:54:52.076, Speaker A: You can use it to turn Cfmms into prediction markets. As commented. So the constant product market, if you work it out for two assets, you get this expression.
00:54:52.268 - 00:54:59.648, Speaker D: Okay, but if I take negative of that, and if I take minus C of minus Q, I don't get the original thing, right?
00:54:59.734 - 00:55:07.796, Speaker A: Yeah, I think you must get something whose level set matches this particular, and it's going to be different in all the other level sets. Actually.
00:55:07.898 - 00:55:12.608, Speaker C: Yeah, I think it relates to my question, actually. You need to have the same concept.
00:55:12.784 - 00:55:56.164, Speaker A: Well, isn't it the case that one is one invariant and one is one homogeneous, and so that you're just going to run into you're just not going to be able to do that. And that's exactly what we're pointing to. So I'm not going to expand on your comment quite yet. Okay. So let me just say that this expression actually appeared in 2007 in Chen and Pennick's paper. They weren't doing Cfmms, but they got this from if you have a log utility and you have a uniform distribution on outcomes, and you try to trade so as to keep that utility constant, one half log plus one half log is the same as the square root of the product being constant. And so they've actually already derived this.
00:55:56.282 - 00:56:04.012, Speaker D: So in some ways, up to the exact axioms, utility based prediction markets are the same as CFMS.
00:56:04.176 - 00:56:45.716, Speaker A: Yeah. And one homogeneity becomes interesting here because the part we thought was coolest is to Scott's comment earlier, this implies that Uniswap has a scoring rule, proper scoring rule associated with it, which is pretty cool. And any convex CfMM is going to have a proper scoring rule. Yeah, that's so, yeah, yeah, and it's actually known it's very rare, but it is a known scoring rule. So yeah, let me just leave this here for a second. Show that picture and then conclude at approximately time. Yeah, okay, let me explain this.
00:56:45.716 - 00:57:37.060, Speaker A: So Cfmms don't quite elicit valuations the way that prediction markets elicit probability distributions. Because if I think Ethereum is worth $1 and bitcoin ten, you think Ethereum is worth 1000 and bitcoin 1000, we can still trade at a ratio of ten to one and no one can tell those beliefs. So you can't distinguish that, but other than that, you could really say that it's an elicitation problem for ratios of valuation. Okay, so this is the problem. Our prediction market equivalents construction produces these kinds of level sets which are ones invariant, but that's not what CFM should look like. They should look one home. Oh, they also do this, which you really don't want to do go into the negatives.
00:57:37.060 - 00:57:38.870, Speaker A: They should look.
00:57:39.240 - 00:57:46.712, Speaker B: So the red level set is what you applied your construction to. And then you're saying these blue ones are the sort of implied ones, if you yeah, okay.
00:57:46.766 - 00:58:07.488, Speaker A: Yeah. Sorry. So I started with a cost function which was LMSR, and I applied it. And one particular level set it produces is this red one. But if you look at all the level sets it produces, they're all the blue ones too. So one level set looks reasonable, but the collection does not. And if you want to change liquidity levels, you want to be able to do that.
00:58:07.488 - 00:58:43.604, Speaker A: So, as someone mentioned, that the correct property is one homogeneity. And basically you can fix our construction to be one homogeneous instead. That's the main result of this. The second main result, one homogeneity means basically that every level set is a scaled version of the other, sort of scaled from the origin out, I'll say, in the interest of time. So the behavior out here is just a scaled version of the behavior down here. And it really means you have more liquidity. So this is what you want your CFMS to look like.
00:58:43.604 - 00:59:08.850, Speaker A: And we can even prove something like any concave one homogeneous increasing you're defining it implicitly. Yeah. We kind of had to make this weird definition in order to convert NEC into a pot. Yeah. I'm sorry, I don't have time to properly explain why this works. Okay.
00:59:10.340 - 00:59:18.550, Speaker F: Maybe one thing to note is that it happens to implicitly give you the perspective transform. I don't know if you were going to make that.
00:59:19.320 - 00:59:43.324, Speaker A: Yeah, sorry. So we talked earlier about how scoring rules use the way to scale it up. The proper way is the perspective transform, and that's what's happening here. Okay, so let me stop there. I guess that's actually okay, you can do this with LMSR. It's interesting. Let me stop on this conclusion slide and let people go take questions from anyone who can stay.
00:59:43.324 - 00:59:44.124, Speaker A: Thank you.
00:59:44.242 - 00:59:45.150, Speaker B: Thanks, Will.
00:59:47.940 - 01:00:33.960, Speaker C: So I think if we can go back to this slide, the second construction that you had, the second main result that you showed. Yeah. This one over here. So this theorem, as I see it, means essentially that I can essentially, to find the phi that corresponds to the scoring rule, I can just take the alpha as phi of Q, substitute into the C's and solve this equation. Right. But then if I do that, want the phi that's resulting from that have also some dependence on this alpha or the K rather that's implicit in the scoring rule C sorry. In the cost function that corresponds to the scoring rule.
01:00:33.960 - 01:00:49.590, Speaker C: So essentially, because C has a K dependent simplicity in it, then does this mean that the phi will also have a K dependence on it that results from this procedure over here?
01:00:50.280 - 01:01:10.890, Speaker F: So now, finally, if you start with uniswap, you get the cost function from it and then you apply this construction back. Indeed, you do get all of Uniswap so that it doesn't have a dependence on K anymore because as you scale, you'll get the other K values back. Is that the question?
01:01:12.380 - 01:01:25.576, Speaker C: Yes, that's what I was asking. So you're saying since even though C has an implicit K dependence, the phi that I get from solving this equation won't have a K dependence.
01:01:25.688 - 01:01:26.350, Speaker A: Right.
01:01:27.700 - 01:01:47.510, Speaker F: It's basically because Uniswap is one homogeneous and it suffices to just specify one of the level curves and then one homogeneity will uniquely fill in the others. So that's basically why you can recover it.
01:01:49.080 - 01:01:49.588, Speaker A: Yeah.
01:01:49.674 - 01:01:50.550, Speaker C: Thank you.
01:01:51.480 - 01:02:00.090, Speaker A: I was just going to say there are a couple things open directions I could mention if there's time, but other should take questions instead.
01:02:01.100 - 01:02:03.690, Speaker C: I think since we're in the Q A portion we have.
01:02:05.980 - 01:02:54.120, Speaker A: Yeah, okay. Curtis so extending connections that prediction markets already have to Cfmms probably could be cool. One is online, no regret learning. So it turns out that this famous multiplicative weights algorithm is basically equivalent to the LMSR prediction market, where basically the time interval is shrinking to zero. You're sort of adapting in real time to trades. And in general, these follow the regularized leader learning algorithms, which are very natural things to try to use for market making or trading, are equivalent to cost function prediction markets. So you should be able to trace that through and say that a CfMM is using no regret Learning to price things.
01:02:54.120 - 01:03:28.644, Speaker A: That'd be a cool result to actually have, but I'm pretty hopeful. Another thing prediction markets do are they work with assets with negative values all the time. And you can extend prediction markets, as I've presented them to deal with assets that people value as negative. So like options that people agree have a negative value, you can price those. And as Tim mentioned at the beginning, we think of Cfmms in the positive. Well, okay, these things are related. Like holding positive quantities of things that have positive value.
01:03:28.842 - 01:03:33.524, Speaker D: I wonder how much of that, though is imposed by the blockchain.
01:03:33.572 - 01:03:33.736, Speaker C: Right.
01:03:33.758 - 01:03:50.332, Speaker D: Because there's no credit and so on. Right, as opposed to being fundamental to the mathematics of the yeah, like for example, if it was implemented like, let's say at a bank and they're extending you credit, they could allow you to hold negative positions or whatever.
01:03:50.386 - 01:04:36.510, Speaker A: Right? Yeah. It seems like it shouldn't be a barrier, but all the pictures we draw clearly stay in the positive orthodont no matter what, and they all assume this sort of trade off that's like, if I have more apples, I should have less oranges. But if oranges have negative value, this whole picture is wrong. Right. So it might be easy to do, but I think there's something proper to do. Prediction markets, we love combinatorial markets, so it becomes about sort of efficiently approximating what you would have done if you wrote down the whole space that could be interesting. And when you do that, this idea of arbitrage reduction becomes interesting.
01:04:38.480 - 01:04:50.096, Speaker D: Just to explore the combinatorial markets, the idea there would be in prediction markets, it's easy to have markets over these N things. You have the scoring rules, whatever. If I want to write down a CfMM curve for N assets, it's not.
01:04:50.118 - 01:05:24.040, Speaker A: Clear, sort of yeah, I just thought of at least porting techniques from there. It's not necessarily easy for prediction markets either, but it's something people did think about and write papers about. Yeah. The log market scoring rule has this unique property that orthogonal markets are kind of orthogonal. Like you can resolve some while keeping the rest going and you don't have to recalculate stuff. So maybe you should use LMSR instead of uniswap, but maybe fruitful.
01:05:25.520 - 01:05:28.540, Speaker C: So what do you mean by arbitrage reduction in this slide?
01:05:29.120 - 01:06:05.108, Speaker A: Yeah, so when prediction market people say arbitrage, they really mean a chance within the market itself to make trades over time that guarantee to make money. When CfMM people talk about arbitrage, they're talking about correcting the price right between different markets. Like this market has this price, this market has this price. So in this case, I mean the prediction market one, which is if I have a bunch of assets, like some of them are options on other ones, or they're relationships that I know, then the prices should reflect those relationships.
01:06:05.124 - 01:06:06.596, Speaker D: For example, one's invariant.
01:06:06.708 - 01:06:44.100, Speaker A: Yeah. So if anything, that's overdetermined where, for example, in my prediction market, I have a security that pays off if a team with a red jersey wins. Well, if you sum up the prices of all the teams with red jerseys, that should equal the price of that security. Can you bake that in as a hard constraint so that people just don't make money arbitraging those things? Can you actually force the market to adjust to trades so that this is always a hard constraint and kind of bake it into the pricing rule?
01:06:44.760 - 01:07:19.200, Speaker C: I have one more question. So initially, can you go back to the slide where you had the handling, the perspective transform as the example? Yes, this one. So I'd like to ask something here, essentially, how does this perspective transform for the cost function prediction market relate to the grand bundle, the one scale environment, essentially, that function C must satisfy? Is there some relation between these two or are they completely unrelated?
01:07:24.100 - 01:07:53.930, Speaker A: This fact, the perspective transform fact, which is if I scale the primal convex function by 100, the dual of that new scaled function is 100 times the old function of Q over 100. So that's a fact about convex conjugates and that's more general than that's. Like all convex functions and that have conjugates. So it doesn't need ones invariants, which is that fact.
01:07:57.760 - 01:08:00.300, Speaker C: So they're completely unrelated, essentially.
01:08:02.240 - 01:08:02.990, Speaker F: No.
01:08:04.400 - 01:08:04.764, Speaker A: Yeah.
01:08:04.802 - 01:08:18.690, Speaker F: The ones invariance is really just coming from the fact that the scoring rule is defined on the probability. Guess, but I was going to slip in this comment. I forgot to mention that.
01:08:20.440 - 01:08:21.012, Speaker A: It is.
01:08:21.066 - 01:08:53.470, Speaker F: Interesting that I think someone made a comment. Maybe it was you, Jason, that you get a scoring role from uniswap, but it depends on K. It's particularly nice when you look at the perspective transform because each level set of uniswap is literally the same scoring rule just scaled up. So you don't even have a complex kind of transform when you look at it as a scoring rule. Yeah, it's that b. So it's just the same exact scoring rule, but scaled up by B, which is especially nice.
01:08:54.080 - 01:08:55.150, Speaker A: That's cool.
01:08:57.140 - 01:09:15.492, Speaker C: That's very nice. But still, that means that the phi will still depend on the B, right? That does not, I guess, guarantee that there won't be a dependence of the phi that's resulting from the procedure on B. Right?
01:09:15.626 - 01:09:24.440, Speaker F: Or is it b would be the geometric mean, say, of the current reserves.
01:09:27.420 - 01:10:16.890, Speaker A: And there will be a dependence. So maybe this will be helpful. If you start with this outermost blue curve and you turn that into a scoring rule, that scoring rule will have a higher B factor and it'll have more liquidity. If you turn that back into a CfMM, what will happen is we'll first get this one curve and then we'll get the one homogeneous sort of extension of that curve, which is this same CfMM everywhere. So whichever curve you start with, you do end up with a different scoring role because it's scaled. But then you come back and you come back to that same level set, but then one homogeneity ensures that you get the same thing everywhere. Did that help Jason? I hope.
01:10:21.500 - 01:10:59.220, Speaker C: I mean, correct me if I'm wrong, but I do think that if I plug in, there the C that depends on the B and then I solve in terms of the alpha, then I think the alpha I'm going to get is going to be the square root of Q one q two divided by B. Right. So I think this is the alpha that I'm going to get from solving this equation. So I cannot really see how this is independent of the piece, but we can take this offline if that's easier.
01:11:00.120 - 01:11:48.980, Speaker F: I think I know what you're asking and I think I ran into this when I was it also confused me, but somehow yeah, so you could think about it. Actually, Bo, could you go to the one with the parallel level? If you, if you choose a different one of these level sets and then you take the one homogeneous extension, you will get a different function. So part of the magic is that it turns out from our first construction, the zero level set is always the right one, so that if you take the one homogeneous extension, you get back the same function. But if you weren't careful about that, you're right that if you choose a different level set of the cost function, then you'll get a different function and you might have some dependence.
01:11:50.120 - 01:12:19.440, Speaker C: Yeah, I think I do agree that throughout this procedure, if you're taking the whole class of functions, then the whole class of function is going to have the correct correspondence, but I think the curves one to one won't have the correct correspondence. I think this is what's going on here. But as you're saying, if I take the whole class, then by one homogeneity, that's going to be fine, essentially. But, yeah, I think that's very interesting. And thank you for giving your viewpoint.
01:12:20.820 - 01:12:27.790, Speaker A: Thanks so much, everyone. And thanks, of course, to RAF and Manisha, six authors and yeah, we'll see you next.

00:00:09.950 - 00:00:18.606, Speaker A: This morning, we're going to have the second talk of the two this week by Katini Bomitsi, who's one of our summer faculty fellows and a professor at George Masoni.
00:00:18.638 - 00:00:19.182, Speaker B: All yours.
00:00:19.246 - 00:01:02.386, Speaker C: All right. Thank you, Tim. So the plan for the day is to talk about anonymous credentials. And I'm going to spend most of my talk actually giving you the background on the space and explain how anonymous credentials and anonymous authentication used to work in the past. And then towards the end of the talk, I'm going to kind of modernize things a little bit and discuss how decentralization can help in the space. So let me start for a second and have you all think about how many online electronic transactions or like digital transactions we now do. We use like, the Metro card, the Office every day.
00:01:02.386 - 00:02:09.446, Speaker C: We use cryptocurrencies. We use services like Netflix, social media, online store services, and so on. And let's think for a second, how much personal information do we leak through all these services that we use? Okay. And also pause back and think how much information would you leak if you were paying for all these services with, for example, physical coins or if you were not authenticating before accessing any of these services? So the amount of information that we leak is a lot. And even if we don't think that we're actually leaking information that can identify us, this is very often wrong. There has been studies that actually show that a very large percentage of the population can be uniquely identified by having three unique attributes like date of birth, gender, and zito. So towards this end, there has been quite some policy discussions the last few years on how can we actually minimize the data that we provide online, both in the European Union but also in the US.
00:02:09.446 - 00:03:12.650, Speaker C: Mostly in certain states. I would say the main principle for these guidelines is that the collection of personal data should remain the absolute minimum that we need for whatever service we're using. So the question that we're trying to answer here is if we want to retain our privacy, does it mean that we have to stop all these very convenient and nice electronic transactions? And the answer is no. Luckily, we have a lot of research and many cryptographic techniques in the space that can help us with that. We can use privacy preserving protocols. And the main focus of today's talk, and I think a core focus for anonymity in digital transactions is that of authentication, because if you think about it, most of the information that we actually leak, it happens at the point that we authenticate in order to access the service. So what is our goal here? So let me start stating what we want by anonymous authentication.
00:03:12.650 - 00:04:17.520, Speaker C: So, ideally, we want to have users that have digital credentials that list the whole bunch of attributes, like their name, date of birth, address, country, maybe some unique ID number we want the Credential to be issued by some sort of legitimate issue. You could think, for example, as this thing like the state identity of I. And then what we ideally want is to use this Credential to use this information in a completely privacy preserving manner. So let's think for a second what happens when people go to buy leakers today, right? So you walk into a store like CDC, actually, you walk into a store and you saw your identity card, and the information that you leak is so much more than what they need to know. So what they need to know is basically that you're over 21 years old. It doesn't matter if you're 22 or if you're 55. It doesn't matter what's your name, what's your address, or any of these or any of this stuff.
00:04:17.520 - 00:05:22.200, Speaker C: So ideally, when we're building towards private anonymous authentication, we should aim for the best privacy that we can get. And the ideal goal here is that we should just literally be proving statements about our attributes that reveal the minimum amount of information that is needed for any foreign type of transaction. So, for example, here Dasa, the aid that is embedded in this Credential is over 21 years old. Another crucial property that we want from SAS digital credentials is that we want the issuers of the Credential to be unable to trace the transactions of the user. So this is not as easy in the physical world. So the state of New York would be very hard to try to trace you where exactly you physically saw your state ID. But in the digital world, if you just think of these IDs as being like a series of bits, it's much easier to actually trace where this information is being used.
00:05:22.200 - 00:06:23.480, Speaker C: So an ultimate goal of anonymous credentials and anonymous authentication is that whenever a user is using their credentials and this might mean that they either might literally solve the Credential as it is, or so certain predicate compute certain proofs on top of the attributes of the Credential. This sewing process should be unlinkable to the issian process. To the issians process. So if the Verifier colludes here with the Credential is here, they shouldn't be able to figure out who was the user that saw this proof. Additionally, even if the Credential user creates more proofs to access other services as well, even if the proofs are on the same attributes, and here I'm conveniently bringing up an attribute that it's not unique, because if it was like the ID number, then maybe there is like an obvious uniqueness property there that should also be unlinkable. Okay? So this proof should not be linkable to this proof. No matter who colludes, no matter who gets access to the Verifiers issuers, nobody should be able to link it together.
00:06:23.480 - 00:07:27.190, Speaker C: Are the goals clear? So if you think about it, and if you ever took like a crypto class, you might already start thinking how can we achieve these properties? By known cryptographic tools. And if you again think of what are the properties that we want here? We want credentials to be issued in a way that obviously they should not be formed. I should not just be able to create fake credentials. And then if I want to do like, proofs using some sort of privacy, it might become pretty clear to you that we might be able to construct some sort of generic constructors using digital signatures for the instance of the credentials and then zero knowledge proofs for the credential showing. The problem with this approach, although it technically works, is that it's not really efficient. Okay? So if you just try to randomly combine different types of schemes together, you're not going to come up with the most efficient constructions. And in certain cases of authentication, you actually really care about efficiency.
00:07:27.190 - 00:07:45.186, Speaker C: So you should be able to access the service and issue proof in like milliseconds. Even seconds are not acceptable. Okay, so literally think of entering the subway, right? Imagine if everyone would have to sit in front of the address and take like 30 seconds to enter. Okay, this is not so for the.
00:07:45.208 - 00:07:50.114, Speaker A: Unlinkability property, if you use each generic, would you just like add a nonce or something like this so that you.
00:07:50.152 - 00:08:03.660, Speaker C: Never yeah, so basically we can just create a fresh zero knowledge proof for everything that you do, for every statement that you saw. And as long as these proofs are not kind of randomizable, you can be fine.
00:08:04.590 - 00:08:13.126, Speaker D: Do you have any concrete numbers, like how slow it might be to use a generic, let's say bulletproof?
00:08:13.318 - 00:08:40.980, Speaker C: Yeah, that's a good point. I don't have concrete numbers and nobody has as far as I know. This might make like a nice, I don't know, student progress. But even if my understanding is that even if verification could not, maybe it's not that bad. Still computing the proof itself with any sort of these generic proofs, it's going to be pretty ugly. Again, we're talking about milliseconds here.
00:08:41.670 - 00:08:45.974, Speaker B: Why does the proof generation need to be that fast if you can kind of like pre compute it?
00:08:46.092 - 00:09:18.698, Speaker C: That's a very good point. So you might not always be able to pre compute it. So it might be the case that actually the authentication process is an interactive protocol with the entity that you want to authenticate. You might not know ahead of time what kind of attribute exactly they're going to ask for. It might be time specific. Again, like for the subway, it might have to be tied to the exact time that you're entering the subway because maybe the charging policy has to do with how many hours you're using the train. So there are many, many parameters that generically, you cannot say that pre computation is acceptable.
00:09:18.874 - 00:09:30.626, Speaker E: There's also issues with difference between time of use and time of check or time of issuance and time to check right, so I imagine that would be even more crucial here with the anonymity anonymous, right?
00:09:30.728 - 00:10:37.514, Speaker C: So absolutely, yeah, there can be a time. So the reason was such generic constructions are not efficient, as I said, is if you just like plugging things together kind of randomly, it's very, very hard to make them compose well and nicely and very efficiently. And this is the reason that we actually have over, I think at this point, maybe like 30 years of research on the subject of anonymous condensers, which basically means that how can we build specific cryptographic primitives for this very particular problem. So very tailored and very, very efficient. So when we think about anonyms credentials, I like to kind of split them in two categories. The so called multi use anonyms credentials that are based on general signatures I would say, well, with certain properties in some cases and zero noise loops. And the so called single use anonymous credentials which are almost exclusively based on a special type of signatures called the blind signature and potentially zero knowledge proofs depending on what you're trying to sort the end.
00:10:37.514 - 00:11:54.980, Speaker C: And as I said, there is a very, very long line of research. I'm not exhausted by any means here. Starting back in the same time, there have been quite a few efforts to actually commercialize to implement those protocols by Microsoft, IBM and Microsoft consortium under a European project that later kind of spilled over, hyperledger indie and even Signal these days actually uses anonymous Credential techniques for authenticating users in groups. So what is the difference between the two and what do we prefer in this case? So the idea of a multi use Credential is that I get a Credential issued once from the HR, so I interact with HR once I get one object and then I can reuse this object multiple times in order to authenticate. So naturally multi use credentials make sense in subscription services or if I actually want to digitalize my state ID or my password. Single use credentials are credentials that are literally issued and can only be used once. And as a matter of fact, if you use them twice you might actually lose bright in case you might be actually able to link them together.
00:11:54.980 - 00:12:49.086, Speaker C: However, there are certain cases where single use credentials is what we need. So for example, you might want to issue some sort of like single use coupon. You're using this type of credentials if you want to build like a new voting scheme where you need to have like a ballot that can only use once. And also single use credentials naturally give what is called or what we used to call in the space before blockchain again electronic cuts. So they would naturally give this coin that you can only use once. The caveat here is that single use credentials are actually much more efficient and this is going to become apparent because the main idea is that you get a Credential issued, you get a signature. And then during presentation, depending of course on what kind of statement you're proving, you might not even need to do a zero proof.
00:12:49.086 - 00:13:21.870, Speaker C: You might just literally show a signature and presentation. That literally means signature verification and done. So you're not verifying the proof because theater is verifying a signature and maybe the proverb needs to do absolutely nothing that heaterally presents a signature. So I would even argue that in certain cases that you know that you're not going to use a Credential many times. So let's say that I know that I'm only going to use a Credential like two or three times. It might actually make sense to issue three single use credentials instead of getting one multi use Credential. So it might actually be more efficient.
00:13:21.870 - 00:14:19.610, Speaker C: So let me start the discussion with single use credentials because I think that actually the techniques are pretty interesting here and they were first introduced back in the core primitive is a special type of digital signatures that are called blind signatures. And for those of you that were here on Tuesday, you might got bored hearing me talking about all these different types of signature schemes. But I saved one for you today that I didn't cover on Tuesday, blind signatures. I could have easily put that on Tuesday as well because they are used in certain web3 layer, two multi applications. But I wanted to say one more signature for you. So the core primitive is a blind signature and I think it's a very interesting type of signatures and they want to explain to you how they work. So when Brands, Stefan Brands defined single use credentials, he used an elliptic f based blind signature.
00:14:19.610 - 00:15:03.230, Speaker C: That was three rounds. And the problem with that scheme was that and again, things that were back in the 90s, people do not really have so formal security models, definitions, so they don't care about security proof so much. So the problem was that no security proof was given. And the interesting part here is that Microsoft Conveyor's Digital Identity project you proved back then, was actually adopting the signature scheme. So when I started working as a PhD student, one of the first tasks that my advisor assigned to me was actually proof security of this scheme. She was like, well, people are talking about the scheme for so many years, it doesn't have a proof security. So I was trying really hard and I was failing.
00:15:03.230 - 00:15:36.202, Speaker C: And at some point we actually came to a realization that it was kind of impossible to prove this information. So again, we didn't find an attack. We essentially came up with an impossibility result. We ruled out in a sense, the number of techniques that one could use to prove the skim secure for the cryptographers in the room. We did that using a technique that's called the meta reduction. So we said that if there is a way to prove the scheme secure, then you can break a hash problem. Okay? So again, this is not an attack.
00:15:36.202 - 00:15:44.986, Speaker C: We're not saying that the scheme is not secure, but this is certainly an issue. Right? We're not as cryptographers, we're not so happy to implement and use schemes for.
00:15:45.008 - 00:15:51.600, Speaker A: Which security is actually the meta reduction was for proving security in a particular way.
00:15:54.930 - 00:16:45.086, Speaker C: The way that it works, we're pretty much ruling out many ways. So it's not like one particular way. But we were even saying metal reduction says that even if you assume that the scheme itself is secure, you still can screw it secure, which is kind of funny. Yeah. So meta reductions, I think we've seen meta reductions for different primitives in crypto. This sort of impossibility metadata for different primitives in crypto the last years. And something that I should also note here is that actually blind signatures are a type of signature scheme that is notoriously hard to prove and there are many subtle details when trying to prove security.
00:16:45.086 - 00:17:56.454, Speaker C: And I'm going to come back to this topic soon. And after we realized actually that this scheme was not secure, well, not secure, was not provably secure, we actually came up with a scheme with very similar efficiency that we could actually so let me give you a high level idea of how blind signatures work and how we can get anonymous credential from blind signatures. So the idea of a blind signature is kind of untraditional to the regular signatures that you have a user that has a document and has a signing keys and that signs the document instead, you can think of a blind signature as a two party protocol. You have a user that has a document and then the signer is a different editing. So what is the goal? The goal is that Alice wants to get a signature on her document from the signer while hiding the method from the signer, while having comfortability. So Alice should not be able to compute signatures that verify under the signer's public key alone. And at the same time, we also want a linkability which basically says that if the signer at the end of the signing process sees the final signature, it cannot link that, it cannot connect that to the signing process.
00:17:56.454 - 00:18:48.310, Speaker C: So it doesn't know that this is a signature that was issued to Alice. So in a very career. The idea is that Alex can take the document, put it in a box, lock the box, and you can think of this as being some sort of a cryptographic commitment here. So I can commit to that, have some secret randomness that was used for the commitment. Send this committed document, this hidden document, to the signer. The signer using its secret key is going to compute a signature that I call Sigma Star. On top of these hidden methods, send the Sigma Star back to Alex and then Alex using Sigma Star and the randomness that used in order to hide the methods can actually unblind the signature to a signature sigma that will verify under the sign of public key for the original document, not for the commitment.
00:18:48.310 - 00:19:32.310, Speaker C: So we need a minimum of two rounds for such client signature protocols. But I hope that this becomes clear because the user needs to send something to the signer before the signing process starts. And the efficient protocols that we have in the space are actually three rounds. Okay, so we have some constructions in two rounds that are not as efficient as we want here. So now, again, the important part is that obviously Alice cannot create signatures herself. But also if the signer sees the signature sigma in this document, they cannot link it to the signature sigma star that they create here. They look like two completely different signatures.
00:19:32.310 - 00:20:14.846, Speaker C: So how can we use these signatures now as a means of anonymous authentication? So let's say that Alex wants to provide this credential to some Verifiers. You could think, for example, of this as being some sort of token. I don't know, think the Uber code that Claire sends us whenever we go out one night. So we have this like one time token. We want to use it to some Verifier uber, let's say. So what we can do is that we can literally just present the signature and the method that says, this is one free ride, and the Verifier will just verify that the signature Verifies under the signer's public key. And again, the nice property here is that even in the Verifier and the signer colludes.
00:20:14.846 - 00:20:25.766, Speaker C: So even if Claire colludes with Uber, they shouldn't be able to find out how we travel, how each user uses one time coupon, their one time code.
00:20:25.868 - 00:20:27.094, Speaker B: Okay, quick question.
00:20:27.132 - 00:20:34.070, Speaker A: Yes. So to do the unblinding, you need to know both the original document and the randomness.
00:20:34.490 - 00:21:34.250, Speaker C: Yeah. So you needed to know the original document because the signature will be very fun to original document, and you typically need to know how you blind this. So basically, again, in a very high level way, you are blinding the document. So the signature is also kind of blinded under the same randomness, and then you somehow kind of divide out this randomness and you have both the unblinded method and the unblinded signature, again, in a very high level. So something that we have to be careful about here is what happens if the user is malicious and tries to reuse the same one time token. So here the problem is that ideally, what should happen is that the Verifier should be able to reject this token because it has been already used. And unfortunately, the only way to do that is to literally maintain a list of all the used credentials, of all the credentials that we've seen and make sure that this doesn't appear there.
00:21:34.250 - 00:22:08.754, Speaker C: Okay, so there are certain techniques to avoid holding this list that might become very large. You might have expiration dates in the credentials. So you might have credentials that only last for a week or a day or a few hours so that you don't really need to hold anything that has expired. So the way that I presented credentials with single use credentials so far, I didn't talk about attributes at all. And this was something that we really cared about. I just said you have this one time token that we literally just want to sew it. And that's why I said that at this point this was super, super efficient.
00:22:08.754 - 00:23:03.254, Speaker C: You see like during sewing they use it with absolutely nothing like zero computation. Literally just presented a signature, verified the signature, that was it. Well, if you start adding more complexity in the system now if you start adding attributes, things will also naturally become a little bit more complicated both during the issuance process but also during the verification process. So now think that in this one time token we also want to add attributes for the user. So we might want to add, I don't know, like secret keys hidden in there, the name, the date of birth or something like that. So the idea here is that so now that the methods might become more complicated or in certain cases you could actually think of the attributes as being like a second method concatenated with a method that we are actually signing. So maybe a simple way to think about this is it.
00:23:03.254 - 00:23:49.014, Speaker C: I think of this as like coins, digital coins. Think of the method as a unique serial number and then think that you're also attaching a bundle of attributes. Why is it useful if you use these coins, let's say to enter the subway, you might be able to show that you get like a senior discount because your age is over, I don't know, 60, whatever should be. And you might want to actually have more risk credentials that have more information even if they're single use ones. So the idea there is that you can start by committing to your attributes. Potentially you might need to include a zero knowledge proof that whatever you committed into here is correct. And in certain cases you might need some sort of physical means to do that.
00:23:49.014 - 00:25:03.950, Speaker C: So you might literally need to show like a physical identity to prove to the HR that, yeah, whatever I'm putting in the commitment are my true attributes. And then the time this now are you want to create a blind signature on some methods that also includes the commitment. If you just literally sign the commitment, this is going to get problematic. Why? Because we cannot rely on the user to randomize the commitment because maybe the user will randomize the commitment in anonymous in a malicious way and add different attributes from the ones that actually the signer verified that are correct. So if we just consider C as the method that we had before and allow the user to hide it. Who guarantees that the user is just not putting different things in there, okay, if it's completely hidden from the issue. So the challenge here is to actually create a blind signature scheme such that the user and the signer jointly randomized C in a way that the final signature will be on a C on a commitment that the signer doesn't know, but at the same time the user cannot obtain the committed attributes.
00:25:03.950 - 00:26:18.070, Speaker C: So to achieve that, we define the variation of blind signatures that we call blind signature with attributes. And things there get quite more complicated, actually show you how it works. But again, the high level idea is this joint randomization of the commitment in order to issue the signature. So at the end, what Alice gets is a credential sigma, a signature on a randomization of the commitment c on the attribute c prime such that it was created in a way that it guarantees that are the same. Attributes included as the ones here that the signer verified, but also in a way that guarantees ambient ability with the C that the signer knows for this commitment, for this user. And if you think about it, you could literally think of this phase as being some sort of like a one time registration phase. So if you think of this as ECAPS, you can think of the issue as being the bank that you register once saw your full credentials, opened your account and whenever you go to your bank to get one time tokens, one time coins, you just run this page.
00:26:18.070 - 00:26:38.582, Speaker C: So you basically keep on re randomizing this commitment, okay? And potentially the bank will be crossing out coins from your account. Does this make sense? I know that these are quite complex ideas if you've never heard about them, okay?
00:26:38.716 - 00:26:44.710, Speaker A: It's easy to say in a sentence or two a little bit more what like jointly randomized means concretely.
00:26:46.030 - 00:27:36.086, Speaker C: So literally what happens here is that, again, think of this as like three round protocols. So the Simon starts by randomizing the commitment. It is a Penderson commitment for those that they know that they're based on this grid log. Literally the signer can pick some randomness and put it on the exponent of the commitment and then this is sent to the user. The user is going to add some additional randomness. The point there is again, that you want to make sure that the user is randomizing, whatever it got from the signer and not something new. So the signature will only go through if the committed method is a randomization of what the signer commuted.
00:27:36.086 - 00:28:32.670, Speaker C: So it might not know what was the second randomness factor used by the user, but it has to guarantee that it's just like adding extra randomness and whatever the signer started with. Because again, if we allow the user to completely randomize things and do whatever they want, they might just put different attributes there that are not fast. So it's pretty tricky again for the cryptographers to get in the room. These blind signature schemes in a sense work as a node proof. So the user is while the sign is actually either proving that knows the secret key or that knows this randomization. So they're kind of pretty involved come up. So on top of the properties that I was mentioning before, like unfortunately and unlinkability, obviously what you want here is that when you open, if you open these credentials, these commitments shouldn't be able to open the different attributes.
00:28:32.670 - 00:29:44.554, Speaker C: So here when you're using these now tokens, these one time credentials with attributes when you present them, if you just want to present them as a one time token and have like this one time access again as before, you might just literally reveal the signature on the method C prime. Or if you need to do some sort of partial opening, the nice thing about this commitment is that there is a very easy and efficient way to just open one of the attributes. So just solve the AIDS and nothing else. Or if you don't even say want to solve the aid, but so some sort of predicate like my aid is over 21 years old, add some sort of zero knowledge proof on top of that. Okay? So having of course you cannot avoid the zero proof here if you want to do some more complicated proof. Again, the properties should be that these are unlinkable. So no matter how many accounts designer controls, no matter how many commitments designer knows and how many tokens it has created, it shouldn't be able to link any presentation of different answers.
00:29:44.554 - 00:30:29.598, Speaker C: And of course we should be mindful about privacy here. So if an HQ has a single user that is over 90 years old, then obviously they can be anonymized, right? So you should always think that the level of anonymity that we get here is some sort of set anonymity on other people that have the same or similar set of attributes as you. So as I said, we came up with this nice scheme that we called Anonymous Cadence's Life and it's kind of stayed the state of the art for many, many years. The scheme is besides giving this three rounds, it is based on intakes. It's relatively efficient. It just has like it's discrete log base. It only has a number of exponentials.
00:30:29.598 - 00:31:08.474, Speaker C: But the thing that I want to highlight here, again as a cryptographer is that the security proof that we had for the enforceability of the scheme, it was only working in the so called sequential setting. So we're saying that our scheme is enforceable. It's impossible for an attacker to false proofs as long as the issuer was issuing one proof at a time. And again, remember that these are interactive protocols. So if you think of the issue as being some sort of server in real life. You might actually want it to have multiple signing sessions open with multiple users. But we didn't manage to prove security and the parallel composition.
00:31:08.474 - 00:31:53.550, Speaker C: We left that as an open problem. So almost ten years later, Wesl had an attack. Okay, so there was a very nice paper that came up and said that many blind signature schemes, mostly discrete log base, but not well, as I guess mostly discrete log base, are not secure under parallel composition and the final Issuance. So this is a concrete attack. This is not some sort of impossibility design. If later I said that if there is over threshold of open Issuance sessions, then we can actually forge signatures. Okay, so this was pretty annoying.
00:31:53.550 - 00:31:55.566, Speaker C: Yes.
00:31:55.588 - 00:32:00.938, Speaker A: So you're saying consider the considered just.
00:32:01.104 - 00:32:35.990, Speaker C: Naive parallel composition when you still it was not naive. The technique was actually using some math. So they literally showed an attack that said that if you have multiple issues, sessions open. So if you started interacting with multiple users for multiple methods so think of this as some sort of like linear composition. So some sort of linear equations. If you combine all the information that you know from all the open signing sessions, combining all them together allows you to create a forged signature tool for something else.
00:32:36.060 - 00:32:40.550, Speaker A: So it's not even like you need them to be proceeding in two bolts like back and forth.
00:32:42.010 - 00:33:30.230, Speaker C: No, if you can pull the information from all of them, then right, so if you're like a network attacker that you're observing what's happening and you have all these sessions open and again, I mean, you need enough sessions to be open, but again, the parameters would depend on every particular scheme. But yeah, you could some sort of linearly compose all the information that you had and manage to and again, this is like an impossibility thing. They didn't just say that security is impossible in the parallel setting, they actually sold an attack. This didn't violate anything with our proof, for example, or other proofs because our proof was only in the sequential setting. We never claimed security in the parallel setting. But this is something that actually raises concerns about how to use these kins.
00:33:30.890 - 00:33:35.660, Speaker A: How did you use the fact? How does the proof use the sequentiality like, is there some way.
00:33:38.320 - 00:34:14.550, Speaker C: The previous one no, again, the reason that this attack works is that these protocols are usually three round. So they use the first two rounds of every open session, not the third one, in order to conclude to a third one like a closing one that works. So if you do it sequentially, if you close every single session before you move to the next one, then you're not able to do that. But if you are able to interact with the signer in a way that you can mold things by using other open sessions at the same time, then you can come up with a four day.
00:34:15.320 - 00:34:23.288, Speaker E: Is it a semantic security issue where you're using some sort of because you're talking about aggregating it and are you doing like pattern analysis on it?
00:34:23.374 - 00:34:43.970, Speaker C: No, it's actually a mathematics based attack. It's called the Rose problem. I can give reference. It's pretty technical. I can give reference and tell you more about it. And again, it doesn't only affect that particular scheme, it affects many blind signature schemes. And as I said before, it's like proving security of these glycerin signature schemes is actually extremely hard.
00:34:43.970 - 00:34:49.680, Speaker C: It has very particular techniques.
00:34:50.580 - 00:34:58.836, Speaker D: When you say you have an attack, do you break your knowledge or you break the there are multiple parts, so.
00:34:58.858 - 00:35:09.900, Speaker C: You break and for the bait and for the bait, you can force signal to do this attack. Yeah. So it was like there for the.
00:35:11.150 - 00:35:18.830, Speaker D: Previous slide where there was a decay proof required. So what happened to the efficiency concern?
00:35:19.730 - 00:35:35.246, Speaker C: Right. So that you cannot avoid if you want to do more complicated protocols here still, there are structures in signature elements that compose better or worse with zero knowledge proofs.
00:35:35.438 - 00:35:38.260, Speaker D: The partial opening is like revealing age.
00:35:39.110 - 00:36:07.766, Speaker C: Good. Yes. So if you literally want to reveal AIDS and not sew some predicate over your age, actually, we can do that very, very efficiently. So no need for zero noise proofs. We just very, very quickly can open part of your commitment. If you want to prove something more complicated and sort of range proof, for example, in your age that you're between some range or over some threshold, this is where you would actually have to do a zero proof. But again, literally opening one predicate.
00:36:07.766 - 00:36:29.346, Speaker C: It's very, very casey so in practice, actually, when people consider the single use credentials, they really try to avoid zero null proofs. So they would literally, for example, for the senior discount in the subway that I mentioned before, they would model this as a binary attribute, zero one. So you would literally just open and not do any sort of serial number. But again, it's like very application specific. Are you going to talk about how.
00:36:29.368 - 00:36:31.854, Speaker D: To make it concurrently compatible?
00:36:31.902 - 00:37:16.770, Speaker C: I guess it's like theoretically, I know that slides, we have some work in progress on that. It's not complete, so I cannot claim that we've done it yet. What we know is that there have been some recent works, I believe Eurocript 2022, that gave some efficient blind signature schemes using the AGM model it's by Stefano Tesaro that are parallel secure, that avoid this attack. However, they do not support attributes. They don't allow you to do this like double sided randomization of the commitment. So we currently have some work on that, but as I said, it's not complete, so that I can claim that it's solved.
00:37:17.350 - 00:37:19.186, Speaker D: So the main challenge here is to.
00:37:19.208 - 00:37:46.406, Speaker C: Make it efficient, I guess, theoretically, yes. Right. So we do have blind signature schemes that do not suffer from this attack. They're in the standard model, but they're not. So we don't have discrete log based, random Moroccan based fixing blind signal. Well, we have this very recent work, as I said, like Europe 2022, but again, it doesn't support attributes, so it's not direct. So it's not direct that you can just take any blind signature scheme.
00:37:46.406 - 00:38:04.146, Speaker C: We don't have any sort of generic compiler to compile any blind signature scheme to a blind signature scheme with attributes. So this like joint randomization of the method is being signed. It kind of needs to be embedded on how its protocol works. So we don't know how to do that.
00:38:04.168 - 00:38:09.220, Speaker D: The next, if you're not worried about efficiency, you can just use.
00:38:12.970 - 00:38:20.120, Speaker C: Completely solve this problem by just taking a zero proof and the signature scheme. But here we want to avoid zero knowledge proof completely.
00:38:21.610 - 00:38:25.706, Speaker E: So when you say efficient, does that kind of just mean less exponential, like.
00:38:25.728 - 00:38:59.110, Speaker C: A technical definition of what's efficient? Yeah, I don't have a technical definition, but yeah. So basically we just want like a few expanciations or a few point multiplications or just a couple of pairing operations. And also we want sort sizes of all this stuff. So this concludes my discussion on single use credentials. So this is a topic that I think is actually open at this point. We don't have an ideal single use Credential scheme with all these properties that I mentioned. We have some work in progress.
00:38:59.110 - 00:39:40.802, Speaker C: Talk to me offline. If you want to hear more about what we're trying to do. I'm happy to explain going back to the multi use setting, I'm going to say a few things here in a much higher level. In a much higher level. So the core primitive here for multi use credentials were again a special type of signatures, but not maybe as complicated as glen signatures and completely different definitions. Here, these are the commands, is the unskill signatures, which are basically signatures and committed values that allow for efficient proofs of signature ownership. So efficient, zero knowledge proofs on top of the signature.
00:39:40.802 - 00:40:23.762, Speaker C: So signature schemes tailored very, very specifically for efficient zero proofs. So the original CL signatures were based on RSA, so they were pretty large and they had some expensive operations. Later works gave signatures with similar properties that are based on ethics and vinegar paints. So for those of you that know things in the space is what we usually call the BBS class signature. So again, signature with similar properties but more efficient. So the idea of this multi use credentials is more similar to the generic construction that I was mentioning before. You have a commitment to your attributes.
00:40:23.762 - 00:41:01.314, Speaker C: You start with, again, some sort of phase that you have to prove that what you have is correct. All the Credential systems need some sort of bootstrapping, need some point of actual truth on how to start. And then you get one of these special signature schemes that allow efficiency and all proofs. The high level idea that you're able to randomize the signature schemes multiple times if you just want to show the Credential without proving anything about your attributes. Literally, you just need some sort of randomization that's still more expensive than single use credentials. That you just literally saw the Credential. If you do zero, you do nothing.
00:41:01.314 - 00:41:49.214, Speaker C: You literally saw the signature here. You have to keep on randomizing them because you want to maintain unlinkability with assignment. No matter how many times you use the signature, this would not be linkable. And as I said, you can repeat that multiple times. For the case of multi pages today, this has been, again, like a lot of research in the space and many extensions here, for example, things like conditional anonymity, you can identify misbehaving parties under well defined conditions. Irrevocable anonymity. How can you, using some sort of third party or threatful techniques, can you figure out towards a user? How can you delegate these credentials? I have a Credential, I'm going to be on vacation.
00:41:49.214 - 00:42:17.580, Speaker C: Can I delegate it to one of my employees? For example, how can you use consistent pseudomins across different services? There have been certain optimizations in the case of the HR, if you know that in a specific setting, the HR, they repire the same entity, you can actually have much more efficient schemes. And there have also been schemes that actually use transit enclaves to optimize certain things and get some additional costs. Yes.
00:42:18.670 - 00:42:23.920, Speaker E: Are there ways to do non repudiation without revealing the identity here?
00:42:27.090 - 00:42:29.310, Speaker C: Without revealing the identity.
00:42:29.730 - 00:42:34.606, Speaker E: So I imagine like a revocable anonymity, one of the applications would be non remediation, right? If someone's trying to claim that they.
00:42:34.628 - 00:43:06.170, Speaker C: Didn'T assert something, yeah, right. But the challenge is always there. How can you do that without the Freed Party? That has a factor to just open up the identity of users. So I guess, like, the first two bullets are kind of connected, right? So in one hand, maybe you want some sort of specific policy that automatically is going to revoke anonymity without the involvement of a third party. While in the second case you might actually involve some party or some threshold, some committee of parties.
00:43:07.550 - 00:43:15.390, Speaker B: You mentioned the revocable anonymity. What about just not you don't want to revoke someone's anonymity, you just don't want their Credential to work anymore?
00:43:15.970 - 00:44:01.846, Speaker C: Yes, revocation is a very important problem. It's actually one of the things that makes credentials pretty hard. So Credential revocation is a hard problem even in the non anonymous. Just think of certificates, like TLS certificates, right? How can we make sure what has been revoked and what not? And even specifically, again, for the case of TLS certificates, our solutions are not great, are not completely online. It takes time to figure out what are the access lists and revoke lists at any point. And there is a lot of risks in the space as well. So when you're adding privacy in the picture, everything becomes even more complicated.
00:44:01.846 - 00:44:52.590, Speaker C: Okay, so I had actually planned to show you exactly how Revocation works, but I think I'm going to keep it so that I try to keep the I mean, I'll save the thing, but I will not show you the exact solution so that I'll try to keep the talk in 1 hour. And if people want to stay longer just to discuss Revocation, we can do that at the end. So again, the high level of Credential revocation is that you might have an accept list of credentials for stability here and just literally throwing the names of the users. But you could think of this as being Credential IDs. And if you literally just keep like a list, it's super easy to additions and delisiums, especially if they're under central management. But the problem is that the size of this list is linear to the number of users that you have. There the number of credentials that you list and it's very, very hard to support user privacy.
00:44:52.590 - 00:45:57.106, Speaker C: So the most prominent solution, in my opinion, for efficient revocation is a special type of cryptographic data structure, I would call it that's called accumulators and cryptographic accumulators are basically a way to compute a very short digest of a large amount of a large set that is actually constant to the number of elements that are included in the set and still be able to compute proofs of membership or nonmembership that ideally are constant in size. So you could think of metal trees also being some sort of accumulator. The digest of the set is okay, at the root of the metal tree that's constant size. But say the problem with at least metal trees is that the proofs of membership are not constant size, they are logarithmic because they're like the path. So accumulators can actually offer trade offs when compared to metal trees to have. And the most important one is that the true set of constant size. So I'm not going to show you exactly how things work.
00:45:57.106 - 00:46:57.702, Speaker C: I have the example of the RSA accumulator. I just want to mention a caveat of accumulators that it's important. The thing is that when you add an element to the accumulator, you have a way you receive some sort of sort proof sort witness that you can use to assess it very efficiently. Proof membership or non membership. The problem though is that when more elements arrive on the accumulator, you have to update this roof. So technically in the older accumulator constructions you would have to update this witness both when additions happen and when deletions happen from the accumulator. But we have certain lower bounds and newer constructions that actually a signal and you can manage to have accumulator constructions that only allow you, that only requires you to update your witness when deletions happen and not when additions happen.
00:46:57.702 - 00:47:56.310, Speaker C: So if you think that you're storing credentials, you could potentially think that it's more often to add new credentials than deleting ones and in that case these constructions make more sense. So we have a series of work on that. Again, keep in mind that in these types of accumulators there is some sort of accumulator manager. So there is some sort of third party that holds the accumulator that is responsible to maintain the accumulator. So in the last 10 minutes of the talk, I want to switch gears a little bit and give you like a high level overview what happens in the centralized space by talking about digital credentials and anonymous digital credentials. And again, I think that we see two types of approaches in the space. The first one is to literally take anonymous credentials as we used to know them in the past and decentralize part of the process.
00:47:56.310 - 00:49:03.230, Speaker C: So the main part of the process that you want to decentralize is a full basician's process. You don't have a single issue to vouch for a Credential, but you might want to have more. The second approach is to kind of take issuers completely out of the picture or partially out of the picture and have users that create their own digital identifiers that they're not like centrally managed at Penpon. So this blends well with what Andrea was discussing yesterday about reputation systems. So some sort of like a web of trust idea that people create their credentials and then they can get kind of some sort of distributed vouching of the Credential, but without having some sort of starting point with a specific issue. So I'm just going to say a couple of things about what we know in this case. So in the decentralized Issuance case of, again, like taking classic anonymous credentials and decentralizing them, the idea is that you might want to have multiple issuers working together to issue a Credential for a user.
00:49:03.230 - 00:50:07.090, Speaker C: One of the most prominent schemes is the Cosmos Credential scheme where actually Sarah is one of the authors and is being used on the NIM project. So the idea is to use a threshold line signature. So these credentials are actually kind of single use credentials. The nice thing is that you can thresholdize the Issuance process. You can start by having a system where you define a number of potential issues, let's say N issues, and then for every new Credential you require that the threshold of them say p of them sign your Credential. So the nice properties of threshold signatures, and for those of you again that were on my talk on Tuesday might already remember what are the good and the bad things about threshold signatures is that you get signer privacy. So when you see a Credential, you're not going to know who were the issuers that vouched for this Credential, you just know that this Credential was vouched by enough issuers.
00:50:07.090 - 00:51:05.966, Speaker C: But the problem is that the process of setting up this set of issuers is actually kind of annoying. So in these threshold signatures you need this distributed key generation process that needs to happen in order for them to agree on their initial keys. And this is a non flexible process. If you want to add new issues or if you want to remove issues, you have to rerun the whole process. Also, it's not very clear how to efficiently add attributes in those schemes. There are ways to add attributes by using different public keys and kind of more like ad hoc ways, but they're not truly embedded in the system. So in a work that we actually have under progress and again, I'm happy to talk with people about this, with colleagues from UMD and CISPA, we are trying to construct a similar scheme that instead of threshold signatures, uses multi signatures.
00:51:05.966 - 00:51:57.008, Speaker C: And remember that the main advantage of multi signatures is that they do not need this coordination among the issuers in order to create the Credential. They have other issues, they're larger and they also reveal who are the issuers for the designers of its credentials. So this can be considered a feature in certain cases. So in certain cases when you see Credential, you might actually want to know exactly who vouch for it. But in other cases it might also be considered like a privacy issue. So it really depends on what's the application here. So the last thing that I want to mention and then just kind of open the floor for discussion and mention some challenges is the idea of decentralized identities.
00:51:57.008 - 00:52:58.840, Speaker C: So the main idea on this whole space is that people want to change the way that we authenticate. Instead of using password authentication, we want to use cryptographic keys like user wallets to be able to authenticate. There are efforts like signing with Ethereum or efforts like the can we do decentralized identities? Which is again a research work that Andreo is one of the offers, he's a late tool, I don't remember, sorry. And the idea there is that, again, it's not like taking traditional Mahouse credentials and trying to decentralize them. It's mostly like I'm a user, I have some information that I want to use in the space to start authenticating. They have some very interesting ideas on how can you bootstrap using Oracles like deco to transfer knowledge about your keys, your identities from other places. They have some nice accountability extensions.
00:52:58.840 - 00:53:34.960, Speaker C: The level of privacy that these schemes offer are not to the point of anonymous credentials. So if parties are colluding with each other, you can actually de anonymize users. And also revocation is not again very efficient if you want to do things in private. And again, as I said, revocation is a crucial point. Here something that I want to mention. Now that I mentioned revocation for the decentralized setting, remember that I said before that using these accumulators to do revocation, the centralized setting assumes that you had somebody that holds the accumulator. You had like this accumulator manager.
00:53:34.960 - 00:54:01.770, Speaker C: If you try to decentralize that if you try to remove the accumulator manager and have a distributed accumulator, then things become much more complicated and much more expensive. So you actually need to hold the whole accumulated set to be able to compute proofs. So this is another open research problem on how can we actually have assistant accumulators that are completely distributed. Yes.
00:54:01.840 - 00:54:12.586, Speaker D: Just out of curiosity, the practical applications of decentralized identity, are there any projects that are building some applications?
00:54:12.618 - 00:54:27.378, Speaker C: Yeah, NIM is building this idea of threshold diving anonymous credentials. And I don't know about the status of can IB. I don't know if you know, Andre, what's going on.
00:54:27.464 - 00:54:29.620, Speaker D: We have some application in mind.
00:54:30.150 - 00:54:50.906, Speaker C: Yeah. So I think Meme actually cooperates with certain parties in the European Union. I don't know, governmental, I guess they have some governmental access and they're trying to build some pilots for European identities or whatever. And yeah, for Can, I deem maybe.
00:54:51.088 - 00:54:53.050, Speaker D: Like a government ID system.
00:54:53.120 - 00:55:27.960, Speaker C: Yeah. Again, Europe tried that before with this ABC for trust system, before the age of blockchains, I guess when blockchain was starting maybe like 1213 years ago. But they didn't do math after the pilot finished. So I cannot really predict what's going to happen there, but I kind of feel that we're getting more ready for that. Also in this space, Neem and Cocoonat were actually also using smart contracts for these threat issues with credentials. So they were literally running.
00:55:31.630 - 00:55:41.942, Speaker B: With NIM. What's the role of an Identifier? What are they doing this for? I mean, I know that it's like a mixing network or like a network layer.
00:55:42.086 - 00:55:56.480, Speaker C: Yeah. I think that part of their system is actually building these digital credentials and then they're using mixing techniques. I think it's kind of like two different components there.
00:55:57.410 - 00:56:09.922, Speaker B: So for the issues with the accumulators open problems that you mentioned, I mean, are these also things that are straightforward with generic zero knowledge proofs, but it's the open problem to make them efficient or is it difficult even?
00:56:09.976 - 00:56:14.790, Speaker C: So you mean if I don't use an accumulator and literally just use like a list of stuff?
00:56:14.860 - 00:56:15.414, Speaker B: I guess so.
00:56:15.452 - 00:56:45.054, Speaker C: Or some kind of yeah, I guess zero knowledge proofs on top of accumulators. Kind of a second step as well. So when you think about accumulators, we don't necessarily need to think about privately preserving proofs of membership. But what I'm saying is that even in the non private setting, even if you just literally want to show non private credential is revoked or not is in the list or not in the distributed setting, we don't have great constructions so far.
00:56:45.172 - 00:56:47.326, Speaker B: Even with generic as a verifiable, computing.
00:56:47.358 - 00:56:52.050, Speaker C: Would be the appropriate practical construction with generic techniques.
00:56:53.590 - 00:57:03.080, Speaker B: By special you mean that any of these parties can issue and you don't want to reveal who they are, right?
00:57:03.770 - 00:57:16.860, Speaker C: Yes. So what you want to do is you want to get a Credential that was issued by many of these issuers at least a threshold of them without knowing who they are.
00:57:21.550 - 00:57:23.482, Speaker E: Do you think maybe we can use.
00:57:23.536 - 00:57:26.026, Speaker B: Advantage of some sort of multi prover technology?
00:57:26.208 - 00:57:33.086, Speaker C: Yeah, that's what we're doing right now, we're trying to use it multi signature. I'm not sure what you mean by multi proverbs though.
00:57:33.108 - 00:57:39.234, Speaker B: Oh no, I meant more like we know that say I have two provers and I know that they don't like.
00:57:39.272 - 00:57:41.646, Speaker E: My assumption is that they don't collude.
00:57:41.838 - 00:57:50.870, Speaker C: Then that by provers you mean issuers of the Credential or I mean, in my mind these are the issues and this is the prover. The user that has the Credential.
00:57:52.250 - 00:58:00.840, Speaker B: Yeah, you're right, the user proves right. It's not the issue that provide proofs. Okay, yeah, okay.
00:58:03.290 - 00:58:20.190, Speaker C: Yeah. So some final thoughts. Again, generic solutions exist for most of the problems that I'm raising. Efficiency is a big challenge. Think that many of these applications are really time sensitive. You want literally milliseconds or microseconds. You might want to implement such things in lightweight devices, not even smartphones.
00:58:20.190 - 00:59:25.746, Speaker C: If such things are implemented on the blockchain like this issuance process or these credentials or these proofs are stored on the blockchain, you really care about sizes, storage or gas costs. If these are around two smart contracts there is a bootstrapping problem of course and can ID help? Some ideas on how to start there? There is a big problem of accountability, which is a general problem with privacy preserving technique. So private is great, but we need some sort of accountability if we want this technique to actually be adopted. There is a problem of how can we do backup, how can we do identity restoration, particularly in the distributed setting if there's no trusted party to help us? Revocation is a big problem in my opinion. It gets so expensive to prove that your Credential was not revoked, it starts getting annoying and I want to claim that basically post one secure solutions are nonexistent again, like efficiently and satisfying the goals that we have. So that's again a very open space. I got a question about kind of.
00:59:25.768 - 00:59:46.358, Speaker E: Like the concept of anonymous that we were talking about here. So seems like most of it was on the actual message content or I guess the message that's being passed back and forth. Right, but wouldn't you also need some sort of surrounding or some kind of mixed network or something, right, if you were able to see activity?
00:59:46.534 - 01:00:07.954, Speaker C: So you mean like in network level? Yes, absolutely. So I completely left network level out of here. But you're absolutely right that even if I'm hiding all my cryptographic keys and cryptographic information, if I'm using consistent IP, then of course there can be have.
01:00:07.992 - 01:00:36.346, Speaker E: You looked at anything like autonomic Identifier systems? So you were mentioning the self issued identity. Right, so there's techniques where you can actually cryptographically issue your own Identifier without even anchoring it to a blockchain or something, right? Creating delegated versions of those that are just like ephemeral. Would that address some of the issues? Potentially from a setup, I guess, right.
01:00:36.448 - 01:01:23.770, Speaker C: But again, you need some sort of bootstrapping. You need some point to start, right? So after you have this bootstrapping, after you start by getting some real life proof that these are your correct attributes and you get your fresh credential, then you can really play along. You can delegate things, you can get additional anonymous credentials on top of your already existing credentials that are unlinkable with each other. You can kind of keep on building on your digital identity. But there has to be some sort of bootstrapping to my mind, which is pretty natural, right? Somebody needs to literally verify your identity at some point. Again, if it's like just a secret key, for example, ethereum. And what you just need to know is that I have a key, I have an account, it's different.
01:01:23.770 - 01:01:30.810, Speaker C: Right? But if you want to start adding physical attributes, then you need something there. You need some entities on class attendees.
01:01:31.230 - 01:01:36.000, Speaker B: Are there scenarios where just a timeout based replication works?
01:01:38.210 - 01:02:13.722, Speaker C: Yeah, absolutely. And that's something that I mentioned, for example, so this is more easy. I get to doing these one time credentials because they can have very short expiration dates, so you don't even need to revoke them. Basically for these consistent multi use credentials, it's kind of harder to have expiration. I mean, you might have still, but it's kind of harder because you start building on top of them. As I said before, use the credentials, get additional credentials down the path. So if something expires up their roots, then things might start going wrong.
01:02:13.722 - 01:02:37.440, Speaker C: But even if you have expiration dates, you might lose your device, you might misbehave. And we really want to revoke you. So we cannot avoid the problem of revocation just by using expiration dates. But it's a way to at least kind of use.
01:02:39.490 - 01:02:51.308, Speaker B: Yeah, I guess I'm just thinking on the web of TLS, that's a much, much easier setting. We still haven't planned time out.
01:02:51.394 - 01:03:08.610, Speaker C: Yeah, we can talk more. We actually have some discussions with people who work in the space that build things like Cr light that based on Bloom features. So I can tell you more. We have some discussions irrelevant one aminity just like.
01:03:10.600 - 01:03:31.210, Speaker B: A second question, which is in a totally different direction. When COVID came out and people were talking about vaccine certificates, initially the anonymous Credential crowd was really excited. Good application. Do you know that ever went anywhere? Was there any quality that said, let's actually try this?
01:03:32.160 - 01:03:53.730, Speaker C: That's a good point. I think at some point most of the research actually shifted towards tracing, like privacy tracing, but for like you're right. I do remember talking about vaccine credentials. I don't know what happened. I would guess if something happened would be in Europe. Sarah, you're aware of anything?
01:03:54.660 - 01:03:59.016, Speaker B: Did we miss the greatest opportunity to credential?
01:03:59.148 - 01:04:10.168, Speaker C: Yeah, well, again, I. Think that the focus kind of really fitted on the anonymous tracing, because that was what was really being implemented. I guess most of the people kind of yeah.
01:04:10.254 - 01:04:17.320, Speaker B: I guess in retrospect, though, if we had another pandemic, we sort of decided the anonymous trade thing is worthless.
01:04:20.000 - 01:05:18.280, Speaker C: So maybe that's something. All right, thank you. I was not really paying attention to the microphone. Somebody was talking about me. Very nice. I mixnet with all first network layer privacy goods and then coconut Cadence website. Okay.
01:05:18.280 - 01:05:26.220, Speaker C: The idea with it I mean, Anya, if you're still here and you want to unmute and tell us more about me, more than happy to hear.
01:05:35.190 - 01:05:36.530, Speaker A: Should be a fail.
01:05:40.550 - 01:05:41.460, Speaker C: All right.
01:05:52.950 - 01:05:59.050, Speaker B: I dumped my credential from my New York one and my Australian. They both had, like, a digital signature.
01:06:00.750 - 01:06:26.820, Speaker C: I mean, they're not anonymous. They don't have any I mean, I I know them, but I never we had sounded some, but it was not time. Yeah, we'd be happy to talk to them. I mean, are they under there?
01:06:28.950 - 01:06:31.582, Speaker B: I think, like, Canada may have actually done something related.
01:06:31.646 - 01:06:32.430, Speaker A: Seriously?
01:06:32.590 - 01:06:34.110, Speaker E: Because the Sovereignty Foundation.

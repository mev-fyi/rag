00:00:07.230 - 00:00:07.780, Speaker A: You.
00:00:09.750 - 00:00:26.210, Speaker B: Welcome everyone, to the last a 16 Z crypto research seminar of the week. Last but not least, we have Milesh High. Milesh is an economist at Rice University. He'll tell us about the wisdom of the crowds and higher over beliefs and maybe a little bit about decentralized Oracle healthy.
00:00:27.350 - 00:01:03.502, Speaker A: Thank you. Thank you very much for having me. And hopefully those of you online can hear me. So I want to start with a disclaimer, which is the talk I'm giving is not directly related. I don't have in mind a direct set of applications for the kind of things I'm proposing. Why am I presenting this? Well, this has sort of been a hobby horse, broadly construed of mine for the last few years as a game theorist or economist understanding the economics of expertise. So people have there are these people, they call themselves experts.
00:01:03.502 - 00:01:46.314, Speaker A: They claim to know something more about the underlying unknown state of the world than the regular population. And for various reasons you might be interested in evaluating their expertise. Aggregating their expertise. Today I'm going to drill down into a very specific setting, but that's sort of one set of questions I've been thinking a lot about over the past few years in a Web Three setting. There are several settings, I'm told, reliably by people in this room over the course of this week where you might want to aggregate diffuse information. So one that came up was aggregating the opinions of backers in a DFI lending setting or I'm going to carry catcher. One that I thought I understood a little bit better before coming here, which is Oracles and Smart Contracts.
00:01:46.314 - 00:02:44.974, Speaker A: So let me tell you my caricature of it and you can tell me I'm all wrong. So a smart contract, as an economist, if I was modeling it, all I'd say is it's something that's trying to implement different outcomes based on an unknown input, an input that isn't known at the time of writing down the smart contract. Something else is potentially going to come in and is going to be a relevant variable. This input is not potentially something that's even on chain. So you need these people, Oracles, these other gadgets that are going to provide the input so that the smart contract can function. And if you're going to be relying on things that are off chain, you want to understand the incentives of these Oracles, what can be manipulated, what can be aggregated, what can you do with the information from these Oracles? And you want to understand that so you can expand the set of contracts you write in the first place. Sometimes we're talking about Oracles that are reporting some state of the world that in principle is commonly known or understood off chain.
00:02:44.974 - 00:03:40.610, Speaker A: So the outcome of a sports event is something that everyone knows, it's just that the chain doesn't know it. That's not the kind of setting that this talk will immediately correspond to. But in other cases, even the oracles might have only noisy information about the state of the world that you're trying to condition on. So you're trying to write a contract, for example, on the price of something, and no particular oracle knows the price, but they all know noisy versions of those prices. They're sampling different AMMS, they're sampling different exchanges. What can we do? How can we get sort of this disparate information and aggregate it in a way that's so that's my high level pitch for why you should pay attention if you don't care about the underlying techniques. Okay, all right, so I'm just going to launch into a formal model.
00:03:40.610 - 00:04:05.040, Speaker A: This is not a high level overview talk. It's a very specific model. So the idea is that there is an unknown state of the world. Nobody knows it. It's not something that will be revealed at any stage. But there are agents, experts, oracles, if you must, there's a lot of them. So we're going to rely on large number theorems who observe some information about that state.
00:04:05.040 - 00:05:36.214, Speaker A: They observe that information and what they observe or not what they observe, but kind of the distribution of information, how it's distributed among these agents is known among the agents themselves, but not known to the aggregator. So the question is, how well or can I identify this unknown state of the world when there are a bunch of agents who know something? They know what each other they have information about what each other know. But I want to design a prior free. I want to design a mechanism that does not condition on the settings of what they know. I want to do as well, or can I do as well as a bayesian aggregator who actually knew the underlying prior, who knew the underlying information structure, and how well can I do relative to that? Okay, so here's the motivating example for why the obvious thing you'd think like take the majority is not good. So this is due to a paper by Pralek, Seung and McCoy, and the question they ask people I'll keep returning to this paper, but just the question they ask people is, is Chicago the capital of the state of Illinois, yes or no? And in case you didn't know, it is not the capital of Illinois. So the true underlying state of the world is that Chicago is not the capital of Illinois.
00:05:36.214 - 00:06:47.274, Speaker A: But in lab experiments, you poll a bunch of people on the street, people will say yes. Not only will people say yes, but if you ask them, how confident are you? Everyone who says the answer is Chicago is super confident that the answer is Chicago. So waiting, for instance, the votes by some self reported confidence score is not going to help you fix the problem. Okay, so the question then is when we have just a bunch of experts for now, don't worry about them trying to manipulate the to they have information about whether or not Chicago is the state of the chicago is the capital of Illinois. We're trying to learn, is Chicago the capital of Illinois? But majorities can be wrong. Can we still aggregate that information? And how? I'm going to propose a procedure, population based mean aggregation, that fully aggregates agents informations in the setting. So if you actually gave me a large number of agents, I can be very sure that this procedure will work within the context of our model.
00:06:47.274 - 00:07:42.446, Speaker A: And the main innovation of this procedure is that it's going to allow not just for questions of the sort, is Chicago the capital of Illinois? But also multiple state questions. So is Chicago the capital of Illinois, or is Springfield the capital of Illinois? Or is Ubana the capital of Illinois? So there is a mechanism out there which I will review, which is actually very clever and very interesting. It's called the surprisingly popular mechanism. It's a surprisingly nice mechanism, if you will, that does it. And once we've sort of covered the mechanism, I'll sort of show you also that it's not just that you can use this mechanism to aggregate the state of the world. You can also use this to truthfully incentivize elicitation of the underlying beliefs, even though you'll never learn a true state. So you couldn't use a scoring rule straight up because you don't know the capital of Chicago.
00:07:42.446 - 00:08:11.050, Speaker A: You're trying to aggregate that information to learn it in the first place. Okay, so that's sort of the high level pitch if there are any questions. Otherwise, I'll soldier on. Okay, so here is just simple formal model. We're going to have a set of states of the world. Omega, there's going to be l possible states of the world, and there's going to be a bunch of agents. So I'm just going to formally only consider the case of an infinite set of agents.
00:08:11.050 - 00:08:47.640, Speaker A: You can imagine laws of large numbers would give you good concentration and good properties, even with a finite set. What's known to the agents, unknown to the aggregator is the following. Each of these agents is going to observe some signal. That signal is going to be information to them about the state of the world. There's some joint prior over the state of the world times the signal the agent sees conditional on the state of the world. And that's denoted by P. This P is understood by the agents.
00:08:47.640 - 00:08:59.740, Speaker A: So agents understand at least probabilistically what information other people also have. If I see a signal, I know something about Andy's signal. Yeah.
00:09:00.270 - 00:09:04.026, Speaker B: Does the aggregator know the marginal along Omega or not even that.
00:09:04.128 - 00:09:56.906, Speaker A: Not even that. So the aggregator knows. All the aggregator knows is he's willing to buy the common prior that the agents are sort of understanding the thing. And we can relax that too later, but that's going to be the thing. What agents are going to have then, of course, because they started with this prior p if agent I saw a signal si the agent I is going to update to some prior mu I and that prior mu I is going to live in the space of probability distributions over. And one more piece of notation I'm going to define given a prior, assuming concentration hold. For instance, if the signals are IID across agents conditional on the state, there is going to be a state by state average population belief when the true underlying state is Omega.
00:09:56.906 - 00:10:29.766, Speaker A: And I'm going to define that as mu bar omega. Again, the principal, the aggregator does not know any of these things. They just know that there is AP. The question then is if there is such a set of agents. If I knew P, of course I could learn back the true underlying Omega just by I know P. If I ask all the agents for their signals, I know an infinite set of signals that are drawn from some distribution. I can back out what the state must be.
00:10:29.766 - 00:10:33.754, Speaker A: The question is, what could I do if I didn't know P and had to do something?
00:10:33.872 - 00:10:41.642, Speaker B: Okay, assuming that each pair of distinct states induces distinct average sorry. Assuming that each distinct pair of states.
00:10:41.696 - 00:11:27.258, Speaker A: Induced distinct population, for instance, you could do that straight up. If I knew the P, I could do that even if it induced different population averages. If it induced a different quartile and some the mean is not the only thing I could check. If I knew P, I could check a whole bunch of things. In particular, I could just check the whole distribution of posteriors and compare it against all right, so here's an example just to walk you through everything that happens. And here is also the surprisingly popular mechanism of prelaxian McCoy explained within the context of a specific example. So let's suppose we have the two states.
00:11:27.258 - 00:11:51.762, Speaker A: Omega one is the capital of Illinois. Omega two is that Chicago is not the capital of Illinois. And of course, omega two is the true state. We don't know it. This is the specification of the priors. So agents are going to see a conditional Eiid signal. Everyone starts with the belief that Chicago is likely to be the state of Illinois, the capital of Illinois with 0.7
00:11:51.762 - 00:12:15.114, Speaker A: probability. Chicago is not the capital with 0.3 and they see these signals. So this is the probability of seeing sorry, this is the probability. This is the posterior that you have upon seeing signal one. This is the posterior that you have upon seeing signal two. So this is the conditional probability an agent would update to given their states.
00:12:15.114 - 00:13:05.654, Speaker A: Conversely, this is the probability of seeing a particular signal in a particular state. You can work out the population average beliefs that must be occurring in the population when a given state is the true state. So if Omega one was the true state, then the population average beliefs, if you work through the math, it'd be five 7th and two 7th two thirds. If Chicago was not the capital, then it would be two thirds and one third. So this is the model that's understood among the agents not known by the aggregator. And here is the surprisingly popular mechanism. It's really easy to describe.
00:13:05.654 - 00:14:01.538, Speaker A: So we ask every agent, what are your beliefs about the state of the world? That's great. Once I ask them all for their average, all for their beliefs, I can calculate the average belief by a law of large numbers. The average belief in the population when the stake is Omega must be the true underlying average mu bar of Omega. It's just that I don't know what the mu bar of Omega should be state by state. Now, note that this is by itself, this is not just. If I knew this, it doesn't tell me what the state of the world is. Because even if I understood the signal structure among agents for two different priors so for the prior point seven, point three, the population average belief when Chicago is not the capital will be two third, one third.
00:14:01.538 - 00:15:07.410, Speaker A: But if agents started with the prior 36 over 55 and 19 over 55, then two third, one third would be the population average when Chicago was indeed the capital. So even if you have an infinite number of agents, and even if all of these agents are getting a IID signal without knowing the prior, the aggregator is facing an identification problem. What's the sort of trick that PSM introduced? They say, suppose we don't just ask agents about their beliefs, but we also ask at least one agent about their expected population average belief. So you ask them, what do you think? You don't just ask them, do you believe Chicago is the capital of Illinois? With what probability? You also ask at least one agent, what do you think will be the average probability that all the participants in this poll will submit?
00:15:07.490 - 00:15:10.230, Speaker C: Is there some reason we can't ask them about priorities?
00:15:11.610 - 00:15:43.762, Speaker A: So that's a bit of a epistemic question of can you ask people about what their priors would have been before they saw any information? So we normally don't like to assume that people can go back to what they would have felt was the underlying prior before they saw information. People exist knowing the information that they know. It's hard for them to back out that thing. You're right. I mean, in some sense there's a trivial solution to this question. Just generalizing further. I could just ask one of the agents, tell me this whole distribution P, and then thank you.
00:15:43.762 - 00:16:34.706, Speaker A: Now I'm going to calculate this. What I'm trying to propose is things that you might be able to work in practice. And I'm shockingly, actually going to have data at the end. Well, Prelak Seng and McCoy actually ran experiments showing that their mechanism works well in practice on a bunch of lab experiments, it's worked well in the field. I'm going to show evidence using their data that our mechanism also works well on their practice, to be fair, because we haven't drawn our okay, so what's their mechanism? You ask one agent for their expectation of the population average belief. So what do you think is the expected you're not sure what the population average belief is because you don't know what it is in society, but you have some belief about it. So tell me what your expectation of the population average belief is.
00:16:34.706 - 00:17:29.250, Speaker A: So for instance, if the agent, the agent understands that in state one, the average belief in the population would be 5727. The agent understands that in state two, the average would be two third, one third. If they saw signal one, their beliefs are zero 6.4. So of course they would report, if they were faithfully doing, reporting their expectation of population average beliefs, they would report zero 65.35. Similarly, if the same agent instead saw signal two, they would have reported this zero seven 5.25,295 based on their weighting, the other information they have, and that effective weighting in either case. Note that in the true state of the world, chicago is not the capital of Illinois.
00:17:29.250 - 00:18:37.020, Speaker A: The true population average belief is two third, one third the average belief that results in the population. So when you ask this agent what do you think the average should be? They say, well, regardless of what information they see, they either say that Chicago is not the capital of Illinois on average among the population with probability zero three five or with probability 00:25, whereas in truth, the average in the population comes out to be one third. So in both cases, with respect to that agent, chicago not being the capital of Illinois is surprisingly popular. Prelak Seung and McCoy mechanism just says the surprisingly popular state of the world, that is, where there is one state of the world out of two, where the actual realized average beliefs in the population exceeds one person's elicited expectation of the population average in the population. That's what you call surprisingly popular. And they assert that that is the true state of the world. Well, they prove it.
00:18:37.020 - 00:19:24.518, Speaker A: So this is not just heuristic, you can give a straightforward reason for why this must be true. Okay, it doesn't matter which agent you ask. So that's a great question. Why is it that it doesn't matter with what agent you ask? Here's a theorem, they have a different proof. There's a simpler theorem that is true. So in a two state setting with two or more signals for any agent, I the induced belief on omega, that's a random variable in state omega, first order stochastically dominates the induced belief on omega. At any other state omega prime, your belief on omega is a random variable.
00:19:24.518 - 00:20:29.502, Speaker A: You will have some distribution of that in state omega, you'll have one distribution in state omega prime you'll have a different distribution of the belief you place on the state of the world. Being state Omega, the former first order stochastically dominates the latter. So when you aggregate up, because you're just averaging a bunch of first order stochastically dominant distributions, the average belief of the true state always has to be surprisingly popular for any agent, no matter whom you ask. Now, some things I should note. The original prelike in McCoy also works. If you at the first order, you don't just ask people for beliefs on what is your belief that Chicago is the capital of Illinois? You could just ask them, is Chicago the capital of Illinois or not? And elicit just a second order belief about what do you think the fraction of the votes is? That works too, in the original mechanism. It works very well in practice for binary states.
00:20:29.502 - 00:21:18.078, Speaker A: I'll show you the data in a little bit, or I'll show you the data right at the end because I'm a theorist. But the issue with the surprisingly popular mechanism is that for more than two states of the world, you need very strong assumptions. So there is no counterpart to this first order stochastic dominance relationship. If you have more than two states of the world, this only works for two states. What does that mean? The fosd like for distributions. What's the actual definition there? What's the actual definition of first order stochastically dominant? It means you put a lower probability, the probability with which you put it. So distribution over probability distributions is just a probability distribution on the real line between zero and one.
00:21:18.078 - 00:21:55.110, Speaker A: It means one distribution. First order stochastically dominates another distribution if it puts lower probabilities on any lower interval. So you look at any given x, the probability distribution. One takes a value less than x is smaller than the probability distribution. Two takes a value. The random variable generated from distribution two takes a value less than x. So post order stochastic dominance just means that regardless of where you look in the distribution, the first distribution is more likely to give you a higher number than the second distribution.
00:21:55.110 - 00:22:40.214, Speaker A: CDF is strictly above the other. Well, it has to catch up, but it's strictly so the first order stochastic dominance is strictly below because the survivor function is strictly above. Even if you ask many people instead of just one person about their beliefs. Yeah, there's no benefit in particular in this mechanism to asking multiple people, because you could, of course, take multiple people, average them and look at what is surprisingly popular. The theorem is still true for more than two states. With more than two states, very non knife edge examples start to break down. So here is an example, I'm just putting it up here.
00:22:40.214 - 00:23:24.230, Speaker A: I do not want to walk you through this entire set of numbers, but it's an example sort of where you can just calculate again, we're not doing anything, we're not adding anything else. So it's still a prior. There's still Conditionally IID signals. You're still calculating posteriors, you're still calculating population average beliefs. The trouble is that when you then run this mechanism, you could have multiple surprisingly popular states. Because when you're comparing two numbers that sum to one with another two numbers that sum to one, only one of them can be surprisingly popular. But when you have three numbers that sum to one versus three other numbers that sum to one, two of them could be surprisingly popular.
00:23:24.230 - 00:23:58.238, Speaker A: Indeed, this is the set of surprisingly popular states. If you tried and did something like most surprisingly popular, that's not going to be correct either. I'm not saying that this couldn't work in practice, but at least theoretically, you'd have to make very strong diagonal dominance assumptions of basically in state one, something has a strong enough there's enough dominance on the diagonal to guarantee that something like most surprisingly popular works.
00:23:58.324 - 00:24:02.340, Speaker C: Do you have just ask multiple questions? Could you not just ask multiple questions?
00:24:04.230 - 00:25:06.614, Speaker A: So you can't ask multiple questions. You might say, tell me whether the state is omega one or omega two. Omega three. Note that this mechanism relies on the fact that conditional on a given state of the world, the population average is deterministic or close to deterministic. When I have two states of the world that I lump into one underlying state of the world, from the perspective of the question, the population average condition on my question state of the world is random because it depends on what the actual resolved state of the world is, right? So if I ask is Chicago the capital of Illinois or is it Ubana or whatever, I can't resolve the question of whether it's Ubana or Springfield. Conditional on the state of the world being Ubana or Springfield, the population average distribution is going to be a stochastic variable. You see what I'm saying? All right.
00:25:06.614 - 00:25:36.080, Speaker A: So that's the mechanism. That's their beautiful mechanism. Let me tell you our theorem here's. The assumptions. So the assumptions for now, just imagine that the signals are still conditionally IID. We can generalize this substantially. We need going back to Tim's assumption, we are going to assume that the probability generating distribution is such that in any two states of the world, the population average is different.
00:25:36.080 - 00:26:33.790, Speaker A: If you had some reason to think that population averages might be the same, but you could pick some other quantile that was different, you could work with that, and that would be fine. And the most tricky one perhaps to describe, but you'll see where I'm using it because this is an embarrassingly simple mechanism to describe is that what I want is that the support of the priors that people have in the population is a full support set. It has an interior relative to the set of priors on delta l. So it's not the case that there are three states, but all possible priors in the population lie along a single line, okay? And I'll show you some simple examples that generate that. So here's the example again. Here's two states of the world, chicago is capital, chicago is not capital. Again, agents are going to see a conditional eid signal.
00:26:33.790 - 00:27:33.846, Speaker A: These were the distributions. Now, let me tell you the question that we're going to ask that is slightly different or how we're going to do it, that's slightly different than Prelixing and McCoy. So remember that by a law of large numbers, when we know in the state of the world that Chicago is not the capital of Illinois, the average belief in the population is going to average out to two third one third that we know when we see two third one third. We don't know how to interpret it. We don't know whether that's coming from because Chicago is the capital or Chicago is not the capital. And like I showed you a few slides back, for two different priors, two third, one third could have been the population average for the same signal, distribute for the same signal conditional signal information for two different priors, two third, one third could have been the average under both Chicago and not Chicago. What we're going to do instead is just do the next thing that someone should have thought of.
00:27:33.846 - 00:28:15.598, Speaker A: And I guess we did. Which is that instead of asking just one agent for their population average, you ask two agents now for their population average belief, subject to the proviso that these are two agents with two different underlying beliefs to begin with. So you ask every agent for their beliefs, just like in Prolexion and McCoy. But you now ask two agents, what are your population average beliefs? So agent one who had reported zero 6.4, if you recall, we did the math and we said this agent would naturally report zero 65.35. Agent two who reported belief zero 8.2, would do the averaging differently.
00:28:15.598 - 00:28:59.250, Speaker A: They would report zero 75.29 five. And the trouble is, even though we don't know what the population average belief is state by state, we know that for each agent their belief times the population average belief, their averaging has to equal their average. So this is just law of total probabilities. What must I be reporting for my population expected average? It's my belief that the state is state one times what the population average is in state one, plus my belief that the state is state two times what is the population average in state two. If you have two equations and two unknowns, you can recover the unknowns. So you can just do the matrix inversion.
00:28:59.250 - 00:29:36.846, Speaker A: So once we have from two agents one who said zero 6.4 recovered, that they think that the population average is zero 69 5.35 and this one is zero 8.2 says zero seven 5.295. We can infer that the only way these two agents could be making these two reports is if they believe that in state one it's 5727 and in state two the population average is two third one third. Then we now know five seven two 7th versus two third one third. We compare to what we are seeing.
00:29:36.846 - 00:30:55.396, Speaker A: The population average is actually realizing to in the population and concluding the true state. Does the description of the mechanism make sense? There is literally nothing in this mechanism beyond this inversion step. So this would be a good time if the definition of the mechanism is not clear. All right. So more formally, what are you going to do? You're going to ask each agent for their belief mu I calculate the average in the population mu hat select l different agents such that their elicited beliefs are a full rank matrix elicit from each of these beliefs, their conditional population, what they believe, their expectation of the average posterior beliefs in the population alpha i. And note that just alpha I for each agent I must be mu I times the unknown mu bar. So you can just recover mu bar, the vector, the matrix of what the population averages are state by state.
00:30:55.396 - 00:31:26.800, Speaker A: As the inverse. You just want this matrix to be full rank. Preferably you want it to be a well conditioned full rank. If you're going to do this in practice this works. The theorem then is just straightforward. Under the assumptions the population mean based aggregation procedure recovers the true state almost surely. Okay, you can start relaxing these assumptions.
00:31:26.800 - 00:32:06.110, Speaker A: So for instance, I said signals are conditional eid. That is, you're just getting a signal that is IID drawn conditional on the state of the world. The only thing we are using about conditional Iidness is that the average belief in the population is deterministic function of the state. You don't have to assume conditional IID. You can assume any form of limited correlation. The only thing you need is that a law of large numbers holds. So pick your favorite mixing property, for instance, vanishing correlation from faraway agents.
00:32:06.110 - 00:32:59.170, Speaker A: As long as you can pick up a law of large numbers from the appropriate textbook, you will get back that the average population belief is a deterministic function of state. And you can still use our theorem, or we have a theorem for that. The other assumption is that for any two states, as Tim pointed out, we are assuming that the average belief in the population is different across states. And this of course ensures that we can read off the true state from the recovered mu bars. But you didn't have to ask average beliefs. You could have asked tell me your 70th percentile or tell me some other function of the average, not off the average, tell me some other function of the distribution of beliefs. And as long as you're convinced that that is different across states and that's a deterministic thing that concentrates, you can use this trick again.
00:33:01.300 - 00:33:08.290, Speaker B: Maybe I missed it. I thought the. Fact that you got a linear system kind of was driven by using means.
00:33:08.740 - 00:33:23.540, Speaker A: No, the linear system is from the fact that the agents, when you ask them for their average expectation, they would take averages. So you don't have to ask them for the expectation. You just want any statistic that concentrates.
00:33:25.960 - 00:33:37.544, Speaker B: Even in the two outcome case, you kind of get more from this mechanism in that you actually can compute the mu bar. Whereas in the previous mechanism you didn't get necessarily mu bar, you just got the right omega.
00:33:37.592 - 00:34:16.568, Speaker A: Yeah, but in some sense, if you believe the assumptions of the model within this mechanism, you're seeing the mu bar for the state of the world that it actually is. Now, this mechanism will also tell you what the mu bar would have been in some other state of the world. If there are settings where that is interesting to you, then yes, you're getting more. But what you are getting more is that if you go to three states, you now have something you can actually do which is mu bar in each of them. And therefore, remember, surprisingly popular doesn't work for three states or is not guaranteed to work. You can use it, but you might get multiple surprisingly popular states and you.
00:34:16.574 - 00:34:28.940, Speaker B: Might so basically I should think of each second order query as getting the one more conditional average belief.
00:34:33.920 - 00:35:27.192, Speaker A: The other one was just that the convex hull of the support has an interior relative. So that, for instance, if the space of possible beliefs is the three dimensional simplex, all the beliefs in the population don't lie in a line that would be problematic because then I wouldn't be able to do this matrix inversion step. It's not a strong assumption, it's a pretty generic assumption to just assume that these beliefs in a population will lie in a full dimensional set. But one sort of cute reuse we found on a paper that did something completely different by people at least Tim knows pretty well. They did it for full rank extraction in auctions. But essentially suppose.
00:35:27.256 - 00:35:30.748, Speaker B: Agents, this is the Kramer McLean generalization.
00:35:30.844 - 00:36:02.170, Speaker A: This is the Kramer. McLean generalization. So deep in there somewhere, they need to prove that they can get back up to full rank. And you can just reuse the same result to say that, look, even if agents are seeing some signal that is not going to give the signal structure is per se not going to give them to full rank. But different agents see different numbers of those signals. So you see L minus one draws of that. So we have a non generic signal structure, but some of us might see more of those signals than others.
00:36:02.170 - 00:37:26.052, Speaker A: Then again, the set of posteriors expands out to a full rank set. This is sort of just the explanation of why all right, now, what else can we do with this mechanism? We could ask, like I said, the original PSM paper asked agents to vote for what alternative is likely? If I had two alternatives, I could use our mechanism as well. Elicit votes from all agents, elicit expected vote shares, and then as long as the population vote shares are different in the two states, you could still use PMBA for the same reasons as before. More interestingly, and maybe something that you might be interested in is elicitation. So, so far I've just assumed that agents are going to tell you stuff truthfully when we assume that people are going to tell us stuff truthfully, this works great. But normally if you want to elicit beliefs, normally to elicit beliefs, you actually need to observe the underlying state of the world and use something like a proper scoring rule on the underlying state of the world. Because this mechanism is going to derive an underlying state of the world.
00:37:26.052 - 00:38:12.660, Speaker A: You could sort of do a double scoring rule on this mechanism that then also makes it incentive compatible for everyone to report the true state. So here's sort of how it would work. You elicit just the mechanism is going to run like the mechanism. So you're going to elicit beliefs from all agents. You're going to elicit expected population average beliefs from two agents. Since the population average beliefs among all these agents, the first order agents are observed rewarding the two agents with a proper scoring rule on the realized population average, incentivizes them to report their true expected what they actually believe to be the expected population average. So you've now got the second population averages correctly.
00:38:12.660 - 00:39:00.720, Speaker A: Now you can run PMBA, you can extract the two states and all the agents you elicited their first order belief from. You can reward their beliefs based on a proper scoring rule, using the extracted state as the thing you score against. And this way because I'm using an assumption that the set of agents is large, so none of these agents can affect the underlying first order population average. But given that truthful reporting of beliefs is therefore a Bears Nash equilibrium so it's not just that Tmba is solving aggregation, it can simultaneously solve incentivization.
00:39:01.780 - 00:39:20.200, Speaker B: So you could imagine stronger incentive. Basically if you look at any, if you zoom in on any agent, it's actually dominant strategy to work. There's a theory about contract functions.
00:39:20.780 - 00:39:45.840, Speaker A: I think the only place where I need a Bears Nash equilibrium is so it's not a dominant strategy because if I think everybody else is messing up, then I don't know what to do. But it's not necessarily no longer an dominant strategy for me to report my belief truthfully.
00:39:46.900 - 00:39:48.976, Speaker B: You could imagine different mechanism where it.
00:39:48.998 - 00:39:58.070, Speaker A: Still lives even I don't see how in other context oh, another context, yeah.
00:40:03.160 - 00:40:05.030, Speaker B: You can't do that. Is it obvious that you do?
00:40:06.620 - 00:40:08.570, Speaker A: I think if you were willing to rule out.
00:40:12.300 - 00:40:26.750, Speaker B: But I mean, just imagine in a situation where any given projection you just get like the prior scoring rule plus some additive shift which is a function of purely of other people's reports. I see. You see what I'm saying?
00:40:27.200 - 00:40:29.628, Speaker A: Purely a function of the issue is.
00:40:29.714 - 00:40:34.284, Speaker B: So from my perspective when it fixed the other reports it's just some added a shift to a broker score.
00:40:34.412 - 00:40:55.412, Speaker A: I think the issue is I think if suppose I think that everyone else is deviating in a way that even though my belief is 0.6.4, I think everyone else is deviating so that this mechanism is going to be screwed and report the wrong state of the world. Now I have an incentive to deviate and report that state of the world because that's going to maximize my score.
00:40:55.476 - 00:40:57.960, Speaker B: This is the unrealized versus realized outcome.
00:41:00.780 - 00:41:02.888, Speaker A: So this is the problem with yeah.
00:41:02.974 - 00:41:04.484, Speaker B: I was thinking of the realized realized.
00:41:04.532 - 00:42:32.176, Speaker A: So you don't actually observe if you then later observe the state it would be easier to pull this off. Yeah. All right. One of the things that this going back to your question about using two beliefs or asking more people for their beliefs in the baseline mechanism there's no reason to if you have L agents you can elicit it from them and go home happy. But if you think that agents are actually not hyper rational in the sense that they perfectly know exactly what's going to happen in the population, they actually just have noisy estimates off population averages, then you can still get this mechanism to work by taking population averages, by asking many people the higher order question and averaging over that if that higher order estimate is more sort of reliable for some concentration region. So the model here describes we have a model of sort of agents have just misspecified beliefs about the population average so they just have errors but those errors cancel out in aggregates. Then you can just instead of asking two agents for their population aggregates for instance, you could ask two large sets of agents for their population aggregate.
00:42:32.176 - 00:43:14.884, Speaker A: Even though no individual agent knows the correct population aggregate, the average will give you a reliable outcome. And this is actually what we're going to use in practice in a second. Okay, so this works great. This allows us actually this can be generalized further so we can handle even some agents who are partisan and so on, but we're still working out exactly what we can handle. So in a highly optimistic move, the final sentences of your abstract that were circulated to you promised you things that you're not going to get today, but I promise they will be there at some future point in the paper.
00:43:15.082 - 00:43:51.356, Speaker C: Okay molest is that related to like I think it's totally unrelated to your model but behaviorally it's definitely newly popular in political survey to ask these higher order questions with some kind of theory. I'm not sure there's a lot of evidence of it but there's some theory that you report more honestly. It's almost like a list experiment style idea, but different where it's I see. I won't tell you my real belief, but if you ask me what I think other people believe, I'll actually reveal something more truthful about myself. I think it's completely different from your model, but it sounds like it could be related to this idea about partisanship.
00:43:51.468 - 00:44:55.860, Speaker A: No, I think I saw sort of the press on that last year, and it gives me hope that, again, that these things one of the pushbacks we got when we started talking about this is yes, but population averages. Who. And, you know, people might be able to tell you their beliefs, but who in their right minds would have any meaningful information about population averages? And that sort of thing gives me hope that there is meaningful information that people are finding. So yeah, you're right, it's outside my model. But it's more like evidence that we are finding that groups of experts not just know what they know, but they also have some meaningful information about what others know. This paper is just taking interest to its limit and saying what could you do with that? And you can do a lot. A concern that you might have is that this is trying to do too much with very noisy data.
00:44:55.860 - 00:45:41.300, Speaker A: So you're trying to invert a matrix based on elicited stuff about expected population average beliefs. Maybe we're just asking for too much. Maybe just the surprisingly popular is just more robust in some sense. So how well does this mechanism work in practice? The original authors are delightful in the sense that they both, in the original paper promised that they would make their data available to anyone and then actually followed through on it, which unfortunately is not super common in the social sciences. It is also true, by the way, that so I'll tell you a little bit more about so here are the studies that they ran. So they ran three sets of studies. In study one, they ran a state capital study.
00:45:41.300 - 00:46:13.672, Speaker A: So what did they do? They told a bunch of respondents. Here is this prompt x is the capital of state Y. So Chicago is the capital of Illinois. Birmingham is the capital of Alabama, 50 states. They ran a bunch of surveys. Every responder had to respond with true and F with whether they think this is true or false and also respond with their predicted population average. In each case they also elicited a confidence.
00:46:13.672 - 00:46:46.250, Speaker A: So this is not just true or false, this is how confident I am in that so they're not exactly running the study I would like to run, but we haven't run our study yet. The second study was general knowledge. So respondents were given general knowledge statements of the know, just a fact about the world. Japan has the highest life expectancy in the world. True or false or Zaire, I don't know. They pick an African country and name the capital. Do you think it's true or false, things like that.
00:46:46.250 - 00:47:51.564, Speaker A: Again, same thing. Response with true or false and predicted population average study three, they collected a bunch of pictures of lesions and they already knew from the case files of those lesions whether those lesions were benign or malignant. So in all three states, the experimenter knows the underlying ground state, the true underlying state of the world, and they need to know this so that they can actually evaluate the mechanism. So here it's slightly different and this one's going to be slightly trickier for us to handle too. So they asked a bunch of dermatologists, they showed them the lesion and they asked them, was it benign or was it malignant? Do you think this if someone presented to you with this, is it benign or malignant? On a one to six scale, one is benign, six is malignant. Also they ask, what do you think other dermatologists would say? So one is like, everyone will agree that it's completely benign. Eleven is complete, everyone will agree that it's crazy malignant and scales are in between.
00:47:51.564 - 00:48:27.124, Speaker A: Now, these are scales, so that's tricky, but that's life doing lab work. In each case, we know the truth of the world. We have the elicited data. They compared majority and surprisingly popular. We can throw in our mechanism, which so I just want to sort of highlight the numbers. So there are 50 states. I know this because I passed my citizenship test, while back capitals majority, for instance, does really poorly.
00:48:27.124 - 00:49:07.504, Speaker A: So the majority of elicited things for a given state matches up with the true capital of that state. Only 62% of the time, surprisingly popular does really well. It gets back 90%, correctness. So 90% of the time, even though the majority does not know the state of the world, the surprisingly popular answer is indeed the state of the world. When we ran our mechanism, we got close to surprisingly popular. So even though we are doing something slightly more intensive on the underlying data, we are close to surprisingly popular. This is general knowledge.
00:49:07.504 - 00:49:45.244, Speaker A: Again, there were 68 general knowledge questions. Majority did basically a little better than a coin toss. Surprisingly popular did way better than a cointos. PMBA does close to surprisingly popular, the dermatology study. Now, the majority is trained professionals, you'd expect them to be good, they do reasonably well. 63%, surprisingly popular does significantly better, 71%. PMBA doesn't quite perform as well and sort of part of it, as we think is the issue with dealing with the scale.
00:49:45.244 - 00:50:25.550, Speaker A: So we have several difficulties with this study, not difficulties with their study, but difficulties with using their study data for our things. So, I mean, I should really just do my own experiment and show off, but instead I'm just going to tell you that it's awesome. We were quite excited when we just finished doing this, like last week and got PMBA to perform close. So, for instance, note few things. One, we are still in a two state world, so this is the best possible world for the surprisingly popular mechanism. We, of course, are theoretically as good as surprisingly popular, even in the two state world. But we're dealing with real world data, so we'd hope that in a three state or a four state question elicitation, we could do better.
00:50:25.550 - 00:51:32.812, Speaker A: Note also that the original experiment elicited votes and not beliefs. So what we're doing when we do PMBA is we are taking all the people who said true, then using their confidence scores as their beliefs on the state being true, averaging that out, averaging their second order beliefs out. So this is sort of PMBA, the robust version, where you average in a population to try and get a better estimate, and this is the one that performs the best. We ran a bunch of others, for instance, taking the median expected population average or taking sort of max. This one seems to perform the best and seems to perform the closest to surprisingly popular. All right, there's some other theoretical niceties that you can prove in this population. So going back to your question about why not ask agents the prior, sort of one of the epistemic things in game theory is priors are just modeling devices.
00:51:32.812 - 00:52:16.844, Speaker A: People don't know priors, people know posteriors. But if they're hyper rational agents, they could just not just tell you they're posterior. They could tell you they're posterior about everyone else's posterior, they could tell you they're posterior about everyone else's posterior about their posterior. And you could construct an infinite hierarchy of beliefs. In theory, you could just ask everyone to elicit this entire hierarchy of beliefs. So two things. One, even if a finite set of agents reported their entire hierarchy of beliefs, you have a mechanical procedure by which the posterior you would result in is the same as the posterior you would have gotten if you knew the prior and you just saw the signals directly.
00:52:16.844 - 00:53:12.324, Speaker A: So you don't need to know the prior per se. Knowing the infinite hierarchy of posteriors is sufficient even in an arbitrary correlated world, even with a finite set of agents. Also, the converse is not true. So you cannot guarantee that you could converge to the pooled information posterior of a sort of Bayesian aggregator who knows the prior for any finite thing. So in finite populations, all we can promise is sort of you could do our mechanism, you can do something reasonably good based on sort of your laws of large number bound. And conversely, knowing higher order beliefs probably would not be super useful unless you knew the whole set. There's a whole bunch of literature on this.
00:53:12.324 - 00:53:47.692, Speaker A: I've cited sort of select. It's another small community that has crossed over into the EC community. So this idea of using higher order beliefs has, of course, been used in aggregation. The further back idea was actually to use this for elicitation. So the Bayesian Truth theorem was by the same author and based on the same idea. And that's been generalized substantially more interestingly. This set of mechanisms has also been successfully used not just in the lab, but also in practice.
00:53:47.692 - 00:54:36.590, Speaker A: So Rigol, Hussam and Roth, for instance, actively take these kind of peer prediction mechanisms to the field in India and use it to find out. Use poll micro entrepreneurs on what micro entrepreneurs think is the best, which of them should be the best one to get the loan, but also poll them for their higher order beliefs and use that to and they find that when they I think my understanding of the findings is using that to allocate funds works better than, like, random allocation or using beliefs. So this sort of thing seems to have some hope for actually working. And that's sort of why I got interested. I will stop early in the interest of time. So.
00:54:41.440 - 00:54:54.460, Speaker B: It'S like the big question is the feasibility of setting sort of higher order beliefs in practical settings. And I think your point says like consumption seem to be doing it.
00:54:56.430 - 00:54:56.746, Speaker A: Just.
00:54:56.768 - 00:54:58.670, Speaker B: Thinking about like a blockchain setting.
00:55:02.450 - 00:55:58.174, Speaker A: I guess I figure I think if you think of a community of people who actually suppose go back to the DeFi lending thing. So there's a bunch of us who have to evaluate loans. And I know that I evaluate, I don't know, marketing projects well, but I know you evaluate technical projects very well and I get a signal when I look at the project. I think the technical is weak. So I now have some information potentially on how I think you will evaluate the project. So in a community of experts who maybe knows each other a little bit or knows sort of stuff about the rest of their community, or it's a repeated setting where they know each other's evaluation schemes, over time you would imagine that they'd have some information about how other people might vote. So that's one hope.
00:55:58.174 - 00:56:26.554, Speaker A: The other one is by the way, again, I only have so these are entrepreneurs who knew each other. They were from the same community. So it worked. This lab was a purely classical social science lab experiment. Bring a bunch of students this was dermatologists bring them into the lab, they don't know each other. It seems to work. Now can we scale this? I have no idea.
00:56:26.554 - 00:56:27.882, Speaker A: It would be interesting to try.
00:56:27.936 - 00:56:32.938, Speaker B: And you're saying despite the fact they're in no position like computer posterior structure.
00:56:33.034 - 00:57:08.360, Speaker A: Yeah, I can't imagine that. Then you had a posterior but they're giving numbers that seem to meaningfully average to something that we can use. And going back, it seems like there is information people seem to have meaningful information about out there, about what they think population averages are. People seem to be more willing to share that even than their own beliefs. So finding ways to harness that is probably useful and interesting.
00:57:08.810 - 00:57:53.590, Speaker C: My impression is this is like some new stuff I saw on political science Twitter so take ten grains of salt. People are really bad at self reporting confidence levels seem to perceive some, I think, average people very reasonably, like I told you to answer the question, so yeah, and they don't carry a lot of meaning with it. But when you ask them the higher order thing, they reveal that they have a lot less confidence answer. And that's part of why I think survey people are starting to like it a lot because it seems like we have all these crazy things in politics where people insist things that are pretty clearly false or true and they think it might be fake performance. And when they answer these high rider questions, they seem to stop performing. So they'll admit that like well actually.
00:57:53.660 - 00:58:47.590, Speaker A: Most people probably don't so I should have had one more column here so because they elicited confidence they could actually do something called confidence weighted majority. Confidence weighted majority sort of robustly on average just barely outperforms majority sometimes does worse for the reasons that you are saying. So that's sort of why basic I mean that's sort of the call for you should do something else other than majority and confidence doesn't seem to help but yeah, it's an interesting question on how do you sort of robustly harness something that you'd be willing to bet money on that this works? I can only tell you that this has promise.
00:58:48.090 - 00:58:57.500, Speaker C: Can you explain why the pricing popular method especially well, in the first line there sorry? In the first line yeah because extremely well.
00:59:01.570 - 00:59:54.026, Speaker A: I don't have a good sense maybe the only thing is sort of these were all American so this has tricky things to do with parsing the data because it's a one to six score and so on. This is a straight up true or false question and it's American lab candidates in being asked questions about America versus sort of global general knowledge questions. So maybe they just have a lot more information about what other people think about the country. So maybe it's a statement of their higher order beliefs are actually more informative. Whereas here it's not just that I don't know the answer I also don't know really what other people know. So everything is ill conditioned when I start doing inversions is there some information theoretical which this PMDA is optimal or is like upper bounds?
00:59:54.058 - 00:59:54.800, Speaker C: I don't know.
00:59:58.050 - 01:00:55.040, Speaker A: So in some sense this isn't a hard theorem but in the following sense if you buy the assumptions of the model we know that you cannot do anything with just first order beliefs. We are asking sort of l times l more information we know we can't do anything with anything less than that. So we're asking the least amount of questions you could possibly ask and get a guaranteed answer that is within the model guaranteed to be correct so that's the sense in which this is information theoretically optimal, I think. But that's not a formal answer. That's just saying we're asking very parsimoniously few questions relative to what other information is out there that these agents have. We could have done sort of if you really were brave, I could ask you about your beliefs. About my beliefs? That your beliefs are about.
01:00:55.040 - 01:01:00.620, Speaker A: But that only happened in Doctor Strange love. All right. Thank you.

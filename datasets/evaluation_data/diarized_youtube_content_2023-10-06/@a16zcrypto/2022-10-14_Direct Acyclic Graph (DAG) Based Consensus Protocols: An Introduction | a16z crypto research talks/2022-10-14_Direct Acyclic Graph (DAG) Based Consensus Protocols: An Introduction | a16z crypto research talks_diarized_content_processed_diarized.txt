00:00:06.480 - 00:00:07.030, Speaker A: You.
00:00:09.880 - 00:00:25.060, Speaker B: Welcome everyone, to the last a 16 Z research seminar, at least for now, seminar series we're going to end, not dissimilar to how we begun today. It'll be tag based consensus.
00:00:25.880 - 00:00:48.450, Speaker A: Thanks. Okay. Yes. So I'm going to give what I hope is a nice, easy introduction to Dag based consensus protocols. I think most of the talk won't be that technical, but this being a tutorial, I'm going to go through like, a couple of proofs, okay? So there'll be some parts where some concentration is required. So please do like, pepper me with the questions. The more questions the better.
00:00:48.450 - 00:01:42.880, Speaker A: In fact, I'll finish early if there aren't enough questions. Okay? So don't worry about slowing me down. Okay, so we're going to talk about Dag based consensus protocols. I guess the first natural question, let me just minimize that so I can see the slides, is what is a Dag based consensus protocol and why might we care about these things? I think it's safe to assume everyone knows what a blockchain is. So obviously in a standard blockchain, the way it works is the blocks at least the blocks account, the blocks actually have their transactions executed is all in a sequence with each pointing to the last one. Okay? And in a protocol, I have to get that to go forward. In a protocol like bitcoin, forks do occur, right? But ultimately only one side of the fork ends up counting in the sense that only one side of the fork actually has their transactions executed.
00:01:42.880 - 00:02:35.468, Speaker A: And in fact, certainly in the context of bitcoin, forks are seen as being a bad thing, right? Basically, forks threaten security, and so we actually have to slow things down and slow things down quite a bit in order to prevent them happening too much. Okay? So on a very basic level, a very sort of simplistic thought is, wouldn't it be great if somehow both sides of the fork could count without threatening security? If we could do that, then we could produce blocks much more quickly. This would be a good thing. Okay, so that's exactly what happens in Dag based protocol. So now blocks are allowed to have multiple parents and multiple children, and the resulting structure we call the Dag, or a directed acirculate graph. A graph is just a bunch of nodes or blocks with edges between them. It's directed because the edges have a direction to them.
00:02:35.468 - 00:03:13.624, Speaker A: It's acyclic just because they're all pointing in the same direction, which means we don't have cycles if you follow edges in the correct direction. Okay, so that's simplistic idea behind it. On maybe on a slightly deeper level, the idea is that protocols like bitcoin in some sense confuse two tasks. Okay? So blocks have a dual role. On the one hand, the blocks are used for relaying sets of transactions. On the other hand, they're also used in order to establish consensus on the ordering. Okay? And the idea is with a Dag based protocol.
00:03:13.624 - 00:04:14.354, Speaker A: We don't want to let a block's role in establishing consensus get in the way of its role in relaying the transactions. Okay, so the idea is the Dag will just relay the set of transactions, maybe together with some sort of minimal ordering on those transactions that's required to make sense of them. We need at least some sort of ordering on the transactions to make sense of them because sometimes transactions will lower than others to be valid, right? Even before we start worrying about double spending and stuff, maybe Alice has transferred to Bob will only be valid after Charlie's first transferred some funds to her. Okay, so we need some sort of minimal ordering on the transactions. So Dag is just going to grave the transactions with some minimal ordering information. And then the idea is that we'll be able to carry out a consensus protocol then on the Dag structure to totally order the transactions after the fact at no extra communication cost. Okay, so you're just going to lay the Dag.
00:04:14.354 - 00:04:57.740, Speaker A: The Dag will tell you what the transactions are. And then after you've lay the Dag, each individual party is going to be able to take their Dag and run a little algorithm on their own to decide how to totally order the transactions and have no extra cost, right? That's the ideal. Okay, so in terms of throughput here, you've stopped consensus being a bottleneck. That's the plan. It's a different sort of consensus protocols you run. The Dag might have different latencies and stuff, but you're not getting in the way of the throughput. Okay, so to summarize then sort of the Dag structure, which could be very efficiently produced, that just relays the transactions with some sort of minimal necessary information on the ordering there before you even start worrying about double spending and that kind of stuff.
00:04:57.740 - 00:05:36.850, Speaker A: And then at no little extra communication cost, we're going to be able to carry out a consensus protocol on the Dag structure which totally orders the transactions. That's the basic. Okay, now let's start looking at some examples of Dag protocols. So to keep it simple, first of all, so ultimately, in order to execute general smart contracts, we're going to need to have a total ordering on the transactions. But for now, let's start off with a simpler task. We're just going to implement a payment system. Okay, so we're just going to implement a payment system, first of all.
00:05:36.850 - 00:06:13.310, Speaker A: And again, just to keep things simple, let's start off by considering just the permissions case. Okay, so we have a fixed set of parties involved in the protocol execution. So they're end parties. Everybody knows exactly who everybody else is right from the start of the protocol execution. And maybe, well, suppose we have a publicly infrastructure as well. Okay, so the payment system I'm going to present is the one. So EHE Japiro Uni came a couple of weeks ago and gave what I thought was a fascinating talk.
00:06:13.310 - 00:06:39.670, Speaker A: In that talk he presented the payment system. I'm going to go over now. So if you completely understood every aspect of that, and I'm sorry for the repetition. I guess personally I didn't understand all of it until I went back and read a bit of the paper. So I'm hoping it's worth going over it again. Now we have a bit more time today so I can spend some more time going through the details. Okay? So I'm going to present Udi's system, which I think is a very elegant system.
00:06:39.670 - 00:07:24.102, Speaker A: The whole thing I'm going to present will work in the Asynchronous setting. So to remind you what that is, that means that when you send messages, they are eventually delivered when they could take any finite amount of time. Yeah. And so you can sort of think of the adversary here as controlling message delivery subject to that constraint that eventually messages have to be delivered. Everyone happy with that. Okay? And one other sort of slight simplification here. So generally when we're talking about blockchain protocols or state machine replication protocols, there's a separation between the parties who are actually carrying out the consensus protocol and the clients who are producing the transactions.
00:07:24.102 - 00:07:59.694, Speaker A: Okay? So here I don't want to worry about that sort of complication. Just to keep things simple, I'm going to imagine that it's actually that the parties who are carrying out the consensus protocol are the ones who are producing the transactions. Okay? So in particular, that means that the blocks that each party produces that can just be involved with like including their own transactions. There's not a necessary simplification, we don't have to assume that. Okay. I'm just doing that to make the presentation slightly slicker. Okay? So what we have to do is we have to form the Dag structure in some way and then we have to sort of think about how we prevent double spending and stuff.
00:07:59.694 - 00:08:35.050, Speaker A: Okay? So to form the Dag, it's very extremely simple. So we could have honest parties produce blocks whenever they can, and I say one at a time there. So here I'm allowing that different parties could produce different blocks exactly the same time. I just mean for an individual party, if they're honest, they'll produce their blocks one after another. So they produce blocks whenever they can, whenever they like. The basic rules very simple. So when they produce a block is you just point to all existing leaves as seen by that party, obviously, according to the Dag structure they actually received.
00:08:35.050 - 00:08:59.780, Speaker A: So that's the simple rule and that's it. Okay, so that's how we form the Dag. Extremely simple. So a couple of other details I should add in though. So we're assuming here that parties sign their blocks so we can't forge blocks and pretended by other people. And also we're not going to add a block into our Dag until we see the parents of that block. Okay? So you can imagine sort of down with closed Dag structures the whole time.
00:08:59.780 - 00:09:12.396, Speaker A: Okay, so a little terminology. So, yeah, you have to sort of memorize a few definitions as we go through here. I'm afraid if someone does a block.
00:09:12.428 - 00:09:18.224, Speaker B: With four predecessors, like, you save it on the side until you also heard.
00:09:18.262 - 00:09:50.700, Speaker A: About all those predecessors. Yes, exactly. Okay, so when a block points directly to another, we're going to say acknowledges the block being pointed to. Okay, so here U one acknowledges U two and U three, and observing is just a transitive closure of acknowledge. Okay, so U observes V. There's a directed path from U to V. Okay, so U one here observes all the other blocks.
00:09:52.560 - 00:09:54.520, Speaker B: Columns here with the different players.
00:09:54.680 - 00:10:10.590, Speaker A: Yeah. Yes, exactly. One column for each player, just a nice way of picturing it. And then we're imagining sort of time going up, the same exact thing. Okay, so U observes V. Just observe if there's a path from U to V. Okay.
00:10:10.590 - 00:10:45.942, Speaker A: And a basic observation here. So the instructions mean the blocks of an honest party will be in a sequence in the sense that each block produced by P will observe the previous blocks produced by P, because each time he goes pointing to the leaves. Right. So if you're honest, I'll be in a sequence in that sense. Okay, so if all parties were honest, then this would be what's required. Okay, but obviously we have to worry about people who might be dishonest. We're imagining sort of Byzantine failures.
00:10:45.942 - 00:11:03.040, Speaker A: Some people are allowed to behave dishonesty here. So, okay, what's the basic problem? But the problem is that a dishonest party could try to cheat or double spend by producing what you might call Equivocating blocks. Okay, so these are incomparable blocks where so each neither observes the other.
00:11:04.210 - 00:11:08.260, Speaker B: If everyone was honest, you still have to talk about how to interpret that.
00:11:08.710 - 00:11:32.790, Speaker A: Well, okay. No, I mean, you could just regard transactions as being valid. Right? I mean, if nobody's cheating, then there's no problem. We're not trying to totally order everything here, right. It's just a payment system. Okay, so what we're worrying about is just that we have to worry about people cheating. They might try and cheat by producing, like, Equivocating blocks.
00:11:33.610 - 00:11:36.006, Speaker B: The only possible conflicts are blocks by.
00:11:36.028 - 00:11:48.890, Speaker A: The same party in this setting. Okay? Because I've said that each party will just include their own transactions, their own block. The general setting is going to be essentially the same. Okay? But in this setting, my blocks conclude my transactions.
00:11:51.110 - 00:11:55.060, Speaker B: There's no notion of conflict between transactions from different people.
00:12:00.990 - 00:12:03.820, Speaker A: Okay, so how do we deal with that?
00:12:04.510 - 00:12:07.134, Speaker B: Order still sort of matter. Like, if A pays B and B.
00:12:07.172 - 00:12:16.974, Speaker A: Pays well, that's the ordering that's given by the Dag. So the Dag is giving you this minimal ordering. You're putting them into the Dag in an ordering that makes sense.
00:12:17.012 - 00:12:19.966, Speaker B: Is there a canonical total ordering or it doesn't matter what the total ordering.
00:12:19.998 - 00:12:31.320, Speaker A: Well, no, you're not establishing a total ordering. Right. So if any transaction depends on others, then those have to be included amongst the parents of that block. But you're pointing to all leaves, so that's fine.
00:12:36.160 - 00:12:39.790, Speaker B: They both have block B through B's, total order.
00:12:43.980 - 00:13:07.058, Speaker A: Okay, so how do we do this? It's quite simple. Okay, so some more definitions, I'm afraid. Okay, so we're going to say A block U approves v. Block V produced by P. Okay. If it observes it and it doesn't observe any P block, that equivocates with it. Okay.
00:13:07.058 - 00:13:42.740, Speaker A: So as an example here, so U one approves V. In this case, it acknowledges it, but we don't require that. We require just that it observes it and it doesn't observe this other Equivocating block here. Okay, so that was for blocks. Now we want to extend the definition to parties. We'll say party p prime approves V. Just if some P Prime block approves V so there's at least one block produced by P Prime that approves it.
00:13:42.740 - 00:14:15.354, Speaker A: So this is important here. So in particular, in this situation here, then this means that P four approves V, even though U Two, which is a P Four block, doesn't. So U Two is observing both of the equipmentating pair. But here, P Four approves it just because there is the P Four block, u One, that approves it. We just require one P Four block that approves. That's all. Happy with that.
00:14:15.552 - 00:14:18.518, Speaker B: So this would happen only if P Four was dishonest.
00:14:18.614 - 00:14:38.866, Speaker A: No, here, P Four is being entirely honest. They produced this block before they saw this one later on. Or it could even be that they're forced to because P Two has observed this one, and then they're forced to point to that leaf. Okay. Yeah. In this picture, I guess you have an option of whether to point to it. Okay.
00:14:38.866 - 00:14:47.270, Speaker A: So maybe a better picture would be if you, P Two, have produced blocks that observe this one and not that one, and then P Four is forced to observe the other block.
00:14:52.770 - 00:14:56.238, Speaker B: Observing and approving isn't distinguished with how.
00:14:56.244 - 00:15:02.936, Speaker A: You approve the link. Say again? Sorry, the blocks don't say, I approve.
00:15:02.968 - 00:15:07.228, Speaker B: This block, I observe that block. They just have a list of blocks they're observing.
00:15:07.404 - 00:15:22.020, Speaker A: Yeah, well, yeah, I guess you could phrase it like that, yeah. Okay. You just point to some parents that defines the set of blocks that you're observing, and then from that, there's a definition of which ones you're approving.
00:15:25.980 - 00:15:35.484, Speaker B: Fundamentally, it's really just like a Dag in the mathematical sense, with a labeling of each note of the player. And then all of these are just.
00:15:35.522 - 00:15:54.520, Speaker A: Defined extraneous definitions on top. Right. You're not thinking about these definitions as you form the Dag. You just form the dag. Okay. So we have in that definition, though, okay, so one party approves a particular block, just that they produce some block that approves it. The block in question.
00:15:54.520 - 00:16:38.290, Speaker A: Okay? So now a basic observation that is an honest party can't approve two Equivocating blocks produced by some party P. Okay, why is that? Well, consider the first block by P Prime that approves one of those two blocks. Again, it can't approve both at the same time because if it's observing both, then it's approving neither of them. Yeah. So consider the first block by P Prime that approves one of the blocks or then all subsequent blocks by pre prime, right? They're on a sequence, so they're also observed they'll still observe that first block, right? So they can't approve the other block. Either they observe or they don't. By the way, they're not going to approve it.
00:16:38.290 - 00:17:18.800, Speaker A: Okay? So honest parties can't approve both sides of an Equivocating pair, only one side. Okay. And now basically we're done almost, right? So we say V is approved by a supermajority if it's approved by N minus F parties. Okay? So N is the number of parties involved, f is our number of faulty parties, which we're thinking of as being less than an N over three. So that's our notion of finality. That's our notion of confirmation. Right? We say V is approved by a supermajority, it was approved by N minus F parties, and then we're done.
00:17:18.800 - 00:18:15.264, Speaker A: So we're supposing F here is less than N over three. What we have now is the two Equivocating blocks produced by P can't both be approved by a supermajority, because then if it is, then we have two sets of N minus F parties. Those two sets, just by a simple county argument, have to have some honest party in the intersection, but that honest party couldn't approve both sides of the Equivocating play. Okay, so we get so, right, so to form the Dag, it's extremely simple because they have honest parties basically point to existing leaves when they produce a block. A block approves V produced by P if it basically observes it and it doesn't approve any Equivocating block. And then a party approves a block just if it produces some block that approves the block in question. Okay? And then we easily get safety.
00:18:15.264 - 00:18:45.766, Speaker A: Right? So V is approved by we say V is approved by a supermajority. It was approved by N minus F parties. It's established as safety because two Equivocating blocks produced by P can't both be approved by a supermajority just by simple intersection. What are the properties for aiming? We want that when you produce Equivocating blocks, they can't both be confirmed, basically. That's why yeah, safety. Well, so loneliness is relevant. Okay.
00:18:45.766 - 00:19:27.310, Speaker A: It's kind of trivial in this circumstance. Okay, so basically what you want so here, as long as everybody's producing infinite many blocks, if I produce a block, it's not part of a Crib Gating pair and I send it to the honest miners, then we're in the Asynchronous setting, but it will eventually be delivered. Right? So they're producing infinitely blocks when those blocks are pointing to all the leaves, they'll eventually observe my block and so approve it because it's not part of an equivocating pair. Okay, so liveness is fairly trivial here. Okay. So I know I think that's kind of like an extremely simple, elegant protocol. Now, I was kind of impressed by how simply that could be done.
00:19:27.310 - 00:19:57.190, Speaker A: Yeah. And it's worth noting also here that you have this is a deterministic protocol which works in the Asynchronous setting. So that might sound sort of OD if you're familiar with results from consensus, because there's this famous result of Fischer, Lynx and Peterson which says basically you can't do consensus in the Asynchronous setting in a deterministic fashion. There has to be some sort of randomness involved. So here we haven't got a contradiction because we're not solving by Zantane equivalent. Okay. We're solving a certain weaker problem.
00:19:57.190 - 00:20:38.964, Speaker A: Okay. So I don't know, I think that's a very sort of simple, elegant protocol at this point. Hopefully you're convinced that Dags are useful. And that's my first thing I understand. If it can only include transactions that you propose in your block, then how does this work? If I acted as like, P two and P three and did my double spend that way? The thing is, all of this, I've sort of simplified it slightly. If you want to do it for transactions instead, you can just do exactly the same definitions, basically. And you say, like, one block approves a transaction if it observes it, but it doesn't observe any conflicting transaction and the same sort of proofs go through.
00:20:38.964 - 00:21:18.958, Speaker A: Okay, right. Okay. Very quickly, give like a clear statement of what part is it not solving? I mean, I guess you'd have to sort of come up with a reduction and then see how the reduction fails, I guess. So maybe that's the way to answer that. Is it by design? Agreement is a particular task. Okay. Maybe if you replace by Antony agreement with State Machine replication, just think of them as essentially being equivalent in some sense.
00:21:18.958 - 00:21:52.174, Speaker A: So State Machine replication asks for us like a total ordering on transactions which we're not producing here. I think that's an interesting question. I think that's a fascinating question. It's made slightly less interesting by the fact it's quite easy to get a total ordering. So I think it will be worth really going into that in detail if it wasn't quite so easy to get the total ordering. But yeah. Okay.
00:21:52.174 - 00:21:53.920, Speaker A: So that's payment system.
00:21:55.890 - 00:22:03.106, Speaker B: The last thing you just said almost seems to contradict your answer to math. You're escaping it by not having a total ordering. And you just said, Joe, it's actually.
00:22:03.208 - 00:22:08.580, Speaker A: Really easy to get a total order, okay. If you introduce randomness and stuff, I'm saying, okay when I say it's really easy.
00:22:11.830 - 00:22:15.666, Speaker B: Can you not already get easily a total ordering from what you've spent so far?
00:22:15.768 - 00:22:44.574, Speaker A: Because different people are going to have see different versions of the Dag at any given cobodian time. So it's very easy to take a function that takes any Dag and just like stretches out into a linear order, but different people are going to see different versions of Dag at different times. If you just do that simple thing, then you're not going to have safety, they're going to see different sequences in their total order. Okay, so it's easy. Okay, it's not easy. I guess we're going to go through that now. Right, so it's easy in the sense that there's no extra like a communication cost to it.
00:22:44.574 - 00:23:15.170, Speaker A: Okay. Like let's say the naive way of yeah, satisfying. Yeah, okay. I mean, certainly termination is part of it. I guess we'll see later on, maybe. So think in terms of bydantine broadcast rather than bydantine agreement. Maybe it's clearer.
00:23:15.170 - 00:23:26.090, Speaker A: So there definitely the termination is the thing that's impossible in the asynchronous setting. Right, so once you remove the termination or do a weaker version of termination, which we'll see later on, then it becomes possible in the asynchronous setting.
00:23:27.070 - 00:23:34.346, Speaker B: The fact that you don't get a total ordering, is that fundamentally because you're an asynchronous model or is it more.
00:23:34.528 - 00:23:40.542, Speaker A: General, the fact that we can't achieve a total ordering without randomness. That's true because we're in the asynchronous model.
00:23:40.596 - 00:23:44.318, Speaker B: If you're in the parallel synchronous model, then actually you could maybe go to this.
00:23:44.404 - 00:23:50.606, Speaker A: Yeah, okay, yeah. So then yes, exactly. You have to yes, you wait for the period of synchrony and then you'll be able to extract the toad loading.
00:23:50.638 - 00:24:04.338, Speaker B: Without randomness asynchronous model. Like, you have some Dag and you have a canonical ordering, but then you have no idea how long in the future it might be before you get some old block that causes you to rearrange the beginning part of your sequence.
00:24:04.434 - 00:24:55.400, Speaker A: Yes, sorry, the naive protocol to get a total ordering, what is that? I think maybe that would help me understand the naive protocol. You could take any Dag and just like you can just stretch it out so you preserve the ordering relation, just add in, extend the order. Now you got a total ordering. You could do that, but then you're not going to have your safety condition being satisfied. Right, because different people are going to see different versions of the Dag. I've seen this path over here, you've seen that half over here, and we're going to be producing incompatible sequences if we do that. Okay, so we have to read that there's sort of like no point in time where everyone is actually first licensed to claim that eventually you don't know when you've heard of the same set of blocks and yeah, sorry.
00:24:55.400 - 00:25:20.910, Speaker A: Okay, so that's supposed to be the simpler, elegant part of the talk. Now we want to go into total ordering part. This part, I'm afraid, is a bit more fiddly. There's quite a lot of definitions involved. So again, feel free to make me to go back over definition stuff. I hope this part isn't overly fiddly. Okay, so now we want to extract like a total ordering on transactions.
00:25:20.910 - 00:26:13.510, Speaker A: I'm going to try and try and sketch how we do that. And the basic point, as I said before, is the idea is that we can do that at no extra communication cost because we just relay in this dag and at no extra communication cost each individual party will just look at their dag and they'll gradually form this total ordering in such a way that we have the safety condition. Everyone's always got some compatible versions of that total ordering. Okay? So first of all, we're going to look how the Cordial Miners protocol does this and then we'll also see how Dag Rider works in detail. Basically, it's similar proof, so it's really just one. So first of all, I am going to give the dag a little bit more structure. Okay? So what we're going to do now is we're going to divide the dag up into rounds, round one, round two, round three, and so on, and each honest party will produce one block in each round.
00:26:13.510 - 00:26:59.804, Speaker A: Okay? And we're going to say that an honest party will produce a block in Round R plus one as soon as it sees N minus F blocks in Round R. Okay, we can do that in the Asynchronous setting, right? Because you just inductively suppose that everybody's going to produce blocks in Round R, then I'll send those blocks out. Everyone eventually see those blocks, N minus F of them because the 40 parties might not. Okay? And so eventually everyone will proceed to round R plus one and they all produce blocks in that round and so on. So that's the rule. So an honest party is going to produce a block in round R plus one as soon as it sees N minus F blocks in round R. Again, F is a number of faulty parties and the rule is, well, basically the same rules before.
00:26:59.804 - 00:27:13.830, Speaker A: So the block produced must point to those N minus F blocks in round R that you've just seen and also any other leaves from previous rounds. Okay, so basically it's the same as just all the leaves, basically. Right, okay, just make it explicit that it points to those N minus F as well. Okay?
00:27:15.240 - 00:27:17.620, Speaker B: So the only new data is the.
00:27:17.690 - 00:27:51.570, Speaker A: Round yes rounds and the rules as to when you proceed between yes. Okay, if party two, let's say here we've got N is five and F is one. So we're waiting to see four blocks in a round before we proceed. So we suppose party two here is just see these four blocks, then they'll produce a new block that points to those, but also there's this leaf down there, so they'll point to that guy down there. Okay, so the rules for forming the Dag clear. Great. Okay.
00:27:51.570 - 00:28:25.764, Speaker A: And then so how are we going to extract this total order? Well, we don't have to use a notion of leaderBOX, but it's a fairly sort of natural way to proceed. That's what we're going to do. So we're going to use a notion of leaderBOX. What we're going to do is we're going to divide all the rounds into waves. Basically each wave will consist of five rounds. So wave one is rounds 12345, wave two is six, seven, 8910 and so on with that. Okay, so we're dividing into waves.
00:28:25.764 - 00:29:01.228, Speaker A: Each wave consists of five rounds and then for the first round of each wave we're going to select the leader. So in round one we'll select the leader. Round six we'll select leader. Round eleven we'll select leader and so on. And then blocks produced by the leader, like in that round they'll be called leader blocks. So if I'm the leader for round one, I produce a block in round one that'll be called a leader block. Is that crystal clear? Yeah.
00:29:01.228 - 00:29:03.180, Speaker A: Waves consistent, five rounds.
00:29:04.080 - 00:29:07.816, Speaker B: So with an honest leader you'll have one leader block. With a dishonest leader you may have picked.
00:29:07.848 - 00:29:35.364, Speaker A: Yeah. So the leader block. Exactly. Okay, so here I don't need to worry yet about how we're selecting the leader for each round at the back of our minds here, here we know that now we are going to come up against the FLP impossibility results. We know we are going to have to use some randoms at some point and it's in choosing the leaders that the randoms is going to come in. Okay, so have that in the back of your mind if you like, but for now I don't want you to worry about how the leaders are selected. But there are leaders somehow.
00:29:35.364 - 00:29:36.104, Speaker A: Okay.
00:29:36.302 - 00:29:39.050, Speaker B: Do you think safety will be for a worse case order?
00:29:40.300 - 00:30:14.714, Speaker A: Well, yeah, we'll get safety without it's for the likeness that we need the randomness. Okay, so yeah, we could choose leaders, deterministically and be safe, but we want likeness. Okay, so is that all crystal clear? Great. Okay. As we've just saying before. Okay, so it's hopefully fairly easy to see. I mean it's quite easy to extend any dag structure to a total order if you're not worried about things like safety conditions and things.
00:30:14.714 - 00:30:36.314, Speaker A: Okay, right. So we can assume given that we're given some function tau which takes any Dag and extends it to a total ordering. Okay. So we're going to assume given a tau of that sort and that will just be a tool that we're going to use. Doesn't yet suffice. Why? Because it doesn't have the required safety safety condition. If people just use this towel they're going to be producing incompatible sequences.
00:30:36.314 - 00:30:52.450, Speaker A: Okay. But it's going to be a tool that we can use. Okay. A little bit notation. Okay, so for block U, so square brackets u is just that's the initial segment of the dag defined by U, like the below U. Okay. All the stuff that you observed.
00:30:52.450 - 00:31:38.112, Speaker A: Okay, so first of. All the rough idea is this. So here I'm being a little bit vague first and I'll make it more precise later on. Okay? So for some commonly agreed sequence of leader blocks, whatever that means. And we have to make that precise for some commonly agreed sequence of leader blocks, like U one, U two, U Three, and so on. What we're going to do is we're going to define the total ordering to be so tau of U one and then concatenated with tau of this, remainder here, like the stuff that U two observes that isn't already observed by U one, concatenated with this, remainder here, concatenated this, remainder here, and so on. Okay? That's what we're going to end up doing and hopefully it's clear on some sort of basic attuitive.
00:31:38.112 - 00:31:43.832, Speaker A: Obviously I'm being vague at this point but if there really is some sort of commonly agreed sequence of leader blocks, then this should sort of be okay.
00:31:43.886 - 00:31:55.320, Speaker B: Right, so tau of U two minus U one. So I should interpret U two minus U one just as like set difference. Give me a new gag for which tau is going to follow.
00:31:55.390 - 00:32:28.240, Speaker A: Yes. Okay, so that's the rough picture. We want to to able be form some sort of commonly agreed sequence of leader blocks and then we're going to form the total order in this sort of way. It's obvious here though that we can't just use any sequence of leader blocks because people might sort of disagree on them. Malicious actors might produce equivocating pairs of leader blocks and so on. Okay, so the blocks we use will have to be confirmed or final in some sense. We're going to need some sort of notion of finality here.
00:32:30.470 - 00:32:33.940, Speaker B: This would all be easy with only honest readers. Right. Then there'd be no problem.
00:32:35.190 - 00:33:10.828, Speaker A: Yes. If all the leads blocks were honest, it'd be multiple leader blocks in the same round. Okay, so to recap then, the idea so far is we're dividing the sets of round into waves. Each wave is five rounds. We're somehow selecting a reader for the leader for the first round of each wave and we're calling their blocks in that round leader blocks. If we could agree on a sequence of leader blocks, then that sequence could be used, as I guess described to find the, to find the required total ordering. Okay.
00:33:10.828 - 00:33:28.616, Speaker A: And what we said just before is that to agree on the sequence, obviously we'll need to find some notion of finality for leader blocks. Okay. So everyone can agree on which blocks are final. Okay. So now what we're going to do is define if you can do this.
00:33:28.638 - 00:33:42.444, Speaker B: Is it clear you will have the SMR? You'll have consistency in that kind of okay, just because everybody eventually agrees on the initial segment and then everybody eventually.
00:33:42.492 - 00:34:24.990, Speaker A: Agrees yeah, you're just totally ordering stuff so you're meeting the SMR requirements. Okay, so what I guess said there is that we need to establish a notion of finality for leader blocks. Everyone agree on the right sort of sequence to use, right? So just a couple of definitions. Again, I apologize. Number of definitions, it's not my fault. Okay? So by a supermajority of blocks, we mean a set of blocks produced by a supermajority of miners or validators or whatever we'd have called them, okay? So take the set of blocks, take the set of miners who produced at least one of those. That's a supermajority, okay? And now we're going to say a block V is ratified by a block U.
00:34:24.990 - 00:35:01.170, Speaker A: If U observes a supermajority of blocks, approving V, so maybe a little time to absorb that. If you familiar with tendermint, then one way you could think of this, you can sort of think of you as seeing a stage. So in Tendermint, you have like two rounds of voting in each block. You might get in the first round, you might get a stage one QC or corner certificate. In stage two, you might get a stage two QC. Here you could think of you as like seeing a stage one QC for V because each of these blocks is approving V. You can think of that as being a vote for V.
00:35:01.170 - 00:35:49.560, Speaker A: So U is seeing like a stage one QC. So you can think of when you see a stage one QC, you vote for it. So you can think of you as representing like a stage two vote in a tendermint setting. Okay? If you're familiar with tendermint, that's helpful. If you're not, it's unhelpful. In that case, forget what I just said, just take it at face value, okay? And then we're going to say a leader block of wave W is final if it's ratified by a supermajority of blocks in the final round of the wave. Okay? And again, for those who know tendermint, this is like V receiving a stage two QC, right? Each of those blocks that ratifies it, that's like a stage two vote.
00:35:49.560 - 00:36:47.766, Speaker A: Now you've got a supermajority of those. So you've got our stage two QC, okay? And again, that's hopefully a helpful way to think about it if you know tendermint. If you don't, then just take those definitions at face value. Okay? So I guess, yeah, it's quite helpful if you can try and remember those definitions for what's going to follow. Okay? Everybody happy? Okay, so we said we needed a notion of finality. Now we've got that notion, we can go back and we can make our previous I sort of outlined how we got to define our total ordering, but now we can make that precise using the notion of power to be defined. Okay? So any given point in the execution, each each party is going to have some dag structure.
00:36:47.766 - 00:37:19.986, Speaker A: They want to extract some sort of total ordering from that. So what we're doing is we're defining a function or which will take any dag structure, which you're thinking of being the Dag structure that a party might have at a given point in the execution, it's going to output some totally ordered sequence of blocks. Okay? And what we said before is basically it's going to suffice to select an appropriate sequence of leader blocks. Appropriate in some sense. So all we have to specify now is precisely how we define that sequence. Then we'll have defined ward. So the way we define that sequence is as follows.
00:37:19.986 - 00:37:53.534, Speaker A: What we do, we take D. We take the last final leader block in D, that's this guy here. We take the last final leader block in D. Let's call that guy U, okay? And then this guy here. And then we ask, what's the last leader block in D that's ratified by U, not necessarily final, but what's the last leader block that's ratified by U? That's this guy here. So that's u prime. And then we ask, what's the last leader block ratified by U Prime? That's this guy here call that U double prime.
00:37:53.534 - 00:38:23.606, Speaker A: We keep on iterating, and it's how we define our sequence. Okay, so again, the way you define the sequence, we just take the last final leader block that's U. Let me ask, what's the last leader block ratified by U? That's this guy. What's the last leader block ratified by that one, that's the next guy, and so on. And we iterate in that fashion to define our sequence. Okay. And then again, so once we've got this sequence, u one, U two, U Three, and so on, our output is just tau of the stuff below, u one, concatenated with tau of the stuff in the remainder.
00:38:23.606 - 00:38:34.560, Speaker A: Concatenated with tau of stuff in the remainder there. Okay, so that's just a definition. It shouldn't be clear yet why that works, but at this point, it's important that the definition is clear.
00:38:35.650 - 00:38:37.294, Speaker B: Yeah. Let's talk about it a little bit.
00:38:37.332 - 00:38:37.920, Speaker A: Okay.
00:38:46.690 - 00:38:59.586, Speaker B: Leader blocks are present in, like, round one, round six, round eleven, round 16, and the round five blocks tell you whether or not some round one block is finalized or not.
00:38:59.608 - 00:38:59.890, Speaker A: Yeah.
00:38:59.960 - 00:39:25.750, Speaker B: Okay. And so some will be successful just in the same way, like, tendermint some rounds, you'll succeed in producing a confirming block, and some you won't. So here there will be waves where the graph in those five levels finalizes the block at the first level of that wave. So now just help to this recursive thing, okay. What the picture I just said? How does this interact?
00:39:25.830 - 00:39:44.542, Speaker A: Right? Okay. So here again, it won't be clear why this is the right definition yet, but it's just a definition. So we take the last final leader block in the Dag yeah, it's fine line. Okay. And then we look at what's the last leader block ratified by that one. So it could be the previous one, or it could be an earlier one.
00:39:44.596 - 00:39:45.950, Speaker B: Which may or may not be final.
00:39:46.020 - 00:39:59.894, Speaker A: Which may or may not be final. Right, okay. Then we just keep on iterating. What's the last leader block ratified by that one? What's the last leader block ratified by that one? We keep on iterating back. That defines our sequence. Then we feed it into town. We get our so maybe you should.
00:39:59.932 - 00:40:07.126, Speaker B: Answer this later, but I am curious, why not just use the final leader blocks and not worry about this kind of iteration in between?
00:40:07.308 - 00:40:36.820, Speaker A: Yes, okay, that seems like the first thing to try. Okay, well, certainly we'll see if proof that works and maybe because we'll think about what will happen if that we do that as well. Okay, fine. Okay. Sorry, can I ask another just to help understand what's going on? Say that for example, things are working normally and then there is some leader in some round for some reason points to no previous block, and then that leader does broadcast. So there's some leader in some round who points to none. He can't do that.
00:40:36.820 - 00:41:09.200, Speaker A: You won't regard him as being ignore the block unless he points to a supermajority in the previous round. Right. Okay, so shall I move on? At this point, we're happy with the basic definitions. All we've done so far is we've defined how we extract the total ordering. Right? So now what we got to do is we've got to prove safety and we got to prove liveness. Okay, so let's see safety first.
00:41:10.130 - 00:41:22.142, Speaker B: Sorry, I still want to understand recruitment a little bit. So, like, you start from a block that's final, then you look at the most recent one that they ratified, then you look at the most recent one that that one ratified.
00:41:22.206 - 00:42:00.138, Speaker A: Exactly, yeah. Okay, so basically from this point, it's going to be pretty easy to prove safety if we have the following lemma, and the following lemma will be pretty easy to prove. Okay, so the following dilemma says if a leader block is final, then in fact it's ratified by every subsequent leader block. Okay, so being final means that you're ratified. You've got by a supermajority in the final round of that wave already. This just says, okay, actually the next leader will also ratify you, and the leader after that will also ratify you and so on. Okay, so that's a lemma.
00:42:00.138 - 00:42:28.342, Speaker A: It's quite an easy lemma. We'll see proof of that in a second. But first of all, I just want to assume that lemma is true and see why it quickly leads to safety. Okay, well, what do we have to prove to prove safety? Basically what we got to prove is this. So if D one and D two are two dags held by honest parties, p one and P two, maybe at the same time, maybe different times. Okay. Then ordered D one, the total ordering that corresponds to D one and the total ordering correspond to D two.
00:42:28.342 - 00:43:16.610, Speaker A: These are consistent, right? One is an initial segment of another of the other. That's what we want to prove for safety. Happy with that. Cool. Okay, and the next point we want to prove that the next observation is but it suffices to show that the sort of total ordering corresponding to d one is an initial segment of the total ordering corresponding to d one union d two. And the total ordering corresponding d two is also initial segment of the total ordering correspond to d one of the union, right? Because if they're both initial segments of this common string, then they have to be compatible. Okay, so in general, then it suffices to show that if you've got one Dag held by one user and another Dag held by another user, that could be held by another user, and the first one is a super.
00:43:16.610 - 00:44:09.906, Speaker A: If it's a subset of the second one, then the total orient corresponding to the first one is an initial segment of the total ordering corresponding to the second one. Okay, so in general, it's for us to consider the case that d one is a subset of d two. Maybe that's slightly confusing notation because I'm using some D two in different ways there, but okay, are we happy with that? So we just have to show that if one Dag is held by one user and a second Dag is held by another user, and that second Dag is a superset of the first, then the corresponding total order is an extension of the total order for the first smaller set. Okay, so let's consider that case. Okay, let's suppose d one is a subset of d two. And now we want to show that the corresponding total laws are consistent with each other. Okay? So consider the cases.
00:44:09.906 - 00:44:53.570, Speaker A: So, first of all, if d one has no final leader, then the total order corresponding to it is just the empty sequence. Then we're done, because that's compatible with everything. Otherwise, suppose the last final leader block in d one is just this node here, U. Okay? Then how do we form the total ordering on d two? Well, we take the last final leader in d two, this guy is up, this guy up here, right? And then we go to the last final leader ratified by that one, the last final leader ratified by that one, and so on. And what we need to be true is at some point this thing is where to hit this node U. We can't go past the node U, but that follows just directly from the lambda we previously stated. We said if U is a final leaderBOX, then it's ratified by all subsequent leaderBOX.
00:44:53.570 - 00:45:21.630, Speaker A: Okay? So this node here will be ratified by all these guys. So we can't go past U in the ordering in the sequence. That means the total ordering corresponding to d two would just be the total ordering corresponding to d one. Concatenated with the tower of these guys, concatenated ti of these guys and concatenate the tower of those guys and so on. Okay, so it's an extension of the total ordering correspondence d one because it could be the same thing. Right. But it's certainly compatible.
00:45:21.630 - 00:45:40.466, Speaker A: Happy with that. So I stand up for it. Yeah. Going back to question, if you're like waves are just one round, then this in the liveness proof. We're going to need waves to be five rounds long. So far we're not using the other rounds in the wave at all really. Right.
00:45:40.466 - 00:46:10.050, Speaker A: But we're going to need five rounds in the wave in order to make sure that the liveness happens. I'm going on. Yeah. Okay, so that all works, but we assume this basic lever, right? So if a leader block is final, then it's ratified by every subsequent leader block. Okay. So let's just quickly prove that this is kind of easy. We can do this just by approved by picture.
00:46:10.050 - 00:46:31.610, Speaker A: So two cases to consider here. This is the first case and the second. So the first case is this is a final leader block here. And the first case is we're considering a leader for the next round. Sorry, the first round of the next wave. Okay, so this is the final leader block here. So what does this picture mean? So here we have, this is the final round of the wave.
00:46:31.610 - 00:47:05.250, Speaker A: All these guys are ratifying this guy here because each one of these can observe some supermajority of blocks approving it. Okay, these supermajorities aren't all necessarily the same. It just kind of looks like they are in the picture but it's hard to draw a picture probably. Right? Okay, so here, this is the final round of the wave. Each of these guys ratifies this, so they're each observing a supermajority of docs that approves that. Okay, so the first case is that the next leader we're considering is the one for the first round of the next wave. In that case, this guy here has to acknowledge a supermajority.
00:47:05.250 - 00:47:31.990, Speaker A: That's the rules of forming the Dag, that supermajority. And this one have to have some honest node at the intersection. But then this guy is observing a supermajority blocks approving him. So is he. So in that case he also ratifies the block. And then the other case is basically the same. Okay, now we're considering it's not necessarily the first wave round of the next wave, it's some later wave.
00:47:31.990 - 00:48:02.200, Speaker A: That's basically the same argument. So here we have a leader block here. They have to approve, acknowledge directly acknowledge some supermajority of nodes. Again, this supermajority and this supermajority have to have some honest node in the intersection. This honest node block here, that's the same honest node, right? This one has to observe this one. So again, this guy still observes the supermajority of nodes approving the relevant block, right? The final block. Okay, so in both cases it's quite a simple observation there.
00:48:02.200 - 00:48:14.988, Speaker A: Okay, so we have security. Okay, so now we're almost at the end of the fiddly bit of the talk easier in a little bit.
00:48:15.074 - 00:48:22.140, Speaker B: You made this analogy between kind of ratifying and finalization.
00:48:25.800 - 00:48:43.070, Speaker A: Yeah. Is that analogy to this argument? A little bit? I knew you were going to ask that question. I thought that when I was given that analogy, it was mainly just to help me sort of think about remembering the definition. How precise analogy is. I'm not sure it's worth thinking about. Yeah, okay.
00:48:46.320 - 00:48:49.580, Speaker B: There never exists two stitch, two QCs.
00:48:53.840 - 00:49:33.788, Speaker A: It's something slightly different going on because in tendermint you're using locks and that kind of stuff and I don't think quite the same stuff is happening here. I thought about it a bit, but maybe it's worth thinking about more. Okay, so we've done security. Now we have to show liveness this part. I'm going to sketch a bit more. I'm going to go before proof. Okay? So first of all, for liveness, it suffices to show hope, it's pretty clear the existence of infinitely many honest final leader blocks, okay? Because if I produce a block and I send it out that eventually it will be delivered to the honest parties, they will be producing blocks that observe it.
00:49:33.788 - 00:50:05.336, Speaker A: So it's going to be incorporated into our total order. As long as they're producing infinite many final leader blocks, that's our task. Okay? Now though, we come up against this problem that we're going to need randomness in the asynchronous setting. Okay? So what happens? So if we don't proceed in random fashion, we don't use any randomness. Let's suppose we just announce ahead of times a P three is going to be leader at the beginning of the wave. Well, then what the adversary can do is they can just delay messages from P three. And as the honest parties, we don't know.
00:50:05.336 - 00:50:31.680, Speaker A: So maybe P three is just a dishonest party. Maybe they're never going to send any messages. We don't know whether the message has been delayed and honest, or maybe they're dishonest. So we can't wait forever. Eventually we have to go on with something else and we have to add some other stuff into our total ordering and then so it won't work. Okay, so this won't work. So what we can do instead though is let's suppose we don't elect a leader initially, okay? What we do is just allow them to keep informing a Dag in a standard fashion.
00:50:31.680 - 00:51:12.330, Speaker A: And if we do that, what we'll find is that we end up with a supermajority of blocks from the first round of the wave down here, which are ratified by all blocks in the final round of the wave. That will just sort of happen by some commentatorial argument that isn't that fiddly, which I'm sweeping under the rug slightly. Okay? So then what we can do is we can toss our global coin in order to retrospectively select which guy is a leader for this wave. We have like a more than two thirds chance of selecting one that has actually produced a final block for that wave.
00:51:13.870 - 00:51:22.620, Speaker B: Every honest node behaves as if you're saying like the behavior in waves by honest nodes was kind of.
00:51:25.190 - 00:51:38.614, Speaker A: Yeah. You didn't even know who the leader was. Right. So you just proceeded and the way the dag structure formed, you just get a lot of blocks down here being ratified by a lot of blocks up here and so then you just randomly choose a leader and it has a good chance of working out and producing.
00:51:38.662 - 00:51:42.854, Speaker B: A final leader is a little bit misleading terminology.
00:51:42.982 - 00:52:08.940, Speaker A: Okay. Yes. I don't know, better name than does it require? Yeah. So here we got K is five. I mean, it's a little bit sort of fiddly. So here K is five for Cordial minors for Dag Rider, which will see in a bit k is four. Yeah, it's one of those arguments.
00:52:08.940 - 00:52:34.150, Speaker A: It's not actually that hard, but it's maybe it's fiddly for talk. You sort of do up some truth table. You count number of ones and stuff. No, three. Well, for this one, let's say for Dag rider you need four. But you can sort of cheat by overlapping the last round of this one or the first round of the next ones, you can bring it down to three. Okay, but basically the sort of argument seems to require four.
00:52:34.150 - 00:52:57.824, Speaker A: Okay, so that was cordial miners. Yeah. So at this point, basically most of the hard work is done. Hopefully it'll be easier from this point. Okay, so now let's look at Dag rider. Okay, so this is I'm going to say it's pretty similar, but now we're going to deal with the possibility of Equivaleating blocks in a different way. So previously we allowed equivalentating blocks, they were added to the dag and then we had to deal with them.
00:52:57.824 - 00:53:34.568, Speaker A: Now basically we're going to just prevent equivalent blocks from being added to the dag in the first place. And we're going to do that using what's called reliable broadcast. Okay, so let's look at Reliable Broadcast first. Okay, so as we were talking about a little bit earlier on. So basically Reliable Broadcast you can think of as being like a relaxation of Byzantine broadcast where you weaken the termination condition. The difficulty with Byzantine broadcast in asynchronous setting is you're forced to terminate even if the broadcaster says nothing. So that's obviously just impossible because if the brocaster said nothing, you don't know are they honest, we're just waiting for their messages, I've got to terminate now, or are they just dishonest and so on.
00:53:34.568 - 00:54:15.180, Speaker A: Okay, so we weaken the termination requirement. Okay, so again, just define the problem. So the setup is that one party is designated the broadcaster and they give in some input and then requirements as follows. So first of all, we have like an agreement requirement which says if any honest party terminates, then they must all terminate with the same output in V. But that's allowing that maybe none of them terminate, especially if the leader is dishonest and they're sending no messages whatsoever, you're allowed not to terminate. So that's the agreement requirement. And then we have a validity requirement that says, okay, but if the broadcaster is honest, then all honest parties have to terminate, giving their input as their output.
00:54:15.180 - 00:54:35.424, Speaker A: We have the definition, so it's essentially like Byzantine broadcast, but we've weakened the termination condition to say in particular, okay, if the broadcast is dishonest, you don't have to terminate, but if any honest party does, then you will do have to.
00:54:35.462 - 00:54:52.068, Speaker B: Okay, yeah, that's fine. In some sense, as a note, you should be thinking, I'm only going to terminate if I convinced myself that others will eventually terminate other audit quarries. That doesn't mean it's not allowed. Some audit quarries terminating and some not, right?
00:54:52.154 - 00:55:15.992, Speaker A: Yes. Okay, so this is what I'm going to show you is the sort of simplest version of this. This is Braca's broadcast. It's a very nice, elegant sort of protocol. Again, this works in the asynchronous settings entirely deterministic, et cetera. Okay? And then there are more sophisticated versions and more efficient and stuff, but this is a very nice simple one. Okay? So initially, unsurprising, the broadcaster sends their value to all.
00:55:15.992 - 00:55:41.090, Speaker A: Obviously, if they're honest, they'll send a single value. If they're dishonest, they might send multiple values. And then there are three circumstances in which any party speaks after that. So first of all, when P receives the first value from the broadcaster, they echo that value. They send a message, echo V to all parties. Okay? So hopefully that's not too surprising. You receive that value, just echo it to everybody.
00:55:41.090 - 00:56:57.130, Speaker A: Okay? Second circumstance in which you speak, if P receives echo V messages from N minus F distinct parties and it hasn't yet voted, then P votes for V by sending a vote for V out to all parties. You see N minus F echoes all for the same value, then you vote for that value. So so far what we've achieved basically is that honest parties can't vote for different values, right? Voting for two different values, that corresponds to like, two different sets of N minus F echo messages, right? But two sets of N minus F parties must have an honest party in intersection who can't echo two values. Okay? So so far what we've achieved is honest parties can't vote for two distinct values. And from there, okay, it's going to be easy to ensure different honest parties can't decide different values. Okay? So we're in a strong position so far for that. Okay? And the last condition on which someone speaks is, so if P receives vote V messages from F plus one distinct parties and it hasn't yet voted, then P also votes for V by sending a vote V message to all parties.
00:56:57.130 - 00:57:48.752, Speaker A: Okay? And the point of that is to ensure that if any honest party decides V, basically you're going to decide V. I haven't written it down yet, but wouldn't it? You'll decide V when you see N minus F votes for V. So if any honest party decides V, that's because they've seen N minus F votes for V, that means all parties have seen N minus two F votes. For V, which means they've seen F plus one votes for V, which means that all honest parties will vote, which means that all honest parties will terminate. Okay, we'll go through that again a little bit, okay? And then the determination is specified. Just as I previously said it's, an honest party decides V if it receives vote V messages from N minus F distinct parties. Okay, so let's prove that works.
00:57:48.752 - 00:58:22.124, Speaker A: Okay, so I've just made it smaller and put it on a box there. Okay? So first of all, we're going to show, just showing the same thing we observed before. So honest parties can't vote for different values. Suppose they do. Suppose P is the first honest party for vote for V, and that P Prime is the first honest party to vote for some different value v prime not equal to V. Okay? In that case, each of these must receive echo V messages from N minus F distinct parties, right? If you're the first one to vote for a value, it has to be for this first reason here. It can't be for this reason because this requires there to be F plus one votes already.
00:58:22.124 - 00:59:03.720, Speaker A: At least one of them has to be honest. So if you're the first person to vote, it has to be for this reason here, right? Okay, so then P receives echo V messages from N minus F distinct parties. P prime receives Echo V prime messages from N minus f distinct, distinct parties. But in those two sets of N minus F parties, they must have an honest part in intersection, right? And that's a contradiction because they couldn't echo both values. Okay, so that's just what we said before. So honest parties can't vote for different values, and then what do we have to show? Well, we have to show that if the broadcast is honest, then nobody's going to sort of terminate with their input value as their output. Okay, but here that's easy, right? Because if the broadcast is honest, then they're going to send the same value to everybody.
00:59:03.720 - 00:59:31.412, Speaker A: Everyone's going to echo that value, and then nobody's going to vote for that value and they'll all decide on that value, right? Hopefully that's clear from the protocol, right? They'll send it out, everybody will echo that. So they'll all see M F echoes for that value. So they'll all then vote for it. We'll all see M f votes. You could vote this way or that way, depending on what you see first. But either way, everyone will vote for it. All honest parties will vote for it, right? Okay, so that case is easy enough.
00:59:31.412 - 01:00:02.460, Speaker A: And the last thing we have to show is. The agreement property. Okay, so now suppose an honest party decides V. Well then that means they receive N minus F votes for V, right? So that means all parties receive at least N minus two F votes for V. Yeah. Okay, but we're assuming F is less than N over three. So that means that they all receive F plus one distinct votes, right? Okay, so that means all honest parties are going to vote for V either through this first mechanism or through the second mechanism.
01:00:02.460 - 01:00:38.280, Speaker A: Right? And also because they kind of already voted for other values. So all honest parties will vote for V, so they'll all decide for V. Okay? So again, I think that's very elegant slick protocol. That's very nice. Okay. And again, note this is a simple deterministic protocol which works in the asynchronous setting and in mean you might think it's interesting or maybe you don't think it is. It doesn't even require PKI if we have authenticated channels.
01:00:38.280 - 01:01:17.796, Speaker A: Okay, so now back to Dag Rider. So basically the protocol works very similarly to Cordial Miners, the protocol we were describing before. Okay? But now we're going to deal with accruating blocks differently. Rather than allowing them to be added to the Dag, we're just going to stop them being added to the Dag. We're going to say for each round, each party has to go through some reliable broadcast. Either everyone will decide on one value for them or none. So you can't produce Equivocating blocks you.
01:01:17.818 - 01:01:21.044, Speaker B: Don'T know at any given moment in time. You may not know whether you'll ever.
01:01:21.082 - 01:01:39.032, Speaker A: Decide about no, you do. Yeah. You don't know. Exactly. Okay, so what's the outcome of this? So this allows you to reduce the number of around in each wave by one. The cost is that rather than just allowing people to add directly blocks indirectly, you have to go through this broadcast protocol. Right? So that's adding to latency.
01:01:39.032 - 01:01:55.036, Speaker A: I think I've got the various rounds of the broadcast protocols to go through for each block an advantages. So I described bracket's broadcast there, which is very simple. We can do some more efficient things, clever things can be used each round.
01:01:55.148 - 01:01:59.356, Speaker B: You're doing N parallel executions of this broadcast protocol.
01:01:59.468 - 01:02:33.784, Speaker A: Yeah. Okay, but then we can use efficient versions of reliable broadcast. I'm going to describe they can be used to make the expected amortized communication complexity per transaction. Order n for dag rider. Okay, so order N is the best you can possibly do per transaction because it at least has to be sent to all parties. But there is a bit of sort of cheat going on here because basically the way you achieve this is through some other techniques and through batching. So batching means you basically stick lots and lots of transactions into each block in order to hide the communication costs like they have the consensus.
01:02:33.784 - 01:03:11.636, Speaker A: Okay? So in order to achieve that, it's not that bad. You have to add n log n many transactions into each block. Maybe that's fine in some other protocols, like Honey Badger is like N squared login or something. So maybe that is more of a cheat. Okay, so now let's start thinking about our Dag protocols are actually good. How do they compare with your monolithic protocols where everything's in a row? Okay, so first of all, I'm going to look at communication complexity. I'm going to preface this by saying I don't think communication complexity is a very good way of comparing how protocols are efficient basic.
01:03:11.636 - 01:03:36.610, Speaker A: I mean, it's the standard way it's done in the distributed computing literature, but I don't think it's a particularly good measure. Okay, but anyway, because it's a standard way we'll go through that first. Okay, so far we've been looking at the Asynchronous setting, so let's stay there for a little bit. Okay. I was going to say later on though. So we focused on the Asynchronous setting. You can of course you can define Dag protocols, which are specialized to work in the partially synchronous or the synchronous setting or whatever.
01:03:36.610 - 01:04:19.736, Speaker A: Okay, so let's start comparing with some non Dag protocols in the Asynchronous setting. First of all, and in particular, let's think about so Viber is basically a modification of Hot Stuff, which works in the Asynchronous setting. Hot Stuff is designed to work in the partial synchronous setting where message delivery has like good periods and bad periods. You're only required to make progress when you have good communication. But we can sort of modify Hot Stuff quite easily to work in the Asynchronous setting. So how do we do that? Well, basically we have the same threat to liveness as we had before. Right? So if we just select a leader in advance suppose we produce of K blocks.
01:04:19.736 - 01:04:49.720, Speaker A: We now want to produce the K plus first block. If we just select this guy is going to be leader in advance. Well, then university can just delay their messages. Again, it's the same thing, right? So as the honest guys, we don't know, is the leader honest and their message has been delayed, or are they dishonest? Are they never going to produce anything? So eventually we'll have to move on. Okay, so that doesn't work. So what we do is something sort of similar. So what we do is we run N instances of Hot Stuff three phase protocol for the next block simultaneously, n simultaneously.
01:04:49.720 - 01:05:13.490, Speaker A: Each party is like acting as a leader once for one of those. And then what we can do is we wait for N minus F of those to complete. That would eventually have to happen. Okay. And then same subtract as before, we randomly select a leader. And if they produce a confirmed block, then we use that one and we just discard the rest. Seems extremely wasteful, right?
01:05:19.540 - 01:05:21.760, Speaker B: Trick doesn't seem very specific to Hot Stuff.
01:05:21.830 - 01:05:48.156, Speaker A: No. Okay, it's true. I'm using Hot Stuff rather than tendermint because the instructions in hot stuff of the sort. Wait for a minus F, then do this. Wait for a minus F, then this. Whereas with tendermints relies on timeouts and stuff, which won't work in Asynchronous setting. Okay, so hopefully that's basically clear how we can get it to work in the Asynchronous setting.
01:05:48.156 - 01:06:05.076, Speaker A: Okay, so what's the communication complexity there? Also for each instance it's order N. We've got N of them. So that's order n squared. We're imagining our blocks are of constant size here. Okay, so it's good. This is order N squared, expected, expected communication complexity per confirmed contraction. Now of course it's expected because now we got randoms involved and stuff.
01:06:05.076 - 01:06:05.830, Speaker A: Right, okay.
01:06:10.440 - 01:06:11.900, Speaker B: What is the randomness?
01:06:12.080 - 01:06:55.712, Speaker A: Well, I mean, it could be that you never produce anything bad leaders over. Yeah. Okay, so that gives you N squared, but okay, then there are things you can do with batching, including more transactions and blocks and some other type of clever tricks. So Dumbo is a modification of Weber, the protocol you just talked about, which modifies that using batching and some other tricks that gives you order N expected, like amortized communication complexity per confirmed transaction. Okay, so again, you can get to the optimal case. Order N, as I said here, is optimal because each transaction has to least be sent to the end different parties. Right? So you can get the optimal case as long as you're happy to accept this batching, which again, there is a trade off there because that can increase your latency.
01:06:55.712 - 01:07:52.696, Speaker A: Right? Depends how fast transactions are coming in. But if you have to wait for N log N transactions or N squared log N or whatever, then that can slow things down. Okay, so cordial miners, we've got order N squared, expected amortized communication complexity per transaction using batching, and again using some slick reliable broadcast protocol for Dag Rider in your order N, expected amortized communication complexity per transaction. A slight sort of complication here is we haven't worried yet about. So in a Dag structure, if you've got an actual situation where all the clients are sending in their transactions, they're presumably going to want to send those transactions to multiples of miners, multiple validators in order we can't censor them. So then there's a danger of having like repetition of transactions in order to make these calculations. We're basically ignoring transaction repetition here.
01:07:52.696 - 01:08:27.950, Speaker A: So there's a slight complexity there, but you can get around that by sort of randomly sampling which transactions you're using and that kind of stuff. Okay, but that isn't specified in these protocols. It is specified in Honey Badger, for example, but it's not worried about here. Okay, so that was for the Asynchronous setting. How about for the partially synchronous setting? Okay, so Bullshark is basically like Dag Rider, but it's sort of optimized in some way to work for the partially synchronous. Okay, what do we find here? So again, we're looking at hot stuff. So hot stuff has sort of like order end complexity within views.
01:08:27.950 - 01:08:53.294, Speaker A: I guess at this point, I'm kind of assuming, you know, hot stuff for a bit. Sorry about that. Okay, so hot stuff has, like, order n complexity within views. It doesn't tell you how to efficiently manage your view changes. So use my protocol for fever. That gives you two N messages per view change. So if you use that combined with hot stuff, then what you get over here, then you have order n communication complexity when network conditions are good and all parties are honest.
01:08:53.294 - 01:09:13.954, Speaker A: That's, like, under good conditions. So now it's not expected order n. It's not amortized order n. It's just order n. Right. Per transaction, you have order n amortized communication complexity when network conditions are good. But you have Byzantine parties, so the amortization is over.
01:09:13.992 - 01:09:14.578, Speaker B: What?
01:09:14.744 - 01:09:34.860, Speaker A: Yeah. So you might have, like, f many faulty leaders in a row, but yes, you're just averaging out overall. Okay. And you get order n squared communication cost in the worst case, right, to produce a confirmed block when network conditions are good. And we buy zantaner bursaries. So order N squared to produce a confirmed block in the worst case.
01:09:38.620 - 01:09:38.936, Speaker B: If.
01:09:38.958 - 01:10:21.338, Speaker A: You go to bullshock, okay, we're missing out this case. We're going straight to the amortized version. So we get the amortized version again, order n amortized cost. But then when you look at the worst case cost to produce a confirmed block now, this looks massive, right? So the worst case, we got to order end to the four log N communications lost to produce a confirmed block in the worst case when network conditions are good but with bizarre antidiversaries. But the point here is, in that worst case, when you do finally confirm a block, you're then confirming loads of blocks, everything below that. Right? Okay. So what's the basic picture there? I guess maybe that sort of sound of it.
01:10:21.338 - 01:10:41.300, Speaker A: The overall picture is so far, dag protocols are basically they're all pretty similar. You can get pretty close to optimal if you're not worried about batching and if you're not worried about latency, then you can get pretty close to optimal. It's pretty close so far. Okay, but obviously, communication capacity isn't really what we care about, right? What we really care about is.
01:10:44.870 - 01:10:48.370, Speaker B: Bullshark. You said that was an optimized version of Dagger.
01:10:50.650 - 01:10:53.766, Speaker A: So why is it better? Yeah. You're asking why is it better than.
01:10:53.788 - 01:11:03.602, Speaker B: The other guy was the second bulletin bullshark? How does that compare to the other Dag based protocols?
01:11:03.746 - 01:11:20.218, Speaker A: So in the other ones, we're in asynchronous settings, so there's no worst case. Right. So this line here disappears. So here we really talk about this. Isn't it deterministic now? So we have a worst case, and the optimization of ball shark isn't really to change these figures that you don't this figure exists.
01:11:20.314 - 01:11:33.314, Speaker B: The worst case would have been infinite. You could try to evaluate those protocols in the partially synchronized model and ask about.
01:11:33.432 - 01:11:50.898, Speaker A: Yes. Right. So then you'll get the same figure, then if you make it deterministic. Okay, so basically the difference with Bullshock is working very similarly to Dag, but you managed to reduce the latency. So now we don't need the four rounds. Now we only need two. So the argument for liveness changes, I'm.
01:11:50.914 - 01:12:02.250, Speaker B: Just trying to understand where the end of fourth comes from. So it sounds to me like you're saying all of the Dag based stuff, you have this issue that after a long string of business leaders, you'll have to have catch up a bunch of confirmations.
01:12:04.270 - 01:12:31.598, Speaker A: That figure will be the same. Okay, so I guess there are quite a lot of figures there, but the basic picture so far is, okay, maybe it's fairly similar for the Dag and the non Dag structures. Okay, but what we really care about is latency and throughput. Right. And I'm saying basically, there aren't really the prevailing methods in distributed computing. Just consider your the main thing is to look at your communication complexity, so it's difficult to analyze these things in a rigorous way. So basically what we have to do is just, like, run experiments.
01:12:31.598 - 01:12:57.710, Speaker A: And then when you're running your experiments, of course, you have to make sure we really are comparing apples to apples. We mean the same thing by transaction. We have the same Internet connection speeds, we have the same processes and so on. Right. Okay, so as an example, this is a team behind Bullshark, compared the performance of Bullshark. So Tusk is basically it's like Dag Rider just with some optimizations involved. Okay, so just think of that as like a slightly optimized version of Dag Rider polestar.
01:12:57.710 - 01:13:03.562, Speaker A: No dag rider works in the Async resetting.
01:13:03.626 - 01:13:04.570, Speaker B: As does Tusk.
01:13:04.650 - 01:13:32.150, Speaker A: As does Tusk. Yeah, and Hot stuff as well. And what they found that the following is under good network conditions, we're not here, everybody's behaving nicely. Our network connection is always good and so on, running as fast as possible. Okay, so for hot staff, you get 50,000 transactions a second for 20 parties. 30,000 transactions for 50 parties, and with a latency of around 2 seconds.
01:13:32.730 - 01:13:34.146, Speaker B: This is all honest. Notice.
01:13:34.258 - 01:13:57.694, Speaker A: This is all everybody just being good. Yeah, everybody's being honest. We're not exploring how bad it goes when people are naughty. For tasks, we get up to 160,000 transactions a second for 20 or 50 parties. I'm not sure why it's exactly the same. Somehow the network wasn't saturated for 20, but now the latency is slightly larger. Okay.
01:13:57.694 - 01:14:20.390, Speaker A: And for Bullshark, we're getting 130,000 transaction seconds for 50 parties with latency around 2 seconds. I don't know why they didn't get the figure for 20 parties there. I'm not sure that's the figures they get. Okay, so I don't know to what extent you can take those as being like, gospel. Maybe one of them is coded in better than the other one. I don't know. Okay, but anyway, so it seemed to be the case that the Dag protocols are being pretty efficient.
01:14:22.660 - 01:14:25.810, Speaker B: Was it stress tested under non ideal conditions at all?
01:14:26.500 - 01:14:37.028, Speaker A: I don't think those were included in the party. I don't want to promise sorry. We're included in the paper. I can have a look at later on if they are these numbers are.
01:14:37.034 - 01:14:40.616, Speaker B: Close enough to each other. Other considerations might be what you'd use.
01:14:40.638 - 01:14:48.490, Speaker A: To, I guess, from this. My basic takeaway is that they look like they're doing pretty well, but there's nothing definite there.
01:14:51.170 - 01:14:53.940, Speaker B: In terms of what a transaction is.
01:14:54.630 - 01:15:05.720, Speaker A: Yeah. So here a transaction is just 512 bytes. We don't really care how long it takes to execute it because all we're doing is we're ordering them, like shifting the job of actually executing it to somebody else. Maybe.
01:15:08.410 - 01:15:10.754, Speaker B: They should really just quote like a database.
01:15:10.882 - 01:15:52.776, Speaker A: Yeah, I think they're probably doing this because people are just used to talking in terms of transaction rate transactions per second. Okay, so just to finish off with then. Okay, so we've mentioned cordial, miners, dag rider, bullshark, task. Basically these are the sort of state of the art protocols just to go through some maybe some older protocols. So hedera hashgraph this is a permission Dag based protocol. An issue there is it has exponential expected latency in the presence of Byzantine failures. So maybe this protocol is like perfectly good when people are being nice, but if people start acting badly, then you've got potentially huge latencies there.
01:15:52.776 - 01:16:06.990, Speaker A: And basically the reason is that they're not using any global coin. Everybody just tosses their coins individually. So you're kind of waiting for people to toss their coin, everybody the same way in the same round before you finally agree. Right. So you've got a potentially very inefficient process there. Okay.
01:16:08.160 - 01:16:09.900, Speaker B: Is your sense in practice?
01:16:14.420 - 01:16:52.196, Speaker A: Well, if you're happy with setting up a global coin, et cetera, maybe there are issues in doing that, I don't know. But I guess in particular, Aleph is a version which basically takes a hedera hash graph and essentially implements it with a global coin. So then you cut it down to constant expected latency. You also achieved your best possible amortized and expected amortized communication complexity. If you're happy to accept batching, which you may or not may not be. Avalanche also uses Dag structure for the transactions. When you add a transaction in, might have to point to two previous transactions.
01:16:52.196 - 01:17:26.580, Speaker A: Okay. And then sorry, I don't know if you're aware of avalanche. So what you do then you decide on conflicting transactions and Dag by repeatedly sampling the opinions of other parties. And the egg structure plays a role in that because when you vote for a particular transaction there, you also vote for all the other sort of predecessors in the Dag. Okay, so Avalanche requires syncret for liveness and the communication complexity there is order KN, where KN is the required number of samples. So that depends on your security parameters and depends on N. And again, Avalanche provides a payment system, but no toad laudering.
01:17:26.580 - 01:17:46.520, Speaker A: And then we have some sort of proof of work protocols. Right. So Spectre is a proof of work. Dag based protocol, again, that just provides a payment system, doesn't provide a total ordering. Tangle is pretty similar to Spectre. But, Inspector, you've got blocks of transactions in Tango. You're adding them individually, but okay, so Spectre doesn't provide you with total ordering.
01:17:46.520 - 01:17:53.660, Speaker A: So Phantom and Ghost Dag, that's an extension of Spectre, which does give a total ordering on top of the Dag.
01:17:55.670 - 01:17:58.260, Speaker B: Would you say that these are obsolete now?
01:17:59.110 - 01:18:10.030, Speaker A: I don't want to annoy anybody. No. I don't know. I mean, I don't want to go that far. Okay. Thanks, Mr.

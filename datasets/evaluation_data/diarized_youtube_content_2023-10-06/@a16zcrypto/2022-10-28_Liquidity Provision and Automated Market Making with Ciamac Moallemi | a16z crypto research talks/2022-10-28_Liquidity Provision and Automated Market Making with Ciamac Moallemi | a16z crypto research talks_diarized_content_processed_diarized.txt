00:00:06.360 - 00:00:06.910, Speaker A: You.
00:00:09.680 - 00:00:32.980, Speaker B: All right. Welcome back, everyone. So I feel like this week it's kind of like a microcosm of the multidisciplinariness of web3, right? We had governance on Monday yesterday, we had consensus this morning, and this afternoon we're going to hear a little bit about DeFi, specifically by Simac Molemi, who's my colleague at Columbia, who's in the business school there, talking about Quid proficient in AMS.
00:00:33.560 - 00:01:23.920, Speaker A: Thanks, Tim. And this is joint work with Jason, who is a PhD student at Columbia. And of course, Tim, who you all know. Just to begin, by way of background, what I mainly work on is I'm an operations research person and I mainly work at the intersection of stochastic modeling and optimization. And main applications I think about are in quantitative finance. So things like quantitative trading, market microstructure, high frequency trading, those sorts of things. And recently I've become, let's say around 2017, came interested in blockchain and been looking at sort of blockchain, and particularly now DFI through that lens, through those particular sort of quantitative finance kind of tools.
00:01:23.920 - 00:02:21.904, Speaker A: And so this will be an example of that. So, having said that, Tim has warned me that some of these tools, specifically ideas like sort of black scholes pricing and stochastic differential equations and so on, aren't really so well known in this community. So I do have to use those tools. However, I'm going to try and be sort of very informal and focus more on the intuition rather than getting being very precise about the technical details. So I will try to be gentle on that topic, but I will simultaneously also ask you to be gentle because this is sort of preliminary work and we are very much looking for sort of feedback and comments. So with that, let me go ahead and get started. So what we're talking about here is liquidity provision, market making mechanisms for exchange.
00:02:21.904 - 00:03:11.908, Speaker A: It's helpful just to sort of take a step back and see what are the dominant mechanisms for exchange for trading. Right? So the problem is, suppose you want to exchange assets. So, for example, you have ethereum and you want to buy dollars or vice versa. That'll be our running example. If you look at what the traditional solution for that is in the TradFi world, maybe 90 plus percent of the TradFi world, certainly like liquid assets have converged on one sort of market structure. And that's the electronic limit order book, right? So there might be some variation in terms of how this is sort of precisely implemented and so on. But the basic structure is you collect these things called limit orders, which are orders each attached with a assigned quantity, like either you want to buy or you want to sell.
00:03:11.908 - 00:04:27.916, Speaker A: And there's a certain quantity and also attached to a price, the so called limit price. And the exchange, be it Nasdaq or Coinbase or whatever, they accept these offers and they collect them and they try to greedily match them, right? And so after things are matched, what you're left with is something like the list over here in the lower right, where you have a bunch of sell orders with different quantities at different prices and at lower price levels, you have a bunch of buy orders and that's the available liquidity. And someone can sort of show up and either buy at one of those higher prices or sell at one of those lower prices and so on. And again, for the most part the market has really converged to this structure. But there are a number of issues that it has, however, right? And a first issue relates to trying to do this on chain, right? So naturally it would be nice to maybe have an electronic limit order book, but maybe not have Coinbase or whoever sitting in the middle have something that's sort of completely decentralized. But the problem is there's a lot of storage and computation and updating here you have to keep track of all these orders, the matching process. You have to sort of walk through the order book.
00:04:27.916 - 00:05:24.524, Speaker A: Moreover, these are typically updated at very high rates, like in an exchange like Nasdaq, you might have a thousand updates on the timescale of a millisecond in terms of people adjusting their orders and so on. So again, in the context of something like Ethereum, which has sort of very limited kind of computational capacity, this doesn't really work on chain. And the second kind of issue is you can't just set up a limit order book and immediately start trading. You have to have someone providing liquidity, right? You have to have market makers that are basically going to provide liquidity over time. So Tim shows up and wants to buy. He's an organic buyer and I'm an organic seller. I might not show up till ten minutes later, right? So ideally we'd like to be matched, but someone has to intermediate in the middle and that's the job of a market maker, right? Now, the market making in these limit order books is a very labor intensive strategy.
00:05:24.524 - 00:06:45.610, Speaker A: As I mentioned, they're sort of constantly updating their quotes. There is a lot of sort of proprietary knowledge in terms of sort of how to do that effectively. People sort of compete on that. So if you just sort of, sort of set up an order book for some new token and say, okay, market go, it's not going to happen, right? The market makers won't participate unless it's already a liquid market and they already know they're going to make money or alternatively, unless you pay them, right? So if you're trying to trade maybe long tail assets, this isn't really effective by itself, right? You also have to sort of bribe these market makers. So as an alternative, what has been suggested is this idea of automated market making, right? And this is an idea that I think emerged earlier in the prediction markets, sort of literature, not exactly in this form, but inspired by that. The key idea is to have these sort of liquidity providers, but rather than this kind of active trading, it's going to be something much more passive and much more rule based, right? So the liquidity providers will supply pools of the other two assets. So in this case, ETH and USD, they will always provide quotes to either buy or sell either one of these in exchange for the other.
00:06:45.610 - 00:07:41.164, Speaker A: But these quotes are done by an automated mechanism, right? So in the context of a smart contract, they would be done by the smart contract itself. You wouldn't have to have these market makers actively managing a market making strategy. And of course, once you suggest this, the key question is, well, how do you do this? How do you set the price? What is the quoting mechanism? And again, the key idea sort of proposed by Vitalik and subsequently elaborated on by others is to sort of leverage this prediction market idea. And this is the idea of a constant function market maker. The idea of this is as follows. You're going to have two assets, right? And you're going to maintain reserves in those two assets. So in this case, x would be maybe ethereum, y would be the US dollar or USDC or whatever.
00:07:41.164 - 00:09:00.852, Speaker A: And the rule of the pool would require that an invariant be maintained. In other words, there would be some function f, and we require that f of XY equals l. But otherwise, as long as you maintain that invariant, you can move between any configuration of x and y. So, for example, if you're at the purple point, you can jump over to the other green point and that would involve buying y from the pool and in exchange depositing x to the pool, right? So this is the idea of a constant function market maker, this bonding function being the so called constant function. And so, for example, the most prevalent rule is the constant product market maker, where you require the product of the reserves in the two pools to be constant or equivalently, we could require that the square root of the product I e. The geometric mean be constant, right? And that's what's used in the older version of uniswap. And what you can see, if you look at this for a little bit is if you have a mechanism like this, if you have an invariant curve and you observe where you are in the invariant curve, for example, if you're at the red point in terms of what are the reserves on the horizontal axis for x? And what are the reserves on the vertical axis for y? That implies a price.
00:09:00.852 - 00:09:29.164, Speaker A: Indeed, the slope over here is giving you sort of the local trade off for how much of y you have to give up for a certain amount of x. So that slope I can interpret as a spot price I e. The price for a very, very small trade, an infinitesimal trade. And there we go. There's my quoting mechanism, right? So I have an automated kind of quoting mechanism, as promised. There are minimal storage needs. I don't need to store all these limit orders for buying and selling and whatever.
00:09:29.164 - 00:10:18.012, Speaker A: All I have to basically do is store one number, that number L, which is sort of the aggregate level of liquidity, which tells me what level set am I on in terms of the invariant function and computations can be done very quickly, right? So in a limit order book, to sort of figure out a trade, I have to sort of walk through these orders and sort them and so on and so forth. Here the computations are sort of very easy and are typically done with closed form algebra, EiE, like addition, subtraction, square roots and so on. So very amenable for smart contract implementation, very amenable for gas golfing and so on. So yes, what does the square root do here? If x and y are fixed sorry, if X, y fixed or constant, it doesn't matter. Take the square root. It doesn't really take matter. For the purposes of this talk, it won't matter.
00:10:18.012 - 00:11:00.196, Speaker A: You could take x and y, you could sort of get rid of the square root, but including the square root makes the function a homogeneous and that allows us to actually interpret L as some kind of additive level of liquidity. So there are reasons I take the square root, but for purposes of this talk, it doesn't matter. And you can just imagine the constant product. So I've presented two mechanisms here. We have the electronic limit order book, we have this constant function market maker. They look quite different on the surface. And the agenda here is to sort of think about these things and try and understand and see are they the same, are they different, how can we compare them? And what's the best mechanism, if you will.
00:11:00.196 - 00:11:53.144, Speaker A: And so what I'm going to talk about today is I'm going to talk about sort of two things. First, I'm going to take these two mechanisms that I showed you and I'm going to redefine them in sort of a common framework, so I do have the language to speak of them at the same time. And so we will begin to sort of see what are the trade offs and we'll see how they fall into the same framework, albeit with different design choices in the two cases. So that'll be the first part of the agenda. The second part of the agenda, I'm going to specifically focus in on constant function market makers, because indeed they are new, certainly relative to electronic limit order books. And what we're going to do is we're going to try to understand the economics. And what I mean by that is if you're a liquidity provider, if you're thinking of depositing money in one of these pools, depositing ethan and USD.
00:11:53.144 - 00:12:58.412, Speaker A: What are your considerations in terms of is that going to be a good investment or not? Right, so that's our plan. Any questions before I launch into it? Okay, so just in the interest of time, I'm not going to go over the literature. I will just say at a high level, there's three strands of literature I think are quite relevant. There is the classical options pricing literature and in particular in finance, there is also a literature that applies options pricing theory to market microstructure thinking about things like limit orders. So that's sort of quite relevant. There is a second strand of literature from really maybe Hansen's paper is a good starting point, talking about sort of prediction markets. And as I mentioned before, that's the inspiration and starting with Buterin Coppelman and Lou and sort of really with DFI Summer in 2020 and so on, there's been kind of an explosion of more recent literature just really focusing on what I'm talking about today, which is using these AMMS for exchange and not for prediction markets analysis.
00:12:58.412 - 00:13:42.156, Speaker A: Why is option pricing particularly I'm sorry, why are options particularly relevant? Well, I think you'll see in a second, but you'll see in the second half of the talk. But just to sort of give you a preview, at some level you can think of a limit order as an option, right? Like you leave an order in the market and someone later can come and sort of exercise it and it looks like at some level like a call or a put, right? So those ideas are going to come back and be relevant. So that's sort of the classical thing we'll see in the second half of the talk, how options pricing comes in. By the way, Andy was explaining to me today that he had a prior life as an options trader. So he's going to keep me honest when we get to that part of the talk. All right. So let's talk about a general framework for exchanges.
00:13:42.156 - 00:14:28.104, Speaker A: So again, our agenda here is to try and understand different design choices in making exchanges. And prerequisite is to have a common notion of exchange which simultaneously can sort of think about something like a limit order book as well as a constant function, a market maker. And if you can incorporate both of those things, it must be a very rich design space. And the question that we would like to answer, and I think we do answer, is what is the right parameterization to think of choices in that design space? Okay, so let's start. We're going to imagine we have two assets. The X asset will be a quote unquote risky asset, which we'll take ETH as the running example. The Y asset will be what people in finance like to call the numeraire.
00:14:28.104 - 00:15:12.152, Speaker A: And that just means the unit of account. In other words, what do we express our prices in? Right? So this is just for convenience. It's not sort of fundamental, but when I talk about prices, it'll be the price of one unit of X in terms of units of Y. So in particular how much USD for one ETH. Sort of typically the common way we think about that particular coin pair. And if I'm going to tell you a framework for exchange, there's sort of two sides that I have to explain. One is the side of what do the liquidity providers see? In other words, what's the API that they are kind of exposed to? And then the flip side is if someone comes to trade, what is the mechanisms of that? So let's start with the API for liquidity provision.
00:15:12.152 - 00:16:04.460, Speaker A: The idea is as follows. You're going to have a bunch of liquidity providers and each of them is going to submit a demand curve. So the Ith liquidity provider will submit a demand curve called Xi. This will be a function of prices and this specifies the quantity of risky asset of ETH that that liquidity provider would like to hold at a given price level across all price levels, right? So this terminology is a little bit weird because we have these liquidity providers, so we think of it as the supply side of the market. But really the demand I'm talking about here is kind of their demand for the risky asset and because it's going to turn out that these demand functions are downward sloping. So that's why I use this terminology. But even though I say demand, I'm really talking about the supply side of the market.
00:16:04.460 - 00:17:00.092, Speaker A: So we have these demand curves from each liquidity provider. The next thing that we'll do is we'll aggregate across all the liquidity providers by simply summing their demand curves and I get some aggregate liquidity. And then of course, over time we might have new liquidity providers arrive, we might have some of them depart, or maybe they want to change the demand curve that they've submitted. So this X will be updated over time to at any time be the sum of the then current individual demand curves. So that's the API from the perspective of the liquidity providers. How about the traders? So again, these are people who are arriving and they want to trade against this particular mechanism or exchange at any given time. We're going to call the quote unquote state of the exchange to be this aggregate liquidity curve object and also a price.
00:17:00.092 - 00:17:38.644, Speaker A: So let's say the price is a p zero. When a trader arrives, they observe the price p zero. And what they can declare is they can declare that they want to move that price p zero to another price, let's say p one, right? And so what happens when they do that? Well, they get a certain quantity of the asset, right? So if in aggregate the pool wanted to hold x of p zero at p zero, and then it's going to move to X of p one. At P one, this is the quantity that should go to the trader. So if it's positive, the trader is buying. If it's negative, the trader is depositing that quantity of coins. Now of course they're going to get these coins.
00:17:38.644 - 00:18:27.708, Speaker A: They have to pay something. And so that's the second part of the trading API. And so here's the payment rule and I'll walk you through this. But I'll tell you at the onset, this is sort of the obvious thing you would do. The idea is that if you're moving from the price p zero over to the price P one, there's a whole bunch of intermediate price levels, right? And we have this aggregate demand curve which is telling us how much liquidity is supplied across those price levels. So what I want to do is I want to sum across the intermediate prices and I'm going to take that price and I'm going to take the marginal quantity that is offered at that price and I'm going to multiply those two and add them up. And that should be the cost to sweep through the aggregate demand curve from the price level p zero to P one.
00:18:27.708 - 00:19:35.132, Speaker A: Now, of course, here I'm imagining that the prices are continuous, right? So I can't really do a sum, I have to do an integral. So for example, if the aggregate demand curve was differentiable, I could sort of generalize the sum to the integral where I integrate over prices. I take price times marginal quantity at that level and I have to do a sign correction. So that's the negative sign, right? But we're actually going to be even more general than that because we want to allow for demand curves that have jumps, right? We want to allow for things like step functions. So we're going to take the generalization of this sum as not just like a Riemann integral, but Riemann Schultz's integral, which basically I'm integrating directly against increments of this object. So you can just view the last expression as a generalization of the regular integral that allows me to integrate against increments of something with jumps. Any questions so far? Okay, so so far, hopefully this seems reasonable.
00:19:35.132 - 00:20:32.652, Speaker A: What I'm about to argue is in fact, this is really the only thing you can do, right? So why is that? So I'm going to define a notion of incentive compatibility. And what incentive compatibility means before I go through the definition is basically I've been honest about what I've been saying, right? So I've been saying that this is the demand that's going to be held by the pool at different sort of price levels. But why is that? Who is enforcing that? Well, incentives are enforcing that. In particular, we're going to say that this exchange is incentive compatible. If whenever the trader values the risky asset at some price P tilde no matter what the price on the exchange is, when they arrive, they're going to move the exchange price to Ptilde. Right? So that's the definition of incentive compatible. And simply by the fact that I've used those words, maybe some of you who are familiar with mechanism design should sort of start to realize that this is a setting which is actually familiar.
00:20:32.652 - 00:21:13.552, Speaker A: This is a setting where we can apply a Meyerson's Lemma. Right? And so what does Meyerson's Lemma say interpreted in this setting? It says that this exchange mechanism I'm describing is incentive compatible under two conditions. The first condition is that the aggregate demand curve is non increasing. In other words, it has to be sort of downward sloping, as I promised. As prices get higher, the pool has to hold less of the risky asset, number one. And number two, that payment rule that I argued is intuitive is in fact really the only thing you can do, right? There's really no other kind of flexibility. Right.
00:21:13.552 - 00:21:48.204, Speaker A: So for those of you who maybe know some of this theory, let me just give you a quick glossary. What in mechanism design would be called the type in this case is the price. So we have a single parameter typespace that is one dimensional and continuous, what mechanism design people would call the alternatives. Those are the quantities. The utility function is linear. We're just valuing one unit at the price p tilde. And finally, when I talk about the demand curve in mechanism design language, that is the allocation function.
00:21:48.204 - 00:22:26.240, Speaker A: Right, but all of this kind of maps exactly. And in some sense this is telling you that this is sort of the fundamental object, this X. There is nothing sort of in a general sense leveraging on all this work and mechanism design. There's sort of kind of nothing else you can do in terms of you can't allow other X's. If they're not monotone in this way, they won't be incentive compatible and you can't have any other function in terms of how you charge for the quantity. Yes. So this model kind of assumes the LPs are just kind of static.
00:22:26.240 - 00:22:57.456, Speaker A: There's IP for the liquid fighters here, right? I'm sorry, there's no sense of ice. C for the LPs here, there's no sense for the ice. So I'm assuming the LPs are static and that's going to be sort of running throughout. So you're right that as conditions may change, LPs may exit and enter and so on. But throughout this talk, I'm going to imagine we're at time zero. The LPs commit to something and then maybe over some kind of short time scale, maybe a day, whatever. How does that work out? That's going to be the setting we're looking at.
00:22:57.456 - 00:24:17.396, Speaker A: And this is purely from the buyer's perspective. Okay, so if this is sort of the design space, what are the kinds of alternatives we're seeing? Well, all the alternatives that I presented to you so far in terms of the limit order book and the constant function, market makers, they fall into this simply with restrictions on the demand curves that are allowed, right? And in particular all of those mechanisms, you're not allowed an arbitrary curve X. However, you're allowed curves X that are determined by some basis functions, right? So if I require that either X or Xi be parameterized by some basis functions if those basis functions are non increasing and if I combine them with positive coefficients in other words, I look at something in the cone. Generated by basis functions then the aggregate function will also be a non increasing and so therefore everything will be incentive compatible and I will be fine. And maybe sort of the thing to think about is exactly what are those primitive basis functions and how many of them are there, and so on. And maybe one notion to think about how complex a mechanism you have is something about the size or the cardinality of the number of basis functions. So let me give a bunch of examples.
00:24:17.396 - 00:25:25.280, Speaker A: Any questions before I show the examples? Okay, so let's talk about a limit order book. If we think about a limit order book I showed you, it's a collection of orders with quantities at different price levels. If I view that as an aggregate demand curve, what you're seeing is you're seeing a step function as you cross each of those price levels and as you increase the price and you take liquidity, the remaining available decreases according to a step function, right? So the way to think about those liquidity jumps at discrete price levels is to say that my quote unquote basis functions are something like this. This is like a limit order, right? It's a limit order to sell, where if the price is below the price of the limit order, you own the risky asset. Once the price goes above, someone buys it from you and your position is zero. But your demand curve, I, e, you go from here from L to zero, that is given by a step function. And moreover, the price levels are only at discrete indices, multiples of a tick size, right? So here, this tick size is typically, usually small, often is very small.
00:25:25.280 - 00:26:42.360, Speaker A: So by taking combinations of basis functions, you can get pretty close to any monotone decreasing function, or non increasing, I should say. But maybe you need a lot of these basis functions, right? So this is a setup where you have a lot of fidelity in terms of you can express whatever curve you want or hopefully get close, but maybe you need a lot of information. I need to give you a lot of bits in terms of the coefficients. On the other hand, if we look at the constant product where the bonding function is given, there, if you decide to participate in this mechanism, all you can do is decide how much of this do I want? Right? So in other words, that's like you have a single basis function and you're simply deciding what multiple. And if you go back and you sort of look at the curve and you do some calculus and so on, relating prices to quantities in the invariant curve I showed you for this bonding function, for the constant product market, what the implied demand curve is, is that it falls off as the square root, right? So here you can only take multiples of one over square root of P. That's sort of the only option. So very low complexity, but also not so expressive.
00:26:42.360 - 00:28:09.140, Speaker A: And so let me give you a third choice. This choice is uniswap V three. And so uniswap V three is a variation, an improvement, I would say, over uniswap V two that was introduced, I think, maybe six months or a year ago or something on that kind of timescale. And the primitive in uniswap v three is to take this uniswap V two constant product thing, but to do it over a compact interval, right? And so that's the concept of a range order. It's like the constant product formula where you're falling off as one over square root of P, but instead of falling off as a one over square root of P over the entire real line, it's concentrated on a range between a lower end PA and an upper end PB. The benefit of this is this is more capital efficient, right? When you have the function over here, which is over the entire real line, you're depositing tokens that may never, ever trade because price would have to be really high for those tokens to trade, right? On the other hand, here you're guaranteed that once you hit the price of PB, all of your risky tokens are gone. And that's good in the sense that they're doing something, they're being traded, they're not just sitting there and sort of wasting space somewhere, right? So these points are also on a discrete price grid.
00:28:09.140 - 00:29:27.436, Speaker A: The tick size is a basis point. It's a geometric grid, not an additive grid, which is larger than the typical tick size for a limit order book, which is something like a penny. So on like $100 stock, this would be a 10th of that, right? On one hand, it's coarser. Also, I think the expectation is you wouldn't use a huge number of these orders to express your preferences because the amount of gas required to sort of be a liquidity provider is going to scale with the number of subcomponent range orders you have. But you can start to see this is something in the middle, right? By maybe using a handful of these, by maybe not having PA and PB just be one tick, but having them be over longer ranges, you can start to get sort of an intermediate outcome where you're somewhere between a limit order book, which is very kind of expressive, but on the other hand, very complex and something like a constant product market maker, which really sort of one dimensional and easy to. Handle, but on the other hand, maybe not so expressive. So that's sort of the spirit of the idea.
00:29:27.436 - 00:30:23.228, Speaker A: Again, as I mentioned, this is sort of ongoing research. I think it's a very nice and kind of classical framework we're in in terms of this kind of Myerson framework. But I think the big open question we're thinking about right now is what is the right measure of fidelity? Right? So how do we know how much expressiveness is what we need? How close we need to get to whatever the optimal demand function is? So in order to sort of have this trade off, we can sort of quantify the left side, the complexity in terms of the number of basis functions, but we need to understand what's there on the right. But I think the main insight of what I'm telling you right now is that these demand curves are really the sort of the right object, right? They're a right object. When people sort of usually talk about constant function market makers, they really focus on the bonding function. F. In my mind, F is a computational device.
00:30:23.228 - 00:31:31.110, Speaker A: It's great if you're writing a smart contract because you want to be efficient in that dimension and so on. But it doesn't lead you much economic intuition here. Thinking about the demand curve, not only does it unify these different objects, but it also has a lot of economic meaning both in terms of what we saw with Myerson's Lemma but also in terms of what we're about to see in terms of options pricing. So I'm going to pause here before I move to the second half of the talk and see if there are any questions. Yeah. So for the uniswap V three basis functions, in what sense are those as good as select step functions approximating any downward sloping demand curve? I think if you had enough of these and they were fairly spaced, I mean, you could sort of get pretty close in both cases. So I think if you sort of formally took a limit where you had sets of this type of basis function versus just a step function for a limit order book and you send the tick size to zero, you would get some kind of convergence to sort of whatever function you wanted.
00:31:31.880 - 00:32:17.392, Speaker B: I would say two things that are not fundamental but conventions is the V three basis functions. First of all, usually it's a wider range for the order books. I think of the tick sizes being like a pendant, basically, right, possible. And then the other one is actually, I believe, uniswap V three uses intervals that are constant size and log space. So it's basically like every 10% increase we'll get you to a new kind of bucket, basically. So in the limit, presumably you're getting all sort of non increasing functions from either one, but this is exactly how you see it. The rancher of approximation that you care about may suggest using sort of the relative sizes or the absolute sizes accordingly.
00:32:17.392 - 00:32:20.612, Speaker B: So there's some dependency. Does that make sense?
00:32:20.666 - 00:33:29.816, Speaker A: Yeah. Question from Zoom so uniswap V three tick ranges technically are supported from PA to PB. I know we need this decreasing assumption, but if we're being exact right, I mean, you wouldn't have any liquidity between zero and PA for a single uniswap V three pool, right? Wouldn't it be all in one asset? Like if your order is out of range, if your range order, if the current price is not within the range, wouldn't you all be in either asset X or asset Y? I'm not sure. I wasn't sure if trades occurred for that single pool. So trades don't occur, but what that means is the tokens you've deposited are all one kind of token. But if people can't trade using that token, is that liquidity? Well, they can't trade at the current price level, but if the price level moves so that your order becomes in range, then they will be able to trade. Okay, so what I'm going to do now is move to the second half of the talk, and here we're thinking about the economics.
00:33:29.816 - 00:34:31.212, Speaker A: And so, again, I'd like to assess the constant function market maker from the perspective of someone who is providing liquidity and sort of at a high level. Is this a good investment? Should I become a liquidity provider? What are the factors to sort of think about? And I'm going to break that down into three sub questions, right? So the first sub question is as follows. If you invest in a CfMM as a liquidity provider, you're going to be impacted by market risk. What do I mean by that? Again, if you have this ETH USD pool, what are you literally going to do? You're going to deposit ETH and USD, right? And in particular, you own ETH, right. At this instance, you own some ETH that is in the pool. And so one aspect of your performance is not to do necessarily with the particulars of the pool and that mechanism and who's trading against you and so on, but simply like, does the ETH price go up or go down? Right? If the ETH price is going down rapidly, then maybe no matter what the structure of the pool is, you're going to lose money. And maybe if it's going up rapidly, you're going to make money.
00:34:31.212 - 00:35:01.956, Speaker A: Right. And what we'd ideally like to do is we'd like to disambiguate these two. We'd like to sort of separate it, right? Because if you want to make a directional bet on what the ETH price is going to be, there are other ways to do that. Right? And so it's phrased differently that market risk can potentially be hedged. Right. So sort of what do I mean by that, again? So suppose you want to provide liquidity, but you don't have a view on the price of ETH. What you might do is you might put a bunch of money into a CfMM, have a bunch of ETH there, but again, you don't want to be long ETH.
00:35:01.956 - 00:35:59.450, Speaker A: So what you would do is you would come up with some other contractual mechanism. Perhaps you go to FTX or Binance and you trade ETH futures and you go short, right? So the idea there is whatever the profit and loss you have because the ETH price is going up and down in the pool, will be offset by your futures position on binance. So that allows us to sort of really isolate what's specific to the pool as opposed to being long the underlying assets. So that's sort of one thing. It allows us to disentangle these two things. The other thing is, even if you don't want to hedge, or maybe you can't hedge because there's no way to go short or something, I think it's nevertheless interesting to sort of separate the profit and loss of this pool investment into something which has to do with what did the market do? And something which has to do with what are the characteristics of this mechanism. Right? So that's one question we're going to try to answer.
00:35:59.450 - 00:37:37.196, Speaker A: All these questions are related, by the way. The second question we're trying to look at is we have this idea from the first half of the talk of this liquidity demand curve, right? So again, I'm imagining at time zero, a liquidity provider shows up, they are committing to this liquidity demand curve, right? And then that's going to sit there on the chain for a while. They're somehow giving up optionality, right? So they're committing to this thing and then later prices evolve, people come and trade against it and so on. But you've sort of committed to this thing and there should be some value for sort of moving first, if you will, and having other people who may possibly take advantage of you, right? And so the question is, what is the cost for giving up that optionality? That's the second question. And the third question is, if you're going to be paying a cost, there has to be some kind of benefit also, and that benefit is trading fees, right? So a different way to look at sort of the second question is if there is some kind of cost due to optionality, we want it offset by trading fees. And to the extent we understand that cost, we can understand what are good rules for fee generation, right? Because again, we'd like these two things to be commensurate your fee income versus your option cost, both of which I'll be more specific about, should sort of net out. So these are three different questions which are sort of slightly different lenses into the same underlying point, which is what is the Cfmmmm from the economic perspective of a liquidity provider? And our contribution here is we're basically going to answer these.
00:37:37.196 - 00:38:12.964, Speaker A: We're going to introduce a metric called lever or loss versus rebalancing, which will simultaneously address all of these. So that's a little bit vague right now, but let's sort of dive into it and see what I mean by all this. All right, but before, let me just give you a preview of the kind of results we're going to have. So what I'll show you at the end is this result. I'll justify this, and what you can see is the output of this theory. This lever idea is going to be sort of very concrete tradable implications. So let me give you such a concrete example.
00:38:12.964 - 00:39:00.212, Speaker A: Consider not uniswap V three, but the old Uniswap or any other constant product trading pool where you're trading ETH versus USD, right? So on Uniswap v. Two, the trading fees were 30 basis points. So if someone comes in to trade, you earn 30 basis points of that trading volume. An important ingredient in our model is going to be the volatility of the risky asset. In other words, how much does it move to day to day? And just to use a ballpark number for the volatility of the ETH USD pair, maybe 5% is a reasonable number. Our analysis would yield that there is a daily sort of running pre commitment cost, this thing we call lever of about three basis points on the value of the pool. Right? So imagine, let's say this pool was worth $100,000,000.03.
00:39:00.212 - 00:39:52.804, Speaker A: Basis points means every day you bleed $30,000 in terms of this pre commitment cost. The flip side, of course, is you get trading revenue. And if we want to equalize the revenue you earn from trading to how much you're paying in terms of this pre commitment cost, the break even if you do the algebra is you need to be trading on a daily basis about 10% of the pool. Right? So again, 100 million dollar pool, you're going to be paying $30,000 a day in terms of lever cost. In order to recover that lever cost from the fees, you need to be trading $100 million of ETH every day to generate $30,000 of fees. Yes. Are we assuming anything about correlations between sigma and volume? So I'm assuming sigma is constant, but that's a good point.
00:39:52.804 - 00:40:15.260, Speaker A: In a more sophisticated model, usually volume is high when sigma is high. But for the purposes of this discussion, it's just sort of the starting point. Sigma is going to be constant. Right. This gives you something very concrete. You can look at this pool and to decide whether to join or not. It's basically assessment of do I think 10% of the volume is going to trade in the next day or not? Right.
00:40:15.260 - 00:41:17.520, Speaker A: And moreover, our theory will tell us how this varies with things like both the structure of the CfMM, in other words, its demand curve, but also with market conditions, in other words, how it scales with things like volatility. Right. So this is just a preview of what the kind of output of our model is going to be let me dive into it, all right? So the setup is going to be a continuous time black Scholes kind of classical options pricing setup. And so there's going to be stochastic differential equations and so forth, as I already alluded to. The downside of this kind of setup is that it's technically more complicated. But there's a huge upside in that we're going to get closed formulas for everything, right? And that's sort of part of the upside of the original Black Scholes model, is that you get nice closed form expressions for everything. Again, without loss of generality two assets, a risky asset and a numera, the model easily extends to more than two assets.
00:41:17.520 - 00:42:07.776, Speaker A: Without loss of generality, I'm going to assume the risk free rate is zero. So in other words, if you just have dollars sitting on the side, you don't earn any interest on them. I'm going to define a P of T to be the market price of the risky asset. And I assume that this is something that's externally evolving and is observable. So I think sort of the mental model here is you're trying to sort of value this ETH USD pool on uniswap V two, but maybe also you have access to trade on finance. And let's assume that trading on finance is frictionless and you can see the price and so on. Again, it's a model, right? So we're going to make some assumptions, but our assumption is that there is an observable external price and we have to give sort of dynamics for this price.
00:42:07.776 - 00:43:11.348, Speaker A: And so the most sort of natural thing is to assume that it's a random walk or more properly, a martingale, right? And so, in other words, if I sort of think about what's the most immediate martingale, I would sort of write down probably the increments would be something like normal distribution, right? And so in particular, sort of in finance, a typical convention is we don't work directly with the prices. We work in terms of returns because that's better. So sort of a baseline model might be to think that, okay, if I look over a short period of time ahead, if I'm at time T and I look at up to delta T, this is my percentage return. I want that to be normally distributed, right? And the way you kind of make that rigorous, the proper sort of technical device is to write down a stochastic differential equation, right? So this is sort of maybe the informal description on the left. On the right is sort of the formal Stochastic differential equation where I say the instantaneous return. So here I was going over delta T. Now I'm sort of shrinking the delta T to zero.
00:43:11.348 - 00:43:58.656, Speaker A: The instantaneous return is the product of a constant, the volatility and a brownian increment, something that looks like something's normally distributed, right? So again, I have a random walk is a price process and I'll just point out that this is very standard. This is sort of basically the Black Scholes setup. Any questions? Okay, let's talk about the CfMM. So again, we're going to assume there's a constraint set. That's the same picture we saw below. We're going to make a couple of assumptions. Speaking to Pranav's point, we're going to assume that the set of liquidity providers and their demand curve stays constant, right? So we're going to ignore minting and burning of LP shares.
00:43:58.656 - 00:44:31.230, Speaker A: We're going to imagine we're looking at a short interval of time. We're going to ignore trading fees for now and we'll come back to that because that's quite important. We will also ignore a bunch of other low level stuff. So we're going to ignore the fact that there's gas, we're going to ignore the fact that in blockchain really the world is discrete time, it's not continuous time and so on and so forth. But that's going to be our abstraction. So our starting point for the analysis is going to be to write down this object. This is what I call the value function.
00:44:31.230 - 00:45:25.152, Speaker A: I'm going to denote it by z of P. The input is a price level. And what I'm doing here is I'm solving an optimization problem where I'm looking across all feasible sets of reserves according to my invariant. And I'm trying to find the pair XY, which has the least value if the price of the risky asset is P, right? And so this is a pretty standard sort of device to sort of mathematical device to sort of look at these pools. You can sort of think about it as kind of a coordinate change or reparameterization, if you will, where instead of sort of thinking so much about the reserves, I'm going to think instead about prices. And this is something that's been done by a number of others, a particular series of papers by Ngiris that all really kind of leveraged this type of function. And I'm going to make an assumption about this.
00:45:25.152 - 00:46:06.524, Speaker A: This will be my one technical assumption. Number one, I'm going to assume that an optimal solution exists. And number two, I'm going to assume that this value function itself is well behaved, namely it's smooth in the sense of being twice continuously differentiable. So these are technical assumptions that I need, but they are basically satisfied by every AMM that I've seen. So it's not really much that I'm asking for here. And one thing I'll point out, why is this function important? If you sort of think about this for a second, if you solve this problem for all the different values of P, the X star of the P that you have is the demand curve. That is the same object we saw in the first half of the talk.
00:46:06.524 - 00:47:34.020, Speaker A: And why is that? Well, sort of imagine the price level is P, right? And imagine that everybody knows the price level is P. If the reserves, what someone will do, let's say an arbitrageure, they will show up at the pool and they will try to extract as much money from the pool as possible. Assuming that the price level is P. And this transaction is zero sum between the arbitrageure and the pool. Right? So the Arbitrageur trying to extract as much money is the same as the value of the pool being minimized under that price assumption, right? So if everything is incentive compatible and so on and the price level is P, you should expect the value of the pool to be a V of P by the action of these Arbitragers, right? So this is exactly the same object as we saw this x star in the first half of the talk. Okay? So just to give sort of a concrete example, all of this is maybe dressed up in some math, but it's all sort of very basic algebra. So for example, for a constant product case, uniswap v two, the demand curve I showed below goes as one over square root of P and uniswap v two has constant product, I should say has a nice property that along the demand curve you hold the same dollar value in the risky asset and in the numerair.
00:47:34.020 - 00:48:14.516, Speaker A: And so this is the value function simply by plugging in those formulas. So this is just simply write down the lagrangian, take derivatives, do some algebra and so on. There's nothing really magical happening here, it's just a better representation. So now getting back to the let me do an intermediate lemma, one more sort of technical lemma that's also a little bit elementary. First part is that if I take the derivative of the value function, that gives me the demand curve. In other words, the quantity of the asset, the risky asset held at the price P. That's the first part.
00:48:14.516 - 00:48:43.792, Speaker A: And the second part is that if I take the second derivative, the second derivative is actually negative. In other words, this is a concave function. Right? So I'll just sort of quickly write down the proof. Again, this is sort of fairly elementary. The first part is basically what economists call the envelope theorem. But Tim has convinced me it doesn't really deserve a special name. It's basically just combining first order conditions and the implicit function theorem and so on.
00:48:43.792 - 00:49:34.748, Speaker A: It's an elementary rule about taking the derivative of the value of an optimization program. In terms of the second feature, if you've ever seen convex analysis, if you have the maximum of a bunch of linear functions, that gives you a convex function. If you have the minimum, that gives you a concave. This is a minimum and so this is concave. So again, these are sort of elementary facts about optimization, but we're going to leverage these too heavily in what comes. So now we're going to start to get to the valuation part again. Our assumption is that we have these Arbitragers, what blockchain world people call searchers who are continuously monitoring the market, who are also able to trade in the external market and who are sort of trying to get those two to converge.
00:49:34.748 - 00:51:21.584, Speaker A: And so by the same logic I explained before, these arbitraries trying to extract the maximum value from the pool corresponds to putting the pool into the state where it has minimum value for the LP owners, right? And so in other words, if I want to look at the value of reserves at any time, I'm going to denote by V of T the value of the reserves at time T. That has to be the function V evaluated at PT. Again, because of the actions of these arbitragers who are continuously monitoring, they will always move the pool into the lowest value state at the then current price because they want to make money. And again it's zero sum, right? So again, using the running constant product market maker example, that means that V of T is proportional to the square root of P of T in a constant product setting. This is just simply plugging in the formula from before, right? Now, if you recall at the beginning when we were talking about motivation, the first question I asked is how do we understand the risk inherent in this pool? Right? So in order to think about that, I'm going to try to generate the same kind of risk in a different way. What I'm going to try to do is I'm going to try to separately mirror the risk that's embedded in that pool, except I'm not going to do it via a CfMM or a pool. I'm going to do it by trading on my own in the external market, right? And so that's the idea and that's what we're going to call the Rebalancing strategy, right? So to be precise about what we're doing, the Rebalancing strategy is going to be a self financing trading strategy which starts out holding exactly what the pool held at period zero.
00:51:21.584 - 00:52:10.130, Speaker A: Again, x star evaluated at X star and Y star evaluated at p zero. But at every time T afterwards it will adjust the risky holdings to match what the pool would have held, right? So here we're imagining a dynamic trading strategy that's sort of trading over time and again. Its main goal is to just do what it thinks the arbitragers should have the risky asset that it thinks the arbitragers should induce in the pool at that time. The idea being if you're holding the exact same amount of the risky asset, maybe that's going to mirror the overall risk of the pool. And indeed we're going to see that's the case. But one thing we're going to need is we're going to try to understand what is the value of this Rebalancing portfolio. And so I need to do a little bit of algebra to do that.
00:52:10.130 - 00:52:57.504, Speaker A: The idea is that if this strategy is a self financing strategy, you're going to start out with some initial value, the same initial value as the pool. And if it's self financing, there's no way money could have come in. The only way money could go in or leave is through trading profit and losses and my period trading profit and loss. If I discretize time every delta T is I held some position at the beginning of the period and then there was a price movement and then that's how much I made in the Ith period. And then if I sum across that overall periods, I should get how much money I have at the end. And of course, passing a limit to sort of a continuous time. I can write that down as an integral of the position process against increments of the price process because that's exactly what I had in the sum over here.
00:52:57.504 - 00:53:29.812, Speaker A: So again, this is just motivating, this integral. We will see this formula later. But there's one other point I want to make right now is that it's not hard to see also that this is a Martingale, right? In other words, it's also a random walk. If you take, for example, the expectation of what will its value be in the future, it's the same as its value now. Now, why is that? Well, at some level it shouldn't be surprising, right? At some level you have an underlying asset that's a random walk. The x. The p process is a martingale.
00:53:29.812 - 00:54:23.900, Speaker A: Right? If I'm trading on top of that, it should also be a Martingale, right? And indeed that's true. It's true for any self financing trading strategy. And one way maybe to more technically see that is if you look at this sort of discrete formula at the top and you take Tower property of expectation, you will see that I'm always taking an expectation against a future price increment, which is zero mean, right? It's a Martingale difference, right? So that's going to be an important property too. All right, so we have all the technology set up. Now we're ready for the main result. What we're going to do is we're going to define loss versus rebalancing as the difference between the value of the Rebalancing strategy portfolio versus the pool value. Phrased differently, we can write the pool value as taking the Rebalancing portfolio value and subtracting this loss versus rebalancing.
00:54:23.900 - 00:55:02.488, Speaker A: And the main result is to characterize that loss versus rebalancing, which is as follows the loss versus Rebalancing is the integral of some function L, which depends on price and where this function l is always greater than or equal to zero. So there's a formula over here. I'll come back and parse it over the course of the next couple of slides and give you some intuition of what's going on here. But I want to make a couple of points which should be immediate. One is that first of all, this is non negative, right? You're integrating something which is positive. It's also going to be positive. So indeed it is a loss, it is a cost, right? It will never be negative, it will never be a gain, number one.
00:55:02.488 - 00:55:34.320, Speaker A: Number two, it's nondecreasing. It will always be sort of increasing. So in that way, it's sort of a running cost that's increasing over time. The predictable thing we will come back to in a second what I mean by that. And I want to make one more point, which is that probably many people have heard of something called impermanent loss, or sometimes people call it divergence loss or so on. That is not this, that is something else. And I'll come back in a bunch of slides to relate this back to the much better known concept of impermanent loss.
00:55:35.060 - 00:55:41.092, Speaker B: We're reminding people that V double crime is non positive, right? The concavity of E is showing up here.
00:55:41.146 - 00:56:04.840, Speaker A: Yes. So this is where the concavity of V is important. Yes. And it always has to be concave. So that's okay. All right then let me just sort of give you a quick intuition and I'll jump to sort of more formal results. So basically the intuition is if I write down the expression I had above, this was the formula for the value of the Rebalancing portfolio.
00:56:04.840 - 00:56:33.268, Speaker A: This is the formula for lever. Right? And if I write that same equation in differential form, this DVT that's telling me over the next instant in time, what do I expect the value to do? I see there's two components, a red component and a blue component. The red component has a DP, it has a price increment. This has market risk, could go up, could go down. Right? So that's what I'm calling the market risk component. And it is exactly the same as the Rebalancing strategy. On the other hand, this blue component, there's just a DT there.
00:56:33.268 - 00:57:11.488, Speaker A: So over a very short interval of time, you know that that's going to go a particular direction. And in a local sense, in an instantaneous sense, this part is riskless, whereas this part has market risk. So what we've done is we've isolated the market risk into one segment. Where does this cost arise from? So it arises from the following. If you recall the Rebalancing strategy, remember that XSTAR, the demand curve was downward sloping. What that means is the Rebalancing strategy sells when prices are high and buys when prices are low. In other words, as prices are fluctuating, it makes money.
00:57:11.488 - 00:57:39.476, Speaker A: On the other hand, the CfMM pool, its value is path independent. It just depends on what's the price at the end. So what's going on here is the Cmfm pool does not make money from the price fluctuations. Its value is path independent. Instead, the money goes to Arbitrageurs, right? So the Arbitragers aren't here for fun, they're doing it to make money. And where is this money coming from? There's only one other participant in the system. It's the LPs, right? And so basically the lever is.
00:57:39.476 - 00:58:18.132, Speaker A: The profits earned by the ARBs who rebalance the pool. And obviously that's going to be positive and obviously that's going to be non decreasing over time because otherwise the ARBs wouldn't trade in this way. It is an adverse selection cost. It is a cost you're paying to people who are more informed than you because they're arriving later with better information about the then current prices. Just in terms of the functional form, I can write it out in terms of two things. If you look at that formula, the first component has to do with the price variance of the risky asset, something with the volatility and so on, but volatility squared. So we're talking about variance and the second term V double prime.
00:58:18.132 - 00:59:08.890, Speaker A: Recall that V double prime is X star prime which you may recall from the first half is the instantaneous liquidity at this price level, right? So again, this formula makes a lot of sense. This lever cost is higher the more volatile the asset is and also the more liquidity there is at that price level. Why? Because the more volatile it is, the more money the ARBs make, right? Similarly, the more liquidity there is at that price level, the more the ARBs can trade against the pool and they can make more money. So again, this feeds into all of that intuition. Let me try to wrap up quickly so we can do these calculations for uniswap V, two in particular, just plugging in that formula. We get this expression over here, it has the nice property that the lever cost is proportional to the value of the pool. So in other words we can interpret it as like kind of a running tax on the pool value.
00:59:08.890 - 01:00:16.060, Speaker A: And this is the result I showed you at the beginning, right? On a daily basis, if the assume 5% volatility, the running cost is sigma squared over eight, which plug in 5%, evaluates to three basis points a day. Just to briefly talk about impermanent loss. Impermanent loss is basically what we would call loss versus holding. The idea is you just start with the portfolio at the beginning that the pool had and you just maintain that portfolio. Well if you do that, the expression that you get is that the loss versus holding is your lever loss plus some other term which involves market risk, right? So loss versus holding or impermanent loss, that's another metric. But it does not separate market risk and does not separate into cleanly into market risk versus adverse selection. So in some sort of very specific sense, in sense of the Duke Meyer decomposition or so on the loss versus rebalancing, our metric is external and it's the only one that sort of cleanly accomplishes this separation.
01:00:16.060 - 01:01:19.968, Speaker A: So what about fees? So just to sort of superimpose fees on top, let's have a simple model where we have the Arbitragers as they are and then we have some noise traders who arrive and they pay fees. And I'm not going to be specific about this, I'm just going to define that f of T is the cumulative fee process collected up to time T. And without going through all this algebra just in the interest of time. The upshot is if you want this to be fairly priced, if we want the value of the pool at time zero to be the same as its initial cost, we need the lever to sort of balance out with the fees. Right? And so that gets me to sort of where I was at the beginning, right? If for example, in this pool the fees are 30 basis points of the volume, that suggests that the trading volume needs to be about 10% of the pool value in order for this to balance out. And interestingly, this 3.1 125 that comes from the 5% it scales with its square.
01:01:19.968 - 01:01:52.268, Speaker A: Right? So for example, I just looked at a chart today. If I look at how volatile has ethereum been over the past two years, it's varied by a factor of ten. There are points in time where it was not very volatile at all and points in time when it was sort of ten x more volatile. And that suggests that the trading fees should also vary on that scale. Right. You should have two orders of magnitude difference in the trading fees in times versus where it's not volatile, versus times when it's volatile because that's what's fair to the liquidity providers because that's the cost they're paying in terms of adverse selection. Right.
01:01:52.268 - 01:02:46.552, Speaker A: And so that sort of leads to the idea of maybe we should have dynamic fees. It's sort of natural to sort of think about us scaling fees with volatility. That happens in traditional markets too. When market makers are quoting prices, when they're quoting bid and ask spreads, they widen them in volatile times and narrow them in times that's not volatile. But if we want this to happen over two orders of magnitude, maybe it should be baked in the contract. And you could imagine doing things like looking at recent volatility and scaling the fee level by volatility or looking at maybe what has the lever been in the recent past? Right? It has been higher or lower than the fees that are collected and doing some kind of procedure where you adjust fees to try and equilibrate those two. So our hope is that this idea gives a lot of nice closed form expressions that they can be the basis of better mechanisms for sort of figuring out how to set the fees.
01:02:46.552 - 01:03:53.120, Speaker A: So apologize for going over time, but I'll stop there's. I can ask a very broad question. I guess in the long run, suppose the traditional markets continue to exist and the good AMMS that are designing are also there. Do you envision the liquidity equilibrium to be do you see one winning over the other? Do you envision a stratification of different kinds of liquidity demand to happen or is it hard to predict? I haven't thought about that. My sort of prediction would be that the Cfmms, there's really like a lot of cleverness in them and a lot of sort of great engineering, but it's really oriented around the limitations of a blockchain. Right. If you had sort of unlimited computation, if you could run your own servers, it seems like the rest of the world has converged into this limit order book structure.
01:03:53.120 - 01:04:43.410, Speaker A: I don't know, but my personal belief is that the real value of CfMM is not that it's a better mechanism, but that it runs on the blockchain and that it plugs into all the other DeFi Legos and so on. So my prediction, I mean, I think I'm pretty sure it's currently true that it's more expensive to trade on Cfmms, certainly for popular tokens. I think that'll persist because their utility is not that, again, it's a better mechanism, but that it's an on chain mechanism. Does this LDR exist for the limit order books, too? A similar concept exists, but not like this. And the thing that breaks down is the twice differentiability. So there is a du meier decomposition. You can have a Martingale and a decreasing piece, but it is not this.
01:04:43.410 - 01:05:18.728, Speaker A: It's something more complicated and you would get it out of the black Scholes formula and so on. So do people pay fees in traditional exchanges based on that, or is that a difference? So on traditional exchanges, what happens is that the participants aren't passive. They're constantly modifying their orders. Right? So the model in an AMM is that you give your liquidity curve and because it's expensive to interact with the blockchain, you leave it there for a while. On Nasdaq, it's not expensive to send orders to Nasdaq. So on a second by second basis, you're constantly adjusting. And if all of a sudden it looks like there's a Fed announcement, the market is volatile, they will widen their quotes immediately.
01:05:18.728 - 01:05:24.930, Speaker A: So it really happens in real time. But it's not part of the mechanism. It's that the market makers are smart and they do it themselves.
01:05:27.940 - 01:05:36.530, Speaker B: Another question is, will there be passive liquidity provision as we take time to infinity or large in the future.
01:05:38.260 - 01:05:38.636, Speaker A: Like.
01:05:38.678 - 01:05:42.612, Speaker B: Five years from now? Is there any market for passive liquidity provision? It's not clear.
01:05:42.666 - 01:06:23.030, Speaker A: Right? Yeah, maybe. I think maybe another point you could like so let's say the blockchain scales so that the computation isn't a problem. Maybe the second point, though, was that you do have to attract market makers. So I think if you have illiquid assets, there is a and by the way, when I said the rest of the world is limit order books, I'm making up numbers here, but 90% of it is the 10% that isn't is illiquid stuff. So, for example, if you're trading corporate bonds, which are really not fungible, and there are hundreds of thousands of them, and it's sort of a market by appointment that does not trade on a limit order book you sort of call people and there's a search market and so on. So it could be a place for these for illiquid assets. Limit order books don't work well there.
01:06:23.030 - 01:06:25.030, Speaker A: Thank you for coming.

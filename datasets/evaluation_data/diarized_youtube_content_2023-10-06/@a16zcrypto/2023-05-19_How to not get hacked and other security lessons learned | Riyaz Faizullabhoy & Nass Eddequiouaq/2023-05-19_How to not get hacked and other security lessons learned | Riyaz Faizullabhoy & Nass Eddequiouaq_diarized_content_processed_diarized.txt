00:00:10.250 - 00:00:53.998, Speaker A: So today our talk is all about security. Lessons learned from seeing incidents in the wild, thinking about attack types and understanding holistically, what are the threats and then given that, how not to get hacked for your protocol or project or app and taking all those lessons learned and making it practical. So before that, as Jeff mentioned, this is us, NASA Riaz. We used to be CSTO and CTO at http z crypto, thinking about security and infrastructure kind of across the portfolio, but the broader ecosystem. We also worked at Facebook on the labor project. So thinking about consumer scale security, blockchain integration into wallets custody and then also have thought about security from the institutional side. So you're both at Anchorage early.
00:00:53.998 - 00:01:42.758, Speaker A: I was a founding engineer, nas joined also very early thinking about for institutions, what does security look like with crypto, withholding but also staking voting, other web3 interactions. Prior to that we were at Docker working on security, so more traditional security with OS, security authorization authentication. And that's where I passed the verge. We've been working together for seven years, but NASA is on the security team at Apple, has also been working on Capture the Flag and Red teaming exercises. And I was doing a security PhD at UC Berkeley before dropping out and doing all this in industry. So, agenda for today, really two main focuses. First we're going to look at security incidents that we've seen in the wild and really first take a broad view just looking across the space, but then deep dive into three in particular with Nomad, Ronan and BadgerDAO.
00:01:42.758 - 00:02:31.834, Speaker A: We're going to take the lessons learned from those incidents, but just broadly from what we see in the space and then apply it to be more practical. And think about when you're building a company product protocol at each stage, as you think through design, development, testing, what are the best practices and how to actually build security in for you? So we're going to start with overview and here's a list of some notable hacks that we've seen in the space by dollar amount. This data is from Rect Leaderboard, which you haven't seen it before, really recommend you take a look. It's actually very interesting. It shows all the attacks as well as a debrief, as well as what was known to be stolen or Mitigated. And as you can see, a lot of these hacks are in the nine figure range. And so obviously security is very important.
00:02:31.834 - 00:03:17.910, Speaker A: But I think one thing that we're going to really dig into today is, if you notice on the very far right, is there are different waste and different attack vectors for each of these incidents. Obviously key compromise being a big one, software bugs, you can think about it from like a smart contract perspective, but other pieces and we see website compromise. But really today we want to first kind of center our conversation around understanding that there's more than just the smart contract. And I think everyone in Web Three tends to initially see that as the shiny thing for security and thinking through the smart contract security. But really there are many classes of attacks and this is a nonexhaustive list of four of them. But as you can see, there's quite a lot of incidents and just funds stolen across different categories. And some of these categories are web3 specific, some aren't.
00:03:17.910 - 00:04:12.054, Speaker A: And so we're going to talk about those today. So for example, with code exploit that really refers to the smart contract incident, we'll talk about Nomad and Nas will walk us through that today. What happened? There's been another there of others that we've seen in the space but in the next box over with Apt, also known as Advanced Persistent Threat, this is a known security attack vector and class for Web Two as well. And it's been a classic where there's an intrusion either by spear phishing or some other compromise. An attacker gets in your system, they start poking around to figure out what they want to steal, what they want to attack and then go forward. And so this is actually, if you remember way back when, the big Sony hack in Web Two world, but also we'll talk about them today, but anything Lazarus kind of tends to fall in this category and we expect it to still be a category in Web Three going forward. A Web Three specific class of attack, just given the new decentralized nature of web Three is oracle and governance manipulation.
00:04:12.054 - 00:05:11.738, Speaker A: Now that we have these decentralized systems where decisions can be made by many members in the system in a decentralized way, token holders, this actually opens up also a new attack vector where this can be used to abuse the system or introduce decisions into the protocol that may actually hurt it. And so we've seen in the space a couple of these. We expect these to continue, but again, this is a new to Web Three type of class, just given the new possibilities of technology. And then lastly today we're going to talk through an example with Badger Dow, but wanted to bring back a classic also Web Two, but now seeing it in web Three class of attack and front end compromise. Now that we have decentralized applications, we have front ends that you can interact with on the UI that you connect your wallet to. This is actually now also another part of the critical path for user funds or core user interactions where if an attacker was able to get in there, they can disrupt your protocol or project or app. And so we've seen this with Badgerdo and others and we'll talk more today about BadgerDAO.
00:05:11.738 - 00:05:15.090, Speaker A: And so with that I'll hand off to Nas to talk through Nomad.
00:05:16.630 - 00:05:59.920, Speaker B: Thank you. So I think that Nomad is a very interesting example of security issue due to logic bug. And it's really something that could have been avoided, first with better testing, better kind of audit, kind of a gatekeeping of anything going to prod, but also to a certain extent, lack of circuit breaker essentially as part of the protocol. So let's dive into it. Nomad, what is it? It's a trustless bridge essentially connecting multiple chains. So Ethereum Mainnet. There was Avalanche and a few others.
00:05:59.920 - 00:07:01.262, Speaker B: And it really doesn't have a centralized party that is operating the entire protocol. It instead relies on execution of code as part of smart contracts and kind of proof generation and proof verification on chains that it connects. And so what happened on August last year, and I believe that many people here were part of crypto Twitter, right? And kind of like seeing things happen in real time. Essentially we started seeing a tremendous amount of transactions draining the bridge that looked very identical. And so we didn't see the bridge circuit breaker kind of triggering those watchers and more people starting to drain the bridge by replicating successful transactions and just switching the destination address. So I think that today we should take some time to kind of dive into it and take time to understand what really happened there. So just more context on bridges.
00:07:01.262 - 00:08:05.350, Speaker B: For those who are not familiar, there are kind of like two main buckets of bridges, trusted bridges and trustless bridges. Trusted bridges depend upon essentially centralized entities or systems to operate and for their operations to conduct. Whether you want to kind of verify transactions on one chain and relay them to another one and make sure that those things only get executed once, but also trustless bridges that operate without this central party and rely instead on smart contracts and algorithms to function. And nomad is the latter. So Nomad is an optimistic trustless bridge that enables secure communication and messaging, kind of like relay across multiple chain. So at a high level, the lifecycle of the normal lifecycle of a message across chains looks like the following. A user will initiate a transaction on the origin chain and essentially send it to the bridge router.
00:08:05.350 - 00:09:16.590, Speaker B: The home contract that lives on this origin chain will essentially pick up this message, organize all the messages into a merkel tree, and then send them to the corresponding replica contract that lives essentially on the destination chain. And after a dispute window, which we're going to explain in a little bit, the destination chain verifies and processes the message. And the final step is just execution, essentially of the logic that allows this transaction to get processed and for the recipient to receive the message or the transaction. So a bit more on optimistic bridges. So how does it work? You essentially have the optimistic verification of messages. And what does it mean? It kind of like falls into three key aspects. The first one is that messages are signed on the origin chain and it actually takes kind of like a timeout period for them to actually be finalized and executed on the second chain.
00:09:16.590 - 00:09:19.680, Speaker B: And during that period of time.
00:09:21.410 - 00:09:21.822, Speaker A: You.
00:09:21.876 - 00:10:44.490, Speaker B: Essentially have a decentralized set of parties that can inspect and monitor fraudulent activity for the messages that are being passed across the bridge. So those kind of like the entities, the decentralized network of entities that can perform verification of fraudulent activity are called the watchers. Those watchers are just off chain entities looking into all of the messages that are passing through and can actually veto those messages if they can prove that this is a fraudulent message. And lastly, there is just the trade off of latency that in general, those systems, those optimistic systems, take more time to get to a finalized state because of this kind of, like, timeout window. So back to the transaction flow. I think that today is going to be interesting to go over a little bit more in depth on how does the Replica contract works, which was the component that actually was impacted here. Then go with an example of the happy path of us leveraging the nomed Bridge whenever we want to transact, and then what actually went wrong in last August.
00:10:44.490 - 00:11:37.830, Speaker B: So for the Replica contracts, you can essentially see it as the contract that serves as an inbox for messages on the destination chain. It enables kind of the cross chain communication, receives all the inbound messages, and then enforces this dispute window, during which all the watchers can kind of look into all the messages and potentially veto the fraudulent ones and flag them. So that's the Replica contract. And in the kind of the Happy Path set, it like Riaz, for some reason, you owe me a little bit of money. Riaz will want to send $200,000 to Nas. Riaz is on the origin chain. I'm on the destination chain.
00:11:37.830 - 00:12:27.926, Speaker B: What's going to happen is that Riaz is going to obviously send a transaction to the home contract on the origin chain. The message is then processed, added to the merkel tree, the root gets updated, an updater will sign an update, and then essentially kind of like relay this information to the Replica contract on the destination chain. And after the time window, the message is proven, processed, and then gets actually executed, and I receive the $200,000. So that's great. Everything works well. And then something actually went wrong last August. So the Nomad team actually pushed an update to this Replica contract.
00:12:27.926 - 00:13:46.886, Speaker B: And this update, they actually had done a tremendous amount of auditing prior to this update on the vast majority of pretty much kind of like the entire code base at that time started adding a few updates, very benign updates, and then pushing them to production, which is essentially Ethereum mainnet. And it appears that it was not tested as it should have been. So what happened there is essentially a vulnerability was introduced as part of this code update where the Replica contract allowed unauthorized transactions. So to go a bit more in depth. The update that was actually done was, and it was back in April, where a default value of zero was accidentally set for the new trusted root hash. And this means that essentially the bridge would accept any uninitialized value consider valid. So the Replica contract that processes all of those cross chain messages receives transactions, alterations can be made to those.
00:13:46.886 - 00:14:41.670, Speaker B: And due to the vulnerability, the attackers could essentially alter various part of the transaction and actually have it still considered valid by the bridge. Because at that point in time, the trusted route that the bridge was kind of calibrating against was telling that everything was fine constantly. So really allowing attackers to claim funds that were meant for other people. And the hard part here is that this loophole was essentially exploitable by anyone. And we're going to see that this is pretty much what happened. And for those who are here, it kind of looked like the first on chain bankrupt everyone could kind of see live. So let's take the happy path that we had before.
00:14:41.670 - 00:15:18.258, Speaker B: So Riaz wants to send a valid transaction, $200,000 on the origin chain. The bridge will essentially kind of like validate. The message is valid. The valid message will be kind of like approved, will have a proof generated for. It, will be sent to the Replica contract that actually contains a bug now. And what happens? Well, it actually works just as we expected because it's a valid message and we actually see Nas receiving $200,000. That's great.
00:15:18.258 - 00:16:35.062, Speaker B: But something else happened that day. And what happened is that due to the code logic bug that was introduced in the Replica contract and kind of running with an unintended trusted root hash, attackers could essentially take the transaction that RIAs originally sent for Nas, change the address of Nas to their own, and essentially just resubmit this transaction. And the Replica contract that runs again with the mistakenly trusted unauthorized transaction would just approve it. And so you essentially had I don't know how many people, honestly, I think that it was probably like just hundreds of people just seeing what was happening and trying that themselves. A lot of people actually sent back the money. But there are very key learnings here, right, because obviously we're all running and building sorry, systems that will run in a decentralized fashion. And so the critical part here is, regardless of what you're building, get every single thing that you're shipping to prod thoroughly reviewed audited.
00:16:35.062 - 00:17:42.858, Speaker B: Audits are just a point in time view of whatever you ask the third party to review. Right? Like, they don't have any information of things that are outside of the scope that you give them, and they don't have information about what you push to your repositories after they come in and kind of have a view. Right? So that's the first thing. Anything that you push to Prod should be reviewed very thoroughly. But on top of a third party reviewing your code, you really need to have systems in place that enforce kind of like the testing of both the happy and the unhappy path as if it was production, right? Like here we essentially had something that probably could look benign because it was about state and code of the bridge that were mismatching. So whenever you want to test your system and you should do that every single time that you push things, you should make sure that you're copying the state and the code that actually runs in production on mainnet before releasing it. So extremely important.
00:17:42.858 - 00:19:07.382, Speaker B: And third, finally ensure that you have circuit breakers that allow you to pause things, give you some time essentially to understand what is happening, figure out a solution and then obviously get consensus and then push it to production. So all those three things are absolutely critical to put in place. We're obviously going to kind of see how those things kind of get incorporated as part of the secure developments lifecycle, but very important takeaways another very interesting security issue that has nothing to do with Web Three and was actually performed by some of the most sophisticated attackers known essentially in the world was the Ronin bridge. So let's dive into what happened there. So, unlike Nomad, which is a trustless bridge, roland is a trusted bridge, which means that it relies essentially on a set of centralized parties to operate the bridge and more specifically having a quorum that is made out of. So at least five Validators need to come to an agreement on which transaction to process as part of the bridge out of the nine. So here we have a very traditional kind of like corporate environment.
00:19:07.382 - 00:19:31.780, Speaker B: Everyone here is building a company, hiring employees, starting to build kind of infrastructure, right? And the idea here is everyone is going to have some form of access to resources as part of the company, whether it's documents, whether that's systems that are running. And so here we essentially had an employee that was kind of like on the technical side on the house.
00:19:34.630 - 00:19:35.006, Speaker A: And.
00:19:35.048 - 00:21:12.130, Speaker B: Then other entities that are part obviously of running validators as well that are independent from this party, right? So very traditional kind of like corporate environment. But just like the vast majority of people in this room will be at some point a phishing attack was actually performed on one of their employees. What happened there is that this person got in touch with someone else via LinkedIn. The person on LinkedIn asked them to open essentially a PDF document on their machine. And the part that is very interesting is that people often forget that whether that's SVGs, whether that's PDF, it's not just text or images and formatting, it's actual code that is running every time that you open this file within the reader, right? Like whenever you have a PDF reader, it actually will execute code that runs within the PDF or not every time, but the vast majority of the time. So the part that is pretty interesting there is if you think about this type of attack, this is something that everyone in this room can essentially be subject to, but also everyone in web two, right? Like it has nothing to do with web3. Everyone goes on LinkedIn, tries to hire people, and then can potentially open resumes and just job offers, you name it, right? So what happened here is the employee downloads the file.
00:21:12.130 - 00:22:13.878, Speaker B: This file actually contains malicious code that is ready to get executed by the PDF reader. And you get kind of like a recipe for a successful phishing attack if somehow the attacker managed to understand what kind of vulnerability lies in the PDF reader. So this is exactly what happened. It actually was a successful execution of the malware, which actually provided remote access to Lazarus. Lazarus, for those who are not aware, is, I would call it kind of like the offensive arm of north Korea of one of them, highly successful, has been essentially performing the same kind of highly successful phishing attacks and very high profile for decades at this point. And again, nothing to do with web3. And they know how to do it really well.
00:22:13.878 - 00:23:01.218, Speaker B: They know how to gain access to a corporate environment and then move laterally within the environment to gain access to more information. They will try to stay in stealth for as long as possible, evaluate all of the resources and then take advantage of those things. So this is exactly what happened here. They gained access, they pivoted laterally to gain access to every single one of the validators internally. But that was not it, right? We're up against Lazarus. And so what they did is not trying to find additional vulnerabilities within the bridge itself. It actually tried to target vulnerabilities within the entities that have access to the validators and operate those validators.
00:23:01.218 - 00:24:05.322, Speaker B: So what they did here is after gaining access to four of the validators, they still needed one more. And so they ended up pivoted not just within the corporate environment, but actually across corporate environments. So they actually jumped from one company to the next through, essentially through this malware that was now infecting all the systems. And so now they actually managed to find a vulnerability that was part of an access to another company via this first one, which allowed them to gain access to the fifth validator. And once they had five validators out of the nine, they were able essentially to unlock the access to the Ronan bridge and essentially start creating transactions that would then send them assets. So pretty much what happened. Again, extremely motivated, extremely sophisticated attackers, very well funded, very patient, that are lurking around in this space.
00:24:05.322 - 00:25:01.018, Speaker B: And this is the type of attack that we also need to stay safe against and really protect ourselves against. So not just web3, really, you have to think about security on a very holistic way, right? It's really corporate security, operational security, key management, least privileged security device security. Really, you have to think about it from all the angles because this is really how you build a secure business, right? Like it doesn't mean that because you are in Web Three, you are more secure. No, you actually have all of the security from Web Two to take care of plus actual security in Web three. And so to actually kind of double down on that, reyes is actually going to present another very interesting case with Badger Dow that is, again, nothing to do with Web Three specifically.
00:25:01.194 - 00:25:59.658, Speaker A: Great. So I'll talk about badger dow So Badger Dow is a DFI platform based on bringing bitcoin to DFI and web3 via Ethereum and smart contracts. And so I've oversimplified it, but you can think of it as a DAP. Where there is a front end, there are a number of smart contracts that interact with DeFi and Ethereum smart contracts to get yield. And so to kind of explain more about what happened in this hack, we're going to first talk through the Happy path. And so if you're a user using Badger Dao, at some point, some down the line, you're going to connect your wallet to the front end app and you're going to, at some point, submit an approved transaction where you approve Badger Dao smart contracts access to your wallets and therefore can participate in the DeFi interactions that are going to happen on chain with your wallet. So you'll go to the front end, you'll approve that front end will either already have the address or get the address of the Smart contracts that you're going to approve with and make sure it's the right ones that are from Badger Dow.
00:25:59.658 - 00:26:22.770, Speaker A: They're going to bring it back to you. Say it's like zero, X, ABC, one, two, three, whatever it is, you're going to get that in your wallet, whether it's MetaMask, whatever it is, you're going to sign it. You're going to submit to the blockchain and you're good to go. You're off to the races. You're making yield with Badger Dow. So that's the Happy Path and that's the architecture at a very, very high level. It but what happened in this incident was we started noticing funds starting to move in a way that wasn't expected.
00:26:22.770 - 00:27:10.402, Speaker A: And the team started looking into it and this message got posted and that was essentially describing the root cause of the attack, which was an API key for Cloudflare, which I don't know if you're familiar with Cloudflare. They're quite prevalent, used for DDoS protection and CDN management both in web Two and web3, pretty common was compromised. And so Cloudfare obviously working with the front end of Badger Dow also allowed the attacker an opportunity to inject malicious JavaScript into the front end. And so when you have the ability to inject malicious JavaScript, what can you do. So let's see now. So now you can imagine we have our devil emoji for this front end that is now compromised. We now have a user going the same way, going to approve to interact with DeFi on BadgerDAO.
00:27:10.402 - 00:27:58.850, Speaker A: They approve, but now the script can intercept that request. And instead of faithfully going back and getting the right BadgerDAO address or getting what is expected, it can then instead supply the attacker address and just completely forego that flow. And now we're having users approving their funds and their wallets to attacker addresses. And so the attackers were essentially harvesting these approvals. They also actually, very interestingly, exposed an increased allowance method. And the reason why this is interesting is that and it kind of ties into more about the Holistic security picture is MetaMask started getting better at showing very scary messages of, hey, you're approving this contract, all of your funds. Are you sure you want to do this? And so they did this workaround where they were able to, hey, let's use increased allowance instead, which these contracts was able to achieve the same result.
00:27:58.850 - 00:28:40.098, Speaker A: MetaMask didn't recognize the method, and so it was much more opaque to the users. And they just clicked through and said, okay, I'm going to approve this. Essentially the same effects for the attacker. They're able to harvest all these approvals, getting access to these wallets, and then when the time was right, they could then on their own time go and transfer funds to the addresses that were approved to by those users that were affected by attack. And so, again, similar to Ronan and we've talked about previously lessons learned here. Is there's more than just the smart contract security? And thinking about the key management, really thinking critically about what is the critical path about how funds can move, or how an important interaction in my system goes through. And thinking through all the dependencies and core components along the way.
00:28:40.098 - 00:29:29.570, Speaker A: And those dependencies, they may not even be your own software, right? This could be cloudflare. It could be some dependency that you'vendored into, your code that is maintained by another company, another open source library, but really understanding what is the security bar across all of these components, what can go wrong? What do I need to plan for in case of compromise of an API key? How do I detect that and going forward from there? And in a similar note, I'll add on to on the class of front end attacks. We've also seen attacks on DNS systems. So you can point to a different front end and a different website entirely, attacks on name servers as well, kind of in a similar vein. And so this is with DApps having a front end, even if you have keys somewhere else, this is still a critical part of the system. And so with that, I'll hand off to NASA that we've kind of seen an overview and deep dive some of these attacks, some lessons we can learn and practical advice.
00:29:30.630 - 00:31:38.826, Speaker B: So now I think it's very important to take quite a bit of time to go over not just the learnings but how to make kind of take actionable kind of learnings from those things. So first and foremost we talk through several examples, right? Like there is kind of code bug within kind of like smart contract level contract happens to be non upgradable which prevents any form of solution to be put in place if not already present. And we've seen also kind of like traditional web two attacks with whether that's phishing, whether that's taking advantage of a weaker link in the supply chain. And so really all of those things make it clear that we need to tackle security from all angles, right? Like this is the bar that we need to get to, to keep the company safe, the product safe and the user safe, right? So security really should not be an afterthought for anyone in this room and you're going to iterate more and more over the product. So doing kind of like taking care of security early really compounds over time if you think about it, everyone here is going to keep building great things, right? And you're going to iterate over the product and just get more things out and as soon as you kind of get systemized kind of like security as part of the supply chain and kind of like your automation systems you actually will have that in place for every single iteration along the way. So really let's make security scale and this is what we're going to talk about here starting with kind of the software development lifecycle and how to introduce security into each one of those steps in a way that is very actionable. So first and foremost we're seeing kind of like boxes here.
00:31:38.826 - 00:33:54.578, Speaker B: The real version of the software development lifecycle if you want to think about it is really a loop, right? Like the idea is that it's not really just a set of iteration, it's really a set of iterations over time that kind of starts with designing, then testing of your software, deploying it, getting it in the hands of your users and then monitoring and kind of like having visibility into whatever is happening. So that's really designed to help you enforce the best practices over time across product iterations. So the software development lifecycle as many of you know starts with the design phase, right? Like the design phase is the moment where developers essentially detail the blueprint of the architecture, the different services, the different components, the modules, the interfaces, data models, you name it, right? This is really how the moment where we all think about what product do we get in the hands of our customers and users. And really this stage ensures that the system meets not just the requirements from a functional perspective but also established guidelines, best practices, right? Like whether. We're talking about just quote quality or just security, many things maintainability, you name it so really important to have that in place and as part of this comes security, right? And one thing that people kind of overlook but it's actually extremely important is using the right tool for the job. Anything that you can do to bring simplicity to your day to day is actually more time that you allocate for thinking about security, to think about just adding better features really complexity is your enemy both from a functional perspective but especially in security. Second, the thing that we will hear extremely often in this pitch especially is to never roll out your own cryptography.
00:33:54.578 - 00:35:29.590, Speaker B: So I know that some people in the room might be building on top of pretty advanced cryptographic building blocks or developing some themselves. If you don't have a choice, obviously this is the path that you want to take but you want to do it the right way. No one here should ever kind of cut corners if you can avoid to roll on your own crypto, just do it. There are tons of things out there that have been kind of reviewed by the entire cryptography community that are ready to be used by everyone essentially in the space. And finally here before we get to kind of like the cheat sheet is really understanding your tools and dependencies and the fact that each one of those things introduce a risk, right? Like anything that you leverage from a third party that is outside of what you've built is also part of the attack surface that the attackers have access to, to take advantage of your systems, your product, your own users and all of those things need to be part of how you think about the attack surface of what you're building, essentially. So a quick cheat sheet for code development and of course we'll provide the slides after not going to go on every single one of them but probably like two very important ones that we've seen a lot of issues around especially recently. I think that the first one is probably dependencies and kind of like dependency security.
00:35:29.590 - 00:36:54.554, Speaker B: So again, every new dependency is a risk and to limit it first obviously review thoroughly every single piece of software that you use as if it was your own right? Because the attackers, it doesn't matter for them if it was written by someone else or your own team so they will be able to leverage it either way. So really review it as if it was your own code. And then, once you have a proper review in place, hard code them, ensure that it's the right hash, like you have the hash immutable hash of anything that you're running, that you're verifying signatures if possible, or actually even import all of your dependencies within your actual code repository to ensure that your code lives alongside its dependencies and second circuit breakers. So we talked about kind of circuit breakers not being present, for example, for the Nomad hack. And that once the issue was found, there is no way essentially to prevent anything from happening. It's even more critical when we're talking about Web Three. So to think about circuit breakers the right way, I think that you have to position yourself as if the attacker already has researched issues in your own software.
00:36:54.554 - 00:38:18.646, Speaker B: They've taken time to test it thoroughly, whether that's like on a testnet, on a fork of main net and kind of like really they're ready essentially with everything in place to take advantage of your systems or people. And so your time here is the time actually works against you in this environment, right? Like your goal is to actually give you yourself kind of breathing room and really just expand the time window that you have to understand what's happening, what kind of solution can you build and then how to deploy it and make it accessible, right? So really, having those things in place is extremely important and it's oftentimes about time. The additional thing that I would add is most hacks in this space actually could be prevented by adding restrictions and constraints on the kind of like 0.1% of the scenarios, right? Like trying to move an amount of money that is obviously extremely suspicious anyway and would only impact kind of like the top 0.1% of the users. And so it's very important for people here to think about trade off whenever designing circuit breakers because it's oftentimes fine to kind of bother those kind of like 0.1% users for the rest of the people using the protocol to be safe.
00:38:18.646 - 00:38:53.720, Speaker B: So think about, you know, when it comes to like, Web Three, think about pause functions for your contract. Think about obviously upgradable contracts that allow you kind of like pushing fixes to the network, whether that's baking periods for kind of governance proposals to take effect, time locks for sensitive actions on contracts. So, like, all these things, it's kind of like layers in depth that kind of like stack and make the job harder and harder for the bad guys.
00:38:55.610 - 00:39:26.602, Speaker A: All right, so now that we have code, let's talk about testing and pre production. So code is written. We're on the path to production. And we've already discussed this. But testing is your friend, especially for security, especially for systems where the core part of the system involves financial tokens or other monetary value. Where correctness is so intertwined with security that if something goes wrong and it's not correct, it means there's a security vulnerability in your system. So definitely have a robust testing plan beyond just unit test and code coverage.
00:39:26.602 - 00:40:28.770, Speaker A: Really on integration testing with both code and state like we were talking about, with Nomad thinking about, it very holistically, how you're testing. Is it actually mimicking what's in production? Is it actually realistic both for the happy path and then thinking about the unhappy path and how to stress test your system. On that note, on the testing and this environment, best practice is to treat staging like a production environment and for a few reasons. One is if it's a main net fork or as close as you get to mainnet, get the conditions in the state as close as possible. Two is when it comes to things like responding to security incidents, to getting paged for something going wrong with capacity, whatever it is, you're training yourself and getting yourself ready for production so that when it happens in production, it's already stressful enough. But you have a playbook, you have a runbook, you have a checklist of how you address issues and it's been battle tested in this environment. And this environment, by treating it that way, by being paged or being alerted for staging and treating it like that way, you're getting that battle tested experience for production and so you're ready to go when it's time for a prod.
00:40:28.770 - 00:41:19.130, Speaker A: When we were setting up infrastructure both in staging and production, this is a good time to think about how we are going to lock it down. And two classic security principles here. So one is principle of least privilege idea here is not to give any more permission than absolutely needed to any person or system. So for example, if you have a, let's call it a service that has the ability to add a user probably shouldn't also give it access to manage smart, contract deploys or some other sensitive action. And so understanding what are the security boundaries between different components of my system, whether they're smart contracts, whether it's systems, understanding the security level of each and the privilege level of each. In a similar note, other security classic is separation of duty. And that is similar to the above, making sure a single entity doesn't have the ability to do everything or too much.
00:41:19.130 - 00:42:07.778, Speaker A: And so this often also culminates in sensitive actions like contract deploys or key management. There are a number of best practices here like using multisigs gnosis and others. And so there are ways to split this up. But just knowing where these high privilege systems are and understanding how much you can pare down in how much any single system has access in your environment is very important. And of course, we can't talk about getting to production without talking about audits. And as we were discussing, think of audits as they're a piece of your security story, they're not everything in your security story, they're a point in time for a certain scope with a certain auditor who has a certain set of skills and expertise and that's what you get out of an audit, still very valuable. And you should definitely do it for whatever you bring to production, but do it with that framing and understanding what guarantees you're getting from the audit.
00:42:07.778 - 00:42:52.674, Speaker A: And it's not your full security story. The thing with the audit too that I think is very valuable as you get on doing audits is understanding the best way to maximize what you get out of the audit. And a lot of this is like what you put in is what you get out. And what I mean by that is being very involved in the audit. Often with audit companies, you're able to ask for background on who they have on the team, who can work with you, understanding there's a fit in terms of, of their background, if they're very good at solidity or some other technology, if it matches with you or not. And you can be selective in that case. And it's good to be also making sure that they're onboarded and they're ready to go, so that when they show up, it's very clear to them how to best get into the code, how to understand what they're even looking at, understanding what their scopes to do, and they don't get lost in rabbit holes.
00:42:52.674 - 00:43:21.594, Speaker A: And so often when I've done audits with Nas, we are very hands on with the auditor. Daily check ins or whatever makes sense. Just really make sure that things are on track and you're not straying away from what you're really trying to get out of the audit and you're getting things moving forward. Other thing too, that I've seen as a pattern, and I think is worth discussing is that it's okay to have multiple auditors. You can't expect one person to be able to understand everything in your system. It's front end, a smart contract, back end. And it's totally okay to have multiple auditors who are specialized and are experts in those fields.
00:43:21.594 - 00:43:55.290, Speaker A: You may have like one auditor who's doing your AWS infrastructure, another audit firm or auditor doing smart contracts. And that's totally okay. It's a little more overhead, but you're able to really maximize the value of what that person is an expert in and can give you that best advice and best review. And so you're not getting kind of like best here, but then mediocre on other parts of the system. And so that's on the audit, definitely take the time to really put an effort and so you can maximize what you get out of the audit and get a really good audit. Okay, so now we have set up staging, we've done an audit, it's time to go to production. Super exciting.
00:43:55.290 - 00:45:13.166, Speaker A: And really key takeaway here is you should be able to know as soon as you press that button or whatever you're doing to get production, you put your contract, you put your infrastructure, you should very quickly be able to understand, or even before you even push the button, is what's actually running there. And what I mean by that is, are you able to point to an exact git hash, an exact build, an exact chain of commits or pull requests and reviews or exactly what was audited? So you have the confidence that you know what's in there. And by doing that, you know that if there's an issue, you already have the context of what is the exact version of what I'm doing and what I have for deployed. What were the changes from the last time? I have the understanding so that if there's an issue I'm able to then very quickly diagnose or at least much quicker than if I didn't know. And best friends again, tools here that you can use are reproducible builds. So make a build, always spits out the same code or same build, no matter what, whenever you build at different times, having the same sha, documenting versioning tagging, making sure you're organized around here is really helpful. And then on that too, having a checklist both for happy path, understanding what's going in in terms of both code and state and builds but then also if you need to make a hot fix, if you need to do a rollback, what does that process look like? Having that runbook and checklist defined and testing it in staging in the pass phase will make sure that you're ready for production.
00:45:13.166 - 00:46:43.694, Speaker A: If you deploy something and things are not looking right, you can very quickly jump in and diagnose. And so you should be able to kind of pre deployment, post deployment, have these checklists, have this understanding and it'll help you both for just functionality but also for security, right? And if you have an issue you're very easily able to understand what did I change, what do I need to look at and get that context? So now we're in production and now that's not the end. We have to actually support what we have in production, making sure that it's a good experience for our product, our users, our protocol. And so here making sure that you have monitoring, logging and alerting and what I mean by that is for monitoring you often get kind of the base like CPU usage, memory usage for free from cloud providers or other systems. But understanding and having a picture of what's happening on my machines, do I have custom emitted events for my smart contract that I'm able to look at and aggregate and see are there a bunch of users onboarding the platform, is everything looking normal? Being able to understand that having that data is really important both from like a product perspective, but then we'll see from security logging understanding both happy path, unhappy path, business logic, specific understanding of exactly what code paths are. Triggering when, how often, and being able to basically have all that data because you need both these inputs to really have a strong incident response and alerting program. And what I mean by that is that you should be able to take these events, whether it's through monitoring stats or logging, and be able to trigger alerts that your team has again, a checklist or a runbook on.
00:46:43.694 - 00:47:21.600, Speaker A: How to triage take in these alerts, how to start with a diagnosis process, if there's anything in terms of just security and how to think about that. But then a tight response loop of we see these logs, we see these monitors, we see this alert. Do we need to then roll back? Do the circuit breaker take any action, roll forward. But having that in place, that you're not caught blind and you're not finding out however many days, hours, weeks later that you've been potentially hacked, and then having to figure that out post facto and so really important that you have this continued support even though you've pushed to pride and life is great, the story doesn't end there.
00:47:24.050 - 00:48:50.346, Speaker B: So we kind of saw the four kind of main steps along the way but that's not it, right? As we mentioned, this process is not going to happen once, it's not going to happen twice, it's going to happen many times. Everyone here is going to go on to build amazing things and so you need to make sure that you keep designing and shipping great features safely, right? Like this is very much kind of like an iteration and this framework is really here to help you kind of think about security throughout all the steps but also throughout all the multiple iterations of the company. So we're back to zero every single time for every single iteration. And that's great, right? Because that really means that your system will actually apply the same verifications over the multiple layers of the defense in depth for everything that you push, everything that you design, everything that you test. Kind of like always having those things as systemized as possible. The last word here. We really want everyone here to kind of keep in mind quite a few things and takeaways that you get to apply as early as today or yesterday really is.
00:48:50.346 - 00:50:09.700, Speaker B: So first and foremost, security threats are not just bugs in the code, right? It comes from all the angles where we talked about corporate security, operational security, product security, front end security, back and security, product key management, you name it, right? There are all of these things that you have to be extremely intentional and conscious about whenever you think about building them and making those decisions but also kind of checks and balances to ensure that all those things are done securely. So therefore make sure that you think about security holistically rather than a checklist item. The worst thing that you can do is thinking about the security. Like boom, I checked the box, I can essentially move on to the next thing. No, it needs to be very intentional and thought through from the get go. So as part of that automation, as much as you can automate and just add as part of well defined processes that you go through every single time with the team or let your systems do that, it's very important to kind of keep that do the work so that you can go on and focus on building other things. And of course, we talked about secure design.
00:50:09.700 - 00:51:06.354, Speaker B: We see a lot of unit testing. I think that integration testing was probably the thing that we saw lacking the most in general whenever looking at systems. So really make sure that you have a system that really tests things out as if it was production with the same code, the same state, everything the same and treat it just like it was in production, right? That's really the bar that you should have for essentially building in web3. And so this is really a marathon, right? That's not a sprint. You'll get to really add things over time but just start thinking about it from today. This is the right moment to really be extremely conscious about security and really have it scale within your product, within your corporate environment, but also your culture and your DNA as a company. So, thank you so much and very excited to answer any question either.
00:51:06.472 - 00:51:26.586, Speaker C: Thank you both for the talk. Really incredible two questions. First one is on the topic of circuit breakers. You touched on a lot of different functions that are pretty important. So pause functions, things like that. What's your take on how to balance that with decentralization and not going back on commitments to users about software that you've deployed? Because of course, these are all processes that you may need to change code or deploy new contracts for.
00:51:26.688 - 00:52:28.414, Speaker B: Yeah, I think that on the ones that we mentioned, when you think about kind of whether that's timelocks, whether that's kind of like governance proposals, having a baking time, all of those things work really well hand in hand with essentially kind of like decentralized systems. I would say that probably kind of like the pausing is probably the thing that is something that you need to think about from kind of like an automated perspective. Like if you can automate the pausing based on several factors, whether that's too many transactions, just too much volume flowing through per unit of time, you kind of define those things. But I'm pretty sure that in general, the community will be very excited about making trade offs there so long as it keeps things as secure as possible. And you prove really well that you cannot DDoS essentially the protocol through kind of like malfunctioning of those multisig here is your friend.
00:52:28.452 - 00:52:52.820, Speaker A: So you have to decide what is most sensitive versus what can be automated. But multisig is a way for you to say we're still decentralized to this degree, as if same with deploying a contract. So there's no one size fits all on how you set that up or what is multisig versus not. But you can think through what can be automated versus what's multisig and how big the multi SIG should be both for response time, training off with security.
00:52:53.190 - 00:53:15.742, Speaker C: Got it. Second question really quick, as people that live in brief security and been around this for a while, of course, if you get burned by any of these hacks or things like you care about security, like if you're just a company, even if you have nothing to do, if security is your main focus. But how do you guys sort of pitch all of these things to audiences that maybe don't have this as priority number one? Because a lot of this is like if you get burned retroactively, you're going to care about it. So if you've never been burned well.
00:53:15.796 - 00:54:09.760, Speaker B: I feel like we've done the full Rudy on this. I think that at the end of the day, you need to make security a core part of the proposal of the value prop, right. Like security should be a feature of the product rather than kind of like the checkbox. If you can advertise it, leverage it, and kind of like a lot of people are going to Bitcoin because, among other things, it's also extremely secure, have been extremely thoroughly reviewed and many other things that were done as part of the development of Bitcoin. And so I do think that to a certain extent, it's really on people in this team to understand how to make the security narrative work for them. Right? Like you're going to do it probably anyway, so you may as well just make it work towards kind of like the value proposition of whatever it is that you're building.
00:54:10.450 - 00:54:53.758, Speaker A: I think there's also like you're going to have external pressure anyway, whether it's community or regulators. That's one piece and then there's the internal piece of beyond that, what is your security culture and what you think makes sense at different stages. And the way that we often think about it too, and from doing a lot of custody is thinking about security as economics and how much money would it take to hack our system and how much money then should we invest in security? And thinking about that's another framework you can use to just think through how because you're not going to go full overboard. Like we're going to put everything in the Swiss Alps for this thing at startup stage, but thinking through that and thinking through the path and being one step ahead of attackers as you grow, okay, we're getting bigger. We need to up our security game because this is what we've thought through of them as a model.
00:54:53.844 - 00:55:18.710, Speaker B: Yeah, I think that the unique challenge here is probably kind of it's very easy to kind of see the chart of whatever value your product and your company is protecting quickly rise. Right. So this is why the piece of staying one step ahead is always critical because you should still kind of hedge on anticipating such growth, essentially, of kind of the value that you're protecting.
00:55:19.130 - 00:55:44.106, Speaker D: I have a question around some of these Phishing attack cases like the Ronan Bridge. So that attack was initiated through Phishing. And I'm wondering what are your recommendations as far as some preventative measures for phishing attacks? Is it better employee training and compliance? Is it anti malware software on computers? What do you think is a good way to prevent these types of attacks?
00:55:44.138 - 00:56:26.406, Speaker A: It's a good question. I think the way I think about it is just thinking about the layers and defense and depth and so there's practical steps along all what you just mentioned. So from the get go, from your email, other point services, what kind of scanning do you have in place? What kind of protections do you have in place? So for example, Gmail has advanced phishing scanning. There's other companies that you can add on as well to do that. That's one touch point. I think the other broader touch point is you should model the system, or at least we would in the kind of a security custody system as well. Is thinking about what happens if kind of change the framing of phishing is like what would happen if your laptop was open or your employee's laptop was open in the office, someone grabbed it and they had the laptop.
00:56:26.406 - 00:57:01.334, Speaker A: What could they do or what could they not do with the laptop alone? And thinking of it as like, okay, imagine we're already hacked what's possible or not possible and for what is possible are there things we can put in place? Whether it's additional layers of control with multisigs or other ways, we architect the system to limit the blast radius of that from happening. So often too in a common audit, security audit test will be you give the auditor employee laptop and say have fun, tell me what you can find. But that's another way to just think about it. And beyond the initial layer of defense, what do you have behind the point.
00:57:01.372 - 00:57:46.854, Speaker E: That you made on basically Web Three having these expanded protections and essentially being even harder to secure compared to Web Two? I think that was really salient given that fact. I have kind of like kind of two questions. One is the biggest companies in Web Three say your open seas, your uniswaps, kind of how far are they on the curve for adoption of kind of enterprise security solutions? Are they already using things like okta, mobile device management and things like that? And then kind of the second part of the question is it's basically what are the design choices, the different design choices that these web Three companies have to make given that it is like an increased security risk compared to Web Two?
00:57:46.972 - 00:59:17.250, Speaker B: Yeah, that's a great question. So we actually work pretty closely with Corey and the team at Ad Openc, for example, and other companies. Not to kind of like reveal too much about the set of things, but the web3 companies understand really well. And we used to have kind of like constant conversation with them to just ensure that the path between again, kind of the economics of what they protect and the responsibilities and what they have in place always kind of follows the same line right on the graph. And so a lot of work is being done by teams obviously kind of like everything in place, whether that's device management, whether that's intrusion detection kind of like already incident response kind of relationship already established with the best companies in the space so that if anything happens, getting already being ready, right? Because as I mentioned, I think that's something that also people here should take into account as kind of like the growth kicks in. Make sure that you already have a relationship established with an incident response team because those incident response companies, it takes a lot of time. If you don't have the right relationship with the CISO of the right people internally it actually takes time to get in touch with them, establish the contract and kind of get moving on the attack.
00:59:17.250 - 01:00:12.980, Speaker B: And again, as I mentioned, the time is working against you, right? You don't have time to send an email, a LinkedIn message, wait for the person to answer, none of that. Right? So trying to kind of get ahead and already have those relationship established early on is pretty important. So just wanted to put that there because that's something that kind of came up pretty often and so yeah, I think that there's a spectrum, obviously. I think that it's fairly hard oftentimes for companies in web3 to understand at which step of the journey they are and I think that this is just good to have those conversations so that you understand that it's actually generally a lot earlier than what it seems. Right. But overall I have seen great people building great complex security features within the entire 60 portfolio for sure.
01:00:13.430 - 01:00:44.070, Speaker F: I wanted to ask about testing and kind of like since college CS classes, professors would be like test your code, write your test cases and people don't listen. And now with developers there's a trade off between creativity and putting them under pressure and you have to write these codes. So just thinking about that, what's best practices to ensure your engineers are on it and are you still using it as a creative process? Is automation the key here? What's your guys'thoughts there?
01:00:44.160 - 01:01:31.174, Speaker A: Good question. I think part of it is cultural and setting the tone of we expect whenever you put up a pull request this is the bar we accept as a company or whatever. And that bar you set a foundation and can have that scale without you having to police and kind of check in on it and whether that's like having always mandatory code reviews by certain code owners. Having a certain code coverage is kind of one of those things that it doesn't tell the full story because you can just write not so great tests and still have great coverage. But there's other kind of ways to try to encode that. But certainly making and thinking about. Security as part of that build development to testing as part of the process and just embedding it as much as you can is a way to just get things started and then over time you can add more as you grow in that case.
01:01:31.174 - 01:01:44.698, Speaker A: But certainly I personally advocate for always having testing along with a feature because does it work both from a correctness but also where you're dealing with tokens or other value, it becomes a security concern as well.
01:01:44.804 - 01:02:20.666, Speaker B: Yeah. By the way, on the code coverage, I think that a lot of people oftentimes people just think about it from code coverage during unit testing. Make sure that you also add that for integration testing. Right. You also want to make sure that your integration testings really cover a lot of the path that your code takes and more broadly really fully agree. I think that it's oftentimes just more cultural. I do have to agree that the kind of software infrastructure and kind of like tooling that is available within Web Three on the integration testing side is probably a lot weaker than where it should be.
01:02:20.666 - 01:02:46.930, Speaker B: So I think that's as a space something that we need to do a much better job at, but there is still kind of a lot being done there and really kind of like the culture pieces doesn't really rely on kind of like front end work that you might be doing back end anything really. It's really just all encompassing and really will scale well across the entire company as you grow, as you go in different directions and kind of build different components.
01:02:49.050 - 01:03:29.540, Speaker G: I honestly have like 1000 questions but I'll try to keep it to just a couple. One is like you mentioned how you want to make sure only audited code makes it onto main net. And I've been trying to talk to a bunch of teams and it seems like there's not like a consistent way that people are tracking what are their devs deploying. There's a lot of different process around that. Have you seen any useful tools or approaches people have used to, one, know what all the contracts their dev team is deploying to production and also is there any tooling that helps with tracking what's been audited, what hasn't and making sure only audited code makes it there?
01:03:30.390 - 01:04:30.214, Speaker B: That's a great question. I think that so far in the space I've mostly seen that being manual, all the contracts might be referenced, and whether that's Immunify or other platforms, it kind of just lays down like, hey, here are all the things that you can kind of go ahead and have a bug bunny on, or just all the things that have been reviewed. I haven't seen kind of something that really kind of almost like source graph style just gives you like this thing was part of the code and this thing has changed since then. I think that I haven't seen that happen or being built so that would help certainly especially for just decentralized communities to look at it and just very quickly understand like okay, that was part of it. We can have limit even from a financial perspective. Right. You don't want to go over the same thing again and again necessarily if the entire component didn't change.
01:04:30.214 - 01:05:07.810, Speaker B: But there might be obviously side effects, which is one of the reasons why oftentimes people tend to just re review everything. There are interactions that you may not have thought about. For example, the no meta hack was like an interesting run, right. The vast majority of the protocol didn't change. Just like the code that interprets some already existing state changed and so this actually created the issue. So I wouldn't say that it's because you already have something that tells you hey, this is everything that has been reviewed that you should necessarily have too much confidence about it because of these kind of side effects.
01:05:08.230 - 01:05:37.466, Speaker G: Thank you. Just one more question is around the monitoring. Have you seen how people are making possible contracts or other ways to kind of put the brakes on when they manually detect something is wrong or they find out something is wrong. But have you seen from some companies we've talked to, they seem a little bit cautious on making it so that say like monitoring detects an anomaly and then it can maybe pause their contract or something like that.
01:05:37.488 - 01:05:43.146, Speaker B: Have you you mean the automation? So essentially kind of like yeah, yeah.
01:05:43.248 - 01:06:11.320, Speaker G: Because we were looking at stuff like Forta and others and I think one challenge they've been having know they have all this alerts and they know they detected like an hour ago that something's been hacked. But it seems companies are somewhat cautious around taking that and then actually connecting it into the contract. Have you seen anybody one actually implement where monitoring can pause their contract? And do you think that's something that can even happen in the future?
01:06:12.090 - 01:06:14.674, Speaker B: There's kind of like the liability piece that is also tricky.
01:06:14.722 - 01:06:50.274, Speaker A: Yeah, I think also from just a it depends on the protocol too. We talked about decentralized. How decentralized is it versus automated? There's no one size fits all here. Off top of my head, I don't know if I have any examples of who's been automating it, but it's certainly like in my mind too, there's the pause and then there's also the resume and there's ways to play with this one can be automated. This one has like a multi SIG. How big is the multi SIG? There's a lot of variables there and so I think there's not going to be a one size fits all. I haven't at least seen a pattern yet, but I think it's interesting question and worth watching.
01:06:50.392 - 01:07:22.560, Speaker B: Yeah, and it's mostly also because there is no one size. I think that if you want to pause that means that you need to expose essentially the mechanism right. And kind of have some form of agreement and consensus around who should be able to call this thing. And I don't think that a lot of companies would want to kind of carry the liability there. Even if they don't have access to the resume kind of piece, it's still kind of like a liability. I'm not too sure. I don't think I've seen that happen.
01:07:22.560 - 01:07:52.562, Speaker B: Yeah. The other piece that is hard there is that oftentimes a lot of companies understand that a lot of the attacks are kind of like single transaction. Right. And so sometimes it's just hard in nature to kind of detect things because it's not like you're going to have many opportunities to kind of learn what the attack is going to look like. So? Yeah. I don't know. All right, awesome.
01:07:52.562 - 01:07:55.700, Speaker B: Well, thank you so much, Nasmiraz. I appreciate it.

00:00:13.130 - 00:01:12.160, Speaker A: I'm Jonathan Doton, and it's great to be here. For six seasons, I had the incredible opportunity to have some therapy, to sit there in a room with the funniest people that I'd ever met in my life, and to create a television show called Silicon Valley that in many ways reflected pieces of my own journey. Working in tech, working in media. But as I think we'll discuss today, it embodied a set of larger ideas around what it means to be a founder, especially now. What I want to cover with you today is a little bit about that journey. And it was quite uncanny in the sense that what I was originally asked to do when I joined the show was to write all of the technical dialogue. So anything that sounded accurate or that needed to be convincing to Silicon Valley, well, it was formed out to me, and then I went out to a group of about 200 consultants that, on any given season, would help us get to the finite detail about what it meant to actually create the type of technology that we were showcasing on the show.
00:01:12.160 - 00:02:28.738, Speaker A: But in the first episode of every season, we would write scenes like similar to the one that you saw there. What we would do is we'd focus in on the stakes. Why did all of this matter? And what became initially a set of questions around how we could create a plot for a show very quickly bubbled up into something that history kind of caught up with us. And we started to understand that, well, we had a deeply political show, actually, that it was starting to address some of the key questions around the centralization of power and the flow of information, and even the questions around how would the Internet survive. And over time, what we started to understand was that the elders who had created the Internet as we know it, they were starting to recognize that something was terribly amiss. And so as our show started to deal with these plot points, we also started to recognize that there were some great solutions that were out there. And I found my way over to the Internet Archive in 2018 and sat down with founders, some of whom are here, to talk about what a vision might be for the future of the Internet that was restoring its original architecture as a decentralized Internet.
00:02:28.738 - 00:03:12.294, Speaker A: And so we spent time together talking about all these things. And heading into season six, I started to recognize that actually this might actually be possible. And it changed me. And as season six rolled around, I started to recognize that I wanted to also fight for something like this, and that the show could be an incredible platform to start a conversation. But knowing that likely that was our last season, I said, well, what am I going to do so. As we started writing the last season of the show, I picked up another access badge over to Stanford, where Dan Bonet gave me the opportunity to join the center for blockchain Research. And together we created a starling lab.
00:03:12.294 - 00:04:11.850, Speaker A: And the idea was to think about how we could use a variety of different cryptographic tools to help authenticate records that were vulnerable, specifically records around human rights. So we began by creating a framework, and that what we said was that at each step of the information gathering process, as you capture, store and verify information, all of those steps were actually quite vulnerable. And all of them could be strengthened by the use of various forms of cryptography. So we set out to create some iconic examples to illustrate to people the vast power of the technology. We began by working with the USC showa Foundation to take the visual history archive, which has 55,000 testimonies of the survivors of genocide. It's about five petabytes worth of data, and we made it content addressable. We gave it a CID, and then we started to put it onto decentralized networks, first ipfs, filecoin storage onwards.
00:04:11.850 - 00:05:05.558, Speaker A: And we started to recognize that there was actually something very powerful because we could instantiate here a new form of archive, one that was actually stronger because it was decentralized, one that actually could retain its integrity because it was decentralized. And that was very moving because we started to understand that this was a new form of engagement and participation. So historians that we started to work with, they understood this, actually, they understood the reasons for this type of redundancy. They also were on the cusp of understanding that with shallow fakes and then deep fakes, that preserving these types of records would be increasingly difficult. So we continued and we started to develop an array of different prototypes. And I want to quickly go through some of the highlights. We moved on as the George Floyd protest were to actually take the oral histories of photographers who sat there and for the first time were being able to confront systemic racism in the newsroom.
00:05:05.558 - 00:05:49.262, Speaker A: All of that certified, notarized, put on chain. We worked with Reuters to take a new cryptographic pipeline into the field, where we actually worked to establish ways of notarizing photos directly in the field, coming right off of the cameras, and then creating a whole information supply chain that went from the field to the newsroom to the end user. Worked with Adobe to develop a new set of standards on that. And so what we were able to do is not only create cryptographic hashes and registrations of the information, but then take that information and inject it directly into the metadata of the file. So you had this portable object that had not only a marker of its own information, but also its own authenticity. So there you go right there. You have links back to the onchain references.
00:05:49.262 - 00:07:35.014, Speaker A: We continued through that process of piloting into the late summer, and then every photograph that was taken from the election all the way to the inauguration, including January 6, was put through this pipeline, all of it cryptographically registered. We moved on to Syria. There we worked with war crimes prosecutors to start to take evidence that was collected by civilians in a highly chaotic disinformation environment, to figure out ways in which we could preserve critical evidence for a form of warfare that at this point has continued with impunity and likely will not get justice in the near term. So how can we preserve that information, preserve its integrity? Sadly, that work prepared us for our work in Ukraine, where we started to take very vulnerable forms of ephemeral content, such as telegram posts, and find ways to put it into something like this. A cryptographic equivalent of an evidence bag, where you could take that digital information, put it inside the bag, establish critical metadata in an immutable way, create a chain of custody that could take it all the way from the researchers and the investigators to the point in which it could actually be self authenticating in a court of law that we developed with a whole framework that allowed us to sit with a team of lawyers, and we actually submitted a dossier that had evidence of war crimes that were accounted for in Kharkiv, Ukraine's second largest city. But we included in that a dossier that also had all of the cryptography to back up all of the documents that we had found, and we submitted it as part of an article 15 submission. It was the first cryptographic dossier ever submitted to the ICC that continued with additional work that we've been doing to actually bring jurists into the battlefield.
00:07:35.014 - 00:08:30.650, Speaker A: And so here we were, figuring out ways of actually taking content that is inherently synthetic, it's metaverse VR content. But how can we prove that it is authentic? How can we prove that it hasn't been manipulated to the point of distortion and make all of that admissible in court? Finally, we worked on this project here with Rolling Stone for a year. We developed an investigation to find out the identity of that individual. It's one of the most notorious photographs from the war in the Balkans. And on the eve of the 30th anniversary of the start of the war, we actually found him living modern day Serbia, living with impunity. And we were able to uncover new photographs that for the first time showed his face. But as we did that, we wanted to ensure, because this photograph has certainly been manipulated in any number of ways, that we were able to cryptographically preserve our entire process.
00:08:30.650 - 00:09:48.280, Speaker A: So as you read the article, every single photograph, every single piece of evidence that we brought forward in the investigation had within it an authentication certificate where we're able to use our framework and to cryptographically capture, store, and verify all of the information, put it on multiple chains. And we were able to do this in not just the photographs in the main article itself, but then we had an entire archive where we had hundreds of pages of documents and other forms of documentation. So, for example, something like this, a payroll record from serbian intelligence, we were able to not only establish its authenticity where we had found it online, but also we were able to use zero knowledge proofs that Dan Bonet developed with his students to ensure that we could redact information. So you see the black boxes there and prove that the only change that was made was this permissible change to protect people that didn't need to be named in this investigation, but prove all of that without, of course, revealing the underlying information. So this just gives you a sense of all the incredible things that we were able to do to then create a web of content that was able to link all these individuals together and take them from their relationships from 30 years ago into the present day. Using their social graphs, we were able to link all them together. They out in the open, because remember, if they're walking free, they were friends.
00:09:48.280 - 00:10:56.150, Speaker A: All of that then linked together from a pattern of violence that we found back from 30 years ago that even persisted into modern day Ukraine, where they were supporting new militias. All of this now registered on chain. Amazingly, at the end of the process, not only were able to release all of this information, but we were also able to get serbian prosecutors to now re examine the case, and hopefully there will finally be justice to the victims of this massacre. So I think what's important about all of this work is, yes, it's been a blur of work, but once again, history has caught up to us. There were so many newsrooms that I was not necessarily welcome in. People were saying, what? You're just sitting there using cryptographic technology? It's crypto, right? It's speculative. Right? What's the difference between you and all the other kind of casino crypto projects? And the prejudice there was challenging? What I can say is that finally the release of Chatcheept, the mainstreaming of AI, finally dawned.
00:10:56.150 - 00:11:39.414, Speaker A: On people to say, wait a second, how are we possibly going to be able to preserve historical records? How are we going to be able to admit things in a court of law, knowing that there's this drastic threat now to the authenticity of digital objects? This moment was a watershed moment in which people surged from a fundamental misunderstanding of the technology now into something else. I want to share with you a little bit about what I've been seeing. Think of these as postcards from the edge of AI. For last year, I've been working in Abu Dhabi to create a climate GPT model. We're training from the ground up. It's a 400 billion token model. And the question was, how could we actually get access to sufficient amount of compute and renewable energy? And we've been able to do it.
00:11:39.414 - 00:12:36.540, Speaker A: Actually, our genesis node for inference is going to be attached to Aldafra, which is going to be, as of, I believe this week, the largest single site solar array in the world. And we're creating a model that now is going to be trained in a way with renewable energy. And most importantly, collectively held. We're registering all of the attestations of the creation of this algorithm with cryptography, and also we're putting it in the custody of a DaO. It's going to be registered at the ADGM, completely legal. And this could potentially form the basis of a new form of public AI. The idea being that this is showing a way for us to coexist with AI, to be transparent, and most importantly, it's finding us a way to be able to showcase a new form of collective governance of this type of very powerful technology and potentially provide an alternative to, of course, centralized forms of control.
00:12:36.540 - 00:13:25.414, Speaker A: So the interesting thing is, like, what we are up against here is the designation of the very core technology that we are working with here. This is an h 100, which is the type of card that we would like to be training on. It's the most efficient out there. We actually can't get access to it outside of the United States because it's essentially considered a munition at this point by the commerce department. So the extinction event that we're trying to deal with, with a climate GBT, well, now, suddenly, actually, the dominant discourse is not about climate change in our case, it's going to be that we're going to have to prove to people somehow that AI itself is not an extinction event. And more importantly, that open AI, like truly open AI, open source AI, is somehow not the extinction event that everyone seems to be claiming. The dominant narrative is that this type of technology needs to be controlled the same way as a nuclear weapon.
00:13:25.414 - 00:15:06.940, Speaker A: And when I think a little bit about who is calling for this type of thing, what are the dominant voices that are trying to establish this form of regulation? My point is not that the regulation is problematic, or the discussion about regulation is problematic, but it's to ask, maybe, like the show, who's got an interest in ensuring that only they could be the arbiters of what's good and what's bad? I think there is a lot to be concerned about the emergence of a new AI digital divide. And if we're going to combat it, we need to be very careful about how a closed source AI could expose us to any number of these types of risks. And my question for the people here is that, asking, can we possibly have a better story of the types of things that you create here in this room? Could it actually create the basis for a new way for us to establish trust? And I can tell you, in dealing with all of the human rights activists, that they need help. And I found it particularly ironic that three weeks ago, the world's leaders convened at Lechley park to talk about trust and safety in AI. And how in the world could they not look at the important primitives that were created there, modern cryptography that saved us from the jaws of centralized fascist power. How is that possibly not on the table as one of the key elements for how to be able to establish secure, trusted, confidential, open AI? So we have to work hard. There are people here in this room that have incredible technology that can ensure that we have the right types of discussions, that we avoid, the types of false choices that are being presented by powers that don't necessarily have the Internet at a whole in its best interest.
00:15:06.940 - 00:15:43.400, Speaker A: And I think we need to end the illusion of this kind of powerlessness and the nihilism, and to say what we truly have is not a crisis of safety. We have a crisis of trust, and we need to form a new basis for that. So I'm excited with all the people that I've been working with, all the different projects around the years, to say, can we possibly ground this conversation in a new approach and in a new challenge for web3? Because I believe the most important challenge that web3 has ever had has just begun. Thank you.

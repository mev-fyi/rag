00:00:07.710 - 00:00:08.260, Speaker A: You.
00:00:10.310 - 00:00:42.380, Speaker B: Okay, so welcome to day two. So just quick reminder of the agenda for today. We're going to have basically 1 hour for group discussions. We're going to split into three groups. There were three questions that we introduced yesterday. So each group is going to work on one of these questions and then we'll come together at the end of the hour and have hear from someone from each group for ten minutes. So let's try to solve these problems.
00:00:42.380 - 00:02:31.870, Speaker B: Okay, so just reminder of what the questions are so that you can decide which group you want to be a part of. So the first question is about revenue sharing and specifically this question of if you have multiple roll ups or users or applications which are contributing to the mev of the blockchain, then how do you figure out what each participant's marginal contribution to mev is? Is that discoverable? Is it discoverable if you're also going to then give a rebate to each of these applications roll ups users based on their marginal contribution? So that was the first question. The second question was about and remember, for this question it's specifically focused on because this question has appeared in multiple contexts. As I mentioned, it's connected to user to order flow auctions. But specifically the problem here is we're looking at if roll ups were to run their own chain, then they would be generating some profit from mev. And if they're now going to be sharing a common chain for sequencing, they want to be convinced that they're going to be making at least the same profit as if they were running their own chain, right? So the question is comparing these two different worlds where each roll up is running its own auction. I had this comparison here with the searchers versus giving their order flow to a sequencing layer and then having the sequencing layer run the auction for them with the searchers and then give them rebates.
00:02:31.870 - 00:03:01.110, Speaker B: The second problem is about mev mechanism independence. So different roll ups may have different approaches to mev. Some want to run auctions to try to optimize and democratize the distribution or use it for funding of public goods. Others want to prevent it entirely. Some favor a first come, first serve ordering policy. Some favor some content oblivious policy. Some may favor a random ordering policy.
00:03:01.110 - 00:04:32.050, Speaker B: Who knows, right? The question here is to what degree can a shared sequencing layer be agnostic to these different approaches and simultaneously support roll ups that can choose their own ordering policies? And also caveats of that, right? If we did have a sequencing layer, which does that, what are the trade offs? Does it impact interoperability? And finally, there's a question of how a sequencing layer that is not executing for each roll up should charge for transactions. So one challenge here is that because it's not executing on each roll up, it doesn't necessarily have the ability to charge based on the gas consumed by transactions because in order to check how much gas transaction is consuming, you have to execute it in general. So it could be charging just based on the size of data. But again, now everything that gets sequenced has to be then executed by the execution layer. That's the whole idea here. The execution layer can't choose what to execute and whatnot otherwise it would have the power of deciding what gets included rather than the sequencing layer. So how should transaction fee mechanisms work with shared sequencing layers? There's another question of how the sequencing layer verifies the correctness of this fees that could be an independent roll up, some minimal state that's just being used for fees, but that also could create a UX challenge where users now have to pay in two different currencies.
00:04:32.050 - 00:04:52.620, Speaker B: So there's a question of how to deal with that. Great. So those are the three problems and we're going to split up into three groups. I think one is going to be in here and then two are going to be in conference rooms. I think the one in here is the only one that's going to be recorded. So see everyone at the hour.
00:04:53.550 - 00:05:58.478, Speaker C: I think there's like two different problems, both of which are really hard here. One is even just to know what the mev is. So first of all, at the level of the shared sequencer, like when you combine everything, how much mev is there and then maybe even more hard to understand how you'd ever know what it is, is the counterfactual. If a roll up ran on its own, what would the MEB would get if it was standalone? So question one, I view is just like elicitation, like how do you even find out what these numbers are? Question two, which is completely separate, is like suppose magically you knew all of these numbers, how would you do the distribution? That's maybe the easier problem. I kind of feel like that starts connecting to the stuff Quintess talked about yesterday around Shapley value and that kind of thing and there's not going to be any perfect solution, but I think there at least you probably get a handle on different trade offs if you actually knew the know. I feel like it's good to just like whenever we're working on something to be clear in our minds which of the two things we're trying to tackle because they're both, I think, pretty hard problems.
00:05:58.644 - 00:06:15.880, Speaker A: So if you had a trusted shared sequencer and the searchers just put in bids for bundles of transactions and there was kind of like a bid for each individual transaction in the bundle, seems like that would be a starting point.
00:06:16.730 - 00:06:25.100, Speaker C: For figuring out what would have happened in the standalone roll up like a lower bound on how well it would have done. So you're saying users at least are.
00:06:26.510 - 00:06:35.500, Speaker A: Well, if there's a competitive market for searchers, then you should, I see, get some sense of how much each individual transaction is adding to the value.
00:06:40.530 - 00:06:43.586, Speaker C: So does it be listed at the shared sequencer level or for an individual.
00:06:43.688 - 00:06:48.578, Speaker A: Roll up at the shared sequencer level? Right, that makes sense.
00:06:48.744 - 00:06:52.146, Speaker C: I agree, because you could always have.
00:06:52.168 - 00:07:05.580, Speaker A: Like bids for just an individual transaction at one roll up. And if there's a higher bid to include it as part of some cross roll up bundle, then that's a signal about how much mev is being added by this sort.
00:07:06.030 - 00:07:24.350, Speaker D: So can you really differentiate mev per transaction nore because it's not often that this one transaction is causing that mev and sometimes it's the case, but sometimes it's like you need two other transactions in order to actually extract that correctly.
00:07:25.970 - 00:08:14.286, Speaker C: I think there's another good point that how much mev is generated by the interaction between transactions as opposed to just like but if you think about the order flow auction vision, the way I hear about it, it's often like a transaction has some mev and then the ofa is designed to elicit what that is. That's sort of what you were saying, Joe. And then know there's actually like a ton of extra mev maybe that's generated if you take different transactions and assemble them in just the right magical way. And that, again, seems like a harder version of the problem. So I sort of agree with Joe's suggestion that just like maybe it's not true. But to get started, let's just imagine the transactions kind of have their own well defined what we then what could we do? And then you can worry about sort of complex interactions. That would be my.
00:08:14.388 - 00:08:25.426, Speaker A: Maybe the market would fail for some reason. But you could start with the assumption that you figure out the individual mev because that some searcher will put in a bid for just a bundle of.
00:08:25.448 - 00:08:26.734, Speaker C: One transaction of one transaction.
00:08:26.782 - 00:08:27.380, Speaker A: Right.
00:08:29.350 - 00:08:43.942, Speaker C: You could imagine say there's like three different searchers and they each tell you kind of the standalone mev of three different transactions. But maybe then a builder is like, oh, if I sequence them B and then the bundles B and then A and then C, I'm going to get all this extra stuff for myself. Right.
00:08:44.076 - 00:08:58.350, Speaker A: Some searchers see that too and put in a bid and say, like, if I can run A, B and C, I'm willing to bid like X, Y and Z for each of them. And if there's a competitive market that should sort of they should bid the entire surplus out.
00:08:58.420 - 00:09:04.874, Speaker C: Yeah, this is a great question. Maybe I think it's a good unless.
00:09:04.922 - 00:09:06.480, Speaker A: They have some alpha, right?
00:09:06.930 - 00:09:36.242, Speaker C: Well, no, there's something else which is also hard, right? Which is just that if you auction off transactions separately, the amount of information you're getting total, like if it's N transactions, you're getting N numbers back as far as the transactions. Whereas if you actually have these interactions, there's kind of like N factorial different outcomes. You might want information about. So there's inherent information loss if you only ask people about transactions separately.
00:09:36.306 - 00:09:36.486, Speaker A: Yeah.
00:09:36.508 - 00:09:40.966, Speaker C: I mean, I was thinking you might hope that in a competitive market, they sort of figure out how to bid in a smart way and extract most of it.
00:09:40.988 - 00:09:44.242, Speaker A: Maybe I was thinking people could put in bids for any set of transactions.
00:09:44.306 - 00:09:44.854, Speaker C: Oh, I see.
00:09:44.892 - 00:09:48.000, Speaker A: Yeah. Then you do get into this exponential flow up.
00:09:48.530 - 00:10:12.226, Speaker D: I'm wondering if there's a similarity between a problem of thinking about mev for one domain, another domain versus a combined domain, versus the problem of thinking about mev for one transaction, another transaction, and the combination of the transactions if there's some similarity there. Because you could make the same argument, like we're trying to solve a problem of whether it's mev from this domain or this domain or this roll up.
00:10:12.248 - 00:10:12.974, Speaker E: Or this roll up.
00:10:13.032 - 00:10:21.506, Speaker D: But I think a similar problem that we haven't first solved at all is like the MEB for this yeah, just restrict to one domain.
00:10:21.538 - 00:10:25.078, Speaker A: I don't see how the cross domain changes the economic picture.
00:10:25.174 - 00:10:40.298, Speaker D: I think it should be pretty much the same problem to figure out, like, did the mev come from this transaction or this transaction within the same domain itself? Because I think it's kind of the same problem and that itself might doesn't.
00:10:40.314 - 00:11:13.814, Speaker E: That assume some normal distribution of alpha or surplus, which is not the way we'd see it. A uniswap roll up would be 95% of the MEB in the current context. And you would say, if I'm a sequencer and I know that that sequencer uniswap versus like, a payments chain, you're probably going to have the shared state that wants to be near each other with all the mev on one roll up and then the cross domain, the distribution is unlikely to be nice and uniform. It's going to be very concentrated around hotspots of state convention, all that stuff.
00:11:13.852 - 00:11:14.374, Speaker A: Yeah, it's fine.
00:11:14.412 - 00:11:43.154, Speaker D: I mean, you can make the same argument for uniswap transactions versus transactions from some other contract on one domain itself. There's some mev that comes about just from extracting uniswap transactions themselves, and then there's some mev that corresponds to maybe like pulling transactions from some other contract, maybe like a flash loan contract or like an Huawei or something like that, and the combined mev from both of those contracts. So I think it's kind of a similar problem.
00:11:43.272 - 00:11:57.974, Speaker A: I guess you are adding a third entity because there's the users who submit the transactions and then there's this shared sequencer plus the roll ups that sit on top of the shared sequencer. So you do have to split the pie with a third party in this.
00:11:58.012 - 00:12:00.950, Speaker D: Case, right, with the sequencer shared.
00:12:02.490 - 00:12:20.586, Speaker A: Maybe these are the two separate questions. There's like how you split the mev between different transactions in a bundle that are dependent on each other in some way, and then how you split the total mev between the shared sequencer and all the constituent roll ups that are sort of providing more of like a flow over time of transactions.
00:12:20.698 - 00:12:25.870, Speaker C: Yes. If you imagine a world where the shared sequencer takes zero, then they sort of become sort of the same problem.
00:12:25.940 - 00:12:45.126, Speaker A: I think, right, sort of, except there's still the question of these individual roll up. Servers could sort of walk from the whole thing and say, I'm better off not being part of a shared sequencer, then I can capture all the mev. And you have to think about how much they should get over time so that they don't want to do that.
00:12:45.228 - 00:12:59.670, Speaker E: Yeah. There's a selection bias for what would want to be on the shared sequencer. In that selection bias, it's like, why am I using a shared sequencer? That would probably have some properties natural to the fact that we're in multiple domains. Right. That's why we're using the shared sequencer.
00:12:59.830 - 00:13:14.462, Speaker A: Presumably you're using the shared sequencer because you think it will grow your business overall. Right. Because more users will want to use your roll up if it's part of a shared sequencer because they can get better atomicity or bridging or whatever.
00:13:14.596 - 00:13:34.280, Speaker E: We know that there's maturation of these things that changes, right. When you launch uniswap with no liquidity. That's a very different, like, pre saturated uniswap versus post saturated is a very different why I would use a shared sequencer. Right. As these things mature, they have different properties and you start to see different infrastructure support.
00:13:35.050 - 00:13:54.794, Speaker A: Yeah, makes sense. I mean, I would think using a shared sequencer, you have to give something up, like some percentage of the total mev flow. But you're hoping the whole pie will be bigger by being part of the shared sequencer ecosystem and making some meta decision to stay with it.
00:13:54.832 - 00:13:54.986, Speaker E: Yeah.
00:13:55.008 - 00:14:19.778, Speaker C: And that's actually something I'm very curious about. Right. And we can tie it back to that. Back to the question of just, like, suppose you even knew the mev of people combined and what they would be separately, right? So, like, really simple two roll ups, each one could get, like, mev ten by themselves. Now, the question is, what's mev? If you put them together, right, if it was 20, that would be really simple. You just refund it like 50 50, right?
00:14:19.944 - 00:14:21.886, Speaker A: It should be like neutral about joining.
00:14:21.918 - 00:14:46.614, Speaker C: Yeah. Then they're like, indifferent. Now, if it's 30, right, then maybe the shared sequencer takes some and maybe they each get back more than ten and so they're sort of happy. But one thing I'm worried about is what if it's 15, right? Do we have a sense of that? Do we have a sense that it's always sort of synergies between people in the same sequencer? Is it clear that more is better always, or I'm not sure. Is it so super additive how it could be worse?
00:14:46.662 - 00:14:54.640, Speaker A: Because the worst case scenario is that there's no cross chain mev and then they should still have the same amount of separate mev, right?
00:14:55.490 - 00:15:02.720, Speaker C: Yeah. I don't know if it's too roll up. Maybe. Okay, maybe that would be a good sanity check.
00:15:03.110 - 00:15:13.714, Speaker E: Could it get worse if you change the properties of block times or something that has some interactive thing? Okay, we have to inherit the block time to get this network effect. Thus we have different MVP properties.
00:15:13.842 - 00:15:37.600, Speaker D: Could end up with like pathological edge cases where it would be different because if you do the state update on one chain first, then that kind of affects the second chain is using this one as like an oracle. And that's why the state gets updated on the second chain as well, which makes the mev there smaller when you're trying to execute that transaction later.
00:15:38.290 - 00:15:39.280, Speaker A: I see.
00:15:40.290 - 00:15:51.520, Speaker D: So basically doing both of them separately one after the other might not actually result in the sum of the mev, but that's kind of maybe a pathological case.
00:15:54.130 - 00:16:06.454, Speaker C: And then, Joan, on your point about the network effects, I'm actually just sort of coming out of Josh's presentation yesterday to me that could you imagine a world where people are using a shared sequencer just because they wanted a really lightweight launch of the roll up and.
00:16:06.492 - 00:16:18.614, Speaker E: See of an immature launch? You don't want to launch your own set of sequencers because you can't launch a centralized one single sequencer. And so you get a lot of immature things launching on the shared sequencer layer just from an ease of launch.
00:16:18.662 - 00:16:24.122, Speaker C: Perspective, among which there may be no network effects, among which it may just be purely additive, maybe kind of quality.
00:16:24.256 - 00:16:24.554, Speaker A: Okay.
00:16:24.592 - 00:16:40.994, Speaker E: And that's why we go through this maturation cycle. The properties of the shared sequencer should change like ethereum with no state versus ethereum with all the rich. State is a very different function. So you can see a winner take all dynamic in one of these shared sequencer networks. If it gets the place everyone wants to launch a marginal roll, it might.
00:16:41.032 - 00:16:46.530, Speaker A: Also give you some credibility when you're launching too, like it's a test food stack or whatever.
00:16:46.600 - 00:16:46.882, Speaker E: Yeah.
00:16:46.936 - 00:16:51.640, Speaker A: Also just like credible neutrality that you're not asking people to trust your own.
00:16:54.490 - 00:17:06.650, Speaker E: Economics of scale, which is the sequencers, because they have DevOps is fixed. Let's say that's a fixed cost and they're scaling that might make them more efficient, more higher uptime, better SLA style performance.
00:17:08.430 - 00:17:21.860, Speaker A: Maybe possible that you get more MEP out of being part of a shared ecosystem because the searcher market is better and more mature. They'll squeeze more out.
00:17:23.110 - 00:17:36.054, Speaker C: So what is the vision there? Like, if people had to guess, just suppose you have a shared sequencer with like 30 roll ups. Is the thinking that probably you would have a searcher that just looks across all of them at the same time or they'd be specialists. I have no idea.
00:17:36.252 - 00:18:00.734, Speaker E: You get like searching liquidity, which is if I have this pretty complicated cross chain arc and it's doing a solver whatever we're calling the searcher's algorithm to start to figure out what it's going to include. It needs more complex things to get these, like, nine roll up mev transactions. And that searcher liquidity might be where everyone, the transactions could have better get confirmed password, more likely, all that sort.
00:18:00.852 - 00:18:36.230, Speaker D: So one kind of potential counterpoint to your argument where you have new roll ups, sort of joint shared sequencing is the fees can potentially be higher because let's say there's limited processing power the shared sequencer has, and it's handling 30 different roll ups. What can happen is if a new roll up wants to do lower fees, then maybe those transactions don't get included when the shared sequencer is creating its sequence versus if they did their own roll up, they could probably give users much lower fees.
00:18:37.770 - 00:18:51.454, Speaker E: Yeah, it's a lifecycle question you got, which is early in the lifecycle. That's not a problem. Once we give saturated block space or saturated sequencer, then we would have to then we're full. What do we do now?
00:18:51.652 - 00:18:58.606, Speaker D: Yeah, like adding a new roll up to an already full sequencer, like shared sequencer is interesting.
00:18:58.708 - 00:19:06.034, Speaker E: You can see people giving out negative economics at first, like Uber to attract roll ups. Come build here. We'll basically sequence for free, right?
00:19:06.072 - 00:19:06.594, Speaker D: We don't care.
00:19:06.632 - 00:19:14.598, Speaker E: We'll give everything back to you such that we want to bootstrap our network effects to get these searcher liquidities and other things because it's worth it for us to pay.
00:19:14.684 - 00:19:17.846, Speaker F: At the beginning, it almost feels like.
00:19:17.868 - 00:19:26.126, Speaker A: Designing an optimal currency area. Well, there's this big question in economics.
00:19:26.178 - 00:19:28.490, Speaker G: I guess the first thing I've understood.
00:19:30.030 - 00:19:54.370, Speaker A: Well, you could probably explain it much better than me, but there's a question like should the EU keep adding members? Should all countries be on one currency? When is it better for a country, a small country, to have its own currency? And you have the opportunity to be part of network effects from being part of a much bigger currency area, but you give up local control. The monetary policy might not always be tuned to what you want specifically.
00:19:57.140 - 00:20:01.600, Speaker C: So any lessons from traditional economics we can take for that reasoning about these?
00:20:01.670 - 00:20:35.950, Speaker G: Well, one thing which is a little bit puzzled by, and that is are we assuming that there's multiple shared sequences or there's competition in this space? And then I think then kind of what you were saying is that that division will happen through the competitive process, right? So the people who are offering the flow will have some knowledge of what they can get on their own and the sequencers have some knowledge of.
00:20:38.000 - 00:20:38.316, Speaker E: The.
00:20:38.338 - 00:20:52.690, Speaker G: Economies of scale or whatever it happens to be. And they'll be willing then to pay. Right. And they'll pay each one of the potential inflows a different amount depending upon which has the most value. So that'll come out of the competitive process.
00:20:57.680 - 00:21:27.190, Speaker A: I think we're assuming there could be competition it's not clearly a winner take all market but it would probably be a small number. I think it would be like maybe the analogy is like airline alliances where there's like a couple and plus one or two independents probably, like you said, I think in that case they've hammered out some negotiation between every member airline and the alliance and they're probably all getting a slightly different take of everything.
00:21:31.670 - 00:21:31.986, Speaker B: Right?
00:21:32.008 - 00:22:10.240, Speaker G: So that's a good analogy in that the different airlines want to partner with an airline which fills in the gap that they have. Right? And presumably for these sequencers there's two things which are very similar and there's two things which are different and you want to get the things which are different in order to maximize the agglomeration benefits. Like if you have buyers and sellers then you want both of those, right, but you don't want all buyers or something like that.
00:22:12.530 - 00:22:13.774, Speaker A: On the other hand, if you're thinking.
00:22:13.812 - 00:22:27.490, Speaker E: About cross chain mev, you want the similar ones together. Right, because that's where the Arbitrage opportunities are. Like if you have two chains with AMMS, you want them on the same sequence here so people could efficiently arbor.
00:22:31.470 - 00:22:58.230, Speaker A: So that makes it sound like it might be a winner take all market then with the one caveat that I think in cryptocurrency space sometimes like natural winner take all markets, people don't want to appear like that. There's one big centralized piece so there might be some pressure for appearances to not seem like totally unified on one shared sequencer.
00:23:07.840 - 00:23:45.770, Speaker E: Yeah, we didn't talk about the returns to vertical integration saying like it's the same entity all the way through the stack and how much advantage does that give somebody? Again, we try to design these things so there is no advantage inherently so that you get no benefit from knowing things that no one else knows. But we've seen it in PBS a little bit. Some of these things are integrating and getting access to flow that other people aren't and because of that they can quote better, they have a cheaper rate on binance so they can quote tighter on their on chain, off chain ARB. Those are things that are naturally obvious when we're designing some of these things and they might.
00:23:50.780 - 00:23:57.630, Speaker C: So what caution should we have then thinking about the design from that? Like what are the lessons that we should take from that?
00:23:58.960 - 00:24:08.930, Speaker E: Because some of these things were emergent and not obvious I guess is the bigger thing. I think people were obviously aware that PBS would have some centralizing forces, obviously.
00:24:11.060 - 00:24:50.188, Speaker A: So I'll make a conjecture. We talked about the two different revenue split questions between individual transactions and between the roll ups. I think the first one needs to be solved algorithmically because that will happen like a million times an hour. Different transactions from different chains will be bundled together and you have to sort of split the fees or the MEB like rebate the second one might play out on a very slow timeline. I don't think that roll ups will switch between shared sequencing layers like multiple times a day or even like you.
00:24:50.274 - 00:24:53.200, Speaker C: Renegotiate your contract every couple of years or something like that.
00:24:53.350 - 00:25:09.380, Speaker A: I think that could be solved at like human level by negotiation around the table and everything. I suspect both ties will change very slowly. So you don't need some automated mechanism necessarily.
00:25:09.800 - 00:25:11.350, Speaker E: I guess we solved it.
00:25:11.960 - 00:25:21.192, Speaker A: Well, I was going to say it feels like we could still attack the first problem independently, which doesn't even have to do with shared sequencing necessarily delicitation or which part.
00:25:21.246 - 00:25:21.850, Speaker H: Yeah.
00:25:24.220 - 00:25:36.540, Speaker A: In the second part you could still try to come up with guidelines for like if you are the shared sequencer or the roll up in the negotiation, like what should you ask for, when should you decide you're better off independently?
00:25:40.170 - 00:25:44.440, Speaker C: Yeah, like you said, that's probably not programmatic, right? That's probably outside of that.
00:25:44.890 - 00:25:57.740, Speaker A: Well, you still might want to agree to some programmatic split though so that as your volume changes over time, your payout changes. Right. You probably won't just agree to some static amount per month.
00:25:58.110 - 00:25:58.570, Speaker C: Yeah.
00:25:58.640 - 00:26:09.886, Speaker E: The interesting thing is it's kind of like an information revealing game too, which is so let's assume that the people who are making this decision are the world Service providers and they say our contract is 5% and whether this is.
00:26:09.908 - 00:26:13.490, Speaker A: Public or not, although 5% of what? We still have to answer that question.
00:26:13.560 - 00:26:38.520, Speaker E: Right. And then I guess my point was more around the interactivity of the next person, say well, we'll do it for 2% or we'll do it for one. Right. A lot of these contracts, as far as I know, are done opaquely and people don't really actually know the competitive dynamics unless they're in a negotiation with private information. There's not like actual selective pressure on the fees there.
00:26:43.940 - 00:27:03.296, Speaker C: So Joe, you suggested as far as like 5% of what? So one initial stab would be like the sum of the winning searcher bids basically. Right. Then that gets pretty weird incentives for the shared sequencer to collude with searchers to keep those bids low. Right. So it's like how do you audit.
00:27:03.328 - 00:27:09.736, Speaker A: The not if a shared sequencer is also getting a tip percent of the same thing? Although maybe they have a case.
00:27:09.758 - 00:27:12.852, Speaker C: The worry would be they extract a lot off chain. That'd be the concern.
00:27:12.916 - 00:27:13.530, Speaker A: Right.
00:27:14.460 - 00:27:20.620, Speaker C: So there's a question of like auditability of the shared sequencers kind of overall revenue seems tricky.
00:27:22.720 - 00:27:30.444, Speaker A: I see. So you're saying they collude to have lower nominal bids that they're paid off.
00:27:30.642 - 00:27:32.396, Speaker C: There's like a sign agreement where they.
00:27:32.418 - 00:27:33.776, Speaker A: Sort of split the extra.
00:27:33.958 - 00:28:02.970, Speaker E: You need like a cr list basically to say this is what we expect, this is what we're seeing and this is the delta. That means that this person's polluting and not providing dYdX is working on this for their kind of like shared order books. Do you know how many they have? 20 nodes. They have like eight order books. They have to figure out is one node extracting a bunch of MPV. But to see that, they have to see some common order book.
00:28:04.700 - 00:28:25.740, Speaker F: But they also made some very weird design decisions, like only posting trades on all the ads and cancels are there. I can spoof isn't it the point spoofing MEB. That's like completely unrealized ever to the final reviewers and trades.
00:28:26.420 - 00:28:34.310, Speaker A: The dream of the intense model, though, is like, that you don't have to publish on chain all this stuff that's never matched or consummated or whatever.
00:28:36.280 - 00:28:45.256, Speaker F: Yeah, but if you're trying to get an audit trail for you definitely need to know something about just kind of.
00:28:45.278 - 00:28:48.090, Speaker A: Kills your efficiency, though. Ryan sure.
00:28:49.500 - 00:28:51.096, Speaker E: You are making that trade off.
00:28:51.198 - 00:29:02.220, Speaker F: There's probably something possibly either get comfortable efficiency up to some approximate thing where you completely lose. Yeah.
00:29:02.370 - 00:29:26.660, Speaker A: I suspect in practice people will go for the efficiency, rely on some trusted brand, which would make it even more winner take all. But if a shared sequencer has a brand where people trust that it's not colluding or it's giving a legit audit trail without it being on chain, isn't that how Flashbots basically works today?
00:29:27.990 - 00:29:37.350, Speaker F: Well, PBS, you have sort of an audit trail, in fact by accident because none of the builders have turned off.
00:29:37.420 - 00:29:38.040, Speaker E: The.
00:29:39.770 - 00:29:43.234, Speaker F: Historical data from all the auctions.
00:29:43.362 - 00:29:45.618, Speaker A: Which is kind of hilarious.
00:29:45.794 - 00:29:58.250, Speaker F: I think eventually they will someone will be like, okay, it's not hard to transform, but right now it's like social consensus on everyone broadcast the historical data of all the visit they've ever received forever.
00:29:58.670 - 00:30:00.620, Speaker A: How is that authenticated, though?
00:30:01.070 - 00:30:02.780, Speaker F: You don't have it on your team.
00:30:15.260 - 00:30:21.400, Speaker C: But you're saying taking those at face value, you could check that the highest bidder was the one that was selected.
00:30:22.140 - 00:30:41.170, Speaker F: You can also use that to see if people are subsidizing because you can see the amount they're remitted post auction and the auction price. You actually feel like all the small builders are paying subsidies right now, like pretty high subsidies, like 20%. So forget about 5%.
00:30:42.020 - 00:30:53.110, Speaker A: You could probably make that slightly better cryptographically if you committed to the full set. And then you could sort of prove individually to people that their bids were actually included. Right.
00:30:55.880 - 00:31:00.900, Speaker F: I feel like the latency aspect of this makes it very unlikely.
00:31:01.800 - 00:31:05.176, Speaker A: Well, you could do that as some post hoc auditing thing, right.
00:31:05.198 - 00:31:10.970, Speaker F: That's not yeah, right now that's what you could actually assuming you trust.
00:31:18.110 - 00:31:38.130, Speaker A: So if you're worried about this collusion problem or like accurate data reporting, though, I'm trying to think if you could solve that by changing what the 5% or what the take is actually computed over, like, is there some other signal that's harder for them, less incentive for them to manipulate?
00:31:39.750 - 00:31:48.130, Speaker E: Should there be competitive forces at some point, though? Like assume the searchers can pick from different shared sequencing. Layers. I guess you're saying that there's collusion.
00:31:48.210 - 00:31:52.642, Speaker F: Not the searchers would be in on this collusion.
00:31:52.786 - 00:31:57.590, Speaker C: The searchers and the sequencer would be taking the cut that should be going to the roll ups.
00:31:57.750 - 00:32:09.920, Speaker A: Basically, it's like a three party deal, right, between searchers roll ups and shared sequencer. And there might even be pressure on other pairings of two of those to collude. Right.
00:32:12.530 - 00:32:26.580, Speaker F: You do already see where the builders that are searchers definitely are shading their bids. This is what I'm saying. I don't know how long this will last. Probably another few weeks.
00:32:29.480 - 00:32:38.596, Speaker A: Is this like an inherent principle that anytime you have like three parties trying to split some pot, like two of them, any two of them are incentivized to collude?
00:32:38.708 - 00:32:46.324, Speaker C: There is a divide the dollar kind of example, which is just like a very cartoonish version of this. Three people try to split a dollar.
00:32:46.372 - 00:32:46.584, Speaker A: Right.
00:32:46.622 - 00:32:51.420, Speaker C: The point is, like, no matter how you try to do it, there's always an incentive for two of them to make a side agreement.
00:32:52.720 - 00:33:10.680, Speaker A: Interesting. Yeah. Buy the dollar. Yeah. Makes sense. So then that implies even if it was 5% of something else.
00:33:12.970 - 00:33:13.478, Speaker B: There'S kind.
00:33:13.484 - 00:33:46.520, Speaker A: Of this fundamental problem in this space that this all is supposed to happen pre consensus, I guess this is what Turin was saying a second ago. But either you commit to everything at the consensus layer, in which case you've nuked the benefits of having L two S, or you sort of have to trust somebody because the data is not all going to be authentically committed. Like at that point you're running everything on chain.
00:33:48.700 - 00:33:49.450, Speaker C: Yeah.
00:33:51.580 - 00:33:59.996, Speaker E: Ben's argument would be you get some heterogeneity versus, hey, we're just specializing in this and we're making some trade off that's very optimized for this specific kind.
00:34:00.018 - 00:34:01.480, Speaker F: Of back and forth.
00:34:01.640 - 00:34:05.470, Speaker E: And that would be the marginal improvement versus just committing to the lo.
00:34:13.990 - 00:34:29.240, Speaker F: I think there's also communication complexity. I mean, if everything was FHU originally, it's not.
00:34:31.930 - 00:35:16.710, Speaker C: I feel like the comment, I forget who made this, but the idea that the competitive forces plus kind of like the reputation. If you build a reputation as a sequencer, you will probably be able to extract more from that. And then there's a question of how do you get that reputation? Maybe you sort of enable audits or what have you. But I wonder if from my perspective, one sort of maybe weird analogy is when I think about publishers for books and the contracts I sign with them, right. So for US distribution, I might work with Cambridge University Press and I sort of trust them more or less. But then when I do the Russian translation of one of my books, right. I just sort of say, like, pay me a good advance because I don't expect to ever see another dollar after the advance, basically.
00:35:16.710 - 00:35:24.010, Speaker C: And so you could imagine similar kind of shit sequencing layers out there with the same trade offs.
00:35:28.350 - 00:35:48.606, Speaker E: Yeah. Empirically on l one. There's the biggest trading infrastructure service provider who's generating transactions for most of the big trading desks. We spent time with LTV. Our customers care mostly about inclusion. They need to get their transactions in as fast as possible. They don't care if they're going out to the public men pool, whatever gets us included as fast as possible.
00:35:48.606 - 00:36:07.190, Speaker E: That's what everyone cares about. The notional value of that. I think they do like, a couple of billion dollars buying a day through that specific kind of condition. We don't care. And so all we care about is reputation. And really that's how they're making their transaction pipeline decisions.
00:36:08.010 - 00:36:10.198, Speaker A: So you're saying they don't care about me?
00:36:10.364 - 00:36:28.220, Speaker E: They don't care about mev because their customers, like, all their customer cares is, I want to get this inclusion as fast as possible. And so if they were putting it through some shielded pool with 10% of the hash rate or inclusion rate, they would not do that because they want everyone to see it. They want to get inclusive as fast as possible. So they don't care about getting.
00:36:30.370 - 00:36:31.166, Speaker A: Interesting?
00:36:31.348 - 00:36:32.318, Speaker E: Not really.
00:36:32.484 - 00:36:37.540, Speaker A: Are we sure that's rational? Like, do they understand what they're actually giving up by getting front run?
00:36:40.230 - 00:36:59.974, Speaker E: Maybe they cooperate. Their flow does not have a ton of MEV associated with it's. Generally the second leg of a settlement of a trade. Like, I'm just settling, okay, I'm sending you this asset. So it's just a transfer? It could be just a transfer. Right? Generally, most trading is like here. Like here you want to see one.
00:36:59.974 - 00:37:41.360, Speaker E: And so front running is not a giant thing if they're running much more complicated on chain trading strategies properly. But they don't care about that, which I was shocked at. I see, so they're just doing the price discovery and so far off chain, and they're just settling on chain? Possibly. So there's no information. But again, their customers care about just they want to make sure everyone's using it. I guess the reason I brought that up was really these transactions are very heterogeneous in terms of what people care about, why and why they're going to broadcast one set of surgeries versus another. And sometimes inclusion is the principal effort.
00:37:42.420 - 00:37:54.708, Speaker A: Is it possible that different roll ups would somehow work with multiple shared sequencing layers? Or is the only model we could think of that they're tied to one shared sequencer and they're sort of exclusive with it?
00:37:54.874 - 00:38:07.560, Speaker F: Some of them want multiple data. Harder to reason out, really. I don't understand how you reconcile a fraud proof when you have two layers.
00:38:09.740 - 00:38:12.260, Speaker A: But they're not like multiple redundant data.
00:38:12.350 - 00:38:14.750, Speaker F: It's unclear how the redundancy is done.
00:38:15.360 - 00:38:29.184, Speaker A: You can choose your own because there's a model. There's like a Raid Zero model where you just write the data separately to every data availability layer and then it seems pretty obvious. But if you're like, striping it half half, then I agree.
00:38:29.222 - 00:38:30.130, Speaker C: It's a different.
00:38:32.180 - 00:38:43.030, Speaker F: I think the rigor of data availability thing is allowing the developer to choose what portion of their state you could write it for.
00:38:45.880 - 00:38:51.000, Speaker A: I don't know. Users of the contract are eating that risk.
00:38:52.780 - 00:38:55.770, Speaker F: I feel like, to me, it seems great.
00:38:58.160 - 00:39:13.960, Speaker A: So what would it look like, though, if a roll up server had multiple shared sequencers that it was party to? It could just kind of alternate blocks.
00:39:16.400 - 00:39:20.510, Speaker C: The shared sequencers are ultimately both posting to Ethereum, say?
00:39:22.160 - 00:39:25.592, Speaker A: Well, you mean like all the roll ups?
00:39:25.656 - 00:39:28.860, Speaker C: Like, are they in the same two?
00:39:29.010 - 00:39:52.160, Speaker A: I guess. I mean, imagine it's a bunch of roll ups that sit on top of Ethereum and then there's like, multiple shared sequencers. Know, I don't want to be tied to Cocoa or PEPC here. I want to use both of them. Because if clients just care about max inclusion, you could say, like, oh, we take transaction bundles from multiple shared sequencer layers.
00:39:55.330 - 00:40:02.126, Speaker D: I guess maybe a simpler question is, can the roll up have a shared sequencer and also have their own sequencer?
00:40:02.318 - 00:40:03.330, Speaker A: Definitely another model.
00:40:03.400 - 00:40:06.258, Speaker D: Yeah, clients can decide whether they want.
00:40:06.264 - 00:40:35.580, Speaker A: To go through the shared sensor. Yeah, I mean, the trick would be, like, what happens when some searcher bids a lot for a bundle that includes Transaction X and then Transaction X is preemptively executed through the direct sequencer or some other shared sequencer, and then it kind of like precludes some entire transaction bundle. Like there would be these weird, dependencies, I guess.
00:40:38.530 - 00:40:44.350, Speaker F: Type of thing where like the main sequence announces that they're not.
00:40:44.420 - 00:40:45.040, Speaker A: Taking.
00:40:50.450 - 00:40:54.340, Speaker F: I don't know. I only heard of this concept because.
00:40:58.980 - 00:41:26.808, Speaker G: Is the thinking more that the types of transactions that you would want to sequence together? Is that going to be changing across different roll ups all of the time? Or is it going to be the case that sort of two roll ups have a natural kind of connection and that it's going to be a more permanent thing, that these are the ones you're going to want to sequence together?
00:41:26.974 - 00:42:06.794, Speaker A: I think it will probably drift over time, but in the short run, I think there will be some stable sort of pairs that see a lot of synergy. You were saying a second ago, some clients have a very simple flow. It's just a bunch of trades. So maybe they're like, we don't care about the shared sequencer, we just want to submit direct to the roll up and sort of be done with it. There's not a lot of mev, so who cares? And then others might be like, oh, we should go through this shared sequencer so that there's more cross chain. MAV captured the non obvious thing.
00:42:06.832 - 00:42:59.614, Speaker E: If you're comparing these, like equities where you're saying, like, okay, I'm just doing Arbitrage, I'm buying Google here and selling Google here is that we don't have one to one fungibility of assets. Actually, if you're on different roll ups on different L ones, right? Like, they are actually literally different security assumptions, trust assumptions throughout the stack. And so if you're trying to do this cross domain R, you're actually buying and selling two different assets. At the end of the day, you're buying like arbitrary meath and optimism, which are not the same thing. And so arbitrage is almost the wrong word for it because it is not a one to one swap. And so a lot of these intense, these cross domain atomicity ideas, people think they can be deterministic like zero one or binary, but they're really like a probabilistic curve of how like are these two assets. It's like how like are USDC? Well, USDC is one to one.
00:42:59.652 - 00:42:59.806, Speaker A: Right?
00:42:59.828 - 00:43:37.026, Speaker E: It breaks this concept because it's all wrecking back. Yeah, exactly. So like the syntheticness of it is actually a probabilistic score that when you're doing arbitrage, you have to assign the likelihood that you're going to get back to the actual data. And so that's actually much trickier than I think most people realize is the searchers have to have a tolerance between zero and one. It could be 0.7, it could be zero two when they're doing these cross chain cross domain things. And that brings in a lot of discretion and choice and market forces, which is not as synonymous as people think with architecture.
00:43:37.026 - 00:44:12.450, Speaker E: If we assume number one form of MEV is centralized decentralized arc for the same asset, that actually makes sense. Like Ethan Binance and Ethan Binance, it's counterparty risk, but when you end up with the assets and so my reason I bring that up is if it's possible for the sequencer to improve that in some way or give you better. I don't know how I've been thought through enough why shared sequencer would provide that. That would be something that would be an edge and be interesting.
00:44:14.660 - 00:44:16.276, Speaker D: So right now the shared sequencer would.
00:44:16.298 - 00:44:38.840, Speaker E: Just give you the ability to atomically do the two trades, but they wouldn't let against each other because it's different where's their DA. I think it gets much more complex the more we break apart what the asset is. Like how much heterogeneity we have in assets makes atomic arbitration harder in my.
00:44:38.910 - 00:44:41.930, Speaker F: Mind will also decentralize trans.
00:44:49.640 - 00:44:50.196, Speaker A: That's right.
00:44:50.218 - 00:45:04.300, Speaker F: You're saying like two different things. Yeah, exactly. They sort of have to agree on those get reduced back to like, oh, I'd rather send one sequence if I want those guarantees.
00:45:07.250 - 00:45:15.970, Speaker E: Which is where a lot of these network effects would show up. It's like I can get better and better and better. More liquidity. I have more sequence of liquidity.
00:45:18.540 - 00:45:47.136, Speaker F: Does anyone know how op stack bridging is supposed to work? Or do they have they chosen? Because I don't understand. There's all these different roles that source people each full sequence. Your op stack thing, somehow you eventually can go back to op mainnet. Is that the same sequencer? Do you like every sequencer sequencing op stack chain have to guarantee that they are a sequencer main chain, I don't know what the guarantees are.
00:45:47.318 - 00:45:58.540, Speaker A: Too bad to Kevin from optimism on yeah.
00:45:58.610 - 00:46:03.810, Speaker E: Wow, well sorry, honestly the audio is not great.
00:46:04.180 - 00:46:38.780, Speaker F: I did show yeah the question was how does maybe bridging but how do cross op stack roll up transactions work? Does a sequencer who's sequencing an op stack roll up have to also have be sequencing the main op stack chain or do they have some guarantees on inclusion? Are there any attempts that guarantees on inclusion to the mean op chain?
00:46:41.200 - 00:46:44.528, Speaker E: Yeah, this is absolutely ours and I.
00:46:44.534 - 00:46:46.464, Speaker F: Think we're still figuring it out.
00:46:46.582 - 00:46:51.424, Speaker E: Honestly, that's approach right now with the staff is everyone's using the exact same.
00:46:51.622 - 00:46:57.716, Speaker F: Configuration and all the same modules? That will be easier for us to.
00:46:57.738 - 00:47:07.860, Speaker E: Figure this out in the future. I think right now it's in the research basis that's happening a lot more than Carl.
00:47:11.180 - 00:47:15.976, Speaker F: I don't think they need to use the same sequencer though to do I.
00:47:15.998 - 00:47:16.570, Speaker A: Think.
00:47:19.100 - 00:47:20.956, Speaker F: In the long term we should.
00:47:20.978 - 00:47:23.580, Speaker E: Probably be using proofs to verify.
00:47:25.760 - 00:47:26.136, Speaker A: Cross.
00:47:26.168 - 00:48:54.360, Speaker F: Chain messages between those side chains. But do I get any guarantees that the main sequencer will verify proof within K blocks on the main chain? More from the Arbitrage standpoint of like suppose I was doing Arbitrage between AOP stack chain and the main chain. I want some sort of latency guarantee or maybe guarantee is the wrong word, but some type of probabilistic measurement of how long until I get included. Is there any form of trying to bound that or make that? Do you think the main chain sequencer will have some inclusion guarantees where some portion of a block is allocated to verifying other op stack chain proofs or something? Like on every block sorry, it was cutting out basically the question was like on the main op stack chain will there be some portion of block space allocated just to verifying these messages versus it being competing? Yeah.
00:48:56.590 - 00:48:59.580, Speaker E: That'S currently not a part of the design.
00:49:02.190 - 00:49:07.200, Speaker F: Like kind of like functioning as settlement change or something like that.
00:49:08.610 - 00:49:18.690, Speaker E: Just exclusive access, like something reserved for the cross domain stuff versus it competing with all the other blocks.
00:49:21.770 - 00:49:23.686, Speaker F: Yeah, there's really not a plan.
00:49:23.788 - 00:49:25.126, Speaker E: There to be a distinction of like.
00:49:25.148 - 00:50:00.450, Speaker F: The op maintenance function like any other op stack. Well that's a cartel. That's interesting. The op stack sequencers and the main net sequencer have to have come to some economic agreement to guarantee this verification within some time. Otherwise it's just like two separate chains then that's just like a normal bridge, you know.
00:50:17.330 - 00:50:20.850, Speaker C: Is that a simple problem even if you put the economics sort of aside?
00:50:23.590 - 00:50:45.494, Speaker F: Well, a form of this arrangement might be like other op stack chains. If you pay some amount of op you're guaranteed include some block space is reserved only for this verification. But suppose the other op chain could prove it was running exactly the op stack with particular module modules that were.
00:50:45.532 - 00:50:50.100, Speaker B: Supported who's presenting from the first group.
00:50:51.350 - 00:52:06.202, Speaker H: I think, to summarize. So we talked about how to share revenue from mev. I think we said there are kind of two distinct problems that we were maybe getting muddled together a little bit, which is how to split the mev between different transactions that are included in a bundle and then how to share it kind of three ways between searchers roll ups that are on top of a shared sequencer and the shared sequencer itself. The proportion that searchers get is probably tied to solving the first problem of figuring out how much each transaction is really adding mevys and what each transaction should be paid. So the first problem, I think we said it's hard because there's kind of an exponential space of different combinations of transactions and it's hard to elicit the value of each one before you can even start thinking about chapli values or ways to split the value up. But that problem kind of exists even without a shared sequencer. So maybe it's more interesting in the shared sequencer case because the space gets even more complex and more transactions go into a bundle maybe.
00:52:06.202 - 00:53:22.050, Speaker H: And maybe the values are in different assets on different chains, but fundamentally the same problem but more complex. And then the second problem of how to solve kind of the three way split between shared sequencer, the constituent roll ups and the searchers, the good news, I guess, on that problem, we felt like we had maybe even less of a sense of what a good split is. But that problem between different roll ups that are sort of joining as part of the shared sequencer, the shared sequencer itself and then also searchers that are submitting bundles of transactions but at least the split between the different roll up servers on the shared sequencer and the shared sequencer itself. We are thinking that that won't need to be solved nearly as often or as quickly because roll ups won't be switching between shared sequencers really quickly. It will be much more of like a sticky arrangements that they meet for a long time. We had some questions about, I guess how permanent that would be. Like what the feasibility would be, what the friction would be for a roll up server to switch from one shared sequencer to another.
00:53:22.050 - 00:53:44.698, Speaker H: We were also curious if it made sense if there was any model for a roll up to take transactions from different shared sequencers in some kind of arrangement, or if they're sort of inherently tied in a one to one relationship with a shared sequencer that we kind of came up with at the end. So I was curious if anybody else has thought of that before, thought if.
00:53:44.704 - 00:53:46.938, Speaker B: There'S any model just repeat that last question.
00:53:47.104 - 00:54:11.198, Speaker H: If there's a model for a roll up server to work with multiple shared sequencers in some way, or if it's inherently kind of a one to one relationship like a roll up server takes all of its flow from one shared sequencer and that's it. It could be multiple shared sequencers, or it could be one shared sequencer, plus it has its own roll up specific sequencer, kind of like a direct submission pathway.
00:54:11.294 - 00:54:23.320, Speaker B: Well, you're essentially asking if there's a way in which you can use multiple consensus protocols to agree on your order. You could take some kind of logical composition of what the outputs are.
00:54:25.450 - 00:54:29.160, Speaker H: Or you could possibly round robin between them.
00:54:31.450 - 00:54:41.530, Speaker B: Right. I mean, I guess you're essentially designing a meta level consensus protocol that's now taking individual consensus protocols as input.
00:54:42.030 - 00:54:44.202, Speaker H: So you're saying it sounds hard.
00:54:44.336 - 00:54:51.514, Speaker B: No, it's not hard. It's not clear what I mean, it may compromise on the properties that each give to you, but there are compositions of consensus protocols.
00:54:51.562 - 00:54:51.918, Speaker A: Right?
00:54:52.004 - 00:54:55.626, Speaker B: I mean, even ethereum is a composition of two consensus protocols, essentially.
00:54:55.818 - 00:55:18.520, Speaker H: Right? Yeah. So, I mean, we were thinking about that because that might change the dynamics of basically, like the easier it is for roll ups to switch between shared sequencers or take transactions from multiple they might be able to demand sort of a higher cut of the mev because they would have more ability to leave and get a better deal on another shared sequencer or just do it themselves.
00:55:19.610 - 00:55:39.262, Speaker B: Was the conclusion that it's difficult to just figure out a way of estimating the marginal contribution of each roll up to the mev or in other words, how much they would be making on their own? And therefore the conclusion is that at least we don't know how to solve that yet.
00:55:39.316 - 00:56:08.360, Speaker H: Yeah, I think the conclusion was like, we don't know how to solve it. We were thinking of really simple things like the shared sequencer and also the individual roll ups, get some fixed take of searcher bids for different transactions that are included in a bundle, and then somehow some of that goes to the shared sequencer and some of it goes to the specific roll up server for each transaction. That's something that you could at least know.
00:56:10.910 - 00:57:11.282, Speaker B: Sorry to make this interactive, but I feel like the simplest question that is related to this would be let's say that you have two transactions, two items that you're auctioning off. And nobody really wants these items individually. They just want them together. If you were to run two separate auctions for them, then you still might have bidders bid on both because there's a certain probability that they will get both and they're not going to bid as much as they would for the pair of them. If you ran a joint auction because of there's some price to that risk. So is there a way to run an auction where you can discover how much they would bid in the separate auction case even though you're giving as an option the bundle?
00:57:11.346 - 00:57:20.298, Speaker H: Okay, so maybe we could go through that because that, I think, can illustrate the two different problems we were thinking about. So I think the classic thing is like a left shoe and a right shoe.
00:57:20.474 - 00:57:32.526, Speaker B: Yeah, that's great. I want both shoes. So the pair of shoes to me is $100. I don't want the left, I don't want the right. But I'm willing to bid on both because there's a certain chance I'll win.
00:57:32.548 - 00:58:15.642, Speaker H: Both auctions and say, like, for some reason the left shoe and the right shoe are being auctioned on two different chains, two different roll ups. We're thinking like, the first problem would be basically figuring out what value those two combined really gives. And that was the first problem. We were saying that it's the same whether they're auctioned on the same chain or on two different chains. Right. You still have, like, searchers can put in a bid for the bundle of two. And in the simple case, you can notice that searchers are willing to bid much more for a bid on both right, than for separate bids.
00:58:15.706 - 00:58:31.670, Speaker B: I guess my question is, if you're running the auction, though, for both, why would anyone bid individually on each? If they can just submit a bid on both, why would they truthfully report, like, if we were running separate auctions, this is how much I would bid on each. If we're running an auction now, that's giving the pair.
00:58:33.850 - 00:58:53.690, Speaker H: If the value is like, truly zero, then you would see zero bids. And I guess you would impute like, a value of zero if you don't see any bids. But somebody might bid some epsilon, right. Like you said, there's a probability that they end up with both or they end up with one and sell to the person who has the other. So there's probably like a non zero price even just for the right shoe.
00:58:54.910 - 00:59:09.520, Speaker B: Oh, interesting. You're saying that if you give people the option to bid on both or either one individually, then you think that some people might still bid on one because they can then sell it to someone else, but they won't have to compete for the bid on both or something.
00:59:10.450 - 00:59:35.194, Speaker H: So suppose someone puts in a bid for the right shoe for like a dollar and someone puts in a bid for the left shoe for a dollar, and then you see like, a bid for both is like $100, right? Then that gives you some signal that there's a lot of value of the two together, and then you have to figure out a way to split that surplus. But at least you'd have some idea of what it is.
00:59:35.232 - 00:59:38.570, Speaker B: Is there like a theory of this problem in auction theory?
00:59:39.070 - 01:00:06.930, Speaker C: Yeah, it connects pretty strongly to the literature on combinatorial auctions. There you don't have a notion of an ordering like you do on transactions, but it's the same features where you have like an exponential size set of things that you're worried about. And so people's preferences might be over that very rich exponential size set. And then you have to decide on the biding language. And do you just like, elicit bids on individual items or do you allow them to bid on bundles? And if so, how do you compute prices? So that's all I think somewhat relevant to this discussion.
01:00:07.370 - 01:00:15.910, Speaker H: The problem is just like we said, getting bids on every sort of subset of items and also like exponential number of subsets.
01:00:17.210 - 01:00:48.210, Speaker C: I guess if you take like, say, spectrum auctions or something like that, which are kind of a real world deployment of commerce, real auctions, there a lot of what you do is you're kind of like lazy about it so you don't sort of upfront ask everybody for their bid on all exponentially many things. You're like, look, if you feel like bidding on this bundle, feel free and then we'll figure it out at the end. And so there are these rules about how do you charge prices based on bids on different bundles in that literature, which perhaps one could draw on.
01:00:48.360 - 01:01:19.286, Speaker B: I don't know that I'd be as concerned about the exponential number of combinations, because if we have, let's say, five roll ups and that we're looking at sharing revenue with, I mean, there can be many more. Of course. But let's say there's five in particular that are trying to come up with a revenue sharing model. And the builders are building blocks wholesale for each. So it's really just bidding between either building a block for an individual roll up or some combination of subsets of the five, which is tractable.
01:01:19.478 - 01:01:34.110, Speaker F: Yeah, but one problem with some of these things is their communication complexity is not low. Like you might have to have many rounds. The resale of the shoe is adding extra communication complexity rate because you have to have another auction for the resale.
01:01:34.690 - 01:01:38.686, Speaker B: What level of communication are we talking about here if there's only five items.
01:01:38.718 - 01:01:41.394, Speaker F: That are being possibly exponential in five?
01:01:41.512 - 01:01:44.898, Speaker B: Well, 32 round, are you willing to.
01:01:44.904 - 01:01:45.954, Speaker F: Do chain at 32?
01:01:45.992 - 01:01:47.474, Speaker B: Okay, 32 rounds would be a lot.
01:01:47.512 - 01:01:52.866, Speaker F: That's what I'm saying. You shouldn't kind of underestimate that effect latency wise.
01:01:52.978 - 01:02:35.986, Speaker C: And actually one high level takeaway from that commercial auctions literature is that this specific case, the ten together, is really hard in many senses. It's only going to be a bounded number of transactions where you have this complementarity. But if it might be like large sets of bundles that all of a sudden unlock all this value, that's just very difficult to deal with auctions. So at the moment, we haven't even solved the case where in my opinion, we haven't even properly solved the case where the transactions don't interact at all, right? And then you can also imagine, okay, let's go to the case where maybe you get like a 20% increase if these things go together. What can we do there? That would be my advice to focus there.
01:02:36.168 - 01:02:56.486, Speaker B: It seems like this problem arises in other industries, right? Like you have shops in a mall. Maybe it's not addressed through auction theory, but it's a similar situation where you could have one flagship store that's contributing the most in terms of revenue and should get a discount on its rent.
01:02:56.598 - 01:02:58.502, Speaker C: But like you say, you would not do that with an auction.
01:02:58.566 - 01:02:59.180, Speaker B: Right.
01:02:59.870 - 01:03:03.242, Speaker C: Long negotiations with lots of people at the same table at the same time.
01:03:03.296 - 01:03:05.534, Speaker B: Right, cool. Okay, maybe yeah, go ahead.
01:03:05.572 - 01:03:57.866, Speaker H: Yeah, I was just going to say, yeah, the stores in a mall is probably a place to end on because we were thinking like the combinatorial auction part is kind of like needs to be solved algorithmically quickly. It's a hard problem. It exists in some form, shared sequencer or not. And then with shared sequencers, with roll ups joining your shared sequencer or splitting off on their own, deciding what to do, that's something that you could start by just like hammering out an agreement, like a paper contract slowly around a table and assume that your roll up is not going to change more than yearly. Right. Or at least not super fast. So that's maybe more like the stores in a mall aren't literally having an auction, but they do have some slow back and forth and they do give the big corner store better rent.
01:03:57.866 - 01:04:12.210, Speaker H: And it's probably all not very transparent and maybe not completely efficient, but they approximate it with people negotiating. So, yeah, we were thinking like, maybe that happens with roll ups deciding to join this shared sequencer.
01:04:13.270 - 01:04:15.826, Speaker B: Cool. All right, thanks.
01:04:16.008 - 01:04:18.760, Speaker H: Did I miss anything from the people who are in the group?
01:04:20.730 - 01:05:05.406, Speaker B: Great. Okay, I'll do the group two. Maybe we can pull this whiteboard. This is the Mev agnostic sequencer. So the idea here is that we have some shared sequencing layer. Okay? Again, we can just think of this sequencing layer as Ethereum itself. It could be something that's a module on top of Ethereum which is maybe more optimized for data availability and ordering.
01:05:05.406 - 01:06:22.922, Speaker B: But for purpose of the discussion, we can just think of the base roll up model where basically roll ups are doing computation, but they want to use the decentralized layer one for ordering and availability of data. Right? So let's say now, because Ethereum itself is not really implementing Threshold encryption or time boost, like first come, first serve ordering policies or other kinds of ordering policies. To what degree can these different roll ups running on top of this common sequencing layer have their own ordering policies? So let's just look at a few examples. So let's say that we have this roll up one which wants to do some Threshold encryption. So what we talked about is how this roll up one could designate its own, and we'll talk about the caveats of this in a moment, but it designates its own Threshold encryption set. Okay? It designates its own set of servers. This could be involving the governance of the roll up or not.
01:06:22.922 - 01:07:00.382, Speaker B: Whatever. Again, it could be decentralized as well. The concept is simply that if each roll up were running on its own, trying to decentralize it, they wouldn't each be able to end up as decentralized as the sequencing layer itself. So for purpose of the discussion, we're going to assume that every roll up can designate a set of servers. It won't necessarily be as decentralized as the common sequencing layer, but they can still introduce it. And that will be important for the discussion of what are the trade offs here of having this separate set of servers that's in charge of something. So in this case, the set of servers that's specific to this roll up will be Threshold Encrypting every transaction.
01:07:00.382 - 01:08:12.510, Speaker B: So every transaction that a user submits, so the transaction is valid for the roll up if and only if it's Threshold Encrypted under the correct key. And users would just be submitting their transactions still to the sequencing layer, threshold Encrypted under this shared key and it would be ordered along with everything else that the sequencing layer is ordering. And at the end, when the roll up reads from the sequencing layer, then this set of servers will threshold decrypt the transactions at execution time. And if something is not Threshold Encrypted, it would just be dropped. It wouldn't be considered valid. Let's go for another example first before we talk about what could be. In other words, what are we losing by introducing this extra set of servers? Are we still gaining a lot from the shared sequencing layer? What properties are we gaining, which are we losing? So let's say we have a roll up, two that's doing first come, first serve.
01:08:12.510 - 01:09:24.070, Speaker B: So in first come, first serve, generally there's two components, right? There's some atomic broadcast or consensus protocol. There's also some set of servers that need to agree on timestamps for transactions. A transaction needs to be sent to every server participating in the timestamping and then they need to broadcast those timestamps to each other. And there's some mechanism to end up agreeing on what the outcome is. Of course, there's the Condorset paradox, but we're just ignoring those details. So the idea would be the same designate a set of timestamping servers and the transaction would have to be sent to each of these servers to get timestamped before it would be considered valid by this roll up. So that we'd have this timestamped, transactions would then be sent to the common sequencing layer.
01:09:24.070 - 01:10:39.790, Speaker B: An important thing to note here is that when you have some kind of first come, first serve ordering mechanism, there is a much sharper trade off between the latency of the consensus protocol and its decentralization. Because a transaction needs to be sent individually to every single server to get timestamped and then they need to broadcast their timestamps to each other. Whereas in other consensus protocols, there can just be a leader that collects all the transactions and then broadcasts a hash of the transaction to basically erasure codes and shards and makes available the data and collects signatures. So, point being, there's more restrictions here in terms of what needs to happen in a very decentralized set of servers before a transaction gets approved. So here we would definitely be looking at a set of timestamping servers that's much smaller than the set of servers that are participating in the sequencing layer. So now the question is, okay, well, sequencing layers that are common, they're supposed to provide us with a few different properties. So first, censorship resistance.
01:10:39.790 - 01:12:09.558, Speaker B: These are things that come from decentralization censorship resistance, certain economic properties, the fact that the leader in a consensus protocol is elected once in a blue moon, if the distribution of stake is very flat, then it behaves in a short sighted way. So it will just take whatever it can get to build the most valuable block. It won't try to engage in long term revenue maximizing strategies. So this is important for like EIP 1559, it's important for PBS, it's important for proposer builder separation. And then finally there's the finality guarantee which or non Occupication, right? Once something has been stamped as final by this sequencing layer, then based on the fact that there's a lot of stake behind this that will get slashed if there's some liquidation later, the user knows that the transaction is final. Okay, so now let's look at which of these properties are preserved when roll ups are introducing this extra set of servers. So the first thing that goes out of the window a little bit is censorship resistance.
01:12:09.558 - 01:13:02.650, Speaker B: I'll say at the end, maybe one way of recovering it. But this is important to recognize this set of servers that are in charge of Threshold decrypting can now censor transactions. This is not entirely true for Threshold Encryption. If we introduce some kind of time lock encryption mechanism because Threshold encrypts the transaction on its own, it doesn't have to first send it to these servers for approval. So if this is somehow time lock encrypted, but the trap door is secret shared among these servers, then that might be okay for censorship resistance, but certainly with first come, first serve sequencing because this set of timestamping servers needs to receive the transaction first. The weakest link is now for censorship resistance is now this set of timestamping servers. Okay, but censorship resistance is not the only thing that the shared sequencing layer is providing.
01:13:02.650 - 01:14:48.590, Speaker B: So to the extent that these ordering policies like threshold encryption or Timestamping don't entirely control the ordering and they don't necessarily control, like, atomic dependencies between transactions, other things that a builder network might handle the ability to be compatible with PBS and also the pricing of getting things sequenced on this common sequencing layer can still benefit from the decentralization of this in terms of antimonopolistic properties. On the other hand, it's important to recognize that if you have the ability to censor for your roll up, then for just transaction inclusion, you can jack up prices, right? So the timestamping servers could raise a base fee that could be well above whatever the base fee is for the sequencing layer. But on the other hand, when it comes to mev that cannot be extracted just by these timestamping servers or just by these Threshold Encryption servers, we're still potentially getting the benefit of this common sequencing layer in controlling for mev. Then finally, finality. So we still have finality from the sequencing layer. One way of thinking about this is, like, let's say that a roll up has a designated builder, a centralized builder, for that roll up, right? Would there still be a benefit to running on this common sequencing layer in terms of the finality that it's giving? And the answer is yes. So a builder can censor transactions, but it's not as trusted to provide finality, right? The builder could still cause double spending if it tells someone, hey, your transaction is final, and then equivocates later before settlement on the L one.
01:14:48.590 - 01:16:07.080, Speaker B: So in many ways, the sequencing layer is now acting as a notarization service, which says, okay, builder, what do you want to have? Final? Okay, now this is final, right? So the sequencing layer is still providing this final stamp of approval, which gives users confirmation that their transaction is done and won't change before it's settled on the L one. And lastly, when it comes to censorship resistance, we talked about how what we could do is have an ordering policy that's just for the beginning of a block and not the tail, and that regains some censorship resistance. So, for example, we have a policy that's implemented in the roll up which says the beginning of every block has to be Threshold encrypted, but the end doesn't need to be, or the beginning has to have these timestamps on it. But then there's some tail of the block that doesn't have to go through the timestamping servers. And that's interesting. To explore more in terms of interoperability, we talked about ways that we can still have a builder, a shared builder, that can, say, make some promise to a user that it will only include transactions if they execute on both roll ups. That is still possible, but we need to be careful about making sure that the Threshold Encryption or the timestamping isn't on an already valid transaction, that there's some step where the builder gets something Threshold encrypted or gets it.
01:16:07.080 - 01:16:24.090, Speaker B: It's easy for Threshold Encryption, but gets like, a part of the transaction timestamp before it adds a signature so that these sets can't submit the transactions independently. The builder can still participate in an auction and only submit both transactions if it's able to do both. Okay, so that's problem two.
01:16:24.160 - 01:17:13.190, Speaker I: All right, we'll try to go through is this working? Problem three really quick. So problem three is somewhat similar to what was discussed in problem one. What we roughly talked about was kind of the user experience of how transactions are going to be submitted through like a shared sequencer. And a lot of the questions was around payments. And so how would a user pay for a transaction to be included on one roll up or many roll up or like a shared sequencer? And what is the chain of payments that needs to happen? If we assume there's kind of three layers where you have a roll up and you have a shared sequencer and you have a DA layer or a settlement layer or whatever want to call it later, right? Presumably the user probably wants to own like one token and they want to pay for that token. If we think about the existing user experience using ETH, right, if you're going to use like Uniswap and you're going to submit a payment for uniswap, uniswap has a front end. The user is actually interacting with the front end and signing a transaction.
01:17:13.190 - 01:18:27.262, Speaker I: That front end needs to interact with some stateful RPC to actually generate this kind of transaction bundle to give the user the opportunity. So we assume that flow is probably going to be the same and that a user is still going to interact with a front end or something to generate a transaction. And then there's a question of when you get a collection of roll up transactions, how do those get submitted to the shared sequencer? Where we trended to. Just trying to really summarize this is essentially like a PBS market where we assume there will be some market, whether it is off chain or whether the shared sequencer itself has some kind of protocol owned building or enshrined PBS solution such that the transactions are submitted to the shared sequencer would be submitted by sophisticated actors. And the key benefit they provide is that these sophisticated actors can be assumed to be running this kind of multi roll up knapsack problem to determine what is like a good block to submit to the sequencer. Because one of the core things you want to resolve here is that we use the shared sequencer of a roll up up here, right? A roll up is going to have some stateful execution loop that is going to have some limit on the amount of execution it will do for a given amount of fees and or it's going to have a strict computational limit, right, to be able to run a node. The shared sequencer is strictly not going to be aware of that limit.
01:18:27.262 - 01:19:07.454, Speaker I: So if you include a bunch of transactions in the shared sequencer, the subset of those for any given roll up may mean that there's like 100 transactions and only like 50 of them execute. That's undesirable. That's structurally pretty similar to getting reverting transactions. And so we model this similarly to what you saw with Priority Gas auctions prior to MEP. Guest right where you can say you can resolve this by having off chain actors that are economically incentivized to be state aware of a given roll up such that when they construct like a bundle or a block for the shared sequencer. They are actually aware of the state and thus the limitations of the execution that would actually occur on one or more roll ups. From the shared sequencer side.
01:19:07.454 - 01:19:38.422, Speaker I: Again, you can question of whether we actually end up with ever having transactions as in like a single roll up transaction submitted to the shared sequencer, or if the steady state is such that shared sequencer is only ever. Really doing what we see with these protocol owned and optimistic relays where the shared sequencer says I don't care what is in the block, that's up to the roll up. That's not my job. I want a set of bytes and the highest bid for that. And that's what we're seeing on east validators for optimistic relays. Right now they just want what is the block that pays the highest bid. That's what we see a steady state potentially reaching.
01:19:38.422 - 01:20:30.970, Speaker I: The other questions that we got into a little bit was what is the fee payment mechanism on the sequencer, right? You can say the sequencer presumably has to still have some mechanism where it can do accounting on it such that it will actually include a thing kind of giving us these kind of economic properties and finality of non equivocation. Like if it actually accepts a bid, why would it do that if it didn't have a guarantee that bid was actually paid? That's easiest if it's just on the native state machine of the shared sequencer. But it could also be some various models that the Suave guys have proposed, right, where you can say, okay, you're going to post this on this bulletin board and the payment settlement is going to happen. It could happen on the roll up, it could happen on some settlement layer, it could happen on ETH, it could happen like out of Band, on Venmo, whatever. But there's various designs for how the actual payment is going to occur of this is the proposer for this round of the shared sequencer. They're going to choose to accept the block. How they do so is a pretty broad design space.
01:20:31.040 - 01:20:31.466, Speaker A: But yeah.
01:20:31.488 - 01:21:38.394, Speaker I: So, in summary, somebody's like Users will have normal interactions with RPC nodes for given roll ups and you will probably have some sophisticated group of PBS esque incentivized actors who will say, I'm only going to create and submit. Blocks of transactions to the sequencing layer that are not going to revert for the execution layer? Because why would they bother to include these transactions that are presumably not valid to someone else on some other layer and various designs for how you can kind of hold that accountable? Useful things to note, right, is like standard as EPBs is like a still pretty novel kind of design space. We've seen some stuff from the skip guys and protocol and building on Osmosis question of how much state needs to happen in the sequencing layer and how generic that needs to be to satisfy various kind of inclusion mechanisms, or how you're getting a guarantee of the execution, the guarantees. Generally, we should assume that these off chain builders are like semi trusted people that do have the opportunity to brief an end user. But it's going to be essentially like a reputation based system, as we have with searchers builders in east today. Did I miss anything from the group? I know we had, like, five or six things. I think there are a couple, but, like new idea.
01:21:38.394 - 01:21:39.726, Speaker I: Remember the one that we missed?
01:21:39.838 - 01:22:03.930, Speaker A: No, I think that was pretty comprehensive. The only thing was we also thought about what if the builders might be malicious? And for that there are different methods. I think one of them is just short term, is using Tees, like having them being run on Tes. The other one is later on proving that this is the gas cost via succinct proof. But these are like future steps.
01:22:05.870 - 01:22:34.530, Speaker I: It generally converges to the normal kind of PBS design space, which is rather broad, but we think there's actually a lot of good parallels. It just says, okay, does your napsack problem become combinatorially, more expensive? Because now you say, I'm not just simulating one state machine, I'm simulating one state machine against many others. And this gets into kind of the revenue sharing mechanism, right, where you say, well, how do you determine what was, like, the optimal block? How do you determine the sharing? Well, you have to calculate a bunch of counterfactuals, and that can be an expansive set depending on how many roles you have using a given shared sequencer.
01:22:35.030 - 01:22:35.586, Speaker C: Cool.
01:22:35.688 - 01:23:02.814, Speaker B: All right, thanks so much. If the discussion leads from each group, could maybe just send me some notes on what you discussed and I'll share them with everyone in case that was too fast. But yeah. Thanks, everyone. This was really fun. And hopefully you got convinced that there's some interesting problems here. And if you're continuing to think about it and then please reach out to anyone here.
01:23:02.814 - 01:23:13.680, Speaker B: Everyone who came in terms of a guest, I think is very interested in this problem space. So hopefully this can be the start of a longer discussion that we all end up having. Great. Okay, thanks so much. Yeah.

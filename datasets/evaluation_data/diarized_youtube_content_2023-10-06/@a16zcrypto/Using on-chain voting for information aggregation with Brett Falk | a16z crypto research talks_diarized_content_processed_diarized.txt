00:00:07.890 - 00:00:08.440, Speaker A: You.
00:00:10.810 - 00:00:36.266, Speaker B: Welcome, everyone, to today's a 16 Z crypto Research seminar. I'm very pleased to welcome Bret Falk, who's a professor at the University of Pennsylvania, did his grad work at UCLA, finished there 2010. Working mostly on multiparty computation stuff, I guess. NPC, yeah. So he works on lots of different parts of the blockchain space, including some stuff that, you know, is near and dear to many of our hearts, which is voting, which is what we're going to talk about today. So, Bret, it's all yours.
00:00:36.378 - 00:01:04.594, Speaker A: Thanks for the intro. I'm glad to be here. Yeah. So just as I haven't met most of you, so here's the slightly longer background. It's like, I got into cryptography mostly in secure multiparty computation and thinking about practical applications of secure multiparty computation. We did some stuff on trying to calculate the probability satellites are going to collide without revealing the underlying data. And now in the MPC space, I do a lot of stuff on distributed oblivious Ram.
00:01:04.594 - 00:01:55.462, Speaker A: So how can you do secure computation in a Ram based model as opposed to an circuit based model? But I've also been doing for the last bunch of years now, like, more and more blockchain stuff. I teach the blockchain course for Penn's MCIT online program for the last eight or nine semesters, I think, and been doing some stuff on stablecoins with people at the Stevens Center for Innovation and Finance looking at NFT royalties. We've been doing some modeling of trading fees and AMMS on the crypto side, I've been really interested in using Threshold signature schemes. It's like kind of a cool application of MPC. But today I want to just talk about this thing on chain governance. So this is not exactly my area, but it's something I think is really interesting. And so I'll keep this sort of at a pretty high level.
00:01:55.462 - 00:02:34.670, Speaker A: Hopefully this should be like a fun talk and not too technically deep, but there's lots of papers behind it that we can talk about later if you want. So this is in two parts. First, governance to elect block producers for consensus committees, and second, Dow governance. And I think they're useful to think about in a little bit different ways, and we've modeled them a little differently. So here's part one. This is based on this paper with Jerry Sukalis, who's at Bu, and Alone Benheim, who's now at Microsoft. But basically the idea of this model is like, there's a lot of proof of stake blockchain protocols where you elect a consensus committee and then that once that committee is elected, they run some classical consensus algorithm.
00:02:34.670 - 00:03:08.894, Speaker A: And for the purpose of this talk, we don't really care what that consensus algorithm is. We just sort of care how do you choose this committee in a way that's good for you? And from a cryptographic standpoint, the simplest notion of good for you is two thirds honest. That's like the very simplest criteria you could consider. And these committee based consensus is used in a lot of places. Like, it's the foundation of all the Cosmos chains. And so there are lots of Cosmos chains you've probably heard of, right, and are familiar know, and it's also for other chains like Tron and EOS. And so it's used a lot.
00:03:08.894 - 00:03:48.300, Speaker A: And one of the main advantages is that these chains get instant finality, right? So if you have Nakamoto Consensus, you have a longest chain rule, right? You can have chain splits. And before the merge, Ethereum had like 300 uncles per day. Bitcoin has only about one uncle per month. But there's still an issue of finality. It makes Bridging hard, makes a lot of things hard, whereas most committee based consensus chains advertise instant finality. And what this means is that basically that they assume that the elected committee will be honest every single time, and then you can claim instant finality, and then you get no forks. So this is sort of a nice thing.
00:03:48.300 - 00:04:25.714, Speaker A: One other thing that I kind of like about committee based consensus is if you have like a kind of small, semi static committee, you can do kind of interesting stuff. You can ask the committee to do other stuff for you. So you can have a secret mem pool, because the committee members are all running Intel SGX, like the secret network. You can ask the committee members to do things like a distributed key generation, like Osmosis has been talking about doing this kind of thing. You can ask the committee members to hold shares of a secret. So Algorand research had this stuff on. Can a public blockchain keep a secret by secret sharing to committee members? You can have the committee members be price Oracles.
00:04:25.714 - 00:04:43.574, Speaker A: So Terra did this before they collapsed. It's sort of an interesting kind of thing. If you need price Oracles as part of your chain, you just ask them to do this. You can elect block producers for other chains. The Binance chain does this for BNB. You can build bridges like this. A lot of this is like a nice architecture for a lot of cross chain bridges.
00:04:43.574 - 00:05:27.930, Speaker A: So like THORChain, Axelr Zeta chain, these are all Cosmos chains, where the committee members also run validators on these other chains, so they can manage liquidity pools or bridge contracts. So it's kind of like an interesting something that's nice that you can do with these committee based consensus protocols. So it's sort of a reason why we might want to think about using them. The big problem with them is that they tend to be kind of small and stagnant. The consensus protocol means that you can't have a really big committee. And so these committees are kind of small and they don't change that much. Even if you have elections a lot, the committee is pretty stagnant.
00:05:27.930 - 00:06:28.714, Speaker A: And so that's kind of a problem compared to a proof of work chain. For example, they have a lot more leader rotation. But assuming we are going to think about committee based consensus, the question is like how do we elect a committee? That's like what I want to talk about here. You have one question is sort of what is the civil resistance mechanism? How do you identify committee members and voters? This can be proof of stake, it can be proof of work. Most people think of the proof of stake model but it has been proposed that you could run Cosmos on top of proof of work if you wanted to and just run tendermint at an elected committee. There is an early paper BIZCOIN which basically said you can have like a hash based Byzantine agreement protocol on top of bitcoin to get some finality. But then once you have the proof of stake, once you have the mechanism for identifying who's a voter and how much their vote weight is, the question is how do you aggregate votes? The Cosmos chains basically all use a single vote.
00:06:28.714 - 00:07:02.854, Speaker A: Like you get a vote and it's proportional to your stake. But as an address you get one vote. You could have approval voting where you can approve of any number of people. EOS does this and Telos does this and whatever you think about EOS, it's still an interesting voting mechanism. And you could have a lottery based system. There's lots of different ways you can kind of think about this. So I want to talk about sort of like how does this system work in terms of mostly on approval voting because that's kind of the interesting thing here.
00:07:02.854 - 00:08:08.560, Speaker A: So what's the best way to choose this committee and how does approval voting play into this? But we'll start as a warm up with the lottery based system because this is kind of the easiest to out analyze. And so if you look at the algorithm paper they make an assumption. They say 80% of the stake is honest and the classical consensus protocol will succeed if two thirds of the committee is honest. And now you have a concentration bound right? What's the probability that a binomial with a binomial with parameter zero eight is below two thirds? It's very small. And they suggest in some of their parameters that you want to choose this so that this probability is below either like ten to the minus twelve or ten to the -18 and if you want to claim instant finality. You want to say that you'll never ever have a bad committee. And so they say if the failure probability is ten to the minus twelve and you elect a new committee every 4 seconds, then you can have a failure time of on average 128,000.
00:08:09.090 - 00:08:12.190, Speaker C: Do they have any resilience against bad committees or are they just dead?
00:08:14.770 - 00:08:26.466, Speaker A: I can't speak to exactly what their code is doing now, but in the original paper, I think there's no resilience. You just have to say there have.
00:08:26.488 - 00:08:35.986, Speaker B: Been versions where they had like a sort of emergency backup procedure, where if there's a fork, the next committee votes on the branch which branch of the fork to extend. I don't know what actually got deployed.
00:08:36.018 - 00:08:43.074, Speaker C: But doesn't the committee attendee, pick the committee or have a huge amount of influence on the committee? Pick the randomness.
00:08:43.202 - 00:09:22.840, Speaker A: Okay, so there's a big question, right? If you were going to do a lottery, doing the randomness right is obviously really hard. That's sort of not the purpose of this talk, right? Algorand right. They're using verifiable random functions and so you have some control over that, but not very much. Right? So there's like a seed that goes into the VRF in the next committee. Everybody generates their own VRF output and then you choose the lowest bunch of them. It seems that there's not that much you can even if you're the current committee you get to choose a little bit, but you don't have that much control. There's other things you can do.
00:09:22.840 - 00:10:23.530, Speaker A: Ethereum also does something kind of like this and they have randao where people it's a commit reveal scheme and so you can ask questions about what is the randomness going into this lottery based mechanism. I was just putting this up sort of as a baseline thing of if you're thinking about honest committees, here's kind of the analysis that would come up in the original Algorand paper and you can just say you have a turn off bound. And so if your stake percentage, if your percentage of honest stake is above your threshold, then as the number of tokens goes to infinity, then your chance of an honest committee goes to one exponentially quickly. And in some of the stuff Silvio sort of said we like lottery because there's no mechanisms behind. Like it's hard to design a good mechanism. It's sort of like the simplest kind of thing, where there's less that can go wrong. There's no rewards for block producers, there's no slashing, there's no voting.
00:10:23.530 - 00:11:29.790, Speaker A: And maybe this is a good thing we're going to be talking about when there is voting, but this is sort of the baseline and ethereum after the merge, right. Does the same kind of thing where for finality so I didn't quite put them in the committee based consensus model because their consensus is sort of split here. But the finality gadget chooses a committee every epoch and they do a similar kind of analysis with different numbers. They assume two thirds of the stake is honest and then they analyze the probability that more than one third of the committee will be dishonest. So you again get this turn off bound, that gives you something nice. They choose their committee size to have a two to the -40 probability, which is basically the same as ten to the minus twelve, which is what Al Grand chose. And So sort of looking around where These Things Came From, there's like An Old like Vitalik had Thrown out some numbers of saying, we Think two thirds and one third and two to the -40 and that seems to have been how these numbers were chosen.
00:11:29.790 - 00:11:47.878, Speaker A: And then now there's 128 committee members because if you do this binomial probability you get 111 you need and you round it up to a power of two and you get 128. And so there's a little bit of arbitrariness in sort of how these things are chosen. But this is the analysis that kind of backs them. As far as I can tell, some.
00:11:47.884 - 00:11:53.426, Speaker B: Of the parameters are arbitrary, but two thirds, I would not have thought are you mean you don't want it to go more than two thirds?
00:11:53.618 - 00:12:16.330, Speaker A: Yes. Yeah. You have to assume two thirds of the stake is honest to get the one third. So right. For them, they want a probability that no more than one third of the committee is malicious. Right. Whereas Algren wanted the probability that here they want no more than two thirds of the committee is malicious and Algorand wanted no more than one third of the committee is malicious.
00:12:16.330 - 00:12:30.180, Speaker A: But then this question of how much of the stake is honest you need to assume more of the stake is honest than your threshold. Algorand assumes 0.8 because that's more than two thirds. And here they assume two thirds because that's more than one third.
00:12:30.950 - 00:12:36.594, Speaker B: Yeah, here my guess would be like two thirds on a stake seems necessary to have kind of reliable liveness okay.
00:12:36.632 - 00:12:37.460, Speaker A: Yeah, sure.
00:12:38.390 - 00:12:40.290, Speaker B: That assumption you inherit from other things.
00:12:40.360 - 00:12:41.250, Speaker A: Okay. Yeah.
00:12:41.320 - 00:12:50.390, Speaker B: And then more than two thirds malicious also seems like a bad threshold to cross. These, I think, are a little less arbitrary. One third, two thirds.
00:12:53.310 - 00:13:42.386, Speaker A: The lottery based committee consensus works well in these analysis. The committee is large enough and the supermajority of the stake is honest. And the question is sort of can you do something better with voting if you allow people to vote? So we made a model that was just trying to capture what was done in the past year, which is you have a really dichotomous outcome. You win if two thirds of the committee is honest and you lose if more than one third. Or you can choose whatever parameters, some alpha fraction, whatever is the tolerance in your consensus protocol. But for now, you think you win if you can elect a committee with two thirds honest people, and you lose if less than two thirds is honest. We assume that all the voters, their goal is to create an honest committee.
00:13:42.386 - 00:14:29.046, Speaker A: They just don't really know who's honest or not. You have very little information in these systems when you're electing somebody to be on the committee. And for this model, we kind of ignore secondary characteristics of who you might want in a committee, of whether they're extracting mev or whether they have really low latency or something like that. Just as like a first step, we want to say, can we recreate the lottery analysis with some voting. And we're going to start with approval voting because I think this is the sort of most general that's been used, right? There are lots of voting schemes and we'll talk about some of them later, but people have actually been using approval voting to elect consensus. And here the idea of approval voting is you don't get to vote for one person. You get to approve of up to K candidates and they all get your full vote weight, right? Your vote is not split between them.
00:14:29.046 - 00:15:14.886, Speaker A: If you vote for three, they all get your full approval and then you count. The committee is made up of the people who get the most approvals. And in normal a single vote system, like in Cosmos, you get one candidate. So this could be like one approval voting. You get only one person you can vote for. And the problem with approval voting is basically that it's kind of complicated for the voters. Even if voters are not assumed to be strategic, like even if you're an honest voter, there's not an obvious sort of honest strategy, right? Like if I think the candidates are from best to worst, like ABCD or actually here, I guess in this example, I think they're best to worst in BADC, do I vote for just the best or do I vote for the two best or the three best or the four best? It's not actually obvious.
00:15:14.886 - 00:15:29.820, Speaker A: There's no heuristic for voters. Voters kind of have to be strategic almost because of the way that the system is set up. Whereas normally for a single vote election you can be if you're sort of a myopic or a non strategic voter, it's kind of obvious you vote for the person you like best, right?
00:15:32.270 - 00:15:35.338, Speaker B: K here is chosen by the voter.
00:15:35.354 - 00:16:14.726, Speaker A: Or K is okay, so sorry, in terms of how many people you are allowed to vote for. So in EOS they just cap it at 30. Normally we assume that you can vote for up to you don't have to vote for this. You get to choose how many people you vote for up to some threshold or maybe there's no threshold, right? You can vote for everybody if you wanted to. So we'll focus mostly on when people are voting for fairly small numbers, but for your thoughts you can think of like K equals 30. You can vote for up to 30 people, say. And that makes sense when the committee is for us of size 21.
00:16:14.828 - 00:16:23.258, Speaker B: I was asking because if K is like small, you can almost cheating a little bit, but you can almost say what I mean by honest strategy is that you actually vote for K people.
00:16:23.344 - 00:16:25.514, Speaker A: Yeah, you always vote for that many people, 30.
00:16:25.552 - 00:16:26.886, Speaker B: That's sort of unreasonable.
00:16:27.078 - 00:17:07.130, Speaker A: So that's right, you could say and we'll look at this a little bit, we'll do some simulations and stuff where basically we say like, suppose everybody just votes for their top two or very votes for the top three. And the sort of punchline is that that actually does really pretty well, even though that's not the optimal strategy preference like BACD or whatever. You're saying that the votes have like different priors over which. So here's the little bit of this model. We assume there's M candidates and M is known. Every candidate for the committee is probability with some is honest with probability P and dishonest with probability one minus P. So there's two types of candidates, good and bad candidates.
00:17:07.130 - 00:17:17.790, Speaker A: You have N voters and every voter receives a signal about the candidate's type. And this allows them to calculate a posterior that that candidate is honest.
00:17:17.940 - 00:17:21.338, Speaker C: In practice, that signal is past behavior, not current round behavior.
00:17:21.434 - 00:18:07.358, Speaker A: Yeah, I mean, it could be past behavior. It could be like what you heard about them on Twitter. It could be so we assume it's a very noisy signal. Right. But you have some information about the candidate. Then the question is sort of how does this voting work as an information aggregation mechanism? Like is it good at sort of crowdsourcing the weak signals that people get? My intuition, when you started this, I thought, yeah, what's the information structure? Like, what do you are assuming the signals are IID conditional on type? Yeah, the signals are, IID conditional on type. So yeah.
00:18:07.358 - 00:19:14.206, Speaker A: So and I sort of thought there was like a simple thing would be maybe like if you want two thirds of the committee to be honest, you vote for people who you think have a two thirds chance of being honest. Like I thought there would be some kind of simple thing like this and you could solve it in like an hour and it would be fun. And and so we would call this like a threshold voting strategy where you basically vote for everybody who you think is above some threshold tau of being honest. And if you do this, then you can analyze things reasonably nicely because the signals are, IID, conditioned on type. Then the number of votes, if everybody follows a strategy like this, the number of votes each candidate gets is independent, conditioned on type. And it's a Poisson binomial, right, where it's not like a regular binomial because you might have different voters vote for you with different probabilities, because the different voters might have different precision. So it's like you're adding up a bunch of zero ones with different probabilities, but they're independent because these signals are independent.
00:19:14.206 - 00:20:08.434, Speaker A: So we get a Poisson binomial. The number of votes for a malicious producer or malicious candidate is also a Poisson binomial with different parameters. And now you're going to get some separation. And now the chance that you have an honest committee is a little bit messy because now you have to say, what's the probability that if the committee is of size K, what's the probability that the two third K sample from this distribution is above the one third K sample. From this other distribution, you can get kind of messy sums for doing this and you can actually solve this out. And so you can get some analytic bounds on this when people behave like this. And so here if you have one voter and you set some parameters and you do this, you get actually like if the voter says, I'm going to vote for everybody who's more than 0.2
00:20:08.434 - 00:20:21.686, Speaker A: honest, this is not good. This is like where you think, here I'm voting for everybody who at least has a 0.6 chance of being honest. So this almost looks good. There's like a spike that's like around two thirds. Turns out it's not at two thirds in this example. It's like at 74%.
00:20:21.686 - 00:20:47.598, Speaker A: And basically what's happening here is here your threshold is too low. You're kind of voting for everybody and you have no distinguishing ability. And here you're voting for nobody and you have no distinguishing ability. And there's some way where you can start to distinguish so that's look good. If you have two voters, though, it's bad. All of a sudden things get totally messy because now every candidate gets zero, one or two votes. Here your threshold is too low, everybody gets two votes, and then you move the threshold up.
00:20:47.598 - 00:21:26.560, Speaker A: If both voters follow the same threshold, then here the good candidates get two votes, the bad candidates get one vote, and then you move it a little bit and they both get one vote. And then here the good candidates get one and the bad get zero. And then here they both get zero. And so it's kind of a mess, right? Even with two voters, there's not some clean strategy of vote for two thirds honest like I was hoping. In three voters you get three peaks and it's bad. But once you get a lot of voters, right, the central limit theorem kicks in. Basically you have concentration bounds and everything is kind of fine whatever anybody does.
00:21:26.560 - 00:22:24.350, Speaker A: And so as long as everybody follows a threshold sort of in the middle, it all works pretty well. But there's not like this clean sort of thing that I was hoping for when I started this. And so the question is, like, how should you choose this optimal threshold? If you were going to try to be a voter, how should you think about this and what value maximizes the committee? This is actually really complicated because it depends on the number of voters a lot in this complicated way. But once you have a lot of voters, things are generally okay. But if you think about it for a minute, this isn't the only kind of strategy. Like another type of strategy is basically don't have some threshold, but instead vote for the top three people you think are best. That's actually a different class of strategy than vote for everybody you think is like a 75% chance of honest and even these two strategies, you can have more complicated strategies, but these two are sort of the ones we focused on because they seem kind of the most natural in this cardinal voting strategy.
00:22:24.350 - 00:23:01.194, Speaker A: You just vote for the top Kappa candidates in our thing, and then you get single choice voting if you vote for the top one candidate. So it's sort of like a generalization of single choice voting. The problem here is that now who you vote for is not independent anymore. And so you can't get any kind of analysis. It's a mess because if somebody is at the top, they've pushed somebody else out of the top. But you can do some kind of simulations. Actually, even before this in EOS, we scraped all the votes from EOS and it does seem like people are kind of doing this.
00:23:01.194 - 00:23:11.120, Speaker A: The committee size is 21, and so this is the fraction of the stake and how many people they voted for. Right. So the limit is 30. So a lot of people just max out their votes and just vote for 30.
00:23:13.730 - 00:23:16.546, Speaker C: Are these proprietary clients? Is this open source clients or is.
00:23:16.568 - 00:23:57.866, Speaker A: This there's only like one client. When you say client, the client, you mean the node. They're private companies running these nodes. I think they're all running the same software client. You can take this with a grain of salt in terms of but this is sort of the approval voting data we can get because Cosmos doesn't do approval voting. But it's just sort of interesting to see whether this huge spike at 21 like a lot of people seem to have this heuristic, which is if you want a 21 person committee, you vote for 21 people. And and that heuristic actually works when you're the single voter.
00:23:57.866 - 00:24:23.174, Speaker A: So if you only have one voter, you can show that this voting for and you want a committee of size K. Voting for K people is optimal and you get the best thing. So here's how many people you vote for. If you vote for ten, it's not good, but if you vote for 21, that's the best. And it gets worse as you go down because you get less discrimination. And just for reference, here's this single voter threshold thing that you can never get as high following the threshold strategy as you can just voting for the 21 best.
00:24:23.372 - 00:24:25.462, Speaker B: So optimal here could mean a couple of different things.
00:24:25.516 - 00:24:26.120, Speaker A: Yeah.
00:24:27.130 - 00:24:29.042, Speaker B: First, I assume you mean probability.
00:24:29.186 - 00:24:30.794, Speaker A: Probability of honest committee. Okay.
00:24:30.832 - 00:24:35.510, Speaker B: But even then, is it conditional on signals Optimals?
00:24:35.670 - 00:25:32.442, Speaker A: No, this is right, because if you can condition on signals, you can have now an even sort of broader class of saying we focused on these two really simple types of strategies, which we called like threshold. In cardinals, you vote for everybody with this probability more or the top 21 or something. But you could imagine saying something that the strategy is much more complicated depending on the exact signals you get. If there's a gap between signals, then you do something. Those strategies get even crazier so you might be able to do something. So this is optimal in the sense of if you assume your strategy, you have to fix your strategy before you see the realization of your signals. And then you can now ask this question of like, well, if people are going to follow a kind of cardinal strategy and maybe a suboptimal one, but how does it work if you ask people how many people they're going to vote for and it actually gets better.
00:25:32.442 - 00:26:02.854, Speaker A: So if everybody votes for just their top choice, this is the success probability for some low parameters. So this is like single choice voting. If everybody votes for their top two, you do a little better. If you top three, you do a little better. Top four, you do a little better and seems to get it's increasing for a while. So basically even if people follow a suboptimal kind of strategy, they just follow these heuristics like, I'm going to vote for the top five people. You do much better than if you just say everybody votes for the top one person.
00:26:02.854 - 00:26:19.226, Speaker A: And in this really idealized model where everybody's incentives are aligned and so the voters are giving you some information, you do obviously better than a lottery because in the lottery it's just random, right, in this model. And so the lottery is this fixed line because you don't get to vote for anybody.
00:26:19.328 - 00:26:26.270, Speaker C: But a lottery where we remove sorry about that. A lottery where we remove the bad people according to some strategy might be better.
00:26:26.340 - 00:27:14.922, Speaker A: Yeah, maybe. We're thinking of the single shot analysis because the algorithm paper considers the single shot analysis. You say we want the probability we don't consider even repeated elections because we just want the probability to be so low that if we take a union bound over every election we're ever going to do, the probability will still be small. Right, but yeah, there's then all kinds of interesting stuff if you now say we're going to do repeated elections and now you can penalize people, right, and you get all kinds of sort of more interesting mechanisms basically. But yeah, this doesn't really incorporate that at this point. But in these things all the methods converge sort of exponentially quickly in the number of voters. But the optimal strategy is super hard.
00:27:14.922 - 00:27:29.294, Speaker A: But the kind of interesting take home for me was that the approval voting seemed to really help in this information aggregation here in terms of getting this committee that even though you can't find an optimal strategy, having everybody vote for two people actually does better.
00:27:29.492 - 00:27:32.082, Speaker B: You just mean the graph on the previous slide, right? Okay.
00:27:32.216 - 00:27:37.090, Speaker C: Are you going to talk about protocols for it or just in terms of the bandwidth? We're always going to pay an extra.
00:27:37.160 - 00:28:00.566, Speaker A: N factor to do that. Yeah. So no, we. Didn't consider that at all in terms of but I don't think that's a big thing in terms of well, okay, so in terms of the protocols. Right. So the way a lot of these things are set up and so one reason these things stagnate is you vote by locking in a contract and you can move your votes at any time. So it's sort of continuous voting, but then you're not sending around these vote.
00:28:00.566 - 00:28:03.500, Speaker A: It's not like you're sending around these votes all the time.
00:28:03.950 - 00:28:12.350, Speaker D: Do you have a notion of the max possible in this setting? If you actually had one party get everybody's signal and aggregate them?
00:28:12.420 - 00:28:17.326, Speaker A: Yeah, so that's basically going to be the best and that's like where would.
00:28:17.348 - 00:28:18.826, Speaker D: It be on this graph, I guess.
00:28:18.948 - 00:28:41.818, Speaker A: Yeah, so that's basically the single voter setting. So if you basically just say in this setting where everybody's incentives are aligned, the best thing you could do is just everybody give me your signal, I will calculate the posterior based on that and then I will vote, do the one vote for everybody. And then the best thing you can do is to vote for the 21 people you want. If you can agree.
00:28:41.904 - 00:28:48.378, Speaker D: I guess I'm just wondering where it would fit on this graph. Like what would the actual success probability be?
00:28:48.464 - 00:29:19.560, Speaker A: Okay, so I mean, this number requires to get a graph where we had to set a bunch of sort of random parameters like what's the operi probability that a candidate is honest and what is the variance of the voter signals and stuff. So in terms of how high it would get, that basically you're right, actually, for these parameters, I don't have that on this graph. And that's a good question. Yeah, so I put it on the other graph, but I don't have it on this graph, so I don't know what it would be off the top of my head.
00:29:22.490 - 00:29:27.314, Speaker D: Because it kind of looks like the approval roding. It looks like it's hitting an asymptote.
00:29:27.362 - 00:30:01.518, Speaker A: Yeah, it certainly can't always get better, right. Like at some point it's got to go back down because you're kind of losing information if you've approve of every candidate in the space. So again, this also depends on there's some fixed known number of candidates and once you get close to approving of everybody, you lose any power of discrimination. But yeah, that's an interesting question. I don't know. And so there's like a bunch of other questions you can ask about this. We started looking, we have a recent paper on using quadratic voting as an information aggregation mechanism.
00:30:01.518 - 00:30:26.794, Speaker A: But there's other types of voting. You can have kind of ranked choice voting. Quadratic voting is kind of even orthogonal to approval voting. You could have quadratic approval voting because quadratic is just like how you weight your stake. You can imagine this model is like very simple right now, right? It's just everybody's honest. But if you have some malicious voters. What fraction of malicious voters can you tolerate? You could sort of try to optimize for a committee that has some secondary features like performance or something.
00:30:26.794 - 00:31:02.834, Speaker A: You could imagine vote buying in these systems. And so there's a lot of kind of interesting things here. But our first step was to try to move these analyses of the lottery mechanism into a system where there's voting because a lot of these committee based consensus have interesting voting mechanisms. Okay? So that was what we're thinking about in terms of electing blockchain committees. But then there's the second kind of voting. I mean there's lots of kinds of voting, but the second thing I want to talk about is sort of Dao governance. And it seems like the voting models here are pretty different in terms of how you think about token weighted voting in the Dao context.
00:31:02.834 - 00:31:41.278, Speaker A: So we're going to switch gears a little bit. We'll still talk about approval voting because approval voting still comes into these systems and this is more work in progress so I won't have as clean results. But let's talk about sort of Dow governance. So Compound sort of started a lot of the Dow governance hype in 2020 and they introduced governance at the beginning of DFI summer and this was lots of fun. And then lots of people kind of forked compounds governance. Governance either like directly forking their contracts or essentially taking their model. And their model is what gets called like initiative voting or sometimes amendment voting.
00:31:41.278 - 00:32:12.860, Speaker A: And the way it works is like voters make yes or no proposals. You need to have some threshold. So in Uniswap you need like 1% of the tokens to be able to make a proposal. And for Compound you need 25,000 comp tokens to make a proposal and then all the voters have some window of time to vote yes no on this proposal. And if it gets a majority in that time, then it passes, otherwise it fails. And the time windows seem to be about three days. There's lots of sort of similarities in how these systems are done.
00:32:12.860 - 00:32:53.506, Speaker A: We scraped all the votes from Uniswap compound lido and Ave and Maker. And so separate from this talk, if you're interested in actual voting behavior, we have that too. But then the outlier here is Maker. Maker went and did their own thing which they call continuous voting. And we'll talk about that in a little bit. But basically there is no time window and you can just vote for any proposal that's ever been made. And that kind of thing makes sense in this model where what we're going to talk about is the proposals are mutually exclusive, right? So anytime some proposal comes up, it's mutually exclusive, you can only be in the state of one proposal.
00:32:53.506 - 00:33:23.006, Speaker A: And this is why this is called like an amendment voting. You're amending the laws but there's like only one set of laws. And this makes sense for a lot of blockchain votes where you're setting the fees on uniswap or something. You're setting the loan to value ratio on Ave or something. There can be only one loan to value ratio and somebody might say it's like 60%. Somebody can make a proposal to make it 70%. But you can't have both, right? There's just one parameter here or like the liquidation threshold, how low does your collateral have to go before you're liquidated? There's like one parameter here or one parameter per collateral asset.
00:33:23.006 - 00:33:50.330, Speaker A: But these are mutually exclusive. Some DeFi votes are not mutually exclusive. Like do we deploy to this layer two or that layer two? You could do both. This analysis doesn't really capture that and the continuous voting model doesn't address that at all. So just as we talk about the rest of it, we're thinking of the mutually exclusive votes here. Yeah. Just to clarify, you think about binary votes, right? Not voting on the continuous.
00:33:50.330 - 00:34:26.486, Speaker A: You can think of a continuous kind of thing. You might be voting on something continuous like what the fee should be. But the voting mechanism, like what compound has set up is only binary votes. So if you want the fee to be 3% or 0.3%, somebody needs to make that proposal and then you get to vote yes no, and if you want it to be zero point 35%, somebody needs to make that proposal. So it's an interesting question and actually we have another paper on looking at essentially where the votes are continuous. So imagine you want to set a fee and it's from a continuous space like zero one, and voters get to propose what they want the fee to be.
00:34:26.486 - 00:34:58.414, Speaker A: And then you do stake weighted aggregation to find the fee. How does that do as an information discovery mechanism? So again, I like these models where voters have imperfect information. Nobody knows what would be the best fee to maximize the profits for uni holders. But we assume their incentives are aligned, they have different amounts of information. You'd like to sort of crowdsource from these people something. So you can ask this question where voters are allowed to make a continuous vote. We have a paper on that.
00:34:58.414 - 00:35:43.134, Speaker A: I'm not going to talk about it much here, but I'm happy to talk to you after. It's a really interesting model, but it's an interesting question to me. Why doesn't compound do that, right? Compound could have done that, but they don't. And again, it only works for some things like continuous voting doesn't work of like do I deploy to Arbitrum or not, but for fees and stuff, which is a big part of a lot of this, or loan to value like system parameters in general. It's a really interesting question. Why not allow people to vote continuously in there, not continuously in time, but have continuous voting space? So when I started thinking about this, I wanted to see who's written about this and I found this paper that was analyzing crypto initiative voting. I was like, great, somebody already did this, I don't need to do it.
00:35:43.134 - 00:36:21.674, Speaker A: And it turns out it was written in 2004 analyzing exactly this voting mechanism on crypto initiatives. And I was like, how is this possible? It was very funny. They model this exact kind of thing for initiative voting or amendment voting, and here's what they mean by crypto initiatives. And I want to go through this example because it's a fun example. And they say, suppose you have something, there are three proposals and there are three voters, okay? And we say Q is the status quo. So this is like we're starting things out. The initial fee is zero 3% and somebody wants to make a proposal A to like zero 5% and somebody makes a proposal B to zero 7% or something.
00:36:21.674 - 00:36:49.490, Speaker A: And here's the voters, there's no uncertainty. The voters know what they want. And so initiative voting says first if we vote A against Q, somebody proposes A, a wins two to one, somebody proposes B. Now the status quo is A, right? And A still wins over B, right? And so the final outcome is A. So this is like how initiative voting works. But voter one is unhappy here. Voter one wanted B.
00:36:49.490 - 00:37:15.978, Speaker A: So what does voter one do? Voter one introduces what they call a crypto initiative and that's where this crypto initiative came in, which is they say voter one can introduce a new initiative and voter one introduces this new option X. And now what happens if the votes are in the order AXB A beats Q like it did last time, but now X beats a two to one.
00:37:16.144 - 00:37:22.446, Speaker C: How did XJ jump ahead into the second position? They can just put it in the second position.
00:37:22.468 - 00:38:06.240, Speaker A: Yeah, so they get to choose. You're a malicious party. You craft an initiative that, you know, you look at the three voters, you can choose your own preference of ordering of it and you just choose it. So you craft an initiative so that voter two hates it and voter three loves it. And maybe depending on the voters, that's not possible. But assume for a second that you have that control, right? And then in the third round of voting, b beats X and B is chosen. So by introducing this crypto initiative, which you didn't want, voter one actually gets to move from A to B and they get to make themselves happier, right? And so the point of that paper was to say, like, this mechanism is really vulnerable to this kind of attacks of people introducing initiatives that they don't want.
00:38:06.240 - 00:38:29.806, Speaker A: And another thing you can notice from this graph, right, is that the outcome is also not Pareto optimal, right? Like everybody would have procured Q to B, but B was still chosen, right? This is bad. And so this is sort of like classical stuff that was sort of new to me, but it's classical in the voting literature and there's like a really nice way to think about this, which is in terms of explain why it's.
00:38:29.838 - 00:38:31.010, Speaker B: Called the crypto initiative.
00:38:31.090 - 00:38:59.040, Speaker A: Oh, they called a crypto initiative because it's like a secret kind of initiative that is put in there for your secret, like your malicious goal of making bu win here. But that was the only thing there was no cryptocurrency initiatives. Yeah, I guess maybe more, but yeah, when you search for cryptography and initiative voting, or crypto initiative voting, this comes up and it's great. And I was like, it's perfect. It's exactly the model.
00:39:00.450 - 00:39:18.254, Speaker B: I feel like this is conflating two different things, right? One is just like the specific voting procedure you're using, right. And so, like, round based procedures have lots of problems. The other thing is this kind of insert an extra initiative that's right. But basically satisfying would be like extra initiatives screw up always.
00:39:18.312 - 00:39:38.940, Speaker A: You might do voting, but the extra initiatives are much easier to screw up the round based thing. Right. Extra initiatives are not going to where everybody's preferences are fixed and known. Right, and they're not going to screw up plurality voting. Really? Actually, that's not true. They can screw up plurality voting, too. That's an interesting question.
00:39:39.710 - 00:39:45.630, Speaker B: I guess you're saying that if you look at Compound, uniswap, et cetera, they're basically doing round based voting.
00:39:46.370 - 00:40:42.030, Speaker A: Yeah, they are doing round based voting. And in terms of thinking about round based voting, there's this really nice notion of this tournament graph where you just say you make a graph of all of the proposals and you have directed edges from which one would win in a head to head competition. And what basically this third initiative did is it puts in this X, which now makes this cycle, and now you can get anywhere. And this is like the condorse paradox, where even though everybody's preference orders are transitive, the final ordering is not transitive. And you can say that there's this notion of like a condorse set where basically everything in the set is preferred to everything outside of the set and is the smallest set. With this property that in this initiative voting, then the outcome is always part of the condor say set and anything in the condor say set can be reached. So the outcome is very dependent on the ordering of the initiatives.
00:40:42.030 - 00:40:48.638, Speaker A: And this is, again, potentially an issue with this iterative type of voting.
00:40:48.814 - 00:40:57.982, Speaker B: Once you have condor say cycles, you're just in trouble, basically. Right. And in particular, the first part of that, that's a good thing, the first property, right?
00:40:58.056 - 00:40:59.558, Speaker A: Yeah. That you always get to something to.
00:40:59.564 - 00:41:07.480, Speaker B: Be part of that and then I don't know, it feels like the extra initiatives would be bad for all.
00:41:08.890 - 00:41:17.862, Speaker A: Yeah. No, that's a really interesting question. Right. It's like which ones are susceptible to adding extra initiatives and having the outcome be much worse?
00:41:17.926 - 00:41:21.660, Speaker B: Presumably all of them I would think so, yeah.
00:41:27.250 - 00:42:18.826, Speaker A: To sort of change things up, right? Maker does what they call continuous voting and they can do this because their executive votes at least are in this exclusive. They're the mutually exclusive because they're actually voting on a contract. They have their system parameters are set by a contract and you just get to say I want this address, this is the contract, I want to hold the system current. It's like a list of variables basically. And so you just vote on this list of variables and these things are for adding and removing collateral types and vault types and various system parameters. And as sort of an aside, if you've spent some time with MakerDAO, they made up bizarro names for everything they do. So we wanted to think about these kind of dao governance and the way I wanted to think about it was different than sort of the analysis we saw in terms of these classical analyses where everybody has a strict preference ordering.
00:42:18.826 - 00:43:18.562, Speaker A: I want to say that basically again, people have imperfect information but their preferences are mostly aligned. Like if you're voting for the loan to value ratio or what types of collateral for MakerDAO we can, to a first approximation, I think, assume that all the Maker voters want Maker to succeed mostly and they want to choose things that will benefit the protocol the most. There's a lot of uncertainty of what should the loan to value ratio be to be the safest or what should the collateral types is it safe or not to use Bitcoin or WBTC as a collateral type? And so as like an example, they have limited information. Here's an ave proposal and it's a proposal like this adjust 14 total risk parameters. I'm pretty confident that nobody who voted on that really had perfect information on what that meant. Even the people who proposed it did a bunch of simulations right, as Chaos Lab and they're probably pretty well informed, but they still don't know what's going to happen next year. So I think this model of having weak information is really interesting.
00:43:18.562 - 00:44:41.290, Speaker A: And so then the question is how does this kinds of initiative voting or continuous voting or approval voting play into this question of information aggregation? So we have this model where basically every proposal has some unknown quality, like proposal Q has unknown quality QJ and the voters receive some signal, which is some noisy signal about the quality and then they have to choose which proposals to vote for. And Maker not only does continuous voting, it does continuous approval voting. So you can approve of a whole bunch of spells, but of contracts with the parameters and the one with the most approvals wins. And so the question is kind of like what type of mechanism is best at crowdsourcing information here it's kind of like the last one but in now a different model and we're thinking about this kind of initiative or head to head voting. And then you can also ask questions about malicious attack. I have some early results on this and so I won't go too deep into this because we're just sort of finishing these things or we're working on these now. So I don't know how easy this is to see here, but basically we said suppose what is the expected quality? This is an example, you have four proposals, they have different qualities and everybody gets a signal about these qualities and the qualities are between zero and one.
00:44:41.290 - 00:45:56.558, Speaker A: And what's the expected quality of the winner where the randomness is over the random signals people get. There's three cases for initiative voting because it depends on the ordering, right? Initiative voting is like very dependent on the ordering. So we say imagine you have the best case ordering, that's this gray line or brown line, I guess up at the top, if initiative voting, if you have the best case ordering, does really well, but you can focus on the red line, is the random ordering. So if you just choose a random ordering of the initiatives, you do pretty well. Like once you have some voters, right, the expected quality of the proposal goes up to one really fast and interestingly it does better than this is plurality here. Again, these colors are hard to see here, but basically plurality voting does worse at aggregating information than initiative voting in a random order and it only crosses at the worst order if you say the worst possible. If the maliciously ordered proposals for small numbers of voters, plurality voting does better, but plurality voting does badly.
00:45:56.558 - 00:46:47.826, Speaker A: I was surprised about this in terms of crowdsourcing information and then you can ask, well, what if you allow approval voting like maker does? Does that do better at aggregating information here and here again, the approval voting is super hard to the other things, right? In our model it's sort of simple. You can get analytic closed form expressions and you can model everything. And approval voting, you have to simulate. But approval voting basically does worse if everybody votes for their top two. That actually does worse at information aggregation than either plurality where everybody just votes for the one or even the random ordered initiative voting. So this was a surprise to me in terms of this information aggregation that this initiative voting somehow is good for that. So here only one proposal wins, right? Yeah.
00:46:47.826 - 00:47:25.326, Speaker A: So here only one proposal wins. Approval is kind of the case of having more votes than their outcomes. But it's basically a way of saying like I have limited information, right? Here are two, right? So I'm a voter, there are two candidate proposals I both think are pretty good, right? And if I'm only allowed one vote, I may have to choose and I kind of choose randomly between them. And if I choose one that other people didn't choose, then that's kind of bad and so you can still think of approval voting even when there's one winner. And so again, this is implemented in MakerDAO. There can only be one winner, but you can approve of any number. There's no limit on the number of approvals you can make.
00:47:25.326 - 00:47:29.700, Speaker A: With this idea that I'm kind of indifferent between these, I just can't distinguish them.
00:47:31.670 - 00:47:37.614, Speaker B: And so if you checked, are these rankings pretty robust over different we've tried over some sets.
00:47:37.662 - 00:48:14.240, Speaker A: Yeah, I mean, so, yeah, again, we've had to choose. This plot here is there are four proposals that were uniformly distributed in one. But it seems reasonable we can't actually go up to big numbers because approval voting gets so complicated once you have a lot of proposals calculating the winning probability. If you have a lot of voters and a lot of proposals and everybody's voting for two, and if you want to simulate whatever these are, it's not so bad. These are simulations, but it doesn't scale well for a lot of proposals. Basically.
00:48:17.170 - 00:48:21.522, Speaker B: In hindsight, is there an intuitive reason why you're seeing this?
00:48:21.576 - 00:48:32.610, Speaker A: I'm not sure. I was trying to figure this out. I don't know why this is. I'm saying this is like pretty new. We're still thinking about this. I don't know why this is. Because I thought approval voting would be better.
00:48:32.610 - 00:49:29.778, Speaker A: Right? Like, that was what I thought coming into this. And here's where it is kind of better. If you're worried about malicious takeover, this is another thing that a lot of the white papers will talk about is like how you imagine somebody's attacking your Dow or something. How much vote power do they have to get to do something bad? What's the difference between preferences and beliefs? What's the difference between saying I have different preferences? I'm trying to get the maximum expected utility versus just saying I have different signals of one centralized quality. Okay, so in our model, every proposal has a true quality. And you get some signal, you get some noisy signal, you get like a quality plus epsilon, and every voter's payoff is increasing. For simplicity, think it is exactly the quality of the proposal that's elected.
00:49:29.778 - 00:50:29.094, Speaker A: So if you elect the proposal with true quality Q, then every voter's payoff is Q. But I mean, voters make decisions based on their expected quality, which is S. And so I guess how is that different than saying, okay, let's imagine everyone's utility, like actual utility is drawn from the same distribution as S is drawn. And then you're like, instead of saying Q yes. You say your utility is some distribution f yeah, actually, I don't know off the top of my head how that would change things. Sorry, we could talk about that, but yeah, I'm sorry, I don't know what that would so the other thing we want to ask is suppose you have some minority that wants to kind of tank your proposal and get you to choose the worst of the options, right? Like how does your system hand up handle against that? And here approval voting does. Well, initiative voting is kind of the worst.
00:50:29.094 - 00:51:23.180, Speaker A: So this is on the X axis is the percent of the vote that the malicious party controls. So here they control like 10% of the vote. And you say here again, there's four proposals and what's the chance that the adversary can get you to choose the worst of these proposals, right? The adversary wants to destroy things and so if they have 10% of the vote and you're doing two approval voting, they never get you to choose the worst one. But if you're doing this initiative voting, actually like 20% of the time they get you to choose the worst of the proposals. And so this initiative voting is up here. The adversary has much more control once they for these cryptographic parameters of the adversary controls a third of something. If the adversary controls a third of the voting power, they can always get you to choose like the bad proposal in the initiative voting and they almost never can if you allowed two approval voting, which is kind of interesting.
00:51:23.180 - 00:52:13.914, Speaker A: And I think what's happening here is that basically voters are not that good if their signal is bad. Voters are not that good at distinguishing two proposals that are kind of close to each other because they get some distribution and two distributions are close, the voters can't distinguish them. And so in head to head voting and this initiative voting, the adversary can kind of push you a little bit to the bad one every time. So if the adversary controls 10% of the vote, it can kind of push you kind of like 10% towards the bad one. And if two things were almost the same, they can push you to the worst one in the first vote and then the second vote they can push you a little bit more to the worst one. In every vote they get to push you a little bit towards the worst one, basically. And in the continuous voting where you get to see everything, 10% of the vote just isn't enough to get you towards this bad one.
00:52:13.914 - 00:52:30.994, Speaker A: All the voters can see that this is the worst one and none of the voters were voting for this worst one anyway. And so this kind of thing that like the sequential voting allows the adversary to sequentially push you towards the bad outcome seems to give you this kind of lack of robustness reuse its state.
00:52:31.032 - 00:52:32.626, Speaker B: To attack every vote as opposed to.
00:52:32.648 - 00:53:23.620, Speaker A: Just have it in a one shot. Yeah, I think that's the and again, this approval voting helps you with this because again, it kind of just puts all the votes towards the slightly better stuff. Like if you vote for two things, you just have tons of votes for the slightly better ones and you're never going to let the adversary get you to the really worse one. So this is sort of where we are at this initial analysis of this. But they're interesting questions like sort of how much, if the adversaria gets to introduce new proposals, what happens here? And we haven't thought about that too much. And just as final wrap up as mentioned before, we have a paper that is asking what happens if you allow people to directly vote on a parameter. So this is a paper we called Token weighted Crowdsourcing and I'm happy to talk about that later.
00:53:23.620 - 00:54:59.674, Speaker A: There's other things, right? You can have rank choice voting and if you have rank choice voting that's not even a single thing, right? You have to say once people rank their votes, how do you actually choose the winner based on these rankings? And I haven't seen much in terms of how does rank choice voting work as an information aggregation mechanism? Again, in this kind of model where people have poor information but sort of aligned preferences, how does rank choice voting work and how does it compare to these kind of things? I think that's like a really interesting question that I'd be interested in exploring in the future. And then there's questions if we have a minute or two. Another kind of question in this space that I think is really interesting is for different types of systems you might want to really protect the minority stakeholders. So from the original Dao, this is like a section from the original Dow white paper which is like you have a community investment fund and they were really worried of this thing if you put in like 20% of the money to invest and you have no say in where it gets invested. And so a big chunk of the white paper and a big chunk of the complexity of the system was to prevent against this majority robs minority attack. And so that notion of a Dow had this thing if people vote to invest your money in something you don't like, you could fork off to choose a child Dow which then the fact that you could choose these child Dows had a big effect in terms of how the whole Dow fork played out. But this was all about this question of you have a community investment fund and if you have 5% of the stake or 10% of the stake, it's not like you get to choose 5% of the outcomes, you get zero choice.
00:54:59.674 - 00:55:40.666, Speaker A: And so how do you ensure that people have proportional representation that if you're voting to invest in things or if you have Bitcoin grants or something, if you put in 5% of the money, you should choose 5% of where things go? And so just looking around, there have been really interesting proposals in the political science literature that I haven't had that much time to think about but I want people to think about in the blockchain space. So one of them is Storable votes which. Is right. You know, there's going to be sequential proposals so every month we're going to allocate $10,000 or various things and if I choose to abstain this month my vote carries over to next month. And so if I have 5% of the vote maybe I could get closer to 5% of the money to allocate.
00:55:40.698 - 00:55:45.174, Speaker C: Stake weight is basically divided across your votes. You could just say like I could spend this much and budget.
00:55:45.322 - 00:55:53.474, Speaker A: Yeah, no but I mean it's not exactly the same. Right, because if I vote it goes.
00:55:53.512 - 00:55:56.930, Speaker C: Up own the system in that one final vote.
00:55:58.890 - 00:56:41.214, Speaker A: Yeah. Another proposal that I found in literature is this balance voting which imagines like two phase voting. So you have like a two step thing where so imagine you want to add a collateral asset to maker or something. In phase one you get to choose yes or no. Do we add the collateral? And then the people who get to vote in phase two were only the people who lost the vote in phase one. And so phase two might then set the parameters around how you get to use this. There are obviously potentially issues around this but again, it's kind of an interesting type of model that both of these systems are designed to get at this thing that the Dow mechanism was trying to do with its child dows and would be, I think, pretty straightforward to deploy in the blockchain space.
00:56:41.214 - 00:57:06.714, Speaker A: And so I think people should kind of be thinking about I don't know, again if these are exactly the best mechanisms but there's an interesting question of if your goal is to protect minority stakeholders, how should you do that? That's mostly what I wanted to share with you today but I think there's lots of open space in this blockchain voting system. Thanks. Yeah.
00:57:06.752 - 00:57:08.662, Speaker D: On those last two points about storable.
00:57:08.726 - 00:57:46.390, Speaker A: Votes and balanced voting, are you aware of any real world applications? So I found a handful of papers and these are links and I can give you the slides. They've tried them, I think, in some lab experiments and I don't remember if there were any in the crypto space. I've never seen anybody talk about this in the crypto space at all but I just wanted to throw these out here more to just get people thinking of like there's a lot of mechanisms that you could use. The space of how you aggregate votes is just enormous and depending on what you want, you should think about these crazy mechanisms.
00:57:47.130 - 00:58:00.038, Speaker D: So curious. Do all of these basically assume the vote is completely synchronous that you can't employ a strategy based on the votes that have been that you can see other people have cast within that round?
00:58:00.134 - 00:58:08.654, Speaker A: Yeah, in our model all the votes are completely synchronous. Yeah, that's right. That's also an interesting question, right? Yeah.
00:58:08.692 - 00:58:20.586, Speaker D: Well, that's definitely something we've been thinking about, about running tally privacy while elections are actually happening. So you can simulate the synchronicity, but yeah, that's obviously one solution with crypto.
00:58:20.618 - 00:58:22.980, Speaker A: Is just as high as synchronous. Yeah.
00:58:23.350 - 00:58:38.306, Speaker D: I guess the other question is if there's any actual strategy proof. Well, I guess no election strategy proof, but is there anything that's better or the strategies are more difficult assuming that the election is not synchronous?
00:58:38.498 - 00:59:00.670, Speaker A: Yeah, I don't know the answer to that. I bet there is. Right. That's, again an interesting question, but we haven't looked at we just assume everything is synchronous. And sort of related to that, there's interesting questions about bribing voters. Reviewers on these papers immediately ask about, like once you can do this, you can ask about Bribing voters. And blockchain is a great space for bribing voters.
00:59:00.670 - 00:59:28.680, Speaker A: So there's a little bit of cryptographic stuff you could do there, which I think is actually an interesting question about. Even if you make the vote tally private using some ZK mechanism, usually in most of those things, the voter still has the witness so they can still effectively sell their vote. And so you want some kind of like deniable encryption kind of mechanism so that you couldn't effectively sell your vote. This is sort of like an interesting thing of can you make that?
00:59:30.110 - 01:00:04.330, Speaker B: Okay, so I wanted to mention reality aware social choice is a variant of social choice, which could be a basis for civil resilience. I'm going to share in the chat. Try to share in the chat a reference yeah. Which is relevant for approval voting and also parameter selection in the presence of civil voters. So just wanted to call your attention to that. Another strand of research in this direction.
01:00:04.490 - 01:00:07.780, Speaker A: Great, thanks. It.

00:00:09.100 - 00:00:20.988, Speaker A: I'm very happy to introduce Nisrit Tas, who's a PhD student at Stanford doing all kinds of great work. David Shay's group. So very happy to have him here. And Nisrit, the floor is all yours.
00:00:21.164 - 00:00:54.236, Speaker B: Okay, let's get started then. Yeah. Thank you for inviting and joining the seminar. I am, I am Nusrat Tas and I will be talking about crypto economic security for data availability committees that I will refer to as DAX for short. This is joint work with professor Dan Bonet here at Stanford. Let's get started. So I would like to start with a survey of the data availability landscape on L2.
00:00:54.236 - 00:01:44.344, Speaker B: So we here have a graph of trust versus the cost for the layer one blockchain, which many of these L2 systems depend on. So the first solution that comes to mind in the data availability landscape is on chain data. And this is a concept encapsulated by roll ups and some examples include Starknet and Zk sync. So in the solution, the data is simply put on the layer one chain. As a result, the cost for the layer one chain is high, but the trust is also high because the layer one chain is trusted. For the security of the L2 applications, an alternative solution is to use an off chain data availability committee, or DAC for short, to store the data. So these DACs are used to perhaps store the data temporarily and to make it available if they are needed by the applications.
00:01:44.344 - 00:02:38.640, Speaker B: And this is a concept encapsulated by volidioms such as Starkx and ZK Porter. There are new ones like Eigen layer, so the cost for the layer one chain is much smaller as compared to the on chain data solutions. But the trust is also smaller because we now have to trust an external set of entities that we call the DAC to persist the data. By the way, please interrupt whenever you have any questions or if anything is unclear. And a newly emerging paradigm in this space is off chain data with data available to sampling. So in these solutions, the data is again delegated to an external set of validators. But these validators persist the data in the form of a separate blockchain like the celestial blockchain or polygon avail, and these solutions typically support data availability sampling.
00:02:38.640 - 00:04:00.948, Speaker B: This data availability sampling solution enables light clients to verify the availability of the data without downloading the full blocks in these off chain blockchains. Here, as this figure indicates, there is an inherent problem with the data availability committee solution, namely the low level of trust that we have on these solutions as compared to the onchain data and this indeed constitutes the heart of this presentation. Ideally, security of L1 architecture relies solely on the L1 blockchain. This implies that we cannot simply trust the data availability committees, because that would mean that we would be introducing an extra trust assumption on the security of the l one architecture, and in particular, a malicious DAC can promise to preserve the data, but simply delete it because it's more profitable to not spend the effort on persisting the data. Luckily, there are solutions, like proofs of custody, through which these lazy DAC members can be slashed and they can be reliably punished. And the keyword here is reliable. The other line of attack a malicious DAC can do is to basically promise to reveal the data whenever the data is queried, but simply withhold it even though it has the data in its memory.
00:04:00.948 - 00:04:48.996, Speaker B: And it might do this because it might try to extract some random out of the querying clients. Unfortunately, unlike the lazy DAC members problem, there is no solution to reliably slash the data with the committee members in the case of such attacks. And the reason why there is no solution to reliably slash them is something called the fisherman attack. So fisherman attacks tells us that the lack of data cannot be provably punished without the existence of a trusted third party. By the way, I took this term from a blog post by Vitalik, so I don't know what is the exact term for this attack. Some people just call it the non accountability of data available to attacks. But let's go with the fisherman attack because it's much shorter.
00:04:48.996 - 00:05:47.416, Speaker B: And let's see why this is the case, why we need a trusted third party, and as almost all of the impossible to result in consensus work, this is an indistinguishability argument. So we have two worlds, world one and world two, that will be indistinguishable in our view if we assume that we are some late coming watchtower to this system. So in world one, we have a malicious block producer that publishes a block, but withholds some part of the data. Upon observing that some of the data is withheld, an honest client raises an alarm. At this point, Watchtower intervenes and starts inspecting the block. However, as soon as seeing the Watchtower intervene, the malicious block producer can publish the missing data and make it look like the block is available or has been available since the beginning of the time. So the malicious block producer made the client look like as if it has raised a false alarm.
00:05:47.416 - 00:06:24.340, Speaker B: In world two, it's the exact opposite. The blog producer is honest and it publishes a full blog. But the client is malicious and it raises a false alarm. And at the end of the day, these two worlds are indistinguishable in the view of a late coming watchtower. So in order to make them distinguishable, we need a trusted party that we trust to have been observing this system since the beginning of the time. And that will tell us which one is honest and which one is adversary. Is it clear so far why withholding data cannot be accountably punished?
00:06:24.760 - 00:06:31.210, Speaker C: Why can't peace sign the block? And then if they publish it with missing data, you can prove it.
00:06:33.980 - 00:07:06.550, Speaker B: So P does sign the block. So we can think of the block as having a header, and the header contains a commitment to the transaction data. And then p signs this header, but the transaction data itself, it can withhold some part of the data. So the question is, why doesn't it sign the whole transaction data? That is because then to verify the block, everyone needs to download the full block. But we generally want to support like clients so that they don't have to download the full block to verify the block to verify the signature. Right.
00:07:07.080 - 00:07:09.030, Speaker C: What does publish mean here?
00:07:09.480 - 00:07:42.156, Speaker B: It means that it produces the block. And let's say we have a blockchain and it's slotted, and then each slot has a leader, and a leader is supposed to propose a block. So it proposes a block with some of the data missing. And let's say the validators are also dishonest. So they all vote for this block, even though part of the data is missing and the block becomes finalized. And then a client, upon seeing this block, it cannot get part of the data, perhaps part of the data it actually needs. So it raises an alarm.
00:07:42.156 - 00:08:11.690, Speaker B: But at this point, the block producer can publish the missing data. And because it doesn't sign the whole data, it just signs the header. It can always withhold part of the data within the block and publish it much later. Is that part clear? Why it sized the header? Because we don't want the client to have to download the whole block to verify the block. Yeah. So let's go forward.
00:08:12.300 - 00:08:16.670, Speaker A: I think there was also a question in the chat that was on the specific point.
00:08:17.200 - 00:08:55.572, Speaker B: Okay, what if the header uses an accumulator that supports proofs of non inclusion? Okay, so let's say the header has an accumulator. Well, Merkel trees, for instance. Okay, let me think. I will address this question a little bit later. I guess I will address towards the end of the talk. I'll just go forward quickly. Yeah, I would like to open a parentheses here about data availability sampling.
00:08:55.572 - 00:09:50.372, Speaker B: So a common misconception in the field is that data availability sampling solves this fisherman attack. Well, this is not correct. So what data availability sampling does is that it enables like clients to verify the availability of the data without downloading the whole data. It can send some repeated samples sampling requests to the block producer, and the block producer can reveal these requested parts of the block, and then the like client will rest assured that the rest of the block is also available under certain assumptions, like a mixnet. However, these data availability sampling solutions cannot prevent the fisherman attack, and it does not make withholding data a provable offense. And the reason is because the block producer can simply choose to not reply to any of these queries by the DAS sampling client. And then the client will conclude that the block is not available and it will complain to, let's say, a later watchtower.
00:09:50.372 - 00:10:47.100, Speaker B: And then when the Watchtower intervenes, the block producer will again reveal their data. So this means that DAs cannot make the withholding data provable offense. You cannot make attackers accountable for their actions. And this is exactly where our work comes into the steps in we propose a DAC protocol that uses an on chain contract and financial incentives to deter the DAC nodes from adversarial behavior. Here, our trusted third party is the on chain contract that lives on the layer one blockchain, which we are allowed to trust for our L2 application. Then we analyze the interaction of the DAC nodes clients in this contract as a dynamic game. And most importantly, we assume an adversary that can not only corrupt the nodes, but also bribe the nodes, and we will see what this extra power gives to the adversary.
00:10:47.100 - 00:11:53.536, Speaker B: And then we also define a notion of optimality for the contract and show the optimality of the contract that we propose for our work. So the interactions of the participants in our DAC protocol can be modeled as a dynamic game that involves three parties that I have previously alluded to. So the first party is the DAC members are called nodes for short, and they are denoted by the notation p one through pn, where n is the number of nodes. And then we have a client v that sends a sequence of data queries to the nodes. And most importantly, we have our contract that lives on the l one chain, and it's used to punish misbehaving nodes, such as nodes, that we withhold the data when the client has a query. And let's make this model more concrete in a voldium setting. So here we have our voldium chain that contains the transactions and state commitments to the blocks, and we have our parent chain which is our l one blockchain here.
00:11:53.536 - 00:13:05.460, Speaker B: So the validium posts the state commitments of its volidiom blocks onto the parent chain along with a proof of validity for the state. However it delegates the data or the responsibility of persisting and making sure that this data is available to a committee of diagnos and there are n diagnodes here. We typically assume this data is erasure coded and we will see why this is a good solution later. And these DAC nodes are responsible to reveal the data upon query. And of course we have a client that might send a query to the DAC nodes and in this example the query could be a short request like an inclusion proof for its account within the latest valid state as recorded by the parent chain. We assume that if k or more out of these end nodes respond to the client over the network, the client using these responses can recover the answer to its query and then the client is happy and the protocol terminates successfully. So here this cape is a parameter of our model and this k is determined by the eraser rate of the eraser coding solution.
00:13:05.460 - 00:14:23.100, Speaker B: Okay, so this is a rosy setting. It might as well be the case that there is an adversary that might corrupt some of the DAC nodes and then these corrupted DAC nodes might opt to not reveal the data to grieve the client, right? So if there are less than k nodes that respond over the network to the client, our on chain contract steps into the game and our on chain contract basically gives the client a venue to complain about this lack of data over the network. So this complaint is simply the query sent to the contract. And to send a query to its contract, the client has to put up a base payment of pc coins. So this could be either to cover the gas cost of complaining to the layer one blockchain, or it could also be adjusted as a parameter to deter spamming clients and to have some leverage over the DAC nodes. The complaint contract is assumed to hold a stake of ps coins from each of the DAC members, the DAC nodes. So upon receiving a complaint, the complaint contract starts a timer and it waits for a timeout period.
00:14:23.100 - 00:15:11.660, Speaker B: So during this timeout period, the DAC nodes are responsible to observe the contract and send their responses to the contract to avoid perhaps getting punished. So if the nodes reply send their responses to the contract by the timeout period, then the client can simply observe the contract at the end of a timeout and retrieve the data from there. And if there are enough responses sent to the contract, the client can again combine them to recover the answer to its query. And we assume that there is, again, a cost associated with sending a response to the contract. And this cost is taken by the DAC nodes, it's denoted by PW. And we assume that this PW is less than the collateral staked by each node. And in reality, it could be much less than this collateral.
00:15:11.660 - 00:15:31.270, Speaker B: And this could either be, again, the cost of covering the gas cost on the layer one blockchain, or it could also encapsulate the cost of generating the correct response to the client's query. Is this set up clear so far?
00:15:33.820 - 00:15:37.624, Speaker A: Are you going to go into more detail about sort of this challenge response part?
00:15:37.742 - 00:15:55.228, Speaker B: Yes. Okay. Yes. And if the client can get the response, the protocol indeterminates successfully. Okay. So, so far, I have alluded to the existence of an adversary. So let's make it concrete and let's see what the adversary can do.
00:15:55.228 - 00:16:40.040, Speaker B: So, first of all, it can corrupt f out of these end nodes, and these are byzantine faults. It means that under the control of the adversary, these f DAC nodes can deviate from any prescribed code arbitrarily. And here we assume that f is less than m minus k plus one. This is to ensure that if the f parameter is too large, then these corrupted diagnose can simply withhold their responses and grieve the clients perpetually. So we don't want them to be too strong to have any meaningful security. And another important observation is that the rest of the diagnosis, the ones that are not corrupted, are rational. So this is the first power of the adversary.
00:16:40.040 - 00:17:17.396, Speaker B: The second power of the adversary is to offer bribes to these rational nodes, so it can offer a total bribe of p zero coins. Again, p zero. Here is a parameter of the protocol to the rational nodes, and in return ask for a favor. So these nodes who accept the bribe are not really corrupted, so they accept the bribe only if they think, let's say, their payoff would be better in the future, and they would do whatever the adversary is asking to them. And AdvErsity basically tells them, hey, I am offering you some fraction of this p zero coins. Please do this action for me. And the node looks into its payoff.
00:17:17.396 - 00:18:06.090, Speaker B: If it does, this action accepts the bribe, and then it makes a decision to either accept the bribe or reject it. And the same goes for the client. The adversary can offer a bribe of p one coins to the client in return for a favor. And we assume that the adversary can have a coordinated plan across these bribed and adversarial nodes and clients. So it can make up a plan of, let's say, coordinating the nodes who accepted the bribe, and then the nodes that are already corrupted by the adversary. And we assume that each rational node aims to maximize its net utility, which is denoted by this function, and here x is the payoff at the end of the game. And in this talk, for simplicity, we consider some linear utility function, and we will see how much the results generalize to our risk averse nodes as well.
00:18:06.090 - 00:19:09.484, Speaker B: So what is this adversary doing in this system? Like, what is the goal of the adversary? So the goal of the adversary is to violate security that is defined as follows. So we say that key security is satisfied if the client receives k or more correct responses from the nodes, either over the network or through the contract by the beginning of some swap t. So here t is a latency parameter for our security. And in other words, we can express security as being satisfied if the client can recover the answer to its query, which requires k or more correct responses from the nodes. Is the adversary and security definitions clear? If so, I would like to again briefly open a parentheses on this k parameter. So I have previously mentioned, the data is typically erasure coded across these DAC members, and I would like to dwell on the reason why this is the case. So, the typical numbers for this k parameter are one or n.
00:19:09.484 - 00:20:00.860, Speaker B: So k equals one corresponds to data being replicated across the whole committee members. And it means that every node stores the whole data. But it also gives a higher notion of security, because now the adversary has to corrupt or bribe all of the DAC members, the DAC nodes, to violate security. On the flip side, if k is equal to n, this means data is just divided among the nodes. The storage per node would be much smaller because the data is divided, so it will scale as of one over n. However, now the security is much worse because it's sufficient for the adversary to corrupt a single node and anything in between. These two numbers can be represented by eraser rate, and then in this case, k can be denoted as some constant alpha times n.
00:20:00.860 - 00:20:53.964, Speaker B: And this corresponds to the solution where the data is first eraser coded and then divided among the nodes. And this makes the storage per node within a constant of the previous 1d over n, which is a very little amount. And it also makes the system more robust, because now the adversary has to corrupt a constant fraction of the nodes. So now that we have seen security, we have seen the adversary, the nodes and the client. We need to characterize what this contract does. We should examine how to design the best contract and for this purpose, I would like to introduce a node subgame that will be a part of the final dynamic game. So in this node subgame, we assume that the contract receives a query at some slot t.
00:20:53.964 - 00:21:44.380, Speaker B: So this query is a complaint, right? Suppose a client did not see enough responses over the network, so it sent its query to the contract at some slot here. So this is exactly the point our nodes hub game starts. And then the baseline payoffs at this point for each node is set to be zero. And we introduced this indicator variable xj that would equal one if the node pj sends a response to the contract by the next slot, or it will be zero otherwise. So here I am normalizing the slot to be one. And the length of this slot in reality can be thought of as equaling the length of this timeout period. And xj basically encapsulates the response of the node to this query over the contract.
00:21:44.380 - 00:22:42.188, Speaker B: And at slot t plus one, after a timeout period, the game ends and the final payoffs of the nodes are realized. Now, perfectly natural question to ask is, how should the contract behave if the nodes are responsive, or if they are responsive? And in general, what would be a good notion of optimality for this contract? We have a huge design space here. How should we narrow down the space and find the best contract? So here are the parameters we have seen so far. To answer these questions, we should put some structure on the contract. And for this purpose, we will represent the contract by a slashing function. So this slashing function is the contract's punishment or reward for a node PI, given the actions of all of the nodes, including PI's actions. So at flot t plus one, then the contract has the opportunity to observe the actions of every node, and it basically gives a reward or punishment to each node.
00:22:42.188 - 00:23:01.270, Speaker B: And this reward of punishment per node is denoted by this function F-I-X. And it takes value from minus ps to some positive real numbers. So the reason the negative side is kept at ps is because each node has a collateral of ps staked in the contract, and the contract cannot take away more than ps as a result.
00:23:03.500 - 00:23:08.650, Speaker A: Let's see, you're calling it a slashing function. It's really like a payment function, right?
00:23:09.100 - 00:23:54.680, Speaker B: Yes, but the payment can be negative because it can take away the collateral by each node. Okay, well, the name of the function is actually giving away what the function is going to be doing. Unfortunately, we will see that it will not actually give any reward. But here's an example which does not have to be and is not optimal. According to our future definition. So in this example, the contract simply takes away all of the collateral here, minus ps if the node is unresponsive and it gives a reward of one coin, whatever the denomination of the coin is, if the node is responsive. So this is an example contract.
00:23:54.680 - 00:24:51.204, Speaker B: And to further illustrate what happens at the end of the game, the payoff realized for the node PI in the absence of any bribe would be this expression basically the reward or the punishment of the contract minus pw times xi. So pw times xi means that if the node sends a response, the variable xi is one, then it basically needs to pay PW coins to send a response to the contract. And if it doesn't, it doesn't pay. This okay, now let's slowly build towards a notion of optimality for this slashing function, which represents the power of the contract. So an optimal slashing function has three main features. So the first feature is the compliance. So compliance is a general set of properties that we want any good contract to satisfy.
00:24:51.204 - 00:25:24.576, Speaker B: So it narrows down our search space to a set of good contracts, and amongst them we will find the optimal one later using the remaining two features. So a compliant function satisfies these following basic properties. So the first one is symmetry, that is motivated by fairness. It says that the function should not depend on the node's identities. The second one is no rewards. This is more contentious, but this is for economic feasibility. It says that the function should not pay us rewards, it should only slash the nodes.
00:25:24.576 - 00:25:58.640, Speaker B: So the reason we impose this constraint is because we want to have a net flow of money towards the contract. We don't want the contract to lose money. Second, if the contract offers rewards to the responsive nodes, this opens up a different attack vector. So in this attack vector, the node can simply withhold its response over the network, force the client to go to the contract, and only then it reveals the response over the contract. And this way it gets extra rewards. So we want to avoid this attack vector. As a result, we don't want to offer any rewards.
00:25:58.640 - 00:26:43.710, Speaker B: The third feature for a compliant function is security under no attack. This is a very basic one. It says that when there is no bribe, when p zero is equal to zero, basically there should be k or more responses in the contract. In the subgain we have seen, we will strengthen this to construct the optimal slashing function. And the final one is b, minimum punishment. Again, this is more contentious than the rest. So this says that for every action where security is satisfied, so where k or more responses are sent to the contract, we should have that the contract should not punish the nodes too much.
00:26:43.710 - 00:27:29.470, Speaker B: It should only punish them by some b coins, where b is potentially much less than the total collateral. So the reason we impose this b minimal punishment requirement is we don't want to punish benign errors too much. So let's suppose there is no adversary coordinating the nodes, and then one of the nodes cannot send a response due to some network outage or downtime, which we have at Stanford of time to time. Yeah. So in this case, we don't want the node to lose all of its collateral or lose a large amount of money just because of some maintenance issue. When there is no coordinated attack and security is satisfied. Again, in our optimal slashing function, we will strengthen the sport property, just like we will strengthen the third one.
00:27:29.470 - 00:28:17.070, Speaker B: Let's strengthen the security. So the second feature of an optimal slashing function is security optimality. And it says that a compliance slashing function would be security optimal if for all bribes, p zero, that is greater than equal to zero, there exists a probability q zero, that is a probability of failure, such that security is satisfied in the node subgame with probability at least one minus q zero in all Nash equilibrium of the subgame. And furthermore, there should not exist any other compliance slashing function with a larger probability of security or with a smaller probability of failure. So, is this definition clear? So, here we are strengthening the third property.
00:28:20.560 - 00:28:22.670, Speaker A: What's the probability over here?
00:28:24.400 - 00:28:58.520, Speaker B: So, we have fixed the bribe p zero, and then we are saying that for each p zero, the probability is across. We look at all Nash equilibrium of the subgame, given our optimal contract. In each Nash equilibrium, there is a probability of failure, and then we pick the largest one amongst these probability of failures. Let's say this largest one is q zero. And I'm saying that there should not be any other compliance slashing function with a larger largest probability of failure amongst its own Nash equilibria.
00:28:58.860 - 00:29:03.560, Speaker A: Okay, but is the randomness coming just from mixing over strategies?
00:29:04.400 - 00:29:46.840, Speaker B: Okay. Yes. So the adversary can, adversary can propose mixed strategies to the nodes in return for its bribe. For instance, adversary can say, I'm going to offer you a bribe, and then as a node, you don't have to withhold your response, but you should withhold your response with a certain probability. So as an adversity, I will just flip a fair coin, and then according to the result of this fair coin, you will withhold your response or not, and the node can basically look at its expected reward, and then at the end of this game, if it accepts the bribe, and then make a decision. So this is where the probability is coming from. So the probability is also coming from the node, mixing across strategies.
00:29:46.840 - 00:30:16.876, Speaker B: So these are the two main vectors. So the proof considers both of them. Does that answer the question? Yes. Thanks. So, security optimality, in layman terms basically means high or highest possible security. And the last feature of an optimal slashing function is punishment optimality. And this is strengthening the fourth requirement, this b minimal punishment requirement.
00:30:16.876 - 00:31:17.728, Speaker B: So a compliant slashing function is punishment optimal if the contract satisfies b minimal punishment for some b, and no other compliant contract can satisfy b prime, minimal punishment for a smaller b prime. So it means that the punishment optimal compliance function imposes the minimal punishment when security is not violated. So these are pretty strict requirements. And it might actually turn out that there is no optimal slashing function that satisfies all three properties of security, optimality, punishment optimality, and compliance. Well, luckily there is one, and it's actually a very simple one, the most intuitive one, given all we have seen so far. So this optimal flashing function does not punish the node if it sends a response to the contract. It flashes all of the stake from the node.
00:31:17.728 - 00:31:51.280, Speaker B: The node loses all of its stake if it does not send a response to the contract. And the data cannot be recovered because very few nodes send a response. And in the case that the node does not send a response to the contract, yet the data can be recovered from other nodes responses. The punishment amount is much small. It's only slightly larger than the cost of sending a response to the contract. Yeah, so it's as simple as that. And this function satisfies our optimality requirements.
00:31:51.280 - 00:33:04.400, Speaker B: And to state it more formally, this flashing function is optimal for both risk neutral and risk averse nodes. Here there's an asterisk on risk averse because we have considered utility functions of the sort x to the new, when new is between zero and one. I don't want to over promise, but I have a feeling that it's to generalize to a larger set of concave utility functions, but I have to do more work for that. And then the failure probability that we have seen the q zero p zero for risk neutral nodes on this optimal contract is this expression. First of all, before we go into the expression, I would like to remind, what is this failure probability? So we have our optimal slashing function, and we have fixed the bribe amount p zero. We know what this bribe amount p zero is, and then the adversary can do a lot of different strategies, and it can offer different bribes to different people and ask them to do different things. And at the end of the subgame, we look at all Nas equilibria and we find the one with the largest failure probability.
00:33:04.400 - 00:34:04.212, Speaker B: And given that versus powers, and it's this value, and this value is equal to the expression we see here, and this expression increases linearly as total bribe goes up. It decreases as the minimum number of rational nodes that the adversary must bribe to violate security increases. So this is the minimum number of rational nodes the adversary should ask to withhold their data from the contract. It can always ask its minions, the adversarial ones, the already corrupted ones, to withhold the data. And again, this probability of failure decreases as the total collateral goes up, because then it means there is more punishment for each node if it withholds its data. Okay, I was planning to offer a proof sketch for optimality, but I will be a little bit more quick with the proof sketch. Let's cheat a little bit and say we already proved our slashing function is compliant.
00:34:04.212 - 00:35:39.304, Speaker B: It satisfies these four natural properties, and then if we actually try to do this ourselves, we will notice that for any compliance slashing function, the punishment should be less than the cost of sending a data, sending a response to the contract if the node is unresponsive, if xi is zero, and this is necessary for security to be satisfied with overwhelming probability and even when the bribe amount is zero. So we need this even when the bribe is zero, if we have adversarial nodes. And this lemma also implies a punishment optimality of our compliance slashing function, because it indeed punishes the non responsive nodes, an amount that is just below PWA. And then after assuming away all of these properties, we only have to prove security optimality of the contract, and to prove security optimality of the contract, we first show an upper bound. We show that the error probability for our optimal slashing function, given a fixed p zero, is upper bounded by this expression. Because of time constraints, I will quickly skip this, and if we have time at, then we will return. And the flip side of proving the security optimality is to show that for all compliant punishment optimal slashing functions, this error probability is larger than this expression, which this also applies to the optimal slashing function that we have seen.
00:35:39.304 - 00:36:02.530, Speaker B: As a result, it gives the type bound, and these results are purely for the risk neutral nodes. For risk averse nodes, we can do the same proofs, except for the fact that I don't know how to characterize this expression. I can do it for some expression here that would end up being the same, but I don't know how to characterize that.
00:36:05.460 - 00:36:08.788, Speaker A: Could you go back to that? Actually, something on that slide confused me.
00:36:08.874 - 00:36:11.940, Speaker B: Yes. This one or the previous one?
00:36:12.090 - 00:36:31.140, Speaker A: This one, yeah. Specifically, the phrase asks them to collectively withhold their responses is probably q zero, p, not. So who's flipping the coin? So, I guess I'm a little. Equilibrium concept.
00:36:31.300 - 00:37:06.432, Speaker B: Yes, that's a very good question. So, what the adversary is doing is it tells each of the nodes, I'm going to offer you a bribe. And then if you accept the bribe, I will tell you to do the following thing. It tells the node, I will ask you to withhold your response with some probability, but it's the adversary who is flipping the coin, because adversary can coordinate across the favors that it has asked from the bribe nodes and the adversarial nodes actions. So the adversarial nodes are purely corrupted by the adversary. So there is no bribe associated with them. They are adversary's minions.
00:37:06.432 - 00:37:44.272, Speaker B: The rest are offered a bribe. An adversary can coordinate across the actions of the ones that accept the bribe and the ones that are offered that are already corrupted. So the adversary can flip a coin and ask all of the nodes that accept the bribe to withhold their responses according to the outcome of this coin. So, here, there is a big assumption, the assumption being these actions are atomic. Right? Because flipping a coin, offering a bribe, and not taking the action are not necessarily atomic. So the question of how we ensure atomicity is another part of this work. So there are two ways we can ensure it.
00:37:44.272 - 00:38:04.840, Speaker B: First of all, we can assume a trusted third party that ensures the agreement or atomicity between the nodes that are offered a bribe and the adversary. Or we can assume repeated games. And in the case of repeated games, we can show that we can sustain an equilibrium where the actions end up looking like atomic.
00:38:06.780 - 00:38:27.224, Speaker A: Interesting. So, for the first version of that, I almost wonder if this is more naturally phrased in terms of correlated equilibria, as opposed to natural equilibria. So that might be worth thinking about. And then the repeated game stuff. Is that just using the folk theorem?
00:38:27.352 - 00:38:30.816, Speaker B: Yes, it's just using the folk theorem. Okay. Yeah.
00:38:30.838 - 00:38:38.800, Speaker A: The folk theorem is often viewed as more of a negative result than a positive result. You know what I mean? Because there's, like, so many equilibria.
00:38:39.800 - 00:39:31.030, Speaker B: Yes. So the fault theorem is, again here more like a negative equilibrium, because it gives the adversary the power to interact with these nodes in a more atomic way. So the reason we needed for the fault theorem is that because suppose adversary offers a bribe and tells. I will do some action for me when I flip a coin and then the node takes the bribe, and then the coin ends up being the result that the node should be told its response. And the node just deviates, right? Because it has already taken the bribe, why should it be told its response from the contract and potentially suffer some punishment? So that is why the repeated games are needed to ensure this trust that when they promise to do some action, they will do the action. Or another way we can ensure this is true at trusted third party. Thanks.
00:39:31.030 - 00:40:22.744, Speaker B: Yes, and now let's go into the repeated game. So we have seen a sub game, we have seen how the optimal contract is, contract is structured and with the notion of optimality for contracts. And let's now bring all of this information together in a repeated game. So we assume that before the game starts, the nodes and the client are input a query, because without a query there is no game. And at this point the game starts and the baseline payoffs are set to zero for both the node and the client. And at any slot until t equals four, a node can either send its response to the client over the network, or send its response to the contract if there is a query on the contract. If there is no, then the contract doesn't accept responses, of course, and at any slot the client can send a query to the contract.
00:40:22.744 - 00:41:05.600, Speaker B: So this is an important detail, that the repeated game does not start with a query already sent to the contract. It only starts with the node and the client knowing that there is a query. So nodes knowing that they should reply to the client and the client accepting, waiting for a reply. But the client does not necessarily have to send its query to the contract. So this will be part of the game. And if the client learns the response to its query by slot equals four, then it gains a payoff of PF coins. And here we assume PF is a large number that is larger than the cost of complaining on the contract or the adverse bribe to the client.
00:41:05.600 - 00:41:46.930, Speaker B: So for instance, it could as well end up happen, being that the node sent k or more responses over the network to the client. In this case, the client need not complain on the contract, and the client already learned the response, the answer to its query, so it can end the game. At this point the game could end and the payoffs would be realized. Or if the client is malicious, it can still send a query to the contract because the adversary asked it to do so. Then the game might continue, but the game definitely ends by t equals one. So these are the parameters we have seen so far. Lots of them.
00:41:46.930 - 00:42:33.390, Speaker B: I just want to flash the screen for a second to remind people. So we have two extra ones that we will see next at the bottom. Okay, so how do we now incorporate the client into this game? Right. So far we have only had a sub game of interactions between the contract and the nodes. Now we have a client. As a result, the contract should have some reaction to the client, and its reaction is structured as follows. It says that the contract basically doesn't offer any reward or punishment to the client if the data can be recovered, because, well, the contract knows that the client already earns a payoff of PF, which is a large number.
00:42:33.390 - 00:43:29.420, Speaker B: On the other hand, if there is a query on the contract and there are less than a k responses on the contract, which means that now the contract thinks the client did not recover the data. Contract doesn't know if it recovered the data to the network or not. It only knows how many nodes responded to the contract. In this case, the contract offers a compensation to the client. There is some amount Pcomp and it's assumed to be larger than the cost of complaining on the contract, and we need to have this. This is necessary for security. If PComp is less than or equal to PC, then there are some equilibria that are very pathological, where the nodes can promise to not ever reply to the contract or send their data to the client over the network, and it will be more profitable for the client to simply remain silent and not complain on the contract.
00:43:29.420 - 00:44:31.190, Speaker B: So to avoid these kinds of pathological equilibria, we need to have this compensation and what can we claim given our modified enhanced contract and the repeated game? So we can claim the following. Suppose there is an adversary that has some fixed bribes, p zero and p one to the node and the client respectively. And suppose these satisfy the following inequalities. This first one is the one I already talked about, where we need this p one to be less than Pcomp minus PC, so that the client sends a query to the contract if the nodes are unresponsive over the network, or even if they stick to being unresponsive over the contract. And the second inequality comes from the expression we have seen so far. The expression for error probability had this value as its denominator and this value as its numerator. If p zero is equal or larger than this, then the security will be violated with probability, with overwhelming probability in the sub game.
00:44:31.190 - 00:45:22.980, Speaker B: And if these are satisfied, then given our optimal slashing function that we have seen in the previous slide, for any adversary a that offers p zero and p one bribes, the maximum probability for security is violated in the previous dynamic game. In NNS equilibria is upper bounded by the same expression that we have seen for the subgame. And moreover, if k is equal to one greater than one, when there are more than one dac mem node for any other slashing function, there is a subgame perfect equilibrium where the adversary with bribe p zero violates four security with a larger or equal probability than this expression. So in some sense, our optimal contract is still optimal when we generalize to rational clients and an adversary who can offer bribes to client.
00:45:27.000 - 00:45:38.308, Speaker A: Yeah, so the issue with having bribable sort of users is that they may not do the challenge.
00:45:38.484 - 00:46:14.740, Speaker B: Yes, exactly. Imagine, like the nodes simply tell the user, hey, no matter what you do, we will never reply to you. In this case, the issue is now the user. It knows that it won't get any responses over the network, and it knows that even if it sends a query to the contract, it won't get any responses from the contract. And querying the contract has a cost associated with it, which is this pc amount. So the client, the user simply thinks that I should better remain silent. And this is an equilibrium where the client security is not satisfied and adversary is successful.
00:46:14.740 - 00:46:57.600, Speaker B: Now, even if this, there is a compensation and there is a pc amount, the same could happen if the adversary can offer a bribe to the client. Right. The adversary can cover the difference between these two, and it can say to the client, hey, look, these nodes are pledging to never send their responses even to the contract or to the network. You better remain silent and I will give you this p one compensation. So it turns out that now the client would find it more profitable to not send a query to the contract. So it's like a very pathological equilibrium. And this is a theorem that is stated for risk neutral nodes.
00:46:57.600 - 00:47:54.900, Speaker B: This expression in particular, but theorem holds for risk averse nodes with a different expression here that I could not find a closed bond solution for. And the flip side of this theorem is, if p zero is small, right? P one was just like the cost of sending a response to the contract, and p one is also sufficiently small. Well, here it's a much more complicated expression that I would rather avoid putting here. And the unfortunate thing is, if k is equal to one, then four security can be satisfied in all Nash equilibrium without the client sending a query to the contract. In this case, the single DAC node will realize that it maximizes its payoff or utility. Then it simply responds over the network. The problem with this expression is why it's unsatisfactory is, well, we have more k greater than one most of the time.
00:47:54.900 - 00:49:27.756, Speaker B: And when k is greater than one, if none of the nodes are sending a response over the network in the equilibrium, then a single node cannot increase its payoff by sending a response over the network, right? This single node, even though if it wants to be honest, it doesn't gain any reward from sending its response over the network, because it knows that because other ones are not sending their responses, the client will put a query to the contract no matter what. And then as a result, we need to assume that k is equal to one, in which case the node has full agency over its payoff. Given the client's actions, other nodes cannot grieve it. And of course, all of these results would remain very theoretical if we do not put numbers to these bribe amounts and failure probabilities. So we calculate the bribe that is needed to violate the security with this probability, where we assume the value of eat is just one $200 and the number of diagnoses 300,000 to match the magnitude of the size of the validator set on proof of stake Ethereum, we assume that the adversarial fraction and k is one third. This is to match the resilience of proof of stake Ethereum again, and each node stakes 32 e, the minimum amount a node can stake in proof of stake Ethereum. We just use it as our benchmark.
00:49:27.756 - 00:50:03.550, Speaker B: And we said, okay, let's look at how much bribe the adversary should offer to violate security with probability 0.1% for a single query. And let's focus on the bottom expression. This basically tells us the bribe needed to violate a security for a single query is $3.9 million, which is quite a large amount if we are talking about a single query. And each time there is a new query, adversary needs to spend the same amount on the contract, either in bribes or in bribes. Basically, yeah.
00:50:03.550 - 00:50:32.390, Speaker B: And? Well, the rest of the table is for risk averse nodes, and there is a gap between the lower and the upper bound characterization for this error probability because of the fact that we could not find a closed form expression. So the solution for this error probability comes from a problem statement, and the problem statement is not convex. As a result, we could not solve it.
00:50:32.760 - 00:50:45.224, Speaker C: Can you put that 4 million in context? It sounds like a lot of money, but if you could brick an entire roll up server for $4 million, it might do a lot more damage than 4 million.
00:50:45.422 - 00:51:35.820, Speaker B: Yes, that is true. So the context is let's say there is a single client that wants to learn, that wants to learn a proof of inclusion for his account balance, right? And then it sends a query to the contract, and this is the bribe amount that person needs to pay to the DaG node so that they don't reveal the proof of inclusion to the client for it to withdraw its money. It will probably result in a loss of trust in this L2 system if a client cannot get this proof of inclusion. But I don't know how this loss of trust will compare against $4 million. So this $4 million, when it's paid, it does not necessarily break the whole system, it just grieves a single client. But if this is an important client or important transaction, of course it could be more serious.
00:51:37.600 - 00:51:40.908, Speaker C: Would this be like per query, you'd have to pay 4 million?
00:51:40.994 - 00:52:37.656, Speaker B: Or is it like in perpetuity, if you grief the same client for just no, this is per query. We also consider in the paper, what if the adversary coordinates actions across multiple queries, right across the responses of the bribe? Then the adversarial notes across multiple queries. It turns out it does not give adversary extra power. The results end up being the same, meaning that in each query, adversary needs to spend $3.9 million to grieve the client whenever there is a query on the contract. Just curious, did you get any feedback from Ethereum foundation whether they are interested in this mechanism? We did not get any feedback, as far as I know, from them. Specifically, we got some feedback from people who work on oracles or decentralized oracle networks.
00:52:37.656 - 00:53:50.092, Speaker B: So they were thinking that this scheme of this contract, and as a query analysis, it is useful for them because they have the problem of some of the people who are supposed to reply to a contract withholding their responses. Let's say there's a vault going on and these people don't vote on it, so they want to have some slashing mechanism on them. So they thought that this work is quite applicable to them. So one, I guess, problem with the applicability of this data availability versus these decentralized oracle networks is in the Oracle network, the response to the query by the node is very small, right? It's just a yes or no vote, let's say, or like some small amount of information. And in my example, for the data that has been requested, proof of inclusion, that is also a small amount that you can put on chain. But what if the client's query is asking for a lot? Let's say it's asking for the data in 1000 blocks now in a volatile setting, you might not want to put data for 1000 blocks onto the layer one blockchain. So these kinds of large queries will have a much larger cost PW, like the cost of putting the response to the contract for the nodes than the other settings.
00:53:50.092 - 00:54:48.324, Speaker B: So then the analysis and the assumptions there, this PW being much smaller as compared to ps, and this numerical side breaks down a little. And let me just end with a small discussion point. So our work can arguably discourage centralization of storage. The reason for that is now when storage is centralized, everyone delegates the storage responsibility to a central node. So these DAC members, they pretend as if they are storing the data, but they don't. But now if the central storage has a downtime, it looks as if these DAC members are corrupted and they don't reply to the contract, right? And then they endure a large slashing cost. So our solution as a result might discourage them from centralizing their storage.
00:54:48.324 - 00:55:50.510, Speaker B: Now the downtime of this storage entity that they are centralizing towards is much more costly for the DAC nodes. Another discussion is on this value of pc, the cost of sending a query to the contract. There is a trade off here between preventing denial of service attacks by the clients and then making this pc higher to prevent these DOS attacks and to make it lower so that the queries are much cheaper for the honest clients. And finally, I would like to end with an open problem about what would be the most realistic utility function. I am guessing it's not the linear one that I looked into. And given this optimal slashing function, would there be a closed form solution for the failure probability when the nodes are risk averse? Because even though we showed its optimality in the sub game for risk averse nodes, we couldn't characterize this solution because the problem ended up being non convex. And if someone could solve it, what would be the expression, either numerically or mathematically? Yeah, thank you very much.
00:55:50.510 - 00:56:43.964, Speaker B: I think there was a question on the chat that I did not reply at the beginning of the talk. What if the headers use an accumulator that supports proof of non inclusion? So the proof of non inclusion, okay, so it will be like, suppose the header has accumulator and it says that, okay, so these are the data that is accumulated. And here are the proof of inclusions, right? So a client comes and asks for the data. So the block producer gives the data and the proof of inclusion with it. And it might perhaps give a proof of non inclusion for some of the data, right? It can give a proof of non inclusion for a data that's not there. But it cannot give a proof of non inclusion for every data that is there. So when the client receives the response, it will be all right.
00:56:43.964 - 00:57:24.510, Speaker B: But if the block producer is malicious, it can basically just remain silent towards the client, like just not say anything to the client at all. So the client doesn't know what is inside the block. And then as soon as a watchtower comes in, then the block producer gives all of the response right. It gives all of the proof of inclusion or non inclusion for the data that's not supposed to be there to the watchtower. So the issue with the fisherman attack is that the watchtower does not have any way to monitor what happened between the client and the malicious block producer back in the time when the watchtower was not available, was not in the system. I'm not sure.
00:57:26.800 - 00:57:41.010, Speaker C: Yeah, that does answer my question. Thanks. Have you talked to anyone in the lightning world? Because this seems like something that could be used to prevent the griefing attacks that they've been struggling with for a while.
00:57:43.380 - 00:58:17.064, Speaker B: Yeah, that's very good feedback. Thank you. I did not look into lightning network that much myself, so I was not aware that this could have some use there. But yeah, I think we should strengthen because I had the sense that data availability might not always be the best application of this work because of this on chain cost being too high when the queries ask for a large amount of data on like, a single inclusion proof. But, yeah, it will be great if I can find more applications. Yeah.
00:58:17.102 - 00:58:37.570, Speaker C: Because, I mean, you're kind of hitting like three birds with 1 st here. It's like proof of data availability, proof of non censorship, and proof of non griefing kind of thing. And actually, I think the proof of non griefing is something that there are the fewest potential solutions for out there. So, yeah, it's interesting.
00:58:38.340 - 00:58:41.410, Speaker B: Yes, I would definitely take a look at it. Thank you.
00:58:41.940 - 00:58:45.200, Speaker A: This is great talk. Thanks so much for taking the time.
00:58:45.270 - 00:58:48.620, Speaker B: Thanks for listening. Thanks so much. Bye.

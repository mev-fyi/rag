00:00:07.890 - 00:00:08.440, Speaker A: You.
00:00:10.730 - 00:00:38.046, Speaker B: All right, good afternoon, everyone. Welcome to today's a 16 z crypto research seminar. Very pleased to welcome Elaine she, professor at Carnegie Mellon University. Elaine has worked on all kinds of different things across computer science. For example, she was visiting us last summer, gave us talk then about mechanism design. Funnily enough, today she's speaking about the very first thing I ever saw her talk about many years ago, oblivious Ram. And getting us all up to date about sort of the practical impact of it.
00:00:38.046 - 00:00:39.338, Speaker B: So, Elaine, all yours.
00:00:39.434 - 00:01:05.190, Speaker A: Thank you so much for the introduction. So I'm going to tell you about Oblivious Ram, or O Ram for short, and how it evolved from theory to actually large scale real world deployment. So the plan is the following. I'm going to first tell you a Signal story. It's also the motivating example for the talk. And then I'll tell you how to construct oblivious Ram. I think some of you may not have heard about Oblivious Ram.
00:01:05.190 - 00:01:32.922, Speaker A: It's a simple algorithm which I teach to my undergrads in my crypto and algorithms class. So you'll learn about it today. And at the end, I'll talk about the applications and the challenges towards real world deployment. Okay, so let me begin with Signal story. Okay, so Signal, as you know, it's a private messenger app. It provides end to end encryption for the messages you send. And they also want to support private contact discovery.
00:01:32.922 - 00:02:20.762, Speaker A: So in contact discovery, it is what you think, right? Tim sends his address book to Signal, and Signal tells, you know, here are your friends, they're also on Signal. You can connect to them, you can send them messages. Okay, so this is very useful feature, but Tim is worried that of course his contacts are top secret, so he's hesitant to do that. And so what do you do? Here's a naive solution. So let me first start with the strawman solution, and then I'll tell you what Signal is doing. So here, imagine Signal has some trusted hardware, a secure CPU in the cloud, intel SGX, for instance. And you can think of the secure CPU as creating a hardware sandbox.
00:02:20.762 - 00:03:15.730, Speaker A: So anything outside is encrypted, like the communication is encrypted, data at rest is encrypted, and the data is only decrypted inside the enclave where the computation takes place. Okay? So you may think this solves problem because all the data contents are encrypted, we must be safe. But actually, if you think about it more carefully, encryption alone doesn't quite solve the problem. And it is well known that access patterns to even encrypted data can leak very sensitive information. Like in this case, if Signal observes that the server is accessing, let's say, a record corresponding to Etai, then they can know that Etai is Tim's friend. And you may be tempted to think that just by permuting all the user records on disk can solve the problem. But actually, this doesn't really solve this problem.
00:03:15.730 - 00:04:09.310, Speaker A: In particular, if you just permute the data signal can still learn the social network graph, like even though it's anonymized. And what's wrong with this? If you actually have a known social network graph with actual user identities, you can correlate the structure of the two graphs and de anonymize everyone in this anonymized social network. And this was actually work. So I had a work along these lines and also Arvind Narayanan and his co authors also had several papers de anonymizing social networks. And the moral of the story is like even though graph isomorphism, we don't know an efficient algorithm for the worst case instance. For these real world instances, it's like very easy. Okay, so this is like signals problem, but access pattern leakage itself is actually a really more general problem.
00:04:09.310 - 00:04:46.994, Speaker A: So let me show you some other examples of access pattern leakage. So here's a medical example. Let's say you are storing genomic data in the cloud, let's say 23 me and the doctor is accessing certain Snippets in the genomic data. So for instance, if you see the doctor is accessing Snippets related to liver problem, you know, maybe the patient is being screened for liver problem and this is sensitive medical information. Okay? And this is another example. Everyone's familiar with binary search. Like if you have a database, you want to do binary search on top of it, you would look at the middle element.
00:04:46.994 - 00:05:34.922, Speaker A: Depending on the result of the comparison, you either recurse on the left half or the right half. So now imagine you can see the sequence of all the axes. You can learn exactly what key is being searched, right? So this basically leaks everything about the query. So more generally, from a programming language perspective, if your program has conditionals that depend on secret variable, let's say this if depends on the last bit of the secret key and then depending on which branch is taken, you have different memory traces in each branch. And in these cases, just by observing the memory traces, you can learn the value of the secret variable. Okay? So finally, here's another example. This is an actual attack that was launched by some researchers in UT Austin and Microsoft Research.
00:05:34.922 - 00:06:19.446, Speaker A: And they showed, suppose I'm running some off the shelf image processing software inside SJX enclave and the only thing I can observe is very car screen access patterns, namely which pages, memory pages are being fetched into the enclave. And even with such car screen access patterns, they can pretty much recover the location and shape of the objects. So this is pretty significant problem. And the question we want to ask is how can we provably defeat access pattern leakage and meanwhile preserve efficiency? So this is what we are going to answer today. Okay, so let's go back to Signal story, right? So Signal encountered this problem back in 2017. They came up with a solution. They say, okay, we are going to linear scan the whole database upon every query.
00:06:19.446 - 00:06:53.878, Speaker A: Linear scan is always safe because it doesn't leak which record is being accessed. And they're actually doing something slightly smarter, which is a batch linear scan. So whenever a batch of queries come in, they answer this batch in a single linear scan. This is a linear cost scheme, obviously. So N is the total number of memory blocks, a total number of user records, beta is the batch size. And because they had this linear overhead, they had to have 500 servers to basically work with the load they have. Okay, so eventually time moved forward.
00:06:53.878 - 00:07:23.294, Speaker A: In 2022, something exciting happened. They got rid of the batch linear scan and they changed to Pathoram, which is an algorithm that we had published back in 2013. Actually, Hubert is one of the co authors on this paper and he is also in the audience. Okay, so now we have basically log squared overhead instead of linear. They were able to cut down the server cost by 100 x after deploying Path. Oram also? Yes, Tim.
00:07:23.412 - 00:07:29.380, Speaker B: So did they just find your paper or did you tell them they should do this instead? Or what's the story?
00:07:29.830 - 00:08:08.910, Speaker A: There's actually a story because back in 2017 they published a blog post and they were claiming that the batch linear scan was outperforming pathoram. So likely they didn't implement Pathoram in the way that they should have done. Okay, and also actually I will mention later that this log squared has very small constants. So it is like just really log squared. Actually in practice, it really just behaves more like log n and I will explain why later as well. So basically, if you are a signal user and signal asks you to send contacts, just feel safe to do that. They are running my algorithm, it must be very secure.
00:08:08.910 - 00:09:02.910, Speaker A: Okay, all right, so let me actually tell you about how oblivious Ram algorithms work, but I'm also going to tell you a little bit story about this whole area, how this area evolved over time. So what is oblivious Ram? Orm is an algorithmic technique that can probably obfuscate the memory access patterns. And the security you get is very strong. You can think of it basically it gets you the same security as encryption, right? So at first sight it's counterintuitive because we know we can encrypt data, but access patterns are a side effect of a program's execution. So how can you actually encrypt side effect? And if you look under the hood, I'll tell you how these algorithms work, but just at a very high level. These algorithms are permuting the memory blocks and they keep shuffling them as you access them. And in this way they can obfuscate access patterns.
00:09:02.910 - 00:09:59.022, Speaker A: And if you think of Orm here's kind of like a diagram that says what it does, the input is a sequence of requests. Every request is either read some address or write to some address. Okay. And then it will translate each request into multiple physical axes. And the security it promises is that the distribution of these physical reads and writes should be independent of the input request, the secret input data. Okay? And just to distinguish, like, sometimes we also call these addresses the logical addresses, and the physical reason rights are called physical addresses. And if you ask, okay, what is the security boundary when you actually deploy Orm on a trusted enclave, this is what happens.
00:09:59.022 - 00:10:55.726, Speaker A: Like, you are actually running Oram inside the secure enclave, right. This hardware sandbox I talked about earlier, so everything inside is secure. And the memory, you can think of it as being the adversary, right? Adversary can observe all the memory axes. Okay, so let me go back to Oram, right? So Oram was initially proposed by Godrich Ostrovsky back in the 1980s, and they showed that actually there exists asymptotically efficient Orams, right? So remember, the naive solution, linear scan was linear overhead, and they could construct something with lock cubed overhead, which is like very nontrivial in the asymptotical sense. Unfortunately, these algorithms are very complex and they suffer from astronomical constants. So basically, you really cannot implement these algorithms the way they're described. Okay? And on the other hand, they also showed if you want a generic Oram scheme, you have to suffer from at least login overhead.
00:10:55.726 - 00:11:06.070, Speaker A: So the overhead is defined by comparing the overhead of the secure algorithm versus the overhead of the insecure algorithm. So this is a multiplicative blow up question.
00:11:06.140 - 00:11:07.730, Speaker C: What does generic mean in this context?
00:11:07.810 - 00:11:56.658, Speaker A: Generic mean if you want to have a compiler that compiles any program to an oblivious counterpart. So if you ask about any specific computation task, it may not be subject to this lower bound, but if you want a compiler that works for any program, take an insecure program, give me a counterpart that's secure. That compiler has to incur log and overhead. I started working on Oram back in 2011, and back then there were actually a line of work already that tried to improve Godrick Ostrovsky, but they were still kind of working with the same framework they had proposed. So all these schemes are within the same framework, but with some optimizations, you could get rid of one log n, so you get log square n. But nonetheless, all these schemes are very complex. They basically suffer from the same drawback of Godrey Kostrovsky.
00:11:56.658 - 00:12:49.046, Speaker A: They're not practical. Okay, so I looked at the space and I asked, okay, so what are the important questions for Orm? I mean, obviously the first question is, can we ever make Oram practical? And the second question I was interested in is, like, there's this obvious gap between the upper bound and the lower bound. Can we bridge this theoretical gap? Okay, so I started working on Oram, and I guess in the next, I don't know, maybe more than ten years, we were able to answer both questions. I mean, the first question I told you about the large scale deployment of orm, I'll tell you actually the algorithm for the second question. I will not focus on this theoretical question in today's talk. But we also were able to bridge this gap and we were able to construct an optimal oram with Logan overhead theoretical construction. And the practical one happened not to be the same one.
00:12:49.046 - 00:13:35.330, Speaker A: I mean, it would have been nice if there were the same one, but this theoretical one is actually not practical. So I'm going to be focusing on the practical side today. Okay, why is the theoretical practical? The space is actually a little bit complicated. There are simple algorithms that are actually optimal if your block size is large. But if you want to be optimal when the block size is just like log n, which is the standard assumption in the word Ram model, in all the algorithms literature, then the scheme we have is complicated. I guess it's not easy to explain why it's complicated. Anyway, maybe when you see our construction, the construction I'm going to tell you today is log squared overhead.
00:13:35.330 - 00:13:59.630, Speaker A: In theory, it behaves more like log n overhead in practice. Okay, so let's see how to construct an orm. So actually, I'm not going to directly tell you path oram. I'm going to tell you a scheme that's predecessor to Pathoram. It's called the binary tree orm. And basically this binary tree oram itself is a framework for constructing orms. And once you understand the framework, I can tell you what path orm is in just one sentence.
00:13:59.630 - 00:14:42.942, Speaker A: And also, by the way, this framework basically completely departs from Godrick and Ostrowvsky original algorithm. So let's first think about a straw man. I mean, this is actually the same strawman I mentioned earlier. So what if you just take all the memory blocks and you randomly permute them? And now what do you get from this? If you access some block, you don't know which logical address it is. So it seems like this gives you some security, but it's actually not too much security. And the issue is because if you go back and access the same block, you are leaking statistical information, you see, okay, this block is accessed more often than others. Or maybe these two blocks are often accessed together and you can then have statistical inference attack.
00:14:42.942 - 00:15:25.286, Speaker A: And this is for the similar reason like deterministic, encryption is not secure because it leaks statistical information. Okay? So permuting things in memory gives only one time security. In other words, if you only access every block only once, then it's secure. But if you access the same block multiple times, it's no longer secure. And the moral we should learn from the story is that it seems like every time you access a block, you have to relocate it. Because if you don't relocate it, the next time you access it, you create a linkability, you leak statistical information so that's why I want you to keep this insight in mind. It will come up again when I talk about the scheme.
00:15:25.286 - 00:15:51.694, Speaker A: So this is a key insight. The blocks have to move around in memory, and in fact, as soon as you access it, it has to move around. Okay, so as I mentioned, we have a binary tree based approach. And this is like, in some sense, it's a simple data structure that I teach to my undergrads. Every node in the tree is called a bucket. The bucket has finite capacity. A bucket can store two types of blocks, real blocks and filler blocks.
00:15:51.694 - 00:16:18.330, Speaker A: So the filler blocks, they don't encode any useful data. They're just there for security. Okay, so the most important invariant of the scheme is that every block is mapped to some random path. So here, let me first cheat a little bit and assume the CPU can store an entire position map, which records where every block is. So this position map, as you can see, is very large. It's linear in size. Eventually, we do want to get rid of it, and we will.
00:16:18.330 - 00:16:53.878, Speaker A: But for now, let's just live with the idea there's a position map, and let's say the position map I want to access block X. I can look up the position map starting my CPU's cache, and I find out, okay, X is on the blue path. And now all I have to do is I just have to read this blue path and I'm guaranteed to find the block X somewhere. Once I find it, I will remove it from the corresponding location. And now I'm holding it in my hand in the CPU's register. Okay, so at this moment, remember what I said. The key insight was right.
00:16:53.878 - 00:17:41.430, Speaker A: At this moment, it is important to relocate this block. I have access because otherwise the next time I access it, I will go back to the same path and that leaks information. So how do I relocate it? The most natural idea is just to pick a new random path. Let's say I happen to pick the green path. I want to move the block X to this green path. And I mean, of course I have to update my position map to reflect that, but I also actually have to write the block somewhere on the green path. And how do I do that? This is a little bit subtle because the question is, where on this green path can you write the block X? Can you write it to the leaf node? You find a filler bucket, you find a filler bucket.
00:17:41.430 - 00:18:03.302, Speaker A: Filler slot. Yeah, filler slot. But the issue is, I guess the question is it secure to, let's say, just write it into the leaf? Also, by the way, maybe I didn't make it clear. I'm going to assume everything is encrypted. So the only thing that adversary can see is the access patterns. Okay? So I'm not going to just repeat the encryption again and again. Yes, Jacob.
00:18:03.366 - 00:18:11.726, Speaker C: I'm missing something because if the adversary can see that you read one block, where do you write it? Like the adversary won't the adversary just.
00:18:11.748 - 00:18:34.918, Speaker A: Be able to see that you just yeah, exactly. That's the reason. So it's not secure to write it to the leaf node. Right? Because the leaf node reveals the whole path. Like you cannot leak what the whole path is because if you leak it the next time, let's say you are accessing the same block you can see, okay, this block from the blue path was relocated to the green path and now I'm going back to the same path. So that leaks information. So you cannot write it here.
00:18:34.918 - 00:18:56.060, Speaker A: That's crossed out. And for similar reason, you cannot write it to any of the internal nodes. So even though the internal nodes are like seemingly more secure, they still leak partial information about the path. Okay, so the only thing left is the root. I mean, of course it's safe to write it to the root because the root is on every path. If I write it to the root, I don't leak information about the new path. Right.
00:18:56.060 - 00:19:24.150, Speaker A: So let's do that. And I mean, we are going to encounter a problem if we always write to the root. But for the time being, let's say we are doing that and if this is actually the scheme, then we can actually think about the security. The security is actually easy to see because every time you access something, you are going to visit a random path. And not only so the path has not been disclosed before, it's a fresh random path. You haven't seen the choice of the path before. Yes.
00:19:24.220 - 00:19:30.194, Speaker C: Just to clarify, are you like taking a read from every bucket along the path?
00:19:30.242 - 00:19:35.590, Speaker A: Yeah, you have to read every location because you cannot disclose which location actually contains the block you want.
00:19:35.660 - 00:19:38.746, Speaker C: But when you're doing the new write, you're just writing once to block the.
00:19:38.848 - 00:20:12.840, Speaker A: You have to do a fake write on all the other positions. So you also cannot tell which was the location it was written to. Okay, yeah, but that's actually a great question. So essentially the implicit assumption is like the read and writes, they always go hand in hand when you read it, you always write it back. You either write the original blog back or you write an updated block back and you always re encrypt the new thing that you're writing back. Okay, so this is very nice, but there's one remaining problem we have to solve. And the problem is obvious because okay, there's a problem.
00:20:12.840 - 00:20:52.850, Speaker A: And the problem is just like we cannot keep writing to the root because the root will overflow very soon. So how do we deal with this question? Okay, so basically what I'm going to do next is first I'm going to tell you how to resolve this overflow issue and then remember, I have been cheating so far. I still have this position map in the CPU cache. I will get rid of that and then I'll talk about some improvements to the algorithm, including pathoram. So let's first think about how to resolve this overflow issue. Okay, so to prevent overflow, our idea is also pretty simple. We are going to have some background Eviction process.
00:20:52.850 - 00:21:46.722, Speaker A: And the Eviction process is like some maintenance process that tries to move the blocks up the tree towards the leaves in a way such that no bucket will ever overflow with extremely high probability. So the question is, how do you design this Eviction process? There are two seemingly conflicting goals. Like we want to spend a reasonable amount of work on the Eviction, right? So if we spend too little work, then things can become crowded and overflow. If we spend too much work, then the cost is too high. So eventually when we count the cost, we are going to amortize this background Eviction process to each request. So the cost will be amortized to each request. Okay, so how can we kind of balance these two goals? So here's a first attempt and this is the approach suggested by the original binary tree oram so the idea is also very simple.
00:21:46.722 - 00:22:17.130, Speaker A: Every time we make a request, we are going to pick two random buckets at every level for Eviction. Of course, the root level has only one bucket. So we are just going to Evict that bucket twice. Okay, so what does it mean to pick a bucket for Eviction? So here's what it means. Suppose this bucket is chosen for Eviction. What I will do is I will scan this bucket, find a real block in the bucket, and I will evict the real block to one of the children. And which child should you write it to? There's only one correct answer because that block has already been assigned to a random path.
00:22:17.130 - 00:22:41.300, Speaker A: And depending on the path you have assigned it to, it should either go left or go right. So in this example, let's imagine the block you have chosen should be going right. So on the right hand side, you are making a real Eviction. On the left hand side, you have to make a fake Eviction. You have to pretend you are Evicting to this bucket by reading and writing every position in the bucket. And this is for security. It hides which child you are actually writing it to.
00:22:41.300 - 00:23:29.698, Speaker A: Okay? So similarly, if you happen to pick this bucket for Eviction and the bucket doesn't have any real block in it, you just make fake Evictions on both sides to hide the fact that the bucket load is empty. So if you do this, you can see actually the Eviction process itself doesn't break security because the access pattern of the Eviction process is completely independent of the requests. Because for every request, I'm just picking two random buckets at every level. For Eviction and I'm reading and writing that bucket chosen as well as two children. Right, okay. So as I said, the Eviction process doesn't leak any information and this is easy to see and what remains to. I still need to convince you that this actually solves the overflow problem.
00:23:29.698 - 00:24:08.718, Speaker A: And in fact, we can prove if you set the bucket size to be roughly log n, then with extremely high probability, none of the buckets will ever overflow. And if you want to prove this, you can either use QE in theory or use like measure concentration bounds. I'm going to give you a very rough intuition of the proof. So in fact, the intuition is if you look at every single bucket, the DeCure rate is twice as high as the incur rate. And this is why I'm choosing two buckets rather than one at every level for Eviction. So that two matters. So if the DeClue rate is twice as fast as the incur rate, you can roughly think of it as an Mm, one Q.
00:24:08.718 - 00:24:29.774, Speaker A: And the queue length, the probability, the number of jobs remaining in the queue exceeds R is exponentially small in R. So this proof is cheating a little bit because there's actually dependency on these buckets. But if you just apply like the discrete version of the Berks theorem, you can essentially think of each bucket as being independent.
00:24:29.922 - 00:24:31.450, Speaker C: What do you do with the leaves?
00:24:31.870 - 00:24:39.450, Speaker A: What do you do with the leaves is guaranteed. Leaves, we use just churn up bound.
00:24:41.150 - 00:24:42.918, Speaker C: How do you think you know leaves?
00:24:43.014 - 00:25:06.594, Speaker A: Leaves is like you are throwing M bars into M beans and every bean like if the bean size is login, there's no overflow with extremely high probability. So because everything is assigned to a random leaf. Right? So you are throwing N bots into N beans. Actually you only need to have like the last level only needs to have like n over log n buckets. So if you throw N bots into N over log n buckets, you're fine.
00:25:06.792 - 00:25:08.610, Speaker C: Do they ever get the queue?
00:25:08.770 - 00:26:03.026, Speaker A: Sorry, the last level you don't have to Evict. Yeah, because the boss and beans, that already covers it. Okay, so this is our first algorithm and the cost so far is like for every access I claim, it incurs log square cost because you are reading a path. And then you pick two random buckets at every level for Eviction, right? Bucket size is log n. So log n times log n, you have log n squared. Okay, so I still have to convince you how to remove the position map because right now I'm assuming the CPU starts this large position map and the answer is one word recursion. Okay, so how do you get rid of it? You have this position map, you start it in a smaller orm and then you recurse recurse until the position map is constant in size and then you start that in the CPU cache.
00:26:03.026 - 00:26:37.650, Speaker A: So as long as your block is large enough to start two indices, like the path information for two blocks every time, you can reduce the size of the orm by a half. And after log n stages, you get down to constant. So this recursion does incur an extra log n overhead. So basically log n squared becomes log cube. But what I want to mention is actually this recursion log n is a different sort of log n because in practice this recursion depth is like usually two or three. And that's because this log has a large base. Like the block usually can store many, many indices.
00:26:37.650 - 00:27:16.106, Speaker A: So that's why for this scheme it's log cubed in theory, but in practice it behaves more like log squared and we can get rid of one of these logins, which is the bucket size log n. Right now the bucket size is log n. The question is, can we make it constant? Indeed we can. And this is exactly path orm. But if you make the bucket size constant, you have to make the eviction more aggressive. So what does this mean? Like in the binary tree orm I talked about, the eviction is kind of silly, right? Because I chose this bucket for eviction. I'm scanning the whole bucket anyway, but I only ended up evicting a single block.
00:27:16.106 - 00:28:07.562, Speaker A: Why not just try to evict as many blocks as possible? Because I've already touching this bucket, right? Okay, so pathoram says, okay, we are going to try to use the most aggressive eviction algorithm possible and this allows us to make the bucket size constant. I mean, of course the proof of this is like pretty nontrivial. So the idea is every time you read, you are going to evict along a path and you will take all the blocks along the path and you will try to pack them as close to the leaf as possible. So evict as far as possible, except that you have to always be subject to the path invariant. So remember, every block is assigned to a random path and you can never break that invariant during eviction. So this is the basic idea of the Pathoram algorithm. If you do that, log cubed becomes log squared in theory.
00:28:07.562 - 00:28:35.346, Speaker A: In practice it's more like log n because one of the log has a large base. Okay, so the advantage of this algorithm is like it's really simple. The pseudocode is like 16 lines of pseudocode. We are even counting NDF and four. It's so simple you can print it on a t shirt. Okay, so let me summarize. Tree based Orams, right? So these are like simple data structures.
00:28:35.346 - 00:28:43.730, Speaker A: In my opinion, they're actually even easier to describe than binary search trees. For me, it's easier to teach this than binary search trees.
00:28:43.890 - 00:28:45.970, Speaker B: Elaine, I bet you mean balanced binary search trees.
00:28:45.980 - 00:29:11.278, Speaker A: Yes, but balanced binary search trees. Exactly. Okay, so the key insight is like a block is remapped to a. New random path every time you access it. And you have to relocate the block in a way that doesn't reveal the new path. And that's the key insight. And for the eviction process we have to design it in a way such that there's no overflow.
00:29:11.278 - 00:29:17.810, Speaker A: And typically for these constructions, proving no overflow is actually the hard part. The security proof is always kind of trivial.
00:29:18.410 - 00:29:22.790, Speaker C: Okay, what do you do with those overflow?
00:29:25.610 - 00:30:08.238, Speaker A: You can actually tune the parameter such that the overflow probability is as small as encryption failure. In that case, if there is indeed overflow, it depends on whether you want to go for security failure or correctness failure. There are two choices. If you want to go for security failure, you want to be perfectly correct, then you just somehow retry a different path. Okay, so let me talk about the applications right now. There's a lot of interest in industry about Orams. Okay, so I saw on Twitter Andrew Miller used to have this decision tree about do you need a blockchain? So I tried to do something similar for Orm.
00:30:08.238 - 00:30:49.422, Speaker A: Do you need an oram? Okay, so here's a very simple decision tree. Do you need trusty hardware? Pretty much. If you do, you need Oram. Like this basically goes hand in hand with Intel, SGX and other trusted hardware. Unless your program is not interesting, unless your program is like a simple straight line program that doesn't have branches or it doesn't have data structures. But the set of such programs is very limited. I'm not talking about cryptographic secure multiparty computation at all in this talk, but the answer is the same for secure computation, it's not often talked about, but if secure multiparty computation actually becomes practical, you also don't want to take these programs and convert them to circuits.
00:30:49.422 - 00:31:28.010, Speaker A: You'll be using Oram because converting programs to circuits will incur polynomial blow up. So anywhere you need secure multiparty computation and your computation task is interesting, you also need Oram. Okay, so of course I'm going to talk about blockchain applications, right? So Oram is gaining a lot of attention in blockchains. Here are some applications I've heard of privacy preserving transactions and Smart contracts. I'll briefly tell you the flashbot use case and I'll tell you about privacy preserving lightweight clients. I'll just go over them pretty quickly. So privacy preserving Smart contracts and transactions.
00:31:28.010 - 00:32:33.538, Speaker A: So I'm actually stealing Andrew's slide. Okay, so there's like several layer one blockchains that are encrypting transactions on chain and then the miners are running basically Intel, SGX, or trustee hardware to run these transactions. Okay, so you think know encrypting the data gives you security, but actually it does not. And the problem is that so these are some of these companies that are doing this. And the problem is I think this is Andrew's attack. He looked at this memory trace for secret network, and from this memory trace you can actually pretty much learn all the information they claim to hide like the sender's account, the receiver's account, so you get basically no security. Okay, so I mean, what's the solution to this problem? Of course you want to use Oram, right? Oram will hide the access patterns and you can no longer see who's the sender, who's the mean.
00:32:33.538 - 00:33:20.814, Speaker A: There are other examples. Like, let's say your smart contract is accessing some NFT. And if the miner can see that, okay, you are interested in this NFT, they can front run you and basically buy the NFT to jack up the price. They can do this arbitrage. Okay, flashbots is also interested in Oram and this is their scenario. Okay, so what is flashbots? So you may have heard of like DeFi and uniswap and arbitrage opportunities on blockchains, right? So I don't have time to go into details, but at a very high level. So there are these parties called Searchers and they're just watching transactions posted to the public pool and they're looking for arbitrage opportunities.
00:33:20.814 - 00:33:47.050, Speaker A: So let's say they find some transaction that they can arbitrage and how do they do the arbitrage? They are going to both front round and back around the transaction. This is called a sandwich attack. And they create a transaction bundle. And now they are going to work with Flashbots to submit this bundle. So they basically submit this bundle to their private pool. And Flashbots promises, okay, I'm going to create a block that contains your bundle and we are going to split up the profit. For instance.
00:33:47.050 - 00:34:48.378, Speaker A: Okay, so what Flashbots wants to do is they want to run this private pool inside SGX enclave because they want to guarantee the security for their customers. They're also saying even individual users, not just searches like even individual users, you are encouraged to submit through our private pool because we can give you the protection against front running and back running. But of course, they also have to convince their customers like they themselves are not front running their transactions. Right? So, I mean, again, whenever you have trusty hardware, you'll need SGX, you'll need Orm because otherwise Flashbots can still see, oh, you are looking at this NFT, I can front run you that way. So this is another potential scenario, and I think Andrew actually mentioned to me they're actually looking into Oram for this reason because they want to earn their customers trust. Privacy preserving library clients is another application. Like, your phone cannot start the whole blockchain lock, but it wants to access some transactions.
00:34:48.378 - 00:35:21.750, Speaker A: So mobile coin is like using Oram for some purpose like this, but they actually have two different usages for Oram. This is one of them. Okay, so these are the potential applications in blockchains. I'm sure it's not an exhaustive list, so if you know other applications, I'm very happy to talk to you about it. And before I conclude, I want to mention our ongoing effort and some of the challenges we face to deploy this technique in practice. So we are building what's called oblivious STL. So this is like a standard library for oblivious algorithms.
00:35:21.750 - 00:36:05.058, Speaker A: More specifically, you can think of it as the oblivious counterpart of the standard STL library. Right? C has STL. Java also has its own library, but we want to provide an oblivious counterpart and we want to offer things like data structures, like map set, priority queue, range query data structures. We want to have common algorithmic building blocks like sorting, shuffling, graph algorithms and so on and so forth. So let me explain why I think there is an urgent need for such a library. So even though, as you have seen, oram is like a very simple binary tree data structure, there's actually still interestingly, there are still challenges towards deployment. And the first challenge is just lack of awareness.
00:36:05.058 - 00:36:43.074, Speaker A: Like, for instance, signal. It took them five years to realize they should be using path Oram rather than like a naive linear scan. And it's also very interesting to contrast Orm and ZKP like zero knowledge proofs. I mean, of course these are very different algorithms that they're used for different purposes, but ZKP has a lot of awareness in the blockchain community. The algorithms are actually much more complicated than Oram. I would say this market is very segmented because there are so many different algorithms and there's no one size fits all algorithm, because every algorithm is better at this, but maybe not so great at something else. The barrier of entry is higher.
00:36:43.074 - 00:37:08.250, Speaker A: Like if you want to find programmers to program CKP, I think it requires a lot of expertise, whereas in comparison, Oram algorithms are actually very simple, but there's just less awareness that you need there's actually for almost every task you need, there's a unified solution. The barrier of entry is also lower. A lot of these techniques are actually very mature from an academic perspective.
00:37:10.190 - 00:37:23.982, Speaker B: Elaine, it's probably worth saying, I mean, go back a I mean, a lot of the current interest in the left column is driven more by scalability concerns than privacy concerns, whereas there's no kind of scalability story on the Oram case.
00:37:24.116 - 00:38:07.920, Speaker A: That's right, unless you are doing linear scan, then there will be a scalability concern. All right, okay, so there's another reason why we need to have this oblivious STL. One question is, why not just throw O Ram at everything, just implement path Oram and call it done. And the problem is that if I know what I need is a map, a priority queue, I need sorting, I need this graph algorithm like breadth first search. You don't actually have to go through the generic Oram transformation. There are often a much more efficient oblivious algorithm for your specific task. So if we are going to create a library for these common data structures and algorithms, you can often get like a log n saving on top of just naive oram everything.
00:38:07.920 - 00:38:43.834, Speaker A: Okay, so there's a line of work on oblivious algorithms, there's a mismatch of performance metrics. And let me explain what this means. Like, when we study algorithms, let's say, undergrad algorithms, when we teach algorithms, we implicitly use the word Ram model. And this is when your CPU is reading a memory. But you can read and write data in bytes, in single bytes, and in this simple model, it's very clean. And the nice thing is, like, the computation overhead is the same as the memory overhead. So that's why when we learn algorithms, we talk about running time.
00:38:43.834 - 00:39:11.010, Speaker A: There's only a single overhead metric. There are no two different metrics. But when it comes to SGX, it's not the case if your enclave wants to access some data that lives outside the enclave. So your enclave may need to access some encrypted data that lives in insecure memory or disk. You have to do a page swap. You have to talk to the operating system, hey, operating system, get me this page. And the page is at a four KB granularity.
00:39:11.010 - 00:39:58.130, Speaker A: If you just want to read one byte, you still have to pay this four KB granularity cost. So this model actually has a name in the algorithms literature. It's called the external memory model. I mean, external memory model was invented initially not for SGX, it was for something else. But SGX is actually a perfect fit for the external memory model. So what we really need is external memory algorithms. And why are these page swaps so expensive? Because to do a page swap, you have to do a context switch, you have to do a system call, you have to encrypt and decrypt the page, right? Like the thing you fetch in, you have to decrypt it, but you also have to cache something out, and you have to encrypt that sometimes, if your data cannot fit in memory, you also may involve a disk swap, which is heavyweight.
00:39:58.130 - 00:40:27.820, Speaker A: Okay, so let me show you why external memory is important for SGX type implementation. So this is work that came out of Berkeley. It's prior work, oblix. So the number shown here is not their exact algorithm, because we couldn't run their code. We asked them for help and we couldn't compile their code, and we didn't get enough help to compile it. So we created a version that's better than their algorithm. Like, we did some things they didn't do right, we did it correct.
00:40:27.820 - 00:41:08.694, Speaker A: And what happens is we can see the page swap is more than 90. So I think for their actual work, it's probably even higher than this, because we already did optimizations. So that's the dominant cost. And then we basically redid everything using external memory algorithms. This paper is appearing in Usenic Security, and my student Afonso will be giving a talk in August. So we are saving like a ten to 100 x factor than a Bleax on real world data sizes. And with this improvement, the page swap is only like roughly 60% overhead and Compute is like 40% actually.
00:41:08.694 - 00:42:01.158, Speaker A: I mean, initially it should be quite surprising to you for something as simple as like so this is, I believe it's Map not Oram, but it uses exactly the same techniques as Oram, the algorithm I showed you. It's like some simple binary search tree, some binary tree data structure. So it should be quite surprising that we can get so much saving out of a simple data structure. And finally there's a challenge which is like the security of the implementation itself. And I guess we can also look at Oblix as an example. Like if you look at their code, it doesn't actually achieve the security they claim to achieve because the code they are running inside the enclave, it has these branches that conditions on secret variables and every branch has a different memory trace. So if you can do cache timing attack, you can actually learn the access patterns inside the enclave.
00:42:01.158 - 00:42:23.710, Speaker A: So this kind of problem is not something we should leave the programmer to figure out because there's actually a very nice formal method technique. It's called memory trace oblivious type system. With my collaborators, we had several papers that show how to just automate the task of making sure your program is memory chase oblivious.
00:42:24.210 - 00:42:27.220, Speaker D: So you said there's a cache timing attack here.
00:42:27.750 - 00:42:59.354, Speaker A: So in the SGX context, the weakest security you want is like the page swaps are oblivious. But that's usually not enough because if there's a co resident user application, the user application can do a cache timing attack. Like it can pollute some cache line because the user application and enclave application, they are sharing cache. So by doing these cache timing tricks, you can learn exactly inside the enclave which memory location is being accessed. And there are lots of papers that show how to do these cache timing attacks. So we understand it very well.
00:42:59.472 - 00:43:07.886, Speaker D: I see, yeah, I mean, that makes sense. But then is the example here actually cache timing or is this just this.
00:43:07.908 - 00:43:57.506, Speaker A: One is a cache timing issue because sometimes you can even just attack by measuring the runtime of the program depending on how bad it is. Because each branch has different memory traits, even the timing behavior will be different in some sense. But anyway, from an academic perspective, this is again a solved problem. These techniques are very, very mature. What remains is just to actually get them deployed in the real world. Okay, so this is why I think oblivious STR will overcome a lot of these challenges we face in terms of deploying Orm at a large scale. We also want to go for these features in the medium term.
00:43:57.506 - 00:44:38.582, Speaker A: We want to have parallel versions of these algorithms. We do have some algorithmic works on these topics like oblivious parallel algorithms. We want to implement some oblivious programming abstractions. So if the programmer uses these abstractions, we can convert them to an oblivious counterpart much faster than generic Oram. And I mean, we want to use these type system techniques, compiler optimizations, to make sure your oblivious implementation is the fastest possible. Okay, we have started working on oblivious STL, but I think we really want to scale up the effort. So, so far we have released an oblivious map and our next step is to release oblivious sorting algorithms.
00:44:38.582 - 00:45:12.280, Speaker A: But we have a lot more things to do. There are some preliminary open source code you can look at. Mostly this oblivious STL is in the first URL and the second one contains reference implementations of Oram algorithms. Okay, so to conclude, I want to show you another large scale application of Oram. Apparently if you go to Pittsburgh, you can buy Oram's donuts at coffee shops. So I will take you out and buy you an Oram if you come to visit me. Do you need an orm? Yes, thank you.
00:45:12.280 - 00:45:14.760, Speaker A: Yes.
00:45:15.130 - 00:45:33.670, Speaker C: I have a question about Oram. So I guess in your implementation, whenever you fetch the data from the leaf level, you first put it to the root, right? Then I guess it takes certain amount of time for it to migrate from the root to the leaf again. And I guess you cannot access that piece of data in that time period.
00:45:33.750 - 00:45:43.470, Speaker A: Otherwise you can because the read is accessing the whole path. So as long as you are always moving it along that path, you are reading that path, you can always find it somewhere.
00:45:44.130 - 00:45:48.238, Speaker C: So you pretend I read all the way to the leaf level, but I don't actually.
00:45:48.324 - 00:45:52.882, Speaker A: Yeah, the read reads the whole path, so it means it reads the root every time I see it.
00:45:52.936 - 00:45:53.314, Speaker C: Makes sense.
00:45:53.352 - 00:45:55.234, Speaker A: Thanks e time.
00:45:55.432 - 00:46:08.326, Speaker E: Yeah, I guess there is kind of a gap between the linear scan and the logarithmic ones. So in practice, do you see cases where square root n or n to the one over k will be better trade off for some use cases, I.
00:46:08.348 - 00:46:29.120, Speaker A: Think for only very narrow scenarios because I guess as I said, this log squared is more like a log n and these constants are very small. So if there's an asymptotical difference, you can probably find some very narrow region or where you can argue or maybe square root n is a little bit better, but I think very narrow region probably.
00:46:30.370 - 00:46:52.342, Speaker D: So I think one of the challenges that might remain and maybe all of these applications is about distributed trusted hardware clients. So even in MobileCoin, I think they have I understand they're one of the best or they talk about it, but it's kind of an unsatisfying thing. So if they want to have lots of servers, then each server has to either have like a shard of the data or something if you want them.
00:46:52.396 - 00:47:24.990, Speaker A: That's actually a really interesting question. So if you have MapReduce or Spark, you can get constant overhead. It's no longer login. So I think this is one of these citations I hit there parallel, like I guess one of these papers is about, okay, MapReduce and Spark in the algorithms community. It's called the massively parallel computation model. It's another NPC massively parallel computation. And we show that any massively parallel computation algorithm can be made oblivious with constant overhead and that constant is a small constant.
00:47:24.990 - 00:48:08.290, Speaker A: There's a different interpretation of your question, I think. I've been talking to some companies who might be interested and another kind of parallelization they need is, I think is what systems people call Sharding. But it's essentially a parallel mean you don't want to implement oblivious parallel ram in the way they're described in theory papers. I think snoopy is maybe one practical example of oblivious parallel Ram. So essentially these Oram algorithms are very amenable to Sharding. They're just naturally designed to Shard. You can cut off the part near the root of the tree and then it becomes multiple subtrees and the access pattern is naturally load balanced because every request just goes to a random subtree.
00:48:08.290 - 00:48:25.140, Speaker A: So that's why they are so amenable to Sharding. Oh actually also back to your question, you asked about square root n, but the thing is also we don't know any algorithm that's square root n that's simpler to implement than the log n version, the log squared n version. And I think that's another reason why you don't want to go for square root n.
00:48:26.950 - 00:48:42.466, Speaker E: Actually, two quick questions, I guess. So is there kind of interest or something special happening for MPC friendly oram going back to Andrew's question, and the other one is about maybe hardware friendly oram would something change or would you do the same?
00:48:42.508 - 00:48:47.606, Speaker A: Yes, that's a great question. I assume by MPC you mean multiparty.
00:48:47.638 - 00:48:55.174, Speaker E: Computation if you want to implement the oram not on kind of one secure enclave, but basically as a multiparty computation.
00:48:55.222 - 00:49:44.590, Speaker A: Yeah. So I think for most MPC type scenarios what you need is circuit oram. So what I talked about is pathoram. And the difference between circuit oram and pathoram is in circuit oram, you want the Oram algorithm itself to be implementable in a small circuit and there you need to change the Eviction algorithm. You can get exactly the same asymptotical bounds as path orm, but you are changing the Eviction algorithm such that the Eviction algorithm itself can be easily implemented in a small circuit because you are going to compute that circuit with MPC. Whereas for hardware trusty hardware scenario, really you can just work with pathoram. But for something like Intel SGX you don't want to just implement pathoram as is as in the original paper, you want to apply these external memory algorithm techniques on top so you can minimize the number of page swaps.
00:49:44.590 - 00:50:27.286, Speaker A: And also, I think there's also some details I omitted. Like basically if you want to resist cache timing attacks like you want even the access patterns inside the enclave to be oblivious, then you actually need to implement the oram the Eviction algorithm itself in an oblivious manner. And this is like there's some tricks to do it obliviously efficiently. What you need to do is use oblivious sorting. For instance, the oblique X paper. I guess for some strange reason they were using some improved version of a quadratic algorithm. But actually it's actually well known.
00:50:27.286 - 00:51:12.374, Speaker A: What you should do is you use two oblivious sortings to implement the Eviction algorithm. Yeah. If you had to run oram in a distributed fashion, as you were saying, cut out the top of the tree and then maybe distribute the subtree, is there work to making that Byzantine resilient? Like if you want to allow for fail. I've actually seen a paper that has the title Byzantine something oram in the title I confess I haven't looked at the paper. But I think these are very good questions because from my experience talking to these companies, a lot of them are interested in some extra property on top of oram sometimes it's maybe Crash Fault tolerance. I mean, yours is a stronger version of Crash file. They want to tolerate crashes.
00:51:12.374 - 00:51:27.870, Speaker A: They want to maybe sometimes have some database type guarantees. So I think these are also some of these engineering efforts we have to make to make these schemes suitable for these types of deployments.
00:51:30.530 - 00:51:39.220, Speaker B: Tim so obviously you need randomization in a lot of these algorithms. Is that kind of a solved problem? Like getting good randomness kind of within these?
00:51:40.790 - 00:52:17.246, Speaker A: Yeah. How to get good mean? I guess this is like a somewhat orthogonal mean. There's like some work by Yevgani Dodis, I've seen some papers. He has looked at these randomness generator implementations in Linux and proposed some more secure variants. So I think we can just directly rely on that line of work. I think all you need is like generating randomness once and then you can use a PRG to extract it, to stretch it. Right.
00:52:17.246 - 00:52:34.462, Speaker A: You can use like AES to stretch some short random C to long randomness. And this would suffice here. Really? You don't have to always sample true randomness for the whole algorithm. Okay. Thank you so much. Yeah. If you are interested in oblivious STL, talk to me.
00:52:34.462 - 00:52:38.200, Speaker A: I'm always happy to talk about it. Okay, sounds good. Thank. Here.

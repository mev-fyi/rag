00:00:09.230 - 00:00:52.640, Speaker A: I'm the founder at Chia. It's a proof of space and time based blockchain. So as you'll see, it's rather similar to proof of work where other people are going towards proof of space. This is more of a true Nakamoto other people going to proof of stake, where this is much more true Nakamoto consensus, but rather proved over proof of work. As I will get to here. And I believe some of these techniques, particularly around how vdfs are integrated, are likely also applicable to proof of stake as well. So that seems to be a message that's worth getting out there.
00:00:52.640 - 00:02:09.560, Speaker A: So, first of all, in physics, you have this basic formula, work equals force times distance. Proof of space and time winds up being kind of analogous to this. That proof of work is roughly comparable to proof of space times proof of time, that you're mixing together proofs of space and time, where space is kind of like force and time is kind of like distance, and that acts like proof of work. Only the benefit is that you do these are two linear steps that can be done where you just mathematically multiply them together without actually doing them in tandem, which causes a lot less electricity to get burnt than if you're just doing proof of work. So key to this whole thing is proofs of time, which in the literature go by the much less poetic name verifiable delay functions. And people talk about verifiable delay functions for security, but they're often these like add on things that they have some consensus algorithm where they cram in vdfs in various places for security. And this is really presenting a very different vision of them, where they are integral to the consensus algorithm itself, like very deeply embedded into the entire thing.
00:02:09.560 - 00:03:23.918, Speaker A: I believe this makes it so that you can avoid having to do a lot of the slashing that people are talking about these days, that it's not entirely clear what exactly the slashing is supposed to accomplish if you're trying to make clear definitions of things, but kind of hand wavely slashing is meant to punish people for bad behavior, where if you throw in vdfs, you can generally make it so they just kind of can't do the bad behavior. You just put up these impassable walls and you don't have these problems. So first off, for definitions on our primitives, a proof of space is something where you have a plot file, just this stuff that's stored, which is not proof of replication. It's important to note it's simply proving that you have this space. And because you have this thing. You can respond to challenges very rapidly with something where you can show the quality of your response and then you will be able to sign things using this response. It's important that the signatures you have produce unique outputs for the constructions coming up as well.
00:03:23.918 - 00:04:10.990, Speaker A: We're using BLS signatures for that kind of hand wavely. You can implement something like this by filling your disk full of bingo cards in sorted order. Because you pre sorted them, you can respond to challenges very quickly and see how high quality of a response you came up with. That specific type of construction is subject to time space trade offs, which are called helmet attacks in this context. In other places they're considered good, here they're considered bad. There's a fix for those that's way beyond the scope of what I'm going to be talking about right now. It's in the beyond Hellman paper.
00:04:10.990 - 00:05:01.360, Speaker A: I'm very proud of that when I came up with the trick myself. But the final result kind of winds up acting as if it's just doing lookups on pre computed public keys. So you can just intuitively pretend it's doing that and your intuitions will be right. So then you have proofs of time. A proof of time has an input to it, and a number of iterations it has to run, and it is not parallelizable across those iterations. It is extremely sequential across all of them. And another important property of it is as it is generating this output, it's possible to generate a proof that the output is correct, and that proof is quickly verifiable by anybody.
00:05:01.360 - 00:06:00.802, Speaker A: And it does not slow down the process of generating the VDF output in order to generate that proof. These constructions didn't really exist when I started Chia, I always tell people, don't have invent new math here anywhere in your product roadmap. I'm a total hypocrite on that one, but I whined about needing verifiable delay functions until our advisors invented them. We are specifically using 1024 bit binary quadratic forms with Wislowski proofs. This is the first ever deployed in the wild actual usage in cryptography of class groups as far as I'm aware. So that's kind of neat. All right, so intuitively you can say, well, we can alternate between these.
00:06:00.802 - 00:07:02.738, Speaker A: And so our first green paper described a very simple approach where you simply alternate between these, where you have a proof of space and the quality of the proof of space determines the number of VDF iterations necessary to finish it, and higher quality proof results in less iterations that had a number of problems. So we're using this much more complicated construction that I will now explain. So what's going on here is time is going to the right, arrows pointing to the left are secure hash pointings. These dotted lines are VDFs running. The arrows are just secure hash pointings. These are next slide to explain. This whole construction is accomplishing a bunch of things, and I'm going to walk through these in this presentation.
00:07:02.738 - 00:07:32.990, Speaker A: So on the left here we have things that are being used. On the right, we have. In the final thing, we have chia security. Yay. So first thing we have is splitting the chain. So here in our chain, there are actually four things going on here in four different kind of rows. So here we have what's called the challenge chain.
00:07:32.990 - 00:08:05.094, Speaker A: And then here we have the infused challenge chain. And here we have the rewards chain. And up here we have the foliage chain. A very important component of what's going on here is that not very much is happening in the trunk. Right here. Up here in the foliage is where all the actual transactions go. That's important because transactions are extremely malleable.
00:08:05.094 - 00:08:55.450, Speaker A: Users can trivially change what's in transactions. And when you're going for a construction like this, you get a lot of these same grinding problems as you get in proof of stake that someone who has some fraction of the space can, because it doesn't cost any power to try different things, people can just do that. People can try a million different versions of the history for the next minute or two and just pick out the one that works best for them. This is sometimes referred to as the nothing at stake protocol. I hate that term because it's kind of proof of stake propaganda, because stake is a solution, not a problem. The problem is grinding is what you have. That's the form of the attack, is grinding.
00:08:55.450 - 00:09:48.278, Speaker A: And so almost everything in this construction, this kind of complicated looking construction, is all about dealing with grinding problems. So your very most basic thing is that your proofs of space, your vdfs, and your signature algorithms all produce unique outputs that you can't just twiddle them and make a kind of valid looking output that might be not quite right, but looks okay. You can't do that at all with any of the primitives being used here. If you don't have that, none of these techniques work. So the next thing up is to try and make it so that the amount of stuff getting factored into all of your challenges is as small as possible. So, number one, it's absolutely critical that the actual transactions are not factored into this. So you have this reward chain down here, which is telling you who made the blocks.
00:09:48.278 - 00:10:28.102, Speaker A: And every time someone makes a block in the reward chain, they sign a block in the foliage chain. There's a public key in the plot that was used to make the block in the reward chain. And that can sign, well, sometimes sign, I'll explain that in a bit. But those sign blocks in the foliage chain that contain actual transactions. So the foliage chain is kind of hanging off of all of it, and the whole thing doesn't work at all if you don't make that distinction. Obviously there's more distinctions here because there's three things in the bottom, not one. But I will get to that.
00:10:28.102 - 00:10:29.794, Speaker A: Okay, next you have ram.
00:10:29.842 - 00:10:30.726, Speaker B: Quick question.
00:10:30.908 - 00:10:31.446, Speaker A: Sure.
00:10:31.548 - 00:10:37.626, Speaker B: So is it like a one to one correspondence between blocks on the foliage and reward, or is one a subset of the other?
00:10:37.648 - 00:10:38.460, Speaker C: Or how should.
00:10:42.990 - 00:11:26.118, Speaker A: Only some of the blocks on the reward chain make foliage blocks? But that's because they can kind of happen in parallel. I'm going to get to why that is in a little bit. Blocks in the reward chain happen about every 20 seconds. Blocks in the foliage chain happen about once a minute. Basically, a block in the reward chain can't make a foliage block if it happens too soon after a different. After something that made a foliage block. Just because you have a dependency relationship between the blocks there and the thing is designed to make it so you don't need super unbelievably low latency to actually function good.
00:11:26.204 - 00:11:38.110, Speaker B: So I should think about kind of the first thing that happens is transactions gets posted to the foliage chain. Now, I think of those as fixed. And now validators are trying to kind of validate it and earn rewards subsequently on the reward chain.
00:11:38.850 - 00:12:10.162, Speaker A: Hold on. Validators are like bitcoin validators here. They're full nodes, so they're very much like bitcoin things. They actually have a complete copy of the entire history of everything. They're validating every single block that's made. We have a lot of them. This presentation doesn't explain there's over 100,000 of these running, because often when people are running farmers, they're running a full node, and it just doesn't cost that much to run a full node just due to good engineering.
00:12:10.162 - 00:12:44.610, Speaker A: Basically, the utxo set is a good idea, but a full node is not contributing to the weight of the chain. We sometimes call those validators more often full nodes, but they're like bitcoin full nodes. And there are farmers which are like bitcoin miners, which are moving things forward. And there are a lot more of them than in bitcoin. They're a lot more distributed, but they're performing an analogous thing. So this is very unlike proof of stake, which kind of mushes together those two concepts.
00:12:45.030 - 00:12:45.970, Speaker B: Excellent.
00:12:46.470 - 00:13:19.230, Speaker A: Yeah. All right, so the next thing is we have correlated randomness. So you see here, there's this infusion that happens at the beginning of a slot. Slots are like ten minutes. And then you see, as this goes forward, nothing new is getting pulled into the challenge chain. All the challenges that come up during that time are VDF outputs that happen along this one line of things. And only at the end of the slot is another infusion done from the infused challenge chain.
00:13:19.230 - 00:14:00.140, Speaker A: If any of you know about the work of David C's group, they call these epochs. But as I twiddled the numbers, what they call epochs wound up being ten minutes. So we don't call them epochs. But the idea here is the challenges for this entire grouping of things here are all based off the same value. So if someone's trying to manipulate things, the very first thing you can do is reduce the amount of stuff that everything is derived from. So that's why you have this separate challenge chain happening here. That turned out to be like an important insight into how the whole thing works.
00:14:00.140 - 00:15:05.726, Speaker A: Then you need is delayed gratification. You want it to be that when someone's making a decision, they have a decision, and decisions need to be available, because if nothing else, someone can make of alad block and go, you know what? I'm just not going to do this because I represent some significant fraction of all the farmers and just happenstance in this particular time, if I don't present this, then it's going to change future challenges in a way which happenstance is good for me. And so it's worth it to me to withhold this particular block. Even though I'm losing out on the value of that block, I'm gaining more than that in the future. This is an unavoidable potential attack on the system. So what you want to do is make it so people don't actually know what the effects of that withholding is going to be. So it's never worth it to them to do that because they won't be able to check and see if it's worth it to them.
00:15:05.726 - 00:15:35.642, Speaker A: And then you try and make it so that by the time they might go, oh, wait, it would have been better for me to withhold this. It's too late. They've already published it or gotten orphaned off. So that's kind of what this shows right here. So you have this infused chain, and the rule is that the very first block made, my pointer is acting weird. The very first block made gets infused into the infused challenge chain. The infused challenge chain then does nothing.
00:15:35.642 - 00:17:01.094, Speaker A: It's just sitting here vdfing until the end of the slot, at which point it gets infused into the challenge chain, and then it goes forward and makes, like, a challenge. So this block here is made off of this challenge, but this happened because of this right here. And so you didn't know whoever was going to make this block didn't know that that was going to happen until this time occurred, and they needed to make the decision about whether to publish this way back here. And further, the reason why there's a separate reward chain going on here is this thing is getting buried. See, all the blocks that are pointing to the reward chain past this point where this block got infused are now burying this block. And so if this was not published, then this building on top simply wouldn't have happened, and this block would have gotten orphaned into nonexistence. And if this was published, then this will now be at the appropriate time, then this will now be very widely published and everything is built on top of it and can't be taken back anymore at this time over here, when you actually find out about what's happening with the rewards based off of it.
00:17:01.094 - 00:17:49.906, Speaker A: So that's why there is this whole separate reward chain, is to make this burying happen. Okay. Another thing that's quite important is that there's only one Time Lord. One tends to kind of naively make it so that you assume that everyone has to do their own VDfing, which is not a great idea. It's pretty hard to have the very best VDF, and it's pretty expensive to do it all the time. So this whole system is set up so people can simply publish their blocks. And as long as there's one honest time Lord out there in the world, it will be infusing their stuff into it and they don't have to worry about it.
00:17:49.906 - 00:18:43.622, Speaker A: And part of what makes this possible is that the Timelord's outputs don't do much of anything. The only decision the Timelord makes is whether to include stuff or not. And by definition, an honest Time Lord is just trying to include everything. And then on top of that, there's also these delays. There's all these times between when a challenge happened that enabled a block and when the block actually got infused to overhear. So, every one of these back pointers is there to introduce this delay, which is meant to make it so that you can publish a block to the network, and then it will have time to get to the Timelords that are out there, that are fast and get infused as they move things forward. And if you didn't have these delays, there would be substantial advantage to whoever it was that had the smallest latency to everything.
00:18:43.622 - 00:18:55.420, Speaker A: And this is a problem in bitcoin as well, that there are places where, if you get the jump on someone by just ever so small an amount, you will win more blocks. And that's a bad thing.
00:18:56.190 - 00:19:05.710, Speaker B: Question, could you elaborate a little bit like Time Lords? Like, which parts of this figure do they contribute to or organize?
00:19:06.290 - 00:19:08.394, Speaker A: All the vdfs are made by Time Lords.
00:19:08.442 - 00:19:09.038, Speaker C: Okay.
00:19:09.204 - 00:20:06.734, Speaker A: All these dotted lines are made by lords. So there are a number of time lords out there running in the chia ecosystem. There are farmers who are making blocks. There are full nodes which are doing validation and sending out transactions that are in the mempool and distributing finished blocks, and providing services for wallets who want to know what's going on right now. And then there are timelords who kind of finish blocks that are going out and publish new challenges and proofs that they're valid as they occur. And then there are these things called blue boxes that compactify the proofs of the VDF outputs after the fact. The proofs that you get fast are bigger than necessary, so you can have these other things that generate smaller ones later.
00:20:06.734 - 00:20:41.514, Speaker A: And those can be slow because they can do it at their leisure. You can compactify things in parallel, because you know all of them after the fact, and have different machines compactifying different ones. That's the general ecosystem. It's very much a ripoff of bitcoin. But, yeah, the Time Lords are doing all the VDfing. There's a bunch of them running out there. We had a funny experience where some mystery Time lord appeared that was running quite a bit faster than ours, and we have no idea what it was.
00:20:41.514 - 00:21:03.810, Speaker A: We think it was like some next gen intel processor that someone, some intel engineer, just decided to try running a Time Lord or something, and left it running for a week and then took it down. We have no idea. What we definitely know is very fast. If there's anything in the universe that you can remotely prove, it's that you have a fast Time Lord.
00:21:05.430 - 00:21:08.660, Speaker C: How much faster was it? Just curious, was it like.
00:21:11.030 - 00:21:24.730, Speaker A: I think we were running like, 250,000 iterations per second. And it was running like 320. Something like that. Maybe it could have been overclocked. Not entirely sure what was going on there. So we couldn't. Death.
00:21:24.730 - 00:22:05.094, Speaker A: Okay. And then there's a bunch of empirical things leading to better security here. The thesis of this whole thing is that disk space is out there. There's lots and lots of storage capacity that's out there in the world that's underutilized or getting thrown out. And that that can be leveraged to with very little additional power costs make a very high security parameter. And this has been out for a while now. So we've tested this security thesis and turns out it works.
00:22:05.094 - 00:22:32.874, Speaker A: So Chia is now at over 20 x bibites. So that's more than that in ex sub bytes. This is powers of two versus power of ten thing. And this has dropped over time. But the price of Chia dropped by like a factor of 50 from the peak here. While the security parameter didn't really drop all that much. Where an equivalent change in a proof of work based system would have just been a disaster.
00:22:32.874 - 00:23:11.930, Speaker A: Those sorts of price drops have happened and caused the whole system to stop working. We're here chugs along just fine. We're also coordinating the circular drive initiative which a bunch of the hard drive manufacturers are joining in as well. We're changing industry standards that currently call for old drives that are no longer reliable to be shredded to allow them to be wiped. Which is generally pretty easy because they're generally encrypted just on the drive these days. And you can just throw out the keys. But the industry standards haven't kept up with that fact over time.
00:23:11.930 - 00:23:43.222, Speaker A: Old drives are not reliable enough for archival storage but still plenty reliable enough to have plots sitting on them. Because if you're doing archival storage if any of it starts getting corrupted that's a big problem. And if it gets calamitously all gone that's a huge problem where if you're just farming. No big WHOOP whatever. If a little bit of it gets corrupted maybe once in a great while you should have gotten a reward. But it failed. And if it dies then oh well.
00:23:43.222 - 00:24:14.590, Speaker A: It died at that moment. But nothing worse happens other than you no longer get the benefits of farming off of it. So this is going to continue to unlock a lot more storage. I always warn people about investing in farming that people who started farming at the beginning of this cycle here, people who had pre plotted beforehand and were farming here. They made bank. They made crazy amounts of money. But markets don't like it when there's a legitimate way of doubling your money in a month.
00:24:14.590 - 00:24:47.958, Speaker A: And so it turned into this crazy high net space. And this is likely to be a highly competitive commodity thing going forward because these are not like special purpose asics like you get in proof of work mining. This is just normal drives which are already a commodity thing. And then people are tapping into the absolute cheapest versions of all these they possibly can. It's a tough market. Some people are making money farming, but the expectation is people who are good at it are going to be able to do it. People who aren't are going to have a lot of trouble.
00:24:47.958 - 00:25:59.762, Speaker A: And also there's a lot of people who just have these old dead drives that someone's throwing about, a bunch of drives and someone's like, hey, how about you just give those to me? And they're like, here, have them, whatever, and then they start farming off of them. So there's a lot of that going on, which results in it being very widely distributed. So in proof of work, you get these economies of scale about power and other things, not really much at all with proof of space. So this is the chart of the biggest pools you can see. The very largest pool is only like a fifth of all the space thereabouts. And then on top of that, the things that say op here, that stands for official protocol, the things using that protocol, which is more than not now, in that protocol, the pools don't make the blocks, the actual farmers are making the blocks with the pools just kind of helping smooth out rewards that everybody's getting, which is all they really should be doing. So that's contributing to the level of distribution of the thing as a whole.
00:25:59.762 - 00:26:51.214, Speaker A: Also, a really silly but important point is the number of reward events we have per day is much larger than you have in like bitcoin. We have 5000 reward events per day, which makes it so that the viability of farming on your own and the viability of running a small pool is much, much greater than it is when you have a much smaller number of reward events per day, because things are already much more smoothed out just at the chain level in terms of the statistical fuzz. And then finally we have vdfs. You need your Time Lords to actually be the fastest they can be. You need nobody to have like a faster Time Lord than anyone else. So we are using squaring in 1024 bit class groups. That's actually by its nature pretty good for speed.
00:26:51.214 - 00:27:34.174, Speaker A: It turns out it's spending most of its time in extended GCD which is pretty easy to optimize and pretty sequential by its nature. We did a couple of competitions with $100,000 prizes for improvements in this. Got things quite optimized, turns out. Also Intel IFMA architecture is good for it. And on top of that, we have put money into getting actual Asics made. So we're getting a run of twelve nanometer chips, a small run, probably around 100 of them, which we're going to have in our hands around the end of this year, and we're going to be selling most of them. They're going to be selling for like $1,000.
00:27:34.174 - 00:28:52.200, Speaker A: We are not selling these out of profit at all, but we're going to have an application process for people who want to buy them, because we kind of want to get them into the hands of people who want to help out with the ecosystem and study them and provide value that way. That's it for the notes I put together for a presentation, so I can just do Q and A. Now, I should probably also note that, that first, this basic construction here probably can just be applied fairly verbatim to proof of stake. The main nuance is the block making then has to be made by stake, right? So you take your stake that you have and hash that together with a challenge to find out the quality of it and multiply by its size as well. And that has additional potential grinding, because restaking is a grinding vector, so you just need to make it so that it takes a while to restake. So it takes like on the order of like a day maybe for that to happen in order to prevent grinding attacks there. Does anyone have any questions? This is all very highly technical set of things.
00:28:52.730 - 00:28:58.940, Speaker B: Graham, this is great. So I don't know if you can see the chat, but Sam just posted, I believe, a couple.
00:29:00.750 - 00:30:16.962, Speaker A: Okay, how much faster does a malevolent time load need to be from the honest ones for things to break? And since plots are keyed to the farmer, does this mean that a malevolent farmer would be forked out of consensus pool by users? So in answer to the first one, I'm not really sure being like 10% faster doesn't make that much big of a difference. The earlier construction that I had, that simply alternated vdfs and proofs of space, that one suffered a lot from having faster timelords being a problem, because there, it was just straightforward. If you had twice as fast of a Time Lord, you get double the rewards of anyone else. So there was this very straightforward business model of running a faster Time lord and charging for it. And that was potentially problematic. This new construction, it's a little hard to say. It has this property that when you're time loading, you can't really just move your own stuff forward because you kind of wind up moving everyone else's stuff forward while you're at it.
00:30:16.962 - 00:31:17.638, Speaker A: So you need actually quite a big chunk of all farming capacity to be colluding along with this faster Time Lord in order to get any benefit out of it. It's a little hard to make particularly coherent metrics about exactly what that means. We don't have a super great analysis of it, but being a little hand wavy, it definitely has this property that you're mostly just kind of helping everyone if you have a faster Time Lord. If someone had a ten times as fast Time Lord, pretty high probability they could mess with things and cause issues. But if someone's like 10% faster, it's really not a big deal. The next question has to do with things being keyed to the farmer. I assume that this is asking, if someone behaved really badly, would there be a potential for there to be a soft fork that just bans somebody? Short answer is no on that one.
00:31:17.638 - 00:31:47.234, Speaker A: We haven't seen anything vaguely resembling that kind of bad behavior happening in the network. This is not proof of stake. It's just much harder for people to mess with the thing at all. But there's actually a fair amount of privacy inherently for farmers, that if all else failed, you could always just redo all your plots. You have all your space and you could rerun all your plotting. That would have some cost with it. Although we've gotten the cost of plotting down a lot as well.
00:31:47.234 - 00:32:10.194, Speaker A: That's been really interesting working on that. And then. Because just anyone can join. This is true Nakamoto consensus. Right. The big distinction with proof of stake is when you have something like this, people can just join and leave at any time. There's no requiring permissioning from someone who's already there to join the club.
00:32:10.194 - 00:32:52.738, Speaker A: You just do it. There's no stopping anybody at any moment from just joining and leaving because of that. You can sort of virtually leave and join. You wipe your stuff, you make new pots, you're good to go. And also, if you were to anticipate that people were doing this, you could build things in a way where people couldn't tell that you were all the same entity across your whole thing. That right now, the main way you tell that a whole bunch of things were all done by the same farmer has to do with the pooling protocol. That the farmer is intentionally kind of mushing their stuff together, tying it together with this kind of interesting bit of smartcoin programming to allow them to jump between pools.
00:32:52.738 - 00:34:16.366, Speaker A: Your rewards are tied to going to being collectible by a particular singleton that's sitting on chain, and you can set that singleton to be currently controlled by a particular pool where you can pull the plug and reclaim control of it yourself. As a farmer, this is good use of smart coin functionality with a very minimal hook at the consensus layer to enable this. And it has the very nice property that when you have a pool, it's the farmers who are making the blocks, not the pool. And yet people can leave the pool if they want to, where the pool can't stop them from leaving. However, it also does make it inherent to how it works. It makes it so that your stuff is all tied together on chain that people can kind of see, oh, it's this particular singleton doing things, which is a little bit of loss of privacy for a particular farmer, although you don't have to use just a single singleton, you could split it among multiple ones, or in the extreme just not do it at all, just completely go it alone as a farmer yourself with no pool usage whatsoever. And then in the extremely unlikely scenario of the exact same plot making two different blocks, people could see that.
00:34:16.366 - 00:34:31.350, Speaker A: But that almost never happens anymore because the net space is so gigantic and you could always just delete individual plots that did that. So at the expense of not getting the benefits of pooling, you can get all the privacy you want as a farmer.
00:34:39.370 - 00:34:56.160, Speaker C: Quick question about your instantiation of the VDF. So the assumption is somewhat non standard. I guess the technology is kind of new with these class groups. I was wondering if you could share, how was the process of setting the parameters up?
00:34:57.570 - 00:35:30.920, Speaker A: Yeah, class groups are not actually that obscure in number theory. They're kind of comparable to like elliptic curves or something like that. It is a different security assumption. It's not a particularly obscure or scary one or anything. It's something kind of normal. And there's different security assumptions with the proofs that we're using, although you could always just change the proof format if there was a problem in those. So that's not even really a concern at all.
00:35:30.920 - 00:36:28.650, Speaker A: There is interesting questions of how you set the parameters to the whole thing, like what are the security assumptions to it. The big attack is someone being able to find the order of the group. It's very important that these are groups of unknown order, and they don't really have to remain unknown forever. They just have to remain unknown until people are building other stuff on top of the whole thing. So if you just found the order of one of the historical groups, that would get you nothing whatsoever in terms of the blockchain here. And people did a bunch of work on trying to do RSA based groups of unknown order, and having a setup ceremony for those that did not go well. But the advantage of this is, all you need to have a new group of unknown order is a new prime.
00:36:28.650 - 00:37:20.186, Speaker A: So we take our challenge and we hash it to 1024 bit prime, just by making a bunch of random digits of the appropriate length, and checking for primality, and modifying it until it's prime. Basically the. From there, you have to pick an initial point, which is another interesting subtlety. And we're actually making a new class group. Every single time we start a new VDF, we're not reusing groups at all. And the initial point that we use each time is setting. We make sure that our primes are seven mod eight, and then we set a to two and b to one, and just calculate what c should be in order to satisfy that.
00:37:20.186 - 00:37:30.880, Speaker A: And that's our initial point that we use. And then it's repeated squaring of that thing, and then we throw it out when we're done with that. That's the fairly technical details of what we're doing there.
00:37:38.070 - 00:37:53.730, Speaker C: I have a question about the rewards. Can you first comment on how the different players in the ecosystem are rewarded, and in particular, the Time Lords, and how much security relies on the design of those incentives?
00:37:54.150 - 00:38:43.266, Speaker A: Yeah, so the Time Lords are not directly rewarded. Running a Time Lord is a public service. So it's kind of like running a full node, right? Running a full node is costing you something not directly benefiting you. So the idea is you try to design it so that the costs are as low as possible to make it happen by design. There's no rewards for running a Time Lord. It would actually introduce grinding attacks if there were. But you only need one good Time Lord on the network, and we're going to great expense to make sure that there's plenty of good hardware out there to make it not crazy to run a Time Lord.
00:38:43.266 - 00:39:44.954, Speaker A: So we're running a few Time Lords now, other people are running a few Time lords. When we come out with our hardware for it, which is going to be around three times as fast, we're going to distribute that to a whole bunch of people. There will be a fair number of Time lords running out there in terms of incentives on other things. Like I was saying, again, there's no direct incentive for running a full node, although we have over 100,000 of them running, because people often run them when they're running a farmer, and we have a lot of farmers, and it's not terribly expensive to run a full node. The real rewards are for farming, and it's very bitcoin like your rewards are a combination of fixed block rewards and transaction fees that happen. And there's a transaction fee market for just space in blocks. And there's a schedule on how this is going to go.
00:39:44.954 - 00:40:35.610, Speaker A: There's going to be a couple of happenings that are going to happen. There's going to be like three of them after that. There are going to be no more happenings, because having a blockchain that's entirely secured by transaction fees is a very scary thing to have happen. So we don't want that. My hope is we tried to run the numbers in such a way that even in the terminal case where we're running the whole global economy, you still have the bulk of, you still have the bulk of rewards to farmers coming from the fixed block rewards with a nice bonus, a meaningful bonus, but not the bulk of it coming from transaction fees when there's high transaction fee pressure.
00:40:36.270 - 00:40:52.960, Speaker B: Curiosity. You mentioned in passing the work out of David Sage group, which I assume is like their era of time idea, which I think was sort of vdfs in a proof of stick context. Could you compare contrast a little bit with their work?
00:40:53.330 - 00:42:08.040, Speaker A: I'm not sure where the latest of their stuff is. It definitely got something very directly off of their stuff, because at the beginning of 2020, I had actually been trying to come up with something better than what we had, and it just wasn't working very well. And then his group claimed to have a proof that this correlated randomness thing worked very well. And it turned out there was a subtlety, I'm not remembering off the top of my head, my old thinking, there was a subtlety about exactly what was mixed in. It turned out you had to not merely delay how long it took for things to get mixed in, but really dramatically reduce the amount of data that was mixed into challenges in order to make everything work. And I wound up then spending most of 2020 on this rather complicated construction that I was just explaining, which is much, much better than the old one, but requires this whole series of things to happen on it to be really effective at stopping grinding attacks. So I think this is the most.
00:42:08.040 - 00:42:27.770, Speaker A: What I have here is the most sophisticated, like really fleshing out of the whole thing that anyone's done to date. But yeah, that group is also thinking in terms of really leaning pretty heavily on vdfs.
00:42:30.830 - 00:42:35.680, Speaker D: Ram, do you want to know why we called it VDF and not proof of time in the origin?
00:42:37.670 - 00:42:38.420, Speaker A: Sure.
00:42:39.910 - 00:43:00.838, Speaker D: We thought about proof of time. It was one of the original ideas. I think we wanted to go with delay instead of time, to try and avoid people thinking that there was some specific guarantee about time, as in wall clock time and more, that just. There's a proof that some delay happened. But you can't reason precisely about the.
00:43:01.004 - 00:43:49.080, Speaker A: Yeah, verifiable delay function is definitely a more descriptive term. It's just not as cool. So I believe that's Joe talking. Joe is whining about needing these. I was also whining about them. And it spoke to Dan Bonet about it, who actually seemed a bit skeptical that I had an actual use for such beasts in the wild, because they had not become important up until then. It's kind of interesting because the question of existence of vdfs wasn't exactly a new one, because there had been time lock puzzles, time lock cryptography, for a long time, which was kind of just on the edge of useful, but not quite.
00:43:49.080 - 00:45:00.426, Speaker A: And then there were these ancillary questions of, like, could you do, basically, could you make vdfs? Is a question that had occurred to me and I had worked on it and I had gotten absolutely nowhere. But the funny thing is that the VDF constructions are actually the newer, more elegant ones are based off the same thing as the old timelock puzzles were, that they're repeated squaring in a group of unknown order. And it's just the timelock puzzles require a trap door, where now people have these clever tricks for being able to make the proof. Even if the person doing the squaring doesn't actually know anything, they just know that they did the story. There's two different proof techniques, actually using the same repeated squaring in a group of unknown order thing. There's a piachak and Wislowski. And so Kristoff sent me a preprint that he did of how to do this with his proof technique, which is actually being used for validation of very large primes.
00:45:00.426 - 00:45:46.246, Speaker A: Now, it's kind of neat. And so I sent it along to Dan, and Dan was like, oh, yeah, and you could remove the trusted setup using class groups. And I was like, ok, we can do that. What's a class? So that's how we wound up where we are now. The Ethereum people really want to do well, they had a bit of a disaster with RSA groups, but they really, really want to do post quantum vdfs. Now. There are some benefits to that, because you can make it so the actual hardware to generate the outputs is much smaller, although you wind up having to do this crazy zero knowledge stuff for the actual proofs.
00:45:46.246 - 00:46:22.360, Speaker A: And so that winds up being a much beefier rig with other assumptions that it's based off of. They have hardware coming out for that as well, but they don't actually have the proof system set up for it yet. So I don't know exactly what their plans are for what they want to do with vdfs. I do know they're not actually ready to do it yet. So I needed something expedient and functional and workable, and this is something that we've had deployed in the wild for a year and a half now. So it was the obvious choice when we just needed something working.
00:46:22.810 - 00:46:49.970, Speaker D: I think the short answer, Bram, is the ETH foundation. The plans are a little unclear on vdfs, if they're ever going to be included as part of the beacon chain, but they're doing this BLS signature thing instead. And the plan is like they could strengthen that with vdfs to prevent this withholding attack. That's possible to give you a bit of bias, but it's not clear. There's not like a target launch date for that. And they're waiting on hardware.
00:46:50.870 - 00:46:55.700, Speaker A: Yeah, I would advocate for really going all in on the whole thing.
00:46:57.430 - 00:47:08.962, Speaker D: That was obviously what I wanted to see happen too with east, but I think the VDF project kind of missed the deadline for the merge, so now it's not really on the front burner.
00:47:09.106 - 00:48:08.140, Speaker A: Yeah. Another interesting thing with timelock cryptography is the utility of that is still very much in the open. The existence of decent VDFs raises the question of whether you could do batch unlocks of time lock puzzles. So the problem with time lock puzzles is you can build them, but the expense of unlocking them is massive, which wouldn't be a problem if you could batch unlock a whole bunch of things. So no matter how many time lock encrypted messages you were trying to crack open, at the same time, you still only had to run some number of iterations of your repeated iteration thingy. And the viability of that as a mathematical primitive is still very much an open question. Kind of interesting potential field of research.
00:48:14.430 - 00:48:43.494, Speaker B: On a different topic. One thing that was really interesting is how when you mentioned in passing about farming pools, and I agree with you, that ideally their role should be in sort of reward smoothing over time. So variance minimization. But you made this point that actually maybe you already get enough of that, even at just sort of a very small percentage because of the higher frequency of reward events. Is that just because there's like a faster block time? And then like a related question.
00:48:43.532 - 00:49:13.760, Speaker A: Yeah. So the story is I cranked the numbers as much as I dared. So we have like around 5000 reward events per day. And the numbers started to scare me if I cranked it more than that. So that's what we're doing. And for better or for worse, we're sticking with it. One nice thing about consensus algorithms, you deploy them, and unless you do hard forks all the time, like the ETh foundation is big on doing, we don't do hard forks ever.
00:49:13.760 - 00:50:01.710, Speaker A: And if you don't do hard forks ever, you can just stop worrying about stuff. Because it's deployed, it's not changing, we can't do anything about it. But I cranked up the number of reward events as high as I dared, and I thought I was pretty good because at that amount of rewards, even very small farmers, I thought, would have their rewards smoothed out pretty quickly, even if they weren't part of a pool. So we deployed without a pool protocol actually being written. Although there was a hook in the consensus algorithm for it. The hook is very simple. All the hook says is you can have plots that instead of tying their rewards to a particular public key, tie their rewards to a particular puzzle hash.
00:50:01.710 - 00:50:43.526, Speaker A: So that's just where their rewards are going to go. And the smart coin chia also has a very powerful on chain programming environment that's utxo best. That's a whole other presentation to explain that there's plenty enough functionality to enable pool protocol there. But we hadn't started working on it yet because I did the math. And we had around 100 petabytes of space at launch, which I thought was a crazy huge amount at the time, but it still looked fine for smoothing. Oh boy. And then we launched and our initial coin price was just crazy.
00:50:43.526 - 00:51:40.000, Speaker A: Just insane. Which caused a ridiculous amount of resources to be put into building up farming capacity, which is great from a security standpoint, but it meant that small farmers weren't getting smoothing, they were just not getting any things at all. Even if they had pretty great positive expected value. Because coin price was so high, their chances of actually getting it were very small. So people rolled out really janky, completely insecure, horrible pool protocols, which people blamed me for. And then I said, okay, well, we're working as quickly as we can on a real pool protocol because obviously we need it a lot faster than we thought. And then I had no end of hate range down on me because it wasn't done yet, and it took us like ten weeks to get it out, and people claimed I was a mass murderer for taking so long on this.
00:51:40.000 - 00:52:44.702, Speaker A: Yeah, but that's how we wound up where we are today with the pool protocol. And that's why there's still significant amounts of space that were plotted before the real pool pooling protocol came out that are using pools that don't work that way. There's been hardly any new stuff plotted since the real pooling protocol came out using the completely insecure older way of doing things. Just people. Everyone agreed that the better way was better, thankfully. But yeah, you get these constant factors that matter, right? So you don't always hit asymptotics, right? Sometimes you have these real world empirical numbers. Visa handles, I don't know what the number is, but somewhere around 100 transactions per second, I think actually a lot less than that, but in that neighborhood.
00:52:44.702 - 00:53:51.250, Speaker A: And so when you're dealing with scaling, you probably don't need to deal with scaling more than that, right? You have real users have Internet connections that have some capacity, so you have some scale that you can assume that your full nodes can handle. And given the very large number of full nodes we have, pretty clearly the scale that we're running at is entirely reasonable for a real practical full node to handle. Most likely an order of magnitude more than that, and most definitely two would be seriously problematic and result us in us having very, very few full nodes. So we've kind of hit a bit of a trade off where the amount of bandwidth necessary to run one is pretty tiny and the amount of cpu is something that, like a raspberry PI can handle just fine. That's kind of our target for that. And that's with it having basically the same capacity as an ethereum full validator. And it gets the better scaling, mostly just from better engineering.
00:53:52.590 - 00:53:53.720, Speaker B: Graham, thanks so much.

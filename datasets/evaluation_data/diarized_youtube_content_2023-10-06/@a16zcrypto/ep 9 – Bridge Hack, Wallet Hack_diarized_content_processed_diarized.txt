00:00:00.330 - 00:00:00.880, Speaker A: You.
00:00:04.930 - 00:00:57.326, Speaker B: Welcome to Web Three with A Six and Z, a show about building the next generation of the Internet. From the team at A Six and Z crypto that includes me, your host, Sonal Choxi. This show is for anyone, whether developer, engineer, researcher, artist, community manager, company leader, entrepreneur, policymaker or others seeking to understand and go deeper on all things crypto and Web Three. This week's all new episode digs into recent high profile hacks that took place in the crypto space. Over the last week. We not only dig into the details what happened, including a more technical breakdown of the how and how we know, but we also cover the categories and issues specific to and not specific to Web Three security, as well as solutions and advice for builders. We also touch on related trends and topics such as the role of open source communication around hacks, as well as social media status, signaling and much more.
00:00:57.326 - 00:02:12.930, Speaker B: Throughout, we try to help tease apart what's hype, what's real, as well as what's signal and noise in the narratives out there. Joining me for that this week are experts from the Asics and Z crypto security team, including security engineer Matt Gleason, CTO Riaz Faisulaboy and CISO Or chief Information security officer Naseem Edikiak, both of whom worked previously at Facebook, Anchorage and Docker and Naseem Or. Nas also appeared on an earlier episode of this show on NFTs and Security, in case you missed it. But for this episode, just to quickly recap for your context, the hacks that we're specifically covering are first, the hack of the Nomad Bridge, which connects several different blockchains, including avalanche, ethereum, Evmos, Moonbeam and others, with reported range of between $185 to $190,000,000 stolen. And then we also cover the hack of the Slope Wallet, a noncustodial browser based wallet that was reported to affect nearly 8000 users on salana as well as other ecosystems, with a reported range of between four point five to eight million dollars stolen. It occurred a week ago, and Slope just posted their latest update today, confirming some of the details we discuss in this episode, which was recorded a few days earlier. As a reminder, none of the following is investment, business, tax, or legal advice.
00:02:12.930 - 00:02:27.930, Speaker B: Please see a Six and Z.com disclosures for more important information, including a link to a list of our investments. With that, the first voice you'll hear is Riaz, followed by Matt's talking about the Nomad hack and the broader category of DFI bridge hacks.
00:02:30.030 - 00:03:41.374, Speaker C: This one to me is interesting because when we think about Web Three security, the impression that I get is that many people think of it as this very obscure, dark art sorcery of smart contracts and how blockchain and Web Three works totally. And when you step back on this incident, it's really a logic flaw about updating state in one place and not how to handle it in another place. Nothing specific to how bridges or validators key management, any of that stuff is nothing unique to that. We've seen similar hacks before both in Web Three and in Web Two and earlier systems. And so I think we could take a lot away from just software development lifecycle, how we test upgrades, how we think and reason about sensitive code. But it's one of those hacks where everyone is again zeroed in on bridge hacks. Are bridges a bad pattern? Are they all insecure? Are they all the big targets? And each of these incidents, I'd say there have been different classes of attacks, some of them specific to smart contracts and very specific, whether it's Oracles or other Web Three native concepts, but a bunch of them haven't.
00:03:41.374 - 00:03:49.378, Speaker C: And this is an example of one that really is quite a well understood type of bug, but obviously affected a bridge.
00:03:49.474 - 00:04:36.302, Speaker B: Yeah, just to give people a quick context, just at a very basic conceptual level, bridges basically connect blockchains. They're exactly what they sound like. They're a bridge literally between two different blockchains, two different blockchain ecosystems, which is really important because that allows you to connect different types of information, transfer assets and tokens, more importantly, enable cross chain collaboration, et cetera. So that is a point of a bridge. And when I think of a bridge I live in, you know, and I'm constantly going to the East Bay to visit my friends, there's a lot of traffic on bridges because there's a lot of people trying to get between things. I mean, I don't know if there's necessarily a lot of traffic know these blockchain bridges, but the idea being that there is a concentration of things, which would be my guess for why people are targeting bridges. I don't know what you guys think about why people are targeting bridges.
00:04:36.446 - 00:05:14.554, Speaker D: I mean, the key things to capture about why bridges would be targeted are twofold. One that you already brought up, which is that they'll have some concentration of funds. This bridge had like 150 or $180,000,000 in it. And the other one is they're built to transfer the funds. So the main logic in the bridge is to transfer the fund to someone else. And so if you're going to have a mistake and the mistake is in the logic of the transferring, then you're going to allow you to transfer it somewhere else. And that's exactly kind of what happened here, right? There's a mistake in the transfer process and they have a big concentration in funds.
00:05:14.554 - 00:05:26.306, Speaker D: And so the exploit that happens is I get to get all the funds, or in this case, they didn't get all of them, but they get a sizable portion of it and then cause a lot of chaos along the way.
00:05:26.408 - 00:05:50.686, Speaker C: I was going to add, like you mentioned, the concentration in the cars on the bridge. One piece of bridges too, which makes them a target, is much how you can see the number of cars and the traffic on a bridge from far away because you can go on your favorite Blockchain Explorer and check out these contracts, check out what's going in out of a bridge. You can see kind of the equivalent of the traffic on the bridge and the funds locked in a bridge and you can measure your output of what you can get.
00:05:50.788 - 00:06:18.706, Speaker A: Exactly. And similarly, you have also full visibility into incidents as they happen. We started seeing a lot of different people that realized what the issue was and started also draining the funds. Some of them returned them as part of the fund recovery process. People who are essentially white hats, but some other people may have just drained it for their own benefit. And all that thanks to the transparency of the system.
00:06:18.808 - 00:06:27.874, Speaker B: Yeah, exactly. It's a constant theme, right? The very transparency is sometimes a very thing that it's a double edged sword. But I have to say it reminds me of the olden days of highway robbery.
00:06:28.002 - 00:06:38.230, Speaker D: I think it's the first bank run style exploit we've ever seen, which is just this chaotic everyone piling on. I mean, the hack was a mess of transactions.
00:06:38.310 - 00:06:43.754, Speaker B: I was literally thinking that the analogy that I would use here is like looting. Like when you have looting and people are all taking advantage.
00:06:43.802 - 00:06:49.006, Speaker D: Well, some of those people returned the funds, but yeah, it was crazy.
00:06:49.108 - 00:06:58.082, Speaker B: So let's talk more about the technical aspects, like break it down. I'm curious for you guys to share how you know things, some of the method behind the scenes as well as the what happened.
00:06:58.216 - 00:07:39.310, Speaker D: So I'll start like really high level. So this is literally a hack we've seen before. Qbridge was kind of exactly the same pattern when we look at it now. So basically what happens is a contract gets audited, it gets changed, they set some weird insecurity faults, add a weird path, and then it gets exploited real hard in terms of the technical details of this one. So inside the Replica, so this is a contract. Inside their system, there's this process function. And this process function is going to go through and basically verify that, hey, I have seen this message before.
00:07:39.310 - 00:08:17.162, Speaker D: It has been proven, meaning it's gone through a merkel proof, so I know it's genuine. And then I'm going to process what it tells me to do. And so what basically happened here is in the process of proving it, they're using something called this acceptable route. And the acceptable route is going to go through and basically go, okay, has it been proven before? Yes. Okay, then that is proven. Has it been used before? If the answer is yes, then I'm not going to treat it as proven. And then otherwise I'm going to look to see when the merkel route that I'm relying on was put into place.
00:08:17.162 - 00:09:22.560, Speaker D: So merkel route allows you to basically prove that, like, hey, I've done this anyway. So through all of that, the bypass ends up being in some of the weirder logic around which acceptable route is checked. So in solidity, when you call something, when you call a mapping specifically and you call it with an uninitialized value, it's going to just return zero. And so what would happen here is it would go, okay, well, what is zero an acceptable root in the case where you gave it a message, it is never seen. And the answer the contract ended up giving is yes, which should blow your mind because what that means effectively, is if it's a message it's never seen before, meaning if it's a message that has an address modified to something different or something similar, then it's probably going to accept it. And when it accepts it, it's going to do what the message says. In this case, transfer $200,000 to me, please.
00:09:22.560 - 00:10:12.910, Speaker D: And the reason this happened is because a default route, basically an initial route that was set to zero. And so, again, the system thinks, hey, the route of zero is accurate, and as a result, I will accept any message that I haven't seen before. Which from a technical aspect is kind of scary, right? Because what it means is you're a bouncer at a door and you're taking tickets, doing what the tickets say, but if you've never seen the ticket before, whatever's written on it, go do it. That's not a secure system. So it creates a lot of problems. And so that's kind of what we saw. Is this just like piling on of people realizing, hey, I can change the address in this message, which, by the way, makes the message something it's never seen before, but now I can send this and it'll give me $200,000.
00:10:12.910 - 00:10:15.278, Speaker D: They didn't even have to know how the exploit worked.
00:10:15.364 - 00:10:25.926, Speaker B: Okay, so that's why the bridge was able to be drained of funds so quickly. But I just want a bit more detail on the root cause because how did that happen in the first place? Could you guys break that down a bit more?
00:10:26.028 - 00:11:37.882, Speaker A: So the root cause is essentially at the message passing level. You have two chains for every single deposit that happens. On chain A, the information needs to be transmitted to chain B. And on chain B, the funds should be able to be withdrawn at the same amount. Right? What happened is that the message passing and the mechanism by which the messages get validated on chain B ended up being broken. And this mechanism was broken through a software update that essentially did not account for the state that was stored in the smart contract and pretty much started taking the same variable in the state of the contract and interpret it differently. Essentially, the zero that was saying that transactions should be reverified or were already included didn't mean the same thing after the same zero meant, this transaction has not been verified yet.
00:11:37.882 - 00:11:48.970, Speaker A: Approve it. So this is the moment where a zero in the state, a specific variable doesn't mean the same thing before and after the software update.
00:11:49.050 - 00:11:49.680, Speaker B: Interesting.
00:11:50.050 - 00:12:08.946, Speaker A: And so as a company managing the bridge or as a set of developers managing the protocol, you should obviously make the state and the code work together, right? When you update one, you should update the other. But in that case, only one was updated. And so this is really what happened during this hack.
00:12:09.058 - 00:12:13.638, Speaker B: I want to know how you guys figured it out, looked at it, how do we know what's happening?
00:12:13.804 - 00:13:25.402, Speaker D: Realistically, we basically start from what is actually going on on the blockchain. And so if you looked during the attack, which was like highly chaotic, you see a bunch of these transactions and all of them have this call data that looks almost identical with exception of one field. And that one field is the address of the sender themselves. And so you see a few of these and you go, what's going on? They're just sending the same message with just a slight deviation, which is who to send the funds to and then it's sending the funds to themselves. And so when you're sitting in that situation, you have to consider, well, where could this have gone wrong? And if you look at their system and you go, okay, they're going to take messages, they're going to prove the message is real or genuine and then they're going to do what the message says. Where is the problem? And it could be a problem of doing what the message says or it could be a problem of how they're proving the messages. And so what seems more likely in that case when you're just looking at it from the outside is they're probably just not proving it properly.
00:13:25.402 - 00:14:23.770, Speaker D: And so once you know that, you go, okay, something's wrong in the proof function. And then you go looking through their functionality, typically on like ether scan, and then you go, all right, where could this have gone wrong? And so you go look at the process functionality, you see that the only thing doing the proving is this acceptable root function. You look into the acceptable root function and you're like, man, it looks okay ish, but it's clearly malfunctioning for some reason. And then you consider, hey, if this is a message that's never seen what's the acceptable route or what route is it checking? And you're like zero. It's like, all right, what is the contract recording for acceptable root of zero? Oh, it's a one that's really, really bad. And it's like yes. And so once you get to that point, you're like, well, I know there's a problem with proving I don't know if it's a problem for sure, but I know there's a problem with the proving of the transactions.
00:14:23.770 - 00:14:53.334, Speaker D: And I can kind of surmise that, hey, people sending a bunch of transactions. There must be a problem with proof. I have at least one problem with the proof. I'm pretty sure this is what it is now. It doesn't have to be. You can be wrong, but you have a pretty good lead there. And then you just kind of follow that one up and go, okay, what else could it be? Or is there something else I should be keeping an eye out for? And in this case, there's not really anywhere else it should be malfunctioning.
00:14:53.334 - 00:15:13.006, Speaker D: And so that's kind of the process behind how you end up finding or how you end up attributing this kind of exploit to a specific bug. And a lot of that is instinctual at the end of the day because it's a threat model. It's like if you've hacked systems before, you go, oh, this is where I think it goes.
00:15:13.188 - 00:15:13.438, Speaker A: Yeah.
00:15:13.444 - 00:15:47.994, Speaker C: I think one thing with the bridges and just generally with Blockchain is that we have access to all this transaction data of Legit transactions going through the Bridge Malformed transactions and we can use those as data points to help influence during this process. Which paths do we think are still possible or not possible and kind of dig down deep into this process? So in this case, we could see the bridge transactions going through. And so we knew that transactions were being processed and help us lead to the conclusion that maybe the processing itself is flawed and how it lets messages go through.
00:15:48.112 - 00:15:59.694, Speaker B: On that note, is there anything to be said here about what would improve? Because I do want to add obviously not just what happened, how it happened methodological, but suggestions for future avoidance of such.
00:15:59.812 - 00:16:33.322, Speaker A: Yes, for sure. So, across the web, three security incidents that we've observed over the past years is that a lot of entities do not leverage integration testings as much as they should. They're not really building the systems that prevent them from making mistakes systematically. The idea behind integration test is that you are actually testing the behavior of the system as a whole, provided some inputs, and verifying that the outputs match.
00:16:33.376 - 00:16:35.386, Speaker D: What you expect for that, especially when.
00:16:35.408 - 00:17:47.570, Speaker A: Several components are working together, aka code and state, and sometimes multiple software components. And so one thing that could have avoided this issue and a lot of the others that we see in the space is just being a lot more rigorous on the integration testing that has been done. If you start first testing against a local copy of essentially like ethereum or if you're testing on testnet or some other test environment and that you actually run the same code as in production and the same state as in production aka mainnet and essentially go through the process of ensuring that transactions are only approved if they're supposed to be approved, that transactions only get applied once and cannot be replayed. Essentially, this set of use cases that apply to your infrastructure not having these integration tests in place is pretty much flying blind. You're essentially thinking like okay, I trust my code because it is good, because it was reviewed by some people internally. In that case, not even auditors. The auditors did their job before this code change.
00:17:47.570 - 00:18:14.026, Speaker A: And so you're pretty much relying on one person, sometimes two people, to actually validate that the entire system works. What you should do is actually building software infrastructure that will tell you when you made mistakes that will prevent you from making these mistakes systematically. So that's something that should be worked on a lot more across the entire Web Three space.
00:18:14.128 - 00:19:36.190, Speaker C: Yeah, there's a couple of things here that I highlight. One is writing tests, integration tests with smart contracts is well understood and people and different projects do it. The other piece on this hack in particular that is interesting to me because again, it's not new to Web Three, is understanding how in this case, we had a variable that wasn't defined, solidity default to a value of zero, and that's not new to solidity. Other languages, go, et cetera, have default values. And knowing that, having tests that on your end check for what happens if this is zero, what happens if it's undefined, what happens to a very large value and you have this gut instinct of checking the boundaries of what can and cannot or should not happen. But even then, having this negative case in that if we happen to make a mistake and we let something go undefined, how does the system handle and recover in that case? So when thinking about testing, it's common practice to think about the various edge cases. What happens if a variable is zero? What if it's undefined? What if it's a very large value negative? And thinking through the boundaries of these edge cases, of what you may not expect, but it is still possible, is a way to have these negative tests and these guardrails to ensure that your system will recover.
00:19:36.190 - 00:19:43.202, Speaker C: In the scenario that you have a bug or somehow some user input happens to be outside of your expectation.
00:19:43.346 - 00:19:51.146, Speaker B: Are there tools readily available? Are we at a state here where there is tooling ready made? I'm wondering if there's like an easy way to do this.
00:19:51.248 - 00:20:56.698, Speaker D: If I were to add anything to the is there a framework to help avoid this? The answer is no, because the same kind of exploit is happening like multiple times to multiple organizations. Obviously, if they had the tooling to put them in a place where they could avoid it, I think every developer would opt to avoid it. And so, realistically, I saw this in Web Two space as well. It's just a very hard problem because you cannot anticipate every edge case that can happen. And in fact, even your security engineers are not writing those types of tests because oftentimes you really just need to run them once or twice and then you're pretty sure that it's not an issue. A lot of this comes down to whether or not we end up getting a framework that enforces some quote unquote, secure by default capacity. So this is what we've seen in industry, ending vulnerabilities generally is like, hey, we have a real problem with cross site scripting, which is a Web Two vault.
00:20:56.698 - 00:21:04.574, Speaker D: Then you have the design of frameworks that don't allow you to do that on accident. You have to do it on purpose now.
00:21:04.692 - 00:21:22.918, Speaker B: Right. And the trade off there is, is it like an innovation one, like the ability to flexibly, figure things out? Because I do remember this evolution of security. I remember with networking and other security, it was very interesting to see them move towards a castle model to another type of model. And it's very connected to how you can build things.
00:21:23.084 - 00:22:02.370, Speaker D: Exactly. It's like much more restrictive. And so unless you have this very feature rich framework that also offers this security guarantee, it's a really hard sell. People just want to do what they can to make their product work and to make their product good for their consumers. They're not going to care as much about the security guarantees of the framework. I mean, web3 might, but web two didn't. And so it's only when the feature richness gets to a point where we need to do this because it's not only easier, it ends up being better and then we just happenstance get all these little guarantees too.
00:22:02.370 - 00:22:07.830, Speaker D: That's probably where we're going to see that or the evolution we'll see in this space as well.
00:22:07.900 - 00:23:22.262, Speaker A: Yeah, because currently everyone is pretty much testing. So there is the Web Three frameworks across JavaScript and Python and Forge can also be used. Forge and Foundry can also be used to write unit testing and help in integration testing. But the main idea here is the one that Matt touched on, which is you need to share components, build shared components that will become secure by default, that will become the standard in order to essentially eliminate the class as a whole. And that might look like, for example, for bridges, the message passing and transaction proving mechanism, it doesn't feel like the big category of bridges that verify through merkel proofs will gain a lot by re implementing it from scratch every single time. It might make sense to actually share it and try to build the flexibility into what kind of messages you allow to pass and so on as part of this framework. But just like standardizing, at least at a higher level, these mechanisms will help getting everyone to participate in the development and also the security of the specific component.
00:23:22.326 - 00:23:25.110, Speaker B: Right. This goes to your point about open source too, more broadly.
00:23:25.190 - 00:23:25.626, Speaker D: Exactly.
00:23:25.728 - 00:23:40.562, Speaker B: Give me a super high level scorecard on each one of these on the scale of one to ten. And I know it's not like easy to distill. I'm just trying to get a sense where would you put that on? Of all the hacks so far, in the Web Three space. And also relative to Web Two hacks, you don't have to give me a simple answer, but give me the bottom line on that.
00:23:40.616 - 00:24:17.422, Speaker A: Basically, I would say that the Nomad hack was pretty bad in the sense that it happened 30 in the open. There was no real communication with the team during the entire hack. The size, obviously, of the hack from just a financial perspective is gigantic. We're talking about close to $200 million. And there was also no pausing mechanism as part of the bridge. So as soon as the issue was found, there was no way to stop it. So it was kind of like on the white hats to gather as much funds as possible proactively before they were getting stolen, because once it was found, there was no coming back.
00:24:17.476 - 00:24:28.622, Speaker C: Essentially, yeah, it's a very large number. We've seen larger number for dollars hacked, but given that the entirety of the bridge could get drained and there was no pause, as Nas mentioned, was catastrophic.
00:24:28.686 - 00:24:31.122, Speaker D: Yeah, I'd say generally like a nine out of ten.
00:24:31.176 - 00:24:49.690, Speaker B: Okay, so just to recap, we've talked about what happened in the Nomad bridge hack, what we know, how we know it, how to figure stuff out, what to do. But one thing I also like to do is sort of provide a map and a terrain for the listeners for how to think about these things. Where does it sort of fit category wise in the overall related Web Three hacks out there?
00:24:49.760 - 00:25:15.134, Speaker A: Yeah, on the category side, this one was pretty much like logic bug and mismatching between state and code. There was Wormhole, which was more of a cascading, kind of like supply chain security notice. And then the Ronan Bridge hack, which is more the validator key management level. I think that it's kind of like the three big categories that we see.
00:25:15.252 - 00:25:39.734, Speaker B: All right, so that was a Nomad hack, which happened this past week, a bridge hack. Now let's go into the other big hack that happened it's like, almost exactly a week ago, which was a wallet hack of the slope wallet. Let's talk about what happened there, and let's especially tease apart the fact versus the speculation, because I actually found it really hard to follow this one and track it, and then we can go into how we know in other details and big picture themes. But first, let's start with the facts.
00:25:39.862 - 00:26:30.330, Speaker D: At 04:00 P.m. Pacific on Wednesday, a bunch of transactions started showing up on Salana, signed by the addresses themselves, transferring all their money and some of their tokens out of the addresses. It actually repeated, I think, one or two times. So people who transferred more money in got looted a second time in a lot of cases, and effectively no one knew where any of it was coming from. Obviously, the immediate suspicion is, hey, if so many private keys are getting hacked, this is probably not phishing, because we've never seen phishing be this successful. It probably has something to do with wallets, which I think is why people honed in on, like, hey, we think the wallets are having trouble. We don't know who, but we probably should try to get that information.
00:26:30.330 - 00:27:33.946, Speaker D: And unfortunately, user generated telemetry is obviously a little bit flawed, which is that people will report what they remember or what they think the situation is and not what it is, which makes it very difficult to respond to the incident. So in the case of what we know now is there were logs sent by the mobile applications of Slope and possibly the web applications of Slope to a sentry server controlled by Slope that contained both the seed phrases and the private keys of wallets. And these would be wallets attached to Slope. And so what it affects, obviously, mostly salana, I think there were in a total of something like 50 transactions in Ethereum, but 50 transactions relative to 8000 is kind of a tiny number. And that's kind of like where it sat, according to the facts. Right? So this is not us speculating. This is just what we saw and what we saw unfold.
00:27:33.946 - 00:27:50.878, Speaker D: Now, if we want to speculate, the speculation sits on that we can probably attribute the hack to Slope, but that's still something that will have to be verified as time goes on. And realistically, we don't know if it can be completely verified.
00:27:50.974 - 00:27:57.126, Speaker B: And can you guys walk me through a bit more about what you saw as well, like, as this unfolded? Kind of how you know what you know, right.
00:27:57.228 - 00:28:06.854, Speaker C: For this hack, over 8000 up to 10,000 wallets were compromised and drained in quick succession. As we watched it unfold, we saw.
00:28:06.892 - 00:29:11.466, Speaker A: The set of withdrawals from a huge amount of wallets, thousands of different addresses, and that all had very different patterns, withdrawing to four different addresses. The addresses that were getting drained didn't seem to have anything in common. People were not necessarily in front of their computers or phones, and the transactions were actually signed by the signing keys of these addresses. And this is very different from the majority of the issues that we see in the space, because what tends to happen as kind of like larger scale scams is someone puts up, like a fake mint page. The mint action. When you connect your wallet and kind of approve the transaction, it is actually delegating the permission to drain to another wallet, to drain NFTs to drain funds. And more rarely is it like an actual withdrawal.
00:29:11.466 - 00:30:27.160, Speaker A: Right. So that would mean in that case that either someone managed to scam and get people to approve withdrawals across thousands of addresses all at the same time, which ended up not being very realistic because the owners of these addresses were actually not signing anything at the time that were not even at their computer or phone. Or somehow, someone got access to the cryptographic. Materials that are the private keys behind the account. And there were all kinds of reports where the pieces of software that seemed to be affected, if we were listening to the people's early report, were that either all of the wallets are affected or Solana blockchain is affected, or the cryptographic algorithm that was used to generate the keys was broken. Essentially all of these options were scary. And so it took quite a lot of surveying among users to understand exactly who was among the drained and victims was using which kind of software and hardware actually.
00:30:27.160 - 00:31:23.078, Speaker A: And the answer lied in the fact that it was one given wallet, or at least that seems to be the accepted option. And the accepted Bruce cause is that the Slope wallet was actually logging private keys upon key generation and setting them in some cases to a remote server, a remote self hosted instance that they own. And so the interesting part here is that people were actually exporting their keys that they generated in the Slope wallet into other wallets. And so this is why we ended up having the reports of people saying I was actually using Phantom and got hacked, I was actually using this other trust wallet and I got hacked. And this is actually the part that was the most confusing. And so we had a lot of very conflicting information essentially boiled down to.
00:31:23.244 - 00:31:51.614, Speaker C: Complete loss of private keys because the transactions were being signed by the keys themselves due to the keys being leaked in plain text by A. Wallet that was used for many users and in some cases, used in addition to other wallets where they imported those keys or exported those keys to and from Slope. So we saw a multitude of users would use slope as well as other wallets drained over the time frame of this attack.
00:31:51.732 - 00:32:08.070, Speaker B: One quick thing on this, why is it so hard to know on this case? Just really basically straightforwardly. I feel like if everything is kind of open and out there, and we have all these security people that are so smart and all this tooling and a whole bunch of people, why is it so hard to figure out what happened?
00:32:08.140 - 00:32:09.254, Speaker A: That's a great question.
00:32:09.372 - 00:33:29.870, Speaker C: I think there's multiple angles to it, and this incident in particular exacerbated the inefficiencies of how we collect and analyze this data. So firstly, the number of wallets in this case that were affected, the number of users back to Matt's point about telemetry and getting good, reliable, correct data about what actually happened as opposed to what people remember, so that we can then take those facts and move forward. In this incident, the data was not very clean, and so it led to many different directions of exploration. Rampant speculation on Twitter about even if Solana itself was hacked at the network level, if there were cryptography non reuse bugs, if there were supply chain issues across multiple wallets, all of these being very unlikely cases but just given the data that was out there was very difficult to hone in on a path forward. And in the case of this incident too, yes, there is available data on the blockchain. We can see the transactions, we can see the wallets being drained but there's also stuff we can't see. So for example, we can't see metadata or code of wallets if they're closed source or even for live traffic and what goes back to their servers separate from the blockchain itself.
00:33:29.870 - 00:33:40.274, Speaker C: And so in that case, that's where we rely on incident response and collaborating with partners to really dig in and get that information and analyze it to move forward.
00:33:40.472 - 00:34:24.062, Speaker D: Yeah. And in this case, the parties that are affected, like the people with all of the information will not share it. They're actively disincentivized from doing so because it could result in them getting sued over some of this. And so they're not going to be in a place where they should be that forthcoming about information on exactly what happened. They'd go through lawyers and that's unfortunate for the ecosystem but is kind of like what they should do. And so we end up in this speculative bubble now where we're saying like, hey, we think it was Slope, we think it's related to this logging that we have evidence of but we don't really know. Right?
00:34:24.196 - 00:34:53.370, Speaker A: Yeah. Disinformation before it kind of went dark is that autosec who worked with them on auditing and incidents responses that only a subset of the private keys to accounts that were drained were locked. And so it is a bit hard to understand the truth, the damage control part or if there was actually more to this hack than just this logging from the Slope mobile application.
00:34:53.520 - 00:35:03.150, Speaker B: Okay, that was helpful for answering that. So what could have been done in this case? Theoretically? Again, we don't know. So we can't map it perfectly. But what are some of the best practices or lessons learned here?
00:35:03.220 - 00:35:31.302, Speaker A: I would say that there are two things that I think we should work on as an ecosystem. The first one is just having a formal process for incident response. Whether we're a bridge, whether we're implementing a protocol, whether we're implementing a wallet. There is a lot of value in defining a clear process to gather the information, get the right person and not too many people in the right room.
00:35:31.356 - 00:35:31.574, Speaker D: Right.
00:35:31.612 - 00:36:49.470, Speaker A: Because that becomes really chaotic when more than the required parties are present and having the right set of almost like kind of like a checklist style approach to the incidents response. This has been done for decades in web two and there is no reason that web3 cannot reuse the exact same processes, especially on something like wallets which is very much a traditional piece of software infrastructure. Right. It is just key management essentially at the end of the day that ends up signing transactions and just like managing keys. So I think that there is a lot of value in working on such process. And the other thing that I would like to see is just shared components as well as I was talking about for the bridge hacks, I would like to see shared components on things such as key management. I would like for all of the parties involved in the ecosystem, all the wallets to work together on the key generation to work together on building abstractions that make these types of errors, logging keys essentially not possible.
00:36:49.470 - 00:37:13.558, Speaker A: Key leakage should be a common problem to every single wallet and it is not really going to make your business, but it's certainly going to break it if you don't handle it well, which is what's happening now. And so truly working as an ecosystem to build these abstractions that enforce the secure behaviors by default is extremely important.
00:37:13.724 - 00:37:18.950, Speaker B: Got it. Okay, second hack, quick scorecard and assessment of how bad was it?
00:37:19.020 - 00:37:41.486, Speaker C: This one, I'd say when we were first investigating, looked like it could have been much worse in terms of amount of funds taken because the number of wallets that were compromised was so large. So that respect, it was scary. In terms of number of wallets being drained, the funds actually drained could have been much worse. So in that sense, I'd say it's lower.
00:37:41.588 - 00:37:56.354, Speaker A: Yeah, I would say that the exact same security issue with another wallet, with MetaMask or some high profile and widely used wallet could have resulted in a ten out of ten for sure.
00:37:56.472 - 00:38:23.322, Speaker D: I mean, it feels like a six or seven out of ten, not because of the phone or because of what we think went wrong. That is catastrophic. Honestly, for Slope, I feel for them, obviously breaches and anything like this is like the number one nightmare that anyone can have when you're developing these kinds of tools. But just the general blast radius wasn't that wide. 8000 wallets is not 2 million.
00:38:23.456 - 00:38:47.742, Speaker B: That's a very helpful framing. Okay, so I got your scorecards on each hack. Putting it in context, how bad is it really? I do want to pick up one more thread you guys mentioned with this one about the narrative and the confusion. Like how off or confusing was the chatter out there for each hack, like both hacks relative to the facts, what was the signal to noise proportion for each? And you can answer this lightning round style if you want. Let's start with the first hack. Matt?
00:38:47.806 - 00:39:18.398, Speaker D: I think people found the root cause fairly quickly, or at least what we believe was the root cause. And so I don't think there was much noise there's a bit of noise on not knowing what was happening during, but I didn't see a lot of speculation on like, hey, I think this wrong thing is happening. It was mostly a bunch of people sitting down trying to find what happened. We found what happened a few posts blasted out on Twitter and basically told you exactly what happened. So the signal and noise was very.
00:39:18.484 - 00:39:22.286, Speaker B: Good, good ratio there. All right, and how about the second one?
00:39:22.388 - 00:40:03.162, Speaker A: The second one was probably the worst ratio that I've seen in the space. There are multiple reasons for this. The first one being that a lot of the information is closed source and off chain. So this is not something that the security researchers have access to. The information that was received from surveying people was also very bad and a lot of very incorrect statements. So we got wrong data that we kind of analyzed not as well as we should have. And then people who were on the outside were also kind of making wild guesses that ended up being untrue.
00:40:03.162 - 00:40:56.486, Speaker A: The second part was that there was no guidance, there was no one really in charge of the investigation which resulted in people going in very different directions. So that was chaotic to the incident's response and research for the nomad hack. People were making suppositions or incorrect data on when the audit was done compared to the vulnerability being introduced. And so it can actually hurt the reputation of audit firms involved quite badly. And so I think that getting these facts right before saying such company had audited, how could they miss this and so on is very important. You should really get your facts straight before think such thing because we're talking about actual businesses that are based almost entirely on reputation.
00:40:56.598 - 00:41:09.858, Speaker B: Yeah, okay, just one last thread to pull on this one. I just want to talk a little bit more about the social media side that you both commented on. I mean there's clearly more nuance and implications here beyond the obvious. Can you guys say more about that?
00:41:09.944 - 00:42:24.502, Speaker D: We had a lot of user presented data, we had a lot of that kind of thing and then we had a lot of security kind of influencers who are newer to security and especially are more concentrated in the AppSec domain trying to speculate what happened. And because of their expertise, obviously they're going to bias towards very specific types of techniques and very specific types of hacks and they're not going to look at some of the more kind of reliable things that we see that are really kind of boring. Right? But it boils down to this is a very new space, we have a lot of people who have come in and this is all they've kind of known. They tend to hyper focus on the things they find both interesting and the things they kind of know the most about as opposed to fixating on kind of the more boring stuff that we we actually see happen. And so the signal and noise was really bad and I think it continues actually to be pretty bad. Well, that's the narrative on slope actually it's much simpler than people made it out to be and so the speculation was rampant and so, yeah, we're going to have a lot of security theater.
00:42:24.566 - 00:42:55.410, Speaker B: It's a little performative actually, isn't it? Like it's a performative hacking. As you know, there's this phenomenon on Twitter where there's like a lot of people performatively trying to figure things out and share and blah, blah, blah, and it's become like a social game and even on Reddit, people always try to solve problems. I get it. If there's one thing I've learned covering this space a long time and I've heard this over and over and over again from every security researcher I've ever worked with, which is it's almost always the most mundane thing. I mean, you kind of said that earlier, but it really is shocking how sometimes it's not actually the most entertaining thing.
00:42:55.480 - 00:43:03.046, Speaker D: Yeah, I mean, like 99 times out of 100 it's the stupid boring thing and you're just sitting there like, oh.
00:43:03.148 - 00:43:30.986, Speaker B: Occam's razor always the case. One line we had in media when I worked at Wired and covered a lot of this stuff is attribution is hard. You have to be very thoughtful. I mean, even on the podcast Darknet Diaries, they won't cover a hack until at least a year later to make sure they have all the information they need before they go into detail because it's really hard to figure that stuff out. And it actually has implications on what people pay attention to, what signals they inflate. They add more weight to X, it causes more distraction.
00:43:31.098 - 00:44:22.110, Speaker D: That's actually a real problem. And there is a big problem, at least in the web Three space, where you're letting the security influencers kind of hit the narrative in the war room. And so it's a bunch of people that are frankly like, hey, I've been hacking or doing CTFs, but have you ever hacked a network? And it's like, no. Okay, so how would you do it? It's amazing. A lot of it becomes the more infeasible stuff. It makes it exceedingly hard to react to an issue, and it also makes it very, very difficult to recover in terms of a PR aspect because everyone's minds are going to go to the rampant amount of noise and rampant amount of speculation that was taking place. And people are going to be like, hey, we want to see that this won't be a problem in the future.
00:44:22.110 - 00:44:50.674, Speaker D: Regardless of whether or not it was ever a problem. And so we're going to have a lot of fallout for a lot of the wallets and them putting in efforts that are probably not warranted or cost effective simply because there is so much hubbub about specific types of attacks that might have happened that are just super far fetched. And what probably actually happened is exactly what happened to four or five other places.
00:44:50.802 - 00:45:05.262, Speaker B: Yeah, totally. I know we already covered what could help in each of those hacks, but is there anything else we should be thinking about more broadly? For next steps like any remaining or quick advice or mindsets for builders to consider that you guys want to share.
00:45:05.396 - 00:45:40.758, Speaker C: I think especially understanding that the asymmetry of the groups out there that are trying to get private keys, valuable information, valuable assets versus eight person small team or up and coming startup, really understanding that security is so key. To the system, but also finding ways to not be directly liable or associated with targets of high value. Because the asymmetry between who is out there in those kinds of attacker groups it's an uphill battle.
00:45:40.854 - 00:46:19.746, Speaker D: There's a lot more importance for Web Three companies to essentially make sure that their company doesn't have anything worth stealing. And so what you need to do is make sure that you don't have user private keys. You don't have your own private keys stored in insecure places. Just make it so that if someone were to break in, they can't really steal anything worth anything. Is really the biggest kind of lesson learned generally in the Web Three space from a lot of the hacks that we've seen, not just these one note.
00:46:19.778 - 00:46:26.454, Speaker B: On that, that doesn't make sense to me simply because isn't the point when you're a builder to have things of value? Like build things of value?
00:46:26.572 - 00:46:58.002, Speaker D: Yeah. So you build things of value in that you build platforms for users and things for people to gain value from. When I'm talking about nothing of value, hackers want basically the currencies, right? They want the thing that is immediately valuable to them. They don't want to pirate your platform. That would be a lot of work. They want your users keys, they want your own keys. They want things that are attached immediately to cryptocurrency which they can translate immediately into value.
00:46:58.002 - 00:47:08.902, Speaker D: That's why they're in the space. That's why they're headed after these companies. So when I say value, that's what I mean. I don't mean your source code or any of those kinds of things, right?
00:47:08.956 - 00:47:09.986, Speaker B: That's very helpful.
00:47:10.098 - 00:47:53.986, Speaker A: The mindset to have is very interesting because it really clashes with the kind of Wagami transparency and trust in the Web Three space, right? We're all going to make it together. We're all going to build the space together, which is true. But at the time of building that protocol, the platform, the bridge, the wallet, whatever piece of infrastructure you're building, you have to assume that your machine will get compromised, that someone will open the door by mistake to the attackers. And so trying to build with the assumption in mind that the bad people are already in the network, they're already on my computer, what can they do? This is really the approach that you should take.
00:47:54.088 - 00:48:27.882, Speaker B: What I'm hearing you say when you say that Nas, is it's like, sure, the default ethos could be very collaborative and friendly and we're all going to make it wag me. But the flip side of it is your default mindset should be be on defense, always proactively be on protecting as well. Makes a lot of sense. And just one quick note on the Asymmetry thread that both Matt and Riaz brought up. Summing it up very simply most of the builders are much smaller and less organized by default than any organized groups of hackers will be. It's a classic. This has been true since the beginning of all kinds of hacks.
00:48:27.882 - 00:49:02.090, Speaker B: So one note on that is nas. Is it true though, that in this context, the only way to get around that Asymmetry is to actually band together. And this goes to what you said earlier about having shared components and things that are solid because the community has come around standards and ways to do it. And obviously when you think of open source, that is a key feature, not bug of Web Three ethos. And when I think of open source, I remember the classic Bill Joy quote about how the smartest people in the world will not only work for you. And the benefit of open source here is that you can have multiple people collaborating together to really harden these systems.
00:49:02.590 - 00:50:01.434, Speaker A: This is exactly the idea. Essentially, this space needs to come together on security critical components that can be reused across platforms rather easily and that do not make businesses, but can actually break them when done poorly. There are a lot of independent security researchers that are extremely interested in participating to these efforts. We're actually seeing a lot of the security manpower being external to the startups. So in order to leverage them, we should probably open things up, build all together collaboratively so that we don't even need to think about tomorrow. Hey, did we mess up this thing when re implementing it? Right? It's a little bit like people building on top of Linux. You can create your own distribution of Linux tomorrow, but you're not going to have to rebuild the entire kernel from the ground up.
00:50:01.434 - 00:50:37.490, Speaker A: You're not going to have to think, okay, did I reimplement the Linux kernel the right way? Did I interface properly with key management and hardware and so on and so on. So we've done that for the past decades. We should continue to do that in Web Three. Riaz and I have been working on fairly extremely sensitive infrastructure for the past five years and this is truly the thing that we realize this is needed, building these common abstractions along with the rest of the industry that can be reused and eliminate, but class as a whole forever, right?
00:50:37.580 - 00:50:38.810, Speaker B: Composable security.
00:50:38.960 - 00:51:05.914, Speaker C: This is really a rising tide lifts all boat situation where we can build on top of known good secure libraries, tools, so that we don't have situations where people can easily shoot themselves in the foot, make mistakes as an ecosystem. And I think really, if we band together as a community and work together on this, I expect it'll help us build the next generation of amazing web3 apps.
00:51:06.042 - 00:51:13.618, Speaker B: That's a great note to end on. Riaz, Nas and Matt, thank you for joining this week's episode of Web Three with a Six and Z.
00:51:13.704 - 00:51:14.482, Speaker C: Thank you so much.
00:51:14.536 - 00:51:14.974, Speaker D: Thank you.
00:51:15.032 - 00:51:15.750, Speaker A: Bye.
00:51:17.690 - 00:51:50.922, Speaker B: Thank you for listening to Web Three with a six and Z. You can find show notes with links to resources, books or papers, discussed transcripts and more at asics and Zcrypto.com. This episode was produced and edited by Sonal Choxy. That's me. This episode was technically edited by our audio editor, Seven Morris. Credit also to Moonshot Design for the art and all thanks to support from Asics and Z Crypto. To follow more of our work and get updates, resources from us and from others, be sure to subscribe to our Web Three weekly newsletter.
00:51:50.922 - 00:51:58.560, Speaker B: You can find it on our website at asics and Zcrypto.com. Thank you for listening and for subscribing. Let's go.

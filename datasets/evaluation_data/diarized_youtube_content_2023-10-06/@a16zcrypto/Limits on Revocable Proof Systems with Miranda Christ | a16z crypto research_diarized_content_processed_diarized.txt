00:00:10.360 - 00:00:31.672, Speaker A: Very happy to have one of our own back in the house, Miranda Christ, who was one of our summer research interns last summer. And she'll be talking about an FC paper that she has with Joe Bonot that got some of the best paper reviews that I've ever seen. So I think this could wind up being a quite fundamental result. Looking forward to hearing the details. All yours, Miranda.
00:00:31.816 - 00:01:22.770, Speaker B: Thank you. I'll be talking about my work that will be appearing at FC limits on Stateless Blockchains. This is Joint work with Joe Bino and this was done mostly while I was an intern at a 16 decryptor research last summer, which was a lot of fun. So I'm sure you all already know what a blockchain is, but today I'm going to be treating it as a pretty simple kind of data structure. And so I'll start by describing the functionality that I'm going to talk about today. So at its core, a blockchain involves two kinds of parties users that submit transactions and validators who are responsible for determining whether these transactions are valid. So in particular, we want to make sure that a user, Alice, actually has the money she's trying to spend.
00:01:22.770 - 00:02:21.296, Speaker B: And one problem that we care a lot about in blockchains is the double spending problem where Alice goes and spends a coin and then she later comes back and tries to spend that same coin again. Now, she shouldn't be able to do this because the coin has already been spent. But we need to make sure that whatever underlying data structure we have for our blockchain doesn't allow Alice to sort of reuse a coin that she's already spent. And we also want to make it very easy for people to be validators because usually we'll have some sort of assumption that the blockchain runs smoothly as long as half of the validators are honest or something like that. And the easier it is for regular people to become validators, the easier it'll be by say like a law of large numbers for us to have a majority of honest validators. So it's very important to make becoming a validator pretty accessible and cheap. So we have our users and validators.
00:02:21.296 - 00:03:17.130, Speaker B: And what happens in our blockchain is users will have coins that they want to spend and validators will maintain a set of all valid coins. And so if this user is trying to spend its coin c it'll send a transaction to the validators. And the validators, since they have the set of all valid coins, will be able to determine by looking at the set and the transaction whether to accept or reject the transaction. So the validator can just check whether the coin is in this valid set and accept if so. Now, as I've described the validator's job so far, the validator has to maintain directly the set of all valid coins and the set might be very big. In particular for bitcoin this set is the number of unspent transaction outputs which I have graphed here from the beginning of Bitcoin until right about now. And you can see that this value has been growing pretty steadily over time.
00:03:17.130 - 00:04:04.470, Speaker B: Can I ask a question? Is this tied to the UTXO model where so you seem to be saying that the set of transactions, sorry, a bunch of coins are valid and as opposed to a bunch of coin user pairs are valid. Is this choice of how you define the set of valid things relevant to the results you're getting? Yeah, good question. So that's the way I'm going to describe it for this talk. But it actually doesn't matter. So our results also apply to say like coin user pairs like you said. Also if you're maintaining instead of a set of coins a list of account balances, anything like that, the results will still apply. But just like for now, we can think of our blockchain as operating in the UTXO model.
00:04:04.470 - 00:05:04.916, Speaker B: Okay, so for Bitcoin right now, the amount of data that validators have to store in order to maintain the set isn't too large, it's only a few gigabytes. But again, if the trend continues and the number of Etxos continues to grow, this might become a problem down the road. So even though it's not so bad now, it is something that we'll have to deal with later. Especially when we take into account the fact that Bitcoin right now supports relatively few transactions per second, about seven. And Visa, which is much more practical, supports up to 24,000 transactions per second. So if our longer term goal is to have a blockchain that supports truly everyday transactions and achieves a throughput closer to Visa, then if we scale up the number of UTXOs proportionally, the storage cost will become prohibitive for validators. So it'll be 3400 times a few gigabytes which starts to become more than any of us can store on our laptops.
00:05:04.916 - 00:05:39.856, Speaker B: And you would need specialized hardware for this. So now I'll finally tell you what a stateless blockchain is. It was proposed to address this growing state problem and make it so that validators don't have to store this full set of coins directly. So in the stateless blockchain model we have validators storing only a constant size state which I'll call V. And constant size means that it doesn't grow as the number of coins in the set grows. So this is very small. You can think of it as say, a merkel route.
00:05:39.856 - 00:06:23.848, Speaker B: And now users are responsible for submitting proofs that their transactions are valid. So since the validator doesn't store the entire set of valid coins anymore, the user will have to prove to the validator that its coin is unspent. So here that's shown where the user again has their coin C. And along with C, the user stores a proof pie that C hasn't been spent yet. And as before, when the user wants to make a transaction it sends this transaction to a validator. But now, in addition to the transaction itself, the user attaches that proof. And so the validator will check if the transaction is valid by looking at its state v the transaction and this proof.
00:06:23.848 - 00:07:26.600, Speaker B: And then it'll decide again whether to accept or reject. So how do we actually build a stateless blockchain? I'll start by walking you through a pretty simple example using a merkel tree. This is not the best construction, but it'll help illustrate what a stateless blockchain does exactly. So here we have our merkel tree and we're going to use the leaves of the tree to store the unspent coins. So the idea is we're going to use this merkel tree to succinctly store the set of unspent coins and these coins are at the leaves and the validators will store the root as their constant size state. So the way that this root is computed is by taking the hash of, say, these two coins to obtain this node, then taking the hash of these two nodes to obtain the root. And so the root will sort of commit to all of the unspent coins and the validators will store only this route, which has constant size relative to the number of coins.
00:07:26.600 - 00:08:25.012, Speaker B: And the proofs that users maintain to prove that their coins are unspent are the merkel inclusion proofs of their coins. So here, if this coin is Alice's, the inclusion proof that she maintains is its partners up the path from her coin to the root. So these two circled nodes. And when Alice wants to spend her coin, she sends this coin along with the proof. And validators can check by hashing Alice's coin with this first part of the proof to get this and then hashing this with the next node in the proof to get the root. And so validators can check that the route obtained this way by using the proof and the transaction matches the route that they're storing. But one problem with this construction is that Alice's proof changes when, for example, Bob's coin is spent.
00:08:25.012 - 00:09:11.210, Speaker B: So Alice keeps Bob's coin as part of her inclusion proof. And if Bob spends this coin, then in the merkel tree, this coin will be removed. So say this node will be rewritten with all zeros. And now, since this is part of Alice's proof, alice will have to change her proof. And thinking about what this means for the blockchain, this starts to become a bit annoying. Say I'm Alice and I just want to put my coin away in a wallet and leave it alone and come back and spend it in a month, if some faraway Bob makes a transaction, I will have to change my proof. So instead of leaving my wallet alone, I'm going to have to constantly be looking and seeing what transactions other users are making and updating my proof based on what they do.
00:09:11.210 - 00:10:11.390, Speaker B: So I, as Alice, can't operate in isolation I need to care about what everyone else in the world is doing on the blockchain if I want to make sure my proof is up to date. And this is very annoying for me, but there's some hope that we can do better than the Merkel Tree, and in fact, there are several more efficient constructions that are efficient in different ways. So one other thing you might have noticed with the Merkel Tree is that the inclusion proofs are quite long since Alice has to include the entire path of the tree. So the proofs aren't constant sized, they're logarithmic sized. But these more efficient constructions, in particular a construction from RSI Accumulators and a construction called Hyperproofs from Vector Commitments, achieve constant size inclusion proofs, which is much better. Vertical trees, which were proposed by Ethereum, cut down on the size of the inclusion proofs, but not quite to constant. And this is a nice proposal as well.
00:10:11.390 - 00:10:51.080, Speaker B: One other thing to note about Hyperproofs is they have a nice sort of batching technique where if you're updating many users proofs at once, then you can do it more efficiently in batch compared to how long it would take if you computed each user's proof individually or updated each user's proof individually. So there are some nice improvements here, but unfortunately, they all share the same problem, which is that they require frequent proof updates. So for all of these, like we saw in the Merkel Tree example, if Bob spends his coin, then Alice will have to update her proof.
00:10:54.620 - 00:11:13.360, Speaker C: Sorry if it's a stupid question, but I don't understand how you update once the proof is used. Even before Bob using Alice's proof, somebody has to have some sort of state here, because Alice should not be allowed to use her proof twice.
00:11:14.740 - 00:11:52.216, Speaker B: So you're asking how the Validators update after Alice spent her coin? Yeah, sure. Yeah. So here, because when Alice makes her transaction, she submits her coin and she submits her inclusion proof. The Validators can use this inclusion proof to update the root of the Merkel Tree. And the way that they do this is they reset Alice's coins Leaf to be all zeros and then they can hash it with this node in her inclusion proof to get the new value for this node. Then hash the new value of this node with the value of this node and obtain a new value for the root.
00:11:52.408 - 00:11:55.740, Speaker C: And then everybody else needs to recompute their proofs as well.
00:11:55.890 - 00:12:33.000, Speaker B: Exactly, yeah. When the root changes, everyone else needs to recompute their proofs. And so that's why this construction is a bit problematic. But, yeah, the nice thing about Merkel Trees is you can update the Validator state based only on Alice's coin and the inclusion proof that she gives. And this will be true of the next example that I show as well. So I'll walk through a construction from RSA Accumulators, mostly to get us familiar with Accumulators and also see some improvements that we can make. But why the problem of proof updates still remains.
00:12:33.000 - 00:13:25.080, Speaker B: So with the RSA accumulator construction, we are going to use an accumulator to store the set of valid coins. And I'll describe to you now how this accumulator works. We assume that we're given a generator g for a group of unknown order. And the way that we're going to store the set X of all valid coins is we'll compute a state V sub x, which is equal to G raised to the product of all X's in X. So here we can assume that each coin is connected to some string that is a prime, some coins are represented by primes. And then we can take the product of all of these primes and raise the generator to this power. So this is what the validators store to capture the set of valid coins.
00:13:25.080 - 00:14:46.310, Speaker B: And the way that a membership proof for some coin Y in the set is computed is it's going to be the state raised to the power of one over Y. And the way that we can compute this, if we know all of the coins in the set X is we just compute the product of all of those coins, but omit y and then we raise G to this power. So one thing to note here is we can't compute directly this arbitrary element to the one over Y power unless we can do something special. Because we can't. Because given the strong RSA assumption in general, it's hard to find this Y prime such that or sorry, it's hard to compute this value v sub x is the one over Y prime for arbitrary Y prime. But because of the way that this is constructed, because it's the product of everything in the set X, we can compute this to the one over Y just by omitting Y from that product. So one convenient fact to note here is that the state for the set you get when you remove Y is equal to the membership proof for Y being in X.
00:14:46.310 - 00:15:52.890, Speaker B: And why is this useful? So remember that the validators store a current state that they're going to need to update when a transaction is made. So if the current state stored is V sub x and Alice spends a coin Y, the validators will need to change the state to now capture the new set that you get when you remove Y. And since Alice submitted this proof pi sub y with her transaction validators, first check that this proof raised the Y's power is indeed equal to the old state. And if it is, they accept her transaction. And then because the new state that validators should store is equal to Alice's membership proof, validators can compute the new state just by setting it equal to the proof that Alice submitted. And so this is very nice. This is sort of analogous to the way that I showed to update the merkel route using the inclusion proof before.
00:15:52.890 - 00:16:30.870, Speaker B: But this is even cleaner. It doesn't really require any computation for the validators. They just set the new state equal to the proof. But now one problem is that the other users in the system hold proofs that are valid for the old state, but not the new state. The new state is V sub x to the one over Y. And now these old proofs won't be valid with the new state because the way you check if a proof is valid is you raise this proof to the X and this to the X is going to be V sub x. It's not going to be equal to V sub x to the one over Y.
00:16:30.870 - 00:17:24.260, Speaker B: So that's a bit of a problem. It means that none of the old proofs of other users will be valid anymore. And one cool insight that this RSI accumulator paper has is that there are tricks for computing this new state, for computing this new proof, so all of the other users can update their proofs relatively efficiently. But the fact that they have to do this update at all is a huge problem because it means that they'll have to be online and they'll have to be monitoring other users transactions. So sort of no matter how efficient you can make this proof update, as long as the update has to happen, it's very annoying. So again, when a transaction is made in this construction, all other users have to update their proofs, which is undesirable.
00:17:25.640 - 00:17:38.490, Speaker C: Sorry, another question. When I spend my Y, suppose I spend my Y and I give it to you, how do you create a new proof for that spec that you can spend your Z now?
00:17:39.120 - 00:18:43.820, Speaker B: Yeah, it's nontrivial, so there's some number theory tricks that they do, but yeah, you are able to do it with the information that is out there. So, yeah, I'm not going to describe it now because it's actually a little bit involved. Yeah, sorry. So the question that this leads us to ask is whether it's even possible to have a stateless blockchain where users never have to update their proofs. And one place to look for this answer is an impossibility result by Camacho and Javia from 2010. And this applies only to accumulators. It says that if N elements are stored in an accumulator and half of these elements are deleted, then it takes roughly N information to update the remaining elements proofs.
00:18:43.820 - 00:19:45.520, Speaker B: So this sort of intuitively tells us that a lot of the remaining elements proofs will have to change because in order to update these proofs, you need a lot of information linear and N, but it sort of doesn't apply directly to stateless blockchains yet. And so that is the question that we address in this work. And unfortunately, we find that, no, we can't have a stateless blockchain where users never have to update their proofs. And our informally stated theorem says that for a blockchain with endcoins where users never have to update their proofs, validators must store a state of size omega of N. So if you have no proof updates, then sort of asymptotically validators might as well store the full state. There's no asymptotically compressed scheme that you can have.
00:19:45.670 - 00:19:57.370, Speaker C: Is this assuming that anybody can trade with anybody, or will this be true even if I have end users? But only N number two can trade among themselves. Another N of two can only trade among themselves.
00:19:57.980 - 00:20:49.916, Speaker B: Good question. This assumes that everyone can trade with everybody. So yeah, if you are able to sort of split the chain into a bunch of distinct chains where in each chain users can only interact with others in that chain, then maybe you could get some savings. But as long as you want everyone to be able to trade with everyone else, the impossibility holds. So I'll walk you through sort of a high level overview of how our proof works. We are going to show an information theoretic impossibility. So basically we're going to say that if such a stateless blockchain exists, then we're going to be able to violate the laws of information theory and sort of compress information more than it should be able to be compressed.
00:20:49.916 - 00:21:37.480, Speaker B: You can think of a stateless blockchain as like a compression tool. It takes this big state and compresses it into a small state. And if a really good stateless blockchain exists, then it's doing impossibly good compression. And the way our argument will go is we're going to consider two users, Alice and Bob, who share a stateless blockchain. And Alice is going to secretly choose a set of coins to spend and she's going to tell Bob which set she chose by transmitting him some bits. And we're going to show that she can use impossibly few bits to tell Bob which set she chose to spend. So this will be our contradiction.
00:21:37.480 - 00:22:47.420, Speaker B: And the first thing that we need to do is formally model a stateless blockchain, which we do now. So at its core, a blockchain basically needs to capture a set of provable statements that can later be revoked. And what I mean here is provable statements are of the form i, Alice, have this coin and these statements can be revoked when I, as Alice, spend that coin. So we need to capture some statements that at one point are true but might later become false. And we call this sort of protocol or data structure a revocable proof system. And we assume that at the beginning of time we're given some set of true statements. So this is, say, an initial set of unspent coins and there should be a function that takes in the set s and computes the state that the validators store this V along with proofs for each of the coins that each of them are valid.
00:22:47.420 - 00:23:46.320, Speaker B: There's also a revoke function that takes in the full state it takes in a subset of statements t that are going to be revoked, and it outputs an updated state B prime and updated proofs for all of the elements that were not revoked. There's also this verify function. That is what the validators run to make sure that a transaction is valid. So the verify function takes in the state a specific statement or coin and a proof of that statement, and it outputs either true or false. We want two properties from a revocable proof system. The first is correctness, which says that proofs of truth statements always verify. So for blockchains, this says that if Alice behaves honestly and has a coin, she should actually be able to spend this coin.
00:23:46.320 - 00:25:00.756, Speaker B: And security says that it's hard to find a false statement and a verifying proof for that statement. So again, applied to blockchains, this says that Alice shouldn't be able to convince validators to let her spend a coin that she doesn't actually have. Okay, so now that we have our model, I'll show you our argument. We assume that Alice and Bob are two users of a stateless blockchain, and so they agree ahead of time on a set of statements s, say, a set of initial valid coins and a proof of each of these statements, and also a starting succinct state for the blockchain. Now, Alice is going to choose her secret subset of coins to spend or revoke, and she's going to run the revoke function to compute the updated state V prime. And she chooses the secret set uniformly at random. Now she sends the updated state V prime to Bob, and Bob is going to try to compute what set Alice chose to revoke.
00:25:00.756 - 00:26:04.564, Speaker B: So the way that Bob is going to do this is he's going to go through all statements in the set s and check if their proofs verify against the new state. And now Bob is going to output a guess of the set that Alice revoked. So the way that he does this is if he sees a statement whose proof no longer verifies, then he includes it in the set, because that should mean that the statement was revoked. So now I'll argue that with high probability, bob is successful in reconstructing the set that Alice spent. Remembering that Correctness says that proofs of non revoked statements still hold. So this means that if a statement wasn't revoked, then since its proof still holds, bob will not include it in this guess of the revoked set. And security says that proofs of revoked statements do not hold.
00:26:04.564 - 00:27:22.460, Speaker B: So this means that if something was revoked, then its proof will no longer verify, and so Bob will include it in the set that he outputs. And so this set should be correct. And you might have noticed that I said with high probability here, and the reason why Bob doesn't succeed all of the time is because our security guarantee is just that it's hard to find a false statement and a verifying proof for that statement, not necessarily that it's impossible. So these false proofs might exist, but it should be computationally hard for Bob to find them. So with negligible probability, Bob might happen to find a proof for a revoked statement, but this really should not happen in practice. Okay, and so why is it a contradiction that Bob succeeds in reconstructing this set? Well, remember that Alice had two to the size of S or two to the little N choices of this set to revoke. And we know that information, theoretically, her choice should take N bits to encode if she's communicating it to Bob.
00:27:22.460 - 00:27:50.790, Speaker B: But here, all that Alice sent to Bob was this updated state V prime, which, remember is constant. So instead of taking M bits to encode her set, alice has encoded it in only a constant number of bits. And this is impossible. So this tells us that such a stateless blockchain can't exist because then Alice would succeed in this impossible encoding, which shouldn't happen.
00:27:51.800 - 00:28:16.184, Speaker A: Miranda? Yeah, let me just make sure. I'm glad you deterred to the with high probability comment. I was literally wondering exactly that when you talked about it. So just to make sure it's not so much like Bob getting lucky finding some fake proof, there's some chance, however small, that when you go from V to V prime, it just so happens that one of your old proofs still works for one of the revoked statements.
00:28:16.232 - 00:28:18.316, Speaker B: Is that yeah, exactly.
00:28:18.498 - 00:28:19.230, Speaker A: Okay.
00:28:20.160 - 00:28:25.692, Speaker B: Yeah. Yeah. So if that's true, then Bob sort of really succeeds in finding a fake.
00:28:25.756 - 00:28:35.972, Speaker A: Proof, not through any, like, Bob's not trying to find a fake proof. It's just kind of bad luck with the update function, I guess, right?
00:28:36.026 - 00:28:37.412, Speaker B: Yeah, exactly. Okay.
00:28:37.466 - 00:28:38.500, Speaker A: All right, thanks.
00:28:38.650 - 00:29:34.840, Speaker B: Yeah. Some annoying stuff to deal with that. So the proof ends up looking less clean than how I'm presenting it here, but yeah, that's sort of just the technicality. Sorry, Mary, did you have a question? It may be part of the unclean stuff in the paper now, but I guess I'm curious whether the fact that Alice needs exactly NBits to encode versus, like, slightly less because of this. I'm just curious whether this probabilistic part implies something about the total information necessary not being fully Mbits, but maybe slightly less. Yeah, so it implies that her choice should really take N minus one bits to encode. But yeah, the loss is so small that it doesn't end up mattering for the bound asymptotically.
00:29:38.780 - 00:30:05.890, Speaker A: Actually Miranda, is your omega of N actually N minus one, or is it really like some constant less than one times N in your theorem statement? In theorem statement, you showed this earlier. You talked about needing omega of N updates. Does the proof actually show a leading coefficient of one? Is it really like, N minus little low of N? Or is it really like, you only get a half N or a third N or something like that.
00:30:06.340 - 00:30:20.004, Speaker B: Yeah. For this theorem where you have no proof updates, I'm pretty sure it's really a leading constant of one, but I would have to check to be 100% sure.
00:30:20.202 - 00:30:24.120, Speaker C: Maybe I missed it, but I don't think he used any interaction between the coins.
00:30:26.220 - 00:30:28.090, Speaker B: Any interaction, you said?
00:30:28.540 - 00:30:39.260, Speaker C: Yeah. So even if you have two communities, they don't interact with themselves. That seems linear updates are necessary. Linear communication is necessary.
00:30:43.360 - 00:31:49.170, Speaker B: One thing you could do is you could have a global state V prime for each of your sort of subchains, where each has an insular community that can only interact with each other. And then you can ensure that if a coin is spent within your community, you might have to change your proof. But if a coin is spent in another community, then you don't have to change your proof. And so you can get a sort of trade off between the number of V primes that you store and how often you have to update your proof. But I think you're right. As stated, this proof still goes through even without some interaction assumption. The next question that we ask, since we can't have a stateless blockchain where users never update their proofs, is whether we can relax this and only ask for a blockchain where users don't update their proofs very often.
00:31:49.170 - 00:33:05.944, Speaker B: And we show that the answer is unfortunately, still no. Where if we have a constant state blockchain with Ncoins and a constant fraction of coins are spent, then roughly a constant fraction of the users must update their proofs. And I'll show you how we can modify the old version of the proof to get this slightly stronger result. So remember before Alice was choosing this set of coins to revoke and getting an updated state, and now she does an additional step here, where she's also going to create a list of all of the non revoked statements whose proofs happen to change. So in our new kind of stateless blockchain, we might have proofs changing occasionally. And so Alice is going to make a list of these statements whose proofs just happened to change when the state was updated, and she's going to send this list to Bob along with the updated state. Now, Bob is going to have to do some additional work when he constructs his guess of what set Alice chose to revoke.
00:33:05.944 - 00:34:14.610, Speaker B: And so when he checks if proofs of statements still verify against the new state, he's also going to check if each statement is included in this list, and he's going to output a guess again. So what is this guess now? It's going to include all statements whose proofs both no longer verify and that were not included in the list. So what this list tells Bob is it consists of statements whose proofs no longer verify, but not because those statements were revoked, because they just happened to change when the state was. Updated. So if Bob sees that a statement is in this list, he knows that it wasn't revoked, its proof just changed. So he includes exactly the set of statements whose proofs don't verify and that were not included in this special list. And for the same reasons as before, with high probability, bob is successful in reconstructing this set.
00:34:14.610 - 00:35:00.480, Speaker B: But the information that Alice sends to Bob has changed a little bit. So in addition to sending this constant size state V prime, she's also sending this list L. And the size or the length of the list depends on how many statements had their proofs changed. So suppose that we have a stateless blockchain where at most, k proofs change in any state update. Then Alice is able to write this list using klog N bits, where to write down each statement or to write down the index of each statement, it takes log N bits. And there are most k of these statements in the list. So the list takes klog N bits.
00:35:00.480 - 00:35:55.980, Speaker B: And again, the size of the state that she sends is constant. So Alice has encoded this set in constant plus klog N bits. But again, it should take roughly N. Or accounting for the with high probability, it should take N minus one bits for Alice to do this. Actually, yeah, this tells us that the leading constant in that theorem is one. So this gives us that O of one plus k log n should be at least M minus one, and rearranging is how we get our theorem. So to state the theorem again and show you visually what it tells us, we have that for any stateless blockchain with N coins.
00:35:55.980 - 00:37:08.410, Speaker B: When a constant fraction of coins are spent, then nearly a constant fraction of users have to update their proofs. So this says that there's a roughly linear relationship between the number of witness or proof changes and the number of deleted elements or revoked statements. So I've plotted this relationship for varying sizes of the state, the succinct state that validators store. And this says that as more elements are deleted, more witnesses change. And what you'll notice is here, each of these curves is just duplicated and shifted to the right as the size of the validator's state increases. So what this tells us is we eventually start to get this linear trade off or near linear trade off between a relationship between the number of deleted elements and the number of witness changes and increasing the size of the state that validators store doesn't help very much. It just sort of delays when we start to see this relationship.
00:37:08.410 - 00:37:18.190, Speaker B: And so we can increase the size of the succinct state, but it doesn't help us that much.
00:37:20.960 - 00:37:28.320, Speaker A: So, Miranda, this log factor, do you have a sense of this is an artifact of the argument or something unavoidable?
00:37:29.140 - 00:37:53.190, Speaker B: Yeah, it might be an artifact of the argument. Like, the way that we encode the list is pretty simple. We just write down each of the K indices. So I think you could do a little bit better for some regimes of the relationship between K and like, you don't really care.
00:37:55.080 - 00:38:04.340, Speaker A: The bob already knows the pi eyes. Right. So you're literally just encoding the indices of the statements with the proof updates.
00:38:04.720 - 00:38:26.530, Speaker B: Yeah. So there's some hope that for some regimes you could shave off the log N. But I tried thinking about how to encode the list in a fancier way and it seemed like for some K's, this was kind of the best you could do. Yeah.
00:38:27.140 - 00:38:31.184, Speaker A: Like K equals N over two kind of regime, you're saying?
00:38:31.382 - 00:38:32.310, Speaker B: Yeah, exactly.
00:38:32.680 - 00:38:33.430, Speaker A: Okay.
00:38:36.200 - 00:39:16.370, Speaker B: But in practice, I think the log in the denominator isn't that bad. In my mind. It's kind of just a constant. Or nearly a constant. Yeah. So here's another graph where this is going back to the thing I pointed out early on, where if we want to scale up the throughput, then we'll start running into problems. So here each of the curves represents a blockchain with different throughput where it only goes up to 100 transactions per second, which is still very far from, say, Visa, which was at roughly 24,000.
00:39:16.370 - 00:40:19.520, Speaker B: And again, on the Y axis we have the number of witness changes, but here it's the number of witness changes per day. Sorry, here I'm using witness and proof interchangeably. So the number of proof changes per day. And on the x axis we have the logarithm base two of the size of the state that the validators store. And so you can see here that the number of proof changes per day is basically the same as the size of the state increases up to some sort of threshold value, at which point you start to get big improvements. But for, say, the 100 transaction per second blockchain, the size of the global state is still pretty big. So it's like two to the 26th or something like that at the X axis.
00:40:19.520 - 00:41:31.308, Speaker B: And this tells us that unless you're willing to store something close to the full state, you're not really going to get a useful trade off between the size of the state that the validators store and the number of witness changes that you see per day. So basically, up until you reach this point, sort of varying the size of the state, that validators store is not going to help you. So what does this result tell us? In practice, you might see it and think that stateless blockchains are dead. And definitely it tells us that there's no Holy Grail data structure that solves this proof update issue on its own. So no matter how clever we are, we're not going to be able to sort of math away the proof changes that users have to do. And this is because the state that's being stored has to go somewhere. So an analogy that I like is if you squeeze a water balloon, then you're never actually going to make the water balloon any smaller.
00:41:31.308 - 00:42:22.560, Speaker B: The water is just going to seep through your fingers and go somewhere else. So what's happening in the stateless blockchains is if you're taking the state away from the validators, then instead it's sort of being offloaded to users in the form of these proof updates. So really the state is just being distributed among the users when you take it away from the validators. But not all is lost. There are some constant factors, state compression tricks that can help in practice. And if you really want to use a new model, maybe you can have users outsource these proof updates to a third party that stores the entire state. So you could still have validators storing a constant size state and users storing these proofs.
00:42:22.560 - 00:43:35.230, Speaker B: But a third party that stores the full state can update these proofs on behalf of the users. This is called the proof serving Node model and there's been some work in particular, Hyperproofs explores this pretty thoroughly and talks about coming up with an incentive system to maybe incentivize these proof serving nodes to update these proofs where the users pay them some small fee for maintaining their proof for them. But there's still a lot of work to do here and I'm curious to see where this model goes, especially because now it seems like this might be the best bet for stateless blockchains actually working. So this revocable proof system that we defined for the paper is actually much more general than only capturing stateless blockchains. Again, it really has these three functionalities. A way to compute a six inch state from a larger set of true statements, a way to revoke some of these statements, and a way to verify any of these true statements. And there are many other things that fit this model.
00:43:35.230 - 00:44:40.050, Speaker B: One thing that kind of fits it is actually roll ups. And so one implication that this has for roll ups is you can't have a roll up that has persistent account balance or any other kind of proofs. So imagine that you want to have some roll up that puts a succinct state on chain and allows users to prove a statement about their account balance where the proof lasts for many, many blocks. Say, hopefully the proof lasts forever. So you want Alice to be able to say that she has at least one coin in her account and as long as she doesn't spend that coin, her proof of this still holds. Here the roll up is providing the same functionality as the stateless blockchain where you have a succinct state that's put on chain and the state changes over time as other users are making transactions. And so it says that Alice's statement about having a coin must have a changing proof as the succinct state on chain is changing as well.
00:44:40.050 - 00:45:39.904, Speaker B: So there's sort of no way to get around this impossibility by using something like a roll up. And in addition, this impossibility result applies to any data structure that can be used to build a revocable proof system. And we saw a construction of a stateless blockchain from an accumulator, for example. So we know that an accumulator can be used to build a revocable proof system. And there are many other data structures of interest that can build a revocable proof system as well. So this includes also vector commitments, map commitments, and authenticated dictionaries. So what our impossibility results says about these is if you have a succinct global state, say a commitment to a vector, that's where the elements of the vector are sort of controlled by different users, where each user maintains a proof for their element.
00:45:39.904 - 00:46:06.190, Speaker B: Then if other users change their elements and the resulting commitment is updated, then the original user will have to change their proof. So thanks for listening. If you're curious, in checking out the paper, it's available on Eprint and will be appearing at Financial Crypto, and I'm happy to take any more questions.
00:46:10.080 - 00:46:22.210, Speaker D: Does that impossibility result for the revocable proof systems, does that capture things like the weird VDF proof of work style, like short lived proofs, that kind of thing?
00:46:24.980 - 00:46:25.840, Speaker B: Um.
00:46:28.200 - 00:46:34.630, Speaker D: Methods for kind of like pushing the revocability kind of outside of the accumulator system.
00:46:35.400 - 00:46:38.550, Speaker B: So what are these short lived proofs used for?
00:46:40.620 - 00:47:02.780, Speaker D: Basically, they are a way of kind of revoking a proof by making it you can't tell whether or not the proof was valid, or someone running a VDF basically solved some puzzle that allowed them to create fraudulent versions of the same proof.
00:47:03.600 - 00:47:19.750, Speaker B: Oh, I see. Okay, I vaguely remember these. So I think with those, you still aren't supposed to have a proof of a statement that's false. So maybe like, after is that correct?
00:47:21.560 - 00:47:22.870, Speaker D: I'm not sure.
00:47:23.480 - 00:47:57.100, Speaker B: I think that's the case. In which case the impossibility should still go through. So because it's like information theoretic, it doesn't matter how long this game between Alice and Bob takes. So even if it might take Bob, or even if it might take Alice a long time to, say, compute the new state, or even if it took a long time to compute the proofs to begin with, sort of time doesn't matter in our argument. And so I would expect it to still go through if you have VDS.
00:47:59.540 - 00:48:52.720, Speaker A: Miranda just going back to the roll up interpretation, so should I sort of think of that as I don't know, I had this mental model, it's like, okay, so a new state diff, say, is published every block on L1 by the roll up, let's just say, saying, what account balances changed, right? And so you might expect something like the obvious way to do it is just kind of like with every block, if balance has changed, you just sort of publish basically the new merkel route and sort of some the corresponding kind of proofs so that people following along can sort of update the merkel tree. And so I think what you're saying is that basically the proof size, or does your results say this your proof size should be scaling with the number of accounts that get touched per update. Is that a consequence?
00:48:54.580 - 00:49:28.530, Speaker B: We don't have anything about the proof size, I guess. So. One thing this says is if you want the user's old proofs to directly verify with the new state, then the new state will have to be quite large. But it doesn't rule out the possibility of including enough information in each block to update all of the proofs.
00:49:31.910 - 00:49:38.210, Speaker A: Do you think any roll up that's just sort of posting updates frequently maybe can escape this impossibility?
00:49:40.810 - 00:49:49.862, Speaker B: Possibly, but I think the amount of information that you would have to post to let everyone update the proofs would be very large.
00:49:49.996 - 00:50:25.170, Speaker A: Right. So that gets into the proof size kind of thing. Right. If you do it infrequently, basically your result is kind of saying you can't do clever batching of this stuff, right? Yeah, I feel like that is a pretty natural interpretation in the roll up world, which is, as accounts get touched, somehow that information needs to get communicated down. Maybe it's infrequent updates that are big updates, maybe it's frequent updates that are small updates, but like, the total amount of updating stuff that's being posted has to be scaling with the number of accounts that are affected.
00:50:25.750 - 00:51:43.034, Speaker B: Yeah, that's true. But I think changing the proof size is sort of not the bottleneck our impossibility goes through, even if the proofs are extremely large. Because when Alice and Bob are communicating right, alice is only sending the new global state to Bob, and so it goes through even if the proofs are arbitrarily large. So I guess applied to rollups, it would say that the size of what's on chain in every block would have to be quite large, even if the user's proofs are long as well. Miranda, is my interpretation correct? That what you're saying is impossible for roll ups? Is if I want to have a roll up with small footprints on chain such that a user of the roll up can come online once, get a proof that they have something on the roll up and go away for a month later, come back to the base chain and be able to use that stale proof. This is not possible unless the footprint was in fact linear size. I think that's what your result is saying.
00:51:43.034 - 00:52:22.570, Speaker B: Yeah, that's much better stated. Exactly. It doesn't matter that my proof was massive. The point is that I was offline for a while and now there's just no hope of me happy about proof. Yeah, exactly. But just to clarify, if I come back to withdraw from the roll up on the main chain, but I can observe the full history of the roll up, say if it posts some updates frequently, then potentially I can update my proof in order to withdraw. Right? Because there are some linear amount of transformations that have happened, possibly they have enough information to allow me to update the proof.
00:52:22.570 - 00:52:48.530, Speaker B: Yeah, that's true, but if you wanted the original proof to hold directly verified against the new state of the roll up without any sort of updates based on the prior history, then the new state of the roll up would have to be quite large. But, yeah, it doesn't rule out being able to look at the history and sort of update your proof late.
00:52:49.110 - 00:52:54.960, Speaker A: All right, great. Well, thanks so much, Miranda. Great talk. Very cool result.

00:00:00.330 - 00:00:00.880, Speaker A: You.
00:00:04.210 - 00:01:11.678, Speaker B: Welcome to Web three with a six and z, a show about building the next generation of the Internet. From the team at a six and Z crypto. This show is for anyone, whether company leader or other entrepreneur, creator or developer, media or policymaker, seeking to understand and go deeper on all things blockchains, crypto and web3. We're back with all new episodes, beginning with some conversations from our recent second annual founder Summit, including today's episode, which covers human rights, such as recent crises in various regions around the world, and the role of technology such as the decentralized web. Our special guest is Jonathan Doton, tech founder, Emmy nominated producer, and writer who spent six seasons on HBO's show Silicon Valley. Doton is also the founding director of the Starling Lab for Data Integrity at Stanford, which prototypes, tools and principles to bring historians, legal experts, and journalists into the new era of Web three. So here he's in conversation with our very own Robert Hackett, who has joined to host the show a number of times so you'll recognize his voice and who was also a former senior editor at Fortune.
00:01:11.678 - 00:01:33.530, Speaker B: Among other things, they discuss how cryptographic technologies can help establish ground tooth in conflict zones, the history of open source regulation, and more. As a reminder, none of the following should be taken as business, legal, tax, or investment advice. Please see a six and c.com disclosures for more important information, including a link to a list of our investments.
00:01:33.870 - 00:01:55.426, Speaker A: Hi, everybody. I'm Robert Hackett. I'm an editor here at a 16 z crypto. I got to say, while you were just talking about how the government is viewing this stuff, I'm getting an intense bout of deja vu. Didn't we fight these battles in the 90s about cryptography being munitions? And there was the clipper chip. And I thought we all agreed that it was not the way to regulate this stuff.
00:01:55.608 - 00:02:28.074, Speaker C: Yeah, it's truly strange. And if you go and talk to folks like David Chom or even Christine Peterson, heroes that have kind of established what we might think of as our understanding of modern cryptography or open source technology, I think they're all baffled as to what's been going on. And I must say, this is something that is incredibly recent and fast moving. I think the consensus around open source technology in the last three weeks has evaporated as we've known it. We can't rely on the types of consensus that we had before. So. Yes.
00:02:28.192 - 00:02:30.394, Speaker A: What do you mean by that? Elaborate on that point.
00:02:30.432 - 00:03:06.658, Speaker C: Well, I mean, if you look back at the first crypto wars in the early 1990s, we started to establish the basis of what we've all come to rely on, which is that code is a form of expression. It cannot be regulated by the government in all ways. And that this is very important for us to sit and take stock of these discussions, because with the illusion of this form of imminent threat from AI, it's not to say that there aren't concerns around AI, but the question is, what are the measures that you're going to take? And it's hard to believe that Supreme Court precedents from 30 years ago are suddenly being ignored and tossed aside. So we're in a critical moment to reclaim all of this discussion.
00:03:06.754 - 00:03:16.794, Speaker A: I have to ask, given the work that you do at Starling and your focus on human rights, if you had to pick between AI alignment and effective accelerationism, what would you pick?
00:03:16.912 - 00:03:55.318, Speaker C: Well, let me share with you what I'm most concerned about. I think we need to take the tone of this conversation in a dramatically different place. And even the question around like alignment. My question is not about whether or not you're going to create harbor metrics around that, but it's this notion that somehow a form of applied statistics is going to create in the near term, some form of sentience, out of control form of automation. We have tons of mechanisms to continue to control technology, and I think that if we need to start from that basis, there are a series of things that we can do, and we don't necessarily have to change laws and we can be compliant with the laws that exist on the books without having to basically say, everything is new.
00:03:55.404 - 00:04:19.518, Speaker A: Diplomatic answer. So I want to return to some of your work, but first I've got to ask. You gave us a high level description of your career trajectory, but I feel like I missed a few of the connecting dots here. You went from writing jokes for tv to archiving testimonials from witnesses and survivors of genocide. I mean, how do you go from point a to point b there?
00:04:19.684 - 00:05:11.290, Speaker C: Well, I think the earliest parts in your career are often the most formative. And within about a two year period, I went from on my way to college, my dad said, can you please, please trust me? Take a job at my friend's startup and work as a programmer, just in case all your crazy ideas don't work out. Maybe here's your backup plan. So in the first web bubble, I actually worked in technology that did user interface design and front end programming. And then I started a career in Hollywood. Afterwards, I wanted to follow my passions, and that took me all over the world working in 30 countries, and then ended up working for the United nations as well, and all of that within a very short period of time really created the essence of the things I care about. So now, with something like starling, I can dip into those experiences and so can sit there with international lawyers because I worked with them earlier in my career.
00:05:11.290 - 00:05:21.386, Speaker C: And you often think when you do these types of crazy things in your early 20s, when am I ever going to use this type of thing again? And in the end, it all kind of makes sense. Just takes a little beat.
00:05:21.498 - 00:05:42.582, Speaker A: So, by the way, we will open this up to questions in a little bit. But first, I'm going to ask you a few more questions. We have conflicts erupting globally right now. I understand you're Israeli. And it makes me wonder, given that that country was formed in the wake of the Holocaust, what sort of personal motivations you have for this kind of work in human rights.
00:05:42.726 - 00:06:18.862, Speaker C: So, obviously, the last month has been incredibly challenging for anybody who wants peace. It is a somewhat hopeless situation right now. My own motivation on this with the work. Well, first of all, I should say that we are engaged in the conflicts, in prooperational security matters. I can't talk about exactly what we are doing. But what I can say is that we are very concerned about the way in which things have progressed there, both in the cause to go to war and also the methods of fighting in the war. And our North Star comes from work that I did with the last surviving prosecutor from Nuremberg.
00:06:18.862 - 00:06:25.142, Speaker C: Got a chance to interview Ben Forens. He's an incredible human being. At the right young age of 100 years old, I got a chance.
00:06:25.196 - 00:06:27.640, Speaker A: That is amazing. When was that?
00:06:28.170 - 00:07:08.246, Speaker C: Two years ago. Wow. And what he told me, which is what I carry forward into this work, was that the lessons from Nuremberg, and mind you, he was the very first prosecutor to ever use the term genocide in a court of law. He said that the lessons from Nuremberg are that nobody is above the law and the eyes of the world are watching. So take that as you will, but that is somebody who saw the very worst of mankind, successfully prosecuted all of that in a court of law. So those precedents are important to uphold, and they are apolitical. And they speak to the importance of how even in the worst times, there.
00:07:08.268 - 00:07:17.810, Speaker A: Are still rules that is extremely powerful. How might Starling's technology apply in a conflict zone like Israel or elsewhere?
00:07:17.970 - 00:07:56.754, Speaker C: So again, I want to be careful to not be very specific, because as an academic institution, we have to take even extra measures to work with organizations that do work in the field. We can't be in the field ourselves, but we work with partners that are. So a couple of things I can say broadly. First of all, that as we look at the information landscape right now, there's obviously a lot of challenges with understanding what is real. And interestingly, I should say that with generative AI, what we have seen is not a flood of miss and disinformation coming from there. Generally speaking, if generative AI has been using, it's been used as a form of expression of protest, of creating these hyper objects, as it were, for expression. And I think that's important.
00:07:56.754 - 00:08:50.018, Speaker C: So it shows that we're not in this immediate situation in which we actually cannot disambiguate. But that's a very narrow window right now, in which the tools that are available right now to the masses haven't been able to create the type of confusion that they may very well. So we are working with journalists, we are working with historians, we are working with lawyers, and we're trying to find ways in which we can do something very simple, which is simply establish the original pixels, the time, the date and the place in which a photograph was taken. That's it. And I know that sounds relatively easy, but obviously, it's incredibly complicated in those types of chaotic environments. And the idea behind this is to be able to establish a form of hygiene around the information and persistence, because you have to understand that none of this, if it is ever brought to a court of law, will be something that's dealt with in the near term. We're looking at something upwards of decades.
00:08:50.018 - 00:09:05.590, Speaker C: When I was in Bosnia working on war crimes, in the beginning of my career, I was dealing with evidence that was at that point, 15 years old. So that's the scale and the challenge, essentially the temporal challenge that we're facing.
00:09:05.670 - 00:09:23.182, Speaker A: Rafiq Anadal, the artist, said something yesterday that really struck a chord with me. He said data, he believes, is a form of memory. I feel like the work that you're doing is just like the best possible example of that. We've got just a couple of minutes left. I want to squeeze in a couple of questions, if we can. Does anybody have anything they might like to ask?
00:09:23.316 - 00:09:38.086, Speaker D: Thanks for the work you're doing. Have you seen any of this new evidence with the technology that you're using, actually used in any cases in the international court of justice yet? And if not, what's your expectation? What did that all happen?
00:09:38.268 - 00:10:37.190, Speaker C: So, the founder of our legal program at the Starling lab is the current ambassador at large for global criminal justice. And so with Ambassador von Stock, we've been exploring a variety of ways of making sure that folks over at the DOJ and elsewhere are aware of this type of technology. And the article 15 submission that we did to the ICC was our proactive way of showing the court and briefing the court, or I should say the prosecutors at various points to say, hey, this type of stuff really matters. And I think that they've come around to understand that this is a possibility. And the hops to, let's say, analogies here in the domestic court system, they're not as far as you might think. There is a whole body of law and evidence practice around self authenticating information, CCTV evidence that can be brought for word from, let's say, like the New York Times. There are ways in which the courts just understand that you don't have to go and have the four person of the printing press of the New York Times in court to be able to explain that this is a legitimate front page of the New York Times.
00:10:37.190 - 00:11:38.838, Speaker C: Right? So it's those types of traditions that we're trying to draw in to ensure that things can become self authenticating. But I want to explain the Highwire act on this, because this is actually really difficult, is that for as much as we are excited about the possibilities of providing attestations of this kind, remember, there's a very thin line in which this form of authentication of information could suddenly become a form of surveillance. If this is something that a user does not actually know that they're participating in, then you could have a situation where a government, or, let's say a manufacturer or a nefarious agent could ensure that this was the default, and they could ensure that basically, there's a way of tracking everything back to, let's say, a specific mobile phone. And that could be its own human rights problem. And so that's part of the challenges that we've been looking at. And I must say that as abstract as that was originally, I had researchers go and look at cell phones out of North Korea, and we worked on this standard with Adobe. If you've been reading about the content authenticity initiative, they did something very similar to what has been put forward with a form of cryptographic attestations around the integrity of images.
00:11:38.838 - 00:12:08.754, Speaker C: But what the North Koreans did, mind you, eight years before we did, is they ensured that the hashes that were created there became a form of content moderation and censorship. So there was an allow list, and if I sent you a photograph and it wasn't on the allow list, then it would be instantly deleted on this forked version of Android that they had so it could be traced back to me. It would also be deleted if I sent it to anywhere. Both of those things are massive existential problems. So that's why we have to be careful with this type of technology.
00:12:08.872 - 00:12:30.970, Speaker A: Quite orwellian, I believe. There's a book in the library that we have here, seeing, like, a state which talks all about this sort of information legibility, and how when a state has such information, is able to identify and name things, it has power over it, and then you're subject to the motivations of that state in a place like North Korea might not be so good. Do we have any other questions in the remaining time?
00:12:31.120 - 00:12:45.418, Speaker E: Thank you. So it seems like, ultimately, the authenticity of the images comes down to trust in the manufacturers of the cameras or phones that took the images. So to what degree does that play a role here, and ultimately, how that would be used as evidence.
00:12:45.594 - 00:13:34.714, Speaker C: So there's a cleavage right now in the technology path. So the professional grade cameras are actually the ones that have the least amount of technology around this front. Whereas mobile phones have excellent cryptographic technologies, there are already trusted execution environments. You have a way to access it directly through the operating system. And so one of the things that Dan and I have been working on is trying to advise the camera manufacturers of ways that they might be able to create what is currently state of the art for mobile phones with authentication of, essentially, the operating systems there to ensure that the right os is installed, that same type of system could actually be put into cameras. It took years, but we got a kind of concept camera built by canon this summer that did exactly this. But remember, all of this, though, still requires a lot of work, because it's vulnerable.
00:13:34.714 - 00:13:43.474, Speaker C: And if it's not something that is opted into by the photographer, then it is a form of surveillance. So we need to be very careful with this type of technology.
00:13:43.672 - 00:14:00.954, Speaker A: I have so many more questions that I want to ask you. We are, unfortunately, out of time, but I'm going to ask you one more before we exit the stage, which is, if you were writing Silicon Valley in 2024, give me the one sentence log line. What would be the plot, or what would happen given the current world in which we live?
00:14:01.072 - 00:14:05.420, Speaker C: I mean, seeing Richard and Gavin in an MMA fight would be.
00:14:06.190 - 00:14:08.902, Speaker A: That is great. I love that. That's fantastic.
00:14:08.966 - 00:14:09.830, Speaker C: That'd be my vote.
00:14:09.910 - 00:14:13.390, Speaker A: And then we capture it all with Starling's metadata.
00:14:16.850 - 00:14:42.450, Speaker B: Thank you for listening to web3. With a six and Z, you can find show notes with links to resources, books or papers discussed, transcripts. And more@asicscrypto.com. This episode was produced and edited by Sonal Choxy. That's me. The episode was technically edited by our audio editor, Justin golden. Credit also to moonshot design for the art and all thanks to support from ASICs and Z Crypto.
00:14:42.450 - 00:14:58.120, Speaker B: To follow more of our work and get updates resources from us and from others, be sure to subscribe to our web3 weekly newsletter. You can find it on our website@asicsnzcrypto.com. Thank you for listening and for subscribing. Let's go.

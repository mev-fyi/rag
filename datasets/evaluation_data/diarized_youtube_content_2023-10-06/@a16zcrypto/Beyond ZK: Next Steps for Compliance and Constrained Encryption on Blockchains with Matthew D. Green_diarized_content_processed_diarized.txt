00:00:07.530 - 00:00:08.080, Speaker A: You.
00:00:10.050 - 00:00:29.514, Speaker B: All right, welcome everyone, to today's a 16 Z crypto research seminar. Very happy to introduce Matt Green, professor at Johns Hopkins University, super well known in the blockchain space as an applied cryptographer more generally. Very ambitious talk title for us today. We dialed it down a little beyond ZK.
00:00:29.642 - 00:00:47.010, Speaker A: Yeah, thank you. Good. So I changed the title of this talk. I was going to had all sorts of exciting stuff to lure people in, like compliance and constrained encryption. I dialed it down a little. I'm going to talk a little bit more about different ways of computing on encrypted data. And some of them have something to do with blockchains, and some of them are non blockchain related.
00:00:47.010 - 00:01:19.066, Speaker A: And this whole thing kind of fits together because I have this kind of obsession with figuring out how do we do different modes of computation. I've always wanted to do since I was a grad student, but that we can't necessarily do with the tools that I had as a grad student. And now we're starting to see all these new tools. Let's see what kind of things we can do with them and look a little bit farther in the future. Mostly I work on applied crypto. Most of you know me, but I should probably say, what do I do? Mostly I've worked on a lot of privacy preserving protocols. I do a lot of stuff with, like, messaging and encryption.
00:01:19.066 - 00:01:48.134, Speaker A: So it's all very practical. Sometimes I look at reverse engineering things, like, we did a bunch of reverse engineering stuff during the snowden time and looked at dual EC. I spent a lot of time on Twitter shouting at Apple. And this actually is a talk that has something to do with Apple. I tried to get them excited about it, and they said, this is totally theoretical, so that was not exciting, but mostly it's all fun and practical. The motivation for this talk is a little bit what I just said. We have learned over many years to do things that seemed impossible.
00:01:48.134 - 00:02:22.258, Speaker A: Impossible is a strong word infeasible when I was a grad student. So specifically, I remember having the biggest struggles when I was designing protocols as a PhD student. Like, oh my God, I have to hash something like, how could I possibly do a zero knowledge proof that I've done a real hash function? That was like, the most impossible thing. So we had to engineer around all that stuff. And now I talk to people and they're like, oh, yeah, you just throw shot three into a hash function or into a snark or something, and it's like the whole world has changed, and it's good. I'm happy the world has changed because it means that we can now do these great, powerful things. But it sucks because in other ways, it means that the problems aren't as interesting anymore.
00:02:22.258 - 00:02:48.720, Speaker A: And one of the things that's made this possible is obviously the rise of succinct zero knowledge because it gives us this amazing ability to do things. We have all these different technologies. I'm going to kind of categorize them with succinct zero knowledge. Obviously. The idea is we can reason about secret data, which is something I care a lot about, with a limitation that that data has to be owned by a single person, right? So I have to know my witness. I can't necessarily do joint computations over data, but that's okay. We can do some things with that, and it's really good.
00:02:48.720 - 00:03:39.838, Speaker A: The next thing, obviously, the next frontier that we haven't really tackled in the practical world is really efficient computing on encrypted, or rather private data, which we can do with things like Fhe, fully homomorphic encryption and MPC, and that lets us do joint reasoning over secret data. This is kind of the next thing hasn't really happened practically. The even better next thing that we might be able to get to someday is obfuscation, or limited obfuscation that we can actually achieve, which is the ability to reason jointly about secret data owned by more than one party without doing interaction. So that's kind of a dream world. Like, maybe someday we'll be able to do that. And then the final step, which I think is the coolest possible thing, is not only can we do obfuscation, maybe someday we could do programs that actually have limited state. So I can give you a program, an entire program that you can run, and that program will not let you just feed every possible input into it and get the output, because that would be very bad.
00:03:39.838 - 00:04:06.998, Speaker A: We can actually somehow limit the number of times you can query that. So it's kind of just all of the additional things with joint state and limiting the number of interactions. And this actually, unfortunately, is even stronger than obfuscation. And so this is the hierarchy of all the computing on encrypted data things. Maybe, I don't know, somebody could tell me if that's theoretically true. The thing I want to say oh, good, it came up, is like, we're doing great at succinct everything. I know Justin's here, so he's making improvements every day.
00:04:06.998 - 00:04:32.878, Speaker A: Wonderful. The fhe stuff pretty academic. And all this other stuff like, yeah, there's some theoretical results, but outside of using hardware, which I am going to talk about a lot, we don't really know how to do these things in practice yet. Okay. Why do we care about this? Well, ZK and I'm sorry, it's not like, quite enough to do a lot of things we care about. I was going to spend a lot more time motivating that, but I didn't really have time to give that in this talk. But I can give you just one.
00:04:32.878 - 00:05:17.566, Speaker A: We know it does scaling, we know it does private cryptocurrency things, but once you start building other protocols, it starts to kind of you run into these problems. The big problem I can just tell you like, I have a startup. And the problem we ran into was somebody said, hey, it's a compliance startup, how do you do suspicious Activity reporting? So the idea is I want to send a transaction on some kind of part of a blockchain and the bank has a policy that they're going to evaluate on that transaction and they're going to say, look, there's going to be a suspicious activity report generated if and only if you violate that policy. Which is great. It's not great, it's bad, but this is what banks actually want. And the question, the thing you can do is you can say, okay, ZK is wonderful. I will just check my own data on the non secret policy they're going to hand me.
00:05:17.566 - 00:05:43.506, Speaker A: And then if I violate the policy, I will encrypt a message that says I'm in trouble and then I'll put a ZK proof that I did that. But of course no criminal is going to actually do that part. They're not going to do that if the policy is public. They'll just circumvent the policy by not doing the transaction. So you need some way to actually do a joint computation where two parties are putting input. This is very simple. We're not talking about the world of MPC, we're talking about essentially two party computation.
00:05:43.506 - 00:06:16.114, Speaker A: But it needs to be like very low interaction, non interactive MPC, which we can do. But the point is, even achieving very simple kind of functionalities that you do every day when you go to the ATM machine, really to do them privately is beyond ZK. And you start having to tack in these other functionalities like nimpc, which are harder. So this is not totally easy. You can't solve things like mev, as far as I know, with just ZK and you can't do a whole bunch of other things like private smart contracts and exchanges and so on. I would claim. I don't know if it's true, but I think it's true.
00:06:16.114 - 00:06:53.070, Speaker A: Okay, good. So what we really want, and I'm just going to jump through a lot of this, is not a talk on everything to do with MPC. It's not a talk on definitely not a talk on building obfuscation schemes. But what we really want to build is we want to build something that kind of acts like a trusted box. It's a trusted execution environment where we can put all of our software, arbitrary software, preferably inside of this box, along with any secrets we want. We can ship this box out to the world so they can run it and they can use that box and they can execute programs. And this is kind of the dream of all computing unencrypted data people.
00:06:53.070 - 00:07:33.814, Speaker A: It's not something we've achieved, but this is the goal. If we want to build this thing. We have kind of three options today. One of them is we can build some kind of network where a bunch of nodes are doing MPC maybe we trust not everybody in this network but we trust some subset or large quorum of them and so we can outsource to them. And there have been these know, we wrote this thing called Fluid MPC and there's this thing called YOSO where people are trying to do this so it may happen. There are tees, so there are networks like Oasis and Secret where people are trusting the hardware like Intel SGX built into their machine and claiming that that works and it may or it may not work. And then there are these stronger cryptographic technologies.
00:07:33.814 - 00:08:10.242, Speaker A: We're slowly iterating towards, like, one time programs in Obfuscation, which hopefully ten years from now, when you're all like, there's grad students among you, my age, you'll be like, I remember when we used to say obfuscation was not practical and we were working around it, but now it's, like, totally practical, so I hope that happens. We'll see. I like to believe it'll happen. So let's kind of zoom out and talk about an abstraction. So I want to talk about some problems for now, let's skip through and imagine we've got this object, this perfect tee and this tee might be a cryptographic. It might be a piece of software that somehow works in the way I want it to. It might include hardware.
00:08:10.242 - 00:08:35.882, Speaker A: It doesn't matter for the moment it's just a box. The perfect tee has a handful of properties. It's got an input output API. It has a program and some secrets in it. Correctly executes this program, nobody can tamper with the program execution. We can verify like we can know that what's coming out of it is valid. It never leaks those internal secrets except if the functionality inside the program leaks them maybe through some output.
00:08:35.882 - 00:09:21.694, Speaker A: And then there's this question mark we like it, we'd really like it to keep like we want to be able to put some data into it and then later put some more data and know that what we're getting out is the output of repeated calls. So that would be very useful. The problem is, and I want to just be clear that when I say like, tee here I may be including certain kinds of hardware there are things that tes in general can't always do very well, even if we have them. And one of them is they can't communicate with the world. So tes are kind of a prisoner. They're a prisoner inside of another computer and that computer is the host machine and it doesn't matter if we're talking about software obfuscation or if we're talking about hardware. These little computers don't have direct network access and they don't even have access to peripherals of the computer.
00:09:21.694 - 00:10:07.686, Speaker A: They interact with the world through this possibly untrusted machine which we generally assume is kind of compromised and not very safe. The second thing they can't always do is keep state reliably and I'm putting a kind of an asterisk on that right. So if you have a secure enclave inside of your phone or your computer, it may have some like NVRAM that's trustworthy that's secure, so it can keep state itself. But let's say that you have two copies of that tee. So one on one phone, one on another, how do you make sure that they have the same state? Well, maybe they can communicate. What if you have a blockchain based system based on tees where every computer is replicating state across a contract? Now maybe they have to talk to each other in some way. So things get harder when you can't necessarily rely on state keeping.
00:10:07.686 - 00:10:35.122, Speaker A: It can be hard. And in software, if we figured out how to do this in software, we're totally dead because software can never keep state because you can always rewind everything. And so just to show you, I'm going to just sort of skip past the communication. I think that we all believe the part I hope, about communication being hard if you don't trust your host machine, but let's just say that let's get past that part. That's not really what I want to focus on. So we want to be able to communicate. Yeah, there we go.
00:10:35.122 - 00:11:03.582, Speaker A: The state keeping part I think is a little bit more interesting. So I'm going to spend a little more time on that. State is challenging because increasingly the storage of data, it can be located inside of a te if it's a hardware tee. But a lot of your data needs to be put out on some untrusted host machine. And that means you need to make sure that the host machine can't tamper with the data. So you can encrypt that data under a key that you, the tee, know and that the host machine doesn't. And you can authenticate the data.
00:11:03.582 - 00:11:41.430, Speaker A: But no matter what you do, you still have the possibility that that host machine is going to give you a rollback. They're going to take some old data. And the only way you can avoid rollback attacks is if you already have the ability to keep state internally, which is to say maybe you can keep a hash or a version or whatever it is, of the current data. So without the ability to keep state, you're always vulnerable to rollback attacks. And these rollback attacks can be really, really bad. For example, let me give you the simplest possible example. One of the most common te functionalities today that you've used probably at least once today is you logged into your phone and that's done using a piece of hardware.
00:11:41.430 - 00:12:17.986, Speaker A: That piece of hardware will accept up to ten attempts at entering your Pin number and there are delays. But that's all software. That's window dressing over the real protection, which is that when you hit attempt number ten that's incorrect. Your phone will wipe its state. It will keep a counter. When that counter hits ten, it will wipe the key or lock in some way, and that fundamentally requires state, and that state has to be kept inside of the enclave. If it's not kept inside of the enclave, if it's kept out in the host, which is untrustworthy, the host can replay you get to nine, and it just keeps replaying state number nine over and over again, and you get an infinite number of attacks.
00:12:17.986 - 00:13:09.334, Speaker A: And Apple used this back in like 2015 to break into that iPhone that the San Bernardino attackers used. And so this is actually how a lot of these attacks work, is they find ways to replay state so they can bypass these limitations. Okay, good. But like, generally speaking, we also know cryptographic protocols behave badly in the face of rollbacks, so we want to avoid them. All right, so how do we get around this in practical hardware systems? In hardware tees, Intel SGX used to give you internal does anyone remember these monotonic hardware counters that were in intel, the first version? So intel used to give you a limited number of monotonic hardware counters, which was cool. The problem is, once an enclave grabbed one, it had it forever until it released it, and there were a finite number of them. And the other problem is they're made out of flash memory, so if you use them too much, they would literally burn out.
00:13:09.334 - 00:13:41.326, Speaker A: So you had this problem if you're using a shared computer, like an Amazon host or something like that, it could basically destroy the machine just by grabbing all the hardware counters or overriding them a lot of times until the NVRAM stopped. And so the result was that intel looked at this and said, crap, we can't provide counters in server hardware anymore. And so they just removed the entire mechanism. It's gone. And the newer versions of SGX took all that stuff out. So that's been gone for years, and now you have to do your trusted statekeeping in some other way. Let's see what else.
00:13:41.326 - 00:14:10.742, Speaker A: So this is one possible way to avoid statekeeping problems. People have talked about building consensus networks where you have a lot of different systems and assume some of them are honest. You could do that. There's this paper called Rote from a few years back. You can do all these different things. And obviously the problems get harder when you have consensus networks with multiple enclaves in them that have to stay synchronized, like smart contract networks. Now you have this problem that not only do you have this rollback attack potential, but the state can be rolled back all over the place and it gets really messy.
00:14:10.742 - 00:14:43.378, Speaker A: So these problems are not super fun to deal with. Okay, I just want to briefly mention that we've talked about I've been talking a lot about Intel SGX and hardware, but I'm really, really trying to put my arms around this whole idea, including software. The ideal te is pure software obfuscation. We know there are some impossibility results, but we all ignore them and we move on. And the basic idea of these is that we do know that some functionalities can be obfuscated. We can do this actually using real assumptions. Now, like, there are actual real assumptions, and some of the papers are not efficient, but you can actually do this.
00:14:43.378 - 00:15:07.818, Speaker A: They're like bilinear maps and weird latice stuff, so it's not crazy. So you can do these things. And if you build these obfuscation things in some way, you can do a whole bunch of stuff. I'll get back to the stuff. Okay. What I want to talk about very briefly is how public ledgers can kind of help with using Tes, and whether Tes is hardware or software obfuscation. Okay.
00:15:07.818 - 00:16:10.190, Speaker A: Ledgers are very valuable, not really surprising. But ledgers are these kind of public existing networks that solve two of the really basic problems that we have with Tes. One is that we have to do state keeping, so we can use these somehow to keep our state for us. And the other is these networks are censorship resistant, so we can use them as a channel to communicate with people, whoever people are. And so the basic idea of these things is if you start with a very simple basic ingredient, which is proofs of publication, whatever that means, a proof that I published something on a blockchain. Let's imagine we have a blockchain for which I can publish a transaction and get back something that I can use to convince any third party that this particular transaction was published on the blockchain. Now, what does that actually mean? Like, in practice, if you're talking about bitcoin or a proof of work blockchain, how do you build that? Well, one way to do it is you basically put the transaction there and you get a fragment of the blockchain seated, let's say, at some place that we all trust.
00:16:10.190 - 00:16:36.386, Speaker A: Let's start with some basic block number. We start from that hash, and then I get a fragment of the blockchain. It doesn't have to be a very big fragment. It can just be a few hundred blocks. I take that fragment and I can take it to anybody. And since bitcoin, et cetera, is a proof of work blockchain, if the number if the hash rate in that blockchain is high enough, I should be able to make an economic argument to someone that this is probably good. It's not a cryptographic argument.
00:16:36.386 - 00:16:59.274, Speaker A: I can't prove to you that this is actually a publication. But if it would have cost me $37 million to make this fragment of blockchain by myself, you could probably trust that this is a piece of the bitcoin blockchain. So it's verifiable in proof of stake ledgers. It's a little more complicated. It's actually much less complicated. But like, when you think about the actual security, it's more complicated. So, proof of stake ledgers, of course we have signatures, so we just check a signature.
00:16:59.274 - 00:17:22.822, Speaker A: It's great. Except the problem is the signatures are from validator committees who change all the time. And once they're done with their job, they could leave. And we don't exactly know what happens to their signing keys after that. So you could be given a false blockchain from a series of changing committees. It's a little riskier, but maybe we can make some strong assumptions that it's okay. So let's assume that we have proof of stake ledgers and we can do this thing.
00:17:22.822 - 00:17:58.382, Speaker A: And then there are bdfs and Joe can tell me whether that helps here or not, but not right now. Okay? He shook his head hand a little bit. All right, so obviously we can do things with this once we have a proof of publication blockchain of some kind, it's really simple to build functionalities. Even if we have a non stateful functionality, we can turn that functionality into a very simple stateful functionality using this really simple conceptually protocol that's a little gnarly to actually build. All you have to do really is you post. So the idea is we have this thing where we post a string and we get, let's say, a copy of the full ledger just to make life simple, conceptually simple. That's our proof of publication.
00:17:58.382 - 00:18:25.494, Speaker A: Given the full ledger and the string on that ledger, we know that it's been published. We can run a protocol that's super simple. So what I do, sorry, is the user doesn't communicate directly with a secure computing device. They don't talk to the tee. Instead they have some input that they want to provide to the functionality. So what they do is they post that input to the publicly verifiable blockchain and they post it along with maybe the current state of a long running computation. They put that there, it could just be a commitment.
00:18:25.494 - 00:18:59.414, Speaker A: They don't have to publish that to everybody. And they get back from the ledger the ledger contents and whatever this proof is that proves that this thing was published. So they have these two ingredients. Next they take their input as well as this ledger stuff and the proof and they basically send it into the secure computing device. The secure computing device verifies the ledger proof. This was actually published to the ledger and it outputs its initial output, at least the first iteration of the run, and it gives back an updated state. And so you've got now this kind of this state thing and then you have to do some additional things.
00:18:59.414 - 00:19:36.190, Speaker A: We have to be a little bit careful here. So what we're doing here is using the ledger basically to bind a specific input and a specific previous state so that we can't place that state on the ledger twice. We're assuming that the device can look for repeated invocations of itself. So what we're doing basically is we're making sure that we've only called this thing on this particular state once. The secure computing device will verify that and it will produce an output. We have to be very careful that that output itself doesn't contain randomness. That means we could get two different outputs on the same state and input.
00:19:36.190 - 00:20:04.762, Speaker A: So we have to do a little more work to make sure that output is deterministic. So we'll assume there's some kind of key inside the secure computing device and it will generate its random coins using the inputs and with a PRF or something. Or a PRG and a PRF. And so we'll produce all the random coins for this. But now we have a deterministic output. And so we can basically make sure that once you run this, you can basically only run it on the next state and the next input. And so this is a really kind of weak explanation of it.
00:20:04.762 - 00:20:44.674, Speaker A: This is the full algorithm for what you actually do. Essentially, you have to basically run through this entire algorithm where we have the state coming from a blockchain, the publication proof, and you run through all of these things and you verify, you recompute the randomness and then finally somewhere down here you actually run a program. So this is the extra work you have to do. But the nice thing about this is we can basically build fully stateful programs that have deterministic pseudo randomness and can't be rewound as long as we have any blockchain that has a proof of publication ledger. So this is kind of a nice result. So it's blockchains doing something for us rather than these tools doing something for blockchains. We can also use this approach to publish things on the ledger.
00:20:44.674 - 00:21:11.618, Speaker A: So if the functionality, let's say I have a functionality where if I enter a password wrong too many times, it wants to publish something to the ledger to tell the whole world I'm trying to break in, it can do that. It can basically give me an output and say either you put this on the ledger and come back to me with a proof you did so, or you'll never be able to run me again. So this gives you sort of a limited way to push data out from this tee out onto the blockchain and to collect information back. Yes.
00:21:11.784 - 00:21:25.870, Speaker C: Just consider having multiple blockchains. Like what if I have state zero on the bitcoin blockchain and the output is state one, but then I have state zero on ethereum?
00:21:26.030 - 00:21:51.034, Speaker A: Yes. So the assumption here is that this is tied currently to a single blockchain, so it knows which blockchain it's expecting a ledger proof from. You could probably come up with some way to extend it to multiple blockchains and then you'd have to be careful that everything was in sync. If I get approved from blockchain one, then I can go out and do bad things on blockchain two. So you'd have to be very careful about that. But something like that. You can make all of these proofs very succinct to using nizics, using Snarks and so on as well.
00:21:51.034 - 00:22:31.734, Speaker A: So you could have 50 blockchain proofs and compress them into something very small. But yes, you have to be careful so you can use this for trusted I O and so on. So this gives you a nice way to kind of and here we're talking about a practical system. This gives you a nice way to use trusted execution environments like real ones inside of computers to actually do things on blockchains where you have state and you don't have this rewinding capability. And actually a bunch of people have written about this both kind of in the practical setting and the theoretical setting. If you move out to the theoretical setting, which I think is kind of interesting, you get this result, which is not the only one, but it's actually kind of one of my favorite weird theory results. And basically what it shows is the following.
00:22:31.734 - 00:23:01.406, Speaker A: It says that if you have witness encryption, it's a strong assumption and you have blockchains, and there's a lot of details in blockchains. Then you get one time programs. And one time programs are the best thing in the world. One time programs are the strongest thing on that list. They're obfuscated programs you can only run once and you can make them so you can run end times. And it turns out that we have all these known results that one time programs are complete for all of cryptography. So every other function you might ever want to realize, you can realize from one time programs.
00:23:01.406 - 00:23:08.006, Speaker A: So blockchains are the key ingredient we didn't really know that we needed and so we can build all sorts of stuff with them.
00:23:08.108 - 00:23:24.474, Speaker B: So question a result like this admits multiple interpretations, right? So one interpretation would be like, oh, we're closer to one time programs than I thought. The other one would be like, oh, I guess I'm more skeptical about encryption or like blockchains of whatever the form that they need. So how do you like to interpret it?
00:23:24.512 - 00:23:57.894, Speaker A: I like to interpret it as blockchains themselves. There's a lot of detail in Blockchains, right? We're making this assumption that we can really trust essentially this third party, right? Like third parties. If we have a trusted third party. One time programs are not that hard. And blockchains are this idea that we can take this group of people who are collaborating to do something that is not build one time programs. They have lots of things they want to do other than build one time programs, but we can use them as a general tool because they're already doing all this computation we don't care about like DeFi and all that stuff. Let's take all that work they're doing and with no extra effort, let's turn it into a cryptographic tool that builds everything else.
00:23:57.894 - 00:24:29.870, Speaker A: And so I like that. It's not that they're doing something wild, it's just that they're doing something. They're treating this thing as a piece of infrastructure. For cryptography rather than building some custom cryptographic protocol like Rote, where everyone has to deploy it and nobody ever will. So I think that's what's interesting about this. And so if blockchains become ubiquitous and they have the right properties, then maybe we'll see them getting used for all this powerful stuff. And this is really powerful because witness encryption is very just to be clear, for those who don't know witness encryption, it's like the ability to encrypt something, a piece of data.
00:24:29.870 - 00:24:48.182, Speaker A: Like, that's all it is, encryption scheme. And you can encrypt a piece of data so that if you have the right witness to some NP relation, you can open that up. And it's very strong as a cryptographic notion, but it's a very simple cryptographic notion. So getting all this power, like all of cryptography and NPC out of it is kind of neat. Yeah.
00:24:48.316 - 00:24:52.070, Speaker B: Could you maybe say what their definition of blockchain is there?
00:24:52.140 - 00:24:54.886, Speaker A: Oh, no, you don't want to look. It's not a good idea to look.
00:24:54.908 - 00:24:58.854, Speaker B: At that intuitively, though. Like, is it an append only ledger?
00:24:58.982 - 00:25:15.086, Speaker A: It's an append only ledger. That's a proof of stake append only ledger that uses unique signatures for reasons having to do with the way witness encryption works. Most of that stuff is really kind of that's theory part. Like we could kind of not focus on too much and then do they.
00:25:15.108 - 00:25:17.502, Speaker B: Need like smart contract functionality too?
00:25:17.636 - 00:25:22.698, Speaker A: Come on, that's smart contract. They didn't use the word smart contract. They need a blockchain that lets you post things and get back a proof.
00:25:22.714 - 00:25:25.438, Speaker B: That you posted it, but not necessarily execute.
00:25:25.534 - 00:25:29.906, Speaker A: Yeah, no logic, just post and proof. And you have to trust that proof. Why?
00:25:29.928 - 00:25:31.810, Speaker B: Proof of stake? That seems orthogonal to everything.
00:25:31.880 - 00:25:49.974, Speaker A: Oh, yeah. It's not so much they care, it's more they need a blockchain that uses signatures. So if your blockchain is binance signing everything on one computer, that would be great. In fact, they would be very happy. As long as binance used their weird unique signature, they would be very happy. But like, a proof of stake blockchain would do the job because its protocol fundamentally uses signatures.
00:25:50.102 - 00:25:55.258, Speaker B: Yeah, sorry, not to not to hover on the maybe this isn't no, this.
00:25:55.264 - 00:25:57.770, Speaker A: Is a really good thing to hover on. So hover.
00:25:59.970 - 00:26:06.858, Speaker B: Do they fundamentally need efficient sort of verification of each block? Do they need like a kind of compact certificate?
00:26:06.954 - 00:26:08.702, Speaker A: Yeah, we have that. Right.
00:26:08.756 - 00:26:16.930, Speaker B: But so could I guess the question is, could it work for proof of work or other things if you had? And do they need guaranteed finality?
00:26:18.070 - 00:26:23.234, Speaker A: They don't. Okay. The hard answer is, do they just.
00:26:23.272 - 00:26:25.074, Speaker B: Assume it without really naming it?
00:26:25.192 - 00:26:47.334, Speaker A: So they're theoretical cryptographers, so they're trying to build from actual witness encryption, which is why they have these strong requirements. Now, if you're building from something that probably doesn't exist, like extractable or witness encryption, then you could probably make it work with like a proof of work blockchain and it would be fine, but your assumption would also be economic. You're not getting a cryptographic guarantee that things secure, you just get something weaker.
00:26:47.382 - 00:27:00.014, Speaker B: But I've seen these things go off the rails when the theoretical crypto people don't understand, like front running or a mem pool or they don't understand that blockchains don't really give you guaranteed finality right away.
00:27:00.132 - 00:27:24.482, Speaker A: Yeah, I think the idea here is you could state this differently. Like if your proof of publication ledger gives you something you believe to be finality, then you get something you believe to be a one time program. And I think there's a lot of belief in there. But the security level is going to be if you ignore the theoretical details, the security level is going to be if the blockchain gives you finality, you get a one time program. And if not, it gets iffy.
00:27:24.626 - 00:27:29.162, Speaker B: And they don't need any kind of guarantees of synchronous publishing with no front running.
00:27:29.216 - 00:27:32.250, Speaker A: No, they don't. I mean, their model is a little simple, but they don't.
00:27:34.910 - 00:27:40.902, Speaker C: Question about something you said previously. How do TUS make sure they get the latest date?
00:27:40.976 - 00:28:12.134, Speaker A: Do they keep the yeah, yeah. So here's the deal. So in a simplified model, you get the whole ledger, which is really simple, but it's very big. If I were the obvious attack that I could run, this is not a theoretical attack. I could just chop off the most recent end block, so I get an old copy of the ledger. The nature of the way these protocols work, though, is all that would let you do like the thing I described before is it would just let you rerun on a previous input that had already been run. So you can always run the functionality many times.
00:28:12.134 - 00:28:25.930, Speaker A: It's just that you can't change the input. So, like to run it on a different input, you would need to put a second input onto the ledger later. And so rerunning the functionality easy, but getting it to run on two different inputs, that's the hard part. So truncation doesn't help you.
00:28:26.000 - 00:28:33.770, Speaker C: I see. But say if you're fed old state to the te and then based on that old state, maybe ionoid reuses the nonsense.
00:28:33.930 - 00:29:17.990, Speaker A: So you have to be super careful that there's no randomness in the functionality, that everything comes from that old state and the input and the input can never be run twice or the old state, and now you're safe. Yeah, it's very if finicky with that. Yeah, a little bit of randomness blows all these things up. But fortunately, like, software obfuscation doesn't have randomness, but like a hardware, a piece of hardware would okay, all right, I'm going to talk about something different. The through theme here is that one time programs are very interesting and it would be very exciting to me if we had something like this. There are different ways to build them so we know we can get to them through blockchains and witness encryption or obfuscation. We know we can get to them through like Intel SGX.
00:29:17.990 - 00:30:02.534, Speaker A: The question is, could we get to them through some other thing that is maybe stronger than these cryptographic assumptions but more realistic and realizable and that we could actually deploy in practice. And so for a bunch of years I've been looking around for that thing that we could hijack so that we could get one time programs, arbitrary one time programs on real hardware. And there's this old result that is so simple, it's kind of like, I don't want to say it's stupid, it's so simple, it's elegant, but like super simple, which is by Goldwasser, Kalai and Rothblum from 2008. And their idea is really simple. So you want to build one time programs. You don't have Intel SGX or some other big processor you trust to run your arbitrary software. So maybe you can use some other piece of hardware that's much simpler.
00:30:02.534 - 00:30:31.410, Speaker A: And this result, if you don't know it, is great. What they say is, hey, what if we use tokens? And a token for them means a tiny little computing device that has a very simple functionality on it. So the idea is I want to make a one time program. I am going to do some stuff in software, I'm going to send you a piece of software, but I'm also going to send you this little token. You plug it into your laptop and now that's going to help you run the one time program once. That's their idea. And it's a really simple idea.
00:30:31.410 - 00:31:14.402, Speaker A: Like I'm sure if you haven't seen this before, you could work out most of the high level intuition really quickly. If you think about Yao's two party garbling protocol, the way it works is you'll build the circuit, you garble it and then ultimately what you do is if you have a second party, they perform oblivious transfer with you to get a bunch of labels that let them execute the circuit. And oblivious transfer is a one out of two functionality. For each wire they get one label and then they can run the circuit. So this is the basic idea. So what they want to do now so the observation is that this kind of Yaos garbling protocol is almost like a one time program except for the interaction. So maybe we can replace the OT with this piece of hardware which is non interactive, which I can just send you.
00:31:14.402 - 00:31:39.206, Speaker A: That was their observation. And what's the particular functionality they need to build? Well, it looks like this. It's really simple. You initialize it and you put two keys into it, k zero and K one. When you evaluate the thing, you have a read phase. So I send it to you and you have a bit and you want to either get key zero or key one based on your bit. So you call the thing and you say, give me that key, give me bit B, and it will hand you one of those keys.
00:31:39.206 - 00:31:55.386, Speaker A: And then of course, what it's actually going to do is destroy the other key permanently. So you can never get that back. So far, so good. Questions? Good. Once you have that functionality, it's really obvious to see how to build a one time program. You just garble a circuit, you do all the stuff. You have two labels for each input wire.
00:31:55.386 - 00:32:34.314, Speaker A: You feed those two labels into a token for each wire. So you end up with actually a bunch of tokens which you could put on a single device. And then you send the hardware to the receiver along with the garbled circuit. They pick their input, they go to the tokens, they ask for the right key for each wire or label for each wire they run, and execute the garbled circuit end. That's it. And there's some complexity in actually getting security under a simulation definition, but it's a very simple idea. So the question you might ask is, if it's this simple to build one time programs, why don't we have one time programs? Why aren't we for simple functionalities? There's a lot of stuff.
00:32:34.314 - 00:33:03.342, Speaker A: Like if I look inside my iPhone, right, there's a trusted piece of hardware, it's called the Secure Enclave processor. And it would be really nice for me to be able to write programs that I can put on my phone that will run once and are obfuscated that nobody can hack that are on here, and I can do anything I want. And with Intel SGX, in theory, you can kind of do that. But there's no Intel SGX on an iPhone. But there is a secure Enclave processor. Do you know how you get arbitrary software running on the Secure Enclave processor? Yeah. You don't.
00:33:03.342 - 00:33:21.402, Speaker A: You never do. Only apple can do that. By signing it, they've made an effort to make sure that nothing ever runs on that processor. So you can never run your own software on an Apple phone or most Android phones, which also lock down. They have this thing called Trust Zone, which is a virtualization system, but they lock it down. So nobody has built one time programs anywhere. It would be really useful if we had them.
00:33:21.402 - 00:33:55.774, Speaker A: The hardware we do have doesn't let us run arbitrary functionalities. We could probably if we were on an Intel SGX machine, we could do stuff. We can't do it in most places. And on top of that, everybody who deploys these things are going out of their way to make you get approval from the manufacturer to run things. Maybe if we had other functionalities maybe the problem is that we don't have one time memories. Maybe if we just shipped one time memory functionality all over the place, we could build one time programs everywhere. But the problem is, nobody makes one time memories, because why would you make a one time memory, like a weird thing to manufacture.
00:33:55.774 - 00:34:39.122, Speaker A: Why would Apple say, I'm going to make a bunch of one time memories? They're not gonna do that. But imagine a world where one time memories existed, where lots of one time memories were out there. And imagine that world was a world we live in where not only are there one time memories available to us right now in this room, but on top of that, there are cloud providers with millions of one time memories just sitting inside of them. And those cloud providers have built them in hardware security modules so they can't access the secrets I put into them. I can just call up that cloud provider and say, give me 1001 time memories and put my secrets into it. Imagine that was the world we lived in. That would be a world where I could basically make a one time program and email it to you along with a URL for where those particular one time memories were.
00:34:39.122 - 00:34:58.086, Speaker A: You could go to the cloud provider and get the keys and run that program, but nobody else would ever be able to run it twice. Be really nice. We do live in that world. It turns out that we've lived in that world for like, about a year and a half, and we didn't know it. So Apple actually deployed something new in 2020. So more than a year and a half. It's called a counter lockbox.
00:34:58.086 - 00:35:30.190, Speaker A: This is buried somewhere deep inside of the Apple documentation. It's not currently, unfortunately, to user space exposed, but it exists, and it will be someday. I think the basic idea is they have this thing inside of their hardware. It's a functionality they expose called a counter lockbox. Each counter lockbox stores a 128 bit salt, a 128 bit passcode Verifier don't worry about that's. A hash of a password, and an eight bit counter, as well as an eight bit maximum attempt value. And there are potentially hundreds or thousands of these that you can instantiate in an iPhone.
00:35:30.190 - 00:35:54.630, Speaker A: So all they are is little password, things you can put stuff in. So this exists, and it doesn't just exist there, it exists in icloud. Right. It turns out that icloud has hardware security modules full of these things that basically store keys under a password, give you ten attempts, and will erase that key if you make all ten attempts. And it turns out it's not just in icloud keychain, it's everywhere else, too. It's in. And by the way, Apple has destroyed their access to these HSMs.
00:35:54.630 - 00:36:13.294, Speaker A: It's inside of Android in this thing called a hardware backed key store, which is run by Trust Zone. Not entirely as secure as we'd like it to be, but it's pretty good. Google deployed it, WhatsApp has it. In fact, there are like hundreds of different services. Not hundreds. Let me rephrase. There are seven different services that offer this, and they offer these capabilities.
00:36:13.294 - 00:36:34.354, Speaker A: Maybe we could hijack those and use them to build obfuscated type functionalities. Let's talk about what this functionality looks like. Okay, so a one time memory is a different thing. This is a counter lockbox. The basic idea is really simple. You go to this lockbox, you say, I want to set you up. You give it a password as well as in a maximum attempt counter A without loss of generality.
00:36:34.354 - 00:36:55.742, Speaker A: Just assume it's ten for now, but it could be anything you want. And then the way we phrase this is it generates an encryption key for you. Let's assume that key is long enough and it hands it back to you. That's the setup phase. Later on, when you want to access it, you say, I think the password is X, and you put that into it. It checks to see if the password matches whatever it's stored. It might be a hash, doesn't matter.
00:36:55.742 - 00:37:25.158, Speaker A: And if the password is correct, it hands you back the key that it's stored. Otherwise it hands you back bot and it increments a counter. And then presumably when that counter gets large enough, when the counter reaches A, it deletes the key in its memory. So this is the very simple functionality. How do we get one time programs from something like this? Well, the idea here is we need to do some stuff. Actually, I'm not going to get into the maximum temp counter values. It doesn't matter.
00:37:25.158 - 00:37:47.790, Speaker A: So how do we do this? I kind of showed you a model of why we might want to do this. Let me just show you very quickly, and then I'll come to how we do it. All right, imagine I had a bunch of lockboxes on my phone. I could create a one time program. I could store them on my phone. Anybody who comes along to my phone or who I send my phone to will be able to run that program exactly once because all the lockboxes are inside my phone. Just want to show another model.
00:37:47.790 - 00:38:32.350, Speaker A: I could put that program on the cloud and I could evaluate it somewhere else. And I could also have some kind of mechanism where I can actually send the lockboxes from one piece of trusted hardware to another. So these are the models we're in. But sorry, going forward, how do we build these things? All right, let me give you a bad intuition for how you could build one time program stuff using these lockboxes. Let's assume that our goal ultimately is to build one time programs. But we're going to start by figuring out, can we build one time memories? Okay, so we want to build a one time memory from a counter lockbox. Our naive intuition is we are going to send the receiver two counter lockboxes which have, let's say, k zero in one and k one in the other.
00:38:32.350 - 00:38:50.686, Speaker A: And they're encrypted under passwords p zero and p one. I'm not even sure what I wrote this slide to do. So I'm like, actually going through it as we see. Let's see what stupid thing I did. Okay, so what happens next? I actually have no idea. I send the receiver one of the two passwords. Like, that's not a non interactive functionality.
00:38:50.686 - 00:39:18.090, Speaker A: How does the receiver evaluate these lockboxes? So it gets only one of the two keys but never the other. It's actually not totally obvious to me, like, what the strategy is. So this whatever thing I was doing here does not work. Let's try a different idea. What I'm actually going to do is I'm going to make two lockboxes, and they're both going to have this maximum attempt counter set to one. You get one guess at each lockbox. They have two different keys in them.
00:39:18.090 - 00:39:41.134, Speaker A: One's k zero and one's k one. Put two to k zero is in one, k one is in the other. You get one shot at opening them, and each one has a password, which you get one attempt to guess. What passwords do I sign to these things? Everyone's like, I have no idea what's going on here. Why are you talking about one time memories? Okay. Yeah. Zero, one.
00:39:41.134 - 00:39:58.674, Speaker A: That's it. So I set up these things, and I've set them up so that they basically have passwords that are equivalent to the bit that you'd guess. Okay, zero and one. Now the receiver gets these two lockboxes. All right, so they have this thing. There's actually one step. I should probably hit the down button.
00:39:58.674 - 00:40:27.934, Speaker A: I'm not going to tell you which lockbox is which. I'm going to shuffle them. You're going to get these two black boxes, and they both one of them is set up with password zero, but you don't know what it is. The other one's set up with password one, and they have the appropriate keys in them. So what's your guessing strategy? Well, look, if you really are an honest person and you want to get k zero, it's a very simple strategy. You query both of the lockboxes on password zero, one of them is going to barf and say error, and one of them is going to open up and hand you k zero. But all you wanted was one key.
00:40:27.934 - 00:40:50.674, Speaker A: You didn't need both keys. So this is a great thing, ditto one. You could query both on one and you get k one and a bot, but you don't care about the bot. So this is great. And yet the problem here is and I see you smiling, so you see the problem. What is the problem with this approach? We've talked about the honest receiver strategy, but obviously the malicious receiver has a different strategy. And what is that? Try to get lucky.
00:40:50.674 - 00:41:13.754, Speaker A: Guess zero on one. And obviously if they get lucky on that one, they know the other one's one. And now they get both of those keys. And didn't say this before, but it should be known that if you get both wire keys, labels on a garbled circuit. The thing unravels, like a sweater in a homemade sweater. It's very bad. It just completely collapses and you lose all security in some circumstances.
00:41:13.882 - 00:41:23.162, Speaker B: Why don't you just try zero for one of them? And then you're guaranteed to get at least one, possibly two, with this strategy?
00:41:23.226 - 00:41:25.934, Speaker A: Yes, you are. But are you guaranteed to get two?
00:41:26.052 - 00:41:27.982, Speaker B: No. You're guaranteed to get at least one.
00:41:28.036 - 00:41:28.254, Speaker A: Yes.
00:41:28.292 - 00:41:30.290, Speaker B: And you have a 50 50 chance of getting this.
00:41:30.360 - 00:41:46.546, Speaker A: I agree with you. This is the right strategy. I mean, you definitely should do that. So what's going to happen in that strategy? Well, good. So if I query on zero, I pick one at random, say maybe that's the zero one. There's a 50% probability I'll be lucky and that will give me k zero. And there's a 50% probability I will be unlucky and I'll get bought.
00:41:46.546 - 00:42:14.878, Speaker A: And if I get bought, that key k zero is gone forever, which, as you point out, is not a disaster. I can still get k one. With probability one, that's fine. But I've lost K zero. So I've gone from the 50% chance I completely destroy the security of this entire construction, which is awesome for me as an adversary, 50% probability I'm forced to be essentially honest. So that's it. Once you have a 50% probability that someone is honest, obviously we all know that the next thing you do is you just make them do it over and over again.
00:42:14.878 - 00:42:43.894, Speaker A: So the cost of that is you're going to have to give them lots of lockboxes. So instead of just giving you let me just forward a little bit. Yeah. So this is basically saying what I just said, which is we can query, we get lucky with probability and get both keys with probability one half at most. The obvious amplification strategy here is, well, we've now built this thing before let me rephrase. The thing we've built is this leaky one time memory. That kind of works but sometimes doesn't when you have an adversary who's able to get lucky.
00:42:43.894 - 00:43:41.994, Speaker A: So if we've got a leaky one time memory, we can turn this into a better one time memory, basically just by amplifying. And what we do is we basically just give you a lot of these leaky OTMs, which means, unfortunately, I have to give you something, like to get two to the negative 40, I have to give you like 80 lockboxes or something like that. I have to give you a bunch of lockboxes, and I have to make it so that the wire labels are a combination of the outputs from many different lockboxes. So the actual construction you get oh, yeah, I'm sorry. I want to say a thing which nobody cares about, but I need to say it because it's really important to me. Does anyone here know about all the results by Crepo from like, 1980 N, about how you can take a random one half OT and turn it into anything you want in an OT world, okay? It's well known that if you have an OT that's crappy like one half the time it does the right thing. You can use these interactive protocols to make it into any OT you want.
00:43:41.994 - 00:44:11.554, Speaker A: OT 41 OT two one. You can do all these things. So the obvious intuition is do that stuff that was solved in the 1980s. It doesn't work in this case because those protocols are all fundamentally interactive. We spent a bunch of time looking at that, so that's not going to work. The thing you do is the obvious thing, which I just described, which is what you do is you secret share your two keys and so you break them into S shares. You store one share in each of these leaky OTM abstractions, and then you hand them all to the adversary.
00:44:11.554 - 00:44:39.514, Speaker A: The adversary goes and if they're adversarial, they will get lucky sometimes, they will get unlucky sometimes, and the probability they get unlucky on at least one is as high as you want it to be. And now they're not going to be able to get your secret and you're fine. So far, so good. Okay, this is the obvious thing. Great. This is good. So what I want to kind of convey to you is that this is a lot of lockboxes, all right? We have to give you like 80 lockboxes or something to get one wire label to you, which sort of sucks.
00:44:39.514 - 00:45:07.780, Speaker A: It's not great. And if your program has, let's say, N input bits, you're going to have to do this for every input wire and it adds up really fast, so it's not super great. So can we do better? And I want to stress that this paper was at TCC, so if this gets a little weird, it's going to get a little weird in a second. What we want to do so we're currently spending, let's say lambda is our security parameter, which was, like I was saying, 40 or 80. What we want to do is we want to not spend. We want to get rid of that lambda term. We want to get rid of a lot of stuff.
00:45:07.780 - 00:46:03.574, Speaker A: But the intuition here, and I'm just going to move through this very quickly, is let's imagine we have a one time program with a lot of input wires, a lot of input bits. So instead of basically getting some lambda security parameter times n number of lockboxes, which is where we were heading o of that, maybe we can do something really clever, where if we have a lot of input wires, we can kind of, like, shove that lambda security parameter down into this thing so we don't have to pay for that multiplicative parameter. And when we do that, what we really want to do is we want to get a constant number of lockboxes per input bit. But that sucks. So we want to get a constant number of lockboxes per program, and I want to stress what I mean by that. So I want to run a program that takes in a gigabyte of blockchain data, and I want to do that with 80 lockboxes. And it doesn't matter if it's 10GB, I still want it to be 80 lockboxes.
00:46:03.574 - 00:46:24.994, Speaker A: That's the ultimate goal I want here. So this is something that going from what I showed you before to that is the hard part. And it's not totally clear that that's the easiest thing to do. We don't get to 80, but something like that. Okay, there are two techniques we need to do that. I'm going to run through them very quickly because I don't want to bore you all with too much of this stuff. But the really cool idea here is a couple of techniques that we can use.
00:46:24.994 - 00:47:37.682, Speaker A: So the big problem, I said before that if you ever get two input wires on the same garbled circuit on the same wire, two input labels on the same wire of a garbled circuit, the entire garbled circuit collapses around you. Is that statement true? What actually happens? Like you're all PhD students, you've thought about garbling recently. Those of you who are cryptography students have thought about garbling recently. What actually happens when you get two different input labels on the same input wire of a garbled circuit? Like, everyone told you not to do it, right? But did you ever do it just to see what would happen? Did you ever think about what would happen if you did that? Does the circuit collapse? It's not necessarily the case. So it turns out that the way garbled circuits are constructed, you use these two labels to encrypt a gate, and then that gate is basically a table of encrypted stuff. But actually, and I'm kind of hand waving here, if you imagine a garbled circuit where, let's say one wire doesn't matter, getting two labels on that wire isn't going to hurt you, is it? I mean, it's not really going to affect the output. So it's eventually, at some point, getting all those labels, you can unwrap some gates, but you're going to hit some dead point in the circuit where it's not going to hurt you that much more badly.
00:47:37.682 - 00:48:13.166, Speaker A: So basically, if we can build some kind of circuit where the input wires getting two labels on some of the input wires does not hurt you, maybe we can survive a limited number, let's say it's a logarithmic number or some small fraction, that the adversary is going to get two labels on those wires. Maybe we can somehow immunize our garbled circuit against this, make it robust against some of these losses. And that's basically the idea. So there's this technique called robust garbling. And what robust garbling does is it survives. You can build a garbled circuit, you can immunize it against getting two labels on a. Bunch of the input wires.
00:48:13.166 - 00:49:11.670, Speaker A: It can be basically if you can bound the number of wires for which you're going to get two labels to some constant fraction, you can use this technique and I'm not going to spend a ton of time covering it. But the rough idea is we need to do for very specific functions. What we need to do is we take our arbitrary garbled circuit and we tack some extra functionality to the top of it. This extra functionality is designed so that even if the bad guy is able to evaluate two different inputs on certain input wires like zero and one bits, it won't matter once you get past that extra functionality. And I see Bret nodding, so what is that extra functionality? I'm not sure I'm explaining this well. I want to build a functionality so if you get two different you can only evaluate this functionality. You have some input, but at some small fraction you can evaluate that functionality on two different zero and one at certain positions.
00:49:11.670 - 00:49:33.354, Speaker A: And you want to make sure that even when the adversary is allowed to flip a small number of bits on some fixed input, it's not going to actually change what comes out of the bottom of the circuit. So you've got this general circuit that does some general functionality and you want to bolt something to the top of it that can survive these different options. What is that thing? I'm afraid it's on this board. No, it is not on the board.
00:49:33.392 - 00:49:36.274, Speaker C: Thing in front of some signature verification.
00:49:36.422 - 00:49:49.726, Speaker A: Oh, that'd be good. I don't know how to do that. That would be good. But we want to make sure that we can like you're right. So we could bar if we could just say, no, you can't do that. We don't have a signer here. So I'm not sure because remember, the adversary provides the input.
00:49:49.726 - 00:50:14.954, Speaker A: So you're probably right, if we could sign it wouldn't be a problem. But then the signature verification functionality might be insecure. So I'm not sure. Basically some kind of code. So yeah, error correction coding. So we apply error correction coding to the input. We have this functionality that's basically a decoder and what it means is if the adversary can flip some bits that those bits get wiped out in that decoding process and what gets to the general functionality is going to be the same either way.
00:50:14.954 - 00:50:39.406, Speaker A: And so you can build a system. This is not really our contribution. This is by a bunch of people ending in tromer and they figure out how to do this and it's really clever. So I'm not going to go through the details of this because it's long and it's incredibly boring, and it required us to implement a bunch of painful stuff using certain codes. And it was one of these papers where they're, like, use code and it will work, but they didn't say which code. And then when you actually implement it with a code, you get totally different results. And it was painful.
00:50:39.406 - 00:51:24.666, Speaker A: So I'm going to skip past this, but this is the general intuition. Attach a decoder to the top of your circuit and then you can survive a little bit of leakiness. I want to get to the last part, which I think is sort of interesting. So I wanted to show you where we're at now. Leaky one time memory currently requires two lockboxes per input wire, plus we were able to get some small extra constant fraction. From this, we were able to use leaky one time memories, just one leaky one time memory per input wire, plus this extra encoding stuff that we had to do so we could survive some bad results on the inputs. And the original function had N input wires.
00:51:24.666 - 00:52:11.254, Speaker A: And so now, because we've added this little bit of extra resilience, thanks to the code, we now have N plus gamma or something. Total leaky one time memories. You have to multiply that by two to get the total number of lockboxes. So we still have this dependency on N, which is the number of input bits to the program. How do we get rid of that? The answer is actually really simple and it's this beautiful tool and the last thing I'm going to talk about here, this beautiful tool that is called Laconic OT, which all of these smart cryptographers have been inventing and designing for no reason at all because nobody seems to have an application for it. But it's actually like the most amazing thing in the world. The basic idea of this is you can take let's say that I have a huge database.
00:52:11.254 - 00:52:44.006, Speaker A: I want to do OT for like a million different things, a million times OT, and I have a whole bunch of bits. Like I want to get bit zero on this one and bit one on this one. I get this huge database of bits I want to ask for in an OT protocol. But normally I'd have to send you a whole bunch of stuff and you'd have to send me a whole bunch of stuff back. With Laconic OT, I can take that whole database and crush it down something that's basically a hash. And then I send you the hash, and then you send me back something that is O of N, where N is the number of secrets that you're actually wanting to send me. But the point is, my move in the protocol is really tiny.
00:52:44.006 - 00:53:37.542, Speaker A: It's just a hash, my entire database, a billion bits down into a single hash. And then you can do the rest of the OT with me. And so the way this works is we have this function that basically takes in the database, spits out a digest, and like this tiny little digest is there. And then the encryptor the person who's the other side of the OT can basically take in that digest and run through all of the values they want to send you and they can do all this stuff. How does that help us in this one time memory, one time program setting? Well, it means that basically we can write a single one time program that takes in a, let's say, 256 bit hash input, and that basically internally inside the one time program. It will basically then decrypt a whole bunch of stuff. So we can basically get all of our instead of if our program input is like a gigabyte, we can hash that gigabyte of bits down into a small hash.
00:53:37.542 - 00:54:04.078, Speaker A: And now we can just do essentially one time programs, evaluate that and then feed it to the circuit, which means we get down from something like a gigabyte of bits down to like 256 bits of actual input wires into the circuit. Is any of that making sense? Does that sound reasonable to you? Justin made a face, but I don't know if it's because he's having, like, I was sleeping because the baby or not. Yes. So if you use this laconic OT, do you use this in a non.
00:54:04.094 - 00:54:06.982, Speaker B: Black box way or black box way inside the program?
00:54:07.116 - 00:54:38.302, Speaker A: Yeah, good question. It's actually a really good question. No, you don't have to use it in black box weding. No, you don't. There's some gnarly stuff with adaptivity that comes up which you can solve using random oracles and things like that, but you can get around most of those problems. Seriously, are you using it in a non black box? Do you mean like, are we using it like the code of the electronic OT inside the yeah, if you mean like, are we just using like the algorithm is written? Yes, we are. It's very simple.
00:54:38.302 - 00:55:18.554, Speaker A: We're just putting that in and then we're decrypting a series of bits. I think you're using something like a DDH based yes, there's this crazy one that's built on DDH and it seems really good, except it involves garbled circuits. And that's not great because now you have garbled circuits, you can actually pull the garbled circuits out and put them on the side, but it's really inefficient because each garbled circuit in that scheme has to do a scalar multiplication. And scalar multiplication is like the easiest thing we do in cryptography. But it turns out that it's like hundreds of megabytes in a garbled circuit for reasons I don't totally like, and that's the problem with it. So it is totally doable. You can make it work.
00:55:18.554 - 00:55:48.210, Speaker A: You don't have to garble double garble anything. You can do it outside, but it's not good. And there are these newer practical pairing based, which I haven't really looked at for how practical are they? But there are newer constructions that are better, similar to registration based encryption. These things are all related, so some of them are better. And so it's possible this might be sort of efficient. We're not sure we did not go and actually implement Laconico T. Okay, good.
00:55:48.210 - 00:56:37.330, Speaker A: So I'm nearly there. I will stop boring you with Laconic OT, but I'm mostly just going to point out that our resulting protocol is just now reduced. We did the calculation, we did an implementation of everything but the Laconic OT, and we showed that for an arbitrary input size program, we were able to get the thing down to about 1024 total lockboxes, which is not 80. I wanted it to be 80, but 1024 is like, a good number, and that's the reason this paper is at TCC and not USNIC. Security. Like, someday when it's 80 and we can actually, like, I can send you a program on the iPhone, it will be a different thing, but we're not quite there. It's almost efficient, and it also requires these more efficient constructions of Laconico T.
00:56:37.330 - 00:56:38.770, Speaker A: So it's really close. Yeah.
00:56:38.840 - 00:56:45.510, Speaker B: Why is 80 so much better than 1024? They both seem like they would add up pretty quick if you were doing this regularly.
00:56:46.010 - 00:57:26.420, Speaker A: Well, the way you get lockboxes and I sent my students to do it, and they said no for reasons. The way you get lockboxes on the cloud is you sign up for a Google account, right, and Google gives you a lockbox for free, and so does Apple, right. Anytime you sign up with an icloud account, you get a lockbox for free, and now you need another 1023 of them. So you sign up for another 1023 icloud accounts for free. And if you can do this now you have 1024 lockboxes, but also Apple has booted you out of their systems. And if you actually own an iPhone, you're in big trouble because you can never use it again, because if they link that back to you, it's abuse and it's bad.
00:57:26.870 - 00:57:31.602, Speaker B: But I mean, use the number 80, and that whole story is so true.
00:57:31.656 - 00:57:54.234, Speaker A: The reason is because I think we could probably steal 80 lockboxes out of Apple, but 1024 was like, too much. Like my students wouldn't do it. Now the serious answer is 1024 is not bad. Here's the rough result. 1024, the ability to store 1024 encrypted passwords means you can basically build a one time program over any functionality of arbitrary complexity. I think that's pretty cool. That's an actual number.
00:57:54.234 - 00:58:17.246, Speaker A: It's not an o of, it's a real number, and it's not a huge number, and I think that's kind of neat and maybe it'll go down. A lot of this stuff has to do with specific choices around codes and some other decisions that I think maybe crankable down. So I'm a practical person. I wanted to see it as something that we could really, really do. I thought 1024 was too high, so that's it. Okay, good. What's the summary of all this? Well, we're kind of all over the map.
00:58:17.246 - 00:58:54.730, Speaker A: My parting thoughts here are these kind of ideal objects are the thing we're trying to build. I don't mind if we build them with hardware. I don't mind how we build them, but we have to build them in some way that actually makes sense. And I've seen a lot of people building weird things that I don't know that are totally secure, and they may be much more common in different forms. Like we can certainly build arbitrary functionality. Another thing I think is really interesting about this is like these SGX things keep getting broken constantly, right? Like nobody trusts SGX because Daniel Genkin keeps breaking it. But what if we could? I mean, I don't know, really? I'm not a hardware, but like yeah, you hear garbled circuits.
00:58:54.730 - 00:59:39.360, Speaker A: That's terrible. Why would he do garbled circuits? But these functionalities? Apple clearly believes that running arbitrary software on their phones is bad, and they've made a big effort to make sure nobody does that because they think it will make their phones less secure. But maybe Apple isn't scared of giving you 1024 lockboxes or a few thousand lockboxes. And that means that at the cost of a little bit of garbling now you have really powerful functionalities on your phone. So maybe this is good just as a way to use processors in a much, much lighter weight way to do things that we wouldn't necessarily be able to do. Maybe, given that all we're doing in blockchains is stuff like making signatures and things like that, maybe like having a garbled circuit do that isn't a ridiculous thing to ask. And then we could reduce it to these simpler functionalities so we'd have much less hardware exposure, I hope.
00:59:39.360 - 00:59:52.660, Speaker A: Yeah, so these things exist and maybe we can sort of hack around with these tools until we have actual software obfuscation and tools that actually work. And that's it. Thank you. Any questions?
00:59:54.070 - 01:00:21.814, Speaker D: So you're saying at the end, right, one possible way forward is Apple could give you 1024 lockboxes per email address, and that would then make it so you could kind of deploy this. What if they changed the lockbox functionality? They gave you the OT that you wanted, right? Then you don't have to do this amplification, but it actually doesn't. Am I right in thinking that that wouldn't actually help you as much? You'd rather have them give you a thousand if you'd rather have 1024 lockboxes than one OT?
01:00:21.942 - 01:00:31.866, Speaker A: What I like about lockboxes is they're useful for other things. And I think if Apple just exposed the world to a lot of them, most people would use them for encrypting things because I think that's a great idea. And then you could hack on but.
01:00:31.888 - 01:00:37.778, Speaker D: If you go the other way, right, if you have OT, you could also use you could generate lockboxes from OT, right? Like OT is complete for everything.
01:00:37.944 - 01:00:47.570, Speaker A: Yeah. If you had OTMs, though, like it'd be a little big and a little ugly. Yeah, you could do that, but obviously you'd still have to do the stuff with Connor OT and you'd have to do a lot of things to make it efficient.
01:00:47.990 - 01:01:20.206, Speaker D: But I guess just the question is that by going through these robust garbled circuits, you actually don't end up losing anything from the lockbox. Like, the fact that you have a lockbox and you want OT means that you're generating these sort of leaky OTS from the lockboxes, but the robust garbling kind of saves you there. So in the end of parameters, you're not going to get something. Like if Apple today said, we gave you OTS instead of lockboxes, you'd still have about 1024 now.
01:01:20.388 - 01:01:21.754, Speaker A: Yeah, actually it would be smaller.
01:01:21.802 - 01:01:23.070, Speaker D: A little smaller, but not much.
01:01:23.140 - 01:01:28.110, Speaker A: Well, 256 maybe. Yeah, because you could go directly to the laconic OT and you could yeah.
01:01:28.260 - 01:01:35.378, Speaker D: You could skip a lot of the robust. But I thought that I don't know how much that loses, but I thought it wouldn't lose them. You think it loses like, a factor of four or something?
01:01:35.464 - 01:01:59.580, Speaker A: We lose a factor of two just by using these leaky OTMs, and then we lose an additional factor. It's like an additive factor, and I don't remember what it is, but it's very dependent on the code we use, which might not be the right code, the best code, and that's how you get to 1024. But like, already, that's the difference between 512 and 1024, and it's very specific to the block size of the code and all sorts of messy stuff because it has to work over bits and things like that.
01:02:01.470 - 01:02:25.806, Speaker B: To be clear, you're talking about Apple giving you lockboxes that are in the cloud as opposed to on your device. Is there any verification that there actually is a lockbox in the cloud? And Apple's not just simulating the whole thing when you query it. So at that point, why don't you just have the why don't you just have them be a trusted third party sort of obfuscator?
01:02:25.918 - 01:02:58.714, Speaker A: I mean, I love like absolutely the answer is, if Apple is willing to be a trusted third party obfuscator and run HSMs for us, we should do like, let's just have them do that. The hack idea here is that they're not doing that, they're revealing these functionalities, and more and more people are revealing these functionalities. So let's use those functionalities. Let's misappropriate those functionalities for the purpose we really want, which is obfuscation. It's a little hard right now. And the other is that this functionality happens to be useful for lots of things. So it's much more likely that people are going to deploy that in a cloud server than they are to give arbitrary people SGX.
01:02:58.714 - 01:03:51.630, Speaker A: There's a flip side to this, which is if you don't believe we should be hacking lockboxes to do bad things, let's imagine you happen to be on a computer that has lockboxes. People don't want you running arbitrary programs in this form. What bad things could you do to a computer that exposes a handful of lockboxes if you happen to be on that machine. And one answer is you can build really terrible malware. And so the point is, even if you turn off Intel SGX, even if you don't let people run arbitrary computations, if you just accidentally expose 1024 lockbox instances, they can infect your computer with malware, that the malware itself lives only on your computer, never has to talk to command and control and does terrible things. So the fact that we can get computation from simple functionalities is good, is a hack, but also bad because bad people can use it as a hack to do stuff. And that's the other reason we should care about this, I would argue.
01:03:51.630 - 01:03:55.374, Speaker A: Yeah.
01:03:55.572 - 01:04:00.194, Speaker D: Does the Solana phone expose any extra functionality that Apple or Google might not?
01:04:00.312 - 01:04:01.394, Speaker A: Sorry, does the what?
01:04:01.432 - 01:04:05.570, Speaker D: Does the Solana phone expose any extra functionality? I don't know if you know.
01:04:05.720 - 01:04:06.766, Speaker A: Solana phone?
01:04:06.888 - 01:04:08.470, Speaker D: Yeah, Solana released, like, a new phone.
01:04:08.540 - 01:04:21.580, Speaker A: I was really hoping I heard you. Like, literally my brain is just like bonk. Like, I don't know. I don't know. The answer is I don't know.
01:04:24.170 - 01:04:44.460, Speaker B: Yeah, maybe this is getting way ahead of the game, but do you worry about some kind of environmental pushback with all this one time hardware? If people are really using it on a large scale and the blockchain people get a hold of it and all of a sudden they're using billions of boxes a day and Apple has to.
01:04:46.190 - 01:05:07.262, Speaker A: We just make it reusable. It doesn't have to destroy itself, it just has to destroy the key. Destroying keys is easy and so that's okay. Destroying I hope destroying keys is easy. Right. It just has to turn off the power or cycle to zeroize the thing a little bit so that maybe isn't as bad. I mean, there is a risk that if you use a used piece of hardware, someone's hacked it and then it's like reusing someone's bitcoin wallet.
01:05:07.262 - 01:05:14.102, Speaker A: Maybe not the best idea from a hygiene perspective, but they should be reusable. Sorry, go ahead.
01:05:14.156 - 01:05:33.478, Speaker C: So you mentioned this challenge where you need to make the one time program deterministic and use part of the input as the randomness. First, are there any cases where you need the one time program to be truly randomized where you can't use the input as the randomness? And then second, is there a hope for constructing these truly random one time programs?
01:05:33.654 - 01:06:04.502, Speaker A: Yeah. Okay, so the first question is if let's assume we have a piece of hardware just to make life easy, we can put a key into it. And so that means that we can derive pseudorandom coins from any input. And as long as we never allow repeats, obviously repeats would mean repeated coins, which would be terrible, but the whole protocol stops you from repeating inputs, so you get pseudorandom coins and they're not truly random. Though I'm trying to find an application where they would be bad. I mean, if your PRF or your PRG is good enough, theoretically, nobody should know. It should be fine.
01:06:04.502 - 01:06:29.218, Speaker A: So I feel good about that. But there is the possibility if that key leaks out, and that's the scary part now, somebody could possibly get the key and regenerate those past coins because it's all deterministic. Maybe I haven't thought about this. Maybe you could make it forward secure somehow so you could guard against that attack a little bit. But those are the things that I would worry about. The quality of the coins would be fine, but the attacks on the system would mean, like, really bad outcomes. That wouldn't be the case with randomness.
01:06:29.218 - 01:07:23.834, Speaker A: Imagine doing TLS with forward security, right? Like, hey, I'm doing Diffie Hellman, and it's totally secure because I used an ephemeral key, but it wasn't an ephemeral key. Or like every past bitcoin key I generated is actually I mean, I guess bitcoin keys are deterministic now, but if you'd wanted them to be random, they wouldn't really be random because anyone who hacked it would get those keys. So, yes, they're bad things. As far as how you'd realize it with randomness, it would be bad because it would totally kill the construction, I think. But maybe you could find a way to allow some limited parts to be random. Okay. For specific functionalities, you could say something like, I will allow you to use randomness here, because it's okay with me to have multiple outputs at the same if you knew that it was safe to output multiple different outputs to the same input at the same state, you could make it use randomness.
01:07:23.834 - 01:07:27.930, Speaker A: It's just that you'd have to think very hard about whether that was safe for every functionality.
01:07:28.090 - 01:07:34.590, Speaker C: But you don't see a way to avoid allowing the adversary to see multiple outputs because of the randomness.
01:07:34.930 - 01:07:42.760, Speaker A: Yeah, I don't. If you can think of a way right here, I can't, but yeah, I'd be interested. Okay.

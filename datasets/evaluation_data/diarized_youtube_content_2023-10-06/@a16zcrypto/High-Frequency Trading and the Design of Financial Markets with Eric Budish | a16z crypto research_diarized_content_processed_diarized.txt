00:00:07.440 - 00:00:07.990, Speaker A: You.
00:00:09.960 - 00:00:45.144, Speaker B: All right, welcome everyone. Let's go ahead and get started to today's a 16 Z crypto research seminar. Very happy to introduce Eric Bootish, who's a professor in the business school booth at University of Chicago. Eric's a super well known market designer. He's worked in a lot of different application domains and matching markets, financial markets, which is what I'll talk to some about today. Although even though it's motivated by traditional financial market, I think we'll see some ideas that are also useful in sort of a decentralized finance context. Also, for sort of the Web Three crowd, he wrote a paper, the first version, I think in 2018, around the economics of security of the Bitcoin protocol.
00:00:45.144 - 00:00:49.432, Speaker B: Also an important paper, but I'll leave it to him to now start talking about high frequency trading.
00:00:49.496 - 00:01:22.760, Speaker A: All right. Thanks, Tim. It's great to be with you for the week. I really appreciate it. So I'm going to talk about a series of papers that I've worked on over the past decade or more. We were joking at the break about how we're now the old guys, but on high frequency trading and the design of financial markets. Let me start with probably the most famous idea in finance, certainly the first idea you get exposed to as a graduate student in the subject, which is the efficient markets hypothesis.
00:01:22.760 - 00:02:38.310, Speaker A: My distinguished colleague Gene Fama famously defined the efficient markets hypothesis as a market in which prices, quote, fully reflect all available information. And he was wise enough to note that it's kind of a comically extreme hypothesis if you take it literally. And he distinguished several different versions of the efficient market hypothesis, in his words, to pinpoint the level at which it breaks down the weak, semistrong and strong depending on whether you can beat the market based just on the basis of past prices as your information set. Beat the market based on past prices and other forms of public information as your information set, like earnings reports and so forth, or company forecasts, or the strong form in which the market you can't beat the market on the basis of either public or private information. And what he concluded at the time this is in the work in the fish and markets hypothesis held up very well in the weak and semistrung form, but that there was already a lot of evidence against the strong form of the hypothesis. The translation is to beat the market, you have to have private information. You have to know something that the rest of the market does not know.
00:02:38.310 - 00:03:52.392, Speaker A: There have been decades of research on efficient markets theory since, and the modern professional consensus is that there is some predictability in financial markets that asset prices have some predictability over longer time horizons. For example, using whether the price earnings ratio in the market is high or low or dividends are high or low, that kind of thing. The debate is over the interpretation of this predictability of asset prices? Is it rational variation in the price of risk? Is it more behavioral? There's also debate about the magnitude, since exploiting inefficiencies in financial markets is hard. But the consensus in the profession has been that in the short horizon, in the short run, efficient markets theory works very well. There's 100% agreement with a statement about short run efficient markets and an IgM experts panel which I'm involved in. And then here's a quote from the 2013 Nobel citation to Pharma and Schiller. Schiller is famous for this predictability over the long run, by the way, that if it's possible to predict with a high degree of certainty short term asset pricing fluctuations, there's money to be made.
00:03:52.392 - 00:04:38.468, Speaker A: Such a situation would reflect a rather basic malfunctioning of the market mechanism. So this intellectual and context in mind, I was genuinely perplexed as a really new assistant professor at the time. It was 2010. I still kind of remember Starkly when I first read about this, when I started reading about the arms race for trading speed among high frequency trading firms. And a famous early salvo in the race for trading speed was spread networks. They invested $300 million to dig fiber optic cable connecting financial markets in Chicago to financial markets in New York. This cable shaved round trip data transmission time from 16 milliseconds to 13 milliseconds.
00:04:38.468 - 00:05:14.064, Speaker A: So by three thousandths of a second, it's about 100th of the time it takes to blink your eye. Industry observers described three milliseconds as an eternity. They joked at the time that someone's going to go through the Earth with a tunnel rather than around the Earth with fiber optic cable to save even more time. And this joke actually sort of came true. No one actually did the tunnel. But microwaves are faster than fiber optic cable because of the physics of how light travels through glass versus through air. So the cable became obsolete within a year, and the arms race for speed has continued.
00:05:14.064 - 00:06:15.376, Speaker A: It's now commonly measured in millions and even billions of seconds. So microseconds and nanoseconds and as you'll see, I'll do some of the quantification later in this talk. It's on the order of tens of billions of dollars of expenditure per year. There's hardware, software, these communications links like spread networks, but a lot of high quality human capital devoted to shaving tiny amounts of time off of trading speeds. So the question I was flummoxed by was, how could such tiny speed advantages be worth investing so much money? If you see an arms race for trading speed, you assume it's an irrational response to an opportunity to make money. But I was trying to figure out what was that source of economic profit, of economic rent, because three milliseconds is too short to be about fundamentals, right? So fundamentals think of quarterly earnings, or five year forecasts of a company's profitability. Quarterly earnings are released once per 8 billion milliseconds.
00:06:15.376 - 00:07:15.630, Speaker A: So three milliseconds isn't about that. And the opposite of fundamental information is what's called information. And economists have long been very skeptical about trading based on technical information. So when you see on CNBC a chartist talking about a head and shoulders pattern or a 200 day moving average, economists kind of laugh at that stuff. They think it's not serious, usually amusing, often comforting, but of no real value. And the answer that my collaborators and I came up with this is again over a series of work that I'll tell you about over the last ten plus years, is that the arms race for trading speed is a response to an underlying structural flaw in the design of modern financial exchanges. The most commonly used financial exchange design around the world, globally and across asset classes, is something called the Continuous Limit Order Book.
00:07:15.630 - 00:07:57.556, Speaker A: And the flaw is that it both treats time as continuous. So time is infinitely divisible and processes requests to trade serially. So one at a time in order of receipt. And what I'll show is that the combination of continuous time and serial processing creates riskless arbitrage profits from symmetric public information. So information that, in principle at least, is disseminated to the whole market simultaneously and symmetrically in a public way nevertheless creates an arbitrage rat. So this is a violation of efficient markets theory built straight into the market design. The violation in even the weakest form of efficient markets theory.
00:07:57.556 - 00:08:28.320, Speaker A: And these riskless arbitrage profits, they're kind of not supposed to exist. And I'll show you that they harm liquidity. They're like a tax on liquidity. We're talking about mev at lunch, which is also kind of like a tax on using ethereum, for example. And these rents induce a never ending arms race for trading speeds. A never ending arms race to be ever so slightly faster than the next guy, again, now commonly measured in nanoseconds. It's ridiculous, but it's also really wasteful.
00:08:28.320 - 00:09:07.564, Speaker A: The market design solution that I'll talk about is what I call frequent batch auction. So put time into units. The time unit could be quite small, but a long time for a computer. So think like a millisecond or maybe up to a second, and then process requests to trade in a batch process using an auction. So really going from continuous serial to discrete batch, that's the core of the idea I'll talk to you about for the next hour. So I'll talk to you about this over a series of papers. Al Roth, my mentor and advisor, likes to talk about market design research occurring over long series of papers, and this is no exception.
00:09:07.564 - 00:10:28.696, Speaker A: I'll talk about the first paper published in 2015, that really kind of developed data, empirical facts about high frequency trading that hadn't really been understood before. And then this theoretical understanding of the market design as the kind of underlying root cause of the issue. And then batch auctions as the market design response. And I'll talk about a more recent work published in 2022 in the paper that's forthcoming that are about two of the most common questions that came up in response to the first paper. One, just how big a deal is this? How do we quantify the arms race for trading speed? That's this paper that I'll talk to you about that was joint with researchers at the UK financial markets regulator. And then the other question that came up over and over again, is a solution going to come from private sector forces or from some kind of regulatory response? So will the market fix the market? I'll talk to you about the economics of financial exchanges and how that shapes their incentives to innovate on their market design. And then last, I'll talk about my most recent research on the topic called Flow Trading with Crampton, Kyle, Lee and Malek that takes the batch auctions idea to the trade of multiple assets at a time.
00:10:28.696 - 00:11:10.070, Speaker A: So it's more of like a combinatorial market design for finance. I'll talk to you about that at the end. And then I'm going to mostly talk about, quote unquote TradFi, which I use non. Ironically, in traditional finance is very important and towards the very end I'll draw some connections between this research on high frequency trading and the design of financial exchanges in traditional finance and issues that arise in crypto markets. Mev is an important one. There's a lot of Sniping in crypto markets. I'll cover a bunch of connections towards the end and try to draw parallels as I go as well.
00:11:10.070 - 00:11:39.856, Speaker A: Okay, so let me talk about this 2015 paper. Please chime in with questions as we go or at the end. However you like is fine. So I'm going to start with some empirical facts about how financial markets behave at very high frequency time horizons. This is data from the two financial instruments, two most commonly traded financial instruments that track the S and P 500. And as you'll see, if you look at the axes, this is from quite some time ago. This is data from 2011.
00:11:39.856 - 00:12:21.432, Speaker A: And what this is showing is the price of these two instruments. One is a futures contract that trades in Chicago. One is an ETF that trades on the various equities exchanges, really in New Jersey and various server farms there. And this is prices over the course of the trading day where what we're doing, we got a kind of data that researchers hadn't studied previously called direct feed data from exchanges. And it's the kind of best quality data you can get. We're just plotting the midpoint price over the course of the trading day for these two financial instruments. And as you'll see, they're different instruments.
00:12:21.432 - 00:13:18.400, Speaker A: Futures and ETFs are a little bit different, but there's a pretty tight arbitrage relationship between the two of them. They both track the S and P 500 and as you'll see, their prices move in basically perfect lockstep over the course of the trading day, even this is quite a volatile trading day here's. An hour of trading data, a minute of trading data, and then this is about the amount of time it takes to blink your eye. This is 250 milliseconds of trading data and what you see is prices that at a daily basis look like they're moving in perfect lockstep, as you'd expect, given the arbitrage relationship at high frequency are moving in a much choppier manner and there's lots of arbitrage opportunities. So at this moment, as an example, the price in Chicago jumps up, the price in New York hasn't responded yet. There's an arbitrage, buy the cheap one, sell the expensive one. And there are different moments where the reverse is true.
00:13:18.400 - 00:14:12.092, Speaker A: So the next thing we did is we just count up all the arbitrages. We ask how long do they last, how much money is at stake, and so forth. So first of all, how long they last comes way down over time, over the time period of this data set, which was from 2005 to 2012, how much money the arbitrages are worth, this is per share traded is actually pretty flat over the course of the data set. And then the frequency of the arbitrages varies quite a lot over the course of the data set. Again, 2005, 2012 or so. But the variations based on whether the market happens to be volatile that day, not a time trend, which makes sense. Like if the market's really volatile, there'll be lots of opportunities to take advantage of slightly steel prices.
00:14:12.092 - 00:14:40.712, Speaker A: This is probably my favorite chart from the paper. This is the correlation of these two assets at different time horizons from a millisecond up to 100 milliseconds. And these are two assets that at a daily basis have a correlation of basically 1.99 something. They're really the same economic exposure. And what you can see is at 100 milliseconds, the correlation is getting higher and higher in each year of our data. It's nowhere near one, but it's getting higher and higher in each year of our data.
00:14:40.712 - 00:15:12.950, Speaker A: So this is information getting from Chicago prices into New York prices and vice versa, faster and faster each year. But at high enough frequency, the correlation is basically zero. If you think about it, structurally, there's just nothing in the financial market architecture that could allow these two assets prices to jump at exactly the same time. They're trading in two separate, continuous limit order books. How on earth are they going to move simultaneously? So the correlation completely breaks down at high frequency. Eric, can I just ask you yeah.
00:15:14.120 - 00:15:30.712, Speaker C: Is it true that that breakdown at high frequency is really not predictive at all of a change in the underlying slightly longer time horizon correlation between the two? That is, it really is just you see what I'm asking?
00:15:30.766 - 00:16:27.470, Speaker A: Yeah. The way I think about it is there's some and this will come through in the model, there's some fundamental not super well understood process that drives just the daily fluctuation in, say, the S and P 500. But then the very microstructure arbitrage relationship between these two ways of trading. The S and P 500 I see as almost like a form of just noise and rent extraction. And the market design I'll show you over the next bunch of slides is going to help us understand, usually, if there's an arbitrage let me just kind of I should have emphasized this point a slide or two ago. Usually if there's an arbitrage opportunity in a financial market, it gets competed away once it's obviously understood by once, it's understood by a wide variety of people. What I'm showing you here is that the arbitrage opportunity, it gets competed down in time, but it doesn't actually disappear in dollars.
00:16:27.470 - 00:17:06.004, Speaker A: And that will become clear once I go through the kind of conceptual model for why this arbitrage is an intrinsic feature of continuous trading. Usually arbitrages get competed away, but this one's sort of structural. So there's lots of trades just like this one where you have highly correlated, highly liquid assets where you can arbitrage one off the other. So here's just for funds, a bunch of pictures in. Treasury bonds got different kinds of equity indices. Currencies gold and silver and other commodities. You could do oil, natural gas.
00:17:06.004 - 00:17:49.172, Speaker A: I put coffee up here, I think, for fun. Here's just a long list. One of my collaborators, John Shims, in his prior life was a jump Trading, a big high frequency trading firm. And he came up with this list in like 30 minutes. Insiders know just how many good arbitrage peers there are in financial markets. Then there are other sources of rents. In the race for trading speed, the second one is probably the most relevant for thinking about crypto markets, actually, which is in the stock market, you can take a stock, it trades on 15 ish different exchanges, and you can arbitrage if prices vary from one exchange to the next.
00:17:49.172 - 00:18:31.596, Speaker A: And there are stock market regulations that prevent different exchanges, prices for the same asset from getting too out of whack with each other. I'll come back to that later in the talk. But in crypto markets, the price of bitcoin could trade at very different prices across different exchanges. I think that's how SBF got off the ground, right? There's a lot of arbitrage of that forum in some other markets, there's some in traditional finance, there's probably a ton. In crypto, there's a race to respond to public news. So the consumer confidence number comes out of the University of Michigan or the Fed announces an interest rate shift that creates an arms race for speed. There's races to what's called the top of the book.
00:18:31.596 - 00:19:19.590, Speaker A: There's a lot of races everywhere once you start looking for them. All right, the next thing I want to talk about is the question that just came up, is the theoretical root cause of these arbitrages from public information from kind of obvious pricing patterns. The arbitrage I just showed you like my grandma could spot that right? She's almost 100. The hard part is not spotting the relationship between prices. The hard part is physically exploiting them, not understanding the mispricing. So the model is a descendant of a famous model by Glouceston and Milgram. Picture a security and I'll go through it at some I'm not going to give the full mathematical details but I'll give you the key mathematical intuition of the model.
00:19:19.590 - 00:20:08.396, Speaker A: There's a security that trades on a continuous order book market. There's a publicly observable signal of the value of this security and I'm going to assume that the signal just jumps around in a poisson process. And I want to make the purposely strong assumption that the asset is just worth the price of the is worth this public signal. So if the signal jumps up all market participants agree this is the new value of the asset. So I'm trying to create a quote best case scenario for price discovery and liquidity provision in a continuous limit order book by assuming away asymmetric information. For example the players are going to be investors in trading firms. Investors arrive to market wanting to buy or sell one unit they're not informed.
00:20:08.396 - 00:20:53.200, Speaker A: And then there's trading firms that are always present in the market. They want to make a market. They want to make a market with bids less than offers for example. So given the model setup and this is purposeful you might conjecture that providing liquidity from it to investors so from trading firms to investors has zero cost and that Bertrand economic competition would compete the cost of liquidity down to zero. So effectively being able to buy an arbitrarily large quantity of this asset x at the price of this public signal y at a zero bid ask spread. Why would you predict that? All of the usual sources of cost of liquidity and finance I've assumed away. So inventory costs assumed away.
00:20:53.200 - 00:22:02.730, Speaker A: Risk aversion I've assumed away asymmetric information and adverse selection I've assumed away and so forth. But that's not what's going to happen in this model because of what we call Sniping or latency arbitrage and it's a phenomenon that's special to the continuous submit order book market design. So here's the visual that will help you understand the idea of Sniping. So suppose a bunch of trading firms here's the current level of the signal y and I'm making a market with bids and asks around that current public signal and suppose that signal jumps. You can think of this as a change in the price in Chicago that affects where the market should be in New York. Or you could think of this as a change in the price of coinbase that affects where the price should be on uniswap or cowswap or others. So a trading firm that's providing liquidity in New York is going to send a message to cancel their orders that are now stale and replace those orders with new quotes that reflect the new public information.
00:22:02.730 - 00:22:58.520, Speaker A: At the same time, other trading firms observing this symmetric public information will send a message to the exchange seeking to Snipe to pick off the steel. Quote and because the market design is processing this burst of activity in a continuous time serial process, it's kind of a coin toss who gets there first. So even though it's public and symmetric, there's some large probability that as a liquidity provider I'm going to get picked off. It's N minus one over N in the model. So what this visual shows us is that in a continuous order book even symmetric public information creates arbitrage rents. So these mechanical orbs like I showed you in the S and P 500 arbitrage case are kind of built into the market design. Again, it's not supposed to happen in an efficient market.
00:22:58.520 - 00:23:38.832, Speaker A: We're all used to the idea that you can get paid if you know something the rest of the market does not know. But what this analysis shows us is that in the continuous limit order book market you can get paid knowing something the rest of the market does know. And in equilibrium, these arbitrage rents are ultimately paid by investors as I'll show you on the next couple of slides. And that Nobel citation I showed you earlier, it's wrong. Asset prices, the Nobel said asset prices are predictable in the long run but quote next to impossible to predict in the short run. That's wrong because asset prices are actually extremely easy to predict in the extremely short run. So at millisecond level there's a lot of predictability.
00:23:38.832 - 00:24:35.080, Speaker A: Again, all right, I'm not going through the full mathematical details of the model but I want to give you a couple of equations that give the key, kind of the key mathematical intuition for equilibrium. So in equilibrium there's a bid ask spread that's going to be the left hand side of this equation that reflects there's some poisson arrival rate of investors lambda Invest if I'm making a market, the way I make money is an ordinary investor comes to market and buys from me at the ask or sells to me at the bid. This is how much money I make from ordinary investors showing up to market. And the way I lose money is on the right hand side. It's when there's a jump in the public information which happens with arrival rate lambda jump if that jump is big. So if that jump is bigger than my half spread so here's my bid and ask. The jump is up to here.
00:24:35.080 - 00:25:04.400, Speaker A: I'm going to get picked off with high probability. How much am I going to get picked off? That much. The difference between the jump size and half of my bid ask spread so that's this amount here that I'm going to get picked off. So in equilibrium my revenue from making a market to investors is going to get offset by my costs of getting sniped. And that's going to uniquely pin down the equilibrium bid ask spread. Yes, Tim?
00:25:04.470 - 00:25:07.868, Speaker B: Just for large N, the N minus one over N has gone away. Right?
00:25:07.974 - 00:25:40.604, Speaker A: There's a subtlety in this equation, which is that if I'm the guy making the market, I get picked off N minus one over N of the time and then in equilibrium because I have an opportunity cost of making a market and not being a sniper. And that's the last one over N. If I'm a fast guy making a market, I get picked off N minus one over N of the time. And then one over N of the time. Yeah, one over N of the time I get out of the way. But that's my rent. That's the way I get paid.
00:25:40.604 - 00:26:09.712, Speaker A: You get paid by being a successful sniper, one over N at a time. And then I get that last little bit. If I'm a slow guy making the market, then I get picked off 100% of the time. That actually happens a lot in our data, which I'll get to in the next. There's kind of a blend of both cases in the data. Um, if you then add endogenous entry so now you can invest in a costly speed technology. You get one more equation where the left hand side is again, this revenue from liquidity provision.
00:26:09.712 - 00:26:58.096, Speaker A: And then the right hand side is how much entry is there, how much investment is there in trading speed? The economic interpretation of this equation is that the investment in trading speed dissipates the pile of rent created by sniping, which in turn gets passed on to investors as a larger than zero bid ask spread. Again, in this model, the spread should be zero. In a richer model, which I work on in some subsequent work, you can have both sources of bid ask spread private information and public information. But this model is trying to strip out the nonessential ingredients. So you get this equivalence. Again, the arms race prize the expenditures on speed and the cost to investors. So profits in an arms race have to come from somewhere.
00:26:58.096 - 00:27:17.036, Speaker A: There's profits in the mev game. They have to come from somewhere. The kind of attacks on users of ethereum. So one of the predictions that comes out of this model is that the arms race for speed is never ending. So let me just show you some fun data on that. So here's the first microwave link between Chicago and New York. You'll see, it zigzags a little bit.
00:27:17.036 - 00:27:46.896, Speaker A: It's not a very straight line, but microwaves are faster enough than fiber optic cable that it was still faster than the spread networks cable. This microwave link from Chicago to New York. Next time you're in downtown Chicago, visit Millennium Park. Here's the bean. And then here's the top of the Aon Center, which is where one of the microwave hops is. So next time you're there, take a look. And then here's the microwave network filling out over a six or seven year period.
00:27:46.896 - 00:28:40.280, Speaker A: This is using FCC microwave license applications. Good use of you can see and you can see the line getting straighter and straighter in each year of our data. You can also see down here that Washington DC is in a very straight line link to Chicago and New Jersey. That's because a lot of symmetric public information gets released from Washington DC. So Fed announcements, the jobs number, and that creates Sniping races. Okay, so the last thing I want to do for this paper, and then I'll go through some of the newer work, is how to fix the Sniping problem with the idea of frequent batch auctions. So at a high level, frequent batch auctions take the current market design and make just two key changes.
00:28:40.280 - 00:29:19.296, Speaker A: So time is treated as a discrete variable, not a continuous variable. And requests to trade are processed in batch, not serially. A little bit more fully, take the trading day, divide it into equal length batch intervals. I'll use tau as the notation. Think of Tau practically for equity markets, it might be a millisecond for the flow trading idea that I'll talk about towards the end, where you're trading portfolios of assets, it might be appropriate to use a slightly longer interval for computational reasons. So maybe a second. Still pretty fast, but a lot slower than nanoseconds.
00:29:19.296 - 00:29:48.844, Speaker A: During the interval, you can submit bids and asks, just like with the current language, can freely modify bids and orders at any moment in time. Orders that aren't executed just stay outstanding in the market. All kind of just like standard limit orders. At the end of each interval, the exchange aggregates all supply and demand, if you will, all outstanding orders. There's two cases, either supply and demand cross or they don't. Yes, go ahead.
00:29:48.962 - 00:29:56.232, Speaker D: Yeah. In the actual batch during that time period, is there information being released back to traders?
00:29:56.296 - 00:30:37.564, Speaker A: Wait till the bottom of this slide. If supply and demand intersect, then the market clears. A uniform price priority is still priced and time, but treating time as a discrete variable. So if my orders have been hanging out in the market for many batches and yours are new, this batch, I have time priority over you. But if we've both arrived in this batch, we're treated as exactly the same. And then information policy, to your question, the same information policy is in the continuous market, where in the continuous market I send an order to the exchange. The exchange economically processes the order, and then I get an update of what happened.
00:30:37.564 - 00:31:02.464, Speaker A: Like, oh, a new order got added to the book, or there was a trade at such and such a price. Same thing. In the discrete time batch market where I send the order to the exchange, the exchange economically processes the order and. Then the market gets an update. The difference is the economic processing is happening in discrete time. What's a big difference versus crypto markets? In crypto markets you send the order to the exchange. Think of it as sending an order to the mem pool.
00:31:02.464 - 00:31:39.436, Speaker A: It's then like public and visible for all to see before it gets economically acted upon and that gives rise to lots of rent extraction. It's a bad design from the perspective of financial exchange design. I mean, it doesn't make any sense. Okay, so after each interval, report all the trades, report all outstanding orders, just like I was talking about. I find it helpful to think about the FBA proposal through the lens of three cases. I found this to be a helpful way to explain it. The first case is in a particular batch interval.
00:31:39.436 - 00:32:36.080, Speaker A: So picture a millisecond, nothing happens. So then what's going on? There's a lot of orders to sell and a lot of orders to buy, and they're just kind of flashing to the market once per millisecond, if you will, just hanging out, providing liquidity, just like in a limit order. Book how there's an outstanding bid and offer that's the analog in a batch auction market in periods of calm where not much is happening. A second case is that there's a small amount of trade. So the market's kind of hovering bid ten, ask twelve, someone shows up and wants to buy 100 shares at twelve. That would also a very common case and that executes very analogously to us in a limit order book market. The third case is though, if there's a burst of activity in the interval, so if there's some information innovation that causes a lot of algorithms to respond, then using the auction is very different from using the limit order book.
00:32:36.080 - 00:33:35.668, Speaker A: That's kind of the whole point of using the auction is to manage that burst of activity using an auction with price competition as opposed to the serial process, which is speed competition. So the auction I think quite intuitively reduces the economic relevance of tiny speed advantages. Most public information arrives at a time where all market participants can see it in time for the next batch. So most information will have arrived from the previous batch and you have a whole batch to think about and decide what to do for the next batch. Information that comes externally could arrive anywhere in this window and there'll be a tiny interval towards the end where if you're a little bit faster than me, if information arrives at that critical window, you see it and I don't. So speed is not zero relevance, but it's a lot less economically relevant. Whereas in the continuous market, if you're a billionth of a second faster than me, that's relevant always.
00:33:35.668 - 00:34:32.580, Speaker A: Like any piece of new information, a tiny speed advantage is always relevant. The second value of auctions, which is more subtle, is that auctions change the nature of competition from competition on speed to competition on price. So imagine that information arrives in that critical window where if you're faster than me, you see it and I don't. But now imagine that there's two of you and one of me, and I'm vulnerable to getting picked off. But the two of you now have to compete in an auction. So you have incentive to pass through to me a better price that reflects the public information even though you're faster than me. So in a Bertrand Nash kind of equilibrium, you'll pass through you'll perfectly pass through the innovation and the public signal in different auction games that might be more partial, but you get competition on price because of the auction.
00:34:32.580 - 00:35:16.868, Speaker A: There's a conceptual point that I like to make about the purely computational benefits of discrete time. I think this is a good topic at the intersection of computer science and economics. So I want to briefly advertise it here, which is continuous time markets at some computational level make no sense. It's as if they're assuming that computers are infinitely fast. And we all know computers are very fast, but they're not infinitely fast. And some of the Chicago, New York stuff is like, quite literally relativity differences between geographies. It takes time for light to get from one geography to another, and a lot of that the computational and speed of light constraints go away if you have discrete time, not continuous time.
00:35:16.868 - 00:35:49.904, Speaker A: So you get a much cleaner financial system. If you go from continuous to discrete. You get a cleaner regulatory paper trail, for example, which you don't have to adjust for relativity anymore. So I think it's a good topic. Next paper I want to talk about is about quantifying the Sniping problem a lot more widely and broadly than we were able to do in the previous paper, using a really cool new type of data that I was able to get by working with regulators who used regulatory muscle to get a kind of data no one had gotten before. I see a hand up. Yeah, go ahead.
00:35:49.904 - 00:35:50.432, Speaker A: Yeah.
00:35:50.566 - 00:36:04.176, Speaker C: On the second to last point, I guess, about the lower powered but arms race incentives still exist. It seems like the magnitude of those incentives is decreasing in the time interval.
00:36:04.288 - 00:36:13.640, Speaker A: Yeah. The key ratio in the paper is delta over tau, where delta is the speed difference between you and me and tau is the time interval.
00:36:14.140 - 00:36:16.996, Speaker C: What's the cost side of making tau bigger?
00:36:17.188 - 00:37:00.020, Speaker A: That's a hard question. My honest answer is in the paper I act as if going from tau of continuous to tau of very fast discrete doesn't cost anybody anything. As a mathematical matter, we're pointing out that there's a discontinuity in the efficiency of the market as you go from continuous to very fast discrete. A hard question is what happens as you further lengthen tau from, say, a millisecond. It's hard to take seriously that there's costs of waiting a millisecond to trade. It's not hard to take seriously that there's costs of waiting a day to trade and what those costs are is not very fully modeled. It's something I'm thinking about, have been thinking about for a while.
00:37:00.020 - 00:37:10.692, Speaker A: But this whole agenda really is about going from zero to something very fast with an open mindedness about further benefits and costs of going to something slower.
00:37:10.756 - 00:37:15.036, Speaker C: And making tau a random variable doesn't do you're just going to integrate across that and it's not going to change.
00:37:15.058 - 00:37:54.264, Speaker A: The power of the incentives in this model. It kind of doesn't accomplish anything and it makes the market kind of more confusing. But I have a lot of thoughts on the randomization. Europe is now about 5% frequent batch auctions in European equity market, most in European equity markets, mostly using randomized batch auctions, but with kind of a different information policy. They're more like dark pools than exchange. There's a lot of kind of weeds in that discussion that I would be very glad to talk about offline in this model. Randomization doesn't accomplish I mean, is there.
00:37:54.302 - 00:38:05.164, Speaker C: A risk if the Tau gets really long that people won't want to submit trades early in the time period because they might be sort of stale by the time the batch auction actually happens.
00:38:05.202 - 00:38:42.676, Speaker A: Yeah. This I think, is kind of an important practical detail. You're allowed to freely cancel your order whenever you like. So if you want to submit an order let's say the batch interval is 1 second, which is eternity, and you submit an order and then 990 milliseconds into the second, some news comes along that makes you change your mind. What price you want to offer at. You can adjust your quote freely cancel, freely modify at any moment in time. You can't confuse the market by sending a message, canceling it, sending it, canceling it, and having that all get disseminated publicly.
00:38:42.676 - 00:39:01.964, Speaker A: So that's part of why information gets disseminated in discrete time is to not open up scope for gaming with non actionable orders. Because if I release an order to buy a lot and then cancel it at the last second and send in an order to sell a lot, that's like manipulation. That doesn't accomplish it.
00:39:02.002 - 00:39:07.180, Speaker C: So when you say you can't, is that kind of from a TradFi like it's a legal standpoint?
00:39:07.340 - 00:39:42.452, Speaker A: Well, in this design, information doesn't get disseminated in discrete time. So if I submitted that order and then canceled it, you wouldn't see that I'd done those things. So it wouldn't any point to and also, yeah, it is illegal to purposely try to manipulate the market and I think there's good reasons that we have those laws. But that's another longer conversation. I think a lot of TradFi rules and regulations were just discovered for good reasons and crypto is discovering those. Rediscovering some of those principles slowly.
00:39:42.596 - 00:39:59.148, Speaker D: Is the randomness a big issue in these frequent batch auctions? Because all the bids that come in during the same time block, you're randomizing prices, not randomizing which of those get filled.
00:39:59.244 - 00:40:48.000, Speaker A: Yeah, but keep in mind that in most milliseconds there's not going to be a burst of activity in most milliseconds, or most seconds even. But yeah, if there was a need to break ties, you could break ties pro rada. You just wouldn't break ties based on time priority. So I think you're absolutely right. I don't think of it as a big issue, but you're absolutely right that there might be a need for tie breaking. Let me talk to you about the Quantification paper and I'll try to go a little bit more quickly through the fewer slides for each of the other papers when we go through them a little bit more quickly. All right, so this paper, this is joint with researchers who at the time were at the UK Financial Conduct Authority, mateo Aquilina and Peter O'Neill, and it uses a new kind of data to measure latency arbitrage in a way that hadn't previously been doable before.
00:40:48.000 - 00:41:24.264, Speaker A: It's called message data. So limit order book data, like we used in the previous study, and that's widely used in financial research, provides a complete play by play of the limit order book. It's great for lots of studies. But what it doesn't have is if Tim and I are racing to pick off a steel quote and Tim wins and I'm a little bit too late, it doesn't have the fact that I tried to get that trade. And just missed because I'll get bounced back with essentially an error message. Or if I was trying to get out of the way of Tim, tim picked me off and I just missed canceling. Limit order book data won't have that.
00:41:24.264 - 00:42:03.716, Speaker A: I just missed because I'll get bounced back with kind of an error message, you're too late to cancel. So the simple insight of this paper is that these failure messages, these attempts to trade that fail, are a really good empirical signature of the fact that there was a race going on, because races have winners and losers. Limit order book data, you see that someone traded at twelve, but you don't see that three other people tried to trade at twelve and just missed. But there are computers keeping track of this stuff. So we kind of subpoenaed, and it's the wrong word, but we use regulatory muscle to get this full back and forth message traffic between market participants and in this case the London Stock Exchange.
00:42:03.828 - 00:42:05.768, Speaker C: But only the regulator has that data.
00:42:05.854 - 00:42:38.272, Speaker A: Like the traders themselves decides their own rejections. They wouldn't see the traders themselves would see their own rejections. The exchange keeps it, but more in an audit trail, like they keep it to audit in case something is disputed. But they weren't keeping it in a user friendly format, and I don't think that was to make our lives difficult. As researchers, I think this data just isn't studied very much unless there's a need to audit it. But it's really great for studying high frequency trading. So we were the first, to my knowledge, the first ever to really study it.
00:42:38.272 - 00:43:31.780, Speaker A: So we got message data from the London Stock Exchange under a formal request. Nine weeks of message data for the whole UK stock market from fall 2015, with millionth of a second level accuracy. This data allows us to directly quantify a lot of stuff. I was super interested in quantifying for a long time. How often are there races? How long do they take? How many participants are there? Are the winners and losers pretty concentrated? How much is it worth overall? Here's a visual of how a stock exchange architecture is fairly typical of how it works. A trader would send a message to the exchange, so I want to buy 100 shares at twelve. It passes through one of a bunch of gateways on its way to what you think of as the exchange itself, which is sometimes called the matching engine.
00:43:31.780 - 00:44:36.424, Speaker A: The matching engine would do something like add this order to the book, or execute this order against the resting order, and then send messages back to that participant saying like, oh, you just added an order to buy 100 shares to the book at twelve. And it would also send messages back to public data feeds, like there's a new order to buy 100 shares at twelve. And we grabbed all of the message data just outside of the boundary of the exchanges systems on the way in and on the way out. So we could see, for example, if T One, T two and T three were all trying to trade the same 100 shares of twelve at very close to the same time. We'd be able to see that in this data. The way we define a race is we look for cases where there are multiple participants, same symbol, same price and same side of the market. So buy at twelve or cancel my offer at twelve, where there's either a mix of offers to buy and attempts to cancel, or just a lot of offers to buy, where some succeed and some fail, all at, quote, the same time.
00:44:36.424 - 00:45:16.150, Speaker A: And of these, the first three are kind of empirically trivial to define. We do some sensitivities around each one. The same time is harder to define empirically because in a theory model there's such a thing as the same time. You make time discrete and you analyze what happens at the same time. In data, no two things happen at exactly the same time. So the main approach we look at and what I'll show you results from is two events are said to be two messages are said to be at the same time. If they're sufficiently close together in time that the second couldn't possibly be a response to the first just because the first didn't have enough time to kind of make the round trip and that's about 200 millionths of a second.
00:45:16.150 - 00:45:39.724, Speaker A: As you'll see, the modal race is really five to ten millionths of a second. So the modal race is much faster than even that. So here's the main results of the paper. First of all, races are very frequent for large cap UK stocks. About a race per minute, they're fast. The modal race lasts between five and ten millionths of a second. So that's what is a you blink your eye, it takes 300,000 millionths of a second.
00:45:39.724 - 00:46:04.992, Speaker A: It's really, really fast. This is kind of astonishing to me. So over 20% of the UK stock market, this is back in 2015, was high frequency trading races. So just kind of pause for a moment on that. A huge fraction of market volume is trading races. Race participation is very concentrated. The top six firms win over 80% of races.
00:46:04.992 - 00:46:36.792, Speaker A: They also lose over 80% of races. Which makes sense, given the model, right? We're kind of racing, I win sometimes, you win sometimes. The top firms are also disproportionately aggressive, so they're disproportionately taking stale quotes. And this relates to Tim's question earlier. It's actually fairly frequent that the guy being Sniped isn't as fast as the guys doing the Sniping. I don't see identities, just to be clear, but we can track if it's the same firm over time. All anonymized races are small per race, so they average about a couple of bucks, half a tick.
00:46:36.792 - 00:47:10.600, Speaker A: But because it's 20% of volume, it adds up. So there's a couple of different ways to quantify what it adds up to. One is to use and for those of you interested in this area, I really point you to this. Part of the paper is to use empirical market microstructured decompositions of the cost of liquidity in financial markets. We augment those to add Sniping. And Sniping is about a third of the decomposition of the sources of the cost of liquidity. And this is in traditional financial markets.
00:47:10.600 - 00:48:04.376, Speaker A: If those of you are interested, I can point you to the relevant references and relevant part of the paper afterwards. But Sniping is about a third of the source of the bid ask spread in this market. You can also do some kind of theory based empirics and ask, well, if you used a different market design that didn't have Sniping, so specifically, if you use frequent batch auctions, how much lower would the market's cost of liquidity be? And you have to take into account that as you narrow the market's cost of liquidity, that's a good thing. But that also is going to increase adverse selection as kind of an endogenous response. And that's a 17% reduction in the market's cost of liquidity. And then it adds up to a lot of money. It's about a half basis point tax on trading volume, which adds up to about $5 billion a year in stock markets alone.
00:48:04.376 - 00:48:15.600, Speaker A: So if you extrapolate to bonds, foreign exchange, futures markets options you get 5 billion is already real money, as they say, and you get to significant dollars per year.
00:48:15.750 - 00:48:21.344, Speaker D: Did you say you have to extrapolate bonds don't trade in continuous order books normally, right?
00:48:21.382 - 00:48:58.488, Speaker A: Some do, some don't. So treasury bonds in the US do, some other bonds don't. There's a wide variety of market designs. So I want to talk about the magnitudes in this study for just one slide, which is there's a sense in which the magnitudes are huge and then there's a sense in which the magnitudes are tiny. I think both are sort of true. The cost per transaction is actually pretty small, like a half basis point. Tax on trading is not exactly a five alarm fire, but the sums as a whole are large, like a third of the cost of liquidity is kind of massive.
00:48:58.488 - 00:49:46.616, Speaker A: $5 billion per year in just the stock market, not even counting all the other asset classes that trade this way. You take an NPV of 5 billion a year, you can get the big. That's a lot of money. You kind of have a concentrated dispersed dynamic. I've been reading a lot of Political Science and Political Economy lately where you have this small group of participants that make a lot of money from this issue. This issue is existential to those participants and the issue is sort of at the expense of a larger number of market participants who don't care about it so much. Kind of the dispersed in the language of Mansour olsen let me talk about the question of will the market fix the market? I'm going to do this paper very quickly and then talk about this paper is now coming out in the Journal of Political Economy and then I'll talk about the flow trading paper and then I will wrap.
00:49:46.616 - 00:50:45.580, Speaker A: So market design research usually focuses on designing the best possible market mechanism for a given problem. And what we're going to study in this paper is a different kind of complementary question. Suppose you actually have a good market design for a given problem. Researchers have already done that part of their job. Will it actually get adopted by the private sector? What are the private incentives for stock exchanges to adopt? In this case, frequent batch auctions? This is an innovation and technology adoption question. Do the private incentives of financial exchanges align with what's socially best for the market? Will the market, if you will, fix the market? The way we study this question is with a model that's very closely tailored to the institutional details of modern electronic financial exchanges. So the players are exchanges, trading firms, informed traders and uninformed investors.
00:50:45.580 - 00:51:33.884, Speaker A: Exchanges choose their market design and then set prices for trading and also prices for accessing their exchange quickly. So for what we call speed technology, the trading firms decide whether to buy this speed technology and then all market participants play a trading game, kind of like in the previous paper we take the regulatory details of modern financial exchanges quite seriously. In this paper in particular, stocks are fungible across exchanges. That's an idea called unlisted trading privileges and then the frictionless search and information provisions in regulation national market system. In the US stock market the first thing we do is we study what we think of as the status quo. The game in which all exchanges use the continuous limit order book design. In equilibrium of that game.
00:51:33.884 - 00:52:15.256, Speaker A: Trading fees are perfectly competitive. Where exchanges are able to make some economic profit is from selling speed technology. And the intuition there is that if I charge a high trading fee and you don't, then an investor choosing where to trade can just go to the market without the fees. If Uber charges a much higher price than Lyft, you can go to Lyft. But now if there's a speed sensitive trading opportunity on Nasdaq, nasdaq kind of has a monopoly over selling fast access to that opportunity so it can charge a price for that that does not get competed away in equilibrium. And this aligns very closely with facts that we document in this paper. So trading fees in the US stock market are very competitive.
00:52:15.256 - 00:52:38.610, Speaker A: It's as close to Bertrand competition as I've ever seen. About 0.1 cents per share per side traded. So at $100 stock 1% will be a buck a basis point. Will it be a penny? It's 100th of that. So trading fees are really small in the US stock market but the speed technology fees are pretty significant. They're over a billion dollars a year and they've been growing pretty quickly.
00:52:38.610 - 00:53:23.148, Speaker A: We then study games in which there's some adoption in which one or more exchanges adopts the frequent batch auction design. The first result is because of the frictionless search. If there's one adopter it actually wins a lot of share. In any equilibrium it wins share and earns profits. Because if I make a better market, like let's say Lyft has better prices than Uber and you're regulatorily required to check both which in the US stock market you kind of are then Lyft's going to get a lot of share from Uber. So it's not a chicken and egg problem. But then the second result is that if there are multiple adopters of this better market design then the design kind of wins.
00:53:23.148 - 00:54:18.892, Speaker A: But the exchanges are back to brutal Bertrand competition. But now they've blown up their one good business which is selling fast access because the market is less speed sensitive. And then so a third result is that there exists an equilibrium in which the incumbents stay at the status quo market design, just keep the market continuous, keep earning the billion plus dollars a year of a speed technology rent. It's kind of like a cooperation in the repeated prisoners dilemma. This analysis then has a lot of policy implications which in the interest of time and just given the crowd I'm going to skip just to get to the next paper. There's actually been a lot of positive policy progress on this topic recently. The securities and Exchange Commission, for those of you interested, has proposed to have auctions be a large part of the way retail investors in the United States trade stocks.
00:54:18.892 - 00:54:56.488, Speaker A: I wrote a detailed letter about that. It's on my website if you're interested. All right, last thing I'll talk about in the last five minutes or so is the idea of flow trading. This is with Pete Kyle and Peter Crampton. Mina Lee and David Malek. So we figured out a way to take the batch auctions idea to the trade of arbitrary portfolios of assets, where what we mean by a portfolio is an arbitrary, linear combination, real valued positive or negative weights on assets. This allows you to encode complements across assets, substitutes across assets, and it allows you to encode portfolios.
00:54:56.488 - 00:55:47.484, Speaker A: It allows you to encode arbitrage. I want to buy A, sell B if their prices get out of line, portfolios and arbitrage are at the heart of finance. And we're excited because we figured out a way to trade portfolios directly and engage in arbitrage strategies directly. This in particular, one thing I'm excited about is it builds a solution to the correlation breakdown problem directly into the market design. Because rather than waiting for X and Y to diverge and then having a batch auction to compete Y back to X or vice versa, you can just submit an order to the exchange. I want to buy X, sell Y whenever their prices diverge, and that's like a string that ties their prices together, prevents them from diverging into the first place. And to accomplish this, we had to marry the frequent batch auction design to prior work by Pete and Mina that proposed the idea of smooth trading.
00:55:47.484 - 00:56:37.180, Speaker A: They figured out a way to using downward sloping demand curves to express requests to trade as a flow over time. So instead of I want to buy 100 shares of Apple, I want to buy one share of app up to one share of Apple per second, and at most 100 shares total. And if you think about the way large institutional investors trade, they trade gradually over time using sophisticated trading algorithms. This builds in what they want to do already directly into the market design. So you could, for example, get the TWAP, the time weighted average price quite directly with our design. This is some of the mathematics in the paper. I'm running very low on time, so let me just kind of go through the highlights of this very quickly.
00:56:37.180 - 00:57:32.880, Speaker A: A portfolio is just a vector of portfolio weights that lives in RN, where ends the number of assets, where each weight could be just a real valued positive or negative number. You can make a market with two portfolio orders that are the positive and negative of each other. And the way you would express demand is with two limits, what we call a lower limit and an upper limit, where the economic interpretation is if the price is the lower limit or better trade at my full rate. So if I want to buy, say, two portfolio units per second, trade all two of them, if the price is at my upper limit, or worse, trade zero, and then linear interpolation in between those two limits, then there's a maximum execution rate and a cumulative quantity to be executed. This is the math of one portfolio order. Eric yes.
00:57:32.950 - 00:57:38.128, Speaker B: Should I think of this as kind of you're shooting for maximum expressivity subject to computational tractability?
00:57:38.304 - 00:58:02.680, Speaker A: Yeah. What we get in this paper is we get something pretty expressive, I think is expressive in a way that's quite useful for finance. You can express portfolios arbitrage. You could do customized ETFs. ETFs are a huge fraction of the US stock market and they're expensive. They cost investors on average 20 basis points. And you could build your own ETF directly with our language.
00:58:02.680 - 00:58:26.464, Speaker A: It could be a long, short ETF built directly with our language. It's very expressive, not arbitrarily expressive. And that's going to help us get Existence theorems and then computational results. So we think of it as a sweet spot. It's a pretty good language that has existence results and computational performance. And there's no theorem. I can say that it's the best such language, but I really like it.
00:58:26.464 - 00:59:06.124, Speaker A: So that's short of a theorem, but it's a genuine, I guess, biased economic view. But that's the way we're thinking about the paper, that expressiveness Existence computation. So hopefully a sweet spot among those three. This is what I just told you about in the previous slide, just in math. Let me skip it in the interest of time. The market clears jointly across all N assets. So we all submit our orders to trade individual stocks or portfolios or long short arbitrages or whatever at any moment in time.
00:59:06.124 - 01:00:05.996, Speaker A: So let's say the market's querying once per second. The market has to find prices for all, say, 500 assets in the market. And this is the math that expresses that idea, where if there's an excess demand vector over all of the assets in the market, the goal is to find prices such that the excess demand vector zeros out. So D of pi equals zero. This is N equations where the N's number of assets and N unknowns, and we're able to prove that prices exist that clear the market, then we're able to find them. So this is just kind of the Existence theorems can formulate the problem as, because the demands are linear, you can think of it as a quadratic objective function that then has a derivative that's linear and that lets us use ideas from quadratic programming to state and prove theorems for the existence and uniqueness of optimal quantities. And the existence of market clearing prices.
01:00:05.996 - 01:00:21.080, Speaker A: And the proofs are actually relatively straightforward. They use. Math. I didn't previously know math on quadratic programming and convex optimization, but it's math you can learn from textbooks and we're able to have in the end, like pretty succinct, pretty succinct proofs.
01:00:21.820 - 01:00:24.036, Speaker B: Theorem one and two, basically convex duality.
01:00:24.148 - 01:01:00.564, Speaker A: Yeah, it's duality for a quadratic program. That's right. Why did this work? And I think if you think in terms of quadratic programming, like, yeah, it kind of works. But the reason why I was so surprised that it worked is that there's so many negative results for existence of prices. If you have complements, and this language lets you have complements because you could say, I want to buy A and B together as a portfolio. That's like a form of complementarity in GE theory and in the indivisible goods literature. Complements make existence and computation really hard.
01:01:00.564 - 01:01:33.580, Speaker A: Think of all the work Paul Milgram's been doing over the last several decades. The existence proof here is pretty simple. Why is that? If you go through the proof, we're taking advantage of a bunch of features that are not present in other market design problems with complementarities, the goods are infinitely divisible. We're treating goods as infinitely divisible. You could take a share of stock and cut it into divisible slices. The portfolio demand schedules are restricted to be downward slopings. They're piecewise linear demands.
01:01:33.580 - 01:02:06.650, Speaker A: The utility for each order is only defined on the line segment corresponding to that specific portfolio. So it's not really your utility is zero off diagonal. It's not defined off the diagonal. All the quantities are bounded. And then the key limitation of the language to Tim's question is I can't link what happens in this order to my preferences in that order. So I can't, for example, say, buy whichever of Apple or Google has a better price in the next batch relative to my value. I could say I want to buy a portfolio of half an Apple and half a Google.
01:02:06.650 - 01:02:33.468, Speaker A: I only want to buy it if the portfolio is this price or lower. But I can't say buy me whichever of these two is more attractive given my preferences. So there are limits on what I can express with this language. And as you think about it, like, oh, there's some real things you can express and then there's some limits. So we think of this as hopefully a sweet spot. This is the conversation Tim and I were having a few moments ago. We can compute prices quickly using what are called interior point methods.
01:02:33.468 - 01:03:11.736, Speaker A: Let me skip the details because I'm already over time. Let me pose a couple open topics that I think connect this whole agenda to some topics in crypto. Put those up and then I'm happy to chat as long as you have questions or over coffee about anything you like. So here are a couple of research topics I'd love to see in crypto markets that relate to this agenda, and financial exchange design and high frequency trading. So first of all quantification. So someone should do the study we did with the UK data for crypto markets. And I bet you you'd find that Sniping is a massive percentage of volume and a massive tax on trading.
01:03:11.736 - 01:03:55.524, Speaker A: We're talking at lunch about how there's mev that relates to the reordering of transactions within a batch, which is kind of crazy that you can do that in a financial market. Like just, well, I'm going to rearrange your orders to extract value from the traders. Whoever thought of that? It's kind of an evil genius, very clever. And then also you can quantify it as a percentage tax on trading and I bet you that would be large too. We found half a basis point. I bet you it's much larger in crypto markets. And I should have said there's the reordering and then there's also just the price on coinbase changes and that leads to Sniping on uniswap.
01:03:55.524 - 01:04:31.560, Speaker A: I bet you that's massive too. So a lot of information design questions and information policy of exchanges that I think would be very interesting to study as I alluded to Reg, NMS and the US stock market engineers, this very brutal price competition. It's very efficient for the market. It limits the magnitude of within stock arbitrage. Crypto markets don't have these limits that might be a good way to study these matters of information policy. So I think that would be a great study to do. And as a result also, I bet there's lots of within symbol arbitrage.
01:04:31.560 - 01:05:41.630, Speaker A: And then the last couple of studies I'd point to, so one is implementing frequent batch auctions in crypto markets. I've been a technical advisor to cowswap and they're doing a multi asset batch auction exchange. It's kind of inspired by the flow trading paper, a difficulty they face, and I think crypto markets face more generally is a kind of philosophical one of a lot of auction design takes advantage of quasilinear preferences over stuff and money. Money is a numerator good like the US dollar, but crypto markets are hesitant to declare a numerator good because I'm not going to get into the philosophical debates, but it makes the math a lot harder. And then they have this kind of decentralized solver competition which I think is kind of creative. I think that's interesting to think through the economics for a centralized exchange, adopting FBAS and whether they face these kind of will the market fix the market perverse incentives. And then there's a lot of research around minor extractable value that I think is very interesting to study, very similar to the data and colocation economics we study in the will the market fix the market paper.
01:05:41.630 - 01:06:19.716, Speaker A: There's the quantification of the dollars and the tax, there's the question around exchange design to counter mev. So FBAS would certainly do it. I wonder if there are other complementary ideas. And I think a really interesting open question is protocol design to counter mev? The fact that you can rearrange transactions in time to steal or extract money from the transactions is sort of crazy. It'd be really interesting to think about a protocol at a more abstract level than just finance that solves the mev problem. Let me stop there. Thank you for your time and attention.
01:06:19.716 - 01:06:22.344, Speaker A: Glad to chat further or take any questions you have.
01:06:22.382 - 01:06:35.132, Speaker D: Thank you for the flow trading. You have to eventually approximate prices down to like a penny, right? Does that approximation of the optimum lead to issues?
01:06:35.266 - 01:07:10.650, Speaker A: So you said like a penny, as if a penny is small. In financial markets, a penny is large and we can get prices down to on the order of millions of pennies. And so then economically it's not very important. And then computationally, no computation. It's not a hard computational issue either. But it is important just to I went through this very quickly. It is important in the if you think about how stock markets work, my critique is of the time being continuous and I want time to be discrete instead.
01:07:10.650 - 01:07:53.476, Speaker A: Another critique, and this is more impedent, Mina's prior work is that another issue is that prices are very discreet. Prices come, for example, in the US stock market, in pennies and it would solve a lot of issues if it would simplify a lot of complexities if prices were more continuous. So the flow trading idea is kind of flipping the sign on both of those. Instead of time continuous, prices discrete, we have time discrete and prices continuous also quantities continuous. And practically you could I mean, it would take some regulatory action, but practically you could easily trade millions of shares in millions of pennies.
01:07:53.588 - 01:07:59.288, Speaker D: Would that mean like, the banks would have to settle trades at millions of.
01:07:59.294 - 01:08:24.058, Speaker A: Pennies of the yeah, that's just not hard because banks are really good at multiplying numbers together and then rounding. At the end of the day, if you round to the nearest penny, no one's doing the Superman scam. That's going to be fine. Yes.
01:08:24.224 - 01:08:55.382, Speaker B: So on the first point, I forget the details of everything about how cowswap works, but you mentioned two things already that are important. One is using a different mechanism by using the sort of batch clearing. Another is the competition, which I assume is important. But then also this kind of isn't there like a different information hiding? Isn't stuff like not going through the public mem pool instead this kind of being hidden from other people to see. So I was curious, what do you think is driving which of these is the most important?
01:08:55.436 - 01:09:21.786, Speaker A: Do you think that's a great question. Yeah. So cowswap again, I've been a technical advisor to them. Again, if you put orders in the mem pool, that's very snipable. They're trying to avoid that. Thank you for bringing that up. So they have this multi asset batch auction design, which I think is pretty clever.
01:09:21.786 - 01:10:48.274, Speaker A: The solver competition idea is because it's part philosophical, and it's part practical, which is that the philosophical is, well, you don't want to have a centralized authority saying what the prices are, which to me, I have a philosophy major from undergraduate. I philosophically disagree with that, but that's okay. I have nothing against exchanges saying what the price is as a function of clear rules. But the more practical difficulty is that a lot of the pricing data is external to cowswap because it's pretty small. So a lot of batches are found by taking some orders that come into cowswap and combining them with orders or liquidity on other exchanges and kind of doing a grand batch, if you will, between cowswap and uniswap SushiSwap all the other swaps out there. So the solver competition is a way of taking inside information and external information where, computationally, it'd be hard to design the exchange that takes in all of the external information without, like, a reg and a mess that says what the external information has to report to you. So the solver competition is a way of dealing with that incompleteness.
01:10:48.274 - 01:11:17.520, Speaker A: So you can imagine Kaustlav saying, here's the best exchange only trade. And if you can do better than that, bringing in external liquidity, that's the solver competition. And that's, in effect, what they're doing with some we call them envy freeness constraints. It's a pretty neat design. I don't want to get into a plug. I want to plug my own research. It doesn't feel appropriate for me to plug cowswap, but I really like what they're doing.
01:11:17.520 - 01:11:19.660, Speaker A: All right. Thank you.

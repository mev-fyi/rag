00:00:10.730 - 00:00:45.670, Speaker A: Hi. I'm really happy to be here, get to know all of you. Yeah. So this talk is about zero knowledge proofs. So I'm going to start with what are they? Yeah, so I thought I'd start with so ish. Our head of community and social asked a bunch of us from the research and engineering teams recently to explain zero knowledge proofs in one tweet to someone new to the Web Three space. And I thought I would start by mentioning some context, which is that in the Web Three space, in particular, the term zero knowledge has been overloaded.
00:00:45.670 - 00:01:13.778, Speaker A: So in a precise sense, zero knowledge refers only to a certain privacy property. But people often use the term, especially in the Web Three space, to refer also to performance properties of zero knowledge proof systems that many of them happen to have. So zero knowledge, it's really a misnomer, it should only refer to the privacy property, not to the performance properties. So the tweets all had to sort of grapple with this. So. Sam Ragsdale. Tweet was first.
00:01:13.778 - 00:02:02.514, Speaker A: So he said a zero knowledge proof mathematically demonstrates to a third party, typically called the Verifier, that you've done a computation honestly without revealing the details nor requiring recomputation. Okay, so that property not requiring recomputation, that is a performance property. So that says the Verifier is really fast. Technically, that's not what zero knowledge refers to. What zero knowledge does refer to is Sam's phrase not revealing the details. So in fact, of course, if you're proving to somebody that you did a computation correctly, that someone does have to know exactly what computation you're claiming to have done correctly because if you did even one step wrong, your proof should be rejected. Right.
00:02:02.514 - 00:02:42.670, Speaker A: So when Sam says not revealing the details, he doesn't mean the computation I'm claiming to have run is not fully known to you. No, the Verifier knows the computation. There are certain other details that zero knowledge says the proof will not reveal. So we'll try to clarify that through the remaining tweets and then I have a whole presentation to clarify the issue. Okay, so then Joe Bono colleague on the research team says ZK proofs are essential for Web Three because they allow us to ensure correctness while maintaining privacy. For example, we might prove that a financial transaction is genuine while not revealing who paid whom or how much. Okay, so Joe is really focusing here on the privacy aspect.
00:02:42.670 - 00:03:31.760, Speaker A: I think it's really hard in the tweet, so it might not be clear why it would be useful to show that a financial transaction is genuine without revealing who paid whom or how much. So hopefully I'll try to clarify that moving forward. But now we're getting towards details of what zero knowledge really means. So what's being revealed and what's being hidden by the proof. Okay, so Lara, who's speaking tomorrow? Another colleague from the research team said ZK proofs and blockchains are typically used for statements like this, I'm entitled to authorize action F because I hold a secret that satisfies requirements R without telling anybody the secret. Okay, so this is actually very close to how I think about zero knowledge. So the property zero knowledge means the prover is proving to know some secret information.
00:03:31.760 - 00:04:30.580, Speaker A: He wants to prove he knows the information, but he doesn't want to actually reveal anything about the secret to the Verifier other than, of course, that he knows it. Okay, so then I was the final tweet, so I specifically sort of broke things up into this privacy aspect, which the term zero knowledge really refers to, and the scalability or performance aspects, which the term zero knowledge does not actually refer to, even though people use it to refer to both, which is confusing. Okay, so in terms of scalability, these zero knowledge proofs often have the property that I can prove. I did a hard computation on some data, so the blockchain, for example, the Verifier doesn't have to do the hard work itself or store the data. So this is what Sam was getting at in his first tweet, saying the verifying the proof doesn't require re execution. It's saving the verifier work. So scalability is all about using the zero knowledge proof to make the prover do some hard work so the Verifier doesn't have to do the hard work itself.
00:04:30.580 - 00:05:16.618, Speaker A: Okay, now we get to the privacy property, which is what zero knowledge really refers to. And the classic Web Three application is I can prove I put some amount of money into a mixing pool without revealing the deposit transaction that was mine. So the people taking the money out of the pool kind of can't be linked to which entity they were when putting the money in. That's why it's called a mixing pool. You kind of can't tell. You can't link money going in, the money going out. Okay, so those are four tweets, but since I have a talk, I can actually give you definitions, and I think it's useful to see both, like, the 180 characters or whatever it is version and then the full slide and talk version.
00:05:16.618 - 00:06:08.318, Speaker A: So I'm going to start with what is a zero knowledge proof in a slide, and we'll talk about what are people using them for today. I'll tell you a little bit about how they perform today, and that'll be enough information to start to understand the public discourse around zero knowledge proofs and how they're being deployed today, which actually can be fairly challenging. There's a lot of context that if you don't have it going in the conversation, I think gets very confusing. So that's one of the main goals I have to sort of impart how to like the right context, understand the conversation as people discuss this technology. And finally, I'll give some predictions for the future. Okay, so let's start with the talk version of what is a zero knowledge proof and Snarks and I'll say what a Snark is kind of a funny acronym. Snark is really referring to things like performance, and zero knowledge is referring to privacy.
00:06:08.318 - 00:06:57.026, Speaker A: And people just lump everything together today as zero knowledge proofs, which can get confusing. Okay, so my first slide here is on the zero knowledge, the privacy part, and I like to explain what zero knowledge means when I give a talk through an example. So imagine Alice controls some bitcoin wallet and wants to prove to Bob that she actually controls the wallet. So the trivial way to prove this is she could reveal her private key to Bob. Think of the private key as like the password to the wallet, but then, of course, Bob controls the wallet, too. So this is like a totally valid proof that Alice controls the wallet, but she doesn't want to use that. Okay, so what a zero knowledge proof will let Alice do is the exact same thing.
00:06:57.026 - 00:07:27.078, Speaker A: She'll convince Bob she controls the wallet, but Bob will learn nothing about her password, about her private key. And that's what zero knowledge know. Alice is claiming here to know a certain piece of secret information. We often call that piece of information the witness. And a zero knowledge proof will convince somebody that Alice does know that secret, but it revealed nothing about the secret other than that she knows it. Cool. Okay, so that's zero knowledge.
00:07:27.078 - 00:08:17.210, Speaker A: Now we'll talk about Snarks, which is an acronym referring to the performance of the proof system. Okay, so now the idea is know alice once again is proving to know some secret information. And again, the trivial proof system here would be to just send the secret information to Bob or to the Verifier, who can just directly check that the witness is valid it satisfies the property Alice is claiming it does. It actually is the password to the Bitcoin wallet or something like that. Okay, so A Snark, which stands for Succinct. Non Interactive Argument on Knowledge. It just achieves the same effect of convincing the Verifier that the prover knows the secret information, but it's less expensive for the Verifier.
00:08:17.210 - 00:09:17.600, Speaker A: So zero knowledge is about not leaking the secret information to the Verifier, and Snarks are about saving the Verifier time and communication relative to checking the secret information directly. Okay, so Snarks on their own don't care whether the Verifier winds up learning stuff about the secret or not. It's all about how efficient is the Verifier. Okay, so Succinct means that the proof should be short, and typically it also means that they should be fast to check. So at a minimum, they should be shorter than just sending the entire witness to the Verifier, which is like kind of the trivial baseline. The prover can always just send the information it claims to know to the Verifier. And ideally, checking the validity of the Snark proof will be significantly faster than just checking if Alice actually sent her password checking that the password indeed controls the wallet in that example.
00:09:17.600 - 00:10:12.606, Speaker A: Okay, this is really important part of the talk to kind of stop and see if there are any questions. If there are, the microphone would be great to use. But does this make sense? Does anyone want to ask for clarification? Yeah, I'll repeat the question. Great. Okay, so the question was, what is the difference between zero knowledge proofs that I've described so far and public and private key encryption? And the question specifically, I believe, focused on an application where if I want to prove to somebody that I possess a private key corresponding to a public key, then I can just sign a message. Yeah. So that would be an example of a valid proof for that particular application.
00:10:12.606 - 00:10:59.198, Speaker A: It would be. So the application of I know the password to a bitcoin wallet, which is another way of saying I know a private key corresponding to a public key is a very specific one where you don't need the full power of snarks. So the revolution over the last ten years in snark design has been especially in obtaining efficient snarks that can prove any statement. And we'll talk more about how the workflow works, where you write a program that checks the witness and the prover, uses the program to kind of prove it correctly applied the program to a witness. Yeah. So in very particular applications, such as the one you just asked about, you don't need the full power of a general purpose snark. You can tailor one specifically to that application.
00:10:59.198 - 00:11:24.630, Speaker A: They can be much simpler. Then there's another question. I'll repeat the question. So go ahead. Yeah, so the question is, what is the witness W in general? What data type? What's an example? So it varies wildly by application. In this little example, which it's a real example, but it's also simple enough, I could call it a toy. It would be very useful.
00:11:24.630 - 00:12:08.920, Speaker A: W would just be the secret key. It'd be alice's secret key. It'd be her password in something like what people call a ZK roll up, even though many of them are not actually zero knowledge. The witness would be a whole bunch of blockchain transactions, each of which has been signed to represent that they've been authorized by the owner of the wallet that the transaction is originating from. And you can go through application after application, and it's always just the proverbs claiming to know some information, and the witness is just that information. So it's very hard to say, oh, it's like this data type, it's an array of integers in cryptographic applications, it's often just secret keys or, I don't know, 256 bytes or something. Often.
00:12:08.920 - 00:13:01.414, Speaker A: Anyway, more questions. The question was, can I talk about the cost of snarks at a high level? The verification tends to be relatively cheap, which is why we can run the snark verifier on a blockchain in many settings, although there is significant variation in just how cheap the Verifier can be. So the bottleneck tends to be proving costs. Bottleneck, in terms of how complicated a statement can we actually use a Snark for today? And there are a lot of these costs that are relevant from runtime to memory usage. Yeah, I'll say much more about that. If our Snark is zero knowledge, we should append the letter ZK to the front of Snark to indicate that. So a ZK Snark is a zero knowledge one.
00:13:01.414 - 00:13:43.090, Speaker A: But a Snark by itself doesn't have to be zero knowledge at all. It can reveal information about the witness to the Verifier. Okay, yeah. So let me just briefly summarize things that Snarks are used for today, but I think they're going to be used for a lot more stuff in the future. So maybe the most prominent application today is L two roll ups, validity roll ups. And I did mention this in response to one of the questions recently. Like here, the idea is that in order to keep both work and data off the blockchain, you're going to try to kind of keep as many transactions as possible on an L two.
00:13:43.090 - 00:14:52.870, Speaker A: Layer two and the layer two will prove to the layer one blockchain, like Ethereum, that a bunch of signed, valid transactions were processed on the layer two. And the layer one blockchain will kind of not have to directly process those transactions itself. And this is important because any data that we store on the layer one blockchain or any work that the layer one blockchain does well, that has to be replicated over and over again by every blockchain node in the world for that layer one. So we're kind of just treating the layer one as a very sort of limited computation, limited verifier that we'd much rather just kind of have verify proofs that the layer two correctly process transactions rather than have the layer one blockchain actually verify all the transactions directly. And I'll say more about this soon. So we're also now seeing the emergence of bridges between blockchains based on Snark technology. You start proving things like you prove to the bridge or the bridge proves to the blockchain.
00:14:52.870 - 00:15:35.750, Speaker A: Like, I correctly ran a lite client for blockchain one that locked a bunch of funds, so now it's okay to sort of use those funds on the other blockchain, something like that. So there are a lot of bridges that do not use Snarks, but we're starting to see more and more bridges that do. Okay. We also see privacy focused blockchains. So, yeah, even though the validity roll ups from two slides ago are often called ZK roll ups, the ones I put on that slide are not today ZK. They're not privacy focused. So on this slide, we have just a small sampling of projects that are privacy focused.
00:15:35.750 - 00:16:59.780, Speaker A: So the idea is that people can transact on the blockchain, and if you don't use zero knowledge proofs today, it's essentially like just having your entire bank account public for the whole world to see. It might be pseudonymous where it's not your government given name associated with your accounts, but it's known that it's not too difficult to link real world entities to these accounts. And so it really is like just having your entire blockchain public for the whole world to see every time you transact. So with these zero knowledge proofs, you can still manage to transact while keeping a lot of your personal information secret, essentially. Okay, so in a little bit bigger picture, I think eventually these Snarks, ZK or otherwise, will start to become public infrastructure the way today's encryption algorithms are. So just as today's public key encryption algorithms were once like state of the art cryptography that enabled the ecommerce commerce revolution, snarks are just very advanced cryptography, and eventually they'll just be sort of old hat. The way you go onto Amazon today and buy something and you don't think about it, the cryptography just works.
00:16:59.780 - 00:17:27.980, Speaker A: In fact, a lot of vendors who are it's not just the users of these e commerce sites who don't know anything about cryptography. A lot of the vendors also don't have cryptographers on staff. Everything just works. It's public infrastructure, essentially. And there are obviously companies in the ecosystem that are making money somehow off of this, I'm sure, but everything just works. No one really thinks about it. No one has to know the details of just how performative the encryption algorithm is.
00:17:27.980 - 00:18:03.910, Speaker A: Is it really secure? No one has to think about that. I don't think we're there today with Snarks, but I think we'll eventually get there. So, yeah, I think the issues today are these things are just not performative enough quite yet, and they're not easy enough to use that. I think any startup in the space should know something about these. I think the two key things to try to learn a little bit about are their performance. So you have a sense of if you want to use a Snark, like what is reasonable to try to use it for and what isn't today. And unfortunately, I think you should also know about their security.
00:18:03.910 - 00:18:54.600, Speaker A: So I'll say a little bit about that as well. Okay, so just as a quick checklist for when you definitely should care about Snarks, and even if you don't meet any elements of this checklist, I think it doesn't hurt to know something about them anyway. But if you care about privacy for your users, or you want lower transaction fees, both relative to just posting raw transactions to L one, you're going to need to know something about Snarks. If nothing else. You're going to need to know what ZK roll up to use if you're privacy focused, I really mean ZK roll up in the precise sense. And if you only care about scalability, I mean, validity roll up. And probably at some point, most startups in the space that are active on the blockchain, there are transactions, will care about at least one of these two things.
00:18:54.600 - 00:20:10.874, Speaker A: Now these Snarks are also essentially just getting built into the blockchain infrastructure, okay? So if you care about the blockchain infrastructure, you're going to have to know a little bit about Snarks for that reason. So for example, as cross chain bridges start to get built based on Snarks, which we're starting to see now, if you want to move assets between blockchains, you should probably know a little bit about how these bridges work. And also Ethereum itself with upcoming EIPS are going to build at least some components of some Snarks into the base layer itself. So in protodank Sharding there's something called KZG commitments, which a lot of Snarks use, not all Snarks. And protodank Sharding will use these KZG commitments for something called data availability. Sampling the details, I guess, aren't super important for this talk, but perhaps you've heard that Ethereum itself is sort of running a massive trusted setup with thousands of participants over several months and this is what they're using it for. So they're trying to kind of allow, they call them Blobs, like more data to get kind of posted on chain.
00:20:10.874 - 00:20:53.280, Speaker A: And that creates issues that they are then trying to address using some components of Snarks at the base layer. Right? So it's the same sort of thing that I mentioned before about how eventually this will all be public infrastructure. It's like when you use the Internet, you don't need to know how TCP IP works, but you are using it every day. And these Snarks or components of them, are actually getting built into the Internet of Web Three, namely the base layer. L one blockchains. Okay? And then finally, a lot of businesses will just want to use Snarks just because of the idiosyncrasies of their business. I mean, just as one example and I'll give more later.
00:20:53.280 - 00:22:00.514, Speaker A: Yeah, I mean anything that involves off chain computation by untrusted parties. So I think over time, every day we see new advances in AI and it's becoming clear and clear that it's going to transform society in unpredictable ways. And right now those models and the ability to train those models are gated by a handful of entities. And I think one of the use cases of Web Three that at least excites me is to kind of ungate these resources that will be clearly essential to society and cause significant disruption moving forward. Like the entities that currently control this infrastructure, they are subject to their own incentives. The public does not control their decisions and they might be acting in entirely good faith, but they just have different incentives than everyone else. So just as an example in that application, the whole point is that a lot of hard computation is going to be done.
00:22:00.514 - 00:23:00.920, Speaker A: That's the whole point of cloud computing. And in a decentralized world you don't actually trust whoever is doing that. Computing, even if it's your idle GPU on your laptop. So that's just a setting where it's very clear a lot of difficult computation is going to be done by entities we don't trust but would like to work with, right? So these snarks are going to be essential for allowing people who don't trust each other to work together anyway, especially when a lot of hard computation is getting done. Okay, so I think there are tons of reasons everyone should care about Snarks at least a little bit to know at least about a 1 hour presentation's worth. So that'll be my goal today, is just to try to convey what I think every startup in the space should know. So let me start with just Ballpark sense of how these things perform today, with the main goal being to know kind of what would be reasonable to try to use a snark for today and what wouldn't be.
00:23:00.920 - 00:23:31.402, Speaker A: Okay. So generally, as I previously mentioned, the verifier is cheap. In particular, significantly cheaper than kind of the trivial verifier that would directly take the witness the prover claims to know and check it for correctness. So that's good. These Snarks are just completely useless if verification is not cheaper than the trivial approach. So that's good. As I mentioned before, there is still significant variation in the cost of Snark verifiers.
00:23:31.402 - 00:24:34.226, Speaker A: So, for example, plank proofs, when verified on ethereum today, cost about 300,000 gas. And another kind of snark proof called Starks, they take 11 million gas today. This is a bit of a moving target because the security level of the proof systems has been increasing and for some of them that causes the gas cost to go up, and for others it doesn't really. So in terms of applicability, in general, the bottleneck tends to be the prover performance. And my rule of thumb is that the prover today in general is always going to be at least six orders of magnitude slower than just directly checking a witness for validity. Now, for particular applications, it can be way less than that. For very structured correctness checks, this million fold slowdown for the prover to actually prove that it did something correctly won't come up.
00:24:34.226 - 00:25:20.194, Speaker A: It won't be that bad, at least. But in general, if you don't tell me anything about the statement the prover is going to claim, you're going to have to factor in at least a million fold slowdown. And one nice thing about this million fold slowdown is it's entirely parallelizable. So you can just throw GPUs at it and if you have enough GPUs, it'll eat up that entire million fold overhead. But you did just pay a million times more total work. So at some point, depending on how ambitious you are in terms of the statement, you're asking the prover to prove that ten to the six slowdown is untenable. Fortunately, in a lot of blockchain applications like roll ups, the statements the prover is proving are, in a cosmic sense, pretty simple.
00:25:20.194 - 00:25:57.040, Speaker A: I mean, they can still kind of push the limits of what we can handle today. But proving I know a bunch of valid blockchain transactions that have all been authorized with digital signatures is ultimately a pretty simple statement, right? Like proving, like, I ran this cloud computing computation that would have cost $50 to run on Amazon because it killed a cluster for an hour or something. I mean, that's another thing entirely. It's just night and day. So this million fold slowdown. While Snarks have come a long way in their performance in the last ten years or so, you can't just ignore it and say, oh, we were there. It's not even close to that.
00:25:57.040 - 00:26:55.834, Speaker A: Okay? And there are endless more subtle in the weeds issues, especially as you compare different Snarks to each other in terms of their security properties. And can you have the prover produce a bunch of proofs but not post every individual proof to the L one? Rather just aggregate the proofs down into a single proof so you can spend many, many years studying this stuff and still not have it all clear in your head. Like, there's so many different things people care about and axes on which to compare these protocols. But this slide kind of covers the high points in terms of approver time and verifier time. There's a lot more details about the performance characteristics of Snarks in this a 16 z blog post, which we can distribute if there's interest in that. Okay, so I want to now give a sense of just how Snarks work. I often get the question, hey, I want to use a Snark.
00:26:55.834 - 00:28:03.190, Speaker A: I don't know anything about them though, like, how do I get up and running with a Snark? And that's really a question about just what is the existing tooling today. And so I'm going to tell you a little bit about how to think about that tooling and both its strengths and limitations. Okay? Before I tell you about the tooling, I want to tell you how I like to think about Snark design. And this is a little bit aspirational what I'm about to tell you because the tooling isn't quite there yet today. There's no fundamental thing keeping the tooling from achieving this. But aspirationally we'd like a developer to start by writing a computer program in a high level language, whatever they like rust, C, python, who cares? And this computer program you should think of as taking as input the witness that the prover is claiming to know and checking that the witness is correct. So in this simple example that I had before about Alice claims to control a bitcoin wallet, this computer program would take as input her password, her private key, and check that indeed the private key controls the wallet.
00:28:03.190 - 00:28:50.418, Speaker A: Okay? Now, in order to use a Snark for the prover to prove that it knows this witness, kind of the development process would proceed in two steps. Ideally, the following two steps would be hidden from the developer, right? The developer just writes the computer program, and the developer is done. Okay? So the first step is these Snarks need to use something called an intermediate representation. It's kind of just like a very, very low level way of expressing the computer program. So you have to take the computer program written in a very high level language, which is nice to program in, and turn it into kind of the world's lowest level language. It's kind of like even lower level than the assembly code on your laptop or something. So this is something called a circuit or generalizations of circuits.
00:28:50.418 - 00:29:48.162, Speaker A: We just call them intermediate representations in general. And that procedure to go from the computer program written in, say, rust or python or something, to the circuit is called a front end. Okay? And in general, there's already a lot of performance overhead just in kind of that step because the circuits are like a pretty awkward way to represent a computation. Your laptop has a bunch of native instructions built in that it can do in like one step, one machine step that are pretty gross to do inside a circuit, the kinds of circuits we use in Snarks. Okay? And then after you kind of identify the circuit, you apply what's called a back end to the circuit. That allows the prover to prove basically that it correctly evaluated the circuit on the witness. And because the circuit was equivalent to the computer program, like evaluating the circuit on the witness is equivalent to running the computer program on the witness.
00:29:48.162 - 00:30:25.966, Speaker A: And the computer program, its whole point was to check that the witness satisfied the properties the approver claimed it did. So you sort of put these two steps together and you have your Snark. So together the prover is proving, hey, I know this witness that this computer program would have accepted as valid. The Snark is kind of the combination of the front end that spits out the circuit and the back end that proves the prover evaluated the circuit correctly. So you have your rust program. The front end spits out the circuit. The back end allows the prover to prove that it actually knows what we call a satisfying assignment to the circuit.
00:30:25.966 - 00:30:47.980, Speaker A: Any questions? Okay. Oh, yeah. Question. So the question was sort of if the dev only writes the high level program, kind of what's handling the front end and the back end? I guess. Yeah. And the idea is that that will ultimately just be a completely automated process like the Zkevms today. Maybe a little easier application to talk about.
00:30:47.980 - 00:31:22.802, Speaker A: They want the developers to just write smart contracts if Zkevms want it in solidity or something like that. Other projects will have their own domain specific languages. And that's it then sort of the company or has developed the infrastructure to apply the front end. And then feed the resulting circuit through a back end. And then the smart contract, like the roll up smart contract on L One will be running just the Verifier to verify kind of the back end proof. Yeah. So just a brief summary of existing tooling.
00:31:22.802 - 00:32:49.714, Speaker A: If you are a developer, so there's the question of how are you going to express your witness checking program? In what language are you going to express it in? And kind of once I tell you that, everything else is ideally hidden from the developer. Now, today the tooling is maybe not perfectly there where the front end and the back end, the developer just doesn't worry about them at all. There are really nice libraries that kind of make things as easy as they've been able to today, but there's definitely room for improvement. But in terms of how do people write their witness checking programs, so very popular but very low level languages for this are Bellman and Circom. So when people tell me today, hey, I want to deploy a Snark, I want to use Ethereum and I don't want to go write a smart contract on L Two or something, I just want to deploy a Snark directly on Ethereum or something like that, I say, well, can you write in a Circom circuit? No. Can you hire someone who can? People really like writing in Bellman and Circom, but it's almost like writing the circuit kind of gate by gate, so it's almost like not a front end. I don't want to get too overboard in terms of how low level these languages are, but they're pretty low level.
00:32:49.714 - 00:33:35.646, Speaker A: It's like you have to be comfortable kind of almost directly programming a circuit. A bunch of projects have kind of higher level languages but still assembly like. So definitely lower level than probably what anyone in the room is used to programming in, unless you're already designing Snarks yourselves. So a prominent example here is Cairo from Starkware. So this is an assembly like programming language that I hear is like a really nice experience to write in, but again, it's a much lower level language than Rust or Python or something. And there are also, like Snark specific issues that the programmer in some of these languages needs to be aware of. For example, the Snarks all use something called a finite field.
00:33:35.646 - 00:34:25.578, Speaker A: So if you multiply a bunch of numbers together and the number just gets too big, the number will kind of wrap around like an overflow issue. And the programmer for Cairo, I believe, today, still just needs to be aware of that. Like that tracking that is pushed onto the programmer, for example. And there are steps, and this is where I think things will get better quickly towards letting developers program in even higher level languages. I'll just mention one project which is nice is RISC. Zero is a project that is aiming basically to be a front end for something called the RISC Five instruction set, which is an instruction set that actually came from the computer architecture community, was not developed by cryptographers or anything. And there's a large kind of ecosystem today of tooling to turn higher level programs into RISC Five programs.
00:34:25.578 - 00:35:38.054, Speaker A: And once you do that, the idea is you could then feed the risk Five program through risk zero. We'll handle the remaining kind of front end and back end work and of course, all the Zkevm projects. They want to let the developer just write in solidity like Ethereum developers are comfortable with today and not worry about how the front end and the back end are working. So I think there's nothing fundamental standing in the way of the tooling supporting higher level languages that people are more used to than these new domain specific languages like Cairo and Leo and noor, but it's not there today. Okay, any questions about this? Okay, the question is, are you trying to distill what gets kind of presented to the L One down to kind of the minimum possible information just to keep that information and work off L One there? I'd say yes. You're basically trying to prove to the L One that you did something, that something is always, like, just processed a bunch of blockchain transactions correctly. And all that the L One cares about is confirming that you did that.
00:35:38.054 - 00:36:39.834, Speaker A: It doesn't actually care what was in the transactions, just that you handled everything right. So, yeah, that's what the proofs are showing. It's just that all of those transactions were checked correctly and applied to advance the state of the blockchain correctly. And the proof itself doesn't inherently need to contain any information about those transactions. Now, there's a big discussion to be had about data availability, and which is if you're not posting the raw transactions or at least the state updates to the blockchain, anyone in the world who wants to be able to transact does need access to that data. So where does that data live? And people are either storing that today in what's called call data, which is like semi on chain, but they're also trying to move to things like data availability committees that will keep the data completely off chain. But the proof itself, if we ignore data availability, the proof can contain basically no information at all.
00:36:39.834 - 00:37:35.230, Speaker A: In fact, if it's zero knowledge, that's the whole point. It shouldn't contain any information other than I processed a bunch of transactions correctly, and it kind of advanced the state of the blockchain from A to B. And let's not worry about where the information about what even is state B gets stored. In the Zkevm, does the witness include the computation itself? So the term witness refers to the data that the prover is claiming to know. Checking the data is where any hard work to check that data is correct would kind of reside. So I always think in circuits I'm like in the weeds designing the snarks. It's like the witness is the secret information, but the circuit itself is kind of like extra work the circuit does is just as bad for the Snark prover as making the witness bigger.
00:37:35.230 - 00:38:03.750, Speaker A: For the Snark prover, like witness elements and circuit gates are treated typically close to the same. There are some exceptions. Yeah. So the question is, I think the answer to your question is just like work rather than data. Should you call that part of the witness or not? I would say it's not part of the witness, but it all contributes to the proverbs work. And that's really the scalability bottleneck for these Snarks. Okay, so that's sort of a snapshot of the tooling ecosystem today.
00:38:03.750 - 00:38:54.278, Speaker A: And again, I think it's going to get real better real fast. And if you're interested in how the back ends of these snarks work and that's kind of where all the magic happens. Hopefully spitting out a blog post soon about that, that will kind of be my attempt at if you have 15 minutes to read and you want to know how all the magic happens, that'll be the goal. So I'll make sure to distribute that once it's finally ready. Yeah, but in this talk, I didn't want to focus into some very deep dive into exactly how snarks work, but more just how they perform and how to navigate the public discussion around them. Which is what I think. Is really important for startups in the space that might either directly use these snarks or be a customer of a company that is using these snarks or something like that.
00:38:54.278 - 00:39:47.720, Speaker A: Okay, so now I want to talk about how to navigate the public discussion. I think you now have enough context to I can discuss some of the subtle issues. And I sort of started looking carefully at the public discussion around Snarks in web three last summer when I was visiting a 16 Z and it was just very hard to understand what people were talking about. So I want to make it a little easier for everyone else and also just kind of flag some things to be aware of, some kind of things that can trip people up, I think. Okay, so let's start with these validity roll ups, these ZK roll ups with their discussion around their performance. Okay, so this was something that confused me a lot at the start. So I saw a bunch of these L two S talking about processing thousands of transactions per second, even 20,000 transactions per second.
00:39:47.720 - 00:40:25.570, Speaker A: And this did not make sense to me because I know roughly how fast these provers are. And the prover, unless I think with any reasonable computation resources, is not chewing through 20,000 transactions per second. So I asked some of the projects and the answer I got was referred. This is just not counting prover time. This is only counting the time it takes to upload a proof to the L One. Okay, so in a little more detail, there are two performance notions that I think are really important for a roll up. This is latency and throughput.
00:40:25.570 - 00:41:17.574, Speaker A: So latency is like the delay between when a transaction happens on the L Two and when a proof kind of capturing that transaction gets verified on L One. It's like a lag time, and their prover time does matter, right? Because if it takes the prover a week to produce that proof, that's a week of latency. Another big contributor to Latency Today, which might contribute much, much less in the future, is just waiting around for enough transactions to happen on the L Two, that the L Two is ready to start working on a proof. There are a couple of ways to deal with this. So one is just to get a lot more transactions on the L Two, so these batches are filling up really quickly. Another way is to use some other kinds of snarks that can kind of start working on the proof even before all the transactions are there, which I actually think the technology will move towards that soon. I'm a proponent of that.
00:41:17.574 - 00:42:08.582, Speaker A: This is something called incrementally verifiable computation, which is not really a focus, but anyway. So, yeah, two contributors to Latency, but throughput is talking about the number of L Two transactions that can be processed in a given amount of time by the roll up. It's a little subtle how these differ. So I think when these projects are talking about processing thousands of transactions per second, the idea is that there kind of would be continuously uploading proofs to the L One. It might take a while from when a transaction hits the L Two to one, a proof capturing that transaction is done being produced. But through pipelining, you can ensure that proofs are kind of continuously getting uploaded in steady state. This is not happening today.
00:42:08.582 - 00:42:47.890, Speaker A: This is kind of the vision for the future. So as far as throughput goes, prover time is not that important. What's important is just, like, how many transactions each proof is covering, and how long does it take the proof to get uploaded to l One. Right. I found this just kind of deeply confusing to start, so I think it's worth clarifying that. And it does make sense if you're talking about throughput and you're in this steady state situation. Throughput is really determined by just how quickly can proof data get uploaded to l One.
00:42:47.890 - 00:43:41.950, Speaker A: But again, if these proofs take a long time to produce, the latency will be high. So transaction per second is a measure of throughput, and it does not refer to latency at all. And there's actually kind of a direct tension between them, because the larger you allow the latency to be, the bigger you can let the batches of transactions be, because it's going to take the prover kind of longer to prove those batches. But you don't care because we're letting the latency be high. But the whole point of Snarks is the proof size grows very slowly with the statement being proven, the complicatedness of the statement being proven. So, yeah, the bigger the transactions, because these verification costs are kind of very sublinear, the better the throughput, the worse the latency. All right, so now I want to talk about security considerations.
00:43:41.950 - 00:44:49.366, Speaker A: So here's a quote from a document that an organization called the ZK Proof, okay? So this is kind of a community organization involving developers and researchers interested in the zero knowledge proof technology, interested ultimately in developing some standards so that it's a little easier to kind of compare proof systems and make them interoperate with each other and things like that. And there's a reference document that this community has produced, and it does have a quote about security that I want to share. It basically says, if you're just benchmarking a Snark, like in a paper or something to understand its performance, you should have the security level set to at least something called 128 bits. Actually says. Ideally, you'd go higher than that. I'll say a little bit in a second what 128 bits of security means, but it's just a measure of how secure is the Snark, okay? This is not what the Snark community is deploying their Snarks at today, not all of them anyway. So, for example, Starkware today, with its Starkx Dy DX roll up is at 80 bits of security.
00:44:49.366 - 00:45:49.162, Speaker A: Now, I'll tell you exactly what that means. It means that there's a known attack that if it performs two to the X hash evaluations and if you don't know what a hash evaluation is, don't worry about it will succeed in producing a convincing proof of any false statement with probability about two to the -80 plus X. So just to make that a little more clear, two to the 70 hash evaluations will get you success probability about one over 1002 to the 80 will get you success probability pretty close to one. Now, that is 100 trillion times faster getting success probability pretty close to one than the ZK Proof community reference document says should be achievable. And in fact, if you look at how many hashes the Bitcoin network as a whole does, it does two to the 80 hashes in under an hour. And the amount of block rewards in US. Dollar values for that less than an hour of hashing is well under a million dollars.
00:45:49.162 - 00:46:24.886, Speaker A: Okay? I mean, there's been enormous investment in Asics for Bitcoin hashing that there hasn't been for the hash functions used to protect these Snarks, these roll ups. But that just gives you a sense. I mean, the point is, 80 bits of security, in my opinion, is not enough. And the community has actually deployed Snarks at that security level for several years now. So I've been talking about this since last summer, and I'm actually really pleased Starkware has upped their other roll up. They call it the Stark. NAD and or Sharp prover from 80 to 96 bits, which is much better.
00:46:24.886 - 00:47:02.926, Speaker A: But today I think dYdX has over $300 million of total value locked. It's still at 80 bits of security. A lot of the other projects that are using similar proof systems, they're around 100 bits, which is that basically means the known attacks are not feasible. But if slightly better attacks were identified, it wouldn't take that big an improvement over the known attacks to be back in a worrisome situation. So I've been trying to kind of encourage the community to up the security level. This is all in terms of known attacks. Okay, so now I want to finish talking about yeah, so here's just a tweet.
00:47:02.926 - 00:47:29.814, Speaker A: Stark where saying they're going from 80 to 96 bits in their Sharp, their StarkNet roll up. Now I want to talk about bugs. So security flaws that the protocol designers are not aware of. Okay, so these Snarks, they're complicated, and that's why it's taken several years to develop these Eke EVMs. There's a lot of engineering involved. I've looked at the code bases. It's not pleasant.
00:47:29.814 - 00:48:00.920, Speaker A: There's a lot of security critical code that's not commented periodically vulnerabilities are found. This is not unexpected. I just want to highlight a couple. So Trellabits found an issue in a number of libraries that belief had been deployed last year. This was an issue with something called the Fiat Chamir transformation. What that is, isn't important. What is important is this was a known issue that has arisen over and over again over the years.
00:48:00.920 - 00:48:36.660, Speaker A: It affected something called the Helios proving system, I think like ten years ago. And then some voting system that a country had deployed, I forget which country had the same issue. So in my opinion, protocol designers should have been aware of this. It was known and library after library had exactly this issue. I think the issue might have stemmed from some academic papers. The academics are writing a paper and they're not expecting somebody to protect a billion dollars of assets with the little cold box they put in their paper and like one person looked at. But that kind of is what might have happened here.
00:48:36.660 - 00:49:09.366, Speaker A: Okay, here is another vulnerability. This is actually in the tornado cache. Smart contract. The main thing I want to highlight here is the vulnerability was actually in this Circom library. So people really like writing circuits, writing their front ends in Circom, and this was some issue in the library. Okay, so the point being that if the security bug is in some library, that everyone's using everyone's hosed. Okay, so actually Vitalik gave a talk at one of the recent Ethereum conferences, definitely in the last six months in Colombia.
00:49:09.366 - 00:49:55.046, Speaker A: He basically suggested that we should be deploying Snarks. We shouldn't just deploy one, we should deploy two or more. The reason being that he's sufficiently concerned that these will just have bugs. And the bugs will just mean that they're totally insecure that we should kind of have two or more so that you have to get kind of doubly unlucky or break both. But my personal opinion is going back to the Circom bug that's a library everyone uses. So these two Snark implementations are not likely to be totally independent of each other, so this might not actually help that much. And there is another recent proposal that suggested just using trusted hardware in addition to Snarks as sort of a Band Aid.
00:49:55.046 - 00:51:05.006, Speaker A: Until we're actually confident that the Snarks are bug free. I don't want to weigh in on what I think about these ideas. I just want to highlight, like the Ethereum Foundation itself is very aware that these are complicated code bases and likely to be buggy for a while and suggesting concrete steps to take as a result. As a result, I think anyone who is using those code bases, even as a customer, even if you're not interacting directly with them, unfortunately needs to be aware of this situation moving forward. It affects everyone. So that's just context that I wanted to cover. And yeah, I just briefly mentioned coming back to the question before about security, directly comparing the security of different Snarks is kind of impossible in the sense that you have to just list out all of the security assumptions, right? So some Snarks do not have a trusted setup, which means there's not some complicated people call it a ceremony, but where many different participants each kind of contribute to the generation of what's called a proving key structured reference string.
00:51:05.006 - 00:52:00.690, Speaker A: And if all of those participants kind of got together and they could reconstruct some secret and then kind of produce convincing proofs of false statements forever and ever. So trusted setups, like, are a security issue, but if you're like Ethereum and you run a trusted setup with 300,000 participants, I don't believe that all 300,000 people are going to get together and reconstruct the secret and go and counterfeit Zcash or something moving forward. I just mentioned Zcash because they had an issue with a trusted setup previously that would have allowed that. But yeah, on the other hand, then the trusted setup Snarks all use elliptic curves. So if you manage to break an elliptic curve based crypto system, you would break those Snarks. But we don't know how to do that today. I mean, all the cryptography everyone uses today is based on ellipticurves.
00:52:00.690 - 00:53:10.760, Speaker A: Once quantum computers come around, which might be another several decades, we'll have to switch from that because quantum computers can break elliptic curve cryptography. On the other hand, the Snarks that avoid trusted setups and avoid elliptic curve cryptography are getting deployed sometimes at a level where they're breakable today. So it's just very saying, oh, one is more secure than the other is just very difficult conversation to have. Personally, I am most concerned with known attacks today and having a little bit of wiggle room so that if those attacks improve a little bit, but there's not some complete break of the protocol that they're still secure, that's my personal view on how the conversation should kind of be framed most productively. So the systems that I've been a little bit critical of, essentially due to their avoidance of elliptic curve cryptography, which in general is good, because eventually we have to get rid of elliptic curve cryptography. They have this property that the more bits of security you want, the bigger the proofs have to get, which means the bigger the gas costs. Okay? It doesn't really affect the prover time, it affects verification time.
00:53:10.760 - 00:53:46.500, Speaker A: Now this gets a little more complicated as today people are using what's called Snark recursion or Snark composition, which sort of starts to intermingle, like verification time, improving time. Let's not get into that. So that's really the trade off. So when I gave a presentation this summer, the 80 bits of security Snark was at about 5 million gas per proof. And I was looking at the 96 bit of security version last night, it's up to like 11 million gas. But not all of that is attributable to the security increase. I think other things about the system must have changed too.
00:53:46.500 - 00:54:26.850, Speaker A: So really the gas costs just should have increased. Roughly 30% ish due to security, and then the rest must be just because other things are changing about the proof system. So that's really the tension in a nutshell is verification costs versus security level for that class of Snarks. That makes sense. Other questions. Okay, so the question is, what is the name of the known vulnerability? So this is something that comes up anytime you use something called the fiat Chamir transformation, which is a way to take an interactive protocol and make it non interactive. So, like, the Snark proof can just get posted on the blockchain for anyone to check at their leisure.
00:54:26.850 - 00:55:07.066, Speaker A: And the N in Snark means non interactive. And yeah, if you know anything about the fiat Chimera transformation, it all involves hashing. And essentially anything that might be under the control of the adversary needs to be hashed. And these proof systems were not hashing. Everything that might be under the control of the adversary in particular, they were probably not hashing. Some, I don't know for sure, but it's probably some analog of the statement being proven, something like that. So if the adversary can choose the statement being proven, the adversary could come up with some statements and the convincing proof for that statement.
00:55:07.066 - 00:55:52.270, Speaker A: Now, the statement might look like gibberish, but it's still like a false statement that it has a convincing proof for. So, yeah, it's kind of a weird sort of bug where you can have the bug and not necessarily get totally owned, but you don't want the adversary to produce convincing proofs of false statements, even if the statement that it's finding convincing proofs for is like kind of a nonsensical statement. It's still not something you want to be running the risk of. So somewhere on the slide, I think it has something about random forge proofs for random statements. Yeah. So they weren't hashing the statement being proven, so the adversary could kind of mess with the statement being proven to find a false statement and a proof for it. But the statement is just like a weird random statement.
00:55:52.270 - 00:56:20.438, Speaker A: It's nonetheless not a vulnerability we want in the system. Yeah. So people will call weak fiat chimere versus strong fiat chimere. That's what to look at. All right, so, yeah, let's talk about future applications of Snarks. So I'm not a particularly creative person, so I'm really just going to tell you things I've heard discussed as possible applications of Snarks that would be exciting. So I've already discussed kind of decentralized cloud computing, which I am personally excited about.
00:56:20.438 - 00:57:18.330, Speaker A: I think it's not great for society that kind of the resources that are going to underlie kind of the coming AI revolution or whatever are kind of currently gated by a handful of giant private companies. So I think that using Snarks, you could have the whole world be a cloud computer and kind of produce a Snark proof that all of the work it was hired to do, it's actually doing it correctly, as you go. In a similar vein, because a lot of what people use cloud computing for today is machine learning. I think people there's now a buz phrase, zkml ZK machine learning. So I think that will become much more efficient very quickly, kind of by exploiting special structure in the statements that are relevant to machine learning. This could unlock things like letting smart contracts make decisions based on data that is on chain. And so their decisions might actually change over time as the blockchain evolves.
00:57:18.330 - 00:58:05.350, Speaker A: Also just using the blockchain to perform learning in public so that this gets really powerful if people start signing their data, because then you can prove, hey, I trained up this model on some data set. I'm not going to tell you what the data set is, but I can prove to you that every piece of data in the data set was signed by some entity that's reasonably trustworthy. So you can kind of get privacy and learning happening at the same time. So I think getting people to sign their data is really powerful. Unlock for zero knowledge in a lot of settings, but especially learning. Okay. You can also imagine private biometrics to access accounts or establish identity.
00:58:05.350 - 00:59:01.014, Speaker A: In Estonia, I believe the government just issues digital ID cards, and then anyone could presumably go around and prove they're over 18 because they hold an ID card, and they can prove in zero knowledge that their ID card has been signed. And the message that was signed is some birth date that's more than 18 years ago or something. Like that. So digital identity is obviously a potentially impactful application that obviously does require potentially buy in from an authority to issue credentials to people. Okay, there's like a paper from 2015 on fast but untrusted hardware here in this paper. Anyway, the idea was there's only like four countries in the world that have state of the art foundries. And so any other country might not want to run security critical applications on a state of the art chip because they didn't have control of its manufacturing.
00:59:01.014 - 00:59:42.710, Speaker A: It could be vectored or something. So you could have the fast chip run the computation quickly and actually prove it did it correctly. You just have to run the Verifier on a chip you trust. So if the chip is much slower, it's okay because it's just the verification being done there. We're going to have a lot of issues with deep fake detection. So people have been looking at basically cameras signing images and then people proving that they obtained some image by editing a signed image in an authorized way or something like that. And we'll just see the injection of privacy into things where privacy is not today electronic money.
00:59:42.710 - 01:00:46.650, Speaker A: Obviously today you post your whole bank account publicly to the blockchain, right? So we talked about how you can use mixing pools and things to potentially avoid that. Of course, my personal view, this shouldn't be surprising, is the situation with blockchains today is vastly less private than kind of the Web two situation, because even though the Web Two situation does have all sorts of transactions are getting reported regularly to the government and what have you, at least your whole bank account isn't public. So I think without using zero knowledge to change the state of affairs, we sort of have an even much worse privacy situation today as we move towards distributed blockchains than we do with the centralized ecosystem. Yeah, and again, I'm not very creative. I just kind of designed these protocols. So I think there's all sorts of unlocks that are going to happen in the future and really interesting stuff to discuss. Question in the back.
01:00:46.650 - 01:01:42.078, Speaker A: So the question is, can I elaborate on getting data signed? So today there are already some devices that will just sign everything they produce, particularly with digital cameras, but I forget what they call it. Authenticated sensors or something. The idea is with Internet of things or something, we're just going to have all these sensors all around and maybe they'll be signing the data they produce. The idea is like some chip is getting grafted onto the sensor and so it's very difficult to tamper with the chip once it's there. And then the manufacturer should be throwing away the secret key as soon as it sticks the chip on the sensor. And in this way you get some amount of confidence that the data coming off the sensor was really produced by the sensor. But in general, it doesn't have.
01:01:42.078 - 01:02:20.966, Speaker A: To be sensors signing things. It could be just some institution that people think reasonably highly of and that has a reputation they want to protect, taking responsibility. And when it either puts out data sets or gives data sets to its customers or something, they're signed. And then anyone who has that data can prove that they ran whatever computation they want on some data set that's been signed. And what this avoids is the following situation. So let's say I ran a giant ML model on some giant data set and I want to prove to you I did everything correctly. Okay, but you don't know the data set.
01:02:20.966 - 01:02:57.540, Speaker A: We have a problem now because I can make up data, so you can build into the analysis like some sanity checks. Like if it's height data, you can make sure no one is 10ft tall. So you can build in sanity checks. But if the data isn't signed, it's still like how do you know that it's like real data? If it is signed, you know that whose ever signature is there authorized the data. So its legitimacy is sort of pushed onto whoever signed it. Without any signing. There's really nothing to stop somebody from making up data other than simple sanity checks to make sure it looks okay.
01:02:57.540 - 01:03:41.746, Speaker A: Yeah, so maybe I'd be very excited if anyone wants to talk about future applications because again, I mostly just listen to them and then repeat them. I work at in the weeds of designing the Snarks, not how they're used. Okay, so just wrapping up here, I can make some predictions for the future. So in terms of performance, let me just sort of remind you that today, I think in general there's a six order magnitude or more slowdown for the Prover compared to just checking a witness with no proof of correctness. Okay, so I think this is going to come down. I am optimistic about that. I actually think that maybe three of those orders of magnitude might disappear fairly soon.
01:03:41.746 - 01:04:35.640, Speaker A: I think maybe one might come from sort of better front ends, meaning smaller circuits. Another order of magnitude might come from better back ends, meaning once you tell me what the circuit is, the proof will just get faster to produce for that circuit. And then I think there's maybe another order magnitude or more from specialized hardware and so forth just building up better engineered systems and things like that. I do think that the techniques that achieve this, this is my very personal view, are not necessarily the techniques that people are deploying today. So I think people will have to remain flexible. Both the companies deploying the Snarks and any of their customers just should be prepared also for the transitional pains. I think no one should get too invested in a particular way of doing things today because I think it'll change.
01:04:35.640 - 01:05:29.218, Speaker A: Another major bottleneck for the prover today is just space requirements. And this thing I very briefly mentioned before called IVC incrementally verifiable computation. I'm very optimistic will not only let you do things like start processing a batch of data before the whole batch is sort of in, but it also should significantly reduce the prover memory requirements, which actually is one of the big bottlenecks today even more than prover time. Yeah. So I think performance improvements are coming. I think it's going to be a bit of an engineering challenge if they come from techniques that differ significantly from what people are doing today. Also, I think that a lot of the bottlenecks in what people are doing today in roll ups that are keeping the signatures off chain so that they don't have to pay the gas costs of putting those signatures on chain and verifying them on chain.
01:05:29.218 - 01:06:45.454, Speaker A: I think probably the bottleneck for the prover is just proving knowledge of digital signatures, which means you don't necessarily need like a completely general purpose Snark to improve the current bottleneck. You can just have a Snark that's very specific to proving knowledge of digital signatures. So I think we're going to see major improvements on that front, kind of more specialized kind of gadgets for the things people are doing today that are the bottleneck and they can sort of be added on to think of it as an ASIC or like a coprocessor that's helping out a general purpose CPU. So the things that are the bottlenecks kind of are handled by the special purpose stuff, but it doesn't restrict the generality of the whole thing because you have a general purpose CPU as well. I actually think that as society moves to post quantum secure cryptography and like the National Institute of Standards and Technology is trying to decide today, they're about to run a second competition for deciding what post quantum cryptography to use because a bunch of finalists from the first competition got broken, like within months of the competition ending. Lara will talk some about that tomorrow. I would actually like to see society kind of consider the snarkability of the primitives, especially the signature schemes, as they decide what to switch to.
01:06:45.454 - 01:07:17.974, Speaker A: This stuff is very sticky and once you sort of say, we're going to switch to this, it's like very hard to change that decision. This is probably a tough case to make because proving knowledge of digital signatures right now mainly just comes up in like ZK roll ups. Right. It's like most of society is not convinced that that is an essential application to have in mind as you make major decisions about what cryptography to use. But I think it is something that should be considered. Yeah. So just some commentary there then.
01:07:17.974 - 01:07:58.280, Speaker A: Finally, this is my last slide. I think that these things will get much more usable very soon. I think the tooling has some gaps in it today and it's not because of any fundamental technical issues that need to be solved. It's just we need more builders. We need more people who understand Snarks and hopefully they can make it the case that no one else in the world has to understand the Snarks. So I think we will see the ability of developers to program in high level languages that they're used to already, rather than learning domain specific languages that a lot of projects have developed. I don't know how good the performance will be right away, but I'm optimistic it'll get there.
01:07:58.280 - 01:08:43.380, Speaker A: I think that in general, these major Herculean efforts of the Zkevm projects, for example, which has taken multiple years to implement the Snarks as they need them, I think that effort for those experts will also get much less where maybe you could build a new Zkevm in a matter of months instead of years and eventually less than months and so forth. And I think along the way there are going to be security issues, just bugs and the community sort of coming to a consensus about what is an appropriate security level and things like that until we reach that stage. I think everyone unfortunately does have to have some awareness of these security issues that I try to discuss today. Okay, so that's everything I had to say. Thank you and let me know if you have questions.
01:08:49.210 - 01:08:58.200, Speaker B: Quick question for you. What do you see the roles of nansen like the data platform for traders and Dune sort of playing in the role of ZK tech?
01:09:00.110 - 01:09:10.314, Speaker A: So maybe I don't know enough about the trading platforms to fully understand. Are you asking will Snarks sort of change how people do trading either like.
01:09:10.352 - 01:09:19.310, Speaker B: More of the transparency on the data to see more accurately what's happening on chain? There's a level of anonymity that comes with ZK tech.
01:09:19.460 - 01:10:26.686, Speaker A: Yeah. So what ZK unlocks generally is sort of scalability and privacy. I think they will clearly change how trading is done on chain because you don't have the same experience with on chain trading today as you do in like a brokerage account, some centralized thing, right order books and blah, blah, blah. The reason is scalability issues and as Snarks get more and more performative, we'll be able to move all of that stuff off chain and have it prove to the chain. So certainly the trading experience is going to change just for that reason. Some of transparency you run into just like the data availability issues with all of the roll ups, it's like the gas savings from roll ups is likely capped at maybe 100 X or something if you're storing all the data on chain and maybe that 100 X I can't keep track of. It all moves so fast with the various EIPS like protodank, sharding.
01:10:26.686 - 01:11:10.994, Speaker A: The whole point is kind of to make things cheaper for roll ups. And so maybe just by sort of declaring things to be cheaper, that moves the 100 X to 1000 I don't know, to 1000 X. But the real unlock is if people find a way to keep that data off chain. And yeah, the question is just the data does need to be available and you can sort of brick the whole system if it's not. And so if you keep it with like five entities, is that really better than the current situation today of a handful of brokers or something like that? So that's an ongoing problem that has nothing really to do with Snarks. Is that what you were asking, or were you asking about something totally different?
01:11:11.032 - 01:11:24.038, Speaker B: No, I mean, that partly answers it, I guess. There's a bunch of SQL developers on Dune querying the blockchain right. Creating really cool dashboards from the ability of everything being so transparent and so available.
01:11:24.124 - 01:11:24.886, Speaker A: Oh, I see.
01:11:24.988 - 01:11:33.260, Speaker B: And you sort of talked about how right now we just have our bank accounts on chain and everybody can see that, but it seems like there's a new world coming.
01:11:33.630 - 01:12:28.646, Speaker A: Yeah. It's a great question about is privacy intention with transparency? I don't have great answers to this. One thing I think is clear is privacy is not fundamentally intentioned with something like compliance. And probably transparency can something similar can be said about that, you know, for these dashboards and things like that. So the idea with privacy and compliance would be you prove that a bunch of transactions are consistent with some government mandated compliance policy, but you reveal nothing about the transactions other than their compliance. So you're revealing sort of like just a bit. The technical challenge here is bit is compliant or not compliant? The technical challenge here is to express the compliance policies.
01:12:28.646 - 01:12:54.222, Speaker A: It has to be in as precise a form as Imaginable, like a circuit that sort of takes the transactions as input and checks that they're compliant. Right. Any computer program probably you can say something similar about the sorts of data analysis things that you're asking about, but that's vague and I just really need to know more about what the dashboards are showing.
01:12:54.286 - 01:12:54.702, Speaker B: Totally.
01:12:54.766 - 01:12:55.234, Speaker A: Yeah. Cool.
01:12:55.272 - 01:12:55.682, Speaker B: Thank you.
01:12:55.736 - 01:12:57.014, Speaker A: Yeah, thanks for the question.
01:12:57.212 - 01:13:15.034, Speaker C: Hey, Justin, thanks for the talk. I have two questions, actually. So one is, as you mentioned, the approving opens up attack surface that in libraries, et cetera. So since Vitalik's proposal you think is not effective, what do you think are the alternative for that?
01:13:15.232 - 01:13:56.230, Speaker A: Yeah, it's a great question. Can we use these until we're confident that they're not buggy? How do we know that they're not buggy if we don't basically create a bug bounty for them by deploying them and letting people I don't have strong thoughts. I mean, I think that Justin Drake'sgx proposal is a reasonable band Aid. Yeah. It's just very hard to like it's like any new security critical technology is hard to work out the kinks. But if you look at these code bases, there's a lot of code. It's complicated.
01:13:56.230 - 01:14:15.966, Speaker A: It's not super well commented. Yeah, there's not a good answer. I think there just will be some breaks. Hopefully most of them are identified by white hats before black hats and band AIDS in the meantime are good, I guess. Yeah, it's a tough question.
01:14:16.148 - 01:14:34.562, Speaker C: Okay. And my second question is, from my understanding, optimistic roll ups mostly cost come from call data storage and then CK mostly come from validity proof. So generator proof. So which one do you think the cost will decrease faster? Does the curve look like yeah.
01:14:34.616 - 01:15:49.130, Speaker A: So I don't have a great prediction for this, especially I really am the expert on just the Snarks. I'm not sure it's necessarily the case that the bottleneck for gas costs for the validity roll ups is the proof checking. So if you're using like a plank proof today, I'd say that's definitely not the case because it's under three hundred K gas for proof. So already the bottlenecks might be coming from all the call data already. In which case my understanding is the validity roll ups need less call data because they can kind of gross up transactions in a way that you can't if you want to support fraud proofs. Yeah, I think we might already be at the case where you should be really looking at call data versus call data on the gas cost front. And then the other thing to look at obviously is like prover bottlenecks on kind of the latency front or just the cost that today is not public when the provers are centralized of just how expensive is it to run the prover.
01:15:52.130 - 01:15:53.374, Speaker C: Okay, got it.
01:15:53.412 - 01:15:53.710, Speaker A: Yeah.
01:15:53.780 - 01:15:54.222, Speaker C: Thank you.
01:15:54.276 - 01:16:48.910, Speaker A: Yeah. Thanks for your question. Earlier you talked about ungating AI. I just organized AI for good hackathon and I was wondering how could you use Snarks for either accessing or really using models on chain? Yeah. So using models, I think is pretty clear, where every time you need the model to perform inference on a new piece of data to make a prediction about that data or make a decision based on it, you wouldn't have the blockchain evaluate the model on the piece of data. You'd have someone do it off chain and prove they did it correctly to the blockchain. In terms of performance, training is significantly harder than inference, but I'm optimistic we'll even be able to prove to the blockchain we train this stuff correctly.
01:16:48.910 - 01:17:31.820, Speaker A: Then you run into the issue, is the data signed or if it's not signed, how do you know? It was like legit data or something, which I already discussed, but in general, I think these issues will be solved ultimately. Yeah. The other question was the accessing. Accessing? Yeah. We're seeing efforts now where the goal is to kind of have a heterogeneous decentralized mass of compute hardware. You could just kind of sign your GPU up or something, your personal GPU, but no one's going to trust that when you say, hey, I ran your workload correctly, pay me a dollar. Because here's the answer.
01:17:31.820 - 01:18:30.730, Speaker A: You're going to want that dollar if you can get it without actually using your GPU, that's better than having to run your GPU to get it right. So we're going to need proofs that the answer returned by this decentralized mass of compute hardware are correct. And the hope is that the Snarks just get performative enough on the prover end that that's doable. And I'm not optimistic for a completely general purpose thing, but I think the really key stuff that is just as I think proving knowledge of digital signatures will get much better and that's today a bottleneck for all the projects trying to keep those signatures off chain. I think most of the unlock of this stuff is like training up models and all the models are today doing roughly the same thing. And so you can specialize your Snark to that and I think it gets much more believable that you could actually produce a Snark proof that you did everything correctly. Gotcha.
01:18:30.730 - 01:18:35.306, Speaker A: Does that make sense? Yeah. Thanks Justin.
01:18:35.338 - 01:19:03.674, Speaker B: Thanks for the talk on the front end side of things. So either today with Circom and really low level representations for computational logic or something in the future where it is like Python or Rust, is there a fundamental disconnect between a user or somebody writing this circuit representation for logic and you knowing that that logic represents what you want to prove, if that makes sense. So it's almost like by having to codify this in some representation, it's like the user's burden to have a correct representation for what they're trying to prove. Like for simple things. I'm sure it's not an issue, but.
01:19:03.712 - 01:20:03.114, Speaker A: As the logic gets complicated yeah, so I think that this is a major concern. So I haven't dove into the weeds of the Zkevms now, but a bunch of the Snarks, the roll ups when they were just handling transfers and NFTs, I did look closely at that and they basically had literally tens of thousands of lines of Bellman or Circom expressing these circuits like highly optimized circuits. They needed, presumably the optimizations for performance. I mean, I think it's almost impossible to believe that there's not like somewhere in you give me all those projects, each one with 20,000 lines and yes, there's overlap, that there's not a bug anywhere in there and one little bug all of a sudden like the tornado cache situation bug, you can actually exploit the contract maybe. Was that what you were asking? Yeah.
01:20:03.152 - 01:20:10.814, Speaker B: So I guess, given that, how do you respond to that? Because even for moderately complex logic, this just sounds like it gets really terrible really fast.
01:20:10.932 - 01:21:26.550, Speaker A: Yeah, no, it's a big challenge. I'd say two things. I'd say formal verification can do it's very time intensive, I understand, to formally verify the correctness of things, especially these circuit satisfiability instances which are kind of like a weird programming model because they take non deterministic advice, inputs, details aren't that important, but I think you can do that. But I hope we don't live in a world where some developer has to hand code a circuit for performance reasons every time they tweak what they want to prove and then go through formal verification all over again. I hope we wind up in a world where there's like a general purpose front end, maybe something that looks like risk zero that can kind of handle any program for a reasonable instruction set architecture. That front end gets formally verified that the circuits it spits out match exactly the program you feed into it and then you apply a back end to the circuit that comes out of that front end. That back end has also been formally verified that it matches some spec and their security proof.
01:21:26.550 - 01:21:35.100, Speaker A: I think eventually that is going to happen and I think until it does happen, there will be bugs. To be honest. I think it has to happen.
01:21:35.550 - 01:21:36.460, Speaker B: Thank you.
01:21:38.510 - 01:22:23.980, Speaker A: Hi. Thanks. There question on float point arithmetics, especially when it comes to let's imagining, doing an inference, proving inference in machine learning and how big of a bottleneck that is, for example. Yeah, so it's a great question. So I am told that a lot of machine learning models actually just for performance reasons, forget about Snarks, like just to train the model, at least the expensive parts of the model are already often done at kind of low precision arithmetics. Even as low as like eight bits, eight bit integer arithmetic, that sort of thing. Plays very nicely with Snarks for sure.
01:22:23.980 - 01:23:17.194, Speaker A: Snarks work over these finite fields and you don't run into any overflow or mismatch issues if you're dealing with eight bit integer arithmetic. And yeah, I think that even going up to certainly 32 bit floating point would be great. And I'm excited about some work that I is not yet ready to talk about today, which I think will make something like that much nicer is the short version. Today dealing with like 32 bit floating point would be especially according to an IEEE standard, you don't want to mess with how floating point is implemented or something like that. It would be a performance nightmare. But I think when I was saying I can see an order magnitude here and here and here coming off sometime soon, I think those same techniques will also make floating point stuff nicer. Yeah.
01:23:17.194 - 01:23:53.858, Speaker A: Are you referring to when you don't need to prove that you have run the specification and just prove like that? No, actually prove it. Okay, I'll just mention it's unpublished work. But I'm excited. So there's something called lookup tables that are popular in Snark design. It's especially helpful for certain things are not nice to do in a circuit. Like your laptop can do them in one step and in a circuit it takes hundreds of gates or more or something like that. And you can sometimes make that less nasty by using what's called a lookup table.
01:23:53.858 - 01:24:34.254, Speaker A: The details aren't that important and I'm working on some better lookup arguments, which I think will really unlock more uses of the tables. It'll let us use much bigger lookup tables, which is sort of what you need to handle some of these operations, like 32 bit floating point. Okay. Thank you. Yeah. So a lot of really nasty performance bottlenecks today, I think will get better, but the techniques to achieve them, I think, are going to be different than what people are doing today. And so projects should be ready for those techniques to change.
01:24:34.254 - 01:24:37.410, Speaker A: Yeah, that okay. Thanks so much. Yep.

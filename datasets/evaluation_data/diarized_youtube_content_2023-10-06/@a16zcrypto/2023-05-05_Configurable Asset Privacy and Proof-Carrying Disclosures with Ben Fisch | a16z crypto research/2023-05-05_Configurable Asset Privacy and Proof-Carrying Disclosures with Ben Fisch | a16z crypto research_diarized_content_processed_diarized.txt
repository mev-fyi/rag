00:00:09.270 - 00:00:43.810, Speaker A: Welcome, everybody, to the seminar for the week. We're really glad to have Ben fish, who just finished his PhD at Stanford last year working with Dan, and now he's just started as a professor at Yale. He's the co founder and CEO of espresso. Ben's known for his work on VDFS, on proofs of proofs of replication or catalytic proofs of space, his work on darks and SuperSonics, a whole lot of different so, as well as his crack climbing techniques.
00:00:45.370 - 00:01:42.546, Speaker B: Thanks, Jeremy. Yeah. So I'll talk about configurable asset privacy and proof pairing disclosures for privacy pools. This will be mostly focused on this protocol. That an application smart contract application that we built in espresso systems called cape, which is currently deployed on arbitrum's testnet and also on ethereum's testnet gurley, and has been getting a lot of traction in the last few months and should hopefully be live soon with some pretty big users soon. So this is the espresso team just briefly credit to all 26 of them for all the work that went into the system that I'll be presenting today. And there's two products that espresso systems develops.
00:01:42.546 - 00:03:03.262, Speaker B: One is called tape, which is a protocol configurable asset privacy on the ethereum application layer. And that's what I'll be talking about today. The other is a decentralized sequencer for ethereum roll ups, and I won't be talking about that today. So Cape comes into this picture where there's generally an all or nothing approach to privacy where you can have blockchains that either are completely transparent and they don't have any privacy for user transactions or other protocols, whether they're in a smart contract like Tornado Cash or entire blockchains like Zcash or Monero where transactions are entirely private or even anonymous from the public view. And so cape is trying to offer new options in between that. In particular, they give users more flexibility on defining the level of privacy of assets that get created, and this can in particular be used to balance risk management and user. So, hypothetical case study, but very realistic, as you couldn't see from the hypothetical description, a us regulated stablecoin issuer mints some USDX on ethereum.
00:03:03.262 - 00:03:55.570, Speaker B: The issuer needs high level visibility into how USDX is being used. The ability to track the flow of USDX originating from any illicit sources, the ability to freeze assets if necessary. But they also would like to give their users some level of privacy so the general public cannot view transaction details of their transactions. And the problem with the status quo is that users can only achieve privacy via sort of mixing services like tornado cache, let's say completely shielded pool. And that's fine for a while, but then there may be some illicit flow into the pool, which is visible, but then soil is the whole pool, and the pool gets sanctioned. Now the issuer has to ban and freeze the entire flow of USDX from the mixer. And this is a very high collateral damage to innocent users who are just using it for some level of privacy.
00:03:55.570 - 00:04:53.730, Speaker B: So, with that in mind, that's sort of the motivation for introducing this configurable asset privacy protocol, which can enable issuers of digital assets to create custom privacy policies. And in the first version of Cat, we focus on a fairly restricted class of policies that involve viewing keys and freezing keys. So, viewing keys, what are they? Well, there's a privacy policy that designates certain parties and the data that they can see. So for example, there's an auditor that can see the details of transactions over a threshold amount. A freezing key would be a policy that designates parties who can freeze assets. And there could also be some conditionals in there. Digital credentials are something that policies can take into account.
00:04:53.730 - 00:06:05.210, Speaker B: So the viewing policy, for example, may say that for transactions over a certain amount, not only can you see the amount being transacted, but you can see certain verifiable credentials of the sender and reception addresses. And finally, we built this in a way for it to be EVM compatible so it can be deployed on top of any EVM blockchain. It currently is deployed to the Ethereum Gurley testnet and also Darbitron testnet as of a few weeks ago. The design principle behind Cape is giving the maximum flexibility to asset creators and exchanges to take decisions around privacy and control. So that creators of digital assets have the ability to restrict how their assets are being used on Ethereum or other blockchains by configuring these privacy control policies and exchanges. And other endpoints can also take responsible decisions on which assets they want to accept so they can take into account their privacy control policies. So, let's go into a bit of a more technical discussion of how this Cap protocol works and also talk a little bit about the current version versus the future version.
00:06:05.210 - 00:07:03.050, Speaker B: So at a basic level, it's very similar to Zcash. So if you're familiar with how Zcash works, then this is pretty much review. There is a ledger, we're implementing it in an Ethereum smart contract. So the ledger is managed by Ethereum smart contract. But you can think more generally that the Cap protocol just requires some ledger and it contains a record set, right? And transactions will take as input two records and they'll create two outputs. And I'll talk a little bit in a little bit about how this is private. Right now, we're not really describing how privacy is achieved, but in general, you just look at the ledger as having a record set and every transaction is effectively removing two records or however many records and creating some new records.
00:07:03.050 - 00:08:23.126, Speaker B: And the anatomy of a Cap record is that it has an asset identifier identifying what asset it is. It has an owner address saying who owns it. It's a public key, it has an amount, and there is a flag that says whether it's frozen or not. And then a blinding factor because these things will be cryptographically committed. So how do we define assets? Well, when an issuer creates an asset, it derives an asset ID based off a pseudorandum function of its secret key as the issuer and some description of what the asset is. So you could have two different issuers create assets of the same description but they will be different assets because there's different issuers and you want to prevent someone from forging assets on behalf of an issuer that they are so you wouldn't want someone to be able to create assets of USDC if they're not circle for example. So record commitments and nullifiers, let me introduce these so a record commitment is just a cryptographically hiding commitment to a cap record.
00:08:23.126 - 00:09:12.390, Speaker B: You take the plain text of the Cap record and you produce a cryptographic commitment to it. It could be the hash of this record with the secret notes. That's what the blinding factor would serve as and a nullifier is a function of the record commitment itself and it is a PRF that takes in also a nullifier key. So you can only derive this nullifier if you know this nullifier secret key and I won't say exactly yet how we define the nullifier key. We do it in sort of a clever way to enable this freezing functionality. But before we talk about freezing, you could just set the nullifier key to be like the secret key of the owner, for example. That's how it's done in ZCache.
00:09:12.390 - 00:10:13.030, Speaker B: So we'll define the nullifier keys later but think of it as something that's unique to the owner of the record and so that thus can only be created by this owner and every time there's a unique nullifier for any given cap record. So a transaction will take in, as we said, some inputs and produce some outputs but the transformation it actually makes to the ledger is it doesn't actually remove the inputs from the ledger, we don't want to touch those inputs, we don't want to reveal which inputs were actually taken as input to this transaction. So the transaction just produces these nullifiers for the inputs and that prevents them from ever being spent again. So no other transaction in the future will be able to take the same inputs because they've already been nullified. What's?
00:10:13.190 - 00:10:14.650, Speaker A: Cap and cape.
00:10:14.990 - 00:11:12.030, Speaker B: Oh, cap and cape. So Cap is configurable asset privacy protocol and Cape is Cap on Ethereum. So you said that the nullifiers aren't linkable to the thing. That nullify they are not linkable from a public viewer's perspective. But if you know the nullifier key there's a unique nullifier that you can derive. So how does it enforce that if the nullifier is out there you can't spend the original thing if you can't link them? So if somebody were to try to do a new transaction that uses the same input, they would create the same nullifier and so because the nullifier already exists on a ledger, you would not allow that to happen. So every transaction must create and thus nullify all its inputs and it can't produce nullifiers that already exist.
00:11:12.030 - 00:12:00.240, Speaker B: So in addition to this, which is basically I'm describing a Zcash transaction, we also have something called a viewing memo, which I'll describe. And then the owner memo is what allows the recipient to decrypt what happened, and the owner memo is present in Zcatch as well. So the new thing here is this viewing memo and I'll describe how that works. And then there's a zero knowledge proof, which I'll also describe in the next slide, which shows that this whole thing was done correctly. So the zero knowledge proof is going to show that the outputs are balanced with the inputs and that the nullifiers were computed correctly. So you didn't just produce some arbitrary nullifier. That has nothing to do with the record.
00:12:00.240 - 00:12:38.602, Speaker B: Okay, so not assuming any background here, this may be review for every single person here. So I go very quickly through it. But I feel like you have to include a slide on what zero knowledge is in these presentations. So zero knowledge proof is a protocol or the goals approver wants to convince a Verifier that some statement is true without revealing some secret evidence. So it knows some private input W such that this program evaluated on a public input X. And this private input W is equal to one. The prover is an algorithm that has this program.
00:12:38.602 - 00:13:19.080, Speaker B: It also has the public input X and the secret input W. The Verifier has the same program, but it only has the public input X. There's some protocol. We like to use non interactive zero knowledge proofs when we're dealing with blockchains, and that's necessary for cap in a non interactive proof. The prover would just send a proof that convinces the verifier that this witness w exists, this private input exists. And the soundness guarantee is that it's infeasible to produce a valid proof that the verifier algorithm will accept if the prover doesn't know such a W. And zero knowledge means that the proof doesn't reveal anything about W.
00:13:19.080 - 00:13:50.202, Speaker B: So the zero knowledge proof systems that we use are called preprocessing proof systems with universal setup. So there's some setup that's done one time. It's already been done for a lot of these proof systems like Plunk. And our proof system is based off of Plunk. So the parameters already exist. They've been done multiple times in various different trusted setups by different projects. And the preprocessing takes these parameters.
00:13:50.202 - 00:14:30.970, Speaker B: It takes some circuit representing the program that's being proven and it generates what's called a proven key and a verification key for this program. And then the proof algorithm can use the proven key in order to produce a proof given the public input X and the private input W. And the verify algorithm will only need this verification key. So it doesn't need to remember what the circuit was. It doesn't need to remember what the program was. It just takes in this verification key and it can verify a proof against the public input and it outputs either zero or one. One being that it accepts, zero being that it rejects.
00:14:30.970 - 00:15:28.990, Speaker B: Okay, so what is going to be in our zero knowledge proof? Well, our zero knowledge proof for Cap is going to prove that the commitments and nullifiers were computed correctly as defined that the inputs are part of the record set, that the sum of the outputs is equal to the sum of the inputs. By the way, the way that it proves the inputs are part of the record set involves some merkel proofs and I'm sort of skipping over that as a detail here. I'll come back to it later when you see the full picture. That detail doesn't matter that much, it's for efficiency. But the zero proof has to prove that the inputs are part of this record set somehow. It could take the full record set as input, right, if it wanted to be less efficient and the transaction satisfies the asset policy. And this is saying the viewing memo is properly encrypted using the viewing key.
00:15:28.990 - 00:16:33.266, Speaker B: So what is this asset policy? So the asset policy specifies a viewing key. Okay, there could be multiple viewing keys if there are multiple auditors that have different viewing rights, but we can just focus on the case of one viewing key. It optionally specifies a viewing threshold which says that the details of this transaction need to be encrypted under this viewing key only if the amount being transferred is over $1,000. For example, it will specify whether the amount should be viewable to the person who holds the viewing key, it should specify whether the owner should be viewable and it should specify whether the credentials should be viewable or not. And this can be also including which credentials. So you can represent the Credential as a vector of attributes and it would be basically a bit vector saying which attributes should be viewable to the holder of the view key. And finally it says whether there is a freezing key or not.
00:16:33.266 - 00:17:31.234, Speaker B: And I'll explain freezing next. But if there's no freezing key, then nobody has ability to freeze records. And if there is a freezing key, then somebody has the ability to freeze and I'll explain what that means. So the zero knowledge proof needs to prove that this transaction satisfies this asset policy. So as an example, if the policy says that the view key holder should be able to see, always see the amount in the owner, then the zero knowledge proof proves that the viewing memo is properly encrypted using this viewing key. So that guarantees that the holder of the viewing key would be able to decrypt this information, which would include the amount in the record and the amount in all the input records and the owners of all the input records and output records. And finally, it also needs to prove that the free status is not changed.
00:17:31.234 - 00:17:40.460, Speaker B: Remember, the free status is just a bit zero. Or one says this record is frozen or not frozen. For a normal transaction, you're not able to change the freeze status. Right.
00:17:41.230 - 00:17:47.142, Speaker C: Where does the asset policy live? Do I specify with the transaction what asset policy I'm satisfying?
00:17:47.286 - 00:18:09.106, Speaker B: Yeah, so the asset policy is actually taken into account as part of the definition of the asset itself. So basically the asset itself is sort of commitment to this policy. You can also have a table of asset policies, but that is not how.
00:18:09.128 - 00:18:13.282, Speaker C: We currently do you think each asset ID is associated permanently? One asset policy.
00:18:13.336 - 00:18:14.418, Speaker B: One asset policy. Okay.
00:18:14.504 - 00:18:16.130, Speaker C: On creation you specify this.
00:18:16.200 - 00:18:29.080, Speaker B: Yeah, we've gotten some user requests to make asset policies updatable without changing the asset type. And so we have a design for that update that separates these things out.
00:18:30.250 - 00:18:41.454, Speaker A: I asked a lot of questions about details of these asset policies, but you mentioned like freezing a record. Is there a notion of freezing an account? Like freezing all records tied to yeah.
00:18:41.492 - 00:19:07.426, Speaker B: That'S a really good question. So no, currently not there's just freezing an individual record. There is no real concept of an account. I guess you could have a policy that says freeze all records that share the same owner address. But even if you were to do that, users can also use different accounts.
00:19:07.538 - 00:19:14.040, Speaker A: Well, I guess you'd have to get into some permission system for being able to register an account.
00:19:14.890 - 00:19:25.286, Speaker D: Yeah, if you have an appropriate viewing key for an asset, you can just freeze all the individual assets that correspond to some owner.
00:19:25.318 - 00:19:25.514, Speaker B: Right.
00:19:25.552 - 00:19:26.838, Speaker D: Or some credential.
00:19:26.934 - 00:19:46.238, Speaker B: The idea is that all people who freeze will also be able to view, otherwise they don't know what they're freezing. So you could go through and look at everything and figure out which ones you want to freeze. But we currently don't in the protocol itself, make it more convenient or automatic to freeze all records associated.
00:19:46.414 - 00:19:51.058, Speaker D: Yeah, it's kind of designed sort of in mind with freezing is a very rare thing.
00:19:51.144 - 00:19:51.780, Speaker B: Right.
00:19:52.150 - 00:20:04.566, Speaker A: Have you had anybody request a permissioned ownership model where you have to sort of do KYC or somehow just to get your address, so not anybody can.
00:20:04.588 - 00:20:26.138, Speaker B: Create a new address. So people are interested in these credentials which do function as that, but not necessarily explicitly in terms of you can only get this specific asset. But if you do have credentials tied to ownership, then you can define policies where you freeze all records associated with a specific Credential. The Credential then becomes the permissioning aspect.
00:20:26.234 - 00:20:32.814, Speaker D: You could say an asset can only be transferred to someone who has the appropriate Credential, and the Credential would be your KYC.
00:20:32.862 - 00:21:10.538, Speaker B: People are interested in that. So this viewing memo, some engineering details here. We worked very hard to make the circuit efficient that could efficiently prove that you're encrypting plain text under this viewing key. So we use elgamal hybrid encryption to encrypt the plain text under the view key. The elgamal public key is over the Job jump curve and we actually have rescue based string cipher. So we prove the symmetric encryption. It's not an LDML encryption of the plaintext because that would make decryption really annoying.
00:21:10.538 - 00:21:58.170, Speaker B: So we actually have a symmetric encryption of the plain text using a Snark friendly symmetric primitives. So the full protocol will also involve a merkel tree. Before a transaction, you have a record merkel tree over the records, you have some nullifiers. The transaction will take some inputs, nullify them, create some new outputs, those new outputs get inserted into the merkel tree. There's a zero knowledge proof showing all those things that I just mentioned, that the viewing memo was created properly, that the inputs are nullified properly and it will add these nullifiers to the nullifier set. It doesn't touch the inputs and the inputs remain in the market tree. No public user knows which inputs were involved in the transaction.
00:21:58.170 - 00:22:58.554, Speaker B: So let me now say how freezing works. So as I mentioned, we derived the nullifier key in sort of a slightly different way from the usual way in order to freezing. The idea is that freezing will appear to everyone else as just a normal transaction. Like anything else. Nobody can see that something is being frozen, it just appears as a normal transaction. But we restrict things in a way so that the freezer can't spend the record normally because it doesn't have the owner key of the record, but it can derive the nullifier. Okay? And when it produces this special freeze transaction, it will be proving in zero knowledge that basically the zero knowledge proof that gets created during a transaction says either I'm the owner and I'm able to do whatever I want, or I'm just the freezer.
00:22:58.554 - 00:24:00.734, Speaker B: And if I'm just the freezer and I don't actually know the secret key of the owner, the only thing that I can do is flip the freeze bit from zero to one. So this has the guarantee that the freezer can flip the freeze bit from zero to one, but it can't change the owner of the record. So you can just freeze, but you can't take custody, you can't transfer to someone else, you can just unfreeze which flips the bit back and now it's just a normal record. We also prevent the owner from ever like one of the other things checked by this zero knowledge spend circuit is that when a record is frozen, the owner will not be able to transfer the record, will not be able to take it as input. The only thing that's necessary though, for this to be supported is that the nullifier, for this to appear as a regular transaction, the freezer needs to be able to derive the nullifier. And so how do we do that? How do we ensure that the freezer and the owner can derive the same nullifier, but nobody else can. So it's essentially sort of a Disney Hellman style shared key between the freezer and the owner.
00:24:00.734 - 00:24:33.440, Speaker B: So we just defined that this is an elliptic curve notation. The nullifier key is the freeze secret key times the owner secret key times the elliptic curve point G. Right. You can think of this if you're more used to the exponent notation. This is G to the freeze secret key times the owner secret key. And since the freeze public key is freeze secret key times G and the owner public key is owner secret key times G, both of these parties can derive the nullifier key, but nobody else can.
00:24:39.010 - 00:24:49.730, Speaker C: The freezing is just done at the full discretion of the freezer. Is that right? It's not like there's some commitment to that's, right. Conditions under which freezing happens.
00:24:49.800 - 00:25:11.160, Speaker B: That's right. Currently it's not the full discretion of the freezer, but you could add conditions. Right. And those would go into the circuit that allow the freezer to prove that what it's doing is allowable. So currently we just check that if you're a freezer, only thing you're doing is flipping the bit from zero to one. But there could be other conditions that would go in there. We don't currently support that.
00:25:11.160 - 00:25:31.600, Speaker B: This is sort of a recurring theme of, oh, we do this, but we don't do that. And so I'm going to talk about in Cap 2.0, where we sort of want to expand this so anyone can create their custom policies and not just restrict the policies that we've come up with, which are really just an MVP and trying to figure out what our initial users will care about the most.
00:25:31.910 - 00:25:44.278, Speaker D: But one thing that is already possible and that I think could be a good solution, is you can certainly thresholdize the freezing key. Also the viewing key, right, like you.
00:25:44.284 - 00:25:50.838, Speaker B: Can say, can easily be turned into completely work and you don't require protocol changes for that.
00:25:51.004 - 00:25:52.840, Speaker D: You say like three out of five.
00:25:55.210 - 00:26:11.414, Speaker E: Quick question on the freezer. If you're a validator and you see a freezing transaction, can you front run it with spending the record to another key that doesn't have the same freezing capabilities so that you kind of avoid?
00:26:11.462 - 00:26:18.698, Speaker B: So the nice thing about freezing is that from the public's perspective, they don't know that it's a freeze transaction. It looks like a normal transaction.
00:26:18.794 - 00:26:20.926, Speaker E: I see, because all you see is.
00:26:20.948 - 00:26:36.610, Speaker B: That a nullifier is being created and an output record is being created and you might want to take some dummy inputs and dummy outputs. We also allow for dummy inputs and dummy outputs to obfuscate the number of inputs and outputs to a transaction so that you can't just say, oh, there's one input and one output. Maybe it's a freeze.
00:26:37.590 - 00:26:41.800, Speaker E: As an owner, do you understand that this is a freezing transaction for you?
00:26:42.490 - 00:26:51.610, Speaker B: So if you're an owner and then you'll be able to see that it's a freeze transaction because you can tell that the nullifier was your nullifier.
00:26:51.950 - 00:26:52.618, Speaker E: I see.
00:26:52.704 - 00:26:57.674, Speaker D: But you cannot change whether a transaction is freezable or not.
00:26:57.792 - 00:26:59.226, Speaker B: You can't do that, but you can.
00:26:59.248 - 00:27:08.030, Speaker D: So you can transfer it to a different like you could transfer it to a different record, but that record will also be freezable.
00:27:08.530 - 00:27:09.182, Speaker B: Right.
00:27:09.316 - 00:27:13.646, Speaker D: So even if you are able to front run, then the freezer just freezes.
00:27:13.678 - 00:27:21.730, Speaker E: Your new records because new records derived from the previous one kind of preserve the same freezing capabilities.
00:27:22.870 - 00:27:24.414, Speaker D: That's part of the asset definition.
00:27:24.462 - 00:27:37.830, Speaker B: It's part of the asset definition itself rather than the record. Yeah, it's not that the record itself has a freezing policy, it's that the asset ID is associated with the freezing policy. So the freezer can freeze any record of this type.
00:27:37.900 - 00:27:39.880, Speaker E: I see how makes sense though. Thank you.
00:27:42.430 - 00:27:47.914, Speaker C: Are all the inputs have the same asset ID or can you mix so.
00:27:47.952 - 00:27:53.482, Speaker B: All the inputs no, you can have transactions that are mixed. Okay.
00:27:53.616 - 00:27:57.498, Speaker C: So like if any of the inputs are freezable, then all of the outputs.
00:27:57.514 - 00:28:28.906, Speaker B: Are going to no, it depends on the ID you create. Yeah. The freezable is really a property of a record rather than a transaction itself. So you can have transactions that take inputs of multiple types and have outputs of multiple types. But at any point in time, if you have a record of type asset A and that it's freezable, like it's USDC and Circle has a freezing key, for example, then it will be freezable. But the balances have to match up.
00:28:28.928 - 00:28:31.530, Speaker D: Per asset, asset by asset, asset by asset.
00:28:33.070 - 00:28:34.300, Speaker C: So you could have some.
00:28:36.670 - 00:29:13.480, Speaker B: Another good example of this again is a paper recently on dispute resolution. Right. Or referral transaction or dispute resolution. So you could have the freezer could be a distributed set of judges that have a threshold key and they're able to freeze. Right. But they would only be doing this subject to some freezing would be a necessary component of implementing any form of dispute resolution where you have a certain period during which you can do this transaction where you can reverse the transactions. Right.
00:29:13.480 - 00:29:49.378, Speaker B: So the ability to freeze would be a necessary starting point for that. I think that it's an interesting question of how to fully do dispute resolution within a privacy protocol. We haven't done that yet, but that would be a cool new feature of Cape. So currently this is deployed as a Cape contract. So there's a bunch of other system components involved in here. There's a relayer which relays the transactions. This is necessary when you're building applications on top of Ethereum because the fees need to be paid from a public account.
00:29:49.378 - 00:30:05.350, Speaker B: And so if users submitting their transactions directly, then it wouldn't privilege privacy. So there needs to be a relayer. There's what we call the Ethereum query service, which users are using to get filtered events from the Cape contract, et cetera.
00:30:07.050 - 00:30:07.986, Speaker A: What's Borley?
00:30:08.018 - 00:30:58.354, Speaker B: Is that a test? Oh, it's one of the testnets. So we also support wrapping of Ethereum assets. So you can create new assets, you can mint new assets in the protocol, but you can send ETH to the contract. You can send USDC or USDT to the contract. If you're sending some ERC 20 asset that already exists on Ethereum, then it has to be wrapped under a certain type. And every asset type, as we described, has basically an issuer or a sponsor, right? And it has certain policies associated with it. So you could have multiple wrapped versions of east that are endowed with different visibility policies.
00:30:58.354 - 00:31:46.680, Speaker B: And as a user, you know what you're getting into. So I want to wrap my ETH, but I'm using the view key of auditor A or the view key of Auditor B. I know what I'm getting into. And this is also useful because issuers that already have created assets on Ethereum don't want to necessarily issue new assets. So if there's a stablecoin issuer that already has minted a ton of its stablecoin on Ethereum, would like that stablecoin issuer to create a wrapper with a certain policy for its assets and then would be able to wrap its existing ERC 20 tokens that already exist on Ethereum indicate that not have to mint it from scratch. The details of this diagram really don't matter. Actually, it wasn't that useful to include the diagram here.
00:31:46.680 - 00:32:27.362, Speaker B: One of the features of this is an optimized plunk. We referred the Cap Circuit. So we just do some engineering tricks to optimize the constraints for the things that we're doing. And all this work went into getting the proof generation time down to just 3 seconds. So in Cap 1.0, as I've been describing, the policy configuration is limited to a template of viewing and freezing options. And the reason why we did that is because for privacy, we wanted to have just one circuit which encapsulates all policies.
00:32:27.362 - 00:33:24.934, Speaker B: And so there's a single circuit that represents a transaction and the zero knowledge proof that you need to create for the transaction and the policy is just an input to this circuit. So there's like a single verification key and that ensures that you can't tell which asset is being transacted. Right. If we allowed users to just specify their asset policies as a different circuit and the validators would just have basically a different verification key for each asset type that's being transferred, then now people know which asset is being transferred. But we also want people to be able to create their own policies as a circuit since it's much more expressive, right, and you could use a universal circuit, but that's going to be crazy inefficient. So we would like users to be able to build their own policies as a circuit and just represent the policy as like a policy verification key, which is. Inside the asset record.
00:33:24.934 - 00:34:04.018, Speaker B: And that's what we're going to enable in Cape two point in Cap 2.0. But to do that, you need what's called one level proof recursion. So I'll talk about that, but basically this is what it would look like. So currently the asset policy is basically a description of a bunch of options, right? Is it viewable? Is it not viewable? What's viewable? Which credentials are viewable? Is it freezable? Is it not? In Cap 20, we'll just replace all of this with a custom verification key, and the verification key would be the pre processing snark. Or this is your knowledge circuit proof system preprocessing of whatever the policy circuit.
00:34:04.034 - 00:34:06.230, Speaker A: Is, assumption that that policy is public.
00:34:06.300 - 00:34:31.678, Speaker B: Though you can publish these policies, and certainly any user who's using the asset should know what the policy is. You can't tell what the policy even currently, you can't tell what the policy is by looking at an asset record because it's committed. But you do know if I'm a stablecoin issuer and I create a policy for my stablecoin, I'm going to publish what that policy is. So all users know what it is.
00:34:31.764 - 00:34:34.046, Speaker A: But maybe you want to keep some pieces of it.
00:34:34.148 - 00:35:31.498, Speaker B: Maybe, yeah, that's a good question. So in any case, the way that these transactions will work is in the first step, the user is going to create a proof that the transaction satisfies the policy using their policy proving key. Okay? But we don't want to reveal this proof because we don't want to reveal to the validators which policy proving key was used. Right? So the step two is going to create this policy proof then becomes an input to a single transaction circuit, which is going to verify this proof against the policy verification key that is committed in the record. Okay? So that means that this transaction circuit needs the ability to verify zero knowledge proofs. And this is called one level proof recursion. So we have a protocol for one level proof recursion called Verizi.
00:35:31.498 - 00:36:16.266, Speaker B: More generally, it's a new construction of decentralized private computation, and at its core, it's a one level proof recursion for Planck. And it achieves a pretty impressive improvement just in terms of practical engineering. Not necessarily a theoretical improvement, but in terms of practical engineering, a nine x improvement on proof generation time and a two point x improvement on memory usage. And this is a paper that will appear in usenex this year. So some statistics for Cape. These statistics are a bit old, but you can sort of see we've had a lot of users interacting with it on testnet, even though it's only on testnet. And so we saw some kind of exponential growth.
00:36:16.266 - 00:37:12.400, Speaker B: And the total aggregate statistics now are that 305,870 total contract actions have occurred across Curly and Arbitrum. There's 40,000 unique addresses, and we just launched an Arbitrum two weeks ago, and there's already 13,000 interactions. So it's cool to see people experimenting with it. So there's a generic challenge here of designing software and decentralized systems to encourage positive use and discourage misuse, which is sort of part of the design philosophy of this. And any technology that protects privacy can be misused in some way. I think it's a very challenging topic right now how to approach privacy protocols and blockchains. And in the wake of tornado cash being sanctioned and everything, there's a lot of discussions happening across government and industry on how to design systems that encourage good use and sort of discourage poor use.
00:37:12.400 - 00:37:38.280, Speaker B: It's sometimes hard to define, though. There's a duality to what's bad and what's good, of course. But this does impact some of the decisions that we try to take in Cape. So, for example, should we require all assets to have some up, right, that could be an example of something that we would do in order to encourage to discourage people from using it in a way that someone wasn't taking responsibility for what's happening.
00:37:39.530 - 00:37:45.100, Speaker A: Why can't someone just create one with a view key that's like provably nobody knows the private key for?
00:37:45.470 - 00:38:06.260, Speaker B: Yeah, and that was sort of the second point here, which is that there are still ways of even if you introduce some of these mitigations, there's still ways of getting around it where you could prevent maybe some cases of like you could prevent people from having like a hash of zero or something being the view key. But you can't have the hash of anything, right.
00:38:07.030 - 00:38:09.234, Speaker D: You can prove that someone must know.
00:38:09.432 - 00:39:16.866, Speaker B: They have to give like a proof of knowledge of signature as a key. Yeah, you can already have to produce a signature. There's ways of preventing those cases. But even if you do all of those things, somebody could still do multiparty computation. General STP. I'm not making a very clear point on this slide, but I thought it was sort of an interesting thing to expose to you of sort of the challenges that we think through and especially when talking with regulators or different people who are concerned about what regulators think of what the overall what we're doing. Often when you talk to regulators, you're asking, what are you doing to discourage this? Right? And you can take certain steps to try to do that, but then there's always a loophole, right? So I think that another thing that's a challenge for the whole industry right now is that in order to have even systems like Cap that try to achieve a balance between risk management and privacy, you need a more fine grained approach to regulation of privacy technologies.
00:39:16.866 - 00:40:33.010, Speaker B: And so an example of this would be if USDX had a view key held by issuer X and Cape is detected to be handling some other asset from an illicit source, then USDX should not be automatically affected. So you need regulations where just because the protocol cape is being used to launder money by North Korea, but there's some asset in the thing which is obviously separated and not at all touched by this, then you shouldn't sanction the whole protocol. You should have a more nuanced, fine grained way of deciding what to do. I would say like an even more extreme example of that when it comes to something like a completely shielded pool is that if users can provide zero knowledge proofs to exchanges, if their withdrawal didn't originate from a sanctioned address, then they shouldn't be affected by the sanction. So you need regulations that are sensitive to these kinds of subtle things and that's an ongoing challenge, an education challenge too, I think regulators to understand that nuance. So we have a blog, Postal A 16. Z wrote a very nice post on this but inspired by that in the last few minutes, I'll say some work that I've been doing with my grad student Josh at Yale, which is proof carrying disclosures for shielded.
00:40:33.010 - 00:41:48.150, Speaker B: So, as you all probably are aware, the US treasury this year sanctioned tornado cash which made it at least virtually impossible for any US users to interact with the contract even if they weren't using it for any illicit use. And also users who had assets into haircash had their assets basically locked or frozen. So there's various mitigation strategies that you can take. You can try to restrict privacy pool deposits to accounts on an Allow List. You can require zero knowledge membership proofs for a specific Allow list upon withdrawal of funds from the pool. You could go even further and require view keys, an auditor who can see certain things. Some of the challenges involved in sort of designing a privacy pool that, again, would sort of mitigate the collateral damage that occurred when the tornado cash was sanctioned and have a situation where the government can say, oh, well, we want to stop money laundering, but we don't want to completely ruin the utility of this protocol for all the innocent users.
00:41:48.150 - 00:42:40.794, Speaker B: If you have some system based on an Allow List, then Allow Lists are going to vary by jurisdiction. So there could be multiple allow lists. If you have users post membership proofs on Allow Lists on chain, then this does weaken the privacy guarantees. It reveals some action about the user and we have multiple Allow Lists. And intersection of Allow Lists can reveal even more. And so the question that we're asking in this research project is can we support multiple Allow Lists in a single privacy pool and can we avoid posting memberships on chain? So can we sort of delegate the verification of membership proof just to the recipient of funds and have the membership on Allowless be a hidden attribute of a record that's passing through this privacy pool? And the answer is yes. There's like a really nice primitive that you can use for this called proof carrying data.
00:42:40.794 - 00:43:35.740, Speaker B: And this is sort of a really nice application of proof carrying data where you can create attestations of Allowless membership that can be carried through the private transaction graph and then ultimately at any time send directly to the recipients of funds. So if I'm transacting over a private protocol like Cape or even Zcash, right, then every transaction creates some output records. At any point in time you have a proof that the inputs to the records were members of an Allow List. So the outputs are also members of an Allow List and you can keep carrying this proof through. And if you want to send your money to Coinbase, then you can give them this proof. You say look, my funds, I have a proof that these funds did not originate from any sanctioned list or that they're on an Allow list. And since the membership proofs are never posted on chain, it doesn't significantly change the GAX costs at all.
00:43:35.740 - 00:45:00.902, Speaker B: So what is incrementally verifiable computation? It's sort of an extension of zero proofs or really snarks more so than zero knowledge proofs, which are similar to zero knowledge proofs. I didn't explain them at the beginning, but they're when the zero knowledge proof is short and efficient to verify relative to the statement that's proving and in incrementally verifiable computation you can think of it's sort of a distributed computation happening. And at every step there's some output of distributed computation that's taken as the next step. And at every step you produce a proof that verifies the previous proof and then also proves some statement about the new step that's happening. And proof carrying data is just generalizing this to some directed a cyclic graph, which is a transaction graph of a blockchain, right? And so in our particular case, we'd be proving that the things that are deposited into a pool are from an Allow list that's visible, they came from an Allow list, say on ethereum main chain. And then at every step within the pool there was some transaction that happened, it took some inputs that were on Allow list and it created outputs that are thus on the Allow list. And so that's the idea.
00:45:00.902 - 00:45:47.858, Speaker B: So every transfer output has an Allow list membership proof. Users can generate these membership proofs for the outputs, so this could be integrated with Cap, for example, for subsequent transfers, users generate new membership proofs that test the validity of the previous ones and users can share these newly generated membership proofs with recipients at any time. And that's the idea at a high level here, this is just a simple application of proof carrying data. Getting it to work runs into some, as usual, engineering challenges and making it efficient. You end up needing to use merkel history trees and things like that. There are some gotchas, but I'm not going to get into the gotchas since I'm low on time. So thanks.
00:45:47.858 - 00:45:49.140, Speaker B: That's the whole talk.
00:45:49.590 - 00:45:50.160, Speaker C: Thanks man.

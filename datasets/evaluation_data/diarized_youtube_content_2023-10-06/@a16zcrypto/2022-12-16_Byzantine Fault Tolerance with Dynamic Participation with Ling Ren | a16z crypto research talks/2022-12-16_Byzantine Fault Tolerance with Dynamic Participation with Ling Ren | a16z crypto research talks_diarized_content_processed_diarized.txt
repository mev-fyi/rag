00:00:06.360 - 00:01:00.110, Speaker A: You. I'm sure everybody knows about the consensus problem and we say a blockchain problem is that the goal here is to build a ledger. It's also called state machine replication. All these different names in the literature. But the high level idea is that we want a set of participants to agree on the totally ordered list of values, despite that a fraction of the participants are malicious and they try to create disagreement among honest participants. And in this talk I'm going to focus on what we call layer one, meaning that we will focus on how to agree on these values. We're not going to care about what these values represent, what they mean.
00:01:00.110 - 00:02:26.570, Speaker A: They have different meanings in different applications, for example, currency or storage, smart contracts, et cetera. So it's called state machine replication because if we can agree on these values then every participant can locally evaluate these commands or state transitions and all the participants will stay in consensus, in sync with each other. For example, here the nice situation would be that every transaction is agreed upon and everybody can apply this monetary transfers and agree on the total balance for each account. And what the bad guy tries to do is to create a disagreement. The bad guy tries to create two transactions, both coming out of his own account. And if, say, the two honest users, A and C, they decide on different transactions, then this is called a double spend attack for our layer one it's called violation of safety or consistency. And so this is a very basic introduction about the consensus problem.
00:02:26.570 - 00:03:50.544, Speaker A: The first thing I want to point out is that this is a classic problem has been around for at least four decades. So what's new about the bitcoin or the whole blockchain innovation? And more importantly, it's not just about what's new. So we can identify some new features of bitcoin but we should also ask is it good? Is it important? So there's some new features that may actually be drawbacks or limitations of bitcoin or they are nice but not as important as people think. So yeah, this is not directly related to my talk but I think it's a good exercise and make it the more engaging to just ask this question what do people think? What do you think are good, important and novel in bitcoin and blockchains proof of work? Permissionless. Yes, that's the first thing that people notice that the bitcoin system allows anybody to join. And I would say this is a novel property of bitcoin and it is a good property. But I would also argue that it may not be as important as touted as people believe it is.
00:03:50.544 - 00:05:05.888, Speaker A: The reason I say that is nowadays the community is kind of moving away from proof of work towards proof of stake. And in my opinion, proof of stake is permissioned. Just like the classic consensus algorithms, proof of stake is no more or no less permissionless than classic algorithms. The reason is that in proof of stake, basically you have voting power if you have coins in the system and the ledger writes down every single coin holder, every single account holder. If you want to participate, you have to purchase some coins from others. So those people have to sell you are willing to sell you their stake and that is the permission you need to get to get in. The fact that newcomers can purchase stake does not make it permissionless because we can also imagine for a classic fully permissioned, traditional protocol say we have 100 parties running consensus.
00:05:05.888 - 00:06:15.744, Speaker A: A newcomer comes and asks hey, does anyone want to sell me your membership? If they make a deal and new person comes in and some old member leaves, that's the same thing as stake changing hands, right? But that's not to say proof of stake has no advantage to classic consensus. It does. And there's a very important one that it supports dynamic participation in the sense that the total number of participants in a classic consensus is fixed. When I say 100 participants, it's just this 100 participants, most of them have to be participating all the time. Whereas in proof of work, proof of stake, that's no longer the case. The universe of total participants is very large, but anytime there's only a small fraction of actually participating and it can go up and down. And this is the bitcoin's hash rate over time.
00:06:15.744 - 00:07:45.420, Speaker A: And we can see over the years it has increased a billion fold. And that is not to say that bitcoin's participation increased a billion fold because it's a combination of two things more participants and also each participant having better hardware and better compute power. But still, it's safe to say that the bitcoin participation also increased hundreds or thousands of folds since its invention. And you can also see there are also cases where the participation suddenly drops by half, or even more than half because, say the price crashed and many miners are no longer interested, no longer profitable, or there may be government crackdowns on certain mining operations. And if we zoom in to a smaller period, you will see that this sort of sudden drops in participation or sudden increases in participation are actually fairly frequent. When I zoom out, it's hard to see because everything is drowned out in the grand scheme of things. But if we zoom into about a few months, you can see the bitcoin demonstrated a phenomenon level of robustness to participation, sudden changes in the participation.
00:07:45.420 - 00:07:58.210, Speaker A: And this is a protocol. I would say it's novel, good and important in bitcoin that classic protocols do not have.
00:07:58.980 - 00:08:01.410, Speaker B: Why was that last graph put jagged up?
00:08:06.280 - 00:09:00.036, Speaker A: Yeah, I didn't really investigate. Okay, so first I should clarify that this bottom is not zero, so it's not as dramatic as it shows. But still, I think these two are about 40% drop. Yeah, I didn't investigate this every single instance, it seems that there are just miners shutting down their system and opening up regularly. And since we're on the topic, I'll just give one more example that certain properties of a bitcoin may be novel, but not necessarily good. For example, it's commonly considered a new property in Bitcoin that security kind of increases over time. When a block first shows up, you can't finalize it.
00:09:00.036 - 00:09:52.372, Speaker A: Yet when it's buried deeper and deeper in the chain, you have more and more confidence that it's going to stay. So this is also a somewhat novel property of Bitcoin, but it's not a good one. It leads to long confirmation latency. If we can finalize it right away when it shows up and don't have to worry about it grows deeper and deeper, that's a better protocol. So this notion of long latency or security increasing over time is a property we would like to avoid, if possible. And the longest chain style protocols that Bitcoin pioneered have this drawback, and the classic BFT does not. So that leads me to the central question we'd like to ask in this work.
00:09:52.372 - 00:10:56.520, Speaker A: Can we achieve dynamic participation and low latency at the same time? So, basically, combining the best of both worlds. All right, so then this is the outline of my presentation today. I'll first help review the longest chain style protocol and the classic BFD protocol, and we will see why they have the respective trade offs. And then I'll give more rigorous definitions and models. And then the main part of the talk is to extend classic BFD algorithms to support dynamic participation. And if we have some time left in the end, I can throw some open questions. What else is novel in Bitcoin that we should try to achieve, try to try to obtain without paying for its prices and drawbacks? All right, so I'll go over this briefly.
00:10:56.520 - 00:11:40.202, Speaker A: I think everybody knows how Nakamoto's longest chain consensus work all the time. We're doing some local random lottery. Each node is trying to solve a puzzle. At some point, some node is going to solve it, and the winner of that puzzle is allowed to append one more block to the chain. And we keep doing that. And once a block is buried deep in the chain, we consider it committed or decided. So this longest chain protocol, this lottery based protocol, is what allowed Bitcoin to have dynamic participation.
00:11:40.202 - 00:12:21.450, Speaker A: So suppose suddenly half of the nodes, or more than half of the nodes, disappeared left the system. The protocol is still going to work at some .1 of the remaining nodes will solve the puzzle and become a winner. And at some point, another winner is going to show up. The rate of winners showing up will be reduced, but it will keep going. This is what makes the longest chain style protocol dynamic in terms of participation. However, it is also the reason for its long latency and the latency of longest chain particle.
00:12:21.450 - 00:12:50.680, Speaker A: I put a somewhat complex formula here. There are multiple factors that contribute to its latency. The first one is this confirmation depth. We say that you can only be confident of a decision if it's buried deep. How deep? That is usually a security parameter. In practice, it's six. But if you want to get a higher level of security, you may have to wait for dozens of blocks or even higher if you want a cryptographic level of security.
00:12:50.680 - 00:13:49.426, Speaker A: And this is just a simple illustration. If this confirmation depth is that too small, then there is a chance that a higher chain is going to show up and overtake what you believe to be the committed decision. Okay, so there are other things that leads to the long latency of Bitcoin. The second one is that there is a notion of block interval in Bitcoin, every block per ten minutes. And this interval needs to be set to be considerably larger than the network delay, than the message delay, upper bound. Otherwise your chain would not grow nicely as a chain. Otherwise, then there are concurrent solutions found, concurrent puzle solutions found all the time, and your blockchain will become a block tree.
00:13:49.426 - 00:14:31.400, Speaker A: And that reduces the fault tolerance of the protocol. So the higher fault tolerance you want, the higher latency it will be. So approximately, we always say bitcoin tolerates minority, but it's not really 50%, it's more like 49.7%, something like that. Some later systems, like Ethereum pushes this further by reducing the block interval. And then they're sacrificing their tolerance to something like 45, 46%. So we cannot push that too far.
00:14:31.400 - 00:15:34.934, Speaker A: And the last term is what I'll call the actual participation level. So if you think about it in a bitcoin style system, we kind of have to make a guess that how many people are around, how much computation power is around. And then we need to set a difficulty to make sure that a block shows up, on average about ten minutes. But if that guess is off, for example, if suddenly 80% of the people left the system, 80% of the computation power left the system, then you wouldn't get one block every ten minutes. You will have to wait for like 40, 40 minutes, 550 minutes for one block to show up. If the participation level is a lot lower than what you expect, the latency will increase. And on the flip side, these two are kind of two sides of the same coin.
00:15:34.934 - 00:16:52.960, Speaker A: If the participation level is a lot higher than what you expect, then you would lose fault tolerance. All right? So on the other hand, we have classic BFT protocols that following the line of work started, pioneered by Lamport and Shockstack and Peace and all the way to Paxos PBFT. All of these protocols, they, roughly speaking, follow a paradigm where we have a leader. One node serves as the leader, the leader makes a proposal, and the other nodes vote on the proposal, usually in two rounds, sometimes three rounds. And at the end of the two rounds, if both rounds of voting succeed, meaning that enough votes are gathered, then they will make a decision right there. And usually enough votes means one half of the total participants or two thirds of the total participants. And that's what we call a quorum threshold.
00:16:52.960 - 00:17:59.250, Speaker A: And hopefully you can see this style of classic BFT protocol has very good latency. It's going to make a decision in a few rounds, so it's a constant amount of latency. However, it doesn't support dynamic participation because it expects to receive one half or two thirds of the total number of participants to vote. And if, say, half of the people leave the system, then you will never be able to get a quorum of votes and the protocol loses its liveness. Okay? Now coming back to the central question of this talk, we have these two styles of protocols. One have dynamic participation but not low latency, the other has low latency but does not support dynamic participation. And the main purpose of this talk is to show you a new protocol that achieves both at the same time.
00:17:59.250 - 00:19:03.368, Speaker A: Let me just very quickly mention some related works that attempted the same problem, but some of them reduce the latency but doesn't quite get the constant optimal latency. And there's one work that did get constant latency, but it's targeting an unknown static participation, not really dynamic. Okay? So now let me make things a bit more formal, more rigorously. We have set of N potential participants. So this is permissioned because the list of participants is known to everybody and we have a PKI, everybody knows everybody's public keys. For now, I'll just keep the set fixed. I don't anticipate any problems to extend it to a changing set, to model stake changing hands.
00:19:03.368 - 00:19:49.672, Speaker A: But we haven't done the full analysis, so I don't want to make claims there at any time. T only a small Nt participants are active, the rest of the participants are inactive. And we do require an honest majority among the active. So less than half of Nt can be adversarial. Okay? And any participant can transition between inactive and active at any point. So this is the dynamic participation part and they can do so without giving any advanced notice. And it can happen in adversaries control.
00:19:49.672 - 00:20:40.772, Speaker A: The adversary can choose to say shut down these set of nodes and bring up another set of nodes without any constraint. I think technically we do have a constraint that the attacker cannot shut down everybody. Then nobody remembers what happened in the past. That's not okay as long as there's one honest node staying there. I also remark that we currently assume that the adversarial participant never goes inactive. But this is more of a technicality because if it's a bad node, since it's Byzantine, it can do anything. It can give its secret key to another bad node and then goes inactive.
00:20:40.772 - 00:21:50.140, Speaker A: That's as if it never goes inactive. So what I'm trying to say is that the protocol I'm going to show you should work fine if the adversarial participation actually fluctuates. But we don't know how to model that. We don't know how to model an adversarial participant goes offline if it reveals its secret key. The adversary can only go up, cannot go down. But yeah, what I'm trying to convey is that if we have a magic way to say that this 100 adversarial nodes, suddenly half of them are gone, only 50 remain and those who are gone did not reveal their secret key, then our protocol should be able to handle that case that adversary goes up and down. It's just that we don't know how to model or formally forbid these bad nodes from giving up their secret keys or giving up the future messages they would have sent if they were active.
00:21:50.140 - 00:22:53.000, Speaker A: That's why I think it's a technicality in terms of the model, not a limitation in terms of the solution. Okay, that's a short summary of our model. N total participants and only a fraction of them are active at any point and it can change at any point. And the problem we're trying to solve is kind of a variant of state machine replication or atomic broadcast. Participants send values and they want to agree on the ever growing sequence of these values. And there's one more important assumption we need to make in the model. That is there is a known upper bound on the message delay or this is the synchronous model and this has been shown to be necessary.
00:22:53.000 - 00:23:22.890, Speaker A: So Andy and Tim in the audience formalized this. If there is no such bound then essentially the network can partition. The two partitions should both make progress because the protocol is supposed to support dynamic participation. They do not know the existence of the other partition. They thought the other partition just went offline. They need to keep going on their own. Then there seems to be no chance in solving the problem.
00:23:22.890 - 00:24:19.930, Speaker A: Okay, so yeah, this is the otherwise the dynamics. Participation is impossible. I think I took out that one remark that Joe was asking what's the difference between this model and the sleeping model? Here we are assuming that a node, if it went offline, it knows it went offline. A node went offline by knowingly shutting down its computer. The last time I talked to Elaine she said she assumes that a node does not know if it's online or offline. Yeah, I have some reservations about that model, both its applicability and whether it's solvable. That's why I choose not to call it a sleepy model.
00:24:19.930 - 00:25:24.700, Speaker A: Okay, so now coming back to the classic BFT, we're going to try to extend it to support dynamic participation. And here is the main challenge. The main challenge is that it's based on a static quorum. So the quorum size is chosen based on the total number of participants. For example, half of n. So if very few nodes are online then you will never be able to get such a quorum. So we have to extend this notion of a static quorum to a dynamic quorum, that a quorum should be defined based on the actual participation, not the total population.
00:25:24.700 - 00:26:17.480, Speaker A: However, the problem is that we don't know the actual participation. So the best we can do is to define a quorum threshold based on the perceived participation. Meaning that I will ask the active nodes to send a message I am awake, I am here. And then we count how many I am awake messages there are and that is my perceived participation. And the quorum size, which is how many votes I require, will be set to be say half of the perceived participation. And again I use big n to denote total population, I use small n to denote the actual or perceived participation. My perceived participation may be different from yours.
00:26:17.480 - 00:27:12.580, Speaker A: That's the biggest problem we need to solve. So the challenge is that malicious nodes may announce them partially, right? So I tell Tim hey, I'm here, but I don't tell Andy. So they perceive different amount of participation, that means they will set different quorum thresholds. And the issue with that is then this set of votes which we also call quorum certificate is no longer transferable. So for example here node A perceived a higher participation level. So therefore node A require more votes to be in a quorum. So if there are like five votes here, so node B may consider that to be a quorum.
00:27:12.580 - 00:28:45.324, Speaker A: Node B will be happy and make a decision. However, if node B send this quorum to node A, node A will say no, that's not enough, that's not a quorum, that's insufficient number of votes, I'm not going to commit and that will be a big problem. So the central challenge in this work in this talk is to restore this notion of certificate transferability in the context of dynamic quorums. Okay? So let me say a bit more on that. Certificate transferability is very important in classic BFT but it's just so fundamental and so trivial there that we usually don't think about it. Now once we're aware of this problem, hopefully I can give you some intuition that this notion of transferability is routinely used everywhere in classic protocols. It's very common that in BFT protocols we have something like this if one node makes a move, then every honest node weekly support that move.
00:28:45.324 - 00:30:28.300, Speaker A: It's like if you want to get a paper accepted, one reviewer needs to champion it, the other reviewers need to be not against, need to be neutral or weekly supportive. There are many examples in the classic protocols it's very common that we have mechanisms to ensure that if one node makes a decision then every other honest node kind of locks on that decision, you can think of it as a soft decision, or if one node makes a soft decision, then everybody has seen that proposal. Something more concrete, if one node cast their round two vote, then we want to ensure that every other honest node has received round one votes, something like that. And this can be formalized with the notion of a graded agreement over there, if you're familiar with the problem, if you're not familiar with the problem, it's okay, it's not that important. But if you have heard about this notion, then it roughly says if one node outputs a value with a grade one, meaning that with confidence, then other node should output that value with lower confidence. There are many such steps in traditional BFT protocol and we usually don't even think about them because it's so easy to do to ensure this in classic protocols. Because all you have to do is to design the protocol such that a node makes a move only when it receives a quorum of votes.
00:30:28.300 - 00:31:32.770, Speaker A: And then you ask that node to forward this quorum of votes to everybody else. So they will also recognize that as a quorum of votes, they received it a bit later. So they will not be the strong champion of that move, but they will weakly support that move. So all of these things can be trivially guaranteed by this notion of certificate transferability. Right? Now if we can restore this notion of transferability in the context of dynamic quorum, then we can mimic the traditional protocols and basically follow their ingredients and follow their recipe and we will get a dynamic participation protocol. And the key technique is what we call a time shifted quorum. So step number one, if you've seen graded agreements, then we'll try to do graded agreement here.
00:31:32.770 - 00:32:28.020, Speaker A: So step number one, every node will send a pre vote message for the value it supports and also they will send awake one. This is the message that announced themselves. I am participating also. Yeah, I'm assuming lockstep rounds for simplicity. Now that the execution is divided into rounds, all the message sending happened at the beginning of the rounds and by the end of that round, all the messages sent in that round are received. So this is kind of idealized the model, we can get rid of it, but I'm going to assume that for simplicity, for ease of presentation, we're also going to ask everybody to forward all the newly received messages. Okay? So then in round two, first we will do the forwarding.
00:32:28.020 - 00:33:07.940, Speaker A: Everybody will forward these messages they received in round one. Additionally, we'll do accounting. Everybody will count how many prevote messages they received by the end of this round, by the end of the second round. And we'll call that variable V one. So bear with me, I'm dumping you, the entire protocol on you, but hopefully the intuition will be clear afterwards. Now, third round, every node will do another round of counting. They will count again how many prevailed messages they received.
00:33:07.940 - 00:33:57.920, Speaker A: So this is the total. So v two is certainly greater than v one. Greater or equal than v one, then they're also going to count how many Awake one messages they received by the end of the round three. And additionally, they're going to send awake two. That's another round of announcement that I am still here. Okay? Now lastly, if v two is more than half of m two, they were going to send the vote message. So this is saying the number of votes meet the threshold of a perceived participation.
00:33:57.920 - 00:34:44.080, Speaker A: Then they were going to do a proper vote. You can think of this as pre vote as the first round of voting and the vote as the second round of voting. Okay? Now lastly, they're going to count yet again the number of awake one messages received. By now they're going to call that m three and then they're going to make their moves. If v one is greater than half of m three, they're going to make their proper move. If number of votes is larger than half of number of Awake two, they're going to do the weak supporting move. Okay? So why does this work? Let's now bring in another node.
00:34:44.080 - 00:35:48.120, Speaker A: The property we want to ensure is that if one node makes the strong move, then everybody makes the weak move. Now let me first point out some important observations. Notice that the v one of any node will be no greater than the v two of any other node. In this case, let's say this node has a v one here that's no greater than the v two that any other node got in the next round. This is because we're doing the forwarding. So if this node seeing v one prevote, it's going to send them to everybody else, right? So by the next round, everybody will see everything this previous node has seen. Okay? Hope that's clear.
00:35:48.120 - 00:36:41.200, Speaker A: The same logic. The m two of this upper of a node is going to be no greater than the m three of any other node. Also because of forwarding right? Anything that was seen here will be seen over there. Okay? Now we are pretty much in business. Now if any node makes a strong move, so their v one is greater than half of v three m three. Let's say this bottom node is making a strong move. Now because of these two inequalities, if you look at any other node, their v two is greater than this guy's v one.
00:36:41.200 - 00:37:42.080, Speaker A: And their m two is smaller than this guy's m three. So if this v one greater than m three, half of m three holds for this one node, then v two greater than half of m two will hold for every other node. So that will make sure if one node makes a strong move, then everybody will vote. If everybody votes, then everybody will see that votes is more than half of awake two. So everybody will do the weak support. Yeah, that is pretty much the key technique in this work. Then we kind of got back this property that if one node makes a move, everybody is weakly supportive of that.
00:37:42.080 - 00:39:04.900, Speaker A: Yeah, I'll skip the detailed protocol, but from there the time shifted quorum can be used to build a graded agreement and the traditional BFT can be viewed as a series of graded agreements. Usually we don't view them that way because it only complicates things, but once we're in a dynamic situation, it's helpful to break down a traditional protocol as a series of graded agreements. And then we plug in that previous thing I just showed you and then we will combine that with a random leader election using VRF, VDF or any other mechanism. Then we will get a consensus protocol with expected constant latency. But it's not super efficient. Concretely, our graded agreement has seven delta latency, we need five of them and our total expected latency ends up being a fairly large constant. So some future directions can we get better concrete latency and can we reduce the communication cost of this protocol? Right now we're doing a lot of forwarding.
00:39:04.900 - 00:40:05.116, Speaker A: Everybody is forwarding every single message. That is fairly expensive. Having said that, I find the protocol very interesting. This is the first BFT protocol that handles dynamic participation and achieves a constant latency. It's very short list of some questions that I think are interesting and open. Motivated by this question I posed in the beginning. What else is novel, good and important in bitcoin? If we can identify these properties, then we can ask can we get them without paying for the proof of work? And longest chain latency of bitcoin style particles, to give you a few examples, the longest chain particles likely handle intermediate model between synchrony and part of synchrony, but we don't know what it is.
00:40:05.116 - 00:40:42.250, Speaker A: We haven't been able to formulate such one. Some examples, some other examples longest chain protocols should be able to tolerate some message logs, but we haven't been able to formalize them. Same thing for sparse gossip network. Is it an ad hoc trick or can we prove that in some model it provably solves consensus and lastly, incentives. It's also a big question with a lot of open problems there, right? Yeah, that is the end of my presentation. I'm happy to take questions.
00:40:47.500 - 00:41:00.220, Speaker B: You have you thought about extending this or the relationship with a sublinear communication model where you randomly sample who's participating in every round?
00:41:02.000 - 00:41:25.350, Speaker A: Right, we haven't tried it seems compatible to me. One challenge is then do you put a threshold, do you determine the size of the committee beforehand? What happens if the participation drops below the committee size?
00:41:26.840 - 00:41:40.664, Speaker B: It's interesting how in something like Algorandor, I guess anything with VRS where you kind of randomly pick who's eligible to participate in each round, you. End up with a random number of participants that you don't really know.
00:41:40.862 - 00:41:41.524, Speaker A: Right.
00:41:41.662 - 00:42:00.320, Speaker B: Nobody knows the number of people whose VRS hits the threshold. So it's kind of interesting. It's related to like you don't really know how many people are active. And in that case, it's not that people are asleep, it's just like they didn't get a winning ticket. You just have some probabilistic notion of what to expect. Right, I guess they could also have gotten a winning ticket.
00:42:02.360 - 00:42:22.250, Speaker A: Right? Yeah, that's a good observation. But I will point out that I think there is a difference in terms of how unpredictable it is. So with VRF, you have a fairly good idea that it's going to be very close to the target you set because of a law of large numbers.
00:42:27.980 - 00:42:37.852, Speaker B: They don't want it to be so big that the law of large numbers really kicks in. They're usually like 100 or 200 nodes.
00:42:37.996 - 00:42:53.684, Speaker A: Right, but I think at that level, law of large numbers, some would apply and you may get like 10% 5% error. But here we're really trying to target very wild swings and sort of the.
00:42:53.722 - 00:43:04.200, Speaker B: Steps of the protocol. Do you need the set of active nodes to stay fixed across those steps?
00:43:05.820 - 00:43:26.728, Speaker A: Yeah, that's a great question. We don't need it for safety. We do need it for liveness during this period. Okay. Yeah. Because the claim I made here is that if one person makes a strong move, then everybody makes a weak move. That's the safety lemma.
00:43:26.728 - 00:43:48.180, Speaker A: But it doesn't say that there will be one person making a strong move. That one part needs the stable period. So in that sense, we're kind of adopting the mentality of Apache Synchrony that we're going to maintain safety, even it's wildly swinging, but we're going to get liveness only when there is a stable period.

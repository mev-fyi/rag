00:00:09.160 - 00:00:41.060, Speaker A: Thanks everyone, for coming. So this talk is designed to be accessible to everyone, even if you're not familiar with zero knowledge. There are some of you in the room who are very familiar with zero knowledge. I hope it won't be too boring. And of course, one of the best ways to make sure it won't be is ask questions anytime. That goes for everyone, of course. This is a talk I gave one of the invited talks at Eurocrypt last year and it's really going to cover the different models for zero knowledge and how they've adapted in recent years.
00:00:41.060 - 00:01:36.952, Speaker A: And a lot of this, as I'll kind of claim, has been driven by the applications that we've been seeing for zero knowledge and the kind of constraints in which we want to use zero knowledge proofs. And so there's really this nice cycle of finding new applications, using those to inform new models, coming up with really practical zero knowledge proofs for these applications and then sort of attracting attention for other applications. So I'm going to talk a lot about modeling and kind of like use cases. I'm not going to talk so much about the details. There's lots of other places to find out about kind of how we build zero knowledge proofs. I'm sure those of you who stay around longer in the summer, like for example, when Justin comes, will also have the opportunity here to learn a lot more about that as well. So just to kind of COVID the definitions of zero knowledge, again, for those of us who might not be familiar with them.
00:01:36.952 - 00:02:28.388, Speaker A: So basically, in a zero knowledge proof, we have a prover, this parrot here, and they want to convince some verifier, this vulture, that basically there exists a witness w corresponding to some instance of a language. So basically they want to convince the verifier that some statement is true, namely the statement that this instance is in the language. And they want to do this basically without any interaction in a non interactive serial knowledge proof. And they want to do this really this is kind of what serial knowledge means without revealing any information about the witness that they hold. Okay, so the kind of setup is here the prover basically has the instance and a witness. They produce a proof, they send that over to the verifier. The verifier takes in just the instance, not the witness and the proof.
00:02:28.388 - 00:03:10.320, Speaker A: And on the basis of this proof, they either decide that, yes, this instance really is in the language, or they say, actually, I'm not convinced. Okay, so the two kind of intuitive properties that we want zero knowledge proofs to satisfy are we want them to be sound. Meaning it should be hard for the prover to convince the verifier if this statement isn't true. If this instance isn't in the language and then we also have zero knowledge, which is kind of what I said intuitively, that the verifier shouldn't learn anything about the witness. So in particular, the only information that they should learn is that, yes, the statement was true. The instance is in the language. Okay, so this is like very I mean, lots of us are very formal, but this is kind of very formal, very abstract.
00:03:10.320 - 00:04:14.904, Speaker A: So I thought I would use my favorite example of a zero knowledge proof, which is, where's Waldo? So, okay, some of you are nodding. That's already great. At Eurocrypt, I spent like three awkward minutes trying to explain where's Waldo? To people. Yeah, well, that's me, but yeah, so where's Waldo? You are trying to find Waldo or Wally or whatever you say in your country of origin. And so the idea is know, finding Waldo is hard, but the prover has already found Waldo and they now want to convince the verifier that they know where Waldo is. So how do they do this? So basically the idea is that there's this page in this book and it has some dimension M by N. And what the verifier is going to do is out of some opaque material, cardboard or whatever, they're going to cut out a rectangle that is basically twice as big in each dimension as the page, right? So it's two M by two N.
00:04:14.904 - 00:05:17.484, Speaker A: And now what they do is they kind of put this big piece of cardboard on whatever, they hang it up in a room. And this is kind of all the verifier can see, right, is this big piece of cardboard. And now what the proverb does is they kind of go behind the big piece of cardboard with the book or with the page, and the verifier can check that they don't have anything else on them. And then they sort of cut out this little window in the middle of the piece of cardboard. And the verifier can go up and inspect this and they can see that this is Waldo, right? And so there's really absolutely no way for the prover to cheat here, right? Either the verifier sees that Waldo is in the window or they don't. And then the prover had to know where Waldo was to hold this up or it's not Waldo and this is not convincing. And then in terms of zero knowledge, the idea is that because of the dimensions of this piece of cardboard, maybe the prover was holding up the page here.
00:05:17.484 - 00:05:43.764, Speaker A: Maybe they were holding it up here. It really could be anywhere behind this, right? We wouldn't see it kind of hanging out over the edge. We just don't see the page at all. We don't see the book. And so we don't know its position at all behind this large piece of cardboard. Okay, so let me get into these definitions in just a little more depth in terms of what they actually look like. Cryptographically, right? So hopefully the intuition is now quite clear.
00:05:43.764 - 00:06:29.172, Speaker A: But in terms of actually modeling them formally with games and stuff like that. It's not actually really clear. Like, for example, what does it mean to say that, oh, the Verifier doesn't learn anything, they don't learn any information about your witness. So what this means, right, so first things first, before we can define anything, basically we need all non interactive zero knowledge proofs need to have an extra thing that I didn't include in the original interaction, which is something called a common reference string or a CRS for short. So we know that this needs to exist. We can't do non interactive zero knowledge without it. But there's a lot of different options for kind of what this string looks like and what structure it has.
00:06:29.172 - 00:07:06.956, Speaker A: So this is very important. This is going to be very important later in the talk, I should say, when I get into kind of like the modern advances in serennology. So this reference string can be completely random, in which case we call the setup for the zero knowledge proof trustless, meaning we don't need anyone to generate it or anything. We can just pick random numbers or it needs to have some kind of structure. And if it needs to have some kind of structure, then we call this a trusted setup. So again, we'll see these terms later on. And then also this common reference string can be specific to a given relation.
00:07:06.956 - 00:07:58.268, Speaker A: So it can be used only to prove things for a specific language or it can be universal, meaning you can reuse this common reference string for many different types of circuits for many different things that you might want to prove. Okay? But basically we need this common reference string to sort of come from somewhere and we need the prover and the Verifier to both have access to it. Okay? So then the way we define zero knowledge is we say that now the Verifier here is the adversary. And the goal of this adversarial Verifier is of course to learn information about the proverbs witness. So what we do is we say, okay, you can have your interaction with the prover. That's one thing that can be happening. The other thing that can happen is that we can actually replace the prover with a simulator.
00:07:58.268 - 00:08:44.764, Speaker A: And this simulator is actually not going to know the witness at all. They're going to run some kind of simulation algorithm that takes in the reference string and only the instance, they don't know the witness and they're going to output a proof. So of course, the way I've written this, this doesn't look good. Like the simulator can't just take in the reference string in the instance and be able to convince the Verifier that would violate soundness. And so the idea is that basically the simulator can also participate in the generation of the common reference string. And in generating the common reference string, they can output some simulation trap door that allows them to basically fake proofs. All right, instead of just outputting the CRS.
00:08:44.764 - 00:09:34.880, Speaker A: They're going to output the CRS and this trapdoor, and then they're going to keep that trapdoor around for themselves when they go to simulate proofs. Okay, so we sort of have now these two different interactions. One with an honest prover who knows the witness, one with a simulator who doesn't know the witness at all, but knows some sort of, like, universal trapdoor. And we basically say that zero knowledge holds if this Verifier can't tell which of these interactions is happening, whether it's interacting with the honest prover or with this simulator, who, again, does not know the witness in any way. So, yeah, that's zero knowledge. And then we say that we have perfect zero knowledge if, in fact, these distributions are identical, not just computationally indistinguishable.
00:09:35.860 - 00:09:44.036, Speaker B: It's been a while since I took a crypto class, but I remember, I think, seeing a definition without a trapdoor that just said that the Verifier can.
00:09:44.058 - 00:09:54.372, Speaker A: Simulate the entire interaction, that's probably for interactive zero knowledge. When you talk about rewinding and producing a transcript, is there a relation between these?
00:09:54.506 - 00:09:56.864, Speaker B: Is there a relation between you or they're just different definitions?
00:09:56.912 - 00:10:43.510, Speaker A: Like, if you have a Sigma protocol, you can transform it into a non interactive zero knowledge proof using the fiat shamir. Heuristic right. So Sigma protocol is basically the prover sends a message, the Verifier sends back a fully random challenge, and then the prover responds with the third message of the protocol. And so the idea is that you can collapse this by just replacing the fully random challenge with a hash of the first message. And if we're in the random oracle model, this is as good as having the Verifier pick the random challenge would. But the way you would prove security for that kind of protocol is you would still prove it using the interactive style definitions. You would still talk about rewinding and issuing two different challenges or something like that, and then you would just let fiat shamir take care of the rest.
00:10:43.510 - 00:11:37.080, Speaker A: The way I've defined sort of the definition I've given here is really soundness, right? I say there exists some witness for this statement. Often what we want to show is a little stronger. We want to show not only that there exists some witness, but that actually, I know this witness, right? So when we start thinking about how zero knowledge gets used, especially in cryptocurrencies and blockchains and stuff, it's often not really useful to say, oh, yeah, someone out there might know the witness, or it just exists in a mathematical sense. It's really important to say that actually I know it right. So, for example, going back to the kind of where's Waldo example, it wouldn't really be very interesting for the prover to Wally Waldo no, I'm English now. Embarrassing, Waldo is on the page. I'm embarrassed.
00:11:37.080 - 00:12:24.676, Speaker A: So, yeah, to say, oh, Waldo is somewhere on the you know, there is some configuration of the know such that if you hold it up, you'll see Waldo. It's more like, no, I want to know that you found Waldo and that you know where it is. So this is a kind of stronger definition that we can call a proof of knowledge. Or really, again, the way we capture this formally is not necessarily super intuitive, but it's this idea that we can extract the witness from any verifying proof. So now the idea is that the prover is the one who's adversarial. They're trying to convince the verifier of something that is not true, or yeah. And so, again, we kind of do a similar thing.
00:12:24.676 - 00:13:30.030, Speaker A: We can say that we're going to replace the verifier with this emu extractor, and we're going to say that basically what the emu can do is they can run this extract algorithm that takes in the instance and any verifying proof, and from that can output a witness for the instance right. Can output a witness such that X and W are in the relation. So, again, this is way too sketchy. You can't run this algorithm as I've stated it, because this would completely violate zero knowledge if anyone could do this. So, again, we're going to just do the exact same kind of thing. But on the other side, we're going to say that, hey, how about we have the extractor generate the CRS in some special way so that instead of just generating the CRS, they also output an extraction trap door, and then we're going to require that extraction trap door to be able to extract witnesses. And so then we can say that extractability holds if there exists a polynomial time extractor that can do this.
00:13:30.030 - 00:14:16.984, Speaker A: And then we say that this is a proof of knowledge if this can be done for all provers computationally unbounded, and that this is an argument of knowledge if this works for all polynomial time provers. So, again, it's not always like, basically, this is the best we've come up with for saying that a Turing machine knows something is being able to extract it. Yeah. So, again, not always the most intuitive, but hopefully not too shocking either. So let's talk about constructions. And in particular, I want to focus on one particular aspect of zero knowledge. So on the left, we kind of have the assumptions that they're based on.
00:14:16.984 - 00:15:12.044, Speaker A: So we've got, like, discrete log pairings, collision resistant Hash functions. This little symbol means that it's like Plausibly post quantum secure. And then on the bottom here, we're going to have the size of the proof, and this is linear or whatever in the size of the witness. Okay. There's sort of a feasibility result that sort of says, oh, we can get the size of the proof to be polylog in the size of the witness. But by and large, for the first sort of two decades, three decades of research into zero knowledge, we were really sort of, like, not stuck, but we were really in this column in terms of having the size of the proof be linear in the size of the witness. And yeah, that's basically where all of the constructions were.
00:15:12.044 - 00:16:09.580, Speaker A: And then there was this kind of breakthrough result in 2009 by former colleague of mine Jens Grott and he showed that you could actually have the size of the proof be sublinear in the size of the witness. So this is what we now call a succinct non interactive argument of knowledge which you may know by its very trendy name, a Snark. So just to show you the distinction there, a Snarg is also a thing and that's when you don't have extractability you just have soundness. And then the knowledge part is when you're guaranteed extraction. I guess also Snark sounds better than snark. Okay so that's sort of where I'm going to leave things for now with the development of zero knowledge. And then the other sort of thing I want to talk about that was happening at roughly the same time I guess as Jens work was the kind of development of blockchains.
00:16:09.580 - 00:17:13.516, Speaker A: I'm just going to go through this fairly quickly I guess I'm assuming a lot of people here are familiar with this. So a blockchain is basically just an ordered collection of transactions. So each block is basically just a list of transactions sort of in a committed form. And the way things work today at least like in an L1, is that all transactions in the chain basically get captured by all peers in the network which we can consider to be the full nodes and then they all get sort of replayed to ensure that they all agree on the current state of the blockchain. Right? So we sort of all play through the transactions in order and in that way we can agree in a simple, let's say bitcoin or something in terms of just like transfer of coins. We can all sort of replay the transactions and then that way we can all agree on who has coins at this given point in time. So let me sort of give basically the simplest sort of thing.
00:17:13.516 - 00:18:13.604, Speaker A: We could be trying to maintain the simplest state which is really just like balances who has how much money at a given point in time. So let's imagine that we have our four birds and they're all going to have registered addresses in the system, so we can have sort of some tree with all the leaves representing their public keys, and then we can sort of have a concise representation of this in terms of the root of the tree. And then we can have another tree representing the balances associated with each of these addresses or keys. Right? And so we're going to want to maintain the leaves in the kind of same order. And so the idea is that transactions are just going to be very simple transfers. So we're going to have the index of the sender, the index of the recipient, the amount being sent, and then a sort of signature on all of this to make sure that people can't spend each other's money. And we're going to say that this transaction is valid if the sender has enough money.
00:18:13.604 - 00:19:09.216, Speaker A: Meaning when we go and we look in this balance tree at their index, the amount that's stored there is greater than or equal to the amount they're trying to send. And that the signature in this transaction. Verifies meaning under the public key that we obtain from the address tree, the signature on the rest of the transaction data verifies that's sort of making sure that transactions are good. And then the other thing we can do is if we do think a transaction is good, we can process it, meaning we can incorporate it into the global state, right? We can replay the transaction and use it to update the state and see what the new state is. Right? And so processing this, again, quite simple transaction basically means that we take the amount that's being sent, we subtract it from the sender's balance and we add it to the recipient's balance. Yeah. Okay.
00:19:09.216 - 00:19:55.604, Speaker A: So in terms of checking transaction validity, oh, this is an example, I don't know if we need an example for this group, but I'll go through it really quickly. So let's imagine everyone starts with ten coins and then the idea is that when we go to verify, let's say we have a transaction and the parrot is sending what is that, a seagull? There we go. The parrot is sending two coins to the seagull. No, to the emu because it's a zero node to the seagull. I can't count. And so, yeah, so we're going to use their public key to verify the signature. And then when we go to process a transaction, we're going to again subtract two from the parrots thing.
00:19:55.604 - 00:21:28.944, Speaker A: So now they're at eight and then the seagull is now going to be at twelve because they're going to get those two. And just to note, the other sort of concrete thing is that then the root of this balance tree is going to be changing constantly as we process these transactions, right? So the changes we make in the leaves are going to propagate up to the root and this will result in a new root of this tree. Whereas if we assume like a static set of participants, the address tree is basically never going to change. Okay? So this is just like a kind of formal statement of these things so that you can see where you've probably already seen where I'm going. But I'm just writing this out in terms of what I've just said, but showing this as an instance and a witness in some relation, right? So we have the kind of like validity relationship which says that the information in this transaction is valid and then we have the kind of like state update relation which basically says that as I'm processing transactions into the current state, I'm producing this new state. So the old state is like in black here and then the new state is in purple and the idea here is that I'm proving the kind of correct relationship between the new state and the old state. Okay? So now let's sort of consider again the model that we currently have for how the state gets updated and how participants sort of hear about it and react.
00:21:28.944 - 00:22:57.970, Speaker A: So let's imagine we have a full node represented by this flamingo and so being a full node in this miniature system basically means that they maintain full copies of both of these trees, the address tree and the balance tree. And now the idea is we have participants and they're sort of broadcasting their transactions out into the network. These transactions are getting heard about by some relayer and they're just kind of collecting them and then at some point what they do is they put all these transactions into a block, right? So we can already phrase this in a slightly different way than what would happen like today, which is we can have the kind of header of the block be the root of the address tree and then it can be now the new root of the balance tree taking into account all of the transactions in this block. Right. And then the body of the block can contain all of the transactions. So the idea is again, like how do things kind of work today? The idea is that the full node is basically going in order to check is everything valid here? They're basically going to replay all of those transactions and by replay them, I mean they're going to apply them sequentially to the state that they have stored and then they're going to get the new state, this purple one, and then they can compare it against what's in the header of that block. But fundamentally they're taking all the transactions and replaying them and that's kind of the way we have to do things.
00:22:57.970 - 00:23:32.716, Speaker A: Yeah. And then of course if they're happy then they're going to update their balance tree with the new information. Okay, so let's imagine doing things a different way. Very conveniently. Of course I've phrased this all in terms of statements in a given relation. So let's imagine that in the block, in the body we can say okay, here's the new balance tree for those of you who care about these things and who want to have that information. And then here's also a proof for those two different relations.
00:23:32.716 - 00:25:06.664, Speaker A: So one, a proof that all the transactions that I sort of factored into this block are valid and then two, a proof that I processed all those valid transactions correctly and that I really used them to produce this new state. And so the idea is that now what does it mean to check if this was okay? Well, basically this just means checking. So the instance here is just like all the roots of all these trees, right? So the root of the address tree and then the two things like the root of the old Balance tree and the root of the new one, and then just this proof. And so the idea is that the full node can still check this and they can still sort of look into the body of the block, take the new Balance tree and use it. But conveniently, light clients who don't want to maintain the full state, who might just be maintaining the headers like the roots of the trees, can also perform this check, right? So we can have sort of more people doing this. And yeah, this is kind of the idea really behind something like a roll up for those of you who are familiar with such things. So something super funny about roll ups and about the use of zero knowledge proofs in roll ups is we don't care at all if they're zero knowledge, right? We don't care if the proof were as large as the witness, meaning the list of transactions, then this would not help us in any way.
00:25:06.664 - 00:25:38.272, Speaker A: We would not be interested in this at all. So we actually don't care that these are zero knowledge proofs. The only property that we're interested in here is Succinctness, right? So there's no point in using general zero knowledge proofs. There's only a point in doing this if we're using things like Snarks. This is like a ZK roll up and it's funny because the ZK is totally unnecessary. But there are other sort of types of roll ups where we do care about having zero knowledge. Like maybe each individual transaction you prove something about it even to the relay server.
00:25:38.272 - 00:26:43.770, Speaker A: But anyway, this is kind of, again, really funny, especially since this industry has been very excited about zero knowledge proofs and very excited about adopting them. But maybe it's not surprising that this graph I showed of kind of the constructions we have, a lot of the work over the past decade plus has really been on shifting this very far to the right, right? So again, this feasibility result in 2009 said that the size of the proof could be sublinear in the size of the witness. A lot of the work has been on making the size of the proof constants in the size of the witness. So for example, the state of the art today, this is again Jens construction by Jens. The proof has three group elements and it requires three pairings to verify. And that's true literally no matter what the size of the witness is. So that's crazy, right? Like that we can do that.
00:26:43.770 - 00:27:30.968, Speaker A: So let me sort of say there are obviously downsides, right? It's not like we can just do whatever we want, whenever we want. So one of the big issues of Snarks in particular, so the term snark, I guess is very complicated. It means different things to different people. So if I say snark without anything in front, you can probably assume I'm talking about a constant size snark, meaning where the size of the proof is constant. So one of the big things that people have been chipping away at quite steadily over the past really like three years is focusing on this question of prover runtime. So for a lot of the constructions we have, the runtime of the prover is n log n and also like big constants. It's not just like an asymptotic thing.
00:27:30.968 - 00:28:34.828, Speaker A: There's been a lot of really cool papers recently focusing on having the size of the prover be linear rather than n log n. And the only thing I'll say about that just to I mean an area I think is cool is that area. But also I'll just mention so a lot of the complexity of these circuits for Snarks revolves around hash functions. So encoding Shaw 256 inside a circuit requires a huge amount of constraints. So I just want to very briefly mention a really, I think, interesting line of work looking at coming up with Snark or stark friendly hash functions. So for example, even something like Peterson, which is like an algebraic hash function, is much friendlier in terms of the number of constraints it requires, which I've kind of highlighted here. So yeah, this is using Socrates to basically say how many constraints do we require just to prove knowledge of a hash pre image basically.
00:28:34.828 - 00:29:30.104, Speaker A: So we can see it's like an order of magnitude for Peterson as compared to Shop 256. The downside of Peterson is it's kind of like slow to compute outside of this circuit. And so yeah, there's recent works like Poseidon for example, that kind of tried to get the best of both worlds and in fact get better than Peterson in terms of the number of constraints. So yeah, that's just like a very brief know if that's something people are interested in exploring further. So the current constructions that we have by and large for constant size no, actually all the constructions that we have for constant size Snarks require what's called a structured reference string. And so again, going back to this idea, the common reference string, I said it could be either random or it could be structured. And having a structured reference string basically means sort of relying on these trusted third parties in some way.
00:29:30.104 - 00:30:01.016, Speaker A: So let me sort of get into that a bit more. So there's really sort of four ways that we can consider of how to generate a reference string. So these are shown here. We can have a sort of completely trusted approach, a subverted approach, a transparent approach or a kind of general multiparty computation. So let's first look at this idea of the trusted setup. So let's imagine that we just have one party generate this structured reference string on their own. So.
00:30:01.016 - 00:31:11.330, Speaker A: Why does this mean that we have to trust that party? It's not necessarily obvious, and in fact, it's not like a universal fact. Like, you could imagine having systems where one party could generate it, but not necessarily know the trapdoor. But I said a lot of the focus we have is on perfect zero knowledge. And so what that means is that actually the process of generating even the honest structured reference string essentially, incidentally produces the simulation trapdoor, right? So like these algorithms for generating the simulated reference string and for generating the honest one are actually the same algorithm. So I said I would finally give like an example. So for example, if we just have a really simple structured reference string which just consists of these kind of like monomials in alpha, in the exponents, we have like g, g to the alpha, g to the alpha squared, g to the alpha to the Q. Then the idea is that the simulation trapdoor here is just alpha and that basically there's no way to generate this reference string without knowing alpha yourself.
00:31:11.330 - 00:32:19.924, Speaker A: So does that make sense? Great. Okay, so the idea is that this tau that you learn in generating the reference string single handedly is the simulation trapdoor. And if you remember the definition of zero knowledge with the simulation trapdoor, you can provide proofs of false statements. So in, for example, something like Zcash, if we allowed one single party to generate the reference string, then that one single party could spend coins that they don't have, right? Because they could provide convincing proofs of I'm sending money that I have put into the shielded pool, but that would be a lie. But they could do it anyway because they could simulate those kinds of proofs. All right, so this is why this is not really realistic in any deployed system, right? Like there are real consequences of allowing a single party to do this. And even if that party is very nice and very honest, they would have significant financial incentives to use that simulation trapdoor in some way.
00:32:19.924 - 00:33:33.288, Speaker A: And so we really wouldn't feel comfortable with such a system where one party would have all that power. Okay? So let's kind of go to the complete other end of the spectrum and let's consider a subverted reference string setup where basically now we can say, you know what, the adversary can just fully generate the reference string themselves however they want. So this was considered by a paper at Asia Crypt 2016 by Nihir Balari, Georg Fuchsbauer and Alessandro Scafuro. And the idea here is these are very strong definitions, basically. So if we define subversion soundness, then we want to say that even if the prover fully subverted the reference string, meaning they fully know the trapdoor, it should still be hard for them to prove false statements. All right? And then on the other side we can talk about subversion zero knowledge, which says that even if the verifier, the adversarial verifier fully subverted the setup process, meaning they fully know the trapdoor that they still can't break zero knowledge, they still can't tell if they're interacting with the proofer or with the simulator. So again, these are very, very strong definitions.
00:33:33.288 - 00:34:15.930, Speaker A: And so maybe it should come as not a big surprise that one of the main results in this paper is a big impossibility result, which basically says that you cannot achieve subversion soundness and regular zero knowledge at the same time. So for those of you who are interested, they do have some positive results. For example, they show that you can achieve subversion soundness and subversion witness and distinguishability at the same time, which is like a weaker notion of zero knowledge. And they show that you can achieve subversion zero knowledge at the same time as regular soundness. But to be honest, the one we're really interested in is the first one. And so we just know that we can't do it. So that's unrealistic as well.
00:34:15.930 - 00:34:56.440, Speaker A: So transparent setup basically says that you just generate a uniformly random string. And this is kind of the idea of a Stark. That's what the T sort of stands for. So I'm not going to say much about really there's people in this room who are much more expert in Starks than me. Justin is probably going to come and tell you all sorts of exciting things about Starks. The thing I will say is there is a trade off, right? So in general, you can't get constant size proofs, there are polylog in the size of the witness. But on the other hand, you do get this really nice property that you don't have to trust anyone for the setup.
00:34:56.440 - 00:35:01.416, Speaker A: That's really all I'll say there. Yeah.
00:35:01.598 - 00:35:25.890, Speaker B: So in the transparent setup, the reference string is random. And if we have, say, a random oracle, a random function that gives us randomness, or if we say that the digits of pi, I don't know, behave randomly, then that actually then leads to subversion. It just probably is not in the plain model. It's just in, say, random.org model.
00:35:26.420 - 00:36:07.660, Speaker A: There is no subverting the process if the process is just like hash pi. Okay? So the last thing I'll talk about is this last model, which is basically, okay, we can't really let any one person do it. So let's just get a kind of bunch of people together and have them generate the reference string together. All right, so this has been done a lot. So researchers have spent a long time developing optimized. If we just wanted to use general MPC, this would be slow. MPC is not really designed to scale to that many participants.
00:36:07.660 - 00:37:19.140, Speaker A: And so researchers have spent a lot of time developing optimized NPC protocols for this exact problem right, for generating these structured reference strings. So, yeah, this has been also run in practice in these kind of complex ceremonies. So, for example oh, yeah, sorry. No, that's actually the next point I wanted to make. Well, before I get to the idea of universality, I'll just say again, these things have really been designed to kind of scale, to tolerate dropouts, to work really precisely for this setting. But there is this downside of doing these kind of ceremonies, right? So one is, well, you're still relying on all those people to not collude, right? So if there's a small number of participants, that's kind of why we care about scaling them, I should say, to a large number of participants, right, because essentially if all of them collude, then they can take their randomness that they used and piece back together the trapdoor and then that's too bad. So that's kind of why we really care about having more and more participants, to convince ourselves that it's more and more likely that not all of those participants would get together and collude.
00:37:19.140 - 00:38:08.340, Speaker A: But the other sort of downside, aside from the fact that, well, we're still sort of trusting in some sense, is that if the reference string is not universal, meaning it doesn't work for kind of all the circuits we might want to consider proving, then we need to rerun it, right, basically every time the protocol changes. And this isn't just hypothetical. So Zcash has actually done this. So in the first sort of iteration of the Zcash yielded pool sprout, there were six participants in this trusted setup ceremony and then they sort of changed the zero knowledge proof they were using. They made a lot of changes in the protocol. And so for this second ceremony for Sapling, they by that point had developed much more optimized NPC protocols, so there were a lot more participants. But crucially, it did have to be rerun.
00:38:08.340 - 00:39:11.720, Speaker A: And now I should say, if I am talking about Zcash concretely, they've really, two weeks ago or something, just got orchard out. So that gets rid of the need for trusted setup ceremonies, which is cool, but yeah, but hopefully the point remains that every time we rely on trusted setup ceremonies, we're just going to get ourselves into this cycle where every time we want to patch or update, we're going to need to consider the complexity of running this kind of process. Which is a complexity, for sure. So I just want to very briefly mention, I do want to leave time for questions. This kind of alternative idea that I developed along with a bunch of my collaborators, jens Grott, Merkel of Kulweis, Mary Mallor, Ian Myers and Sean Bowe at Zcash. And this is the idea of an updatable snark. So this work, I think we started out focusing a lot on updatability and being kind of inspired by that and the model for it.
00:39:11.720 - 00:40:45.684, Speaker A: But one of the main sort of side effects of this work in some sense was actually coming up with actually having a snark that gave you a universal reference string instead. But yeah, so the idea of an updatable snark is that we sort of start out and someone says, okay, here's the reference string as I see it and I know the trapdoor from it, okay, like full disclosure, I know the trapdoor because so far it's just me who's contributed to it. And the idea is that this is a universal reference string from which sort of circuit specific reference strings can be derived, okay? But what everyone is going to be contributing to and agreeing on is the universal reference string and then they have this kind of update proof which basically says, okay, I took what was there before, which for now is nothing, and I folded in my additional randomness alpha, okay? And this proof can be made public, it can be publicly verified against, again, the kind of using as the instance like the previous reference string and the new one. And so the idea is that right now this is like a fully trusted setup, right? The parrot has fully generated the reference string by itself and they fully know the trapdoor behind it, they fully know the randomness. But now another participant can come along and can say, well, hey, I'm going to fold in some additional randomness myself and then maybe the parrot comes along again and is the next one to fold in randomness. But basically this process can kind of just continue indefinitely. This process is also open to anyone.
00:40:45.684 - 00:41:51.992, Speaker A: Anyone can come along and say, hey, I'd like to participate. And so the idea is that no one is going to know the trapdoor if we just think of the trapdoor as like some combination of all the individual bits of randomness. As long as one party is honest, no one is going to know the trap door. And so crucially, if you don't trust the existing set of participants, just jump in and update it yourself. And now you do because hopefully you trust yourself to throw away your own randomness or whatever, right? So this process doesn't have to have an end and that's quite different because you could say, oh, surely this is just like itself an NPC and in some ways it is, but the idea is that it's not sort of time bounded. We don't say, okay, now everything's done and this is the structured reference string, we can just continue updating it on the fly. And so really what we can think of this is as sort of like augmenting the security that we would get from a ceremony or something like that, right? So we can say, okay, we can run the ceremony, we can generate a sort of like candidate reference string.
00:41:51.992 - 00:42:35.530, Speaker A: Maybe some of us already really believe that this reference string is good and that those parties weren't colluding. But then the idea is that in a blockchain we already have this very sequential process that's going on, right? We're already sort of generating these blocks. And so the idea is that we can just sort of stick these update proofs into the blocks and it's like a quite seamless integration. Right? So again, this is kind of a nice example of where that we sort of looked at the existing structure. We said there's already these parties that are generating things in a sequential way. We're already trusting them to not all collude, right? We're not making any additional assumption at all. They already have a huge amount of computational power.
00:42:35.530 - 00:43:23.960, Speaker A: So this is really not adding a lot of overhead in terms of what's there. And again, the idea is that full nodes can actually verify these individual update proofs. That's kind of the story. So Jonathan Boudel had this lovely sort of rainbow slide showing this amazing kind of activity that's been happening in this space over the past really like ten years. Honestly, this is a little out of date, I should say. Sorry if your protocol hasn't made it to you, but yeah, I think it's really incredible. Zero knowledge is what got me into cryptography and it's really cool to see how this has all happened.
00:43:23.960 - 00:44:37.404, Speaker A: So, yeah, hopefully I've convinced you that it's a really active space, that's for sure. It's a really exciting time to be working in this space. And again, I think there's a real the thing that's really exciting is that it's not all just about making things faster, right? So I think we got things to a point where they were faster, proofs were smaller, things were really genuinely practical, and so that kind of attracted the attention of people interested in using their knowledge, proofs and applications. But I think that it's not just like, oh, here you go, take the fast proof and go away. Really working with people, actually deploying this stuff has in turn really fed back into the theory. Again, not just making things practical by counting bits and stuff, but also coming up with these new models, coming up with things that sort of work in these models. So the whole idea of universality, for example, I feel has a really natural motivation now, whereas before I felt it wasn't explored quite as much because it wasn't as clear why it was really important, whereas now it's like, do you want to have to do this every time you patch your software or something? So I think it's not, again, just about making things sort of faster and smaller.
00:44:37.404 - 00:45:06.570, Speaker A: It's really about really about considering the constraints that people are working with and coming up with solutions, modeling that. And yeah, it's been really exciting. I think there's a lot of ways to contribute, not just the kind of cryptographic, like coming up with the proofs, but really many other things. And I hope I've convinced you of that a little bit in this talk. And yeah, thanks a lot for listening. Happy to take more questions.
00:45:09.900 - 00:45:27.276, Speaker B: Maybe I'll start go back to Jonathan blue's slide. So I guess in the green row on the very far right you have examples of designated Verifier snarks?
00:45:27.308 - 00:45:27.890, Speaker A: Yes.
00:45:28.820 - 00:45:31.712, Speaker B: Do you see applications for those? Where do you think those are useful?
00:45:31.776 - 00:46:32.128, Speaker A: The question was so for lattices the only constructions we've seen of constant size snarks are of designated Verifier snarks which basically means that only a specific entity or something can verify it's not publicly Verifiable. I am not the best person to answer that question. I don't personally know of any I mean obviously in something like a public blockchain it's not necessarily the most natural fit but I am also not that active in that particular space. I mean my sense is from at least some of the authors on these papers and then the later work that they've done I feel like it's almost like oh, we want to build a constant sized narc but we can't quite get there but if we make it designated Verifier then it becomes feasible. So it's almost just about understanding the techniques rather than saying oh yeah, this is necessarily that in and of itself very well motivated.
00:46:32.224 - 00:46:35.520, Speaker B: So are things like a lot easier in that case or is zero knowledge hard?
00:46:35.610 - 00:46:59.256, Speaker A: It's actually funny that's a great question. Basically perfect zero knowledge. It just comes for free. Essentially. Often the proof of soundness is this tortured many page proof with a really complicated definition. And in this other the algebraic group model, which is the only place we can actually prove soundness. And then the proof of zero knowledge is like three lines.
00:46:59.256 - 00:47:12.168, Speaker A: It's just like everything's random, it's fine. So yeah, there's basically no benefit if you say oh yeah, I don't care about zero knowledge it's not like you're just going to get much better constructions.
00:47:12.364 - 00:47:28.410, Speaker B: Go back to the slider too where you had the updated Volkswagen in the blockchain. Do you imagine you could actually update in every block of the chain or what's the cost of redistributing the SRS to everybody?
00:47:28.780 - 00:48:18.970, Speaker A: Yeah, so I would not imagine doing that. You could have it be like every fixed number of blocks or something like that. And then it would just take longer to kind of believe the non collusion property. But yeah, the question of how to get the SRS is challenging. And I mean, I should say anyway, for those of you who follow this space more closely, I don't really think we're going in this direction, right? Because basically people use the techniques in Sonic and stuff to come up with things like Halo which don't require any trusted setup. And so that's more the direction things are going rather than relying on updatability. So that's why I think a lot of the practical details of this haven't been worked out because people have come up with better things.
00:48:18.970 - 00:48:37.260, Speaker A: But yeah, I guess you could imagine having the reference string be stored somewhere not on chain, because it's big. And then anyone given the update proofs could kind of work out, could take that base thing and replay everything and get the new reference string.
00:48:37.600 - 00:49:15.370, Speaker B: I don't know if I actually agree. Plonk uses exactly this model, and it's very widely used now, at least from what I've seen. What happens is that someone did the first version of the website and then new projects say if they adapt it, then they add some random. Maybe not every block, but certainly every project. I mean, that's what probably I would advise the project. If they wanted to use some reference string, then they should take whatever one Aztec is using and add some randomness and maybe get some third parties to add some randomness and then you can use it. And I think that's a beautiful process.
00:49:15.900 - 00:49:28.430, Speaker A: Yeah. So that is something you see a lot like bootstrapping off of existing ceremonies, basically, exactly like I've put here. But yeah, instead of being happening on the blockchain in a regular way. Great.
00:49:29.860 - 00:49:36.400, Speaker B: Where will we be in ten years in terms of knowledge? What do you think the world will look like?
00:49:36.550 - 00:49:37.730, Speaker A: I have no idea.
00:49:39.220 - 00:49:44.610, Speaker B: Do you want to answer? If we decrease ten to five, gives you a descending auction, how many years?
00:49:45.700 - 00:50:33.190, Speaker A: Yeah, it's just like it's all happened. It's all happened so fast. It's been so insane. I literally can't imagine. Basically, I think a lot of the applications I'm interested in, I think we got a lot of mileage out of the original development of Snarks with really crazy small proofs and really fast Verifier runtime. But I feel like now we're bumping up against applications where Oops, like, prover runtime matters a lot too. And that was kind of the part of the talk that I didn't have time to get into, which is like, situations where provers are run in real time, right? Like as I stand there in front of you, or like they're run on my phone and with constant size Snarks and stuff, this is very out of the question.
00:50:33.190 - 00:51:42.824, Speaker A: Even if we dial it back and we use Starks and stuff like that, the prover overhead is very significant. So I kind of hope we find a nice middle ground, basically, where each of these things is fine, where the prover runtime just doesn't completely blow up the second, we want to make the proof and the Verifier runtime pretty fast, but we're going in that direction for sure. I hope we just continue in that direction because I think right now there are a lot of really cool applications that are just that are attracted to this space because Snarks are trendy and cool, but they can't use them at all because the proverb runtime is just so large. So the idea is here. So for private aggregate computations, the idea is that we still really care about Verifier. This is actually kind of what I was getting at with these applications. We really care about Verifier runtime because this central aggregate server has to verify all of the individual proofs that it's given.
00:51:42.824 - 00:52:37.012, Speaker A: We still really care about the size of the proofs because if the provers are on a phone, then this is like bandwidth costs that's like data budget for them. But really prover runtime is a super big constraint. So there's kind of been these just very cool papers. Like, Prio is the best example. And the idea here is we can get the prover to be a lot faster if we just change the model for how things are verified. And if we say, hey, rather than just have one Verifier, what if we have two Verifiers? And we say that these Verifiers can't collude, but somehow they're going to jointly verify these shares of what the proverb creates? And so this is, again, just like an interesting take, like an interesting switch of the model. And that's enabled a lot of really real applications.
00:52:37.012 - 00:53:12.672, Speaker A: So namely exposure notification. The idea is like, Apple and Google are not going to collude, but now we can do things on our phones. And then in general, like ISRG, which is like the nonprofit behind the let's Encrypt Certificate Authority will basically run this as a service. So they'll be like, I won't collude with you. I'll be the other server for whatever you want to do if you just pay me to do that. So that's kind of the summary of that part of the talk. But yeah, just another way that changing the model allows for really dramatically different constructions.
00:53:12.672 - 00:54:04.930, Speaker A: Not just like optimizing what we currently have, but just coming up with something completely different. Do you think it still makes sense to look into specialized protocols, not like general centric protocols and specialized protocols for specific statements? Or do you think we should be mostly focusing on optimizing? Still for sure, in my mind, like a place for that. So, yeah, again, I think this is kind of what we see happening. We've pushed things super far in terms of general computations, and now, especially as we work with more and more practitioners, we're starting to see more specialized things crop up. But then that in turn does feed back into the theory because maybe these specialized things, like, maybe other people are interested in kind of what you can do there and what their constraints are. So, yeah, thank.

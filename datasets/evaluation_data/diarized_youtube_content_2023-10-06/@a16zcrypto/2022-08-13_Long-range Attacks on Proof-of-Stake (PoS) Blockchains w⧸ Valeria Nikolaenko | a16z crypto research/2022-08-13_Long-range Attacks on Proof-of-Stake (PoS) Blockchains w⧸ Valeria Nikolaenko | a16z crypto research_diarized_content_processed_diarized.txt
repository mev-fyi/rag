00:00:06.360 - 00:00:06.910, Speaker A: You.
00:00:09.360 - 00:00:27.660, Speaker B: All right. Morning everyone. Welcome to a 16 Z Crypto Research seminar. Part Two proof of stake blockchains by our own Lara Nicolenko from Tuesday. We know about kind of like a general lands, the general landscape and then today she's going to drill down onto long range attacks and some other issues.
00:00:27.810 - 00:00:55.720, Speaker A: Thanks, Tim. Yeah. So today we're going to deep dive into one particular attack on proof of stake blockchain. That's not possible in proof of work blockchain. And that's I guess in my view the hardest attack to combat. And there are different approaches and we'll see different trade offs that they offer and maybe if there is time at the end we can have a little bit of brainstorming. Maybe you guys have other ideas of how this can be mitigated.
00:00:55.720 - 00:01:37.320, Speaker A: But yeah, we'll start with the definition again of the long range attack. Just to remind you, I will not redefine the proof of stake. Hope everybody kind of has the mental model in mind. And then I will discuss different mitigation approaches. So, proof of stake blockchains are typically proved to be safe when a threshold of validating nodes is honest. And when you violate this threshold, then you lose safety and then you can create forks and double spend on those forks. So you break the finality guarantee when the number of Byzantine validators kind of go over threshold.
00:01:37.320 - 00:02:22.964, Speaker A: And when I will be talking about corrupting a validator or corrupting a validating node, what I will mean is corrupting a signing key of that node. So when I'm saying a node, just think about a signing key. Corrupting a node is corrupting its signing key. So during the time that validator is active and participating in kind of producing blocks for consensus, it has some stake locked. And in case of a deviation from the protocol, if it is observable, typically you can slash the validator stake. So get it penalized for misbehaving, for not following the protocol and causing the blockchain to fork effectively. So for ethereum 2.0
00:02:22.964 - 00:03:25.432, Speaker A: for example, slashing conditions can be very harsh. So for ethereum consensus layer, validator can lose potentially his old deposit. So three to 100% it will immediately forcibly be ejected from the validator set and will additionally has the remainder of his coins locked for 36 days before they can withdraw if there are any coins left if he wasn't slashed completely. So validators have really, really strong incentives to stay honest while they're validating. And there is even some lockup period after they stopped validating to make sure that if they were misbehaving while they were validating, somebody have enough time to kind of collect this data and maybe present it back to the protocol to get their stake slashed in any case. So there is a little bit of window when the stake continues to be locked, but the validator is not validating the chain anymore. So it's just idling there.
00:03:25.432 - 00:04:00.096, Speaker A: Lockup periods can vary. For example, for ethereum it's one day the stake continues to be locked. But we've seen much larger lockup periods. For Cosmos, for example, it's 21 days that the stake continues to be locked. So the high level idea of all of that is that active Validators, they stay honest due to incentives if the protocol is designed well. And let's look at kind of the lifetime of a Validator. So Validator will have to hold some assets on the blockchain to be able to lock them up to participate in the consensus.
00:04:00.096 - 00:04:41.650, Speaker A: There will be some period when he holds some assets on the blockchain. Then there will be some period when he staked those assets to indicate that he is willing to participate as a Validating node. Typically, there is a window before he is let into the Validator set. For example, Ethereum kind of does some speed limiting of how many Validators can join at a time. So they create some queue, and you're waiting in this queue to start Validating. So they want to make sure that the validating set is not changing drastically in an instant. So you will have gradual increase and gradual decrease kind of some downfring of the size.
00:04:41.650 - 00:05:24.856, Speaker A: So the stake period is a subset of the holding asset period, and then the Validating period is even smaller. But the Validator has even if he was holding some assets in the past, as time kind of progresses, he can just exit the chain completely. He can use an exchange and just get rid of all of his assets and kind of not be incentivized in this blockchain anymore. So after he sold his assets and exited the blockchain, there are essentially no incentives for this Validator to keep his old keys that were kind of guarding all of the stakes secure. So when there is no incentives. Yes.
00:05:24.978 - 00:05:31.010, Speaker B: So those keys are going to be different, the Staking keys and the Validating keys? Or could they be the same?
00:05:31.400 - 00:05:39.060, Speaker A: Yeah, typically they are different. Yeah, good question. Typically there's three different keys, all the Staking.
00:05:39.880 - 00:05:52.068, Speaker B: All right, the first key is just like your normal private key for your account, I guess, to move the assets around. So the Staking key will be used only to withdraw your stake or that's.
00:05:52.084 - 00:06:04.350, Speaker A: Other uses to withdraw your stake. Exactly. Yeah. So you will kind of sign with this key. You will sign your Staking key and then well, effectively through transactions and then sign kinetics validating consensus key.
00:06:04.800 - 00:06:09.912, Speaker B: Right. So you're saying you'll cast the votes to the sport vote using your Validating key?
00:06:09.986 - 00:07:00.552, Speaker A: Yes, exactly. You can compromise either the asset key and then you will be compromising the stakes and the Valding key, or you can be compromising the Valding key alone and just causing disruption to consensus. Yeah, great question. We'll discuss keys a lot. So if all Validators become corrupt, then safety can be violated as well. It's not only that the active validators, you need to corrupt the active Validators to break safety, you can also corrupt historical validators. So for example, if your chain was growing nicely and was not forking, at least didn't have any deep forks, certainly for Nakamoto Consensus it can be forking at the deep, but usually the longest chain wins.
00:07:00.552 - 00:07:49.676, Speaker A: So you don't have deep forks. So if your chain was growing nicely, everybody was staying honest. But then at some point maybe these validators who were finalizing one of the blocks or epochs just exited the system completely and then sold their keys to the attacker. And the attacker now kind of got hold of all those consensus keys. Although this is a point in the past, it can still create an alternative block and due to costless simulation of proof of stake blockchain kind of continue this work onwards and grow it very fast so that it's about the same length as the honest chain. And the poor user who was not online was not following. Maybe he just entered the blockchain.
00:07:49.676 - 00:08:33.710, Speaker A: He cannot differentiate between the two forks, or at least that Arker has the potential to make it indistinguishable from the top ones. Let's kind of discuss the keys a little bit. So you can kind of map the number of validating keys depending on time. And your blockchain can at certain times have a lot of validators validating. Sometimes it will drop. And so of course, when the number of validators is really low, that's a kind of nice point for that target to try to collect all of that keys. Typically the blockchains have low number of validators in the beginning, so it catches up, but sometimes it can have kind of drops in the number of keys as it goes.
00:08:33.710 - 00:09:40.910, Speaker A: All right, so hope that gives you a high level idea and we will discuss now mitigations for this problem. So I will show you five different approaches and then maybe we can brainstorm if there are ideas on more stuff to explore. So the first is the most simplest one is checkpointing. So the idea is that you have some centralized checkpointing mechanism and for example, you can hardcore the checkpoint, checkpoint being just the hash of a block. So it's super small, it doesn't have to be the whole state of the blockchain can just be commitment to that state like a hash of the block. So you can hardcore the checkpoint into the GitHub code base. For example, when everybody is downloading that GitHub code base and they're using it to synchronize to the blockchain, the code base will just kind of figure out which chain you need to pick if there are any deep forks in there.
00:09:40.910 - 00:10:19.130, Speaker A: So, for example, Genesis is hard coded into the GitHub of all the clients. And you think maybe this is an undesirable kind of because it's centralized, but if you look at the kind of blockchains today, it's kind of pretty centralized in terms of what client everybody is using for execution. Client, the most popular is guess and it's taking about 83, 84% of the total nodes. So 80% of nodes are running yes. Client from the GitHub. And for consensus clients, most of them are using prison. So 60% of them.
00:10:19.130 - 00:11:13.546, Speaker A: And that's data from January 2022. And another idea of what you can do with the checkpointing is you can checkpoint to a proof of work blockchain, of course. And then there you don't have the problem of it being susceptible to long range attacks. So if you put your checkpoint there, you can be sure it will not be rewarded by some deep fork. And actually, some of the projects, even not related to blockchain, are using proof of work chains to checkpoints of their stuff to put some hashes and answer their accounts. Yeah. So the problem is the top approach is kind of centralized because you rely on the fact that everybody will be downloading the client, that all the clients will have the same checkpoint.
00:11:13.546 - 00:11:37.160, Speaker A: So you either have a centralized place to download your clients or the clients still have to consent on which checkpoints should be there. And of course, the other approach has a problem that it's proof of work blockchain. The whole point of proof of stake is to get rid of proof of work. So kind of you're back to the original problem you were trying to solve, which is not great.
00:11:38.650 - 00:11:41.240, Speaker B: Are there any existing systems which do this?
00:11:41.930 - 00:11:48.066, Speaker A: I think only as a precaution, not like other main part of the protocol.
00:11:48.258 - 00:11:50.620, Speaker B: So some do do as a problem.
00:11:51.150 - 00:12:00.346, Speaker A: Well, actually, I'm not 100% sure. Like for DM blockchain, we're thinking of doing it because it's bitcoin did it.
00:12:00.368 - 00:12:03.014, Speaker C: For a very long time, but they were rooted in 2016.
00:12:03.062 - 00:12:03.266, Speaker A: 2017.
00:12:03.268 - 00:12:06.670, Speaker B: And so how did they implement?
00:12:07.170 - 00:12:13.490, Speaker C: It was just exactly like this. It was just in Bitcoin core client. They just had a line to say, this hash should be in the blockchain.
00:12:16.470 - 00:12:17.810, Speaker B: The Genesis Flyer.
00:12:19.830 - 00:12:27.330, Speaker C: Yeah. I think they have to send me these six or seven different checkpoints throughout time before they actually move because it was heavy.
00:12:29.210 - 00:12:51.466, Speaker A: Nice. Yeah. Also, if there is a hard fork and you want your client to follow one of them, you'll have to put a checkpoint in there so that it synchronizes to the correct fork. Yeah. So Joe's understanding is that checkpointing exists more as a social convention rather than an automated protocol step, right, yeah, good point.
00:12:51.648 - 00:13:24.120, Speaker D: I don't know if that was clear, what I wrote. I'm a little out of it, but yeah, I think a lot of this is my understanding anyway. I've seen some projects that they don't have sort of an automated checkpointing system, but they sort of manually put them in code or clients enforce them anyway. And they're sort of established by some undefined human level protocol, basically, which I think is mostly because people don't want to sort of admit that this is what they're doing.
00:13:26.250 - 00:13:57.620, Speaker A: Yeah. Great comment. Thanks, Joe. Yeah. Okay, let's discuss the second approach for key evolving cryptography. So it's a good practice for validators and essentially for everybody on the blockchain to kind of rotate their keys once in a while because the attacker can kind of be slowly crawling to get your key there. And if you rotate it, you kind of push the attacker back also.
00:13:57.620 - 00:15:11.210, Speaker A: Yeah, but you need to be careful because the moment you wrote this time when you rotate your key, you make yourself a little bit vulnerable to attack rotate. I mean, you sign a transaction that basically moves you from this key to a fresh key. Yeah, you just change the key. Yeah, right. And let's see if, say, the set of validators is growing and at some point you're compromising, say, two validators out of a big set, then although you cannot attack the chain at this point, if validators were not rotating their keys, that immediately means that you are compromising the validators from the sets prior to that. So if at some point you start getting, say, two thirds of validators compromised, then that's the point when you can start forking the blockchain. So, although it seems like you're not compromising enough, if the validators were keeping the same keys, compromising them for the last epoch is essentially the same as compromising them for some previous epoch where you would have a supermajority of them compromised and can fork.
00:15:11.210 - 00:16:07.514, Speaker A: So to mitigate that, like people were proposing to use keyword encryptography, you will rely on their assumption that honest nodes will regularly rotate their keys and honestly forget the old ones. So you can either do this with onchain transactions when you sign a transaction directly, that kind of moves you from public key one to public key two. And secret key two is completely independent of secret key one. But if that's expensive, if you don't want to submit a transaction, pay the fees for every key rotation. You can use some clever tricks around time evolving secret keys. And the team from Algrand was proposing the pixel signatures. The idea there is the public key stays the same.
00:16:07.514 - 00:16:46.760, Speaker A: So you don't need to rotate it because only the public key is their own chain. So the public key is the same, but the secret key kind of is evolving with time. So with every epoch number, you're kind of shaving a little bit of information from your secret key so that it starts to be more and more restrictive and you cannot go backwards. So your secret key one is the most powerful. From that, you can evolve all the next ones. But from secret key two, say, you cannot go backwards and figure out what was the secret key one and the signature that you verify. It also will take an index I.
00:16:46.760 - 00:17:14.506, Speaker A: So you cannot produce, say, sigma one using secret key two. That will not be possible. So you cannot kind of go back and compromise kind of forge sigma one using secret key two. That's a very nice trick. I know they were proposing to use it as algorithm. I don't know if they ended up using it. It's kind of quite elaborate scheme.
00:17:14.506 - 00:18:01.646, Speaker A: It involves some hierarchical identity based encryption based on BLS signatures. But anyway, that's a nice approach. If you're not comfortable with the kind of complicated cryptography, you can always just ask your validators to rotate the key frequently. Okay. The problem of course, with this approach is it's incentive incompatible. So why would honest validators forget their old keys if there is incentive for them to keep the old keys and then when they exit the system kind of sell those old keys to the adversary, then it's unlike well, it's a little bit maybe naive to expect all of them to behave honestly and just keep forgetting information. Especially since you cannot check whether they forgot the information or not.
00:18:01.828 - 00:18:16.610, Speaker B: I guess the way I think about it is it may actually be a little bit of a pain to truly delete old keys. It's not so much that they want to keep them, it's just like they don't want to put in the effort to make sure that they don't keep them. You know what I mean?
00:18:16.680 - 00:18:23.000, Speaker A: Yeah, exactly. Even if you wipe out the memory, how can you be sure that it's been wiped out?
00:18:24.010 - 00:19:04.690, Speaker D: There is an argument for why you would want to erase your old keys, which I haven't seen made very widely, but I think it's pretty simple. If people believe that you're erasing your old keys, then you're not a target. It's kind of like when you park in San Francisco and open your glove box to show that there's nothing to steal. Because if people break into your system to steal your old algorithm key, they might steal other stuff too. You probably have like pooled things. So if you don't want to attack the system, there isn't at least some incentive if you can convince other people you've erased your old keys because then you're not a target.
00:19:05.990 - 00:19:16.310, Speaker A: Yeah, I guess the question is how would you convince somebody that you've erased it in your analogy, kind of how do you show that you have nothing in the tranquility?
00:19:17.850 - 00:19:30.220, Speaker D: Fundamentally, we don't really have any way to do it. You could do it using SGX or something like that, but yeah, there isn't like a cryptographic way to prove you've deleted anything.
00:19:31.790 - 00:20:25.070, Speaker A: Yeah, interesting. Yeah, good point. That GX can help if you rely on your trusted hardware assumptions. Okay, so that's the second idea and it kind of is not perfect as well. So the other idea is how about we keep everybody online and if everybody is online all the time, kind of checks in with the chain very frequently, there is no way you're going to fool them into believing some deep fork because they've been just following the correct fork all the way. So, for example, ethereum consensus layer, which is a combination of Casper finality gadgets and LMD Ghost fork selection rule that I was describing in the last talk in their paper, they also discussed long range attack. And that's exactly kind of the approach that they propose.
00:20:25.070 - 00:20:59.174, Speaker A: Just to cite them. They say in the paper, each client will log on and gain a complete up to date view of the chain at some regular frequency, say, once per one to two months. So that's a very strong assumption to swallow. Right, because there can be clients who never been active on ethereum, but who want to join. They need to figure out what's the correct chain or at least maybe who are the active clients who've been monitoring this chain. And then you're back to the same problem. Yeah.
00:20:59.174 - 00:21:55.754, Speaker A: So the problem is the clients can be sleepy, and you still want to give them some way to sync to the correct chain, even if they were sleepy. Okay, so the fourth approach is finality gadgets of an Akamoto consensus. So the Casper FFG here is the finality gadget. And some people kind of think that they help with long range attacks somehow, but I'll explain what they do, and you'll see that they're solving a different problem, actually. So the examples of some prominent finality gadgets is, of course, Ethereum consensus layer, which is Casper finality gadget. And Grandpa, that's a finality gadget on top of Polkadot Nakamota consensus. So the idea is to use validator committees to vote on epochs to finalize them.
00:21:55.754 - 00:22:26.050, Speaker A: So you'll be just running a committee based BFT chain on top of your longest chain to guarantee deterministic finality. So Casper yeah, let's look at Casper protocol. Very brief. I will describe the high level idea. It's based on tendermint. Although maybe reading it, it's kind of hard to figure out what this consensus protocol is. But it's essentially tendermint.
00:22:26.050 - 00:23:06.398, Speaker A: In LMD Ghost, in the underlying Nakamoto Consensus, you have each validator vote once per epoch. So validators are shuffled into committees, and in each slot, a leader is proposing a block, and the committee of that slot is voting for the block. So validator is assigned to exactly be a member of one committee. He can be at most one leader. There sorry, he can be assigned to a committee, and then he can be selected as a leader from that committee or not. So in any case, he is voting once per epoch. So it's voting on that block.
00:23:06.398 - 00:24:05.198, Speaker A: And Casper, in addition to that voting, it asks the validator also to vote on the previous epochs. So you are trying to finalize the previous epochs. And together with voting on your current block, you'll also be voting on what are the epochs that you believe should be finalized. So each validator will be submitting two votes. There's essentially tendermint votes. If you remember how tendermint works, one vote will be saying that I want to finalize this epoch in form of a prepare phase of the tendermint and some previous epoch that already collected a quorum certificate of prepare votes to commit it. So, just to remind you, the Tendermint has these three stages where the block is proposed and this block proposition in our case is Epoch proposition.
00:24:05.198 - 00:24:39.310, Speaker A: And that's happening from the underlying consensus layer. So the underlying Nakamota Consensus, it proposes an epoch to finalize and then all validators kind of vote in two stages. They submit their prepare votes and commit votes. The difference here is that it's a different committee that is voting on the epochs. So this committee, this last committee here is voting on Epoch I plus one. And then the committee after that one will be casting a second vote on this epoch. So you are changing the committees that are voting.
00:24:39.310 - 00:25:41.870, Speaker A: So this is just a nice pipelining idea that they had. But actually, I think the Casper paper is from 2017, at least when they had the original idea. And that's why it's kind of very similar to tendermint. But I don't think maybe they've reconsidered. Maybe there is a way of just thinking to simplify their protocol with ideas that appeared in Hot Stuff because Hot Stuff was later and Hot Stuff has this really nice pipelining of voting so that maybe you don't need to vote twice, you can just vote once and this kind of helps you confirm all the previous epochs. So anyway, I don't know, maybe there is a way for improvement there for Casper Protocol to simplify their voting mechanism. All right, but you see that still you have this problem that if the old committee is compromised, your BFT gadget does not guarantee your safety.
00:25:41.870 - 00:26:28.566, Speaker A: So you can still fork the epoch voting and create an alternative fork of Epochs. So you have to rely on the committee staying kind of honest in perpetuity. So you're back to the same problem. So overall, I just want to say that these are great ideas, but they solve a different problem. So these gadgets are turning probabilistic finality into deterministic finalty, but it doesn't solve the long range attack. Yeah. And then the rest of the talk I will spend kind of describing the paper that we wrote with Sara Zubi and George Danezis when we were working on the DM blockchain was called different names.
00:26:28.566 - 00:27:20.622, Speaker A: DM was the last one. So we were exactly just trying to figure out is there are better ways to prevent branch attacks. And the idea that we had kind of summarizes winkle in one sentence is make users vote inside their transactions on the current state of the blockchain. So you not only have kind of validators voting your BFT consensus and DM was BFT Consensus, but you also make the users who participate in the system also participate in your consensus. So we'll see how it plays out. It will be easiest for me to describe the protocol on top of BFT consensus that has terministic finality. But this doesn't have to apply to BFT Consensus.
00:27:20.622 - 00:27:55.290, Speaker A: Only it can also apply to BFT Consensus. That's a finality gadget on top of Nakamota. So you can add this on top of your finality gadget, for example, if you have Nakamoto Consensus underneath or you can maybe adapt Winkle to directly work with Nakamoto Consensus. But we haven't done that since DM was a BFT blockchain. So we're focusing only on BFT blockchain. Let's start from the beginning. So blockchain is you start with Genesis and then you produce blocks of transactions.
00:27:55.290 - 00:28:48.910, Speaker A: Your block is the parent hash of the previous block and the list of transactions and then validators kind of work to finalize this block. And at the end they get some certificate that think of it as an aggregate signature. That is a proof that they have all consented to append this block to the blockchain. And a single block commits to the full history up to Genesis because it contains the parentheses, so it has this nice chaining. But for the purpose of this talk, we will be focusing on epochs instead of blocks. So when I show you this rectangle with a list of transactions, think of an epoch of transactions because anyway, the BFT blockchain orders all of the transactions totally. So you can just think about these blocks as epochs.
00:28:48.910 - 00:29:37.482, Speaker A: So validators work on finalizing the next epoch of transactions and they stay honest when active. So the typical BFT assumption is that you have three F plus one validators and at most F can be corrupt. So validators kind of figure out if they want to consent on this block. At the end they produce a certificate, they move to the next block or epoch. And so that's how they evolve the yeah, think of validators, notarizing epochs here. So validators are effectively just a set of public signature verification keys, as I was saying. And the certificate is an aggregate signature and validators are typically implied by the previous epoch.
00:29:37.482 - 00:30:57.030, Speaker A: So the validators notarizing through the first epoch are retrieved from the Genesis. So the Genesis will just define okay, this is the first set of validators that we're going to start with and then from the previous epoch you retrieve kind of the next set of validators that we'll be finalizing. So validators to finalize e two are retrieved from e one, epoch and so on. And to finalize e three, you need to retrieve validators from e two. Yeah, and I was explaining in the beginning that if everybody is honest, you have a single chain, but if past validators are corrupted, they can fork and create an alternative chain that will totally confuse the user about which is the correct one. So I will oversimplify a little bit and that's what we do in the paper in that we view transactions that are simple money transfers and that makes the overall model much simpler, but it can be adjusted to work with more elaborate transactions as well. So the transaction will be just of the format, a sender a receiver and the amount and signature will be a signature of the sender on this triple.
00:30:57.030 - 00:31:49.180, Speaker A: So Genesis Dwelk assumes it gives some initial allocation of coins between the accounts and an epoch of valid transaction modifies this allocation. Right? So if you have transactions that sends one coin from Alice to Bob signed by Alice, your next state of the database will be that Alice will have one coin less and Bob will have one coin. Yeah. So you process just transactions sequentially, kind of redistributing the coins between accounts. Okay, this is oversimplification. Of course most of the blockchain have some scripting or programming language that makes it a little bit more complicated than this model. But we'll be focusing on this model just to understand the high level idea.
00:31:49.180 - 00:33:07.682, Speaker A: So let's see what the corrupt validators may do. So when they have corrupted the value in the set and they're trying to create an alternative fork, what they cannot absolutely do is they cannot forge signatures from honest accounts. So for example, if you had your funds in Genesis and you were not moving them anywhere and you still keep your account key to yourself, the adversary will not be able to suddenly steal your funds. So it can not forge transactions from honest users, but it can definitely censor, it can drop transactions of honest users and for itself it can double spend, it can create new transactions from corrupt accounts. So it's kind of good. If you are idle and not transacting, then the attacker will not be able to do anything to do much with you. But if you're say big exchange and all the time you would have a lot of money coming in and a lot of money coming out and this happening in every epoch, then attacker can just attack your exchange by censoring all the transactions that were coming in.
00:33:07.682 - 00:34:02.690, Speaker A: And so it will very quickly in his alternative work kind of deplete all of your funds, all of the funds of the exchange. So the idea is to change this. The whole idea of Winkle is to change the transaction format and to also ask users to vote on the last epoch. That's sort of a natural thing I feel to do. I'm a little bit surprised that none of the blockchains kind of thinking about doing that. But it definitely will kind of involve a little bit more work on the validator side because now they will need to make sure that the last epoch that the transaction is voting on conforms kind of with the fork at which you are finalizing the transaction. So you need to make sure that the transactions in the epoch are voting on some epoch that was there on this chain, on the same chain.
00:34:02.690 - 00:35:04.866, Speaker A: So when the transaction additionally kind of has this last epoch, it will be voting with the sender account on this epoch. So be like a second layer of consensus or voting happening where users. Themselves by just transacting on the blockchain will be voting on the state of the blockchain. So it's a little bit kind of maybe hard to implement because it will also involve changes to account states. For example, if you are a receiver and you're receiving money with different votes, you need to kind of to keep track which of your coins have been voting for which epochs. And so as a result, coins will sort of have a non fungibility flavor. Start having this non fungibility flavor in that some coins will be voting for one epochs and some coins will be voting for other epochs.
00:35:04.866 - 00:35:42.020, Speaker A: So just to give an example here, suppose there are three accounts, alice, Bob and Charlie. Each of them has one coin and this coin is voting on some first epoch e zero. Then if the transaction moves coins from Bob to Charlie, say from Bob to Charlie, one coin moves and its vote is e one. Then the coin moving to Charlie will now be stored in Charlie account. But it will have a different vote from the other coin that Charlie has. And then if Alice Bob sends Bob, one coin will also get the vote on the coin updated. Yes.
00:35:43.750 - 00:35:58.402, Speaker C: I think the first one, I think Solana does something like this. It's called proof of history. And so in your transaction you put in like the block cost or whatever of something. I don't know if they use it for consensus, but they're doing something along these lines.
00:35:58.466 - 00:35:59.080, Speaker A: Interesting.
00:36:00.410 - 00:36:14.506, Speaker C: I thought it was really weird I looked at it, but then you just make sense. The second question was what happens if Alice defends coin to herself? So in that sense, Alice sends to another account that belongs to her, she.
00:36:14.528 - 00:36:15.930, Speaker A: Can update her vote.
00:36:16.370 - 00:36:22.030, Speaker C: Yeah. So in that way it's sort of just voting but it doesn't cost her any money to do that.
00:36:22.100 - 00:36:22.766, Speaker A: Yeah, exactly.
00:36:22.868 - 00:36:30.370, Speaker C: Have you consider using transaction fees for this? So the more transaction fees you pay is the weight of your vote.
00:36:32.230 - 00:36:34.866, Speaker A: Say it again. So you will be depleting here.
00:36:34.888 - 00:36:41.350, Speaker C: My understanding is that if I send one coin to Charlie that one coin is sort of used for the vote.
00:36:41.690 - 00:37:05.706, Speaker A: Yes. No, actually, sorry, maybe I wasn't explaining this right but the whole account of a sender will get their coins updated and only sends one to Charlie. Her all hundred coins will get updated to that vote every time she sends a transaction. She can vote with all of her stakes.
00:37:05.738 - 00:37:20.610, Speaker C: Have you consider using transaction fees? So there's a cost to help us to do that. So instead of using your balance, you could just use NFC. You have to pay a dollar as a transaction fee involved. Then you can have a real cost to your vote.
00:37:21.270 - 00:37:26.814, Speaker A: Oh, yes. You think of lowering transaction fees if the only thing you're doing is just updating the vote.
00:37:26.942 - 00:37:35.080, Speaker C: What I get is that right now the vote is weighted by the balance. Have you considered the vote just being the quantity of transaction fees that they pay?
00:37:36.170 - 00:37:39.526, Speaker A: Oh, but that will be lower than the balance.
00:37:39.638 - 00:37:46.570, Speaker C: Well, it doesn't mean that it costs them money to vote because right now it doesn't cost them anything to vote.
00:37:48.590 - 00:37:56.880, Speaker A: Well, you still have the transaction fees, right? Oh, you're saying that the more transaction fees you pay, the kind of the stronger your vote is.
00:37:58.690 - 00:37:59.840, Speaker C: Considered it?
00:38:01.650 - 00:38:25.240, Speaker A: Yeah, maybe that's a good idea. Like to express how strong you believe the chain. Yeah, we haven't explored that. But the worry there is I don't know, maybe I'm not sure many users will be willing to pay transaction fees to kind of strongly express their vote. They would rather probably.
00:38:27.470 - 00:38:34.138, Speaker C: So ethereum $10 million a day or something on fees. $10 million of loads you would get as well.
00:38:34.224 - 00:38:41.610, Speaker A: Yeah, definitely. Thank you.
00:38:41.760 - 00:38:50.720, Speaker B: It's funny, it's almost like the FP 59 basically transactions even turn into this kind of non transferable governance token in the effect.
00:38:51.170 - 00:38:52.160, Speaker C: Yeah, exactly.
00:38:56.550 - 00:38:57.250, Speaker A: Cool.
00:38:57.400 - 00:39:16.022, Speaker D: Could I ask maybe I'll get to this, but why doesn't a long range attack apply for these types of votes too? Because seems like people making transactions, once they're not using their keys anymore, they can also be compromised, right?
00:39:16.156 - 00:39:51.060, Speaker A: Yeah, absolutely. You're absolutely right. I'm going to talk about that next. So just to maybe briefly say that the stake of the overall system is of course protected by many, many more keys than you have on the validator set. And so the argument, of course, that you're not like solving the problem completely, you're just making it better so that more keys are protecting now the blockchain not just validator's keys, but now also the user's keys. But I'll get to that with some numbers. That's a good point.
00:39:51.060 - 00:40:39.694, Speaker A: Yeah. So coins will be voting on epochs. So if you consider the state of the accounts in your last epoch, you will just see what the coins are voting on, kind of retrospectively, and you will see which and that's transitive. Like if a coin is voting on an epoch after the epoch that you're interested in, you will also count its vote towards the previous one. So kind of if you're voting on some subsequent epoch, it kind of transitively translates to the voting on all of the previous chain. So you will see which of the epochs gets about two thirds of the votes. And this threshold is flexible.
00:40:39.694 - 00:42:04.734, Speaker A: We are showing that maybe it doesn't have to be two thirds, depending on the assumption that you want to have. But you can also go with BFT assumptions and consider the checkpoint finalized if it's voted by two thirds of coins according to the state of the accounts on the last epoch. Cool. So essentially we are kind of showing a security theorem saying that if the adversary has some max F fraction of stake to begin with and that's the accounts that it has compromised and can double spend from and at maximum some S stake moves within an epoch. Then if you can bound this F plus S over two by one third, then you can prove that the adversary cannot accumulate more than two thirds of stake to create a checkpoint on the fork. So for a user to see which chain is the correct one, it will kind of observe the chain for a while. And if it's not producing any checkpoints, or if it doesn't have any checkpoints at all in the last interval that's sufficiently big, you will be suspicious of this chain and think that you are synchronizing to the wrong one.
00:42:04.734 - 00:43:14.260, Speaker A: So the adversarial chain will not be able to produce checkpoints. And that's kind of the core security argument, the core theorem that we prove if you're attentive enough, you have this additional assumption that a maximum S stake moves within an epoch. And that's essentially to prevent kind of this exchange attack that I was describing. So if you can reroute by censoring transactions, if you can reroute too much stake so that you end up with a lot of stake at the end, you can make it so that you have more than two thirds. But if you bound the number of stakes that moved within an epoch, you should not be able to do so. But of course that will require so first, S is really, really large and it's super unlikely that any chain will within an epoch have like a sort of its stake moving. But if you still anticipate this scenario, then you can financially just end the epoch a little earlier and then start the next one.
00:43:15.910 - 00:43:34.940, Speaker B: So what would be approaches to bound against? Like, do you envision that you would want to modify your protocol so that you could have an overbound on S? Or is it more just kind of empirical? Like you could just sort of see how much what S was in hindsight and then conclude what the security was.
00:43:36.910 - 00:43:40.586, Speaker A: You're asking about how in practice will you pick yeah.
00:43:40.688 - 00:43:43.930, Speaker B: How would you get any control over S in practice?
00:43:44.090 - 00:44:17.430, Speaker A: Yeah. So in practice, I guess you will pick your assumptions with which you are comfortable, like how many Byzantine notes you want to tolerate and how many sleepy notes you think of it as like same as S. And then, yeah, if your epoch starts approaching that S, you can just stop producing new blocks within this epoch. Or maybe you can do something with transaction fees that they will climb up and kind of disincentivize people to submit more transactions.
00:44:17.790 - 00:44:24.570, Speaker B: That's a good point. S may be hard to observe, right? And S, at least you can observe from the blockchain.
00:44:28.030 - 00:45:16.010, Speaker A: Just to summarize the security theorem saying that checkpoint and epochs cannot be forked. So we're kind of changing the assumption. We're making it a little better. So before we were relying on validators to stay honest and either in perpetuity or staying honest and alert and now we're changing that into users staying honest and alert. And the argument to Joe's point is that the validators are typically up to 1000, sometimes up to 2000. But in any case it's not a super big number and all blockchain users can run from million to a billion. So usually it's a much, much bigger population and you have much more keys protecting users funds rather than kind of validating keys.
00:45:18.350 - 00:45:52.630, Speaker D: The pushback I would give you on this point is that the number doesn't really matter. You care about the distribution and there are like a coinbase has millions of those keys, right? There are really concentrated places that have a lot of them. Hopefully those are also places with really good security that are hard to compromise. But I guess it's not like the fact that the number is bigger doesn't make it obvious to me that it's harder to compromise enough of them to comprise a majority of the stake.
00:45:53.450 - 00:46:33.378, Speaker A: Yeah, great point. And so we were trying to study the distribution of these keys and how much stake they have and I'll show you some graphs hopefully perfect. You're like ahead of the talk. So the experiments that we carry this paper of 2019, this is pretty old. Of course it would be super nice if somebody redoes the experiment. I bet the just overall dynamic of the chains have changed a lot in the last three years. But that's the graphs from 2019 that I'm going to be showing you.
00:46:33.378 - 00:47:34.070, Speaker A: So this graph shows the fractional stake and then how many keys are protecting that stake for bitcoin which is red on top and ethereum on the bottom. So two thirds of stake, for example, in bitcoin is protected by 15,000 keys and in Ethereum only 800 keys. I don't know, maybe the numbers have changed drastically, I'm not sure. But that was the state in 2019 and so it was really nice that kind of our paper was allowing flexible threshold. Thresholds and you can kind of balance your Byzantine assumptions with whatever other bounds, other things you have to bound. So you can kind of raise your threshold from two thirds to something higher. And of course if you go higher, for example, 90% of the stake is protected in bitcoin by 125,000 keys and ethereum by 12,000 keys.
00:47:34.070 - 00:48:40.830, Speaker A: And then if you go higher of course it starts climbing up very rapidly but we'd be nice to see what situation is now. So of course the more users take votes the higher is the assurance. So you would probably just analyze these graphs for your current blockchain and determining your threshold to make sure that you have protection of more keys than your validator set. And then we're also analyzing Winkle's efficiency. So we were saying, okay, let's take ethereum or bitcoin and see how quickly will they be checkpointing if we have every user vote on the latest available block. And these graphs are sort of indication of how frequently the stake is moving in the system. Because if stake is moving really fast, then you will have time to checkpoint to be really low.
00:48:40.830 - 00:49:32.080, Speaker A: If stake is idle and it's not moving, it's not voting, then the time to checkpoint will be really high. And of course in 2019, I don't know, people weren't transacting much at all. And for example, for Ethereum blocks were checkpointing about 200 days and for bitcoin about 600 days. So that's how much it takes for two thirds of the stake to move. But of course you can also add incentives if you are to switch to Winkle, introduce Winkle, you'll have to maybe incentivize people to vote more frequently. So maybe they are not moving their funds, but at least they are a little bit more active on the blockchain if you want to incentivize them to support the security of the blockchain. So that with incentives you can get this numbers to be lower.
00:49:32.080 - 00:50:16.190, Speaker A: But without incentives, of course these numbers are too high. You cannot afford your valuers to stay honest for three years to get a checkpoint that's too long. And so our idea was at that time to introduce delegation. And you can I guess the argument here is that there are a lot of cold wallets there that are holding funds and they don't want to touch their keys at all, never. Like they have it stored somewhere securely and only in kind of exceptional circumstances. They want to pull it out of the storage. But typically these cold wallets also have some warm or hot wallets that are transacting more frequently.
00:50:16.190 - 00:51:18.206, Speaker A: So maybe just a cold wallet can designate a hot wallet to vote for it. And so it would be natural to have this delegation mechanism where more idle accounts are delegating to more active accounts. But of course the argument is that you now start adding back decentralization but with proper economic incentives you can make sure that your delegates are not growing to be too big. Like not everybody is delegating to coinbase or something. So you would incentivize people to redistribute the delegation. But of course, if we are to take the most frequently transacting accounts and use that as our delegates, then depending on the number of delegates that you have, the time to checkpoint will drop significantly. So even for a million delegates, those are the most actively transacting accounts.
00:51:18.206 - 00:52:06.430, Speaker A: On bitcoin and ethereum your time to checkpoint will be less than four days. Which is great because you can afford probably to keep validator stake locked for four days and just keep them honest while being incentivized so that you have enough time to produce a checkpoint. Overall, what Winkle is doing is it's building on top of validator consensus layer where you need to have two thirds of validators to vote. At most one third can be Byzantine. But that consensus layer is kind of complicated. It's interactive, it's computationally intensive. The validators should run expensive.
00:52:06.430 - 00:52:44.414, Speaker A: Nodes should have some infrastructure usually. And this consensus layer is safe, while validators keys stay secure. But on top of that, you can add user based kind of consensus or checkpointing with flexible thresholds. You can play with the number of votes that you want to collect and the Byzantine threshold that you want to tolerate. And it's very simple for users, it's non interactive. The only thing they do is just they include an additional hash inside their transactions to vote on some epoch. Yeah.
00:52:44.414 - 00:53:42.242, Speaker A: And users don't need anything else, they don't need additional infrastructure. Probably each user has a good understanding of what is the current chain because I would imagine users should be thinking with the chain once in a while just to figure out how much money they have in their account or what's the current value set so that they can verify the signatures on their transactions from the stat and such. So users should already have some idea of what the state of the blockchain, so it's not asking too much for them to include this hash of the epoch inside their transaction. With this new layer, the whole blockchain stays secure as long as users keys keep it secure. And arguably it's like philosophically a better model. Maybe you don't have just valuers guarding the chain, but you also have the whole population of the blockchain kind of helping it to stay safe. Yeah.
00:53:42.242 - 00:54:32.900, Speaker A: To summarize the main part, so we were discussing bronze range attacks and we were looking at different approaches to mitigate them. So checkpointing is done in practice, but it's too centralized, key evolving cryptography, I guess it's a good practice for any blockchain to implement, but it's not incentive compatible. So if there are strong incentives to sell the key afterwards to the adversary, then you might not be honestly deleting your old keys. So that will not help. But that's definitely a good still thing to have. Keep everybody online seems like a recurring theme for protecting long range attacks because in Winkle also you have users kind of to check in what's the latest state of the blockchain. So either way they're also kind of keeping themselves online.
00:54:32.900 - 00:55:18.800, Speaker A: And we're also discussing finality gadgets that are helping the Nakamoto Consensus to have the domestic finality that BFT gives. Of course, the time to finality will still be the time to domestic finality will be very large for this combination of Nakamoto and finality gadget. So it's not a way to kind of speed up finality. To speed up finality you need to move to BFT, but that's a way to just make it deterministic instead of eventual. And then we discussed winkle. That kind of argues why it's a good thing to maybe have a user based consensus on top of your blockchain. Yeah, that's all I have.
00:55:18.800 - 00:55:30.100, Speaker A: And maybe we can discuss a little bit if people have ideas around what else can be done.
00:55:39.430 - 00:55:45.106, Speaker B: Are people looking at BDS at all to sort of help with long range attacks.
00:55:45.298 - 00:56:01.760, Speaker A: Yeah, I think they do. The problem is kind of with VDF you can still pre compute multiple forks of your VDF and then kind of keep one of the VDF forks secret, kind of with stealthish mining approach and then release it when you want to attack.
00:56:03.650 - 00:56:13.842, Speaker D: So Tim, are you suggesting the idea that you can tell a fork hasn't existed for very long because it doesn't have a long VDF computed on top of it?
00:56:13.976 - 00:56:19.902, Speaker B: That's right. It's almost like using VDF as a proof of work surrogate, except it's sort of certified.
00:56:20.046 - 00:57:02.914, Speaker D: Not really a proof of work. It's a timestamp surrogate. Yeah. There's a paper that does a whole bunch of formal modeling about this. It's called computational timestamping. I'm not sure anyone's seriously trying it and I'm not sure it's a great idea just because the attacker speed advantage kind of over time will always be able to make their chain look longer than the honest chain. If you assume that they have some two X speed up or some nontrivial speed up over the honest parties, yeah, I think it's a good theoretical idea.
00:57:02.914 - 00:57:05.650, Speaker D: That is not that attractive in practice.
00:57:06.390 - 00:58:35.340, Speaker A: The other ideas are kind of a bit naive as well. Maybe you can keep rewarding old validators, give them a little bit of a diminishing reward, maybe to maintain security, to just keep them incentivized. That's not a great solution. Or maybe you can do some kind of perpetual liquid staking so that their stake kind of continues to be subject to slashing forever. But you can still get some liquidity through liquid staking. But I think maybe I also think yeah, true. Definitely most of the projects just think they're going to solve it somehow with social consensus if this attack yeah, we are still to see how this works.
00:58:38.270 - 00:58:55.302, Speaker B: None of the existing proof of state chains include anything in protocol designed explicitly to protect against long range attacks. Is that right? Or like you said, they all just are sort of implicitly assuming that it'll be useful to the social layer. A bit of renown.
00:58:55.386 - 00:59:38.094, Speaker A: Yeah, most of them, well, they had sort of mitigations which is key evolving cryptography checkpointing, but none of them is perfect. And you see that winkle is also kind of makes your assumption weaker and that you now rely on the bigger population of keys, but it's not solving. Also if all the past users have exited the chain for some reason and they have an incentive to sell their old keys, then you can also kind of fork user consensus as well. So definitely people are concerned and trying to figure out how to solve it and they just have mitigations but none of them solve the problem completely.
00:59:38.292 - 01:00:05.222, Speaker B: In general, I'm struggling to have an opinion about whether this attack is based mostly theoretical or whether it's kind of thing where it was theoretical then I'd feel more comfortable with this idea that. Oh, like, okay, we have this ad hoc backup of social checkpointing or something. Whereas if we thought it was like an inevitable sort of attack then starts feeling like you might want more in protocol protections against it.
01:00:05.276 - 01:00:05.542, Speaker A: Yeah.
01:00:05.596 - 01:00:06.866, Speaker B: Do you have any thoughts on that?
01:00:06.988 - 01:00:52.710, Speaker A: Yeah, I definitely had a concrete thought for an attack. I didn't want to feed it to anybody to implement. But oftentimes, for example, Ethereum Consensus has access to Validator keys. So your execution layer, because you need slashing to be done there, your execution layer has access to validator keys. And so in principle, somebody can write a smart contract that will be saying here is a bounty and you can claim this bounty if you provide a secret key to that smart contract. Now, you can not provide it in the clear, but you can encrypt it and prove that it's correct. So you need some complicated cryptography to do that, but it's not impossible.
01:00:52.710 - 01:01:14.080, Speaker A: And there is some smart contract with a large bounty for collecting valid keys, you would imagine maybe Valids will just use it, especially if they want to abuse the chain and that's a real threat. Right. I don't know how they will be putting this contract down, for example.
01:01:15.330 - 01:01:29.666, Speaker C: So for this thing of validators selling keys though, wouldn't they then lose any rewards they got on the main chain? Like if attacker forks the chain or something along attacking, they also stand to lose from losing whatever things they've done. Right?
01:01:29.768 - 01:01:33.220, Speaker A: Yeah. Right. Well, yeah, you need to trust a little bit.
01:01:37.690 - 01:01:39.720, Speaker C: Cash out on coinbase or whatever.
01:01:40.090 - 01:01:50.940, Speaker A: Exactly. You'll have to trust the attacker to not attack during some window so that you have the time to cash out. Yes. So, yeah, there is some trust relation will be there.
01:01:54.960 - 01:02:13.910, Speaker C: I think if you took the wing pool stuff and you did transaction fees forward, it might be interesting for combat combat selfies mining. So the problem with selfish mining obviously is like a short term range attack in a way. It may be interesting to see if I could talk with selfish mining in general.
01:02:15.320 - 01:02:17.792, Speaker A: Your idea of kind of waiting by transaction?
01:02:17.856 - 01:02:44.030, Speaker C: Yeah, transaction fee maybe. You take the same idea of users lost block half they saw, they put that in a block with the transaction fee, then you pick the one with the heaviest fees. Then maybe that could also help with selfish mining because now as a selfish miner adopted pay equal or more transaction fees. So it's not just doing the work.
01:02:48.640 - 01:02:52.380, Speaker A: I see. Interesting. So you're saying the southeast miner will have to pay more?
01:02:52.530 - 01:03:03.810, Speaker C: Yeah. Because in 1559 the pocketers are forced to pay a fee and so you could use that idea that there's a minimum payment to do. So you mining now?
01:03:06.740 - 01:03:23.370, Speaker A: Yeah, that's definitely an area direction to explore transaction fees. We haven't thought about it much. Sounds good then. Well send any ideas if you get one my way and we can see if we can do something better here.

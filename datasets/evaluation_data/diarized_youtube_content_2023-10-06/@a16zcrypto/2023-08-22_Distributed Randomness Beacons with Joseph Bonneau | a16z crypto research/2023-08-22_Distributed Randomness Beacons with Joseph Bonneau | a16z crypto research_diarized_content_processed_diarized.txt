00:00:07.410 - 00:00:07.960, Speaker A: You.
00:00:10.010 - 00:00:39.230, Speaker B: Kicking it off today. Very happy to introduce Joe Bono, professor at NYU and also a research partner here at a 16 Z crypto. Many of you probably know Joe primarily as a fearless, semi professional rock climber, but believe it or not, he's actually an amazing computer scientist who's done a lot of excellent work over the last decade, including has been in this space for a very, very long time, longer than almost anybody I know on the academic side. And today he's going to talk about what I know is one of his favorite topics distributed randomness beacons.
00:00:39.650 - 00:01:03.894, Speaker A: Thanks, Tim. Great. Yeah. So the goal today is really to give an overview of the whole space, not to talk about anyone protocol. A lot of this is based on paper that I wrote with my student Kevin Schoi at NYU that turned into an Sok a systemization of knowledge paper. That was Oakland. So two weeks ago, actually, just one week ago, kevin and I were out of the Oakland Conference, and Kevin presented the work.
00:01:03.894 - 00:01:51.782, Speaker A: This is a much longer presentation, going through a few more protocols, but I'm going to keep it pretty high level, tried to keep it pretty much algebra free and at a conceptual level, the different design strategies for how you can build a DRB. But give a quick background on what a DRB is for those of you who haven't seen it before. It's a really old idea that a group of people want to generate a shared random value. They might not necessarily trust each other, so they want to use some kind of technology. Classically, they would use a physical device to try and generate randomness that everybody could see they could use for something like a lottery, but hopefully that nobody can manipulate. So dice are a very ancient technology that we still use today all the time. Variations of dice, too.
00:01:51.782 - 00:02:25.760, Speaker A: It's so old, of course, you can find mosaics pictures of people rolling dice. There's also this claritarian device that they used in ancient Greece to actually select citizens to be representatives in the Athenian Parliament. And this device has completely forgotten the history, although there's some surviving examples. But apparently we don't even know exactly how it worked. We just know that it was used for this purpose. So this is ancient technology. We'll circle back how this ancient technology is actually still being used today.
00:02:25.760 - 00:03:16.046, Speaker A: But this talk, of course, is about replacing devices like these with some kind of cryptographic protocol. So the cryptographic abstraction that would replace all that technology is called an ardent beacon. The idea in the abstract, the ideal form, is some kind of service that periodically publishes random values. So in each epoch, this beacon is going to produce some new output that should be totally random and unpredictable and that should just go on forever. So if you want to hold a lottery, everybody participating can just say, well, hold this beacon at some specific epoch in the future, and that will be the randomness that determines the lottery. So at a high level, you want this beacon to output uniform randomness. If it doesn't output uniform randomness, that's actually not really a big problem.
00:03:16.046 - 00:03:43.938, Speaker A: We know how to fix that cryptographically with a randomness extractor if we have to. But if it was a perfect beacon, it would just give us uniform randomness from the start. Obviously, everybody should have a consensus on what the values are. If different people don't agree on what the beacon is outputting, it's not very useful. For a lottery. We'd like it to output a lot of randomness very regularly, and it should be secure. So attackers shouldn't be able to predict what's going to be output by the beacon.
00:03:43.938 - 00:04:16.850, Speaker A: They definitely shouldn't be able to manipulate it and they shouldn't be able to block it or take the service down either. So those are all kind of high level goals. And I'll show you a little bit more detail how we turn these into cryptographic definitions. So lotteries are the obvious application. They're what motivated the study of DRBS and all of the physical tools that can approximate beacon. But I want to stress there's a lot of other applications, especially in the blockchain or Web three space. So not just lotteries, not just games which require randomness.
00:04:16.850 - 00:05:09.220, Speaker A: There's a lot of important security applications like random Ice auditing. So this is pretty well understood in elections, but there are a lot of other situations too where you'd like to randomly audit something. You can use beacons to generate cryptographic parameters randomly, for example, to choose coefficients of an elliptic curve. The big application that we'll see come up a lot is choosing leaders or choosing committees for some sort of consensus protocol. So a lot of consensus protocols in the blockchain space essentially have a beacon running under the hood. In some cases, that's a service that you could remove and run by itself. Or in some cases, for example, in Ethereum, the beacon chain exists for the consensus protocol, but it will also be made available to application developers to use if they need randomness for their application.
00:05:09.220 - 00:06:00.658, Speaker A: And then a couple of kind of more interesting ideas, as far as I know, haven't actually been deployed yet, but are out there. What you could use a beacon for, one is to randomize transaction ordering as a hedge against mev. So you commit to a set of transactions and then based on a future beacon value, you shuffle the transactions before executing them. Of course. Does that prevent all MAV? No, but it could be a useful hedge. And you can also use beacons for cryptographic proofs. So instead of doing fiat shamir, which gives an attacker potentially the opportunity to grind over a lot of challenge values, you could have approver, actually commit to the first step of their proof, wait a little bit, then sample.
00:06:00.658 - 00:07:10.620, Speaker A: A beacon value and use that as a challenge which would allow you to run various types of proof systems potentially at a much lower security, well, more efficient for the same security level than if you're doing fiat shamir and allowing the attacker to potentially grind over challenges. So that's an interesting idea. I haven't seen it actually deployed, but if we had really good beacons, maybe that's something that people would do more. And the goal. I think one of the powerful ideas of a beacon abstraction is that you could have just one beacon service that ran and was really high secure and everybody trusted, and then all of these applications could build on top. Of one beacon, including lots of different people doing different lotteries for different purposes, could all use the same beacon potentially rather than having to have everybody create their own beacon, which is kind of a pattern that you see with smart contracts today, where a lot of different games, for example, build essentially their own randomness service or beacon into their own application. Okay, so a couple of approximations that have existed before distributed randomness beacons, which would be the main focus.
00:07:10.620 - 00:08:04.030, Speaker A: The simplest way to do it, obviously, is to just have a trusted third party. So NIST actually ran a beacon for a while where they produced the output using some apparatus that was in their basement in Maryland, and then they just signed the result. They had a lot of interesting literature about how the randomness was generated with kind of entangled photons, but of course there's no verification that any of this actually happened. At the end of the day, you're just trusting NIST to do this. So obviously not something that we'd like to do, not an assumption that we'd like to make that one centralized party is behaving correctly. There's physical displays of randomness that should say physical randomness, not public randomness. All of these are public randomness, but things like roulette wheels, dice, bingo wheels, those are still pretty commonly used in state lotteries, partly because they make really good TV.
00:08:04.030 - 00:08:51.126, Speaker A: Well, at least they make better TV than cryptographic protocols do. Maybe that's something we could turn to the production staff and ask how we can make cryptographic DRB more interesting to watch. But anyway, those don't give you any cryptographic verifiability manipulating. Those should be something that a good magician is able to do. Everybody's seen a magic show where obviously magicians can pretend to be choosing a card randomly, and they're choosing a preselected card. They know exactly what it is. So it's kind of interesting to me that everybody knows that magicians are able to do that, but they think that the rotating wheel on TV when they do Mega Millions is compelling proof that the result was actually randomly chosen.
00:08:51.126 - 00:09:07.858, Speaker A: There seems to be a mental disconnect between people not realizing that that could be manipulated if the people running it weren't trustworthy. Although of course, there's a whole auditing regime backing it up that gives maybe some more trust that magicians don't have to deal with.
00:09:08.024 - 00:09:14.146, Speaker B: Joe has an encyclopedic knowledge of manipulations, of physical randomness. So I encourage you to ask of.
00:09:14.168 - 00:09:59.438, Speaker A: Good, there's lots of good stories that have happened that I could chat about. Okay? And then the last thing which is a little bit closer maybe to a DRB or what we call, what we call it in the sok implicit beacons. So using data sources like asset prices, prices of large gap stocks in the stock market, blockchain data and using that as a source of randomness. So that's actually I think a sensible thing to do. We don't really have a good model for either of those sources of what security guarantees gives you. I actually think that's a good project that could be worked on. This is commonly used to in Ethereum.
00:09:59.438 - 00:10:32.330, Speaker A: Lots of applications just take the most recent blockash as a source of randomness. So it's a decent idea and it gives you some randomness but we don't really have good quantification of it. So I'm not going to talk about that anymore in this talk. What I am going to talk about is distributed randomness beacons. The goal here is that we have a multiparty protocol. So we have n participants. They all contribute some entropy and somehow some output comes out of that which we'll call omega in this talk capital omega.
00:10:32.330 - 00:11:13.530, Speaker A: And of course we have to make some assumption about the adversary, that the adversary doesn't control all of the participants. And we'll see some protocols are honest majority and some aren't. But there has to be at least one honest participant to have any hope here. And then a bunch of common kind of cryptographic assumptions are made. Crypto basically works, the attacker can't break signatures, things like that. Probably the more limiting one is that all of the papers that we looked at in the literature make a partial synchrony assumption. So nobody has really made a randomized beacon that's designed to work in a fully Asynchronous network.
00:11:13.530 - 00:11:45.540, Speaker A: So that's kind of just where the literature is today. But so that's the goal. End parties are going to come together. You can phrase the whole thing as an instance of MPC, although these are almost all ad hoc NPC. I don't know if anybody is trying to do a DRB from generic NPC and we assume most of the time that this is going to happen repeatedly. So the same committee, maybe some people will come and go and the committee will be slightly dynamic but usually we want repeated randomness over time.
00:11:46.310 - 00:11:52.840, Speaker B: So for the partial synchrony so there's going to be like liveness type guarantees after things settle down.
00:11:53.370 - 00:12:34.610, Speaker A: Yeah, there's going to be liveness guarantees. So yeah, I mean if you had fully asynchronous then you would never get like a true liveness guarantee but maybe that's something you can live with. Okay, so first example, just kind of a warm up. So I'll try to present all the protocols at a very high level with these pictures of dogs that my student Kevin really likes. And we'll see that these are the honest dogs. We'll see the dishonest dog in a second. But the first example, which is the only real human protocol here, is some version of rock paper scissors.
00:12:34.610 - 00:13:17.890, Speaker A: So rock paper scissors is a really simple protocol. Everybody just submits an entropy contribution, which we'll call e here. And then somehow these are combined. The simplest example would be just summing them all up mod k, and that being the output, which is basically how Rock Paper Systems works. So this is actually secure if you have one honest participant with the big caveat that you need perfect synchrony here. So you need everybody to submit their entropy at exactly the same time. So why is that the case if you don't have perfect synchrony? If there's any network delay, the last participant to actually submit their entropy contribution, this is the evil dog.
00:13:17.890 - 00:14:02.240, Speaker A: Now they can look at the entropy contributions of the other participants and they can basically choose their contribution that will make the output be whatever they want it to be. So they can actually force whatever output they want. There can be some desirable output, like they actually win the lottery. And this is pretty intuitive. Everybody knows in Rock, Paper Scissors, you should be able to win every time if you can see what your opponent is playing before you go. So that's why kids in the playground try and approximate perfect synchrony by counting one, two, three, go, and then getting into dispute about if you're supposed to go on three or supposed to go on shoot, which comes after three. This should be all warm up here.
00:14:02.240 - 00:15:09.330, Speaker A: And the side note one way that you can make this less trivially broken, rather than just adding everybody's entropy contribution or doing something else that's fully linear, in which case the attacker can easily force whatever output they want, you could hash everybody's contribution, and that makes it slightly harder for the attacker to get whatever they want as an output. They have to actually grind over possible outputs and then they can choose the best one. In some cases, that might actually be okay. For example, if the output is like choosing a random committee from a large set, the combinatorics might make that grinding and choosing committee that's really good for the attacker is actually difficult. And there's also kind of a classic line of research. So in the 80s there were all these papers on coin flipping or collective coin flipping, which is kind of the historical antecedent to the modern, I guess, idea of a DRB. And they focused a lot on this question of having a combination function that wouldn't give too much influence to any one participants.
00:15:09.330 - 00:16:02.258, Speaker A: So, for example, you could take a majority if you're generating one random bit, you could have all the participants contribute a random bit and then output zero or one based on the majority of the bits that were actually submitted. And that way, even if you're the last participant to go, you probably won't actually be able to influence the output at that point. So there's various other kind of tree based constructions that can limit how much influence the last contributor actually has. But there's also like a known lower bound that the last contributor will have a lot of influence. If there's N participants, they have to have at least a probability one over N of slipping the output if you're just outputting a zero or a one bit. So probably more biased than we're really willing to tolerate in practice. So this is sort of a deadline of research that I think people aren't thinking about too much anymore.
00:16:02.354 - 00:16:05.782, Speaker B: That's for like a worst case order that people go in, right?
00:16:05.836 - 00:16:53.560, Speaker A: Yeah. Okay, so moving past Rock, Paper, Scissors, which, like I said, not very practical, what's actually very close to practical and is essentially the basis of all the other DRVs that I'm going to talk about is the commit reveal, which is hopefully also something that people have seen before, but I'll go through it nevertheless. It's basically just adding one more phase to the rock, Paper, Scissors idea where everybody commits to their entropy contribution before they actually reveal what it is. So you have a phase one where everybody commits using a cryptographic commitment function. Then you have a phase two where everybody reveals what their entropy is. Of course, that commitment function should be hiding. So seeing everybody else's commitment doesn't reveal any information about what their entropy contribution is going to do.
00:16:53.560 - 00:17:43.394, Speaker A: And then you can combine everybody's entropy. So it's actually pretty close. It gives you a random output as long as you have at least one honest participant. The only flaw is that if you have a malicious participant, who's the last one to reveal, so they can see everybody else's entropy contribution in phase two, they can then sort of mentally simulate the rest of the protocol and say, if I do reveal, this is what the output will be. And if they don't like it, they can just abort or withhold their entropy contribution, and then the protocol won't finish. Nobody else will know what their entropy contribution was, so they can't compute what the output would have been. So this gives them one bit of bias.
00:17:43.394 - 00:17:57.130, Speaker A: They can basically choose keep the current output as it is or force a restart of the protocol and then they'll get a new random output and maybe they can do this multiple times before the other participants sort of get tired of them and kick them out or take some other action.
00:17:58.270 - 00:18:11.022, Speaker B: I guess the alternative version is you could have the output be well defined even in the absence of at least one value. Like you write the sum, right? You say the sum of whatever you had and so then you'd only be choosing between two different outcomes, right?
00:18:11.156 - 00:18:37.446, Speaker A: Yeah. So you're saying have the output be well defined even if somebody doesn't contribute? Well, I guess some protocols kind of do work that way that they can recover from somebody dropping out. But you want everybody's contribution to influence the final result. Right. Otherwise, I guess I'm not totally sure.
00:18:37.468 - 00:18:43.398, Speaker B: What you're well, I was just like you read sum right there sum over EI is the output, right?
00:18:43.484 - 00:18:45.946, Speaker A: Right. So you're saying, like, it could be.
00:18:45.968 - 00:18:47.594, Speaker B: The sum over the ones you know about.
00:18:47.712 - 00:18:49.866, Speaker A: Yeah. So that still gives bias, though. Yeah.
00:18:49.888 - 00:18:52.250, Speaker B: But there's two choices at that point that you're picking between.
00:18:52.320 - 00:18:53.114, Speaker A: Right, I see. Yeah.
00:18:53.152 - 00:18:54.986, Speaker B: You're not going to have this repeated abortion.
00:18:55.018 - 00:19:33.910, Speaker A: Yeah. The problem though is that if you have a coalition of malicious participants, if you have like K malicious participants, they'll have two to the K choices. They can choose whichever subset to withhold to give the best result. Okay. So basically all the other DRVs I'm going to talk about, you can sort of think of all of them as patches to this last revealer attack and commit reveal. So hopefully everybody feels good with commit reveal because everything else will be an extension that tries to fix this last revealer attack. So I'll get to the other protocol, but just comment on definitions.
00:19:33.910 - 00:20:20.406, Speaker A: I think one of the key things we found when we were doing the survey is that nobody agreed on the definitions. There aren't standard definitions. So we tried to generalize all the definitions in the literature into kind of a framework that captured everybody's definitions and we came up with three kind of universal properties and all the other a lot of people define other variations, but in the end we convinced ourselves that every other property dropped out of these three. So the first is unbiased ability. If attackers are in the protocol, they can't produce a distinguishable bias. So I'll get a little bit more into that definition on the next slide liveness. So if attackers are participating, they can't prevent the protocol from producing output or produce some sort of null output.
00:20:20.406 - 00:21:05.574, Speaker A: So the protocol should hopefully produce output even if there are attackers participating. And unpredictability means attackers can't predict any property of the output. So it could be they can't produce the last bit or they can't predict the parity. So our definition actually captures this notion that there's no property that they can predict, at least with better probability than randomly guessing it. And we make a distinction between intra unpredictability. So in some protocols, attackers might learn early within a round, so I'll show an example later. And in some other protocols, if attackers are the majority in one round, that allows them to predict the next couple of rounds, or in some cases even predict the beacon for the rest of time.
00:21:05.574 - 00:21:21.180, Speaker A: We call that interdictability when you can actually predict across epochs, so that's potentially worse. Although there's a lot more protocols that have this intro and predictability where some of the participants might learn the output slightly earlier than some of the others.
00:21:22.990 - 00:21:35.450, Speaker C: Question if the beacon output smaller values, safely selection, it only selects one of hundred. Do you have to change the definitions for unpredictability, or does it have any lambda security parameters?
00:21:35.530 - 00:22:07.420, Speaker A: Oh, yeah, the definition still works. We basically just say, like, if attackers are in the protocol, they can't predict any better than if they weren't in the protocol. So you can always predict some. Like if you're predicting the leader out of N people, you can always predict one out of naively. Right? So our definition says you can't do any better if you're participating in the protocol. Another note is that I didn't specify how many attacker are participating in the protocol. I didn't specify how many nodes they actually control.
00:22:07.420 - 00:22:45.474, Speaker A: And that's that's going to be different. For different DRVs, some try to maintain security even if the attacker has N minus one of the participants under their control. Some limit the attacker to only having a minority of nodes. So hopefully I'll make that clear. So as far as unbiased ability, the way we defined it, which took some work, actually to come up with a definition that captured all the different notions you wanted. Our notion is that we run the beacon kind of twice in parallel. Once with all honest participants and one is an infiltrated run that the attacker is able to control some number of the participants.
00:22:45.474 - 00:23:47.900, Speaker A: And again, they might be in minus one or it might be some minority coalition. So each of those produces some output, and then the attacker gets one of those two outputs by coin flip, and they have to make a guess which output they actually got. And if they can actually do that with any advantage over one half, then we say it's biasable and notice. One of the things that's interesting about this definition is that the attacker can actually have a private biasing strategy. So they could bias it in such a way that's undetectable to anybody else without some secret key, but the attacker can actually notice, which would be like a potentially really interesting attack if you could bias it in a way that provably nobody else could detect unless they knew your secret key. Okay, it makes sense. I don't think we're going to go too much more into definitions of that in this talk, and I'm happy to chat with you guys offline about some of the more fine points here.
00:23:47.900 - 00:24:55.294, Speaker A: All right, so basically for the rest of this talk, I'm going to go through a flowchart of different DRB families, all kind of starting with commit reveal, like I said, which is vulnerable. So the simplest way to patch commit reveal is if you have a clear economic model. So if you have a clear economic model of what the attacker stands to gain from actually biasing the DRB output, then you can do a commit reveal punish protocol. So the way that works, it looks a lot like commit reveal, except in addition to committing, all the participants actually have to put some money on deposit. So notice we have a smart contract in the middle there that's capturing everybody's deposit who's participating in the protocol. And then in the reveal phase, you get your deposit back when you successfully reveal your entropy contribution. So the two honest participants here get their deposit back, and this malicious participant who aborted it, who didn't reveal their entry contribution, they don't get their deposit back.
00:24:55.294 - 00:25:53.050, Speaker A: It's captured by the smart contract. In this case, what happens? Does it get burned or does it go somewhere else? It's maybe a separate question. All right, so what does this really value? Well, if you can say with certainty that the attacker their utility, this is a really simple case. Imagine their utility is zero with probability one minus P, or it's some positive value capital U with probability P, and that's the probability over an honestly run DRP. So if the attacker is trying to manipulate by repeatedly aborting the protocol so they get what they want, this is just really trial. So they have to do one over P minus one runs of the protocol. And from that, you can directly compute how big everybody's deposit needs to be such that the attacker is not incentivized to try to manipulate.
00:25:53.050 - 00:26:02.160, Speaker A: So really nothing fancy going on. It's kind of just saying the attacker has a certain utility and they're not going to attack if the cost of the attack is going to be bigger than that.
00:26:03.010 - 00:26:08.378, Speaker C: Do they usually then rerun the protocol or try to recover and still calculate an output?
00:26:08.474 - 00:26:48.170, Speaker A: Yeah. This is assuming that if anybody aborts, you restart the protocol. And of course, the attacker doesn't get legal process back in that case. So it's expensive for them to keep doing it. So maybe this is okay if you well, first you have to be sure that you have the economic model, right? And maybe this is okay if you have a very low probability event that the attacker is trying to force. In general, this is a really efficient patch to commit reveal, especially if you have a smart contract that they're very good at capturing deposits and not giving them back. People misbehave.
00:26:48.170 - 00:27:28.650, Speaker A: So it's not a surprise that this is how Randao worked, which was one of the first DRVs that was implemented on top of ethereum. It's been pretty widely used. It's efficient, and it's very easy, given a simple economic model, to prove that this is actually secure, that the attacker is not incentivized to abort the protocol. The problem, two problems, really. One is that you need to lock up a lot of capital to make this work. And if anybody drops out of the protocol due to an honest fault, if their network connection goes down, or there's the gas war and they're not able to submit their entry contribution on the network, they'll also lose their deposit. So that's a risk.
00:27:28.650 - 00:28:04.550, Speaker A: But probably more importantly than that, it's hard in practice to really bound what the attacker's utility is. Especially if we want to design a beacon that's used for multiple purposes, different attackers might have different values and those would all have to sort of be somehow reasoned about in advance, which I think is difficult to do. A lot of certainty, but this is still implemented and this is actually how the Ethereum beacon chain works today. So stakers actually get splashed if they don't reveal their contribution.
00:28:07.050 - 00:28:23.754, Speaker B: I mean, you could imagine this sort of utility model. You could imagine saying that's kind of really the problem of the downstream user. Right. So you could imagine just saying, like, look, here's the beacon. We guarantee it up to sort of this value. It's up to you, the application designer, to decide whether that's good enough for you.
00:28:23.872 - 00:28:58.178, Speaker A: Yeah, I think the question is, and I don't think anyone's really worked this out, this is on my future work slide, is what happens if multiple lotteries are all being run on the same beacon and the attacker try and manipulate all of them at once? I guess if they're all sort of independently hashing the result, hopefully you get some sort of like multiplicative security and the attacker doesn't benefit from trying to attack them all at once. I think that's the difficulty. Like if you say it's guaranteed up to a million dollars, but if multiple people are running million dollar lotteries in parallel using the same beacon yeah, the.
00:28:58.184 - 00:29:07.202, Speaker B: Hope would be that any one individual, from their perspective, they don't care that these other people might once in a while be losing money. My likelihood of losing money is kind of just capped.
00:29:07.266 - 00:29:07.974, Speaker A: Right?
00:29:08.172 - 00:29:09.320, Speaker B: That'd be the hope.
00:29:10.170 - 00:29:37.060, Speaker A: Yeah. Interesting to think about there. I don't think anyone's really tried to formally reason about this beyond sort of the very basic mathematic. In particular, I think Randall is just a blog post. I don't even think there's really been an academic paper about it. It's almost one of those things I think seems too simple and obvious to be an academic paper. So maybe that's something to chat more about.
00:29:37.060 - 00:30:10.634, Speaker A: All right, so that's commit, reveal, punish. So the next step in the flowchart, if we're not going to go down the economic security route, is to ask if we can make an honest majority assumption. And if you can't make an honest majority assumption, then really the only game in town that we know about is to use time based crypto or delay based crypto, which actually leads to really simple and kind of efficient protocol. So notice there's two malicious dogs. Now, because we're in the dishonest majority.
00:30:10.682 - 00:30:17.150, Speaker C: Model, is there impossibility result that time based crypto is necessary?
00:30:17.650 - 00:31:11.390, Speaker A: Not directly in the case of DRBS, but there are some generic. FTC impossibility results that I think imply this, but I don't think someone's I think by implication, from what we know about MPC, what's the intuition that the commit, reveal, punish doesn't work if you have a non honest majority? Oh, it does. Yeah. So maybe that wasn't clear, but yeah, I was thinking, like, if you're in the economic world, you could also do a delay based thing where you could do commit, rebuild, punish. But at this point, we're out of economic security. I still want to dishonest majority. Then the only thing that works is that I think okay, so the simplest example is unicorn.
00:31:11.390 - 00:31:37.202, Speaker A: And it's really simple. It's kind of just reveal or contribute. There's no commitment at all. So all the participants publish their entropy contribution directly. Again, no commitment. You reveal exactly what you're doing, and then you combine all these together and you run them through a delay function. In modern use, this would be a VDF.
00:31:37.202 - 00:32:38.598, Speaker A: At the time this was proposed as unicorn, they had kind of a pseudo BDF called slot. But the idea is that this delay function is slow to compute, and in the case of a BDF, you get efficient verification, kind of as a bonus. So why does this work? Let's say that you have one malicious participant who's the last one to choose their entropy contribution. Here they can try to think about what would happen if I choose a specific entropy contribution, but actually combining all the other entropy contributions with this possible choice and running it through the delay function. They don't have enough time to actually evaluate the delay function before some deadline. The protocol imposes that they have to actually publish. So the benefit really why the delay function is powerful is that it ensures that the attacker can't compute the result fast enough to actually decide whether or not this is a good choice.
00:32:38.598 - 00:33:14.174, Speaker A: In fact, for any choice that they would try to think about, they can't simulate the rest of the protocol fast enough to choose whether that's a good choice for them or not. So again, really simple protocol. It's only one phase. Everybody just contributes the value. You collect them all together and run them through the delay function, and that's it. The only real kind of downside of this is that the delay function has to be computed every time. So there's a variant that was recently published by me and students.
00:33:14.174 - 00:33:57.760, Speaker A: The B in this case is me. And so we called it Bicorn because it's kind of a variant of unicorn, but with two possibilities. And the idea of Bicorn, it works more like commit reveal. So there is a commit phase followed by a reveal phase. And if everybody reveals so if every participant is honest, then you get the result right away. There's no delay function. But if any number actually, as participants are dishonest, don't actually reveal their committed value, then you can still run a delay function and get the result.
00:33:57.760 - 00:34:49.034, Speaker A: And this uses time commitments, although we use a special time commitment that's really ad hoc for this application. But the cool thing is that there's a homomorphism in a time commitment so that you can add all the time commitments together and just open once. So there's only one delay function, no matter how many participants there are. And it also guarantees that in the optimistic case or the pessimistic case, you get the same result every time. So there's no benefit to the attacker of forcing the protocol into the pessimistic case. All they can do is slow things down, but the result will be the same in any case. And of course, you can apply punishments here so you can combine with some ideas from commercial punishment and say if the attacker forces the protocol into the pessimistic case, they sacrifice the deposit, but they can't actually manipulate the randomness.
00:34:49.034 - 00:34:52.794, Speaker A: They can just bow it down and kind of annoy everybody. Just to clarify.
00:34:52.842 - 00:34:58.154, Speaker B: So there's some function, not the VDF, which aggregates the C sub eyes and gives some random output.
00:34:58.202 - 00:34:58.800, Speaker A: Yeah.
00:34:59.250 - 00:35:02.450, Speaker B: So last time, like, delay function was actually giving you the randomness back.
00:35:02.520 - 00:35:03.042, Speaker A: Right.
00:35:03.176 - 00:35:07.810, Speaker B: Whereas here the VDF is just to get those C OTS, just to get the input.
00:35:08.150 - 00:35:36.378, Speaker A: The delay function is not really giving you randomness. It's a deterministic function. It's just kind of re randomizing. And that's true in both cases. But it is true that the delay function in this case is not exactly a VDF, but at core it's also repeated squaring mod n. So it's basically the same geographic slope function, but the inputs and outputs are slightly different.
00:35:36.464 - 00:35:43.040, Speaker B: I mean, you could always basically make it random. Well, I guess it depends if you're comfortable with random oracle assumptions and that kind of thing.
00:35:43.410 - 00:36:10.840, Speaker A: Yeah, but even then, I guess it depends on what you mean by random. But it has to be deterministic functions that everybody gets to say the result. Right. I guess there's no extra entropy coming in through the delay function. I mean, I think Brand is saying in the comments it's a hash function. VDF is a hash function which takes a long time to compute. I think that's exactly right.
00:36:14.010 - 00:36:18.106, Speaker C: And your construction, does it work for any VDF or is it no.
00:36:18.208 - 00:36:54.430, Speaker A: Yeah, so it really only works for repeated squaring in a group of unknown order because it's not generic across VDFS. It's kind of building this special time commitment. Right, okay. So in general, for unicorn and for Pycorn, they're really efficient. They allow flexible participation. There's no setup, so different group of people can show up in every epoch and they work with a dishonest majority. That's probably the most important thing, that you only need one honest participant and they always finish.
00:36:54.430 - 00:37:35.400, Speaker A: So it's impossible to block these protocols. So they almost have everything that you want. Really the only two downsides one is just the practical requirement that someone has to be around to compute this VDF and the VDF can slow down. It has to take some minimum time by design so it slows the protocol down a bit. And there's also this intra epoch predictability problem. If the attacker has a faster VDF evaluation circuit than everybody else, they can learn their results early. That's kind of just an inherent limitation of these protocols.
00:37:35.400 - 00:38:38.060, Speaker A: So again, they can't manipulate, but they can potentially learn the result before everybody else. And that means that if you're an application building on top of this, you have to sort of assume the output might be public and you'd have to say stop collecting bets or stop allowing people to move in a game or something like that before you actually know what the output is yourself. All right, so that's delay based DRBS. And these are on the roadmap to be added to ethereum with the min root PDF which they've been working on. So the goal is to at some point add these to the beacon chain and again, they're kind of going to do it in combination. So they're still going to do a commit reveal, punish style thing, but then they're going to add a DDF on top. And the goal is that they still have some economic security argument even if the BDF completely collapses and the attacker can compute it instantly somehow.
00:38:38.060 - 00:39:34.910, Speaker A: Okay, so moving down the flowchart, everything else will be in an honest majority model. The next question is if you have a static participant set. So if you have the same participants running for many, many runs, and if you do, there's a family of pretty efficient protocols that are what I call pseudo random DRBS. And the reason is that they rely pretty heavily on a setup. The setup is really just some distributed key generation. So the output is that there's some shared public key. It's essentially a secret shared VRF key and all of the participants have one share and you've set it up so that actually computing this VRF requires T out of N participants to cooperate.
00:39:34.910 - 00:40:28.420, Speaker A: So there's distributed setup of DKG. This could be centralized too, although I don't think that's proposed quite as often. The important thing is that the setup itself has to be a DRB. So you're basically running sort of one expensive DRB to get this key and then you can run an efficient DRB through many rounds after that. When I say the setup has to be a DRB, it should be that no participant can manipulate the actual public key that you get or else they could sort of manipulate to something that they've pre computed values or something like that. So you need to ensure that everybody is contributing entropy to this setup and that it's not easy for any coalition of malicious participants to manipulate the setup. But once you've gotten through that, which is usually kind of all the hard work here and I'm not going to get into dkgs because that's basically a whole long talk.
00:40:28.420 - 00:41:17.454, Speaker A: But once you have a DKG and you have this shared key, then it's very easy. You have some input in each round that could be as simple as just the round number. It could be the DRB output from the previous round. Couple of options, but everybody computes a partial signature, a partial VRF evaluation, and you combine those and the result is basically a VRF evaluation on that input with the shared public key. So the output is deterministic in each round, so there's no possibility for bias. The argument for that is very straightforward, right? Once you've committed to this key, there's no more entropy being contributed in each round. So notice the participants here aren't contributing fresh entropy in each round.
00:41:17.454 - 00:41:46.874, Speaker A: They're just computing a function of this round input. And that kind of makes it obvious that there's no possibility for bias here. So that's kind of the benefit here. There's a bunch of other protocols in this family. One of which is cool is Strobe, which does kind of use a threshold RSA. One of the ends in that long author list is our own Lara. Not sure which n actually.
00:41:46.874 - 00:42:24.786, Speaker A: In fact, we should put her on this bottom, see if you could actually recite every one of those author names. But Strobe basically does this with generating a threshold RSA key between all the participants. And the nice thing about Strobe is that you can actually run the protocol backwards. So if you have a current output, you can generate all the past outputs from that very efficiently. Which is nice, but I guess I jumped the more well known one, which is Dran. There's also what Dfinity uses, which is threshold BLS signatures. I'll talk about that more on the next slide.
00:42:24.786 - 00:43:02.820, Speaker A: But that's kind of the simplest and most efficient way to do it, because threshold BLS is really elegant and efficient. And there's a couple of other protocols that use Schnor. They use kind of a similar thing to BLS that doesn't require a curve of pairings. I like that name a lot, too, because they call it Glow DRB. And Glow is actually the author acronym. They were lucky that their names worked out that way. So on the topic of Drand, it's actually, I think, the only cryptographic DRV that runs that isn't specifically tied to a blockchain project that I know about.
00:43:02.820 - 00:43:41.326, Speaker A: So that's out of date. It's obviously oh, no. Yeah, it's eleven out of 18. I think maybe it's not eleven. Those numbers are out of date because we can see the 18 current well, we see 18 logos here, which I think are the current participants. But anyway, so Drand is kind of a project that a bunch of different universities and different crypto projects and a couple of other companies that cloudflare run nodes in. They have a threshold BLS key.
00:43:41.326 - 00:44:37.810, Speaker A: They compute a new signature every 30 seconds, which gives you 256 bits of output and it's just on the web, so I was going to just show so they have a kind of a nice web interface with a cool animation. It's not like the bits actually come in one after the other. They all come in one such JavaScript animation, but every 30 seconds it updates, so we should get a new one. But anyway, so it's really nice to have a nice API. So you can build applications like blockchain or non blockchain applications on top of this. And it's actually been running for a couple of years. As far as I know, it hasn't had any downtime, so it's been kind of a reliable service and there's a process to apply if you want to join this and add an extra node.
00:44:37.810 - 00:45:29.010, Speaker A: So it's quite nice. And again, it's very efficient with threshold BLS. So again, efficiency is the main goal here. It's also like efficient to verify really the two main challenges. One is generic to any honest majority DRB, which is that if you assume that T honest participants are needed to get output in a given round, any N minus T participants can actually block output. So you're sort of inherently trading off the number of participants you need to actually be honest to make progress versus the size of a coalition that can kill liveness for you. And you can see the parameters that Dran chose, they sort of favored.
00:45:29.010 - 00:46:37.234, Speaker A: They didn't choose T to be 50%. So it's a little bit harder to predict the output in advance than it is to block liveness, which is probably a sensible choice, but that's kind of a trade off that you need to make here. The bigger problem with kind of the simple form is that there's no recovery if there's ever a compromise. So if you manage to compromise all these nodes in DRAM and steal their keys, you can predict every output infinitely far into the future because it's a deterministic protocol at that point. So it might be prudent in practice to repeat every so often just so that the window from damage is limited. All right, so if we don't have a static participant set, but different participants are coming and going each round, you can ask at least if it's a small participant set and you'll see in a second why it needs to be small. But if you have a relatively small participant set, there's this family of commit reveal recover protocols.
00:46:37.234 - 00:47:34.758, Speaker A: And I'll comment here that probably more than half the academic papers are in this family. It's not clear that this is really actually the most interesting use case, or if it's just the one where there's the most different papers to write, but this is kind of where the bulk of the papers actually work. So really simple commit reveal recover works like Commit Reveal. Everybody publishes a commitment, but they also publish a secret shared version of their actual entropy commitment. And it's secret shared to all the other participants in the protocol and they use a tool called PVSS publicly verifiable secret sharing so that they can prove that they've actually done this secret sharing correctly. And that guarantees that even if they go away and don't open their commitment, the rest of the participants, an honest majority of the rest of the participants can recover. So if everybody reveals it works just like normal commit reveal.
00:47:34.758 - 00:48:22.618, Speaker A: But if somebody drops out, the honest participants can get together with this extra information that they got in round one. They can run this PBSs reconstruction function and that will allow them to reconstruct the entropy contribution of whichever nodes dropped out. But again, obviously there needs to be an honest majority here, but they'll get the same result by recovering the missing piece of entropy. So that's the idea. There's a lot of different versions of this, like I said, which use kind of special PBSs. Some of them amortize the PBSs over multiple rounds to try to get the efficiency better. Some of them just dispense with the optimistic case completely and say we're just going to secret share a bunch of values and then collectively reconstruct them.
00:48:22.618 - 00:49:02.534, Speaker A: So there's a lot of remixes of this basic idea. The downside, well I should say the benefit is that this gives you kind of flexible participation with fresh entropy in every round. The downside beyond the basic honest majority assumption is that the efficiency is not nearly as good here. So these all require N squared communication to do all of the secret sharing. And if you're in the reconstruction case, I guess in the really simple kind of classic commit reveal that causes extra overhead as well. So the N squared is really the killer. And that's why I said this family only works if you have a small participant set.
00:49:02.534 - 00:49:44.690, Speaker A: It's a big participant set that ends, birds can kill you. So if you do have a big participant set and this is the last family to present, then the solution here is to do some kind of committee selection before you actually run one of these potentially less efficient protocols. So in a committee based DRB, you have a large set here, some honest, some malicious participants. And the first step is that you just subsample this and get some random committee for this specific round. And there's a bunch of different ways to do this. You could deterministically pick your committee. It could be like public or secret who's on the committee.
00:49:44.690 - 00:50:22.666, Speaker A: So I'll show some options on the next slide. But somehow you get a committee and hopefully that committee is small enough then you can run either commit review, recover or something that's not by sufficient. Maybe if it's running for a lot of epochs you can do some pseudo random protocol but that would work kind of just as it was on the last slide. The key really is how you sort of randomly subsample the nodes down for the specific round. And again, the way I've drawn it here, we got lucky. We had two honest and one malicious node. Obviously it would be bad if you selected altering malicious nodes to be your committee for the round.
00:50:22.666 - 00:51:10.800, Speaker A: They would be able to manipulate the beacon for that round. So there's a bunch of different ways that you might select the committee. The simplest is to just rotate and they get more and more complicated. You could feedback in your aminus from the previous round or you could do some private selection using PRS or even single secret leader election is kind of the most fancy modern way to do it, where a lot of the research is happening. Now in general, moving down the slide here, we have better adaptive security. So round robin, the attacker knows in advance who's going to be on every committee. So if they can preemptively corrupt those nodes before a specific epoch, they can manipulate the epoch, they can manipulate the randomness in some epoch that they care about.
00:51:10.800 - 00:52:03.246, Speaker A: Whereas with the private leader election, even an adaptive attacker doesn't know who to corrupt in advance. And then once you have your committee, like I said, there's at least two options for how you actually generate the randomness in a specific epoch. So lots and lots of protocols here not going to go over all these individually, but basically every combination of different strategy for selecting a committee and for selecting entropy exists and people have written papers about. So there's been a lot of really great research here. So what this gets you really is that it can be scalable. Even if you have large number of participants, you don't have to eat that N squared cost over the whole participant set. And you can do this in sort of a modular way.
00:52:03.246 - 00:52:59.220, Speaker A: So you can sort of drop in and out different strategies for committee selection and then different DRVs once the committee actually forms and that allows you to trade off lots of different security parameters that you might care about. The challenge here is really that committee selection is an extra risk if you select a corrupt committee that you're sort of hosed for that round. Plus you still need to run a DRP, which can have all the problems that we talked about before. So I'll say this again on my future work, but this is where Ssel would really help. So Ssle is a hot research topic that really makes committee based approach better. I think we still haven't hit the limits of really good efficient SSoV protocols. So I hope that we're going to have better protocols in a couple of years than we have today.
00:52:59.220 - 00:53:34.060, Speaker A: So lots of combinations are possible. I mentioned some of these already. You can sort of combine the idea of punishment in a lot of these protocols to punish participants who drop out to try to get better efficiency. I mentioned modularity for the committee based approaches. There's kind of this other question of could you run multiple DRBS in parallel? Just combine the results. That's actually a little bit tricky. If you do it naively, whichever the last protocol to finishes, it basically becomes the last contributor and can negate what the other ones did.
00:53:34.060 - 00:54:03.430, Speaker A: But you can actually fix this with delay functions. So you can have multiple DRBS run even if they're not guaranteed to finish at the same time. If you have a long enough delay function, you can combine them securely. Although at that point, if you're trusting a delay function, it's not clear why you wouldn't just use unicorn. But this is something that you could do. There's a lot of other practical considerations that I didn't talk about. Even just efficiency has a bunch of different dimensions.
00:54:03.430 - 00:54:45.426, Speaker A: I sort of talked about different protocols and what the security model is. But it's interesting to reason about what happens if the security model breaks. So some of them, for example, if the honest majority assumption fails, that just allows predicting. Sometimes it allows biasing. So that might be you might care about how bad things break if they do break, as well as this issue of recovering from some kind of temporary fall. So the obvious advertisements, if you want to know all the details, they're in the paper. I think this is kind of a tradition with sok talks, is that you show unreadable snapshot of the table, sort of justify that.
00:54:45.426 - 00:55:20.394, Speaker A: There's a lot of detail in the paper that's being left out of the talk. So the paper is online now, if you want to go and read it. Let's see, there's a question in the chat. Oh, somebody said what's? Graham said chia uses yep. Karma. What's? Ssle? So a single secret leader election. So it's a way to choose a leader for a round, or more generally, a committee for around such that the committee is not immediately known.
00:55:20.394 - 00:55:33.822, Speaker A: So they can sort of stay private until they need to act and then they can prove that they're on the committee. It's a really powerful primitive. I think it was introduced in 2021, 2020 maybe. There have been a lot of papers coming out about it recently.
00:55:33.966 - 00:55:38.766, Speaker B: I sort of think of it as like, imagine magically used VRFs and got exactly one winner.
00:55:38.878 - 00:55:41.518, Speaker A: Yeah, or exactly K winners.
00:55:41.694 - 00:55:42.690, Speaker B: Prescribing.
00:55:46.250 - 00:56:23.006, Speaker A: All right, so I guess a couple suggestions that came out of this work of areas people should look at. Obviously, I already beat the drum of Ssle is really powerful, so that's a good research topic. All the definitions in the current DRB literature are game based. Well, a lot of papers don't even really have security definitions that just present a protocol, but mostly they're game based. So I think it's a good project to try and have UC definitions for DRBS. People haven't really taken that on yet. Nobody's really proved adaptive security of most of these protocols.
00:56:23.006 - 00:57:20.162, Speaker A: There's kind of a missing link to randomness extractors. And I think maybe more importantly, we haven't really proved fundamental limits sort of in each of these five models for what you can achieve. I don't know if it's proven that that N squared communication is inherent to the PBSs model or if that's just the limit that every protocol seems to run up against. Miriam asked if it's inherent that you need some time based crypto to get around an honest majority assumption that also hasn't really been directly proven. So that would be a nice result. On the engineering side, I think VDFS are really powerful, so getting those out, having hardware for them as soon as possible, as Bram said, chia has been using PDFs for a couple of years. I said before, like PDFs are not quantum computers, they're not a theoretical object that doesn't exist.
00:57:20.162 - 00:58:31.740, Speaker A: They exist, and Chia and possibly other projects are using them now. But there are some engineering things we can improve, like having really fast hardware available to honest parties. And on the economic side, I mentioned having a security model for implicit beacons based on asset prices or blockchain data would be really nice as well as for the commit reveal punish model, being able to reason about deposits when the attacker sort of has a more complex utility function. So mostly people have said the attacker gains utility U with probability p. Nobody's really looked at what happens if there's sort of a more complex suite of options that give different utility to the attacker. Or maybe you have multiple attackers that get different utility and they have to sort of jointly contribute. And then the last thing I'll say is, in addition to all the cryptographic research, actually getting people to use DRVs in the real world, so outside of kind of crypto or Web Three projects, it's been a long term goal of mine for a long time.
00:58:31.740 - 00:59:22.282, Speaker A: So like I said, really ancient technology people have used for a long time to generate randomness. For a lot of the big lotteries today, not just mega millions and powerball, but things like the NBA Draft or seeding the World Cup tournament. They're basically still using the ancient technology. They still do ping pong balls on TV for the NBA Draft. So I think a key challenge would be convincing people outside the crypto space that DRBS are actually better than this physical randomness approach, which is hard because it's not very intuitive. People think that they can at least understand the ping pong bomb model much better than that. So kind of a long term goal is that things like the NBA Draft would actually be using a cryptographic DRB in the next 510 15 years.
00:59:22.416 - 00:59:34.560, Speaker B: I should think it's regressing. I watched the draft this year and it was one person in a private room doing the ping pong experiment and then reporting the results back to everybody else.
00:59:36.450 - 00:59:51.638, Speaker A: And the fans don't actually buy it. The fans think it's rigged every year no matter what. So trying to say like, they have room maybe for more convincing things, but the fans don't seem to believe it. But maybe they would come up conspiracy theories with crypto too.
00:59:51.724 - 00:59:57.670, Speaker B: I mean, 31 of the 32 teams lose every year. Some of them are going to have conspiracy theories.
00:59:59.710 - 01:00:05.500, Speaker A: All right, so those are the slides I had prepared and I'm happy to take questions on any of these.
01:00:07.870 - 01:00:25.486, Speaker C: I was interested in what you mentioned about how you can use this to kind of DRBS in general to get around Fiat. Shame. Is that something that because then you can avoid the random Oracle model and also how that interacts with the UC and stuff. Is that something people have thought about?
01:00:25.668 - 01:00:45.830, Speaker A: Yeah, I'm not sure. This might be a question for Justin if this idea has really been formally written up anywhere, but I've heard it proposed and it's pretty intuitive that if you just need a random challenge in some step of your interactive proof protocol, you can generate that using a DRB and replace Yashmir.
01:00:46.970 - 01:00:59.260, Speaker C: Yeah, I guess it's like usually it comes up more in modeling and theory where people will complain if you're technically saying you're in the UC. So it's maybe not as practical a.
01:01:00.990 - 01:01:33.030, Speaker A: Mean. I guess if you have the DRB as a black box, kind of strong assumption that it's outputting randomness, then yeah, it seems like it gets around needing a random Oracle. I don't know. Has anyone really formally written about this, Justin? Like interactive proof protocol? It's been mentioned in the introduction of some papers, hasn't actually been deployed, to my knowledge. There's actually a lot of confusion about that encounter people who thought it was deployed when it hasn't been not seen it deployed.
01:01:33.770 - 01:01:36.066, Speaker C: Some people are still using hash.
01:01:36.178 - 01:02:11.700, Speaker A: Everything's being run just with Fiat shmir non interactive. Yeah. It's a question too, of how much efficiency that value if you're doing like a roll up proof this way. Right? And while it could make the proofs shorter, they're now spread over multiple blocks, so that maybe increases some kind of latency and it's trade offs all over the place. The beacons might be biasable a bit. Any other questions?
01:02:14.070 - 01:02:24.230, Speaker C: Good question about bias. Beacons that have the bias, if you use them for leader election, can you cause a cascading effect kind of slowly?
01:02:24.730 - 01:03:02.720, Speaker A: Yeah, I think you can. I think some of the proof of Stake protocols try and help that. I think algorand there's like withholding attacks, right, where you have a winning PRS, you don't contribute, but I think they sort of rely on the fact that it's hard to grind over committee selections for the next epoch and actually get one where you're a majority unless you're already really close to a majority. So they have a whole combinatoric or statistical argument for why this doesn't buy the attacker that much, but it is like part of their security model.
01:03:03.410 - 01:03:04.300, Speaker B: All right, thanks. Again.

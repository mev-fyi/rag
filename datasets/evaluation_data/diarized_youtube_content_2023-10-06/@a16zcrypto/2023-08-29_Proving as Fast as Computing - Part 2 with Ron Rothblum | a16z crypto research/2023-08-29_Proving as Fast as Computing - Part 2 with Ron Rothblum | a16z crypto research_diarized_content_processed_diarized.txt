00:00:10.160 - 00:00:20.100, Speaker A: Thanks, everyone, for coming. We have Ron Rothblum here again from the Technion to tell us additional details about proving as fast as computing. So, part two, take it away.
00:00:20.170 - 00:00:22.724, Speaker B: Awesome. Thanks, Justin. Okay.
00:00:22.762 - 00:00:22.964, Speaker C: Hi.
00:00:23.002 - 00:00:54.560, Speaker B: Good morning, everyone. So as far as I can tell, everyone that's here was also in my previous talk. I will try to do, like a really brief reminder what was going on last time and what I plan to cover this time. Okay, so the setup, which I guess we all know by now, we're trying to construct succinct arguments, basic notions of completeness and soundness. So correct statements you should be able to prove, false statements you should not be able to prove other than some small probability. And we're doing this for NP statements. And we want short communication.
00:00:54.560 - 00:01:04.432, Speaker B: Zero knowledge is sort of optional. And we're focusing throughout this talk on circuits, mainly on boolean circuits.
00:01:04.576 - 00:01:05.270, Speaker C: Okay.
00:01:06.200 - 00:02:05.128, Speaker B: As was said last time, I'm going to present protocols that are interactive. They are public coins who can reduce the interaction using fiatromere. At least heuristically okay. One thing that's going to pop up a lot in the talk today is epsilon, which is the soundless error, which we would like to be as small as possible. Okay, so what we covered last time, we're going to go into a little bit of reminders of some of the technical stuff. But the main technique that we discussed is this technique that we call code switching, which morally, the way I think of it, is a way to design IOPS so that you can encode whatever you care about using some code that has nice properties. It does need to be a tensor code for what we showed, but then pretend that the encoding that you sent was actually encoded under some other different tensor code that may have other useful properties and execute the protocol as though that were the code that had actually been sent.
00:02:05.128 - 00:02:58.810, Speaker B: But then at the end, switch, meaning verify emulate access to the sort of pretend virtual code using the actual code that was sent. So that was the idea behind code switching, which we saw. And using this, we were able to derive linear size provers for arithmetic circuits and high rate IOPS. So just something that I think I wasn't maybe clear enough about last time clarification in terms of sort of credits. So this idea of code switching was in my work with Noga from 2020, but our mindset was deriving high rate IOPS, IOPS that are very short and sort of follow up works, sort of use the fact that you can use the same technique, give or take, to construct these linear size provers for arithmetic circuits. Essentially, one way to do it is to take our approach and replace the high rate codes with a linear time encodable code. And that would be good enough.
00:02:58.810 - 00:03:46.936, Speaker B: So going back to the main, so far, what we saw last time in terms of actual proofs were how to construct argument systems for arithmetic circuits. But the main theorem that I stated and did not prove was for Boolean circuits. So the main theorem said that for Boolean circuits, which in a sense are the most challenging case, we want a strictly linear size prover expressed as a Boolean circuit. And in terms of verification, we have o of circuit size preprocessing. As was pointed out, this preprocessing is non reusable. So if you don't like it, we will need to have a linear size Verifier and the communication is polylogarithmic. The number of rounds is log, can easily be made log, log.
00:03:46.936 - 00:04:22.496, Speaker B: And the silence error is an arbitrarily small constant. So we'll try to sort of see more or less the proof of that today. Then we had the second result, which a result of Justin, which sort of under the same assumption, linear time computable or linear size collision resistant hashing. Same assumption as before. Here what the big benefit is that we get two to the minus lambda soundness error rather than a constant. And the overhead that we pay is sort of exponentially better than the nave thing of just doing things in parallel. So it's only polylogarithmic in this lambda.
00:04:22.496 - 00:05:02.480, Speaker B: So that's the green part. The red part is that we only know how to do this for certain types of Boolean circuits. So ones that have a lot of repeated substructure. We'll see this today. But here the Verifier can really be sort of as long as the substructure that's being repeated is small enough, the Verifier is going to be really fast. Any questions so far? It's stuff that we've seen, and I will hopefully not bore you too much with a little bit of more reminders about underlying techniques because we're going to use them extensively today. We sort of saw that the main technical tool that gives rise to all of this stuff is this notion of IOPS or interactive oracle proofs.
00:05:02.480 - 00:05:24.520, Speaker B: We saw this before. It's kind of for those coming from theory, it's a multi round version of PCPs. For those that are not, you just send over long messages. But at the end of the day, the Verifier only reads a few bits. And we saw that using vector commitments or Merkel trees, you can move from IOPS into succinct arguments.
00:05:25.180 - 00:05:25.592, Speaker C: Right?
00:05:25.646 - 00:05:39.452, Speaker B: So the easy part is using the right assumptions. The easy part is getting good vector commitments. The hard part is designing good IOPS. So that's what we need to focus on. And we'll get to the size challenge later in the talk. So far, so good.
00:05:39.586 - 00:05:39.884, Speaker C: Okay.
00:05:39.922 - 00:06:44.080, Speaker B: In terms of tools, we have error correcting codes, these mappings, taking messages into code words. We will care very much today about these two parameters, the rate, the amount of overhead of the code and the distance of the code, how good of an error correcting code it is, how much do code words avoid each other? And we had this theorem saying you can't have your rate and eat it too. So Singleton bound saying that overall, the sum of the rate and the distance can be at most one. So we'll come up and codes are linear and systematic. We covered all that multiplication codes, codes that have this property that if you multiply pointwise two code words, the resulting vector belongs to some related code, like we see with Reed Solomon and tensor codes, which we're going to use again extensively today, have this property in code rows, in code columns, or vice versa. We see that the effect of tensoring two codes is sort of doubling the rates of the two rates of the codes. The effect of the distance is doubling the distances.
00:06:44.080 - 00:07:19.356, Speaker B: Please stop me if you have any questions. This is just covering stuff from last time. Very soon we will stop covering stuff from last time. This is the last sort of reminder slide sum check, typically viewed as a protocol for checking that the sum of a low degree polynomial is equal to zero to some vouch, some predetermined value, using an interactive proof with very small communication. Here I'm abstracting it. I'm thinking of it as a sort of general protocol that you can hope to have for any code. So we were looking at a code word, W, belonging to a code e.
00:07:19.356 - 00:07:39.584, Speaker B: Think of very long code words and we're interested in computing the sum of the message bits or message symbols or elements of this code. So you can do this for low degree polynomials, for tensors, more generally, for read solvent using mix work with IOPS. Yeah, solve this.
00:07:39.622 - 00:07:41.440, Speaker C: We saw. Good.
00:07:41.590 - 00:08:09.660, Speaker B: So at this point, I want to introduce sort of a new abstraction which will turn out to be very useful, which is you can think of it as a generalization of sum check. We call this an inner product check. So it looks very similar, but now instead of having so the notation switched a bit, but we'll be okay. Instead of having access to a single code word, I'm giving you oracle access to two code words, c and C prime. And the goal is to compute the inner product between the two message parts.
00:08:10.880 - 00:08:11.484, Speaker C: Okay?
00:08:11.602 - 00:08:46.644, Speaker B: So in sumcheck, we had one code where we were looking at a sum. Now we have two code words and we're looking at the inner product. So this abstraction, on one hand, it's actually, if you think of it, it's really used throughout everything, but it has never materialized as an abstraction. And I think the reason for that is that it's sort of typically trivial to get why? Because if your code C is a multiplication code, what you can do is take the pointwise product of C and C prime and now do some check on that. So you've done this multiplication, then some. Overall, you have an inner product. So that is what is happening sort of everywhere.
00:08:46.644 - 00:09:34.564, Speaker B: And usually there's no need to point it out because you just do the multiplication and you're done. In this work, it's going to be actually crucial to distill this notion. And the reason is that we don't have any linear time encodable multiplication codes. So if we want to do something sort of like this picture, we cannot just follow this idea, multiply the code words and run some check because we don't have fast enough multiplication codes. So at the heart of this theorem that I'm going to prove to you is going to be a construction of some code C that is linear time encodable. It is not going to be a multiplication code, but nevertheless, it supports this operation. So you can do this inner product check using a linear size prover.
00:09:34.564 - 00:09:44.810, Speaker B: There's an IOP for proving sort of this inner product check, this extension of sum check with a strictly linear size prover. And also then coding of the code is linear size.
00:09:45.600 - 00:09:46.012, Speaker C: Okay?
00:09:46.066 - 00:10:16.420, Speaker B: So that's going to be sort of the heart of the technical result. Okay. So really we're going to have two steps. The major one is the first one. This is all about getting the result with the constant soundness error. So the first step is constructing a protocol code and a corresponding inner product check of linear size. Once we have that, then going from that to IOPS for general circuits will be pretty straightforward.
00:10:16.420 - 00:10:49.364, Speaker B: So the focus is on constructing this thing. So let's give it a shot. Right, so our goal now, again, is to design a code that is linear time encodable, but for which given two code words using an IOP, you can compute the inner product of the messages. So let's design a code. And given all of these different types of codes that I've told you about, here's maybe a natural suggestion. So I'm going to take my code C to be a tensor of two codes. It's a very highly skewed tensor.
00:10:49.364 - 00:11:02.884, Speaker B: So in one direction we're going to have like a very small code, and in one direction, a very large code. So it's a tensor of D and E. D is sort of the large code, and we're going to fix a parameter A. Think of it as a constant ten.
00:11:03.002 - 00:11:03.332, Speaker C: Okay?
00:11:03.386 - 00:11:35.640, Speaker B: So A is equal to ten. So code number one takes pretty long messages of length N over ten. Think of N as being very large, and I want it to be a linear time encodable code. We have such codes, and I don't need much beyond that. So D is a linear time encodable code, or maybe a tensor thereof, but ignore that. So D is sort of fastest code that you have lying around. The other code that I will need is a code E, which is a tiny code, right? It's encoding just like ten bit messages.
00:11:35.640 - 00:11:39.570, Speaker B: And there I do need for E to be a multiplication code.
00:11:40.340 - 00:11:41.088, Speaker C: Okay?
00:11:41.254 - 00:11:52.596, Speaker B: So if I could have I think Tim asked about this last time, if I had a linear time and codable multiplication codes, I would need all this nonsense, but I don't. So encourage students to think about follow.
00:11:52.618 - 00:12:02.328, Speaker D: Up on that question. Is there any hope in kind of saying linear time encodability plus multiplative code lets you do fast forward transforms or something like those?
00:12:02.494 - 00:12:09.528, Speaker B: Potentially, I do think that the multiplication property underlies FFTs, it'd be great if.
00:12:09.534 - 00:12:22.030, Speaker D: You could say, like, the barrier actually is faster FFTs. That would be pretty convincing. Otherwise, the worry is that there's a lot of work to kind of get around this log factor that would be more directly sort of gotten rid of through other means.
00:12:23.040 - 00:12:40.588, Speaker B: So regardless, it would be, from my understanding, from sort of coding theorists, it would be major progress, really major progress to design linear time encodable multiplication codes. And you're asking I'm doubtful that if you had that, then you would have a speed up for FFT.
00:12:40.684 - 00:12:41.100, Speaker C: Okay?
00:12:41.190 - 00:12:51.044, Speaker B: But I think such a code would be a good replacement in a lot of places where you use FFT and you would have the faster evaluation, like.
00:12:51.082 - 00:12:53.880, Speaker D: In TCS applications or actually for signal processing.
00:12:54.620 - 00:13:41.030, Speaker B: I don't know enough about signal processing to be confident about it, but it underlies sort of a lot of nice properties of Read Selman as a code follow from it being a multiplication code. So the Burlicamp Welsh decoding algorithm and stuff like that, the underlying thing that you have, or the use of read Solman also in MPC, so that is a TCS or CS application comes from the multiplicative property. So I think it would be very exciting to develop such a thing, not exclusively only for IOPS, but more generally, but since we don't have such a thing, we'll resort to sort of more elaborate techniques. So, again, we have our big code D, which is very fast. We have our code E, which is a small code. We don't care so much about its encoding time because it's working on a constant size object.
00:13:42.840 - 00:13:43.216, Speaker C: Right?
00:13:43.258 - 00:14:25.940, Speaker B: So D is linear time encodable, e is a multiplication code. And just as a sanity check, let's see what is the overall encoding time when we tensor these guys. So if I want to encode so the blue part is the message, and I want to generate all of the orange stuff, the encoding, what do I do? Well, as we said, for tensors, say I encode each one of the rows that will take me N over a times some function of A, which I don't care about so much overall, that will be linear in N. Think of A as a constant. And then encoding all of the rows, I have some function of a number of rows. For each one, the encoding is linear in N. Overall, I will have linear in N.
00:14:25.940 - 00:14:41.000, Speaker B: Okay? I mean, there's no real reason why not use a relatively efficient multiplication code like read Solomon here, but I don't really care so far. Questions? So just in terms of the overall encoding time of this new code, it is linear.
00:14:42.460 - 00:14:42.824, Speaker C: Okay?
00:14:42.862 - 00:15:09.590, Speaker B: So I've shown you a linear time encodable code, but the heart of the matter is showing you this procedure for computing inner products, right? So let's try to do that. So here's a picture of what we have in mind. We have two code words from this newly designed code and we're trying to compute the inner product of the blue parts, right? So notation wise, we're trying to compute sort of distance sum of over I-J-C-I-J times c prime I j.
00:15:11.400 - 00:15:11.764, Speaker C: Okay?
00:15:11.802 - 00:15:37.084, Speaker B: So let's try to do this. And here's the first attempt. So we know that all of the rows belong to our multiplication code, right? So if you take the first two rows, you multiply them. The result should lie in sort of in the product code. Does that make sense? You multiply the second two rows, it also lies in the product code. We go along and we do all of these. By the way, this can all just be done in the proverbs head.
00:15:37.084 - 00:16:09.412, Speaker B: So far, nothing has been sent. So I'm doing all of this. And now I want to add up all of the green rows. And now I want to claim a couple of things about the resulting sum. First thing I want to claim is that this resulting sum belongs to the product code of E. Do you see why this is true? So recall that each one of the green rows belongs to the product code because we just did multiplication and this product code is linear. So when you add stuff up, the resulting thing also belongs to the product code.
00:16:09.546 - 00:16:09.844, Speaker C: Okay?
00:16:09.882 - 00:16:23.690, Speaker B: So that's one observation. The second thing is that I want to say that if I look at the first laser doesn't work. If I look at the first three entries of W and sum them up, I claim that I'm supposed to see something of interest there.
00:16:25.420 - 00:16:27.116, Speaker C: Okay, what is it?
00:16:27.138 - 00:16:44.304, Speaker B: Well, it's exactly the result that I'm looking for. If you look at the inner product between the blue parts of C and C prime versus the three first entries of W, each entry of W was computed essentially as an inner product of the corresponding columns. Now you add them up, overall, you get the inner product.
00:16:44.502 - 00:16:45.824, Speaker C: Okay, great.
00:16:45.862 - 00:17:22.316, Speaker B: So I have the prover compute all of this stuff. Just send W to me. It's a short message. I check that the sum of the first three bits is the original claim that I have about the inner product and the W is a code word. And now I seem to be in a really great, in really great shape. Because if the prover sends the correct W as defined here, then I'll just see the sum there and I'm done. So if Approver is trying to fool me, she has to send some other alternate W tilde which disagrees with W.
00:17:22.316 - 00:18:09.580, Speaker B: So we know that W is a code word of estar. We know that W tilde is a code word of E star, because we explicitly check that. So if we have two distinct code words, they have to disagree on a lot of locations. That is what the distance guarantees, right? So now a very natural idea would be for the verifier to choose a column at random and then sort of you just need to check that the value in that column was computed correctly. So run another linear product, another inner product check on this column. Okay, so here's the picture, right? So we're saying that if the prover is trying to cheat, she will send a different W tilde. The red boxes are marking sort of places in which W tilde differs from W should be a large fraction.
00:18:09.580 - 00:18:48.890, Speaker B: Now, our verifier, so the verifier doesn't see which ones are red or blue. She just chooses a random. If we are lucky, she hits one of the red boxes. In which case, if we just run an inner product check that this value over here was computed correctly, meaning that the value there is basically the inner product of the two corresponding arth columns of C and C prime, then we're done. It seems very natural, seems very reminiscent of sumcheck and stuff that I showed you. It is actually. It also doesn't work.
00:18:48.890 - 00:19:18.192, Speaker B: And the reason is the following. So the problem is, basically we want to recurse. We've shrunk the problem by a constant factor, by an A factor. We're pretty happy and seems very natural to recurse. But the problem is that the column code is not from the code that I designed. It's from this linear time encodable code, which I don't have much control over in particular. If I wanted to recurse, I would need this decode the column code, to be itself a tensor code.
00:19:18.192 - 00:19:22.260, Speaker B: And if I wanted to keep recursing, it would have to be a high dimensional tensor.
00:19:22.840 - 00:19:23.540, Speaker C: Okay.
00:19:23.690 - 00:20:14.976, Speaker B: That's a major problem. Because if I wanted to overall just keep recursing, recursing, recursing, what I would have is that there would not really be a code D. What I would have would just be a high dimensional tensor of a multiplication code E. And that's a problem because we saw before that if our code E has distance delta, we saw that the behavior of distance and rate is that it sort of you raise it to the power of whatever number of times you tensor it. We saw that if you do it once, it squares and so on. So the main thing is, if we want our code E to have constant distance because we're aiming for constant sums, even just the first round, it means that the rate of the code C becomes vanishing and just sending it over will be too long. So we cannot do this trick.
00:20:14.976 - 00:20:24.360, Speaker B: Doing this sort of what I described here is really just doing some check essentially, which will not work by itself or sum check for tensor codes.
00:20:24.780 - 00:20:28.932, Speaker D: Is there like a different operation you could interleave it with to keep the parameter?
00:20:29.076 - 00:21:40.480, Speaker B: Yeah, but so far this doesn't work and a different operation will be code switching. So the idea exactly, we keep the entire picture that we had as before we've selected the arc column, but now I'm really as promised, the arc column is coming from a linear time encodable code, not a code that not a tensor code that I can keep recursing on. But luckily enough, we have this mechanism of code switching. If we're not happy with the code, we just switch to some other code, right? So what we'll do is we'll ask for the prover to send a fresh so the arth column was encoded via the linear time encodable code. And I'm going to ask the prover, hey, Mr. Prover, can you please send it to me under a fresh encoding under a nicer code? Okay, at first glance it may seem kind of weird know, these things were already encoded. If I want to switch to some other code, why didn't I apiori encode them using that code? And the point is that the prover only needs to encode the arth column using this new code rather than all of the columns, and therefore she can afford to introduce more redundancy.
00:21:40.480 - 00:22:19.084, Speaker B: Because we are only encoding a single column, we can use sort of better encoding in terms of distance that has worse rate because we don't need to encode each and every column. So that's the key idea. One thing to worry about, which maybe because you came to the talk on Tuesday, you're not going to be too worried about, is that the prover could send the wrong encoding, not like not send the encoding of the same message under a different code. But let's ignore that for now, we'll get back to that later. So for the moment, whenever I ask the prover to send a fresh encoding of a message, let's believe that it actually does.
00:22:19.122 - 00:22:20.748, Speaker C: So good.
00:22:20.834 - 00:22:46.390, Speaker B: So given this idea, I think the protocol almost is immediate. And here's the bird's eye view. So the point is that as we recurse, we're shrinking by a factor A. I'm using L to denote the depth of the recursion because I was something else before. So L is the depth of the recursion in level zero. We're starting off with a message of length N. As we go along, we shrink by a factor of A.
00:22:46.390 - 00:23:31.190, Speaker B: And the point is that after L levels of recursion, we are handling messages of size N over A to the L. And I claim that at this point we can afford to introduce an overhead in terms of time. An additional like A to the L over two overhead. In a second, we'll see why, basically because of how the geometric series works. But let's believe me for a second, that you can afford this extra overhead in time. Given this extra overhead in time, you can afford to use to get to have lower rates. And if you believe that using a code that sort of hits the singleton bound, you'll have like, rate A to the minus L over two and you'll get distance one minus that.
00:23:31.190 - 00:23:36.580, Speaker B: So this will be our distance in the code and the L level of the iteration.
00:23:37.160 - 00:23:38.036, Speaker C: Why is this good?
00:23:38.058 - 00:24:18.240, Speaker B: Now, you just do some back of the envelope calculation. If I'm summing the work that the proof is investing overall throughout all of the rounds, then you have this sort of expression, which luckily enough, because of how some of geometric series works, is strictly linear. That's on the one side, on the other side in terms of soundness. Now, instead of having we don't have a constant soundness error in each level of the recursion. The soundness error in each level keeps going down and down, right? It's like in every round, it's A to the minus L over two. And if we choose our A to be large enough, that will be sufficient. It will be a constant, basically a constant determined by A.
00:24:18.240 - 00:24:52.312, Speaker B: So I have this slide with the worm's eye view. I think the bird's eye view is better. So let me skip it. Let me mention one important thing, is that I wanted to always this should be A to the minus L over two. I wanted the distance of my code to be one minus A to the minus L over two. But I mean, in the beginning, I was talking about using sort of a binary error correcting code because I'm looking at boolean circuits. I want the binary code to be compatible with that and not to have overhead coming in from just using a larger alphabet.
00:24:52.312 - 00:25:44.430, Speaker B: But binary codes can have, at most distance, one half. And here I want sort of distances approaching one. So actually, as I PROCEED throughout this protocol, not only am I going to be switching codes, I'm also going to be switching fields. So I start off with a small field and gradually throughout the protocol, whenever I switch a code, I'll also switch to a larger and larger field. I'll be working with extension fields, so it will be okay. So as we make progress, we're switching both codes and the underlying field just so that we can get the good distance from the code. So just to summarize, what does the protocol look like? So we have our basic code, C zero, which is the code that I told you, right? It's a tensor of a linear time encodable code with a multiplication code, right? So n over a times a that's c zero.
00:25:44.430 - 00:26:18.036, Speaker B: The prover computes the W, that thing that we had on the bottom, right, as before, sends it over to the verifier. The verifier chooses a column, so we column R zero. Now, the prover sends a fresh encoding of the arth columns. This will be C one and C one prime. These are fresh encodings under sort of a new code, c one, which is analogous to C zero. It's again like a tensor of a linear time encodable code with a multiplication code. Where the multiplication code? Now, we can afford for it to have worse rate and better distance.
00:26:18.036 - 00:27:09.640, Speaker B: In particular, if you see look at the next W that is sent, because we're using a multiplication code with worse rate, it's going to be a little bit longer. So this keeps alternating where the sizes of the message C, the columns keeps shrinking, but the size of the W's keeps increasing as we go along. So one thing I didn't tell you about is the consistency checking, although that really is very tightly connected to what we saw last time with code switching. So the point is, now in each round, the prover is sending a fresh encoding. So the Verifier already has an encoding of CL, and the prover sending a fresh encoding of the same message under a new code that's called that CL plus one. And we want to check that indeed the messages encapsulated within are the same messages. So we need a way to do this.
00:27:09.640 - 00:27:53.050, Speaker B: And first of all, as I said last time, using these procedures of local testing and self correction, at the very least we know that what the prover sent are indeed code words. We just need to check that the messages inside are the same. So let's see how to do that. So this sort of lemma, let's imagine that we have sort of a general lemma. It says if we have two tensor codes, c and D, where their message sizes are the same, k, the block length, the size of code words can be different. So N and N prime, but both are tensor codes. Then I claim that there is an efficient procedure for checking membership in this language, namely that given two code words, the message inside is exactly the same.
00:27:53.050 - 00:28:29.440, Speaker B: So let's actually show the proof of this quickly. We as a verifier are given oracle access to C of M and some D of M prime. And our goal in life is to check that M is equal to M prime. So just as a mental exercise, let's compare C of M versus C of M prime. What we have is M coding under D of M prime. But let's think of C of M prime. What do we know? Well, if it happens to be that M is equal to M prime, then certainly C of M and C of M prime are equal.
00:28:29.440 - 00:29:17.090, Speaker B: But if M is different from M prime, then C of M and C of M prime, not only are they not equal, they're not equal in a lot of places because they are both code words of C. So now if you imagine choosing a random coordinate I of this code. Then if M is equal to M prime, of course, C of M and C of M prime will agree on this coordinate. Whereas if the messages are different because the code has distance, they will disagree with high probability. This is all nice as a mental experiment, but the verifier doesn't actually have C prime of C of M prime, but still, a verifier chooses I, and we have these properties. And let's indeed assume that we were lucky enough. We hid one of the don't have to be super lucky because we have distance, but indeed, we hit one of the coordinates on which they differ.
00:29:17.090 - 00:29:28.660, Speaker B: The next observation is that if you look at CM prime in position I, because C is a linear code, this is some linear function of the message M prime.
00:29:29.160 - 00:29:29.572, Speaker C: Right.
00:29:29.626 - 00:29:46.956, Speaker B: We don't have direct access to this because we only have access to D of M prime. So the situation that we're at is that we have oracle access to D of M prime, and we want to check some linear function of M prime, and we've seen a way to do this.
00:29:47.058 - 00:29:47.708, Speaker C: Right.
00:29:47.874 - 00:30:24.920, Speaker B: So sort of sum check does this we again run into this annoying issue that we had last time that we have coefficients, because this is a specific linear function. It's not just a sum, but the exact same issue that we had last time we have here and the exact same solution. So if you're careful about it, we can observe that the coefficients of this claim, if C is a tensor code, the coefficients, viewed as a matrix, have rank one and then sum check just works, plug and play. So that's how we check consistency throughout all of this. The prover sending over these fresh encodings.
00:30:27.020 - 00:30:28.664, Speaker C: Questions. Yeah.
00:30:28.782 - 00:30:34.436, Speaker E: So what is the tensor structure of D? Like, does D need to be a high dimensional tensor?
00:30:34.628 - 00:30:41.708, Speaker B: No. So D was the linear time encodable code. It can be a square tensor of your favorite linear time encodable code.
00:30:41.794 - 00:30:44.156, Speaker E: I see. But I'm doing some check over it.
00:30:44.338 - 00:30:54.770, Speaker B: It's enough to do sort of so think of like some check over a square thing. So you just need like a quadratic saving. Quadratic saving is enough for you.
00:30:55.220 - 00:30:55.584, Speaker C: Good.
00:30:55.622 - 00:31:15.076, Speaker B: So we've seen the key part, which is the linear time inner product check. Using this. How do we get IOP for circuits? Basically following the same template that we saw last time, which is quite standard. So we have a circuit. We're trying to construct an IOP for this circuit. Let's assume the circuit just contains NAND gates. We denote the wire values by W.
00:31:15.076 - 00:32:06.936, Speaker B: If you hear as a function, I use K as the number of wires just because that was the size of messages in my code. And we have these sort of I think of it as permutations saying for each gate, what are its left and right inputs? Same thing that we had exactly we had last time. But the things that we need to check now are sort of this NAND check that W in position I is equal to the NAND of WLI and WRI. To check that indeed WL and WR were computed correctly. So this is sort of function composition, the circle there and that the input and output is consistent. Okay, so that's exactly the same picture that we had last time in terms of how our IOP is designed. But my point is sort of just showing or reminding why really the key point is an inner product check.
00:32:06.936 - 00:32:46.390, Speaker B: So let's look for example, on this test, this sort of permutation test, how did it work? Well, we wanted to check that this happens for all indices I. What we said is you can choose a random or pseudorandom vector r the test that it happens for every I reduces to this kind of inner product. And now you rearrange or relabel, and both sides that you have are basically an inner product. So you just run our fast linear time inner product check and you can do this and the same thing you can do for the Nantest even more direct.
00:32:47.240 - 00:32:47.892, Speaker C: Good.
00:32:48.026 - 00:33:35.590, Speaker B: So what do we have so far? We basically proved the first theorem that I showed you, that for every boolean circuit we have an argument system with constant prover overhead for boolean circuits with constant prover overhead and constant soundless error. That was the first result. Maybe before moving to the second result, just a quick digest, which also relates to one of your questions from last time. So in all of the previous works that were using code switching, there was sort of one sharp code switch we encoded under a fast code, we pretended that we had encoded under some different code and the end we switched. Here we're doing sort of a much more gradual process. We're alternating. We're doing this very gentle gradual code switching in each and every step and gaining from that.
00:33:36.360 - 00:33:41.224, Speaker E: Just as a reminder, when we didn't have this inner product check, what did.
00:33:41.262 - 00:33:50.010, Speaker B: We use last time for those inner products? We did, we just didn't give them a name. What we could say is.
00:33:51.900 - 00:33:52.328, Speaker C: If you.
00:33:52.334 - 00:34:21.996, Speaker B: Use a multiplication code, you can just multiply two code words, the result, and now the inner product will now just be a sum of the product code word. So it just didn't have a name, but it was there. Okay, so let's talk about how do we get two to the minus lambda soundness error. We are going to pay for that. The payment will be polylog lambda over ahead for the prover, which is very modest.
00:34:22.028 - 00:34:22.224, Speaker C: Right.
00:34:22.262 - 00:34:57.380, Speaker B: Just to remind ourselves again, lambda is what? 128. We're not saying multiply by 128, we're saying you multiply by a log of that. So it is a very mild overhead. Okay, so we want to get IOPS. The first task that I'll show you is how do we get a linear time inner product check with two to the minus lambda soundness error where I allow myself this polylog lambda overhead. So same thing that we did before with constant proof or overhead and constant soundness. Now I want to achieve with two to the minus lambda error and polylog lambda overhead.
00:34:57.560 - 00:34:58.192, Speaker C: Okay.
00:34:58.326 - 00:35:33.052, Speaker B: And it will turn out to be pretty easy. I'll show it to you on the whiteboard. So now our goal is again to solve the same inner product design, a code that supports inner product check, where we're aiming for very good soundness error. But we're willing to tolerate this polylog lambda overhead. So here's the idea. The code will be yet again a tensor code and it will again be a tensor. Where this kind of skewed picture actually this, let's show here.
00:35:33.052 - 00:36:13.220, Speaker B: So here's the message and here's the entire code word. The tensor is skewed. The number of columns is lambda. The security parameter and number of rows is n over lambda. For my row code, I'm going to use a read Solomon code with say, rate one half or one third or something like that. So this is like overall, this is maybe like o of lambda. For my column code, I'm going to use the code that we just used or sorry, that we just constructed.
00:36:13.220 - 00:36:50.286, Speaker B: So it's some code that supports linear time inner product checks with constant soundless error that itself came from a tensor. But I want to forget about that. So it's some code that supports efficient inner product checks. Okay, so this is the code that I'm using to get this new result. I want to show an inner product check. So I actually have two code words. So this is a code word c, sorry, code word c and code word c prime.
00:36:50.286 - 00:37:17.380, Speaker B: And my goal is to compute the inner product between I think it was blue before. Let's try to be consistent. I want to compute the inner product between these two things. I'm going to follow the sort of same moral strategy as before. Think of taking each row here of both of these as a multiplication code. I'm going to do the point wise multiplication. This is just in the proverbs head.
00:37:17.380 - 00:37:51.680, Speaker B: Just need to do it up to here. So these are obtained by just multiplying viewing each one of these as a polynomial. Multiplying the two, I get this and I add all the stuff up and I get the same W that I had before, right? And exactly as before, there is W that is computed correctly. And if the proverb wants to cheat, it has to send some W tilde, which is different. What we did before is to choose a random coordinate and check it. What I'm going to do now is different. I'm going to check each and every one of the coordinates of W.
00:37:51.680 - 00:38:10.286, Speaker B: How? So like coordinate number one, how do I check it? Well, how was it computed? It was computed as the sum of these guys. And these guys were each computed as the product of these two columns. So really the first coordinate here is just itself an inner product between these two columns.
00:38:10.478 - 00:38:10.786, Speaker C: Right.
00:38:10.808 - 00:38:52.930, Speaker B: So I'm going to run the protocol that I had before, which sounds weird because it only has constant soundness error, and I'm shooting for two to the minus lambda soundness error. The point, though, is that when the prover sends cheats and sends w tilde, it's going to send a false claim on constant fraction of these coordinates. So it may very well be the case that the value here is different and I only have constant soundless error, so I won't catch it. But it's also going to be different in a bunch of other coordinates and in each one of them. So in like, o of lambda coordinates and in each one of them, I have a constant probability of catching the prover. So overall, I get my two to the minus lambda to the minus omega lambda probability of catching.
00:38:54.470 - 00:38:55.074, Speaker C: Okay.
00:38:55.192 - 00:38:55.954, Speaker B: Questions?
00:38:56.152 - 00:38:56.610, Speaker C: Yeah.
00:38:56.680 - 00:39:08.342, Speaker E: So for the column code, you still do need this code to support in a product sum check. And also it has this systematic property that encodes the message, like it keeps the message intact at the first.
00:39:08.476 - 00:39:30.190, Speaker B: Yeah. So for me, it's very convenient in dealing generally with tensors to think of systematic code, usually for free. So I usually just don't worry about thinking of non systematic code. If you're asking whether it generalizes the non systematic code, possibly, I haven't thought about that.
00:39:30.260 - 00:39:38.162, Speaker E: But here you're using this very special code that allows you it itself is a tensor code. Right, right.
00:39:38.216 - 00:40:01.398, Speaker B: So I kind of forgot about it. What I cared about is for it being able to compute the inner product. You're right that we constructed that itself from a tensor code. And I think at some point I thought it out. We're doing a lot of tensoring. Some of it is unnecessary. It's just as useful abstractions because I don't want to worry about I just want to think, oh, this supports inner product check.
00:40:01.398 - 00:40:29.966, Speaker B: I'm not trying to save on the amount of tensoring. Definitely, if you were thinking of making this practical, that's something you would want to do. But here I'm just looking for the asymptotic statement and the cleanest way of stating it. Thank you for the question. Okay, good. So we pretty easily got this two to the minus lambda soundness error. Let me show you another sort of issue that comes up usually when designing IOPS.
00:40:29.966 - 00:41:34.714, Speaker B: Often we need to check. So something that comes up a lot and we'll have a sort of related solution is that we are given access to a code word and we want to check, I'll say in double quotes, that it vanishes or essentially is zero on some nice structured part of the domain. Let's say over here, people use vanishes because people usually think about polynomials, and polynomials are zero means that they vanish. So I want the protocol where I have oracle access to this code word C, and I want to check that it's sort of identically zero over here. So the traditional method of doing this is saying, hey, if this code word is supposed to vanish here, let's choose a random linear combination and look at the inner product of this code word with a random vector. That's sort of the usual way, what we saw a bunch of times both last time and this time. And the problem that I have here is that this usually works.
00:41:34.714 - 00:41:50.250, Speaker B: It usually works really well. It has like one over field size soundness error, which is usually just perfect. But we are looking at very small fields. We're looking say at GF two. So this would only have one half soundness error, which I cannot afford.
00:41:50.410 - 00:41:50.974, Speaker C: Right.
00:41:51.092 - 00:42:19.250, Speaker B: One thing I could do is repeat this, but then I would need to repeat lambda times I get N times lambda instead of N times polylog lambda. So I cannot do the standard trick. So let's see how we do this again. Very simple. So let's look for a second on this using all the colors. Let's look at this part over here. We want to check that the red part vanishes.
00:42:19.250 - 00:42:30.166, Speaker B: Okay, what I'm going to do is think of encoding this guy with so encoding each row using an additional aircraft.
00:42:30.198 - 00:42:30.970, Speaker C: Encode.
00:42:34.270 - 00:42:56.340, Speaker B: Okay, a linear aircraft encode. So I took these guys each row here and encoded it over here. So I have this kind of picture. What do I know? Suppose that this guy was not identically zero. There was some like annoying seven hiding here. Everywhere else was zero. So it's hard to catch because it's just like one place.
00:42:56.340 - 00:43:55.042, Speaker B: So the observation is that if I have this annoying seven here, seven is just an example. Okay. Then the entire row here will have a lot of sevens or like other numbers, non zeros, right? A lot of the entries here will be corrupt. So now what I'm going to do is run this sort of vanishing test on each and every one of the columns, each one with a constant soundness error. So for that I can again, for each one of those I can use the random linear combination and I can use the code from before because I'm only shooting for constant soundness error. But I do this for each and every one of the coordinates. So as before, because a constant fraction of them so of lambda are corrupt with to the minus omega lambda, I'm going to catch it in terms of this machinery so far would be good enough to get you the NAND test that we need when you're constructing IOPS for circuits.
00:43:55.042 - 00:44:26.210, Speaker B: Let's talk for a second about the permutation check. When we want to check the things are permutation of one another. So we want to check something of the form that we have here. Sorry, that C of pi I is equal to C prime of I for every index i. And the way we solved it earlier today and last time was using this idea of random linear combinations relabel and that's that. But now we are running again to the issue that our field is small. We cannot afford a one over F error so we cannot use this trick.
00:44:26.210 - 00:45:13.760, Speaker B: So we need a solution and I don't have one, which is unfortunate. If you have one, I'd be more than I would be extremely excited to see it. What I do have is a solution that works if the permutation is nice enough. So before we had a solution that worked for every permutation here, it will only work for permutations that are nice and that is the reason why we can only handle these circuits with regular substructure I'll give just like an idea flavor of why for structured permutations things are easier. I'll leave some room in between. So the situation that we care about is that we have C and C prime and the contents of the message. There are supposed to be a permutation, a specific permutation of the contents of the message here.
00:45:13.760 - 00:45:51.506, Speaker B: But in reality we know that in our IOP, the message here is going to sort of be like the values of the wires of the circuit and here it's going to be sort of the left or right wires or something like that. So think of it as if I do something like take some small function and repeat it. A lot of times what I will see here will be sort of the value of the input and then the value after the first step, value after second step and so on all the steps of the function. And then if I look at the sort of left wires and right wires, morally what you're supposed to see is the same picture but shifted up or shifted down in a direction.
00:45:51.638 - 00:45:51.982, Speaker C: Right.
00:45:52.036 - 00:46:47.070, Speaker B: So this will maybe go here. Everyone will be shifted up. So that's the kind of permutation that we will be restricted to. But why is it easier to handle such permutations? Well, you can think of an intermediate code word in which you sort of separate there were sort of two things going on or actually the way I described it yeah, the way I described it, there's not much going on. All you have is the permutation is basically just like move one up kind of flavor. In reality there's going to be stuff going on locally between the layers but let's ignore that for a second or forever. So we're just thinking of doing something like a very specific permutation, moving the rows up by one and that is simple enough that we can handle directly without using the random linear combinations.
00:46:47.070 - 00:47:24.060, Speaker B: So morally speaking, without getting into all the details, let me just cover one more annoyance mainly because it really annoyed us. But there's a happy ending to this story. So this is an issue that we call predictability. So suppose we've worked hard, we've designed an amazing linear size IOP. So IOP that can be computed by a linear size prover and we have our linear size vector commitment. What do we do now? Well, instead of sending the IOP messages, we commit, we decommit, everyone is happy and we're done. But here's like a super annoying issue.
00:47:24.060 - 00:47:42.458, Speaker B: So suppose that you've run the IOP and you've committed to all the messages. Now the Verifier says, hey, come on, I want to open up these coordinates. Now, what you need to do is take all your IOP messages and project them to these coordinates or select these coordinates.
00:47:42.634 - 00:47:42.974, Speaker C: Right?
00:47:43.012 - 00:48:27.198, Speaker B: So it really sounds like really trivial, but we're in a circuit model in which it becomes really annoying. So what you're trying to design is a circuit that gets its input, a long string and a bunch of indices into the string. So a string of length N K indices into this string and it outputs the projection of the string to these indices or select or selection. So really like a multiplexer, but for a bunch of indices, not just one. And the naves, if you try for 10 seconds, you'll get a construction of size N times K. So doing something separate for each index. But K is going to be the number of queries in our IOP, which is lambda at least.
00:48:27.198 - 00:49:13.142, Speaker B: And the IOP string is the circuit side. So if you did the nave thing, just this stupidity would give you to circuit size, time, security parameter, which we want to avoid. So the question is, can you do better? And in principle, there's no reason why not. I mean, the input to your circuit is just of length, sort of N plus K and maybe you can do a better circuit. So for the first two papers we had really annoying ad hoc solutions which were sort of saying we're going to design our IOP with a very particular query set. So like, indices that we select are going to have a very specific structure which was hard to maintain and hard to have. And for those kind of indices we had a good circuit.
00:49:13.142 - 00:49:52.806, Speaker B: The happy ending is that we have an upcoming work in which we showed you can do this in general. So there is a circuit that gets input, a string in indices and in size N plus K outputs their projection. Okay, so that's that. Let me sort of conclude with some open problems. Something that I'm very interested in and would love to see is do these ideas, which are you've seen? I'm taking a very asymptotic point of view. Can they have practical relevance? Can we use them potentially to get better soundness for subject that was somehow the limiting factor. I think we can get better soundness.
00:49:52.806 - 00:50:57.358, Speaker B: But the question is, can this be practically irrelevant in terms of more theory questions? This polylog lambda overhead, I think would be amazing result to get rid of getting like strictly linear size circuits with small subconstine soundless error, ideally exponentially small. I should mention that this question is a major question also in sort of kind of more traditional zero knowledge proofs, which are not required to be succinct. So if you insist on zero knowledge but don't require the communication to be succinct, if you want strictly linear size provers and negligible soundness, this has been explicitly open for 15 years of major interest. So that's super interesting. One way to get to do it would be VL linear time encodable multiplication code, which we don't have. Another thing is sort of getting constant round or getting even a non interactive solution. Another thing I'm very interested in.
00:50:57.358 - 00:51:32.920, Speaker B: So there have been really beautiful works, sort of starting with work of Justin's on getting improving the prover efficiency of GKR. I would say an important protocol in the literature. Let me not go into the not super important, but the state of the art is that this protocol can be done for arithmetic circuits with a linear size or time prover for Boolean circuits, which is sort of the default notion, I think, from a complexity point of view. We don't know how to do this and let's skip number five, maybe. Okay, so I'll end here.
00:51:34.170 - 00:51:35.850, Speaker E: So I wanted to ask you about number five.
00:51:35.920 - 00:52:13.842, Speaker B: Okay, let me explain number five then. Right. So I was kind of like throughout this talk, I was kind of shoving zero knowledge aside, basically said we can tack on zero knowledge for free. The reason that this works is sort of once you have a succinct argument, morally, you can just add zero knowledge for free on top of that. But it is not so friendly in particular. It means that you're going to be making sort of something that we call non black box use of cryptography and not something that's going to be very friendly in practice. A better way of doing this would to have our IOP itself be zero knowledge.
00:52:13.842 - 00:52:25.994, Speaker B: And then when you just compile it in a traditional sense of merkel trees, things would work out. So the question here is trying to, at the level of the IOP, make it zero. So sorry, go ahead.
00:52:26.032 - 00:52:32.330, Speaker E: No, that's what I wanted to know. But did you think about this Vo protocol?
00:52:34.450 - 00:52:39.294, Speaker B: Not so much. I think you're not on that.
00:52:39.332 - 00:52:39.630, Speaker C: Right.
00:52:39.700 - 00:52:51.700, Speaker B: I think Ale has a version with the code switching and for arithmetic circuits that gets zero knowledge. I suspect that similar techniques could work here, but I haven't thought about it too much.
00:52:55.670 - 00:53:04.310, Speaker A: Do you have a sense of what kind of algorithms can be executed in a Boolean circuit without overhead.
00:53:06.490 - 00:53:07.350, Speaker B: Sha?
00:53:09.850 - 00:53:13.340, Speaker A: This multiplexer thing apparently can, but it's a whole paper.
00:53:15.310 - 00:53:20.230, Speaker B: The multiplexer, I think, is a bad example because this is something that is really of triviality for an algorithm.
00:53:20.310 - 00:53:20.746, Speaker C: Right.
00:53:20.848 - 00:53:23.260, Speaker B: So something that's really trivial algorithm. Just like.
00:53:26.110 - 00:53:47.400, Speaker A: I'm actually thinking of, like, Pippinger's algorithm, which sort of has to put things in the buckets. And I guess we don't know that you could do something like that in a circuit without overhead. But I'm wondering if there's some kind of intuition or rule of thumb for where the line is.
00:53:49.690 - 00:54:05.130, Speaker B: So, not surprisingly, random access is a problem. Is that like a rule of thumb? I think it's a great question. I don't have a great answer, unfortunately.
00:54:06.110 - 00:54:10.474, Speaker A: Random access is definitely a problem. Maybe it's the primary problem.
00:54:10.592 - 00:54:10.922, Speaker C: Right.
00:54:10.976 - 00:54:46.166, Speaker B: I'm trying to think if things like, I mean, random access is a problem, but in some sense this multiplexer thing is addressing this so we can do something. It is still, obviously, I mean, in a Ram, you just need, like, K trivial Ram operations to retrieve K indices. You were saying you need O of N, which costs a lot of work and sweat and so on. So I'm not sure if it would be like plug and play into some other Ram algorithm. Yeah, very interesting.
00:54:46.348 - 00:54:56.714, Speaker E: Does this projection thing have other applications in circuit simulation of Ram algorithms and things like that? It seems like a pretty fundamental question.
00:54:56.832 - 00:55:25.360, Speaker B: I agree. The reviewers did not, I don't know, something explicit. It feels to me, very fundamental and basic and something that should have been pointed out in the 70s, but apparently it was not in terms of applications in general to doing Rams. I don't know. We do have an application of this for doing Batch Peer, which is some other crypto thing, but yeah. Thank you.

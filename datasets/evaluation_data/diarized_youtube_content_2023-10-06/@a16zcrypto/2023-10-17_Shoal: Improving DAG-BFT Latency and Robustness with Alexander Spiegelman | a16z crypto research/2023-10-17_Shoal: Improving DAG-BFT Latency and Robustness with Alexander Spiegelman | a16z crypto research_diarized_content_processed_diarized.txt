00:00:10.120 - 00:00:36.100, Speaker A: Really glad to have Sasha Spiegelman speaking at our seminar today. I've known Sasha for a long time. Sasha did his PhD at Technion. Then he worked at VMware with Dalia Malki and ETA Abraham. And then we met at Novi Research, where we worked on the DM blockchain at Meta. And Sasha then joined Aptos as a co founder team member. I remember Aptos was just four people.
00:00:36.100 - 00:00:46.496, Speaker A: Sasha was one of them. And now Aptos is about 100. It's a big company with a big, fantastic research team. Welcome, Sasha.
00:00:46.528 - 00:01:06.876, Speaker B: Thank you, Lera. Thank you for the introduction. And thank you all for inviting me. I actually don't remember the last time I was nervous before a presentation, but this setup is very serious to me. So yeah, excuse me. It will take me probably a few minutes to get into it. Last time I presented, I gave a talk in I 16 Z.
00:01:06.876 - 00:01:35.172, Speaker B: It was last year I presented bullsharks. Today I'm going to talk about Shoal of Bullsharks, and I hope the name will explain himself during the presentation. Yeah, let's start. So this is a joint walk with Balaji Wati and Zikun from Aptoslabs, some backgrounds. Before I jump into it, this is at least my journey in the Dag based consensus. There are other walks, but these are my journey. Like started in Potsy 2021.
00:01:35.172 - 00:02:07.008, Speaker B: We presented like Fury, how you can take a dog and order it with zero over it completely just by looking at the dug. Then in Novel, we demonstrate a system how we can build this dug very efficiently. Then bullshark. We improved latency by taking advantage of the culture of synchronios assumption. And now the new work I'm going to talk about today is Shoal, which improves this latency even farther. Let's start with novel. So just a reminder, not a reminder if you never heard about it's, also fine.
00:02:07.008 - 00:03:01.020, Speaker B: I'm not assuming anybody knows nothing about it, but as I said, Novel is a system to build the Dag. And the two main key points to take out of Novel is that first, that we made the observation that decoupling the data dissemination from the metadata holdering is the key for performance. Meaning that if previously data was disseminated as part of the consensus protocol here we made the observation, we can disseminate the data on the side, provide some proof of availabilities into the consensus, and then the consensus only has to deal with the metadata. This unlock a very high throughput and also allow to scale out architecture review for more machines, and the other machines take care of the data dissemination. All the ring metadata is very cheap. So this is like one key observation. The second contribution of narrow is actually how to take and really build this very efficient round based dug.
00:03:01.020 - 00:03:45.188, Speaker B: Okay, so once we have this dug, we have these three protocols dug, Rider, Tusk and Bullshark. You look at this round based Dag and the cool thing about all of them is that out of this structure you can have a total order with zero communication. Hoverhead everybody are just like there is a protocol, there is a system to build the dag. But each of the validators has a local view of this dag. And completely locally the validator can look at this dag, interpreted the edges and the nodes in some way that represent consensus logic. And completely locally, no hoverhead, no extra communication, you just alter everything. So this is very cool about Dugs.
00:03:45.188 - 00:04:23.384, Speaker B: And here comes the motivation for this work. So, this is the graph from the novel paper. We compare here like novel with different implementation of hot stuff. This is a latency throughput graph. So the vanilla hot stuff, they're roughly about like one eight hundreds, 2000 transactions per second can support. Then if we implemented this idea of decoupling data dissemination from the consensus logic, we improved the throughput quite a lot. But when we use tasks like directly building the dag and ordering the dag directly, we were able to actually achieve a very much higher throughput.
00:04:23.384 - 00:04:51.232, Speaker B: And so this is very nice because we want higher throughput. But if you look at the latencies, the hot stuff latency was better. So the task, I mean, we want both of them, right? So throughput okay, good. But what about latency? And this was the motivation for the bullshark work. If you see here, it's kind of the same graph. And this is the bullshark is going to be in blue here. Compared to Task, we saved quite a bit, like 33% close to the hot stuff latency.
00:04:51.232 - 00:05:11.096, Speaker B: Now almost there. The goal in Aptos was to implement this bullshark and Narval. We already currently have narwhal. We call it quorum stall. This is our local implementation. I mentioned it one time. In the end again, and when we started implementing bullshark, we realized that the latency is going to be worse because we actually not use hot stuff in Aptos.
00:05:11.096 - 00:05:45.368, Speaker B: We use joltin and joltin reduced one round trip from hot stuff. So reduces the latency by 33% compared to hot stuff. So then it's actually somewhere here on the graph. So we pay quite a lot in latency and we didn't want to accept this. So we are starting this research and thinking how can we improve it. And this is the motivation for Shoal. If I need to summarize in like one sentence, shoal is a general framework to take any of these protocols and to add pipelining leader reputation and the ability to get rid of timeouts completely.
00:05:45.368 - 00:06:27.584, Speaker B: And I mean, Dag, rider and task asynchronous doesn't have timeouts, but bullshark is partial synchrony. Bullshark has timeouts, so we are able to completely eliminate timeouts. And this is how with these three features, we are able to improve the latency of bullshark by a lot. Theoretically we could apply to any of them, but we are interested in bullsharks. So we will have a Shoal of bullsharks I know I already talked about bullsharks previously last year, but I won't spend a lot of time about it, just some overhead. I can explain Shoal in a self contained manner, but just I'm going to spend ten minutes just to give better intuition. So otherwise it's going to be a little bit out of context.
00:06:27.584 - 00:06:50.940, Speaker B: So I spent some time to explain roughly what we're doing in bullshark and then it will give better intuition about the Shoal paper. So this is the dug. It's round based, meaning that it advances in rounds. In every round. We have at most one node per each validator. And the important property, one of the important properties is that each node refers to N minus F nodes in the previous round. We are going to use it for quorum intersection.
00:06:50.940 - 00:07:23.296, Speaker B: This is the property. Another important property is that this duct can grow completely asynchronously. Because all you need is in order to advance around in order to advance around here and to broadcast this node, I need to receive I minus F nodes from the previous round. And by the BFT assumption we have n minusf are always honest. So I will eventually receive their nodes and I will be able to publish my next node. And this is how it's going to grow. The honest parties can always grow the Dug, even during a complete asynchrony.
00:07:23.296 - 00:07:50.280, Speaker B: So this is like one of the features. I will also talk about it more when I will talk about eliminating timeouts. So another property of this is non equivocation. This is part of how we implement the Dug. So you can think about it intuitively. You can get this property if you take each node and you're a library broadcast it, then the reliable broadcast give you this property of non eqcation. One of the properties of library broadcast that everybody are delivering the same node.
00:07:50.280 - 00:08:22.564, Speaker B: In practice, that's a bit costly. So this is not exactly what we are doing. But we can say you can have some sort of efficient, reliable broadcast implementation in terms of the abstraction, how to think about it, you can think about reliable broadcast just to understand how we get this non eqication. So what non equation gives us is that we build the Dag asynchronously and each validator has its own local view. So this can be a local view of validator one. This can be a local view of validator four. You see that four already has this node.
00:08:22.564 - 00:08:55.092, Speaker B: One doesn't have this node because of the asynchronous manner of the network, right? This can happen. But if they both, like in this example, have the node validator the second validator two, around two, they both have the node. The node has to be exactly the same, similar, everything is exactly the same. The same references, the same metadata for transactions, completely everything. And then if you apply this logic, you actually have the same causal history. By causal history I mean all the nodes that can be reached from this node, like by a path. Right.
00:08:55.092 - 00:09:22.696, Speaker B: So the same causal history, this is a critical property of the Dug and it simplifies a lot when you're reasoning about the consensus logic of the Dug. So when we come to, we have this local view, we want to alter everything. That's our goal. We don't want to send any extra messages. We don't want to look at it and order it. So the way we do it is this is Validator One local view. We're going to interpret the Dug and we're going to take the first round is going to be an encore round.
00:09:22.696 - 00:10:06.420, Speaker B: The second is going to be the votes round. Again, encore votes, NCO votes for every encore. For the partial synchronous version of Bullshark, which is the one I explaining here, we will have a predefined every even round we'll have a predefined encore. Everybody upper your way, agree on these two in the randomness and Doug Rider and the other and task, you need to elect it in retrospect, not in this one. This is simple. You just upper your reagree and then the goal is going to be to just decide which encode I'm going to order, which I'm going to skip. And then after I order this, I'm going to go one by one and order the causal history by the sum deterministic rule.
00:10:06.420 - 00:10:38.036, Speaker B: And since there is no equication, all Validators will come up with the same order. We say that a node in the voting round votes for the encore if there is a puff, and in the commit rule that we have a direct commit rule. The direct commit rule requires F plus One votes to commit an encore. So in this example, Validator One looks at his doug, this is the first anchor. Can I commit it? Can I directly commit it? The answer is no. I only have one vote and F plus One in this case require F is one. F plus one is two.
00:10:38.036 - 00:10:54.504, Speaker B: I don't have enough votes to directly commit. However, I can commit a two. I have three votes I can commit. Right. The direct commit rule requires F plus One. Where is the subtle part? The subtle part is that, okay, this is what I see, not I. Validator Four.
00:10:54.504 - 00:11:38.740, Speaker B: This is what he sees directly commit a one. Now remember, Validators can see slightly different Dugs because of the asynchronous like manner of the network. So Validator One actually didn't commit a One committed a two, and Validator Four committed a One because it saw the node that Validator One didn't see. So we need some mechanism to make sure that even though Validator One didn't directly commit one, you will be able to commit it indirectly. Yeah, you need to order a one before a two. And we are going to use quorum intersection, of course, for this. So we have F plus One rows to require for a direct commit and on the DAC construction, each node refers to N minus F nodes from the previous round.
00:11:38.740 - 00:12:13.232, Speaker B: So together, what we get is that if an anchor A is directly committed, all future encoders will have a path to at least one vote for A. I will illustrate it in a second. And then all future encoders will have a path to A. So here is an illustration. Validator four directly commit a one, remember from the previous example. And then validator one didn't have this node. But when we will continue building this dug, since A to every node, including a two, has to refer to N minus F nodes in this example, three.
00:12:13.232 - 00:12:47.676, Speaker B: So it has to have an intersection with either this or this one of them, it has an intersection. So F plus one to commit and then free N minus F in order to build the dug. So there will be a path between A two to A one. And we can of course apply the same logic going forward. So this is the kind of main qualimental section here on this graph construction. And then we will use the opposite direction. If there is no path from A prime to A, then no honest validation directly committed A.
00:12:47.676 - 00:13:13.024, Speaker B: So here is the protocol on one slide. What I'm going to do, this is our local view of the Dag. And I think I'm running a bit fast here because I already gave this specific talk here. So I am assuming there is some knowledge. But again, stop me if it doesn't make any sense to you, okay? Yeah. Okay. So this is like some local view of one of the Validators, a one we cannot commit.
00:13:13.024 - 00:13:31.656, Speaker B: There is only one vote. A two we cannot commit. Those we don't even see this is it a round based thing here. I mean, the dog goes there's only one Validator whose block I care about. In round one, they're being committed. Sorry. There's only one Validator whose block I care about.
00:13:31.656 - 00:13:52.080, Speaker B: In round one, they're being committed. Is that right? Yes. This is the anchor, right? We all try to commit this. So there's one guy who's the anchor forget. Yes, and it's predefined. But then after we commit this, we are going to commit the all causal history together with it. Okay? So a two, there is of course no zero votes, right? And then a three.
00:13:52.080 - 00:14:21.180, Speaker B: Finally we can directly commit. We have enough votes. Now the trick is what I'm going to do is that I need to check remember the previous example, somebody might have committed A two. Somebody might have committed A one, right? And the logic to check it is exactly what we saw in the previous slide. If there is a path between a three to a two, then we need to commit it. Because it means somebody might have directly committed. Because we said if there is no path, then nobody directly committed.
00:14:21.180 - 00:14:50.132, Speaker B: In this case, it's okay to skip as to a one, there is actually a path. So we need to commit a one before a three because if we had this node and somebody else saw this node, had a direct link here, he would committed it. Right? If we have a path, it means that somebody could have committed it. We need to order it before. Now, it's also true that if we have a path, maybe nobody committed a one. Right. This does never exist for anybody.
00:14:50.132 - 00:15:39.044, Speaker B: But this doesn't matter because everything is deterministic and all the causal history is the same. So the only goal is to make sure everybody agree on the same total order. So when some other Validators will see a three, it will also see a path here, because like the same causal history for everybody from a three, so everybody will agree on the order. Okay? And then once we do that, we need to recursively apply the same logic for a one going back. In this example, this is the first round, so we don't need to do it. And so this was like the main goal, the challenge, how to decide which anchors to order, which to skip. So we decided to I mean, the All Validators agreed first a one, then we skip a two and then a three.
00:15:39.044 - 00:16:08.316, Speaker B: And then we are going to go and deterministically order their causal history. So in this example, a one doesn't have causal history is the first, so nothing. But then for a three we're going to go and order by some deterministic rule. Say we go like up, down and order them here and we put them here. Yeah. And that's going to be the entire bullshit protocol. Again, I'm sorry, I feel it was a bit fast, but I assume there is some knowledge about it.
00:16:08.316 - 00:16:14.160, Speaker B: I didn't want to bore you, but if we have any questions, I'm happy to answer. Yeah, Tim.
00:16:14.230 - 00:16:20.492, Speaker C: So remind me. So like the green blocks, is there a designated leader of that round to suggest that block?
00:16:20.636 - 00:16:54.190, Speaker B: Yes. So this is the end call. And we can say that the Validator that proposed this end call, we can call him a leader, but it's not a leader in the classical sense. When we build the Dag, the leader doesn't have any specific rule, it's just we interpret his node as the end call. That's the only thing. Yeah. So is it true that until a three is committed to nobody knows the total ordering of any of these other blocks? Yes, we will only knew the order of this once we commit it.
00:16:54.190 - 00:17:17.600, Speaker B: That's true. So when two blocks are committed in the same round, which could happen, right. In this case, we causally order them. Yes. But now suppose in the causal ordering, I first select the top block and then the bottom block. But I see the bottom block being committed first and then at the top block. So in my ledger output, how does it preserve safety.
00:17:17.600 - 00:17:46.220, Speaker B: Can you repeat the scenario? Because remember, all the validators agree first on a one and then first on a three. And when I come to see a three causal history, we also see the same causal history. So we can apply the same deterministic rule. Depends on what the rule is. We can decide to start from here or decide to start from here. But this is like all agreed upon from before. It's the same code we are running, right, of how to determine the causal holder.
00:17:46.220 - 00:17:49.390, Speaker B: Does it answer your question? Yeah. Okay.
00:17:50.320 - 00:17:57.068, Speaker A: What Nazrit was asking was for round five, the top white blocks, do we have a chance to be inserted?
00:17:57.164 - 00:18:13.552, Speaker B: Not here, no, not here. It's a good question. In Shoal we actually try to address some of these issues. Yeah. Could you repeat the question? What about these two? When are they going to be committed? Because they cannot be committed as part of a three because of history. Right. They're on the same round.
00:18:13.552 - 00:18:16.440, Speaker B: They need to wait for the future ankle to be committed.
00:18:19.340 - 00:18:23.800, Speaker C: If this is the current picture, it's still possible the later a two will be confirmed.
00:18:24.780 - 00:19:08.436, Speaker B: It might be, but not as an anchor here. I didn't introduce the notion of weak links, but we can use weak links and then say that I can refer to N minus F in the previous round and we call it strong links, the links that we use for this logic. But we can also have the notion of weak links. And you can refer, for example, from here, you can have a weak link here just to refer to this opium nodes that nobody referred to. So when in the future we will alter some encode, this will be like part of the causal history and then we're able to alter it as a regular node, not as an encoder anymore.
00:19:08.628 - 00:19:20.156, Speaker C: So if I'm just thinking about my own view sort of this chain, is it true that when new blocks get added to it, it's always at the end? Or could they go in the middle too?
00:19:20.258 - 00:19:45.052, Speaker B: No, there is no going in the middle. No. You only append there. Yeah. So just to summarize the bullshark, it's simple, at least in my opinion. There is no view change, no view synchronization. You build the Dag it's liddle in the sense that yes, for your question, we do know who is the validator who's supposed to propose the encore.
00:19:45.052 - 00:20:03.220, Speaker B: But when we build the dug, the lidl doesn't any meaning in the system, right? It's not in any way. We depend on him more than the others. So it's little or less in this aspect. I will not talk today about chain quality, fairness, galbit collection, but we can all achieve it fairly easy on the DAC construction.
00:20:03.380 - 00:20:18.652, Speaker C: Sasha, this is probably one of the things you're going to skip, but one of the things I feel like in DAC consensus talks, people never talk about is like how are transactions coordinated across different blocks that are being proposed simultaneously? Yeah, how would you suggest thinking about that?
00:20:18.786 - 00:20:45.380, Speaker B: That's a good question. I think you refer to the question where every validator proposed on block and we can just duplicate all the transactions. This is your question, right? So we don't tackle it on the consensus level. I don't know how. Maybe if you have some ideas, let's do it, but I really don't know how. And we try to tackle it on the upper level. So in upper specifically we have the notion of PFNs and PFNs VFN.
00:20:45.380 - 00:21:10.830, Speaker B: We don't expose the IP of the validators. We have this protection. So we try to solve it there. So balance it through the public full nodes. And of course in the worst case somebody can attack us, but we try to mitigate it on the system level algorithmically. I don't know what can be done. It's an open question.
00:21:10.830 - 00:21:51.772, Speaker B: Is it also true that if I'm an anchor I can control the total ordering of blocks before me based on who I'm voting on and referring to before? Yes, it's true. Because when you know that you are going to be the anchor and you can wait a little bit and say I don't want to refer to this guy, I'm going to refer to this guy, you can do that. So I showed this slide again, but I want to switch back to Shoal. So I'm just reminding you the motivation. This was bullshark and we want to reduce the latency even more. So this was the motivation. We want to make it like this is hot stuff, we want to make it better than hot stuff.
00:21:51.772 - 00:22:12.844, Speaker B: Somewhere close to jolting as much as possible. Because internally this was the consensus we are using. We don't want to increase the latency, we want to at least keep it the same while improving the throughput. So let's talk about Shoal. Let's analyze the latency of the Dag. Let's start with that. So for the encode the latency is going to be two rounds.
00:22:12.844 - 00:22:57.292, Speaker B: I propose the encode in this round and in the good case it's going to be directly committed here. So we have two rounds for the anchor commit. If you think about the nodes in the voting rounds, they will require three because the anchor is going to link to them and then they will be committed here. But if you think about your question, if you think about the nodes in the ankle round which are not the ankle, they will actually will need four rounds because they will only be aldered here with this ankle. Right. So this is one source of latency penalty that we're paying. And the solution that Shoal is going to provide is something that we call pipeline.
00:22:57.292 - 00:23:37.448, Speaker B: It's not really pipeline, it gives an effect of pipeline. It's not really pipeline in the way we usually think about it. And what I mean is that we will have an anchor in every round. So there are no four in this picture, right? You're either an encore and you're older in two rounds or you're going to be eldered in three rounds. That's the first contribution in Shoal and I will explain. The second cause of latency is that in the worst case, you don't always directly commit off end calls. Of course you would like to keep directly committing them, but sometimes the ankle might be the validator, which is the leader.
00:23:37.448 - 00:24:19.864, Speaker B: The validator that proposed the ankle might be slow, it doesn't get enough support, not get enough votes and you don't commit. You will alter it eventually, but only after you get here, right? In this case. So you pay all this latency. If you have a crash validators, for example, like here, you have to skip it, you cannot order it. So all these are sources of latency penalty. Shoal is a framework to provide leader reputation mechanism. So the idea of leader reputation is that I can look at the past, I can estimate who are the strong leaders and I can make sure that I exclude all the rest.
00:24:19.864 - 00:24:56.432, Speaker B: And the leaders that I'm going to choose in the future are going to be from these strong leaders. So it's like increase the probability of the encoders to be actually directly committed. So the idea of leader reputation itself is not novel here. We are actually using it today. This is like even from the damn days we were using it, but it was a bit different because there if you think hot stuff jolting the leader based protocols, you can use this like a little reputation mechanism. But it's best effort from safety point of view. It's perfectly fine if I think that Lera is the leader, but somebody else thinks the team is the leader.
00:24:56.432 - 00:25:21.132, Speaker B: We will not leach consensus in the next round. None of you will be able to get enough endorsement. But nothing bad will like in terms of safety happen. Because next round we will try again. Eventually we'll converge on the leader. Everything is going to be fine here. Imagine, I think that a one and a three are the anchors and somebody thinks that this and these are the end course, like complete mess, right? We are just completely like all they're completely different things.
00:25:21.132 - 00:25:57.668, Speaker B: So we have to agree on the leaders in order to be able to provide safety. So the challenge here is a bit more challenging here on the dug. Let's see how we do it. So one key property of bullshark also tool for dug rider and tasks. But let's focus on bullshark. Remember like five minutes ago we saw this slide, we have the encodes and the first goal is to decide which to alder and which to skip. We order this, right? And as part of the safety of the block of the bullshark protocol, it has to be guaranteed that we agree on the same encode.
00:25:57.668 - 00:26:36.550, Speaker B: And in particular, we are going to agree on the first encode that we are going to order, right? One could decide it here, one could decide it here, another one could go like far in the future, couldn't commit any of it directly. But eventually there will be some path and they will decide to order this first. If this wasn't true, the entire Bush safety would be wrong. So we can rely on this property. We will agree on the first old encore. And this is like the key observation. And if we understand this, the rest of the result is going to be very easy because we are just going to rely on this.
00:26:36.550 - 00:27:09.564, Speaker B: This was the key property. And the key observation is that we can go back and reintropet the Dag deterministically. And what I mean by that, if we look at this example, if I have this local view of the Dag, I need to go to the future in order to understand that this is the first archer I need to order. But as long as we all deterministically agree on this point, we can go back now in time and start reintropreting the Dag again from here. Maybe in some different protocol, maybe in some different way. Like Dag is a full information protocol. This is the observation.
00:27:09.564 - 00:27:44.936, Speaker B: We can do whatever we want as long as we're deterministic and as long as we have these points of consensus in order to agree to start something new. That's a bit vague, what I'm saying, but now I hope it's going to become clear now. So this is the pipeline algorithm upriori. We have this like mapping from around to leaders. Remember, the leader is the validators that's supposed to propose the anchor. So the way it's going to work is that first we're going to start with a simple bullshark protocol. We have the encore in the first round, the anchor in the third round, the fifth round, every other round.
00:27:44.936 - 00:28:13.120, Speaker B: We're going to have the ankle and ignore this for now. We're not going to use them for the first instance of bullshark. So we're going to just run bullshark, okay? And at some point we're all going to agree that this is the first encode to be ordered. This is just an example. It could be this, it could be this, right? But the important thing is that all validators agree that this is the first encode. The bullshit protocol. This instance of the bullshit protocol is altering.
00:28:13.120 - 00:28:38.856, Speaker B: Doesn't matter how far in the Dag I had to go in my local Dag in order to reach this decision. We all reach the same thing. And now we say, okay, so what we are going to do now, yeah, we're going to go back in the dug and start a completely new instance of bullshark from scratch, black box. Like forget about everything you knew previously, forget about it. Delete. Just remember that this is the encode you. Ordered.
00:28:38.856 - 00:29:00.544, Speaker B: Now we are going to run a new bullshark instance from here, here, going forward, right? And this is completely safe because we agreed on this point. So our local code says, okay, we agree on this point. Let's start again from the next round. This is what we are going to do. So now the encoders, like, remember, the encoders were somewhere here. Now the encodes are here. These are the leaders.
00:29:00.544 - 00:29:30.412, Speaker B: Now we are going to tweet these nodes as the encodes and we're going to run another bullshark instance again. In this example, we all deal this one because I want to show you the good path, right? We are going to order like an encoder in every round. But it could be this. And if it was this, then we would start the next instance from here. But in this example, we start the next instance from here. And this is how it goes. Cool.
00:29:30.412 - 00:29:58.788, Speaker B: So this is pipelining and what do we achieve is now that before we had an encore, like every second round. Now we have an encore every round. And it's a complete free optimization on top of bullshark. We didn't do anything. It's just a more clever rule of how to build the nodes. So now I think the shoal of bull sharks will make more sense. Now, why the name? Because what we have here is actually a shoal of bullshark swimming together.
00:29:58.788 - 00:30:31.552, Speaker B: Like, I didn't know the meaning of shoal, but I guess most of you know it's a group of fishes, all sharks, swimming together. And I like this illustration because it's like sharks running in a relay race, passing an anchor from each air for one to another. Right. So this is like, I think, a cute picture. Yes. A question on this pipelining of bullshark. So in the kind of first case, in the normal case, suppose bullshark was committing to anchor in round one and round three.
00:30:31.552 - 00:31:07.916, Speaker B: Can it happen when you pipeline it, you're not doing round one and round four instead, because you're doing the two four interpretation now. So it actually ends up being slower than normal bullshark. Standard bullshark, it was like one and three. But now when you'reinterpreting two, four, six, I say I can't commit to two, I have to commit to four. I think I understand your question. You say in the original let me know if this was the question. In the original bullshark, let's say we could commit this and then we could commit this, right? But now, with this new tricks, we commit this and then we cannot commit this and we will commit this.
00:31:07.916 - 00:31:43.712, Speaker B: This is your question? Yeah, it's possible. But if you think about it, what it actually mean? It means that the adversary is very powerful. You can play it in a way that is too powerful. If he can do that, it could also in the original bullshark, it will make sure you cannot commit this and continue not letting you commit. I can think of dark structures in which what you say happening. But whether this dark structure actually makes sense in the real world is it like something that the adversity can actually make happen? I'm not sure. Other than that it's just like a probabilistic argument.
00:31:43.712 - 00:32:09.164, Speaker B: It can go like go both ways. It's a good question. We thought about it and I hope I satisfying answer. Okay, pipelining not pipelining, leader reputation. So we're going to use the same trick completely. This is like another nice thing. The way we actually worked on it is that first I thought pipelining is impossible.
00:32:09.164 - 00:32:38.344, Speaker B: Then we thought about leader reputation, how to do it because practically we had to do it. Like we have really a practical system. This is actually very important for us today because we have leader reputation today. So we said we cannot deploy bullshark without leader reputation and doesn't make sense. So we came up with this solution and then we realized, oh, the same thing worked for pipelining. Whether like two weeks before we were trying to solve pipelining and decided it's impossible. So that kind of was a nice thought thinking, thought process for us.
00:32:38.344 - 00:33:04.880, Speaker B: Okay, so LiDAR reputation. Well, same. We have this mapping between leaders to round to leaders. We are running an instance of bullshark. We decide this is going to be the first encode holder. Again an agreement point between all validators. We're going to study the causal history of this validator, apply some heuristics to understand who are the strong validators, who are the less strong validators.
00:33:04.880 - 00:33:56.044, Speaker B: Simple heuristic you can think of is like how many nodes did you contribute or how many times in this causal history you're supposed to provide an encode but you couldn't some things like this. And then based on this information, we are going to deterministically assign new leaders going forward. So before we had some leaders and we went far into the future to determine that this is going to be the first ankle to all there. And then we are going to completely change but deterministically across everybody the mapping between leaders, rounds to leaders and we are going to try again now to interpret the dug with completely different ankles and it's completely safe. So I find it kind of cool. So we changed the mapping. We are going to run another bullshark instance.
00:33:56.044 - 00:34:15.540, Speaker B: Now this is if we did only leader reputation. But the nice thing is that we can combine it with pipelining together, right? We can do both. We order an end call, we reshuffle the lidos, the mapping of the Lidders and we actually start the next instance from round two instead of round three. And we get pipelining and lidder reputation with the same trick.
00:34:15.620 - 00:34:24.716, Speaker C: So can you tie these optimizations kind of back to the formal guarantees you might state for such a protocol? So like the pipelining, can you say the latency improves by a factor of.
00:34:24.738 - 00:34:58.296, Speaker B: Two like in all cases, no, the pipelining reduced. So it depends how much you pay for every broadcast. Here we do one and a half round trips, but you could also do it in one round trip if you had like more, but you pay more communication. So it depends on your implementation of the broadcast. But it saves you remember this? Yeah. What it gives you is exactly that here it's supposed to be four and now that's three. In every other round you switch the fall to three.
00:34:58.296 - 00:35:04.010, Speaker B: So the latency for this node stayed the same, but the latency of this node improves by 25%.
00:35:06.140 - 00:35:11.128, Speaker C: How would you phrase from the reputation that's going to give you an improvement.
00:35:11.224 - 00:35:36.852, Speaker B: Where the reputation gives you a very big improvement under faults. If they're actually faults, it gives you a very good improvement. And yeah, I'm actually going to talk about it right now because it gives you even more. I discussed now the algorithmic contribution of Shoal. Now I'm going to talk about the system optimization and the leader. Repetition played an important role here. I'm going to talk about it.
00:35:36.852 - 00:36:12.476, Speaker B: What we achieve here is that we completely eliminate not completely, let's say from every reasonable scenario, we eliminate the use of timeouts. And I think that's interesting because first timeouts are very painful. Like if any of you ever implemented a distributed system, you need to think about these timeouts too long, too short, like how you monitor them. It's really painful. And if you think about leader based consensus, the timeouts are inherent. Like you cannot get rid of timeouts if you have like a single point of failure. Yeah.
00:36:12.476 - 00:36:43.592, Speaker B: The reason you cannot get rid of timeouts is that at some point in the system you are going to wait for a message from the leader. And this is the only thing that's going to trigger you moving forward. You are just waiting for a message from the leader. If you don't have anything else that can trigger you do something and the leader is actually crashed, you are going to just stall forever. There is nothing else that can, let's say, okay, you know, let's try something else. Like you can just wait forever, right? And the timeout gives you that. Like if you time out the lidder, you see, oh, timeout, let's do something else.
00:36:43.592 - 00:37:33.480, Speaker B: Right? Without it you can't and the reason why it's so inherent in asynchronous and partial asynchronous that during asynchronous periods you have these validators they wait for the leader, so then they wait for some time, right. And they don't know whether the leader crashed or simple the weather. The leader is like super slow and like if they just wait another millisecond, they will receive the message and like there is just it's very it's an, it's an inherent problem possibility. It's impossible to distinguish. And this is like most of the difficulty in the synchronic system comes from this point, right. You cannot distinguish between crashed and slow party in the system. So that means that leader based protocol that works in partial synchrony must use timeouts.
00:37:33.480 - 00:38:24.840, Speaker B: Okay, and what's the problem with timeouts? So if you have them too short and the leader is actually good, but the Validators are just always impatient and move forward and time out the leader faster than the network delay, then we are going to keep timeouting in view change. The leader has never reached progress, right? So we cannot have too short timeouts. But on the other hand, if your timeouts are too conservative like you pick a long timeout and the leader actually crashed, you will need to pay this entire latency as a penalty before you can do anything else. And the typical timeout is like 1 second, one and a half second. I think today we use one and a half second in jolten before we will move to the and yeah, like think about it. Somebody crashed one and a half second system doesn't do anything. Anything.
00:38:24.840 - 00:38:52.928, Speaker B: Just stall, right. Really bad. Yes. Shoal in shoal we have a way to get rid of timeouts like almost completely. And what we are leveraging is two things. First is the DAC Construction and second is leader reputation. The cool thing about the DAC Construction is that it advances at network speed and completely asynchronously, right? So remember, I told you before, if we have a single point like a leader and we wait for a message, we just wait for the message.
00:38:52.928 - 00:39:33.052, Speaker B: There is nothing else that can trigger any other behavior. So the Dag is kind of give you this clock, this triggering. Like you keep advancing around and every time and you advance around completely asynchronously no timers, you don't need nothing. And this is my intuition, so I share it with you. And every time you advance around, that's an event that now you can rethink what you are doing, right? And this is something that wakes you up, right? And should I do anything else? And so the Dugs give you this kind of clock and we'll just keep building. The Dag regard is of this guy is being slow, this is actually crashed and the Dag is always network speed. We don't wait, we just build the Dag.
00:39:33.052 - 00:39:53.412, Speaker B: And if we can directly all the risk, we'll try this, we'll try this and we just never wait. Okay, so then let's analysis what is actually going on on the Dag Construction. So we have three cases. The first is a fast leader. As in this example. When I say fast, it's relative to the others. It doesn't mean that the network in synchronous anyway.
00:39:53.412 - 00:40:34.396, Speaker B: The network is completely asynchronous, but it's just faster than the other. Meaning that most of them is going to actually receive this node at the beginning and then they will point to it and they vote for it. Right? So if I'm a fast Validator, I will get enough support. It doesn't matter the system asynchronous synchronous, eventually, in network speed, I will get enough support and be directly committed. This is like, a very nice property of this dark construction. If you compare it to the Lidl based protocol, jolte and hot stuff and PBFT others, and you think about this optimistic, responsive property, they only guarantee it's not enough for the leader to be fast there. They need the system to be synchronous.
00:40:34.396 - 00:41:01.144, Speaker B: And the reason is that even if the leader is the fastest and everything is good, the leader still needs to collect votes, right? If the votes are not coming in the timely manner, everybody else will just view change, right? Timeout and view change. So this is a cool property. If we have a fast leader, we can provide network speed both during synchrony and during asynchrony. For a faulty leader, that's even better. This is perfect. We wait zero time. We just don't care.
00:41:01.144 - 00:41:28.912, Speaker B: We continue building the dag. Right? This is what we do. We just don't care if it actually fault. A faulty validator cost us zero in terms I mean, not really zero, because it's much better to have a good anchor here and commit it directly. But if you compare it to the one and a half second latency that you pay just by waiting before they continue the protocol, we have nothing of that. So we saved here one and a half second. If a leader is faulty, it's faulty.
00:41:28.912 - 00:41:55.756, Speaker B: I mean, what can you do, right? But at least we don't pay this one and a half seconds of waiting to agree on the fact that the leader is faulty. We just move forward. Okay, so this is also very good. Again, if you compare to optimistic, responsiveness, faulty leader sorry, one and a half seconds, that's where you have, like, a proof that they're faulty in some way. No, you don't need the proof, right? The Dag, you just keep building it in network speed isn't committed. Yeah. Eventually, as in this example, you will not order it.
00:41:55.756 - 00:42:17.588, Speaker B: So you do pay some latency penalty, but this is an algorithmic latency penalty, not no timeout. That actually stall your progress. Right? Okay. The only question that we need to ask, which is, like, questionable, is what about slow leaders? Slow leader is a good leader, but it's slower than others, so he doesn't get enough votes. Right. This wasn't fast. Everybody voted for him.
00:42:17.588 - 00:43:03.184, Speaker B: This guy is slow. So if we had a timeout, it could be actually good, because then maybe if this guy would just wait, like, five more milliseconds, he would receive this node, and we'll be able to vote for it, right? And then we'll be able to directly commit it, and there is no need to wait, like, another two more rounds on the dug in order to commit the next encore. So then slow leaders, it's, like, questionable. It's a trade off whether you wait or not wait. In case of slow leader here the leader reputation comes into play because what will happen is that if you are slow, then you will not be able to make sure that your ankles are committed. The little reputation mechanism will exclude you. This is how it works you aren't fast enough, the little reputation will exclude you.
00:43:03.184 - 00:43:55.136, Speaker B: So it will actually exclude only also the faulty nodes, which is also good, but even the slow nodes. So leader reputation will make sure over time that only the faster validators will contribute, will become leaders and cause and we will be able to alder one interesting question that you might ask, so I ask it for you what do we do with incentives? Right? Because we want to be fair, if the validator is slow, we don't want to punish him. Let's say our reward mechanism pay leaders as today. Today our reward mechanism pays leaders right here. Just because I slow and slow is not absolute slow relative to the other. So you're not going to pay my rewards. And the answer to this question will be is that with the Dag we don't need to reward based on the leaders.
00:43:55.136 - 00:44:36.252, Speaker B: There's no notion of real leaders when we build the Dag, it's enough just that you contributed a node and that's already good enough. But the exact revolt mechanism that we are going to use is still to be done. So actually, if any of you is like you're the expert here, if any of you is interesting to review it and to help us, we'll be happy. But this is like a flavor, I thought this is like a natural question and already I gave you some. What are we thinking? Yeah, this is just a summary. We defined property, we call it prevent responsiveness. We compare it to optimistic responsiveness.
00:44:36.252 - 00:46:02.700, Speaker B: So if you think about what I explained before, during synchrony at asynchrony fast and faulty leaders we get network speed, network speed, progress, where with optimistic responsiveness you only get network speed progress, fast leader and synchrony, right? Asynchronous no guarantee at all and faulty leader, even with synchrony you have to pay the timeout penalty in case of slow leader. In both cases for us, without the leader reputation, we need to pay like two round penalty because otherwise maybe we could have directly commit if we had timeout and now we need to wait to commit the next anchor. But here is the hope is that with leader reputation it will be very rare. So I have to say something about FLP here because this is a deterministic protocol and how come we don't use timeouts, right? Where is the FLP comes into play here? And of course it comes so in theory, under a very powerful adversary, which I will show here, we cannot avoid timeouts with a deterministic protocol because what can happen is that imagine an adversary that just controls all the network, right? Just none of the encoders will get enough votes. Like every time there is an encode, there is a leader or suddenly the adversary is so strong so it will eclipse and nobody votes, right? And doesn't matter. You have a little reputation that's very good in practice, but the adversary here is just all powerful, doesn't care, every time it's a different note. In theory this can happen.
00:46:02.700 - 00:46:54.300, Speaker B: Yes. And in order to fight this, to be on the safe side and to provide these guarantees that we like and provide liveness, what we will do is very simple. So in Shoal, what we do is after x, x is a parameter 510, 101,000, whatever your favorite number is well, validator will just fall back to use timeouts. And then of course we have the theoretical liveness in partial synchrony, right? But in practice, under all reasonable adversarial scenarios, they will never fall back to timeouts. You will alder much faster than this adversary will be able to tweak everything, especially with reader reputation. So I think this is very cool because we can actually run a partial synchronial system without we will have timeout somewhere in the background, but they will not impact anything. So here is the number, here are the numbers, the evaluation.
00:46:54.300 - 00:47:30.244, Speaker B: First we wanted to compare all these system improvements, the timeout stuff. So we have the baselike bullshark is no timeouts. Vanilla bullshark has two timeouts actually one timeout on the leader round and another timeout on the vote round. The reason we had to have a timeout on the vote round is because the full bullshark protocol, the quorums, there were two f plus one because we had to support the fallback. I didn't talk about it at all, but just for the recording if somebody asks this question. And so we had to have two timeouts there. But for the partial synchronous version we don't need this timeout.
00:47:30.244 - 00:48:20.484, Speaker B: So this is why we have the green line, just the timer for the leader in the vote round, not for the other round. Sorry, in the anchor round, not for the other round. And these are the results. Obviously, when we have failures, baseline bush without timeout is much better because we don't pay this long penalty every time where we failure. And when we check the no failure case yeah, this is latency, this is the number of validators, this is number of failures. Sorry, I had to say it before, but in the non failure case you see that vanilla bullshock is worse, but the green and the pink actually there's a trade off. This is the thing about slow nodes, slow leaders.
00:48:20.484 - 00:49:03.460, Speaker B: Sometimes it's good to have a timeout just to wait for them a little bit and we can commit them. So it's not a clear without leader reputation, there is no clear win here like what is better. But for our next graphs we are going to consider baseline bullshark, the pink one and compare everything against a bullshark without timeouts because we want to evaluate the algorithmic results. And also because the pink is not strictly better, but better, right? Strictly better here and the same here. So we can use the pink. Okay, so this is throughput and latency graphs. So this is joltian and this is the different versions of shoal baseline bullshark.
00:49:03.460 - 00:49:25.900, Speaker B: The green is like the full shoal. Blue is just little reputation and the pink is just pipelining. And you see that throughput. We achieve like around 120 transaction per thousand transaction per second. We didn't try to optimize this too much. This result is about latency. I guess we can push it like if we did some system optimization, we can push it further.
00:49:25.900 - 00:49:50.404, Speaker B: But interesting is just jolten. This is jolten, not the vanilla jolten. This is jolten. When we decouple data dissemination from consensus, we get like around 55. And for latency, you see this baseline bullshark is the pink. And then both the leader reputation and the pipeline, they both contribute to latency together. Shoal, the green one is actually better than everything.
00:49:50.404 - 00:50:27.200, Speaker B: It means that they separately contribute and there together is even better. And if you compare to jolten here so you see, we started from vanilla bullshark, we started even higher because we had timeouts. But this is like no timeouts vanilla bullshark and we are almost like close the gap, which was the goal of this work, to close the gap with joltein. The thing that we are very nice here in this graph to jolten, the thing that we don't measure is that when we decouple data dissemination from the transaction ordering, there is some more latency to connect these two components. And we gave this latency for free to jolten. So we don't measure it for sure. We don't need this latency.
00:50:27.200 - 00:51:15.724, Speaker B: So the gap is probably even less if there is any gap. Okay, so this was throughput and latency in the failure free case and now the last graph is latency in the failure case. Oh, sorry. Yeah. So what kind of a validator are we asking here? Is this a commodity laptop? What is the validator? Oh, these are very strong AWS machines. Gale replicated strong AWS machine, three different regions. I don't remember the specification by heart, but I can check, so and also it's just the consensus.
00:51:15.724 - 00:51:50.350, Speaker B: All this graph is just consensus. There is no execution here, right? This is just consensus. Just to be clear. Okay, so this is the latency in the failure case and no Jolteon in this graph because when there are failures, nothing was reliable there because we actually wanted to try it with a lot of failures. So Jolteon was completely useless. And you can see that obviously shoal with leader reputation is much better. It's kind of, kind of obvious because it excludes the faulty leaders and runs without them.
00:51:50.350 - 00:52:20.390, Speaker B: Okay, so bottom line for the numbers, for sure. So throughput 120K on our consensus only aptos implementation. Yeah, and I said we could push this number higher. It wasn't the focus. But compared to Joltin, on top of Nalwell, we get two X improvement latency. Again consensus only we get subsecond latency. Compared to vanilla bullshark, it's a 40% improvement without failures and with failures up to 80%.
00:52:20.390 - 00:53:12.356, Speaker B: And then compared to Jolting, when we have high load we get much better latency. And this is because when we have high load we cannot support the throughput and then the throughput start impact latency. Right? So obviously if you have high load, the more throughput you can support your latency is lower, otherwise you just need to wait a long time before you even can enter into the system. Right, and comparable under low load. And yeah, this is just the slide I like to show and papers are online and I like to say good stuff about decentralized foe, the Ties blog and yeah, we also have a blog there about BFT and you can go there to the high level. And for the recording, this is my email and if any questions, anything, just reach out.
00:53:12.538 - 00:53:15.844, Speaker C: So what's deployed like right now? What's like running on mainnet right now?
00:53:15.882 - 00:54:18.992, Speaker B: Yeah, so what's running right now on mainnet? For the consensus, we still run Joltin and we have our own implementation of Novel, which we call Quorum Store. And the way it works, quorum Store is a very simple component. I mean nothing is simple when you actually build it, but conceptually it's simple. It's the data you disseminate, each validator in parallel, disseminate the data and get enough signatures back in return hold the proof of availability. Each signature promises that if I sign to you, I promise you I'm going to hold this data, persist this data in my local database storage until the expiration time and then the validator takes this proof, push it to consensus. Here is this extra latency I was talking about and then Joltin will deal these proofs and then before execution we are going to look at this proof one by one. Hopefully we will have all the data locally because in the dude case we disseminate the data to everybody we should have it, otherwise we look at the proof, we look who signed it and we will go fetch it and then execute.
00:54:18.992 - 00:54:42.870, Speaker B: And this is what we currently have as the plan is to we're in the final processes of implementing Shoal. But the way it works you have to implement, then you have to test it, then you have to test it again, then you have to test it again, then to deploy, then you have to test it again. So it will take some time before we can actually launch it on Mainet. But we are on track. Yeah, hopefully sooner than later. Thanks.

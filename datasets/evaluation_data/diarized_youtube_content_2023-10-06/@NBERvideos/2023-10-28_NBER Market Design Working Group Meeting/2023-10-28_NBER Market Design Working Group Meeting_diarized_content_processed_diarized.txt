00:00:00.570 - 00:00:01.680, Speaker A: Event for today.
00:00:02.610 - 00:00:12.334, Speaker B: First, the meeting is being live streamed, so if you're a presenter, please make sure that, as the screen says here, please make sure that you're sharing your.
00:00:12.372 - 00:00:14.526, Speaker C: Screen so that people on YouTube can.
00:00:14.548 - 00:00:18.206, Speaker B: See what you're talking about. If you are asking a question, if.
00:00:18.228 - 00:00:19.774, Speaker A: You could try your best to ask.
00:00:19.812 - 00:00:55.166, Speaker B: The question into the microphone so that folks who are watching the stream can hear the question, that would be great. And just to be sure that that's going to occur, we're asking all the presenters to repeat the question before they answer it. So that's one point. Second point is the NVR has a code of conduct. So you all hopefully have seen that on the NVR's website when you registered rather than read it again to you guys, please take a look at the code of conduct. We want to have a constructive and welcoming environment here and the last thing.
00:00:55.188 - 00:00:56.974, Speaker C: That we like to do at this.
00:00:57.012 - 00:00:59.406, Speaker B: Conference is make sure everyone knows each.
00:00:59.428 - 00:01:00.634, Speaker C: Other and feels comfortable.
00:01:00.762 - 00:01:02.174, Speaker B: So what I'd like to do is.
00:01:02.212 - 00:01:05.518, Speaker C: Just go around the room and if you could just say your name and.
00:01:05.604 - 00:01:07.280, Speaker D: What university you're from.
00:01:08.130 - 00:02:53.120, Speaker B: Nikhil. You want to kick it off? I'll skip the mic. Nikhil Agarwala. And yeah, you can get Loving You're involved like a seven, eight.
00:03:10.110 - 00:03:11.180, Speaker C: Okay, great.
00:03:11.630 - 00:03:31.360, Speaker B: I think we've had everyone say hello. So Boback, you want to start us off today? Just a reminder, every presentation is allotted a total time of 45 minutes. Okay? So there'll be some time indicators and we want to encourage some active participation as well. So please do interrupt and ask your questions.
00:03:33.730 - 00:04:12.590, Speaker E: Okay, well, thanks so much. I'm really grateful to be here. Thank you to three of our four organizers, I guess, who are here, and Dirk wishing him the best. This is equal pay for similar work with Diego at Amazon Pharmacy and Fuhita Kojima, who many of you may know who's at Tokyo. So since I'm first I thought I'd start off with a bit of an icebreaker. One of the earliest memories I have was going to daycare my dad would drop me off and he would sometimes tell the other kids in the daycare that I was Robin. Robin is Bobby's twin brother.
00:04:12.590 - 00:04:38.440, Speaker E: The issue is I don't have a twin brother. I don't have a brother at all. And this is 30 years ago and still I'm talking about it. I also haven't told him this, but this is great that this is live stream, so maybe he'll find out now. Okay, this will become relevant in a couple of slides, hopefully. Okay, so this is probably the least surprising slide that you'll see today. There are differences in wages paid to men and women.
00:04:38.440 - 00:05:24.210, Speaker E: I'm going to say nothing about the causes of this except to say that, well, firms play a role, right? So firms have some wage setting power and the relative wages that firms pay to different people may violate certain societal fairness schools. And the way that we might see this is, well, people really don't like this wage gap. And the ideal policy that many people have campaigned for is this notion of equal pay for equal work. This is a nice slogan. It's actually directly codified into laws this phrase, equal pay for equal work. So I want to interrogate this phrase for a second equal pay for equal work. So supposing we have two workers, Bobby and Robin.
00:05:24.210 - 00:06:30.890, Speaker E: I know what the first equal means, right? I take their salaries, I subtract the two, and I look to see if there's a zero or not. I'm less sure what the second equal means. Are Bobby and Robin really equal? Does the mustache make them unequal in general, equality seems like a non generic concept. You might wonder, besides just a kind of mathematical notion or topological notion, could a firm, slightly heterogeneized workers and say, well, we don't like paying people with mustaches quite as much. Let's just promote this person to be a slightly different job title? And indeed, this is exactly what happened with the equal pay laws that were passed in the US. In the 60s, where there was job title proliferation, right? Jobs were slightly heterogeneized, so male secretaries got promoted to be executive assistants. And this is actually very blatant in a sense that there were news articles at a time where people were explicitly saying, great, I don't like paying women as much.
00:06:30.890 - 00:06:31.930, Speaker E: You can't make me.
00:06:32.000 - 00:06:32.620, Speaker B: Right.
00:06:33.390 - 00:07:13.862, Speaker E: So this is actually a big problem and more than just a problem that we might think of as a theoretical problem, but it actually caused a new state of laws called equal pay for similar work. And here's an example of such a law. No employee of group G shall be paid a wage less than an employee group G prime, where G prime is not equal to G for similar work. So I've highlighted two things. So the first is we have this notion of groups, and I'll come back to this we also have this word similar. Now, I want to do two things. One, to convince you that, okay, similar and equal are actually meant to be different.
00:07:13.862 - 00:07:42.554, Speaker E: And second, that we should actually care about this distinction from a policy perspective. So I'll try to do both of those things on this slide. Almost all the states in the US. Have an equal pay law of some sort. Up until 2016, all of these were equal pay for equal work laws. In 2016, California updated its law from equal pay for equal work to equal pay for similar work. And the claim was it makes it harder for firms to justify paying different wages to employees.
00:07:42.602 - 00:07:42.814, Speaker B: Exactly.
00:07:42.852 - 00:08:06.658, Speaker E: This notion of you can't just slightly heterogeneize the work and get away with paying different wages. I'm at brown. Rhode island rarely is pivotal for anything, but January 1 of this year, rhode island also switched from equal pay to equal work to equal pay for similar work. And several other states had changed in the interim. And with that change, more workers in the US are now covered under equal pay for similar work laws than equal.
00:08:06.674 - 00:08:07.558, Speaker B: Pay for equal work.
00:08:07.644 - 00:08:47.190, Speaker E: So there was this massive proliferation exactly, aimed at making it harder for workers to pay different wages for different work. So this is really a tale of two stories, right? There are the intended or direct effects of the law, and then what we're going to study are the equilibrium effects. So let's suppose Robin and Bobby are working at the same firm. They're judged to be similar, and we don't have an equal pay for similar work law. Robin is paid more than Bobby. There are plenty of reasons why that might be. Robin might be more productive or there might be discrimination against Bobby.
00:08:47.190 - 00:08:58.118, Speaker E: Once this equal pay for similar work law comes into being, assuming that both of them continue to be hired, and assuming that Robin's pay doesn't fall, what happens?
00:08:58.284 - 00:08:59.800, Speaker B: Bobby's pay goes up.
00:09:00.810 - 00:09:39.910, Speaker E: And we can do this comparison between all pairs of similar workers. And what do we see? We see that wages increase. Everyone but the highest paid person's wage strictly increases and the wage gap closes to zero, at least within these similar jobs. Sounds great. But of course, this leads to the main inquiry and the equilibrium effects. Will Robin still be hired? Will his wage fall? And just to fix ideas a little bit, let me ask a bit of a leading question. Suppose a firm has ten workers of Group G and one worker of Group G Prime, and they all get different wages.
00:09:39.910 - 00:09:48.654, Speaker E: What would we expect this firm to do to comply with the law? What if they had 100 workers of Group G and one of G prime?
00:09:48.722 - 00:09:49.242, Speaker B: Right.
00:09:49.376 - 00:10:09.600, Speaker E: At some point it may seem that, well, we might expect this from to fire that last worker. And that potentially changes everything I said here. So let me jump into the results a little bit, give a preview, and really this is going to be yes.
00:10:12.850 - 00:10:24.354, Speaker B: As far as enforcement goes, how is our courts or other institutions interpreting the difference between equal and similar in the real world? That's a great question.
00:10:24.392 - 00:10:58.720, Speaker E: So the question just to repeat was how are courts interpreting the difference between equal and similar? I can give you an example that has to do with our line of work, academics. So the 9th Circuit has ruled that I want to be careful here, that the right comparison for similar for academics is department and rank. So all associate professors in economics at your or university presumably should be paid the same according to these laws, which is certainly not equal in terms of work.
00:11:05.760 - 00:11:06.556, Speaker B: Anyway.
00:11:06.738 - 00:11:25.276, Speaker E: Okay, so this is really a story of going from a Bertrand Price competition market to a hoteling one. Okay, so I've drawn a picture here where this horizontal line is meant to be the boardwalk where the stores can locate their ice cream stands.
00:11:25.308 - 00:11:25.792, Speaker B: Right.
00:11:25.926 - 00:12:00.152, Speaker E: And without this equal pay for similar work law, we're going to have high competition for the workers. Right. The firms are going to compete for each worker. Now, there may be a wage gap due to productivity differences or due to bias or discrimination, and that's all going to be incorporated into the model. So it may not be that the world before is great, but in some sense, I'm going to try to convince you that the world after is worse. So what happens when we have this group based equal pay for similar work? You can't pay a worker from group G less than another one from G Prime.
00:12:00.216 - 00:12:00.830, Speaker B: Okay?
00:12:01.840 - 00:12:11.704, Speaker E: Firms are going to segregate their workforce in equilibrium, and I've demonstrated this on the picture by putting the two firms at the opposite ends of the hoteling boardwalk.
00:12:11.752 - 00:12:11.964, Speaker B: Okay?
00:12:12.002 - 00:12:23.430, Speaker E: They're going to gain local market power. One firm is going to hire all the men. Sorry, I'm jumping ahead. So one firm will hire the workers from one group, one firm from the other group, and.
00:12:26.120 - 00:12:26.996, Speaker B: That tells us what.
00:12:27.018 - 00:13:22.340, Speaker E: Happens to market power, not so much about what happens to relative wages. Our finding is that the majority group of workers, regardless of notions of discrimination, but the group in the majority, is going to be relatively benefited. So if there is a wage gap before men are paid more than women, possibly due to discrimination, you pass this law, but there are more men, the wage gap is going to increase. And I'll talk today primarily about the model, but we also have an empirical analysis, and this is basically what I just wrote on the previous slide, but in words instead of pictures. I just want to highlight one thing, which is we do have some empirical work. And at this point, I actually started to believe our conclusions once we saw that they seemed to have some evidence. So we look at Chile in 2009, which passed Epsw.
00:13:22.340 - 00:14:05.488, Speaker E: The share of gender segregated firms rose. So this was a law specifically targeting, you can't pay a man less than a woman, a woman less than a man. The share of firms that had only workers of one gender rose, and the wage gap increased. In local labor markets, where there are more men than women, which happened to be something like 85% of the labor markets, but it actually decreased in the female dominated one. So exactly. This notion of the majority group is relatively better. Okay, so I will go first to the model, talk briefly about some evidence, and then I will try to do some market design and suggest a change to the policy that might help fix these unintended effects.
00:14:05.488 - 00:14:07.590, Speaker E: Are there any questions before I jump in?
00:14:09.560 - 00:14:13.764, Speaker B: Okay, so for today's talk, I'm going.
00:14:13.802 - 00:14:47.810, Speaker E: To assume there are two firms and two groups of workers. We'll call them a and B. In our empirical setting, this will be men and women, okay? The two firms will be homogeneous. And we can think of these as just firms in a local labor market. And we'll have a continuum of workers, all of whom who are exogenously deemed to be similar. So we can think of this as kind of a within broad speaking job labor market. Now if we have a different job, we can analyze that as a separate labor market.
00:14:47.810 - 00:15:15.996, Speaker E: Each worker is going to have a type V and G, where V is the worker's productivity. This will just be a number between zero and one. And G will be a group identity. They in group A or group B. Now I mentioned earlier that the majority group is going to be relatively benefited. So we have to have some notion of majority, and the A group will be the majority group, right? There will be an alpha weekly bigger than one measure of the A group and one measure of the B group.
00:15:16.098 - 00:15:16.750, Speaker B: Okay?
00:15:18.640 - 00:15:38.400, Speaker E: Productivities for the two groups are going to be distributed according to these distributions, FA and FB. We're going to be pretty agnostic about these. Just some regularity conditions, full support, unbounded support. And types are going to be common knowledge. There's not going to be any informational, nothing interesting informationally is going to be going on.
00:15:38.470 - 00:15:38.848, Speaker B: Okay?
00:15:38.934 - 00:15:42.420, Speaker E: So I've put productivity in quotation marks throughout this slide.
00:15:43.640 - 00:15:48.388, Speaker B: And so I want to come back to that, which is I'm going to.
00:15:48.394 - 00:15:54.820, Speaker E: Be agnostic about what productivity means and I'm going to be agnostic about the forces that lead to different productivity.
00:15:54.900 - 00:15:55.528, Speaker B: Okay?
00:15:55.694 - 00:16:39.696, Speaker E: So here I've drawn the potential productivity distribution for the A group. It could be that productivity exactly means output, right? That's what I mean. And it could be that the two groups have the same distribution. So this is the A and the B group are equally productive. They generate the same output. Now it could be that there's actually discrimination and it could be that what I call productivity is something like output net of discrimination, right? So in this picture, maybe there's taste based discrimination by the difference between these two peaks and that just shifts the distribution of the B group downward. It could also be that they're just arbitrarily different productivity distributions.
00:16:39.696 - 00:16:56.700, Speaker E: Maybe one group is more productive or has more output than the other. None of my results are going to depend on these productivity distributions. I'm going to be exactly agnostic, completely agnostic. Excuse me. I think in a couple of slides you'll see why we don't care about this in our analysis.
00:17:01.520 - 00:17:01.884, Speaker B: Okay?
00:17:01.922 - 00:17:23.108, Speaker E: So this is the most notationally heavy slide. And so I want to specify an outcome of this game and then I'll talk to you about the timing and the payoffs. So an outcome is going to be a pair F and W. F says who goes where and W says who's paid what.
00:17:23.194 - 00:17:23.684, Speaker B: Okay?
00:17:23.802 - 00:17:48.624, Speaker E: So this Fgiv is the density of VG type workers hired by firm I. And this is just subject to an adding up condition. We can't hire more workers of any particular type than exist in the market. So the two firms together can't hire more than the total supply of workers. Wigv is the wage that firm I pays to VG workers.
00:17:48.692 - 00:17:49.470, Speaker B: All right?
00:17:50.240 - 00:18:18.390, Speaker E: And we're going to make one additional restriction on this, which is a monotonicity condition, which is if you and I are of the same group but you are more productive and we're hired by the same firm, you can't be paid strictly less than me. And actually I was reading Typhoon's 2013 paper about this military matching, and we may have reasons to worry about people hitting themselves in the head with a baseball bat if they could be more productive, if they could be paid more for being less productive. So this is exactly what we're trying to guard against.
00:18:20.200 - 00:18:20.996, Speaker B: Very good.
00:18:21.098 - 00:18:51.680, Speaker E: Okay, so what are the payoffs? The payoffs are really just for the firm. It's a constant returns to supply production function. So the firm will receive wage V minus W for each worker it hires. Okay, so we separated this up, one for each group. For the B group, we take each infinitesimal profit, integrate up. Same with the A's. But we have the alpha here because there are more A's than B's.
00:18:51.680 - 00:18:58.796, Speaker E: And a worker is going to receive payoff equal to the wage that she receives. And if she's unemployed, she just receives.
00:18:58.828 - 00:18:59.760, Speaker B: A wage of zero.
00:18:59.910 - 00:19:00.864, Speaker E: That's her outside option.
00:19:00.902 - 00:19:05.280, Speaker B: We're normalizing. Okay.
00:19:06.150 - 00:19:26.906, Speaker E: And so we're going to basically take the timing of Bertrand's Classic game. So each firm is going to simultaneously make wage offers. Now of course these can be different for different types of workers. So it selects the workers that it wants and makes whatever wage offers they want. These are done simultaneously. Each worker is going to collect whatever wage offers she receives and selects at.
00:19:26.928 - 00:19:27.980, Speaker B: Most one of them.
00:19:30.790 - 00:19:54.954, Speaker E: And we'll look for pure strategy, subgame perfect equilibrium in this game. I want to make an aside briefly. So just like in Bertrand's game, the equilibrium will involve Shill bidding, right? So both firms set a wage equal to marginal cost, but the consumer buys from only one of them. The reason that the firm that buys from sets of wage equal price equal to marginal cost is because the other one does as well.
00:19:54.992 - 00:19:55.194, Speaker B: Right?
00:19:55.232 - 00:20:20.638, Speaker E: We're going to have that notion here. We also have here in a lengthy appendix, that the set of subgame perfect Nash equilibrium for this game is equivalent to the set of core allocations in a cooperative version of this game. And so for these two reasons, I'm just going to describe the outcomes today. I'm not going to talk about strategies. It's going to be exactly pinned down by the shill bidding. And in some sense the timing is not going to be super relevant.
00:20:20.734 - 00:20:23.026, Speaker B: Okay? All right?
00:20:23.048 - 00:20:51.462, Speaker E: So let me talk about the world with and without equal pay for similar work. Without equal pay for similar work. Every worker is hired by one of the firms, we don't know which, and receives a wage equal to her productivity. Now, I've included almost in parentheses here we have a continuum of workers. Everything is going to be subject to deviations by zero measure sets, and I'll soon lose this almost everywhere.
00:20:51.526 - 00:20:52.140, Speaker B: Okay?
00:20:52.830 - 00:21:24.662, Speaker E: So let me just draw a picture because this will be useful later. So suppose we have here I've drawn the productivity space zero one and the wage space zero one. Here the 45 degree line. Suppose we have a worker whose productivity is ve. This worker will receive a wage equal to a productivity, and indeed everyone will, right? So this is how we'll represent the wage function. Now we know everyone's hired, we don't know by which firm. So it might be that one firm hires everyone.
00:21:24.662 - 00:22:04.820, Speaker E: It might be that the firm split the workers in some way. There are many equilibrium, but they all feature this form of wage. And the intuition for this is very similar to Bertrand's original model. So if there's a worker who's not paid per marginal productivity, then, well, the other firm could just deviate and pay a penny more and steal that work. Now this doesn't really hold directly in our setting because we have this wage monetary constraint. We can't just locally raise the wages of some workers because that might affect the way that we're paying workers who are more productive. I don't know if this is of independent interest or not.
00:22:04.820 - 00:22:45.226, Speaker E: Our proof says that Bertrand logic basically goes through with this additional restriction. So it may be that with these downward incentive constraints, bertrand pricing in more general settings also holds. But I won't go into that. The proof is by masochism. Okay, so the first thought is, all right, everyone receives a wage equal to their productivity. Great, why do we need anything? And the reason is exactly this agnosticism about what productivity means. Okay, so recall I'm allowing productivity to include discrimination, right? Or maybe we just don't like pay differences.
00:22:45.226 - 00:22:59.650, Speaker E: Even if workers are differently productive. Anyway, the average pay of any group is just going to be because everyone's hired and because everyone receives pay equal to their productivity is just going to be the average productivity of each group.
00:22:59.720 - 00:22:59.954, Speaker B: Okay?
00:22:59.992 - 00:23:32.320, Speaker E: And so the wage gap, what I'll call the wage gap is just the average difference. The difference in pay between the two groups is going to be this eav minus EBV. This can be positive, it can be negative, it can be zero. I'm going to take this as a benchmark. So this term is going to be important for us. Now, again, in the picture I drew earlier, if there's taste based discrimination by some lowercase B amount against the B group, then this wage gap and workers are otherwise equally. They have the same output, the distributions anyway, then the wage gap would be exactly B.
00:23:36.450 - 00:23:37.440, Speaker B: Very good.
00:23:38.050 - 00:23:43.230, Speaker E: So what happens once we impose equal pay for similar work? And just to remind ourselves.
00:23:45.090 - 00:23:45.626, Speaker B: The type.
00:23:45.668 - 00:24:05.030, Speaker E: Of equal pay for similar work law that we're studying and I think is the most common, is this group based equal pay for similar work. You can't pay a worker from group A less than A worker from group B, and vice versa. So what does this mean? Well, suppose you hire workers from both groups.
00:24:05.450 - 00:24:07.478, Speaker B: Transitivity applies, right?
00:24:07.564 - 00:24:31.372, Speaker E: Take your highest paid A group worker. No B group worker can make less than that. Take your highest paid B group worker. No, A group worker can be paid less than that. Everyone has to be paid the same amount. However, the law explicitly has no bite if you only have workers from one group. So here are two preliminary results.
00:24:31.372 - 00:25:14.060, Speaker E: We have many equilibria with this equal pay for similar work. And generically, all of these equilibria feature segregation. So one firm will hire all the A group workers and the other firm will hire all the B group workers. And there's no unemployment, so everyone is hired again. And the proof is really we can think of it as a kind of if we want to go back to the hoteling example, kind of discretized version of the hoteling example. Well, what if both firms specialize in hiring from the A group? Well, we show that they bertrand compete away profits and there's this whole rich market of B group workers that someone could wade into. So they can't similarly, they can't just both specialize in hiring B group workers.
00:25:14.060 - 00:25:56.110, Speaker E: What if they're both generalists and they hire from both? We show generically that one of them would have deviation to specializing in one group. And then what if one group specializes in one and the other one's a generalist? Well, the one that's specializing in that group can outcompete the other one because they don't face additional wage constraints. I won't go through this proof here unless anyone's interested. So I don't know if segregation is a good thing or a bad thing. I would say probably a bad thing, but I don't think this was exactly what the law was meant to try to fix or change. Instead, it's about wages. So let me jump into talking to that.
00:25:56.110 - 00:26:38.830, Speaker E: And here is the main result. Take alpha to be strictly bigger than one. So there are strictly more A group workers than B group workers. The wage gap under equal pay for similar work is larger than that without equal pay for similar work in any equilibrium with positive profit. And this equilibrium with positive profit, this is all but one, right? So I said there are continuum of equilibrium. There's one that has zero profit and that's going to lead to exactly the same wage gap. So in almost all equilibria, we're going to do strictly worse in terms of the wage gap if you wanted to have B group workers paid more than A group.
00:26:38.830 - 00:27:46.320, Speaker E: So I want to characterize equilibrium a little bit to give you a flavor of the proof. And the following three conditions are equivalent to an outcome being an equilibrium, right? So I'm assuming without loss that firm one is the one that hires the A group workers, and firm two is the one that hires the B group workers. The first condition is an individual rationality condition. No workers should be paid more than their productivity because otherwise the firm would just want to fire that worker. The second is an equal profit condition and this is also kind of like Hotelling's notion of well, the firm should make equal profits, otherwise one firm could just locate just to the inside of the other one and steal the lunch. Okay? In this setting, if the firm that's hiring all the A group workers is making higher profit than the firm hiring all the B group workers, that firm could just pay one cent more to all the B group workers, sorry, to all the A group workers and specialize in those workers instead. And notice that just bumping the wages up by one penny doesn't interfere with any of our monotonicity constraints.
00:27:46.320 - 00:27:52.688, Speaker E: And the last condition is really the novel one that we think is interesting and has some economic content.
00:27:52.854 - 00:27:53.984, Speaker B: Let me tell you what it is.
00:27:54.022 - 00:28:43.216, Speaker E: But in your mind, think of it as an incentive compatibility condition. So we have infinitely many of these conditions that all have to be satisfied. So first, let this wi inverse, epsilon, be the highest productivity worker hired by firm I who is paid less than epsilon. So it's not exactly an inverse, because we can have flat regions. But think of it as a generalized inverse. The following no desegregation condition has to be satisfied for every value of epsilon between zero and one, the profit that firm two receives, which is again the same as the profit that firm one receives, has to be bigger than this sum. And I'll show you what this is.
00:28:43.238 - 00:28:44.470, Speaker B: In a picture in a second.
00:28:46.120 - 00:29:11.096, Speaker E: So let me give you a graphical demonstration of the condition. So suppose these are the wage functions that I want to check to see if they are constituted equilibrium. Firm one pays this red function to the A group workers and B pays the blue function to the B group workers. Well, right away we can see that individual rationality is satisfied because both of these curves fall below the 45 degree.
00:29:11.128 - 00:29:11.980, Speaker B: Line at every point.
00:29:12.050 - 00:29:15.068, Speaker E: That's great, the equal profit condition, what.
00:29:15.074 - 00:29:17.708, Speaker B: Do we have to check? Well, we have to check that this.
00:29:17.794 - 00:30:03.496, Speaker E: Shaded area, which is just the average productivity of the B group minus the average wage paid to the B group, is equal to the same thing, just weighted by alpha, because there are more A group workers in B, right? So the blue area has to be equal to the shaded red area. And then there's these kind of a little bit notationally heavy notice segregation condition. What does this look like? Remember there was one for every epsilon, so I've picked one here. What does this say? Well, it says the profit of firm two has to be bigger than suppose you set a common wage equal to epsilon and you tried to hire everyone you could at that wage.
00:30:03.608 - 00:30:04.472, Speaker B: Who do you hire?
00:30:04.536 - 00:30:14.672, Speaker E: Well, you don't want to hire anyone below epsilon itself. These workers are less productive than the wage you're paying.
00:30:14.726 - 00:30:16.050, Speaker B: You wouldn't want to hire them.
00:30:19.140 - 00:30:42.724, Speaker E: You can't poach any of the A group workers who are paid more than W, one inverse of epsilon because they're already making a higher wage. Their wage offer that they're receiving is already higher. So the workers below this value, you don't want the workers above this value are unavailable to you. And so we get one of these triangles here for the A group workers and we get another triangle for the B group workers.
00:30:42.772 - 00:30:43.416, Speaker B: Similar.
00:30:43.598 - 00:30:50.216, Speaker E: And that's exactly what this condition is. This is the triangle for the B group workers and this is the triangle.
00:30:50.248 - 00:30:51.148, Speaker B: For the A group.
00:30:51.314 - 00:31:05.250, Speaker E: And that has to be less than the profit that the firm is receiving in the candidate equilibrium. Otherwise, well, that firm has a deviation to just paying a common wage and hiring all the workers it can.
00:31:05.780 - 00:31:33.080, Speaker B: Okay, yes, in my head I was trying to work out where each firm sets a wage but then has differential minimum standards for whether, okay, you have to be at least VA or BB in order to get job offer in the posted wage model. Doesn't seem like is that the strategy that's allowed?
00:31:35.340 - 00:32:04.804, Speaker E: So that's a great question. The question was the firm seem, if I can reinterpret the firm seem to be offering different wages to different workers. Now that seems different from a posted wage model where presumably there's a posted wage and then the workers apply and then they can be rejected. Yeah, so that's exactly I agree with you 100%. This is a different model. The law does not require that the wages offered have to be the same.
00:32:04.922 - 00:32:05.204, Speaker B: Right?
00:32:05.242 - 00:32:51.712, Speaker E: Just that the wages paid have to be the same. And I know there are a couple of labor economists in the room. My sense is that a minority of jobs have explicit wages posted and the most recent laws trying to encourage that for similar reasons all require the posting of a range. And so that could still be consistent. Here you say, I'm going to post a range of between zero and one and apply to my job, and then we'll see what your wages and here the wages will exactly be tailored to individual workers. So again, this could be me down here and this could be you up here. And I don't think we want to restrict firms to having to offer.
00:32:51.712 - 00:33:25.372, Speaker E: Both of us the same wage. I would love it. Okay, so what I said was the wage gap increases. So let me get back to the proof. Now that we've given this characterization of equilibrium, well, what does the equal profit condition buy us? The equal profit condition buys us that. Well, if the profits are the same, and we said the profit is just the average productivity, since all the workers are hired minus the average wage to that group. So EBV minus AWB has to be equal to the same thing for the A group.
00:33:25.372 - 00:33:28.444, Speaker E: But there's an alpha term here because there are more A group workers again.
00:33:28.482 - 00:33:29.740, Speaker B: Than B group workers.
00:33:30.880 - 00:34:15.756, Speaker E: Now, by individual rationality, no worker is paid more than they're worth. So these terms are going to be both of these terms are going to be weekly positive. And if alpha is bigger than one, just manipulating these tells us that Awa minus AWB is going to be weekly bigger than the difference in expected productivity between the groups. Now, what is this here? This is just the wage gap under equal pay for similar work. It's a difference in the average pay. And what is this one? This is exactly the wage gap without equal pay for similar work, right? This can be positive or negative, but the gap will be larger. And by larger, I mean more in favor of the A group.
00:34:15.756 - 00:35:04.380, Speaker E: Now, we have a weak inequality here. This inequality will be strict if the profits are positive. If this, which equals this is strictly positive, which happens in all but one equilibrium, we can kind of reconstruct the Bertrand style equilibrium where everyone gets their pay, quote their productivity with equal pay for similar work. Just one firm hires all the A group, and one firm hires all the B group in every other equilibrium. This will be strictly positive. And if we're worried about well, we have a bunch of equilibria even if we have infinitely many of one type that are bad and one that kind of doesn't matter if we're thinking about selection. What this tells us, actually for free from the same set of inequalities is that one equilibrium has a larger wage gap than another if and only if firm profit is higher than the other.
00:35:04.450 - 00:35:04.684, Speaker B: Right?
00:35:04.722 - 00:35:15.120, Speaker E: So if we think that the firms have some capability of selecting one equilibrium over the other, they're going to favor a bigger wage gap. But I have nothing else to say about selection.
00:35:16.020 - 00:35:16.770, Speaker B: Okay.
00:35:19.940 - 00:35:21.856, Speaker E: Maybe I can pause here for a question.
00:35:21.958 - 00:35:55.868, Speaker B: Yeah, please. Oh, sorry. I'm trying to get my head around necessarily at the outset, but how the equal pay for similar work analysts work in practice. Your point is that what equilibrium would look like without the law. Increasing amounts for increasing productivity, right? Genuine productivity discrimination. And then you impose a law that says you have to pay everybody exactly.
00:35:55.954 - 00:35:58.940, Speaker E: The same, just only across group.
00:35:59.010 - 00:36:42.668, Speaker B: If you hire both as and for example, both benefit, then either you have to effectively document that there's heterogeneity productivity or you have to pay everybody the same. It's not or you have to go into this funky equilibrium. Some firms hire only a firm in the world. We see lots of firms paying heterogeneous wages. Is it just most of the time you can document wages are justified by differences in productivity or is it the laws you're modeling at the time? One interpretation is very commonistic. It's very heavy hand. You have to pay everybody exactly the same.
00:36:42.668 - 00:36:53.470, Speaker B: Right. The other interpretation is very reasonable. If you can't justify paying different, paying different amounts because of the difference, then you have to pay the same.
00:36:56.560 - 00:37:17.524, Speaker E: So let me try to restate the question. So the question is, well, one is really kind of getting back to Nicole's earlier question. What does similar mean? Are firms really required to pay workers who are different the same amount? So these laws I didn't include, they have a form of checklist that says, look, this is how we know you and I are not similar.
00:37:17.642 - 00:37:18.116, Speaker B: Right?
00:37:18.218 - 00:37:49.200, Speaker E: And they're basically course metrics of, well, if you're a lot more senior than I am or if you're a lot more productive. But the way these laws are written are to make it hard for the firm to say small differences are going to lead to very different workers and they make clear that productivity, if the gap is sufficiently large, is enough to have workers not be considered similar. So maybe I can answer this type of question by just jumping into some empirics, but there are some more questions.
00:37:49.270 - 00:38:07.090, Speaker B: Yeah, good. So the.
00:38:11.600 - 00:38:32.264, Speaker E: Yeah, so this question is a great one. I'm going to come back to it. That's my last slide. That was going to be the big reveal. This is how I fix things. So the question was, can you make some modifications to the policy to kind of break the form of equilibrium? And indeed that's the direction we're going to go.
00:38:32.382 - 00:38:46.170, Speaker B: Yes. Your partner, which is not really.
00:38:52.720 - 00:39:26.372, Speaker E: That's a great question. So the, the question was about the relative numbers of firms and groups. And the conjecture was that if there are more firms than groups then everything breaks down. The answer is yes. So our model features the standard notion that is in the kind of that troubled Bertrand and I guess diamond later on, which is, well, if we add one more firm, we're going to move from this kind of bang bang from lots of profits to no profits. So we are going to have this notion here. If we have more workers than groups, we will have no change in the wage gap, but we will have segregation.
00:39:26.372 - 00:40:21.188, Speaker E: Now your question was, is it realistic to have more workers than groups, more groups than firms? And actually I would argue that typically there are more groups than there are firms. And the reason for that is intersectionality. So the New York law, for example, the one I showed there are eleven different group identities age, gender, sexual identity, veteran status. And so a gay black male veteran would be different from a gay black male non veteran. And so even if these are binary categories two to the power eleven is more firms than we're likely to have in many labor markets. But again, back to the previous point. So in the paper we study different combinations of workers and groups and firms and that's going to be another solution that I'm going to present to proliferate.
00:40:21.204 - 00:40:39.122, Speaker B: One of these yes. What is the yes?
00:40:39.176 - 00:41:19.126, Speaker E: So we have, we do have some heterogeneity analysis with what happens if some firms are bound by the law and others are not. If some firms have self imposed quotas and others do not. Then our segregation finding will hold, but the wage gap finding will not. Okay, let me skip this and let me just jump to a couple of testable predictions. I think I'm almost out of time. So the two main predictions I said were, well, this group based equal pay for similar work laws leads to segregation.
00:41:19.158 - 00:41:21.318, Speaker B: Of groups across firms.
00:41:21.414 - 00:41:38.846, Speaker E: And the second is that the wage gap will increase in favor of the majority group. Okay, let me talk some evidence from Chile. Chile enacted an equal pay for similar work law in 2009 with imposed punishments for firms that were in violation. This is a pretty great testing ground.
00:41:38.878 - 00:41:39.620, Speaker B: For us.
00:41:42.390 - 00:42:29.634, Speaker E: Because this was the first equal pay law in all of Spanish speaking Latin America, which is kind of terrifying that it was 2009 in the US. A lot of the literature has had to grapple with the fact that there are so many overlapping policies that it became hard to disentangle these effects. The law there specifies explicitly two groups, men and women. And it only affects firms above a certain size threshold. So that creates a natural diff and diff approach to estimate causal effects of this equal pay for similar work law. And let me just, forgive me for being very quick. So let me just show you, I think most people will be familiar with this type of picture, but let me just show you some event study pictures and we'll hope that Diego and I did a reasonable job with this.
00:42:29.634 - 00:42:55.498, Speaker E: So here's what happens to segregation. Again, we can think of this as this is the time of the policy. This is the relative change in the wage gap of the treated group to the control group. And we see that it rises by approximately 3%. So these are firms that have workers of only one gender. Now we might think, okay, well, this is not 100%. It's not like all the firms are segregated like in our model.
00:42:55.498 - 00:43:11.694, Speaker E: There are search frictions and things like that. And so we look at another outcome, which is what are the share of firms that are almost segregated? So they're not only one gender, but they're 80% to 99% of one gender, right? So these are the firms that if.
00:43:11.732 - 00:43:13.182, Speaker B: They just got rid of that last.
00:43:13.236 - 00:43:15.598, Speaker E: Worker, would not be in compliance with the law.
00:43:15.684 - 00:43:17.986, Speaker B: What do we see? We see a fall.
00:43:18.168 - 00:43:53.134, Speaker E: And the magnitude of the fall is similar to the increase in the segregated firms, the fully segregated firms. And so our thought is, okay, there's a missing mass of these firms that they're just close to getting out of the bite of the policy and there is an increase in the ones that are fully scot free. And so our interpretation is back to my earlier question. You have ten work, ten women and one man. What are you going to do, just fire the man? And then we have this question of what happens to the wage gap. Here is the wage gap. This is in favor of men.
00:43:53.134 - 00:44:33.180, Speaker E: It rises by also approximately 3%. So let me also just say one thing, and I'll just go quickly. So there are more men than women working in Chile. The labor force participation is relatively low and most labor markets, which we're defining by a geography, by industry region, are male dominant. There are more men than women, right? And so we expect the wages to go up in our model, the wage gap to go up. But if we look at the female dominated industries, more women than men, the wage gap falls. So that's exactly our prediction there with the majority group is health.
00:44:33.180 - 00:44:51.630, Speaker E: Let me just go ahead and conclude there. Okay, so our findings are consistent with our theory. There's a rise in the gender segregated firms, there's a fall in the almost segregated firms. The wage gap rises, but not in the female dominated labor markets.
00:44:53.090 - 00:44:53.840, Speaker B: Okay.
00:44:55.830 - 00:45:00.222, Speaker E: This is pretty bleak. So here I'm plagiarizing Martin Luther King.
00:45:00.286 - 00:45:04.978, Speaker B: Perhaps, which is maybe appropriate theoretically and.
00:45:04.984 - 00:45:34.874, Speaker E: Empirically, equal pay for similar work seems terrible. Should we give up on it? And the answer is maybe not. So just to a couple of these questions, a key force here was unlike equal pay for equal work, where you could just make some epsilon difference in the job title or something like that and get away from the policy. Here the firms have to make a much bigger deviation to get away from the bite of the policy. And in equilibrium, I've tried to convince you that in fact they do. That is the competitive force. They want to separate.
00:45:34.874 - 00:46:10.198, Speaker E: And that's what leads to these kind of depressing findings when it comes to the wage gap. But what if we remove incentives of the firm to segregate by group? There are a number of ways we could do that. We could remove the protected class component from the equal pay for equal for similar work clause. So not the G and G prime. We just say you can't pay two workers who are similar, different wages. We could impose hiring quotas we could also proliferate the number of classes, right? So we have now instead of two to the 11th classes. If that's too few, we have two to the power 100 classes.
00:46:10.198 - 00:46:37.762, Speaker E: Now, each group is so tiny that specializing in one of them is meaningless. All of these will lead to the same form of equilibria. And I've drawn a picture. We have one firm that specializes not in the groups here. Here I'm just keeping groups A and B. But by productivity. One firm will hire the top productivity part of the market, the other the bottom productivity part of the market.
00:46:37.762 - 00:47:13.500, Speaker E: Now there will be unemployment at the bottom in all but one equilibrium. And there's no wage gap within firm. Across firms, there's a large wage gap. And so these are all the findings I just said on the previous slide. The good news is that this can actually close the gender wage gap compared to the no equal pay for similar work. Benchmark doesn't have to. In fact, we can show that there are markets where some equilibria increase, the wage gap, some decrease, but at least this is a way to not give up completely on the policy.
00:47:13.500 - 00:47:22.974, Speaker E: Thank you so much. Really appreciated the opportunity to present the questions. And here's my email, and Diego and I will be here, so please come ask us more questions.
00:47:23.092 - 00:47:23.920, Speaker B: Thank you.
00:47:41.230 - 00:47:42.758, Speaker E: Is this one yours?
00:47:42.934 - 00:47:45.770, Speaker F: Yes, that's EWS is mine.
00:47:49.550 - 00:47:50.358, Speaker B: Yeah.
00:47:50.544 - 00:47:51.326, Speaker E: Oh, it does work.
00:47:51.348 - 00:47:53.246, Speaker B: Okay, great. And you want that?
00:47:53.348 - 00:47:56.480, Speaker F: Okay, great. And yeah, this works.
00:47:57.730 - 00:48:14.006, Speaker B: Trying. Hello, everybody.
00:48:14.108 - 00:49:03.380, Speaker F: I'm Typhoon Cernmas, and I thank organizers for this opportunity. Today I'll talk about the recent crisis in India, and I'll try to make two points. One will be about a specific market design application. The other one will be a bigger point. I'll make a conceptual point about the framework that I've been talking recently. So Bobby started with his childhood, so let me start with my mid early adulthood. So I graduated in 1995.
00:49:03.380 - 00:49:27.482, Speaker F: It was a very exciting time to be economic. Know, people like Milgram, Wilson, Ross, they were influencing institutions, and I wanted to do the same. And indeed, I wanted to do that a lot more than I want to publish any paper. I want to change the world.
00:49:27.616 - 00:49:28.154, Speaker B: Okay?
00:49:28.272 - 00:49:47.714, Speaker F: So I was very inspired by spectrum options, nationalism matching problem. There was one problem. I had no experience. Nobody would commission me for these kind of tasks, and probably it would never happen.
00:49:47.912 - 00:49:48.514, Speaker B: Okay?
00:49:48.632 - 00:50:29.614, Speaker F: So that wouldn't work for me. So I need to do something else. And that very much shaped how I think about market design right from the beginning. So commissioned market design is fundamentally different than aspired market design by an outsider. And at that point, all the experiences were from commissioned market design applications. In commissioned market design, the need for a change is already established. So you really don't need a persuasion strategy to change.
00:50:29.614 - 00:51:04.006, Speaker F: You might need a persuasion strategy for the details, but people already want to change the institution. Commission design economist is chosen mostly based on past success. She's given lots of leeway on various details. Nobody expects custom made theory. A compelling case can be made through lots of different methodologies. Whereas for aspired market design the need for a change is not established. There will be lots of resistance.
00:51:04.006 - 00:52:02.560, Speaker F: When I get involved with a problem, nobody is happy. And that's part because of my very weak social skills. But I'm also coming with bad news, right? Nobody likes hearing that a compelling persuasion strategy is absolutely essential. Past success or research that merely provides intuition are unlikely to compel decision makers who have vested interest in status quo. And custom made theory might be rather important. So I've been talking about this framework for several months now, which I call minimalist market design. It's a design paradigm where the research question and the policy ambition is actually managed together from the beginning, right? It's the design of the whole thing, not just a research question.
00:52:02.560 - 00:52:38.060, Speaker F: And I argue that this is especially valuable for an aspiring design economist who's an outsider. This certainly been very valuable for me. So there are three main tasks in this paradigm. You first identify the mission of the institution. And the mission is typically not neoclassical, typically not maximizing an objective function. It might be many, many different things. And history of the institution might be very instructive to understanding what is it that these people are trying to do.
00:52:38.060 - 00:52:50.026, Speaker F: The second task is to figure out whether the existing institution satisfies these objectives. Is the institution consistent with the mission?
00:52:50.218 - 00:52:51.006, Speaker B: Okay.
00:52:51.188 - 00:53:42.250, Speaker F: Now the most important strategy is the following if there is a mismatch, I don't just set a maximization problem, look at the equilibrium. I don't do that. I try to find out what is it that causing the inconsistency between the mission and the institution. So I call them root causes. And then the third task is just by correcting, just by addressing these issues as if you are performing a surgeon is performing a minimally invasive set, minimally invasive operation, fix the root cause of the issue and now come up with a new institution.
00:53:42.410 - 00:53:43.214, Speaker B: Okay?
00:53:43.412 - 00:54:01.794, Speaker F: Now in some applications, primary objectives might be collectively invisible. That was the case in school choice. There is an inconsistency between parity efficiency and no justified dan compromise need to made. I'll not talk about that.
00:54:01.912 - 00:54:02.290, Speaker B: Right?
00:54:02.360 - 00:54:42.560, Speaker F: That's a harder problem. Actually, in some very convenient applications, the potential discord between the mission of the institution and the practical implementation can be eliminated by a unique minimalist intervention. And then these three tasks actually determines what institution you want. And that was indeed the case for a number of applications, including the Army's Branching process and joint implementation of vertical and horizontal reservations in India. And today's application is related to that last application.
00:54:44.870 - 00:54:45.620, Speaker B: But.
00:54:47.670 - 00:55:38.180, Speaker F: For today's talk, I will think about another case. In some cases, there might be multiple minimalist interventions that resolve the conflict between the objects and the implementation. What should we do then? We can fix the problem in many ways. Now, I argue that there is one additional task in these settings. So I'm hoping that that will be the gold standard. If there are multiple minimally invasive designs through tasks one to three present a comprehensive analysis of these competing institutions. And if this is about social justice, distribution is a big deal.
00:55:38.180 - 00:56:27.380, Speaker F: This might be a big thing. Oxiomatic methodology might be very helpful in some applications, but it doesn't need to be the only framework. Okay, so here the role of the four task is to maintain informed neutrality between reasonable normative principles in design proposals. So this is a concept Shanghu Li developed and in the context of ethics. But I will generalize this idea and through this application I will try to illustrate why this last element is so important. Okay, so that takes center place in my presentation. So let me go to application.
00:56:27.380 - 00:56:35.620, Speaker F: So the setting is affirmative action in India. And for the purpose of this yes.
00:56:36.150 - 00:57:08.640, Speaker B: I had one question. Everything you said resonates quite a bit with me. The one thing that you didn't emphasize at all is special interests and stakeholders. And it seems to me that I spend like 90% of my time trying to overcome the tyranny of the status quo because of special interest, trying to preserve their rent. So where does that fit in?
00:57:09.410 - 00:58:11.300, Speaker F: Once again, so I do not know what special interest might mean in specific settings. So I'll be particularly interested in applications where there are some legitimate objectives that are either written somewhere or obvious. Maybe it's in the law. In this application, you'll see, there will be lots of interest. But through this presentation I'll show that this fourth element will indeed be very critical to highlight these various compromises between different interest groups. But I will not be trying to figure out what is a legitimate objective, what is not. I'll be agnostic about that and that itself is very important debate, obviously.
00:58:11.300 - 00:58:16.840, Speaker F: Okay, but that is about me. So.
00:58:20.570 - 00:58:43.630, Speaker B: In terms of this whole thing about minimalist yes. Are there really any conspicuous examples that are outside that set? Market design and market design? The only one I can think of, maybe that's exception about ACA.
00:58:47.890 - 00:59:35.870, Speaker F: In many market. Well, that's great news if it is, but I've rarely seen. So basically what I'm doing is there are some missions and which is not captured by typically not captured with a single function that's one input. There's an existing institution. Typical approaches doesn't try to really maintain as much as you can from the existing institution. Let me go ahead with the application itself. So the setting is affirmative action in India.
00:59:35.870 - 01:00:33.902, Speaker F: The main method for affirmative action is through the provisions called vertical reservations. The strongest affirmative action policy in India. It is think about the simplest case where there is one type of job you are trying to allocate like 5000 police officers each year at each state, problems like that. And you can build on this, but that's the simplest case. So let's think about that case. So what is vertical reservation is formulated by a very famous Supreme Court judgment called Indra Sauni in 1992. And originally it was designed as a reparatory and compensatory instrument that corresponds to a specific protective provision in the constitution.
01:00:34.046 - 01:00:34.498, Speaker B: Okay?
01:00:34.584 - 01:01:14.000, Speaker F: And what it does is it sets aside a percentage of government positions and CSET public universities for each of a number of protected groups. Now until 2019, these provisions were exclusive to socially and educationally backward classes. Scbcs that's the official terminology who historically faced cost based operation and discrimination. That's why these were very strong provisions. 15% of the positions were awarded to scheduled cast and so on and so forth. In total, almost 50%.
01:01:14.690 - 01:01:15.440, Speaker B: Okay?
01:01:15.810 - 01:02:04.030, Speaker F: Now in January 2019, in a very controversial constitutional amendment, they were granted for members of a new category called economically weaker sections, EWS. So that was in the amount of 10%, reducing the amount of open positions to about 40%. So that came from like the 10% came from the 50% open positions or merit not open, but merit positions. For the first time, these provisions are awarded to a group based on an individual based transient characteristics. Most importantly, beneficiaries of earlier vertical reservations were excluded from the scope of EWS.
01:02:04.530 - 01:02:05.326, Speaker B: Okay?
01:02:05.508 - 01:02:35.106, Speaker F: And also very importantly, more than 95% of individuals from the general category who are people who are basically members of forward caste, who are not eligible for an SCBC. Pretty much everybody qualifies to be in EWS, making this reservation effectively a forecast reservation, practically.
01:02:35.298 - 01:02:36.098, Speaker B: Okay?
01:02:36.284 - 01:03:40.558, Speaker F: So this was immediately challenged, and in August 2020, it was elevated to a five judge constitution bench of the Supreme Court. In September 2022, in the first day of the hearings, and together with two other issues, the Constitution banks announced the following main issue to examine whether the constitution is violated or not and are EWS reservations invalid for excluding SCBC? So the court said, we'll answer these three questions. This is the most interesting one and the most controversial one, okay? In the last day of the hearings, professor Dr. Mohang Gopal, a renowned constitutional scholar, suggested that compromise that doesn't involve striking down the amendment, and the suggestion was just remove the exclusion clause and all is good.
01:03:40.724 - 01:03:41.294, Speaker B: Okay?
01:03:41.412 - 01:04:15.640, Speaker F: So now what I'll do is I'll look at the implications and implementation of that compromise policy. Now, in November 2022, in a very important judgment, jahir abhiyan 2022, this is now also called EWS quota case. The constitution bench upheld the amendment. Decision was reached in a three two split verdict, and.
01:04:19.870 - 01:04:20.794, Speaker B: It was a very.
01:04:20.832 - 01:05:44.670, Speaker F: Controversial decision, and the sticking point was constitutionality of the controversial exclusion. You can see the extent of disagreement from the opening paragraph of the descending opinion by Justice Ravindra bhatt. So basically that this court has for the first time in seven decades of the republic sanctioned and awarded the exclusionary and discriminatory principle. This verdict was declared as a major victory for central government, but according to many it also created an uproar in the country by undermining social justice. So this was very much tied to general elections and this was a very big case. It was the first live court case, supreme Court case in India's history, very historical case. Now so how did the majority justices justify the exclusion? Well, they were not unsympathetic to the social justice points, but they were of the opinion that the exclusion was inevitable.
01:05:44.670 - 01:06:14.670, Speaker F: There is no other way. So basically you can see the judgment at first plush. The arguments made in this regard appear to be having some substance because it cannot be denied that classes covered by articles this and that would also be comprising poor persons within. But then they are saying if you think logically. Now the judge just starting to make technical arguments, literally proving that you need exclusion.
01:06:15.330 - 01:06:16.080, Speaker B: Okay?
01:06:17.570 - 01:06:48.106, Speaker F: And their proof is the following. So they say the moment there is vertical reservation exclusion is the vital requisite to provide benefit to the target group. In fact, if affirmative action of reservation of a part, in fact the affirmative action of reservation for a particular target group to achieve its desired effect has to be carved out by the exclusion of others, otherwise there will be excessive benefits to the other group and so.
01:06:48.128 - 01:06:49.674, Speaker B: On and so forth. Okay?
01:06:49.792 - 01:06:56.634, Speaker F: So this is the entire justification, paragraph 79 to 82. There is nothing else.
01:06:56.752 - 01:06:57.130, Speaker B: Okay?
01:06:57.200 - 01:07:43.430, Speaker F: So they're saying, okay, this is controversial, but there's no other way. Okay, absolutely necessary. So now what I'll do is I will show that these claims are absolutely wrong, not maybe wrong. And it is in our territory because these are technical arguments. They are not social justice arguments, they are technical arguments. More precisely, I will show that while their technical arguments would be correct under non overlapping vertical reservations, it is false when vertical reserve beneficiaries overlap.
01:07:43.590 - 01:07:44.106, Speaker B: Right?
01:07:44.208 - 01:07:52.750, Speaker F: The moment you are questioning the exclusion, you are also questioning the non overlapping structure.
01:07:53.090 - 01:07:53.598, Speaker B: Okay?
01:07:53.684 - 01:08:03.902, Speaker F: So basically they are making a proof using the old assumptions, even though what is questioned is that particular assumption.
01:08:04.046 - 01:08:04.450, Speaker B: Okay?
01:08:04.520 - 01:08:09.300, Speaker F: So that's how this would reflect if this was a theory paper.
01:08:09.910 - 01:08:10.514, Speaker B: Okay?
01:08:10.632 - 01:08:38.098, Speaker F: So let me give some math. Q sigma is a number of identical positions. Calligraphic I is a set of individuals. Baseline policy is without affirmative action you just give the positions to highest merit score individuals. And the primary affirmative action policy is vertical reservations, which is managed through category memberships.
01:08:38.294 - 01:08:39.086, Speaker B: Okay?
01:08:39.268 - 01:09:21.226, Speaker F: Calligraphic R will denote the set of vertical categories. E will be this new category. EWS g will be a general category for those ineligible for vertical protections. But I'll also talk about old general category which used to be forward cast who weren't eligible for caste based protective categories. Row I is set of VR protected categories. Individual I belongs to. If row I is empty set, then individual I belongs to.
01:09:21.226 - 01:10:15.770, Speaker F: General category g and row will denote the profile of category memberships. If nobody has more than one eligibility, then that's non overlapping VR protections. If there is at least one individual who belongs to at least two categories, then that would be overlapping VR protections. Okay, QC is the number of category c positions set aside for members of category C-Q-O will be open positions which are allocated by merit. Holigraphic v will be the set of reserve categories plus the open category. So these are the categories of positions basically and EV for a given membership provide law indicates eligibility.
01:10:16.350 - 01:10:18.060, Speaker B: Who is eligible for what?
01:10:18.690 - 01:11:13.402, Speaker F: Now, a solution concept in this context is the following. And we need this so that we can accommodate the mandates in Indrasauni or other rules. So for a given set of applications, a choice rule specifies who receives a position and from which categories they do. So it doesn't just specify who gets a position, it's also specifying from which category they are getting. Okay, I'll also talk about sometimes aggregate choice rule, which doesn't specify the specific category. Okay, now what are the mandates under Indra? Sauni. Now, mandates in Indrasaur is actually a little bit more complicated because there's also something called horizontal reservation.
01:11:13.402 - 01:11:42.246, Speaker F: There are four mandates, not three, but they messed up with actually in that more complicated case, but it was recently corrected with a 2022 judgment. That's what we talk about in Summers and Yemen 2022. But horizontal reservations wasn't discussed at all in these discussions, even though when you are implementing the rule, you also need.
01:11:42.268 - 01:11:44.006, Speaker B: To take care of that.
01:11:44.028 - 01:12:11.078, Speaker F: That's why we have an appendix in the paper which does everything also with horizontal reservations, it's just more complicated. But the essence of the thing doesn't need really horizontal reservations. Okay, so the mandates of Indrasania are the following. The first two mandates are very obvious. Non wastefulness. A position cannot remain idle for as long as there is at least one eligible individual. So that's very straightforward.
01:12:11.078 - 01:12:43.930, Speaker F: The second mandate is no justified enemy subject to eligibility of the individual. The higher the merit score of an individual, the higher her claim is for a position. Okay, so that's also very obvious. So the key mandate is the following compliance with VR protections, and it says the following a VR protected position cannot be used up for individuals who deserve an open position based on merit.
01:12:44.430 - 01:12:47.306, Speaker B: If the person can already get the.
01:12:47.328 - 01:12:52.800, Speaker F: Merit position, you cannot use up that particular position reserve position.
01:12:53.170 - 01:12:53.870, Speaker B: Okay?
01:12:54.020 - 01:13:04.450, Speaker F: That makes it a very strong provision. Okay, I'll say that a choice rule complies with intrasoni if and only if it satisfies all three axioms.
01:13:04.790 - 01:13:05.586, Speaker B: Okay?
01:13:05.768 - 01:13:54.130, Speaker F: Now, in India, VR protections have always been non overlapping until 2019 due to cast system, this category. Just didn't intersect since 2019 due to cast system plus the controversial exclusion. So it's still non overlapping. And the following choice rule that we introduce in the context of Boston school choice plays a key role in this analysis. It's called over and about choice rule. So in this choice rule, what you do is first you allocate open positions to the highest merged individuals. And then in the second step, for each VR protected category, you allocate the reserve position to its highest members who remain.
01:13:54.130 - 01:14:14.978, Speaker F: Very straightforward mechanism. And the starting observation is assuming non overlapping VR protections, which is indeed the case in India right now. And ever, over and about choice rule uniquely complies with Indrasan.
01:14:15.074 - 01:14:15.382, Speaker B: Right?
01:14:15.436 - 01:14:37.120, Speaker F: So basically they formulated these mandates. There's only one way to satisfy that and it's over and above. However, if the exclusion is removed from EWS, an individual can be a member of both EWS and schedule, cast or OBC one of these.
01:14:38.610 - 01:14:43.810, Speaker B: Okay, so and this is a special.
01:14:43.880 - 01:15:22.630, Speaker F: Case of overlapping VR protections. It turns out that this doesn't matter as far as open positions are concerned. Like, you should still allocate open positions exactly in the same way under intrasout. Okay, so that's not the tricky part. Then why not just do the same thing for also reserve positions in the second step? Okay, why not now, first of all, over and about choice rule is no longer uniquely defined when there is overlap. Because in step two, how I allocate.
01:15:22.710 - 01:15:23.340, Speaker B: Like.
01:15:25.090 - 01:15:48.434, Speaker F: When they didn't overlap these categories, allocation for them were entirely independent. Like, nobody was eligible for both of them, but now some people are eligible for both of them. It would matter which one I receive, for instance, if I can get from both of them. Okay, for each VR category, basically, step two is not well defined.
01:15:48.562 - 01:15:49.880, Speaker B: So what do you do?
01:15:50.330 - 01:15:56.700, Speaker F: Well, what people typically do is you allocate them one at a time.
01:15:57.390 - 01:15:58.186, Speaker B: Okay?
01:15:58.368 - 01:16:24.340, Speaker F: So let's call these sequential choice rules. Fix the processing sequence for vertical categories and I'll introduce three classes. Sigma o will be open first. Orders of precedences, a subset of would be sigma o subscript e. So that would be open first, EWS last, and then I'll have another class for open first and EWS next.
01:16:24.870 - 01:16:25.620, Speaker B: Okay?
01:16:27.430 - 01:16:37.718, Speaker F: And what you do is following that sequence, you just allocate positions in that category to highest eligible people.
01:16:37.804 - 01:16:39.880, Speaker B: Very simple, right?
01:16:40.410 - 01:17:14.420, Speaker F: Okay, and I'll focus on two of these EWS last, over and above, and EWS first, over and above. Now fix the profile of category memberships. Then all EWS last, over and above, give the same outcome. Basically, once EWS is at the very end and opens at the beginning, it doesn't matter what you do with the rest. Okay, so that's why actually I will speak about the EWS last, over and above. Same thing with EWS first.
01:17:14.790 - 01:17:15.540, Speaker B: Okay?
01:17:16.310 - 01:17:25.160, Speaker F: So the main challenge is it's not the difficulty of abiding by indra sauni, but rather the multiplicity of the choice rules which do.
01:17:25.530 - 01:17:29.362, Speaker B: Okay, now why would that be a challenge?
01:17:29.426 - 01:17:59.280, Speaker F: I'm creating a problem by myself, right? And there are many ways to fix this. Straightforward, let's not worry about it. So I'll start with an initial observation. Suppose everybody is eligible for EDWs in the absorption SCBC exclusion and remember that this was very political. So everybody is eligible indeed. Okay, assume that there is excess demand from forward cast, which you typically do.
01:17:59.650 - 01:18:04.094, Speaker B: The third assumption basically says that when.
01:18:04.132 - 01:18:26.680, Speaker F: You take the ratio for any SCBC category, the proportion of number of category C positions to number of category C applicants is bigger than the same for DWS divided by all general category. And typically you expect so this number is 10%.
01:18:27.210 - 01:18:27.778, Speaker B: Okay?
01:18:27.884 - 01:19:10.162, Speaker F: So this is a fraction of forward cast people which is in the population, they are like 30%. So this number is maybe around one third, whereas number of category C positions is meant to be the same as their proportion in the population. So these are meant to be around 1% if everything is representative of the general category. So this is a safe assumption. And let's also assume that male score distribution for forward cast is either the same or first order stochastically dominates Merritt score distribution for SCBC. Now, by the way, these are preliminary observations. I don't need any of these assumptions for my main results.
01:19:10.162 - 01:19:18.838, Speaker F: I'm just trying to illustrate why this multiplicity is a big deal and these are reasonable assumptions.
01:19:19.014 - 01:19:19.740, Speaker B: Now.
01:19:23.310 - 01:19:42.126, Speaker F: The first proposition is under these assumptions, the outcome of EWS lust over and above is the same as the outcome of the over and above choice rule with EWS exclusion, with the controversial exclusion. So basically this is exactly the outcome.
01:19:42.158 - 01:19:44.580, Speaker B: Of the current policy, right?
01:19:45.670 - 01:20:00.262, Speaker F: Whereas under assumption one only the outcome of EWS first over and about choice rule is the same as the over and about choice rule without EWS reservation at all.
01:20:00.396 - 01:20:01.640, Speaker B: So this is.
01:20:03.370 - 01:21:21.410, Speaker F: The world before this amendment. So basically what I'm saying is under reasonable assumptions with this multiplicity, I can cover the entire spectrum of outcomes by just playing with and all in a legal way. Okay, so what does that mean? But then they make everybody eligible, so they want to look like they are giving affirmative action to poor people, but by making everybody eligible and then by making Scbcs ineligible even though they are even more poor. So basically they're effectively creating a very major forward cast reservation, completely watering down the entire premise of the thing, right? And we'll see the implications of that. But the first part of this proposition already refutes the technical claims of the justices. There is an element oh, sorry, Ravi.
01:21:41.420 - 01:21:44.120, Speaker B: Accepting general category.
01:21:53.420 - 01:22:29.616, Speaker F: It could what I'm saying is if everybody becomes eligible for EWS, then there is no distinction with that policy tool and a forwardcast tool. And they made these eligibility constraints such that this is indeed the case. And this 95%, 98%, they are not my numbers. They are numbers from India. Right, but I don't need that assumption, by the way. I'm just making an illustration, right? I'll not use any assumption at all for my main results.
01:22:29.728 - 01:22:30.980, Speaker B: Zero assumption.
01:22:36.300 - 01:23:05.500, Speaker F: But what the first part says is under assumptions which are pretty realistic, forward customers are still getting all the benefits, right? And you don't need to exclude anybody and cause this big fight. You could have still gotten the same outcome. In particular, the entire premise of the exclusion is false outright. Not maybe false, it's outright force.
01:23:05.660 - 01:23:06.368, Speaker B: Okay?
01:23:06.534 - 01:23:30.810, Speaker F: So indeed, under EWS, loss over and above, the removal of the exclusion does not generate excessive benefits to Scbcs at all. It merely assures that Scbcs are not hurt by affirmative action. That's all it does. Now, removal of the exclusion without additional details is not a good option either, because it creates a major loophole in the system.
01:23:31.180 - 01:23:31.880, Speaker B: Okay?
01:23:32.030 - 01:23:36.270, Speaker F: And we have seen the extent of the.
01:23:39.120 - 01:23:40.140, Speaker B: Loophole.
01:23:40.880 - 01:23:56.960, Speaker F: So the big issue is the following. The amendment allows for a poor member of a forward cast to receive a position, while it denies the same position for a potentially poorer member of an SCBC, even if she has higher merit score.
01:23:57.300 - 01:23:58.000, Speaker B: Okay?
01:23:58.150 - 01:24:13.224, Speaker F: So this cannot be justified by either meritocracy or affirmative action. That's why this was a big deal. And the sounding justices, they characterize this.
01:24:13.262 - 01:24:13.850, Speaker B: As.
01:24:17.740 - 01:24:41.212, Speaker F: And indeed this injustice happened in a systematic way because the cutoffs for EWS was lower than some of these Scbcs. So not only it could happen, it systematically happened. So the modi government basically reversed affirmative.
01:24:41.276 - 01:24:44.770, Speaker B: Action with this policy. Okay?
01:24:45.460 - 01:25:04.964, Speaker F: So now in the last part, I'll talk about how we can avoid this. And what I'll show is we can avoid this crisis at least in three ways. And I will argue that these are the three reasonable ones. And what we find very interesting with.
01:25:05.002 - 01:25:09.928, Speaker B: UTGO is among these three, there is.
01:25:10.014 - 01:25:57.480, Speaker F: One exactly captures the position of the majority justices once the technical error is removed. Otherwise the rest will be exactly what they are arguing should be done. There is another one which will directly, exactly corresponds to what dissenting justices want, and that doesn't require any error or anything. And then there's a technocratic point of view which probably you guys would come up with or also we, I guess okay, so let me talk about these three. Now, first thing is it's not easy to revoke a constitutional amendment because of separation of powers.
01:25:57.980 - 01:26:02.056, Speaker B: So to revoke it, it needs to.
01:26:02.078 - 01:26:52.344, Speaker F: Be shown that there is a conflict with the basic structure of the Constitution. And plaintiffs argued that there is that conflict, which they said there's conflict with right to equality, which corresponds to Articles 14 to 18 in the Constitution. The majority justices said, no, we cannot do anything else. But as I argued, their argument is completely false. Okay, so I next formulate a policy that removes the violation through minimal interference in the vein of separation of powers. Now, let Row Nut be the current profile of non overlapping category memberships. Some people get DWS, some people get SC.
01:26:52.462 - 01:26:53.130, Speaker B: Whatever.
01:26:53.580 - 01:27:13.872, Speaker F: Now, suppose calligraphic J denotes a set of individuals whose right to equality is violated because of that exclusion. So these are members of scheduled caste, scheduled tribe OBC who fit in that income limit. Not all of them, but 95% of them.
01:27:13.926 - 01:27:14.576, Speaker B: Okay?
01:27:14.758 - 01:27:21.616, Speaker F: Now, which individuals in J if any material lose a position because of the.
01:27:21.638 - 01:27:24.892, Speaker B: Violation who are affected? Okay?
01:27:25.046 - 01:27:29.124, Speaker F: Now, a tentative answer might be the following a first order answer.
01:27:29.242 - 01:27:29.908, Speaker B: Okay?
01:27:30.074 - 01:28:16.896, Speaker F: If I'm a member of scheduled cast, suppose if I was instead a member of EWS, not a member of scheduled cast. If that's changing the outcome in my favor, then I'm tentatively affected. But it could be that there might be a forward cast member who received a position and then I'm tentatively affected. Eric is also tentatively affected, but only one of us are really affected, right? So because of that, I need to think a little bit more to figure out who is actually affected given an individual J. Let sigma, what's this rho J row tilde J be just EWS.
01:28:17.088 - 01:28:17.830, Speaker B: Okay?
01:28:18.680 - 01:28:41.710, Speaker F: So for next year's of definitions, I'll fix the profile of category memberships choice role set of applicants. I'll say that a set of individuals J is vulnerable to a violation of Equality Court. If for all of them, once I replace their existing category with EWS, they suddenly start taking a position.
01:28:44.240 - 01:28:47.568, Speaker B: But then, like I argued with the.
01:28:47.574 - 01:28:53.808, Speaker F: Eric example, we might both be vulnerable, but will not be both receiving one.
01:28:53.974 - 01:28:54.688, Speaker B: Okay?
01:28:54.854 - 01:29:29.756, Speaker F: The set who is literally materially affected is the following set. I'll call that maximal set of individuals who suffer from a violation of equality code. If first of all, J is vulnerable, and when I consider any other competing group and change their eligibility, what happens is only members of J actually end up receiving, and not everybody in J prime minus J receive it.
01:29:29.858 - 01:29:30.172, Speaker B: Okay?
01:29:30.226 - 01:29:34.716, Speaker F: If you think you'll see that this is the correct set of people who.
01:29:34.738 - 01:29:37.824, Speaker B: Are actually affected from this, and this.
01:29:37.862 - 01:29:40.130, Speaker F: Is unique, it's easy to show.
01:29:40.660 - 01:29:41.456, Speaker B: Okay?
01:29:41.638 - 01:30:09.530, Speaker F: And the first result says the following if I use EWS last over and above, what will happen is compared to over and above with exclusion, the only additional people who receive the position who didn't receive before is that maximal set.
01:30:10.060 - 01:30:10.810, Speaker B: Okay?
01:30:11.340 - 01:30:20.924, Speaker F: And as a corollary, if there was nobody who's materially affected by this exclusion, nothing would change.
01:30:21.122 - 01:30:21.820, Speaker B: Okay?
01:30:21.970 - 01:30:54.552, Speaker F: So that's the majority perspective. So basically what this is saying is with EWS loss over and above, this is a very minimal change. It's only avoiding those crazy situations where in all three dimensions, one person deserves the position, and yet the forward cast member who has lower score and less poor potentially is receiving it.
01:30:54.686 - 01:30:55.370, Speaker B: Okay?
01:30:55.820 - 01:31:01.930, Speaker F: It doesn't do anything else. Okay, so that's the majority position.
01:31:03.020 - 01:31:06.716, Speaker B: What about minority position?
01:31:06.898 - 01:31:50.650, Speaker F: Now, the legal terminology in India doesn't differentiate between categories of individuals and categories of positions. They like working with partitions, which is kind of okay if we are talking about scbcs. But because of that, general category and open category positions are used synonymously in the country. Legal documents speak of open category individuals and general category positions. And that confusion causes tons of trouble in India. Not just this one, this is just one of, you know, I like root causes. This is a big root cause.
01:31:50.650 - 01:32:33.512, Speaker F: The legal concept of migration, also called mobility, is a consequence of this misleading convention. So for example, when a member of a VR protected category receives an open position with his merit, then he's set to migrate from her category to open category so that they can keep on working with partitions. Okay, so basically they have this makeshift tool to deal with these complicated mandates. What makes the VR policy a higher level AA policy is it provides member of VR protected categories with the benefit of mobility from their category to general category. That's what makes it highest level.
01:32:33.646 - 01:32:34.330, Speaker B: Okay?
01:32:35.340 - 01:33:32.600, Speaker F: And that corresponds to our last axiom, the third axiom. Now, if you look at the dissenting opinion, you see that the descent so not only they want removing exclusion like 25 seconds, they also want mobility, the benefit of mobility, right. And that we can formalize in an axiom which looks similar to our third axiom. And if you do that, EWS first over and above is the unique rule which satisfies that. And that's the other end of the spectrum. I'll not go through the meritocratic method, but there is one which treats all categories neutrally. Okay, so basically the majority opinion, the key arguments are false.
01:33:32.600 - 01:34:11.810, Speaker F: This crisis could have solved in various ways without that crisis. And as Shanghui Li indicates, in addition to studying cause and effect in markets, economists also have comparative advantages stating precise normatively relevant properties of complex systems. So taking advantage of that competitive advantage with minimalist market design, I tried to present how we can come up with various solutions depending on what additional normative position you want to take. But thank you very much.
01:37:56.870 - 01:37:58.180, Speaker E: Nice to see it.
01:39:27.750 - 01:39:31.730, Speaker G: Do you happen to have an adapter for a magnet?
01:39:32.950 - 01:40:31.140, Speaker B: I don't believe so. Give me a second, I'll check. I'm pretty sure you are. You next.
01:40:33.110 - 01:40:33.666, Speaker G: No.
01:40:33.768 - 01:40:52.620, Speaker B: Okay. He took the thing. It's here.
01:40:55.390 - 01:40:57.366, Speaker G: I know, but we don't have any USB stick anymore.
01:40:57.398 - 01:41:23.490, Speaker B: I was meant to say that's. It on there's.
01:41:29.550 - 01:41:30.634, Speaker G: I think also here.
01:41:30.672 - 01:41:33.500, Speaker B: But this one yeah.
01:41:36.670 - 01:41:37.420, Speaker H: Never.
01:41:45.790 - 01:41:46.634, Speaker C: Second.
01:41:46.832 - 01:41:53.274, Speaker B: I just put both of you can speak slowly. You're not being as active as as you thought.
01:41:53.312 - 01:42:04.194, Speaker C: Yeah, that's what I was yeah. I remember from Camillo's presentation that it was very what is it again?
01:42:04.232 - 01:42:11.330, Speaker B: On Windows? Get active on impartable favors. We don't know what to complain about.
01:42:11.480 - 01:42:13.842, Speaker G: No, it had happened to me many.
01:42:13.896 - 01:42:14.820, Speaker H: Times that.
01:42:39.970 - 01:42:41.674, Speaker C: Think they're on they're on desktop.
01:42:41.722 - 01:42:42.830, Speaker G: They're on the desktop.
01:42:44.710 - 01:43:09.860, Speaker B: Just want to double check. Can we see the screen share? Let.
01:43:29.790 - 01:43:31.366, Speaker C: Just double check that all slides.
01:43:31.398 - 01:47:20.060, Speaker B: Are one, but yeah, right. Bring up the station. One guy first and bring the ice. Makes sense. Yeah, but I see how kind of giving the clinic back is gonna be. It.
01:47:52.230 - 01:47:54.420, Speaker D: All right, let's get started.
01:47:55.910 - 01:48:02.390, Speaker B: We are delighted to have Marcino Banchio talking to us about AI and collusion.
01:48:03.610 - 01:48:41.246, Speaker D: Thanks for the organizers for including this paper in the program. It's great to be here. Present artificial intelligence and spontaneous collusion. This is work with Giacomo, who's a PhD student at GSB, and he's on the or market this year. Today I'm going to talk about strategic interactions between artificial intelligence algorithms. This is a topic that has been becoming more and more interesting as time goes on. In online advertising, auctions algorithms are biding at a rate of about hundreds of auctions per second in undisclosed search engines.
01:48:41.246 - 01:49:46.802, Speaker D: Online and online pricing happens at a sort of a slower rate, but still definitely faster than what legacy retailers used to update their prices at. And in both of these settings and in many others, like rental markets and gasoline pricing, many of these settings use algorithms to set prices and set bids. These algorithms are used both for the frequency of actions as well as for the complexity of the environment, because this allows agents to make decisions in a much more fine grained way. However, this increase in the use of algorithmic agents has also been accompanied by concerns by regulators that these algorithms may be facilitating collusion between market participants. And these concerns are all from a year ago when I first prepared these slides. But in the meantime, many more articles have come up where regulators are asking, are these algorithms allowing agents to collude better than they used to? And some of these concerns are supported by papers in the academic literature. I'm highlighting two here, mostly because my paper is going to speak directly to these results.
01:49:46.802 - 01:50:39.270, Speaker D: But there's a broad literature in these results. First, a paper by John Asker heim Fleshman and Alpekis shows that algorithms appear to be converging to super competitive prices in a Bertrand game. A paper I have with Andy Scripage instead, from a market design perspective, shows that first price auctions appear to be more collusive than second price auctions. So algorithms collude much better in these auctions. Now, these are all simulation based papers, but what I'm going to try to do today is I'm going to try to introduce some theory into this literature, try to understand exactly what type of collusion these agents manage to achieve. And if they do well to do this, I'm going to introduce this theoretical apparatus to understand algorithmic collusion. This comprises essentially continuous time techniques that help me characterize the learning outcomes of pricing and bidding algorithms.
01:50:39.270 - 01:51:35.190, Speaker D: And I'm going to show you that algorithms find a new collusive channel which I call spontaneous coupling. Now the peculiarity of this channel is that unlike cartels or unlike Tacitly collusive equilibria, this does not require deliberate intent to collude. These algorithms are maximizing profits and on their way to maximizing profits, they find collusive outcomes. Collusion in particular is arising endogenously from a statistical linkage in the algorithm's estimates. This make it all the more complex to even think about regulation in this setting because regulation, we know, requires this sort of deliberate intent to collude from market participants. And finally, time permitting, I want to try and tell you about a couple of applications of this paper. First one is going to be in the spirit of market design to design some mechanism that are robust to this particular type of collusion from market participants.
01:51:35.190 - 01:51:37.574, Speaker D: I've called those learning robust mechanisms.
01:51:37.622 - 01:52:06.626, Speaker B: Yes. So my takeaway from Asker Freshman in Bacus was more that the amount of data that algorithm would require, number of interactions that algorithm would require, is so large that you'd maybe see super competitive prices, but it would take hundreds of years before with the kinds of frequency that people interact with. So are you going to say something about how long we have to wait until the spontaneous coupling happens?
01:52:06.728 - 01:52:07.186, Speaker A: Great.
01:52:07.288 - 01:52:52.338, Speaker D: So repeating the question, the takeaway from Asker Freshman and Pekus was that it takes quite a while for these algorithms to converge. And in the timescale that pricing algorithm work online, in online retailing for example, it would take hundreds of years. The reality of that is that oftentimes algorithms don't face the cold start problem as it's called in this literature. They get initialized with some sense of what the environment will look like, which already helps convergence a lot. And there's some papers about this that are coming out just now. But more importantly, in some settings, such as online bidding decisions happen much more frequently than once an hour or once every couple of hours. In these settings, like a million iteration is very little.
01:52:52.338 - 01:53:26.570, Speaker D: It takes about half a day to reach that number. And the algorithms I'm going to present today converge in less than a million iterations. I hope that answers the question a little bit. The second application I'm going to talk about, if I manage is going to be to try to interpret some results in the literature exactly the results from Asker Freshman and Pekus and the results from my paper with Andy Scrippage. So if there's no questions about the motivation, I'm happy to jump into the model. And the model is going to be super simple. I'm going to think about normal form games.
01:53:26.570 - 01:54:04.570, Speaker D: There's n agents, every agent knows exactly his action set AI, what actions he can take. What the agents don't know is the utility that they associate to each action. In particular, these agents are so naive they don't even understand that their utility is going to depend on everyone's actions. They think that to every action corresponds a payoff, regardless of what the others do. What they're going to try to do is they're going to try to learn the value of these actions. In a way, this is a misspecified problem. They're going to try and select actions according to a learning algorithm and figure out which action maximizes their profits.
01:54:04.570 - 01:54:42.246, Speaker D: Now, how do they learn? Well, for this talk, I'm going to focus particularly on one algorithm just called Q learning. It's kind of a foundational algorithm for the literature. In particular, variations of this algorithm have shown to be very promising in various settings. For example, by beating the champions in Go. Now, Q learning works as roughly as follows. QLearning tracks a vector of perception for every agent and for every action. So agent I carries a perception, an estimate of the payoff from every action a at time T.
01:54:42.246 - 01:55:21.700, Speaker D: This is called QIT. How do they update these perceptions? Well, they take actions and they observe some payoff, and they're going to use that payoff to update their perception. And the update is going to be essentially a convex combination between the perception at time T and the payoff they observe in that same time. If they don't observe any payoff, they will not update their perception. There's one hyperparameter here, which is alpha, the learning rate. You can think of the learning rate as a measure of persistence. When alpha is really small, the agents take quite a while to update their perceptions and in particular, to change their actions in response to news.
01:55:21.700 - 01:55:58.394, Speaker D: This is sort of an environment in which we don't want agents to be too volatile. And so having an alpha very small helps agents accumulate information and learn correctly about the space. How do agents choose actions? Well, they use perception and they try to maximize their profits. So with a large probability, they're going to select the action that has the highest perception in a given period. This is with probability one minus epsilon with a small probability probability epsilon. Agents are going to run experiments to try and figure out whether their perceptions are correct. And they're going to do this at random.
01:55:58.394 - 01:56:08.558, Speaker D: So selecting an action at random from their action set. Okay, there's much more sophisticated policies than this, which in particular helps with the concerns that you have about speed of convergence.
01:56:08.654 - 01:56:09.010, Speaker B: Right?
01:56:09.080 - 01:56:49.646, Speaker D: But this is a very baseline type of analysis here. So what happens when Q learning plays in a particular game? In particular, in the most canonical game that we have, the Prisoner's Dilemma, we'll have Alice and Bob, two agents that both use Q learning to try and play in this game. This game is parameterized by the attractiveness of cooperation, the parameter G. When G is really large, cooperation is much better than defection. It's about twice as worth as defection. Whereas when G is very low, still the only dominant strategy is defection. But cooperation is not much better than that.
01:56:49.748 - 01:56:53.774, Speaker B: Okay, now, how do agents play in this game?
01:56:53.812 - 01:57:26.426, Speaker D: Well, I'm going to show you the results of some simulations. On the X axis, I'm putting the attractiveness of cooperation. On the Y axis, I'm putting the fraction of time that algorithms play cooperate in what I define as convergence. So the last 300,000, iterates out of a long simulation of 3 million iterations. Well, it turns out that the parameter G sort of helps us understand a little bit how much agents cooperate. In particular, when G is very large, when cooperation is really valuable, agents appear to be cooperating. Very often.
01:57:26.426 - 01:57:49.442, Speaker D: About 95% of the periods agents jointly cooperate. This sort of comes down a little bit to about 80%, 75% when the parameter G is lower 1.2, and then abruptly stops agent completely defect. At all given periods when G is lower than 1.15 or something like that, which is the dashed line here?
01:57:49.576 - 01:57:52.420, Speaker B: Okay, there's a little bit of a.
01:57:53.190 - 01:58:35.834, Speaker D: Discontinuity at this point, which is not clear why that would be there, but it's also not clear why these algorithms would learn to cooperate. This is a dominant strategy game. This is sort of the simplest game that we can think of in terms of incentives, and yet these agents are cooperating. What does cooperation look like is another question, because here I'm showing you that they cooperate for a fraction of time. So what do they do in the rest of the time? How is cooperation sustained? I'm going to look at the dynamics of their perceptions to understand how they play. On this graph, I'm showing you 40 periods and how the perceptions of Alice and Bob on the left and right are evolving over time. The full line is the perception of cooperation.
01:58:35.834 - 01:59:10.650, Speaker D: The dashed line is the perception of defection. Now, you see that at the beginning of these 40 periods, both Alice and Bob are cooperating. The perception of cooperation is larger than the perception of defection. So when they maximize profits, they simply play cooperative. There is some jaggedness in the line because sometimes they run experiments and so of course, their perceptions are going to move around. However, as soon as Bob tries to defect, alice follows suit and we have a short burst of joint defection. Immediately after that, agents revert back to cooperation.
01:59:10.650 - 01:59:50.914, Speaker D: So from the observational point of view, this looks exactly like the observational data from a repeated game in which agents are cooperating in a tacitly, collusive way. It's essentially indistinguishable from that. But remember here, agents do not have the ability to condition on past actions. They can't say, oh, yesterday you defected, so today I want to defect and fight against you. All of this is embedded in their perceptions somehow. And so this is what I'm going to try to understand today, is how is it possible that with such limited information, such limited availability of actions, agents still manage to sustain cooperative outcomes or collusive outcomes.
01:59:50.962 - 01:59:54.326, Speaker B: You I'm going to try and convince.
01:59:54.358 - 02:00:37.506, Speaker D: You in particular that the right way to think about this is to approximate the process in continuous time. This is going to allow me to do a lot of analytical analysis, which in turn, I hope is going to convince you that collusion is happening through what I call spontaneous coupling. Now remember, Q learning for Alice is given by the following update function. It's a convex combination between the perception of Alice at time T and her payoff. But this update is non Markovian. The reward RT that she gets in a given period depends on Bob's actions as well. So of course, Alice's perceptions are not enough to tell me how this perception evolves.
02:00:37.506 - 02:00:48.518, Speaker D: And I want to use Markov techniques to approximate the system. So what I'm going to do is I'm going to stack the vectors together. I'm going to always approximate the four dimensional vector of perceptions.
02:00:48.614 - 02:00:49.260, Speaker B: Okay?
02:00:51.070 - 02:01:27.526, Speaker D: Now let me rewrite Q learning in incremental terms. Let me look at the difference between the perceptions at time T plus one and time T. The difference here is what I call surprise. You see, this is the difference between the reward that agent observe at time T and their perception at time T, what they expected to receive. So this is going to be positive when the agent is positively surprised, and it's going to be negative when the agent is negatively surprised. Now, to approximate this process, what I'm going to do is I'm going to accelerate time. I'm going to make sure that updates occur at a rate one over n.
02:01:27.526 - 02:01:33.674, Speaker D: So instead of waiting for an entire minute for an update, I'm going to have the update happen at one over.
02:01:33.712 - 02:01:38.538, Speaker B: N minutes or seconds, and I'm going.
02:01:38.544 - 02:02:06.530, Speaker D: To take this time to zero. What this does is it accumulates a lot of information in a given amount of time. All of this information must become less valuable if I want to retain the good properties of this system. And so what I'm going to do is I'm going to slow down the update of the algorithm. Every piece of the update is going to contribute less to the total estimate that the algorithm carries. In fact, at the same rate as time is speeding up. What this does is it sort of looks like a law of large numbers.
02:02:06.530 - 02:02:48.622, Speaker D: If this was a path that the algorithm took, well, by increasing the speed and decreasing the updates, I get closer and closer to a continuous line. In particular, there's a way to make this formal is to look for love large numbers for stochastic processes, which is formalized in Kurtz 1970. These are fluid approximations. What this says is that the sequence of processes QN, where N is the index by which time speeds up, converges in probability to bold Q, where bold Q. Here is a system of differential equations where the derivative is exactly the surprise. Now Q is a. Dynamical system, which we have good tools to analyze.
02:02:48.622 - 02:03:28.960, Speaker D: But it's still a four dimensional dynamical system, so it's not exactly simple to visualize and there can be a lot of complications, including chaotic behavior. So to simplify my life a little bit, I'm going to make an assumption that is not without loss. I'm going to make the assumption that algorithms are initialized symmetrically. What that implies, because this is a deterministic system, is that algorithms are going to remain symmetric throughout time. As I said, this is not without loss. But I hope I'll convince you that this assumption actually buys me enough to be able to clearly analyze what's happening in the fully general model. Okay, and I have some analysis about the asymmetric initialization in the paper.
02:03:28.960 - 02:03:49.670, Speaker D: So to understand how these algorithms evolve, I'm going to look at their derivatives, in particular their vector fields. Remember, now we are in two dimensions. Alice behaves exactly in the same way as Bob. On the x axis I plot the perception of defection and on the y axis I plot the perception of cooperation.
02:03:50.810 - 02:03:54.966, Speaker B: Now, if their perceptions evolve according to.
02:03:54.988 - 02:04:43.800, Speaker D: This vector field, we should look at how the arrows move. And if the perceptions start somewhere in this quadrant, they're going to move according to the arrows until they hit this 45 degree line. Why am I plotting the vector field only below the 45 degree line is because agents prefer to defect whenever the perception of defection is larger than the perception of cooperation, which is exactly this quadrant. However, as soon as this perceptions hit the 45 degree line, the motion switches switches because agents begin preferring to cooperate rather than defect. This introduces a whole new vector field which may be completely discontinuous from the previous one. However, the perceptions are simply going to continue to evolve. According to the new vector field.
02:04:43.800 - 02:05:24.926, Speaker D: This 45 degree line is called a switching surface. Because motion switches between the vector field on one side and on the other side. We still need to define a motion on that surface in order to be able to characterize the dynamics of the system. How do we do this? Well, it's actually surprisingly simple. When the normal components of these vector fields point in the same direction, the perceptions simply hit the 45 degree line and continue along in the new space. What's a bit more complicated is to say what happens when the two normals are pointing in the same direction. Well, when that happens, motion hits the 45 degree line, but it can't escape.
02:05:24.926 - 02:06:14.782, Speaker D: It can't move into the other region because of course, the region is pushing into the switching surface. So the only thing that the motion is allowed to do is to stay constrained on the 45 degree line in a sliding motion, which can escape the 45 degree line or may find a steady state. Now, this is all sort of techniques from dynamical systems that are going to be allowing me to think about the prisoner's dilemma and in general, the games that we are interested in. So let's take a look at the prisoner's dilemma again, let me look at a prisoner's dilemma when the parameter, the attractiveness of cooperation is quite low. We're talking 1.1 here. What happens here is that all of the space attracts to a single steady state the steady state that I call the defection steady state QD.
02:06:14.782 - 02:06:52.830, Speaker D: This lives fully below the 45 degree line in the region where both agents are defecting most of the time. This is essentially the Nash equilibrium of the game. The dominant strategy equilibrium of the game, however, and this is sort of where it gets interesting is when we look at a parameter g that is much larger, say, let's say g 1.8. When g is large, there are two steady states. Now, one steady state which has an attraction region in the blue region here is the defection steady state. This is still the Nash equilibrium of the game, so that still exists. But there's another steady state which a much larger attraction region.
02:06:52.830 - 02:07:48.820, Speaker D: And this steady state QC lives exactly on the 45 degree line between cooperation and defection. Here, agents are indifferent between cooperating and defecting. And locally, in order to live on this boundary, they must be playing some cooperation and some defection at all times. It must be that the forces pushing the agents on either side are balanced. The way to balance these forces is by remaining for a local time on either side of the boundary. Now, if you recall this graph that I've shown you earlier, I can try and characterize this fraction using this idea of local time, using this idea that in continuous time, agents must live for a fraction of the time on one side and for a fraction on the other side of the boundary. The analytical techniques buy me an explicit form for that time, for the local time, which looks exactly like this.
02:07:48.820 - 02:08:07.400, Speaker D: So it appears to match pretty well the observational data, even though, remember, the observational data comes from an asymmetric system in discrete time with all the randomness that that entails. In particular, there is a discontinuity exactly at g lower bar 1.15 or something like that.
02:08:08.970 - 02:08:09.720, Speaker B: Great.
02:08:10.970 - 02:08:55.590, Speaker D: Now, what is going on here? So far I've shown you that the continuous time system approximate fairly well the discrete time system. But I haven't told you exactly why algorithms are supporting these cooperative outcomes. The way I understand it is that Alice and Bob are coupled. So they're involuntarily symmetric, right? What happens when agents are involuntarily symmetric is that both agents cooperate for largest stretches of time. This is the case in the shaded region here. And while they cooperate, their perception of defection rises because they're running experiments and they're figuring out, oh, playing defection when my opponent cooperates is quite good for me. So the perception of defection eventually is going to overcome the perception of cooperation.
02:08:55.590 - 02:09:27.540, Speaker D: However, as soon as that happens, in this thin blue line that you can barely see, agents defect together. Immediately after Bob defects, Alice defects as well. She responds immediately to that because of the symmetry. And now both agents are defecting. Neither of them is trying to cooperate. So the perception of defection is going to fall really fast, but the perception of cooperation is not going to fall quite as fast because neither of them is trying it. And that is going to move them back to a cooperative state.
02:09:27.540 - 02:10:06.350, Speaker D: In words, this is what I call spontaneous coupling. Alice and Bob cooperate, and their estimates of cooperation are correct conditional in their opponent cooperating as well. However, as soon as one of them defects, the opponent defects as well. And now both estimates of QD drop because defection is quite bad when both of us defect, but neither of us tries cooperation. So the estimate of cooperation remains almost constant. There's high persistence for these actions that are underexplored. And so as soon as QD drops, enough cooperation restarts.
02:10:06.930 - 02:10:15.950, Speaker B: Yeah. Synchronization. That's right. Can you tell us about your assumption?
02:10:18.530 - 02:11:07.860, Speaker D: Great. No, that's a great time to talk about this. The question is, how much does this assumption of synchronization that I make in the continuous time system affect the results? Well, so these results this is an interpretation of the results that, of course, in continuous time is obvious because agents are symmetric, and so they always play the same action. But as I've shown you, the data matches pretty well with the simultaneous case that I'm studying here. So the synchronized case is sort of a tractability assumption that I make, and it turns out that it characterizes pretty well what happens in the system, which does not have this assumption. My understanding is that these algorithms are essentially synchronizing themselves, and so to study their behavior is sufficient to study synchronous dynamical system.
02:11:09.510 - 02:11:13.700, Speaker B: Does synchrony rise in the limit model?
02:11:18.310 - 02:11:39.740, Speaker D: It relies on the stochastics of the discrete model. However, what happens in the so if I look at the four dimensional system without assuming symmetry, what I see is chaotic behavior that essentially looks exactly like this. So I can show you some pictures. But essentially, agents, even though they're not symmetric, they tend to behave symmetrically even in the continuous time system.
02:11:40.270 - 02:11:56.306, Speaker B: Thank you. Follows, but is one reacting to the other? Does one actually follow the other, or is it just that they both defect? They both start affecting exactly the same.
02:11:56.488 - 02:12:11.794, Speaker D: So there is, in fact, reaction in the sense that you can think of Alice as having a larger perception for cooperation than defection. As soon as Bob begins defecting, her cooperation perception is going to fall really fast, and so she's going to move to defect.
02:12:11.842 - 02:12:15.160, Speaker B: Yeah. Thank you. Okay.
02:12:16.890 - 02:12:54.994, Speaker D: By the way, to speak to the symmetry, this is a system that I did not approximate. So this is simulations, and you can see here that the regions where both agents cooperate and where both agents defect appear to match pretty well across the two agents. So these agents are in fact sort of symmetric even though their perceptions are not, right. Their perceptions appear to be different even in values, but their behavior is symmetric. So this is a new mechanism that sustains collusion. This is a new mechanism. Let me stress that this has nothing to do with obviously explicit agreements, but has nothing to do with repeated games either.
02:12:54.994 - 02:14:00.226, Speaker D: Agents here are not learning that they should punish their adversary for a deviation, right? All that is happening is happening within the algorithm endogenously. And in particular, this really relies on the fact that these are algorithms and not rational agents. This is sort of a way to think about boundedly rational agents playing against each other and their limits on rationality are sustaining outcomes that are collusive in a sense. How do we get away from this? I want to try to put lawn my market designer hat and think about how to avoid spontaneous collusion in practice. Now, one observation from the literature, and this is why I cited Asker Freshman and Bacus and my paper with Andy is that collusion seems to go away when agents have access to counterfactual information. What that means in a Bertrand pricing sense is suppose agents have access to the shape of the demand curve. Then they can compute what would have happened had I chosen a different price today in the auction setting.
02:14:00.226 - 02:14:42.034, Speaker D: This means, let's say I had access to a minimum bid to win information, which is what's provided on many search engines these days. Then what I could do is I could figure out, well, if I bid differently yesterday, would have I gotten the item or not? All of this information is helping agents to compute counterfactuals, but it's not clear why this would be so beneficial from algorithms. So let's go back to theory a little bit. But first let me show you a result of a simulation for first price auctions. Here is a first price auction which both agents have a value of one for the item. You see that in the simulations they seem to be playing by the quarter of their value. So they're shading their bids aggressively.
02:14:42.034 - 02:15:08.042, Speaker D: This is sort of the collusiveness that we talked about in this other paper with Andy. And as soon as they get minimum bid to win information, agents are able to converge to Nash equilibrium immediately. Almost immediately. Now, to explain this, let me go back to the theory. Let me show you one particular dynamical system. This is the dynamical system again of the prisoners dilemma in which both agents prefer to cooperate.
02:15:08.106 - 02:15:08.814, Speaker B: Okay.
02:15:09.012 - 02:16:14.302, Speaker D: Then their payoff is going to be given, is going to evolve according to the following derivatives, which have different learning rates. The action of cooperation is a much higher learning rate given by one minus epsilon halves, which is the fraction of time that the agent plays cooperation and instead for defection only epsilon halves, only a small fraction of time, the agent is actually going to play the faction and is going to learn about that action. So this implies that these estimates, QC and QD, the perceptions are going to have different persistence. However, when we start providing counterfactual information to the agents, agents are now suddenly able to compute their payoff in every single period for every single action. So in particular they no longer need to run experiments because now it's obvious what would have happened had I played something else. Now in the context of the model these learning rates become equal because these fractions in front, they don't need to be there. I don't need to think about what would have happened only when I run the experiment.
02:16:14.302 - 02:16:59.806, Speaker D: I can think about it all the time. This is equalizing learning rates across actions and in the paper this is theorem three. I promise I have a theorem two somewhere in there that all agents having the same learning rate is enough to guarantee convergence onto dominant strategy games. For a large class of algorithms that I call greedy reinforcers, this comprises Q learning. But many others, many algorithms that have Nord Grat for example, are well known in the computer science literature. This gives me a sufficient condition to guarantee that spontaneous coupling will not occur. If agents are using these counterfactual information to update their estimates, then they cannot run into spontaneous coupling.
02:16:59.806 - 02:17:42.138, Speaker D: Their estimates are updating at the same rate and so this cannot occur. In particular, this is suggesting some scope for market design. This is an example in which market policies can influence the learning rate. So can the designer avoid spontaneous coupling and how can they do it? So if I have some time I'm going to go on with this application. Well, implementation in general thinks about truthful implementation in dominant strategy. This is the most common type of implementation problems we have. And what I've shown you so far is that this is not enough when algorithms are playing.
02:17:42.138 - 02:18:25.162, Speaker D: Algorithms don't even understand the concept of dominant strategy and may fail to converge onto those. And so what we would like is a form of learning robust strategy proof mechanisms where all the learning agents are reporting truthfully. In particular, we talked about feedback. We talked about the fact that the designer can provide some information about the world to help them compute their counterfactuals. For example, providing feedback about what would have happened had you played something else, had you reported a different type, let's say. In an imperfect information setting this is equivalent to revealing some information about market participants. All of this happens exposed.
02:18:25.162 - 02:18:57.270, Speaker D: So this doesn't affect incentives within period. But of course this is a repeated game. We are worried about spontaneous coupling but revealing information may be worsening outcomes in other senses. Giving too much information to players may incentivize collusion of a different type. And in particular, we may worry about privacy. We don't want to reveal everyone's types all the times that may be a little bit concerning for other reasons. So what we're going to look for is mechanisms that reveal only as much information as necessary to these algorithms to make them converge.
02:18:57.270 - 02:19:35.010, Speaker D: And of course, the first statement I have is, well, there exists a learning robust strategy proof mechanism. This is a simple one. Just provide everyone with all of the information at all times. This is clearly enough to compute your counterfactuals. It requires kind of a lot of thinking in principle because think about a complex DCG mechanism, it may not be even easier given all the types to compute the allocation. There's a better way to do this that is also more private. And the most private learning robust strategy proof mechanism, according to some order on the amount of information that gets provided, is a menu description.
02:19:35.010 - 02:20:42.762, Speaker D: So this fully characterizes the most private learning robust strategy proof mechanisms. Now, what are menu descriptions? Menu descriptions essentially provide the agent with the outcome that he secured by reporting his type ti as well as a set of outcomes, defined as the set of outcomes that he could have implemented had he reported a different type. Now, menu descriptions in practice essentially look like prices, if you think about an auction minimum bid to wins are exactly menu descriptions. I'm giving you a price for the object, and that's enough to completely describe what you could have implemented had you reported differently. This speaks directly to a conjecture in a paper by David Parks in the early 2000s which claims that prices may be the right way to help algorithms learn. It appears to be the case here that prices are exactly the type of information, the sufficient statistics that the agents need to be able to converge into good outcomes. And it seems like I have a little bit of time, so yeah, question.
02:20:42.816 - 02:21:12.626, Speaker B: Sorry. If I'm putting up an algorithm, I can ignore information that the architect gives. So I guess a key question would be, if I'm playing against other algorithms that are ignoring that information, is it a best response for me to take the information that you give me from the menu description using that? Because that would seem to be necessary to get anything like this.
02:21:12.728 - 02:21:34.054, Speaker D: Very good. So the answer to that question a little bit depends on the discount factor that you have. If you make your algorithm more sophisticated, so you give it this information, it's going to be able to exploit the other algorithms for quite a while before they can catch up in the limit. If one of us uses this information and everybody else doesn't, we still converge onto dominant strategy.
02:21:34.182 - 02:21:34.860, Speaker B: Okay.
02:21:35.470 - 02:21:46.182, Speaker D: That said, this becomes essentially a coordination problem. Coordination problem in the space of algorithm designers where this is we're back to normal game theory where we can think about sort of incentives in the traditional.
02:21:46.246 - 02:22:20.140, Speaker B: Way I love your point of frank but it the most fundamental result is economics signals in market settings that involve and so I think that it is great excitement. Thank you. Thank. Now.
02:22:35.940 - 02:23:05.340, Speaker D: Likely that's right. So so in fact you can see this exactly in the coupling world coupling kind of disappears when there's too many agents exactly. Because of this effect where too many agents are essentially not synchronizing well enough. Right. And it doesn't take much to disappear in the sense that if one of us sort of finds out that he can play defection for a while that sort of kills all type of convergence towards cooperation.
02:23:09.200 - 02:23:39.430, Speaker B: In some sense, it's like a form of delegated pricing to Asia which have different incentives. And in substance, here you delegate operating which has two agents which have a different rationality than they don't think about health effect. So I don't think you're like these responses or policy indications by giving information too much. There firms really see them.
02:23:43.340 - 02:23:46.036, Speaker D: I'm not sure exactly what your claim.
02:23:46.068 - 02:24:02.524, Speaker B: Is, but they benefit from agents ignorant and people will observe that really came.
02:24:02.562 - 02:24:20.228, Speaker D: To you again perfect. I agree with you. So in a way we're moving back to a world of rational agents in which the decisions of which algorithms to make is the one that is relevant. Right? So this paper speaks to at least the second part of that game in which condition on the algorithm where do we end up?
02:24:20.314 - 02:24:20.660, Speaker B: Right?
02:24:20.730 - 02:24:51.870, Speaker D: And that helps us make predictions even in the game, in the rational agents version of that game. But I think in general there are sort of settings in which algorithms are well known. We all know what people use. There are settings in which this is very unclear and the algorithms are very sophisticated. So online auctions algorithms tend to be much more sophisticated than for example in online retail pricing where those algorithms are sort of known and very simple. We're talking like undercut your opponent by Epsilon and something like that.
02:24:54.800 - 02:25:25.560, Speaker B: When they were running sacrifice auctions on ad exc there was worry that the ad exchanges were potentially misrepresenting the threshold price and I guess noble that misrepresenting what the counterfactuals would have been had to take the difference. And so I guess there's a question here about sort of critical communication, right? If you're the designer and you make claims about contrafactuals, in what sense is it possible for the various algorithmic agents to verify those claims?
02:25:26.220 - 02:25:34.830, Speaker D: I have a hard time speaking about this given my current employer but we can maybe talk about the soft line.
02:25:36.720 - 02:26:07.864, Speaker B: Yeah, but since you talked about AI MBA maybe smaller or less modern the question if you talking about learning algorithms, why wouldn't AI algorithm try to get you the cooperative outcome by having very.
02:26:07.902 - 02:26:32.792, Speaker D: Well so that's absolutely a concern. That concern speaks a little bit to the extent of willingness to collude right. That requires intent. I'm trying to design an algorithm that has some form of memory that is trying to exploit the repeated game structure. Right. These algorithms don't even do that. So this is sort of the simplest form of algorithm that you can think of, and the well intentioned one, in a way.
02:26:32.792 - 02:27:06.488, Speaker D: And yet collusion still happens. Right. There's plenty of evidence that when algorithms are able to, in fact, implement acidly collusive strategies, they do because they're trying to maximize profits and they're pretty good at it. So they will try and they will manage. But this is one way in which Zagraman doing this exactly as sort of smarter or less smart people, right. Like, these arguments have some limits on what their rationality allows them to do, and they're using those limits to do better than rational agents. But we can fix this.
02:27:06.488 - 02:27:11.684, Speaker D: Essentially, it's easier to fix this than to fix sort of tacitly collusive outcomes.
02:27:11.732 - 02:27:27.920, Speaker B: In a way. Antigen algorithms, your investigative mean, chose.
02:27:30.660 - 02:27:30.976, Speaker A: To.
02:27:30.998 - 02:27:41.220, Speaker B: Think about also a space. There's an intermediate experimentation algorithm.
02:27:44.280 - 02:28:03.690, Speaker D: Exactly. So there's definitely the case that with different experimentation policies, different things can happen. Common experimentation policy is sort of a logit experimentation. Right. And that tends to look a lot sorry. It tends to look a lot like yeah, exactly.
02:28:06.060 - 02:28:06.810, Speaker B: Yeah.
02:28:09.660 - 02:28:10.810, Speaker H: Must go out.
02:28:22.340 - 02:28:23.084, Speaker B: That's right.
02:28:23.142 - 02:29:03.330, Speaker D: So that paper it's definitely related. That paper shows that they don't converge to Nash in a slightly different sense, in the sense there that there's some games with cycles, and those cycles are what tends to create problems. But we have results where algorithms do converge onto dominant strategy games. Even simple algorithms, in fact, converge to dominant strategy games. This is an example of a single algorithm in which the choice of parameter matters and the fact if we're not careful about choosing experimentation correctly, or if we're not careful about thinking about debiasing our own estimates, then something like this can't happen.
02:29:08.020 - 02:29:08.624, Speaker B: That's right.
02:29:08.662 - 02:29:36.094, Speaker D: So the observationally speaking, this is going to look exactly like a tacitly collusive outcome in which we observe sort of high prices for a while, and then there's going to be a defection period where both players charge low prices and almost immediately go back to high price. So that's exactly the same as in their baseline, I think. So we get exactly the same results in our baseline.
02:29:36.142 - 02:29:36.450, Speaker B: Yeah.
02:29:36.520 - 02:29:50.006, Speaker D: It's slightly different than the Calvano paper, for example, because in that paper, people have states so they can play effectively collusive equilibrium. They're playing the strategies that refer back to the repeated game.
02:29:50.188 - 02:29:51.160, Speaker B: Thank you.
02:29:51.850 - 02:30:37.782, Speaker D: With the time remaining, I think I can quickly go over one other application of this. Most of these papers on algorithmic collusion speak about price collusion or bid collusion, right. Where agents are trying to price collude on bids. I want to show you here that this spontaneous coupling is an incentive. It doesn't have to be about the type of collusion that's happening and so one example here is going to be how these agents are able to sustain what I call market splitting, or market division if you want, which is a canonical problem in Collusion. Okay, it's backwards. Alice, Net, and bob.com
02:30:37.782 - 02:31:01.038, Speaker D: are playing in a platform game. They're trying to advertise on this platform. And there's three keywords. There's a keyword, A, which is matched to Alice for which Alice has a click through rate of one. And there's a keyword, B, which is matched to Bob for which Bob has a click through rate of one. Alice also wants to advertise on Bob's keywords, but she has a much lower click through rate. There's about 0.2.
02:31:01.038 - 02:31:22.078, Speaker D: And then there's a middle keyword, M, which is sort of indifferent between the two. So both of them have a 0.6 click through rate on this one. Now, this game, the value for each keyword, for advertising on each keyword is drawn according to your uniform one, two. And then the winner's payoff is the click through times value minus payments.
02:31:22.174 - 02:31:22.820, Speaker B: Okay.
02:31:23.670 - 02:32:00.900, Speaker D: In this game, there is a dominant strategy, which is to bid on all keywords. It effectively makes no difference because this is a second price auction. So the platform is running a second price auction. There's no point in me withholding my bid on a given keyword. Turns out that if algorithms are choosing which keywords to bid on, sometimes they will converge onto bidding on all keywords, in effect, 60% of the time, but about 38% of the time. Instead, they converge on splitting the market, where Alice is bidding only on Alice and the middle keyword. And Bob is bidding only on the B keyword and the middle keyword in particular.
02:32:00.900 - 02:32:07.646, Speaker D: On those equilibrium, those study states, let's.
02:32:07.678 - 02:32:12.738, Speaker B: See, on those study states, you see.
02:32:12.904 - 02:32:44.698, Speaker D: The blue line here? The purple line, I guess, is the perception they associate to bidding on their own keyword and the middle keyword. And you can see that the other perceptions are rising over time. So they do realize that they would be better off by bidding on every keyword. But as soon as they do, symmetrically, that drops. As soon as one of them starts bidding on the other person's keyword, the other person responds by biding on their keyword too. And that reverts them back to biding on their own keywords only. So this is another example of spontaneous coupling, a game with more actions.
02:32:44.698 - 02:33:37.870, Speaker D: Here they're choosing from a set of bids, combinatorial sets of four. Four or bids for choices of actions. And they managed to collude on their own keywords only. So with that, let me conclude I don't know what's going on here. Okay, well, for the conclusion today, I hope I've shown you that with continuous time techniques, I'm able to characterize equilibrium of these algorithms. I'm able to effectively say something about what's happening in the world of algorithms. And I'm able to show why feedback is so important, why the ability to compute counterfactuals is so important to the algorithms and how this is an effective market design tool when we're facing these problems.
02:33:38.400 - 02:33:39.390, Speaker B: Thank you.
02:34:22.690 - 02:35:26.126, Speaker C: Okay, thanks for having me. I'm presenting joint work with Nikhil Alex Murring, who's a student at the MIT Sloan School, and Pranav Rashbukar, who is a faculty member at the Harvard Medical School. So, as you can see, this is on human machine collaboration. We think that this is an exciting space where there are many open engineering or design challenges that have to take into account the constraints imposed by human behavior. So we hope that it finds some interest in this crowd despite the lack of a market. So I'm sure many of you have heard claims that AI is going to completely change many aspects of our economy and for this reason oftentimes referred to as a general purpose technology like the steam engine and electricity. But what some people say is going to be different, that it's going to be much more targeted at high skilled professions.
02:35:26.126 - 02:35:29.540, Speaker C: So things that skilled people can do.
02:35:30.070 - 02:35:30.820, Speaker H: And.
02:35:32.630 - 02:36:27.320, Speaker C: This is summarized for our application by the following quote from Joffrey Hinton. Joffrey Hinton is one of the three godfathers of modern AI, and he said in 2016 that we should stop training radiologists because it's just completely obvious that within five years, deep learning is going to do better than them. So he actually regrets having said this. So he has taken this back in subsequent interviews. But it's too good not to use it here. But it's perhaps fair to say that the sort of current consensus view is better summarized by this quote by Curtis Langlotz. He's also an AI researcher and a radiologist who says that radiologists who are going to use AI are going to replace those who do not.
02:36:27.320 - 02:37:56.290, Speaker C: And this is also kind of the presumption under which the FDA currently approves of, which there are already many of these approved AI devices are meant to be used by clinicians, as opposed to act autonomously and directly implement suggestions. So in thinking about whether or not humans and machines should work together and if so, how, it's sort of helpful to remind us what are some of their relative strength and weaknesses. So, first of all, algorithms are trained to perform a narrowly defined predictive task, at least that's true and has been true until very recently. And they therefore essentially operate in a vacuum. But humans can sort of draw on other knowledge around them. In this sort of clinical setting, they may have additional knowledge because they have interacted with a patient or with the patient's family, and they can use this sort of non systematic data to reach a better decision. But we also know, we have ample evidence, in fact, that humans do not combine different sources of information effectively.
02:37:56.290 - 02:38:50.062, Speaker C: Also, unlike machines who once trained, have an essentially zero marginal cost of predicting or deciding there's going to be a positive time cost. Involved for human work. And this is especially true in our setting where we're dealing with radiologists. These are some of the highest paid specialists in the US healthcare system, for instance. And so their time is valuable. So we're going to ask is contextual information, is sort of non systematic data valuable? How do humans use different sources of information and combine them? These are, of course, quite general questions that you could ask in many contexts. But we in particular, I want to sort of figure out what does all of this mean, sort of in this context of designing the collaboration between humans and machines.
02:38:50.206 - 02:38:50.466, Speaker B: Right.
02:38:50.488 - 02:39:06.006, Speaker C: And so this leads us then to our third question. In light of our findings for one and two, how would we want to design the human AI collaboration? We have a sort of specific design space. We think that there are many other.
02:39:06.028 - 02:39:07.960, Speaker B: Ways to look at this.
02:39:10.190 - 02:39:50.278, Speaker C: So what are we doing exactly? We are conducting an information experiment with professional radiologists so they read x rays. For us, these are going to be retrospective cases. So these are not ongoing clinical cases, just to be clear. And they sort of involve what I called thoracic pathology. So this is basically everything kind of that's happening at the chest level. So we're going to vary their information. So in particular, we're going to either give them access to a state of the art AI technology or not.
02:39:50.278 - 02:40:06.678, Speaker C: And we're going to vary whether or not they have available this contextual information that in a typical setting they would have at their disposal to decide cases, but on which the machine, for a variety of mostly privacy reasons, is not yet trained.
02:40:06.774 - 02:40:07.420, Speaker B: Okay.
02:40:09.150 - 02:41:25.324, Speaker C: Then we are going to measure how they combine these different sources of information and we will compare this relative to compare this to a Bayesian benchmark. And then third, we're going to ask if you always can get the I signal essentially for free and if human cost, human time, is valuable, costly, how would you, based on di, signal, delegate to different modalities which includes giving it to only the human giving it to only Di or to the human with access to Di, which, of course, the effectiveness of which will depend on how well humans use the eye's information. So here's the outline. I'll talk about a simple decision problem that sort of helps frame and guide some of the empirical analysis. Then I'll tell you something about the experiment treatment effects. Then we'll really try to kind of interpret what's happening without treatment effects. We'll again look at this through a lens of a model of patient updating.
02:41:25.324 - 02:41:56.416, Speaker C: And then at the end, I'll come to the optimal delegation problem. So this is quite simple. There is a decision maker. So think of a doctor who has to decide whether or not, let's say, to implement a treatment. So it's a binary decision, a either zero or one. And there's an unobserved binary state of the world, Omega. Think of the presence of a disease and this decision maker wants to essentially with the action, match the state of the world.
02:41:56.416 - 02:42:35.212, Speaker C: So I want to implement the treatment when the disease is present. And if there is a mismatch between the state of the world and the action, then there's some decision loss incurred and this decision loss may depend on whether or not my error is a false positive or false negative. So you could easily imagine that one is more costly than the other. And in order to make this decision, this decision maker will rely on information. So she may rely on her own information she call se. So the signal of the expert and that of the AI, which is this.
02:42:35.266 - 02:42:36.690, Speaker A: Is which we call SA.
02:42:38.180 - 02:43:53.840, Speaker C: And in our setting we will sort of let this joint distribution of signals be what sort of naturally occurs here, which is basically what is the joint distribution, given that we are looking at the problem of somebody reading an x ray and have this AI that's trained on x rays. So this fits obviously the setting of medical diagnostics as well, this type of model. So this kind of problem has a very simple cutoff solution if the conditional ODS ratio is larger. So conditional on the signal is larger than the relative cost of a false positive to false negative, you want to implement, let's say, the treatment. But note that here we have written instead of Pi, we have written this as P, this ODS ratio. So again, we do allow for the fact that this decision maker may not hold correct beliefs given available information. And we want to know how different are they from sort of the true conditional distribution of Omega.
02:43:53.840 - 02:44:44.330, Speaker C: And so then based on this policy, you get some expected diagnostic value which we call V. We'll come back to this when we go to the optimal delegation problem. So let me tell you now about our experimental design. So at the face of it, it's quite simple. So at a high level we have a simple two by two factorial design where in one dimension we vary access to the AI and in the other dimension we vary access to clinical history. Again, this is information that typically radiologists would be using, but on which the eye is not trained. It turns out radiologists are good subjects for these kinds of experiments.
02:44:44.330 - 02:45:40.250, Speaker C: They do not normally interact with patients. So in fact, when we were sort of designing this experiment, we had a lot of interaction with radiologists and some of them, let's say, work for New York hospitals out of Florida. So it's not totally uncommon. And so what this allows us is to get quite close to the type of controlled decision experiment that you would strive for in economics, but at the same time sort of maintain an environment that's quite natural to their normal workflow. So we think that has some advantages. Where do we get these radiologists from? We are hiring them through teleradiology companies at a peace rate, much like US hospitals would do. So these are the companies that typically provide services to US hospitals.
02:45:40.250 - 02:46:52.340, Speaker C: So something that we want to be very clear about here is that we are defining the ground truth for this decision problem. So remember, Omega to be the majority of five board certified radiologists from Mount Sinai. So this is a consensus based ground truth. And so what this means is that if we had this sort of technology and it would sort of widely diffuse, that we could potentially move the healthcare system or these types of diagnostic decisions from getting one opinion to getting, let's say, one kind of average doctor's opinion to five sort of top of their field opinions. So that's kind of the benefit of this type of technology. But note, you could of course think that there are other types of settings where you do in fact have an independent grant truth that is not based on anything that humans can do. So for instance, maybe you have some independent diagnostic test that's available and the eye is trained on that and so the eye could in principle know things that humans never can.
02:46:52.340 - 02:47:27.790, Speaker C: So that's true but much more difficult than you may think at first and that's due to the selective labels problem. So if you think about it, let's say we have a simple diagnostic test that's cheap it's non invasive, then why look at an image in the first place? Why not directly base the decision on the test itself? On the other hand, if the test is either costly or invasive, then you would typically only order it if the image already is indicative of that being necessary.
02:47:28.130 - 02:47:28.638, Speaker B: Right?
02:47:28.724 - 02:47:39.554, Speaker C: So that leads to a selection problem that's really hard to get around unless you sort of get into unethical territory or you really have to come up.
02:47:39.592 - 02:47:40.180, Speaker B: With.
02:47:42.550 - 02:47:59.030, Speaker C: A good data set or a good setting where this ground truth is not selected. So we therefore go with this sort of convention in the medical AI literature and using this consensus based ground truth.
02:48:01.370 - 02:48:06.286, Speaker B: Yes. Naveen, just a clarification. Did you say whether did the radiologists.
02:48:06.338 - 02:48:08.090, Speaker I: Know that they're in an experiment?
02:48:08.430 - 02:48:12.730, Speaker C: Yes, they absolutely know this and they know that these are retrospective cases?
02:48:15.630 - 02:48:19.020, Speaker B: Yes how are they so.
02:48:20.750 - 02:48:49.400, Speaker C: Everybody gets a peace rate. So this is essentially we just hired them the way a hospital would do, they get a piece rate per case but then we also in the experiment have an arm. So basically an extra treatment dimension where we give explicit incentives for accuracy to some of them. Turns out I'm not talking about those in the presentation today, they don't matter that much. So exanti we didn't know that. But it turns out that explicit incentives for accuracy do not seem to matter much.
02:48:50.970 - 02:48:59.110, Speaker B: Where are the cases that you're showing them? They can talk other than they know these cases somehow.
02:49:00.350 - 02:49:10.080, Speaker C: I mean, there's no chance they can know those cases. They are taken from Stanford Medical. That's where one of our collaborators previously worked.
02:49:12.850 - 02:49:20.530, Speaker B: Other questions, could you give the magnitude of incentives and how we would sort of compare the reputational incentives?
02:49:23.030 - 02:49:28.926, Speaker C: So the incentives for accuracy are quite large, I don't remember the exact details.
02:49:28.958 - 02:49:30.262, Speaker A: But it would close to double their.
02:49:30.316 - 02:49:32.520, Speaker C: Payment if they get it correct.
02:49:36.650 - 02:49:39.480, Speaker B: Yeah, I hope this answers the question.
02:49:40.090 - 02:49:41.180, Speaker C: Other questions?
02:49:42.830 - 02:49:46.218, Speaker B: Okay, so let me tell you a.
02:49:46.224 - 02:50:14.878, Speaker C: Little bit more of how we actually do this. So as I said, radiologists participate remotely. So they do so through an interface that we explicitly developed for this experiment in collaboration with radiologists. The main way that it's different from their standard clinical practice is that instead of getting a written radiological report, we are going to elicit probabilities of the presence of different types of diseases.
02:50:14.974 - 02:50:15.714, Speaker D: Okay?
02:50:15.912 - 02:50:59.966, Speaker C: So they basically enter those with a slider where they may or may not have access to the AI prediction and then we also separately ask them for a follow up decision. So do you recommend to follow up on this case, let's say with a treatment or an additional test? And we were going to use those follow up decisions to back out their preferences for false positives and false negatives. So I will come back to this later on. Again, we want to separate the prediction from the decision task. So let me now talk more about the details of these treatment dimensions. So first I said we give access to the algorithm. What does that actually mean? So they get access to the probabilities that are produced by checksburg.
02:50:59.966 - 02:51:48.718, Speaker C: This is a state of the art neural network, network based classifier that's trained on 250,000 chest x rays, gives probabilities for 14 chest pathologies and it has in prior academic work shown to match or exceed the performance of board certified radiologists. These were radiologists at Stanford. And so the way this was established is you see here, this graph from this publication. What this shows you is the receiver operating characteristics curve. So this is the true positive rate against the false positive rate. You would like to be kind of in the northeast here because that gives you a higher true positive rate while holding false positive rates fixed. And so you can think of this kind of as an economist best as a production possibility frontier.
02:51:48.718 - 02:52:24.154, Speaker C: So depending on your preferences for false positives and false negatives, you get sort of different tangency points on this PPF and can basically implement different types of cutoff rules. I've shown you this simple economic framework earlier and so what you can see here is that these three radiologists that participate in this experiment, they're lying below this curve. So for these specific preferences that were applied here, you could basically by moving them to the PPF, could either reduce the false positive rate by holding the true positive rate fixed or vice versa?
02:52:24.202 - 02:52:24.910, Speaker B: Adam.
02:52:27.890 - 02:52:29.870, Speaker C: Yes, same ground truth.
02:52:35.920 - 02:52:36.860, Speaker B: Laura.
02:53:03.730 - 02:53:37.814, Speaker C: That'S a great question. So again, the question was that usually there's sort of a division of labor between a clinician who actually takes care of the patient and the expert who provides the information. That's something we were very aware of when designing this experiment. We actually explicitly mention in the instruction that we know that there's oftentimes this division of labor. We want them to basically give us the decision that they would base on their report. So that's a great question and we were sort of very aware of this.
02:53:37.852 - 02:53:48.026, Speaker B: When we were designing it. Okay, so here a bit more detail.
02:53:48.208 - 02:54:10.294, Speaker C: On this sort of contextual information. So what is this? These are vitals and labs in addition to sort of these little snippets here, which are called indications. So this gives demographic information on the patient. So here, this is a woman 30 years of age. She has a history of hypertension. She's evaluated for cardiomegaly. So this is an enlarged heart.
02:54:10.294 - 02:54:18.380, Speaker C: So it's a type of pathology for which there is, in fact, no sort of heart biological marker that would tell you this is an enlarged heart.
02:54:20.510 - 02:54:21.260, Speaker B: Okay?
02:54:21.870 - 02:54:43.778, Speaker C: I told you we had this sort of simple two by two factorial design. It's, in fact, not quite as simple. We had to deal with a number of challenges when designing this experiment. The first one, as you may imagine, is power. We're dealing with pretty expensive subjects. We have to pay them $10 a case so we cannot sort of run arbitrary number of treatments. And we had to sort of think about how to deal with this.
02:54:43.778 - 02:54:56.850, Speaker C: And the second is that for our comparison to a Bayesian benchmark, we want to ideally have the same radiologist read the same case both with and without access to the AI.
02:54:56.930 - 02:54:57.510, Speaker B: Okay?
02:54:57.660 - 02:55:41.954, Speaker C: So now when I sort of teach my undergraduates intermediate micro, we sort of see that the fundamental problem of causal inference is in the way here, right? So they may remember something about the case. They may anchor on the eye signal. So we have to deal with this as well. So first, what we do is we are mostly relying on within subject variation. So we're conducting what is called a within subject design where all radiologists in a random sequence go through the different information conditions. This assures that we are balanced on radiologists unobservables and increases power. We also have an initial sort of clean what's called across comparison because the sequence is randomized.
02:55:41.954 - 02:56:32.078, Speaker C: Okay? So we can kind of compare the across treatment effects. So that within treatment effects and reassuringly, they look quite similar. Secondly, so we have radiologists read the same case under different information conditions, but we are including a so called washout period of two weeks where they're only re encountering the same case under different information conditions after they waited for two weeks. So they basically come back a number of different times and then in the end will have seen each of the x rays under a different information condition. And so hopefully this sort of alleviates any concerns about them remembering a case. Intuitively you would think that they don't remember cases. They spend about two minutes or three minutes per case looking at an X ray.
02:56:32.078 - 02:57:08.938, Speaker C: So they do a lot of them, as you may imagine, in a few weeks time. And we also have some tests in the paper that suggest that they don't remember cases. Okay, so let me talk about some data. So first of all, we want to compare how well do those radiologists do compared to the AI. So here I'm showing you the histogram of the radiologist's performance compared to the performance of the AI according to two different measures. The first is the RMSE root mean squared error and the second is the AorOc. So this is the area under the receiver operating characteristics curve.
02:57:08.938 - 02:57:37.280, Speaker C: So that's basically how far is this sort of curve to the northeast. Both measures tell us approximately the same thing, which is that di is better than about two thirds of radiologists on average. So this would suggest that two thirds of radiologists should just simply follow the prediction of the AI. Okay, so let me now.
02:57:39.250 - 02:57:41.710, Speaker B: Are you able to track whether the AI.
02:57:45.090 - 02:57:47.440, Speaker C: We do that, yeah. And that's actually in fact.
02:57:49.890 - 02:57:50.800, Speaker B: Two minutes.
02:57:56.210 - 02:57:56.960, Speaker G: Yeah.
02:57:58.770 - 02:58:33.310, Speaker C: So, so this so we find they spend more time with the AI. So the treatment effect of providing the AI lets them spend more time and the same is true for clinical history. Interestingly. So we have explored this a little bit. How much is sort of time spent? How does it change as a function of sort of the disagreement? We didn't find as much sort of systematic evidence there as we thought we would, but yeah, that's a great suggestion.
02:58:36.370 - 02:58:40.750, Speaker B: Of EA minimizing.
02:58:42.290 - 02:58:54.950, Speaker C: So this is just a classifier and as I sort of shown you, you can basically implement any type of preferences for a given classifier. Right? So it doesn't have an objective. We can give it the social objective.
02:58:55.850 - 02:59:07.180, Speaker B: It just provides a probability score that's calibrated. So just if it says 12%, it means 12% of those cases are going to be popular. Ian how often?
02:59:14.910 - 03:00:09.406, Speaker C: So in some sense, given what we assume, we can test it directly, right? Because we define it to be this way. We think that this is actually necessary for many types of diseases because again, there is no independent ground, truth for actually a large fraction of diseases that we are looking at here. So we think that sort of the space of pathologies where you have to do it this way is nontrivial. There are other settings where sort of, let's say we look at cancer and a patient develops cancer down the line where this may be easier to test. And again, this would be something else that's interesting to explore and may lead to sort of different kind of joint signal structures. Okay, so let me show you the treatment effects. So here you can see on the y axis a measure of the deviation.
03:00:09.406 - 03:00:51.230, Speaker C: So this is a measure of performance, and it's the deviation of the radiologist's prediction from the ground truth. And so here lower is better. And then on the x axis, I'm showing you the treatment indicators. And what you can see here is that clinical history improves their decision significantly, but AI does not. In fact, the point estimate suggests that they do slightly worse with access to AI. And there's no significant interaction effect between the two either. One reason this may happen is because the radiologists simply ignore the ice prediction.
03:00:51.230 - 03:01:24.494, Speaker C: But this is far from true. So here we do the same exercise, but this time on the y axis, we see the deviation not from the ground truth, but the deviation from the ice signal itself. And what you can see is that when they get access to the eye signal, they move towards the eye signal. The disagreement between their assessment and the eye goes down. Okay, so they're making use of the signal. No significant effect for clinical history or the interaction. So it seems like we have a puzzle at first blush.
03:01:24.494 - 03:02:11.654, Speaker C: So we know that the AI is better than two thirds of the radiologists. We know that the radiologists are following the eye signal, but it doesn't improve their decisions on average. So this graph results this puzzle. Here we are looking now at conditional treatment effects, where on the x axis you see a partition of the AI signal space. And on the y axis you see again the deviation from the ground truth, this measure of performance that we are using. And so what you can see essentially is that when the AI is quite certain that either the disease is present or the disease is absent on average. I mean, here we don't have a lot of data.
03:02:11.654 - 03:02:28.686, Speaker C: Most of the data lies here. But on average, they seem to perform better with access to the AI. When the AI is quite certain, when the AI is uncertain. Again, remember, this is sort of calibrated. When it sends a probability of 0.5, it doesn't quite know.
03:02:28.788 - 03:02:29.198, Speaker B: Right.
03:02:29.284 - 03:02:38.190, Speaker C: Then radiologists seem to do worse on average by getting more information from the AI algorithm.
03:02:38.270 - 03:02:49.090, Speaker B: Okay. Okay, so we now, Jacob, say again.
03:02:53.800 - 03:03:35.952, Speaker C: So the liability question is currently quite difficult because again, in our setting, I would say that it wouldn't make sense for them to think that they can resolve themselves of their liability by following the AI. Because again, most of AI devices are sort of not meant to be autonomous or they're meant to assist clinicians in their decisions. But that's an interesting question, sort of in the long run, what happens with liability concerns as we have these devices, whether people just start sort of blindly following following them?
03:03:36.006 - 03:03:50.800, Speaker B: Yeah, it's a good question. Just do they usually have information if they're not giving treatment recommendations?
03:03:52.200 - 03:04:35.316, Speaker C: No. So they typically have this information that's typically kind of transmitted through the EMR system in the hospital that they just see this directly. Not to say that this couldn't happen in the long run. I mean clearly we know we can train AI on text. What stands in the way here is really sort of a privacy bottleneck because you have to basically go through all these written notes and strip them or sort of privacy revealing information. So that's kind of again, this is not something that is sort of a roadblock in the long run, but just currently these types of systems are not.
03:04:35.338 - 03:04:42.260, Speaker B: Trained on this measurement for deviation.
03:04:45.400 - 03:04:47.936, Speaker C: We can look at different measures in appendix.
03:04:47.968 - 03:04:49.940, Speaker A: We do all the different measures in fact.
03:04:50.090 - 03:04:54.872, Speaker B: Yeah, okay, so let me now talk.
03:04:54.926 - 03:05:28.310, Speaker C: About sort of the interpretation of these treatment effects. Okay. So here we're going to make use of a model by Grether. So think about first the case here where B and D equals one. What this is doing it's decomposing this decision relevant ODS ratio. Remember at the beginning I showed you this simple decision framework where you were comparing the ODS ratio to the relative cost of false negatives over false positives. And we can kind of decompose this in log form into two terms.
03:05:28.310 - 03:06:36.116, Speaker C: So this is a decision maker who has again her own information se, gets some new information from the AI and these measures of B and D, to the extent that they deviate from one, tell us whether a decision maker over or under updates to new information SA or over or under relies on her own information. So we give this some terminology. So for instance, when you over update to the I signal we say that you're automation biased and when you under update we say that you're automation neglectful. And then similarly with own information there's a third type of mistake that they could be making which is they could be neglecting the fact that conditional on the ground truth, the signal of the AI and their own signal is not independent. So in a sort of more simple parametric model could think of a correlation neglect here. So in other words, I may not be accounting for the fact that the AI gives me redundant information. So I'll not go into all the details.
03:06:36.116 - 03:06:39.084, Speaker C: But I want to tell you a little bit about sort of what we do with this.
03:06:39.202 - 03:06:44.924, Speaker B: So first we show theoretically that in.
03:06:44.962 - 03:07:44.028, Speaker C: Some cases even though the decision maker is biased, it's still optimal to give them information because it still moves them closer to the Bayesian prediction. So in fact, somebody who is only automation neglectful but exhibits no other type of mistake would still benefit from getting more information from the AI. In all other cases there are signal constellations where when you give radiologists access to the eye signal, they're doing worse. We then show how we bring this equation empirically to the data. We have to test models against each other, so we have a testing framework to select the right model. What do we find? So first we find that they are automation neglectful. So this would sort of suggest by itself that you still want to give them information, but we already know based on the treatment effects that they're doing worse.
03:07:44.028 - 03:08:19.608, Speaker C: So there must be something else going on. And so the explanation here is that they're also engaging in this signal dependence neglect. They're not accounting for the fact that their own information is to some extent redundant with the AI. So the bottom line here is that these potential gains from having radiologists work together with AI undercut by their tendency to not use the information optimally. And so I want to show you this in a more intuitive way. So there's a lot going on here, but I want to sort of walk you through it slowly. So first you see here in black are our conditional treatment effects.
03:08:19.704 - 03:08:20.300, Speaker B: Okay?
03:08:20.450 - 03:08:41.170, Speaker C: So you see, this is just, again, our data and we compare this to other hypothetical treatment effects that you would get from another decision maker, let's say abesian. Okay, how would those treatment effects look for a Bayesian decision maker? Well, a Bayesian decision maker would be doing much, much better.
03:08:41.540 - 03:08:42.348, Speaker B: Right.
03:08:42.534 - 03:09:31.440, Speaker C: So what this suggests is that first, the gains from having these signals combined optimally are large. What if you have a decision maker who doesn't make this mistake of signal dependence neglect and only under response to the AI? In that case, you still get an improvement on average, regardless of what the AI signal is. What you really need is the signal dependence neglect to replicate these treatment effects here, where they're sometimes doing worse on average in the middle. So that's sort of what gives us this shape that we are finding. So you kind of need both of them together. So let me now look at the data in a slightly different way. Instead of looking at the treatment effects, I'm now looking at absolute performance.
03:09:31.440 - 03:10:07.420, Speaker C: But otherwise it's the same. On the x axis, I'm showing you this sort of signal partition and then on the y axis, the deviation from the diagnostic standard. This here is the human's accuracy, just the data. You see our treatment effects here, but not as clearly as before. But you see that when the eye is confident. So it's either saying the case is not there or the case is there with high confidence. Then radiologists get better on average.
03:10:07.420 - 03:10:42.490, Speaker C: In the middle they get worse. So you may be tempted to say that, okay, so when the signal is low, we give them access to the AI signal. When the signal is high, we give them access to the I signal, but not in the middle. But just based on a comparison of these simple averages to the I itself, we see that this cannot be true even if you only care about performance by itself. Okay, and so why is that? Well, if AI improves their decision so when it's confident, the eye is even better.
03:10:43.260 - 03:10:44.010, Speaker B: Okay.
03:10:45.340 - 03:11:28.856, Speaker C: And so the only bucket where we sort of find that AI improves their decision but is worse than the combination is this bucket here from zero six to 0.8. You see this has pretty large standard errors here. So this sort of is kind of paving the way for our full delegation problem. So this was just a simple look at conditional averages and so now we want to do this in a more full fledged way where we are looking at arbitrary partitions of the signal space. And we also want to take into account that human time cost, I mean human time is costly and want to sort of commensurate between time cost and diagnostic quality.
03:11:28.958 - 03:11:44.510, Speaker B: Adam yeah.
03:11:45.360 - 03:12:25.172, Speaker C: So a few responses to this. So first of all, they are exactly these kinds of technologies that provide probabilities out there in the wild. And 40% of our radiologists have some experience with AI. radiologies of all specialties is one where they're actually thinking. If you look at the academic literature, they're thinking about probabilities and sort of how to not surprisingly this is a diagnostic job. So you would think that kind of within the spectrum of doctors. These are doctors who are more accustomed to thinking in probabilities.
03:12:25.172 - 03:12:48.304, Speaker C: But of course this is not to say that in general they have the same sort of problem synthesizing different sources of information as the average human being. So I think that's a good point. But that's not to say that this is not just sort of at the same time a fundamental problem that stands in the way of radiologists using information. Right, so that's exactly in some sense.
03:12:48.422 - 03:12:55.220, Speaker B: What we are after here. Yeah, you're giving the human access to the AI.
03:12:59.720 - 03:13:34.770, Speaker C: That's another great point. I mean this goes beyond what we are doing in the optimal delegation, but that's certainly a sort of more enriched kind of design that you could think about. If you sort of go down this path, you have to also think about what would this do to potential incentives of the human providing information to the AI. So they know that later on it's going to be sort of combined in some optimal form and so maybe that introduces shirking. So there are other interesting questions that come up with these alternative designs. But that's a great suggestion that we have thought about. Again, this would be another interesting treatment arm to run.
03:13:34.770 - 03:14:05.320, Speaker C: Okay, so let me sort of talk a little bit about the details of how we are doing this here. So again, we now want to minimize some loss. It's a combination of decision loss and time cost. And again, the idea is we. Always get the AI signal for free. And then we basically implement we give this to the radiologists, the radiologists with access to the AI or fully automate.
03:14:06.160 - 03:14:06.910, Speaker A: So.
03:14:09.440 - 03:14:44.280, Speaker C: What quantities do we need to do this? We need their time cost as a function of the AI signal. So this comes back to Eric's question. We have measured this directly in the experiment. We get their opportunity cost of time based on what we pay them, which is about $4 per minute. And then we need to commensurate the time cost with the decision loss. So what we are using here is our preference estimates based on their recommendations to follow up on a case or not. We find that the relative cost of a false negative over a false positive is about four.
03:14:44.280 - 03:15:25.664, Speaker C: So intuitively you would think that missing a cancer is worse than going through an unnecessary treatment. And so that lines up with what the observational literature has found on these relative costs. And so then we need to this only gives us a relative cost. It doesn't sort of translate this into dollar value. So what we do to translate this into dollar value is we basically just trace out four different social costs of a false negative. How would this implementation look like? Okay, so that's what I'm showing you next. And we want to contrast basically Bayesian humans with human humans.
03:15:25.664 - 03:15:30.036, Speaker C: Okay. So what would you do if you had a Bayesian human?
03:15:30.218 - 03:15:32.884, Speaker B: If you had a Bayesian human, right.
03:15:32.922 - 03:16:09.164, Speaker C: A Bayesian always uses information optimally. And again, what does this show you? It shows to you the social cost of a false negative. And as a function of that, the share of cases that either go to the human, the Bayesian human with access to the AI, or the human by herself. Okay. And what you can see is you need a pretty high social cost of false negative to get humans involved in the first place. You have to justify their time cost. And you get about 50% of cases decided by Bayesian humans, and they are going to be using the AI because they're using the eye optimally.
03:16:09.164 - 03:16:19.408, Speaker C: There's only so small sliver of cases that's going to be decided by humans without access to the eye. And that's because they take a little bit longer when they have access to the AI.
03:16:19.504 - 03:16:26.870, Speaker B: Okay. Value of higher power.
03:16:27.260 - 03:16:36.830, Speaker C: I mean, this is just one disease. So I have a hard time sort of translating this to you. Want us to go even higher?
03:16:38.000 - 03:17:11.190, Speaker B: Yeah. Expert spend 10 hours striking. Yeah. The question is this radiologist is probably going to go unpick it for months or just probably. Yeah, that's what it cases you're x ray that looking at pneumonia, hypertension or large heart.
03:17:12.840 - 03:18:04.468, Speaker C: Not looking at depends on how bad the pneumonia is. Okay, so what happens with human humans? So here again, we have sort of the same pattern. You want that pretty high social cost of a false negative to have a human involved, but you almost never want to give it to a human with access to the AI. And that's because there's a decent share of cases where they're doing worse with access to the eye, and because they spent more time doing so, they're not using the eye optimally. Right. So that means that a lot of cases go either to the AI or to the human only, but not to the human with access to AI. What we conclude from this now, we don't want to say that this is the last word on this.
03:18:04.468 - 03:19:30.530, Speaker C: This depends on many things. But sort of the current picture from this is that it looks like humans are more likely to work alongside rather than with AI. This means that there are benefits to training, and we have to sort of think about how can we overcome these sort of general forces that work against humans working with AI. Yeah, so that's that's another super interesting sort of design question, which is that, how do you think are humans strategically responding to these delegation decisions, which we're currently completely abstracting away from? Of course, this is just based on our treatment effect implementation. But if you put humans into such a system, they may know that they're deciding the more critical cases, they may increase effort or who knows? Okay, so let me then wrap up. So we have studied human AI interaction in a setting of radiology, which is sort of seen as a canonical kind of profession for this type of automation. We have shown that we give them access to a state of the art AI that's on average better, but they're doing worse with this additional information.
03:19:30.530 - 03:19:51.528, Speaker C: They spend also more time. This makes the delegation problem or this design problem nontrivial. And we currently find that optimally, most cases wouldn't be decided by human with access to AI. And in general, we think, and I think this came already through in the discussion here, that there are many interesting sort of design questions in this space.
03:19:51.614 - 03:27:40.080, Speaker B: So thanks so much. We have lunch now till about 130 in the adjacent room. We just but imagine that using the AI, I guess some other to yeah, chess is like that too, but it takes time to sort of get this frontier more and more. The only time you like mother. Yeah, maybe. Yeah. Because otherwise really but you couldn't but we are using approaches, I think, to like is look like and you see that on the it that follow us.
03:27:40.080 - 04:15:46.090, Speaker B: You hey.
04:15:50.200 - 04:15:51.830, Speaker I: Oh, this is.
04:15:55.410 - 04:16:17.160, Speaker B: Load money. Oh.
04:16:20.330 - 04:16:27.340, Speaker I: I did some crypto consulting at some point, and at that point, when asked second factor stuff.
04:16:48.090 - 04:16:48.694, Speaker B: Perfect.
04:16:48.812 - 04:16:50.230, Speaker H: I think it's so cold.
04:16:52.250 - 04:16:53.814, Speaker I: What temperature do you like?
04:16:53.932 - 04:17:01.130, Speaker G: And not this temperature. It's like five degrees below my temperature. Even Yaka wears a jacket.
04:17:03.070 - 04:17:03.482, Speaker B: What?
04:17:03.536 - 04:17:04.406, Speaker G: He said it's so cold.
04:17:04.438 - 04:17:13.866, Speaker B: Even you wearing a jacket, it's very cold. Perfect. There's no risk of falling asleep.
04:17:13.978 - 04:17:14.942, Speaker G: Yeah, that's true.
04:17:15.076 - 04:17:16.670, Speaker H: You're not going to fall asleep.
04:17:26.270 - 04:17:27.914, Speaker B: That's the paper you gave?
04:17:28.112 - 04:17:29.420, Speaker G: Yeah, it's the same.
04:17:53.310 - 04:17:53.698, Speaker B: All.
04:17:53.744 - 04:17:54.340, Speaker H: It.
04:18:16.050 - 04:18:37.350, Speaker B: Probably needs some help. I'll see if I can help. Thanks. I'm tempted to just to stick this in there but I don't want to make any mistake. Lee yeah, right yeah. Okay so it's online, I believe. What is this? It's a USBC.
04:18:37.350 - 04:19:24.602, Speaker B: I see. Oh, it's both. So here, I think this is where you put it in. That was a USB all right. N-B-E-R. Yeah, that's it. Just if you could copy copy I'll put it on the desktop, it's usually the safest spot.
04:19:24.602 - 04:19:50.360, Speaker B: Right. Thanks for having me. Oh no, happy to paste. This is you? Yeah. Perfect. I'm not the first one? I don't think so. Okay.
04:19:50.360 - 04:28:26.314, Speaker B: I think it's ravi. Jagadesen first. Okay. It good talk. Yeah. You the same artist, it's all people don't it can be our site and that way you can get exactly. There we are.
04:28:26.314 - 04:28:52.340, Speaker B: Now wait, what happened here? Let's see. So share screen, share screen this one is loading. Yeah.
04:28:56.390 - 04:28:57.886, Speaker I: But I guess the clicker cannot.
04:28:57.918 - 04:30:28.790, Speaker B: Be seen on the clicker as it's not the hazel point. Yeah, no about yeah laptop. So we're now going to have three back to back talks. It'll be a marathon, the sessions on auctions and.
04:30:31.480 - 04:31:04.784, Speaker I: So thanks. The title of the paper I'm going to be presenting is auctions with withdrawal rights. A foundation for uniform price. And this is Joint Work with Alexander Heberman who's sitting right over there and who's a graduate student at Stanford. So this is a paper about auctions with correlated private values. One issue that arises in this setting is that because of correlation, different types of bidders will have different beliefs about.
04:31:04.822 - 04:31:07.776, Speaker B: What other people's values are and as.
04:31:07.798 - 04:31:53.730, Speaker I: A result, Bayesian optimal mechanisms. If you think about the revenue maximization problem of a seller, the optimal mechanisms are going to try to screen bidders based on their beliefs. So one way of kind of making that work is to require bidders to take a side bet about what other people are going to bid in order to participate in the mechanism. So that's how things work in theory. In practice things are a bit different. One would expect values to be correlated even in the private value setting because the independence assumption is a kind of knife edge case. And yet we don't see mechanisms that involve side bets being used instead.
04:31:53.730 - 04:32:42.450, Speaker I: Selling mechanisms tend to be more simple. One might see mechanisms like second price or uniform price auctions used instead. So in our view this disconnect between optimal mechanisms in theory and practical mechanisms poses a concern for using the standard Bayesian mechanism design approach to optimal auctions in the presence of correlation. And the goal of this paper is to provide a foundation for one of these simple mechanisms. So for a uniform price auction that applies in the correlated value setting and it's going to be based on a restriction on how on the seller's ability to enforce bidders commitments to buy exposed after the auction is run.
04:32:43.300 - 04:32:44.544, Speaker B: So to be a little bit more.
04:32:44.582 - 04:33:43.232, Speaker I: Precise, the main result of our paper is that if bidders in the auction can withdraw from the auction exposed. So that is after learning the outcome, after learning whether they've won and how much they're supposed to pay, then the uniform price auction is going to become optimal even when values are correlated. And this result is going to hold exactly in a large market limit where the number of agents and the number of units for sale both go to infinity at the same rate and it also holds approximately infinite market. So before getting into our analysis, I want to talk a little bit about the motivation for this key assumption which is that bidders can withdraw from the auction exposed. I think there's two ways to interpret this. One is a literal interpretation. So you could imagine that bidders or someone who buys a good is able to go back and return it.
04:33:43.232 - 04:34:34.272, Speaker I: That's actually like a legal right for internet sales, for example, in the European Union. I think a second interpretation is a little bit is where the withdrawal right is a little bit more implicit. So if you think about the sale of a complex asset by auction, the seller is going to need to make some representations regarding what the asset is and its condition which the winner of the auction will want to verify. And that's typically done exposed because the verification is cost. But in practice if the asset is complex enough, some of the representations are going to be a bit wrong and therefore challenging those representations can give the bidder a channel to effectively withdraw expo. So to reneg on their commitment to buy.
04:34:34.326 - 04:34:57.080, Speaker B: Yes, initial indicative bidding.
04:35:00.960 - 04:35:14.160, Speaker I: I think I can give you one example which many people in the room might have experienced where this is done exposed, which is for example in the housing market. But I'm happy to talk about this more offline.
04:35:16.180 - 04:35:17.760, Speaker B: By complex assets.
04:35:18.180 - 04:36:13.900, Speaker I: I mean houses are just an example of it. Maybe you can talk a little bit more about settings. So I don't want to claim that the possibility of withdrawal is there in all auctions. So one thing that you might think is that a particular consequence of withdrawal rights is what drives this optimality result. So one thing that withdrawal rights imply is that the seller can't implement outcomes that are not exposed individually. Rational, you can't end up charging the bidder, charging a winner more than their value, but that turns out not to be what drives the optimality of the uniform price auction. So if you imagine you restrict the seller to incentive compatible and exposed individual irrational mechanisms, actually there's mechanisms that raise your higher revenue than the uniform price auction.
04:36:13.900 - 04:38:11.490, Speaker I: So what actually drives the optimality of the uniform price auction here is the interaction between the withdrawal right and an incentive constraint and we are by no means the first to point out that there's such an interaction and in fact I think there's a paper by CompTIA and Jehyll that explains very nicely what this interaction is. I'm just going to read you a quote from that paper, just that in the presence of withdrawal rights when considering a deviation an agent takes into account the fact that he can opt out if things turn out badly. So when you can withdraw exposed there can be more of an incentive to deviate and the additional incentive constraints that come from withdrawal rights are what help ensure the optimality of the uniform price auction and therefore give a foundation for uniform price auctions and settings with correlation. So I want to say a little bit about related literature. There's a large literature and mechanism design problems with correlated information and I think one issue that that literature has focused on is this question about whether there are mechanisms that extract full surplus for the seller. I think the difference between what we're doing and most of that literature is we're thinking about a different question, we're thinking about what's the form of the optimal mechanism and can you write down a model in which the optimal mechanism takes a practical form and other foundations have been given for uniform price auctions based on robustness? And the difference here is we do a fully bayesian analysis of the seller's problem assuming withdrawal rights but we do need to assume make a large market assumption in order to get a foundation for uniform price auctions and other people have also thought about various other mechanism design problems with withdrawal rights. So for example, a certain dynamic mechanism design problems we're thinking about a static problem where there's no information arrival later in the game.
04:38:11.490 - 04:39:05.984, Speaker I: So in the remainder of the talk I'll start out by describing the model. Most of the talk I'm going to spend on giving an example to illustrate the key forces and then I'll talk about the main theorem in full generality. So let me start with the model. So there's going to be a common state s which is going to be between zero and one, which you should think about as measuring the level of demand for the good that's being sold. And I'm going to assume common prior. And there's going to be a continuum of bidders, each of which have unit demand and they're going to have private values theta that are drawn from some distribution f that can depend on the state and the values are going to lie in some compact interval. We're going to assume throughout that the distribution of value satisfies the strict monitor and likelihood ratio property.
04:39:05.984 - 04:39:54.032, Speaker I: So in higher states the distribution of values is higher in the likelihood ratio and the source of correlation here is that the distribution of values depends on the state. So if I as a bidder learn that my value is higher. I'm going to believe that the state is higher and therefore that everyone else also has higher value. And there's K units of a homogeneous indivisible good available for sale where K is less than one. Let's say there's a unit mass of agent. This may be a little bit of an unusual way to think about an auction model. In the paper we microfound this continuum setting as a limit of auctions where there are N bidders and K times N units of the good for sale, where the number N of bidders gross large.
04:39:54.032 - 04:40:07.620, Speaker I: And it's been shown in a paper by Jackson and Kramer that there's a non trivial role for thinking about auction design. I guess the other thing I need to tell you about is what exactly we mean by withdrawal rights.
04:40:09.240 - 04:40:10.228, Speaker B: And this is going to be a.
04:40:10.234 - 04:40:55.904, Speaker I: Bit the way we're going to formally set things up is by changing the incentive constraint a little bit. So we usually say that a direct mechanism is based in incentive compatible. If for every type theta and every report that type could make theta prime, the expected utility from reporting your true type theta to the mechanism is at least the expected utility from reporting theta prime. So we're going to think about a class of mechanisms from which bidders don't want to withdraw. So we're going to say that a mechanism is withdrawal proof if the same condition as Bayesian incentive compatibility is satisfied.
04:40:56.032 - 04:40:56.980, Speaker B: But where?
04:40:57.130 - 04:41:28.610, Speaker I: When you think about deviating, the way you calculate your utility is rather than looking at just your expected utility from reporting Theta Prime, you take the expectation of the max of the utility you would get from reporting Theta Prime and staying in the mechanism and zero, which is the outside option that you get if you withdraw. So the interpretation here is that after learning your allocation and payments, so after learning your outcome, you can withdraw freely. And if you choose to do so, you don't get the good, but you don't have to pay.
04:41:30.900 - 04:41:31.312, Speaker B: Okay?
04:41:31.366 - 04:42:19.570, Speaker I: So this max zero is the key little twist that's going to give us the foundation for uniform price. So again, we're by no means the first to think about withdrawal proofness, but because I suspect this condition may not be familiar to many people in the audience, I'm just going to spend a few minutes talking about how it relates to more standard incentive compatibility and individual rationality constraints. One thing to note is that withdrawal proofness is going to imply basin incentive compatibility because we're allowing for the possibility that you misreport and don't withdraw. It also implies exposed individual rationality with probability one, because if you can walk away exposed, there's no way to force you to pay more than your value. For example.
04:42:22.400 - 04:42:23.516, Speaker B: It turns out that the.
04:42:23.538 - 04:43:24.556, Speaker I: Converse is not true. So there are Bayesian incentive compatible, exposed individual irrational mechanisms that are not withdrawal proof. And that's because of this interaction between the withdrawal right and the incentive constraint. So there's a possibility of engaging in double deviations where you misreport and then withdraw if things don't work out. I suspect some people in the audience at this stage are trying to come up in their head with an example of a mechanism that is basin incentive compatible and exposed individual irrational but not withdrawal proof. And you're going to have a hard time coming up with that example just because the standard exposed individual irrational auction mechanisms that you would write down are all withdrawal proof. Now, when you're thinking about a mechanism design problem, though, the distinction between withdrawal proofness and exposed individual rationality is important because there are some complicated mechanisms that look strange that satisfy exposed individual rationality but not withdrawal proof.
04:43:24.556 - 04:43:27.730, Speaker I: I'm going to give you an example of one such mechanism in a few minutes.
04:43:28.740 - 04:43:30.210, Speaker G: Any questions about them?
04:43:32.820 - 04:43:40.260, Speaker I: If not, let me go into an example which I hope is going to illustrate the key issues at play in our analysis.
04:43:40.600 - 04:43:42.612, Speaker B: Can I ask you a clarification? Yeah.
04:43:42.666 - 04:43:55.640, Speaker A: So I guess if the mechanism is stochastic, you're going to take that in the outer expectation. When you say utility from reporting theta prime, that's sort of exposed utility.
04:43:59.600 - 04:44:03.900, Speaker I: Yes. The utilities here you should interpret as exposed utilities.
04:44:05.040 - 04:44:06.892, Speaker A: Everything stochastic is happening down around.
04:44:06.946 - 04:44:07.550, Speaker B: Yeah.
04:44:12.610 - 04:44:49.840, Speaker I: Okay, so let me give you an example. So here there's going to be half a unit of the good for sale. So you can sell to half of the bidders rather than a continuum of states. There's going to be three states and values are going to be distributed on some intervals going to be zero to 84, such that the market clearing prices in the three states are 21, 36 and 56. So you might say, why am I giving you these numbers? It turns out that the distributions needed to come up with these market clearing prices basically come from point masses at the bottom and the top and uniform distributions in the middle. I'm not going to show you exactly what the distributions are. What's going to matter is just what the market carrying prices end up being.
04:44:49.840 - 04:45:36.940, Speaker I: And the question we're going to think about is what's the optimal mechanism subject to if the seller is forced to implement an exposed efficient allocation of the good. So you have to sell in the end to the bidders who have the highest values, but you can choose design the payment rules however you want. And the way I'm going to show you mechanisms is I'm going to depict them using menus. So when a bidder comes to the mechanism, they're going to be given four choices about what they can do. They can either end up never buying the good, they can end up buying the good only if the state is zero. They can end up buying the good if the state is zero or half or they can always buy the good. And their payments in the three states are going to depend on which of the menu options they choose.
04:45:36.940 - 04:46:31.450, Speaker I: So, just to give you an example of a mechanism, let me show you what the menu description of the uniform price auction is here. So for that, if you choose to never buy the good, you never need to pay. If you choose to buy only in the lowest state, you just pay the market filling price of 21 in the lowest state. If you choose to buy in each of the lowest two states, you're going to pay the market clearing prices of 21 and 36 in each of those two states. And you don't pay anything but don't get the good in the highest state. And if you choose to always buy the good, then you're going to pay the market selling prices of 21, 36 and 56 in all three states. I guess the starting point here is to think about what the optimal mechanism is if you just impose in the standard Bayesian way of doing things with a Bayesian incentive compatibility constraint and an interim individual rationality constraint.
04:46:31.450 - 04:47:13.500, Speaker I: So here there's many optimal mechanisms. I'm just going to show you a menu description of one of them. So this mechanism should look a bit weird for agents who never want to get the good. There's nothing strange, they just never pay. But if you want to buy the good, you're going to receive a payment from the seller of 357 in the low state and make payments to sellers in other states. And in the case in which you want to buy the good only in state zero, you actually make a big payment to the seller in state one half when you're not getting the good. And there's some higher payments for types that want to get the good more often.
04:47:13.500 - 04:47:55.910, Speaker I: So here basically what's going on is the bidders who are ending up getting the good are taking a bet with the seller about whether the state is going to be zero or one half. That's I think one way to interpret what's going on here. So one OD property of this mechanism is that the payments are really large sometimes. So these types who want to get the good only in the lowest state are going to have to pay the seller in the middle state where they're not getting the good. And the higher types end up at least getting the good whenever they have to make a payment. But in the middle state they end up paying more than their value. So this mechanism is far from exposed individual irrational.
04:47:55.910 - 04:49:03.334, Speaker I: I think one natural question you might ask is what is the optimal mechanism subject to an exposed individual rationality constraint? So if we strengthen interim individual rationality to exposed individual rationality, again, there's going to be multiple optimal mechanisms. I'm just going to give you an example of one of them. So here, things are going to become a little bit more clean in that in the case in which a bidder wants to buy the good just in the lowest state, you're just going to pay the market clearing price in that state. And if you want to get the good in the lowest two states, you pay the market clearing prices in those two states. So here for the first three items in this menu, pricing is uniform. The place where things are a bit strange is what happens if a bidder says they want to get the good in all three states. And in that case, what you want to do, what the seller will want to do is to pay such bidders 31 and a half in the lowest state and charge above the market killing price in the middle state to charge 56 rather than the market killing price of 36.
04:49:03.334 - 04:49:32.920, Speaker I: And this mechanism is going to raise more revenue than the uniform price auction. It's also exposed to individually rational. No one ever losers never pay and winners never pay more than their value. I think in our example, there isn't strict monotone like the ratio property and as a result, the optimal mechanism is not unique. That said, this -31 and a half that payment is unique and that's the kind of interesting payment here.
04:49:36.180 - 04:49:37.056, Speaker B: So what.
04:49:37.078 - 04:50:07.884, Speaker I: I'm going to claim is that actually this mechanism is not withdrawal proof. So if you think about an agent who can withdraw exposed, there's going to be some who want to do something weird. So there's one other thing that is not explicitly written in the menu, but that bidders are able to achieve by using a combination of making one of the choices in the menu and then withdraw, which is one thing. You can do is you tell the seller I'm going to buy the good, and I want to buy the good in all three states. So I kind of report that my.
04:50:07.922 - 04:50:10.504, Speaker B: Value is high and then I withdraw.
04:50:10.552 - 04:50:13.950, Speaker I: Exposed if the state is anything but the lowest state.
04:50:14.720 - 04:50:16.316, Speaker B: And what I as a bidder am.
04:50:16.338 - 04:51:31.200, Speaker I: Going to be able to achieve by doing that is I'm going to get the good only in the lowest state, that's the only state in which I haven't withdrawn, but I'm going to get this payment of 31 and a half in that state. So here I get the good in some state and I get paid in that state, which is very nice for me as a bidder. So this mechanism is vulnerable to double deviations where a bidder can make a combination of a misreport and withdrawal. So if you think about bidders who you would want to get the good only in the low state, rather than just doing that directly and having to pay 21, they would rather report a high value withdraw exposed and get the good end of payment along with it. So this mechanism is not withdrawal proof and it turns out that the optimal withdrawal proof mechanism here is going to be a uniform price auction. So you won't give this discount make a payment to a bidder in any state. And I want to emphasize that optimality is important to be able to get a foundation for uniform pricing.
04:51:31.280 - 04:51:32.744, Speaker A: So there are actually lots of other.
04:51:32.782 - 04:52:03.490, Speaker I: Withdrawal proof mechanisms and some of those even yield lower expected revenue. So, for example, if you think about a mechanism that implements equilibrium in a pay as bid auction, that's going to give strictly lower revenue than the uniform price auction. So that was shown in this large market context in this paper of Jackson and Crane. So here the point is that the seller's problem, even when restricted to withdrawal proof mechanisms, is a nontrivial one.
04:52:03.940 - 04:52:04.416, Speaker B: I think.
04:52:04.438 - 04:52:56.770, Speaker I: Before I get into the formal statements of the theorems, I want to give you some intuition for why the uniform price auction is optimal in this setting. So let's start with the uniform price auction and think about how the seller could change payments a bit in order to increase their revenue. The key force here is this linkage principle. So values here are affiliated. That's what this monotone likelihood ratio condition is bank. And so what that tells us is that if the seller wants to raise revenue, what they want to do is to link the payments of winners to other people's values. And here, because there's a continuum of agents, what the seller really wants to do is to link the winners payments to the state.
04:52:56.770 - 04:53:59.990, Speaker I: So that means basically to steepen the dependence of the payments of winners in the state. So here I'm going to focus on kind of steepening the winners payments in the low states. That's not without loss, but this is just for intuition. So what the seller might want to do is to charge the bidders who are always getting the good a little bit more in the middle state. But you can't just do that on its own because that's never going to be incentive compatible. If some bidder was kind of indifferent between buying in the bottom two states and buying in all three states, they are now just going to want to not buy in the high state to avoid being charged a surcharge. So if you want to kind of steepen payments in a way that preserves local incentive compatibility, so preserves the property that the bidders first order conditions are satisfied, you also need to offer a corresponding discount, say in the low state.
04:53:59.990 - 04:54:02.596, Speaker I: To be a little bit more concrete.
04:54:02.628 - 04:54:03.210, Speaker B: Here.
04:54:06.860 - 04:55:10.270, Speaker I: If you want to steepen the payments of higher types in the state, you're going to need to offer these same higher types some discounts in the lower states. But this is a problem because here we're going to end up with incentivizing lower types to withdraw. So if you think here about the type, if I charge the higher types only a little. Bit below 21 in the low state, then no one is going to want to pay 21 in that state effort. What you could do, these low types were just supposed to get the good only in the low state for 21 would rather pretend that their values are high, withdraw in the high states and benefit from the discount. The idea here is if you're going to offer higher types a discount in the lower states, then the lower types are going to want to pretend that their values are high in order to take advantage of the discount. And when there's withdrawal, they don't need to get the good at higher prices in the states in which they're not really interested in getting the good.
04:55:10.270 - 04:56:02.620, Speaker I: So there's an important gap here between the intuition and what one would actually need to get approved, which may not be obvious here because of the three state structure. So one issue here is that if you're thinking about this type, a type Theta whose payments we are changing and the type theta Hat, who might want to mimic theta, those two types are going to have different beliefs about states in general and so they can evaluate discounts differently. Like you could imagine offering something that the higher type thinks is a discount, but that the lower type doesn't find as attractive. And so when you take into account that heterogeneity in beliefs, this type of intuition isn't really going to work. So our actual proof doesn't really work along the lines of this intuition. It's a little bit more formal logic, but I think this intuition illustrates the key force that's driving nervous.
04:56:05.380 - 04:56:14.494, Speaker B: Yeah. No.
04:56:14.532 - 04:56:40.310, Speaker I: So here you should think about this is remember, this is a private value setting. So you should interpret the state here as what other people's values are and what the large market assumption is buying us is that conditional on the state, there's no uncertainty about the empirical distribution of values. But here you shouldn't. What the state here is representing is other people's values.
04:56:41.050 - 04:56:42.280, Speaker B: What would it be?
04:56:47.130 - 04:56:50.550, Speaker I: Well, you wouldn't want to do that for a simple mechanism.
04:56:51.690 - 04:56:53.606, Speaker B: That's the thing, right?
04:56:53.708 - 04:57:15.060, Speaker I: I think that one, that one nice property of the uniform price auction, which is kind of the one that's the focal one in this talk is that you actually don't want to do these double deviations involving withdrawal. So I don't think you should expect to see this type of behavior in practice for these types of auction formats yes.
04:57:20.070 - 04:57:23.010, Speaker B: Are withdrawal rights exercise.
04:57:25.830 - 04:57:40.730, Speaker I: So the way we're thinking about this is if you are going to exercise the withdrawal right in equilibrium, the seller is going to do it for you. That's the revelation principle type of logic and we are restricting to mechanisms for which there's no withdrawal exercise in equilibrium.
04:57:41.070 - 04:57:41.946, Speaker B: To make this work.
04:57:41.968 - 04:57:44.060, Speaker I: The private values assumption is important.
04:57:48.990 - 04:57:50.810, Speaker B: Sometimes not sold.
04:57:51.550 - 04:58:26.482, Speaker I: So we're assuming I haven't given you the statement of the result, but we're going to assume exposed efficiency. So in particular the good always has to be sold. That's not essential for the results. If you allowed the seller to withhold the good, one would just need to add reserve pricing and we can make the same type of analysis. So I think at this point I should state the result. Then we can talk more about other questions that people might have. The result is under an assumption on the correlation structure which I'm going to call regular affiliation.
04:58:26.482 - 04:59:10.840, Speaker I: I'm going to tell you exactly what it is in a moment. The expected revenue of the uniform price auction is at least the expected revenue of any other exposed efficient withdrawal proof mechanism. So exposed efficient means you need to implement an exposed efficient allegation of the quit. And our interpretation of this result is that providing a foundation for the uniform price auction based on withdrawal rights and in the paper we also give a uniqueness result. So provide a sense in which no mechanism other than the uniform price auction has this property. And one side benefit here is that the optimal mechanism here is dominant strategy incentive compound. That's not something we imposed, it's a result.
04:59:10.840 - 05:00:13.904, Speaker I: The way we formulated withdrawal proofness was in a bayesian way. So let me talk, I guess in order to complete the statement of this theorem, I have to tell you what assumption was and the assumption is going to be a little bit technical. So the assumption is an assumption on the mixed partial derivative of the log of the density of values. So that's like some measure of the correlation between the state and people and how the state affects the distribution of value. And what this condition says is that for any type theta and any state s, if you take this degree of affiliation and you integrate it over all types, where you fix the state and you multiply that by the integral of the degree of affiliation over all states where you fix the type that has to be at most the degree of affiliation at the type and the state.
05:00:13.942 - 05:00:15.330, Speaker B: That we started out with.
05:00:15.860 - 05:01:23.156, Speaker I: This assumption may seem rather strange. The reason that I want to state it in full generality here is just to highlight that this is not like a functional form assumption on densities. The way I want you to interpret this assumption is as saying that the degree of affiliation between values or between values and the state is neither too high nor too erratic. I'm going to give you a little bit of a characterization of distributions that satisfy this regular affiliation condition to try to argue for this interpretation. So one thing is it turns out that regular affiliation is going to imply some bound on how much people's beliefs, how much different types beliefs about the state can differ. So what it implies is that if you think about two states SNS prime and think about different types trying to do a likelihood ratio test to distinguish between these two states, then the likelihood ratio of one type and the likelihood ratio of another type can differ by.
05:01:23.178 - 05:01:26.104, Speaker B: At most, a factor of e. This.
05:01:26.142 - 05:02:30.910, Speaker I: Is some sense in which regular affiliation is constraining how much the distribution of values can vary with the state. There's also a partial converse. It turns out to this result which is that if the distribution of values comprises a full exponential family like in the econometric sense, the converse will also hold. So regular affiliation becomes equivalent to this bound on how much likelihood ratio tests or likelihood ratio test statistics can vary across times. So just for a reminder, this full exponential family assumption is going to include lots of the distributions that we usually use. So for example, it allows for truncated and unjuncated normal log normal distributions, beta distributions, lots of these types of distributions. Regular affiliation does not require that values, distributions of values come from a full exponential family.
05:02:30.910 - 05:03:16.056, Speaker I: But regular affiliation does require something more than just that, the degree of affiliation not be too high. And that's what I'm interpreting as affiliation being required not to be too erratic. So I should say we do need some assumption like regular affiliation in order to guarantee the optimality of the uniform price option. We have done some numerical work as well to see what happens when this assumption fails. So for example, when there's a high degree, very high degree of correlation between values. And what turns out to happen in our examples is that the uniform price auction still does very well. So it generates something like greater than 90 or often greater than 95% of.
05:03:16.078 - 05:03:20.380, Speaker B: The optimal revenue, but it's no longer exactly optimal.
05:03:25.510 - 05:04:15.250, Speaker I: So let me say something a little bit about how we prove this theorem. So there's two key challenges that arise in this setting. One is that revenue equivalents fails and this is because of the presence of correlation. So here for example, the uniform price auction and the pay as bid auction implement the same allocation of the good but give different revenues. A second issue that arises is this first order approach. So the approach of relaxing bidders incentive constraints to their first order conditions is not going to work. We're going to need to keep track of other parts of the incentive constraint than the local or first order incentive compatibility constraint.
05:04:15.250 - 05:05:05.490, Speaker I: And the reason for that is something I think you can kind of see in the example. In the example I was always talking about these very low types who were thinking about pretending to have a very high value. And if you think about the relevant incentive constraint, that's a non local upward incentive constraint. So where a low type is pretending to have a much higher value than their true value. So in this proof, we're going to need to do two things. One is unlike most proofs in mechanism design, in addition to keeping, we're going to need to come really face to face with the payment rule of the mechanism. And second is we're going to need to think about these non local upward incentive constraints.
05:05:05.490 - 05:06:16.210, Speaker I: So as a result we can't really apply many of the standard tools from mechanism design and actually in some ways the proof isn't really that interesting. What we do is we basically do the only thing you could hope to do in this setting, which is you look at, figure out which constraints are important, figure out what LaGrange multipliers to put on those constraints in order to construct a saddle point of a LaGrange. So the proof is basically by bare hands. I'm going to say a little bit more about the proof than just that. So the relevant constraints that we're going to need to keep track of are of three types. The first one is the standard local incentive construct which is going to take a little bit different form than it would take in independent private values because of the presence of correlation but it's something that one can formulate in this context as well. The second class of incentive constraints we're going to need to track or we're going to need to think about are these non local upward incentive constraints where for deviations that involve misreporting and withdrawal.
05:06:16.210 - 05:06:32.718, Speaker I: So the relevant deviations are where some type theta reports that their value is theta prime, which is above theta. And then they're going to withdraw if the market clearing price exceeds theta. The example to keep in mind here is that if you're thinking about a.
05:06:32.724 - 05:06:35.806, Speaker B: Bidder in a second price auction when.
05:06:35.828 - 05:07:26.910, Speaker I: You can withdraw, the bidder is indifferent between biding their true value and bidding any higher value. And the reason is the worst thing that can happen if you bid above your true value is that you get the good and you have to pay too much. But that's a setting in which you can just walk away. And so that's why these non local upward incentive constraints bind for a second price auction and they bind for a uniform price auction for a similar reason. And last is we need to keep track of some of the individual rationality constraints. So the key point is that all these three constraints bind for a uniform price auction. So these are incentive constraints that hold with equality for a candidate optimal mechanism and we kind of know that those are the constraints we'd have to focus on because of complementary slack.
05:07:26.910 - 05:07:51.266, Speaker I: So the way we do the proof is we just construct LaGrange multipliers on these constraints to make the uniform price auction maximize the lagrangian of the seller's problem. So we're just building a saddle point of lagrangio. And for local incentive constraints one can do this in almost a standard way. So by using something similar to the multipliers that you'd use in the independent.
05:07:51.298 - 05:07:55.030, Speaker B: Private value context it's the non local.
05:07:55.100 - 05:08:54.118, Speaker I: Incentive constraints that cause us a lot of trouble. So there we aren't actually able to write down a formula for them, but we can define them implicitly as a solution of an equation, that's of this type of type of equation called a linear voltera integral equation. So the point here is that the multipliers on these non local incentive constraints depend in a fine way on distributions of values and in a way that's so fine that we are not able to even characterize these multipliers explicitly. So although the optimal mechanism is simple to describe, the multipliers that show that it's optimal are not easy to describe. And the place where we need to use this assumption on affiliation. So this regularity assumption is to ensure that the multipliers on the non local incentive constraints are non negative. And that's because these non local incentive constraints are inequality constraints.
05:08:54.118 - 05:09:23.186, Speaker I: So the LaGrange multipliers on them always have to be positive, otherwise we wouldn't actually have a valid solution of the dual problem. That's the way the proof works. One thing the proof does not give you is a recipe for solving for an optimal mechanism subject to withdrawal proofness constraint. Like in general, this proof is kind of by Hooker crook trying to construct LaGrange multipliers. Given that we know what the optimal.
05:09:23.218 - 05:09:27.778, Speaker B: Mechanism I think that's all I have.
05:09:27.784 - 05:09:29.090, Speaker I: To say about the proof.
05:09:32.390 - 05:09:34.020, Speaker B: Just to understand whether.
05:09:37.270 - 05:10:02.194, Speaker I: Yeah, so I think the key here is in terms of restricting the form of uncertainty that there is, if you're thinking about a finite market, there's kind of two sources of uncertainty. I guess if you just imagine a version of this model where conditional on the state values are drawn, IID from some distribution, then even conditional on the state, there's a second source of uncertainty.
05:10:02.342 - 05:10:06.462, Speaker A: Which is about what people's values actually.
05:10:06.516 - 05:11:12.590, Speaker I: End up being in distribution. And I think the intuition here is that there are additional side bets that you could imagine engaging in that involve both the state and the distribution. But the key source, I think the key issue that comes when thinking about finite markets is that the form of uncertainty at the aggregate level is much more complicated. Okay, so I guess to close, I want to talk about one extension. So one thing that you might be concerned about, about this foundation per uniform price auction is that withdrawal in practice might be costly. So you might lose, for example, lose a deposit if you withdraw. What I want to argue is that although the uniform price auctions is no longer going to remain exactly optimal, it's still going to remain approximately optimal in a sense that I'll formalize in a moment.
05:11:12.590 - 05:11:29.004, Speaker I: But let's suppose that a bidder can lose a deposit of up to delta if they withdraw. Then if you want to write down a version of withdrawal proofness for this setting, the way to formulate it would be to define this condition that we call delta withdrawal proofness, which is defined.
05:11:29.052 - 05:11:30.460, Speaker A: Just like withdrawal proofness.
05:11:30.540 - 05:12:14.816, Speaker I: But here, when evaluating the utility of a deviation, rather than taking the max of the utility you get from staying in the mechanism and zero, you get the max of the utility you get from staying in the mechanism at minus delta. That minus delta is the only difference between this definition and withdrawal proofness as I defined it earlier. So our result here is that under the regular affiliation assumption, the expected revenue of the uniform price auction is at least the expected revenue of any efficient interim individually rational delta withdrawal proof mechanism minus some quantity. So the potential revenue loss from using the uniform price auction is at most 4.5 times delta times the number of.
05:12:14.838 - 05:12:16.400, Speaker B: Units of the good for sale.
05:12:17.460 - 05:12:47.720, Speaker I: We haven't attempted to tighten this 4.5. The point here is that if delta is small, the revenue loss from using the uniform price auction instead of the more complicated optimal mechanism is also going to be small. So just conceptually here, there's one thing to keep in mind, which is this statement is using interim individual rationality. So when we formulated withdrawal proofness, basically, if you can withdraw cautiously exposed.
05:12:49.900 - 05:12:50.168, Speaker B: The.
05:12:50.174 - 05:13:17.812, Speaker I: Seller can only implement exposed individually rational outcomes. So an interim individual rationality constraint is automatic. When thinking about this setting where withdrawal is costly, it's possible that a bidder might want to walk away exposed. So we need to separately impose that they want to come to the mechanism in the first place. And that's why we need to impose this interim individual rationality here, conceptually. So I think that's all I have to say.
05:13:17.866 - 05:15:02.420, Speaker B: Yes, love and the biggest applications that I see are things like houses. But for houses, typically what's done where I offer by the buyer and an escalation cost where you write down number and then it escalates the second price. But a typical case is no competition and your offer is accepted and then figure out to the right possible because I've got inspection projecting the house, but it doesn't fit with your large number. These are situations where there's one, maybe two, maybe three, maybe four, and a single item too. The other case where you mentioned is large acquisition where there's two buildings, four, and there's two diligent, some due diligence after. And so I can certainly imagine the draw there. Again, it's a situation where there's maybe one guy, maybe two guys, maybe three guys, not large numbers, where I see large numbers and I see even for price auctions is in say, wholesale electricity markets where we've got thousands of market participants.
05:15:02.420 - 05:15:30.440, Speaker B: Some of them are very large and quite dominant. So it doesn't fit perfectly. But there all offers are binding, all bids are binding all the time. There's no excuse whatsoever. And I'm hard time thinking about an environment where we have large numbers and we wouldn't have binding bits.
05:15:30.600 - 05:15:40.944, Speaker I: So I think I'm almost out of time. So I wish I had spent more time on describing the finite market results, which I didn't talk about at all.
05:15:41.142 - 05:15:43.184, Speaker A: So our results do tell you that.
05:15:43.222 - 05:16:14.020, Speaker I: Even in finite markets, you're not going to gain much more in revenue from using complicated mechanisms. But let me just conclude so the point here is to show that withdrawal rights provide a foundation for uniform price auctions. This contrasts with the standard Bayesian mechanism design approach where you need independence. The idea is that withdrawal rights sharply constrain the ability of the seller to raise revenue using sidebacks. And what we hope is that this can give a more realistic framework for thinking about mechanism design problems with correlated information more generally.
05:16:14.100 - 05:18:39.450, Speaker B: Thank you. Thank you. Thanks just this is also about option, but it's not going to provide foundation for anything, not where we are aware of. It's a joint work with Mike Peters, my colleague at UPC. At launch time, I was talking to someone who's mentioning Google Ads, and I felt that my talk is going to be really old fashioned because today Google Ads has a lot of AI tools and all these things, and this paper isn't about that, but it's motivated by the question of we think it's actually important that is auctions if you go to Google Ads help page, which I did, there are five factors. They listed for determining whether the outcome of the auction the bid, which is the number, the quality of your ad, expected impact from assets and other formats. I really tried to read the lines, I couldn't figure out exactly what they meant at rank, which is supposedly not known, and context.
05:18:39.450 - 05:19:43.760, Speaker B: Among the five factors, only the bid is quantifiable and it's observable. Everything else is unobservable. So essentially, if I want to think about this in an abstract way, I would say this is a case of unobserved auction. It does not prevent people from actually participating in auctions, but it's unobserved in the sense that you don't know how the winner is selected, you don't know how much you're paying if you win. So we're motivated by this observation and we want to write a theoretical model. We're not trying to explain why auctions are opaque or unobserved, we're just trying to take that as given and then try to understand what's going to happen, make some prediction. So we're going to have rational bidders instead of behavioral in any way.
05:19:43.760 - 05:20:33.038, Speaker B: The departure from the standard auction is that we're going to model auction. As the previous speaker said, there's a foundation now for withdrawing rights. So we're going to model auction as a mapping from profile bids to selection of the winner and upon selection, a distribution of offers. These offers are ticket, even offers, so you can of course reject it when you get the offer. So that's the only departure from the standard set up. And as you know, this departure has no implication whatsoever if the auction is observed in a standard world. This is all fine.
05:20:33.038 - 05:21:06.890, Speaker B: It's not doing anything. So this is our third paper. We have a research agenda. In the two earlier papers we have people who may or may not see the auction. So the auctioneer commits to something and many may or may not see it. We look at different issues but they're kind of difficult. But in this paper we think oh why don't we just take the pure problem.
05:21:06.890 - 05:21:23.598, Speaker B: Nobody sees the auction. Just look at the outcome of that game. Okay. So again this is not a game of no commitment. In fact we are motivated by Google Ads. So there is actually commitment. The platform has computer code and everything.
05:21:23.598 - 05:21:55.542, Speaker B: It's just you don't see it. Maybe it's a trade secret but whatever it is, it's not seen. Okay, so that's enough motivation research questions. Clearly yes. We don't think there's one. Oh, okay. So I didn't I should emphasize again we're going to take the standard environment independent private value.
05:21:55.542 - 05:22:39.298, Speaker B: We're just going to model as a one shot game. As I said, an auction is defined as a mapping from profile bids to selection of the winner and upon selection the distribution of prices, of ticketable offers. In fact. Okay, so that's all the computer code just says if I have these profiles bids who I'm going to select as a winner and upon selection what are the offers I'm going to spell out? Right. So that's the game. So obviously this game looks like a cheap thought game and even though there's full commitment by the seller but you can see that immediately there is always an equilibrium with monopoly revenue. That works as follows.
05:22:39.298 - 05:23:42.726, Speaker B: The bidders, they don't believe their bids have anything to do with whatever the outcome is. You just bid randomly and the seller commits to selecting any bidder randomly and make the monopoly offer, monopoly price offer. So the fact that there are many bidders has no impact on the revenue because they treat everybody as just a draw from the distribution. And as you can see also that Myerson's optimal auction revenue is not achievable. So for example if you take the second price auction that's not going to be an equilibrium because if bidders anticipate this second price auction, the bidder values and the auctioneer of course would commit to first price auction or writing a code okay, I'm going to charge whatever you're bidding. So that's not an equilibrium. First price auction is not an equilibrium either because in equilibrium there is a strategy.
05:23:42.726 - 05:24:21.506, Speaker B: It's fully separating. The auctioneer is just going to invert that strategy extract all surplus. So that's not an equilibrium either. So the question is first question may be are there equilibrium where bids are informative of their values? The answer is perhaps surprising. Yes, there are equilibrium where bids are informative. How do we do that? The idea is actually very simple. After you think a little bit more about it, it has a lot to do with mixing.
05:24:21.506 - 05:25:01.890, Speaker B: So mixing in a particular way that buyers, they're going to mix upwards. Upwards, meaning that they're going to bid higher than their value. This is a case of receiving ticket offers because you can always reject it and the seller is going to mix downwards. This to respect buyers incentive that they're willing to bid high. Okay, so you will see. So second question. Can seller do better than monopoly revenue? Yes, they can do better than monopoly revenue.
05:25:01.890 - 05:25:45.874, Speaker B: When the sort of revenue maximized, we're actually going to construct the actual auction to maximize revenue. So the most profitable equilibrium for the seller. I have a quote unquote example. I only presented this paper once and it was half finished and I was able to draw on the blackboard. But here I realized I didn't have time to put in a diagram or anything, so I'm just going to rely on words. If you pay attention, you'll see what's going on. It's not really an example because then you have to believe what I'm doing.
05:25:45.874 - 05:26:20.778, Speaker B: So there are more than two buyers uniform distribution and there are only two bids. You can think of these as very interested or just interested, but I'm going to number them. One bid is three quarters, another bid is one half. For uniform, one half is a monopoly price. So bidders with values above three quarters, they always say, I'm very interested. They always bid three quarters. Bidders with values between one half and three quarters.
05:26:20.778 - 05:27:16.942, Speaker B: They're going to say randomize. I'm going to randomize between these two bids. I'm going to randomize in such a way that after selecting three quarters as the highest bid, the seller is indifferent between charging three quarters and one half. And after selecting one half as the highest bid, the seller is willing to charge one half. As you can see, the statement I'm making here in terms of optimal price actually doesn't depend on what bidders with low values do because they're not going to accept any offer anyway. There are only two offers, one half and three quarters. What they do, however, is going to determine whether the seller makes more money than monopoly revenue or not.
05:27:16.942 - 05:28:34.760, Speaker B: In particular, there's always an equilibrium in spite of having informative bidding, there's always an equilibrium that the seller gets exactly the same monopoly revenue. That's the case where the maximum revenue after selecting three quarters and after selecting one half are the same. Now, when instead of revenue maximized with just two bids, that's when the guys with values below one half, they use the low bid as much as possible because these guys are not going to accept any offer. So you want to make the high offer more informative, in a sense. So again, the seller's revenue with two bids are maximized if the guys with values below one half use the low bid as much as possible. And then I think the rest of it is just to formalize this construction and show that most of what I'm saying is in fact necessity. Meaning equilibrium has to be like that.
05:28:34.760 - 05:29:27.580, Speaker B: So if nothing else, this is just maybe a cute example, but we think at least this is maybe a kind of environment where unobserved commitment can actually have interesting outcomes. In spite of having a commitment that's unobserved, there's few interesting outcomes you can characterize some more broadly. That's what I'm saying. Okay, so now I'm going to describe the model. This is the independent private value, the simplest kind you can think of. One good zero reservation value, at least two bidders. The values are drawn from F.
05:29:27.580 - 05:29:45.210, Speaker B: The only assumption we make is the revenue function is strictly concave. Actually, even that is not necessary. It just complicates construction. Again, all of work is by construction. So it just complicates console. Let me just assume that it's strictly concave. P Star is Monopoly price.
05:29:45.210 - 05:30:22.860, Speaker B: Pi star is monopoly revenue. The game goes like I said already, the seller commits to symmetric auction. An auction is a mapping from profile bids to select the winner and executive offer to the winner. So that's the first mover. The second mover the buyers, they draw their values and then they submit a bid without observing this mapping. Then the rule of the auction, the rules are implemented. So the payoffs are just the standard payoffs VI minus P if you get the good.
05:30:22.860 - 05:31:14.910, Speaker B: If you don't get the good, the payoff is zero and setters realized value is P if it's accepted. Otherwise it's zero. Okay, so I guess there's no question about that. So I'm going to introduce some notation here. The auction is represented by, again Qi of B which is a profile of bids is the probability that bidder I bi is selected as a winner and G capital GIPB is the cumulative probability that the offer take it. If an offer to bidder I to the winner is at most P. So that's just distribution function.
05:31:14.910 - 05:32:01.660, Speaker B: So together it's an auction. We impose symmetry in a clear way and that's the auction. The biding strategy is represented by H, capital H, which is again cumulative bid bidding distribution. Okay, so that's it H, just some notation to remember, I guess. Equilibrium is defined in a standard way. The only thing that makes it stand out is what is referred to as withdrawal rights, which is the max operator. When you get an offer, you can turn it down if it's higher than your value.
05:32:01.660 - 05:32:53.900, Speaker B: Otherwise it's a standard looking thing basing ash equilibrium. So let me start with the simple environment where the bids are actually going to be finite. Sorry, I said let me just so the environment where there are only finite number of offers ever being made in equilibrium. So this will correspond to the finite number of bids. So now I'm going to use little G as the probability of making the offer instead of capital G because it was defined. As cumulative. Now, little G is a probability.
05:32:53.900 - 05:34:05.600, Speaker B: I'm going to define this PSI chi. I think it's chi chi as the probability that this offer is generated t is generated by a bidder with a bid M. So that's just expect the total probability that from bidder I perspective, if I make a bid M, what is the probability that my bid would generate an offer T? You have to sum up over all the profiles of your opponents and take the auction as given. Let me say that an offer generates T. A bid generates offer T if the sky is strictly positive. Okay. So the first result is what I said earlier is that there is in fact, a linear order of offer distributions.
05:34:05.600 - 05:34:54.304, Speaker B: If you compare two different bids, the higher bid must generate all the offers that the lower bid generates with the same probabilities. I repeat, the higher bid must generates all the offers generated by the lower bid with the same probabilities. Take the case of one half and three quarters. The claim here is that three quarters must generate the offer one half with the same probability as the lower bid. One half generates one half.
05:34:54.502 - 05:34:56.704, Speaker F: Because if that were not true, the.
05:34:56.742 - 05:36:01.300, Speaker B: Guys with values just above three quarters, they will not bid three quarters. You want them to bid three quarters, but they won't bid three quarters. So this means that all the offered distributions can be ranked with a linear water. They're totally ranked. Now, concavity of the of the revenue function allows us to conclude that not only you can rank them, but also there are no missing bids in the sense that there's a one to one correspondence between the offer and the bid. Because if there's a gap, let's say an offer a bid b two generates two more offers than the next lowest bid, then you can combine these two offers together and using concavity that will be the center. This is not going to be any query bid.
05:36:01.300 - 05:37:01.696, Speaker B: The result here is that there's one to one correspondence between the NUM between the bids and the offers. So from now, I'm going to call these bids this offers bids. They correspond one to one. Okay? So now I'm getting a lot of notation, as you can see, which is really not pleasant to present here. Even I can't keep track of all of them. I really apologize for this on you, but in terms of the construction, it's just very simple. So here we're looking at the number, let's say there are l is a total number of bids, which is a total number of offers.
05:37:01.696 - 05:37:34.000, Speaker B: And your strategy has to specify the probability you make each bid. So that's little HK does. Little HK is the probability as a bidder. What is the probability you make that bid? As a function of what? As a function of your value. So HK printhus W is the probability that if your value is W, what is the probability you make the bid Tk. That's all. So phi is a total probability integrated over all values.
05:37:34.000 - 05:38:14.350, Speaker B: And we can now write the sutter's revenue as this simple form p times the probability that the offer isn't accepted. It's conditional on this offer being made. So revenue function RK is a function of P. It's conditional on because it depends on how often this offer and this bid has been made. So a conditional on the total probability that this bid is being made. Now I have to introduce notation for auction. So theta here is the distribution of counts, how many people make bid k.
05:38:14.350 - 05:39:32.580, Speaker B: So theta one therefore, is the number of bidders that make bid T one and so on. Right. Of course, sum of all these setters would be equal to N, that's total number of bidders. And you have multinomial distribution. But I'm not going to point line by line, but you can understand how this is going to work. Now here comes just a little bit more notation. This little G-J-K of theta is the probability that after you're selecting bid k Tk, what is the probability that you're going to make an offer TJ? I repeat, little G j comma k theta is if the profile of bids is theta, what is the probability that after you're selecting Tk, the bid Tk? What is the probability you're going to make an offer TJ? Okay, so now we can compute the implied chi JK, which is the probability that bit Tk generates TJ.
05:39:32.580 - 05:40:36.840, Speaker B: These are all multinomial expressions, well defined. So after this much, there's the Lama that says when do we have an equilibrium? These are extremely straightforward. If you just follow, even if you didn't follow the notation, this just exactly work. What you're saying, what you're thinking about. First example, item one that says if my value is W is above Tk, I'm never going to make lower bids, I'm going to randomize upward. Okay? And item two says okay, so for me to implement this auction for the seller, it must be that every little K, every little TJ is arcmax of my revenue function once I select Tk. So once I select Tk, I'm willing to randomize downward.
05:40:36.840 - 05:41:33.112, Speaker B: All these little T, one through all the way to Tk are arcmaxes of my conditional revenue function. So I'm willing to randomize downward. I'm only going to select the one with the highest revenue if I select k. That must be because the conditional revenue is highest if I select K. And this one says that as a setter, I'm only going to randomize downward again. And the probabilities are the probability that if K generates offer k again is equal to J generates offer k for every higher J. So this is all what I said at the beginning.
05:41:33.112 - 05:42:06.584, Speaker B: So this is how the auction is going to work and equipment is going to work. Okay, I see that everybody's following this precisely the lowest offer is going to be monopoly price. That's not surprising because from the examiner point of view, you're not going to charge lower price than monopoly price. Okay. And equilibrium is going to be weighted average. So how much time I have? 20 minutes. Lots of time.
05:42:06.584 - 05:43:21.720, Speaker B: I can still go through all of lines, but I won't. So I'm now going to just tell you in words what the essential gradients of the construction are. The first one is going to be what we call revenue equivalents. Think about intuitively. The plane here is that in equilibrium, in any equilibrium, the way buyers with values above P star, that's monopoly price, the way buyers randomize above P star, how they randomize does not determine the revenue mile play revenue. Essentially, these guys who are randomizing have to randomize in a particular way to make the seller indifferent. Again, if I select Tk as the highest bid, I have to be indifferent among T, one through Tk.
05:43:21.720 - 05:43:57.400, Speaker B: These are all arcmaxes. Now because of this incentive restriction, the way so long as these incentive restrictions are satisfied, then the way buyers with values above P Star randomizes has nothing to do with the revenue. The revenue does not depend on how these guys randomize because of this incentive condition. Maybe easier to see, maybe not. But you have to trust me. Okay? So that's the revenue equivalents. That's the first part of the construction.
05:43:57.400 - 05:44:37.388, Speaker B: And this is saying that there is a way to do that. You may wonder, oh, can I actually randomize if I have these guys, buyers with values above P star, randomize in a way to make to generate all these arcmaxes, all these local peaks? The answer is yes. And this part again is just by construction. You can do it. Essentially this is easy to do because why? Because you have so much degree of freedom. You just have to generate local maps, right? Local arc, maxes. There are many ways you can split the distribution in terms of bidding strategies.
05:44:37.388 - 05:45:26.920, Speaker B: So you can do that. Okay, so there's a way to do it. The second ingredient of this construction is that it is actually an auction. In other words, any equilibrium revenue of the seller can be generated by an auction where the seller always picks the highest bid. In every equilibrium, the conditional revenue is actually weekly increasing. So in any equilibrium, if I like if PK is the highest bid, then indeed, because it's weekly increasing, I actually have incentive to pick that bid. So it is an auction, works just like an auction.
05:45:26.920 - 05:46:15.972, Speaker B: So the proof idea here is that if we're not true, if there is a conditional revenue that's actually lower than all the rest, it would be impossible for the seller to satisfy the incentive condition that I have to generate. With every high bid, I have to generate all the low offers with the same property as all the low bids that generate. So I'm saying it very fast. But the idea is very simple. It's impossible to have something like bidder. T two somehow has a lower conditional revenue than the bid T one. That's impossible to satisfy incident condition.
05:46:15.972 - 05:46:51.280, Speaker B: So now we can just focus on always selecting the highest bid. Great. And now how do you do that? So this is how you do it in equilibrium. You assign the object to T one, the lowest bid only if everybody bids T one. So you have a seed. You assign the object to T one, the lowest bid only if everybody bids T one. You just assign the object randomly.
05:46:51.280 - 05:47:37.090, Speaker B: What offer you make, you only make T One. That's a restriction in equilibrium. Now when do you assign to T two? You assign to T Two only if T two is the highest bid. And whenever that happens, unless nobody's bidding T two meaning everybody's bidding T one in which case you already assigned. So when you get T two as the highest bid, what do you do? You just make sure that T two generates T one in the same populating as T one generates T one which I have already signed and so on. So you can just assign all these little g's in the auction. Done.
05:47:37.090 - 05:49:02.680, Speaker B: Okay, the first result is going to be that after constructing all these things I said, you ask what is the low least profitable equilibrium there is? Actually the least profitable equilibrium in spite of the fact that higher value bids, higher value bidders, they are informative. Their bids are informative. But there is a way to assign the low value guys, the guys with values below PSTAR, how they participate in the auction. There's a way to assign that so that monopolist the seller earns the same monopoly revenue as Pi Star. Okay? Most profitable equilibrium. Remember this is for fixed, for fixed offers T one through TL these are fixed. So we can ask what is the most profitable equilibrium? The most profitable equilibrium is created by the falling way.
05:49:02.680 - 05:49:45.710, Speaker B: Remember the way that higher value bids higher value buyers. The bid is irrelevant for the seller's perspective, for the revenue perspective. So you're going to assign all these lower guys to T one first. That is you want to maximize the probability, exante probability that bidders use the lowest bid. Now there is an incentive condition. There is incentive condition because if you sign too many of them to bid one then the monopoly, the setter would want to lower the price. When T one is the highest bid, the seller would say okay, I don't want to charge T one anymore, I want to charge something lower.
05:49:45.710 - 05:50:24.014, Speaker B: That's the only constraint. So again, the first step is to assign buyers with values below T one which is monopoly price. Make them bid T one as much as they could. And then conditional on that you make these guys bid T two as much as they could. When I say as much as they could. It literally means that you're going to make the conditional revenue function flat to the left of T one. That's the first step.
05:50:24.014 - 05:51:07.646, Speaker B: The conditional revenue function is going to be flat because if it's not flat, you could put more people on T One. So it has to be flat. It cannot decrease because if it decreases at T one, then the server would want to lower the price. So you want to make the conditional revenue function flat. And when a constraint is not binding, you make them all bid T One. So when it comes to T two, you do the same thing. You assign these guys to T Two so that the conditional revenue function after you select T two is going to be flat to the left of P Star.
05:51:07.646 - 05:51:37.946, Speaker B: And you do this successively. That's the highest revenue. So the intuition is quite simple. You're trying to make these guys make low bids because you want to make the high bids informative. Because these guys, they have values below P Star, they're not going to accept anything anyway. So you want to make them make low bids so you leave room for the high bids to make more money. Okay, this is a very simple idea.
05:51:37.946 - 05:53:10.550, Speaker B: There is a proof that this is in fact the most profitable equilibrium given these bids, given these offers you're going to make. Okay, we have time. So the next naturally is to ask, oh, these are for fixed, fixed offers. Can I actually do a maximization problem if I only make two? If I make only two offers, where should they go? What is the optimal placements? And that problem can be solved. I mean, some standard problem and what you can get from that solution is that you never want to make two offers coincide with each other. In other words, every time, as long as you do this successfully assigning lower value bids, according to the algorithm we have here, you always want to add more offers, more bids. So that leads to the final construction, which is every offer is being made above the monopoly price.
05:53:10.550 - 05:54:25.112, Speaker B: The most profitable equilibrium is going to involve a continuous continuum of offers and continuum of bids. And there is a characterization of what that optimal auction most profitable, sorry, I call it optimal. It's actually most profitable auction. And the actual construction is a little tricky because it turns out that with a continuum of bids, I remember that we want every bidder above P Star to bid upwards, randomize upwards. Immediately you will see that if your value is actually one, there's no place for you to go, right? So, of course, in the end, the construction is going to be that in the most profitable equilibrium, every bidder w with value w is going to place an atom on the bid w and then it's going to have a randomization above w. So you place an atom on w and then you continuously randomize above w all the way to one. That's going to be the construction.
05:54:25.112 - 05:55:12.228, Speaker B: And the way you're going to randomize is going to ensure that the revenue function is completely flat from P star to one. If you select T, that's the highest bid. What you face as a seller is a conditional revenue that's flat from P star all the way to T. So that's the way you construct this most profitable equilibrium. Yeah. I don't have the ability to draw the picture, but I think you understand what sort of understand what I'm trying what I'm trying to do. So it all works out beautifully.
05:55:12.228 - 05:56:01.112, Speaker B: Yes, it yeah, so that that's what I've said. Our earlier papers deal with that question. So indeed, our earlier papers ask the following question suppose you have same problem, same underlying same underlying problem. So everybody is going to draw a type. Either you see the auction or you don't see the auction. If you don't see the auction, you hold the equilibrium expectation about belief, about what the auction is going to be. And if you see the auction, you can participate or you can pretend that you don't know.
05:56:01.112 - 05:56:47.290, Speaker B: You can bid in the same way as people who don't see the auction. So you have this kind of one sided incentive condition and our result is basically that the outcome depends on the behavior you assume about people who don't see the auction. The outcome of that game depends on what you assume to be the behavior of the people who don't see the auction. As you can see here, I have lots of equilibrium. We have lots of equilibrium. So depending on the equilibrium of these guys, you can see. But over there, the big question is if there's fraction of people who don't see what's going on, then how does that affect optimal auction design? That was the question.
05:56:47.290 - 05:57:42.104, Speaker B: And we have some conclusion over there. Yes. So you're emphasizing the unobserved nature of the auction, but seems to me that the most unusual feature of it is that what bidders are doing is they're bidding to receive an offer from the seller. Isn't that really the distinctive feature of what this paper is about? Well, okay, so yes, the motivation comes from the fact that the mappings are not observed. The construction is just standard equilibrium construction. Even though you don't see it, you have equilibrium inference about what the assignment is. And we're asking again, the focus is on what is the most powerful equilibrium because there's always a bounding equilibrium, so to speak.
05:57:42.104 - 05:58:12.244, Speaker B: So we ask can bidders even though they don't see the auction, aren't they worried about being exploited? As I said, first price auction, second price auction. They are not equilibrium auctions. Right, they're not equilibrium. So the question is can bidders bid informatively? The answer is yes. And given that, what is the most profitable construction? So that's the focus? Yes. So you emphasize that you're thinking of the seller as committing to the mechanism. The buyer just don't know it.
05:58:12.244 - 05:58:44.492, Speaker B: Is that any different from the seller just not having any commitment power at all? I don't think so. But you have to specify the PDFs and so on. The outcome is the same. It can make the site the same. But we think the idea here is that online platforms, they're not changing the code computer codes in the real time. Instead, they just commit to computer codes and we just don't know what it is. Like the ads option.
05:58:44.492 - 05:59:19.680, Speaker B: We just don't know what it is. Let me just put this just to give you a sense of how much revenue there is. This is worked out example. So, uniform distribution, two bidders. Monopoly revenue is one quarter. Monopoly price is one half Myerson's. Optimal revenue is five over twelve.
05:59:19.680 - 06:00:00.638, Speaker B: If you fix the offers L offers, you can compute the most profitable equilibrium. So the T's are fixed and that's giving you the most profitable equilibrium. Okay. That follows from this assignment of lower value. Guys bidding, low bids first. And you ask what is the maximum of this? Maximum turns out to be that you want them to be evenly placed under uniform. It's not surprising you want these bids to be evenly offers to be evenly placed.
06:00:00.638 - 06:00:32.874, Speaker B: And maximum revenue has this form. This is increasing in the number of bids and converges to one third. Which is exactly what we get with the continuum of offers. One third with two bidders is one third. I think I'm almost out of time. There's no conclusion. I guess the conclusion is yes.
06:00:32.874 - 06:00:41.390, Speaker B: Unobserved auction actually has action. Right? There is action. That's the conclusion.
06:00:42.770 - 06:00:43.680, Speaker I: Thank you.
06:01:16.640 - 06:01:17.870, Speaker G: Control. F.
06:01:19.840 - 06:01:20.590, Speaker B: No.
06:01:22.560 - 06:01:23.310, Speaker G: Sorry.
06:01:24.720 - 06:01:33.090, Speaker B: No control. L control. L perfect.
06:01:33.780 - 06:01:57.240, Speaker G: Well, thank you very much for including this paper into the program and for sticking around. I'm the last talk before the break, I promise. I'm presenting my paper with Eric, who is in the room back there. Jason Allen, who's at the bank of Canada. So the usual disclaimer applies. And Aluha Taksu, who couldn't be here today. The title is Entry and Exit in Treasury Auctions.
06:01:57.240 - 06:02:47.450, Speaker G: Traditionally, treasury markets rely on dealers to consistently buy debt from the government and actively trade with investors in the secondary market and over the counter market. These dealers are large banks who are obligated to participate regularly in the market. In return, they enjoy benefits. For example, they have privileged access to central bank facilities. Over the last decade or so, another class of investors which we will call customers have entered the market. Our customers are, for example, hedge funds. And unlike dealers, they don't have an obligation to regularly participate in the market.
06:02:47.450 - 06:04:18.036, Speaker G: So the broad question that we are interested in in this paper is what are the market consequences from having committed dealers who regularly participate in the market and noncommitted customers who don't regularly participated in the market? Now, answering this question empirically is challenging because customers, unlike dealers, don't have to report what they trade or what they're doing. So we know shockingly little about what customers are doing in treasury markets and not only in treasury markets and over the counter markets generally. We overcome this data limitation by focusing on the primary market, specifically the Canadian primary market, in which the government issues bonds via regularly held auctions. We document that dealers have been leaving this market since the first auctions took place in 1999 and instead customers have increased their participation in the market, but their participation is very irregular. We then introduce a framework that allows us to highlight a trade off between competition and volatility. What do I mean by that? On the one hand, when you attract customers more market participants, you can increase competition. But on the other hand, because customers don't have to participate regularly, you might also increase market volatility by attracting more customers.
06:04:18.036 - 06:05:37.222, Speaker G: So for example, two auctions might clear at different prices only because one auction attracts a lot of customers and another auction doesn't attract a lot of customers. And not because these two auctions offer bonds that have different fundamental values so that can introduce price volatility when going across auctions that might destabilize the financial system we then quantify. So use our model to quantify the revenue gain from increased competition and the loss from irregular bidder participation and propose a policy that aims at stabilizing customer participation at a sufficiently high level so that we both can increase competition and decrease volatility at the same time. And the idea is to strategically issue more supply in auctions that otherwise would not attract a lot of that would attract a lot of customers to auctions that wouldn't attract a lot of customers. We think that the economic insights that we highlight in this paper are generalized to other market settings in which we have regular and irregular market participants. In particular, this competition volatility trade off that I was talking about. One example are over the counter markets where dealers and investors trade bilaterally.
06:05:37.222 - 06:06:24.200, Speaker G: We have committed dealers and non dealers. So regular and irregular participants in exchange markets you typically have designated market makers or designated exchange members and nonexchange members. And even outside of the financial setting you can have regular and irregular participants. For example, in energy auctions where you have firms that produce nuclear power the regular participants and firms that produce wind, the irregular participants. Now, our structural model can be used to quantify this type of trade off in some of the applications, for example, in the energy auctions. More closely, our paper contributes to two main literatures. The first is a broad literature on government bond market.
06:06:24.200 - 06:07:29.290, Speaker G: Unlike the vast, vast majority of papers in this literature we focus on customers, not on dealers. And we think that's important because customers have been playing an increasingly important role in treasury markets, not only in Canada, but elsewhere in addition, we contribute to literature on auctions, in particular, empirical literature on auctions, on multi unit auctions, to be more precise, those are auctions where you bid for multiple units of the same good. And relative to that literature, we contribute by endogenizing bidder participation in these multi unit auctions, which hasn't been done before. With that, I will jump into the rest of the talk. I will give you more institutional details about the setting, so I explain how the auctions work and some of the details, then talk about the data. I give you two stylized facts that will motivate the model that I will then spell out. Talk about estimation, and then the counterfactuals.
06:07:29.290 - 06:08:15.340, Speaker G: We observe bidding information from all auctions that took place essentially since the first auction was established, which was at the end of 1998 until 2022. We see all the bids that are submitted and who submits the bids. So we can distinguish between, say, a dealer and a customer. In addition, we collect daily average prices from markets in which these bonds are also traded. Those are the secondary market, where the investors trade with the dealers, future market and the repo market. We will use those daily average prices only to try to figure out in which auctions customers want to participate in. Other than that, we won't use that information.
06:08:15.340 - 06:09:18.678, Speaker G: In these auctions, we have two types of bidders which shouldn't come as a surprise. We have the dealers who are large banks and the customers who are, since 2014, mostly investment firms. So think of them as hedge funds. One difference between dealers and customers other than dealers have to regularly participate and customers don't is that dealers in Canada can bid directly to the auctioneer while customers have to bid via a dealer. Which means that they select a dealer and then place their bids to the dealer who can observe the bids and then places the bids to the auctioneer. So our model will need to take that into account if we want to get unbiased estimates. What is a bid or how does the auction work? Canada runs a discriminatory price or pay as bid auction, as was mentioned before, which means that a bid is a step function that consists of maximally seven price quantity tuples.
06:09:18.678 - 06:10:01.020, Speaker G: So here you see such a step function. This bidder asks for a high price for the first 50 million, a lower price for the next 50 million, and so forth. Everybody submits such a step function. Then the market clears the price at which the aggregate demand equals to the issued supply, and everybody pays the bids that they offered for all units that they win. In case there is excess demands at the market clearing price, we use pro rata ratio rationing, which means that you essentially get rationed based on how much more you asked for at the mark clearing price relative to others.
06:10:03.550 - 06:10:06.810, Speaker B: Sorry, is the price granularity? One penny.
06:10:07.470 - 06:10:43.060, Speaker G: So these auctions are actually not in prices, they're in the data. They're in yields. And yields, I think it's 0.1 basis points. So what we do then to work in prices, because it's more familiar to us economists to think of price schedules that are decreasing instead of or demand schedules that are decreasing instead of increasing. We translate the yields that we observe in the data into prices to then plot these types of graphs. And everything I will say will be in terms of prices where you can think of the face value of a bond as being 100.
06:10:43.060 - 06:10:54.510, Speaker G: Okay, so now we have the institutional setting and the data. Are there questions on the institutional setting before I jump into effects.
06:10:59.090 - 06:10:59.646, Speaker B: That we.
06:10:59.668 - 06:11:41.278, Speaker G: Will look at now? So here the first fact is going to be about entry and exit. We see two trends. The first is on the left hand side we see that the number of dealers who participate in these auctions have steadily declined since the first auction took place. So we started with around 24 and now we're down to twelve to 13. There seem to be two rounds of exits, a first round of exits where mostly local banks dropped out of the market. We think that happened because the market switched from a syndicated market to a more competitive auction market. And so these not so competitive local banks were dropping out of the market.
06:11:41.278 - 06:11:57.140, Speaker G: Our study will not focus on the first round of exits. Instead we focus on the second round of exits, which happens after 2014 and their global banks are leaving the market. For example, Deutsche Bank left the market.
06:11:57.830 - 06:12:17.510, Speaker B: I was wondering what it means for these dealers to sort of always participate, because I'm assuming that they also are responsive prices. So that means that they are less responsive to prices or do they have some sort of mandate to set price doors?
06:12:22.190 - 06:12:54.734, Speaker G: Okay, so the question was what does it mean that a dealer has to regularly participate? And the answer is that it is a bit complicated. There are multiple things that are going on. For example, there are bidding limits. A primer dealer has to ask for at least 10% of the issued supply over a certain period. We can look whether that's the case in the data and that's typically the case in the data. So they are demanding in every auction at least 10% of the supply. In that sense, they don't seem to be price sensitive in that they don't show up if the price isn't good enough or something like that.
06:12:54.734 - 06:13:31.634, Speaker G: There are also informal things that are going on that the bank of Canada wouldn't tell you. But I know that if you are a very big primary dealer and you don't bid competitively enough, then you get angry, call and they tell you to not do that. So in the data it doesn't look as if dealers are very price sensitive because basically they cannot. They also are provided a. Price range in which they are supposed to bid. Okay, so we have these dealers who are leaving the market. We will focus on the second round of exits where the global banks were leaving the market.
06:13:31.634 - 06:14:21.200, Speaker G: On the right hand side we have hedge funds, or investment firms more broadly, who are entering the market and that seems to kick off in around 2014, which coincides with the second round of exits of dealers. So we see that the number of hedge funds coming back to the question of how many customers must we have was at the beginning, was low at the beginning, we still had other customers in the beginning. For example, we had some pension funds in the market. So on average I think we have six customers per auction. But here let's focus on the hedge funds. So they have entered the market and by now we are at around eight per auction, eight hedge funds per auctions. And there are basically very few other customers other than hedge funds at the moment.
06:14:21.200 - 06:14:56.220, Speaker G: So you see two things. One, the trend is going up and two, the line is not as smooth as for dealers because hedge funds are only showing up in some auctions and not on others. So unlike dealers who have to be there all the time, they basically select into specific auctions. Now, if you look at this similar trend in other markets, for example, you can look at in the US. We don't have bidding data from the US. It's very difficult to get, but we can look at public data. The trend seems to be similar in that investment funds are moving in and dealers are moving out of the market.
06:14:56.220 - 06:15:49.120, Speaker G: I don't think they have. So perhaps during COVID they made some exemptions because as we know, during COVID governments had to issue more debt. So I don't know off the top of my head whether they also had more frequent auctions during that period, but I don't think there is a plan of making them more frequent in the long run. On average we have 30 around per year which are spaced out relatively evenly. So you can make the math. Okay, so customers are moving in, but only select specific auctions. One natural question to ask is whether we can predict which auctions they select into.
06:15:49.120 - 06:16:36.074, Speaker G: So we had a go on this. We looked at the existing literature on what hedge funds or customers are doing in treasury markets, which is pretty small, and at industry reports and what regulators are saying, and tried to construct variables that capture what the customers might be doing that might drive the participation of customers at auctions. So we are regressing the number of customers in an auction on a bunch of variables that we think might explain or might drive customer participation. One example, I will give you two examples. One example is the basis trade indicator. The basis trade was in the news in March 2020 because it created issues during this period. In the US.
06:16:36.074 - 06:17:18.458, Speaker G: It basically says that you're buying bonds and you're shorting the corresponding future contract. So if buying bonds cheaply is profitable compared to shorting the futures contract, we might think that customers are more likely to participate in these auctions. Turns out that the coefficient is not statistically significant. Like all the other coefficients that we have in this regression other than the bid US spread. The bid US spread is an approximation for the bid US spread in the secondary market in the three days leading up to the auction. So in the US. It would be like the Bid US spread when issued market.
06:17:18.458 - 06:17:32.030, Speaker G: If that spread is high, then we see that more customers show up at the auction. Suggesting that customers select into auctions where they can buy it cheap at auction and then sell high at a high ask price right after the auction.
06:17:33.090 - 06:17:46.420, Speaker B: Just gave us the time frame of three days. I really don't know how many people are going to be getting until I arrive on the day of.
06:17:47.190 - 06:18:09.610, Speaker G: So in reality you are pretty certain about how many dealers will show up because it's announced who is a primary dealer and that's publicly on the website. And I told you that they basically show up all the time. So you know how many dealers you probably don't know exactly how many customers will be participating in the auction.
06:18:13.630 - 06:18:28.702, Speaker B: Or so that's when the customer started. But I guess the variance should we take away that the number is increasing or the variance I think you should.
06:18:28.756 - 06:18:57.340, Speaker G: Take away that the trend is going up. So we have more on average and there is variance. I will not be able to explain what drives the specific variance. So for now, I'm fine with you just knowing that customers don't participate regularly and there are some specific variance, but I won't really speak to this variance in terms of how it moves over time. We will later look at a typical auction which not talk about how variance changes over time.
06:19:00.510 - 06:19:04.010, Speaker B: That is the quantity that visited at reasonable prices.
06:19:06.670 - 06:19:09.200, Speaker G: Do anything where here or later.
06:19:11.010 - 06:19:12.430, Speaker B: You haven't touched on it yet?
06:19:12.500 - 06:19:14.160, Speaker G: No, I probably get to.
06:19:17.090 - 06:19:34.786, Speaker B: So it seems like participation like we looked at FTP inspector boxes, there's hundreds of participants, but only three, I guess is it's not like that? I guess we've got a much richer yeah.
06:19:34.808 - 06:19:48.730, Speaker G: So I think I want you to think about these bidders as two types of bidders dealers and customers. Dealers are those that regularly participate and customers are those that don't regularly participate. Customers tend to be smaller than dealers, so they demand lower amounts.
06:19:50.030 - 06:20:15.038, Speaker B: But I think maybe we're all if they decide to participate, they're actually putting in something useful. In a lot of markets you get these participants that are participants that they want to observe something, some piece of information revealed through participation and they actually are not interested in buying or selling.
06:20:15.214 - 06:20:39.900, Speaker G: I don't think that's so much going on here simply because a lot of the information that they would be observing in the auction is also public information. And as soon as the auction clears, the auction clearing price is public information. How much debt is issued is public information. All of the things that you might care about is public information. So I don't think that's what's going on here. I think everybody who participates in the auction has the intent of buying something. So everybody is serious in that regard.
06:20:39.900 - 06:21:43.534, Speaker G: All right, let's come back to this table. So, we are trying to predict customer participation. We found out that the bid us threatened in the secondary market in the days leading up to the auction can predict whether customers participate in an auction or not. None of the other variables are significant. And overall the R squared on these regressions, both the Ola S regression and when we throw in a year fixed effect as relatively small, which suggests that there are a lot of unobservable factors, unobservable to us that drive customer participation. So we want to set up a model with the feature that market participation is endogenous, where there are two groups of market participants, dealers who can decide at the beginning of the fiscal year whether they participate in all. Auctions of the upcoming year and customers that before each auction, can observe the market conditions that are potentially unobservable to the econometrician, but not to the participants, and then decide whether to enter this upcoming auction or not.
06:21:43.534 - 06:22:46.850, Speaker G: So customers are flexible, dealers have to commit. In addition, we want to make sure that we don't get biased values. So we have to model the biding behavior. The procedure on how bids are placed in the Canadian Treasury auction and here we will follow a paper by Yako KAFA and Ali Hataksu in 2012, which I will keep referring to, which basically modeled the biding process in Canadian Treasury auctions and focused on dealers. So they have shown that it is quite important to take into account that when dealers observe a customer bid, they have an incentive to update their own bid because they learn something about the degree of competition in the auction. What we do differently relative to them is that we focus on customers and we say that customers, strategic customers, have to take into account that dealers will update their bids based on observing the customer bid. We do that differently and the entry exit.
06:22:48.710 - 06:22:49.810, Speaker B: Decisions.
06:22:51.990 - 06:23:26.880, Speaker G: So, here is the model we have n Bard potential dealers and NH potential customers. Those numbers are commonly known. The sequence of events is as follows I will explain how the auction is modeled on the next slide. At the beginning of the fiscal year, each dealer draws an independent cost, participation cost from a distribution that is dealer specific. This distribution is in blue because we will estimate it. So everything in blue we will estimate. Then the dealer decides whether to participate in the upcoming auctions of the year or not.
06:23:26.880 - 06:24:39.794, Speaker G: The number of participating dealers is announced. In practice that happens on the website of the Central Bank, for example. So the number of dealers in the auction coming back to Bobby's question, is known by all market participants before the first auction. Each customer then draws also an entry cost from a customer specific distribution. Again, this cost draw is IID and decides whether to enter the upcoming auction or not to enter, conditional entering each bidder. In these two bidder groups, which are labeled with D for dealer and H for hedge fund customer, each bidder draws an independent private signal from a distribution FGT FG one in this case that is bidder group and auction specific. And the customers, before deciding whether to enter the auction, they know this auction specific distribution, which is meant to approximate these potentially unobservable market conditions that drive customer participation.
06:24:39.794 - 06:25:21.922, Speaker G: So for example, in an environment in which bid our spreads are high, the distribution would have a higher mean value than in another environment. And we don't impose that, but we would estimate that if that's the case and then everybody bids. Now this essentially is the sequence that matters. Now in reality we have more than one auction within a year. So the way we deal with this is by just stacking on the same auction over and over again without allowing for any intertemporal linkage between these auctions. So this is not a dynamic game. It's basically two stage gain and then the same thing repeats over and over again.
06:25:21.922 - 06:25:29.510, Speaker G: So the second auction is going to come around, the same thing happens third auction and so forth until the last auction.
06:25:31.930 - 06:25:55.662, Speaker B: So for the hedge funds cost, that's sort of like this week's auction. Do I want to spend some time evaluating what price you're going to pay? Right, that kind of has that exactly viewers cost. You're paying it once and then that kind of activates you for the full year. Do I want to pay a guide to pay attention to the treasury market? Is that the way to think about it?
06:25:55.716 - 06:25:55.886, Speaker H: Yeah.
06:25:55.908 - 06:26:25.000, Speaker G: So the question was how to think about the costs. I was going to talk about more about that when we show you the estimates, but we can talk about it now. So the way we think about the cost is, as you say, as opportunity costs. So for the hedge fund or the customer, it's do I pay a guy to pay attention and figure out how to bid in these auctions for this specific auction this week. So meaning what prices should I have and so forth and so forth. For the dealer it's more the entire year.
06:26:27.630 - 06:26:27.946, Speaker B: Yeah.
06:26:27.968 - 06:26:29.340, Speaker G: So think of it as.
06:26:31.470 - 06:26:41.582, Speaker B: Pretty the difference in the way the cost okay.
06:26:41.636 - 06:27:18.314, Speaker G: So then this is the sequence. Now we have the auction. The auction, as I already said, is modeled the way that Jakob and Ali were modeling it in their Econometrica paper. The conditional on entering each bidder draws this signal which can be multidimensional from this distribution FTG the signal determines two things. One that determines the willingness to pay off the bidder at all quantity points. So this is a willingness to pay curve that is nicely behaved. For example, it's decreasing in quantity and the curve maps from quantities and this private signal into a price.
06:27:18.314 - 06:27:56.630, Speaker G: So it tells you how much you're willing to pay at a specific quantity point. The signal also pins down the number of steps that the bidder will submit in that auction. So we don't endogenize the number of steps. Jakob has papers where he does that. The way to do it is to assume that there is an extra cost to submitting additional steps perhaps because it's more complicated to compute these additional steps. And then what we observe from the data is the optimal number of steps based on those costs. Because our model already is complicated enough and this is not our main contribution and it has been done in the literature.
06:27:56.630 - 06:28:34.450, Speaker G: We don't use this microfoundation. So we just fix the number of steps for our purposes. Then bidding evolves in three steps. Three stages. First, each dealer submits can submit the step function so a price quantity tuples. Then each customer is randomly matched to a dealer and can submit its step function. And then in the third step each dealer observes the bid of the customer who placed a bid through this specific dealer and can update its own bid.
06:28:34.450 - 06:29:35.458, Speaker G: I want to flag two assumptions which might be the strongest one. One is the fact that customers are matched randomly to a dealer. So reality you might think that some customers strategically choose some dealers over others or that they might split their order to somehow diffuse information across dealers. We show that in the data it doesn't really happen that customers split their order within an auction so we're less worried about that. We also compare what we observe in the data to what will be predicted in a model where customers were randomly matched to the dealer and the distributions look relatively similar. So we think it's a reasonable assumption even though it is not perfect. The other assumption that I want to flag which is different I think the only assumption that's different compared to the Econometrica paper is that we assume that dealers only observe the quantity weighted bid of the customer.
06:29:35.458 - 06:30:20.594, Speaker G: The quantity weighted bid is essentially the per unit price of the bid. So the average price for each unit that you would demand. And the reason why we are making this assumption in the paper we are a little bit more general in that we say the dealer can observe finite moments of the step function. The reason why we're making this assumption is to make it tractable to deal with the anticipation of the customer that the dealer might update its own bid without this assumption. The problem is basically untractable because the customer there are millions of ways in which the dealer could update its bid because the dealer has a private type and submits a step function. So this is basically for tractability. It seems to be reasonable given the data that we have.
06:30:20.792 - 06:30:28.326, Speaker B: Is it important that dealers did twice and then update rather than just waiting until after customer? Yeah.
06:30:28.348 - 06:31:11.774, Speaker G: So I haven't told you this here because I wanted to save some time. But the way it's written right now dealers wouldn't have an incentive to bid early. They would wait until last minute. There would be zero bids in the first stage in the data you do see these updates. And so the way we write down not only we also Jakob and Ali in their earlier paper they wrote down their model is by including a cost, not a cost, a random variable that the bid that you place will not make it in time. So that you always have an incentive to bid. So think about these early bids as five minutes before the deadline and then the last bid last minute before the deadline.
06:31:11.774 - 06:31:19.000, Speaker G: And when you place five minutes before the deadline you think maybe later bid is not going to make it. I didn't write this down here so it's a valid question.
06:31:20.650 - 06:31:25.562, Speaker B: Observe what happens in that one. No.
06:31:25.616 - 06:32:16.394, Speaker G: The dealers bid directly to the auctioneer. Nobody sees the bids but the auctioneer. Only the customers bid through one dealer and this one dealer will observe the customer bid, nobody else. How do bidders and dealers behave in the equilibrium? So dealers will commit to participating in all upcoming auctions if their cost draw the opportunity. Cost shock that they draw at the beginning of the year is below the surplus they expect to obtain from participating in all auctions of the upcoming year. Here coming back to the question that was raised earlier the expectation is taken over how many other dealers will participate in the year because at that point in time that's not known yet. A customer will know this and they enter an auction, an upcoming auction.
06:32:16.394 - 06:33:04.270, Speaker G: If the customer cost is below the expected surplus of the upcoming auction how do dealers and customers bid for dealers? We already know this from the econometrical paper. So this is just a refresher. Dealer has an information theta which includes the private signal of the dealer. And in case the dealer observed the customer bid, it also includes the customer bid or in our case the quantity weighted average customer bid. The dealer then chooses the bid to maximize expected auction surplus conditional on its private information. And taken given how everybody else behaves in market clearing. When you solve this you will find that dealers because this is a payers bid auction they shade their bids so they place a bid that equals to the price.
06:33:04.270 - 06:33:40.502, Speaker G: The price equals to the full willingness to pay at that specific step that's the first term VTD at that step. And then they shade their bid. And the shading factor depends on the distribution of the price at which the market will clear. So this is a shading factor that is known in this literature, which is why I won't go into detail here. One thing that I want to point out, because that's going to be different for customers, is that for dealers, ties can only occur at the last step. And that's intuitively because for a dealer it's not optimal to bid above your value, it can't be optimal to bid above your value. You would lose surplus.
06:33:40.502 - 06:34:47.294, Speaker G: And so in case you tie, there's always a way to deviate to avoid the tie other than at the last step. Now, how do customers bid? This is in terms of bidding, our novelty relative to the literature. Customers know that dealers only will update their own bid if the quantity weighted bid of the customer changes. So this is our simplifying assumption that will make the problem tractable. Why is that going to make it tractable? Because we can split the entire maximization problem into two parts. First, we will, for a fixed quantity weighted bid value, look for the biding function that achieves highest expected auction surplus among all functions that induce the same dealer updating behavior. So, even though I don't know the type of the dealer and the dealer can do crazy things, I know by assumption that the dealer will not update its bit in different ways if the quantity weighted, my quantity weighted bit doesn't change.
06:34:47.294 - 06:35:50.174, Speaker G: And so I have a good idea on what happens in terms of updating behavior. Mathematically, this looked like this. You have the first term that looks the same as for the dealer, so you maximize your expected surplus. And then you have this extra term which says that now you're only looking among functions that produce the same quantity weighted bit, so that you trigger the same dealer updating behavior. And then in the second step, among these partially optimal functions that you found in the first step, you just choose the best one. If you solve this first oops the first problem, this one, you get an expression that looks similar for dealers, similar than for dealers, but that has two extra terms which make things a little bit ugly. The first term here comes from the fact that you're currently only looking among functions that produce the same dealer updating behavior, so that have a specific quantity value bid.
06:35:50.174 - 06:36:36.498, Speaker G: So you have this term and then there is a term ties which if you look in the paper, it is very ugly. It includes all cases where the customer will tie with another dealer, with another bidder and is therefore rationed. So there are two key difference between customer and dealer behavior, which is that for customers it can be optimal to bid above your value. And tie with another bidder and be rationed as a consequence at any step. So that's a little bit counterintuitive. Why would you ever want to bid above your value? So let's go through an example. Consider a customer who submits this nice step function and assume that the solid line.
06:36:36.498 - 06:37:19.150, Speaker G: So here on the x axis we have the BQS, the prices and the quantities. The solid line is a function where all the prices are below your values. And now think about whether it might be profitable to deviate to another function where you bid above your value at the fourth step. Which means that you're just extending the fourth step out by assumption. Then, because the value function is decreasing here in this area, you're bidding prices above your value. Now, this deviation will increase the quantity weight a bit of the customer. And so it's going to, loosely speaking, signal to the dealer that the dealer will face a more competitive auction.
06:37:19.150 - 06:38:00.720, Speaker G: In response, the dealer likely will update its own bid towards a more aggressive bid with a higher quantity weighted average. So here's one way in which the dealer might update its bid. The dealer now bids place switches from the solid line to the dashed line. The dashed line at all points is above the solid line, but at one specific point where it is below the solid line. Now, where the updating lies exactly is going to depend on the distribution of types which I haven't specified and the strategy. So there are many, many ways where this could lie. This is just one example.
06:38:02.690 - 06:38:03.102, Speaker B: Okay?
06:38:03.156 - 06:38:57.200, Speaker G: So the customer doesn't know where the market will clear because the customer doesn't know the private types of the dealers and all the other competitors. But the customer knows the distributions, has a belief on where the market will clear. So the customer can look at different realizations of the market outcomes and see whether it does better or not. So here is one realization of the market outcome initially with our initial bid, where the customer step function is this one and then the residual supply curve. So the amount issued minus the aggregate demand of all the competitors is here. Currently at the initial bid, the market clears here. If the customer deviates to biding above its value at the fourth step, the dealer is going to update, assuming that everything else will stay constant, the residual supply curve changes from here to here.
06:38:57.200 - 06:39:29.238, Speaker G: And given the way we constructed these curves, we will see. When you do this many times you can flip back and forth, I'm not going to do this. Now, the quantity increases, which means that because you are winning at your third step, you're winning in an area where you're still paying prices below your values. You are getting positive surplus. So that's good for you. In this case, it's optimal for you to deviate to bid above your value at the fourth step. Now, in this example, the customer didn't tie.
06:39:29.238 - 06:40:03.240, Speaker G: But this was only one realization of where the market could clear. There could be other realizations of this residual supply curve. And we could easily imagine one realization that goes through this fourth step. And if we are here at the end, the customer is going to be happy to tie and be rationed. So win less because at that point in the function the customer bids above its own value. So you're happy to win a little less because you're not overpaying as much for too many units in the data. For customers it's pretty high, it's 20%.
06:40:04.410 - 06:40:09.926, Speaker B: And the price granularity was 10th of.
06:40:09.948 - 06:40:15.260, Speaker G: A basis point or under, I think it's a 10th. But I had to double check that.
06:40:20.830 - 06:40:31.040, Speaker B: Price granularity because I read if you had very high points of pie, I'm going to start to suspicious that there isn't some communication going on.
06:40:35.170 - 06:40:56.920, Speaker G: So in terms of our model for customers, we cannot rule out that customer ties with a positive probability at any step. So observing a lot of, a lot of ties, 20% of ties for customers doesn't violate our model. There might be other models that can also produce ties, but this wouldn't be against the model that we wrote down.
06:40:57.850 - 06:40:59.078, Speaker B: Let me speed up a little bit.
06:40:59.084 - 06:41:50.882, Speaker G: Because I still want to talk about the estimation and the counterfactuals. Okay, what do we want to learn? We want to learn the value curves for dealers and customers and the cost distributions for dealers and customers. We will do that in the standard way, which is to assume that the dealers and customers are rational and behave like in the game that we wrote down. And then we back out the value distributions and the cost distributions by matching the observed behavior with the predicted behavior from our model. How do we do that for values? Well, for values we know how to do that for dealers. We know from Jakob Castle's paper that we can point identify the value of a dealer using the first order condition with the Shading term that I showed you. And that we can point identify this value for each step that is submitted.
06:41:50.882 - 06:42:40.834, Speaker G: So not everywhere, but for each submitted step for customers. Because customers might tie at any step in the function. The equilibrium condition doesn't only depend on the steps that you submit, but on all potential quantities because you might be rationed everywhere. And so identification becomes difficult. And we use a lot of long lemma to go through deviations and leverage that we are assuming monotogenesity and boundedness of this function to show that we can partially, partially we can bound the values for customers. Customers are willing to pay more than dealers, about seven basis points more, which is quite significant compared to, for example, bid us spreads. This is what you see in the graph.
06:42:40.834 - 06:43:30.454, Speaker G: It shows you the average customer value minus the average dealer value in an auction. So one point is one auction and then the distribution over auction for both the lower bound estimates of the customer value and the upper bound estimates for the customer value. So customers are willing to pay more, which means that they expect to implement more profitable trading strategies from using the bonds after the auction, perhaps because they can do more things than dealers are able to do with the bonds. For cost estimates we match the predicted participation probabilities with the observed probabilities. We find that both cost estimates for dealers and customers are quite high. So these opportunity costs are quite high. For dealers, there are about 0.1%
06:43:30.454 - 06:44:15.510, Speaker G: of the average amount that the dealer wins in a year for customers is 0.3% of the average amount that the customer wins in an auction, which because they win a lot, translates into a big monetary value. Now, we want to analyze how customer entry affects this trade off that I mentioned before, competition versus volatility, how we will do that. Well, we will run counterfactuals. And to run counterfactuals we rely on Eric's amazing technique through which we can compute counterfactuals in multi unit auctions. We do a twist in that we allow bidders to demand slightly more than they are doing in the status quo. But I won't go through this for the sake of time.
06:44:15.510 - 06:45:01.330, Speaker G: Here we run the counterfactual where we vary the number of customers in a typical auction. So we're taking the median auction in our data and compute the equilibrium many times when there are 25 expected customers participating and so forth until zero expected customers participating. And I'm showing you here how the expected price at which the auction clears varies in the number of expected customers that participate in the auction. You see that there is a nice curve. The observed status quo is somewhere here, as I said, about an average six customers that are participating. Attracting one customer and expectation brings a revenue gain of roughly 2.9 million or nine basis points.
06:45:01.330 - 06:45:37.096, Speaker G: Which means that if here is the status quo, you're basically moving up a little bit. I can't really do it because I'm shaking too much. You're moving up that curve a little bit because you're attracting one customer, an expectation, which gives you a revenue boost. Now you have also revenue loss if customer participation is irregular. Why? Because again, that's going to be difficult. If you take one customer and you move them out and in and out, in and so forth, you're moving down and up this curve. And whenever you're going down, you lose more revenue than when you're going up because this curve is concave.
06:45:37.096 - 06:46:44.000, Speaker G: And so if you have irregular participation, that translates into a revenue loss and the revenue loss tends out to be similar to the revenue gain from attracting one customer. The last thing we do is we ask whether we can design a policy that reduces volatility and increases competition in the auction. Now, typically it's very difficult. And I have struggled with this myself to find something that does better than central banks are already doing. So we had a hard time with this. We went through some policy changes, for example in the commitment in the commitment that didn't work but we found one policy that leverages the fact that we can predict in which customers select in which auctions customers select into. So the idea is to take a little bit of supply in auctions that are attractive to customers and put it into auctions that are not attractive to customers to attract more customers in auctions that are not attractive and thereby stabilize customer participation at an average level that is sufficient high to both decrease volatility and increase competition.
06:46:44.000 - 06:47:07.590, Speaker G: So in this paper we study entry and exit in the market for Canadian treasuries. We highlight competition versus volatility trade off which we think is present in many other markets and we propose a policy that is specific to our market setting which can increase revenue by 50 basis points. I think we are out of time.
06:47:08.300 - 06:47:41.020, Speaker B: One thing to do is eliminate the dealers and trade more frequently. So in fact you go all the way to flow trading where you're just trading very small amounts and then it becomes some people just looking at the price process and optimizing with respect to a very well preserved price process. Any particular event has very small trading so there's no market power. You use uniform price option which we learned is optimal rather than pay a bid.
06:47:44.100 - 06:48:06.036, Speaker G: Yeah. I think there are ways that market designers would think that treasury auctions should be run differently. I'm pretty sure that the Central Bank of Canada would not allow me to go from treasury auctions to continuous flow trading. But I do have some hope that they will implement this policy. They're actually quite interested. So in that sense I think we're focusing on these counterfactuals not on the bigger steps that might make more sense from a theory perspective.
06:48:06.068 - 06:48:11.470, Speaker B: I think we should take questions offline so that everybody can get their well deserved break.
06:48:12.720 - 06:48:14.030, Speaker D: We'll be back in.
06:48:19.920 - 07:01:31.752, Speaker B: Back in half an hour. 415. But that's there's like you're getting to, um also never been until we went for a year, so yeah. And and on the very terms not in and wins, basically. Is. Yeah. Basically you're actually if you're actually expanding surprising already did and sort of show that it has been distorting the process away reality.
07:01:31.752 - 07:01:33.020, Speaker B: Some cases.
07:01:35.440 - 07:01:36.190, Speaker G: Yeah.
07:01:42.960 - 07:16:31.630, Speaker B: Investment some people here that possibility. Abstract, actually in bowsh like sorry about that. Second.
07:16:33.520 - 07:16:35.310, Speaker E: Can you take the slide down, please?
07:16:36.240 - 07:16:39.468, Speaker B: Thank you. Okay sorry about that. I thought it was down it's going.
07:16:39.474 - 07:16:40.430, Speaker A: To be 1 second.
07:16:44.560 - 07:16:59.830, Speaker B: So I think now and you're all set. Okay wonderful, thank you. All right.
07:17:26.860 - 07:18:21.048, Speaker A: Okay thank you for having me. This is joint work with Water Desein who is somewhere and Alex Frankel who's at Chicago and could not make it so we are thinking about college admissions. And as many of you are probably familiar with, there has been an increasing trend over the last couple of decades in which colleges in the United States are no longer requiring standardized tests from their applicants. And this sort of started a while back, but I would say sort of became especially prominent last decade. And so here's a screenshot from the Washington Post in which it's talking about the University of Chicago, which was the first top r one university that went test optional, meaning that students could choose whether to submit their standardized scores or not. And just a little bit of a.
07:18:21.054 - 07:18:21.764, Speaker D: Quote from the article.
07:18:21.812 - 07:19:21.900, Speaker A: It sort of says, debate over admissions testing has intensified in recent years. Studies have found a strong link between scores and economic background, and schools that drop test requirements often say they're doing so in the name of wider access. And so one thing I want to emphasize is that this is a pre COVID trend. So by 2019, about a third of colleges in the United States did not require test scores, for obvious reasons. This exacerbated during COVID and in fact, in the 2021 22 season application season, virtually all schools, 95% of them, did not require tests. The interesting thing is even post COVID, if you want to call it that, when certainly the physical restrictions for testing have largely receded entirely in the United States. Most colleges have stayed test optional and some are even test blind, like the University of California.
07:19:21.900 - 07:20:33.296, Speaker A: And this is certainly true for the near term, and many of them have even now started announcing permanent test optional policies. My institution, Columbia is one of them. I should mention that there are a couple of exceptions to this test optional, permanent, or even temporary announcements. So for instance, MIT did announce that it is now requiring standardized test scores for the current application season. However, it really is in the very small minority. There's probably about three or four top universities and by top I mean the terms sort of very broadly that are doing this. So the basic question that we are interested in as sort of people who think a lot about information is why exactly would colleges want to go test optional? And if you sort of think back to that quote from the Washington Post, even if it is true that tests advantage some students over others, and I think there's essentially no dispute about that, surely the tests have some informational content.
07:20:33.296 - 07:22:03.732, Speaker A: And I have this quote from the University of California Standardized Testing Task Force in which it says test scores are predictive of success for all demographic groups and disciplines even after controlling for a variety of factors like high school GPA. And so the question of interest for us know, why not require scores so B test mandatory, but just put very little weight on scores? If in fact, that is what is optimal for the college and potentially even do much more complicated things like adjust the weight that you put or adjust the thresholds that you use based upon various observable characteristics, demographics, socioeconomic status, et cetera. Zero weight is unlikely to be optimal. So our paper begins and I'm not going to be spending time on this in the talk, but our paper begins by formalizing a very simple impossibility result that says that under a broad set of conditions there is no benefit from going test optional. And you probably each have your own favorite story about why this impossibility result is really not a puzzle. And the one thing I will say is that one common explanation that people bring up is that there are costs of taking the test which are differential for different groups. And importantly, our model allows for the fact that there are differential costs to improve your test score.
07:22:03.732 - 07:22:47.628, Speaker A: But it is important that there not be a fixed cost of actually taking the test. And our view is that at least in recent years outside of the pandemic, that isn't actually a significant factor, at least if you sort of take the objective costs into account. So for instance, 25 US states prior to the pandemic required either the Sat or the act for high school graduation. So certainly then sort of taking the test cannot be one of the obstacles. Okay. But I'm happy to sort of talk more about that either towards the end or offline if anyone is interested. I will tell you instead what we do.
07:22:47.628 - 07:23:36.968, Speaker A: So our story is instead one about social pressure and roughly speaking, we are going to present a model in which colleges face costs for making decisions that an observer, let's call it society. This could be alumni, the courts, parents, et cetera. That does not agree with. So whenever the college makes a decision be that admit a student that society thinks should be rejected or reject a student that society thinks should be admitted, the college will bear some disagreement cost. And crucially this will depend upon the available information to both the college and society. So it's not going to be an asymmetric information story. It's instead just going to be about the fact that society sort of is not going to penalize the college for what regime it chooses.
07:23:36.968 - 07:24:05.988, Speaker A: It instead is just going to penalize the college for what decisions it makes given available information. And what we will argue is that not observing test scores is a way in which the college can endogenously, reduce the disagreement cost that it bears and potentially then also improve the decisions that it's making. From its own perspective. Of course, not observing scores is intrinsically bad for the college because it's less information and that's the trade off that.
07:24:05.994 - 07:24:07.076, Speaker D: We'Re going to explore.
07:24:07.188 - 07:24:08.120, Speaker B: Yeah, Mike.
07:24:17.740 - 07:24:48.196, Speaker A: So interestingly and I will elaborate on this very soon the argument will work regardless of whether the college sort of wants to be more selective or less selective for any particular group. In fact, we will allow for there to be different there are different groups of applicants to a college and it may be that for some groups the college wants to be more selective, for some groups it wants to be less selective. The basic idea will apply regardless of which way that goes. And you could easily imagine, depending upon which college and which group, that the.
07:24:48.218 - 07:24:49.750, Speaker I: Preference could go either way.
07:25:16.480 - 07:26:12.990, Speaker A: So as I would say, our story is related but distinct. So it is certainly true that's still a story where not observing information somehow benefits the college because of this observer. However, what's going to be important for us is that it's really about sort of affecting the belief about the observer, about whether a particular student should be admitted or not. So it's a related story where you are trying to avoid seeing information in order to sort of reduce the impact that an observer has on you. But the mechanism, I think, is going to be a little bit more nuanced than it's not a story about you don't want a lawsuit that is purely based upon sort of the evidence that is available independent of the belief that the observer is holding. For us, it really is going to be a story about affecting the belief that the observer holds. So I think it'll become a little bit more clear as I go along.
07:26:12.990 - 07:27:14.240, Speaker A: Okay, so if we take this social pressure mechanism as given, we are interested in understanding what exactly a test optional equilibrium looks like. So how might a college compare students who submit scores and don't submit scores? Which students actually do submit scores? How do the outcomes differ under test optional versus test mandatory? So we'll be able to say a little bit about which students benefit and which ones are harmed. And then sort of the question, the main thing sort of that we're interested that started us out is when exactly is that colleges prefer to go test optional? And it'll turn out that basically this really depends upon how flexibly colleges can treat non submitters in a way that I will make precise. And we have an extended example in the paper of how an affirmative action ban may trigger or exacerbate colleges choosing not to see test scores, which I presume you see is sort of why that would be of relevance.
07:27:15.780 - 07:27:18.896, Speaker B: Okay, so what I would like to.
07:27:18.918 - 07:28:02.192, Speaker A: Do is basically now spend a bit of time going through a simple example. It's got late in the day. In some ways this is very obvious for lots of theorists, but I think it's useful to sort of basically explain the fundamental mechanism that's driving our results. So let's consider a student at some given set of observable characteristics. So this is all the GPA, extracurricular activities, any other demographics, et cetera, that you would like to think of as being observable to the college. And let's suppose that the test score which is going to be denoted T for this student group. Think about it as just being a representative student from that group is just uniformly distributed from zero to 100.
07:28:02.192 - 07:29:09.940, Speaker A: And society the observer has some utility function that depends upon the test score. Again, I'm suppressing sort of all of the other observable characteristics. And let's say it's just this affine function test score -40 if the student is actually accepted we're going to normalize the rejection utility to zero and what this means, therefore, is that society would like the student to be admitted if and only if, the student score is above 40. The college is the one that decides whether or not to admit the student. And we're going to assume that there's social pressure on the college whenever the college's decision conflicts with what society wants given the available information and in particular the disagreement cost which we're going to denote d is proportional to the magnitude of society's expected utility loss from the college's decision. So to make that precise, here's a picture that really illustrates this. So the red curve, the upward sloping thing is the disagreement cost for the college when it rejects the student.
07:29:09.940 - 07:29:53.910, Speaker A: On the horizontal axis is the test score. And so what you notice there is that if the test score is below 40, there is no disagreement cost if the college rejects the student because society also wants the student to be rejected. And whenever the test score is above 40, the disagreement cost from rejecting that person is linear. And this is sort of an assumption that it's proportional to the amount that society disagrees with the decision. Conversely, the blue curve denotes what happens the disagreement cost if the student is being accepted. And this is sort of symmetric where now it's zero if the score is above 40 because now society wants the student to be accepted and it's linear below 40.
07:29:54.600 - 07:30:01.460, Speaker B: Yes. Bobby. Yep.
07:30:07.750 - 07:30:08.500, Speaker I: Yes.
07:30:10.710 - 07:30:11.218, Speaker B: Correct.
07:30:11.304 - 07:30:28.040, Speaker A: So we are making the strong assumption because we want to sort of focus attention elsewhere that there is no asymmetric information between the college and society. So of course that's a very stylized assumption but we want to focus somewhere else.
07:30:29.950 - 07:30:34.026, Speaker B: Okay, so what is the disagreement cost.
07:30:34.208 - 07:30:56.494, Speaker A: The expected disagreement cost for the college of accepting the student regardless of the test score. And so think of this as now the characteristics, the observable characteristics correspond to some group of students that the college really wants to admit. So the student is a fencing champion for instance. And so apparently Ivy Leagues really like fencers.
07:30:56.622 - 07:30:57.300, Speaker B: So.
07:30:59.030 - 07:31:40.670, Speaker A: The expected disagreement cost of accepting regardless of the test score under test mandatory is something positive. Okay, you can sort of written out what the integral is if you can see that light gray shading. But the point is that the college is accepting some students who are below a score of 40 and so therefore there will be some disagreement cost that the college is bearing. On the other hand, if the college were to be test blind, not see the score at all and therefore society does not see the score either, well, then the college actually bears no disagreement cause from accepting the student regardless of the score. The reason being that under the prior, the expected value under the prior.
07:31:42.850 - 07:31:43.870, Speaker B: Is 50.
07:31:44.020 - 07:32:09.126, Speaker A: And so the society's expected utility from admitting the student with no information is positive. It's 50 minus its threshold of 40. Okay, so this is what happens if if the college accepts the student regardless of the score. We could also think about what happens if the college wants to reject the student regardless of the score. I live in New Jersey, so think of the student as being a New.
07:32:09.148 - 07:32:09.910, Speaker C: Jersey.
07:32:13.470 - 07:32:47.070, Speaker A: Now under test mandatory. There is some cost, expected cost for the college and you can kind of work out what it is. It's basically whenever the student is rejected and society wants that person to be accepted, we just sort of integrate up that red curve and it has some value. It turns out to be 18. If instead the college were to go test blind and reject the student without seeing the score at all. And therefore, again I repeat, society does not see the score either. Well, now, sort of society's expected utility under the prior is the same thing as before.
07:32:47.070 - 07:33:35.218, Speaker A: So it's something positive. But importantly, it's still smaller than the cost that the college is bearing when it does see the score. Okay, what's going on in this numerical example, it's probably very clear to many of you, regardless of whether the college sort of wants to admit the student or not admit the student, if it wants to do so regardless of the test score, it's better to just not see the score at all. The reason is that society is bayesian, but it's judging the college based upon the available information. And effectively this is like the college just wants to choose an information policy in order to minimize this function. And this function is a convex function. This disagreement cost function is a convex function either way.
07:33:35.218 - 07:33:40.914, Speaker A: And therefore it's best for the college to just not have any information. This is Allah Bayesian.
07:33:40.962 - 07:33:42.550, Speaker I: Persuasion, logic.
07:33:44.810 - 07:34:44.940, Speaker A: So pooling the students is beneficial. And so in these extreme cases, if the college wanted to make a decision that's independent of the test score, just not seeing the score whatsoever would be the optimal thing for the college. In general, of course, the college would want to condition its decision upon the test score to some extent. And so here's just an example. So suppose that the college now wants to it's still sort of more selective than society is about these New Jersey applicants, but it does want to admit the New Jersey applicant if they have a really high test score. So let's say if their score is above 70 clearly sort of the college cannot implement this policy of admitting the applicant if their score is above 70 and bearing no disagreement. Cost if the college uses either test mandatory because then there will be a cost born whenever the person is rejected between 40 and 70 or under test blind because then the college cannot use the test score information.
07:34:44.940 - 07:35:32.040, Speaker A: However, with test optional now, the college can in fact get its first best, namely its preferred decisions without any disagreement cost being borne. And here's how you can do it. So suppose that the college uses a policy where the student is free to submit their score or not, and the college will only admit the student if they actually submit a score that is above 70. So if the student either submits a score below 70 or does not submit a score, the college will reject the student. Well, in this case, students with scores below 70 are indifferent. And if you're worried about sort of the indifference, we can kind of perturb things in order to break the indifference. So that should not be your focus.
07:35:32.040 - 07:36:06.530, Speaker A: So the students with a score below 70 don't submit it, and they only submit it if their score is above 70. Well, now, sort of the college will in fact get its preferred decision. Moreover, since the expected value of the score below 70 is 35, which is below the society's preferred threshold, society is happy for the students to be rejected when they don't submit scores. So now the college actually gets its preferred decision with no disagreement cost born.
07:36:14.710 - 07:36:15.230, Speaker B: Yeah.
07:36:15.320 - 07:37:08.774, Speaker A: So I haven't told you exactly what the model is. So this was just an example to say, here's a simple case in which the college can actually get its first best. And maybe you're sort of foreshadowing where I'm going, which is in general, we need to specify sort of exactly what can the college do, what is the space of policies that it has available? And we will see that this was just a simple example. In general, the college is not going to be able to get its first best. There's going to be this trade off that I mentioned in the introduction between making decisions that it prefers and the cost of disagreement. And moreover, coming to Mike's question, it has to account for different groups. This was just a particular horizontal slice of a particular group and it's not going to be able to condition whether it requires tests or not based upon the demographic group of the students.
07:37:08.774 - 07:37:21.020, Speaker A: And so we're going to embed all of these considerations in a richer model of test optional admissions. So I'll just pause for a second because this really is the main idea in the paper.
07:37:21.630 - 07:37:36.494, Speaker B: Yeah. Yep. So, yeah.
07:37:36.532 - 07:38:09.574, Speaker A: So the question is about commitment power. So the model is going to be one in which the college is going to have commitment power. I can talk a little bit later about what happens if the college doesn't have commitment power. But just notice one quick observation is that you would expect some kind of an unraveling result if assuming sort of some typical monotonicity assumptions, students will actually want to submit their score. If the score is really high, that should sort of unravel. There is evidence that a lot of students don't submit scores in the last couple of years in particular. So I think that is sort of prima facial.
07:38:09.574 - 07:38:16.830, Speaker A: One reason that suggests that at least we're probably not in an equilibrium yet, but we sort of aren't seeing this unraveling.
07:38:18.130 - 07:38:27.860, Speaker B: For schools that are test optional, is there evidence that the admission rates are significantly different for students who submit scoring versus don't especially?
07:38:30.950 - 07:39:01.690, Speaker A: Yeah, so basically it's really hard to get this kind of data. So I'm not aware of sort of much evidence of this. There are a couple of universities that have in fact, and I think actually one of the UWS, I think not Madison, but another one did sort of provide some information about this not broken up by demographic group or anything. And you can see that sort of there are some differences among the acceptance rate of those who do submit scores and those who don't, although I wouldn't say that there are of a magnitude.
07:39:01.770 - 07:39:05.198, Speaker B: Order of magnitude difference, but I think.
07:39:05.204 - 07:39:06.960, Speaker A: There just isn't much data on this.
07:39:07.330 - 07:39:08.080, Speaker B: Yeah.
07:39:21.480 - 07:40:08.180, Speaker A: So no, we have a little bit of discussion at the very end of the paper in which we talk about capacity constraints. Formally, in the model I'm going to present, there are not going to be capacity constraints. However, you could sort of interpret the benefit that either society or college places on a particular group as implicitly being like accounting for a shadow value of the capacity constraint. Of course, that would be something endogenous, but in principle sort of that's the way we think about it. But let me sort of maybe present the model and then I can address a couple of these questions in more detail. Okay, so here's the model we're going to think about basically one student. Think of it as if you like, as a mass of students who is applying to a college.
07:40:08.180 - 07:40:50.908, Speaker A: There's just one college in the model. An important limitation of the model is that it's a partial equilibrium framework. And so the student has some observable characteristics x that's drawn from some distribution f x, the student has a test score T that is drawn from some distribution that depends upon x. So F of T given x, we have some technical assumptions. The college decides whether to accept or reject. The student makes a binary decision. And we're going to assume that the college's utility from accepting the student is an affined function of the test score, although both the constant and the slope can depend upon the observable characteristics.
07:40:50.908 - 07:41:30.460, Speaker A: So it's given by this VC of x plus WC of x times T that's the college's utility from accepting the student, we normalize the rejection utility to zero. The afion structure, we think monothonicity in the test score is natural. The afion structure is purely for tractability. Society's utility from accepting this student is analogous except that it can have different weights on both sort of how much it cares about the test score and also the constant which coming back, we could sort of interpret it as different shadow constraints.
07:41:32.160 - 07:41:32.812, Speaker B: Okay.
07:41:32.946 - 07:41:40.656, Speaker A: The college bears a disagreement cost whenever it makes a decision that society doesn't agree with. Society is bayesian. And so society is sort of going.
07:41:40.678 - 07:41:44.050, Speaker B: To infer point here.
07:41:44.500 - 07:42:43.924, Speaker A: So society is sort of going to infer that the student has a test score, TS, which is the expected test score given the available information. So if the student submits the score, this will just be the student score. If the student does not submit the score, this will be the expected value of the test score conditional on not submitting. So given the affine structure, we can write the disagreement cost as just being if the student is rejected, then it's zero if society would like the student to be rejected. So if society's utility is negative and it's just going to be society's utility from admitting the student if that's positive. So really just generalizing the example that I had. On the other hand, if the student is accepted, it's analogous where now if society wanted the student to be accepted, so if the max is zero, then it would bear a cost of zero.
07:42:43.924 - 07:43:32.390, Speaker A: And on the other hand, if society wanted the student to be rejected, namely society's utility for admitting the student is negative, then it's proportional to that magnitude. So it's just minus society's utility. Again, let me just repeat. You should really interpret both of these utilities here as being the expected utility for society given the available information because of the affine structure. It's just entering as if the society is just treating the student as having the inferred test score. And so the college's full payoff then is just its underlying utility minus some scaled disagreement cost. And so delta here is just a scalar parameter that we can use to take comparative statics, although I'm not actually going to say very much about that in the talk.
07:43:36.820 - 07:43:50.070, Speaker B: Yes, convexity.
07:43:51.930 - 07:44:35.154, Speaker A: Essentially. Sorry, I should repeat the question. So the question is what's important about the way in which we model this disagreement cost? The important thing is really going to be that the disagreement cost is convex and this piecewise sort of linearity is just a simple structure that allows us to say more than that. But that's really the key underlying intuition. Okay, so a few sort of observations and then a little bit more about the model. So repeat, there is no asymmetric information between the college and society here. The observable X is always observed.
07:44:35.154 - 07:44:59.434, Speaker A: No matter what admissions regime the college is using, the test score will be observed if we're in a test mandatory regime. And the test score will be whether the student submits the score or not will be chosen by the student if the college chooses a test optional regime. You could also think about a test blind regime in which the student cannot.
07:44:59.482 - 07:45:01.150, Speaker B: Submit the test score.
07:45:03.090 - 07:45:23.426, Speaker A: Okay, and so what is an admissions policy? The college is going to commit to a pair of functions. So one of them we call the imputation rule. And you should really think about this as what is the score? The college treats the student as having conditional on all of their observable characteristics if the student chooses not to submit.
07:45:23.458 - 07:45:26.402, Speaker B: A score in the test optional regime.
07:45:26.546 - 07:46:33.192, Speaker A: So formally, it's a map from the set of observables X into the extended real numbers. And we allow for plus infinity, minus infinity just for some convenience. And then paired with that imputation rule is an acceptance rule, denoted alpha, which is a mapping from the observable characteristics. And the score either imputed or submitted into a probability of acceptance. And we're going to assume for, we think, very natural reasons, that the acceptance rule has to be monotonic, meaning for a given observable characteristic, if the student submits a higher score or has an imputed higher score, the student has to be accepted with a weekly higher probability. We study both flexible and restricted imputation. And flexible imputation is the college can just choose any imputation function that it likes.
07:46:33.192 - 07:47:30.050, Speaker A: Restricted imputation is there are some exogenous restrictions on what kinds of imputations the college can do. And we think capturing sort of constraints that might come from external forces is one of the reasons why this formulation via imputations is actually useful. And I will say a little bit more about that in my next slide. So for those of you who are worried about general mechanisms, there is a result in the paper that the college using flexible imputation and monotonic acceptance rules is without loss of optimality. In other words, even if you thought about a broader class of mechanisms where the college simply commits to a mapping from everything that it observes into a probability of acceptance, and without using this sort of imputation formulation or without the monothey restriction, the acceptance rule, the college cannot do strictly better.
07:47:32.660 - 07:47:33.410, Speaker D: Okay.
07:47:35.380 - 07:48:19.212, Speaker A: I have a couple of quotes from colleges here. So if you sort of go on various college websites and look at what they say about their admissions policies, it's quite interesting. So Dartmouth, for instance, says, our admissions committee will review each candidacy without second guessing the omission or presence of a testing element. And I've highlighted without second guessing. And this to us is sort of suggestive that the college is actually I forget who it was, was asked about commitment, but that the college is sort of able to at least claims to have some degree of commitment about what it's doing. And notice in particular, this would be consistent with a non Bayesian. Imputation.
07:48:19.356 - 07:48:19.664, Speaker B: Right.
07:48:19.702 - 07:49:00.696, Speaker A: So we assume that the college can commit to what it will infer or how it will treat a student who does not submit a test score in terms of what test score? It will treat the student as if having and this in particular can be non. Bayesian USC says applicants will not be penalized or put at a disadvantage if they choose not to submit. You know, various colleges have statements like this. This is sort of intriguing because it's not clear sort of how all applicants who don't submit scores could not be at a disadvantage. How could that apply sort of to everyone? And what exactly does it mean not at a disadvantage relative to whom?
07:49:00.888 - 07:49:01.630, Speaker B: So.
07:49:04.400 - 07:49:47.576, Speaker A: One way we think about this is a possible restricted imputation rule is something that we call no adverse inference, which is the college will treat the student if they don't submit the score, as if they have the expected score, conditional on all the observable characteristics, but crucially, not conditional upon the fact that they have not submitted a score. So you'll be treated as sort of the average. And we could do a lot more complicated things. For instance, maybe the college sort of can condition on some dimensions like the GPA, but it cannot condition on other dimensions, like race and so on. This formulation, this framework is flexible with respect to sort of what kind of a restricted imputation rule we can assume.
07:49:47.608 - 07:50:10.260, Speaker B: The college has to use. Forcing you to single score is so restricted here, then, if you don't for anything, just reject everybody. Whereas if you treated somebody who didn't treat the acid or as sort of probabilistically having a prior distribution.
07:50:13.720 - 07:51:19.640, Speaker A: Yeah, but again, we sort of show that if you can pick your imputation rule, this framework is without loss of optimality. Okay, so how do students decide whether to submit? This was sort of another question that I posed at the outset. Our assumption is a very simple one, which is that students with characteristics XT will submit if and only if their actual score is above the impute muted score, given their observable characteristics. And this is optimal for the student because the acceptance rule is monotonic in the score. Of course, this assumes that the student knows the imputation rule and the student is playing a best response. Those of you who either have gone through or maybe going through sort of college admissions, not for yourselves, there's sort of certainly a lot of discussion about students being very uncertain about whether they should submit their scores or not. And we're essentially making an equilibrium assumption.
07:51:19.640 - 07:51:27.228, Speaker A: I are happy to admit that we don't think that we're in equilibrium, but.
07:51:27.394 - 07:51:28.670, Speaker B: Maybe that will change.
07:51:29.680 - 07:52:02.484, Speaker A: Okay, so just to wrap up then, what the overall model is. This is the payoff for the college. It's the underlying utility minus the scaled disagreement cost, where the disagreement, the inference that the college makes is the score. If the score is above the imputation because then the student will submit it. It's the expected score. Sorry, this is the inference that society makes. It's the expected score conditional in the score below the imputation if the student does not submit the score whenever it's below the imputation.
07:52:02.484 - 07:52:04.376, Speaker A: And then that's just reminding you what.
07:52:04.398 - 07:52:06.010, Speaker I: The disagreement cost is.
07:52:06.700 - 07:52:57.770, Speaker A: So one thing to note is that if the student submits the score and so that society then actually infers the score correctly, then notice that maximizing the overall utility for the college is equivalent to maximizing something that we call the exposed utility, which is just a convex combination of college's utility and society's utility. And this should sort of be intuitive even if the sort of exact form is not entirely clear, which is the college basically has its own underlying utility. The disagreement cost has something like the society's utility in here. And so if the score is actually submitted, what the college would do is basically just balance its underlying utility with what society wants it to do. And given the simplicity of our formulation, this is just a convex combination of the two.
07:52:59.260 - 07:53:00.104, Speaker B: Okay?
07:53:00.302 - 07:54:10.210, Speaker A: So I think in the interest of time, I'm going to sort of move forward. Let me tell you about our results. So our first proposition is that under test mandatory, the college admits the student if and only if the exposed utility, this convex combination of its utility and society's utility is positive and it rejects otherwise. This is very elementary because if the score is observed, all that the college is trying to do is sort of just choose. There's nothing for the college to do in terms there's no reason for it to be making a decision that doesn't actually maximize this conflict combination, it just uses the x post bar. And so this means, for instance, that whenever the disagreement parameter, the scaling parameter delta increases, the college is going to become more selective if society's bar is higher than its bar for that particular group of students. And this is extremely intuitive because the more sort of social pressure costs there is on the college, the more the college is going to make decisions like society wants it to make.
07:54:10.210 - 07:54:25.350, Speaker A: So this tells us, for instance, that students who are in a group where society wants the college to be more selective than the college wants to be, those students are going to be.
07:54:29.980 - 07:54:30.948, Speaker F: Harmed.
07:54:31.124 - 07:55:25.944, Speaker A: Whenever the disagreement cost parameter increases because now the college is sort of doing what society wants more. Okay, so turning to test optional, our first elementary observation is that in this framework, if the college can impute flexibly, then test optional is always weekly better for the college than test mandatory. And the reason is simply that the college could just set the imputation level to be extremely low. So that it's effectively as if, if a student doesn't submit the score, they're treated as having the lowest score. And then they may as well submit their score, right? So then this is just going to replicate the test mandatory outcome and therefore the college can't be worse off by being test optional if it can flexibly impute. And I stress sort of if it can flexibly impute because that is something.
07:55:25.982 - 07:55:27.290, Speaker B: That will be important.
07:55:27.820 - 07:56:22.220, Speaker A: Okay, so the thing that we're interested in is when and how can the college do strictly better than test mandatory. And what we will show is that at observables where the college is less selective than society, the college can sometimes do strictly better and sometimes it will do just as it will in fact replicate the test mandatory outcome. And at observables where college is more selective than society, so it has a higher test score bar, it will always do strictly better. That's what we find. And maybe let me sort of skip forward here is that statement a little bit more precisely. So let's consider flexible imputation and observables where the college is less selective. So the college's bar is less than society's bar and the exposed bar is going to be in between.
07:56:22.220 - 07:57:56.840, Speaker A: By definition, our result is that it is optimal for the college to either set an extremely high imputation level let's call it infinity or the max of the support of test scores at that observable and then accept everyone with that observable characteristic or to set the imputation to be the exposed bar and then accept the student if, and only if they submit a score that's above that imputation level. And in particular therefore reject non submitters because non submitters will have the imputation level rather than something above by definition. And so the logic behind this result is fairly easy to convey. So on the one hand, the key question that the college really faces is what imputation level to set and how do we treat non submitters? If the college is going to accept non submitters, well then it has to accept everyone because the acceptance rule has to be monotonic. So it may as well then set the imputation level to be the decision is going to be accept everyone. And then as I alluded to in the example, if we fix what the decision is for a particular group of students, then it's just better for the college not to see any information in order to reduce the disagreement cost. So then it may as well set the imputation level to infinity and therefore have no one submit scores at that particular observable.
07:57:56.840 - 07:58:56.104, Speaker A: So that's sort of the first possibility. And the other is, well, if it's going to be rejecting non submitters then it may as well set the imputation to be the exposed bar so that it's actually admitting all the people that it would want to admit if they were submitting scores. And that's the second possibility. Those are really effectively the only two things that the college has to choose between. Okay, so a result then about which students benefit and which students are harmed is that, well, under test mandatory, the students are going to get accepted if and only if they have a score above the exposed bar. And here, either the college is going to be accepting everyone at this group or it's going to be doing the same thing as test mandatory. So clearly it's going to be accepting more students at the observable characteristic where it is less selective than society.
07:58:56.104 - 07:58:59.870, Speaker A: In other words, at this observable characteristic, students are better off.
07:59:04.340 - 07:59:04.944, Speaker B: Okay?
07:59:05.062 - 08:00:07.830, Speaker A: The other case is what happens if the college is more selective than society, again at a particular observable characteristic. And here what we show is that it's optimal for the college to choose an imputation that's in between the X post bar and the college's preferred bar. So that's the first bullet point there. And what it does in terms of its acceptance rule is accept the student if and only if they submit a score that's above the imputation rule, the imputation level, and therefore it's actually rejecting students who don't submit. And here sort of the logic is a little bit more involved. So I'm not going to be able to explain sort of what the general argument is, but this really is my New Jersey example from the introduction, right? So where in that example the college's bar was 70, society's bar was 40. And so the exposed bar, if you sort of parameterize things equally, is going to be 55.
08:00:08.140 - 08:00:11.656, Speaker B: And that's sorry, I think I got.
08:00:11.678 - 08:00:16.890, Speaker A: My numbers mixed up. But anyway, this really is just the New Jersey example.
08:00:18.780 - 08:00:19.336, Speaker B: Okay?
08:00:19.438 - 08:00:37.970, Speaker A: So in this case, basically what we find is that the student welfare is just the opposite because now they're going to get accepted weekly less than under they're going to get accepted weekly less under test optional than under test mandatory. So they're going to be weekly worse off.
08:00:41.720 - 08:00:43.590, Speaker B: Thanks. Okay, so.
08:00:45.400 - 08:01:17.340, Speaker A: Restricted imputation in general, sort of for any given observable characteristic, the college may be hurt by having to be test optional or choosing to be test optional under a restricted imputation. And one question is sort of can we say anything systematic about which students benefit and which students are harmed? I think I'm running out of time, so I'm going to skip over this. But basically under some assumptions, we can say something. And the upshot is that this may sort of go in the same way as what happens under flexible imputation, or it may go in an opposite way as what happens under flexible imputation.
08:01:17.420 - 08:01:17.952, Speaker B: Okay?
08:01:18.086 - 08:02:27.350, Speaker A: So coming to sort of the college's preferences, does the college benefit from being test optional or not? We argued that under flexible imputation, it always benefits from being test optional. Under restricted imputation, it's ambiguous, right? At any given observable, it may benefit, it may hurt. And then we sort of need to integrate over all of the observables. So we don't have sort of anything very general to say about this. So what we turn to is an extended example that we work through in the paper and we sort of work through this in the context of thinking about a ban on affirmative action. And what we argue is that having a ban on affirmative action, meaning that the college cannot use sort of group membership in order to make decisions, can push the college from being test mandatory to being test blind. Loosely speaking, the intuition is that under a ban on affirmative action, the college may now value test scores less if higher test scores are actually correlated with the group that the college does not want to.
08:02:27.350 - 08:03:14.244, Speaker A: So coming back to, I think maybe Parag's question, this is sort of related to, but we would say distinct from just lawsuits that worries about lawsuits alleging illegal behavior. Because really the mechanism here is by doing this you are actually able to induce a greater degree of alignment in the preferences. Okay, maybe the last point is that we argue that the affirmative action ban can actually backfire on society because society does not want the college to use group membership, which is what it is able to achieve by banning affirmative action. However, society may want the college to use test scores and what the college does is actually respond by not looking at test scores. And this overall could be worse for.
08:03:14.282 - 08:03:18.016, Speaker B: Society in terms of the outcome.
08:03:18.128 - 08:03:30.920, Speaker A: Okay, so I'm done. I will just leave this conclusion slide up and I will stop here. Bobby, I would be happy to take a question, but I think Nikhil would be unhappy.
08:03:57.260 - 08:03:58.010, Speaker B: Yes.
08:04:02.980 - 08:05:06.052, Speaker H: Thanks. So I'm going to present to you Maximizing the Effect of Altruism, which was a title I was very proud of with its joint work with Brandon Lucier, who's my colleague at Microsoft Research, and Nick Wu, who's a student at Yale and was an intern with us two years in a row at Microsoft. So if any of you want to send your interns to Microsoft to do lovely work like this, please do. This really started with a blog post in January of 2020 when Brad Smith, who's the president of Microsoft, the guy on the left, Amy Hood, the Chief Financial Officer, one of my personal heroes. If you've never seen her command the room in an earnings call, you should really listen to a Microsoft earnings call. It's pretty fascinating to see how she manages all these aggressive men asking her questions, not unlike some of my own speaking experiences, but maybe higher stakes. Yeah.
08:05:06.052 - 08:06:44.580, Speaker H: And Sajya Nadala, who's our CEO, and in this blog post, this was when a lot of there was all the news about climate catastrophes before COVID before AI. And so they wrote this blog post saying that they were committing Microsoft to being carbon negative by 2030 and furthermore to remove the historical carbon emissions by 2050. And the problem that they were facing here is that there's just simply not enough carbon removal technology in existence in the world to implement these goals for Microsoft alone, let alone for all the other tech companies that were making similar commitments around this time. And so in response to that, they introduced a $1 billion Climate Innovation Fund to help spur technologies for carbon removal and they asked us what we would think they should do with this money. Not that they listened to us, but at least they asked. So this is, I think, becoming all the more salient and important these days as Microsoft invests more and more money in training massive neural networks to generate things like this picture, which is generated by Dali on the ironic prompt reforestation in the style of Picasso. It was the COVID of Microsoft's 2023 Climate Report, which I find amusing, if not ironic.
08:06:44.580 - 08:08:26.630, Speaker H: And so this is becoming a really challenging goal to reach. So what is this Climate Innovation Fund that they implemented? This is this $1 billion investment and they explicitly stated that they want to deploy this capital in two areas to accelerate ongoing technological development by investing in project and debt finance and to invest in new innovations through equity and debt capital. And so we were looking at this program and we were saying one way you could try to do this, to spend this money is to go instead of being in the business of trying to pick winners because hey, we're an enterprise company making software for other companies. We don't know anything about climate technologies really. So instead of trying to pick the winners of which technologies are going to do well in removing carbon from the atmosphere, we suggested a scheme whereby Microsoft would just promise to buy a certain number of carbon credits at a certain price in the future. And so this is reminiscent of advanced market commitments which we're not the only ones to have these kinds of thoughts. This is a political piece by Susan AThe at all suggesting this same approach that we were talking to Microsoft about and saying like this kind of advanced market commitments worked for vaccines, so maybe they could work for carbon removal as well.
08:08:26.630 - 08:09:19.460, Speaker H: So this is kind of the background. We abstracted this problem and it captures, we think, other scenarios. Things like an altruist, maybe an effective altruist is going to pledge to spend a fixed amount of money to address an environmental issue. And you could also imagine a government agency is maybe given a budget and a mandate to procure goods from a firm to alleviate some kind of shortage. This would be like the vaccine story. And in these motivating scenarios, the key aspect that we had in mind that we really wanted to model was that there's a fixed amount of money or a fixed budget. And so these procurement processes are required to take place with an X post budget constraint.
08:09:19.460 - 08:10:06.044, Speaker H: And so that led us to the following model. We asked about, okay, so there's a principal that wishes to maximize production of some agent and the principal is facing some constraints and informational environments that make this problem challenging. First, there's heterogeneous private production costs. So the firm or the agent here has a differing ability to produce these goods. And the principal also, as we discussed, that first bullet is saying like, Microsoft can't pick the winners in carbon tech. Right. The second bullet is saying that there's X post budget constraints.
08:10:06.044 - 08:10:41.372, Speaker H: We discussed that as well. There's a $1 billion climate fund and it's 1 billion. If Amy Hood says you have $1 billion to spend, you don't spend 1 billion in one. So that's the X post budget constraint. We also have no value for leftover budget. We're going to also relax that to a setting where you do have some kind of outside options. But this is the idea that we want to spend that 1 billion on carbon removal and all we can do is invest in companies in our extension.
08:10:41.372 - 08:11:44.470, Speaker H: We say, okay, maybe you could also buy carbon credits from other places or do something else with the money. And so I'll discuss that extension as well. So then our results in the context of this model, we solved this model, we've come up with a characterization of the optimal policy and I'll show that to you. But sort of some implications of that is that the optimal schedule here is always going to pool the most efficient types. So there's always pooling at the top. And you might think that, well, that seems obvious because there's a budget constraint, so you don't have the money to separate the types at the top. But in fact, that's not what drives this pooling or not the only thing that drives this pooling, because we will also see that for a certain type of cost function, so there's instantiations of the model where the pool size is actually independent of the budget size.
08:11:44.470 - 08:11:49.510, Speaker H: So as you get a higher and higher budget, you don't separate more and more firms at the top.
08:11:50.520 - 08:11:51.270, Speaker G: Yeah.
08:11:54.760 - 08:12:02.820, Speaker B: Setting budget, budget, advertising budget.
08:12:04.620 - 08:13:02.136, Speaker H: Yeah, I mean, just so long as you have this X post budget constraint and you don't get to spend the leftover money buying yourself. Alexis also, I just know effective Altruism as a title. So the practical takeaways that we might want to try and use to influence Microsoft would be things like, hey, your fund, how do you know if you're doing a good thing with that billion dollars you're giving away? Well, there's always pooling at the top. So you should adjust your schedule so that the highest offers are selected by multiple firms. This is like a very loose rule of thumb that you might try to talk to executives about. It's very interesting to try and influence policy and practice, you have to come up with very high level statements like this. We also could imagine saying if efficient firms are sufficiently rare.
08:13:02.136 - 08:14:15.536, Speaker H: This technology is super high risk and you have very low confidence in this being a scalable technology, then you should really kind of have a take it or leave it offer. So you just say you have some target production level and you pay the firm a fixed amount if they reach that target production and otherwise you pay them nothing. And you can also see from our modeling here that if there's outside options like you could spend some of this budget trying to plant trees or something, then you're going to have higher expectations of the efficient types of firms and lower expectations of the inefficient ones. So the optimal schedule is steeper, if you like. And so the fund should offer steeper schedules, the more confident they are in their outside options. There's obviously related literature here. I'm going to go through this quickly in the interest of time, but probably the most related paper here is Barron and Meyerson and the literature of monopoly regulation.
08:14:15.536 - 08:15:09.220, Speaker H: We're different from that because we're not looking into consumer surplus and we have this budget constraint. This is somewhat similar to the literature on delegation, but we allow for transfers. And of course there's a bunch of papers in this community as well as the computer science community looking at mechanism design for social good like we just heard about in the last 45 minutes. And so this falls in that space but is in a different environment. So for the remaining 35 minutes I'm going to give you the model. Then I'll discuss with you the optimal mechanism and the qualitative features of this optimal mechanism around the pooling. And then I'll discuss the extension to separable types where I'll also discuss this idea of outside options for the budget.
08:15:09.220 - 08:15:57.684, Speaker H: So in the model we have a principal agent design problem. The principal would like the agent to produce something costly. So the agent is going to produce some quantity x of this costly product like carbon removal. And the principal's utility is simply x. So the principal just wants to maximize the quantity of production. The agent has a type theta. And this is private information to agent drawn from some prior mu that the principal knows and that's parameterizing how efficient that agent is at producing x, producing this good.
08:15:57.684 - 08:16:56.544, Speaker H: In particular, we have a cost function for the agent. The agent is going to for quantity x, an agent of type theta incurs a cost that's some function of x and theta. I'll assume some form of this cost function which I'll present on the next slide and we'll normalize it so that it's zero for producing nothing, costs nothing to produce nothing. So the assumptions we have on this cost function, we're going to ask that it be strictly increasing in both arguments and twice continuously differentiable and super modular and PSI. And the derivative of PSI with respect to the type theta are convex and x. And we also need mu to admit a density function in a CDF. This is kind of a lot of technical conditions.
08:16:56.544 - 08:17:35.296, Speaker H: They're all pretty, I think, natural. The interpretations here are that the costs are convex and x. So we often think about having convex production costs. We have convex production costs here, and theta is a scalability parameter, like how easy it is for that company's technology to scale, to produce more and more quantity, which is something we care a lot about in the carbon space. And so a higher theta means the costs grow faster. So the lower thetas here are the better types. The lower thetas are, the more efficient firms they have, the more scalable technologies, the higher thetas means that the costs grow faster.
08:17:35.296 - 08:18:45.320, Speaker H: An example of a cost function that you can have in your mind that satisfies all these conditions is theta x squared. So by revelation principle, the optimization problem that the principal face, it's just looking for some schedule of production, schedule X and transfer schedule T that maps the type to output and transfer that maximizes the expected production subject to incentive compatibility. That's the first constraint that I've written there. Individual rationality is the second constraint, and the third constraint is the budget constraint. That's a hard constraint. So for all theta, the transfer to that type, theta, has to be within the budget constraint. Now, of course, we're not implementing direct revelation principle mechanisms with this Climate Innovation Fund, but any feasible solution can be equivalently represented as a transfer schedule that maps a quantity to an amount that we will pay for that quantity.
08:18:45.320 - 08:19:47.384, Speaker H: You can write this as an advanced market commitment, basically. So what's the optimal mechanism in this framework? The first step that I think everyone would write down is to look for some condition under which you can just look for the schedule X and get optimality out of just looking over the schedule X and computing the transfers to satisfy the incentive compatibility constraint. And so you can do that in this setting as well. But as you might expect, we have this monotonicity condition on the schedule. So X needs to be non increasing because the lowest thetas are our most efficient types. But we also have this second thing that doesn't usually show up, which is the budget coming from the budget constraint. So you need to pay the lowest type that's the most efficient firm, the cost of their production.
08:19:47.384 - 08:20:31.144, Speaker H: That's the first term there. And then they're going to get a bunch of information rent, which is the second term there, and that's the guy that you're going to be paying the most to. And so that thing needs to be less than your budget constraint. And of course, the optimal schedule is given by paying every firm their production cost plus their information rents. And this is just saying you can implement this as a subsidy schedule. So that lemma suggests that any decreasing Schedule X will do here. You can see, the first best line is if I knew theta, I could tell every firm what to produce and pay them the entire budget.
08:20:31.192 - 08:20:31.740, Speaker G: T?
08:20:31.890 - 08:20:32.524, Speaker H: I don't know.
08:20:32.562 - 08:20:32.872, Speaker B: Theta.
08:20:32.936 - 08:20:47.824, Speaker H: So I'm going to come up with some X. Any decreasing X will do so long as the weighted area under X is less than T. That's the budget constraint. And this already tells me that one interesting thing, which is if I'm ever.
08:20:47.862 - 08:20:50.656, Speaker G: Going to have any type produce the.
08:20:50.678 - 08:21:00.630, Speaker H: First best, it can be exactly one type that's producing their first best amount. And my production schedule will be a step function like this.
08:21:02.200 - 08:21:02.660, Speaker B: Cool.
08:21:02.730 - 08:21:52.004, Speaker H: So now how am I going to use this dilemma? To solve my optimization problem, I'll do what we all want to do, which is to just look over non increasing X, non increasing production. That's the first constraint there. But I also need to add in this budget constraint. So this is just rewriting. The Lama told me that all feasible schedules look something like this. So I'm just maximizing my objective with respect to a feasible schedule. And now, like in one of the earlier talks today, I'm not going to be able to optimize this point wise because of this global budget constraint there.
08:21:52.004 - 08:22:39.348, Speaker H: So I'm going to have to do something a little bit, do a little bit more heavy lifting. And in order to do that heavy lifting, I'm first going to write this as an optimal control problem, or interpret this as an optimal control problem, where I think about what I would normally think of as the time dimension in an optimal control problem. I'm going to think of the type theta as that time dimension. And then we can use optimal control theory to write the Hamiltonian and come up with necessary and sufficient conditions for the optimality of this program. In particular, this second constraint, which is just a single constraint. I'll take lambda to be the lagrangian variable of that second constraint, wrap it into the objective function. The first constraint I'm going to need.
08:22:39.348 - 08:23:28.150, Speaker H: This is like a continuum of constraints, because theta is a continuum variable. So I need a continuum of lagrangian multipliers, if you like, which is this row of theta. That's a co state variable. That's what the optimal control theory is giving us. So we take that co state variable as the lagrangian of the first constraint, and then we can wrap them into the objective and take derivatives and look at first order conditions and so on. So the interpretation of these constraints, lambda is the shadow value of money, and we'll look at that a little bit more. Rho is a bit harder to interpret in this setting, but maybe you have an interpretation for it.
08:23:28.150 - 08:24:38.520, Speaker H: And so then we apply paganian's, I can't pronounce that name, but optimal control theory solution to write down the conditions. The first thing here is complementary slackness. So if the rho is greater than zero, then x has to. Be constant, where rho is greater than zero. We also get the evolution of the co state variable rho. So that's just a first order condition taking the derivative of that Hamiltonian and then the equations three and four are just the boundary conditions that we have, and constraint five is the budget constraint. So the characterization says that there's an optimal mechanism, XT, which exists, and we get uniqueness if there's a lagrangian multiplier and co state function that satisfy these equations.
08:24:38.520 - 08:25:49.920, Speaker H: Okay, so here's just to have in your mind some sort of what a solution to that problem might look like. We're solving, of course, for this x and this Rho, which is a function of lambda. So the row, the co state variable starts somewhere, it has to start positive because we know that lambda is well, we know lambda is non negative. In fact, it's strictly positive, which we can show, and the PSI function is strictly positive. So rho starts somewhere positive, which means by the complementary slackness condition, when condition one there, when rho is positive, x is constant. And so we start moving like flat for x and falling for Rho. And then at some point rho becomes zero, at which point the schedule x can start decreasing.
08:25:49.920 - 08:26:55.220, Speaker H: So that already suggests to us the first qualitative feature that we see in this problem, which is that there's pooling at the top. This is the result I mentioned at the beginning. So if Rho is positive, as I said, then x is constant by complementary slackness and we know that rho is positive. So there's pooling at the top. Now you can do a little bit more digging and get some more insight by figuring out what this pooling threshold is. So what is the type where I'm asking them to produce the maximum quantity, that quantity of the most efficient firms? So, if you manipulate the math a bit, you can write this equation for the threshold of the pooling type. So theta hat is the largest type that receives the full transfer and produces the maximum amount, is the largest type that satisfies this equality.
08:26:55.220 - 08:28:14.860, Speaker H: And you can see now what the rationale is for this kind of equality. The left hand side here, you can think about that as the marginal direct cost that we pay to the threshold type. So if I take the threshold type, theta hat, and I ask him to increase his x just a little bit, like the x lower bar is the amount that the schedule has for the most efficient types to produce. If I ask him to increase just a little bit, I have to pay that much in direct cost weighted by the mass of firms at that theta hat. On the right hand side, we get the marginal information rent that you would then have to pay to the types that are more efficient than the theta hat. There's the CDF of theta hat mass of those firms and we have to pay them a little bit more in the information rents if we want to increase the production of the theta hat type. And so this suggests that the principal is facing a trade off between utilizing more budget on the inefficient types, which gets more production out of those inefficient types, versus providing information rents to the efficient types and where those balances is where the pooling threshold lies.
08:28:14.860 - 08:29:25.300, Speaker H: So that still doesn't give you intuition as to how does the pool change with the budget. We can try to think about that a little bit by looking at this shadow value of money. So this threshold equation I've solved for lambda already for you. But lambda is if you go one step back in the analysis, this threshold equation has a lambda there, which is the so now you can see that lambda is the marginal value of extra budget, is how much the principal can get out of types that are more efficient than the threshold. And so we should have complete pooling if this condition is satisfied. So we're going to get complete pooling if you always want to pay more in the direct cost to the marginal type because of the value of your budget. And so this gives us the following proposition for complete pooling.
08:29:25.300 - 08:29:41.710, Speaker H: And this I think also has an interesting interpretation, which is that if agents look, I have an upper bound on the CDF, right? What does an upper bound on the CDF mean? Intuitively, it means that.
08:29:43.680 - 08:29:44.236, Speaker C: You have an.
08:29:44.258 - 08:30:10.310, Speaker H: Upper bound on how many efficient firms you think exist in the world. So if the agents of efficient types are sufficiently rare, that is the CDF satisfies that lies below that upper bound, then it's going to be optimal to offer a single menu item. And so the.
08:30:13.240 - 08:30:14.084, Speaker G: Thing that we could.
08:30:14.122 - 08:31:08.112, Speaker H: Compare this to is a naive mechanism, the constant rate subsidy mechanism. So this is a mechanism that would offer just a per unit price up to my budget constraint. So I'm going to say I'll pay you one dollars per unit of production that you produce up until my budget constraint t and then I'm just going to stop paying you. Something else that we know is that this constant rate subsidy is of course suboptimal and that's because the agent is going to choose their marginal cost equal to the subsidy. But a mechanism can set transfers to get an average cost equal instead of the marginal cost. And so this mechanism is suboptimal. And we can see that in the following illustration.
08:31:08.112 - 08:31:40.400, Speaker H: This is the production schedule. The blue top curve on the left is the production schedule from the optimal mechanism and the orange one is the production schedule from the constant rate subsidy. So the optimal mechanism gets more production and it also gets less production from the less efficient types. Sorry, it gets more production everywhere and it spends less money on the less efficient types.
08:31:41.460 - 08:31:41.920, Speaker B: Okay?
08:31:41.990 - 08:32:47.540, Speaker H: So I wanted to talk a little bit about how the size of the pool changes with the budget. And here we can see that oh, Nick is here. So we can see that the lambda which I introduced as the shadow value of money, we can look at this x and this row and draw them on the graph with this dotted function. So let me introduce what these are. As you recall, we have the complementary slackness condition which says that if x is decreasing, then Rho, our co state variable, has to be zero by complementary slackness. And so if we look at the constraints for the evolution of Rho, that will tell us that lambda times PSI minus f has to be equal to zero. So that's the dotted line in this graph.
08:32:47.540 - 08:32:54.504, Speaker H: And when Rho is zero, x has to coincide with that dotted line.
08:32:54.622 - 08:32:55.736, Speaker G: What does this mean?
08:32:55.838 - 08:33:51.484, Speaker H: This means that we're optimizing point wise, so we can optimize point wise for the inefficient types or when Rho is zero. So we're optimizing point wise when Rho is zero. When Rho is positive, then we have pooling. And we can also use this to think about what happens as we get more budget, as the budget increases. Well, production costs are convex, so as the budget increases, the value I'm getting for every extra dollar is going down because I'm getting less production for each extra dollar. So as the budget increases, this shadow value lambda is decreasing, which means this dotted blue curve increases point wise. And whether Rho increases or decreases depends on these sort of parameters of the problem.
08:33:51.484 - 08:34:50.940, Speaker H: So it could go either way, which means that in order for X to hit that dotted line, it could happen earlier or later. So this slide suggests that the pooling region could increase or decrease as a function of the budget T. And what we find somewhat interesting is that it doesn't always decrease. So you're not always separating more types as your budget increases. And in order to illustrate that, I'm going to move to instantiation of the model where the pooling region is in fact independent of the budget. And that's the separable cost region that I introduced at the beginning. So we have a multiplicatively separable cost function, that is PSI is going to be theta x squared.
08:34:50.940 - 08:36:32.496, Speaker H: By multiplicatively separable we simply mean that it's some function of theta times some function of x and then we can solve our optimal control problem for multiplicatively separable cost functions and get a bit more clean closed form solution. And what we see is that the optimal mechanism is going to produce a schedule where the quantity of production that the principal requests is a function of the concavification of the CDF, of the types of the firms. So it might be easier just to look at the example with our theta x squared cost function, the schedule is going to be linearly proportional to the concavification of the CDF so what does this mean in terms of pooling? Here we can look at two examples. I have in this is the theta X squared cost function. The types let's imagine that there's just two types of firms, one and two. So firm one, the efficient type produces the good at cost of X squared and the firm two, the inefficient type, produces the good at a cost of two X squared. And mu is going to be the probability that the firm is of type one.
08:36:32.496 - 08:37:40.068, Speaker H: That's the proportion of efficient firms in the market. So if the principle the first result that we discussed previously is that when their efficient types are rare, we get complete pooling. And you now can see this because we have that nice closed form for this separable case. When the efficient types are rare, that is the probability of the firm being efficient is less than one half. Then the concavification of the CDF, which is drawn in blue, the concavification is the dotted red line. The schedule is going to be proportional to that dotted red line, which is constant at type one and two. And so we get complete pooling on the left, on the right, if the efficient types are sufficiently common, then the concavification of the CDF has a kink in it.
08:37:40.068 - 08:39:29.850, Speaker H: And so the production which is proportional to the PDF takes different values at type one and type two. And so we get a separating schedule. And what you notice here is that this argument, this solution said nothing about the budget t so this was invariant to change this kind of solution only depends on mu, whether I optimally want to separate types or not. So the pool size is invariant to changes in your budget t so I promised to talk a little bit about what happens if we have outside values. And so the principle you could imagine that Microsoft can spend some of this $1 billion on other things like, I don't know, putting data centers in the ocean to cool them and that kind of stuff. And so there's some value to what if I can obtain this X in an outside market, right? And if I can obtain X in an outside market, I might have some value for leftover budget, which means this would be one reason that we might not want to why you might want to include the transfers in the objective function of the principal. And so this changes our problem to have the principal optimizing instead of just the expected quantity of production x, the integral of X, it now wants to optimize x minus KT, where K is the per unit cost of obtaining this good in an outside market.
08:39:29.850 - 08:40:55.644, Speaker H: And so then you can ask about what the optimal mechanisms look like as a function of this k, this parameter of how good is the outside market. And you can use that same sort of optimal control theory I wrote down to solve this problem as well. But here I'll just show you in pictures since it's the end of the day and we're all tired. What you can see is that as the outside option gets better, so as K increases that's the green line there. Sorry. It gets more costly then the firm is demanding more from the more efficient types and less from the least efficient types and the size of the pool is shrinking. The other thing that we can look at is comparing this mechanism, the optimal mechanism, to a naive mechanism, which, instead of optimizing that problem, I can just pretend that I had no budget constraints and solve the problem.
08:40:55.842 - 08:40:56.216, Speaker F: Solve?
08:40:56.248 - 08:42:10.784, Speaker H: The optimization problem without a budget constraint, and then do this naive thing of let's pay for the production up until the budget constraint according to the naive schedule, and then cap it at the budget. So that's a naive mechanism you could implement. And the optimal mechanism, we can see it uses more budget and expectation than the naive sorry, less budget and expectation than the naive mechanism. That's the right hand side. And on the left hand side we can see the optimal mechanism gets more production from the more efficient types and less production from the less efficient types than this naive mechanism. So in conclusion, we've seen this model where we have fixed budget constraint and we want to optimize production. Maybe we have an outside access to buying on an open market some of this production and we solved for the optimal mechanism subject to a budget constraint.
08:42:10.784 - 08:43:33.020, Speaker H: This involved using optimal control theory because we couldn't optimize point wise for this optimal mechanism. And what we saw was that we get pooling at the top. So the principle always pools a positive measure of the most efficient types. We also saw that when this sort of naive mechanisms are going to be suboptimal so this constant rate subsidy, which is a common form of advanced market commitments, in which you buy quantity at a fixed rate up to some budget, this is always going to be strictly suboptimal. And finally, and this is kind of the question that Microsoft was very concerned about when they came up with this scheme in the first place is this scalability issue like Microsoft's very worried that they can't know which carbon tech is going to be the scalable type of tech. And so that's this idea that some firms are inefficient or more efficient than others, and the firms know better what their scalability is than the principal does. And so what we saw was that if efficient firms are sufficiently rare, then we should just offer a single target and pay the entire budget on meeting the target.
08:43:33.520 - 08:43:34.510, Speaker B: Thank you.
08:43:39.610 - 08:43:40.390, Speaker G: Mike.
08:43:42.730 - 08:43:45.790, Speaker B: We providers.
08:43:46.130 - 08:43:46.880, Speaker H: Yes.
08:43:51.490 - 08:43:53.390, Speaker B: Three potential providers.
08:44:02.310 - 08:44:48.046, Speaker H: Yeah. So we thought briefly about setting where we were trying so initially we were thinking about a setting where the firms are competing in a market and there's some market equilibrium that they're reaching and then we were just trying to increase the quantity produced in the market at large. So this was the version of multiple firms that we looked at and we have some results in that direction. But it's definitely something on the to do list is to get multiple firms here. This is clearly for a single firm and we could think about like if you had a per firm budget cap then but that's kind of cheaty.
08:44:48.078 - 08:45:46.000, Speaker B: I agree. Yeah. So I do want to argue that the analysis of this grade problem with the concept of strength, that comes up as a very useful problem because you have to enforce this transfer to the AIDS and by basically punishing them in the future. So it looks like in the reduced problem you solve. So he gets this pulling at the dog and also there's no efficiency at the dog because of the pool that you have, so and yes, same way. So that is all this you may get that in paper but I mean, he didn't do something careful and now I do.
08:45:49.930 - 08:45:50.582, Speaker G: Okay, great.
08:45:50.636 - 08:46:21.120, Speaker B: Thanks for the suggestion, Peter. Well, the particular example of carbon basement, one of the challenges is that when you're paying people to not do things then typically you have to come up with a baseline of what they would do without the subsidy. And that turns out to be a huge practical problem because it's all about them. It turns into a lobbying problem.
08:46:26.290 - 08:47:39.240, Speaker H: Oh yes, this is partly because we have such tight connections to Bill Gates, but Microsoft is really heavily into the carbon removal technologies of the form. Let's make a massive fan and blow air over some sludge that's going to capture carbon and then bury it deep in the earth. I think Microsoft's vision is to do that and not plant trees in part because this additionality of trees is very hard to verify and then they have a lot of ways of I don't know if they have methods for solving this, but they have a lot of discussions of the additionality. And when a project applies for this climate funding you can look online for the form. You have to argue about why this is an additionality as opposed to just replacement. But yeah, they're very not into the biosolution or not so into the BioSolutions. And part of that is because you couldn't plant enough trees on the arable land on earth to solve this problem.
08:48:00.020 - 08:48:00.770, Speaker B: You.
08:48:11.980 - 08:48:35.330, Speaker H: I mean, Microsoft would love that too. We also care a bit. So if you look a little bit more into the objectives, they have things like climate equity and Co benefits of biodiversity and things that sort of push towards the nature solutions too. So there's a whole portfolio, obviously.
08:48:40.020 - 08:49:06.230, Speaker B: Thank you so much. So we are done for today long day. We have a 45 minutes time interval before we head to dinner, which is across the street at Bambara. And tomorrow there'll be breakfast. Where? Just outside here at 830. And we'll start at nine.

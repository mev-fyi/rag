00:00:03.740 - 00:00:43.036, Speaker A: And next we have the spicy SGX panel with Andrew, Jonathan and Phil. So I guess I'll just go ahead with the segue. So I guess the fact that we don't have this merkle tree kind of memory integrity with the new versions of SGX is that kind of a deal breaker almost for SUAV, whereby SUAV is meant to be reasonably decentralized and trustless. And now we're saying that the enclaves might need to be run in Google cloud or what is going on mean.
00:00:43.058 - 00:02:04.470, Speaker B: Even if there's no integrity checks it's possible to do mitigations from the applications that are using it, but that would require being very careful about it. And it's not really just integrity because if you could tamper with the memory while an enclave program is running, you could end up tampering with some access control things that it's doing. So it could affect privacy as well as integrity in that case too, but broadly that's something that can be mitigated. I mean your kind of line of defense would be to add your own integrity kind of checking from registers that don't get paged out. The kind of related question to this I kind of most was excited to respond to is about the kind of difference between the cloud use cases and the client use cases. So the client use cases are clearly being deprecated, no longer supported by, I mean the origin of SGX was like for Blu ray players and digital restrictions management, anti user technology. I mean so that was the first time when everyone began hating trusted platform modules richard Stallman would have huge rants about so like everyone hated trusted hardware know before then because of that really despicable use.
00:02:04.470 - 00:02:43.330, Speaker B: So I think good riddance to the client side SGX ones. The cloud services though are really getting a lot of use out of this and really want it. So I don't see that going away. Like Xeon processors are still going to be supporting SGX of some kind. They really need the integrity checks too. So that's not like a thing that's just not on their radar at all. And I think the real challenge is how the decentralized blockchain applications will be able to blend in with the cloud use cases and act like good customers and not do something that gets them cleft out from the kind of support that the cloud services get.
00:02:47.240 - 00:03:45.396, Speaker C: Yeah, I mean I do think in terms of like obviously any product change to intel SGX like affects the plausible deployments. I will say Suave does not require perfect privacy or integrity necessarily. The goal of using SGX and Suave is partially as defense in depth to iterate the status quo. It's not the same as, let's say using SGX for consensus or something like that, in that if you do manage to break SGX and perform any of these attacks, you'll be able to kind of get an advantage in mev which certainly might be profitable for a short term until people notice. But it's not really the same as having your secrets kind of permanently leaked to the world or your consensus protocol falling over and losing billions or something like that. I think this is part of the loss of subtlety in the SGX world is people love to have very binary views on SGX. Like either it's broken or not.
00:03:45.396 - 00:04:30.052, Speaker C: Either it has integrity or it doesn't. Either you can use it or you can't. Either it's applicable to blockchains or it isn't. And to me there's a lot more subtlety in terms of what specifically are you using it for and does it kind of stand up to that use case. So a few things is like number one in terms of blockchains, I do think there are still blockchain use cases specifically in stopping a lot of these actors that maybe are a little bit stronger than honest but curious, like rational but curious actors from kind of having as much incentive to get an edge. And I think for that it actually could work really well. No matter even if the barrier is small, even if the Iterated game is messy, it still could work well.
00:04:30.052 - 00:05:20.550, Speaker C: And even if that kind of guarantee fails once in a while if a really kind of sophisticated attack gets pulled off. So that's my general answer for suave for all of this. Of course, as Jonathan said in his talk, we aren't like SGX maxis or anything, it's just part of defense in depth. Would love to explore other tees, would also love to have Fhe, although I think some separate spicy panel to be had there on the gap between kind of where we're at today and where we need to be to actually, in my opinion, be usable. So maybe I ranted too much, I guess. One more thing, andrew's question about how blockchain slips into the cloud, like I don't see why we wouldn't be able to do that. It seems like a lot of what people are looking at SGX for is like privacy preserving machine learning and things like that.
00:05:20.550 - 00:06:10.950, Speaker C: There seems to be an analog in this real time financial optimization to cooperative AI, to privacy preserving AI, so you could possibly see all these use cases converging in some way. And also I think the nice thing about mev specifically is it's like a constant real time problem. So whereas a machine learning problem like Android keyswipes or signal contacts or whatever other machine learning problems you might have, you kind of do it once or do it a few times or once in a while here you have to be doing it constantly and the more computation you have, the more you're doing it. So really intel should love that in my opinion, if their business is to sell hardware. So maybe that's how we slip in by just kind of making demand for their product real.
00:06:12.760 - 00:06:37.470, Speaker D: Yeah, that would be welcome, I guess, because I think one of the Pragmatic challenges as well is that it's pretty much only azure as of today that gives you all the flavors of it that you would like. So it's not great either for decentralization to just take it from the end of intel to put in the hands of.
00:06:39.950 - 00:06:51.246, Speaker C: Yeah, you did lag a little, Jonathan. I don't know if it was just me, but I think yeah, I agree with the sentiment, people are lazy and.
00:06:51.268 - 00:06:59.010, Speaker B: Love clouds but there's nothing stopping you from getting an Ikea rack and hosting your own Xeon processor. It's not like they're completely out of range.
00:07:01.030 - 00:08:02.040, Speaker C: Yeah, and if you're an Mev searcher and you want to do a lot of this local wide scale optimization, it seems reasonable to in the long term you're basically an infrastructure provider for crypto so having some server grade hardware seems reasonable to me. Again, not to say it's the ideal status quo where obviously we'd have magical encryption, but I think maybe this is another spicy take. It seems like all the alternatives to SGX introduce other gotchas for blockchains to me. So like MPC being the most practical example, MPC has scalability issues in the size of the committee, it has a really high bandwidth requirement and also it's much more efficient if you have low latency or if you can co locate. So all these to me seem to be equally bad to sometimes breaks if intel screws up and or someone spends a few million on some really good PhDs. But maybe I'm wrong, that's just my spicy take.
00:08:02.810 - 00:09:06.810, Speaker B: Robert covered a bunch of those in his talk. Some of those challenges with mean a lot of the most optimized ones and this is kind of the thing that we found we've been doing this Rattel project, there's a post about it that's like our MP speeds on uniswap kind of AMM and it's an AMM because that's the most complicated thing. We can basically get to work that's practical with MP speeds like a really simple operation and it was a challenge even to do that and we wanted some notion of robustness like availability. That's just what you expect with a blockchain system, but that's not the most desirable operating system. NPC people tend to prefer the maximum privacy and they'll have very systems that just topple over if any node fails. So all of the really hot interesting protocols where they're making the big speed improvements are mostly in the dishonest majority or N out of end sharing setting and then those just aren't applicable if you want something that kind of acts like a blockchain with its redundancy and fault tolerance.
00:09:07.710 - 00:09:36.210, Speaker A: On the topic of fault tolerance, I have a question for Phil about SUA. Presumably there isn't like one master t that's running SUAV. There's some amount of redundancy and in that context if one of the tes is compromised and breaks privacy, how do you detect which and we observe front running happening, how do we narrow down who to kick out of the Committee of Te Operators?
00:09:36.790 - 00:10:17.906, Speaker C: Yeah, so this is a great question and the truthful answer is we don't know yet. So we have kind of like the privacy abstraction for Suave and a few deployment scenarios with trade offs. I don't think we know exactly what we're going to go with. So we'll probably have more kind of community conversations about what makes sense. There the trade off kind of being from more distribution but less attribution and wider attack surface to more centrality and or layering even reputation or committees that would in my opinion, be bad, but we'll put it on the table. So these are the ranges of options you have on who to run it. Certainly one central party is not good, so we might as well just not.
00:10:17.906 - 00:10:50.890, Speaker C: I mean, I guess it adds a little defense and depth to trusting flashbots, but we definitely want more than one. And they should be like different economically kind of separate parties that provide competition and diversity. So that would be like the bare minimum. Ideally we distribute it so everyone's phone runs a swap node and the whole thing is like this chaotic global process. Same with ETH, right? The dream is to have that phone validator and practically you probably land somewhere in the middle as you strive for that thing, I would imagine.
00:10:52.770 - 00:10:54.110, Speaker A: Okay, understood.
00:10:54.530 - 00:11:35.754, Speaker B: I really liked with Suave that Suave has this goal of using enclaves for this disintermediation goal. Like you really want to use it. You'll run this in order to prove to all the people that are using this system that you don't have the ability to tamper with it. I think that's really cool. That's kind of rare in the SGX, I think kind of application world. People seem to be really satisfied with just getting their own data results back and not trying to prove that they don't have these centralized controls left. It's just really cool to know that makes me think that the SGX based blockchains and you have that as a common goal and maybe some progress can get done.
00:11:35.754 - 00:12:27.500, Speaker B: I think no one's really done this kind of end to end job of looking at the entire chain of validation. You can't just say there is remote attestation. You have to have some process by which people in your community are actually looking at the remote attestations for the sake of a spicy take here. The same issue is like with Arbitrum and other L two S. They're built around a very complicated audit protocol that handles the edge cases when something goes wrong and you need to process a fraud proof, but it's hard to go find visible examples of that and follow that process and see it working. That's something that's not unique to the SGX space, but that everyone should probably do a better job of validating their source code and publishing their transparency information where it's usable, but it's especially needed for this use of SGX and maybe you'll solve these problems if you need them for suave and everyone else can use them too.
00:12:28.990 - 00:13:06.790, Speaker C: I have a fun even spicier take, which is a little bit of a troll take, which is that luckily we have no on chain privacy in Ethereum. So you can also use funds flow to do a lot of your statistical analysis and stuff like that. That's how you back out centralized exchanges, cheating. So you would have these same tools in Mev land, like if you were getting bad execution, you could see who sandwiched you on the chain or who was accessing. Perhaps in some cases it may be non attributable and then you're really screwed. But I don't know, in many cases you may be able to kind of divine misbehavior.
00:13:10.510 - 00:14:20.110, Speaker A: So my next question is around latency, and I have a personal story to share. So we recently launched the Ultrasound relay, which is this kind of non censoring relay, and there's actually another non censoring relay which was launched at the exact same time, the agnotic relay. And we basically have the same setup. We're running the flashpots code base and it turns out that for some reason that we're still investigating, we're simulating blocks roughly 200 milliseconds slower than Agnostic and these 200 milliseconds mean that we have roughly a two x penalty over Agnostic. So we're including on chain, we're winning the auction like half the time that we should be. And so my question is, if latency is just so important for MVV, how can SGX win? Because presumably there's some amount of performance overhead, like maybe you can't do all the fancy overclocking and you can't get the latest and greatest CPUs and whatnot. Yeah, I'm curious, how do you reconcile latency with SGX?
00:14:21.170 - 00:14:50.742, Speaker C: Yeah, that's a great question. Well, first of all, I'm very glad to have you in the relay game. So that's amazing. Thank you for running a relay. And I also think part of the challenge in the future is co designing the protocol parameters so you can do things that have somewhat of a latency penalty if they're considered qualitatively better. And maybe because of the way the timing is structured in the protocol or something, there's somewhat less of an impact. Obviously there will always be some edge to having higher latency.
00:14:50.742 - 00:16:01.386, Speaker C: That's not something we can just magic wand away completely. But yeah, so I would say number one, we should minimize the latency impact. Number two, we can lean on ways in which the decentralized tech is stronger to compensate for latency. So if you have this privacy kind of edge that allows you to optimize transactions better for users, and you can attract more economic activity, if you have ability to optimize cross domain, et cetera in a decentralized way, where people actually trust you to do this optimization, then maybe the latency penalty exists, but it's overcome by these other factors. So really look at what is the strengths of the decentralized thing and can we amplify those in enough of an edge to mitigate the latency penalty? Because the more decentralized you get also the more latency penalty. So SGX actually doesn't have that bad of a latency penalty, especially if you provide witnesses. You're basically just executing the EVM with really you can provide state witnesses so you don't even need to do any memory swaps in some cases and that can have fairly low overhead.
00:16:01.386 - 00:16:48.160, Speaker C: Like you said, you do lose overclocking and some other edge enhancements. I think that's within reason there's already a lot of overhead in the building simulation process to kind of get this decentralization and get this merging of many different searchers from around the world with different edges into the most valuable block. So we're already kind of used to paying this latency for network effect penalty and I think SGX specifically is okay. I do worry as we push it more towards Fhe or something like that, or even if we want to do, like, we have some magic new MPC protocol with fairness that works and the latency penalty becomes bigger, we would still probably want to switch to that as a community. And how do we make sure that those systems stay competitive? I think that's like an L one design question also.
00:16:49.490 - 00:17:35.920, Speaker D: Yeah, I think there's two ways to see it as well. If ever one has to pay the same for killing than creating like an edge to some of the users. So I think the most important thing is to make sure that if there is such a penalty, everyone should be in the same setting. And in the Esgx case, to answer your question, things to be somehow again, as long as everyone is in the same setting, I think it's not such of an issue.
00:17:42.780 - 00:17:46.776, Speaker A: Yeah, Jonathan, your audio was a little shaky but I guess what you yeah.
00:17:46.798 - 00:17:50.124, Speaker D: I'm sorry, my connection is like really bad.
00:17:50.322 - 00:18:25.910, Speaker A: No worries. But I guess what you're saying is that if everyone's paying this penalty then everyone's kind of equal. But I guess what might happen is that we'll see maybe a centralized private mempool and then SUAV and then someone will do profit switching between the two. And then the centralized one will just always win. Because it has. Not only maybe a lower latency penalty on SGX, but also it doesn't have to deal with the peer to peer gossip channel, the blah, blah, blah. It's like straight end to end TCP connection from one point to another.
00:18:25.910 - 00:18:37.080, Speaker A: But yeah, as you said Phil, there's a trade off space and hopefully the forces lean towards decentralization.
00:18:37.900 - 00:19:03.460, Speaker C: I hope so. Side note, little known fact this is one of the reasons we run a centralized builder. So that A, we're forced to compete with ourselves and B, that if we do release something decentralized and we shut it down, it's kind of like a statement to the community on what we think the protocol should look like, even if there is a slight dip in profitability for a while. So that's one of the reasons.
00:19:06.760 - 00:19:21.080, Speaker A: So I guess my next question is around memes. SGX has this bad reputation which might be warranted or it might not be, but it's kind of there. Isn't that a tailwind for adoption?
00:19:22.860 - 00:19:23.908, Speaker B: Headwind.
00:19:24.084 - 00:19:24.424, Speaker C: Sorry?
00:19:24.462 - 00:19:24.916, Speaker A: Headwind.
00:19:24.948 - 00:19:31.456, Speaker C: Thank you. Curious to hear Andrew's take on this.
00:19:31.478 - 00:20:11.416, Speaker B: And then I'll yeah, it is a headwind. It's weird. I mean, even in the research publication, it's a lot harder to get like a peer review paper accepted on SGX because there was a glut of papers that were really boring and just said, here's existing paper, we just forced it to run within SGX and didn't have so much else to say. So there's even just a headwind towards getting past that. I don't know, I mean, it just seems weird to me. Like, clearly it seems to me that there's more gut reaction, like overvaluing the concerns about it, that it's far swung the other way. I hope it swings even more.
00:20:11.416 - 00:20:48.430, Speaker B: I don't know if we're at the bottom of SGX negative sentiment, maybe we can go even further and catch the drop on the way. Mean, my experience is that there's still just a ton of low hanging fruit of critical stuff to look at. So I get the sense that very few people are looking at this. The ones who are get kind of diverted and turned off so quickly that they don't even get to the good bit. So you all are here and I'm glad to see that you all are working on it that way, so hopefully we can improve that all around. Yeah, it's absolutely like a negative sentiment, but it's an opportunity too.
00:20:49.280 - 00:21:23.124, Speaker C: Yeah, I totally agree with that. And also Alex's points in the chat. I think the first crop of SGX companies were very much like, OOH shiny new tech toy, let's just plaster this on to every single problem under the sun and try to raise money from our VCs, which is like a common pattern in tech. It's like, okay, iPhone comes out with a new notification type. Like, what old UX patterns can we just plaster this onto and have a new fad? Basically, it's like the same idea. And I also think that turned a lot of people off. Plus, obviously there are some fundamental issues.
00:21:23.124 - 00:22:23.512, Speaker C: It's the same thing as with crypto, right? There's a lot of people that think crypto is a scam and F, all this, it's just like all rug pulls and the tokens are not legit, they're all securities. Whatever other argument you might hear, they're all kind of true to an extent, right? Like all the arguments, they wouldn't be memes if they weren't at least a little true. The same way all the bad SGX takes and all those memes, they are a little true, but both things, I think, lack nuance and so I'm glad that we're having this conversation and that there are people working on it, because I think the next generation of companies is not like the shiny thing companies. We have an actual need and we've gone down many paths and there's really no choice for this weird crypto intersection that's still better than something that's fully trusted. And I think in that niche there's actually a lot of practical gains to be made. Again, as a company, we're being very practical about this. We're not like we are an SGX company.
00:22:23.512 - 00:22:46.290, Speaker C: Our long term goal is to Sgxize the world. It's just like there's not really a choice. And yes, there's a major headwind that's also an opportunity because it means everyone else has the same headwind. And if you're truly convinced that it's the right thing to do and you're correct and you pay the headwind, then that is what an opportunity is also. So I think it's both. Yeah, very excited about it.
00:22:47.620 - 00:23:35.920, Speaker B: I had a lot of fun talking with a bunch of people that I met when doing this kind of unsolicited audit of secret network. So, I mean, it was neat to talk to the Obscura folks. A bunch of projects are using Enclaves that don't consider themselves smart contracts, but middleware of some kind, so Falla is one of them. And it's a little confusing because even though they're a middleware, they still are EVM compatible. That didn't make sense to me until Suave is like that, it's not to be a competing blockchain, but it is EVM and running in enclaves for something else. So they're doing something and the guy from Automata Network, automata is another middleware one, but they aren't I don't think they have open source code, but maybe could be talked into it. So yeah, maybe invite all of them to another roast.
00:23:38.340 - 00:23:52.810, Speaker D: It's probably the best way to go against the headwind is to keep on doing everything in the open. Transparent elance making shell position is well known. And being the first critics of our own design choices, I think.
00:23:59.770 - 00:24:03.640, Speaker C: Your audio is amazing now, by the way, Jonathan. So whatever you did worked.
00:24:06.410 - 00:24:30.558, Speaker A: So I guess my next question is just trying to assume the worst case, as Andrew put it, which is that what if there's a vulnerability that makes all the Attestation keys leak, so there's just no security guarantees anymore from SGX. What would be the plan for Surf? Is it that you fall back to the current model?
00:24:30.644 - 00:24:31.360, Speaker B: I guess?
00:24:31.670 - 00:24:33.858, Speaker A: And does it mean that you kind.
00:24:33.864 - 00:24:57.602, Speaker C: Of yeah, go ahead. Sorry. So yeah, I think there's like a few options that are really practical from today. You kind of summarize them. There's like decentralized, that's what we have with Flashbots and Flashbots Protect. Now then there's committee based, you could call this like the chain link ish trust assumption, something like that. You can layer on some staking and call it decentralized.
00:24:57.602 - 00:25:47.890, Speaker C: Also you can possibly reuse the ETH validator set. These are all like ideas in that camp and build some sort of committee where you have some protocol that aggregates multiple semi trusted kind of inputs into an oracle. You could also do privacy that way certainly either trusting the kind of or of all the people you choose to trust and optimizing their intersection. That's very easy. Or you can use MPC to trust the and I don't know if I reversed those or not. I think it's right so those are like kind of the levels and so yeah, we'll have to probably kind of go to one of those options. So probably ultimately the system will be some will be configured to allow you to fall back to this if SGX is broken.
00:25:47.890 - 00:26:24.006, Speaker C: It would be sad, though I'm very bearish on committees and this is why I think SGX is the only choice, just for the reason that in mev, given that the breaks aren't falsifiable and the incentives are so high and there's a kind of positive incentive boost from being on this committee if you're also a searcher or a builder. That to me makes me very bearish on those trust assumptions actually holding especially under stress. So that's why we think SGX can maybe patch over that like paper machete over that a little bit and so I would be sad if we had to fall back to that.
00:26:24.028 - 00:27:44.400, Speaker D: I guess I think that there's a very interesting assumption in what you've been saying, Phil, is that we're able to identify this new vulnerability and act accordingly. And I think that's what happened up until now in SGX, right, it's mostly been academic or white hat hackers like Andrew's papers that went through the process of disclosing the vulnerability to intel so that they could act accordingly even though we can debate the update process afterwards. What's maybe more interesting, and I'm not saying I've gone answer to that is that if the stake became so large that some people do not have the incentive anymore to go through this process but on the other hand, to try and exploit these new vulnerabilities that they've discovered, then we could be in troubles. Because then you have this asymmetry again between users that exploit and users that pay the penalty basically. And I think again to lean back to your paper, it's kind of like interesting to see and try to cost how much it would be to mount such attacks. I think that would be a very interesting line of research to try and estimate the cost of breaking this and this aspect of the technology.
00:27:47.330 - 00:28:12.066, Speaker C: Yeah, I've always said that that's what's like a few years ago. That's what's missing from this whole SGX conversation. We don't understand the economics of all exploits. It really depends on the marginal cost to break additional chips like whether SGX can be secure at like is that zero for all exploits or no, I don't know. Maybe you know if anyone's done research in this Andrew or Jonathan, but I'm not at least aware of any it's.
00:28:12.098 - 00:29:05.142, Speaker B: Not really my area, but I'm a fanboy of all the people that do this vulnerability research at that level. Have you seen this YouTube from Linus tech tips on a tour of the intel debug lab. Debug Lab is like the spookiest phrase in the context of SGX because what Debug Lab means is they have a big laser thing that'll burn off the top of a production chip. It turns a production intel processor into an FPGA. They can rewire the logic of the chip by beaming it with powerful lasers in their Debug lab. And they gave this little tour of it to a famous YouTuber and it's nice to put like a picture of it to the myth, it must exist myth, but that's what it looks like. That doesn't answer the economics question.
00:29:05.142 - 00:29:24.734, Speaker B: I've heard people say things like $100,000 is what it would cost to get access to that, or the one place in University of Florida that can do it, or something like that. So I don't know the details should definitely we should be trying to find those because that would fit into this kind of analysis. Yeah.
00:29:24.772 - 00:29:46.178, Speaker C: I will say our one leverage point here is a lot of this can be punted to intel. So they have PR skin in the game. Not that we should and we shouldn't answer these questions, but they also have skin in the game. And if someone does build a secret SGX lab to break mev and they succeed, intel's PR is on the line as well. So presumably, you know, we can I.
00:29:46.184 - 00:30:33.090, Speaker B: Think the relationship between the crypto community, including Y'all, and the blockchains that are doing this, I think should try to present like a united lobbying block to intel. So I mean, one of the lessons in the SGX fail paper which like Daniel and Christina and others have been kind of tracing down this, know, a much longer time, it's a much broader point than just the blockchain setting, but no one understands TCB recovery that well. None of the relationships and things that you do afterwards, what it takes to get early notification or not, are so clear. So I don't know. My guess is that it's possible to do a better job negotiating and informing this relationship with intel by acting as a cohesive community rather than just one off startup projects.
00:30:36.980 - 00:30:53.540, Speaker A: One of the things that struck me when you guys gave answers is that you didn't mention AMD SUV as a potential replacement for SGX. If SGX is completely broken, does it mean that Sev is maybe not appropriate for SUAV.
00:30:55.240 - 00:31:49.590, Speaker D: If and Fret model? Well, first of all, I think that the TCB is much larger, so that's like, regardless of the properties of the hardware itself, the question is like whether you want to trust a relatively small application enclave size, or whether you want to trust a. Whole virtual machine that there's absolutely no loopholes that could be exploited in there. And I guess also maybe we should not address all of these technologies under the same name. I'm not very happy about everything falling under the Te name. I think a lot of these techs are now becoming just like confidential virtual machines and we should clearly make the distinction between them too. It doesn't mean that it's bad fundamentally, but it's like we should not expect the same behavior and security properties from two different technologies, basically.
00:31:50.920 - 00:32:44.084, Speaker C: Yeah, I would say that being said, it could iterate into something useful. Like if they see a market demand and I'm not fully bearish on AMD or any other tees, it would be great to have more diversity. If we had multiple solutions that work for the threat model, maybe we could come up with a protocol that you need to break both to get anywhere and that would be nice. Certainly. I think in the same vein as the ASIC for any delay encryption function that EF may do, like maybe one day the EF or other crypto companies together build a tee that's like open source. If this actually does end up becoming critical infrastructure that we can't replace and the other avenues don't pan out. So these are all like yes, they're all kind of like on the research radar, but I think, as Jonathan said today, less attractive for various reasons.
00:32:44.084 - 00:33:13.520, Speaker C: Although we have talked to some people recently who are bullish on AMD, kind of eventually being enough for this use case. You could also maybe even jury rig like the iPhone tees plus Apple's Authenticity check. If you do a network that has enough attestations for your economic security, maybe you could get security out of that. I don't know, but yeah, things to think about, but I think less immediately, obviously applicable than SGX.
00:33:16.740 - 00:33:25.440, Speaker A: Guys, thank you so much for your time. I think we're an hour and ten minutes over, so it may be time to wrap up. Thank you so much to all this.
00:33:25.590 - 00:33:26.610, Speaker B: Thank you all.
00:33:27.300 - 00:33:28.796, Speaker C: Yeah, thank you. Thank you, Justin.
00:33:28.828 - 00:33:30.130, Speaker D: Thanks everyone, that was great.
00:33:30.460 - 00:33:39.130, Speaker C: Spicy moderation and yeah, thanks everyone, that was really great. Thank you Justin, to our tireless roastmaster. That was awesome.
00:33:40.540 - 00:33:42.020, Speaker A: Thanks Sarah, for organizing.
00:33:42.100 - 00:33:45.828, Speaker C: Thank you both. See everyone later, you guys. Bye.

00:00:14.840 - 00:00:47.404, Speaker A: All right. Okay, we're live. Hello, everyone. Welcome to this second session in the flashware series. These live streams are set up to help unravel the intricacies of of trusted execution environments and confidential computing. In the first session, hosted last week, Mo introduced us to Intel SDX and showcased a couple of use cases and examples. If you missed that session, you'll find the recording and all related information in the topic on the forum.
00:00:47.404 - 00:01:01.984, Speaker A: Today, Andrew will present an end to end application in Grameen, as well as introduce us to controlled channel attacks. So without further ado, Andrew, if you want to start the presentation.
00:01:02.964 - 00:01:28.072, Speaker B: Okay, cool. Thank you for the intro. Okay. And thanks for having a couple of people here on Zoom. I guess you folks should be encouraged just to shout out questions for me. And I guess you'll be forwarding questions from YouTube, so that's cool. Okay, so I do have, I think, a bunch that I want to get through, but it should be nice and informal and very self contained and easy to understand.
00:01:28.072 - 00:02:07.984, Speaker B: That's the goal. I do want to try to basically go from the Grammy intro from last time all the way through what I consider a self contained useful example. We can see how close we get to that. I'm going to look at this application setting of using trusted hardware to do a trusted setup like you see in cryptography. Or we might do this by live coding an example of a fact about a document like an anonymous credential using the trusted hardware. And I'll go both into the concept, more of those in a second. And the main thing is I want to show how to do this prototyping environment in Grammy.
00:02:07.984 - 00:02:49.344, Speaker B: So basically we'll use write python scripts. All the implementations we do of these are just going to be a python script, and we'll look at how Grameen can run Python. That's cool, because it's a virtual machine running inside the enclave. So that's a cool pattern to see. Then to finish the example, the main two things to do are we'll go over how to use remote attestation from Grammy, and we'll add that to the example. You need to go all the way through documenting how to reproduce the build of your enclave so other people, not just you, can rebuild it and get the same enclave binary hash, because that's what ties into remote attestation. So we'll do an example of as far as we can get for that.
00:02:49.344 - 00:03:31.870, Speaker B: And then the last thing is I'll do a security focus. So I really want to. My goal for this whole series really is to build security awareness on design considerations you need to include and what you build using Teus. So we'll look at the simplest of a first kind of attack called a controlled channel attack, and the kind that do here I refer to as a spicy printf, because they're just a printf, they're really simple. It's the simplest attack, but we'll look at how it could show up on an encrypted file, demo and Grammy. So that's all the things, but it'll be really self contained. I'll go right into just the concept stuff of introducing these applications and then we'll try the hands on stuff in Python.
00:03:31.870 - 00:03:59.790, Speaker B: It'll make it really easy to really do a faithful job of these. So I have two to go over. So the first one is using a tee as a document checker. So the idea is that you have a full document. Think of it like a digital passport or something, but it has a signature, it has metadata about you. It's your whole passport document. And what you want to do with it is get a claim about your document so you can give it to a relying party.
00:03:59.790 - 00:04:43.164, Speaker B: Sometimes people give the example of like, oh, you want to, you have a driver's license and you want to prove you're above a certain age and get into a bar. It could be something like that. Anyway, the point is that you won't send your whole raw plaintext document to these relying parties. You'll only send it to the service provider to get processed. It'll get processed in the trusted hardware we write and it will output remote attestation. So these relying parties believe the claim you make about your redacted document just on the basis of this remote attestation and just to set up for the security goals. Because I want to basically try to recommend being as explicit as possible about the security goals.
00:04:43.164 - 00:05:22.516, Speaker B: And what we care here about is not even privacy, just soundness. So the document owner provides a document. We might do something like, the document is valid because it has a signature, it has some prefix and related to the hash of the document. And the goal is just integrity. So if you accept this attestation, then you should believe this fact is true, the document, maybe this will become easier when we make up an example for that. I think this most closely relates to. I think if you're a security expert or a modern cryptography person, you might think, oh, this is a canonical application for zero knowledge proofs.
00:05:22.516 - 00:05:41.316, Speaker B: And that makes sense. This is using trusted hardware as a drop in replacement anywhere. You could use a zero knowledge proof if you do both sometimes. That's called multiprover. That's true. I think that's a quality of this useful application. But we can get all the way through something pretty useful by finishing remote attestation and it does something useful.
00:05:41.316 - 00:06:28.552, Speaker B: Maybe it goes faster than a zero knowledge proof. While I'm introducing some concept motivations that are good for a motivating example, I'm really fond of this one, the more I look at it. We'll use trusted hardware to generate a trusted setup for a bunch of cryptography schemes based on RSA. An RSA number is a product of two primes. You use these for encryption and signatures, so this could be the public key for a digital signature scheme. There's another way that you use this that's more relevant here, which is where it's a public parameter, so you can build zero knowledge proof schemes or efficient accumulators out of RSA like this. The point is that no one is supposed to know these p and q.
00:06:28.552 - 00:07:04.742, Speaker B: So basically a number like this is the public trusted setup forum. Some cryptography schemes. The only way to generate it efficiently is to generate a prime p, generate a prime q and multiply them together. But the whole catch is that for this to be useful in a cryptography scheme, you have to throw away p and q when you're done. Those p and q are the toxic waste, because if you know them, you can make false proofs. The whole challenge, which is a hard problem. People do these multi party trusted setup ceremonies when you need something like this, but we'll just do it the really straightforward way, by writing a script to do it and run it in the enclave.
00:07:04.742 - 00:07:52.692, Speaker B: Now when you get a remote attestation, you'll know that it was generated according to this pattern. Here's the little schematic for it. We're going to build an enclave that picks a prime number, picks another prime number, stores and outputs the product of those n, but it throws away the ingredients. When it's done, it deletes P and Q. What you get then by checking the remote attestation, is that you get this number n that came from this process, which means that you have some evidence, some reason to believe that the P and Q are actually disposed of and won't be there to be a toxic waste that leaks and ruins your application. There it is that we're going to be doing python and gramine. So just an example of what this sampling procedure looks like.
00:07:52.692 - 00:08:32.164, Speaker B: You have some way of checking if a number is prime. We want to have like a 2048 bit RSA number. So we pick a half that size, prime number p, half that size, prime number q, print the output, delete the ingredients, and we're done. If we get this to run in a whole enclave, it's plausibly one of these useful applications. Let me pause there, see if anyone has any questions. I think these are examples that I haven't really introduced specifically so far. So these could be good to raise questions like, you know, why would a tea be good for this? Or, I don't know, maybe you have guesses on what would be challenging about this? Or what some caveats could be.
00:08:32.164 - 00:09:11.544, Speaker B: Have you seen it? Somebody tried instead of the ceremony to generate the secrets to use the hardware. Or this is a proposal, maybe it will happen in the future. I would say this is a proposal of the uses of trusted hardware that I know of, you know, and there are several we could talk about some of them, I don't know of any that are specifically like this, doing a trusted setup. So I would say this is a proposal. I would say. Yeah, I have a question here. Go ahead now.
00:09:11.544 - 00:09:34.170, Speaker B: Yeah, if you go back. Yeah, exactly. Here. When you mentioned here, document honor is passing here the. The data, for example, like the id and whatever it contains. And this also like the document owner should also do that to make sure before passing the sensitive information in that part so that the station part is happening on both sides. There are like.
00:09:34.170 - 00:10:04.020, Speaker B: Yeah. So you have in mind that an additional goal is privacy, that even the service provider outside the enclave doesn't have to see the whole document. Yeah, I mean, I'll tell you what. I only wanted to make this. I left that out on purpose only to lower the claimed attack surface for the demo. Just because my claim will be that I get all the way through a gramine production today and I'll set debug true to debug false. And I should finish enough steps that it's plausibly all done.
00:10:04.020 - 00:10:19.842, Speaker B: If I added that to it, I would have to throw encryption in there as well. Yeah. That's the only reason that's there. But you're absolutely right. That would be the right way to satisfy this application scenario. Thanks. Yeah, we're following along.
00:10:19.842 - 00:10:47.000, Speaker B: Okay. All right, so let me go switch to just playing around in Grammy in a bit. I think these are just my notes for what I want to include in the demo. So it doesn't matter that we go over them here because it doesn't hurt either. Yeah, I mentioned what's fun about this. I mean, so you remember from Gramming what do I want to? All right, I'll talk maybe about it as we get to it. But Python will run in Grammy and that'll turn out quite natural.
00:10:47.000 - 00:11:10.400, Speaker B: I'm not saying something that's surprising. This is one of the, if you poke around in the examples directory and Gramine, this is one of the other happy path covered in their documentation. So it's not a stretch example. It's something that's supported and works really well. But it's interesting how this works. So we'll go over and you'll see it again. But Gramine's basically a key part of Gramming is how their manifest files works.
00:11:10.400 - 00:11:50.904, Speaker B: Those are where you say where the Grammy is going to pull all the ingredients of your trusted compute base from, and that basically includes the Python C Python interpreter and all of the standard library files. And you can follow how the manifest works to see all of those. And something that's cool about this is we'll see. It pulls the libraries from your local system installation, but it's configurable. I won't cover it in the example, but you can tweak this a bunch to, you know, install python dependencies and then include those dependencies into your trusted compute base as well. So all right, we'll just go and get to this in the example. That should be enough.
00:11:50.904 - 00:12:28.490, Speaker B: So I will switch to, I'll have two environments here. So at any point I'm going to have to remind myself which one I want to show off with first. I think this is the right one to be in. So I have a mostly I'll just go and start by playing around in the examples directory. In Python, this isn't all cleaned up, so maybe just browsing the directory I can't show you. Well, I'll show you each of the things that's important. This is in the directory.
00:12:28.490 - 00:13:09.190, Speaker B: The thing that's really most important is the manifest template. We can go through what was added in Gramming to make Python get picked up and then included in an enclave. You can build one of the, this will include the libraries that pick up. So the libraries for running Python are already present in your system if this has been installed. This is true for all of the things that get mounted. I think the first Python specific one that's interesting is this one. This is how it picks up all of the files that are on your Python path.
00:13:09.190 - 00:13:39.874, Speaker B: This is working because this is the Grammy manifest template that runs this little jinja templating language or something. This actually evaluates in Python. It picks up whichever Python path is included in the system. When you're running the manifest generator on this manifest template, what else was add something else to mention there? Yeah, okay. This obviously sets the command line arguments to true. You'll see a little warning from Grameen about this. I don't even think that warning is that important.
00:13:39.874 - 00:14:17.974, Speaker B: And regardless, this will allow us to invoke different scripts even after we've compiled the enclave. I'll do something with this encrypted file later, but not until the end of the hour. And I'm not sure there's anything else that's super important to see there. We'll see that it includes in the trusted files, the entire scripts directory. Inside the scripts directory are all of the python files that are just going to get packaged up into the enclave. To run these examples, I'll be running some of these scripts. If we want to make a document editing enclave, we could run that as well.
00:14:17.974 - 00:14:51.300, Speaker B: If I do make, I think that's already been done. If I want to do make SGX again, I can do make clean and make, but I just want to make it actually traverse this manifest file and pick up any changes. And that's the mronclave. So that's the entire root hash of the enclave, including all of these things. Something useful is to look at the manifest file. This is after the templating has been applied. So you can see this is the version of my system libraries it picks up.
00:14:51.300 - 00:15:18.364, Speaker B: And do we have anything specific here? Yeah, here's where it picked the python path. And so it's picking up all of these site packages here. It looks like on this environment I've set it up to point from a local one on my user, so that may be relevant later. Anyway, you get an idea of what this does. So this is the manifest file. It's still not all of the hashes. For example, it just says scripts directory, but it doesn't say what all is in there.
00:15:18.364 - 00:16:02.112, Speaker B: If I try to look at the manifest SGX, this is going to be too huge to traverse, because this is the thing that actually has the hash of every single file that it traversed. This is all of the system libraries on the machine that we did. I'll come back to Docker in a little bit. We'll build an image that has less of all of this, but that's the idea. And I could search for one of the files that I'm expecting. Yeah, so here's where it's actually going through all the scripts and has the hash of all the scripts in that directory. Everything else that we covered about how gramming works in terms of replacing system calls and other tasks.
00:16:02.112 - 00:17:06.434, Speaker B: Well, we'll go into some of that, into a little more detail at the end. But basically this works because it's just running the Python interpreter. That's just a program that can run load all of the scripts that we want it to run in the standard library, but those are all hashed and included in the manifest, so they're just part of the enclave and so on. All right, and then we can look at it running and just create the demo and then maybe we'll go and try to see what we need to finish there. I don't think that happened before, so I'll have to figure out what that problem is. It should run Grammy initiative. All right, who knows what that was.
00:17:06.434 - 00:17:28.234, Speaker B: Okay. I didn't provide any arguments, so I'm just in Python terminal so I can do print. Hi. All right, I can do that. I can also just provide an argument here. So if I want to run one of my scripts, I think this is the one that just comes with it. I get that.
00:17:28.234 - 00:18:08.750, Speaker B: What we'd expect. What else comes in the scripts? I think probably the most interesting one to look at is the remote attestation right away because I may want to build on that. So this is scripts SGX report. We'll just look at it really briefly, then I'll show you what it does. Then I'll show you in the description what it's for. All this script does is it opens up and looks at some of these paths in dev attestation. This is not a real file.
00:18:08.750 - 00:18:47.130, Speaker B: This is something Grammy provides and this is how Gramming implements remote attestation. This is basically python code for opening these Grammy and specific pretend files. By writing to a couple of these and readings from a couple others, you produce a remote attestation. I can run this in my enclave and I should get a summary of this remote attestation. This generated a remote attestation. I'll say more about what that is in a moment. The important thing is this, Mr.
00:18:47.130 - 00:19:15.002, Speaker B: Enclave six 4D matches the one that I saw when I just finished building this. And so those are kind of matching. You basically get a signed report that you can check. Well, I'll flip to where my slides are. And yeah, this came up next so we can talk about it a bit. I thought I'd have a graphic, but I don't have a graphic, so I'm probably going to end up pausing for questions here in a second. So just the notes of what this example then covers is remote attestation.
00:19:15.002 - 00:19:52.194, Speaker B: So back to this example. I either want to produce a claim, an attestation about a document, or I will want to produce a attestation about an RSA number I've sampled. It needs to travel with this remote attestation and what you want to be able to do is have a rule to check this attestation. If it checks out, you accept that number, you accept the claim about the document, otherwise you reject it. This is ultimately going to relate to the root of trust. So you're going to have to have the public key from intel as part of what you check. When you're verifying this attestation you'll have a chain of certificates.
00:19:52.194 - 00:20:28.350, Speaker B: You have to check that the mister enclave in the attestation matches the one that you get from compiling the high level source code that we're claiming to. The attestation also has some user report data. You have to connect the output of the program like the number or the claim about the document to the thing that you're checking. We almost saw that here. Here's this report data. It was all zeros. We'll actually have to make use of that report data in a moment because that's where we will put the number or the hash of the number.
00:20:28.350 - 00:21:52.204, Speaker B: We'll see it can only be 64 bytes, so you can't put more than the hash of something, but that'll be important for it. I showed you what it looked like right in the python code, but basically this remote attestation is a feature of SGX, but the way that you access it through a gramine application is just by writing your payload code uses this pseudo file attestation. Basically you want to set the user report data. That's where you include something from your application like the hash of the thing you're claiming and it picks up the hash of your enclave by default and then you read them from dev attestation report and that's where that just triggers the gramming os libos to provide that attestation for you. What else should I try to show here? I think I had, what did I want to do that actually produced a quote? I wanted to run this and then actually show how to look at a quote and verify it. I think that what I would have done is did I make one of these scripts actually print out the quote? Maybe it was this one. This include a quote at all? I think this is, that's for something we'll do later.
00:21:52.204 - 00:22:28.484, Speaker B: I bet my good example of this is just somewhere else. Oh yeah. I know what's up. All right, I'm going to switch around a little bit to where I have a slightly different thing, but you'll see it's the same concept. There is sgx quote there. Py. Yeah, but does it, oh, did it save it somewhere? Did it save it to outputs or something? I wanted to look at the quote and.
00:22:28.484 - 00:23:01.554, Speaker B: No. Is this that file? I think yes. Okay, but that's not a quote. I had a thing where it would print a quote for me just to the terminal and I think that's all I needed. Maybe it just works. All right, if I'm in here, I see a quote there. So yeah, this is where I want to be and I can produce a pre recorded one if I need.
00:23:01.554 - 00:23:59.934, Speaker B: All right, yeah, that's a little better. Okay, so I'm skipping ahead to a little bit, but I guess it's fine. So I already wrote this RSA demo that implements that sketch that I provided. So we've got our is prime function, we have sampling a prime, that's the whole python script, and then at least make the syntax highlighting show up a little bit. And then after we've printed out and prepared this number, we do the remote attestation bit. So what we will actually do is take, again, this is a 2048 bit number. We can only do afford to whatever, 64 bytes, 512 bits in the user report data.
00:23:59.934 - 00:24:26.214, Speaker B: So I'll just take the hash of that. This is a common technique. Anytime you put something in the user report data, it's almost always the hash of something because nothing else will fit anyway. So we write that to the user report data and then read the quote, and then just print the quote after a little tag and run it. And I've switched machines, but I mean, I'm still just going to be running the same. I'll show you what's different in this thing in a moment. But here we're just running the same.
00:24:26.214 - 00:25:03.054, Speaker B: Okay, well, you saw it, we did run it, and I do think that I just had it output to output, so I probably want to copy and paste it. So this is just hex. I didn't do any automation, so we have to do this manually. I think I put it in quote hex. So I'll just overwrite this. All right, and then I have to do something like this in hex. So I just want to save it as a dot.
00:25:03.054 - 00:25:47.078, Speaker B: All right, and then the tool that I'll use to look at these is gramming quote view. And what this is doing is parsing that quote for me. There's also like the intel reference for this. There's a lot of ways to do this actually. I'll show the solidity way of doing this too. But this remote attestation is this dat file that's output from SGX and you get it from the file system in Grammy like that. And it contains all of this metadata determining the environment that you're on.
00:25:47.078 - 00:26:25.628, Speaker B: The relevant bits are the mister enclave and other relevant things are the processor configuration. These are related to checking that you have an up to date processor, not something that wasn't updated, so it's still vulnerable to APIC leak or whatever from years ago. You've got the enclave, the report data is now here. We set up a sha 256 hash. You have 64 bytes here, even though the sha two is only 32 bytes. That's why we only set the first 32 bytes of this report data field. Then the signature is a stack of signatures that you need to go verify.
00:26:25.628 - 00:27:26.904, Speaker B: This is just the parser, it's not the whole verifier, but this object that we're parsing is the whole remote attestation. I guess this is the question. Do you believe that I've gone all the way to a useful application then? Because I've got this python script that runs and that Mr. Enclave includes all of these files to produce it, so I shouldn't be able to produce a number that when you hash, it gives you a hash that when you parse this shows up in the user report data of a valid enclave. Unless I actually ran this program through the enclave, which gives you some evidence that it doesn't just leak the prime numbers P and Q. So that's already kind of interesting. What else do I want to finish for this? I'll come back to this in a moment because I want to do the reproducible build thing first because I'm already here.
00:27:26.904 - 00:28:12.020, Speaker B: So one thing you might have noticed is that when I switched machines really quickly, well, okay, I have slightly different code base altogether, but I, well, I'll do this, right. If I go to, should have this, exactly the same version here, right? So I'm on this b seven seven, right. Nothing. None of the input files have changed, right. Super clean. I should be at exactly the same thing here. And also nothing's changed.
00:28:12.020 - 00:28:52.440, Speaker B: If I go real quick from this clean thing and I do make here, make here, right, I get seven 8d there. So it's taking a lot longer. It's taking a lot longer because it's pulling in completely different files. I have these systems, different sets of libraries and stuff installed. The manifest is sweeping up all of these library files. As I just point it to my arch lib thing. Different configurations on these different machines will produce different mronclaves.
00:28:52.440 - 00:29:35.524, Speaker B: If I just send you to go download this repo and build it, or I give you a fork of my Grammy where I've changed the examples, you're not going to get the same Mr. Enclave, I'm not quite done giving you this nice evidence that's self contained, that I've generated this RSA number and thrown away the ingredients to finish. One of the things that I want to do is actually make it so that you can tell how I got my Mr. Enclave by making it possible for you to reproduce it as well. Really what I'm in in this directory is this little demo that I've prepared trying to make a tiniest possible self contained application. And so really I can go through each of the things here. So I have a manifest template.
00:29:35.524 - 00:30:01.004, Speaker B: This is really just the same one from the examples. This isn't really different. I guess I just pull in the one file rather than the whole scripts directory, but same principle. What really I want to draw attention to here is my maybe there's something in my make file. There's nothing special in the makefile. This is the same as in the examples too. I think I might have deleted a couple of things from it, but same as in the examples.
00:30:01.004 - 00:30:44.030, Speaker B: But what I provide with this is a dockerfile. This dockerfile is basically what I'm recommending as the simplest way to do something that's plausibly reproducible. What I want is to basically give you a recipe that you can follow for this application, for this git repo that will get you the exact same mister enclave every time. It's actually a really hard problem to solve in general, because any difference in the build environment can cause downstream things. In a sense, you need to really reproduce the build exactly. You'll have to have a perfectly pinned dependency all the way down. What we'll be doing is basically a relative reproducible builds, which is inherently the case.
00:30:44.030 - 00:31:25.648, Speaker B: You can only aim to be reproducible starting from some point, practically a known tagged version of of a compiler system. So anyway, my base image, my starting point for irreducibility is going to be this docker hub image, which is a Docker virtual machine container from the gramming project. It's not the newest one, it's this 1.5. I guess I'm trying to make a point in general out of I want to pick. I'm not being clear about the problem here. I guess I'm going to go through a demo, so what we get from it's fine, and maybe by questions we talk more about the nuances of this. And I'm not going to try to give the full solution for just this demo.
00:31:25.648 - 00:32:17.004, Speaker B: But the challenge with in general, you can't just take a docker and include a whole docker file for setting it up, because as soon as you do apt get update and install a bunch of dependencies. You'll end up getting newer versions of the dependencies depending on when you build the docker image. It's very easy not to make something reproducible using it this way. Even though I have this apt get example here, I'm not actually installing anything with Apt get that touches the enclave literally just from executing the makefile and figuring out where the libraries are. It's not really using the compiler, so ignore this. The point is that we're going to start from this base image and we're not going to do any changes to the base image except for things that are simple and are just in our directory. We will copy this local python file and the manifest template in the makefile and that's it.
00:32:17.004 - 00:32:50.454, Speaker B: And then run SGX. Make the only files that get pulled in here. The only files that get pulled in by the python manifest in the docker image will be the ones that come from this docker image base image, so they will be exactly the same. I could show you the info page for this. It'll be on a tagged release on gramming somewhere. Somewhere in here is 1.5 and so in principle they give all of these image layers.
00:32:50.454 - 00:33:49.636, Speaker B: You could go interrogate this further. You have to take Docker Hub's word for it that if you followed all of these instructions you would get mostly the same thing. Ultimately I can't follow these instructions and produce the image that has exactly this, so instead we're basically just relying on this was put in public a while ago, is stable, has nothing to do with our application, and it's somewhat public and stable, but that's all we can do to it. If Docker Hub deleted it, maybe we'd be in a place where this is just totally unrecoverable, who knows? This isn't a finished solution, but this is relatively stable. Frankly, the only thing I'll do to show that it's stable is I'll just build it through Docker the same way in both places. I'll do Docker build a tag here and then I think I have to run it. That do it.
00:33:49.636 - 00:34:23.334, Speaker B: So output something for me. F 98, did that work? Yeah, how about that? I got the same f 98, the same f nine name. The mister signers are completely off because I'm ignoring code signing for this. Code signing doesn't matter, it's the mRNA. If you have different signers but the same Mr. Enclave, the code is going to do the same thing because the code's fully covered by the Mr. Enclave.
00:34:23.334 - 00:35:23.664, Speaker B: I'll pause here for questions. I think I'm done with everything I can think of to show about remote attestation. Maybe with the exception of maybe just drawing more attention to the existence of smart contracts for verifying remote attestation, lots of the applications I find are most interesting involve a smart contract that consumes and verifies the remote attestations produced by your enclave. This way I have this little on chain stunt of an optimism contract. The optimism contract has a prize pool of like $650 right now. This is an active contest. If you win this contest just by getting a computer with SGX and generating a remote attestation and posting it to the smart contract on optimism, that's how you win a share from this prize pool.
00:35:23.664 - 00:36:20.226, Speaker B: There's a little bonus thing here that says, I guess when was the last time something's claimed? Well, I think if it shows. Looking for something that says bonus, current bonus. That's all I meant. All right, so there's been 20 weeks since the last time someone's tried to play with this contract by sending on the decap event to it. If you look at the events, you can see I think some people claim the award and I think by default it prints the claimed cpu. This is fun because this is from the host, so you could totally fake it and lie, but you can. Oh, and then the rule of contest is the first person to sign up with each configuration of an SGX, so the processor and bidos version both determine it get a share of the pool, but then the bonus goes, so you get a ten x award.
00:36:20.226 - 00:36:51.824, Speaker B: You get 10% of the whole prize pool by being the next one to claim it. You just have to have a different BIOS version or processor type than the people who have claimed it before. The contract code is based on the. I believe this one's based on the rave here. I meant to show contract code. This is from the zoom in, so this might be more reasonable. This imports the rave library for verifying remote attestations in pure solidity.
00:36:51.824 - 00:37:21.914, Speaker B: This has a base 64 decoder that's some decoding that has to be done. It has a certificate verifier because that's that format of those signatures that are in the remote attestation. And it will even verify those signatures. It'll do this elliptic curve verification. All of this is all of the decoding and steps that follows along basically with the documentation from intel on what is the data structure of a report and how do you verify it. And that's what the solidity code does. So it's not even terribly long.
00:37:21.914 - 00:38:04.924, Speaker B: You can go study this and match it with the SGX API documentation if you want to learn it that way. Okay, I will pause for questions. I haven't heard any, but I have one about reproducible builds. Okay, do you know what's the state on the Ethereum projects? Are they taking care of their, their dependencies? Can you do a. I didn't hear the end of that. I mean, but this was about Ethereum. I mean, so we're not even talking about reproducible builds for enclaves, which is reproducible builds for general good practices of software engineering.
00:38:04.924 - 00:38:52.030, Speaker B: No, I can't tell you what the best practices. I know that you should use nics. I know that that's a popular tool for getting this far. I would say that the role that reproducible builds plays here is somewhat more important because it is the basis of accepting this evidence that something was carried out the same way. If you have a signature but it says some program produced this output and you don't know what that program is, then it doesn't do you any good. If you have here's a directory of code that solves your problem, and here's a proof that some program somewhere produced this output that doesn't connect them together, you're still just taking someone's word for it. It's not that even reproducible builds is the only way of solving this.
00:38:52.030 - 00:39:37.374, Speaker B: Maybe you don't get a reproducible build exactly, but you can do some binary analysis like a diff and show that, well, the hashes don't match. On a deeper inspection the only difference is the timestamp on a file or something. Maybe that could be dealt with, but you have to do something to connect the what did I wanted to show here? So I showed you on the, I think what I meant to get to is this little picture. So I showed you with gramine quote view how to parse. And I didn't go through checking, but I described it a quote. This is what it looks like on the block explorer using solidity to go parse a quote and see what the parameters inside it are. And the solidity code also does check it.
00:39:37.374 - 00:40:12.514, Speaker B: So this only does any good if you can match the enclave. Getting a reproducible build is the easiest way to check an mister enclave. You have to do something to check it. I think any best practice for doing this in general also carries over here, but it's much more urgent and important here. Then maybe the last thing that I would say is that the Mr. Enclave only covers what is in your application's trusted compute base. Maybe your project as a whole has a large codebase, but maybe not all of it has to be reproducible because not all of it is inside the enclave.
00:40:12.514 - 00:40:46.064, Speaker B: But that bit you have to at least get right. This is just a starting point. If you can't at least do this one pretty well, then I think you're off track. But it's, it's hard to, um, uh, it's hard to do a perfect job of this. And here the biggest problem is just having to take this as a dependency. So you could do incrementally better than this for sure. Okay, any other questions? Clicking the.
00:40:46.064 - 00:41:27.222, Speaker B: All right then. I want to get along then with just enough time to go into a security discussion. So I want to basically start getting introduced this mental model that I think everyone doing. Security critical stuff. Anything you do involving smart contracts or enclaves is security critical in some way. So you need to have this mentality of thinking like an attacker. That's kind of the basis of most engineering, is about what could go right or then what's happening in the measurable cases.
00:41:27.222 - 00:42:06.934, Speaker B: And security is all you have to reason about what an attacker could do. Even though they're intelligent and you don't know upfront how they're approaching the problem. So you have to think through this kind of what can go wrong. And we've set up these examples that I think have pretty explicit security goals so we can talk about whether they probably or not meet these security goals. What we have to. The most important interface that you need to think about is basically the attacker is whatever you can is whoever is controlling the enclave and gets to run code to the side of it. The service provider.
00:42:06.934 - 00:43:11.694, Speaker B: In the case of SGX, this is really about the kernel on the operating system the enclave runs. The whole point is that even the operating system or someone who has root access or admin access on the operating system can't peek inside the enclave while it's running, can't tamper with it. But the whole point is that that's what SGX gives you. But we're still concerned about this attacker, and the attacker's goal is to basically, well, in our examples just scroll all the way back to these. Right here the attacker's goal, we explicitly ruled out privacy, but here the attacker's goal might be to make the relying parties accept a fake proof about a document that doesn't exist. And in the case of this one, clearly the concern is that we might get a number that's not really the product of two primes, or we somehow leaked information about these two primes to the provider while it's running. So the ATT and CK model is really like you get this guarantee from gramming that this program runs, but it ran in a kernel that's controlled by someone you don't necessarily trust.
00:43:11.694 - 00:44:13.044, Speaker B: That's the whole point. You really have to think from the viewpoint of if you were this setup provider and you were trying to steal the p and Q out of this while it's running, how will you go about doing that and what do you have at your disposal? The attack is the attacker controls everything outside the enclave, and in particular they control the kernel. You should think of the attackers having root access to the kernel, including getting to modify kernel drivers like add a kernel module, reboot the computer if they have to, but they get to control the kernel, then any channel that is through the untrusted operating system means that part of the channel is under the attacker's control. In particular, the kernel is responsible for interrupting the enclave. It can interrupt the enclave at any time and then get control back. It is responsible for system calls. So anytime the enclave needs to make a system call, it has to go ask the untrusted, the kernel some piece of software to do that.
00:44:13.044 - 00:44:49.234, Speaker B: And it's also responsible for page tables. I'm going to try to give a demo and make this really concrete for you, but I'll just focus on the systems calls. One, and in particular I'm going to go after attacking. I'm not going to try to break the RSA example, I am going to go a little bit more just into a contrived setting, but, well, I have an example to make it realistic. Anyway, I'm going to try to show this attack on the encrypted file system in gramming. I haven't introduced that at all, but I'll introduce it quickly and you'll see what it's for. It's something you can add to the python manifest.
00:44:49.234 - 00:45:19.384, Speaker B: You'll see, in my example, when I flip back to it, you already saw this, I pointed it out, but you can say my enclave is going to expect to have access to this output directory. It's going to be an encrypted file. It's encrypted, the process gets to write to it, the enclave gets to write to it. But in the host OS you're not supposed to be able to see it at all. This key name says that only this program with exactly this Mr. Enclave will be able to decrypt that file at all. If you have a different mister.
00:45:19.384 - 00:45:48.824, Speaker B: Enclave, you'd get a different key altogether. You wouldn't be able to read a file made by a different enclave. That's what that parameter is. The way this is implemented in Gramming, we'll have to go into some detail in this, because we'll go into how a surprising attack can show up. But the way this is implemented is that you have your application that's part of the enclave. The Gramming lib OS provides these other things. It provides access to the ceiling key.
00:45:48.824 - 00:46:13.496, Speaker B: That's just a key that you. I won't go into it, but this is the key that you will use for this encryption. It's the key that corresponds to this key name. You will also have the implementation of encryption. So Grammy will have this implementation of an encrypted file system. And then to actually store things to a file, it's going to do an o call. So you may remember from last time.
00:46:13.496 - 00:46:48.996, Speaker B: If not, you'll hear it now. Ecall and Ocall is a bunch. To start up an enclave, you do an e call. That's how you start an enclave. When an enclave needs to access something from the operating system, it requests it through an o call, a call to outside the enclave. You'll see that there's two parts of each one of these O calls. When your enclave goes to access a file, it goes through an encryption layer, then it goes to an O call for writing to a file that actually does an O call.
00:46:48.996 - 00:47:50.630, Speaker B: There will be a stub for it defined in Gramine, but it does the low level ocall instruction that lands in some other code defined by gramming. But it's now in the untrusted OS, and ultimately that's going to invoke an underlying syscall to the real host, to the real file system, and that's going to basically write a whole encrypted block there in the output. Now I will show you, I mean, I could try to give an example of just what it looks like to use this. This is kind of useful, but really the point is I'm trying to zoom in on a very particular thing, which is that when you use, even though this is an encrypted file, it's going to be leaking which part of the file is being accessed. I'm going to make this example, just to be concrete about it. That's going to fill up an array of random users. I'm going to make this on easy mode to make a point, but I'm just going to happen to have a four kilobyte block of user data for each user.
00:47:50.630 - 00:48:40.994, Speaker B: So each user has their own little chunk of memory. I'm going to run this program that first sets up an array and populates it with all this user data. Then I'm going to think of a user at random, and I'm going to output the hash of that user's page. The question is going to be, does this reveal which user? This is like a guess who game is this going to reveal which user was selected to have their data hashed and then output? And if you think of the encrypted file as just, well, this is one whole encrypted file. Any interactions with the file are encrypted, then I'm good. That turns out actually not to be the case. And you wouldn't notice that it's not the case unless you go and do this, what I'm calling a spicy printf attack, which is that basically, even though gramming you just run Grammy, you don't see anything out of the ordinary.
00:48:40.994 - 00:49:23.402, Speaker B: You just see an encrypted file was accessed. An encrypted file was accessed. But in the reality, what you can do is add print statements that log where in the file the access took placed. Now you can't go and modify the code in Gray, that's in the enclave, in the TCB, because if you add a print statement there, it would change the Mr. Enclave and then you wouldn't have access to the sensitive data at all anyway. But if you change the code in the untrusted portion, which is what actually goes and accesses the file, you can just put printf statements there, you can do whatever you want in the untrusted host. The enclave has no way of telling what you're doing on the outside of it.
00:49:23.402 - 00:49:54.554, Speaker B: You can put all the print statements there that you want. I will do a demo of this. I should be set up fine to do this. It won't be in here, it will be in back. In my Grammy directory. I just want to be in Grammy for this terminal and I want to be right here for this. So I have an implementation of this little user thing.
00:49:54.554 - 00:50:33.304, Speaker B: They call it Python three. I need to remove my output directory. Just skip this and go to make. Yeah, probably just do make. All right. Okay, so no problem here. I mean, I can print with the program does, it's not very much to it.
00:50:33.304 - 00:51:09.404, Speaker B: I generate 1000 users. I store it in this output dat. And if you remember from my Python manifest, I set up this output dat as an encrypted file. If I look at, I mean, I wrote to this encrypted file now. So if I look at it, it's binary that is encrypted. So that is an encrypted file even though the contents of it clearly is email addresses and none whitespace. And you know, that was all I got from Grammin.
00:51:09.404 - 00:52:01.600, Speaker B: Now I could edit things in gramming, like maybe the, I want to make it clear that I'm not going to be changing, I'm not going to be abusing something that I shouldn't have access to in this. So like I have debug set to false. I don't have the log level set to anything that's, I wouldn't have log level debug because I have it set to debug that would show up in the generated Python manifest. I'm going to modify gramming to add some print statements in a second and I want to get a nice reference of what my version is. Well, I can just do that report trick, run my script to get the SGX report. That'll be a convenient way to read. I remember that from earlier.
00:52:01.600 - 00:52:28.502, Speaker B: This is the same Mr. Enclave. Now what I'm going to do is go poking around in the gramine codebase. I think I'll flip to GitHub first for this, but then I'll just show you where they go. This, pal is the portable abstraction layer. This is their implementation of all of these file system features, all these Unix features, and this some Linux SGX. This is the relevant implementation of them.
00:52:28.502 - 00:53:22.248, Speaker B: And you see all sorts of interesting things here. Maybe you remember from Moe's demo last week of how there are some components set up. Basically when setting up the enclave, all of those things are here you have all of the definitions of the enclave, e calls, which are ways of jumping into the program. The most interesting ones then for us in this example are enclave ocalls, because this is where they have all of the file operations like ocall read. This is what gramming calls from your enclave. This is still in the enclave, but whenever you go to read a file, when I do file read in Python, it'll go to read here. This in turn will actually carry out ocal stuff.
00:53:22.248 - 00:53:54.524, Speaker B: It sets up the o call and sets that branch there. There's also code in here for basically handling what is on the other side of the o call. So if you go to enclave ocalls, you go to host ecalls host calls you have where it lands in the untrusted operating system. So you also have SGX ocallread. This is in the host, but it was called from SgX. This basically just passes along. All the encryption has already happened at this point.
00:53:54.524 - 00:54:47.444, Speaker B: So this just gets passed along to the untrusted OS syscall. What I have set up here is I'm just going to poke around in that code and add print statements. I am in host access jx host oh calls and well, I probably already had print stuff, so I'll just follow along with where my prints are. So I'll look at. I could add any of these, I'll uncomment these ones. These p reads and p writes. These aren't the most obvious ones, but for the encrypted file system this is actually what it uses to service those.
00:54:47.444 - 00:55:35.108, Speaker B: So this will give the most clear thing to add these print statements. And what I'm going to do is I'm going to leave the enclave here and what I'm going to do is just rebuild Grammin. So wasn't really a whole lot to rebuild, but it did actually pick up those changes. My enclave is still going to be the same. When I generate a report, I think I won't even see anything different at all. But now when I go run that user's test, I'm going to see a different story. So what I'm seeing are printfs every time I write to this file filled with 1000 things.
00:55:35.108 - 00:56:14.696, Speaker B: So it used up my buffer. But what you're seeing is that it's reading a four kilobyte page at a time. That's where all that encrypted data in my output file came from. What do you think happens here? It's going in one direction, then it reads zero, then it keeps going in a pattern, then zero again. I think it's like writing a span of blocks of the file and then going and updating a header, like a summary in the file after it's written. So many blocks. Anyway, all these are just counting up by 4096.
00:56:14.696 - 00:56:51.812, Speaker B: This is one block at a time. The file system will always be writing a whole block at a time, because even if you just change one byte, I think it'll write the whole block. Because the encrypted file system works by encrypting one block at a time. Here's the interesting thing. I filled the user data, and then I selected one at random and went and read that. And so what do I see? I have all of the counting up chunk by chunk, and then when I go to do my random read, well, this is the index of the user account that I read. I think that I only read one page, but it got spanned across three pages.
00:56:51.812 - 00:57:37.476, Speaker B: I think it expanded a little bit to include a little bit of expansion for the ciphertext of each. Anyway, when I want to read one user page, even though that's only 4096 bytes, it actually spans three blocks of reading from the file. So this is called a spicy printf. I'll wrap up, I'm out of the time here, but that's enough of an ending point for that. Is this bad for the application? It really depends. It looks like you have an encrypted file system, but the fact is that there's this leakage might not be obvious to you if you just look at what's output by gramming. Because it's not what's output by gramming that matters, it's what you can do as the attacker here, modifying all of the stuff that's outside the enclave to learn everything that you can about the enclave that's taking place.
00:57:37.476 - 00:58:16.264, Speaker B: So in general, this is called a controlled channel attack. It's called a controlled channel because it's not really a side channel, because it's not to the side. It's just part of the. It's just a channel, right? It's in the front, it's part of the documented interface, but it is something controlled by the attacker. And so whether that affects an application or not, you have to deal with the original, I think, introduction of this term, controlled channel attacks. I've been revisiting it to prepare for this, and it's a really excellent video and paper, so I'd recommend it. They do something similar, but they do it by reconstructing documents from the program.
00:58:16.264 - 00:58:52.018, Speaker B: Traces of a word processor that you can tell as it is jumping around in the code for interpreting a font, basically. So it's a similar kind of thing. And later on we'll talk about ways of avoiding this. One way of avoiding this, if you cared about it, is maybe just loop over the entire array and don't give away which one you're interested in. Actually looks through all of them. I think at some later point we'll talk about oblivious Ram, which is a way to do this. There may be other mitigations depending on the system that'll mostly kind of leave that open.
00:58:52.018 - 00:58:58.494, Speaker B: So this was introducing that, giving a demo of it. Yeah. Any questions? I might stop there.
00:59:09.994 - 00:59:57.634, Speaker A: There's a question in the chat from Leonardo. I'm going to do my best to represent. Read this question. It goes like this. There's been many very fancy and smart side channel attacks to observe what's happening inside the enclave. But what I hear here is that attacking the enclave is usually easier because some current implementations are leaking information but not being careful. Do you think it will be easy for blockchain developers to understand this new verifiable reducible enclave execution and making it safe, or that we will have first a lot of attacks and lost money before they start following the tee best practices?
00:59:59.134 - 01:00:33.162, Speaker B: Yeah, that's such a good question. That's what I'm really concerned with. I absolutely think it is the case that there are more vulnerabilities created by how the applications use Tes then just from the Tes themselves. But it's hard to say that comparatively. I mean, basically both are issues. Side channels are often mitigated in some way by patches, but design things, you still have to catch those too. I mean, something that's on my mind a bunch is that it's not always the case that you get to the point where someone loses money as a result of these.
01:00:33.162 - 01:00:55.868, Speaker B: A lot of the things here involve, I don't know, privacy in some way. It kind of depends. Yeah. I mean, maybe it results in something that you notice. I mean, my biggest concern is, I guess that no one has an incremental incentive to catch all of these. But it is a tragedy of the commons and the better we can. That's the point of all of these.
01:00:55.868 - 01:01:14.324, Speaker B: Raise the standard for best practices and understanding of these. So easy. No. Important, yes. Can it be done? Meaning can we make smart contract developers and blockchain engineers, you know, learn all the basics of this stuff for the important bits of it? Yeah, totally. I think that's obtainable. Easy, no, but doable, yes.
01:01:14.324 - 01:01:28.704, Speaker B: So I leave it there. I feel like I saw there was a follow up. Okay, we're all good.
01:01:29.044 - 01:01:29.692, Speaker A: Amazing.
01:01:29.748 - 01:01:30.384, Speaker B: Yeah.
01:01:31.364 - 01:01:37.964, Speaker A: Awesome. Yeah. Any other questions or are we. We feel satisfied.
01:01:45.504 - 01:01:47.644, Speaker B: Satisfied. Great.
01:01:48.104 - 01:02:14.784, Speaker A: All right, awesome. If you're watching this and you have questions, please do go to the forum. There are slides there's the recording, there's conversations and everything else in between. So go to the forum collective. Thank you so much, Andrew, for this amazing live session. Also, keep an eye on the forum for upcoming sessions soon to be hosted. Yeah, any.
01:02:14.784 - 01:02:23.244, Speaker A: Any last words? If not, thank you all.

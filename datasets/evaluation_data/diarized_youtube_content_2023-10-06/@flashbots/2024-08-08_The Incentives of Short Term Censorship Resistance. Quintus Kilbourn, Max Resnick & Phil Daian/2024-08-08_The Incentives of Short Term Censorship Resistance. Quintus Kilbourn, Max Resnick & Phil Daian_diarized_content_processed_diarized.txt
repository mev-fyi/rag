00:00:03.800 - 00:00:09.150, Speaker A: All right, up next, we have our panel. The panel will be moderated by Quintus Kilburn, who's a researcher at flashbots.
00:00:09.230 - 00:00:16.210, Speaker B: And, Quintus, I will have you introduce your panelists. Thank you. On the right side of the ring.
00:00:17.590 - 00:00:18.850, Speaker A: God damn it.
00:00:20.070 - 00:01:10.630, Speaker B: Okay, so earlier in some of the talks today, we have heard mention of multiple concurrent proposes, but we haven't gotten too much into the topic. And so in this panel, we'll try to cover the proposal or the set, like the class of proposals, I guess, in that direction, give people some context, and then sort of discuss the mev side of multiple concurrent block proposes. There's obviously, like, a consensus challenge to this as well. And Max might mention that a little bit. But today I'd like to focus on some of the incentive issues, how this impacts validators, how this impacts, like, users accessing the chain, et cetera. I guess if people don't know, I fall to my right, who will introduce himself when it's his turn to speak, I guess, and then Max to my left. And I think the rough divide today is that Max has been pushing the multiple concurrent proposes direction.
00:01:10.630 - 00:01:28.992, Speaker B: And I think Phil has some reservations. And so that's going to be the setup, but hopefully it'll be a constructive discussion. So maybe just to get a start at Max, can you just sort of frame multiple concurrent proposes and explain the. The setup?
00:01:29.176 - 00:02:05.390, Speaker C: Yeah, I think. I mean, just to be clear, I'm not trying to push anything. I just think that this is what we should do to make Ethereum better. And so I'm presenting the idea and why I think it's a good idea to make Ethereum better. And if people disagree with me, then we shouldn't do it. And if people agree, then we should do it. The basic idea behind multi proposer is like, two years ago, I was sitting with Elijah, who's one of the co authors on the initial censorship resistance paper, and we were trying to figure out how to solve basically toxic flow, and in particular, the element of toxic flow that gets forwarded directly to the proposer through Mevboost or previously Mev geth.
00:02:05.390 - 00:02:55.088, Speaker C: And so we wanted to figure out how to make that part of the auction that's currently going to the proposers actually go to the app so that we could create lower spreads. And so the first thing we thought about was, let's do an auction. But it turns out that doing an auction is actually quite difficult on chain, because, say you have a $1000 item, the proposer can censor all competing bids, put in a stink, bid for one cent and win the item for one cent. And so in order to stop that, you have to put extremely high proposal tips, and you end up giving away a lot of the value from the $1,000 item to the proposer. So our solution to this was basically, instead of one proposer, let's end the proposal monopoly. Let's make multiple proposers and then make more than one way to get on chain. And then hopefully, no proposer monopoly exists and we can hold an auction again.
00:02:55.088 - 00:03:01.340, Speaker C: And we like auctions a lot, so we think that's a very good direction for DeFi on Ethereum to go in.
00:03:02.320 - 00:03:28.872, Speaker B: Okay, cool. That's the motivation for the problem. And now if we look at the last couple of years, people have been trying to address the short term censorship resistance of ethereum for a while, and that has all come in the form of inclusion lists of various forms. And the most recent proposals are like fossil, which people might be familiar with in the audience. Could you contrast the MCP approach to what fossil has been trying to do?
00:03:29.056 - 00:04:15.156, Speaker C: Yeah, so I think there's two things. So fossil is actually not too far off from what we're talking about. But over time, the inclusion list proposals have gone from one inclusion list from the proposer, which gets included in the next block, to now multiple inclusion lists from, not necessarily the proposer, but from the inclusion list committee that now get included in the current block. And so we actually see the inclusion list proposals kind of trending towards multiproposer. I think that's probably fundamental, because the only way you get censorship resistances by having more than one choke point to get onto the chain. So I don't think they're that different. There is a key difference in that the implementation of fossil has a proposer who has some elevated privileges.
00:04:15.156 - 00:04:43.840, Speaker C: So the fossil, we call them the view canonicalizer. They have some ordering power, and in particular, they can act later than everybody else. And so they have last look. And so I think that's the key difference between fossil and braid, which is the design that we've suggested, which is that braid everybody proposes at the same time. Same time. I know Phil will quibble with that a little bit, but at least in the same synchrony route, everybody proposes. And that's the difference between braid and fossil.
00:04:44.000 - 00:05:29.080, Speaker B: Okay, so just to recap, we're trying to achieve short term censorship resistance the way that all of the approaches are trying to do this that have been proposed so far has been involving multiple actors sort of giving their view, and that being included by the chain in one form or another. What distinguishes the MCP approach is that we're trying to have all those proposals from the committee sort of happen at roughly the same time. And the reason we want to do this is because we want to take away any privileged power that a specific actor will have. Okay, Phil, can you steel man this approach? If you're going to make an argument for why we should pursue the MCP direction, what would your justification be?
00:05:29.740 - 00:06:18.110, Speaker A: Yeah. So maybe to give you all a little bit of lore. Part of it is, it's kind of funny, because most of the time I spent sitting in this room was when I was here in grad school working on MEV for the first time. And very early on into studying meV, this was kind of the first direction I took, was like, can we just have a committee to kind of remove a lot of these issues from the l one protocol? Funnily enough, I took a class in this exact room to try to figure that out on social choice theory and voting and kind of all of these ideas of compressing these vectors into a single order. So I have a lot of empathy for the idea. I think the steel man is exactly what Max said. It's like, why have one input when you can have many? But the question is, then, what are those inputs and what are the incentives behind them? So I think that's where the steel man breaks down.
00:06:18.810 - 00:06:41.210, Speaker B: Okay. And then, Max, I realize there's two components to the MCP. There's the, actually, can we implement this in consensus in a way that preserves the properties that we care about? But leaving that aside, assuming we have the eventual consistency we want, and these kind of things think are the sort of the most reasonable critiques of the direction you guys are proposing.
00:06:41.750 - 00:07:47.684, Speaker C: Yeah, I guess if we kind of assume the hardest part about the consensus, let me just say that is basically, can we get synchronous release, or are the timing games too bad? Or are there games you can play with the attester as well? And so I would say, if I'm attacking the idea, I think it's like, can you demonstrate that that is solid and that we can actually achieve the desiderata that we have there for synchronous release? So I think that's definitely a potential failure point, but that's on us to prove that we can do it in the system that we were describing with braid. I think there's definitely a lot of legitimate critiques of each of the ordering rules. In terms of my personal perspective, I'm spending more like 70% of the time on braid the consensus rule. And I hope that there will be a lot of discussion in input on what the ordering rule looks like in the end. But certainly if you choose the wrong ordering rule, you could get worse outcomes, because the ordering rule is incredibly integral to what game we're actually playing. And if the game is wrong, we could get spam, we could get all kinds of undesirable things that we had in pre mepgath days.
00:07:47.772 - 00:08:25.952, Speaker A: So I'm going to jump in with maybe two criticisms there. Number one, I actually don't agree that the last look or the release is the critical problem. I mean, I think that's one of the many. But I think there's also, like, how do you pay for advantage in the ordering? So can I pay to bias the ordering in my direction even if I don't learn the ordering first? I think that's one example of another, what I call a perturbation vector in the ordering, which are super important to quantify and study. So I think to say the last look is the big problem. You actually need to quantify both of those things and then compare them, which hasn't been done for any of these proposals, I think.
00:08:25.976 - 00:08:37.680, Speaker B: Before we continue, I think this is a good discussion to have. Some people might not be that familiar with the ordering rule discussion and why that's even important. So could you just, like, explain what that is and just high level what some of the proposals are?
00:08:37.760 - 00:08:59.022, Speaker C: Yeah, so there's two stages here. We have the consensus stage where we have multiple proposers. Each of them propose a partial block, and then we zip up all the transactions with the union. And then you apply a deterministic ordering rule on that unordered set of transactions, which spits out an order. Is that sufficient explanation, or is there.
00:08:59.086 - 00:09:03.526, Speaker B: That's sufficient. And then can you just cover. There have been two major proposals so far. Can you just touch on what those are?
00:09:03.558 - 00:09:53.580, Speaker C: Yeah, so there's two proposals. One of them is basically you just sort by priority fee in descending order, so you just execute the highest priority fee first. And there's a modification of that called MEV taxes, where you are able to tax a certain percentage of that priority fee and send it to the app itself to distribute that Dan Robinson and Dave White put out. And then there is another proposal, which is also a modification of priority ordering that I call execution flags, and it basically allows transactions to set a flag of. I want to touch the uni v five pool trading eth USDC. Then when the ordering rule hits the first execution flag, it pulls all the transactions that are trying to hit that pool and executes them as a batch.
00:09:54.510 - 00:10:02.550, Speaker B: Okay, cool. I think that's pretty good. And then just coming back to Phil's point, do you want to just give a quick recap of that and then we can continue from that point in the conversation?
00:10:02.590 - 00:10:33.320, Speaker A: I mean, the point is. So, for many MeV opportunities, what matters is who can touch the state first. That's a broad class of these opportunities we're talking about. Certainly sextech's arbitrage is conditioned on that. And just because you can't control the full ordering doesn't mean you can't bias it in your direction and economically. All you've done then is taken this deterministic arbitrage and moved it to a probabilistic arbitrage, which in general, fewer people know how to price, fewer people know how to bid in the auction in. This was kind of the core of malicious talk, and they can also exercise more pricing power.
00:10:33.320 - 00:10:43.020, Speaker A: So that is one important dimension, basically, against which none of these new l one proposals have been analyzed, which I think is super, super critical for future work.
00:10:43.440 - 00:11:42.176, Speaker C: Yeah, I think in some ways my goal isn't to make uniswap v three or v two work better, because you would actually have to change the app for it to work better, to take advantage of the new tools that we're providing. If you're in this world where all of the apps look exactly the same as they are today, then we give the app developers a bunch of tools and they say, actually, we already sold all our curve and have a couple of houses in Australia, then it doesn't matter because they haven't done anything. The app developers are going to have to uphold their end of the bargain, which is to move apps to a more order agnostic situation, which I think they will do. And there's plenty of companies that are already trying to do this, even now, even though they're severely restricted by the l one. And I think that we would see a lot more movement in that direction if we gave them the tools to do it. So it doesn't necessarily have to look the same way. We can imagine what can be unburdened by what has been.
00:11:42.328 - 00:12:09.894, Speaker A: I mean, no, I think to me, an ordering agnostic system is almost like laughable. From the context of mev, the ordering will always matter. All you can do is make it agnostic to the l one, which basically means you're moving that same game just to some other part of the system. So rather than having the centralization at the l one, you now have it in the Unix auction, for example, which is then influencing your blocks on l one. So I don't think that's actually meaningfully improving the situation.
00:12:10.062 - 00:12:19.948, Speaker C: I mean, an auction inherently is completely order agnostic in that it processes all the bids and then it computes the highest bid.
00:12:20.124 - 00:12:28.020, Speaker A: Not if it's an auction for who goes first. Then it's not agnostic to the underlying order that it's deciding, because that's how you pick winners and losers in an exchange.
00:12:28.060 - 00:12:46.962, Speaker B: For example, I think maybe a good way of having this discussion is to focus on an application. So we talk about all diagnostic applications. We can think of something like, I think Cal swap might be a good example, an on chain batch clearing mechanism. Does that make sense?
00:12:47.066 - 00:13:11.572, Speaker A: Even cowswap is centralized. It's exactly what I'm talking about. They've taken this MeV game and they've moved it to this permissioned off chain system that they're running in a data center. So they haven't in any way made their application ordering agnostic. They're just deciding that ordering on a centralized component. Basically it's ordering agnostic only with respect to the l one semantics, which doesn't actually change the economic power distribution or the centralization of the MEV in your system.
00:13:11.666 - 00:13:19.112, Speaker C: But Phil, why did they do it off chain? Because they couldn't do it on chain because they didn't have the tools to do it on chain because they didn't have censorship resistance.
00:13:19.176 - 00:13:56.580, Speaker A: No, they can't do it off chain because they're leaking information on the user quotes to a network of permission solvers. And the more solvers you leak that information to, the worse outcome you have, because essentially you're diluting the value of the information by simply signaling the bid into the auction. And to deal with that, they need to use things like proprietary fake bid spoofing and permission lists of like policing their solvers manually. And even if you had all the flags in the world, you can't move that off chain because someone still needs to police and create those fake transactions. That basically is a trusted party. Their application is not actually designed to be decentralized, which, by the way, side note, that was one of my original criticisms of them in like, 2017.
00:13:57.760 - 00:14:26.162, Speaker C: Yeah, I think Phil and I have a fundamental disagreement about how important noise trader information is. I tend to think that noise trader information is noise. So it doesn't convey that much information, but it certainly conveys some information. And so there are definitely trade offs there. You could feasibly do threshold encryption and then do a batch auction without revealing information. Right? Maybe in ten years when we have the fhe to do it.
00:14:26.266 - 00:14:55.534, Speaker A: Okay, so threshold encryption has some other gotchas. So I can give you my kind of counter view, my thesis of mev, which is that there's a few things that matter. The first one is actually looking at the real mev game of how economic power expresses in the system. So there's two trading firms. They want to compete, who wins and why. Do they use latency? Do they use spam? Do they use an auction? Do they use capital? What's their advantage? What's their edge? What's their competing game? So that's one example. And I think you have to look at it through the lens of statistical perturbations.
00:14:55.534 - 00:15:21.858, Speaker A: Just looking at deterministic ordering is not enough. So I think that's one bucket, and I think the second bucket that becomes more relevant here is for Ethereum and for the system. What I think is really important are actually four different properties of block building. And that's what determines whether we end up in a decentralized cryptocurrency or not. So the four properties are, number one, permissionlessness. You need to be able to join the system and express your economic value at any time. Number two, distribution.
00:15:21.858 - 00:15:56.052, Speaker A: The system needs to be logically and technically distributed across many computers and many nodes. Number three, geographic decentralized. My mic cut geographic decentralization. And I'm not talking about the Solana definition, where you have one node in the US and one node in Europe. I'm talking about a protocol that's designed to minimize the additional profit from colocation. And the fourth is the ability for a neutral builder to enter the market without a substantial barrier. So that was something like Malesha's talk was addressing earlier, where certain structures kind of biased towards incumbents.
00:15:56.052 - 00:16:12.136, Speaker A: So I think those are the really important properties. I think something like threshold encryption, it doesn't satisfy the geographic decentralization because of this last look issue, because if you co locate, you can run the protocol much more quickly, et cetera. And therefore it's a centralizing market force on block building.
00:16:12.328 - 00:16:48.880, Speaker C: I think we agree that permissionlessness is incredibly important for the ideal block building world. I think it's also very important for applications on chain. And that's why I care about censorship resistance. Because if the proposer can tell you that your bid, your signal of what your demand curve is, is not getting on chain, then they've effectively prevented you from participating in the system and expressing your value. And they can do that for their own gain. And I think that's an incredibly harmful thing that really kneecaps a lot of app designs that we could see on chain.
00:16:49.220 - 00:17:29.755, Speaker A: I mean, I think we all agree censorship bad, right? And there's like time horizons of censorship, like ETH today. Is censorship resistance resistant, if you're willing to wait, MCP is not censorship resistant on a short enough time horizon because you have latency actors that can frontrun you arbitrarily, for example. So I think we're like splitting hairs over like, how fast does the censorship need to be? I don't know if we have consensus among that as a space, certainly I agree censorship is bad, and we want people to be included as quickly as possible, and we want many voices to participate in this. I think where we disagree is, I don't think a committee is the right structure to pick ARB winners and losers, because it opens you up to manipulation of that committee, which is a centralizing force on the committee rather than a decentralizing one.
00:17:29.827 - 00:17:33.719, Speaker C: But why is it better to have one person pick our winners and losers on the committee?
00:17:34.139 - 00:18:15.398, Speaker A: Well, because, I mean, if you have one person pick or a committee, they're all going to be listening to the kind of economic powers that be, right? So what you want, ideally, is like efficient outsourcing of that, which is kind of the PBS thesis. It's not like the validator that's meaningfully building the block or censoring, and in, for example, a suave or programmably private model. It's even less so because they may not even see the contents of that block. What matters is decentralizing the actual building process. If you have MCP, yes, you've said we've taken multiple inputs into this last step, but that doesn't necessarily mean multiple economic parties are involved in the building. If SCP has better latency to all these nodes, they can still censor you for some definition of censorship. They can frontrun you every time.
00:18:15.398 - 00:18:28.500, Speaker A: They can collapse the network to their own validator nodes because they're making more profit per block than anyone else. And I think those are also very dangerous censorship vectors, more than the technical. Are you included this block or not?
00:18:28.800 - 00:19:03.168, Speaker C: Yeah, I don't really see how any of those things are specific to multiproposer. I'm pretty sure that SAP, if they wanted to, has the economic advantage to be able to give a profitable agreement to a bunch of node providers today. In fact, this is like not SCP, but this is something that has happened before. There have been offers that have been made by builders. At least that's the rumor, to partner with validators. And so I don't see how that's a fundamental issue with multiple proposers.
00:19:03.264 - 00:19:44.802, Speaker A: Well, what multiple proposers does is it shifts the game more towards a latency game, because your latency among those proposers is an extremely relevant variable in how much each is able to extract and also the efficiency with which the various Arb firms can extract MEV on top. So you've basically taken like what you have in MeV is you have a three point pyramid. It's either auctions, latency or spam. There's no other known way for these trading firms to participate in the network and get an advantage. They either optimize their latency to various points, they spam people in the network, or they participate in an auction. Those are three things we've observed in practice, if anyone knows a fourth. I'm always open to adding to the model, but I haven't found it yet.
00:19:44.802 - 00:19:55.250, Speaker A: So the question is, how are you moving the dial between these things for these firms if you're moving it more towards latency? I'd argue, if anything, you're centralizing the network more in the long term.
00:19:55.370 - 00:20:24.090, Speaker C: Yeah, but I don't think it's that clear that this is actually more latency heavy or more weight on the latency, because currently you have timing games which are based on, you get an extra, however many milliseconds of proposing monopoly here in this new system, you would have an extra few hundred milliseconds of ability to add transactions, which is valuable, but not necessarily as valuable as an extra 100 milliseconds of proposal monopoly. So I think there's definitely competing effects.
00:20:24.510 - 00:20:52.710, Speaker A: Well, no one's done the math right, because the surface is large. Like you can bribe any member of the committee, you can take action in any member of the committee, depending on your ordering rule. It may be the case that you even have one pivotal node in your ordering. And like how you kind of, like I said, like all these kind of impossibility theorems from social choice, right? Often, like, you have pivotal nodes in the network where bribing these nodes or impacting these nodes is much more profitable. So I think it's plausible that you're right, but I think someone has to actually do this math, which no one's done yet.
00:20:53.290 - 00:21:21.990, Speaker C: Yeah, I think it's important. Well, we're, we're just getting started on it. I think it's important math. I would just say, I want to just clarify that we're not thinking of this from a social choice theory perspective, because in social choice theory, fundamentally constrained by you don't have a strength of preferences. And so this is like a situation where we have tips and so we do have a little bit extra information that lets you get around some of those impossibility results.
00:21:22.150 - 00:21:30.810, Speaker A: I mean, that's not true in like quadratic voting and many other. Right? Like there's all sorts of voting systems that let you express strengths of preferences.
00:21:31.190 - 00:22:02.470, Speaker C: Yeah, but this is a situation, we're not trying to make ordering decisions based on the ordering of each of the individual nodes at all. In fact, we just ignore that information of what order each of the individual nodes put stuff in. We're going to not take that into account at all. All block space is going to be fungible. Basically. Block space in one proposer's block is going to be the same as block space in another proposer's block, because we're going to zip them all up into an unordered set and then apply the ordering rule, which does not depend on any ordering input from each of the proposers.
00:22:02.660 - 00:23:01.090, Speaker B: I want to hop in here because I think we're running low on time. I'd like to go back to something which came up earlier. My understanding broad strokes of the discussion so far has been that the multi proposal potentially addresses some of the censorship issues. Phil's made the point that there are many other one. It may not be the case that this is always true because there might be different dynamics that evolve that favor certain players of others and erode some of the properties you want from censorship resistance, but also that having multiple proposals impacts other properties of the network that we might care about, like geographic decentralization. But my question then, and you did mention some of this, but I'd like you to elaborate, what is the alternative vision if we don't pursue this committee based vision? Can you elaborate on how we get some of these, these centers of persistence and related properties in the network without relying on a committee?
00:23:01.670 - 00:24:10.716, Speaker A: Yeah, sure. So my opinion on all this is everyone in the space should be working on like really one problem at this point. And that problem is let's take a look at the tree, or the DAG, or whatever you want to call it, of economic messages and computations that go into building an ethereum block. And how do we make sure that this process is actually meaningfully including the input of many parties? Now it's not enough to just take the technical protocol and say we add a last step that aggregates the input of many parties. To me, this makes like a kind of error, which assumes that the economics will follow the technology, which is not the case. The question is, how do we take this power? Which right now comes from the fact that SCP has proprietary kind of algorithms that run on binance, comes from the fact that they're renting latency pipes from hedge funds and things like that. How do we take all of these economic forces and meaningfully push power out to the edges of the network, to places in the world where power has not historically existed in the network? And how do we get all of these different parties to kind of be economically meaningful in the block process? I think then, no matter whether it's one entity, one node signing the message, or 50, that's where the censorship resistance is going to come from.
00:24:10.716 - 00:25:20.408, Speaker A: It's going to come from the economic diversity and the fact that no one economic party has economic control of the block production process. I think we do that in a few ways. I think one is tee and other cryptography based tools being very, very careful about geographic decentralization, and not to introduce latency co location incentives, but use these tools to allow these disparate parties in the block production process to collaborate and to join each other's input, but having to accept each other's inclusion properties, and censorship resistance preferences and etcetera. So, one is to build these tools for collaboration, and the other one is to build meaningful demand, basically around the world, for transactions that need to be processed in different ways, that need to be processed in different locations, such that to leave these transactions on the table, and to leave these people's censorship preferences on the table, you need to pay costs. And I think ultimately that's where we get censorship resistance. If you're an app, the question is, okay, we're uniswap. How do we find more order flow that really needs these properties that we are trying to build for ethereum, and build this sticky moat inside block building, such that we can express our users power into the system.
00:25:20.408 - 00:25:41.570, Speaker A: I think that's what every Dapp should be doing. That's what the L1 protocol should support, is this universe of distributed block building. I think the key to do that is to make sure you don't introduce colocations, incentives, blockchains like Solana and many L two s. In fact, even many companies in this room have fallen short in the past and have seen the predictable MEV games.
00:25:44.590 - 00:26:47.900, Speaker B: You're welcome to say something. Otherwise, I have a follow up question. Okay, so if I put it on my MCP hat, I listen to that, and it sounds appealing, but hard to achieve. And I guess both on both sides, we have a lot of details we still need to flesh out to be able to have a really concrete discussion. But one of the things that seems to be true if we don't go in the committee based direction, which includes fossil and mcp, is that we leave one actor with this one bit of control, where if we keep a status quo as it is, the ethereum protocol, as it is today, and we have, or epbs, something very similar, you still have this one proposal, who can choose not to build a block, and that's one bit of control, but a very important, substantial bit of control. Do you think that we can continue with that being the state of affairs? And if we can't, then what is the alternative to using a committee?
00:26:50.400 - 00:27:35.164, Speaker A: Yeah, it's hard to say. I think all these questions, they really depend on the specifics of the protocol. Obviously, ideally you rely on as few people for availability and censorship resistance as possible. The question is, what are the trade offs and what is the most appropriate for building a financial system? I think it is better for ETH as a decentralized system to be in a status quo where there is monopolistic control every 12 seconds. But the economic game to actually build that block is more widely distributed versus like, let's say a world where you have many people inputting into these 12 seconds, but you have like fairly geographic concentration on the economic side. Now, which protocol leads to which world? I don't think anyone's done any of that work. So it's very hard to speculate.
00:27:35.164 - 00:28:14.970, Speaker A: Like, yeah, if you have a magical protocol, I think it would be great to have to not be relying on one person for availability. I actually think this is where these proposals converge. Like, I'm a very big fan of having multiple inputs into a block. I just think it needs to be done in a MEV aware way, such that the actual merging role considers the MEV and interacts with the private information in a very nuanced way to actually merge these outcomes intelligently and efficiently extract and redistribute the value, rather than exposing a lossy game for people to play statistically against with various other network resources. So I think I'm an MCP bull, but it's like Mev aware MCP, please.
00:28:15.470 - 00:28:46.972, Speaker B: I see. Okay. And then, so touching on this MEV awareness, Max, can you talk about like, what. I guess we still have some things to define, but what are some of the changes that would be required if we had braid or whatever MCP implementation we arrive at. It seems like there are important differences around our ability to have, or like, at least in my current understanding of braid, you need people to use the public mempool, for example. Please continue.
00:28:47.036 - 00:29:44.104, Speaker C: Yeah, you don't need to use the public mempool. You can send directly to the proposers. Actually, we modeled it as each of the proposers is running MavBoost, just that they're not running Mavboost collude version. They're each running their own thing, and they're trying to profit maximize for their own block. Not with respect to collusion with a large set of other proposers in the quorum. You don't necessarily need to use the public mempool, which I guess is a good thing, because that leaks information, as Phil said. And I guess what should we do in the next hard fork? If we actually want this as a direction, we should delay the state route by one block so that it's off the critical path, and we're prepared to move towards state route delay, which will be needed for multiproposertainous.
00:29:44.104 - 00:30:02.320, Speaker C: And we should start to think about how we can make sure that there's enough bandwidth available. We need to make sure that we do not give away all the bandwidth to peer das in order to preserve some, at least for the actual chain itself, and not for giving away free da to l two s.
00:30:04.660 - 00:30:39.992, Speaker B: Okay, I'd like to sort of continue a bit more down this line of thinking about external markets for block production. So today, the Mav boost auction is relatively simple. We have one actor who is the right to build the block, and they run the auction most of the time, and it makes sense for them to just take the highest paying block. But in this world, it looks very different, right from the perspective of someone who's trying to land something on chain. There's multiple avenues, and maybe latency, like Phil is saying, is the more important dimension. Could you have you thought through how.
00:30:40.016 - 00:30:44.180, Speaker C: This market would evolve in terms of the latency games?
00:30:45.400 - 00:30:54.940, Speaker B: If I'm running a validator, it's my turn to be one of the proposers. How do I even select what block goes in? Is it just another auction?
00:30:55.680 - 00:31:40.562, Speaker C: Yeah, you just look at the set of available transactions and you try to include the ones that are the highest expected inclusion tip for you, because you're nothing. Getting an ordering tip, the ordering tip is going to be captured by the protocol. It's actually an easier problem of like, I'm just looking at the inclusion tips and trying to maximize my expected value over the inclusion tips and there's some randomness, because if I include something that a bunch of other people are including, I have some reduced rewards for that. But still, I'm going to basically look at the available transactions, some of which may be from the public mempool, some of it which may be private, and try to construct the block that I think maximizes the inclusion tips. And I don't even have to care about the order at all and just subject to validity conditions, maximize my inclusion tips.
00:31:40.746 - 00:31:57.110, Speaker B: Okay, but how do timing games play into this? Because, you know, someone has to release their blocks. You know, someone has to release their block first. You know, there's no true simultaneity. Do you think you see today we see people with incentives to delay their blocks. Do you think this carries forward?
00:31:57.580 - 00:32:44.050, Speaker C: Yeah, I think if we don't do anything about it, then we will see something like that carrying forward. Like I said, I think the timing games, you have to think about what the incentives look like. I actually think currently it's very unaligned behavior not to participate in timing games, because you are basically giving away free money to somebody who will participate in timing games if you don't participate in it right now. And part of the problem of timing games is that the devs set like some zero second all time for honest nodes. And that was actually way too far from where they should have been if they're playing a timing game. And so the honest nodes who are playing a timing game are not anywhere close to the dishonest nodes who are waiting 2 seconds. Dishonest whatever.
00:32:44.050 - 00:33:12.600, Speaker C: They're just rational. I think everybody should play timing games. We should push it all the way to the limit, and then the delta between nodes will not be as high as it is today. It's high because we're trying to cling on with a thread of social fabric. The social slashing committee will come get you if you play a timing game, which they won't, but just everybody go do it and it will not be that bad for Ethereum. And the difference between honest and dishonest nodes will be going down.
00:33:13.580 - 00:33:36.908, Speaker A: I don't know if I agree that it won't be that bad for Ethereum. I think it harms an important builder vector, which is then you need timing games infrastructure to participate in the protocol. And depending on what your returns curve looks like for that timing games infrastructure, if you spend more money on the latency infrastructure and get more profit or more of a percentage of the network, that's then a very centralizing effect on the validator set.
00:33:37.004 - 00:33:46.156, Speaker C: Well, I'm not saying timing games is a good thing, I'm just saying given that timing games exists, the best thing to do about it is to let it rip rather than to try and cling on with the social.
00:33:46.308 - 00:34:14.158, Speaker A: I agree for participants, but I think for the l one we should try to minimize. It is also my perspective on MCP. It's rational there for everyone to play timing games and listen to bribery oracles and play inclusion games, and possibly offer cancellation modules through SGX for backdooring ordering into inclusion, and blah blah blah blah blah. We should assume everyone's rational. The question is then how do we design the l one such that we don't get weird degeneration in the protocol?
00:34:14.254 - 00:34:55.019, Speaker C: Well, yeah, the core thing that we should do is do miss slot penalties. That's like a no brainer, because not having a missed slot penalty is contributing to timing games being much worse in that we're getting more miss slots in equilibrium from not having an appropriate missed slot penalty. And it's just so funny that you try to work on ETH and then they tell you actually like, you can't have any compute because we're going to run everything on a raspberry PI. You can't do anything that involves timing and you're not allowed to slash anybody. So like, what is left? Like what are we? And you can't have a committee anymore either, because Phil said, so what are we supposed to do? Just sit here and just do out of protocol stuff? I don't know.
00:34:56.399 - 00:35:18.590, Speaker A: I mean, I'm not saying you can't have a committee. I think it depends on the protocol. The whole blockchain is kind of a committee right now, and the committee does some stuff. It's just like you don't want the committee to do timing critical stuff or pick our winners and losers directly, I think is my rant, but I am less bullish committees than many in the space, I won't lie.
00:35:19.650 - 00:35:44.240, Speaker B: Okay, I guess you mentioned it, the multimev boost meme, which I think Bert introduced the idea that if you're running these external auctions for multiple proposers, is there not some incentive to run these in conjunction or run them all atomically in almost a combinatorial auction fashion, undermining a lot of the committee based incentives.
00:35:44.740 - 00:36:32.982, Speaker C: Well, it's certainly an incentive to collude. I think if you're building a blockchain and you think that you have collusion, not just unilateral deviation, but actual collusion between more than f nodes that are byzantine, then what are we doing they could just double spend at that point. I think that's a graceful failure argument there, that, hey, if we end up with a blockchain where more than fr faulty or more than fr byzantine, then we'll go back to the proposal monopoly. In that case. That's unfortunate. I'll go work on AI or something else, because I'll give up. But I think there's also a bunch of honest parties in Ethereum who have incentives for the long term health of the system.
00:36:32.982 - 00:37:22.340, Speaker C: Right now, they're running metboost. We run metboost at consensus because our action in running medbus does not change the equilibrium of the whole system. Whereas if we were in a system where we're one of eight proposers, quite a good percentage of the time, or Coinbase is one of eight proposers quite a good percentage of the time, their individual decision has the power to take us from a terrible equilibrium where we have proposer monopoly again, and leave us in a good equilibrium where we have no proposal monopoly and we have apps functioning well. And that's my perspective on it, is basically now we have a one of one honest assumption, and that one guy is not going to censor, and here we're going to have a one of n assumption, and that's better than one of one.
00:37:23.880 - 00:38:06.814, Speaker A: Ooh, I'm so triggered. I have this thing in my brain where I can only think in nuance and any sort of a or b immediately. One interesting thing is, you said, look, if f are faulty in your blockchain, what are we even doing here? I totally disagree with that perspective. For example, in eth, you could consider running mevgeth when flashbots came out to be being a faulty node. Certainly many protocol developers did, and we had almost 100% of the network being faulty and still providing many of the guarantees that we care about. So I think it actually does. In a rational world where everyone's incentive is to move in the same direction, we actually need to handle incentive perturbations, like, maximally against the set of properties we care about.
00:38:06.814 - 00:38:17.350, Speaker A: Without this binary of, like, our nodes faulty, or are they honest? We need to look at, like, what will they actually do in the protocol, and what will they do as a herd, and do we still get the properties that we want out of the system?
00:38:17.470 - 00:39:13.330, Speaker C: So let me just say before you quickly, okay, like we're reasoning by Analogy here, this is not the same as MetBoost. MetBoost was a Unilateral Decision that was a profitable deviation for everybody. And like I said, your decision did nothing change the decision of anybody else to participate in collude boost. Your decision does change the decision of Other People to participate. And if one person in the quorum of eight, or of four, or of 16, or however many proposes we have is honest, then they will not have collude boost because you need everybody participating. And one of the nice things about having eight is that the probability that you have an honest person in there, even if the honest share is quite small, is pretty high because you have to do something to the n where n is the number of proposers. And that's kind of your probability of having a quorum without an honest person.
00:39:13.410 - 00:39:42.728, Speaker A: I mean, I'm going to sidebar that whole argument because I don't think we have time for it, but I will say I was talking about Mevgeth, not mefboost. And there I think it is. Actually, your profit from deviating is proportional to how many people deviate, because the total percentage of blocks of space that was being allocated by the mechanism also matters to the profitability of each block. If you're making 2% of the network blocks through MeV Geth, it's not going to really attract flow and it won't give that 2% of the profit as if 100% of people are using it. They'll get much less.
00:39:42.784 - 00:39:58.400, Speaker B: Actually, that's, I think, a lovely discussion and lovely point to end on. So much, so much more to every interaction in this debate has given us another research topic. So much to come back for next year. Yeah, thanks guys.
00:39:58.700 - 00:39:59.140, Speaker A: Thank you.

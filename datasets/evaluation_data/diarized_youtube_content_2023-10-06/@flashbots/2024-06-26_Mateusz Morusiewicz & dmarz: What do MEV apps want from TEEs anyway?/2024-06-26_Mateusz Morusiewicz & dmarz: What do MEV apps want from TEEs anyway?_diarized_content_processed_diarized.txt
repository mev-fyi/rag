00:00:14.680 - 00:00:37.760, Speaker A: Okay, perfect. We are live. Welcome back to this episode of Flashwares. This is episode five. Today we have Mateo Shah and Dimarse, who will host a session, and Ferran as well. Excuse me. Who will host a session on the unique features that tes enable for Mev applications.
00:00:37.760 - 00:01:05.850, Speaker A: Additional information can, as always, be found on the forum for this session and any upcoming sessions. So head over to collective dot, flashbots.net dot. If you have any questions, that's also where you can post them after this session. Otherwise, feel free to post them in the sideshot. And with that, I'll hand it over to you guys. All right, so, as usual, we have not planned anything.
00:01:05.850 - 00:01:11.874, Speaker A: This is just. Let's just do it live, right? All right.
00:01:11.922 - 00:01:15.990, Speaker B: Doing it live. Hello, DiMars, what's up? How's it going?
00:01:17.170 - 00:01:43.376, Speaker A: Okay, let's jump right into it. I have. Hopefully my screen sharing is working. All right, I want us to draw some stuff. How about let me share. Let me share the link if you're watching on YouTube. Yes.
00:01:43.376 - 00:01:45.020, Speaker A: You can edit this if you want to.
00:01:52.570 - 00:01:54.990, Speaker B: Okay, sweet. I'm in there.
00:01:56.130 - 00:02:10.510, Speaker A: Let's go. Okay, so, Dimars, I would like us maybe to start is by you describing a example application that you'd want to put in a team, and let's see what useful features can provide.
00:02:12.050 - 00:03:00.760, Speaker B: Okay, sweet. I think there's quite a few we could do, so maybe I'll list some options. I think the simplest example would be something like Mev share. So an order for auction where we have a user who submits a transaction or an intent, some piece of information is leaked to the outside world, and then sort of a transaction is sent back, packaged up, and sent to the builder. Another example we could do is something like a dark pool. So that would maybe be, I send in an intent. Something is constantly running what's essentially a non lit order book and is trying to match me against other intents.
00:03:00.760 - 00:03:49.260, Speaker B: Someone then finally sends in another intent. They get matched, packaged into a transaction, and then ships to a blockbuilder. What else could we do? I mean, for a while I worked on a sealed bid NFT auction protocol, which did off chain ordering. I think that's pretty fun. And then something with AI. That's my fourth one. What do we think of those?
00:03:50.720 - 00:04:08.470, Speaker A: All right, yeah, we probably have. So we have booked 2 hours for this. So we have probably enough time to go through basically all of them in any order. I'll probably go with maybe the dark pool first.
00:04:11.170 - 00:04:12.546, Speaker B: That's the fun one.
00:04:12.738 - 00:04:43.710, Speaker A: I think that's the fun one, right? And then we can think a bit longer about what else. Maybe we could do an AI thing because it's going to be short and it's going to be different because I'm sure it will be very much, very similar to the dark pool. Right. And the silic protocol should probably just be a swap. Right, on the swap chain. But we'll see. We'll get into it and see.
00:04:43.710 - 00:04:51.270, Speaker A: Why would we put it natively on a t rather than heavily inserted?
00:04:53.090 - 00:04:53.506, Speaker B: Totally.
00:04:53.538 - 00:04:59.150, Speaker A: All right, so walk me through the dark pool and let's see how well I can draw this.
00:05:00.060 - 00:05:21.760, Speaker B: Okay, sweet. And we're making this up live. So let's, let's go through it. Um, I mean, so let's start with the inputs and the outputs. Inputs are EIP 712, signed to messages. We can call them intents. Um, we should ideally have a ton of intents.
00:05:21.760 - 00:06:03.400, Speaker B: It's like, you know, the, this is the requirement, just so we can think through what type of scale this actually needs to operate on. Not that we're going to poc anything at scale today. Yeah. How many? Let's see. Trying to find how many. How many swaps. Cowswap does an hour, but I cannot find their explorer.
00:06:03.400 - 00:06:29.696, Speaker B: Okay. It is not easy to see how many swaps are happening. Oh, okay. I can look at their settlement contract. It looks like they're going for one a block. Roughly one a block.
00:06:29.728 - 00:06:56.118, Speaker A: All right, so what goes out this one a block. So, and so we have users and we have some kind of LP's. Right. What are they usually called? They're not solvers. Right. This is the solver free. You know, I guess they're smaller.
00:06:56.118 - 00:06:58.890, Speaker A: I guess there's less of them and they're like bigger.
00:07:00.830 - 00:07:03.050, Speaker B: They're huge and we don't know who they are.
00:07:03.470 - 00:07:09.850, Speaker A: Yeah. Anonymous. All right. And they also submitted the order book. Right. It's like the same.
00:07:15.390 - 00:07:19.490, Speaker B: All right, we have from the chat, please restrict to value transfer intents.
00:07:21.070 - 00:07:23.170, Speaker A: That's not much of an intent chat.
00:07:28.030 - 00:07:37.220, Speaker B: What is the definition of a value transfer intent? Does that mean we're just nothing, swapping something?
00:07:42.880 - 00:07:44.952, Speaker A: All right, let's wait for a clarification.
00:07:45.016 - 00:07:57.020, Speaker B: And so we have what if chat, if I send a hug to Mateusz over an intent, is that a value transfer intent? Okay.
00:07:58.120 - 00:08:13.220, Speaker A: All right, so I have some waterbook and LP's probably look exactly the same as users. Right. It's just that they're matching from the other side. Ok. I guess it's all just 712 intents.
00:08:15.800 - 00:08:34.390, Speaker B: Yep. Yeah, I think they would probably, I mean, I think there's quite a large design space here on what the user actually. So what the user sends in and then also what the LP's send in. But let's. We can. We can keep it simple for now.
00:08:34.810 - 00:08:53.790, Speaker A: Yeah, let's keep it simple. All right, so we have, we have this. We have another book. So let's call this the tee box, right? Okay. Let's not call it a catalog. Let's call it the. So if we're designing this app as like.
00:08:53.790 - 00:08:58.576, Speaker A: Okay, well, there's something else here. There's like a matching engine or something like that.
00:08:58.608 - 00:09:17.580, Speaker B: Yep, exactly. Something that basically just needs to, like, pull or have a loop that it's constantly trying to match on. And then we probably need like a, like, batch submitter or something like that.
00:09:22.340 - 00:09:32.760, Speaker A: Okay. Yeah. Because the output of the matching engine is some stuff which doesn't. Isn't immediately useful. Right? Yeah, it's like a chain. Yeah.
00:09:35.740 - 00:09:44.484, Speaker B: Which, which, funny enough, a batch submitter is exactly. Also how opstack l two s work. They create the block and then send it to the batch submitter.
00:09:44.612 - 00:10:22.480, Speaker A: Let's go. Okay, so this is what goes here is the solution, right? Yep. Some matched. So the machine gunching basically just requests orders from the order book, right. I think that's kind of all it gets. And then there's probably like a notification going on. Right.
00:10:22.480 - 00:10:31.240, Speaker A: Notify whenever new orders come. Come around and indicate orders. And what goes here is like assigned TX, right?
00:10:41.300 - 00:10:49.470, Speaker B: Yeah, exactly. And then I. It probably goes to a block builder, which should also be another tapp.
00:10:59.570 - 00:11:10.310, Speaker A: All right, cool. So that's that, right? There are some moving pieces here, right? It's not very simple.
00:11:11.810 - 00:11:39.790, Speaker B: Yes, I would say also, I believe it needs some access to live data from whatever the settlement layer is. Let's just call it an l one. This way you could actually verify if intents are still valid or not and if any have gone through.
00:11:41.010 - 00:11:42.350, Speaker A: Right? Yeah.
00:11:43.330 - 00:11:46.630, Speaker B: Any considerations were missing, chat. Please let us know.
00:11:50.650 - 00:12:08.466, Speaker A: All right. We have some data going from the outside. Yeah, you're right. This is very important. Okay. But important. But it goes in.
00:12:08.466 - 00:12:35.240, Speaker A: Right. So it's not as. It's not as bad. Okay, so change that in. Okay, so we have inputs, we have the state. Right. And we have the outputs.
00:12:35.240 - 00:13:10.520, Speaker A: Okay, so inputs, we already know this is simple. So this is inputs. And then we have the chainstick. It can be a p, two p or just an endpoint. Right. Or like a status. And it's kind of it, right?
00:13:14.020 - 00:13:14.800, Speaker B: Yes.
00:13:17.100 - 00:13:29.990, Speaker A: So on the internal set, we also have the chain state, right? We keep up with the chain locally, probably somewhere. Then we need a signing key for the batch, right?
00:13:33.050 - 00:13:33.450, Speaker B: Yes.
00:13:33.490 - 00:13:39.270, Speaker A: Or do we just output. Or do we just output the 712 messages and call it done?
00:13:41.970 - 00:13:45.826, Speaker B: Yeah, well, we'd still need a key for the messages, right?
00:13:45.858 - 00:13:58.510, Speaker A: Yeah. A cut obstruction. Like, can we have a paymaster for this and not use and just randomly generate a key?
00:14:01.010 - 00:14:02.710, Speaker B: That would be cool for sure.
00:14:04.130 - 00:14:25.572, Speaker A: Yeah, but we need some. Some key. If we randomly generate it, it doesn't matter, I guess. Yeah, a paymaster would be. Would be nice. Yeah, but. Okay, let's probably.
00:14:25.572 - 00:15:26.780, Speaker A: Let's also look at the case where we want like a t key. All right. And then here we have just a batch. All right, so what do we want? Okay, so if we are designing this as an application, like, forget these, right? How would we. How would we do this? How this look like? So we would probably have some idea here, right? Seven point a. Let's take for a second.
00:15:30.120 - 00:15:33.040, Speaker B: Okay. I was emojiifying.
00:15:33.080 - 00:16:01.220, Speaker A: Sorry. Good touch. Okay. Okay. I don't think there's anything out of Dodge network here. So we just want, like an API server, right? So a place that, you know, you can submit 712 signed messages, right?
00:16:01.560 - 00:16:07.274, Speaker B: Yep. Probably just two routes. Some type of admin routes.
00:16:07.322 - 00:16:18.190, Speaker A: Maybe some type of admin routes. Yeah. If we do this as a normal service, we probably would have a separate admin API, right?
00:16:19.290 - 00:16:20.470, Speaker B: Yeah, that's right.
00:16:21.450 - 00:16:42.040, Speaker A: Yeah. Like admin. Or like, you know, an admin console. Like whatever. It doesn't have to be socket, but. But here we have some endpoints. That's like actual URL people to submit to.
00:16:42.040 - 00:16:58.810, Speaker A: Right. And here is private, like console. Console, like input to the API. Let's look along.
00:17:07.910 - 00:17:15.050, Speaker B: At Partha. Andrew is saying, I think the assets need to be escrowed with the te for exclusiveness.
00:17:18.670 - 00:17:19.690, Speaker A: The assets.
00:17:25.459 - 00:17:27.959, Speaker B: Okay, we have those two.
00:17:28.619 - 00:17:53.210, Speaker A: All right. And then we have just. I'm kind of redrawing this, but maybe it would be helpful. So we have another book service internally. Right? Like, imagine this being like, either a separate, like a container or something like that. Or maybe a part of a bigger app, right. We can draw a box here, collect a slightly bigger app.
00:17:53.210 - 00:18:35.456, Speaker A: Okay, so we have the other book and we have the matching. Right? And then, okay, and then this. I think this becomes this way. It becomes kind of interesting, right? Because now we need the key. Right? Where do we store the key? We have the key somewhere here. And it's probably like, you know, goes like this, right? Because this key has needs, like, funds on it. It cannot be like just randomly generated.
00:18:35.456 - 00:18:45.200, Speaker A: If, like, at least if we're designing a regular app, this would be like some kind of thresholds key, I guess, something like that.
00:18:48.260 - 00:19:08.080, Speaker B: I think. Yeah. If this was a regular app, we'd be reading this key in probably through an environment variable. Right. And potentially is threshold. Yeah. No, threshold makes sense because users would likely need to approve to this key.
00:19:08.080 - 00:19:18.970, Speaker B: So if the key is compromised, that would be very bad. Therefore, we need multiple tiers of security behind this key.
00:19:21.310 - 00:19:23.690, Speaker A: Does cowsoft sign their purchase?
00:19:27.790 - 00:19:37.860, Speaker B: I believe in. That's a good question. I actually believe how it works in Cal swap is that the solver is allowed to submit the batch.
00:19:40.960 - 00:19:45.660, Speaker A: Yeah. So it's the solvers, the sign. Yeah. Makes sense. And they just picked the best one, right?
00:19:46.200 - 00:20:10.270, Speaker B: Yes, but solvers. Yeah, exactly. So solvers need to be staked, and then I believe they're allowed to submit a signed transaction solution. That's actually, that's a bit cleaner. But of course, it leads. It leads to the scenario where you need to, like police in case they accidentally send a solution which is incorrect.
00:20:11.010 - 00:20:16.270, Speaker A: Yeah. So this also would work almost exactly like a kousop solver. Right?
00:20:17.570 - 00:20:20.710, Speaker B: I think it would look. It would look quite similar to Kaustapsolver. Yeah.
00:20:21.770 - 00:20:46.340, Speaker A: Right. So we have the private key in just the relevant part. Here we have the orders, of course. Intense and awesome. Intense. And here we will just run, like, a full node. Right.
00:20:46.340 - 00:21:02.220, Speaker A: We wouldn't be bothered to just run the chain nodes.
00:21:04.720 - 00:21:30.670, Speaker B: Yeah. I think there would be some type of validation as well before the intent gets put in the order book service, which, like, I mean, if we wanted to go fast, would be some type of, like, cache with what the user's nonce is and their latest ETH balance. And then maybe also the asset, seeing if they've approved any of the ERC 20s that this dark pool supports.
00:21:41.650 - 00:22:08.400, Speaker A: Okay, so this goes into validation. Okay. Messing up my arrows here. Okay. Intends going to validation then to the order book service. So there's some kind of, like, in memory, like it's a database or whatever. I guess we can add a database here.
00:22:08.400 - 00:22:47.930, Speaker A: Let's get the database. All right, let's look at the key emotification. Right. Okay. And then slammeter assigns. And then the sign transaction goes out. My chain one doesn't fit.
00:23:04.230 - 00:23:13.400, Speaker B: Oh, interesting comments in the chat. Are solvers just decentralized brokers? Only if they use their own inventory.
00:23:14.340 - 00:23:16.440, Speaker A: Are they. Are they decentralized?
00:23:19.780 - 00:23:22.800, Speaker B: Yes. Chat, are they decentralized? Even in that case.
00:23:25.820 - 00:23:43.480, Speaker A: Like, even here, we are not decentralizing the solvers. I mean, the PSN, you probably usually think of them as the solvers. Yeah. This would be a decentralized solver, I guess, and not using their own stuff. Right?
00:23:45.860 - 00:23:46.600, Speaker B: Yes.
00:23:49.220 - 00:24:15.980, Speaker A: Okay. So that's kind of it. Right. That's kind of what we, how we would structure this if we were to do this, you know, ignoring, you know, privacy decentralization. Right. So what's the important bits that we can provide as a. What's the bits that would allow us to make it decentralized and fully private? Right.
00:24:15.980 - 00:24:22.300, Speaker A: First of all, can this key be known outside of the service?
00:24:25.400 - 00:24:30.100, Speaker B: Probably known as in the pub key or the private key?
00:24:30.670 - 00:24:34.450, Speaker A: Yeah. Like, is it, is it important that nobody has access to the private key?
00:24:45.750 - 00:24:47.290, Speaker B: I think likely, yes.
00:24:52.070 - 00:25:03.180, Speaker A: Like if you, if you run, if you go and run this, um, like you just need a key with funds. Right. It actually doesn't matter whose keys key it is.
00:25:04.880 - 00:25:43.380, Speaker B: Um, the, yes. This, I would definitely be interested in hearing from the chat on this because I think we've got some chain abstraction people on this. But I think the, so the main issue is that you need to deposit the intents into a settlement contract. The settlement contract needs to be approved by the user to transfer their funds. That's one route. The other route is the users just transfer their funds ahead of time to a key that this controls, which is probably more dangerous.
00:25:43.960 - 00:26:08.490, Speaker A: Yeah. Okay, so the users, okay, so the worry here is that if the key is known elsewhere, then someone with access to the key could do something that the users don't want because you approve the key. Right. Like you could be matched against something that doesn't make any sense, for example.
00:26:10.950 - 00:26:42.890, Speaker B: Yes. Yeah, I think that's correct. Well, yeah, no, I think it is correct. I think there's no way around it. The only way around it is to unfortunately leak your data. To leak the validity condition around your intent.
00:26:43.990 - 00:26:59.986, Speaker A: Yeah, actually, because we will note. Yeah. So the thing is, because we will batch it. Right. So you will not learn the intent. Like, even if you have access to the key, you will not learn the intent before it's submitted to the batch. Right.
00:26:59.986 - 00:27:08.950, Speaker A: But at that point, you can still try to submit a second batch. Right. That abuses the user in some way. Right.
00:27:11.290 - 00:27:11.858, Speaker B: Yes.
00:27:11.954 - 00:28:08.760, Speaker A: So, because in some cases, this will actually help you because the intents, even though you could screw the user over, you actually don't have the access to the data. So if the builder was also in a t in this case, this actually wouldn't matter because nobody learns the data before it's a part of the chain. I guess you can still argue about unbound. Like you can argue about forking out the block and ankles to happen. But you can also worry about, like, if this is nl two, you can worry about someone trying to go through l one or I don't know if that would be a concern. Okay. Anyway, so we want a key, right? That's only the key, only the t knows.
00:28:08.760 - 00:28:53.080, Speaker A: Right. And then we can, dataserts can be sure that the only way they will be merged and, you know, the only way they'll be a part of the chain is if this particular, if the specific key sign the solution right to the batch. All right, so we probably also want. What else do we want? So there's the chain. Now there's the chain, right. It's the chain state. And there is some kind of data storage, right?
00:28:55.780 - 00:28:56.600, Speaker B: Yep.
00:29:00.990 - 00:29:05.770, Speaker A: So doing anything specific, can it be ephemeral like, I think it can. Right.
00:29:09.470 - 00:30:08.520, Speaker B: So I think it depends on the type of intent. I think if we're, you know, if this service was focused on intents that resolve in the next couple of blocks, then you're probably not that mad if, say, there's a restart and your intent is lost. If you are doing some type of passive intent, which could take days to clear or something like that, then you would definitely want it to persist past a restart. And actually you would want to be notified that your intent is or not even notified. I think it would be good to be able to query if your intent is still in there in a way that doesn't leak the data. So perhaps just a boolean of whether your intent hash is in there.
00:30:15.060 - 00:30:33.450, Speaker A: All right, so like check if still, right. Some kind of like an endpoint where we want to check.
00:30:39.830 - 00:30:52.300, Speaker B: Yeah. Partha in the chat brings up cross chain order matching will require caching. I think let's stick with one chain for now. But that makes it more fun for sure.
00:30:53.640 - 00:30:58.620, Speaker A: So cross chain matching would require a caching. What is that?
00:31:01.440 - 00:31:05.980, Speaker B: I think that's just having multiple chains stay cached up.
00:31:07.520 - 00:31:21.610, Speaker A: Oh, yeah. But that's simple, right? Because what you do is you just. Right. Do more of those chain nodes and, and your service has to, has to handle more than one chain.
00:31:21.690 - 00:31:22.430, Speaker B: Totally.
00:31:22.810 - 00:31:51.160, Speaker A: Because that's it. Like, we're not trying to make this atomic, right? This is not like, going to be atomic cross chains. Yeah. So, yeah, cross chains. Intents will for sure require some additional, some additional care, but I don't think there's anything specific that they need that's not here. All right, so, but for like, passive, passive stuff or passive intense for like, you know, LP's. Right.
00:31:51.160 - 00:32:06.600, Speaker A: We want persistence, I'm sure microsweets and, you know, idv. IDV sensor persistence. Right.
00:32:07.420 - 00:32:11.630, Speaker B: I. Censorship resistance.
00:32:11.970 - 00:32:29.870, Speaker A: Because if you research your server. Server, and then if, you know, if whoever controls the hardware is able to wipe out the state, then they can forcefully empty the order book. Right.
00:32:30.530 - 00:33:54.046, Speaker B: Yeah, I think that brings up an interesting point of like, I'll take some notes down here of like, the ReT model. Right? Like, basically we can have users. Okay, so user submitting intent, LP submitting intent, and then also hardware operator or t operator maybe. I think that's probably like one of the biggest mindset shifts. And building on the TES, you know, obviously with traditional off chain services, you're just sort of entering in a social contract with your users that you want to abuse their data, but the t sort of like absolves a bit your responsibility there. You're sort of saying like, hey, it's on this trusted hardware. You don't have to trust me.
00:33:54.046 - 00:34:11.410, Speaker B: But if they leave in sneaky backdoors, there is still, or not even sneaky backdoors, it's more just things outside of the control box we have created that they can use to alter the outcomes of the app.
00:34:13.710 - 00:34:51.899, Speaker A: Yeah, this here is super relevant because if you expect that there's another coming and you want to match it, right, you can forcefully remove everything and then only put your own and then cut the network connection and make sure that you're the only order in the order. I think you're right. It's a big difference. And also, so this comes in two parts. One, because there's no, there doesn't have to be an expectation that the order, that the operator is not malicious. Right. You can assume they are malicious, and app should still withstand a malicious operator.
00:34:51.899 - 00:35:17.220, Speaker A: But what that gives you is that anyone can run it now because that allows for a malicious operator. And that's the big difference, because now you can decentralize this. That's how you can actually decentralize those services, for sure. Yeah, but it does require some very specific sources, like censorship, resistance, persistent. Persistent storage. Right.
00:35:17.970 - 00:35:30.122, Speaker B: Yeah. It also makes me realize, so one other thing too, is these intents should probably be encrypted to the key on the machine, which. So it's.
00:35:30.146 - 00:35:32.110, Speaker A: So if they're the same key.
00:35:33.290 - 00:35:41.314, Speaker B: Yes, you can. Is it a good idea? Okay.
00:35:41.482 - 00:35:43.030, Speaker A: You could infer. Right?
00:35:43.680 - 00:36:13.780, Speaker B: Yes. And just to clarify for those listening, the attack vector would basically be, you open up a port on this te, but then you open up another proxy server which you tell users about and you run some code there which anytime someone's trading USDC for rooster coin, I could delay it, insert my own before to front run and then reinsert it. So that way encryption would block this.
00:36:16.320 - 00:36:20.224, Speaker A: Yeah. It's like a man in the middle. Pretty much.
00:36:20.272 - 00:36:22.100, Speaker B: Yes, man in the middle for sure.
00:36:23.920 - 00:36:31.980, Speaker A: Yeah. So we want to users to be certain that their intents will only go to the box right into the team.
00:36:33.520 - 00:36:41.880, Speaker B: Is it possible also to give a front end, some type of assurance that they actually talked with the t or is that out of scope right now?
00:36:43.540 - 00:36:47.680, Speaker A: An assurance to the user through the front end? Yeah.
00:36:48.500 - 00:36:51.260, Speaker B: Can we get some type of attestation on the front end?
00:36:51.300 - 00:37:09.920, Speaker A: Yeah, as long as it trusts the front end that works because we can prove it to the front end and then the front end cannot prove it to the user because it's just a bunch of code. But if the user knows what code is running in the front end, for example, because they just deployed it, uh, then they can be convinced that it's correct.
00:37:16.300 - 00:37:25.476, Speaker B: Right. So we need a, I think we need to add a new browser into this. The scope of this as well.
00:37:25.628 - 00:37:44.240, Speaker A: Just kidding. Yeah, I think that's, I think that's, I think that's simple because if you like, you just need someone other than the operator to be able to verify the correctness of the setup. And then whether it's the user directly or if, whether it's a front end, they kind of check it in the same way. Right?
00:37:44.540 - 00:37:45.300, Speaker B: Totally, totally.
00:37:45.340 - 00:37:58.560, Speaker A: So you only need to do this once. I think it would be nice as a kind of framework feature that if you want to put it on your front end, this is the library for it. Right.
00:38:03.130 - 00:38:08.790, Speaker B: Also everyone should download their front ends off ipfs. It's the only safe way.
00:38:09.850 - 00:39:14.890, Speaker A: Please don't put your private keys into the browser and don't sign the IP 712 messages CCR frontend. All right, so how do we convince the users that their intent goes only into this TD app and not anywhere else? The simplest solution would be to use what's called array TL's. It's linked in the forum post. For anyone wondering. It's like a paper from Microsoft and also like a technical solution. How it works is it leverages like the TDS certificate and it puts parts of attestation report like t attestation report into the TL's certificate that you can then check. It's like extra fields that you can parse.
00:39:14.890 - 00:39:50.460, Speaker A: Yes, that's. And it's going to use like a locally generated random key, which is also good. So it's similar to how we could handle the sign key where we just generate it inside the t and make sure that the code never lets it out of the t. That's how we can be convinced that, that the key is only accessible inside the t. Right. Nobody passes it in like here, like in decentralized server. Rather it's generated inside.
00:39:50.460 - 00:40:03.640, Speaker A: So let's redraw this as a te swap and then it should become obvious what should be the features that we want to provide the users.
00:40:07.060 - 00:40:13.530, Speaker B: Also, one note is that we didn't handle making this application distributed yet, but potentially.
00:40:15.470 - 00:40:21.334, Speaker A: Yeah, but so it's at least decentralized. Like this is. This is neither decentralizable nor distributed. Right?
00:40:21.502 - 00:40:22.210, Speaker B: Right.
00:40:23.230 - 00:40:46.480, Speaker A: This here you can decentralize. It doesn't require anything central. Right. So it's like decentralized by nature. Anyone can run it. And as long as you check data station, as long as you know, as long as you're convinced that your intent is going to be safe, you can send it in, which is not the case in the centralized server. It's not like you would be forwarding to anyone.
00:40:47.540 - 00:41:05.880, Speaker B: Right. But I think if we wanted to make it truly distributed, you would need to sync order book services across different instances. But I think that opens up much more to design.
00:41:06.610 - 00:41:55.100, Speaker A: It's a kind of warmth, right? Yes. So how we can solve this, almost trivially I think, is you could put a box here that forwards to just multiplexes. So if the user wants to send their intent into multiple order books, then they'll just be multiplexed. And that's like 50% of the way. It's a different story with the sources, because in a decentralized system you also want the solution, the best solution to win. Right, rather than in whatever notion of best would be for that. For a specific user, the best price they can get to maximize some sort of function with the solution.
00:41:55.100 - 00:42:04.050, Speaker A: And then you would also want to, if the order book is not fully in sync, you then want to sync on what's the best solution and what should actually end on chain.
00:42:14.230 - 00:42:33.660, Speaker B: We've got some comments. I don't want my orders getting involved with multiplexing users. If you store the order book in confidential datastore and let the intent live for a few swab blocks, then settle the order book intermittently via batch auction, it'll be distributed. No.
00:42:35.920 - 00:42:39.460, Speaker A: It will be distributed as long as the confidential story is distributed.
00:42:41.720 - 00:43:19.726, Speaker B: Yeah. I mean, I think this really gets into what is the trade off. Which trade off on the distributed systems landscape. Do you want your order book to have like, I think multiplexing would be, I mean, that's just best effort. That's the l one mem pool right now. Just fire and forget. You could go further by doing some type of eventual consistency or like a byzantine broadcast such that the.
00:43:19.726 - 00:43:44.890, Speaker B: Well, actually, I don't know if that works. What you could basically do is require a certificate back from all of the te nodes that you propagated to. Or you can just like straight up have a consensus protocol that ensures consistency. But again, that comes at the cost of speed, usually.
00:43:47.240 - 00:44:09.780, Speaker A: Yeah. So, okay, we can solve this. We can solve this as storage layer, right? If you get some storage and it's distributed and has whatever properties you want, for example, censorship, resistance, then by us simply providing you the storage service, you don't have to worry about anything else, right.
00:44:13.460 - 00:44:23.920, Speaker B: By simply providing the storage service, you wouldn't have to worry about anything else. Yes, yes, I think so.
00:44:24.820 - 00:44:36.068, Speaker A: Like say for like latency, right? Because you can. Your orders will possibly be delayed. Okay, whatever. I think that works.
00:44:36.164 - 00:44:45.900, Speaker B: Big can of worms, but so, okay, so for the scope of this, we're doing a singleton instance, no communication across nodes.
00:44:46.960 - 00:45:02.220, Speaker A: I think we don't have to stick to very simple use case. I think we can try. Let's see. What if we had a magic wand? If we had a magic wand, what would we possibly want to have from this t environment?
00:45:03.520 - 00:46:00.810, Speaker B: If I had a magic wanda, I would have a docker like YAML setup where I could specify a certain volume that is synced with another node and encrypted as well. But that would be pretty hard because the container would need to have access to new peers that join a peer to peer network. And probably some type of DHT would need to be maintained. But that's super magic lock. I think storage service, which handles peer connection and discovery, would be like the much more realistic magic wand for now.
00:46:03.510 - 00:46:11.210, Speaker A: I kind of like this, though. I'll show you how I think we could make this happen.
00:46:11.790 - 00:46:12.650, Speaker B: Okay.
00:46:13.110 - 00:46:48.106, Speaker A: All right. Okay. Let's build this up in a t. Your app is ideally, the UX is such that you just provided a container, right? Like there's, of course, like alternative solutions, like waSm, stuff like that. Okay. Actually, before we begin, is this open source? Which part of it is open source? There's a bunch of code here, right? There's a bunch of code here. So DM API can be open source, Mars can be open source.
00:46:48.106 - 00:47:07.658, Speaker A: Right? So let's mark them as what's a good open source color green, blue. I'm using green for like t. Oh, right, okay. So the order book is simple, validation is simple. They can be open source, I think, basically.
00:47:07.714 - 00:47:18.070, Speaker B: But everything. But the engine service. I think the engine service could be also realistically be open sourced. But that would be the most understandable thing to keep closed source.
00:47:23.330 - 00:48:03.612, Speaker A: Yeah, I kind of know. I think it, okay, so the only concern with open sourcing this is that someone can abuse like some, you know, some weird, like, it's difficult to have a perfect allocation rule, right. Or like a perfect solution. So people can try to, if they know exactly the code you can try to craft, like specifically to try to exploit flaws in the logic, right. Some kind of, wherever there's like heuristics, right. You can expect some kind of holes signal, right?
00:48:03.636 - 00:48:07.280, Speaker B: Which means the validation service also is potentially.
00:48:09.190 - 00:48:28.490, Speaker A: Now the validation, I would actually keep, keep open source because that's, that's the part where it's better to have everyone look at it, right? Like avoid security by obscurity, rather just have, have everyone review it. Right.
00:48:30.270 - 00:48:39.340, Speaker B: Well, so then what, why would the validations, why to me it seems the same validation service and the engine service.
00:48:40.120 - 00:49:24.784, Speaker A: Oh, yeah, because you can, you know how to validate stuff, right? You know exactly how to go and validate a order, whereas you don't actually know exactly how to, how to provide the solution. Right? Like there's no heuristics in the validation. It's very simple, right? Balance check, right. Nonce check, like whatever, check, done, right. Whereas the solution engine will use a lot of heuristics where you can try to just abuse the heuristic so, you know, match against the trade. There's another trait that's better, that would be better for the user, but because of the heuristic, you win.
00:49:24.872 - 00:50:14.420, Speaker B: Right, okay, but let's say, let's say I'm trying to. Okay, so one of the big attacks is I send an intent in and I then pay the blockbuilder a ton of money so that I remove my approved amount out and try to get in before this matched solution. Ideally, the settlement contract should iterate through all of them. And I, you know, ignore. But, um, but I would think we would add some validation in. That's like, okay, check if account has ever made a transaction. Or you, you know, like things like that, which would like, try to make cyber resistance just a tiny bit harder, which I don't think, which I could find reasonable to not open source.
00:50:16.120 - 00:50:18.260, Speaker A: Yeah, no. What does Chad say about it?
00:50:19.680 - 00:50:23.020, Speaker B: Chat. How do we stop graphing yeah.
00:50:23.400 - 00:50:44.680, Speaker A: Okay. Having the byte dish. Okay. All right. So we have some stuff that we'll be keeping post source, right. So for whatever reason. And that will make this very difficult.
00:50:44.680 - 00:51:04.080, Speaker A: Right. Because if this was all open source, how this would look like is you could literally put it all into a t and call it day, right. Like, you're done. Like, with everything open source, you simply attest. So check what's running. Check the image. Check all the hashes of the binaries.
00:51:04.080 - 00:51:25.418, Speaker A: Right. And if all the code checks out, and, like, the initial state of the VM that you're running matches the expected one, this is the process of attestation. Let's say. Then you're done. Because you know all the codes. We can check that. All the hashes of the binaries check out and the state checks out.
00:51:25.418 - 00:51:45.520, Speaker A: So you know that submitting your intents to the box will keep it safe. Right. But if there is a closed source piece here, then you cannot do that. Right. Like, you don't want to reveal the source code, so you cannot prove to anyone that you don't do something funny here. That's the big difference.
00:51:47.020 - 00:51:52.020, Speaker B: Yeah, because, I mean, you could leak that over the network at the validation.
00:51:52.180 - 00:51:59.920, Speaker A: For example, just do whoop, right. And your data goes somewhere.
00:52:03.380 - 00:52:08.200, Speaker B: It'S super private. Except for this one part where we swear we're not doing anything bad.
00:52:08.860 - 00:52:29.382, Speaker A: Exactly. So that's the tricky part. So let's, you know, let's try to rebuild this. Let's try to rebuild this in a team. So I want to have this for reference. All right. So we want a couple of things, right.
00:52:29.382 - 00:53:01.512, Speaker A: So we thought about for a bit, what we want is we need like, a private key inside the t, but only the t knows. Right. That's important. So that the signed patch. So when you submit a signed patch, only, like, only solutions write according to whatever rules inside the t are ever submitted with your transaction. Right. Nobody can switch the match the solution.
00:53:01.512 - 00:53:35.080, Speaker A: Right. Your intent will only be matched according to the rules of the te. That only works if the private key that you approve lives inside the te. That's the first thing that we need. The second thing that we need is a way for users to encrypt their data, their intents, to a key that only the t knows. So kind of similar to this one. But there is a solution that you can readily use, namely the array TL's.
00:53:35.080 - 00:54:06.530, Speaker A: So we don't have to. This will be very custom. We'll have to do this ourselves. This is almost provided to us. Not quite, but almost and then we want some data storage and very important, it has to be persistent and it has to be censored persistent, which may or may not work. Right. This may actually be impossible in like the simple case.
00:54:06.530 - 00:54:17.170, Speaker A: Yeah, we'll for sure need like some kind of da layer maybe, maybe like a chain.
00:54:19.150 - 00:54:24.400, Speaker B: Yeah. I would say we should drop this requirement for this.
00:54:25.540 - 00:55:04.250, Speaker A: Yeah, we can try. All right. And one of the bits, solution bits is that we want a YAML to specify what kind of storage requirements. We want some kind of configuration where we say that we want this to be synced wherever or like, you know, we want this to be on, I live on ipfs, right. At all times, something like that. And we want some libraries for people to, libraries. Libraries for verification.
00:55:04.250 - 00:55:46.480, Speaker A: Right. So we want like node j's, of course. Am I forgetting about an important language here? Probably not, that's it. So verification of the attestation should be possible in like normal code, right. By the client. Thank you. And also ideally without like querying any other server like you know, that's gonna be difficult.
00:55:46.480 - 00:56:00.240, Speaker A: All right, how do we provide this, like let's say that we are building a framework, right, for tes, which we may or may not be doing. How would we, how would we build an app like this?
00:56:07.670 - 00:56:09.850, Speaker B: Sorry. Yeah, my emojis.
00:56:11.830 - 00:56:21.530, Speaker A: Got to preserve the emojis. Yeah. You know what? Can I, can I group this? No. Oh, I shouldn't, I can wait. No, no, this works.
00:56:25.390 - 00:56:37.422, Speaker B: Some people came for a T app session. This is actually a excaladra tutorial. We're sponsored, no, I'm just kidding. We're not sponsored by Scala draw, although.
00:56:37.486 - 00:56:38.890, Speaker A: We probably should be.
00:56:40.190 - 00:56:44.290, Speaker B: If anyone knows scaly draw people please let them know.
00:56:45.990 - 00:57:05.614, Speaker A: All right. Okay cool. So we want to have here some kind of API server. It's open source so we can just put it here and create a day. This totally works. Okay. Have an API server.
00:57:05.614 - 00:57:58.180, Speaker A: And this is a, simplest would be to just call it API server. And if you're curious about what ratls stands for again, go to the forum. There's links, there's in particular a link to the white paper on, I guess just a paper. So it's a way for the users. Okay, let's put a front in here. How about. But we have a user interacting with some front end and the front end goes and interacts with our Atlas API server.
00:57:58.180 - 00:59:15.688, Speaker A: This guy here has to be able to verify data station. So how this works is, is like this. So the user gives it like the expected measurement. Think of this as like VMM trash bunch of stuff like that. So this the user gets from somewhere, right? Like let's say from GitHub. And then here we pipe in the, right here certificate. All right, so the certificate, the certificate that the front end gets goes into this no unstation verification box and it's returned a.
00:59:15.688 - 00:59:45.676, Speaker A: Ok, there's probably some external service here. If this SGX decap, that's it for something like cloud stations you have to go to the cloud provider, ask them this. Okay, right. So this for cloud proofs, we call.
00:59:45.708 - 00:59:51.600, Speaker B: This crowd proofs which is for if your key is running in the cloud.
00:59:53.660 - 00:59:58.920, Speaker A: So this specific TDX in the cards.
01:00:04.180 - 01:00:09.420, Speaker B: And would you need to do that on every single expected measurement?
01:00:13.360 - 01:00:53.906, Speaker A: So if you're interacting with a specific front end, there's probably just one or like maybe a couple expected measurements. Yeah, they come from somewhere. So maybe it's a part of your front end, maybe it's a part of what the user knows and expects. All right. Not actually sure how to best structure this. All right, so here we had, so here we get 712 intents and we also get, you know, the certificate. Right.
01:00:53.906 - 01:01:04.440, Speaker A: And you have to very, you have to attest. Okay, so I guess what was your question about whether we have to attest whether we have to check the certificate every time we do something with the API?
01:01:04.940 - 01:01:05.720, Speaker B: Yes.
01:01:07.140 - 01:01:24.588, Speaker A: So that's really kind of. No, because this is, you open up a TL's session. So if you think about like an HTTPs handshake, right. When you request the server, the server like in response. Right. Response, you send like a challenge. Right.
01:01:24.588 - 01:01:57.080, Speaker A: Server signs the challenge with their private key. Right. That's exactly how it works. So by the end you establish a TL's session. So yeah, you don't actually have to do this every time you do this just once to establish the connection. And then every time you want to establish a new connection, I guess if your session times out or the boxes started, you want to check it again. Yeah.
01:01:57.080 - 01:02:36.856, Speaker A: And there's ways to get around this. Actually you could possibly do this on once, but that would require us to do something custom here and it's probably better to just go with rtls. All right, cool. So there's no admin API but we need some kind of key service. Right. Still. And the key service must be open source and this generates the key.
01:02:36.856 - 01:03:42.140, Speaker A: Right. And yeah, so what has to be open source is that, you know, all of the, all of the pieces that touch the key have to be either open source and then you verify that they don't click the key right. Or if they're closed source, like ideally you don't pass the key anywhere, you don't pass any confidential data into closed source pieces, but if you do, then you have to somehow make sure that the data doesn't leak out. Right. Let's talk in a second about how can you do that. Right, then we have the order book, I'm sorry, I guess we have the validation first. And the validation is the first tricky bit, right, because it's actually cross source, we assume it's cost source doesn't have to be bad for this exercise.
01:03:42.140 - 01:04:33.914, Speaker A: Let's assume it is. So how do we deal with this? Right, so one of the solutions that we can propose here is just to have a firewall around the validation to put it in jail. So this is some kind of either a subcontainer or like a sandbox binary. So this could be something like wasm that doesn't allow any access to, let's say TCP, right, or like files or any kind of devices on the host. So that's, you can prove that all that goes in for every, like you can verify what goes out of the box. That's kind of the important bit. So you specify what can leave the sandbox.
01:04:33.914 - 01:05:38.680, Speaker A: If it wasn't, then that's simple because you just define the function API and you just don't allow access to anything. In the case of validation, what do we need for validation? And then let's think about it. So we need this change state, I guess that's the problematic part in the chain state. And you need, right, and you don't need all the chain states. And here it gets tricky. So let's assume we have a chain node and it's open source, so we can actually make, I think we can actually make the sandbox request conflict because you can pipe in any data you want. The only problem is that the outputs can leak.
01:05:38.680 - 01:06:25.110, Speaker A: So anytime the arrow goes this way, you kind of need an alarm bell going off. Does this leak data? Right, does this, so the biddition would require, let's say I want, would want a balance of a particular account or like a non sort, which we suggested, which is have they ever interacted with anything like that? Have they ever swapped on the swap? Right. How many entities do they have? And I think as long as the chain node is open source, this doesn't ever leak any data as long as user restricts or into specific calls. You can verify through the API on the chain node that this will not actually gain data apart from maybe for side channels, but let's not worry about those quite yet.
01:06:26.530 - 01:06:27.282, Speaker B: I think I agree.
01:06:27.346 - 01:07:04.392, Speaker A: Right. That's Andrew agreed. All right. Anyway, and that's kind of the case with all the private pieces where we have to put some kind of sandbox around it somehow. We have to verify that the outputs don't leak any data anywhere. But we only allow specific outputs that you cannot, for example, establish a TCP connection with someone or write a file on disk or access a device on the host. That's the job of the sandbox.
01:07:04.392 - 01:07:33.922, Speaker A: And there's a couple of ways you can do it. One being, for example, WaSM, another being solidity is a good one. Right. Mevm, that's the original use case. And. Yeah, but also wrapping binaries through, for example, sid or bubble wrap, those sort like the binary containerization solutions, or by using a container sandbox. Right.
01:07:33.922 - 01:08:06.250, Speaker A: So for example, it's like what you would use in the cloud to separate guests from each other. And then you can define exactly what the container is allowed to do. You control the network interfaces that are passed in. You control all the devices passed in, et cetera. You can simply disallow either of those. All right, that's all to say. That's a lot of words to say that this should be fine.
01:08:06.250 - 01:08:42.480, Speaker A: And the other output is, you know, valid intent. Right. So there's two outputs here. Yeah. One is like request to try not, which is weird to think of it as an output, but if you think about it, it kind of is an output. There's like data coming out. The data specifies which address to go fetch, the balance for, which contract call to use to validate the intent.
01:08:42.480 - 01:09:26.450, Speaker A: All right. And then this goes into the order book service. And then this also will be interesting because this order book needs a start. And now this is going to be, this is going to get interesting. How do we provide, how do we provide the storage to the other sense? Any ideas? Looking to source ideas? No. Maybe.
01:09:35.710 - 01:09:43.210, Speaker B: Could you explain why? Or could you explain the question again and why? It's not obvious. Just allocate memory, bro.
01:09:45.580 - 01:10:28.974, Speaker A: All right, let's allocate some memory. So let's set the boundary of the t, right? This is. So this box is the boundary and where does the storage leave? Right. So this is a VM, basically. And the second VM. And we already discussed about the need for the storage to be persistent. Right? So we cannot actually store it in the VM itself.
01:10:28.974 - 01:10:51.526, Speaker A: We have to store it on either some kind of persistent storage outside of the vm. So let's write the options. So, you know, just disk. Right. There's disk this. There's memory, right. And there's.
01:10:51.526 - 01:11:34.690, Speaker A: There could also be some other layers here, right. There could be some layers here, like orang, for example, to mask the access. Let's not worry about that. Let's see that we allocate some kind of disk space, right? I. And we allow the order book service to, like, the database simply lives on the persistent disk outside of the VM, basically on the host. And my question is, would this work for this app? Is this enough? And my tuition is not ready, because it's very simple to wipe the data. Right?
01:11:35.870 - 01:11:46.770, Speaker B: Right. You're saying it's easier to wipe memory, though, than disk, is that correct?
01:11:47.910 - 01:12:13.090, Speaker A: I think they're both kind of trivial to wipe because as the host. As the host. So keep in mind this host here is untrusted, right? Right. This box outside is untrusted. So you have literally access to the device, to the block device, right. And you can simply just zero, you know, exactly how much state there is and where it is. So you can simply assign zeros to all of it.
01:12:13.090 - 01:12:38.380, Speaker A: Right. So a simple solution here doesn't work. Okay, so how would we. How could we make. So there's a disk, right? There's disk here, but we need some integrity guarantee, right? So that we don't just get erased. Because this. You can erase this disk even without the resource of the VM, right.
01:12:38.380 - 01:13:19.062, Speaker A: This is the important bit. So in some kind of data integrity, right? And our order book service, the storage that provide to the order book service, would write both the disk and to some kind of data integrity layer. Let's say, you know, it's a chain. We don't care if it's a chain or not. It's. The important bit is that when we, when we write something to the disk, we, let's say write the, you know, we keep all the. All the data in a microscope, right? And we post the hash, the root hash to a chain.
01:13:19.062 - 01:13:51.330, Speaker A: And then whenever we want to read from disk, we can check, right, against the chain. This would be better, because then as the T app, imagine that you're disorder book service, you can notice that your disk has just been wiped, right? Because it doesn't match the root cause, doesn't match what's on disk anymore, right?
01:13:54.470 - 01:14:31.100, Speaker B: Yeah, I think that's super powerful. Could we just write down that point? Because I think this showcases why blockchains complement the security of Tesla.
01:14:37.030 - 01:14:50.530, Speaker A: And there's not really many things that can do this. If you don't want to use a chain, there's only really so many things that you can use, and they all will involve some kind of consensus. So it might as well have been a chain.
01:14:51.190 - 01:14:57.370, Speaker B: Exactly. It's security by committee over the data storage.
01:14:58.420 - 01:15:20.532, Speaker A: Yeah. And then you can also verify, right. That the commit does what they're supposed to do. Another way would be, of course, to use something like, you know, just don't store data on disk, store everything in some kind of DHT. Right. You've already mentioned. Right.
01:15:20.532 - 01:15:44.950, Speaker A: So there's, there's some. Yeah, there's some. Some solutions to storage. I. And the problem with this one, the problem with using just chain for data, for data integrity, is that it doesn't by itself necessarily shield you from research. When your disk gets wiped and then you get a restart, you lose all the memory. You don't actually know necessarily where to look for this integrity.
01:15:44.950 - 01:16:41.520, Speaker A: So it has to be tied to a specific app, not even just in a running instance, but would want to have this data integrity or this DHT. Be also aware of the specific, I don't know, set of instances of the app or in general the app, and want to tie this data integrity, this checkpoint to the app so that when the app starts, it doesn't assume it started from scratch. You can actually verify, have I just been restarted? And if I have, I need to go pull my data from somewhere. So super important. All right, so that's for the storage. Simple case is you just mount the disk and then you encrypt the disk with some key. Right.
01:16:41.520 - 01:17:12.870, Speaker A: That's the simple solution, but it doesn't shield you from the host. You can use some kind of data integrity outside the untrusted host. So let's say on the chain some kind of censorship resistance layer that you can access, or you can at least know that you cannot access, in which case you should refuse to start. If your untrusted host blocks this arrow here, it doesn't allow you to access data integrity. You should simply refuse to start the app. Right. That's also important.
01:17:12.870 - 01:18:13.930, Speaker A: And if you want to distribute the data, you can always use some kind of DHT, but it doesn't necessarily help you with integrity by itself. All right, let's just call this encrypted data. It's very important that the t controls the encryption here. And here's some checkpoints. This is against things that are called triple attacks, and this is data distribution. So those are the, like we can, we can already provide you free things as kind of a team, like a framework, a Te framework. Another thing is this sandbox like a Te framework will need this kind of sandbox where if you want to run some private code, you need a way to sandbox it properly.
01:18:13.930 - 01:19:11.210, Speaker A: And there's this very standard, I think, requirement that you need a private key. So that's already free things that we should be providing. And I guess they're ATL's, what's left here, the engine service. And the service will be very similar to the validation. So you have this matching engine here. And again, now we have to think about the sandbox, right? What does it get? What does it not get? So it gets the change state. And again, because the change state, the node is open source, we can simply request the state, which isn't always the case, by the way.
01:19:11.210 - 01:19:47.910, Speaker A: This is not always the case that you can request something from outside. For example, in the case of SGX, this actually is very tricky. And this works very nicely in TDX, but in SGX, this would require the chain not also be in SGX. And actually even that's not enough. This is not straightforward, but if you run to travel, you can always just flip the arrow here and only pipe the chain state in. Right. And just maintain the state inside the sandbox.
01:19:47.910 - 01:20:21.240, Speaker A: It just increases the requirements on memory. All right. And can get the orders here. And, and then lastly, so this outputs matched. Intense. Okay. And because this is called source, we can't, we cannot actually verify that this, that this match is valid.
01:20:21.240 - 01:20:35.580, Speaker A: Right. Also important to note, so we can't actually just push this. We have to have. Right.
01:20:39.480 - 01:20:43.900, Speaker B: And, okay, what does the batch validation do?
01:20:46.280 - 01:20:57.140, Speaker A: What does the batch validation do? It will look at the matched intents and check that it's indeed matched.
01:21:00.090 - 01:21:02.470, Speaker B: Okay, so it's just like a sanity check.
01:21:04.890 - 01:21:12.630, Speaker A: So this is where it becomes tricky. If you don't know how you've been mashed, how can you be sure that you've been matched correctly?
01:21:17.610 - 01:21:41.760, Speaker B: If you don't know how you've been matched, how can you be sure you've been matched correctly? Well, I think all you care about is that your invariant is satisfied. Oh, sorry, wait, did I say invariant? I forgot the cool kids are using the word intent.
01:21:42.980 - 01:21:45.428, Speaker A: No, this is the invariant intent.
01:21:45.524 - 01:21:46.160, Speaker B: No.
01:21:49.180 - 01:22:16.530, Speaker A: Invariant check. I think that's right. And, but can we, can we do more? Can we do better? Because this is not like, because this is really what the guarantee to the user will be, right? The guarantee to the user will be exactly how? Well, you can check that they were matched. Right? Can you check that there's no better, can you check that there's no better candidate? For a match in the open source code.
01:22:23.470 - 01:22:28.730, Speaker B: I don't think it's possible in a privacy preserving way.
01:22:31.070 - 01:22:35.570, Speaker A: But we can access dot de book. Right.
01:22:38.390 - 01:22:45.620, Speaker B: But then we would need to get all valid bids and basically just recompute the optimal bid, which would just be recreating the matching engine. Right.
01:22:48.040 - 01:23:12.080, Speaker A: Sometimes it's easier to verify than to solve. I'm not sure if this is one of those cases like you can verify quickly, of course, that it does indeed that the solution does work. Can you verify if it can be better? Probably not. You're probably right. But we can at least show that it does at least as good as XDev. Right? Okay.
01:23:17.300 - 01:23:39.762, Speaker B: Yes, I will say, yeah. So the one thing. Yeah. So I mean, we get into the cal swap thing, though, where the problem there where you can only verify top of block, you know.
01:23:39.946 - 01:23:42.930, Speaker A: Yeah. And this is here is the case as well.
01:23:43.090 - 01:23:46.350, Speaker B: Yeah. Okay, that's fine. That's fine.
01:23:47.010 - 01:24:05.580, Speaker A: Yeah, I think that is fine. Like if you had the direct line of communication with the builder, you could actually pipe in partial blocks. Right. And also make sure that the same is true outside of the block. Right. So it's not, I think, a limitation of the app. It's a limitation of how closely are you integrated with the builder.
01:24:05.580 - 01:24:47.298, Speaker A: All right. So we have the patch validation, and I think it should be check me suffix at least. At least it has to check the environs. Right. At least has to check that the, that the solution does satisfy the intent. Because if it doesn't, then you can simply send those solutions to the builder, have them revert, and then, you know, the intent. Right.
01:24:47.298 - 01:25:30.460, Speaker A: So we want to, and because of this, we want the key to go here just like this. All right. I think that's it. All right. So, you know, what does, what does the user get? Like, if you build this super complex app, right? What does the user get? Concretely.
01:25:33.160 - 01:26:06.100, Speaker B: The user get, the user has a service they can interact with to facilitate the private swapping of assets in a manner that is verifiable from both the front end code introspection and runtime, maybe.
01:26:29.520 - 01:26:55.796, Speaker A: All right. Yeah, I think that's right. Because so, and again, like the solar, the quality of the solution is only as good as we can verify in the open source part. Right. This is kind of important. Like, we cannot say that they get the best possible batch, they get the best possible solution, but we can say that it will, you know, have an appreciated privacy. Right.
01:26:55.796 - 01:27:18.880, Speaker A: That they will be matched. Actually, can, we don't, we can't, we can't say that they will be matched. Right. Because matching engine could also just refuse to match anything. But we can say that they will be either matched or not matched. And the intent was simply going by it, right? Yes. They will never be mast incorrectly.
01:27:18.880 - 01:28:36.150, Speaker A: All right. I think that's kind of it. And there's one arrow missing here, which is the pub key to. So when we generate the key that we need to have like this has to go through the it in a server. All right. All right. So the public has to go through the TL's service because that's where the TL's session is and the user has already validated that the session is valid.
01:28:36.150 - 01:29:10.328, Speaker A: Right. They check data stations. So if, you know, if the API will only allow this correct pub key to be sent to them, then it's enough for them to request the key from the array TL's. They don't have to actually check any attestation. Again, we could provide a separate attestation report with this public key embedded, but we don't actually have to. We can simply reuse the array TL's API. That's why it's nice.
01:29:10.328 - 01:29:41.510, Speaker A: We don't have to do anything extra. We just generate the key and return it from the API and we're done. It's very nice. All right, I think that's it. That's the service. If you want to put in a t, that's it. I think you could now worry about who provides this code for validation, matching and how exactly to solve this.
01:29:41.510 - 01:30:40.492, Speaker A: But at least we know, we know what we want. So just to reiterate, what we want to provide the service like this. So if you're building a service, it would be really nice if you provided the following, all right, a service to generate keys, right. And you know this will be very similar to the MVM, right, because it solves the same problem, of course. So easy to integrate, easy to integrate the server. Maybe the server is just a thin layer. Oh no, don't remove everything.
01:30:40.676 - 01:30:42.360, Speaker B: No, I'm just copying it. Sorry.
01:30:42.660 - 01:32:07.930, Speaker A: Okay, so the service server could actually be like a layer before the actual app service can be HTTP. All right, so this area TL's server will simply proxy. So I can just call it a sparse and, yeah, that will proxy the intents. Yeah. So that every, like every request that goes through this proxy will be forwarded to the app API server. Unless it's a request of, you know, of a randomly generated key that needs to go through data station that you can't actually, I guess it could do it for the app server to see that it works something like this. Because you like, we have thought about a couple of apps like this, and almost, almost always they need some kind of key that has to be approved.
01:32:07.930 - 01:33:10.656, Speaker A: So next up, we have like a storage solution. Right. Process and storage integrity preserving, optionally with sensor resistance. Right. Like distribute that because distributes department. And both actually will add, will add a lot of latency. Integrity also adds a lot of latency.
01:33:10.656 - 01:34:09.702, Speaker A: But on the other hand, without the integrity of the data storage, it's kind of useless. Like you can't really rely on the data as long as it goes to disk. If it goes to memory, it's different because if it goes to the memory, it's not persistent, but it actually is integrity preserving, which is nice. So for the member, you don't actually have to provide anything specific. There's like asterisks with page tables, but it's not, it's not that bad. Like with the disk, it's really just doesn't work. All right, and this unboxing, right? Yeah, yeah.
01:34:09.702 - 01:34:48.204, Speaker A: Because some, some code, you don't want to be public for whatever reason. And even here, you kind of want some of it to remain private, or at least like parts of it to remain private. All right, so this is what we'll get. Right. So if we are going to provide some kind of framework for building the apps, I think that all of those should be part of it. Okay, let me post for questions. This was a long streak, so I'll pause for comments and questions.
01:34:48.204 - 01:34:50.240, Speaker A: Yeah, dimars, what do you think about it?
01:34:51.100 - 01:34:59.206, Speaker B: There's a bunch of questions from comments from Andrew in the, in the YouTube channel. I don't know if Andrew, if you wanted to comment on these.
01:34:59.238 - 01:35:15.450, Speaker A: I mean, they just streamed in overtime. Yeah, I agree with everything, how it ended up. All right, let's go.
01:35:15.990 - 01:35:19.170, Speaker B: I think here, I'll post these.
01:35:26.800 - 01:36:00.574, Speaker A: I think this chain node will be. Will either be using an oram or of all the l one states streamlined in, or have to store the whole l one state in Ram or an academic queries requiring a subset of state enum. Yeah, absolutely. I absolutely agree. And I think that the simple thing that we can do is provide an orm layer here, or rather here. This will be like integrity preserving by itself and have a bunch of other properties. And the same for the chain.
01:36:00.574 - 01:36:38.088, Speaker A: The chain node also needs disk access, and same applies in persistent storage. That has some integrity built in. Yeah. To connect the local VM disk with the enclaves view. Yeah, exactly. I think the solution where you have, you put it on disk, but you have separate integrity checkpoint somewhere. Okay, next one is for proprietary code.
01:36:38.088 - 01:37:23.850, Speaker A: The matching engine is private, but at least this one is easy to verify that it satisfies the invariance. And this is very important because I'm kind of trying to stress this. The only guarantee that we give the user is what they can actually verify in the code. So the only guarantee that we give to the user, as for the quality of the solutions, is in this batch validation rather in this matching engine. So here it's actually kind of simple to do, but that's not always the case. Right? Sometimes the case will be that it's not easy to verify what this cross source piece outputs. In each case it would be much more difficult to do it correctly.
01:37:23.850 - 01:37:51.130, Speaker A: Is it right that the validation, I don't understand why the validation, what's meant by that still being is the validations proprietary as well? The violation can be proprietary because it's actually not. The validation being closed source doesn't give the user any worse guarantees. Right. It's only there to protect the operator.
01:37:53.430 - 01:37:58.130, Speaker B: Yeah, exactly. You could imagine the validation service being like a cat and mouse game.
01:37:59.830 - 01:38:18.290, Speaker A: Yeah, and it doesn't matter to the user because wouldn't I want some kind of proof that, I don't know, my transaction succeeds? Yeah, I'm not sure what to expect there.
01:38:18.710 - 01:39:01.400, Speaker B: Yeah, there's probably a bunch here because you could, the operator could put like code in there to filter out certain addresses, which wouldn't be great. I think the idea was basically like you could imagine the service wanting to block random constraints like, oh, accounts that have never transacted before should probably are probably, DOS is one example. And a whole host of things like this you could use to try and detect a person. But I agree, it also does open up room for censoring the user.
01:39:05.300 - 01:39:24.460, Speaker A: Absolutely. And ideally it is open source. You can also have both. You can also have an open source part where it checks the balance and nonce, and then a closed source part that does post checks but cannot do anything else but to approve or disallow.
01:39:25.200 - 01:39:45.740, Speaker B: For some reason. This reminds me of Gans general. Is it a adversarial neural networks where it's like we have a private source code and then an open source, and the private source need to convince the open source part that it's not doing something wrong, even though it does still have some secrets.
01:39:46.450 - 01:40:29.810, Speaker A: Yeah, absolutely. And I wanted to touch on one thing that Andrews mentioned, which is that the smashing engine could actually provide in some cases proof of optimality somehow, right? You can actually compute proofs like zero knowledge proofs or full knowledge proofs, I guess, to convince the open source, exactly as you're saying. To convince the open source. That is an optimal batch too. Not just a batch, but an optimal solution, at least according to some logic. You can have proofs coming out of the private code. Yeah.
01:40:29.810 - 01:41:12.050, Speaker A: All right, sweet. Any other comments? Exclusiveness like this came up when you mentioned the possibility of having the order book or something be distributed. And I wonder if it's just clear from this whether this probably matters a lot. It doesn't matter, but it seems like if the other people bidding are also multiplexing to other instances of a similar application, won't it be more likely that they'll somehow conflict with each other? Which. That is really nice if you can guarantee that won't happen.
01:41:14.990 - 01:41:35.796, Speaker B: I think. Yeah, that's almost guaranteed to happen. If there's singleton instances of these that aren't communicating, I mean, the intent will fail. So it's not really that bad. It's probably bad for the operator because there'll just be some gas usage. But I. Two of the same intent can't be satisfied.
01:41:35.796 - 01:41:39.760, Speaker B: So that's like, not awful for the user.
01:41:44.420 - 01:42:20.770, Speaker A: So I guess just wasted compute. If this ends up being done a lot redundantly, and then maybe that's all that's at stake. Yeah. And possibly also some reverts, you could lose some money. And if you have been a part of a bus that didn't land and you have not been a part of the other branches, your intent will actually be revealed. So you want some kind of guarantee from the builder that at least they will not include the failed solutions. All right, cool.
01:42:20.770 - 01:43:04.020, Speaker A: Now the question is, how do we actually provide this? We have. Okay. Yeah. Ferran and Mo, do you have any questions? Maybe not from my side. Nothing from my side. All right. In that case, the next part, I think is how do we actually provide this? How does this technically look like? So this is a vm and, you know, so the NSH idea, and this is what DiMars already said, you know, some kind of docker, like, docker compose set of containers.
01:43:04.020 - 01:43:57.770, Speaker A: Right? Because we are mixing here, like, private code and public codes, and we need to be able to attest the public code. We can't actually provide all of it as a single piece. We actually have to go and split them, or either split them in general, or have only open source parts in one chunk, but then load the private parts. We can't provide all of it at once. One of the solutions is just the docker compose format, or kubernetes like Yamla, some kind of definition like that, where all of those. All of those pieces are simply containers. That would probably be the nicest ux we can go for.
01:43:58.470 - 01:44:02.854, Speaker B: Hey, Mataj, by the way, we can't see yours. I think your screen is either frozen or.
01:44:02.982 - 01:44:15.670, Speaker A: Sorry. Yeah, I'm not yet doing anything, but yeah, initial idea is to provide all the pieces here. I think you can see it now, right?
01:44:18.330 - 01:44:19.110, Speaker B: Yes.
01:44:20.370 - 01:45:36.070, Speaker A: Let's go. So all those boxes could be containers, right? And also the cost source parts. And I think that's like the intuition will suggest that this is a way to preserve the UX that people are used to. And it does compose nicely with our optional services that we can provide, like the service there's already built in. The format is very well known and understood how you mount storage. Right. And how you request specific kinds of storage so you can use the format very nicely.
01:45:36.070 - 01:46:05.520, Speaker A: And I think that's it. Really. And then, yeah, we go and run those, you know, we have a. Okay, how do. How do we run this? So you get a bunch of containers from the users, right? Like Dmarc. Go and build all those containers, right. You put them into like a YAML or like a compose file.
01:46:05.520 - 01:46:35.070, Speaker A: And what do we do with that? Right now is the question. Okay, so let's think about it for a sec. What are the ideas? How can we, you know, we get a set of containers, right? How do we go and run it?
01:46:46.480 - 01:46:47.980, Speaker B: We have a set of containers.
01:46:51.440 - 01:46:53.420, Speaker A: So one way to do it.
01:46:55.360 - 01:47:06.820, Speaker B: Oh, no, I was going to say, I mean, this is quite a complicated. If these are all containers, then it's a pretty complicated setup. We need some type of like container orchestration.
01:47:08.440 - 01:47:47.004, Speaker A: It doesn't. Orchestration. Right. So we need orchestrator, basically. Okay. We need both an orchestrator and a hypervisor or a supervisor, like whichever you want to call. Are you saying this is like a split between a template and like an application specified thing? Like, I'm wondering if you're imagining a docker compose just for defining somehow the proprietary red bits and all of the other things in the VM are, I don't know, part of a higher level, already provided template.
01:47:47.004 - 01:48:17.522, Speaker A: Everything else in the container system. Yeah, I think actually of all of those boxes here as provided in this. Yeah, I guess you can call it template. And then you specify the boxes and custom. You specify which ones, which boxes you want, right. Like the ski service we know, and this proxy, like we know, but you give us, you know, the batch validation, the summitter and the matching engine. Right.
01:48:17.522 - 01:48:42.476, Speaker A: And the validator and specify that the matching engine and the validator should actually be sandboxed. Right. And then there goes the definition of the sandbox. Right. This is how you want it sandboxed. Hopefully it's clear. And hopefully it works because, you know, it can be clear about speaking nonsense, of course, but yeah.
01:48:42.476 - 01:49:34.274, Speaker A: Anyway, so this set of containers, right, and configuration, right. Template is sent to some kind of orchestrator. It's actually both a orchestrator and a hypervisor. And also it also works in the t. Right. So that's the important, that's how I can see this work. So this is the TBM is now exactly bigger.
01:49:34.274 - 01:50:32.780, Speaker A: And orchestrator and the hypervisor actually run inside the t and they will go and run those boxes for you. That's how I can see this. And if you think about it, this should work, including the sandboxes. Because we have the hypervisor here, we can define the rules for how each of those containers, what devices do they have access to? Can they establish connections? We have the firewalls, the IP tables. So we can do some fine grained network sandboxing too, and not just prevent anything from leaking out, but have slightly more details, control. And I think that's kind of it, right. And then the orchestrator can just go and run all those containers as specified.
01:50:32.780 - 01:51:06.618, Speaker A: And this is kind of a soft, like, we know how to do this. Right. We have explored the running like docker images and like podman and some other containerization inside in particular. So we know that we can do this in practice. And. Yeah, and we would be providing you all the services that you'd want. So the standard services, like your app wants a key and a key that only this TDX or this team has access to will provide that to you.
01:51:06.618 - 01:52:03.132, Speaker A: Right. You can just say in your local compose that you want our key management container to run, and we'll make sure that it runs for you or that you want like a node. Right. Those are kind of standard building blocks. Yeah. So Dimars, if as a part of your app development, you are supposed to give us, or give me a docker compose file, and those services that are app specific. So the API server, the batch validation, the order book service and validation matching, and define the connections between those containers, which container writes to which container and update to it, would that be fine for you? Right.
01:52:03.132 - 01:52:04.620, Speaker A: Like a decent ux?
01:52:06.920 - 01:52:09.060, Speaker B: I think that would be a great ux, yeah.
01:52:10.640 - 01:52:11.500, Speaker A: All right.
01:52:12.280 - 01:52:20.140, Speaker B: I mean, that sort of mirrors what I need to do today. Right. When I have a sort of a complex set of services that need to be deployed.
01:52:23.080 - 01:52:38.548, Speaker A: Right. I think that would be ideal. Right. If we can make this work. So there's actually a couple of issues here we need to pass. The private code has to be passed in trustlessly. You don't want to push your private container into Docker hub.
01:52:38.548 - 01:52:39.280, Speaker A: Right.
01:52:39.900 - 01:52:40.640, Speaker B: Right.
01:52:51.540 - 01:53:31.510, Speaker A: So we need some way to encrypt the containers in such a way that only the orchestrator can, you know, decrypt them. That's one thing. And this will be the fun part. We need to win transit stations. We need attestations such that this array, TL's proxy when it passes attestation. Right. You can actually verify not only the top level tevm, which is the orchestrator, but also all the containers that run.
01:53:31.510 - 01:54:21.340, Speaker A: Right. And give me a sec. And this session of trivial, it does work. You can get the containers inside a tevm. So those little boxes, they have access to attestations. You can actually produce attestation reports from those, but it's not trivial to show that the attestation that they get is enough for you. So there's some way to go and research this somewhere.
01:54:21.340 - 01:54:26.380, Speaker A: What are the issues do we see here?
01:54:29.280 - 01:54:33.460, Speaker B: I mean, there's always the question of performance. So how performance is this?
01:54:36.200 - 01:55:10.160, Speaker A: Yeah, so this is tricky. So we can use nested vms and the containers inside the TVM should actually be relatively performant, especially if we enable KVM support inside. And we could in theory. I'm not sure if you can allow hardware. Yeah, like access to the KVM module. I'm not sure if you can. I'm not sure if we can provide access to the KVM module from the private code.
01:55:10.160 - 01:55:35.806, Speaker A: So can we accelerate, you know, do hardware acceleration of the private code because we are giving access to like a raw device. Right. And we don't know what the people are going to do with it. So it could be unsafe. I'm not actually sure. Yeah, hopefully you can. Well, but the open source ones should actually be like very performant, especially in TDX.
01:55:35.806 - 01:56:03.330, Speaker A: Right. If you're talking about SGX instead of TDX, then those of course cannot be containers. They have to be like either wasm or like EVM contracts something like that rather than falling containers, which of course the UX is worse, but should still kind of work. Yeah. There will be huge issues with the chain nodes, of course, with SGX because they're huge and it's very difficult to run them.
01:56:04.750 - 01:56:05.530, Speaker B: Yes.
01:56:31.200 - 01:57:12.572, Speaker A: All right, so that's just some questions of course not it. Not all of it. Yeah. And like, who controls, you know, who controls the orchestrate? Right. How do we make sure that all the containers run? I don't think it's trivial. Hopefully it is, but. All right, lots of questions still here, but yeah, Davex would be nice.
01:57:12.572 - 01:57:17.764, Speaker A: And we're almost at an end, so I'll pause and.
01:57:17.812 - 01:57:18.260, Speaker B: Yeah.
01:57:18.380 - 01:57:19.480, Speaker A: Any questions?
01:57:20.750 - 01:57:23.450, Speaker B: Only question for me next session. Are we coding it?
01:57:25.190 - 01:57:42.290, Speaker A: Hopefully. Like, hopefully you code that and we have the framework, but yeah, this will take some time. Okay. I mean, technically we are doing it right now, so. Yeah, most built alpha.
01:57:47.100 - 01:57:49.444, Speaker B: We're not building a dark pool is just to clarify.
01:57:49.492 - 01:57:51.188, Speaker A: No, no. Yes.
01:57:51.244 - 01:58:02.920, Speaker B: Okay. I mean, let's go to the dark pool part. If anyone is listening to this and wants to provide a dark pool codebase based on this that we can use, please let us know.
01:58:05.020 - 01:58:19.828, Speaker A: Absolutely. And we are building bits and parts and bits of this solution already. We have some other. Some other products that we built very specific things for, like this. You know, this TL's proxy. Right. We are building it for like a different product.
01:58:19.828 - 01:58:48.726, Speaker A: And the key service we, of course, have made for the original MVM. Right. So we have. We have bits and pieces here and there, but connecting them will take something. All right. Okay, I think that's it. So, Fred Einstein, do you want to take over? Yes.
01:58:48.726 - 01:59:07.032, Speaker A: Can you guys hear me? I had to recharge my phones, headphones. Cool. Awesome. Thank you guys so much. This was very interesting. This was the fifth session on flashwares planning many more. So keep an eye on the forum collective, flashpots.
01:59:07.032 - 01:59:20.000, Speaker A: Net, and if you're logged in at the forum, you're able to watch this tag and be notified whenever there's new posts and new sessions planned. So thank you all so much.

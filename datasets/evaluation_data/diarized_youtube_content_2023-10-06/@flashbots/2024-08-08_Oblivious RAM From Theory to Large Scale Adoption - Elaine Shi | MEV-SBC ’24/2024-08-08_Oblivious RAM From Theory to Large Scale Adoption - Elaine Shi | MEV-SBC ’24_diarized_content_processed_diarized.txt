00:00:03.120 - 00:00:45.320, Speaker A: So I'm very excited to be here today. I will talk about the story of Oram and how it evolved from theory to large scale deployment. So I actually, I co founded a small startup company. We are called oblivious labs, and we are developing open source for oblivious algorithms. And basically, if you are interested, you may want to take a look at our GitHub open source project. This is our logo. It's like the lock is like o and this is ol labs, right, the o and with the l inside, but it's also a lock, so it's very secure.
00:00:45.320 - 00:01:30.254, Speaker A: Okay, so first I will tell you what Oram is. Maybe many of you are already familiar with Oram, but for those who aren't familiar, don't worry, I will tell you what Oram is, and in fact I will motivate Oram. With the non blockchain example, I will actually talk about signals deployment, and then we will try to construct an Oram scheme together. It turns out Oram schemes, they are not heavyweight crypto, they're just simple data structures. Hopefully I can explain to you exactly how Oram works in a short talk. And at the very end I will talk about some more applications and what our company has been working on. Okay, so let's see why signal wants Oram.
00:01:30.254 - 00:02:10.500, Speaker A: So signal is this encrypted messenger app. So if you install signal, signal will ask you to upload your address book and with the goal of finding your friends. So basically, let's say Andrew uploads his address book and signal finds out his friends and connects Andrew with his friends. But the problem is, you might be worried about the secrecy of your contacts, so you may not want to share it with the server. Ok, so as we know, signal wants to offer privacy. And here's a strongman solution. How does it work? Imagine the signal server has some trusted hardware, like Intel SGX.
00:02:10.500 - 00:02:34.472, Speaker A: And this trusted hardware is going to create a hardware sandbox. Everything is encrypted. Like your query, the answers, they're all encrypted. The data stored on disk is also encrypted. And the only place where things get decrypted is inside the software enclave. Because inside the sandbox there is a secret key. You can decrypt things, you can compute on them, you can compute the answers.
00:02:34.472 - 00:03:13.008, Speaker A: So it may seem like this gives you all the security you need because it protects the data contents. But actually if you think about it a little bit more, for this particular application, if you only encrypt really there is very little privacy. And the reason is because if the server can observe which records are being fetched. The server is hosting this large encrypted database on disk. The enclave has very small memory. When the enclave wants to fetch some friends entry from this large database, it needs to contact the operating system. So it will tell the operating system, hey, go get this page for me.
00:03:13.008 - 00:03:39.860, Speaker A: Which means the server can directly observe which memory pages or which records are being fetched. And this leaks precisely who your friends are. The point being that if you only encrypt for this kind of application, there is very little privacy. And this is the reason why you may want Orm. So I'll tell you how Oram works, what Orm does, and how Oram works later. But actually here's another. This is a blockchain example.
00:03:39.860 - 00:04:16.450, Speaker A: So let's look at flashbots use case. So as you may be aware, in blockchains a big problem is called minor extractable value, or mev. And this is also why you are here today. And we want to build something called private order flow. Meaning ideally when you submit our transactions, the block builders, the intermediaries, they cannot see the transactions until the block is built. So imagine a pipeline like this. The users will encrypt their transactions and let's say on the block builder, they're running hardware enclave, or tee.
00:04:16.450 - 00:04:51.810, Speaker A: So all the transactions will be encrypted and then you are building the blocks inside this SGX secure hardware enclave. The same problem here happens, because when you build a block, you have to execute the smart contracts on the transactions. And as the smart contracts execute, you'll have to access data that lives on the blockchain. Like you may access the crypto asset you are trading, let's say uniswap. You may access the sender and recipient accounts. If you think about it, the locations you access are precisely the kind of information you want to hide. Which means if you only encrypt things.
00:04:51.810 - 00:05:28.596, Speaker A: Also in this case, if you leak all the access patterns, they are basically. Is very little privacy in this application too. Okay, so here we also need Oram. And the question Oram solves is following. So can we probably hide access pattern, but without too much cost? Okay, so let's go back to signal story. The first solution they came up with is just like simple linear scan. So this is a naive solution.
00:05:28.596 - 00:06:02.590, Speaker A: Let's say with every query I will scan the whole database to find the answer. And of course this doesn't leak my intention, because the server cannot see which entry is matched. The drop back being this is hugely expensive signals database has more than 1 billion records. So in some sense, this is kind of silly. I mean, they improved it slightly. They are using batch to linear scan, which means they make a single linear scan and serve a batch of requests. Within this single scan, the overhead is linear, where n is the database size and beta is the batch size.
00:06:02.590 - 00:06:51.976, Speaker A: And because it's so expensive, back then, they needed 500 servers to serve all the load. I mean, we're in 2024 now, but in 2022, signal realized, okay, maybe we don't want to use the linear scan solution. And instead they implemented Oramdeh, and more specifically, they implemented pathoram, which is a scheme that we published back in 2013. So actually, Hilbert, who's in the audience, is also a co author of the journal version of the paper. He helped us improve the proofs. So, with path or Ram from linear overhead, we can get down to log squared overhead. And even though theoretically it's log squared, I want to mention these two logs are not equal.
00:06:51.976 - 00:07:33.990, Speaker A: One of them has base two and the other has a very large base. So the log with a very large base is really like two or three in practice. So really path or ram behaves like log n in practice rather than log n squared. And with path Oram, they cut from 500 servers to six servers, so they save like 100 x in their operating cost. Okay, so at this moment, I hope I've motivated why we need Oramdez, and we can try to together construct an Oram scheme together. And before that, let me just quickly explain what Oram is. So, Oram was first invented by Godric Ostrovsky back in the 1980s.
00:07:33.990 - 00:08:01.360, Speaker A: But back then, the schemes were theoretical. They were not practical at all. So Oram is an algorithmic technique that lets you provably hide access patterns. And the security is as strong as encryption. Basically, nothing is leaked. And behind the scene what is going on is that you are permuting the data blocks in memory and you keep shuffling them as you access the data. So we will see a scheme that solves this problem.
00:08:01.360 - 00:08:53.394, Speaker A: And this is kind of the abstraction. Like, if you think of Oram as a box, the inputs are the logical requests, and every logical request is either I want to read some logical address or I want to write to some logical address, and it will translate each logical request into a bunch of physical axes. Okay, so the overhead is like if, let's say one logical request gets translated, in this case to five physical axes. We say the overhead is five. The security requires that no matter what your logical, the input logical requests are the output. The physical axes should be indistinguishable. Okay, so in other words, by observing the physical axes, you cannot infer anything about the logical requests.
00:08:53.394 - 00:09:32.412, Speaker A: So if you were to implement Oram in enclave, Oram will actually be running inside the enclave. So it's like part of the trusted computing base. Okay, so how do we construct Oramdeze? Um, we can first think about a strongman scheme. Like the most natural idea is we are going to promote all the blocks in memory. And the benefit of this is like, let's say if I want to access logical address nine, then I would end up going to a random location. And because let's say this, the adversary doesn't know this permutation. Like to the adversary, I'm just like accessing random locations.
00:09:32.412 - 00:10:34.952, Speaker A: So it may seem like this gives you some security. Indeed it does give you some kind of security, but unfortunately, what you get is only one time security, meaning that if you access every block only once, then it's fine, it's secure, because every access will just go to a random distinct address. However, in most scenarios, you are not going to access each block only once. Suppose you access the block nine twice, then you are going to go back to the same location twice, and this will leak statistical information, like frequency, co occurrence, and then you can do statistical inference attack. So therefore, if you just permute upfront, then the scheme is not secure for the same reason why deterministic encryption is not secure. You may know that for an encryption scheme to be secure, it has to be randomized, and it's for the same reason. Okay, so the lesson we learned from this strawman attempt is that the blocks have to move around, and in fact they have to move around.
00:10:34.952 - 00:11:08.720, Speaker A: Like once I access a block, I have to move around immediately, because otherwise, if that block stayed in the same place, the next time I access it, I will just go back to the same location and some statistical information is leaked. Like linkable. Some linkability information is leaked. Okay, so basically this is the intuition, and we can keep this intuition in mind as we see the actual construction. So, as I already mentioned to you, the construction is like. It's actually very simple. It's just a binary tree data structure.
00:11:08.720 - 00:11:44.120, Speaker A: Every node in the tree is called a bucket, and a bucket has a finite number of slots. And so for today's talk, you can assume every bucket has four slots. Every bucket can store either real, every slot can either start a real block or a filler block. So a real block is encryption of real data, and the filler block is just encryption of zero. And the filler blocks are there only for security, by the way. Throughout, I will assume all the blocks are encrypted. So the only thing the adversary can see is access patterns.
00:11:44.120 - 00:12:14.366, Speaker A: And whenever you read the block, you are always going to re encrypt it and write it back. If you want to update the block, you just re encrypt the new content. Otherwise, you re encrypt the same content and write it back. So the server cannot see whether the blocks are being updated or not. Like, the server cannot tell whether you are reading the block or you are writing the block. Okay. The most important invariant is that every block is going to be mapped to a random path.
00:12:14.366 - 00:12:41.570, Speaker A: So imagine I have some block x and it's mapped to the blue path. Okay, in the beginning, I will cheat a little bit and assume the cpu starts a large position map that records where each block is. In the end, I will get rid of this position map. So don't worry. If you think the position map is too big, it doesn't fit in the cpu's cache, then just don't worry about it. I'll get rid of it in the end. Now, reading a block is very simple.
00:12:41.570 - 00:13:27.420, Speaker A: If I want to read the block x, I will read the position map, discover that x is on the blue path, and then I'm going to read every location on the blue path. I'm guaranteed to find the block x. So the most interesting thing happens after I read X because as I said, the block has to be relocated immediately after I read it. So how do I relocate it? Most natural idea again is I want to pick a new path and assign x to the new path. So suppose the new path I pick is the green path. So how do I write block x to the green path? This is the tricky part. I mean, of course I have to update the position map to reflect that, but the next thing I want to do is to actually write the block to the green path.
00:13:27.420 - 00:14:04.754, Speaker A: So where on the path can I write it? Can I write it directly into the leaf? Yes or no? Yes. It is dangerous. You are right. Okay, so it sounds dangerous, and it is dangerous. And why is it dangerous? It's because if I write it directly to the leaf, I disclose the choice of the new path. So imagine the next request is for the same block. Then I would end up going back to the green path so the server can see, oh, you wrote something to the green path and now you're accessing it again.
00:14:04.754 - 00:14:39.000, Speaker A: Likely you're accessing the same block. So this is not okay, because this discloses the choice of the path for the same reason you don't want to write to any of these internal nodes, because all of them will leak some partial information about the choice of the new path. So what we want to do is to write it to the green path without leaking. What is my choice of new path. So the only place that is safe is the root bucket. I can always write it into the root. Because the root is on every path, it doesn't disclose what is the choice of the new path.
00:14:39.000 - 00:15:03.360, Speaker A: I mean, of course there is a problem. I cannot keep writing things into the root because it will become full very quickly. I'll deal with that problem. But at this moment, I want to say the security of the scheme. Suppose we don't have the overflow problem. Then the security of the scheme is trivial to prove, because every request, I will just access a random path. And the choice of the path has not been disclosed before.
00:15:03.360 - 00:15:34.100, Speaker A: Right? And the only problem that's left to solve is I cannot keep doing this because the root will become four. So I have to deal with the overflow problem. So in fact, actually, okay, I lied a little bit. There are actually two remaining problems to solve. One is to overcome this overflow problem, and the other is to just remove the position map which I promised you earlier. So let's do them one by one. I will do this really quickly.
00:15:34.100 - 00:16:05.802, Speaker A: The overflow will be solved by a maintenance process called eviction. And the eviction. Basically the goal is to move the blocks towards the leaves to avoid overflow. The question is, how do we design this eviction process? There are two conflicting goals. One is, I don't want to spend too much work. If I spend a lot of work doing the eviction, the cost when amortized to each request will be too high. So I want to keep the cost low.
00:16:05.802 - 00:16:43.302, Speaker A: But on the other hand, I don't want to spend too little work. If I spend too little work, then it's not enough to avoid overflow. Okay, and I will talk about the eviction algorithm of pathoram, which is the algorithm signal deployed. So Pathoram's idea is I will just evict on the read path, the path which I have just read to fetch my block. Because like, I'm touching this path anyway, I might as well do some maintenance work on this path. And how do I evict on this path? I will use the most aggressive eviction strategy possible. Which means.
00:16:43.302 - 00:17:11.630, Speaker A: So imagine I just grabbed the whole path into the enclave, and I will repack the blocks on the path. I will move things as close to the leaves as possible, subject to the path invariant. So that's it. If you put everything together, this is the path o ram path oram algorithm. I mean, except that I still need to get rid of the position map. But this is super easy, because the solution is just one word. It's recursion.
00:17:11.630 - 00:18:00.370, Speaker A: So how do we get rid of the position map? The position map is linear in size, but it's smaller than the original database. So I will basically start the position map in a smaller oram, and then I get a position map of the position map. And then I just keep recursing until the position map is constant size. At this moment, I can start it in my cpu cache. So the depth of the recursion is at most logarithmic, because every time I can shave at least a constant factor, in practice, the step is just two or three. So this is the lock that has a large base, right? So remember I said the overhead is log squared. One of the logs comes from the height of the tree, and the other comes from the recursion and the height of the tree.
00:18:00.370 - 00:18:31.840, Speaker A: That log is like really log base too. But this log has a large base, because in practice, the block size is like four kb. You can pack many position identifiers in the block, and the recursion depth is just like two or three in practice. So basically, this is pathoram. The scheme is extremely simple. 16 lines of pseudocode, even if we count lines like and different, and four, it's so simple you can print it on a t shirt. Okay, just quickly summarize.
00:18:31.840 - 00:19:10.420, Speaker A: This is tree based Oram. Every block is mapped to a random path in the tree. The most important is the block must relocate immediately after I access the block. And importantly, it has to be relocated without revealing the choice of the new path. The security proof is trivial. Like, I didn't talk about the proof, but the most challenging part of the proof is actually analyzing the stochastic process and showing that there is no overflow, except with negligible probability. Okay, so I will just very quickly mention what our company has been working on, and maybe before that.
00:19:10.420 - 00:19:50.618, Speaker A: Let me just quickly mention some of the other applications of Oram in the blockchain space. I quickly mentioned the flashbots use case in the beginning, but Oram can also be used for privacy preserving smart contracts and transactions. We also want to build an oblivious data access layer for blockchain. So this is a database that hosts the blockchain data. But if you are a wallet exchange, you are a relay, you want to access this database, we can completely protect your intentions. Basically, our service will not be able to see which locations you are accessing. Okay, we have an open source release.
00:19:50.618 - 00:20:19.530, Speaker A: If you are interested, you can go to this URL to check it out. I want to mention something about performance. As I said, this is not heavyweight cryptography. It's just a simple binary tree data structure. So the overhead is very, very low. There's almost no overhead. If you are running oram on an ethereum size database, our latency is only like 20 to 50 microseconds.
00:20:19.530 - 00:20:59.118, Speaker A: I stress it's microseconds, not even milliseconds. So this is extremely fast. Yeah. I also want to mention there are many applications that may be latency critical in flashbots use case, because the block builders are going to be running it. So they really actually do care about the latency a lot. So this is why I think with 20 to 50 microseconds, chances are Oram is not the bottleneck, it's other parts of the system. When your SGX is signing, that's on the order of milliseconds, I would guess.
00:20:59.118 - 00:21:46.658, Speaker A: So this is unlikely going to be the bottleneck in the whole system. Our company also wants to build oblivious STL. So right now, the open source release, if you go to the web page, it contains the oblivious key value star, which is the abstraction that signal uses. It's also the same abstraction for most of the blockchain applications. Um, so what's the purpose of the oblivious STL? So oblivious STL is a oblivious counterpart of the standard. You know, maybe if you are familiar with C STL, you can think of it as a oblivious counterpart of that. And the point being that if you want to run some of these common algorithms, like data structures, map set, priority queue, range, query, data structure, you know, sorting, shuffling.
00:21:46.658 - 00:22:46.504, Speaker A: If you want to run common graph algorithms, the best way may not be to take your non private algorithm and compile it directly with Oram. Because oftentimes if you can design customized oblivious algorithms for these tasks, you can save even additional log n factor, so you can be even faster. So the point of the oblivious STL is we are going to provide a library with these fast customized oblivious algorithms and just make it available for people to use. So this just got started and there's a lot work remaining to be done. I also want to mention today I really mostly focused on Oram together with trusted hardware. But Oram is not just for trustee hardware, it's also needed for scaling things like multiparty computation and fully homomorphic encryption to big data. So today when we talk about multiparty computation and fhe, these primitives are used for small data.
00:22:46.504 - 00:23:37.866, Speaker A: And the reason being if you want to access some memory location, like with MPC and FHE, you would build a circuit to implement this memory access. And the cost is linear. Like essentially you are making a linear scan in the circuit and this is not going to go very far, right? Like as I told you, like with signal, they cannot even afford to make a linear scan in clear text, but this is like making a linear scan of inside the FHE and MPC. So if you want to get rid of this linear memory access overhead, it's the same. You need to have Oram based MPC and Oram based fhe. So in the medium term, we also want to build practical techniques for like Oram based MPC and FHE. And we want to develop programming language techniques to help the help programmers develop oblivious algorithms.
00:23:37.866 - 00:24:36.034, Speaker A: Like for instance, we can use compilers and type system to not only help us make sure our implementations are indeed oblivious programmatically, but we can also make optimizing compilers that take a look at your source code and the compiler can intelligently figure out, oh, you know, for this part of the code you need OrAm, but for this other part of the code, your accesses are safe to reveal. So you don't need Oram for like know these arrays. Okay, so this is our company's vision and agenda. So just to wrap up, do you need an Oram? If you are doing encrypted computation on big data, chances are no matter with trusted hardware or MPC, chances are you need oram. And if you come to Pittsburgh, you'll notice that in many of the coffee shops they carry this oram donut. It's delicious. So if you come to Pittsburgh, I will buy you an oram.
00:24:36.034 - 00:25:03.250, Speaker A: Thank you. Yeah, this is a quick plug. Like, I have some lecture notes on oblivious computation and private information retrieval. And again, this is like our company's open source repository. Thank you. Any questions? We can take about two. I won't go on the recording if you.
00:25:04.270 - 00:25:17.930, Speaker B: Maybe that's better. Hi professor, thanks for the talk. I was just curious, what determines the size of the blocks in your tree structure? Is that just the size of a memory page, or.
00:25:19.870 - 00:25:50.536, Speaker A: Are you asking what is a block? Yeah, I guess block is like, I'm assuming block is the atomic unit of access. So for the case of SGX, indeed it is a memory page. I mean, from the perspective, like if you are worried about the operating system. Basically you are fetching. Whenever you need to do a page swap, you need to go to the operating system and say, oh hey, give me this page there. The block size is the page size. It's like four kb.
00:25:50.688 - 00:26:32.620, Speaker B: Okay, thank you. And then an unrelated question, but since I have the mic, I understand this probably doesn't apply to the MPC fhe case necessarily, but at least in the tee case, there's this alternative approach you can take where the access patterns themselves do reveal information, but you try to block all the channels through which the access patterns leak. So if you prevent, if you have a te structure where the operating system or untrusted code doesn't have access to the access patterns, and maybe you protect the memory bus if you want physical attackers to be protected against as well. Do you think that's a reasonable approach? I guess more on the hardware level.
00:26:34.240 - 00:27:27.560, Speaker A: I think this would require a change to the underlying architecture because today if your data is living on disk and if you want to fetch the data from disk to memory, you need to make a page swap and the operating system needs to help you with that. If you modify the underlying architecture, it might be possible to like, I mean one way is like for instance, intel could just implement ORAm in their cpu and then the software doesn't have to worry about it. And actually this is exactly why people were interested in Oram in the first place. Like back in the 1980s when architects were designing secure processors. Today's Intel SGX in the research community, it was first being researched in 1980s. And back then when they were designing the secure processes, they actually wanted Oram. It's just like there was no scheme practical, so they knowingly left it as a leaky channel.
00:27:27.560 - 00:27:42.406, Speaker A: But actually a group at MIT, Sweeney David and his students, they actually taped out a secure process around OrAm inside the cpu. So in this case you don't need to do it at the software level. It's like done in the hardware itself.
00:27:42.558 - 00:27:43.510, Speaker B: Okay, thank you.
00:27:43.630 - 00:27:46.370, Speaker A: Maybe what you mean by like a protected memory bus?
00:27:47.430 - 00:27:53.038, Speaker B: Yeah, I guess there's multiple ways of protecting a memory bus, right. But yeah, that answers my question. Thank you.
00:27:53.134 - 00:27:53.670, Speaker A: Thank you. Yeah.

00:00:09.050 - 00:00:28.678, Speaker A: Hi, everyone. Hope you're having a nice afternoon. I'm Christopher. I previously worked on IBC for the Cosmos project writ large. Now I work on Enoma. I'm going to talk a little about using distributed key generation and threshold decryption system for some notion of fair order. And I'll talk about what that notion is and whether it might be a notion you want or not.
00:00:28.678 - 00:01:31.900, Speaker A: And I'm just going to sketch some early thoughts on crosschain mev. And given that we've seen a lot of practical experimentation with single chain mev because there are a few really popular blockchains like ethereum and the crosschain design space is very nascent, can we use some of that information about how the economics of markets evolve to try and design crosschain mev systems that work? Or are they probably not going to work? So one disclaimer before I start here. I am pretty new to the mev discourse. Of course I worked on Cosmos, but Cosmos does not have some cost of sophistication must be reached before mev is worth extracting. So even if cross chain mev is possible in principle, I don't think we've seen a lot of it yet, at least in that ecosystem. And there's some sort of terminological mapping to do, which I will try to do as best I can, but some discourses remain slightly diverged. Also, a big thank you to Niketa and Alejo and I hope that I'm pronouncing those names right and Justin Drake for discussions over the past few days, which have been very helpful to me.
00:01:31.900 - 00:02:31.686, Speaker A: So I think an interesting research question that one might want to approach when one is kind of designing architecture from scratch is what kinds of MEB are possible and which kinds can be motivated in principle, like developing a sort of taxonomy that is general. And if you want to develop a taxonomy that is general, you have to reason about it on the basis of sort of information theory. Like what are the agents, when are they making decisions, when are there different events where different agents have different information? And if you derive a kind of structure in that framework, then you can be pretty confident that it's not dependent on specific properties of some particular system. So a very simple information theory taxonomy of mev that I was coming up with a few people and tried to put in a diagram is that we have kind of two two systems. We're just going to call them information systems. One of these systems is the ledger, the blockchain that advances in this kind of quantized time step there's like block one, block two, block three, block four, blah, blah, blah. Maybe it's dag, but still quantized.
00:02:31.686 - 00:03:21.654, Speaker A: Then we have the world, which is like everything else. So cross domain mev problems are kind of the other domain is the world, right? But the world also includes other things which you could consider are like things happening in nature that you might use to inform hedge fund trading decisions, right? Those are also part of the world in the general sense. And the world advances in something we'll just call real time. Of course, there is no such thing, but probably close enough for approximation. Then broadly, we have two classes of actors. We have transaction authors who are, like, crafting a transaction which may do something which they care about related to the blockchain state, may take that state as input, may take prior state as input, or may depend on the state at the time when the transaction is executed. Then there are transaction orders or groupers.
00:03:21.654 - 00:04:04.550, Speaker A: These might be like you can split this role apart or not, but someone has to make the decision or you do everything in batches and then there's no order within the batches but still order across the blocks. Variously, these orders or groupers are called proposers. Now, in, say, a system like Tendermint, the block proposer chooses the order of the transactions. And historically, in most blockchains Ethereum, Bitcoin, the miner chooses the order of the transactions, right? But in sort of like the flashbot style architecture, these roles are more split. So, like in the Proposer builder separation architecture, proposers builders and Sequencers are all separate. So they're like three different nominally three different roles which could, might or might not be performed by the same sort of real world entity. But either way, there's a difference here in events.
00:04:04.550 - 00:04:45.874, Speaker A: So the first event is this transaction authorship where the author of the transaction has access to the states which they can read at that time, so they have access to the blockchain state. It's this particular block which they can currently see. Maybe they're using a light client, they can see which blocks have been finalized and they have access to the world state at whatever the current time in the world is. Then that happens first. And the second event is this event of transaction ordering and block creation which might be split into sub events. Whoever, however, is doing the ordering, if there is ordering, even just like choosing which block to put a transaction in, in a batch system has access to more information about blockchain state. So they have like, maybe some blocks have passed since the transactions authored.
00:04:45.874 - 00:05:29.798, Speaker A: That's some information they could have, but they definitely have a set of possible transactions to include and possible orders for those transactions. The order also has access to more information about the world state because time has passed. So this is like kind of the cross domain mev problem at large. Then you can think of mev as the information asymmetry between these choices, between the user who is choosing to author that transaction at the first time and the decision maker, or possibly multiple decision makers who are deciding to order transactions and put them into blocks at the second time. So if you try and diagram this in an extremely simplified fashion where arrows are information flow. So someone in blue blue diamond is choosing to author a transaction. They have information about the world at this we'll call this time T equals I.
00:05:29.798 - 00:06:33.594, Speaker A: They have information about block one on the ledger. Then that transaction along with a bunch more transactions and more information about the state of the world is available to the Blob of either singular or many entities who are sequencing transactions and creating blocks. And some blocks may or may not have passed on the ledger. In this particular diagram, I said some blocks have passed but you could also tie transactions to specific blocks and maybe there's just more transactions and more info about the world. So from this taxonomy we can kind of characterize like what are the different aspects of mev that we could aim to reduce and how would we have to go about doing it? So one question that might arise is can we reduce the information asymmetry about the blockchain state? And this is maybe the easy problem because there are ways we could reduce this by requiring ordering decisions to be made without information about transactions contents. So our approach falls into this category with threshold decryption. I think a project earlier today called Shutter Network is doing something like quite similar with threshold decryption but for roll ups instead of L1s.
00:06:33.594 - 00:07:27.660, Speaker A: But it's sort of the information theoretic structure of the problem seems to me to be the same. Of course, Penumbra is doing something more with batches which Henry explained, so I won't try and re explain it and get it wrong. But the other question, which seems to be much harder to answer and which makes the cross domain problem quite hard is can we reduce the information asymmetry about the world state? Basically the answer is no because time has passed. So if there is more information about the world accessible to the person who's making the ordering decision simply because time has passed, then we can't encrypt the world unless we pull the world into our encryption scheme. So we can try and pull the world into our encryption scheme. That might be what I talk about later, secret hint but we can't really do anything else except we can try and reduce the latency. So the real latency of this does matter, like in terms of number of seconds, if the kind of mev we're concerned about is based on changes in the world state.
00:07:27.660 - 00:08:08.134, Speaker A: So how do we use cryptography to reduce this? First, asymmetry a there are like different I think there's one component of a threshold decryption setup and another component of the settlement setup. And the settlement component, as far as I can tell, is pretty orthogonal. What we just care here about is the ordering component. But we happen to have the sort of vertically integrated system. So the system we've built is a DKG and threshold decryption system set up to work with Tendermint. Tendermint has BFT consensus. It usually is used in combination with a proof of stake system with regular finality two thirds thresholds things you would expect.
00:08:08.134 - 00:09:28.418, Speaker A: So we generate in our system called Fairvio, a threshold key which has the same share distribution as proof of stake, which allows us to do this guaranteed decryption, which is very important. If you use threshold encryption and encrypt all or some of your transactions but don't necessarily have the ability to decrypt, then someone can withhold data or say that they're not able to decrypt things. If somehow there's a misalignment between how you finalize the order and how you decrypt the transactions so that it's possible for you to finalize an order but then not be able to decrypt some of the transactions, you don't want that, right? So for that reason, we need to integrate these systems very tightly. And in the case of the tendermint architecture, in tendermint votes are broadcast around and we include in those votes the decryption shares, such that when you have two thirds votes, which is like a commitment to a block, you also have two thirds decryption shares, which is exactly what you need to decrypt the transactions. So you will atomically either finalize a block and be able to decrypt the transactions or you will not. So this is like poor man's witness encryption, because we don't have witness encryption yet, but we can fake something similar to the model, except that of course, two thirds of the validators could collude and decrypt the information out of bound. So just a basic flow order.
00:09:28.418 - 00:10:02.990, Speaker A: To explain this from a user's perspective, when you author a transaction in the system, you write whatever your transaction is, you encrypt it to the threshold key. The proposer only sees these encrypted transactions. They have to commit to an ordering, or the other entity who's ordering things has to commit to an ordering of encrypted transactions. That block is finalized with that order finalized, and then transactions are threshold decrypted and then executed. So this is not a scheme for transaction privacy. You could separately make parts of transactions private in another way and you could re encrypt them in the scheme and it would be fine. But this scheme does not provide any sort of long term privacy, it only provides temporary privacy.
00:10:02.990 - 00:11:02.254, Speaker A: So this helps with the first information asymmetry in that now the proposer isn't able to search this computational or the ordering decision maker isn't able to search this computational space of which transactions can be combined in which ways and make the state insert their own transaction sandwich things, usual mev stuff. They don't know anything more about it than the transaction author asterisk. And the asterisk is what about gas limits? But just in case you're interested in a system like this, we've implemented it and you can find it on GitHub. So there's one slight problem here, which is that we have limits on what we can pack into blocks and those limits might be based on different resources. They could be based simply on gas. They could be like multidimensional, like you could do multidimensional EIP 1559. But either way, as long as you have limits on what you need to pack into a block, then you need to give the person who is putting things in a block information about what those limits are.
00:11:02.254 - 00:11:51.034, Speaker A: Otherwise they will not be able to ensure that the block has less than whatever the limit is. So these limits, of course, leak information about the contents of transactions. If transactions are doing arbitrary programmable execution, then if you look like identify this specific AMM transaction always costs like 120,362 gas, even if that transaction is threshold encrypted. You have to put the limits in plain text and so that gas amount will pretty clearly identify to someone what the transaction is doing. It's more statistical information to correlate and there's some potential mev there. It's hard to say exactly what it is without specifying a specific case that you're interested in application wise. However, there's a continuum here where you can give up some accuracy in block packing in order to get better privacy and less mev.
00:11:51.034 - 00:12:43.466, Speaker A: In this sense, you can buy quantizing gas. So in Ethereum or most systems right now, gas is very well, not very, but it's moderately quantized in the sense that we have 120,000 gas, 120,000 to one gas. Small changes in if you use an additional EVM opcode in a transaction, it will change the gas costs. But if we make gas less granular by sort of rounding everything up to the nearest multiple of some constant that we choose, like we can round everything up to the nearest 100,000. So we have 100,000 gas, 200,000 gas, 300,000 gas, then we're revealing less information about the contents of the transactions and there's less of an opportunity for mev. Just to note it. You might think that CKPS could help with this problem, but at least directly they don't.
00:12:43.466 - 00:13:35.810, Speaker A: I mean, if you're doing private transactions where you're pinning to a previous state, then you're not leaking information in this way. But if you just use ZKPs to try and prove something about the gas consumption, you still have to reveal what the gas consumption is. And that's the maybe. How do you avoid this? You basically give up the kind of generality here. You have to make all transactions have identical encrypted sizes and execution costs. Even if you're just doing sort of data availability sequencing and you're not executing transactions on chain, if you are ordering on them on chain and they have different sizes and you use this kind of threshold decryption scheme that still reveals something when the order is picking which ones to include. Still, even with gas limits leaking some information, this seems like it's probably better than status quo in terms of mev.
00:13:35.810 - 00:14:38.758, Speaker A: So what do we do about cross domain mev? Let's see here's the diagram right? Cross domain mev. If I go back a few diagrams. Okay, so we have on the bottom of this we have our ledger and on top of this we have our world. And when we have cross domain mev, we're kind of talking about different domains which are like different ledgers and if we don't coordinate anything between those domains it's just like the other domains are part of the world. So then it kind of reduces it to this thing. That problem is of course, if a lot of relevant information is happening in other domains that would cause there to be mev opportunities like price changes on other exchanges on other ledgers that will create a lot of mev here based on the real time which passes that can be exploited on one right? But if we coordinate a bit between the domains, we have more opportunities. So in particular, if we're using this kind of threshold decryption scheme, we can coordinate on not necessarily like exactly who is doing the encryption or decryption, but we can coordinate on when we do it.
00:14:38.758 - 00:15:22.494, Speaker A: So if we look at, let's say a cross domain system of three ledgers and we have transactions being created, then we have some kind of shared deadline and some interval between a deadline and a shared decryption. So all of the ledgers have to agree. One way of agreeing is to use timestamps like real world timestamps and hope that those are measured correctly. But you could do like send messages between the ledgers but that's more complicated and introduces some liveness assumptions. So maybe in practice a reasonable way to coordinate is just by using timestamps. Then if you require that in order to be included, all of the transactions must be created by this particular deadline they're encrypted. They're, like all of the ledgers, commit to ordering them in a particular fashion.
00:15:22.494 - 00:16:24.546, Speaker A: Then after some slight interval they're all decrypted and executed. Then you get similar properties, at least in the sense of transactions on one ledger, not immediately creating mev opportunities on another ledger. The nice thing about this approach is that we don't need to agree on the specific encryption scheme or key set or data availability layer or execution layer. We just need to agree on the fact that we're doing threshold decryption and we need to agree on the clock. What this does not solve is cross domain message passing mev I E cross chain DEXes might not work, which is that if you are making state changes on one chain and those cause messages to be issued to another chain and those messages like reveal information, then you can threshold decrypt them all you want. As soon as you decrypt the messages which are going to be sent to another chain, that creates the mev opportunity and there will be some competition to fill it in the next round or so to speak. One saving, not exactly saving grace, but interesting corollary that at least I've come to in thinking about this is that this problem just has nothing to do with security unless your bridges fail.
00:16:24.546 - 00:17:01.714, Speaker A: If your bridges fail, then life sucks. But that's not really an mev problem unless mev is making it more profitable to bribe people who are doing your bridges or something. So you have to reason about that. But mostly this is a concurrency problem and if you have a single chain with different roll ups on a data availability layer, you have exactly the same problem with cross roll up messaging and you will face the same design constraints. Yeah, it doesn't seem like there's really anything can be done about that can be done about world mev. Luckily, physical change is slow if you're looking at processes occurring in nature and something from 1 second to the next. Changes in ways that would radically change.
00:17:01.714 - 00:17:36.746, Speaker A: Like the price of an asset that would be concerning, maybe, or create mev opportunities. But it's not clear what those changes might be to me, at least I'm interested in if anyone has ideas. Also another corollary is that real world latency matters. Like if there is world mev, the actual latency from when you submit the transaction to when the decisioning about ordering is made really matters. Like if there's more latency, there's more MVP. The last thing I would say is that at least in the last few days I have become aware of many projects which we're doing. For example, Shutter and Penumbra which were thinking about very similar problems from slightly different angles.
00:17:36.746 - 00:17:50.100, Speaker A: And it seems like there are lots of places where we can, if not standardize everything, at least standardize modular components. And we would love to help out with this in any way that we can. If you have questions, please hit me up on Twitter, email or in person. Thanks.
00:18:09.330 - 00:18:26.580, Speaker B: Hey, so I guess from what I understand correctly, the big problem is just finding a reference point, right? Like a reference time for all of this to match. So it's like finding a proof of history, is that correct?
00:18:29.050 - 00:18:56.586, Speaker A: Yeah, I guess in some sense what you're doing when you send your Unix timestamp to the blockchain is like proof of history. Of course it's not. That's like a consensus oracle usually for what time it is and you measure that by your crystal in your computer. So in that sense, yeah, history, that's like the coordination involved. Was that your question or no? Yeah. Okay. I mean the essential part here is coordinating.
00:18:56.586 - 00:19:00.910, Speaker A: Like when information is available to whom. And for that you need some shared clock.
00:19:08.390 - 00:19:27.734, Speaker C: You had mentioned this thing about the amount of gas that it takes to use an AMM, but that's really just like a portion of information that doesn't necessarily tell you which pool or which tokens you're using. Is it such a big problem or just something to be wary of?
00:19:27.932 - 00:20:05.920, Speaker A: Maybe it's not. I think it depends on you have to model the adversary and if the adversary has other information. Like they have information about timing or they have information about data out in the world and they can correlate that information with the information of the gas limit of your transaction. Maybe they can be more likely to be able to guess what's in it. But you can trade off packing efficiency and privacy by having a less granular gas limit. So there's some control there you can apply to maybe make it not very profitable to attempt to do that. Thank you.
00:20:05.920 - 00:20:20.980, Speaker A: Thank I think I think Clipping close.

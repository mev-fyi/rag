00:00:02.280 - 00:00:46.670, Speaker A: Welcome to the last talk of the day. The title of the talk is using tes without trusting them. It's a clickbait. If you use te, you're going to trust them somehow. So what I meant is, how do you use te without trusting them completely? Okay, so what do I mean by that? Just a quick reminder. What is a tee? Te stands for trusted execution environment. It's an isolated execution environment that protects the integrity and confidentiality of a piece of program, in the end, data right from other software and hardware.
00:00:46.670 - 00:01:46.820, Speaker A: Popular examples of tes include the Intel SGF PDX and tes from other manufacturers and the open source community as well. So the primary features are integrity and confidentiality, as well as the ability to attest to a third party, remote third party, that it is indeed a piece of code x running a genuine te. And this attestation is buzzed down to a signature via key that is protected by the hardware. So the point of this slide is to say that the integrity and the confidentiality guarantees are not independent. The integrity, the correctness of the attestation stems from the privacy or the confidentiality of the attestation feature. Okay. Okay, these three features make te a pretty powerful.
00:01:46.820 - 00:02:55.338, Speaker A: Oh, is better. Okay, good, good. Okay. All right, so, yeah, so these three features make te a pretty powerful tool. The mental model I'd like to thank te in is to think of it as a trusty third party, but secured by the hardware and having a trusted third party really is a very powerful thing, and it solves a whole bunch of problems that cryptography aims to solve. So there has been a lot of use cases in web3. It's interesting that some of the applications were, came out, you know, five or six years ago, early on when shortly after the release of Ethereum, but recently in the last year also, there's quite a visible rekindled interest in te.
00:02:55.338 - 00:03:50.700, Speaker A: And this time around, I would say there's a lot of legitimately new applications, such as the use of TEs in MEV block builders and others like one time signatures implemented by te account encumbrances, as you have just heard from James. And even web two accounts can be encumbered here. I think just insert a quick link the team encumbered just to drop this draft. How to encumber web two accounts. Okay, so this all sounds good, and well, there's a lot of exciting use cases of tes, but just a small problem. Right. Tees as we know them aren't perfect.
00:03:50.700 - 00:04:45.360, Speaker A: TeSgx fail is both a website and a paper. It's a great resource to learn about all the tags that SGX have fall into. There's more recent works that extend the survey, the scope of the survey to a broader range of tes. So this table is taken from this recent Sok paper. So basically you can see that almost all like widely available tes have had some vulnerabilities and almost all of the vulnerabilities broke the confidentiality guarantee and quite a few of them even broke the integrity. You can see the check on the last column of the table. So that's what we know.
00:04:45.360 - 00:05:37.576, Speaker A: That's the past. So if history tells us anything, then what should we take away from these attacks? I personally want to advocate a pessimistic view here. I personally think tes aren't and likely won't be perfectly secure. And of course nothing will be perfectly secure. But building te seems particularly hard with the tools we have today. Reasons include the strong adversary model, the complexity of the modern architecture, and just the way that Te is developed today, the close to source approach and so on. On the one hand, there's hope.
00:05:37.576 - 00:06:36.750, Speaker A: There has been invaluable efforts towards so called secure by design Tes and or open hardware Tesla but in this talk I want to advocate that we probably should be prepared for Te bridges. And it is a hard technical question and a challenge to be able to systematically hedge against the risk of EE bridges. That's the topic of the talk. The key question of the talk how do we systematically hedge against the risk? How do we think about risk? This is not the first time that this question was asked. There has been, roughly speaking, two schools of thoughts out there. Let me quickly summarize. First approach is to, well, you simply put less trust in TE.
00:06:36.750 - 00:07:32.990, Speaker A: For example, the sealed glass proof paper proposed a model where you trust te only for integrity, not for privacy. This model is somewhat justified by empirical evidences because lesser tax break integrity and more attacks break confidentiality. And the paper shows that even in that relaxed assumption about tes, they are still pretty useful. Essentially, they function as a form of zero knowledge proofs. If ZKP is useful, then TE without any privacy is, roughly speaking, equally useful, assuming there's integrity assumptions. True. So that's trust less.
00:07:32.990 - 00:08:42.530, Speaker A: A second approach is to trust the TE, but keep detecting its failure. The example I can think of is the steam framework. The rough idea is you inject crafted inputs to the TE so that when there's leakage, you can not only detect the leakage, but also use the injected inputs to help you prove the leakage to the public. This allows the upper level applications to handle te failures. I won't get into the details of these works, but in this talk I'm going to present two more ideas from our recent works. Idea number one is an extension of the trust less approach. We find that in certain systems that are vulnerable to denial of service attacks, we could use tes to prevent denial of service attacks.
00:08:42.530 - 00:10:04.348, Speaker A: And the result is you have a system that relies on te only for liveness, not for security. While the second idea I'm going to talk about is essentially leverages the detection of leakage and it placed the incentives so that the attacks are disincentivized using insurance and bug bounties and these economic leverages. Okay, so let me start with the first idea, and if time allows I will talk about the second one as well. Okay, so the idea is we put forth this idea in a paper we call the Zeeknet. It's about making a particular kind of anonymous broadcast protocol called dCNets cheap with what we call distrusted execution environments. DCNets are a protocol, non broadcast protocol. So the purpose of such systems is to allow a group of people to broadcast the messages to each other without revealing the sender's ip addresses.
00:10:04.348 - 00:11:11.340, Speaker A: So it's a privacy preserving communication primitive, it's important by its own, and it's also important component of bigger applications like privacy preserving payments and pretty much any privacy preserving systems that you want to preserve. The network layer identity. How do we build the Dcnet? What are the trade offs in available DCNet systems? Dcnets are attractive for their strong anonymity properties, and in particular they're not vulnerable to traffic analysis like Tor. And they are also attractive for the palatable cost assumptions. Modern decent ads usually are run by a group of servers. Users only need to trust that at least as long as one of the servers on istio enjoying this strong anonymity. So this trust assumption, so called, any trust assumption, is rather palatable.
00:11:11.340 - 00:12:20.296, Speaker A: Okay. The downside of DC nets in general is it's easily dossable by clients. Basically by sending well malformed messages, the client can clobber the broadcaster, channel and prevention of denial of service attack like these can be done with cryptography, but it is usually expensive and involves multiparty computation or zero navy proofs. For that reason, and for other reasons, existing DCNet systems, they are cheap on the client side, but they are expensive to run on the server side. You need beefy machines to run to handle the computation and communication load. The problem is, if it's expensive to run these anonymity servers then there won't be a lot of servers. Remember the any trust assumption says that basically the confidence in the system scales with the number of servers you have.
00:12:20.296 - 00:13:18.580, Speaker A: So if you don't have a lot of servers because they are very expensive, then the anonymity of the system is weakened. That is the motivation why we care about making servers lightweight. So then in zipnet, this system, we did a number of things to make DCNAS server cheap. Here I will highlight the part related to Tes. As I said, the big part of the server computation is to prevent the denial of service or detective service. So our idea is let's put a client code in a tee, okay? So te will run on the client side. So this requires the client to do more work, but te will check the client message and only sign off on it if it's well formed.
00:13:18.580 - 00:14:45.720, Speaker A: Okay, so the nice thing about this setup is what would happen when te is bridged, right? So attacker now will be able to bypass the denial of service prevention mechanism and clobber the communication channel. But happily, message corruption is something that's visible, that can be detected. If you notice that the channel is corrupted, then that means there's observable signal that tes are bridged. And most importantly, even if tes are bridged, the core property anonymity is intact because throughout this process we use te to speed up the denial of service prevention mechanism. We never rely on anonymity because we can tolerate this te failures, some te failures, we don't really need a bulletproof te. So it can be something like SGX, TDX, or even something software based. So the benefit of kind of putting this client side verification in te is firstly to get, you know, has this nice trust assumptions in terms of tes.
00:14:45.720 - 00:15:40.040, Speaker A: The result is a much simplified server algorithm and a much, you know, better performance at the low cost. So the server, according to our evaluation, the server is 42 times faster than state of the art at a fraction of the cost. That's because the server can, we don't need to do the expensive format verification at the server. But the takeaway, I hope, is that the way that we use te in zipneta, we think is a nice framework. When te works, we are in the optimistic path of the system. Everything is well and fast. And when te breaks, it doesn't really harm the core property, which is the enemy here.
00:15:40.040 - 00:16:11.090, Speaker A: And importantly, Te bridges is visible. It's detectable because it clobbered the network. The corruption can be detected and this allows the handling of Te bridges. For example, the protocol can switch to a more expensive cryptographic denial of service prevention mechanisms. Until the te is fixed. This may generalize to other protocols. So, yeah.
00:16:11.090 - 00:16:36.460, Speaker A: All right. So that's the first idea, I think. How much time do I have? Okay. Oh, plenty of time. So, right. So the first idea is just to recap, when you design a system, trust the te for less. In particular, in zipnet, we trust it for liveness.
00:16:36.460 - 00:17:18.734, Speaker A: The nice thing is that we don't rely on it for security. And plus liveness failures in this case can be detected. So these are the benefits of this trust model. So I'm going to now just briefly talk about the second idea, which is to set up incentives to disincentivize side channel attacks. So this idea is put forth in a paper entitled crudity carried approach to side channels. Paper is forthcoming in aft 24. This so called stick and carrot.
00:17:18.734 - 00:18:45.382, Speaker A: The name will, you know, the motivation for the name will become clear shortly. This framework is useful for key management applications in tes, like when you need, when you store a key in the TE, and for example, when you use Te to build this, custodial wallets, or when you apply tees to certificate authorities where you use Te to protect the signing key of the certificate. So what is the key observation? The key observation is when it comes to side channel attacks, there are potentially two types of attackers that can mount side channel attacks. The first type is the service provider that operates and runs the TE. So the service provider, for example, the service provider of some custodial wallet service, is the party that has root access to the t. It's the owner of the cloud account, and therefore they can mount all sorts of side channel attacks because they have root access to the TE. Another class of the attackers are what we call remote attackers or outsider attackers.
00:18:45.382 - 00:19:44.400, Speaker A: These attackers can only access the system through public facing interface, through APIs or web interface. These attackers can also potentially mount remote side channel attacks. But it's going to be a lot harder. So they need more time and the cost to exfiltrate keys. Then what's the observation? The observation is we can deal with different two types of attackers differently. To disincentivize the service provider from attacking the tee, we ask, we force the system, force the service provider to set up insurance that will automatically compensate the users if the keys are leaked. You can envision a smart contract being set up that accepts proofs of leakage that automatically disperse a payment to the users who report a leakage.
00:19:44.400 - 00:21:45.500, Speaker A: The goal of this is so that the service provider, despite being a powerful attacker, does not benefit from the attacks. The second approach, to deal with outsider attackers outside the attacks by outsider attackers are going to be slower so we can apply a bug bounty to incentivize the attackers to kind of stop early. By stop early I mean the attacker will kind of rather not finish an attack, but just give up in the middle and in exchange for a partial rewards for the partial keys that stole out of the system. In the interest of time, I will not go into the details, partly because this, this work will be presented at AFT and I invite you to kind of, you know, keep an eye on the longer version of the presentation. So I will just quickly summarize. So the key question this talk asks is what if we embrace the, you know, the assumption or the view that t is won't be perfectly secure? And how can we then systematically hedge against the te bridges? There are of course security best practices that you should follow, but when you design applications of tes, how can you incorporate these risks? From the get go, I surveyed two ideas, two schools of thoughts, and presented one ideas, one idea in each category. They are trust less and faster, but detect failure, trust until failures detected.
00:21:45.500 - 00:21:53.860, Speaker A: So these are the here are the links to the paper. With that, I will stop here and take any questions.
00:21:58.640 - 00:22:31.080, Speaker B: Hi, thanks for the talk. Fun. I have many questions, so maybe this will go into the break. But my first question is for Intel TDX at least availability is a non goal because hypervisor can, for example, performance, degrade vms to, for example, bypass any mechanism that the TD may take to, for example, I'm understanding this is some sort of heartbeat mechanism to ensure that the TD is executing. Is that a fair assumption?
00:22:31.420 - 00:22:38.960, Speaker A: Right, availability is not. Yeah, it's a non goal or availability is nothing. We don't assume te has availability.
00:22:39.340 - 00:22:44.440, Speaker B: So when you say you're saying liveness is guaranteed, how is that different?
00:22:45.300 - 00:23:25.408, Speaker A: So we trust the TE for liveness. That means that if TE is not bridged and if TE is available, the system has liveness. If TE is bridged, system loses live news equally. If the TE become unavailable, the system also loses livens. So, but the difference, I think the reasons for losing losing live news can be due to malicious activities and benign thoughts, and this can be dealt with in different ways. But the point is that, no, we don't trust te for liveness. We don't rely on it for liveness.
00:23:25.408 - 00:23:36.680, Speaker A: What I meant is if te breaches, only liveness is lost. Maybe there's a bit of tautology going on here. I hope you got what I meant.
00:23:36.980 - 00:23:41.280, Speaker B: So I have a follow up to that. How do you detect when the te has been breached?
00:23:41.620 - 00:24:11.000, Speaker A: Yeah, yeah, that's a good question. So this is the part where such ideas are a little bit application specific. So in the DCNet example, the effect of te getting bridged is to have the channel being clobbered. So you could, when you send the message, you could attach a sort of a checksum, and when the checksum is messed up, that's how you detect the te has been bridged.
00:24:12.860 - 00:24:21.800, Speaker B: So you're saying that there's no way for the te to be breached without some channel being clobbered. Like these are both necessary and sufficient conditions?
00:24:22.580 - 00:24:33.580, Speaker A: Yes, yes, because tes will sign off on the messages, and if the messages is now signed off by tes, it will not be incorporated to the channel.
00:24:35.280 - 00:25:16.680, Speaker B: And then. Are there other questions? But I have one more if there's no one else. So one approach to, I guess, achieving the same guarantees as CES is to essentially invert the trust assumptions. So in tes you do not trust everything but the application. The alternative approach is to trust everything but the application such that the application does not get corrupted. And so technologies like TPM and TXT are ways where you can trust your operating system, your firmware, bios, et cetera. How would you say this would defer in terms of hedging against system breaches? I would say.
00:25:19.980 - 00:25:58.638, Speaker A: That'S a good question. I haven't thought much about it. To me that seems like a difference in the size of the TCB, like how much is, how big is your TCB? But the size is a little bit hard to say because some code are more maybe battle testing than others. I think generally this, at the high level the framework wouldn't change because there still is a concern of bridges, whether in system code or application code, and such frameworks can still apply. But I'd like to think more about this question.
00:25:58.734 - 00:26:00.350, Speaker B: Thank you so much. Of course.
